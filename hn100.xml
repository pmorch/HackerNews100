<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 06 Oct 2023 17:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Unreal Engine will no longer be free for all (107 pts)]]></title>
            <link>https://www.creativebloq.com/news/epic-games-unreal-engine-charge</link>
            <guid>37792030</guid>
            <pubDate>Fri, 06 Oct 2023 15:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.creativebloq.com/news/epic-games-unreal-engine-charge">https://www.creativebloq.com/news/epic-games-unreal-engine-charge</a>, See on <a href="https://news.ycombinator.com/item?id=37792030">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="3SQ7DLX5NJZCHBGUGzFPtk">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.creativebloq.com/news" aria-label="Return to News">News</a>
</li>
<li>
<a href="https://www.creativebloq.com/tag/digital-art" aria-label="Return to Digital Art">Digital Art</a>
</li>
</ol>
</nav>



</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"><source type="image/jpeg" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"><img src="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Epic Games)</span>
</figcaption>
</div>

<div id="article-body">
<p>Bad news for those using <a href="https://www.creativebloq.com/tag/unreal-engine" data-auto-tag-linker="true">Unreal Engine</a> for VFX or animation this week – or at least for some. Epic Games has confirmed that it will begin charging industries outside gaming to use the 3D graphics engine next year.&nbsp;</p><p>Until now the company has not charged directly for use of Unreal Engine. Instead it charges royalties for projects that surpass $1m in revenue – and only those that use code from the engine. That means that while the developers of big-selling games pay royalties, those who use Unreal Engine for film making and other uses pay nothing. Epic Games now plans to start charging subscription fees on a per-seat basis, but it has clarified that not everyone will be affected (also see our pick of the <a href="https://www.creativebloq.com/features/best-free-3d-apps">best 3D apps</a>).</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">Tim Sweeney addresses Epic Games Layoffs... #UnrealFest pic.twitter.com/49t4Tf20SA<a href="https://twitter.com/ImmatureGamerX/status/1709216675730542972" data-url="https://twitter.com/ImmatureGamerX/status/1709216675730542972">October 3, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>Speaking at Unreal Fest 2023, Epic Games CEO Tim Sweeney said Unreal Engine would become “a licensable piece of software like Maya or <a href="https://www.creativebloq.com/tag/photoshop" data-auto-tag-linker="true">Photoshop</a>” with a subscription-based pricing model. Studios using it for non-gaming work like animation, VFX and visualization will be charged through a “seat-based enterprise software licensing model”</p><p>The video above, shared from the event by the creative developer <a href="https://twitter.com/ImmatureGamerX" target="_blank" data-url="https://twitter.com/ImmatureGamerX">Immature on Twitter</a>, shows Sweeney outlining the company’s sources of income, which will include licensing Unreal Engine, in the context of Epic's recent decision to lay off 16% of its staff.</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">Won’t affect. There will be minimum revenue thresholds for commercial projecrs, and student/educator use will remain free.<a href="https://twitter.com/TimSweeneyEpic/status/1709731335147831316" data-url="https://twitter.com/TimSweeneyEpic/status/1709731335147831316">October 5, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>Understandably, the news has caused concern among creatives, especially independent filmmakers and non-professionals. Unreal Engine was developed as a graphics engine for gaming, but is now routinely used for real-time rendering and virtual production in everything from animation, to commercials, including by aspiring filmmakers who may not be able to pay for a subscription.</p><p>Replying to <a href="https://twitter.com/TimSweeneyEpic/status/1709731335147831316" target="_blank" data-url="https://twitter.com/TimSweeneyEpic/status/1709731335147831316">a question raised on X</a>, Sweeney has now clarified that there will be minimum revenue thresholds for commercial projects that have to pay for a subscription and that student and educator use of Unreal Engine will remain free.</p><p>There is no detail as yet on what the threshold will be, but the idea seems to be to charge larger studios and developers. It's also unknown what the Unreal Engine price or terms will look like – Sweeney said pricing would not be "unusually expensive, or unusually inexpensive”. The move will not affect game developers who will continue to pay a 5 per cent royalty rate after revenue passes $1m.</p><p>Sweeney said he was announcing the change ahead of time to ensure transparency. Some have suggested that the move was inevitable, noting that it was unusual that access has remained free. However, others have raised concerns that a subscription model could means some creatives cannot afford to use the tool. "Can you imagine that there are some really good unreal engine users that cannot afford subscription in some countries? Please keep it free to use and monetize results for movie and nongame usage," the producer Mihai Ogasanu wrote.</p><p>In our <a href="https://www.creativebloq.com/reviews/unreal-engine-53">Unreal Engine 5.3 review</a>, we note that Unreal Engine continues to redefine the game engine industry with a new skeletal mesh editor, cloth editor and volumetric capabilities.</p>
</div>
<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/mcasa08ogs1651144853.svg"></p>
<div>
<p><strong><span>Thank you for reading 5 articles this month* Join now for unlimited access</span></strong></p><p><strong><span>Enjoy your first month for just £1 / $1 / €1</span></strong></p>
</div>

<p><span>*Read 5 free articles per month without a subscription</span></p>
</div>


<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/mcasa08ogs1651144853.svg">
</p>
<div>
<p><strong><span>Join now for unlimited access</span></strong></p><p>Try first month for just <strong>£1 / $1 / €1</strong></p>
</div>

</div>



<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Daily design news, reviews, how-tos and more, as picked by the editors.</p></section></div>
<div id="slice-container-authorBio"><p>Joe is a regular freelance journalist and editor at Creative Bloq. He writes news and features, updates buying guides and keeps track of the best equipment for creatives, from monitors to accessories and office supplies. A writer and translator, he also works as a project manager at London and Buenos Aires-based design and branding agency Hermana Creatives, where he manages a team of designers, photographers and video editors who specialise in producing photography, video content, graphic design and collaterals for the hospitality sector. He enjoys photography, particularly nature photography, wellness and he dances Argentine tango.</p></div>


<div>
<h4>Related articles</h4>

</div>
</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making Hard Things Easy (276 pts)]]></title>
            <link>https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/</link>
            <guid>37791002</guid>
            <pubDate>Fri, 06 Oct 2023 14:09:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/">https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/</a>, See on <a href="https://news.ycombinator.com/item?id=37791002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>A few weeks ago I gave a keynote at <a href="https://www.thestrangeloop.com/">Strange Loop</a>
called Making Hard Things Easy. It’s about why I think some things are hard
to learn and ideas for how we can make them easier.</p>

<p>Here’s the video, as well as the slides and a transcript of (roughly) what I
said in the talk.</p>

<h3 id="the-video">the video</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/30YWsGDr8mA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<h3 id="the-transcript">the transcript</h3>



<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-0.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-0.png"></a>
</p>
<p>


Hello, Strange Loop! Strange Loop is one of the first places I
spoke almost 10 years ago and I'm so honored to be back here today for the
last one. Can we have one more round of applause for the organizers?


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-1.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-1.png"></a>
</p>
<div>

<p>
I often give talks about things that I'm excited about,
or that I think are really fun.
</p>

<p>
But today, I want to talk about something that I'm a little bit mad about,
which is that sometimes things that seem like they should be basic take me 10
years or 20 years to learn, way longer than it seems like they should. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-2.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-2.png"></a>
</p>
<p>

One thing that took me a long time to learn was DNS, which is this question
of -- what's the IP address for a domain name like example.com?
This feels like it should be a straightforward thing.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-3.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-3.png"></a>
</p>
<p>

But seven years into learning DNS, I'd be setting up a website. And I'd feel
like things should be working. I thought I understood DNS. But then I'd run
into problems, like my domain name wouldn't work. And I'd wonder -- why not?
What's happening?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-4.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-4.png"></a>
</p>
<div>

<p>
And sometimes this would feel kind of personal! This shouldn't be so hard
for me! I should understand this already. It's been seven years!
</p>


<p>
And this "it's just me" attitude is often encouraged -- when I write about
finding things hard to learn on the Internet, Internet strangers will sometimes
tell me: "yeah, this is easy! You should get it already! Maybe you're just not
very smart!"
</p>

<p>
But luckily I have a pretty big ego so I don't take the internet strangers too
seriously. And I have a lot of patience so I'm willing to keep coming back to a
topic I'm confused about. There were maybe four different things that were
going wrong with DNS in my life and eventually I figured them all out.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-5.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-5.png"></a>
</p>
<div>

<p>
So, hooray! I understood DNS! I win! But then I see some of my friends struggling with
the exact same things.
</p>

<p>
They're wondering, hey, my DNS isn't working. Why not? 
</p>




</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-6.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-6.png"></a>
</p>
<div>
<p>
And it doesn't end. We're still having the same problems over and over and over
again. And it's frustrating! It feels redundant! It makes
me mad. Especially when friends take it personally, and they feel like "hey I
should really understand this already".
</p>

<p>
Because everyone is going through this. From the sounds of recognition I hear,
I think a lot of you have been through some of these same problems with DNS.
</p>
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-7.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-7.png"></a>
</p>
<p>

I got so mad about this that I decided to make it my job. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-8.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-8.png"></a>
</p>
<div>

   <p>
   I started a little publishing company called Wizard Zines where --
   </p>
   
 <p>
 (applause)
 </p>
 
   <p>
   Wow. Where I write about some of these topics and try to demystify them.
   </p>
     
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-9.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-9.png"></a>
</p>
<p>
     Here are a few of the zines I've published. I want to talk today about a
     few of these topics and what makes them so hard and how we can make them
     easier.
     
    
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-10.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-10.png"></a>
</p>
<p>
 We're going to talk about bash, HTTP, SQL, and DNS.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-11.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-11.png"></a>
</p>
<div>


<p>
 For each of them, we're
 going to talk a little bit about:
 </p>
   
 <p>
 a.  what's so hard about it? 
 </p>
   
 <p>
 b. what are some things we can do to make it a little bit easier for each other?
 </p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-12.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-12.png"></a>
</p>
<p>
   Let's start with Bash. 

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-13.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-13.png"></a>
</p>
<p>
What's so hard about it?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-14.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-14.png"></a>
</p>
<p>
So, bash is a programming language, right?
But it's one of the weirdest programming languages that I work
with.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-15.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-15.png"></a>
</p>
<p>

To understand why it's weird, let's do a little small demo
of bash.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-16.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-16.png"></a>
</p>
<div>


<p>
First, let's run this script, <code>bad.sh</code>:
</p>

<pre>mv ./*.txt /tmmpp
echo "success!"
</pre>

   <p>
   This moves a file and prints "success!". And with most of the programming languages that I use, if there's a problem, the program will stop.
   </p>
   
 <p>
 [laughter from audience]
 </p>
 
 <p>
 
     But I think a lot of you know from maybe sad experience that bash does not
     stop, right? It keeps going. And going... and sometimes very bad things
     happen to your computer in the process. 
   </p>
   
 <p>
 When I run this program, here's the output:
 </p>
   
   <pre>mv: cannot stat './*.txt': No such file or directory
success!
</pre>

<p>
It didn't stop after the failed <code>mv</code>.
</p>
     
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-17.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-17.png"></a>
</p>
<div>

<p>
Eventually I learned that you can write <code>set
-e</code> at the top of your program, and that will make bash stop if
there's a problem. 
</p>

<p>
When we run this new program with <code>set -e</code> at the top, here's the output:
</p>

<pre>mv: cannot stat './*.txt': No such file or directory
</pre>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-18.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-18.png"></a>
</p>
<p>
Great. We're happy. Everything is good. But every time I think I've learned
everything that go wrong with bash, I'll find out -- surprise! There are more
bad things that can happen! Let's look at another program as an example.
     
    </p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-19.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-19.png"></a>
</p>
<div>

<p>
Here we've put our code in a function. And if the function
fails, we want to echo "failed". 

</p>

<p>
So use <code>set -e</code> at the beginning, and you might think everything should be okay. 
</p>

<p>
But if we run it... this is the output we get
</p>

<pre>mv: cannot stat './*.txt': No such file or directory
success
</pre>

<p>
We get the "success" message again! It didn't stop, it just kept going. This is
because the "or" (<code>|| echo "failed"</code>) globally disables <code>set -e</code> in the
function.
</p>

<p>
Which is certainly not what I wanted, and not what I would expect. But this is
not a bug in bash, it's is the documented behavior.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-20.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-20.png"></a>
</p>
<div>

<p>
And I think one reason this is tricky is a lot of us don't use bash very often.
Maybe you write a bash script every six months and don't look at it again.
</p>

<p>
When you use a system very infrequently and it's full of a lot of weird trivia
and gotchas, it's hard to use the system correctly.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-21.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-21.png"></a>
</p>
<p>

So how can we make this easier? What can we do about it?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-22.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-22.png"></a>
</p>
<p>
One thing that I sometimes hear is -- a newcomer will say "this is hard",
and someone more experienced will say "Oh, yeah, it's impossible to use bash.
Nobody knows how to use it."



</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-23.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-23.png"></a>
</p>
<div>

<p>
But I would say this is factually untrue. How many of you are using bash?
</p>

<p>
A lot of us ARE using it! And it doesn't always work perfectly, but often
it gets the job done.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-24.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-24.png"></a>
</p>
<p>

We have a lot of bash programs that are mostly working, and there's a big
community of us who are using bash mostly successfully despite all the
problems.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-25.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-25.png"></a>
</p>
<div>

<p>
The way I think this is --  you have some people on the left in this
diagram who are confused about bash, who think it seems awful and
incomprehensible.
</p>

<p>
And some people on the right who know how to make the bash work for them,
mostly.
</p>

<p>
So how do we move people from the left to the right, from being overwhelmed by
a pile of impossible gotchas to being able to mostly use the system correctly?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-26.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-26.png"></a>
</p>
<p>

Well, bash has a giant pile of trivia to remember. But who's good at remembering
giant piles of trivia?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-27.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-27.png"></a>
</p>
<p>

Not me! I can't memorize all of the weird things about bash. But computers!
Computers are great at memorizing trivia!

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-28.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-28.png"></a>
</p>
<div>

<p>
And for bash, we have this incredible tool called
shellcheck.
</p>

<p>
[ Applause ]
</p>

<p>
Yes! Shellcheck is amazing! And shellcheck knows a lot of things that can go
wrong and can tell you "oh no, you don't want to do that. You're going to have
a bad time."
</p>

<p>
I'm very grateful for shellcheck, it makes it much easier for me to write
tiny bash scripts from time to time. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-29.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-29.png"></a>
</p>
<div>

<p>
Now let's do a shellcheck demo! 
</p>

<pre>$ shellcheck -o all bad-again.sh
In bad-again.sh line 7:
f || echo "failed!"
^-- SC2310 (info): This function is invoked in an || condition so set -e will be disabled. Invoke separately if failures should cause the script to exit.
</pre>

<p>
Shellcheck gives us this
lovely error message. The message isn't completely obvious on its own (and this
check is only run if you invoke shellcheck with <code>-o all</code>). But
shellcheck tells you "hey, there's this problem, maybe you should be worried
about that".
</p>

<p>
And I think it's wonderful that all these tips live in this linter. 
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-30.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-30.png"></a>
</p>
<div>

<p>
I'm not trying to tell you to write linters, though I think that some of you
probably will write linters because this is that kind of crowd.
</p>

<p>
I've personally never written a linter, and I'm definitely not going to create
something as cool as shellcheck!
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-31.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-31.png"></a>
</p>
<div>

<p>
But instead, the way I write linters is I tell people about shellcheck from
time to time and then I feel a little like I invented shellcheck for those
people. Because some people didn't know about the tool until I told them about
it!
</p>

<p>
I didn't find out about shellcheck for a long time and I was kind of mad about
it when I found out. I felt like -- excuse me? I could have been using
shellcheck this whole time? I didn't need to remember all of this stuff in
my brain?
</p>

<p>
So I think an incredible thing we can do is to reflect on the tools that we're
using to reduce our cognitive load and all the things that we can't fit into
our minds, and make sure our friends or coworkers know about them.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-32.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-32.png"></a>
</p>
<p>
I also like to warn people about gotchas and some of the terrible things
computers have done to me.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-33.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-33.png"></a>
</p>
<div>

<p>
I think this is an incredibly valuable community service. The example I shared
about how <code>set -e</code> got disabled is something I learned from my
friend Jesse a few weeks ago. 
</p>

<p>
They told me how this thing happened to them, and now I know and I don't have
to go through it personally.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-34.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-34.png"></a>
</p>
<div>

<p>
One way I see people kind of trying to share terrible things that their
computers have done to them is by sharing "best practices".
</p>

<p>
But I really love to hear the stories behind the best practices!
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-35.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-35.png"></a>
</p>
<div>


<p>
If someone has
a strong opinion like "nobody should ever use bash", I want to hear about the
story! What did bash do to you? I need to know.
</p>

<p>
The reason I prefer stories to best practices is if I know the story about how
the bash hurt you, I can take that information and decide for myself how I want
to proceed.
</p>

<p>
Maybe I feel like -- the computer did that to you? That's okay, I can deal with
that problem, I don't mind.
</p>

<p>
Or I might instead feel like "oh no, I'm going to do the best practice you
recommended, because I do not want that thing to happen to me". 
</p>

<p>
These bash stories are a great example of that: my reaction to them is "okay,
I'm going to keep using bash, I'll just use shellcheck and keep my bash scripts
pretty simple". But other people see them and decide "wow, I never want to use
bash for anything, that's awful, I hate it".
</p>

<p>
Different people have different reactions to the same stories and that's okay.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-36.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-36.png"></a>
</p>
<p>
That's all for bash. Next up we're gonna talk about HTTP. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-37.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-37.png"></a>
</p>

</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-38.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-38.png"></a>
</p>
<div>

<p>
I was talking to Marco Rogers at some point, many years ago, and he mentioned
some new developers he was working with were struggling with HTTP.
</p>

<p>
And at first, I was a little confused about this -- I didn't understand what
was hard about HTTP.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-39.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-39.png"></a>
</p>
<div>

<p>
The way I was thinking about it
at the time was that if you have an HTTP response, it has a few parts: a response
code, some headers, and a body.
</p>


<p>
I felt like -- that's a pretty simple structure, what's the problem? But of
course there was a problem, I just couldn't see what it was at first.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-40.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-40.png"></a>
</p>
<div>

<p>
So, I talked to a friend who was newer to HTTP. And they asked "why does it
matter what headers you set?"
</p>

<p>
And I said: "well, the browser..."
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-41.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-41.png"></a>
</p>
<p>
But then I thought... the browser?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-42.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-42.png"></a>
</p>
<p>
the browser?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-43.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-43.png"></a>
</p>
<div>

<p>
The browser!
</p>

<p>
Firefox is 20 million lines of code! It's been
evolving since the '90s. There have been as I understand it, 1 million
changes to the browser security model as people have discovered new and
exciting exploits and the web has become a scarier and scarier place.
</p>

<p>
The browser is really a lot to understand.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-44.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-44.png"></a>
</p>
<div>



<p>
One trick for understanding why a topic is hard is -- if the implementation if the
thing involves 20 million lines of code, maybe that's why people are confused!
</p>

<p>
Though that 20 million lines of code also involves CSS and JS and many other
things that aren't HTTP, but still.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-45.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-45.png"></a>
</p>
<div>

<p>
Once I thought of it in terms of how complex a modern web browser is, it
made so much more sense! Of course newcomers are confused about HTTP if you
have to understand what the browser is doing!
</p>

<p>
Then my problem changed from "why is this hard?" to "how do I explain this at all?"
</p>

<p>
So how do we make it easier? How do we wrap our minds around this 20 million lines
of code?
</p>



</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-46.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-46.png"></a>
</p>
<p>
One way I think about this for HTTP is: here are some of the HTTP request
headers. That's kind of a big list there are 43 headers there.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-47.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-47.png"></a>
</p>
<p>
There are more unofficial headers too.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-48.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-48.png"></a>
</p>
<div>

<p>
My brain does not contain all of those headers, I have no idea what most of
them are.
</p>

<p>
When I think about trying to explain big topics, I think about -- what is
actually in my brain, which only contains a normal human number of things?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-49.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-49.png"></a>
</p>
<div>


<p>
This is <a href="https://wizardzines.com/comics/request-headers/">a comic I drew about HTTP request headers</a>.
You don't have to read the whole thing. This has 15
request headers.
</p>

<p>
I wrote that these are "the most important headers", but what I mean by "most
important" here is that these are the ones that I know about and use. It's a
subjective list.
</p>

<p>
I wrote about 12 words about each one, which I think is approximately the
amount of information about each header that lives in my mind.
</p>

<p>
For example I know that you can set <code>Accept-Encoding</code> to <code>gzip</code>
and then you might get back a compressed response. That's all I know,
and that's usually all I need to know!
</p>

<p>
This very small set of information is working pretty well for me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-50.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-50.png"></a>
</p>
<div>


<p>
The general way I think about this trick is "turn a big list into a small list".
</p>

<p>
Turn the set of EVERY SINGLE THING into just the things I've personally used. I
find it helps a lot.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-51.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-51.png"></a>
</p>
<div>


<p>
Another example of this "turn a big list into a small list" trick is command line arguments.
</p>

<p>
I use a lot of command line tools, the number of arguments they have can be
overwhelming, and I've written about them <a href="https://wizardzines.com/zines/bite-size-command-line/">a fair amount</a> over
the years.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-52.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-52.png"></a>
</p>
<p>
Here are all the flags for grep, from its man page. That's too much! I've been
using grep for 20 years but I don't know what all that stuff is.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-53.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-53.png"></a>
</p>
<div>

<p>
But when I look at the grep man page, this is what I see.
</p>


<p>
I think it's very helpful to newcomers when a more experienced person says
"look, I've been using this system for a while, I know about 7 things about it,
and here's what they are".
</p>

<p>
We're just pruning those lists down to a more human scale. And it can even help
other more experienced people -- often someone else will know a slightly
different set of 7 things from me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-54.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-54.png"></a>
</p>
<div>

<p>
But what about the stuff that doesn't fit in my brain?
</p>

<p>
Because I have a few things about HTTP stored in my brain. But sometimes I need
other information which is hard to remember, like maybe the exact details of
how CORS works.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-55.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-55.png"></a>
</p>
<p>

And so, that's where we come to references. Where do we find the information
that we can't remember?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-56.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-56.png"></a>
</p>
<div>

<p>
I often have trouble finding the right references.
</p>

<p>
For example I've been trying to learn CSS off and on for 20 years. I've made a
lot of progress -- it's going well!
</p>

<p>
But only in the last 2 years or so I learned about this wonderful website called 
<a href="https://css-tricks.com/">CSS Tricks</a>.
</p>

<p>
And I felt kind of mad when I learned about CSS Tricks! Why didn't I know about
this before? It would have helped me!
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-57.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-57.png"></a>
</p>
<div>


<p>
But anyway, I'm happy to know about CSS Tricks now. (though sadly they seem to
have stopped publishing in April after the acquisition, I'm still happy the older posts are there)
</p>

<p>
For HTTP, I think a lot of us use the Mozilla Developer Network. 
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-58.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-58.png"></a>
</p>
<div>


<p>
Another HTTP reference I love is the official RFC, <a href="https://www.rfc-editor.org/rfc/rfc9110">RFC 9110</a> (also
<a href="https://www.rfc-editor.org/rfc/rfc9111">9111</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9112">9112</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9113">9113</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9114">9114</a>)
</p>

<p>
It's a new authoritative reference for HTTP and it was written just last
year, in 2022! They decided to organize all the information really nicely. So if you
want to know exactly what the <code>Connection</code> header does, you can look
it up. 
</p>

<p>
This is not really my top reference. I'm usually on MDN. But I really
appreciate that it's available.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-59.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-59.png"></a>
</p>
<p>
So I love to share my favorite references.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-60.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-60.png"></a>
</p>
<div>

<p>
I do sometimes find it tempting to kind of lie about references. Not on
purpose.
But I'll see something on the internet, and I'll think it's kind of cool, and
tell a friend about. But then my friend might ask me -- "when have you used this?"
And I'll have to admit "oh, never, I just thought it seemed cool".
</p>

<p>
I think it's important to be honest about what the references that I'm actually
using in real life are. Even if maybe the real references I use are a little
"embarrassing", like maybe w3schools or something.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-61.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-61.png"></a>
</p>
<p>

So that's HTTP! Next we're going to talk about SQL.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-62.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-62.png"></a>
</p>
<p>
The case of the mysterious execution order.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-63.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-63.png"></a>
</p>
<div>

<p>
I started thinking about SQL because someone mentioned they're trying to learn
SQL. I get most of my zine ideas that way, one person will make an offhand
comment and I'll decide "ok, I'm going to spend 4 months writing about
that". It's a weird process.
</p>

<p>
So I was wondering -- what's hard about SQL? What gets in the way of trying
to learn that?
</p>

<p>
I want to say that when I'm confused about what's hard about something, that's
a fact about me. It's not usually that the thing is easy, it's that I need to
work on understanding what's hard about it. It's easy to forget when you've
been using something for a while.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-64.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-64.png"></a>
</p>
<p>
So, I was used to reading SQL queries. For example this made up query that tries to
find people who own exactly two cats. It felt straightforward
to me, SELECT,
FROM, WHERE, GROUP BY.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-65.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-65.png"></a>
</p>
<div>

<p>
But then I was talking to a friend about these queries who was new to SQL. And
my friend asked -- what is this doing?
</p>

<p>
I thought, hmm, fair point.
</p>



</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-66.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-66.png"></a>
</p>
<p>
And I think the point my friend was making was that the order that this SQL
query is written in, is not the order that it actually happens in. It happens
in a different order, and it's not immediately obvious what that is.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-67.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-67.png"></a>
</p>
<p>

So how do we make this easier?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-68.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-68.png"></a>
</p>
<div>


<p>
I like to think about: what does the computer do first?
What actually happens first chronologically?
</p>

<p>
Computers actually do live in the same timeline as us. Things happen. Things
happen in an order. So what happens first?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-69.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-69.png"></a>
</p>

</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-70.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-70.png"></a>
</p>
<p>

The way I think about an SQL query is: is you start with a table like
<code>cats</code>.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-71.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-71.png"></a>
</p>
<p>

Then maybe you filter it, you remove some stuff. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-72.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-72.png"></a>
</p>
<p>

Then you make some groups.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-73.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-73.png"></a>
</p>
<p>

Then you filter the groups, remove some of them.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-74.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-74.png"></a>
</p>
<p>

Then you do some
aggregation. There's two things in each group.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-75.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-75.png"></a>
</p>
<p>

And you sort it.

And you
can also limit the results.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-76.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-76.png"></a>
</p>
<div>


<p>
So, that's how I think about SQL. The way a query runs is first
FROM, then WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT.
</p>

<p>
At least conceptually. Real life databases have optimizations and it's more
complicated than that. But this is the mental model that I use most of the time
and it works for me. Everything is in the same order as you write it,
except SELECT is fifth. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-77.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-77.png"></a>
</p>
<p>

I've really gotten a lot out of this trick where you try to tell the
chronological story of what the computer is doing. I want to talk about a
couple other examples.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-78.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-78.png"></a>
</p>
<div>


<p>
One is CORS, in HTTP. 
</p>

<p>
This <a href="https://wizardzines.com/comics/cors/">comic</a> is way too small to read on the slide.
But the idea is if you're making a cross-origin request in your
browser, you can write down every communication that's happening between your
browser and the server, in chronological order.
</p>

<p>
And I think writing down everything in chronological order makes it a lot easier to understand and more concrete.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-79.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-79.png"></a>
</p>
<div>


<p>
"What happens in chronological order?" is a very
straightforward structure, which is what I like about it. "What happens first?"
feels like it should be easy to answer. But it's not!
</p>

<p>
I've found that it's actually very hard to know what our computers is
doing, and it's a really fun question to explore.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-80.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-80.png"></a>
</p>
<div>


<p>
As an example of how this is hard: I wrote a blog post recently called 
<a href="https://jvns.ca/blog/2023/08/03/behind--hello-world/">"Behind Hello World on Linux"</a>. It's about what happens when you run "hello world" on a
Linux computer. I wrote a bunch about it, and I was really happy with it.
</p>

<p>
But after I wrote the post, I thought -- haven't I written about this before? Maybe 10 years ago?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-81.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-81.png"></a>
</p>
<div>

<p>
And sure enough, I'd tried to write <a href="https://jvns.ca/blog/2013/11/29/what-happens-when-you-run-a-unix-program/">
a similar post</a> 10 years before.
</p>

<p>
I think this is really cool. Because the 2013 version of this post was about 6
times shorter. This isn't because Linux is more complicated than it was 10
years ago -- I think everything in the 2023 post was probably also true in
2013. The 2013 post just has a lot less information in it.
</p>

<p>
The reason the 2023 post is longer is that I didn't know what was happening
chronologically on my computer in 2013 very well, and in 2023 I know a lot
more. Maybe in 2033 I'll know even more!
</p>

<p>
I think a lot of us -- like me in 2013 and honestly me now, often don't know
the facts of what's happening on our computers. It's very hard, which is what
makes it such a fun question to try and discuss.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-82.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-82.png"></a>
</p>
<div>



<p>
I think it's cool that all of us
have different knowledge about what is happening chronologically on our
computers and we can all chip in to this conversation.
</p>

<p>
For example when I posted this blog post about Hello World on Linux, some people
mentioned that they had a lot of thoughts about what happens exactly in your
terminal, or more details about the filesystem, or about what's happening
internally in the Python interpreter, or any number of things. You can go
really deep.
</p>

<p>
I think it's just a really fun collaborative question. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-83.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-83.png"></a>
</p>
<div>

<p>
I've seen "what happens chronologically?" work really well as an activity with
coworkers, where you're ask: "when a request comes into this API endpoint we
run, how does that work? What happens?"
</p>

<p>
What I've seen is that someone will understand some part of the system, like "X
happens, then Y happens, then it goes over to the database and I have no idea
how that works".  And then someone else can chime in and say "ah, yes, with the
database A B C happens, but then there's a queue and I don't know about that".
</p>

<p>
I think it's really fun to get together with people who have different
specializations and try to make these little timelines of what the
computers are doing. I've learned a lot from doing that with people.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-84.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-84.png"></a>
</p>
<p>
That's all for SQL.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-85.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-85.png"></a>
</p>
<p>

So, now we've arrived at DNS which is
where we started the talk.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-86.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-86.png"></a>
</p>
<div>



<p>
Even though I struggled with DNS. Once I got figured it out, I felt like "dude,
this is easy!". Even though it just took me 10 years to learn how it
works.
</p>

<p>
But of course, DNS was pretty hard for me to learn. So -- why is that? Why did
it take me so long?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-87.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-87.png"></a>
</p>
<div>


<p>
So, I have a little <a href="https://wizardzines.com/comics/cast-of-characters/">chart</a> here of how I think about DNS.
</p>

<p>
You have your browser on the left. And over on the right there's the authoritative
nameservers, the source of truth of where the DNS records for a domain live. 
</p>

<p>
In the middle, there's a function that you call and a cache.
So you have browser, function, cache, source of truth.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-88.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-88.png"></a>
</p>
<div>

<p>
One problem is that there are a lot of things in this diagram that are
totally hidden from you.
</p>

<p>
The library code that you're using where you make a DNS request -- there are a
lot of different libraries you could be using, and it's not straightforward to figure out which one is being used.
That was the source of some of my confusion.
</p>

<p>
There's a cache which has a bunch of cached data. That's invisible to you, you
can't inspect it easily and you have no control over it. that
</p>

<p>
And there's a conversation between the cache and the source of
truth, these two red arrows which also you can't see at all.
</p>

<p>
So this is kind of tough! How are you supposed to develop an intuition for a
system when it's mostly things that are completely hidden from you? Feels like
a lot to expect.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-89.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-89.png"></a>
</p>
<p>

So, what do we do about this?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-90.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-90.png"></a>
</p>
<div>


<p>
So: let's talk about these red arrows
on the right.
</p>

<p>
We have our cache and then we have the source of truth. This conversation
is normally hidden from you because you often don't control either of these
servers. Usually they're too busy doing high-performance computing to report to
you what they're doing.
</p>

<p>
But I thought: anyone can write an authoritative nameserver!
In particular, I could write one that reports back every single message that it receives to its users.
So, with my friend <a href="https://marieflanagan.com/">Marie</a>, we wrote a little DNS server.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-91.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-91.png"></a>
</p>
<div>

<p>
(demo of <a href="https://messwithdns.net/">messwithdns.net</a>)
</p>

<p>
This is called Mess With DNS. The idea is I have a domain name and you
can do whatever you want with it. We're going to make a DNS record called
<code>strangeloop</code>, and we're going to make a CNAME record pointing at
<code>orange.jvns.ca</code>, which is just a picture of an orange. Because I
like oranges.
</p>

<p>
And then over here, every time a request comes in from a resolver, this will --
this will report back what happened. So, if we click on this link, we can see
-- a Canadian DNS resolver, which is apparently what my browser is configured
to use, is requesting an IPv4 record and an IPv6 record, A and AAAA.
</p><p>


(at this point in the demo everyone in the audience starts visiting the link
and it gets a bit chaotic, it's very funny)

</p></div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-93.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-93.png"></a>
</p>
<p>
So the trick here is to find ways to show people parts of what the computer is
doing that are normally hidden.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-94.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-94.png"></a>
</p>
<div>

<p>
Another great example of showing things that are hidden is this website called <a href="https://float.exposed/0x4d000006">float.exposed</a>
by <a href="https://ciechanow.ski/">Bartosz Ciechanowski</a> who makes a lot of incredible visualizations.
</p>

<p>
So if you look at <a href="https://float.exposed/0x4b800000">this 32-bit
floating point number</a> and click the "up" button on the significand, it'll
show you the next floating point number, which is 2 more. And then as you make
the number bigger and bigger (by increasing the exponent), you can see that the
floating point numbers get further and further apart.
</p>

<p>
Anyway, this is not a talk about floating point. I could do an entire talk
about this site and how we can use it to see how floating point works, but
that's not this talk.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-95.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-95.png"></a>
</p>
<div>

<p>
Another thing that makes DNS confusing is that it's a giant distributed system
-- maybe you're confused because there are 5 million computers involved (really, more!).
Most of which you have no control over, and some
are doing not what they're supposed to do. 
</p>

<p>
So that's another trick for understanding why things are hard, check to see if
there are actually 5 million computers involved.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-96.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-96.png"></a>
</p>
<div>

<p>
So what else is hard about DNS?
</p>

<p>
We've talked about how most of the system is hidden from you, and about how
it's a big distributed system.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-97.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-97.png"></a>
</p>
<p>

One problem I've run into is that the tools are confusing.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-98.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-98.png"></a>
</p>
<div>

<p>
One of the hidden things I talked about was: the resolver has cached data,
right? And you might be curious about whether a certain domain name is cached
or not by your resolver right now.
</p>

<p>
Just to understand what's happening:  am I getting this result because it was
cached? What's the deal?
</p>

<p>

I said this was hidden, but there are a couple of ways to query a resolver to
see what it has cached, and I want to show you one of them.

</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-99.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-99.png"></a>
</p>
<div><p>

The tool I usually use for making DNS queries is called <code>dig</code>, and
it has a flag called <code>+norecurse</code>. You can use it to query a
resolver and ask it to only return results it already has cached.

</p><p>
With <code>dig +norecurse jvns.ca</code>, I'm kind of asking -- how popular is my website? Is it popular enough that someone has visited it in the last 5 minutes?
Because my records are not cached for that long, only for 5 minutes.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-100.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-100.png"></a>
</p>
<div>


<p>
But when I look at this
response, I feel like "please! What is all this?"
</p>

<p>
And when I show newcomers this output, they often respond by saying "wow,
that's complicated, this DNS thing must be really complicated". But really this
is just not a great output format, I think someone just made some relatively
arbitrary choices about how to print this stuff out in the 90s and it's stayed
that way ever since.
</p>

<p>
So a bad output format can mislead newcomers into thinking that something is more complicated than it actually is.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-101.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-101.png"></a>
</p>
<p>

What can we do about confusing output like this?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-102.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-102.png"></a>
</p>
<div>

<p>
One of my favorite tricks, I call eraser eyes.
</p>

<p>
Because when I look at that output, I'm not looking at all of it, I'm just
looking at a few things. My eyes are ignoring the rest of it.
</p>
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-103.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-103.png"></a>
</p>
<div>

<p>
When I look at the output, this is what I see: it says <code>SERVFAIL</code>.
That's the DNS response code.
</p>


<p>
Which as I understand it is a very unintuitive way of it saying, "I do not have
that in my cache". So nobody has asked that resolver about my domain name in
the last 5 minutes, which isn't very surprising.
</p>

<p>
I've learned so much from people doing a little demo of a tool, and showing how
they use it and which parts of the output or UI they pay attention to, and which parts they ignore.
</p>

<p>
Becuase usually we ignore most of what's on our screens!
</p>

<p>
I really love to use <code>dig</code> even though it's a little hairy because
it has a lot of features (I don't know of another DNS debugging that supports this
<code>+norecurse</code> trick), it's everywhere, and it hasn't changed in a
long time. And I know if I learn its weird output format once I can know that
forever. Stability is really valuable to me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-104.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-104.png"></a>
</p>
<p>

So we've talked about these four technologies. Let's talk a little more about
how we can make things easier for each other.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-105.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-105.png"></a>
</p>
<p>



What can we do to move folks from "I really don't get it" to "okay, I can
mostly deal with this, at least 90% of the time, it's fine"? For bash or HTTP or DNS or anything else.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-106.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-106.png"></a>
</p>
<div>


<p>
We've talked about some tricks I use to bring people over, like:
</p>

<ul>
<li> sharing useful tools </li>
<li> sharing references</li>
<li>telling a chronological story of what happens on your computer</li>
<li>turning a big list into a small list of the things you actually use</li>
<li>showing the hidden things</li>
<li>demoing a confusing tool and telling folks which parts I pay attention to</li>
</ul>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-107.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-107.png"></a>
</p>
<div>

<p>

When I practiced this talk, I got some feedback from people saying "julia! I don't
do those things! I don't have a blog, and I'm not going to start one!"

</p>

<p>
And it's true that most people are probably not going to start programming blogs.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-108.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-108.png"></a>
</p>
<p>
But I really don't think you need to have a public presence on the internet to
tell the people around you a little bit about how you use computers and how you
understand them.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-109.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-109.png"></a>
</p>
<div>


<p>
My experience is that a lot of people (who do not have blogs!) have helped me
understand how computers work and have
shared little pieces of their experience with computers with me.
</p>

<p>
I've learned a lot from my friends and my coworkers and honestly a lot of
random strangers on the Internet too. I'm pretty sure some of you here today
have helped me over the years, maybe on Twitter or Mastodon.
</p>

<p>
So I want to talk about some archetypes of helpful people
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-110.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-110.png"></a>
</p>
<div>

<p>
One kind of person who has really helped me is the
grumpy old-timer. I'll say "this is so cool". And they'll reply yes,
however, let me tell you some stories of how this has gone wrong in my life.
</p>


<p>
And those stories have sometimes helped spare me some suffering.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-111.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-111.png"></a>
</p>
<div>

<p>
We have the loud newbie, who asks questions like "wait, how does that work?"
And then everyone else feels relieved -- "oh, thank god. It's not just me."
</p>

<p>
I think it's especially valuable when the person who takes the "loud newbie"
role is actually a pretty senior developer. Because when you're more secure in
your position, it's easier to put yourself out there and say "uh, I don't get
this" because nobody is going to judge you for that and think you're
incompetent.
</p>

<p>
And then other people who feel more like they might be judged for not knowing
something can ride along on your coattails.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-112.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-112.png"></a>
</p>
<div>

<p>
Then we have the bug chronicler. Who decides "ok, that bug. This can never happen again".
</p>

<p>
"I'm gonna make sure we understand what happened. Because I want this to end
now."
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-113.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-113.png"></a>
</p>
<p>

We have the tool builder, whose attitude is more like "I see people struggling
with something, and I don't feel like explaining it. But I can write code to
just make it easier permanently for everyone."

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-114.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-114.png"></a>
</p>
<p>

There's this "today I learned" person who's into sharing cool new tools they
learned about, a bug that they ran into, or a great new-to-them library feature.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-115.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-115.png"></a>
</p>
<p>

There's the person who has read the entire Internet and has 700 tabs open. If you
want to know where to find something, there's a good chance they already have
it open in their browser.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-116.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-116.png"></a>
</p>
<p>

We have the person who is just willing to answer questions! "Yeah, I can tell
you how that works!"
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-117.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-117.png"></a>
</p>
<p>

And at the end of all this, sometimes you have someone who likes to write some
things down so that other people can read it and can find it later.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-118.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-118.png"></a>
</p>
<p>

But all of us have different roles and we need to work together. I'm into
writing but a lof of the stuff I've written about, I only know about because
someone told me about it or explained it to me.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-119.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-119.png"></a>
</p>
<p>

To end: the one thing I would like to convince you of is: if you're struggling
with something that feels basic, it's not just you! You're not alone. We're all struggling with a
lot of these things that feel like they should be "basic".


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-120.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-120.png"></a>
</p>
<p>

And we're struggling with these things for a lot of
the same reasons as each other. 


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-123.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-123.png"></a>
</p>
<div>

<p>
And much like when debugging a computer program, when you have a bug, you
want to understand why the bug is happening if you're gonna fix it.
</p>

<p>
If we're all struggling with the same things together for the same reasons, if
we can figure out what those reasons are, we can do a better job of fixing
them.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-121.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-121.png"></a>
</p>
<div><p>

Some of the reasons we've talked about were:

</p><ul>
<li>
a giant pile of trivia and gotchas.
</li>
<li>
or maybe there's 20 million lines of code somewhere.
</li>
<li>
Maybe a big part of the system is being hidden from you.
</li>
<li>
Maybe the tool's output is extremely confusing and no UI designer has ever worked on improving it
</li>
</ul><p>

And there are a lot more reasons.

</p></div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-124.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-124.png"></a>
</p>
<p>

I don't have all the answers for why things are hard. For example I don't really understand why Git is hard, that's something I've been thinking about recently.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-125.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-125.png"></a>
</p>
<p>

But that's something I'm excited to keep
working on and keep trying to figure out.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-126.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-126.png"></a>
</p>
<div>

<p>
And that's all I have for you. Thank you.
</p>

<p>
I brought some zines to the conference, if you come to the signing later on you can get one.
</p>

</div>
</div>

<h3 id="some-thanks">some thanks</h3>

<p>This was the last ever Strange Loop and I’m really grateful to Alex Miller and the
whole organizing team for making such an incredible conference for so many years. Strange Loop
accepted one of my first talks (<a href="https://www.youtube.com/watch?v=0IQlpFWTFbM">you can be a kernel hacker</a>) 9 years ago when I had
almost no track record as a speaker so I owe a lot to them.</p>

<p>Thanks to Sumana for coming up with the idea for this talk, and to Marie,
Danie, Kamal, Alyssa, and Maya for listening to rough drafts of it and helping
make it better, and to Dolly, Jesse, and Marco for some of the conversations I
mentioned.</p>

<p>Also after the conference Nick Fagerland wrote a nice post with thoughts on <a href="https://roadrunnertwice.dreamwidth.org/596185.html">why git is hard</a> in response to my “I
don’t know why git is hard” comment and I really appreciated it. It had some
new-to-me ideas and I’d love to read more analyses like that.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thread-per-core (173 pts)]]></title>
            <link>https://without.boats/blog/thread-per-core/</link>
            <guid>37790745</guid>
            <pubDate>Fri, 06 Oct 2023 13:47:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://without.boats/blog/thread-per-core/">https://without.boats/blog/thread-per-core/</a>, See on <a href="https://news.ycombinator.com/item?id=37790745">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>I want to address a controversy that has gripped the Rust community for the past year or so: the
choice by the prominent async “runtimes” to default to multi-threaded executors that perform
work-stealing to balance work dynamically among their many tasks. Some Rust users are
<a href="https://maciej.codes/2022-06-09-local-async.html">unhappy</a> with this decision, so unhappy that they use language I would characterize as
melodramatic:</p><blockquote><p>The Original Sin of Rust async programming is making it multi-threaded by default. If premature
optimization is the root of all evil, this is the mother of all premature optimizations, and it
curses all your code with the unholy <code>Send + 'static</code>, or worse yet <code>Send + Sync + 'static</code>, which
just <em>kills all the joy of actually writing Rust</em>.</p></blockquote><p>It’s always off-putting to me that claims written this way can be taken seriously as a technical
criticism, but our industry is rather unserious.</p><p>What these people advocate instead is an alternative architecture that they call “thread-per-core.”
They promise that this architecture will be simultaneously more performant and easier to implement.
In my view, the truth is that it may be one or the other, but not both.</p><p><em>(Side note: Some people prefer instead just running single threaded servers, claiming that they are
“IO bound” anyway. What they mean by IO bound is actually that their system doesn’t use enough work
to saturate a single core when written in Rust: if that’s the case, of course write a single
threaded system. We are assuming here that you want to write a system that uses more than one core
of CPU time.)</em></p><h2 id="thread-per-core">Thread-per-core</h2><p>One of the biggest problems with “thread-per-core” is the name of it. All of the multi-threaded
executors that users are railing against are also thread-per-core, in the sense that they create an
OS thread per core and then schedule a variable number of tasks (expected to be far greater than the
number of cores) over those threads. As Pekka Enberg <a href="https://twitter.com/penberg/status/1705484076054904922">tweeted</a> in response to a
comment I made about thread per core:</p><blockquote><p>Thread per core combines three big ideas: (1) concurrency should be handled in userspace instead
of using expensive kernel threads, (2) I/O should be asynchronous to avoid blocking per-core
threads, and (3) data is partitioned between CPU cores to eliminate synchronization cost and data
movement between CPU caches. It’s hard to build high throughput systems without (1) and (2), but
(3) is probably only needed on really large multicore machines.</p></blockquote><p>Enberg’s <a href="https://penberg.org/papers/tpc-ancs19.pdf">paper</a> on performance, which is called “The Impact of Thread-Per-Core
Architecture on Application Tail Latency” (and which I will return to in a moment), is the origin of
the use of the term “thread-per-core” in the Rust community. His understanding of the definition of
thread-per-core is probably relevant here. He enumerates three different features of a
thread-per-core architecture, of which he says only two are absolutely required for high
throughput. This is helpful, because the dispute is really only about the third point, not the first
two; if you are using async Rust, you are meeting both of those requirements.</p><p>The distinction being made is really between two optimizations you can make once you have a
thread-per-core architecture, and which are in tension: work-stealing tasks between your threads and
sharing as little state as possible between them.</p><h2 id="work-stealing">Work-stealing</h2><p>The point of work-stealing is to improve tail latency by ensuring that every thread always has work
to do.</p><p>A problem that emerges in real systems is that different tasks end up requiring different amounts
of work. For example, one HTTP request may require far more work to serve than another HTTP request.
As a result, even if you try to balance work up front among your different threads, they can each
end up performing different amounts of work because of unpredictable differences between the tasks.</p><p>Under maximum load, this means that some threads will be scheduled more work than they can perform,
while other threads will sit idle. The degree to which this is a problem depends on the degree to
which the amount of work performed by different tasks differs. Work-stealing is a mitigation to this
problem: threads with nothing to do “steal” work from the other threads that have too much work, so
that they do not sit idle. tokio, async-std, and smol all implement work-stealing with the goal of
reducing tail latency and improving CPU utilization.</p><p>The problem with work-stealing is that it means a task can run on one thread, pause, and then be
started again on another thread: that’s what it means for the work to be stolen. This means that any
state that is used across a yield point in that task needs to be thread-safe. This appears in Rust’s
APIs as futures needing to be <code>Send</code>, which can be difficult for people with a poor view of their
system’s state to figure out the best way to ensure. This is why work-stealing is said to be
“harder.”</p><p>At the same time, if state is moved from one thread to another, this introduces synchronization
costs and cache misses, violating the principles of a “share-nothing” architecture, in which each
CPU has exclusive access to the state it operates on. This is why work-stealing is said to be
“slower.”</p><p>The point of share-nothing is to improve tail latency by keeping data in the faster caches that
belong to a single CPU core, rather than the slower caches shared by multiple cores.</p><p>I want to return to Enberg’s <a href="https://penberg.org/papers/tpc-ancs19.pdf">paper</a>, which demonstrates the performance improvements
of a share-nothing architecture over a shared-state architecture by benchmarking a new key-value
store (which is share-nothing) against memcached (which is shared-state). Enberg shows substantial
improvements in tail latency between the two architectures. I like this paper a lot, but I think the
way it has been deployed in the Rust community as a soundbite (“71% performance improvement!”) is
shallow and unhelpful.</p><p>To achieve a share-nothing architecture, Enberg’s key/value store partitions the keyspace over the
different threads using a hash function, and partitions incoming TCP connections over the threads
using <code>SO_REUSEPORT</code>. Then, it routes requests from the thread managing the connection to the
thread managing the relevant section of the keyspace using message passing channels. In contrast,
in memcached all of the threads share ownership of the keyspace, which is partitioned, and each
partition is protected by a mutex.</p><p>Enberg’s paper shows that using channels over using mutexes can achieve lower tail latency. This is
presumably because there are fewer cache misses, as each partition, which is accessed over and over
again, stays in only one core’s cache. However, I’m not at all convinced that Enberg’s architecture
is dramatically easier to implement than memcached’s. Enberg’s goal is to make use of advanced
kernel features and a carefully planned architecture to avoid data movement, it’s hard for me to
believe this would be <em>easier</em> than wrapping data inside a mutex.</p><p>A key-value store is pretty much the ideal case for a share-nothing architecture, because it is
fairly trivial to partition the state of the application among diferent threads. But if your
application is more complicated, and requires mutating state in multiple partitions in a
transactional or atomic manner, this requires a lot more attention to implement correctly. There’s a
strong analogy between the advocates of a share-nothing architecture and the hype for eventually
consistent databases over databases that enforced serializability ten years ago. Yes, this can be
more performant, but at the expense of requiring careful consideration to avoid bugs that result
from data inconsistency.</p><p>It’s also important to note that neither Enberg’s implementation nor memcached use work-stealing.
This makes it difficult to relate the core performance claims of Enberg’s paper to Rust’s
work-stealing architectures. One wonders what the results would be to just add work-stealing to
Enberg’s architecture and memcached’s. In Enberg’s it would increase data movement somewhat, but
possibly in a manner which still maximizes CPU utilization. I can’t imagine it would do anything but
help memcached.</p><p>Enberg has carefully designed the implementation in the paper to try to evenly distribute work in
advance, using a balanced partition of the keyspace and <code>SO_REUSEPORT</code>. Despite this, there are
several sources of dynamic imbalance that would appear in practice:</p><ul><li>Hot keys will receive more reads and writes, which causes the thread managing their keyspace to
receive more work.</li><li>Some connections will perform more requests than others, which causes the thread managing those
connections to receive more work.</li></ul><p>My understanding of the paper is that the benchmarking framework did not replicate these
conditions, which would appear in the real world: each connection performs a consistent amount of
work, operating on random keys, so it avoids these sources of imbalance. I wonder what benchmarks
which add work stealing would show if these kinds of dynamic imbalance were tested.</p><p>One can imagine others ways to architect a share-nothing system that may mitigate these forms of
imbalance (such as caching hot keys on additional partitions). And some form of work-stealing may be
such an optimization even if some tasks stay pinned to certain cores to avoid moving their state.</p><p>No one would dispute that carefully architecting your system to avoid moving data between CPU caches
will achieve better performance than not doing that, but I have a hard time believing that someone
who’s biggest complaint is adding <code>Send</code> bounds to some generics is engaged in that kind of
engineering. If you’re going to be using shared state anyway, it’s hard to imagine that
work-stealing doesn’t improve your CPU utilization under load.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thirty Years Ago: MS-DOS 6.00 (111 pts)]]></title>
            <link>https://www.pcjs.org/blog/2023/10/04/</link>
            <guid>37790174</guid>
            <pubDate>Fri, 06 Oct 2023 12:57:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcjs.org/blog/2023/10/04/">https://www.pcjs.org/blog/2023/10/04/</a>, See on <a href="https://news.ycombinator.com/item?id=37790174">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <h2><a href="https://www.pcjs.org/blog/">PCjs Blog</a></h2>

<h3>Thirty Years Ago: MS-DOS 6.00</h3>

<p>Over 30 years ago, in March 1993, Microsoft released <a href="https://www.pcjs.org/software/pcx86/sys/dos/microsoft/6.00/compressed">MS-DOS 6.00</a>,
the next major release of MS-DOS after 5.00 shipped in June 1991.</p>

<p>In addition to several new full-screen utilities, like <code>DEFRAG</code> to defragment your hard disk (licensed from Symantec),
<code>MSBACKUP</code> to efficiently backup your hard disk (also licensed from Symantec), and <code>MSAV</code> to check for viruses (licensed
from Central Point Software), there were a number of new command-line programs, such as <code>CHOICE</code>, <code>DELTREE</code>, <code>MOVE</code>,
<code>MSCDEX</code>, and <code>SMARTDRV</code>.</p>

<p>But the biggest addition to MS-DOS 6.00 was a new feature called <strong>DoubleSpace</strong> (dubbed “MagicDrive” internally) that
automatically compressed everything on your hard disk, providing up to “double” the amount of effective disk space – or more,
or less, depending on how compressible your files were overall.</p>

<p>DoubleSpace was a significant feature that required changes across the entire system.  Most of the action, however,
took place inside a new device driver, <code>DBLSPACE.BIN</code>, that stored all your data in a Compressed Volume File (CVF) generally
named <code>DBLSPACE.000</code>.  In fact, if you booted an older version of MS-DOS (like 5.00), you wouldn’t see much more than that:</p>

<div><pre><code>A&gt;DIR C: /A

 Volume in drive C is HOST_FOR_C
 Volume Serial Number is 5739-B1B5
 Directory of C:\

IO       SYS     40470 03-10-93   6:00a
MSDOS    SYS     38138 03-10-93   6:00a
DBLSPACE BIN     51214 03-10-93   6:00a
DBLSPACE INI        91 10-03-23  12:26p
DBLSPACE 000 131474432 10-03-23  12:26p
        5 file(s)  131604345 bytes
                     2605056 bytes free
</code></pre></div>

<p>When MS-DOS 6.00 starts up, it reads <code>DBLSPACE.INI</code>, which usually looks something like this:</p>

<div><pre><code>MaxRemovableDrives=2
FirstDrive=D
LastDrive=H
MaxFileFragments=115
ActivateDrive=H,C0
</code></pre></div>

<p>and tells the operating system to mount the <em>real</em> drive C: as drive H: instead, and to mount the CVF as drive C:</p>

<div><pre><code>C:\&gt;DIR /C

 Volume in drive C is MS-DOS_6
 Volume Serial Number is 101B-323E
 Directory of C:\

DOS          &lt;DIR&gt;     09-25-23  10:13p
COMMAND  COM     52925 03-10-93   6:00a   1.4 to 1.0
WINA20   386      9349 03-10-93   6:00a   5.3 to 1.0
AUTOEXEC BAT        75 09-26-23   8:55a  16.0 to 1.0
CONFIG   SYS       109 09-26-23   8:55a  16.0 to 1.0
                  2.0 to 1.0 average compression ratio
        5 file(s)      62458 bytes
                   253927424 bytes free
</code></pre></div>

<p>So our original hard disk, a 128Mb drive, now appears to be almost twice as large – thanks to DoubleSpace.</p>

<p>Aside from the new <code>DBLSPACE.BIN</code> driver, the other main piece of DoubleSpace functionality resided in <code>DBLSPACE.EXE</code>, which
operated as both a setup and a maintenance program.  It provided a friendly UI, making it easy to create additional CVFs,
as well as resize, defragment, reformat, unmount, remount, and more.</p>

<p><img src="https://www.pcjs.org/blog/images/msdos600-dblspace.png" alt="MS-DOS 6.00 DoubleSpace"></p>

<p>Feel free to tinker with MS-DOS 6.00 on the website:</p>

<ul>
  <li><a href="https://www.pcjs.org/software/pcx86/sys/dos/microsoft/6.00/">Microsoft MS-DOS 6.00 (Installed)</a></li>
  <li><a href="https://www.pcjs.org/software/pcx86/sys/dos/microsoft/6.00/compressed/">Microsoft MS-DOS 6.00 (Installed and Compressed)</a></li>
</ul>

<h2 id="legal-woes">Legal Woes</h2>

<p>Microsoft bootstrapped its compression efforts by licensing code from Vertisoft, makers of DoubleDisk, a disk compression
product first released in 1989.  Starting with Verisoft’s code, Microsoft created <code>DBLSPACE.BIN</code>, along with operating system
changes that allowed it to be loaded <em>before</em> CONFIG.SYS was processed – so that CONFIG.SYS and any system files loaded
from that point forward could be <em>inside</em> the compressed volume instead of <em>outside</em> it.</p>

<p>Vertisoft was not directly involved with any of that work, but they did help produce other pieces of functionality, such
as code to convert Stacker and SuperStor compressed disks to DoubleSpace – although apparently Stacker conversion was pulled
at the last minute, in February 1993, just as MS-DOS 6.00 was being finalized.</p>

<p>Or rather, February 1993 would have been “last minute”, until the lawsuit filed by Stac in January 1993 forced Microsoft
to re-evaluate.  Stac claimed that the DoubleSpace infringed two of Stac’s patents: <a href="https://patents.google.com/patent/US5016009A/en">5,016,009</a> and <a href="https://patents.google.com/patent/US4701745A/en?oq=US4701745">4,701,745</a>.</p>

<p>For me, life quickly changed on February 13, 1993, when I received this email:</p>

<div><pre><code>From: Paul Maritz
Sent: Saturday, February 13, 1993 12:06 PM
To: Jeff Parsons; Mark Zbikowski
Cc: Ben Slivka; Brad Chase; Brad Silverberg; Jim Allchin; John Mason;
Nathan Myhrvold; Rick Rashid
Subject: special duty

You are both amongst the best x86 assembly language coders that we have at MS.
We are thus asking you to help out with a very serious problem that we face - namely
the STAC / DOS6 lawsuit.

Our lawyers have recommended that we have a backup compression mechanism for DOS6
ready to go as soon as possible. The initial work on this has been done under Rick
Rashid in Nathanm's area. They have a C language implementation of a technique that
we believe is safe (covered under patents that we have rights to). The challenge
is to get this technique into the tightest possible x86 assembly code, as soon as
possible. This is where we are asking you to help. Jimall and Bradsi are aware that
you will be "stolen" for some weeks.

Could you both meet with Rick Rashid as early as possible on Monday to get this
effort under way as soon as is possible. Thanks.
</code></pre></div>

<p>The next several weeks were probably some of the most stressful weeks I’d experienced at Microsoft.  Looking back, it’s amazing
to me that with all the critical-path code that was being rewritten at that late date, MS-DOS 6.00 still shipped the following
month, in March 1993.</p>

<p>I don’t recall all the details of the alleged patent infringement, and I’m not sure I ever knew all the details, because frankly,
it wasn’t necessary for me to know the details.  A number of other people had already been working on the problem and had come up
with several solutions, and it simply fell to me and MarkZ to implement them in x86 assembly – preferably very fast, bug-free
assembly, of course.</p>

<p>As far as I can tell now, Stac patent 5,016,009 was the crux of the problem.  It combined LZ77 compression with hashing, and
while LZ77 compression was fine, and hashing was fine, apparently the <em>combination</em> of the two became a patentable innovation.</p>

<p>So we were initially tasked with writing a compressor based on <strong>Miller-Wegman</strong>, an algorithm that was either not patented or
that Microsoft owned or licensed.  When that turned out to be too slow, we instead built a compressor (internally known as XCFR or
the “Rashid Search Algorithm”) that avoided hashing by using a 256x8 look-up table along with a 256-entry LRU table, and also
incorporated a new Microsoft Realtime Compression Format (MRCF) for outputting the raw bytes and offset-length pairs.  That,
of course, meant that the decompressor had to be rewritten as well.</p>

<p>With hindsight, it’s probably safe to say that Microsoft should <em>not</em> have shipped MS-DOS 6.00 quite so quickly after that
rewrite, because unfortunately, our code (well, in the case below, <em>my</em> code) was not, um, bug-free:</p>

<div><pre><code>From: Chuck Strouss
To: SYS Astro Team Development Group; Peter Stewart; Jeff Parsons
Subject: Bug in DBLSPACE decompress
Date: Monday, June 14, 1993 3:40PM

In RDCOMP.ASM, near the first JC instruction, there is a bug when a block ends
at 10000h and the last several bytes are in a repeat string.  It was reported by
Temporal Acuity Products.
</code></pre></div>

<p>to which I replied:</p>

<div><pre><code>From: Jeff Parsons
Sent: Monday, June 14, 1993 4:49 PM
To: Chuck Strouss; Ben Slivka; Jim Mathews; Peter Stewart
Subject: RE: Bug in DBLSPACE decompress

well... shit!
</code></pre></div>

<h2 id="introducing-multiconfig">Introducing MultiConfig</h2>

<p>On a happier, or at least less contentious note, MS-DOS 6.00 also introduced a feature known as <strong>MultiConfig</strong>, which I
have some fondness for, because it was something I personally championed and implemented.  And – good news – I don’t think
it had any serious bugs.</p>

<p>I don’t recall precisely where the idea came from.  I think it started as something that I and Naveen Jain, a Program Manager
on the team, discussed in early 1992.  He created a preliminary spec in February 1992, and then I implemented the feature
in March 1992 and updated the spec to match what I had implemented.</p>

<p>The code was originally added to <strong>Jaguar</strong>, which was planned to be the next major update to MS-DOS after 5.00.
But at some point, <strong>Astro</strong> – originally intended as a smaller interim MS-DOS update – grew to the point where it was
clearly going to be the next major update, thanks in large part to the addition of DoubleSpace disk compression.</p>

<p>When it was clear that <strong>Astro</strong> would become MS-DOS 6.00, I think management went looking for other low-hanging fruit,
such as any new <strong>Jaguar</strong> features that could be incorporated into <strong>Astro</strong> relatively easily with minimal risk.
MultiConfig fit the bill.</p>

<p>However, it wasn’t a slam dunk.  I had to push for it, because there were a few risk-averse people in management that felt
the risk/reward ratio was too high.  They claimed that most users would not use this feature (which was true), but that point
also worked in my favor: most of the new code would not be executed until and unless someone actually added one or more of the
new commands to their CONFIG.SYS.  So any risks largely affected only “power users”.</p>

<h2 id="what-is-multiconfig">What is MultiConfig?</h2>

<p>MultiConfig was a collection of features added to the processing of CONFIG.SYS, to make it easier to start your PC
in a particular way without having to boot from a special floppy or edit/copy a new CONFIG.SYS each time.  It added some new
commands to CONFIG.SYS:</p>

<ul>
  <li>INCLUDE</li>
  <li>MENUCOLOR</li>
  <li>MENUDEFAULT</li>
  <li>MENUITEM</li>
  <li>NUMLOCK</li>
  <li>SET</li>
  <li>SUBMENU</li>
</ul>

<p>and it included some new ways to interact with CONFIG.SYS.  The message “Starting MS-DOS…” was added as an indirect means
of alerting you that you now had two seconds to press one of several new start-up keys:</p>

<ul>
  <li>F5: Bypass CONFIG.SYS and AUTOEXEC.BAT</li>
  <li>F8: Interactively step through CONFIG.SYS</li>
</ul>

<p>You could also tap a Shift key – that was equivalent to pressing F5.  Apparently there was an Astro “press tour” in August
1992, and someone in that tour suggested adding the Shift key, so we did.  They claimed that holding the Shift key while
starting Windows also bypassed certain files and/or functions, but I don’t recall to what extent that was true.</p>

<p>Additionally, if you didn’t want anyone using your machine to bypass or alter CONFIG.SYS, you could add
these lines to the file:</p>

<ul>
  <li>SWITCHES=/N: disable all start-up keys</li>
  <li>SWITCHES=/F: eliminate the two-second pause</li>
</ul>

<p>/N also implied /F, since if start-up keys were disabled, there was no need to wait two seconds.</p>

<p>Note that SWITCHES was not a new command; other older “switches” included:</p>

<ul>
  <li>/K: Forces an enhanced keyboard to behave like a conventional keyboard (DOS 4.0+)</li>
  <li>/T: Indicates the BIOS time rollover byte is a flag instead of a counter (DOS 5.0+)</li>
  <li>/W: Specifies that the WINA20.386 file has been moved to a directory other than the root directory (DOS 5.0+)</li>
</ul>

<p>Finally, while we’re on the subject of the keyboard-related features, I should add that NUMLOCK wasn’t really a MultiConfig
feature; it was just something I thought would be handy.  Recall that early PCs had no BIOS setup screens, and MS-DOS was
still an operating system designed to run on any PC, including the original IBM PC.  So this CONFIG.SYS command:</p>

<ul>
  <li>NUMLOCK=[ON|OFF]</li>
</ul>

<p>could be used to set your keyboard’s initial Num-Lock state.  A case could be made for this being a legitimate
MultiConfig feature though, since you could select menu items with arrow keys <em>or</em> by pressing the number of a menu item.
So if you wanted to use your numeric keypad, then you would want to ensure that Num-Lock matched your preferred selection
method.</p>



<p>The real power of MultiConfig was the ability to create user-friendly boot menus and let you organize sets of CONFIG.SYS
commands into either named or <code>[common]</code> blocks.  Blocks began with a bracketed block name (eg, <code>[menu]</code>, <code>[common]</code>, <code>[doslow]</code>)
and ended at the next bracketed block name (or end of file).</p>

<p>Here’s a simple example:</p>

<div><pre><code>[menu]
menuitem=doslow,Load DOS in LOW memory
menuitem=doshigh,Load DOS in HIGH memory
menudefault=doslow,15
menucolor=15,1

[common]
device=c:\dos\himem.sys

[doslow]
dos=low

[doshigh]
dos=high

[common]
device=c:\dos\setver.exe
files=30
</code></pre></div>

<p>And the screen that would appear when booting:</p>

<p><img src="https://www.pcjs.org/blog/images/msdos600-multiconfig.png" alt="MS-DOS 6.00 MultiConfig"></p>

<p>Each <code>menuitem</code> in the <code>[menu]</code> block describes a menu item; the first argument is a block name (eg, <code>doslow</code>, <code>doshigh</code>),
and the second argument is a description.  Other <code>[menu]</code> block keywords included <code>menudefault</code>, which specifies the
default menu item (and optional timeout value in seconds), and <code>menucolor</code>, which selects foreground and background colors
for the menu.</p>

<p>In the above example, no matter which menu item you selected, HIMEM.SYS would always be loaded first, because it was in a
<code>[common]</code> block that appeared before the other blocks.  Then all commands in the selected block (<code>[doslow]</code> or
<code>[doshigh]</code>) would be processed next, then all the commands in the next <code>[common]</code> block – and so on.</p>

<p>Another feature was “forced prompting”.  If you included a <code>?</code> after the <code>DEVICE</code> keyword, you would receive an unconditional
prompt for that particular driver.  For example:</p>

<div><pre><code>device?=c:\dos\setver.exe
</code></pre></div>

<p>would <em>always</em> generate the following prompt:</p>

<div><pre><code>DEVICE=C:\DOS\SETVER.EXE [Y,N]?
</code></pre></div>

<p>And that feature wasn’t limited to device drivers.  The following line:</p>



<p>would also generate a prompt:</p>





<p>Below is a more complex example, extracted from an email I wrote back on July 1, 1992 (at 2:34am apparently).</p>

<p>This example illustrates how you could use <code>submenu</code> (as opposed to <code>menuitem</code>) to define menu items that
referred to other menu blocks, in order to create multi-level menus.  Originally, the keyword for that feature was
simply <code>menu</code>, but the <strong>Astro</strong> team (specifically, Betsy Tinney, who helped refine the MultiConfig UI for <strong>Astro</strong>)
suggested a keyword that was clearer.</p>

<p>It also shows how you could <code>include</code> named blocks from other blocks.  For example, a number of the blocks, like <code>[dosumb]</code>,
include another block, <code>[dos]</code>, that contains commands common to the other blocks.  Every block <em>could</em> duplicate those
commands itself, but factoring out common sets of commands made for a more maintainable CONFIG.SYS.  Blocks named <code>[common]</code>
were <em>always</em> processed in the order they appeared, whereas blocks with any other name would be processed whenever
(and <em>only</em> whenever) they were explicitly included.</p>

<p>Finally, this example also uses the <code>SET</code> command, which defines environment variables to be passed to <code>COMMAND.COM</code>.
In addition, a special <code>CONFIG</code> environment variable is automatically set to the name of the block from the final selected
<code>menuitem</code> (eg, <code>dosumb</code>).  This was useful for batch files like AUTOEXEC.BAT, if they needed to customize their actions
according to the selected CONFIG.SYS configuration.</p>

<div><pre><code>[menu]
numlock=off
menucolor=15,1
menudefault=lanmenu,15
submenu=dosmenu,DOS configurations
submenu=lanmenu,LanMan configurations

[dosmenu]
menudefault=dosumb,15
menuitem=dosumb,     DOS 7.00 only
menuitem=dosems,     DOS 7.00 w/EMS
menuitem=dosansi,    DOS 7.00 w/ANSI
menuitem=dos386max,  DOS 7.00 w/386Max
menuitem=dosdbg,     DOS 7.00 w/Soft-ICE
menuitem=cougar,     DOS 7.00 w/Cougar

[lanmenu]
menudefault=winball,15
menuitem=lanman20,   DOS 7.00 w/Lanman 2.0
menuitem=lanman21,   DOS 7.00 w/Lanman 2.1 w/XNS
menuitem=lanman21nb, DOS 7.00 w/Lanman 2.1 w/XNS+NetBeui
;menuitem=lanman21xm,DOS 7.00 w/Lanman 2.1 w/XNS Mono
menuitem=lanman21dbg,DOS 7.00 w/Lanman 2.1 w/Soft-ICE
menuitem=winball,    DOS 7.00 w/Winball

[common]
set tmp=c:\tmp
set linktmp=c:\tmp
set temp=c:\win31\temp
set dircmd=/l/o
set home=d:\tools\bound
set init=d:\tools\bound
set alias=jeffpar
set logname=jeffpar
set mailname=jeffpar
set basspec=d:\tools\dos
set helpfiles=d:\tools\help;c:\src\cougar\dev\tools\help
set country=usa-ms
set proj=c:\src\cougar\dos\dos86
set lib=d:\tools\windev\lib
set include=d:\tools\windev\include;d:\src\myinc
set path=d:\tools\dos;d:\tools\bound;d:\tools\windev;c:\lanman\netprog;c:\win31;c:\dos
set prompt=$p$g

[dos]
break=on
dos=high,umb
files=60
buffers=10
stacks=9,256
lastdrivehigh=z
shell=c:\dos\command.com /p c:\dos /e:1024 /z

[dosumb]
include dos
device=c:\win31\himem.sys
device=c:\win31\emm386.exe noems i=b000-b7ff x=d800-dfff

[dosems]
include dos
device=c:\win31\himem.sys
device=c:\win31\emm386.exe 1024 ram i=b000-b7ff x=d800-dfff frame=e000

[dosansi]
include dosumb
devicehigh=c:\dos\ansi.sys

[dos386max]
include dos
device=d:\tools\386max\386max.sys

[dosdbg]
device=c:\s-ice\s-ice.exe /tra 1000
include dos

[lanman20]
include dosumb
include lanman20_drivers
include lanman_logon

[lanman20_drivers]
devicehigh=c:\lanman\drivers\protman\protman.dos /i:c:\lanman
devicehigh=c:\lanman\drivers\ethernet\ub\ubnei.dos
devicehigh=c:\lanman\drivers\protocol\netbeui\netbeui.dos
devicehigh=c:\lanman\drivers\protocol\xns\ubxpw.dos
devicehigh=c:\lanman\drivers\protocol\xns\ubloop.dos
installhigh c:\lanman\drivers\protman\netbind.exe

[lanman21]
include dosumb
include lanman21_drivers
include lanman_logon

[lanman21nb]
include dosumb
include lanman21_drivers
install c:\lanman\netprog\load.com netbeui
include lanman_logon

[lanman21xm]
include dosumb
install c:\lanman\xnsmono\loadniu.exe -r -d -m:d8 -i:5 -p:4 c:\lanman\xnsmono\exniu2.xfm c:\lanman\xnsmono\1a.lc
install c:\lanman\xnsmono\xnsbios.exe -m:d8 -i:5 -p:4
include lanman_logon

[lanman21dbg]
device=c:\s-ice\s-ice.exe /tra 1000
include dos
include lanman21_drivers
include lanman_logon

[lanman21_drivers]
devicehigh=c:\lanman\drivers\protman\protman.dos /i:c:\lanman
devicehigh=c:\lanman\drivers\ethernet\ub\ubnei.dos
device=c:\lanman\drivers\protocol\ubxns\ubxps.dos
install c:\lanman\netprog\netbind.com

[lanman_logon]
install c:\lanman\netprog\net.exe start workstation
install c:\lanman\netprog\net.exe logon jeffpar2 /y
;install c:\lanman\netprog\net.exe use k: \\jeffpar\astro dos6
;install c:\lanman\netprog\net.exe use j: \\jeffpar\cougar dos7

[winball]
include dosumb
include lanman21_drivers
devicehigh=c:\win31\redirdrv.sys
devicehigh=c:\win31\system\vnbhlp.dos
shell=c:\dos\command.com /p c:\dos /e:1024 /z /k windb
set path=d:\tools\dos;d:\tools\bound;d:\tools\windev;c:\win31;c:\dos

[cougar]
include dosumb
include lanman21_drivers
devicehigh=c:\win31\redirdrv.sys
devicehigh=c:\win31\system\vnbhlp.dos
shell=c:\dos\command.com /p c:\dos /e:1024 /z /k cougar7
set path=d:\tools\dos;d:\tools\bound;d:\tools\windev;c:\win31;c:\dos;d:\cougar

[common]
installhigh d:\tools\dos\keyfix.com
installhigh c:\win31\mouse.com
installhigh c:\dos\share.exe
installhigh c:\win31\smartdrv.exe 1024
installhigh c:\dos\doskey.com /a /e /x /p /k:128 /f:d:\tools\dos\aliases
install c:\dos\mode.com con:rate=30 delay=1
install d:\tools\dos\50.com
</code></pre></div>


<p>[<a href="https://github.com/jeffpar/pcjs/tree/gh-pages/blog/_posts/2023/2023-10-04-thirty-years-ago-ms-dos-6-00.md">GitHub Source</a>]</p>

<p><a href="https://github.com/jeffpar">Jeff Parsons</a><br>
	<small>Oct 4, 2023</small>
</p>


      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Use an old tablet as an extra monitor (131 pts)]]></title>
            <link>https://github.com/alex028502/extra-screen</link>
            <guid>37789371</guid>
            <pubDate>Fri, 06 Oct 2023 11:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alex028502/extra-screen">https://github.com/alex028502/extra-screen</a>, See on <a href="https://news.ycombinator.com/item?id=37789371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-use-an-old-tablet-as-an-extra-monitor" dir="auto"><a href="#use-an-old-tablet-as-an-extra-monitor">Use an old tablet as an extra monitor</a></h2>
<p dir="auto">(as long as you want to use it as a terminal)</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex028502/extra-screen/blob/master/pics/picture.jpeg"><img src="https://github.com/alex028502/extra-screen/raw/master/pics/picture.jpeg" alt="Kindle Fire as Extra Screen"></a></p>
<p dir="auto">I have a couple old kindle fire tablets lying around. One of them has a battery
that lasts about ten minutes. I also never have enough screens and never know
where to put my terminal when I need to tail a log or something.</p>
<p dir="auto">I tried using <a href="https://github.com/pavlobu/deskreen">Deskreen</a> a long time ago
as my optional extra screen when I travel. I can't remember why I didn't get
that habit going.</p>
<p dir="auto">For my extra office screen, I decided to do something different because</p>
<ul dir="auto">
<li>My graphics card seems to be maxed out. I can't even use the internal screen.</li>
<li>I don't know where I put that virtual display adapter.</li>
<li>It seemed like a bit of a detour to send pixels to my tablet when I am only
looking at text</li>
</ul>
<h4 tabindex="-1" id="user-content-so-what-is-then" dir="auto"><a href="#so-what-is-then">So what is then?</a></h4>
<p dir="auto">Well I just ssh into my computer from an android SSH client, open <code>screen</code>, and
then use a program I made that allows me to <code>stuff</code> the characters I type into
the screen session, so it feels like I am typing right into the tablet.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex028502/extra-screen/blob/master/pics/terminal-app.png"><img src="https://github.com/alex028502/extra-screen/raw/master/pics/terminal-app.png" alt="typing app"></a></p>
<p dir="auto">See if you can find this little window in the main picture. That is what I have
to activate using Alt+Tab to type into the terminal.</p>
<h4 tabindex="-1" id="user-content-this-is-an-mvp-and-a-poc-and-stuff-like-that" dir="auto"><a href="#this-is-an-mvp-and-a-poc-and-stuff-like-that">This is an 'MVP' and a 'POC' and stuff like that</a></h4>
<p dir="auto">While I think this approach to using a spare tablet as an extra screen may be
a winner, I am not so sure about this approach to this approach to using a
spare tablet as an extra screen.  Here are the issues:</p>
<ul dir="auto">
<li>You have to give some a mobile app access to your entire computer. This seems
like a shame after the phone OS did all this work to sandbox the mobile app, and
not give it access to your phone or tablet. This is even less awesome for an
iPad since there don't seem to be any open source SSH clients, and even if
there were, I don't think there would be any guarantee that what you see on
github is what has been sent to the app store.</li>
<li>You have to open an SSH server on your computer that exposes you to some
clever hacker in the Starbucks where you are using your spare screen</li>
<li>I can't figure out how to stuff C-SPC, which is a 0x0 - so have a clunky
workaround</li>
<li>It seems weird to execute <code>screen</code> once per key. I wish I could just pipe the
characters in or something - not that I have any idea how relevant that is to
performance.</li>
<li>It's hard to find terminal clients for some old devices (like my iPad)</li>
</ul>
<p dir="auto">What I think might be a better approach to this approach is using a lot of the
bits and pieces in <a href="https://hyper.is/" rel="nofollow">hyper</a>, such as
<a href="http://xtermjs.org/" rel="nofollow">xterm.js</a>, showing the terminal in a web browser, and
sending the characters over a web socket. It would still only send just over a
byte per keypress or something like that, and not use your GPU/HDMI, but could
work on even more devices - any device with a browser, just like Deskreen. The
server app would have to do much more:</p>
<ul dir="auto">
<li>serve the client app</li>
<li>make you type in a four digita code that you see on your tablet screen sort of
like Bluetooth pairing</li>
<li>set up the shell, and PTY probably</li>
<li>listen to the console end of the PTY and send everything down the websocket</li>
<li>send key presses to the PTY</li>
</ul>
<p dir="auto">Both solutions depend on the LAN, which is too bad. Maybe Web Bluetooth or
something for future old devices.</p>
<h2 tabindex="-1" id="user-content-set-up" dir="auto"><a href="#set-up">Set-up</a></h2>
<p dir="auto">I don't really think anybody else should use my Python program that stuffs keys
into the screen session (unless it's an emergency).  You are better off taking
the idea and making your own even better solution. But I'll first explain it
using my program.</p>
<h5 tabindex="-1" id="user-content-enable-ssh-on-your-computer" dir="auto"><a href="#enable-ssh-on-your-computer">enable ssh on your computer</a></h5>
<div data-snippet-clipboard-copy-content="sudo apt-get install openssh-server"><pre><code>sudo apt-get install openssh-server
</code></pre></div>
<p dir="auto">but make sure it is disabled so that you don't have it on unnecessarily, or in
public places.</p>
<div data-snippet-clipboard-copy-content="sudo systemctl disable ssh"><pre><code>sudo systemctl disable ssh
</code></pre></div>
<p dir="auto">start it whenever you are playing with your extra screen and on a trusted
network:</p>

<p dir="auto">disable it the rest of the time</p>

<h5 tabindex="-1" id="user-content-open-a-terminalssh-client-on-your-tablet" dir="auto"><a href="#open-a-terminalssh-client-on-your-tablet">open a terminal/ssh client on your tablet</a></h5>
<p dir="auto">I side-loaded ConnectBot onto my Kindle Fire from F-Droid. I tried to sideload
F-Droid, and then install ConnectBot, but it failed for some reason</p>
<h5 tabindex="-1" id="user-content-start-screen-with-a-known-session-name" dir="auto"><a href="#start-screen-with-a-known-session-name">start screen with a known session name:</a></h5>

<p dir="auto">If you are using ConnectBot on a Kindle Fire, there seems to be a
<a href="https://github.com/connectbot/connectbot/issues/543" data-hovercard-type="issue" data-hovercard-url="/connectbot/connectbot/issues/543/hovercard">known bug</a> that return
doesn't work. There are some workarounds for emergencies in the bug report but
I just configured the above to happen every time I connected.</p>
<p dir="auto"><code>DISPLAY=:0</code> makes it so that you can do stuff like <code>xdg-open .</code> and <code>emacs &amp;</code>
and <code>git gui &amp;</code> in the terminal, and see the result in your main gui session.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex028502/extra-screen/blob/master/pics/settings.png"><img src="https://github.com/alex028502/extra-screen/raw/master/pics/settings.png" alt="ConnectBot settings"></a></p>
<h5 tabindex="-1" id="user-content-install-and-run-my-typing-programme" dir="auto"><a href="#install-and-run-my-typing-programme">install and run my typing programme</a></h5>
<p dir="auto">Don't actually do this.</p>
<div data-snippet-clipboard-copy-content="$ cd [project directory that you cloned]
$ make # to generate images and special null file
$ sudo apt-get install python3-gi
$ python3 start.sh aux"><pre><code>$ cd [project directory that you cloned]
$ make # to generate images and special null file
$ sudo apt-get install python3-gi
$ python3 start.sh aux
</code></pre></div>
<h5 tabindex="-1" id="user-content-actually-just-make-your-own-typing-solution" dir="auto"><a href="#actually-just-make-your-own-typing-solution">actually just make your own typing solution</a></h5>
<p dir="auto">Check this out:</p>
<div data-snippet-clipboard-copy-content="$ screen -S aux -X stuff x"><pre><code>$ screen -S aux -X stuff x
</code></pre></div>
<p dir="auto">An <code>x</code> should appear in your terminal</p>
<p dir="auto">You need to somehow make all the control characters work. The ones you need</p>

<p dir="auto">Look at <a href="https://github.com/alex028502/extra-screen/blob/master/start.py">my program</a> for ideas on how to implement yours that is
even better</p>
<p dir="auto">There is some more debugging advice further down.</p>
<h5 tabindex="-1" id="user-content-create-a-services-or-something" dir="auto"><a href="#create-a-services-or-something">create a services or something</a></h5>
<p dir="auto">That would be cool to have the ssh daemon start the the typing program as a
service whenever the ssh session is opened - like similar to what you can do
with udev.</p>
<p dir="auto">I think you have to do something with <code>ForceCommand</code> in <code>/etc/ssh/sshd_config</code></p>
<p dir="auto">I think you can also watch <code>/var/log/auth.log</code> for <code>sshd</code> and <code>Accepted</code> using
awk.</p>
<h2 tabindex="-1" id="user-content-faq" dir="auto"><a href="#faq">FAQ</a></h2>
<h4 tabindex="-1" id="user-content-how-well-does-it-work" dir="auto"><a href="#how-well-does-it-work">How well does it work?</a></h4>
<p dir="auto">It works really well on my Kindle Fire at the office as a terminal. It is too
slow at home, with my iPad, as my emacs screen. This could be because:</p>
<ul dir="auto">
<li>the ssh client that I found that works with my old iPad is too slow to update
after characters get stuffed in</li>
<li>the wifi network at home is too slow</li>
<li>trying to use it as a full text editor for serious work makes the speed more
noticeable
(I have used emacs at the office set-up in the picture, and it seems to work
pretty well, but it's too small to really try to work with it - I am also
thinking using emacs to display my email inbox with it so I can keep an eye on
my email while I work)</li>
</ul>
<p dir="auto">I am planning to mainly use it at the office to tail logs, but I have been
'daily driving' it for all terminal stuff just to try it out.</p>
<p dir="auto">ConnectBot on Kindle Fire doesn't make it easy to get into landscape mode.
<a href="https://github.com/connectbot/connectbot/issues/868" data-hovercard-type="issue" data-hovercard-url="/connectbot/connectbot/issues/868/hovercard">Here</a> it sounds like you
have to connect a Bluetooth keyboard. That's actually an interesting idea - I
could have made my type-into-the-terminal app act like a bluetooth keyboard for
your tablet instead of inserting characters into the screen session.</p>
<p dir="auto">Originally, I had hoped for landscape, but now I have found a great for my
portrait tablet between my monitors, and found that for small terminal windows,
splitting across is good, and for logs, long is good. The text has to be quite
small to get 80 characters across.</p>
<p dir="auto">I got used to finding the application with Alt+Tab. I tried to drag my mouse
over to the tablet a couple times. I don't really use workspaces. I like to be
able to see as many things as possible by turning my head, and find applications
to bring to the foreground with Alt+Tab. If you use workspaces, I guess it
changes things a little bit.  You could search for the terminal typing app, and
hide your other windows. On GNOME 3, or at least on Ubuntu 22.04, on my
computer, one of the screens never changes with workspace, so I guess the
terminal typing app could go in there. On MATE, both screens are in the
workspace, but I think there is an always in active workspace function
somewhere. Just brainstorming though - I am sure if a workspace user wants to
do the same thing, they'll work it out.</p>
<h4 tabindex="-1" id="user-content-what-about-paste" dir="auto"><a href="#what-about-paste">What about paste?</a></h4>
<p dir="auto">Ctrl+Shift+V for paste works by stuffing your whole clipboard into the screen
session.</p>
<h4 tabindex="-1" id="user-content-what-about-copy" dir="auto"><a href="#what-about-copy">What about copy?</a></h4>
<p dir="auto">I haven't figured out copy yet. I think there must be an easy way to send my
tmux clipboard to the graphical clipboard. Since I start <code>screen</code> with
<code>DISPLAY=:0</code>, any copy to clipboard utility should hopefully "just work".</p>
<h4 tabindex="-1" id="user-content-why-do-you-use-screen-and-tmux" dir="auto"><a href="#why-do-you-use-screen-and-tmux">Why do you use <code>screen</code> <em>and</em> <code>tmux</code>?</a></h4>
<ul dir="auto">
<li>I didn't want all the tmux chrome when using emacs
(you can turn it off with tmux, but then that changes the tmux experience when
I do want to use tmux)</li>
<li>I got the stuff command working with screen, and it's just a MVP/POC so I left
it like that.</li>
</ul>
<h4 tabindex="-1" id="user-content-if-you-are-an-emacs-user-shouldnt-you-use-one-of-the-emacs-shells" dir="auto"><a href="#if-you-are-an-emacs-user-shouldnt-you-use-one-of-the-emacs-shells">If you are an emacs user, shouldn't you use one of the emacs shells?</a></h4>
<p dir="auto">Yeah I never really got into that, and I always have a full screen worth of
open text files.</p>
<h4 tabindex="-1" id="user-content-why-dont-you-just-use-____" dir="auto"><a href="#why-dont-you-just-use-____">Why don't you just use ____?</a></h4>
<p dir="auto">I have to admit, I didn't look to hard to see if there was a ready to go way to
do this - if somebody knows of one, please just submit a pull request that
deletes my whole repo, and leaves only a readme that points me toward the
alternative.</p>
<h2 tabindex="-1" id="user-content-developing-the-typing-application" dir="auto"><a href="#developing-the-typing-application">Developing the typing application.</a></h2>
<p dir="auto">For developing, and getting the keycodes right, you don't really need a tablet.</p>
<p dir="auto">I start a screen session in an ordinary terminal instead of the tablet, and
then run this program:</p>
<div data-snippet-clipboard-copy-content="import sys
import termios
import tty

old_settings = termios.tcgetattr(sys.stdin)
try:
    tty.setraw(sys.stdin.fileno())
    while True:
        char = sys.stdin.read(1)
        print(&quot;%s\r&quot; % hex(ord(char)))
        if char == '\x03':
            raise KeyboardInterrupt
finally:
    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)"><pre><code>import sys
import termios
import tty

old_settings = termios.tcgetattr(sys.stdin)
try:
    tty.setraw(sys.stdin.fileno())
    while True:
        char = sys.stdin.read(1)
        print("%s\r" % hex(ord(char)))
        if char == '\x03':
            raise KeyboardInterrupt
finally:
    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
</code></pre></div>
<p dir="auto">Then I connect my python typer program to that screen session, and compare the
codes that I get when I type straight into the terminal to the codes I get when
I get when I use my typing application.</p>
<p dir="auto">Hopefully after reading
<a href="https://blog.nelhage.com/2009/12/a-brief-introduction-to-termios/" rel="nofollow">this</a> I
will understand more about what <code>tty.setraw</code> does.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Productivity has grown faster in Western Europe than in America (142 pts)]]></title>
            <link>https://www.economist.com/graphic-detail/2023/10/04/productivity-has-grown-faster-in-western-europe-than-in-america</link>
            <guid>37789290</guid>
            <pubDate>Fri, 06 Oct 2023 11:25:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/graphic-detail/2023/10/04/productivity-has-grown-faster-in-western-europe-than-in-america">https://www.economist.com/graphic-detail/2023/10/04/productivity-has-grown-faster-in-western-europe-than-in-america</a>, See on <a href="https://news.ycombinator.com/item?id=37789290">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-body-id="cp1"><figure data-infographic-class="g-fallback"></figure><figure data-infographic-js="1"></figure><p data-caps="initial"><span data-caps="initial">T</span><small>HE EU ECONOMY</small> is now 65% the size of America’s in dollar terms, down from 90% just ten years ago. Slow population growth is partly to blame—the number of Europeans has risen by 1.6% since 2012, compared with 6.1% for Americans. Still, <small>GDP</small> per person is higher, and has grown far faster, in the United States than in Europe.</p><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/091%20Graphic%20detail%20-%20Productivity-8fd34726d8d2617895da583200301f18.mp3" title="Productivity has grown faster in western Europe than in America" controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p>As a result, commentators and think-tanks have set about comparing the economies of some of Europe’s richest countries to those of America’s poorest states. But comparisons based simply on <small>GDP</small> per person are poor measures of economic welfare. Goods and services cost more in some countries than in others, and working more does not always make people better off. Adjusting for these factors suggests that countries like Denmark and Austria are in fact more productive than America.</p><p>The first step in comparing different economies is converting national figures into a common currency. But a dollar goes much further in some countries than others, because the costs of non-tradable goods and services, such as housing or restaurant meals, vary widely. Measuring living standards requires converting <small>GDP</small> figures to “purchasing-power parity” (<small>PPP</small>).</p><figure data-infographic-class="g-fallback"></figure><figure data-infographic-js="1"></figure><p>Europe’s economic performance looks far better at <small>PPP</small> than in nominal terms. In 2012 prices in America were just 5.4% higher than in the <small>EU</small> at market exchange rates. Today, the gap is 46%, largely thanks to a strong dollar. Adjusting for <small>PPP</small>,<!-- --> the<small> EU</small>’s<small> GDP</small> is roughly 95% of America’s, the same as it was ten years ago. Still, <small>PPP</small>-adjusted <small>GDP</small> per person has grown faster in America than in most of western Europe.</p><p>But focus instead on productivity, by dividing these figures by a tally of hours worked, and the gap closes further. As a result of demography—western Europe has a larger share of elderly people than America does—and because of differences in holiday allowances, pensions and unemployment benefits, Europeans work less than Americans do. On an hourly basis, countries like Austria, Belgium and Denmark leap ahead. In France, Germany and Sweden productivity has also grown faster in the past ten years than it has in America.</p><figure data-infographic-class="g-fallback"></figure><figure data-infographic-js="1"></figure><p>Such adjustments are an inexact science. <small>PPP</small> conversions struggle to capture differences in the quality of goods and services and many countries calculate hours worked differently. But in aggregate, western Europeans get just as much out of their labour as Americans do. Narrowing the gap in total <small>GDP</small> would require additional working hours, either via immigration or by raising the amount of time citizens spend on the job. Europeans may well reject this trade-off—they tend to value leisure time, even if <small>GDP </small>figures do not. <span data-ornament="ufinish">■</span></p><p><em>Chart sources: OECD; World Bank. Inspect our code on <a href="https://github.com/TheEconomist/the-economist-gdp-per-hour-estimates/">Github</a>.</em></p></div><div><p>This article appeared in the Graphic detail section of the print edition under the headline "All work and no play"</p><p>Chart sources: OECD; World Bank. Inspect our code on <a href="https://github.com/TheEconomist/the-economist-gdp-per-hour-estimates/">Github</a>.</p></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Are free markets history? The rise of homeland economics" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20231007_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20231007_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20231007_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20231007_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20231007_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20231007_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20231007_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20231007_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20231007_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20231007_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20231007_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20231007_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20231007_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20231007_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20231007_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20231007_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20231007_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the October 7th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-10-07" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Opening up access to GOV.UK Forms: an online form builder (279 pts)]]></title>
            <link>https://gds.blog.gov.uk/2023/10/03/how-were-opening-up-access-to-gov-uk-forms/</link>
            <guid>37789107</guid>
            <pubDate>Fri, 06 Oct 2023 10:54:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gds.blog.gov.uk/2023/10/03/how-were-opening-up-access-to-gov-uk-forms/">https://gds.blog.gov.uk/2023/10/03/how-were-opening-up-access-to-gov-uk-forms/</a>, See on <a href="https://news.ycombinator.com/item?id=37789107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><img decoding="async" fetchpriority="high" src="https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image1-620x413.jpg" alt="A large group of civil servants sitting in an audience looking up at a screen." width="620" height="413" srcset="https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image1-620x413.jpg 620w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image1-310x207.jpg 310w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image1-768x512.jpg 768w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image1-1536x1024.jpg 1536w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image1.jpg 1999w" sizes="(max-width: 620px) 100vw, 620px"></p>
<p><span>Here at GDS, we’re making it easier for departments to build better digital services</span><span>. </span><a href="http://gov.uk/forms"><span>GOV.UK Forms</span></a><span> is an online form builder which can be used to make accessible and easy to use digital forms for GOV.UK. It saves time for departments that are processing form submissions, and time for users that are filling in forms.</span></p>
<p><span>In just a matter of minutes, government teams can replace PDF and other document-based forms with digital forms which all users can access and are legally compliant with the </span><a href="https://www.legislation.gov.uk/uksi/2018/852/contents/made"><span>Public Sector Bodies Accessibility Regulations 2018</span></a><span>.&nbsp;</span></p>
<p><span>Best of all, there’s no need for any technical knowledge and it’s completely free!</span></p>
<p><span>GOV.UK Forms is currently in </span><a href="https://www.gov.uk/service-manual/agile-delivery/how-the-beta-phase-works"><span>private beta</span></a><span>, where we’re testing the product out with a small number of teams that own forms. This is to help us steadily understand how our product is working and what issues we need to address. After that, we’ll move into public beta, where we’ll open up GOV.UK Forms for any central government department to use freely.</span></p>
<p><span>We wanted to share what we’ve been up to since our last update, and what we’re doing to open up private beta for a wider pool of users - a phase that we’re calling ‘Early Access’. This will allow departments with forms that only require current features to start building them, and also allow any government user to try out our product. It will also help us to ramp up our overall user numbers and test the stability of our platform before public beta.</span></p>
<h2><strong>What we’ve done</strong></h2>
<p><span>In October 2022, the Insolvency Service was </span><a href="https://gds.blog.gov.uk/2022/10/06/making-it-easy-to-create-and-publish-digital-forms-on-gov-uk/"><span>the first government organisation to publish a form</span></a><span> with us. This was a relatively simple form as we only supported quite basic features at the time. The vast majority of document-based forms require more complex features to turn these into digital forms, including multiple options, declaration statements and more.</span></p>
<h3><strong>Routing to skip questions that aren’t relevant</strong></h3>
<p><span>One of these features is routing, or skippable questions. If you think of any form that you might have to fill out, for example at the GP or for an application, the chances are that it will say ‘If you answer ‘No’, skip to question 13’ or similar. This is a really core requirement for form building, and we needed to find a way to build this so that people who aren’t digital professionals could understand how to set up this kind of logic for their form.</span></p>
<p><span>We created a new journey for form builders to add this to questions that ask for one answer to be selected from a list of options. They can specify which answer should route people to a future question and which question they should go to. The person filling out the form will then skip questions they don’t need to answer - saving them time and saving processing time too. You can see how this appears for form builders in the screenshot below:</span></p>
<figure id="attachment_35844"><img decoding="async" src="https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image3-620x582.png" alt="A screenshot of a page informing a form creator that if a user answers ‘Yes’ to a question, they will be taken to a further question." width="620" height="582" srcset="https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image3-620x582.png 620w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image3-310x291.png 310w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image3-768x721.png 768w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image3.png 1428w" sizes="(max-width: 620px) 100vw, 620px"><figcaption>A screenshot of a page informing a form creator that if a user answers ‘Yes’ to a question, they will be taken to a further question.</figcaption></figure>
<p><span>We know this is not going to cover all routing needs though - in the future, we’d like to look at building branching (two separate sets of questions depending on the answer), and later down the line we might be able to expand our routing so you can add routes to more than one answer, and also routes based on a combination of answers.</span></p>
<h3><strong>Making a draft of a live form</strong></h3>
<p><span>At the start of 2023, if one of our users created a form, made it ‘live’ (meaning it can now be put on GOV.UK), and then later on wanted to edit their live form, any change made would be updated on the live form immediately. This would cause issues as form builders may be making multiple changes, or change their mind about what they want to edit. And each time this would happen, people that are filling in the form would be at risk of losing their progress.</span></p>
<p><span>So what we did is we made live forms uneditable - instead, if you want to make changes to a live form, you would create a new draft copy of that form. Then you could make all the edits you want, and only make that new version live when you’re happy with all the changes. This new version would automatically replace the existing live form - meaning this change only happens once, and affects a much smaller number of people filling in the form.</span></p>
<h3><strong>Detailed guidance</strong></h3>
<p><span>Our form builder already allows users to add hint text to a question, such as ‘Enter your name as it appears in your passport’. But sometimes on a form there are questions that need a bit more information for someone to answer - for example, specific guidance that they may need to refer to, or industry codes that need to be defined so that the right code is entered.</span></p>
<p><span>To do this, in September we released a feature called ‘detailed guidance’ that will allow this more detailed information to be provided to the person filling in the form. Here’s what it will look like for people filling out an example form:</span></p>
<figure id="attachment_35845"><img decoding="async" src="https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image2-620x522.png" alt="A screenshot of a question that provides more information about adjustments for interviews that can be offered, before asking the user whether they need adjustments" width="620" height="522" srcset="https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image2-620x522.png 620w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image2-310x261.png 310w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image2-768x647.png 768w, https://gds.blog.gov.uk/wp-content/uploads/sites/60/2023/10/image2.png 1434w" sizes="(max-width: 620px) 100vw, 620px"><figcaption>A screenshot of a question that provides more information about adjustments for interviews that can be offered, before asking the user whether they need adjustments.</figcaption></figure>
<h2><strong>What we still need to do</strong></h2>
<h3><strong>User management and self-service accounts</strong></h3>
<p><span>Right now we use </span><a href="https://docs.publishing.service.gov.uk/repos/signon.html"><span>GOV.UK Signon</span></a><span> to allow users to sign into our product and use it. However, each time that a new user wants access, our team has to set that account up. We also can’t give people custom permission levels based on what we want them to be allowed to do (and not do). Signon is currently making improvements to make it more self-serviceable, but this wouldn’t have been ready for us to start expanding.</span></p>
<p><span>So last year we decided that we needed to move off of Signon and use </span><a href="https://auth0.com/"><span>Auth0</span></a><span> (also used by Ministry of Justice’s </span><a href="https://moj-forms.service.justice.gov.uk/"><span>MOJ Forms</span></a><span>) for authenticating users, and bring the permission controls into the GOV.UK Forms product itself. We also wanted to create a system so that users could create their own trial accounts without our involvement (self-service), try out the product, and then be easily upgraded to the next permission level in order to make their forms live.</span></p>
<p><span>Doing this work is one of our key challenges to adding many more users onto the platform, and we’ve designed an easy flow to allow quick access to the product, whilst also keeping enough control of who can make live forms whilst we’re still in private beta. We also want to ensure we’re following good governance practices and ensure Memorandum of Understandings (MoUs) are agreed before somebody from a department is able to make a form live.</span></p>
<h3><strong>Other features</strong></h3>
<p><span>Before we kick off Early Access, there are some other features that we’re working on to implement, including:</span></p>
<ul>
<li><span>an analytics page for each form that shows basic analytics such as submission numbers and completion rates</span></li>
<li><span>email confirmations of submission delivery, so that form completers have a record that their submission was received by the department</span></li>
<li><span>an updated product page with a more detailed public roadmap, guidance on the product, and an easier way to send the team support requests</span></li>
</ul>
<h2><strong>Launch of Early Access</strong></h2>
<p><span>Once we’ve achieved all these things, GOV.UK Forms will be ready for launching into our ‘Early Access’ stage within private beta, with a public beta launch planned for the first half of 2024.</span></p>
<p><span>We are planning to start our Early Access period in November 2023, at which point central government departments can start trying out GOV.UK Forms to see what they can make - and if they meet the criteria, we’ll be providing access to make those forms live. This will open up in public beta when departments can provide their own editor access to form creators. As with any </span><a href="https://en.wikipedia.org/wiki/Agile_software_development"><span>agile development process</span></a><span>, timescales can shift depending on what we find out along the way, and priorities.</span></p>
<p><span>Before we move to public beta, we have some much-requested features that we’ll be working on, including:</span></p>
<ul>
<li><span>uploading file attachments</span></li>
<li><span>saving form completion progress and returning to where you left off</span></li>
<li><span>paying for services within the form</span></li>
</ul>
<p><span>We’re not currently supporting organisations outside of central government, such as local councils or NHS and Police, but we’re hoping that we can see this scope expand later in 2024 and beyond.</span></p>
<p><span>If you’re interested in what we’re up to, please visit our </span><a href="http://gov.uk/forms"><span>product page and sign up</span></a><span> to our mailing list, where we’ll update you when Early Access is launched - and please share with colleagues or any civil servants who may be interested in our form builder.</span></p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Narges Mohammadi wins 2023 Nobel Peace Prize (174 pts)]]></title>
            <link>https://www.cnn.com/world/live-news/nobel-peace-prize-2023-latest-news-intl/index.html</link>
            <guid>37788847</guid>
            <pubDate>Fri, 06 Oct 2023 10:03:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/world/live-news/nobel-peace-prize-2023-latest-news-intl/index.html">https://www.cnn.com/world/live-news/nobel-peace-prize-2023-latest-news-intl/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37788847">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="posts"><article id="h_b4532ec31260fd6918b3d037022829ae"><header><span>1 hr 5 min ago</span></header><div><p><em>Our live coverage of this year's Nobel Peace Prize has ended. Read more about </em><a href="https://www.cnn.com/2023/10/06/world/nobel-peace-prize-winner-2023-intl/index.html" target="_blank"><em>the winner, Narges Mohammadi, and reaction to the prize</em></a>.</p></div></article><article id="h_70221badb0a43a6f5fc666211bb99c84"><header><span>1 hr 13 min ago</span><h2>"A woman, a human rights advocate, and a freedom fighter"</h2><p>From CNN's Lauren Kent and Sana Noor Haq</p></header><div><div><figure><img src="https://dynaimage.cdn.cnn.com/cnn/digital-images/org/b5adc46c-4030-448a-824f-8c650c19611e.jpeg" alt="Narges Mohammadi is pictured at home in Iran during a stint out of prison on medical furlough."><figcaption>Narges Mohammadi is pictured at home in Iran during a stint out of prison on medical furlough. Reihane Taravati&nbsp;</figcaption></figure></div><p>Narges Mohammadi spearheaded the campaign for human rights in Iran, in the face of a regime that has used <a href="https://www.cnn.com/2022/10/19/middleeast/iran-protesters-repression-investigation-intl-cmd/index.html" target="_blank">torture</a> to crush dissent. </p><p>Her rallying cry grew louder in September 2022, after the death of 22-year-old Mahsa Amini while in custody of the morality police sparked <a href="https://www.cnn.com/2023/09/16/middleeast/iran-mahsa-amini-anniversary-protester-mime-intl/index.html" target="_blank">nationwide protests</a>.</p><p>Hundreds of thousands of demonstrators used the slogan -- woman, life, freedom -- to organize the biggest threat against the Iranian regime since it came into power in 1979.</p><p>Even behind bars inside Tehran's notorious Evin prison, Mohammadi used her platform to lead the same chants, according to an audio recording she <a href="https://www.cnn.com/2023/10/06/middleeast/iran-narges-mohammadi-womens-rights-mime-intl-cmd/index.html" target="_blank">shared with CNN</a>, before she won the Nobel Peace Prize on Friday.</p><div><p><q>The motto adopted by the demonstrators -- woman life freedom -- suitably expresses the dedication and work of Narges Mohammadi," Norwegian Nobel Committee chair Berit Reiss-Andersen said.</q></p></div><p><strong>A history of campaigning: </strong>Mohammadi started advocating for women's rights while studying physics in the 1990s, later working as an engineer and writing for reform minded newspapers.</p><p>In 2011, eight years after first collaborating with the defense of Human Rights Center in Tehran -- which was established by the Nobel Peace Prize Laureate, Shirin Ebadi -- Mohammadi was first arrested. </p><p>In 2013, she was released on bail and used her freedom to campaign against the death penalty in Iran. The Iranian regime has historically been among the most prolific executioners in the world. Since January 2022, more than 260 prisoners have been subject to the death penalty in Iran, Reiss-Andersen said.</p><p>Mohammadi's advocacy work against the death penalty resulted in her re-arrest in 2015. </p><p>"Upon her return to prison, she began ... opposing the regime's systematic use of torture and sexualized violence against political prisoners -- and especially women -- that is practiced in Iranian prisons," Reiss-Andersen added.</p><p>The Iranian government has denied the widespread allegations of sexual assaults against detainees, including in an in-depth <a href="https://www.cnn.com/interactive/2022/11/middleeast/iran-protests-sexual-assault/index.html" target="_blank">CNN investigation</a> last year, calling them <a href="https://www.cnn.com/videos/tv/2023/03/01/amanpour-iran-foreign-minister-hossein-amir-abdollahian-full.cnn" target="_blank">“false” and “baseless.”</a></p><p><strong>A Nobel tribute: </strong>"Last year's wave of protests became known to the political prisoners held inside the notorious ​Evin Prison in Tehran.&nbsp;Once again, Ms. Mohammadi assumed leadership from prison. She expressed support for the demonstrators and organized solidarity actions among her fellow inmates," Berit Reiss-Andersen said.</p><p>"From captivity, Ms. Mohammadi has helped to ensure that the protests have not ebbed out.</p><p>"Narges Mohammadi is a woman, a human rights advocate, and a freedom fighter. In awarding her this year's Nobel Peace Prize, the Norwegian Nobel Committee wishes to honor her courageous fight for human rights, freedom and democracy in Iran," Reiss-Andersen said.</p></div></article><article id="h_0d15955d1e9624e30622a57b89957691"><header><span>1 hr 40 min ago</span><h2>Family says award is a "source of solace for our indescribable suffering" </h2><p>From CNN's Jomana Karadsheh and Adam Pourahmadi</p></header><div><p>Narges Mohammadi's family has been reacting to the news of her Nobel Peace Prize win. </p><p>"Although the years of her absence can never be compensated for us, the reality is that the honor of recognizing Narges' efforts for peace is a source of solace for our indescribable suffering," a statement given to CNN said. </p><div><blockquote>"It has been more than eight and a half years since she has seen her children, and she has not heard their voices for over a year. All of this signifies what she has endured on the path to realizing her aspirations. <br>Therefore, for us, who know that the Nobel Peace Prize will aid her in achieving her goals, this day is a blessed day. We express our gratitude to you for your attention to Iran, the oppressed people of Iran, and the prisoners, civil activists, and protesters."</blockquote></div><p>Mohammadi's activism has come at a great <a href="https://www.cnn.com/2023/10/06/middleeast/iran-narges-mohammadi-womens-rights-mime-intl-cmd/index.html" target="_blank">personal cost</a>. She has been banned from speaking directly with her husband, Taghi Rahmani, and her children, Ali and Kiana.</p><p>Rahmani, who was himself held as a political prisoner for a total of 14 years,&nbsp;has lived in exile with their children in France since Mohammadi's imprisonment in 2015.</p></div></article><article id="h_b465df1d53fd6333afa8e3855d60a07f"><header><span>2 hr 19 min ago</span><h2>A brief history of Iran's rules on the hijab</h2></header><div><p>This years's Peace Prize sends a likely unwelcome message to the authorities in Iran, which has for decades been dictating to women how they should dress. </p><p>The Islamic regime made the hjiab compulsory in 1979, after toppling the Pahlavi dynasty. It also created the notorious &nbsp;<a href="https://edition.cnn.com/2022/09/21/middleeast/iran-morality-police-mime-intl/index.html" target="_blank">morality police</a>, tasked with ensuring that the rules are followed. </p><p>Several anti-hijab movements have emerged in Iran over the years, often leading to crackdowns by the regime, with massive waves of arrest and persecution.</p><p>Following the death of 22-year-old Mahsa Amini in September of last year, many took to the streets protesting the mandatory hijab law and other issues. </p><p>The movement was violently quashed, however, and the regime responded months later with a new hijab bill that, if passed, would enshrine unprecedentedly harsh punitive measures into law.</p><p><a href="https://edition.cnn.com/2023/08/02/middleeast/iran-hijab-draft-law-mime-intl/index.html" target="_blank">The 70-article draft law</a>, which was published on Iranian media just weeks before the one-year anniversary of the protests, set out a range of proposals, including much longer prison terms for women who refuse to wear the veil, stiff new penalties for celebrities and businesses who flout the rules, and the use of artificial intelligence to identify women in breach of the dress code.</p><p>Experts said the bill was a warning to Iranians that the regime would not back down from its stance on the hijab despite the mass demonstrations that rocked the country last year.</p><p>Days after the protest anniversary,&nbsp;<a href="https://edition.cnn.com/2023/09/21/middleeast/iran-hijab-law-parliament-jail-intl-hnk/index.html" target="_blank">Iran’s parliament last month passed</a>&nbsp;a draconian new hijab legislation, which authorities said would be enacted for a three-year trial period once the Guardian Council, which oversees legislative matters in the Islamic Republic, approves it.</p><p>Parts of the bill are ambiguous, but some clauses sanction punishments of up to 10 years, and fines between 180 million rials ($4,260) and 360 million rials ($8,520).</p><p>The punishments are a sharp split from today’s measures. Under the current Islamic penal code, those in breach of the dress code face between 10 days to two months in prison, or a fine between 50,000 to 500,000 Iranian rials, what is today between $1.18 to $11.82.</p><p>It is “a clear response to the protests from September of last fall,” Sanam Vakil, director of the Middle East and North Africa program at the Chatham House think-tank in London, told CNN in August before the bill was introduced in parliament, adding that the establishment was attempting to “reassert authority over veiling and the requirements expected of women.”</p></div></article><article id="h_f27d2a44a9a880355a078f0fec6912ad"><header><span>2 hr 37 min ago</span><h2>2022 Nobel Peace Prize winner congratulates Mohammadi </h2><p>From CNN's Sana Noor Haq</p></header><div><div><figure><img src="https://dynaimage.cdn.cnn.com/cnn/digital-images/org/0596872e-fc78-43d4-89c1-ea3c65dd654c.jpeg" alt="Ukrainian rights defender Oleksandra Matviichuk, whose Center for Civil Liberties jointly won the 2022 Nobel Peace Prize with the Russian rights organisation Memorial poses during a interview at the University Catholique of Louvain in Louvain La Neuve, Belgium, on February 16."><figcaption>Ukrainian rights defender Oleksandra Matviichuk, whose Center for Civil Liberties jointly won the 2022 Nobel Peace Prize with the Russian rights organisation Memorial poses during a interview at the University Catholique of Louvain in Louvain La Neuve, Belgium, on February 16. John Thys/AFP/Getty Images</figcaption></figure></div><p><a href="https://www.cnn.com/2023/02/22/opinions/ukraine-russia-war-crimes-putin-democracy-matviichuk/index.html" target="_blank">Oleksandra Matviichuk</a>, a Ukrainian human rights lawyer and defender who won the Nobel Peace Prize in 2022, said she welcomed the committee's decision to award Narges Mohammadi "for her fight against the oppression of women in Iran."</p><p>"We live in a very interconnected world. Right now, people in Iran are fighting for freedom. Our future depends on their success," Matviichuk posted on the social media <a href="https://x.com/avalaina/status/1710224265855840346?s=20" target="_blank">platform X</a>, formerly known as Twitter. </p><p>She heads Ukraine's Center for Civil Liberties, which was founded in 2007 to advocate human rights values in Ukraine, in order to advance democracy in the country. </p><p>The group jointly won the Nobel Peace Prize <a href="https://www.cnn.com/world/live-news/nobel-peace-prize-2022-updates-intl/h_1f56c63a249b62eb56e8a2ab10c2b0b8" target="_blank">last year</a>. It played a significant role in identifying and documenting Russian war crimes against the Ukrainian population since Moscow launched its invasion in February 2022.</p><p>Matviichuk drew parallels between her and Mohammadi's efforts to hold authoritarian regimes accountable, while raising the voices of "people fighting for freedom."</p><p>"It is more than obvious for Ukraine. I live in Kyiv, which is regularly bombarded by Russian missiles and Iranian drones. If authoritarian regimes cooperate, then people fighting for freedom have to support each other much more strongly," she said on Friday.</p></div></article><article id="h_777181cec21a8d9a1a1652d3ab0cf446"><header><span>2 hr 18 min ago</span><h2>Prize also honors "hundreds of thousands" who have demonstrated for women's rights in Iran </h2><p>From CNN"s Nadeen Ebrahim</p></header><div><div><figure><img src="https://dynaimage.cdn.cnn.com/cnn/digital-images/org/6b98c506-9a17-4545-8573-f39c764c1fb0.jpeg" alt="Protesters chant slogans during a protest over the death of a woman who was detained by the morality police, in downtown Tehran, Iran, on September 21, 2022."><figcaption>Protesters chant slogans during a protest over the death of a woman who was detained by the morality police, in downtown Tehran, Iran, on September 21, 2022. AP</figcaption></figure></div><p>“This year’s Peace Prize also recognizes the hundreds of thousands of people who in the preceding year have demonstrated against the theocratic regimes’ policies of discrimination and oppression targeting women,” Norwegian Nobel Committee chair Berit Reiss-Andersen said.</p><p>Reiss-Andersen was referring to the mass protests that broke out a year ago following the death of 22-year-old Mahsa Amini, who died in the custody of Iran’s notorious morality police.</p><p>Days after her death, Iranians took to the streets in unprecedented widespread demonstrations, with many decrying the hijab law, the impunity of the morality police and other issues. </p><p>Some called for the downfall of the regime. Authorities responded violently, suppressing the movement with widespread reports of deaths, disappearances and even torture in custody.</p><p>Iran’s morality police, which had largely pulled back following the protests last year, this year resumed street patrols, and just weeks before the one-year anniversary of Amini’s death and the protests that followed, Iranian authorities began considering a draconian new bill on hijab-wearing that experts said would enshrine unprecedentedly harsh punitive measures into law.</p><p>The country’s parliament passed a new legislation on hijab-wearing last month. </p><p>The Guardian Council, which oversees legislative matters in the Islamic Republic, still needs to approve the bill before it is implemented.</p></div></article><article id="h_e45835042fc8522518ba1a354d581e25"><header><span>2 hr 58 min ago</span><h2>Mohammadi is the 19th woman&nbsp;to win the Nobel Peace Prize</h2><p>From CNN's Thom Poole</p></header><div><div><figure><img src="https://dynaimage.cdn.cnn.com/cnn/digital-images/org/4d450a18-d1c6-49cd-8376-c93229255a35.jpeg" alt="Narges Mohammadi is pictured at home in Iran during a stint out of prison on medical furlough."><figcaption>Narges Mohammadi is pictured at home in Iran during a stint out of prison on medical furlough. Reihane&nbsp;Taravati&nbsp;</figcaption></figure></div><p>Narges Mohammadi is just the 19th woman to win the Nobel Peace Prize in more than 120 years of the prize.</p><p>Nadia Murad,&nbsp;a Yazidi human rights activist and survivor of sexual slavery at the hands of ISIS in Iraq, jointly won the prize <a href="https://www.cnn.com/2018/10/05/middleeast/nadia-murad-nobel-peace-prize-2018-intl/index.html" target="_blank">in 2018</a>.</p><p>Other female winners include Pakistani education campaigner Malala Yousafzai, and Ellen Johnson Sirleaf, who became Africa's first democratically elected woman leader when she became Liberian president in 2005.</p><p>Another Iranian woman, human rights lawyer Shirin Ebadi, won the prize in 2003. </p><p><a href="https://www.nobelpeaceprize.org/nobel-peace-prize/about-the-nobel-peace-prize/women-laureates" target="_blank">The Nobel website</a> says for much of its history the Peace Prize "had almost exclusively been the preserve of highly educated white men from Europe and the United States."</p></div></article><article id="h_0388063b0c8c52248fafd4940a4b9f99"><header><span>3 hr 8 min ago</span><h2>Mohammadi's activism in Iran has come with "tremendous personal costs"</h2><p>From CNN's Jomana Karadsheh, Adam Pourahmadi and Sana Noor Haq</p></header><div><div><figure><img src="https://dynaimage.cdn.cnn.com/cnn/digital-images/org/baf0def6-48e8-484c-8f8b-33892f01836f.jpg" alt="An archival photograph of Narges Mohammadi with her children, Kiana and Ali."><figcaption>An archival photograph of Narges Mohammadi with her children, Kiana and Ali. Courtesy of Narges Mohammadi</figcaption></figure></div><p>The Iranian regime has imprisoned Narges Mohammadi for her advocacy work against the oppression of women inside Iran.</p><p>“Her brave struggle has come with tremendous personal costs," Norwegian Nobel Committee chair Berit Reiss-Andersen said at the announcement ceremony on Friday.</p><p>The government in Iran has arrested Mohammadi 13 times, convicted her five times, and sentenced her to a total of 31 years in prison, and 154 lashes, according to Reiss-Andersenn. </p><p>Following her release on bail, she was re-arrested in 2015 and sentenced to additional time in jail, the Nobel Prize said on the social media <a href="https://x.com/NobelPrize/status/1710219279352606909?s=20" target="_blank">platform X</a>, formerly known as Twitter. </p><p>But even behind walls, she has used her voice to campaign rail against the use of the death penalty in Iran and the regime's mandatory hijab law. </p><p>Earlier this year, Iran's parliament passed draconian <a href="https://www.cnn.com/2023/09/21/middleeast/iran-hijab-law-parliament-jail-intl-hnk/index.html" target="_blank">new legislation</a> imposing much harsher penalties on women who breach hijab rules, days after the one-year anniversary of Amini's death sparked mass demonstrations.</p><p>For refusing to be silenced while in prison, Mohammadi has been banned from speaking to her husband, Taghi Rahmani, and her children, Ali and Kiana, for the past 18 months.</p><div><p><q>I am really proud of my mom,” Ali told CNN, before his mother was awarded the Nobel Peace Prize on Friday. </q></p></div><p>“She was not always with us, but whenever she was, she took good care of us… she was a good mom and still is… I have accepted this kind of life now. Any suffering that I have to endure does not matter.”</p></div></article><article id="h_0eb08f4fb4d01b41462014563bb469ad"><header><span>3 hr 27 min ago</span><h2>Nobel committee's recognition of Mohammadi sends "powerful message to the leaders of Iran"</h2><p>From CNN's Christian Edwards</p></header><div><p>The recognition of Iranian activist Narges Mohammadi by the Norwegian Nobel Committee is a "tremendous achievement for women's rights in Iran," a Peace Prize specialist told CNN.</p><p>“Narges Mohammadi was top of my shortlist. Her win is a tremendous achievement for women’s rights in Iran," Henrik Urdal, director of the Peace Research Institute Oslo, said in a statement to CNN. </p><p>"Women in the country have been fighting for equality and freedom for generations, and the death of Mahsa Amini became a catalyst against oppression and violence. Today’s laureate, unfairly jailed in Tehran, sends a powerful message to the leaders of Iran that women’s rights are fundamental everywhere in the world.”</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CCC Invites to the 37th Chaos Communication Congress in Hamburg (225 pts)]]></title>
            <link>https://www.ccc.de/en/updates/2023/37C3</link>
            <guid>37788153</guid>
            <pubDate>Fri, 06 Oct 2023 07:44:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ccc.de/en/updates/2023/37C3">https://www.ccc.de/en/updates/2023/37C3</a>, See on <a href="https://news.ycombinator.com/item?id=37788153">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>After a three-year break, the Chaos Computer Club will host its 37th Chaos Communication Congress (37C3) from 27 December to 30 December 2023. We invite you to the CCH in Hamburg for Germany's most traditional IT security and technical competence conference, the largest European gathering of the hacker scene.</p><div><p>After the success of this year's Chaos Communication Camp, the hackers have a desire and need for more exchange, topics, workshops and more party. The digital world is once again in a state of upheaval: even more mercenary hacks, even more state Trojans dragged before the Federal Constitutional Court, even more AI hyper-hyper along with wonky ideas like <a href="https://edri.org/our-work/most-criticised-eu-law-of-all-time/">chatcontrol</a>, and even more politicians who only make decisions according to lobby promises. The only thing that helps against this is to inform oneself, get positive impulses for a digital future worth living in and learn what is possible with universal computers.</p>
<p>This is what we want to offer you at 37C3 and all interested people can participate. We call on you to participate in large numbers as volunteers (so-called chaos angels). As always, the talks will be streamed live and then offered on <a href="https://media.ccc.de/">media.ccc.de</a>. We also plan to translate the lectures again into several languages.</p>
<p>As in all Camp years, we've had less time to plan and organise. Therefore, ticket sales will start later and be shorter than usual, both via vouchers and in open pre-sales. More details will be published <a href="https://events.ccc.de/">on our event blog</a> soon.</p>
<p>After being guests to the Leipziger Messe for three years while the Congress Center Hamburg (CCH) was being reconstructed, we are delighted to be returning to the familiar but modernly redesigned building this year. The space available to us there is barely a fifth of what the CCC occupied in the Congress Center Leipzig, but the paths are much shorter and vertical and there's much less volume in need of heating. Thanks to the location in Hamburg, visitors can make use of the abundant infrastructure of accommodation and catering.</p>
<p>Nevertheless, there will be slightly fewer participants at this year's Congress than in the times before Corona. The lecture programme will also be presented on fewer stages. The Call for Participation will start soon, and you will find more information <a href="https://events.ccc.de/">on the event blog</a>.</p>
<p>The 37C3 is guaranteed to take place unless prohibited by the authorities. All <a href="https://www.hamburg.de/coronavirus/">official infection control regulations</a> will of course be implemented. The CCC asks all participants to consider their own awareness of the health risks of large events before purchasing a ticket. Participants with cold symptoms are requested not to attend the event.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese Netizen Fined over 1M Yuan for Using VPN (112 pts)]]></title>
            <link>https://here.news/post/93c46bbd-ea0d-48e2-bba6-135e58887f81/chinese-netizen-fined-over-1-million-yua</link>
            <guid>37787205</guid>
            <pubDate>Fri, 06 Oct 2023 04:51:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://here.news/post/93c46bbd-ea0d-48e2-bba6-135e58887f81/chinese-netizen-fined-over-1-million-yua">https://here.news/post/93c46bbd-ea0d-48e2-bba6-135e58887f81/chinese-netizen-fined-over-1-million-yua</a>, See on <a href="https://news.ycombinator.com/item?id=37787205">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A recent incident in Chengde, China has caused public outrage as a netizen <a href="https://chinadigitaltimes.net/chinese/700552.html?utm_source=dlvr.it&amp;utm_medium=twitter" target="_blank">claimed</a> [*in Chinese] to have been fined over one million yuan and had their earnings confiscated for using a VPN to access GitHub. The individual, according to their defense statement, allegedly utilized the platform between 2019 and 2022 to complete company tasks, provide user support, and work remotely using Zoom. The Chengde Public Security Bureau's Shuangqiao Branch deemed a 200 yuan fine and the confiscation of 1,058,000 yuan in illegal earnings as appropriate.</p><p><img src="https://storage.googleapis.com/artifacts.phonic-jetty-356702.appspot.com/medias/b94a8fd8-b129-4ddc-9afb-fd53066bff5b_image_image.png" alt="Picked image"></p><p>This case stands out from previous instances involving VPN usage, which primarily targeted individuals accessing pornographic content or engaging in political activities. The ramifications of this incident have been felt across a wide range of industries, with many top intellectuals, academics, high-skilled workers, journalists, and multinational trade companies in China relying on VPNs for their work.</p><p>While some argue that the judgment in this case may be debatable, it's worth noting that certain industries have "<a href="https://www.chinalawtranslate.com/en/miit-notice-on-cleaning-up-and-regulating-the-internet-access-service-market/" target="_blank">legal channels</a>" for internet access, as opposed to using privately obtained VPN services. This distinction allows individuals in these sectors to access any website they desire without fear of repercussions, as they operate through official channels.</p><p>However, skeptics question the feasibility of these official channels, as they are not easily obtained. The process often involves various administrative procedures and certificates, making it challenging for the majority of privately-owned Chinese companies to access such channels. Additionally, even if granted access, strict surveillance measures are often implemented.</p><p>The incident has sparked discussions about the limitations imposed by China's Great Firewall and its impact on the country's talent pool. Many individuals, seeking to escape the infamous 996 work culture and age discrimination, contemplate remote work opportunities for overseas companies. However, cases like this serve as a deterrent, as individuals risk facing hefty fines and the confiscation of their hard-earned income.</p><p>Renowned Chinese journalist, Michael Anti(<a href="https://twitter.com/mranti/status/1705970310867227005" target="_blank">@mranti</a>), has criticized the Chengde Public Security Bureau's decision, highlighting not only the excessive nature of the punishment but also the potential impact on Chinese programmers and e-commerce professionals working either abroad or remotely. He questions whether these individuals will remain in China, subjecting themselves to the risk of having years' worth of earnings confiscated.</p><p>One Twitter user <a href="https://twitter.com/Ur1h37O_myz/status/1706160921700409487" target="_blank">raises an important perspective</a> on the incident, highlighting that there are legitimate pathways with private VPNs, including obtaining internet access permits and operating licenses, for information to flow from terminals to networks. All data traffic is connected through the national network's international gateway, and any communication or transmission outside of these authorized channels would not be considered official.  </p><p>As the debate continues, some netizens suggest alternative methods for those working abroad, such as exploring payment options involving USDT or BTC, cryptocurrencies that offer a level of financial flexibility and security.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rails 7.1 Released (239 pts)]]></title>
            <link>https://github.com/rails/rails/releases/tag/v7.1.0</link>
            <guid>37787130</guid>
            <pubDate>Fri, 06 Oct 2023 04:31:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rails/rails/releases/tag/v7.1.0">https://github.com/rails/rails/releases/tag/v7.1.0</a>, See on <a href="https://news.ycombinator.com/item?id=37787130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<li>
<p>Fix <code>AS::MessagePack</code> with <code>ENV["RAILS_MAX_THREADS"]</code>.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Add a new public API for broadcasting logs</p>
<p>This feature existed for a while but was until now a private API.<br>
Broadcasting log allows to send log message to difference sinks (STDOUT, a file ...) and<br>
is used by default in the development environment to write logs both on STDOUT and in the<br>
"development.log" file.</p>
<p>Basic usage:</p>
<div data-snippet-clipboard-copy-content="stdout_logger = Logger.new(STDOUT)
file_logger = Logger.new(&quot;development.log&quot;)
broadcast = ActiveSupport::BroadcastLogger.new(stdout_logger, file_logger)

broadcast.info(&quot;Hello!&quot;) # The &quot;Hello!&quot; message is written on STDOUT and in the log file."><pre><span>stdout_logger</span> <span>=</span> <span>Logger</span><span>.</span><span>new</span><span>(</span><span>STDOUT</span><span>)</span>
<span>file_logger</span> <span>=</span> <span>Logger</span><span>.</span><span>new</span><span>(</span><span>"development.log"</span><span>)</span>
<span>broadcast</span> <span>=</span> <span>ActiveSupport</span>::<span>BroadcastLogger</span><span>.</span><span>new</span><span>(</span><span>stdout_logger</span><span>,</span> <span>file_logger</span><span>)</span>

<span>broadcast</span><span>.</span><span>info</span><span>(</span><span>"Hello!"</span><span>)</span> <span># The "Hello!" message is written on STDOUT and in the log file.</span></pre></div>
<p>Adding other sink(s) to the broadcast:</p>
<div data-snippet-clipboard-copy-content="broadcast = ActiveSupport::BroadcastLogger.new
broadcast.broadcast_to(Logger.new(STDERR))"><pre><span>broadcast</span> <span>=</span> <span>ActiveSupport</span>::<span>BroadcastLogger</span><span>.</span><span>new</span>
<span>broadcast</span><span>.</span><span>broadcast_to</span><span>(</span><span>Logger</span><span>.</span><span>new</span><span>(</span><span>STDERR</span><span>)</span><span>)</span></pre></div>
<p>Remove a sink from the broadcast:</p>
<div data-snippet-clipboard-copy-content="stdout_logger = Logger.new(STDOUT)
broadcast = ActiveSupport::BroadcastLogger.new(stdout_logger)

broadcast.stop_broadcasting_to(stdout_logger)"><pre><span>stdout_logger</span> <span>=</span> <span>Logger</span><span>.</span><span>new</span><span>(</span><span>STDOUT</span><span>)</span>
<span>broadcast</span> <span>=</span> <span>ActiveSupport</span>::<span>BroadcastLogger</span><span>.</span><span>new</span><span>(</span><span>stdout_logger</span><span>)</span>

<span>broadcast</span><span>.</span><span>stop_broadcasting_to</span><span>(</span><span>stdout_logger</span><span>)</span></pre></div>
<p><em>Edouard Chin</em></p>
</li>
<li>
<p>Fix Range#overlap? not taking empty ranges into account on Ruby &lt; 3.3</p>
<p><em>Nobuyoshi Nakada</em>, <em>Shouichi Kamiya</em>, <em>Hartley McGuire</em></p>
</li>
<li>
<p>Use Ruby 3.3 Range#overlap? if available</p>
<p><em>Yasuo Honda</em></p>
</li>
<li>
<p>Add <code>bigdecimal</code> as Active Support dependency that is a bundled gem candidate for Ruby 3.4.</p>
<p><code>bigdecimal</code> 3.1.4 or higher version will be installed.<br>
Ruby 2.7 and 3.0 users who want <code>bigdecimal</code> version 2.0.0 or 3.0.0 behavior as a default gem,<br>
pin the <code>bigdecimal</code> version in your application Gemfile.</p>
<p><em>Koichi ITO</em></p>
</li>
<li>
<p>Add <code>drb</code>, <code>mutex_m</code> and <code>base64</code> that are bundled gem candidates for Ruby 3.4</p>
<p><em>Yasuo Honda</em></p>
</li>
<li>
<p>When using cache format version &gt;= 7.1 or a custom serializer, expired and<br>
version-mismatched cache entries can now be detected without deserializing<br>
their values.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Make all cache stores return a boolean for <code>#delete</code></p>
<p>Previously the <code>RedisCacheStore#delete</code> would return <code>1</code> if the entry<br>
exists and <code>0</code> otherwise. Now it returns true if the entry exists and false<br>
otherwise, just like the other stores.</p>
<p>The <code>FileStore</code> would return <code>nil</code> if the entry doesn't exists and returns<br>
<code>false</code> now as well.</p>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p>Active Support cache stores now support replacing the default compressor via<br>
a <code>:compressor</code> option. The specified compressor must respond to <code>deflate</code><br>
and <code>inflate</code>. For example:</p>
<div data-snippet-clipboard-copy-content="module MyCompressor
  def self.deflate(string)
    # compression logic...
  end

  def self.inflate(compressed)
    # decompression logic...
  end
end

config.cache_store = :redis_cache_store, { compressor: MyCompressor }"><pre><span>module</span> <span>MyCompressor</span>
  <span>def</span> <span>self</span><span>.</span><span>deflate</span><span>(</span><span>string</span><span>)</span>
    <span># compression logic...</span>
  <span>end</span>

  <span>def</span> <span>self</span><span>.</span><span>inflate</span><span>(</span><span>compressed</span><span>)</span>
    <span># decompression logic...</span>
  <span>end</span>
<span>end</span>

<span>config</span><span>.</span><span>cache_store</span> <span>=</span> <span>:redis_cache_store</span><span>,</span> <span>{</span> <span>compressor</span>: <span>MyCompressor</span> <span>}</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Active Support cache stores now support a <code>:serializer</code> option. Similar to<br>
the <code>:coder</code> option, serializers must respond to <code>dump</code> and <code>load</code>. However,<br>
serializers are only responsible for serializing a cached value, whereas<br>
coders are responsible for serializing the entire <code>ActiveSupport::Cache::Entry</code><br>
instance.  Additionally, the output from serializers can be automatically<br>
compressed, whereas coders are responsible for their own compression.</p>
<p>Specifying a serializer instead of a coder also enables performance<br>
optimizations, including the bare string optimization introduced by cache<br>
format version 7.1.</p>
<p>The <code>:serializer</code> and <code>:coder</code> options are mutually exclusive. Specifying<br>
both will raise an <code>ArgumentError</code>.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Fix <code>ActiveSupport::Inflector.humanize(nil)</code> raising <code>NoMethodError: undefined method `end_with?' for nil:NilClass</code>.</p>
<p><em>James Robinson</em></p>
</li>
<li>
<p>Don't show secrets for <code>ActiveSupport::KeyGenerator#inspect</code>.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="ActiveSupport::KeyGenerator.new(secret).inspect
&quot;#<ActiveSupport::KeyGenerator:0x0000000104888038 ... @secret=\&quot;\\xAF\\bFh]LV}q\\nl\\xB2U\\xB3 ... >&quot;"><pre><span>ActiveSupport</span>::<span>KeyGenerator</span><span>.</span><span>new</span><span>(</span><span>secret</span><span>)</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveSupport::KeyGenerator:0x0000000104888038 ... @secret=<span>\"</span><span>\\</span>xAF<span>\\</span>bFh]LV}q<span>\\</span>nl<span>\\</span>xB2U<span>\\</span>xB3 ... &gt;"</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="ActiveSupport::KeyGenerator::Aes256Gcm(secret).inspect
&quot;#<ActiveSupport::KeyGenerator:0x0000000104888038>&quot;"><pre><span>ActiveSupport</span>::<span>KeyGenerator</span>::<span>Aes256Gcm</span><span>(</span><span>secret</span><span>)</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveSupport::KeyGenerator:0x0000000104888038&gt;"</span></pre></div>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p>Improve error message when EventedFileUpdateChecker is used without a<br>
compatible version of the Listen gem</p>
<p><em>Hartley McGuire</em></p>
</li>
<li>
<p>Add <code>:report</code> behavior for Deprecation</p>
<p>Setting <code>config.active_support.deprecation = :report</code> uses the error<br>
reporter to report deprecation warnings to <code>ActiveSupport::ErrorReporter</code>.</p>
<p>Deprecations are reported as handled errors, with a severity of <code>:warning</code>.</p>
<p>Useful to report deprecations happening in production to your bug tracker.</p>
<p><em>Étienne Barrié</em></p>
</li>
<li>
<p>Rename <code>Range#overlaps?</code> to <code>#overlap?</code> and add alias for backwards compatibility</p>
<p><em>Christian Schmidt</em></p>
</li>
<li>
<p>Fix <code>EncryptedConfiguration</code> returning incorrect values for some <code>Hash</code><br>
methods</p>
<p><em>Hartley McGuire</em></p>
</li>
<li>
<p>Don't show secrets for <code>MessageEncryptor#inspect</code>.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="ActiveSupport::MessageEncryptor.new(secret, cipher: &quot;aes-256-gcm&quot;).inspect
&quot;#<ActiveSupport::MessageEncryptor:0x0000000104888038 ... @secret=\&quot;\\xAF\\bFh]LV}q\\nl\\xB2U\\xB3 ... >&quot;"><pre><span>ActiveSupport</span>::<span>MessageEncryptor</span><span>.</span><span>new</span><span>(</span><span>secret</span><span>,</span> <span>cipher</span>: <span>"aes-256-gcm"</span><span>)</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveSupport::MessageEncryptor:0x0000000104888038 ... @secret=<span>\"</span><span>\\</span>xAF<span>\\</span>bFh]LV}q<span>\\</span>nl<span>\\</span>xB2U<span>\\</span>xB3 ... &gt;"</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="ActiveSupport::MessageEncryptor.new(secret, cipher: &quot;aes-256-gcm&quot;).inspect
&quot;#<ActiveSupport::MessageEncryptor:0x0000000104888038>&quot;"><pre><span>ActiveSupport</span>::<span>MessageEncryptor</span><span>.</span><span>new</span><span>(</span><span>secret</span><span>,</span> <span>cipher</span>: <span>"aes-256-gcm"</span><span>)</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveSupport::MessageEncryptor:0x0000000104888038&gt;"</span></pre></div>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p>Don't show contents for <code>EncryptedConfiguration#inspect</code>.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="Rails.application.credentials.inspect
&quot;#<ActiveSupport::EncryptedConfiguration:0x000000010d2b38e8 ... @config={:secret=>\&quot;something secret\&quot;} ... @key_file_contents=\&quot;915e4ea054e011022398dc242\&quot; ...>&quot;"><pre><span>Rails</span><span>.</span><span>application</span><span>.</span><span>credentials</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveSupport::EncryptedConfiguration:0x000000010d2b38e8 ... @config={:secret=&gt;<span>\"</span>something secret<span>\"</span>} ... @key_file_contents=<span>\"</span>915e4ea054e011022398dc242<span>\"</span> ...&gt;"</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="Rails.application.credentials.inspect
&quot;#<ActiveSupport::EncryptedConfiguration:0x000000010d2b38e8>&quot;"><pre><span>Rails</span><span>.</span><span>application</span><span>.</span><span>credentials</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveSupport::EncryptedConfiguration:0x000000010d2b38e8&gt;"</span></pre></div>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p><code>ERB::Util.html_escape_once</code> always returns an <code>html_safe</code> string.</p>
<p>This method previously maintained the <code>html_safe?</code> property of a string on the return<br>
value. Because this string has been escaped, however, not marking it as <code>html_safe</code> causes<br>
entities to be double-escaped.</p>
<p>As an example, take this view snippet:</p>
<div data-snippet-clipboard-copy-content="<p><%= html_escape_once(&quot;this &amp; that &amp;amp; the other&quot;) %></p>"><pre><span>&lt;</span><span>p</span><span>&gt;</span><span>&lt;</span>%= html_escape_once("this &amp; that &amp;amp; the other") %<span>&gt;</span><span>&lt;/</span><span>p</span><span>&gt;</span></pre></div>
<p>Before this change, that would be double-escaped and render as:</p>
<div data-snippet-clipboard-copy-content="<p>this &amp;amp;amp; that &amp;amp;amp; the other</p>"><pre><span>&lt;</span><span>p</span><span>&gt;</span>this &amp;amp;amp; that &amp;amp;amp; the other<span>&lt;/</span><span>p</span><span>&gt;</span></pre></div>
<p>After this change, it renders correctly as:</p>
<div data-snippet-clipboard-copy-content="<p>this &amp;amp; that &amp;amp; the other</p>"><pre><span>&lt;</span><span>p</span><span>&gt;</span>this &amp;amp; that &amp;amp; the other<span>&lt;/</span><span>p</span><span>&gt;</span></pre></div>
<p>Fixes <a data-error-text="Failed to load title" data-id="1717796292" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/48256" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/48256/hovercard" href="https://github.com/rails/rails/issues/48256">#48256</a></p>
<p><em>Mike Dalessio</em></p>
</li>
<li>
<p>Deprecate <code>SafeBuffer#clone_empty</code>.</p>
<p>This method has not been used internally since Rails 4.2.0.</p>
<p><em>Mike Dalessio</em></p>
</li>
<li>
<p><code>MessageEncryptor</code>, <code>MessageVerifier</code>, and <code>config.active_support.message_serializer</code><br>
now accept <code>:message_pack</code> and <code>:message_pack_allow_marshal</code> as serializers.<br>
These serializers require the <a href="https://rubygems.org/gems/msgpack" rel="nofollow"><code>msgpack</code> gem</a><br>
(&gt;= 1.7.0).</p>
<p>The Message Pack format can provide improved performance and smaller payload<br>
sizes. It also supports round-tripping some Ruby types that are not supported<br>
by JSON. For example:</p>
<div data-snippet-clipboard-copy-content="verifier = ActiveSupport::MessageVerifier.new(&quot;secret&quot;)
data = [{ a: 1 }, { b: 2 }.with_indifferent_access, 1.to_d, Time.at(0, 123)]
message = verifier.generate(data)

# BEFORE with config.active_support.message_serializer = :json
verifier.verified(message)
# => [{&quot;a&quot;=>1}, {&quot;b&quot;=>2}, &quot;1.0&quot;, &quot;1969-12-31T18:00:00.000-06:00&quot;]
verifier.verified(message).map(&amp;:class)
# => [Hash, Hash, String, String]

# AFTER with config.active_support.message_serializer = :message_pack
verifier.verified(message)
# => [{:a=>1}, {&quot;b&quot;=>2}, 0.1e1, 1969-12-31 18:00:00.000123 -0600]
verifier.verified(message).map(&amp;:class)
# => [Hash, ActiveSupport::HashWithIndifferentAccess, BigDecimal, Time]"><pre><span>verifier</span> <span>=</span> <span>ActiveSupport</span>::<span>MessageVerifier</span><span>.</span><span>new</span><span>(</span><span>"secret"</span><span>)</span>
<span>data</span> <span>=</span> <span>[</span><span>{</span> <span>a</span>: <span>1</span> <span>}</span><span>,</span> <span>{</span> <span>b</span>: <span>2</span> <span>}</span><span>.</span><span>with_indifferent_access</span><span>,</span> <span>1</span><span>.</span><span>to_d</span><span>,</span> <span>Time</span><span>.</span><span>at</span><span>(</span><span>0</span><span>,</span> <span>123</span><span>)</span><span>]</span>
<span>message</span> <span>=</span> <span>verifier</span><span>.</span><span>generate</span><span>(</span><span>data</span><span>)</span>

<span># BEFORE with config.active_support.message_serializer = :json</span>
<span>verifier</span><span>.</span><span>verified</span><span>(</span><span>message</span><span>)</span>
<span># =&gt; [{"a"=&gt;1}, {"b"=&gt;2}, "1.0", "1969-12-31T18:00:00.000-06:00"]</span>
<span>verifier</span><span>.</span><span>verified</span><span>(</span><span>message</span><span>)</span><span>.</span><span>map</span><span>(</span>&amp;<span>:class</span><span>)</span>
<span># =&gt; [Hash, Hash, String, String]</span>

<span># AFTER with config.active_support.message_serializer = :message_pack</span>
<span>verifier</span><span>.</span><span>verified</span><span>(</span><span>message</span><span>)</span>
<span># =&gt; [{:a=&gt;1}, {"b"=&gt;2}, 0.1e1, 1969-12-31 18:00:00.000123 -0600]</span>
<span>verifier</span><span>.</span><span>verified</span><span>(</span><span>message</span><span>)</span><span>.</span><span>map</span><span>(</span>&amp;<span>:class</span><span>)</span>
<span># =&gt; [Hash, ActiveSupport::HashWithIndifferentAccess, BigDecimal, Time]</span></pre></div>
<p>The <code>:message_pack</code> serializer can fall back to deserializing with<br>
<code>ActiveSupport::JSON</code> when necessary, and the <code>:message_pack_allow_marshal</code><br>
serializer can fall back to deserializing with <code>Marshal</code> as well as<br>
<code>ActiveSupport::JSON</code>. Additionally, the <code>:marshal</code>, <code>:json</code>, and<br>
<code>:json_allow_marshal</code> serializers can now fall back to deserializing with<br>
<code>ActiveSupport::MessagePack</code> when necessary. These behaviors ensure old<br>
messages can still be read so that migration is easier.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>A new <code>7.1</code> cache format is available which includes an optimization for<br>
bare string values such as view fragments.</p>
<p>The <code>7.1</code> cache format is used by default for new apps, and existing apps<br>
can enable the format by setting <code>config.load_defaults 7.1</code> or by setting<br>
<code>config.active_support.cache_format_version = 7.1</code> in <code>config/application.rb</code><br>
or a <code>config/environments/*.rb</code> file.</p>
<p>Cache entries written using the <code>6.1</code> or <code>7.0</code> cache formats can be read<br>
when using the <code>7.1</code> format. To perform a rolling deploy of a Rails 7.1<br>
upgrade, wherein servers that have not yet been upgraded must be able to<br>
read caches from upgraded servers, leave the cache format unchanged on the<br>
first deploy, then enable the <code>7.1</code> cache format on a subsequent deploy.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Active Support cache stores can now use a preconfigured serializer based on<br>
<code>ActiveSupport::MessagePack</code> via the <code>:serializer</code> option:</p>
<div data-snippet-clipboard-copy-content="config.cache_store = :redis_cache_store, { serializer: :message_pack }"><pre><span>config</span><span>.</span><span>cache_store</span> <span>=</span> <span>:redis_cache_store</span><span>,</span> <span>{</span> <span>serializer</span>: <span>:message_pack</span> <span>}</span></pre></div>
<p>The <code>:message_pack</code> serializer can reduce cache entry sizes and improve<br>
performance, but requires the <a href="https://rubygems.org/gems/msgpack" rel="nofollow"><code>msgpack</code> gem</a><br>
(&gt;= 1.7.0).</p>
<p>The <code>:message_pack</code> serializer can read cache entries written by the default<br>
serializer, and the default serializer can now read entries written by the<br>
<code>:message_pack</code> serializer. These behaviors make it easy to migrate between<br>
serializer without invalidating the entire cache.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p><code>Object#deep_dup</code> no longer duplicate named classes and modules.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="hash = { class: Object, module: Kernel }
hash.deep_dup # => {:class=>#<Class:0x00000001063ffc80>, :module=>#<Module:0x00000001063ffa00>}"><pre><span>hash</span> <span>=</span> <span>{</span> <span>class</span>: <span>Object</span><span>,</span> <span>module</span>: <span>Kernel</span> <span>}</span>
<span>hash</span><span>.</span><span>deep_dup</span> <span># =&gt; {:class=&gt;#&lt;Class:0x00000001063ffc80&gt;, :module=&gt;#&lt;Module:0x00000001063ffa00&gt;}</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="hash = { class: Object, module: Kernel }
hash.deep_dup # => {:class=>Object, :module=>Kernel}"><pre><span>hash</span> <span>=</span> <span>{</span> <span>class</span>: <span>Object</span><span>,</span> <span>module</span>: <span>Kernel</span> <span>}</span>
<span>hash</span><span>.</span><span>deep_dup</span> <span># =&gt; {:class=&gt;Object, :module=&gt;Kernel}</span></pre></div>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Consistently raise an <code>ArgumentError</code> if the <code>ActiveSupport::Cache</code> key is blank.</p>
<p><em>Joshua Young</em></p>
</li>
<li>
<p>Deprecate usage of the singleton <code>ActiveSupport::Deprecation</code>.</p>
<p>All usage of <code>ActiveSupport::Deprecation</code> as a singleton is deprecated, the most common one being<br>
<code>ActiveSupport::Deprecation.warn</code>. Gem authors should now create their own deprecator (<code>ActiveSupport::Deprecation</code><br>
object), and use it to emit deprecation warnings.</p>
<p>Calling any of the following without specifying a deprecator argument is also deprecated:</p>
<ul>
<li>Module.deprecate</li>
<li>deprecate_constant</li>
<li>DeprecatedObjectProxy</li>
<li>DeprecatedInstanceVariableProxy</li>
<li>DeprecatedConstantProxy</li>
<li>deprecation-related test assertions</li>
</ul>
<p>Use of <code>ActiveSupport::Deprecation.silence</code> and configuration methods like <code>behavior=</code>, <code>disallowed_behavior=</code>,<br>
<code>disallowed_warnings=</code> should now be aimed at the <a href="https://api.rubyonrails.org/classes/Rails/Application.html#method-i-deprecators" rel="nofollow">application's deprecators</a>.</p>
<div data-snippet-clipboard-copy-content="Rails.application.deprecators.silence do
  # code that emits deprecation warnings
end"><pre><span>Rails</span><span>.</span><span>application</span><span>.</span><span>deprecators</span><span>.</span><span>silence</span> <span>do</span>
  <span># code that emits deprecation warnings</span>
<span>end</span></pre></div>
<p>If your gem has a Railtie or Engine, it's encouraged to add your deprecator to the application's deprecators, that<br>
way the deprecation related configuration options will apply to it as well, e.g.<br>
<code>config.active_support.report_deprecations</code> set to <code>false</code> in the production environment will also disable your<br>
deprecator.</p>
<div data-snippet-clipboard-copy-content="initializer &quot;my_gem.deprecator&quot; do |app|
  app.deprecators[:my_gem] = MyGem.deprecator
end"><pre><span>initializer</span> <span>"my_gem.deprecator"</span> <span>do</span> |<span>app</span>|
  <span>app</span><span>.</span><span>deprecators</span><span>[</span><span>:my_gem</span><span>]</span> <span>=</span> <span>MyGem</span><span>.</span><span>deprecator</span>
<span>end</span></pre></div>
<p><em>Étienne Barrié</em></p>
</li>
<li>
<p>Add <code>Object#with</code> to set and restore public attributes around a block</p>
<div data-snippet-clipboard-copy-content="client.timeout # => 5
client.with(timeout: 1) do
  client.timeout # => 1
end
client.timeout # => 5"><pre><span>client</span><span>.</span><span>timeout</span> <span># =&gt; 5</span>
<span>client</span><span>.</span><span>with</span><span>(</span><span>timeout</span>: <span>1</span><span>)</span> <span>do</span>
  <span>client</span><span>.</span><span>timeout</span> <span># =&gt; 1</span>
<span>end</span>
<span>client</span><span>.</span><span>timeout</span> <span># =&gt; 5</span></pre></div>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Remove deprecated support to generate incorrect RFC 4122 UUIDs when providing a namespace ID that is not one of the<br>
constants defined on <code>Digest::UUID</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Deprecate <code>config.active_support.use_rfc4122_namespaced_uuids</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove implicit conversion of objects into <code>String</code> by <code>ActiveSupport::SafeBuffer</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated <code>active_support/core_ext/range/include_time_with_zone</code> file.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Deprecate <code>config.active_support.remove_deprecated_time_with_zone_name</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated override of <code>ActiveSupport::TimeWithZone.name</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Deprecate <code>config.active_support.disable_to_s_conversion</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated option to passing a format to <code>#to_s</code> in <code>Array</code>, <code>Range</code>, <code>Date</code>, <code>DateTime</code>, <code>Time</code>,<br>
<code>BigDecimal</code>, <code>Float</code> and, <code>Integer</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated <code>ActiveSupport::PerThreadRegistry</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated override of <code>Enumerable#sum</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Deprecated initializing a <code>ActiveSupport::Cache::MemCacheStore</code> with an instance of <code>Dalli::Client</code>.</p>
<p>Deprecate the undocumented option of providing an already-initialized instance of <code>Dalli::Client</code> to <code>ActiveSupport::Cache::MemCacheStore</code>. Such clients could be configured with unrecognized options, which could lead to unexpected behavior. Instead, provide addresses as documented.</p>
<p><em>aledustet</em></p>
</li>
<li>
<p>Stub <code>Time.new()</code> in <code>TimeHelpers#travel_to</code></p>
<div data-snippet-clipboard-copy-content="travel_to Time.new(2004, 11, 24) do
  # Inside the `travel_to` block `Time.new` is stubbed
  assert_equal 2004, Time.new.year
end"><pre><span>travel_to</span> <span>Time</span><span>.</span><span>new</span><span>(</span><span>2004</span><span>,</span> <span>11</span><span>,</span> <span>24</span><span>)</span> <span>do</span>
  <span># Inside the `travel_to` block `Time.new` is stubbed</span>
  <span>assert_equal</span> <span>2004</span><span>,</span> <span>Time</span><span>.</span><span>new</span><span>.</span><span>year</span>
<span>end</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Raise <code>ActiveSupport::MessageEncryptor::InvalidMessage</code> from<br>
<code>ActiveSupport::MessageEncryptor#decrypt_and_verify</code> regardless of cipher.<br>
Previously, when a <code>MessageEncryptor</code> was using a non-AEAD cipher such as<br>
AES-256-CBC, a corrupt or tampered message would raise<br>
<code>ActiveSupport::MessageVerifier::InvalidSignature</code>.  Now, all ciphers raise<br>
the same error:</p>
<div data-snippet-clipboard-copy-content="encryptor = ActiveSupport::MessageEncryptor.new(&quot;x&quot; * 32, cipher: &quot;aes-256-gcm&quot;)
message = encryptor.encrypt_and_sign(&quot;message&quot;)
encryptor.decrypt_and_verify(message.next)
# => raises ActiveSupport::MessageEncryptor::InvalidMessage

encryptor = ActiveSupport::MessageEncryptor.new(&quot;x&quot; * 32, cipher: &quot;aes-256-cbc&quot;)
message = encryptor.encrypt_and_sign(&quot;message&quot;)
encryptor.decrypt_and_verify(message.next)
# BEFORE:
# => raises ActiveSupport::MessageVerifier::InvalidSignature
# AFTER:
# => raises ActiveSupport::MessageEncryptor::InvalidMessage"><pre><span>encryptor</span> <span>=</span> <span>ActiveSupport</span>::<span>MessageEncryptor</span><span>.</span><span>new</span><span>(</span><span>"x"</span> * <span>32</span><span>,</span> <span>cipher</span>: <span>"aes-256-gcm"</span><span>)</span>
<span>message</span> <span>=</span> <span>encryptor</span><span>.</span><span>encrypt_and_sign</span><span>(</span><span>"message"</span><span>)</span>
<span>encryptor</span><span>.</span><span>decrypt_and_verify</span><span>(</span><span>message</span><span>.</span><span>next</span><span>)</span>
<span># =&gt; raises ActiveSupport::MessageEncryptor::InvalidMessage</span>

<span>encryptor</span> <span>=</span> <span>ActiveSupport</span>::<span>MessageEncryptor</span><span>.</span><span>new</span><span>(</span><span>"x"</span> * <span>32</span><span>,</span> <span>cipher</span>: <span>"aes-256-cbc"</span><span>)</span>
<span>message</span> <span>=</span> <span>encryptor</span><span>.</span><span>encrypt_and_sign</span><span>(</span><span>"message"</span><span>)</span>
<span>encryptor</span><span>.</span><span>decrypt_and_verify</span><span>(</span><span>message</span><span>.</span><span>next</span><span>)</span>
<span># BEFORE:</span>
<span># =&gt; raises ActiveSupport::MessageVerifier::InvalidSignature</span>
<span># AFTER:</span>
<span># =&gt; raises ActiveSupport::MessageEncryptor::InvalidMessage</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Support <code>nil</code> original values when using <code>ActiveSupport::MessageVerifier#verify</code>.<br>
Previously, <code>MessageVerifier#verify</code> did not work with <code>nil</code> original<br>
values, though both <code>MessageVerifier#verified</code> and<br>
<code>MessageEncryptor#decrypt_and_verify</code> do:</p>
<div data-snippet-clipboard-copy-content="encryptor = ActiveSupport::MessageEncryptor.new(secret)
message = encryptor.encrypt_and_sign(nil)

encryptor.decrypt_and_verify(message)
# => nil

verifier = ActiveSupport::MessageVerifier.new(secret)
message = verifier.generate(nil)

verifier.verified(message)
# => nil

verifier.verify(message)
# BEFORE:
# => raises ActiveSupport::MessageVerifier::InvalidSignature
# AFTER:
# => nil"><pre><span>encryptor</span> <span>=</span> <span>ActiveSupport</span>::<span>MessageEncryptor</span><span>.</span><span>new</span><span>(</span><span>secret</span><span>)</span>
<span>message</span> <span>=</span> <span>encryptor</span><span>.</span><span>encrypt_and_sign</span><span>(</span><span>nil</span><span>)</span>

<span>encryptor</span><span>.</span><span>decrypt_and_verify</span><span>(</span><span>message</span><span>)</span>
<span># =&gt; nil</span>

<span>verifier</span> <span>=</span> <span>ActiveSupport</span>::<span>MessageVerifier</span><span>.</span><span>new</span><span>(</span><span>secret</span><span>)</span>
<span>message</span> <span>=</span> <span>verifier</span><span>.</span><span>generate</span><span>(</span><span>nil</span><span>)</span>

<span>verifier</span><span>.</span><span>verified</span><span>(</span><span>message</span><span>)</span>
<span># =&gt; nil</span>

<span>verifier</span><span>.</span><span>verify</span><span>(</span><span>message</span><span>)</span>
<span># BEFORE:</span>
<span># =&gt; raises ActiveSupport::MessageVerifier::InvalidSignature</span>
<span># AFTER:</span>
<span># =&gt; nil</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Maintain <code>html_safe?</code> on html_safe strings when sliced with <code>slice</code>, <code>slice!</code>, or <code>chr</code> method.</p>
<p>Previously, <code>html_safe?</code> was only maintained when the html_safe strings were sliced<br>
with <code>[]</code> method. Now, <code>slice</code>, <code>slice!</code>, and <code>chr</code> methods will maintain <code>html_safe?</code> like <code>[]</code> method.</p>
<div data-snippet-clipboard-copy-content="string = &quot;<div>test</div>&quot;.html_safe
string.slice(0, 1).html_safe? # => true
string.slice!(0, 1).html_safe? # => true
# maintain html_safe? after the slice!
string.html_safe? # => true
string.chr.html_safe? # => true"><pre><span>string</span> <span>=</span> <span>"&lt;div&gt;test&lt;/div&gt;"</span><span>.</span><span>html_safe</span>
<span>string</span><span>.</span><span>slice</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>html_safe?</span> <span># =&gt; true</span>
<span>string</span><span>.</span><span>slice!</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>html_safe?</span> <span># =&gt; true</span>
<span># maintain html_safe? after the slice!</span>
<span>string</span><span>.</span><span>html_safe?</span> <span># =&gt; true</span>
<span>string</span><span>.</span><span>chr</span><span>.</span><span>html_safe?</span> <span># =&gt; true</span></pre></div>
<p><em>Michael Go</em></p>
</li>
<li>
<p>Add <code>Object#in?</code> support for open ranges.</p>
<div data-snippet-clipboard-copy-content="assert Date.today.in?(..Date.tomorrow)
assert_not Date.today.in?(Date.tomorrow..)"><pre><span>assert</span> <span>Date</span><span>.</span><span>today</span><span>.</span><span>in?</span><span>(</span>..<span>Date</span><span>.</span><span>tomorrow</span><span>)</span>
<span>assert_not</span> <span>Date</span><span>.</span><span>today</span><span>.</span><span>in?</span><span>(</span><span>Date</span><span>.</span><span>tomorrow</span>..<span>)</span></pre></div>
<p><em>Ignacio Galindo</em></p>
</li>
<li>
<p><code>config.i18n.raise_on_missing_translations = true</code> now raises on any missing translation.</p>
<p>Previously it would only raise when called in a view or controller. Now it will raise<br>
anytime <code>I18n.t</code> is provided an unrecognised key.</p>
<p>If you do not want this behaviour, you can customise the i18n exception handler. See the<br>
upgrading guide or i18n guide for more information.</p>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p><code>ActiveSupport::CurrentAttributes</code> now raises if a restricted attribute name is used.</p>
<p>Attributes such as <code>set</code> and <code>reset</code> cannot be used as they clash with the<br>
<code>CurrentAttributes</code> public API.</p>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p><code>HashWithIndifferentAccess#transform_keys</code> now takes a Hash argument, just<br>
as Ruby's <code>Hash#transform_keys</code> does.</p>
<p><em>Akira Matsuda</em></p>
</li>
<li>
<p><code>delegate</code> now defines method with proper arity when delegating to a Class.<br>
With this change, it defines faster method (3.5x faster with no argument).<br>
However, in order to gain this benefit, the delegation target method has to<br>
be defined before declaring the delegation.</p>
<div data-snippet-clipboard-copy-content="# This defines 3.5 times faster method than before
class C
  def self.x() end
  delegate :x, to: :class
end

class C
  # This works but silently falls back to old behavior because
  # `delegate` cannot find the definition of `x`
  delegate :x, to: :class
  def self.x() end
end"><pre><span># This defines 3.5 times faster method than before</span>
<span>class</span> <span>C</span>
  <span>def</span> <span>self</span><span>.</span><span>x</span><span>(</span><span>)</span> <span>end</span>
  <span>delegate</span> <span>:x</span><span>,</span> <span>to</span>: <span>:class</span>
<span>end</span>

<span>class</span> <span>C</span>
  <span># This works but silently falls back to old behavior because</span>
  <span># `delegate` cannot find the definition of `x`</span>
  <span>delegate</span> <span>:x</span><span>,</span> <span>to</span>: <span>:class</span>
  <span>def</span> <span>self</span><span>.</span><span>x</span><span>(</span><span>)</span> <span>end</span>
<span>end</span></pre></div>
<p><em>Akira Matsuda</em></p>
</li>
<li>
<p><code>assert_difference</code> message now includes what changed.</p>
<p>This makes it easier to debug non-obvious failures.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="&quot;User.count&quot; didn't change by 32.
Expected: 1611
  Actual: 1579"><pre><code>"User.count" didn't change by 32.
Expected: 1611
  Actual: 1579
</code></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="&quot;User.count&quot; didn't change by 32, but by 0.
Expected: 1611
  Actual: 1579"><pre><code>"User.count" didn't change by 32, but by 0.
Expected: 1611
  Actual: 1579
</code></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Add ability to match exception messages to <code>assert_raises</code> assertion</p>
<p>Instead of this</p>
<div data-snippet-clipboard-copy-content="error = assert_raises(ArgumentError) do
  perform_service(param: 'exception')
end
assert_match(/incorrect param/i, error.message)"><pre><span>error</span> <span>=</span> <span>assert_raises</span><span>(</span><span>ArgumentError</span><span>)</span> <span>do</span>
  <span>perform_service</span><span>(</span><span>param</span>: <span>'exception'</span><span>)</span>
<span>end</span>
<span>assert_match</span><span>(</span><span>/incorrect param/i</span><span>,</span> <span>error</span><span>.</span><span>message</span><span>)</span></pre></div>
<p>you can now write this</p>
<div data-snippet-clipboard-copy-content="assert_raises(ArgumentError, match: /incorrect param/i) do
  perform_service(param: 'exception')
end"><pre><span>assert_raises</span><span>(</span><span>ArgumentError</span><span>,</span> <span>match</span>: <span>/incorrect param/i</span><span>)</span> <span>do</span>
  <span>perform_service</span><span>(</span><span>param</span>: <span>'exception'</span><span>)</span>
<span>end</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Add <code>Rails.env.local?</code> shorthand for <code>Rails.env.development? || Rails.env.test?</code>.</p>
<p><em>DHH</em></p>
</li>
<li>
<p><code>ActiveSupport::Testing::TimeHelpers</code> now accepts named <code>with_usec</code> argument<br>
to <code>freeze_time</code>, <code>travel</code>, and <code>travel_to</code> methods. Passing true prevents<br>
truncating the destination time with <code>change(usec: 0)</code>.</p>
<p><em>KevSlashNull</em>, and <em>serprex</em></p>
</li>
<li>
<p><code>ActiveSupport::CurrentAttributes.resets</code> now accepts a method name</p>
<p>The block API is still the recommended approach, but now both APIs are supported:</p>
<div data-snippet-clipboard-copy-content="class Current < ActiveSupport::CurrentAttributes
  resets { Time.zone = nil }
  resets :clear_time_zone
end"><pre><span>class</span> <span>Current</span> &lt; <span>ActiveSupport</span>::<span>CurrentAttributes</span>
  <span>resets</span> <span>{</span> <span>Time</span><span>.</span><span>zone</span> <span>=</span> <span>nil</span> <span>}</span>
  <span>resets</span> <span>:clear_time_zone</span>
<span>end</span></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Ensure <code>ActiveSupport::Testing::Isolation::Forking</code> closes pipes</p>
<p>Previously, <code>Forking.run_in_isolation</code> opened two ends of a pipe. The fork<br>
process closed the read end, wrote to it, and then terminated (which<br>
presumably closed the file descriptors on its end). The parent process<br>
closed the write end, read from it, and returned, never closing the read<br>
end.</p>
<p>This resulted in an accumulation of open file descriptors, which could<br>
cause errors if the limit is reached.</p>
<p><em>Sam Bostock</em></p>
</li>
<li>
<p>Fix <code>Time#change</code> and <code>Time#advance</code> for times around the end of Daylight<br>
Saving Time.</p>
<p>Previously, when <code>Time#change</code> or <code>Time#advance</code> constructed a time inside<br>
the final stretch of Daylight Saving Time (DST), the non-DST offset would<br>
always be chosen for local times:</p>
<div data-snippet-clipboard-copy-content="# DST ended just before 2021-11-07 2:00:00 AM in US/Eastern.
ENV[&quot;TZ&quot;] = &quot;US/Eastern&quot;

time = Time.local(2021, 11, 07, 00, 59, 59) + 1
# => 2021-11-07 01:00:00 -0400
time.change(day: 07)
# => 2021-11-07 01:00:00 -0500
time.advance(seconds: 0)
# => 2021-11-07 01:00:00 -0500

time = Time.local(2021, 11, 06, 01, 00, 00)
# => 2021-11-06 01:00:00 -0400
time.change(day: 07)
# => 2021-11-07 01:00:00 -0500
time.advance(days: 1)
# => 2021-11-07 01:00:00 -0500"><pre><span># DST ended just before 2021-11-07 2:00:00 AM in US/Eastern.</span>
<span>ENV</span><span>[</span><span>"TZ"</span><span>]</span> <span>=</span> <span>"US/Eastern"</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>local</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>07</span><span>,</span> <span>00</span><span>,</span> <span>59</span><span>,</span> <span>59</span><span>)</span> + <span>1</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>seconds</span>: <span>0</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>local</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>06</span><span>,</span> <span>01</span><span>,</span> <span>00</span><span>,</span> <span>00</span><span>)</span>
<span># =&gt; 2021-11-06 01:00:00 -0400</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>days</span>: <span>1</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span></pre></div>
<p>And the DST offset would always be chosen for times with a <code>TimeZone</code><br>
object:</p>
<div data-snippet-clipboard-copy-content="Time.zone = &quot;US/Eastern&quot;

time = Time.new(2021, 11, 07, 02, 00, 00, Time.zone) - 3600
# => 2021-11-07 01:00:00 -0500
time.change(day: 07)
# => 2021-11-07 01:00:00 -0400
time.advance(seconds: 0)
# => 2021-11-07 01:00:00 -0400

time = Time.new(2021, 11, 8, 01, 00, 00, Time.zone)
# => 2021-11-08 01:00:00 -0500
time.change(day: 07)
# => 2021-11-07 01:00:00 -0400
time.advance(days: -1)
# => 2021-11-07 01:00:00 -0400"><pre><span>Time</span><span>.</span><span>zone</span> <span>=</span> <span>"US/Eastern"</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>new</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>07</span><span>,</span> <span>02</span><span>,</span> <span>00</span><span>,</span> <span>00</span><span>,</span> <span>Time</span><span>.</span><span>zone</span><span>)</span> - <span>3600</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>seconds</span>: <span>0</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>new</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>8</span><span>,</span> <span>01</span><span>,</span> <span>00</span><span>,</span> <span>00</span><span>,</span> <span>Time</span><span>.</span><span>zone</span><span>)</span>
<span># =&gt; 2021-11-08 01:00:00 -0500</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>days</span>: -<span>1</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span></pre></div>
<p>Now, <code>Time#change</code> and <code>Time#advance</code> will choose the offset that matches<br>
the original time's offset when possible:</p>
<div data-snippet-clipboard-copy-content="ENV[&quot;TZ&quot;] = &quot;US/Eastern&quot;

time = Time.local(2021, 11, 07, 00, 59, 59) + 1
# => 2021-11-07 01:00:00 -0400
time.change(day: 07)
# => 2021-11-07 01:00:00 -0400
time.advance(seconds: 0)
# => 2021-11-07 01:00:00 -0400

time = Time.local(2021, 11, 06, 01, 00, 00)
# => 2021-11-06 01:00:00 -0400
time.change(day: 07)
# => 2021-11-07 01:00:00 -0400
time.advance(days: 1)
# => 2021-11-07 01:00:00 -0400

Time.zone = &quot;US/Eastern&quot;

time = Time.new(2021, 11, 07, 02, 00, 00, Time.zone) - 3600
# => 2021-11-07 01:00:00 -0500
time.change(day: 07)
# => 2021-11-07 01:00:00 -0500
time.advance(seconds: 0)
# => 2021-11-07 01:00:00 -0500

time = Time.new(2021, 11, 8, 01, 00, 00, Time.zone)
# => 2021-11-08 01:00:00 -0500
time.change(day: 07)
# => 2021-11-07 01:00:00 -0500
time.advance(days: -1)
# => 2021-11-07 01:00:00 -0500"><pre><span>ENV</span><span>[</span><span>"TZ"</span><span>]</span> <span>=</span> <span>"US/Eastern"</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>local</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>07</span><span>,</span> <span>00</span><span>,</span> <span>59</span><span>,</span> <span>59</span><span>)</span> + <span>1</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>seconds</span>: <span>0</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>local</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>06</span><span>,</span> <span>01</span><span>,</span> <span>00</span><span>,</span> <span>00</span><span>)</span>
<span># =&gt; 2021-11-06 01:00:00 -0400</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>days</span>: <span>1</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0400</span>

<span>Time</span><span>.</span><span>zone</span> <span>=</span> <span>"US/Eastern"</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>new</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>07</span><span>,</span> <span>02</span><span>,</span> <span>00</span><span>,</span> <span>00</span><span>,</span> <span>Time</span><span>.</span><span>zone</span><span>)</span> - <span>3600</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>seconds</span>: <span>0</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>

<span>time</span> <span>=</span> <span>Time</span><span>.</span><span>new</span><span>(</span><span>2021</span><span>,</span> <span>11</span><span>,</span> <span>8</span><span>,</span> <span>01</span><span>,</span> <span>00</span><span>,</span> <span>00</span><span>,</span> <span>Time</span><span>.</span><span>zone</span><span>)</span>
<span># =&gt; 2021-11-08 01:00:00 -0500</span>
<span>time</span><span>.</span><span>change</span><span>(</span><span>day</span>: <span>07</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span>
<span>time</span><span>.</span><span>advance</span><span>(</span><span>days</span>: -<span>1</span><span>)</span>
<span># =&gt; 2021-11-07 01:00:00 -0500</span></pre></div>
<p><em>Kevin Hall</em>, <em>Takayoshi Nishida</em>, and <em>Jonathan Hefner</em></p>
</li>
<li>
<p>Fix MemoryStore to preserve entries TTL when incrementing or decrementing</p>
<p>This is to be more consistent with how MemCachedStore and RedisCacheStore behaves.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p><code>Rails.error.handle</code> and <code>Rails.error.record</code> filter now by multiple error classes.</p>
<div data-snippet-clipboard-copy-content="Rails.error.handle(IOError, ArgumentError) do
  1 + '1' # raises TypeError
end
1 + 1 # TypeErrors are not IOErrors or ArgumentError, so this will *not* be handled"><pre><span>Rails</span><span>.</span><span>error</span><span>.</span><span>handle</span><span>(</span><span>IOError</span><span>,</span> <span>ArgumentError</span><span>)</span> <span>do</span>
  <span>1</span> + <span>'1'</span> <span># raises TypeError</span>
<span>end</span>
<span>1</span> + <span>1</span> <span># TypeErrors are not IOErrors or ArgumentError, so this will *not* be handled</span></pre></div>
<p><em>Martin Spickermann</em></p>
</li>
<li>
<p><code>Class#subclasses</code> and <code>Class#descendants</code> now automatically filter reloaded classes.</p>
<p>Previously they could return old implementations of reloadable classes that have been<br>
dereferenced but not yet garbage collected.</p>
<p>They now automatically filter such classes like <code>DescendantTracker#subclasses</code> and<br>
<code>DescendantTracker#descendants</code>.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p><code>Rails.error.report</code> now marks errors as reported to avoid reporting them twice.</p>
<p>In some cases, users might want to report errors explicitly with some extra context<br>
before letting it bubble up.</p>
<p>This also allows to safely catch and report errors outside of the execution context.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Add <code>assert_error_reported</code> and <code>assert_no_error_reported</code></p>
<p>Allows to easily asserts an error happened but was handled</p>
<div data-snippet-clipboard-copy-content="report = assert_error_reported(IOError) do
  # ...
end
assert_equal &quot;Oops&quot;, report.error.message
assert_equal &quot;admin&quot;, report.context[:section]
assert_equal :warning, report.severity
assert_predicate report, :handled?"><pre><span>report</span> <span>=</span> <span>assert_error_reported</span><span>(</span><span>IOError</span><span>)</span> <span>do</span>
  <span># ...</span>
<span>end</span>
<span>assert_equal</span> <span>"Oops"</span><span>,</span> <span>report</span><span>.</span><span>error</span><span>.</span><span>message</span>
<span>assert_equal</span> <span>"admin"</span><span>,</span> <span>report</span><span>.</span><span>context</span><span>[</span><span>:section</span><span>]</span>
<span>assert_equal</span> <span>:warning</span><span>,</span> <span>report</span><span>.</span><span>severity</span>
<span>assert_predicate</span> <span>report</span><span>,</span> <span>:handled?</span></pre></div>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p><code>ActiveSupport::Deprecation</code> behavior callbacks can now receive the<br>
deprecator instance as an argument.  This makes it easier for such callbacks<br>
to change their behavior based on the deprecator's state.  For example,<br>
based on the deprecator's <code>debug</code> flag.</p>
<p>3-arity and splat-args callbacks such as the following will now be passed<br>
the deprecator instance as their third argument:</p>
<ul>
<li><code>-&gt;(message, callstack, deprecator) { ... }</code></li>
<li><code>-&gt;(*args) { ... }</code></li>
<li><code>-&gt;(message, *other_args) { ... }</code></li>
</ul>
<p>2-arity and 4-arity callbacks such as the following will continue to behave<br>
the same as before:</p>
<ul>
<li><code>-&gt;(message, callstack) { ... }</code></li>
<li><code>-&gt;(message, callstack, deprecation_horizon, gem_name) { ... }</code></li>
<li><code>-&gt;(message, callstack, *deprecation_details) { ... }</code></li>
</ul>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p><code>ActiveSupport::Deprecation#disallowed_warnings</code> now affects the instance on<br>
which it is configured.</p>
<p>This means that individual <code>ActiveSupport::Deprecation</code> instances can be<br>
configured with their own disallowed warnings, and the global<br>
<code>ActiveSupport::Deprecation.disallowed_warnings</code> now only affects the global<br>
<code>ActiveSupport::Deprecation.warn</code>.</p>
<p><strong>Before</strong></p>
<div data-snippet-clipboard-copy-content="ActiveSupport::Deprecation.disallowed_warnings = [&quot;foo&quot;]
deprecator = ActiveSupport::Deprecation.new(&quot;2.0&quot;, &quot;MyCoolGem&quot;)
deprecator.disallowed_warnings = [&quot;bar&quot;]

ActiveSupport::Deprecation.warn(&quot;foo&quot;) # => raise ActiveSupport::DeprecationException
ActiveSupport::Deprecation.warn(&quot;bar&quot;) # => print &quot;DEPRECATION WARNING: bar&quot;
deprecator.warn(&quot;foo&quot;)                 # => raise ActiveSupport::DeprecationException
deprecator.warn(&quot;bar&quot;)                 # => print &quot;DEPRECATION WARNING: bar&quot;"><pre><span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>disallowed_warnings</span> <span>=</span> <span>[</span><span>"foo"</span><span>]</span>
<span>deprecator</span> <span>=</span> <span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>new</span><span>(</span><span>"2.0"</span><span>,</span> <span>"MyCoolGem"</span><span>)</span>
<span>deprecator</span><span>.</span><span>disallowed_warnings</span> <span>=</span> <span>[</span><span>"bar"</span><span>]</span>

<span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>warn</span><span>(</span><span>"foo"</span><span>)</span> <span># =&gt; raise ActiveSupport::DeprecationException</span>
<span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>warn</span><span>(</span><span>"bar"</span><span>)</span> <span># =&gt; print "DEPRECATION WARNING: bar"</span>
<span>deprecator</span><span>.</span><span>warn</span><span>(</span><span>"foo"</span><span>)</span>                 <span># =&gt; raise ActiveSupport::DeprecationException</span>
<span>deprecator</span><span>.</span><span>warn</span><span>(</span><span>"bar"</span><span>)</span>                 <span># =&gt; print "DEPRECATION WARNING: bar"</span></pre></div>
<p><strong>After</strong></p>
<div data-snippet-clipboard-copy-content="ActiveSupport::Deprecation.disallowed_warnings = [&quot;foo&quot;]
deprecator = ActiveSupport::Deprecation.new(&quot;2.0&quot;, &quot;MyCoolGem&quot;)
deprecator.disallowed_warnings = [&quot;bar&quot;]

ActiveSupport::Deprecation.warn(&quot;foo&quot;) # => raise ActiveSupport::DeprecationException
ActiveSupport::Deprecation.warn(&quot;bar&quot;) # => print &quot;DEPRECATION WARNING: bar&quot;
deprecator.warn(&quot;foo&quot;)                 # => print &quot;DEPRECATION WARNING: foo&quot;
deprecator.warn(&quot;bar&quot;)                 # => raise ActiveSupport::DeprecationException"><pre><span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>disallowed_warnings</span> <span>=</span> <span>[</span><span>"foo"</span><span>]</span>
<span>deprecator</span> <span>=</span> <span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>new</span><span>(</span><span>"2.0"</span><span>,</span> <span>"MyCoolGem"</span><span>)</span>
<span>deprecator</span><span>.</span><span>disallowed_warnings</span> <span>=</span> <span>[</span><span>"bar"</span><span>]</span>

<span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>warn</span><span>(</span><span>"foo"</span><span>)</span> <span># =&gt; raise ActiveSupport::DeprecationException</span>
<span>ActiveSupport</span>::<span>Deprecation</span><span>.</span><span>warn</span><span>(</span><span>"bar"</span><span>)</span> <span># =&gt; print "DEPRECATION WARNING: bar"</span>
<span>deprecator</span><span>.</span><span>warn</span><span>(</span><span>"foo"</span><span>)</span>                 <span># =&gt; print "DEPRECATION WARNING: foo"</span>
<span>deprecator</span><span>.</span><span>warn</span><span>(</span><span>"bar"</span><span>)</span>                 <span># =&gt; raise ActiveSupport::DeprecationException</span></pre></div>
<p>Note that global <code>ActiveSupport::Deprecation</code> methods such as <code>ActiveSupport::Deprecation.warn</code><br>
and <code>ActiveSupport::Deprecation.disallowed_warnings</code> have been deprecated.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Add italic and underline support to <code>ActiveSupport::LogSubscriber#color</code></p>
<p>Previously, only bold text was supported via a positional argument.<br>
This allows for bold, italic, and underline options to be specified<br>
for colored logs.</p>
<div data-snippet-clipboard-copy-content="info color(&quot;Hello world!&quot;, :red, bold: true, underline: true)"><pre><span>info</span> <span>color</span><span>(</span><span>"Hello world!"</span><span>,</span> <span>:red</span><span>,</span> <span>bold</span>: <span>true</span><span>,</span> <span>underline</span>: <span>true</span><span>)</span></pre></div>
<p><em>Gannon McGibbon</em></p>
</li>
<li>
<p>Add <code>String#downcase_first</code> method.</p>
<p>This method is the corollary of <code>String#upcase_first</code>.</p>
<p><em>Mark Schneider</em></p>
</li>
<li>
<p><code>thread_mattr_accessor</code> will call <code>.dup.freeze</code> on non-frozen default values.</p>
<p>This provides a basic level of protection against different threads trying<br>
to mutate a shared default object.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Add <code>raise_on_invalid_cache_expiration_time</code> config to <code>ActiveSupport::Cache::Store</code></p>
<p>Specifies if an <code>ArgumentError</code> should be raised if <code>Rails.cache</code> <code>fetch</code> or<br>
<code>write</code> are given an invalid <code>expires_at</code> or <code>expires_in</code> time.</p>
<p>Options are <code>true</code>, and <code>false</code>. If <code>false</code>, the exception will be reported<br>
as <code>handled</code> and logged instead. Defaults to <code>true</code> if <code>config.load_defaults &gt;= 7.1</code>.</p>
<p><em>Trevor Turk</em></p>
</li>
<li>
<p><code>ActiveSupport::Cache:Store#fetch</code> now passes an options accessor to the block.</p>
<p>It makes possible to override cache options:</p>
<div data-snippet-clipboard-copy-content="Rails.cache.fetch(&quot;3rd-party-token&quot;) do |name, options|
  token = fetch_token_from_remote
  # set cache's TTL to match token's TTL
  options.expires_in = token.expires_in
  token
end"><pre><code>Rails.cache.fetch("3rd-party-token") do |name, options|
  token = fetch_token_from_remote
  # set cache's TTL to match token's TTL
  options.expires_in = token.expires_in
  token
end
</code></pre></div>
<p><em>Andrii Gladkyi</em>, <em>Jean Boussier</em></p>
</li>
<li>
<p><code>default</code> option of <code>thread_mattr_accessor</code> now applies through inheritance and<br>
also across new threads.</p>
<p>Previously, the <code>default</code> value provided was set only at the moment of defining<br>
the attribute writer, which would cause the attribute to be uninitialized in<br>
descendants and in other threads.</p>
<p>Fixes <a data-error-text="Failed to load title" data-id="1008053433" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/43312" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/43312/hovercard" href="https://github.com/rails/rails/issues/43312">#43312</a>.</p>
<p><em>Thierry Deo</em></p>
</li>
<li>
<p>Redis cache store is now compatible with redis-rb 5.0.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Add <code>skip_nil:</code> support to <code>ActiveSupport::Cache::Store#fetch_multi</code>.</p>
<p><em>Daniel Alfaro</em></p>
</li>
<li>
<p>Add <code>quarter</code> method to date/time</p>
<p><em>Matt Swanson</em></p>
</li>
<li>
<p>Fix <code>NoMethodError</code> on custom <code>ActiveSupport::Deprecation</code> behavior.</p>
<p><code>ActiveSupport::Deprecation.behavior=</code> was supposed to accept any object<br>
that responds to <code>call</code>, but in fact its internal implementation assumed that<br>
this object could respond to <code>arity</code>, so it was restricted to only <code>Proc</code> objects.</p>
<p>This change removes this <code>arity</code> restriction of custom behaviors.</p>
<p><em>Ryo Nakamura</em></p>
</li>
<li>
<p>Support <code>:url_safe</code> option for <code>MessageEncryptor</code>.</p>
<p>The <code>MessageEncryptor</code> constructor now accepts a <code>:url_safe</code> option, similar<br>
to the <code>MessageVerifier</code> constructor.  When enabled, this option ensures<br>
that messages use a URL-safe encoding.</p>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Add <code>url_safe</code> option to <code>ActiveSupport::MessageVerifier</code> initializer</p>
<p><code>ActiveSupport::MessageVerifier.new</code> now takes optional <code>url_safe</code> argument.<br>
It can generate URL-safe strings by passing <code>url_safe: true</code>.</p>
<div data-snippet-clipboard-copy-content="verifier = ActiveSupport::MessageVerifier.new(url_safe: true)
message = verifier.generate(data) # => URL-safe string"><pre><span>verifier</span> <span>=</span> <span>ActiveSupport</span>::<span>MessageVerifier</span><span>.</span><span>new</span><span>(</span><span>url_safe</span>: <span>true</span><span>)</span>
<span>message</span> <span>=</span> <span>verifier</span><span>.</span><span>generate</span><span>(</span><span>data</span><span>)</span> <span># =&gt; URL-safe string</span></pre></div>
<p>This option is <code>false</code> by default to be backwards compatible.</p>
<p><em>Shouichi Kamiya</em></p>
</li>
<li>
<p>Enable connection pooling by default for <code>MemCacheStore</code> and <code>RedisCacheStore</code>.</p>
<p>If you want to disable connection pooling, set <code>:pool</code> option to <code>false</code> when configuring the cache store:</p>
<div data-snippet-clipboard-copy-content="config.cache_store = :mem_cache_store, &quot;cache.example.com&quot;, pool: false"><pre><span>config</span><span>.</span><span>cache_store</span> <span>=</span> <span>:mem_cache_store</span><span>,</span> <span>"cache.example.com"</span><span>,</span> <span>pool</span>: <span>false</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Add <code>force:</code> support to <code>ActiveSupport::Cache::Store#fetch_multi</code>.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Deprecated <code>:pool_size</code> and <code>:pool_timeout</code> options for configuring connection pooling in cache stores.</p>
<p>Use <code>pool: true</code> to enable pooling with default settings:</p>
<div data-snippet-clipboard-copy-content="config.cache_store = :redis_cache_store, pool: true"><pre><span>config</span><span>.</span><span>cache_store</span> <span>=</span> <span>:redis_cache_store</span><span>,</span> <span>pool</span>: <span>true</span></pre></div>
<p>Or pass individual options via <code>:pool</code> option:</p>
<div data-snippet-clipboard-copy-content="config.cache_store = :redis_cache_store, pool: { size: 10, timeout: 2 }"><pre><span>config</span><span>.</span><span>cache_store</span> <span>=</span> <span>:redis_cache_store</span><span>,</span> <span>pool</span>: <span>{</span> <span>size</span>: <span>10</span><span>,</span> <span>timeout</span>: <span>2</span> <span>}</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Allow #increment and #decrement methods of <code>ActiveSupport::Cache::Store</code><br>
subclasses to set new values.</p>
<p>Previously incrementing or decrementing an unset key would fail and return<br>
nil. A default will now be assumed and the key will be created.</p>
<p><em>Andrej Blagojević</em>, <em>Eugene Kenny</em></p>
</li>
<li>
<p>Add <code>skip_nil:</code> support to <code>RedisCacheStore</code></p>
<p><em>Joey Paris</em></p>
</li>
<li>
<p><code>ActiveSupport::Cache::MemoryStore#write(name, val, unless_exist:true)</code> now<br>
correctly writes expired keys.</p>
<p><em>Alan Savage</em></p>
</li>
<li>
<p><code>ActiveSupport::ErrorReporter</code> now accepts and forward a <code>source:</code> parameter.</p>
<p>This allow libraries to signal the origin of the errors, and reporters<br>
to easily ignore some sources.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Fix and add protections for XSS in <code>ActionView::Helpers</code> and <code>ERB::Util</code>.</p>
<p>Add the method <code>ERB::Util.xml_name_escape</code> to escape dangerous characters<br>
in names of tags and names of attributes, following the specification of XML.</p>
<p><em>Álvaro Martín Fraguas</em></p>
</li>
<li>
<p>Respect <code>ActiveSupport::Logger.new</code>'s <code>:formatter</code> keyword argument</p>
<p>The stdlib <code>Logger::new</code> allows passing a <code>:formatter</code> keyword argument to<br>
set the logger's formatter. Previously <code>ActiveSupport::Logger.new</code> ignored<br>
that argument by always setting the formatter to an instance of<br>
<code>ActiveSupport::Logger::SimpleFormatter</code>.</p>
<p><em>Steven Harman</em></p>
</li>
<li>
<p>Deprecate preserving the pre-Ruby 2.4 behavior of <code>to_time</code></p>
<p>With Ruby 2.4+ the default for +to_time+ changed from converting to the<br>
local system time to preserving the offset of the receiver. At the time Rails<br>
supported older versions of Ruby so a compatibility layer was added to assist<br>
in the migration process. From Rails 5.0 new applications have defaulted to<br>
the Ruby 2.4+ behavior and since Rails 7.0 now only supports Ruby 2.7+<br>
this compatibility layer can be safely removed.</p>
<p>To minimize any noise generated the deprecation warning only appears when the<br>
setting is configured to <code>false</code> as that is the only scenario where the<br>
removal of the compatibility layer has any effect.</p>
<p><em>Andrew White</em></p>
</li>
<li>
<p><code>Pathname.blank?</code> only returns true for <code>Pathname.new("")</code></p>
<p>Previously it would end up calling <code>Pathname#empty?</code> which returned true<br>
if the path existed and was an empty directory or file.</p>
<p>That behavior was unlikely to be expected.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Deprecate <code>Notification::Event</code>'s <code>#children</code> and <code>#parent_of?</code></p>
<p><em>John Hawthorn</em></p>
</li>
<li>
<p>Change the default serializer of <code>ActiveSupport::MessageVerifier</code> from<br>
<code>Marshal</code> to <code>ActiveSupport::JSON</code> when using <code>config.load_defaults 7.1</code>.</p>
<p>Messages serialized with <code>Marshal</code> can still be read, but new messages will<br>
be serialized with <code>ActiveSupport::JSON</code>. For more information, see<br>
<a href="https://guides.rubyonrails.org/v7.1/configuring.html#config-active-support-message-serializer" rel="nofollow">https://guides.rubyonrails.org/v7.1/configuring.html#config-active-support-message-serializer</a>.</p>
<p><em>Saba Kiaei</em>, <em>David Buckley</em>, and <em>Jonathan Hefner</em></p>
</li>
<li>
<p>Change the default serializer of <code>ActiveSupport::MessageEncryptor</code> from<br>
<code>Marshal</code> to <code>ActiveSupport::JSON</code> when using <code>config.load_defaults 7.1</code>.</p>
<p>Messages serialized with <code>Marshal</code> can still be read, but new messages will<br>
be serialized with <code>ActiveSupport::JSON</code>. For more information, see<br>
<a href="https://guides.rubyonrails.org/v7.1/configuring.html#config-active-support-message-serializer" rel="nofollow">https://guides.rubyonrails.org/v7.1/configuring.html#config-active-support-message-serializer</a>.</p>
<p><em>Zack Deveau</em>, <em>Martin Gingras</em>, and <em>Jonathan Hefner</em></p>
</li>
<li>
<p>Add <code>ActiveSupport::TestCase#stub_const</code> to stub a constant for the duration of a yield.</p>
<p><em>DHH</em></p>
</li>
<li>
<p>Fix <code>ActiveSupport::EncryptedConfiguration</code> to be compatible with Psych 4</p>
<p><em>Stephen Sugden</em></p>
</li>
<li>
<p>Improve <code>File.atomic_write</code> error handling</p>
<p><em>Daniel Pepper</em></p>
</li>
<li>
<p>Fix <code>Class#descendants</code> and <code>DescendantsTracker#descendants</code> compatibility with Ruby 3.1.</p>
<p><a href="https://bugs.ruby-lang.org/issues/14394#note-33" rel="nofollow">The native <code>Class#descendants</code> was reverted prior to Ruby 3.1 release</a>,<br>
but <code>Class#subclasses</code> was kept, breaking the feature detection.</p>
<p><em>Jean Boussier</em></p>
</li>
</div><div>
<li>
<p>Remove -shm and -wal SQLite files when <code>rails db:drop</code> is run.</p>
<p><em>Niklas Häusele</em></p>
</li>
<li>
<p>Revert the change to raise an <code>ArgumentError</code> when <code>#accepts_nested_attributes_for</code> is declared more than once for<br>
an association in the same class.</p>
<p>The reverted behavior broke the case where the <code>#accepts_nested_attributes_for</code> was defined in a concern and<br>
where overridden in the class that included the concern.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Better naming for unique constraints support.</p>
<p>Naming unique keys leads to misunderstanding it's a short-hand of unique indexes.<br>
Just naming it unique constraints is not misleading.</p>
<p>In Rails 7.1.0.beta1 or before:</p>
<div data-snippet-clipboard-copy-content="add_unique_key :sections, [:position], deferrable: :deferred, name: &quot;unique_section_position&quot;
remove_unique_key :sections, name: &quot;unique_section_position&quot;"><pre><span>add_unique_key</span> <span>:sections</span><span>,</span> <span>[</span><span>:position</span><span>]</span><span>,</span> <span>deferrable</span>: <span>:deferred</span><span>,</span> <span>name</span>: <span>"unique_section_position"</span>
<span>remove_unique_key</span> <span>:sections</span><span>,</span> <span>name</span>: <span>"unique_section_position"</span></pre></div>
<p>Now:</p>
<div data-snippet-clipboard-copy-content="add_unique_constraint :sections, [:position], deferrable: :deferred, name: &quot;unique_section_position&quot;
remove_unique_constraint :sections, name: &quot;unique_section_position&quot;"><pre><span>add_unique_constraint</span> <span>:sections</span><span>,</span> <span>[</span><span>:position</span><span>]</span><span>,</span> <span>deferrable</span>: <span>:deferred</span><span>,</span> <span>name</span>: <span>"unique_section_position"</span>
<span>remove_unique_constraint</span> <span>:sections</span><span>,</span> <span>name</span>: <span>"unique_section_position"</span></pre></div>
<p><em>Ryuta Kamizono</em></p>
</li>
<li>
<p>Fix duplicate quoting for check constraint expressions in schema dump when using MySQL</p>
<p>A check constraint with an expression, that already contains quotes, lead to an invalid schema<br>
dump with the mysql2 adapter.</p>
<p>Fixes <a data-error-text="Failed to load title" data-id="915248782" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/42424" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/42424/hovercard" href="https://github.com/rails/rails/issues/42424">#42424</a>.</p>
<p><em>Felix Tscheulin</em></p>
</li>
<li>
<p>Performance tune the SQLite3 adapter connection configuration</p>
<p>For Rails applications, the Write-Ahead-Log in normal syncing mode with a capped journal size, a healthy shared memory buffer and a shared cache will perform, on average, 2× better.</p>
<p><em>Stephen Margheim</em></p>
</li>
<li>
<p>Allow SQLite3 <code>busy_handler</code> to be configured with simple max number of <code>retries</code></p>
<p>Retrying busy connections without delay is a preferred practice for performance-sensitive applications. Add support for a <code>database.yml</code> <code>retries</code> integer, which is used in a simple <code>busy_handler</code> function to retry busy connections without exponential backoff up to the max number of <code>retries</code>.</p>
<p><em>Stephen Margheim</em></p>
</li>
<li>
<p>The SQLite3 adapter now supports <code>supports_insert_returning?</code></p>
<p>Implementing the full <code>supports_insert_returning?</code> contract means the SQLite3 adapter supports auto-populated columns (<a data-error-text="Failed to load title" data-id="1712735611" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/48241" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/48241/hovercard" href="https://github.com/rails/rails/pull/48241">#48241</a>) as well as custom primary keys.</p>
<p><em>Stephen Margheim</em></p>
</li>
<li>
<p>Ensure the SQLite3 adapter handles default functions with the <code>||</code> concatenation operator</p>
<p>Previously, this default function would produce the static string <code>"'Ruby ' || 'on ' || 'Rails'"</code>.<br>
Now, the adapter will appropriately receive and use <code>"Ruby on Rails"</code>.</p>
<div data-snippet-clipboard-copy-content="change_column_default &quot;test_models&quot;, &quot;ruby_on_rails&quot;, -> { &quot;('Ruby ' || 'on ' || 'Rails')&quot; }"><pre><span>change_column_default</span> <span>"test_models"</span><span>,</span> <span>"ruby_on_rails"</span><span>,</span> <span>-&gt;</span> <span>{</span> <span>"('Ruby ' || 'on ' || 'Rails')"</span> <span>}</span></pre></div>
<p><em>Stephen Margheim</em></p>
</li>
<li>
<p>Dump PostgreSQL schemas as part of the schema dump.</p>
<p><em>Lachlan Sylvester</em></p>
</li>
<li>
<p>Encryption now supports <code>support_unencrypted_data</code> being set per-attribute.</p>
<p>You can now opt out of <code>support_unencrypted_data</code> on a specific encrypted attribute.<br>
This only has an effect if <code>ActiveRecord::Encryption.config.support_unencrypted_data == true</code>.</p>
<div data-snippet-clipboard-copy-content="class User < ActiveRecord::Base
  encrypts :name, deterministic: true, support_unencrypted_data: false
  encrypts :email, deterministic: true
end"><pre><span>class</span> <span>User</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>encrypts</span> <span>:name</span><span>,</span> <span>deterministic</span>: <span>true</span><span>,</span> <span>support_unencrypted_data</span>: <span>false</span>
  <span>encrypts</span> <span>:email</span><span>,</span> <span>deterministic</span>: <span>true</span>
<span>end</span></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Add instrumentation for Active Record transactions</p>
<p>Allows subscribing to transaction events for tracking/instrumentation. The event payload contains the connection and the outcome (commit, rollback, restart, incomplete), as well as timing details.</p>
<div data-snippet-clipboard-copy-content="ActiveSupport::Notifications.subscribe(&quot;transaction.active_record&quot;) do |event|
  puts &quot;Transaction event occurred!&quot;
  connection = event.payload[:connection]
  puts &quot;Connection: #{connection.inspect}&quot;
end"><pre><span>ActiveSupport</span>::<span>Notifications</span><span>.</span><span>subscribe</span><span>(</span><span>"transaction.active_record"</span><span>)</span> <span>do</span> |<span>event</span>|
  <span>puts</span> <span>"Transaction event occurred!"</span>
  <span>connection</span> <span>=</span> <span>event</span><span>.</span><span>payload</span><span>[</span><span>:connection</span><span>]</span>
  <span>puts</span> <span>"Connection: <span><span>#{</span><span>connection</span><span>.</span><span>inspect</span><span>}</span></span>"</span>
<span>end</span></pre></div>
<p><em>Daniel Colson</em>, <em>Ian Candy</em></p>
</li>
<li>
<p>Support composite foreign keys via migration helpers.</p>
<div data-snippet-clipboard-copy-content="# Assuming &quot;carts&quot; table has &quot;(shop_id, user_id)&quot; as a primary key.

add_foreign_key(:orders, :carts, primary_key: [:shop_id, :user_id])

remove_foreign_key(:orders, :carts, primary_key: [:shop_id, :user_id])
foreign_key_exists?(:orders, :carts, primary_key: [:shop_id, :user_id])"><pre><span># Assuming "carts" table has "(shop_id, user_id)" as a primary key.</span>

<span>add_foreign_key</span><span>(</span><span>:orders</span><span>,</span> <span>:carts</span><span>,</span> <span>primary_key</span>: <span>[</span><span>:shop_id</span><span>,</span> <span>:user_id</span><span>]</span><span>)</span>

<span>remove_foreign_key</span><span>(</span><span>:orders</span><span>,</span> <span>:carts</span><span>,</span> <span>primary_key</span>: <span>[</span><span>:shop_id</span><span>,</span> <span>:user_id</span><span>]</span><span>)</span>
<span>foreign_key_exists?</span><span>(</span><span>:orders</span><span>,</span> <span>:carts</span><span>,</span> <span>primary_key</span>: <span>[</span><span>:shop_id</span><span>,</span> <span>:user_id</span><span>]</span><span>)</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Adds support for <code>if_not_exists</code> when adding a check constraint.</p>
<div data-snippet-clipboard-copy-content="add_check_constraint :posts, &quot;post_type IN ('blog', 'comment', 'share')&quot;, if_not_exists: true"><pre><span>add_check_constraint</span> <span>:posts</span><span>,</span> <span>"post_type IN ('blog', 'comment', 'share')"</span><span>,</span> <span>if_not_exists</span>: <span>true</span></pre></div>
<p><em>Cody Cutrer</em></p>
</li>
<li>
<p>Raise an <code>ArgumentError</code> when <code>#accepts_nested_attributes_for</code> is declared more than once for an association in<br>
the same class. Previously, the last declaration would silently override the previous one. Overriding in a subclass<br>
is still allowed.</p>
<p><em>Joshua Young</em></p>
</li>
<li>
<p>Deprecate <code>rewhere</code> argument on <code>#merge</code>.</p>
<p>The <code>rewhere</code> argument on <code>#merge</code>is deprecated without replacement and<br>
will be removed in Rails 7.2.</p>
<p><em>Adam Hess</em></p>
</li>
<li>
<p>Fix unscope is not working in specific case</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="Post.where(id: 1...3).unscope(where: :id).to_sql # &quot;SELECT `posts`.* FROM `posts` WHERE `posts`.`id` >= 1 AND `posts`.`id` < 3&quot;
"><pre><span>Post</span><span>.</span><span>where</span><span>(</span><span>id</span>: <span>1</span>...<span>3</span><span>)</span><span>.</span><span>unscope</span><span>(</span><span>where</span>: <span>:id</span><span>)</span><span>.</span><span>to_sql</span> <span># "SELECT `posts`.* FROM `posts` WHERE `posts`.`id` &gt;= 1 AND `posts`.`id` &lt; 3"</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="Post.where(id: 1...3).unscope(where: :id).to_sql # &quot;SELECT `posts`.* FROM `posts`&quot;"><pre><span>Post</span><span>.</span><span>where</span><span>(</span><span>id</span>: <span>1</span>...<span>3</span><span>)</span><span>.</span><span>unscope</span><span>(</span><span>where</span>: <span>:id</span><span>)</span><span>.</span><span>to_sql</span> <span># "SELECT `posts`.* FROM `posts`"</span></pre></div>
<p>Fixes <a data-error-text="Failed to load title" data-id="1689435061" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/48094" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/48094/hovercard" href="https://github.com/rails/rails/issues/48094">#48094</a>.</p>
<p><em>Kazuya Hatanaka</em></p>
</li>
<li>
<p>Change <code>has_secure_token</code> default to <code>on: :initialize</code></p>
<p>Change the new default value from <code>on: :create</code> to <code>on: :initialize</code></p>
<p>Can be controlled by the <code>config.active_record.generate_secure_token_on</code><br>
configuration:</p>
<div data-snippet-clipboard-copy-content="config.active_record.generate_secure_token_on = :create"><pre><span>config</span><span>.</span><span>active_record</span><span>.</span><span>generate_secure_token_on</span> <span>=</span> <span>:create</span></pre></div>
<p><em>Sean Doyle</em></p>
</li>
<li>
<p>Fix <code>change_column</code> not setting <code>precision: 6</code> on <code>datetime</code> columns when<br>
using 7.0+ Migrations and SQLite.</p>
<p><em>Hartley McGuire</em></p>
</li>
<li>
<p>Support composite identifiers in <code>to_key</code></p>
<p><code>to_key</code> avoids wrapping <code>#id</code> value into an <code>Array</code> if <code>#id</code> already an array</p>
<p><em>Nikita Vasilevsky</em></p>
</li>
<li>
<p>Add validation option for <code>enum</code></p>
<div data-snippet-clipboard-copy-content="class Contract < ApplicationRecord
  enum :status, %w[in_progress completed], validate: true
end
Contract.new(status: &quot;unknown&quot;).valid? # => false
Contract.new(status: nil).valid? # => false
Contract.new(status: &quot;completed&quot;).valid? # => true

class Contract < ApplicationRecord
  enum :status, %w[in_progress completed], validate: { allow_nil: true }
end
Contract.new(status: &quot;unknown&quot;).valid? # => false
Contract.new(status: nil).valid? # => true
Contract.new(status: &quot;completed&quot;).valid? # => true"><pre><span>class</span> <span>Contract</span> &lt; <span>ApplicationRecord</span>
  <span>enum</span> <span>:status</span><span>,</span> <span>%w[</span><span>in_progress</span> <span>completed</span><span>]</span><span>,</span> <span>validate</span>: <span>true</span>
<span>end</span>
<span>Contract</span><span>.</span><span>new</span><span>(</span><span>status</span>: <span>"unknown"</span><span>)</span><span>.</span><span>valid?</span> <span># =&gt; false</span>
<span>Contract</span><span>.</span><span>new</span><span>(</span><span>status</span>: <span>nil</span><span>)</span><span>.</span><span>valid?</span> <span># =&gt; false</span>
<span>Contract</span><span>.</span><span>new</span><span>(</span><span>status</span>: <span>"completed"</span><span>)</span><span>.</span><span>valid?</span> <span># =&gt; true</span>

<span>class</span> <span>Contract</span> &lt; <span>ApplicationRecord</span>
  <span>enum</span> <span>:status</span><span>,</span> <span>%w[</span><span>in_progress</span> <span>completed</span><span>]</span><span>,</span> <span>validate</span>: <span>{</span> <span>allow_nil</span>: <span>true</span> <span>}</span>
<span>end</span>
<span>Contract</span><span>.</span><span>new</span><span>(</span><span>status</span>: <span>"unknown"</span><span>)</span><span>.</span><span>valid?</span> <span># =&gt; false</span>
<span>Contract</span><span>.</span><span>new</span><span>(</span><span>status</span>: <span>nil</span><span>)</span><span>.</span><span>valid?</span> <span># =&gt; true</span>
<span>Contract</span><span>.</span><span>new</span><span>(</span><span>status</span>: <span>"completed"</span><span>)</span><span>.</span><span>valid?</span> <span># =&gt; true</span></pre></div>
<p><em>Edem Topuzov</em>, <em>Ryuta Kamizono</em></p>
</li>
<li>
<p>Allow batching methods to use already loaded relation if available</p>
<p>Calling batch methods on already loaded relations will use the records previously loaded instead of retrieving<br>
them from the database again.</p>
<p><em>Adam Hess</em></p>
</li>
<li>
<p>Deprecate <code>read_attribute(:id)</code> returning the primary key if the primary key is not <code>:id</code>.</p>
<p>Starting in Rails 7.2, <code>read_attribute(:id)</code> will return the value of the id column, regardless of the model's<br>
primary key. To retrieve the value of the primary key, use <code>#id</code> instead. <code>read_attribute(:id)</code> for composite<br>
primary key models will now return the value of the id column.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Fix <code>change_table</code> setting datetime precision for 6.1 Migrations</p>
<p><em>Hartley McGuire</em></p>
</li>
<li>
<p>Fix change_column setting datetime precision for 6.1 Migrations</p>
<p><em>Hartley McGuire</em></p>
</li>
<li>
<p>Add <code>ActiveRecord::Base#id_value</code> alias to access the raw value of a record's id column.</p>
<p>This alias is only provided for models that declare an <code>:id</code> column.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Fix previous change tracking for <code>ActiveRecord::Store</code> when using a column with JSON structured database type</p>
<p>Before, the methods to access the changes made during the last save <code>#saved_change_to_key?</code>, <code>#saved_change_to_key</code>, and <code>#key_before_last_save</code> did not work if the store was defined as a <code>store_accessor</code> on a column with a JSON structured database type</p>
<p><em>Robert DiMartino</em></p>
</li>
<li>
<p>Fully support <code>NULLS [NOT] DISTINCT</code> for PostgreSQL 15+ indexes.</p>
<p>Previous work was done to allow the index to be created in a migration, but it was not<br>
supported in schema.rb. Additionally, the matching for <code>NULLS [NOT] DISTINCT</code> was not<br>
in the correct order, which could have resulted in inconsistent schema detection.</p>
<p><em>Gregory Jones</em></p>
</li>
<li>
<p>Allow escaping of literal colon characters in <code>sanitize_sql_*</code> methods when named bind variables are used</p>
<p><em>Justin Bull</em></p>
</li>
<li>
<p>Fix <code>#previously_new_record?</code> to return true for destroyed records.</p>
<p>Before, if a record was created and then destroyed, <code>#previously_new_record?</code> would return true.<br>
Now, any UPDATE or DELETE to a record is considered a change, and will result in <code>#previously_new_record?</code><br>
returning false.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Specify callback in <code>has_secure_token</code></p>
<div data-snippet-clipboard-copy-content="class User < ApplicationRecord
  has_secure_token on: :initialize
end

User.new.token # => &quot;abc123....&quot;"><pre><span>class</span> <span>User</span> &lt; <span>ApplicationRecord</span>
  <span>has_secure_token</span> <span>on</span>: <span>:initialize</span>
<span>end</span>

<span>User</span><span>.</span><span>new</span><span>.</span><span>token</span> <span># =&gt; "abc123...."</span></pre></div>
<p><em>Sean Doyle</em></p>
</li>
<li>
<p>Fix incrementation of in memory counter caches when associations overlap</p>
<p>When two associations had a similarly named counter cache column, Active Record<br>
could sometime increment the wrong one.</p>
<p><em>Jacopo Beschi</em>, <em>Jean Boussier</em></p>
</li>
<li>
<p>Don't show secrets for Active Record's <code>Cipher::Aes256Gcm#inspect</code>.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::Encryption::Cipher::Aes256Gcm.new(secret).inspect
&quot;#<ActiveRecord::Encryption::Cipher::Aes256Gcm:0x0000000104888038 ... @secret=\&quot;\\xAF\\bFh]LV}q\\nl\\xB2U\\xB3 ... >&quot;"><pre><span>ActiveRecord</span>::<span>Encryption</span>::<span>Cipher</span>::<span>Aes256Gcm</span><span>.</span><span>new</span><span>(</span><span>secret</span><span>)</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveRecord::Encryption::Cipher::Aes256Gcm:0x0000000104888038 ... @secret=<span>\"</span><span>\\</span>xAF<span>\\</span>bFh]LV}q<span>\\</span>nl<span>\\</span>xB2U<span>\\</span>xB3 ... &gt;"</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::Encryption::Cipher::Aes256Gcm(secret).inspect
&quot;#<ActiveRecord::Encryption::Cipher::Aes256Gcm:0x0000000104888038>&quot;"><pre><span>ActiveRecord</span>::<span>Encryption</span>::<span>Cipher</span>::<span>Aes256Gcm</span><span>(</span><span>secret</span><span>)</span><span>.</span><span>inspect</span>
<span>"#&lt;ActiveRecord::Encryption::Cipher::Aes256Gcm:0x0000000104888038&gt;"</span></pre></div>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p>Bring back the historical behavior of committing transaction on non-local return.</p>
<div data-snippet-clipboard-copy-content="Model.transaction do
  model.save
  return
  other_model.save # not executed
end"><pre><span>Model</span><span>.</span><span>transaction</span> <span>do</span>
  <span>model</span><span>.</span><span>save</span>
  <span>return</span>
  <span>other_model</span><span>.</span><span>save</span> <span># not executed</span>
<span>end</span></pre></div>
<p>Historically only raised errors would trigger a rollback, but in Ruby <code>2.3</code>, the <code>timeout</code> library<br>
started using <code>throw</code> to interrupt execution which had the adverse effect of committing open transactions.</p>
<p>To solve this, in Active Record 6.1 the behavior was changed to instead rollback the transaction as it was safer<br>
than to potentially commit an incomplete transaction.</p>
<p>Using <code>return</code>, <code>break</code> or <code>throw</code> inside a <code>transaction</code> block was essentially deprecated from Rails 6.1 onwards.</p>
<p>However with the release of <code>timeout 0.4.0</code>, <code>Timeout.timeout</code> now raises an error again, and Active Record is able<br>
to return to its original, less surprising, behavior.</p>
<p>This historical behavior can now be opt-ed in via:</p>
<div data-snippet-clipboard-copy-content="Rails.application.config.active_record.commit_transaction_on_non_local_return = true"><pre><code>Rails.application.config.active_record.commit_transaction_on_non_local_return = true
</code></pre></div>
<p>And is the default for new applications created in Rails 7.1.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Deprecate <code>name</code> argument on <code>#remove_connection</code>.</p>
<p>The <code>name</code> argument is deprecated on <code>#remove_connection</code> without replacement. <code>#remove_connection</code> should be called directly on the class that established the connection.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Fix has_one through singular building with inverse.</p>
<p>Allows building of records from an association with a has_one through a<br>
singular association with inverse. For belongs_to through associations,<br>
linking the foreign key to the primary key model isn't needed.<br>
For has_one, we cannot build records due to the association not being mutable.</p>
<p><em>Gannon McGibbon</em></p>
</li>
<li>
<p>Disable database prepared statements when query logs are enabled</p>
<p>Prepared Statements and Query Logs are incompatible features due to query logs making every query unique.</p>
<p><em>zzak, Jean Boussier</em></p>
</li>
<li>
<p>Support decrypting data encrypted non-deterministically with a SHA1 hash digest.</p>
<p>This adds a new Active Record encryption option to support decrypting data encrypted<br>
non-deterministically with a SHA1 hash digest:</p>
<div data-snippet-clipboard-copy-content="Rails.application.config.active_record.encryption.support_sha1_for_non_deterministic_encryption = true"><pre><code>Rails.application.config.active_record.encryption.support_sha1_for_non_deterministic_encryption = true
</code></pre></div>
<p>The new option addresses a problem when upgrading from 7.0 to 7.1. Due to a bug in how Active Record<br>
Encryption was getting initialized, the key provider used for non-deterministic encryption were using<br>
SHA-1 as its digest class, instead of the one configured globally by Rails via<br>
<code>Rails.application.config.active_support.key_generator_hash_digest_class</code>.</p>
<p><em>Cadu Ribeiro and Jorge Manrubia</em></p>
</li>
<li>
<p>Added PostgreSQL migration commands for enum rename, add value, and rename value.</p>
<p><code>rename_enum</code> and <code>rename_enum_value</code> are reversible. Due to Postgres<br>
limitation, <code>add_enum_value</code> is not reversible since you cannot delete enum<br>
values. As an alternative you should drop and recreate the enum entirely.</p>
<div data-snippet-clipboard-copy-content="rename_enum :article_status, to: :article_state"><pre><span>rename_enum</span> <span>:article_status</span><span>,</span> <span>to</span>: <span>:article_state</span></pre></div>
<div data-snippet-clipboard-copy-content="add_enum_value :article_state, &quot;archived&quot; # will be at the end of existing values
add_enum_value :article_state, &quot;in review&quot;, before: &quot;published&quot;
add_enum_value :article_state, &quot;approved&quot;, after: &quot;in review&quot;"><pre><span>add_enum_value</span> <span>:article_state</span><span>,</span> <span>"archived"</span> <span># will be at the end of existing values</span>
<span>add_enum_value</span> <span>:article_state</span><span>,</span> <span>"in review"</span><span>,</span> <span>before</span>: <span>"published"</span>
<span>add_enum_value</span> <span>:article_state</span><span>,</span> <span>"approved"</span><span>,</span> <span>after</span>: <span>"in review"</span></pre></div>
<div data-snippet-clipboard-copy-content="rename_enum_value :article_state, from: &quot;archived&quot;, to: &quot;deleted&quot;"><pre><span>rename_enum_value</span> <span>:article_state</span><span>,</span> <span>from</span>: <span>"archived"</span><span>,</span> <span>to</span>: <span>"deleted"</span></pre></div>
<p><em>Ray Faddis</em></p>
</li>
<li>
<p>Allow composite primary key to be derived from schema</p>
<p>Booting an application with a schema that contains composite primary keys<br>
will not issue warning and won't <code>nil</code>ify the <code>ActiveRecord::Base#primary_key</code> value anymore.</p>
<p>Given a <code>travel_routes</code> table definition and a <code>TravelRoute</code> model like:</p>
<div data-snippet-clipboard-copy-content="create_table :travel_routes, primary_key: [:origin, :destination], force: true do |t|
  t.string :origin
  t.string :destination
end

class TravelRoute < ActiveRecord::Base; end"><pre><span>create_table</span> <span>:travel_routes</span><span>,</span> <span>primary_key</span>: <span>[</span><span>:origin</span><span>,</span> <span>:destination</span><span>]</span><span>,</span> <span>force</span>: <span>true</span> <span>do</span> |<span>t</span>|
  <span>t</span><span>.</span><span>string</span> <span>:origin</span>
  <span>t</span><span>.</span><span>string</span> <span>:destination</span>
<span>end</span>

<span>class</span> <span>TravelRoute</span> &lt; <span>ActiveRecord</span>::<span>Base</span><span>;</span> <span>end</span></pre></div>
<p>The <code>TravelRoute.primary_key</code> value will be automatically derived to <code>["origin", "destination"]</code></p>
<p><em>Nikita Vasilevsky</em></p>
</li>
<li>
<p>Include the <code>connection_pool</code> with exceptions raised from an adapter.</p>
<p>The <code>connection_pool</code> provides added context such as the connection used<br>
that led to the exception as well as which role and shard.</p>
<p><em>Luan Vieira</em></p>
</li>
<li>
<p>Support multiple column ordering for <code>find_each</code>, <code>find_in_batches</code> and <code>in_batches</code>.</p>
<p>When find_each/find_in_batches/in_batches are performed on a table with composite primary keys, ascending or descending order can be selected for each key.</p>
<div data-snippet-clipboard-copy-content="Person.find_each(order: [:desc, :asc]) do |person|
  person.party_all_night!
end"><pre><span>Person</span><span>.</span><span>find_each</span><span>(</span><span>order</span>: <span>[</span><span>:desc</span><span>,</span> <span>:asc</span><span>]</span><span>)</span> <span>do</span> |<span>person</span>|
  <span>person</span><span>.</span><span>party_all_night!</span>
<span>end</span></pre></div>
<p><em>Takuya Kurimoto</em></p>
</li>
<li>
<p>Fix where on association with has_one/has_many polymorphic relations.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="Treasure.where(price_estimates: PriceEstimate.all)
#=> SELECT (...) WHERE &quot;treasures&quot;.&quot;id&quot; IN (SELECT &quot;price_estimates&quot;.&quot;estimate_of_id&quot; FROM &quot;price_estimates&quot;)"><pre><span>Treasure</span><span>.</span><span>where</span><span>(</span><span>price_estimates</span>: <span>PriceEstimate</span><span>.</span><span>all</span><span>)</span>
<span>#=&gt; SELECT (...) WHERE "treasures"."id" IN (SELECT "price_estimates"."estimate_of_id" FROM "price_estimates")</span></pre></div>
<p>Later:</p>
<div data-snippet-clipboard-copy-content="Treasure.where(price_estimates: PriceEstimate.all)
#=> SELECT (...) WHERE &quot;treasures&quot;.&quot;id&quot; IN (SELECT &quot;price_estimates&quot;.&quot;estimate_of_id&quot; FROM &quot;price_estimates&quot; WHERE &quot;price_estimates&quot;.&quot;estimate_of_type&quot; = 'Treasure')"><pre><span>Treasure</span><span>.</span><span>where</span><span>(</span><span>price_estimates</span>: <span>PriceEstimate</span><span>.</span><span>all</span><span>)</span>
<span>#=&gt; SELECT (...) WHERE "treasures"."id" IN (SELECT "price_estimates"."estimate_of_id" FROM "price_estimates" WHERE "price_estimates"."estimate_of_type" = 'Treasure')</span></pre></div>
<p><em>Lázaro Nixon</em></p>
</li>
<li>
<p>Assign auto populated columns on Active Record record creation.</p>
<p>Changes record creation logic to allow for the <code>auto_increment</code> column to be assigned<br>
immediately after creation regardless of it's relation to the model's primary key.</p>
<p>The PostgreSQL adapter benefits the most from the change allowing for any number of auto-populated<br>
columns to be assigned on the object immediately after row insertion utilizing the <code>RETURNING</code> statement.</p>
<p><em>Nikita Vasilevsky</em></p>
</li>
<li>
<p>Use the first key in the <code>shards</code> hash from <code>connected_to</code> for the <code>default_shard</code>.</p>
<p>Some applications may not want to use <code>:default</code> as a shard name in their connection model. Unfortunately Active Record expects there to be a <code>:default</code> shard because it must assume a shard to get the right connection from the pool manager. Rather than force applications to manually set this, <code>connects_to</code> can infer the default shard name from the hash of shards and will now assume that the first shard is your default.</p>
<p>For example if your model looked like this:</p>
<div data-snippet-clipboard-copy-content="class ShardRecord < ApplicationRecord
  self.abstract_class = true

  connects_to shards: {
    shard_one: { writing: :shard_one },
    shard_two: { writing: :shard_two }
  }"><pre><span>class</span> <span>ShardRecord</span> &lt; <span>ApplicationRecord</span>
  <span>self</span><span>.</span><span>abstract_class</span> <span>=</span> <span>true</span>

  <span>connects_to</span> <span>shards</span>: <span>{</span>
    <span>shard_one</span>: <span>{</span> <span>writing</span>: <span>:shard_one</span> <span>}</span><span>,</span>
    <span>shard_two</span>: <span>{</span> <span>writing</span>: <span>:shard_two</span> <span>}</span>
  <span>}</span></pre></div>
<p>Then the <code>default_shard</code> for this class would be set to <code>shard_one</code>.</p>
<p>Fixes: <a data-error-text="Failed to load title" data-id="1275315412" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/45390" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/45390/hovercard" href="https://github.com/rails/rails/issues/45390">#45390</a></p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Fix mutation detection for serialized attributes backed by binary columns.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Add <code>ActiveRecord.disconnect_all!</code> method to immediately close all connections from all pools.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Discard connections which may have been left in a transaction.</p>
<p>There are cases where, due to an error, <code>within_new_transaction</code> may unexpectedly leave a connection in an open transaction. In these cases the connection may be reused, and the following may occur:</p>
<ul>
<li>Writes appear to fail when they actually succeed.</li>
<li>Writes appear to succeed when they actually fail.</li>
<li>Reads return stale or uncommitted data.</li>
</ul>
<p>Previously, the following case was detected:</p>
<ul>
<li>An error is encountered during the transaction, then another error is encountered while attempting to roll it back.</li>
</ul>
<p>Now, the following additional cases are detected:</p>
<ul>
<li>An error is encountered just after successfully beginning a transaction.</li>
<li>An error is encountered while committing a transaction, then another error is encountered while attempting to roll it back.</li>
<li>An error is encountered while rolling back a transaction.</li>
</ul>
<p><em>Nick Dower</em></p>
</li>
<li>
<p>Active Record query cache now evicts least recently used entries</p>
<p>By default it only keeps the <code>100</code> most recently used queries.</p>
<p>The cache size can be configured via <code>database.yml</code></p>
<div data-snippet-clipboard-copy-content="development:
  adapter: mysql2
  query_cache: 200"><pre><span>development</span>:
  <span>adapter</span>: <span>mysql2</span>
  <span>query_cache</span>: <span>200</span></pre></div>
<p>It can also be entirely disabled:</p>
<div data-snippet-clipboard-copy-content="development:
  adapter: mysql2
  query_cache: false"><pre><span>development</span>:
  <span>adapter</span>: <span>mysql2</span>
  <span>query_cache</span>: <span>false</span></pre></div>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Deprecate <code>check_pending!</code> in favor of <code>check_all_pending!</code>.</p>
<p><code>check_pending!</code> will only check for pending migrations on the current database connection or the one passed in. This has been deprecated in favor of <code>check_all_pending!</code> which will find all pending migrations for the database configurations in a given environment.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Make <code>increment_counter</code>/<code>decrement_counter</code> accept an amount argument</p>
<div data-snippet-clipboard-copy-content="Post.increment_counter(:comments_count, 5, by: 3)"><pre><span>Post</span><span>.</span><span>increment_counter</span><span>(</span><span>:comments_count</span><span>,</span> <span>5</span><span>,</span> <span>by</span>: <span>3</span><span>)</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Add support for <code>Array#intersect?</code> to <code>ActiveRecord::Relation</code>.</p>
<p><code>Array#intersect?</code> is only available on Ruby 3.1 or later.</p>
<p>This allows the Rubocop <code>Style/ArrayIntersect</code> cop to work with <code>ActiveRecord::Relation</code> objects.</p>
<p><em>John Harry Kelly</em></p>
</li>
<li>
<p>The deferrable foreign key can be passed to <code>t.references</code>.</p>
<p><em>Hiroyuki Ishii</em></p>
</li>
<li>
<p>Deprecate <code>deferrable: true</code> option of <code>add_foreign_key</code>.</p>
<p><code>deferrable: true</code> is deprecated in favor of <code>deferrable: :immediate</code>, and<br>
will be removed in Rails 7.2.</p>
<p>Because <code>deferrable: true</code> and <code>deferrable: :deferred</code> are hard to understand.<br>
Both true and :deferred are truthy values.<br>
This behavior is the same as the deferrable option of the add_unique_key method, added in <a data-error-text="Failed to load title" data-id="1396155024" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/46192" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/46192/hovercard" href="https://github.com/rails/rails/pull/46192">#46192</a>.</p>
<p><em>Hiroyuki Ishii</em></p>
</li>
<li>
<p><code>AbstractAdapter#execute</code> and <code>#exec_query</code> now clear the query cache</p>
<p>If you need to perform a read only SQL query without clearing the query<br>
cache, use <code>AbstractAdapter#select_all</code>.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Make <code>.joins</code> / <code>.left_outer_joins</code> work with CTEs.</p>
<p>For example:</p>
<div data-snippet-clipboard-copy-content="Post
 .with(commented_posts: Comment.select(:post_id).distinct)
 .joins(:commented_posts)
#=> WITH (...) SELECT ... INNER JOIN commented_posts on posts.id = commented_posts.post_id"><pre><span>Post</span>
 <span>.</span><span>with</span><span>(</span><span>commented_posts</span>: <span>Comment</span><span>.</span><span>select</span><span>(</span><span>:post_id</span><span>)</span><span>.</span><span>distinct</span><span>)</span>
 <span>.</span><span>joins</span><span>(</span><span>:commented_posts</span><span>)</span>
<span>#=&gt; WITH (...) SELECT ... INNER JOIN commented_posts on posts.id = commented_posts.post_id</span></pre></div>
<p><em>Vladimir Dementyev</em></p>
</li>
<li>
<p>Add a load hook for <code>ActiveRecord::ConnectionAdapters::Mysql2Adapter</code><br>
(named <code>active_record_mysql2adapter</code>) to allow for overriding aspects of the<br>
<code>ActiveRecord::ConnectionAdapters::Mysql2Adapter</code> class. This makes <code>Mysql2Adapter</code><br>
consistent with <code>PostgreSQLAdapter</code> and <code>SQLite3Adapter</code> that already have load hooks.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Introduce adapter for Trilogy database client</p>
<p>Trilogy is a MySQL-compatible database client. Rails applications can use Trilogy<br>
by configuring their <code>config/database.yml</code>:</p>
<div data-snippet-clipboard-copy-content="development:
adapter: trilogy
database: blog_development
pool: 5"><pre><span>development</span>:
<span>adapter</span>: <span>trilogy</span>
<span>database</span>: <span>blog_development</span>
<span>pool</span>: <span>5</span></pre></div>
<p>Or by using the <code>DATABASE_URL</code> environment variable:</p>
<div data-snippet-clipboard-copy-content="ENV['DATABASE_URL'] # => &quot;trilogy://localhost/blog_development?pool=5&quot;"><pre><span>ENV</span><span>[</span><span>'DATABASE_URL'</span><span>]</span> <span># =&gt; "trilogy://localhost/blog_development?pool=5"</span></pre></div>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p><code>after_commit</code> callbacks defined on models now execute in the correct order.</p>
<div data-snippet-clipboard-copy-content="class User < ActiveRecord::Base
  after_commit { puts(&quot;this gets called first&quot;) }
  after_commit { puts(&quot;this gets called second&quot;) }
end"><pre><span>class</span> <span>User</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>after_commit</span> <span>{</span> <span>puts</span><span>(</span><span>"this gets called first"</span><span>)</span> <span>}</span>
  <span>after_commit</span> <span>{</span> <span>puts</span><span>(</span><span>"this gets called second"</span><span>)</span> <span>}</span>
<span>end</span></pre></div>
<p>Previously, the callbacks executed in the reverse order. To opt in to the new behaviour:</p>
<div data-snippet-clipboard-copy-content="config.active_record.run_after_transaction_callbacks_in_order_defined = true"><pre><span>config</span><span>.</span><span>active_record</span><span>.</span><span>run_after_transaction_callbacks_in_order_defined</span> <span>=</span> <span>true</span></pre></div>
<p>This is the default for new apps.</p>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Infer <code>foreign_key</code> when <code>inverse_of</code> is present on <code>has_one</code> and <code>has_many</code> associations.</p>
<div data-snippet-clipboard-copy-content="has_many :citations, foreign_key: &quot;book1_id&quot;, inverse_of: :book"><pre><span>has_many</span> <span>:citations</span><span>,</span> <span>foreign_key</span>: <span>"book1_id"</span><span>,</span> <span>inverse_of</span>: <span>:book</span></pre></div>
<p>can be simplified to</p>
<div data-snippet-clipboard-copy-content="has_many :citations, inverse_of: :book"><pre><span>has_many</span> <span>:citations</span><span>,</span> <span>inverse_of</span>: <span>:book</span></pre></div>
<p>and the foreign_key will be read from the corresponding <code>belongs_to</code> association.</p>
<p><em>Daniel Whitney</em></p>
</li>
<li>
<p>Limit max length of auto generated index names</p>
<p>Auto generated index names are now limited to 62 bytes, which fits within<br>
the default index name length limits for MySQL, Postgres and SQLite.</p>
<p>Any index name over the limit will fallback to the new short format.</p>
<p>Before (too long):</p>
<div data-snippet-clipboard-copy-content="index_testings_on_foo_and_bar_and_first_name_and_last_name_and_administrator"><pre><code>index_testings_on_foo_and_bar_and_first_name_and_last_name_and_administrator
</code></pre></div>
<p>After (short format):</p>
<div data-snippet-clipboard-copy-content="idx_on_foo_bar_first_name_last_name_administrator_5939248142"><pre><code>idx_on_foo_bar_first_name_last_name_administrator_5939248142
</code></pre></div>
<p>The short format includes a hash to ensure the name is unique database-wide.</p>
<p><em>Mike Coutermarsh</em></p>
</li>
<li>
<p>Introduce a more stable and optimized Marshal serializer for Active Record models.</p>
<p>Can be enabled with <code>config.active_record.marshalling_format_version = 7.1</code>.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Allow specifying where clauses with column-tuple syntax.</p>
<p>Querying through <code>#where</code> now accepts a new tuple-syntax which accepts, as<br>
a key, an array of columns and, as a value, an array of corresponding tuples.<br>
The key specifies a list of columns, while the value is an array of<br>
ordered-tuples that conform to the column list.</p>
<p>For instance:</p>
<div data-snippet-clipboard-copy-content="# Cpk::Book => Cpk::Book(author_id: integer, number: integer, title: string, revision: integer)
# Cpk::Book.primary_key => [&quot;author_id&quot;, &quot;number&quot;]

book = Cpk::Book.create!(author_id: 1, number: 1)
Cpk::Book.where(Cpk::Book.primary_key => [[1, 2]]) # => [book]

# Topic => Topic(id: integer, title: string, author_name: string...)

Topic.where([:title, :author_name] => [[&quot;The Alchemist&quot;, &quot;Paulo Coelho&quot;], [&quot;Harry Potter&quot;, &quot;J.K Rowling&quot;]])"><pre><span># Cpk::Book =&gt; Cpk::Book(author_id: integer, number: integer, title: string, revision: integer)</span>
<span># Cpk::Book.primary_key =&gt; ["author_id", "number"]</span>

<span>book</span> <span>=</span> <span>Cpk</span>::<span>Book</span><span>.</span><span>create!</span><span>(</span><span>author_id</span>: <span>1</span><span>,</span> <span>number</span>: <span>1</span><span>)</span>
<span>Cpk</span>::<span>Book</span><span>.</span><span>where</span><span>(</span><span>Cpk</span>::<span>Book</span><span>.</span><span>primary_key</span> <span>=&gt;</span> <span>[</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>]</span><span>]</span><span>)</span> <span># =&gt; [book]</span>

<span># Topic =&gt; Topic(id: integer, title: string, author_name: string...)</span>

<span>Topic</span><span>.</span><span>where</span><span>(</span><span>[</span><span>:title</span><span>,</span> <span>:author_name</span><span>]</span> <span>=&gt;</span> <span>[</span><span>[</span><span>"The Alchemist"</span><span>,</span> <span>"Paulo Coelho"</span><span>]</span><span>,</span> <span>[</span><span>"Harry Potter"</span><span>,</span> <span>"J.K Rowling"</span><span>]</span><span>]</span><span>)</span></pre></div>
<p><em>Paarth Madan</em></p>
</li>
<li>
<p>Allow warning codes to be ignore when reporting SQL warnings.</p>
<p>Active Record config that can ignore warning codes</p>
<div data-snippet-clipboard-copy-content="# Configure allowlist of warnings that should always be ignored
config.active_record.db_warnings_ignore = [
  &quot;1062&quot;, # MySQL Error 1062: Duplicate entry
]"><pre><span># Configure allowlist of warnings that should always be ignored</span>
<span>config</span><span>.</span><span>active_record</span><span>.</span><span>db_warnings_ignore</span> <span>=</span> <span>[</span>
  <span>"1062"</span><span>,</span> <span># MySQL Error 1062: Duplicate entry</span>
<span>]</span></pre></div>
<p>This is supported for the MySQL and PostgreSQL adapters.</p>
<p><em>Nick Borromeo</em></p>
</li>
<li>
<p>Introduce <code>:active_record_fixtures</code> lazy load hook.</p>
<p>Hooks defined with this name will be run whenever <code>TestFixtures</code> is included<br>
in a class.</p>
<div data-snippet-clipboard-copy-content="ActiveSupport.on_load(:active_record_fixtures) do
  self.fixture_paths << &quot;test/fixtures&quot;
end

klass = Class.new
klass.include(ActiveRecord::TestFixtures)

klass.fixture_paths # => [&quot;test/fixtures&quot;]"><pre><span>ActiveSupport</span><span>.</span><span>on_load</span><span>(</span><span>:active_record_fixtures</span><span>)</span> <span>do</span>
  <span>self</span><span>.</span><span>fixture_paths</span> &lt;&lt; <span>"test/fixtures"</span>
<span>end</span>

<span>klass</span> <span>=</span> <span>Class</span><span>.</span><span>new</span>
<span>klass</span><span>.</span><span>include</span><span>(</span><span>ActiveRecord</span>::<span>TestFixtures</span><span>)</span>

<span>klass</span><span>.</span><span>fixture_paths</span> <span># =&gt; ["test/fixtures"]</span></pre></div>
<p><em>Andrew Novoselac</em></p>
</li>
<li>
<p>Introduce <code>TestFixtures#fixture_paths</code>.</p>
<p>Multiple fixture paths can now be specified using the <code>#fixture_paths</code> accessor.<br>
Apps will continue to have <code>test/fixtures</code> as their one fixture path by default,<br>
but additional fixture paths can be specified.</p>
<div data-snippet-clipboard-copy-content="ActiveSupport::TestCase.fixture_paths << &quot;component1/test/fixtures&quot;
ActiveSupport::TestCase.fixture_paths << &quot;component2/test/fixtures&quot;"><pre><span>ActiveSupport</span>::<span>TestCase</span><span>.</span><span>fixture_paths</span> &lt;&lt; <span>"component1/test/fixtures"</span>
<span>ActiveSupport</span>::<span>TestCase</span><span>.</span><span>fixture_paths</span> &lt;&lt; <span>"component2/test/fixtures"</span></pre></div>
<p><code>TestFixtures#fixture_path</code> is now deprecated.</p>
<p><em>Andrew Novoselac</em></p>
</li>
<li>
<p>Adds support for deferrable exclude constraints in PostgreSQL.</p>
<p>By default, exclude constraints in PostgreSQL are checked after each statement.<br>
This works for most use cases, but becomes a major limitation when replacing<br>
records with overlapping ranges by using multiple statements.</p>
<div data-snippet-clipboard-copy-content="exclusion_constraint :users, &quot;daterange(valid_from, valid_to) WITH &amp;&amp;&quot;, deferrable: :immediate"><pre><span>exclusion_constraint</span> <span>:users</span><span>,</span> <span>"daterange(valid_from, valid_to) WITH &amp;&amp;"</span><span>,</span> <span>deferrable</span>: <span>:immediate</span></pre></div>
<p>Passing <code>deferrable: :immediate</code> checks constraint after each statement,<br>
but allows manually deferring the check using <code>SET CONSTRAINTS ALL DEFERRED</code><br>
within a transaction. This will cause the excludes to be checked after the transaction.</p>
<p>It's also possible to change the default behavior from an immediate check<br>
(after the statement), to a deferred check (after the transaction):</p>
<div data-snippet-clipboard-copy-content="exclusion_constraint :users, &quot;daterange(valid_from, valid_to) WITH &amp;&amp;&quot;, deferrable: :deferred"><pre><span>exclusion_constraint</span> <span>:users</span><span>,</span> <span>"daterange(valid_from, valid_to) WITH &amp;&amp;"</span><span>,</span> <span>deferrable</span>: <span>:deferred</span></pre></div>
<p><em>Hiroyuki Ishii</em></p>
</li>
<li>
<p>Respect <code>foreign_type</code> option to <code>delegated_type</code> for <code>{role}_class</code> method.</p>
<p>Usage of <code>delegated_type</code> with non-conventional <code>{role}_type</code> column names can now be specified with <code>foreign_type</code> option.<br>
This option is the same as <code>foreign_type</code> as forwarded to the underlying <code>belongs_to</code> association that <code>delegated_type</code> wraps.</p>
<p><em>Jason Karns</em></p>
</li>
<li>
<p>Add support for unique constraints (PostgreSQL-only).</p>
<div data-snippet-clipboard-copy-content="add_unique_key :sections, [:position], deferrable: :deferred, name: &quot;unique_section_position&quot;
remove_unique_key :sections, name: &quot;unique_section_position&quot;"><pre><span>add_unique_key</span> <span>:sections</span><span>,</span> <span>[</span><span>:position</span><span>]</span><span>,</span> <span>deferrable</span>: <span>:deferred</span><span>,</span> <span>name</span>: <span>"unique_section_position"</span>
<span>remove_unique_key</span> <span>:sections</span><span>,</span> <span>name</span>: <span>"unique_section_position"</span></pre></div>
<p>See PostgreSQL's <a href="https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-UNIQUE-CONSTRAINTS" rel="nofollow">Unique Constraints</a> documentation for more on unique constraints.</p>
<p>By default, unique constraints in PostgreSQL are checked after each statement.<br>
This works for most use cases, but becomes a major limitation when replacing<br>
records with unique column by using multiple statements.</p>
<p>An example of swapping unique columns between records.</p>
<div data-snippet-clipboard-copy-content="# position is unique column
old_item = Item.create!(position: 1)
new_item = Item.create!(position: 2)

Item.transaction do
  old_item.update!(position: 2)
  new_item.update!(position: 1)
end"><pre><span># position is unique column</span>
<span>old_item</span> <span>=</span> <span>Item</span><span>.</span><span>create!</span><span>(</span><span>position</span>: <span>1</span><span>)</span>
<span>new_item</span> <span>=</span> <span>Item</span><span>.</span><span>create!</span><span>(</span><span>position</span>: <span>2</span><span>)</span>

<span>Item</span><span>.</span><span>transaction</span> <span>do</span>
  <span>old_item</span><span>.</span><span>update!</span><span>(</span><span>position</span>: <span>2</span><span>)</span>
  <span>new_item</span><span>.</span><span>update!</span><span>(</span><span>position</span>: <span>1</span><span>)</span>
<span>end</span></pre></div>
<p>Using the default behavior, the transaction would fail when executing the<br>
first <code>UPDATE</code> statement.</p>
<p>By passing the <code>:deferrable</code> option to the <code>add_unique_key</code> statement in<br>
migrations, it's possible to defer this check.</p>
<div data-snippet-clipboard-copy-content="add_unique_key :items, [:position], deferrable: :immediate"><pre><span>add_unique_key</span> <span>:items</span><span>,</span> <span>[</span><span>:position</span><span>]</span><span>,</span> <span>deferrable</span>: <span>:immediate</span></pre></div>
<p>Passing <code>deferrable: :immediate</code> does not change the behaviour of the previous example,<br>
but allows manually deferring the check using <code>SET CONSTRAINTS ALL DEFERRED</code> within a transaction.<br>
This will cause the unique constraints to be checked after the transaction.</p>
<p>It's also possible to adjust the default behavior from an immediate<br>
check (after the statement), to a deferred check (after the transaction):</p>
<div data-snippet-clipboard-copy-content="add_unique_key :items, [:position], deferrable: :deferred"><pre><span>add_unique_key</span> <span>:items</span><span>,</span> <span>[</span><span>:position</span><span>]</span><span>,</span> <span>deferrable</span>: <span>:deferred</span></pre></div>
<p>If you want to change an existing unique index to deferrable, you can use :using_index<br>
to create deferrable unique constraints.</p>
<div data-snippet-clipboard-copy-content="add_unique_key :items, deferrable: :deferred, using_index: &quot;index_items_on_position&quot;"><pre><span>add_unique_key</span> <span>:items</span><span>,</span> <span>deferrable</span>: <span>:deferred</span><span>,</span> <span>using_index</span>: <span>"index_items_on_position"</span></pre></div>
<p><em>Hiroyuki Ishii</em></p>
</li>
<li>
<p>Remove deprecated <code>Tasks::DatabaseTasks.schema_file_type</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated <code>config.active_record.partial_writes</code>.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove deprecated <code>ActiveRecord::Base</code> config accessors.</p>
<p><em>Rafael Mendonça França</em></p>
</li>
<li>
<p>Remove the <code>:include_replicas</code> argument from <code>configs_for</code>. Use <code>:include_hidden</code> argument instead.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Allow applications to lookup a config via a custom hash key.</p>
<p>If you have registered a custom config or want to find configs where the hash matches a specific key, now you can pass <code>config_key</code> to <code>configs_for</code>. For example if you have a <code>db_config</code> with the key <code>vitess</code> you can look up a database configuration hash by  matching that key.</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::Base.configurations.configs_for(env_name: &quot;development&quot;, name: &quot;primary&quot;, config_key: :vitess)
ActiveRecord::Base.configurations.configs_for(env_name: &quot;development&quot;, config_key: :vitess)"><pre><span>ActiveRecord</span>::<span>Base</span><span>.</span><span>configurations</span><span>.</span><span>configs_for</span><span>(</span><span>env_name</span>: <span>"development"</span><span>,</span> <span>name</span>: <span>"primary"</span><span>,</span> <span>config_key</span>: <span>:vitess</span><span>)</span>
<span>ActiveRecord</span>::<span>Base</span><span>.</span><span>configurations</span><span>.</span><span>configs_for</span><span>(</span><span>env_name</span>: <span>"development"</span><span>,</span> <span>config_key</span>: <span>:vitess</span><span>)</span></pre></div>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Allow applications to register a custom database configuration handler.</p>
<p>Adds a mechanism for registering a custom handler for cases where you want database configurations to respond to custom methods. This is useful for non-Rails database adapters or tools like Vitess that you may want to configure differently from a standard <code>HashConfig</code> or <code>UrlConfig</code>.</p>
<p>Given the following database YAML we want the <code>animals</code> db to create a <code>CustomConfig</code> object instead while the <code>primary</code> database will be a <code>UrlConfig</code>:</p>
<div data-snippet-clipboard-copy-content="development:
  primary:
    url: postgres://localhost/primary
  animals:
    url: postgres://localhost/animals
    custom_config:
      sharded: 1"><pre><span>development</span>:
  <span>primary</span>:
    <span>url</span>: <span>postgres://localhost/primary</span>
  <span>animals</span>:
    <span>url</span>: <span>postgres://localhost/animals</span>
    <span>custom_config</span>:
      <span>sharded</span>: <span>1</span></pre></div>
<p>To register a custom handler first make a class that has your custom methods:</p>
<div data-snippet-clipboard-copy-content="class CustomConfig < ActiveRecord::DatabaseConfigurations::UrlConfig
  def sharded?
    custom_config.fetch(&quot;sharded&quot;, false)
  end

  private
    def custom_config
      configuration_hash.fetch(:custom_config)
    end
end"><pre><span>class</span> <span>CustomConfig</span> &lt; <span>ActiveRecord</span>::<span>DatabaseConfigurations</span>::<span>UrlConfig</span>
  <span>def</span> <span>sharded?</span>
    <span>custom_config</span><span>.</span><span>fetch</span><span>(</span><span>"sharded"</span><span>,</span> <span>false</span><span>)</span>
  <span>end</span>

  <span>private</span>
    <span>def</span> <span>custom_config</span>
      <span>configuration_hash</span><span>.</span><span>fetch</span><span>(</span><span>:custom_config</span><span>)</span>
    <span>end</span>
<span>end</span></pre></div>
<p>Then register the config in an initializer:</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::DatabaseConfigurations.register_db_config_handler do |env_name, name, url, config|
  next unless config.key?(:custom_config)
  CustomConfig.new(env_name, name, url, config)
end"><pre><span>ActiveRecord</span>::<span>DatabaseConfigurations</span><span>.</span><span>register_db_config_handler</span> <span>do</span> |<span>env_name</span><span>,</span> <span>name</span><span>,</span> <span>url</span><span>,</span> <span>config</span>|
  <span>next</span> <span>unless</span> <span>config</span><span>.</span><span>key?</span><span>(</span><span>:custom_config</span><span>)</span>
  <span>CustomConfig</span><span>.</span><span>new</span><span>(</span><span>env_name</span><span>,</span> <span>name</span><span>,</span> <span>url</span><span>,</span> <span>config</span><span>)</span>
<span>end</span></pre></div>
<p>When the application is booted, configuration hashes with the <code>:custom_config</code> key will be <code>CustomConfig</code> objects and respond to <code>sharded?</code>. Applications must handle the condition in which Active Record should use their custom handler.</p>
<p><em>Eileen M. Uchitelle and John Crepezzi</em></p>
</li>
<li>
<p><code>ActiveRecord::Base.serialize</code> no longer uses YAML by default.</p>
<p>YAML isn't particularly performant and can lead to security issues<br>
if not used carefully.</p>
<p>Unfortunately there isn't really any good serializers in Ruby's stdlib<br>
to replace it.</p>
<p>The obvious choice would be JSON, which is a fine format for this use case,<br>
however the JSON serializer in Ruby's stdlib isn't strict enough, as it fallback<br>
to casting unknown types to strings, which could lead to corrupted data.</p>
<p>Some third party JSON libraries like <code>Oj</code> have a suitable strict mode.</p>
<p>So it's preferable that users choose a serializer based on their own constraints.</p>
<p>The original default can be restored by setting <code>config.active_record.default_column_serializer = YAML</code>.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p><code>ActiveRecord::Base.serialize</code> signature changed.</p>
<p>Rather than a single positional argument that accepts two possible<br>
types of values, <code>serialize</code> now accepts two distinct keyword arguments.</p>
<p>Before:</p>
<div data-snippet-clipboard-copy-content="serialize :content, JSON
serialize :backtrace, Array"><pre><span>serialize</span> <span>:content</span><span>,</span> <span>JSON</span>
<span>serialize</span> <span>:backtrace</span><span>,</span> <span>Array</span></pre></div>
<p>After:</p>
<div data-snippet-clipboard-copy-content="serialize :content, coder: JSON
serialize :backtrace, type: Array"><pre><span>serialize</span> <span>:content</span><span>,</span> <span>coder</span>: <span>JSON</span>
<span>serialize</span> <span>:backtrace</span><span>,</span> <span>type</span>: <span>Array</span></pre></div>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>YAML columns use <code>YAML.safe_dump</code> if available.</p>
<p>As of <code>psych 5.1.0</code>, <code>YAML.safe_dump</code> can now apply the same permitted<br>
types restrictions than <code>YAML.safe_load</code>.</p>
<p>It's preferable to ensure the payload only use allowed types when we first<br>
try to serialize it, otherwise you may end up with invalid records in the<br>
database.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p><code>ActiveRecord::QueryLogs</code> better handle broken encoding.</p>
<p>It's not uncommon when building queries with BLOB fields to contain<br>
binary data. Unless the call carefully encode the string in ASCII-8BIT<br>
it generally end up being encoded in <code>UTF-8</code>, and <code>QueryLogs</code> would<br>
end up failing on it.</p>
<p><code>ActiveRecord::QueryLogs</code> no longer depend on the query to be properly encoded.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Fix a bug where <code>ActiveRecord::Generators::ModelGenerator</code> would not respect create_table_migration template overrides.</p>
<div data-snippet-clipboard-copy-content="rails g model create_books title:string content:text"><pre><code>rails g model create_books title:string content:text
</code></pre></div>
<p>will now read from the create_table_migration.rb.tt template in the following locations in order:</p>
<div data-snippet-clipboard-copy-content="lib/templates/active_record/model/create_table_migration.rb
lib/templates/active_record/migration/create_table_migration.rb"><pre><code>lib/templates/active_record/model/create_table_migration.rb
lib/templates/active_record/migration/create_table_migration.rb
</code></pre></div>
<p><em>Spencer Neste</em></p>
</li>
<li>
<p><code>ActiveRecord::Relation#explain</code> now accepts options.</p>
<p>For databases and adapters which support them (currently PostgreSQL<br>
and MySQL), options can be passed to <code>explain</code> to provide more<br>
detailed query plan analysis:</p>
<div data-snippet-clipboard-copy-content="Customer.where(id: 1).joins(:orders).explain(:analyze, :verbose)"><pre><span>Customer</span><span>.</span><span>where</span><span>(</span><span>id</span>: <span>1</span><span>)</span><span>.</span><span>joins</span><span>(</span><span>:orders</span><span>)</span><span>.</span><span>explain</span><span>(</span><span>:analyze</span><span>,</span> <span>:verbose</span><span>)</span></pre></div>
<p><em>Reid Lynch</em></p>
</li>
<li>
<p>Multiple <code>Arel::Nodes::SqlLiteral</code> nodes can now be added together to<br>
form <code>Arel::Nodes::Fragments</code> nodes. This allows joining several pieces<br>
of SQL.</p>
<p><em>Matthew Draper</em>, <em>Ole Friis</em></p>
</li>
<li>
<p><code>ActiveRecord::Base#signed_id</code> raises if called on a new record.</p>
<p>Previously it would return an ID that was not usable, since it was based on <code>id = nil</code>.</p>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Allow SQL warnings to be reported.</p>
<p>Active Record configs can be set to enable SQL warning reporting.</p>
<div data-snippet-clipboard-copy-content="# Configure action to take when SQL query produces warning
config.active_record.db_warnings_action = :raise

# Configure allowlist of warnings that should always be ignored
config.active_record.db_warnings_ignore = [
  /Invalid utf8mb4 character string/,
  &quot;An exact warning message&quot;,
]"><pre><span># Configure action to take when SQL query produces warning</span>
<span>config</span><span>.</span><span>active_record</span><span>.</span><span>db_warnings_action</span> <span>=</span> <span>:raise</span>

<span># Configure allowlist of warnings that should always be ignored</span>
<span>config</span><span>.</span><span>active_record</span><span>.</span><span>db_warnings_ignore</span> <span>=</span> <span>[</span>
  <span>/Invalid utf8mb4 character string/</span><span>,</span>
  <span>"An exact warning message"</span><span>,</span>
<span>]</span></pre></div>
<p>This is supported for the MySQL and PostgreSQL adapters.</p>
<p><em>Adrianna Chang</em>, <em>Paarth Madan</em></p>
</li>
<li>
<p>Add <code>#regroup</code> query method as a short-hand for <code>.unscope(:group).group(fields)</code></p>
<p>Example:</p>
<div data-snippet-clipboard-copy-content="Post.group(:title).regroup(:author)
# SELECT `posts`.`*` FROM `posts` GROUP BY `posts`.`author`"><pre><span>Post</span><span>.</span><span>group</span><span>(</span><span>:title</span><span>)</span><span>.</span><span>regroup</span><span>(</span><span>:author</span><span>)</span>
<span># SELECT `posts`.`*` FROM `posts` GROUP BY `posts`.`author`</span></pre></div>
<p><em>Danielius Visockas</em></p>
</li>
<li>
<p>PostgreSQL adapter method <code>enable_extension</code> now allows parameter to be <code>[schema_name.]&lt;extension_name&gt;</code><br>
if the extension must be installed on another schema.</p>
<p>Example: <code>enable_extension('heroku_ext.hstore')</code></p>
<p><em>Leonardo Luarte</em></p>
</li>
<li>
<p>Add <code>:include</code> option to <code>add_index</code>.</p>
<p>Add support for including non-key columns in indexes for PostgreSQL<br>
with the <code>INCLUDE</code> parameter.</p>
<div data-snippet-clipboard-copy-content="add_index(:users, :email, include: [:id, :created_at])"><pre><span>add_index</span><span>(</span><span>:users</span><span>,</span> <span>:email</span><span>,</span> <span>include</span>: <span>[</span><span>:id</span><span>,</span> <span>:created_at</span><span>]</span><span>)</span></pre></div>
<p>will result in:</p>
<div data-snippet-clipboard-copy-content="CREATE INDEX index_users_on_email USING btree (email) INCLUDE (id, created_at)"><pre><span>CREATE</span> <span>INDEX</span> <span>index_users_on_email</span> USING btree (email) INCLUDE (id, created_at)</pre></div>
<p><em>Steve Abrams</em></p>
</li>
<li>
<p><code>ActiveRecord::Relation</code>’s <code>#any?</code>, <code>#none?</code>, and <code>#one?</code> methods take an optional pattern<br>
argument, more closely matching their <code>Enumerable</code> equivalents.</p>
<p><em>George Claghorn</em></p>
</li>
<li>
<p>Add <code>ActiveRecord::Base.normalizes</code> for declaring attribute normalizations.</p>
<p>An attribute normalization is applied when the attribute is assigned or<br>
updated, and the normalized value will be persisted to the database.  The<br>
normalization is also applied to the corresponding keyword argument of query<br>
methods, allowing records to be queried using unnormalized values.</p>
<p>For example:</p>
<div data-snippet-clipboard-copy-content="class User < ActiveRecord::Base
  normalizes :email, with: -> email { email.strip.downcase }
  normalizes :phone, with: -> phone { phone.delete(&quot;^0-9&quot;).delete_prefix(&quot;1&quot;) }
end

user = User.create(email: &quot; CRUISE-CONTROL@EXAMPLE.COM\n&quot;)
user.email                  # => &quot;cruise-control@example.com&quot;

user = User.find_by(email: &quot;\tCRUISE-CONTROL@EXAMPLE.COM &quot;)
user.email                  # => &quot;cruise-control@example.com&quot;
user.email_before_type_cast # => &quot;cruise-control@example.com&quot;

User.where(email: &quot;\tCRUISE-CONTROL@EXAMPLE.COM &quot;).count         # => 1
User.where([&quot;email = ?&quot;, &quot;\tCRUISE-CONTROL@EXAMPLE.COM &quot;]).count # => 0

User.exists?(email: &quot;\tCRUISE-CONTROL@EXAMPLE.COM &quot;)         # => true
User.exists?([&quot;email = ?&quot;, &quot;\tCRUISE-CONTROL@EXAMPLE.COM &quot;]) # => false

User.normalize_value_for(:phone, &quot;+1 (555) 867-5309&quot;) # => &quot;5558675309&quot;"><pre><span>class</span> <span>User</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>normalizes</span> <span>:email</span><span>,</span> <span>with</span>: <span>-&gt;</span> <span>email</span> <span>{</span> <span>email</span><span>.</span><span>strip</span><span>.</span><span>downcase</span> <span>}</span>
  <span>normalizes</span> <span>:phone</span><span>,</span> <span>with</span>: <span>-&gt;</span> <span>phone</span> <span>{</span> <span>phone</span><span>.</span><span>delete</span><span>(</span><span>"^0-9"</span><span>)</span><span>.</span><span>delete_prefix</span><span>(</span><span>"1"</span><span>)</span> <span>}</span>
<span>end</span>

<span>user</span> <span>=</span> <span>User</span><span>.</span><span>create</span><span>(</span><span>email</span>: <span>" CRUISE-CONTROL@EXAMPLE.COM<span>\n</span>"</span><span>)</span>
<span>user</span><span>.</span><span>email</span>                  <span># =&gt; "cruise-control@example.com"</span>

<span>user</span> <span>=</span> <span>User</span><span>.</span><span>find_by</span><span>(</span><span>email</span>: <span>"<span>\t</span>CRUISE-CONTROL@EXAMPLE.COM "</span><span>)</span>
<span>user</span><span>.</span><span>email</span>                  <span># =&gt; "cruise-control@example.com"</span>
<span>user</span><span>.</span><span>email_before_type_cast</span> <span># =&gt; "cruise-control@example.com"</span>

<span>User</span><span>.</span><span>where</span><span>(</span><span>email</span>: <span>"<span>\t</span>CRUISE-CONTROL@EXAMPLE.COM "</span><span>)</span><span>.</span><span>count</span>         <span># =&gt; 1</span>
<span>User</span><span>.</span><span>where</span><span>(</span><span>[</span><span>"email = ?"</span><span>,</span> <span>"<span>\t</span>CRUISE-CONTROL@EXAMPLE.COM "</span><span>]</span><span>)</span><span>.</span><span>count</span> <span># =&gt; 0</span>

<span>User</span><span>.</span><span>exists?</span><span>(</span><span>email</span>: <span>"<span>\t</span>CRUISE-CONTROL@EXAMPLE.COM "</span><span>)</span>         <span># =&gt; true</span>
<span>User</span><span>.</span><span>exists?</span><span>(</span><span>[</span><span>"email = ?"</span><span>,</span> <span>"<span>\t</span>CRUISE-CONTROL@EXAMPLE.COM "</span><span>]</span><span>)</span> <span># =&gt; false</span>

<span>User</span><span>.</span><span>normalize_value_for</span><span>(</span><span>:phone</span><span>,</span> <span>"+1 (555) 867-5309"</span><span>)</span> <span># =&gt; "5558675309"</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Hide changes to before_committed! callback behaviour behind flag.</p>
<p>In <a data-error-text="Failed to load title" data-id="1456102052" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/46525" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/46525/hovercard" href="https://github.com/rails/rails/pull/46525">#46525</a>, behavior around before_committed! callbacks was changed so that callbacks<br>
would run on every enrolled record in a transaction, not just the first copy of a record.<br>
This change in behavior is now controlled by a configuration option,<br>
<code>config.active_record.before_committed_on_all_records</code>. It will be enabled by default on Rails 7.1.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>The <code>namespaced_controller</code> Query Log tag now matches the <code>controller</code> format</p>
<p>For example, a request processed by <code>NameSpaced::UsersController</code> will now log as:</p>
<div data-snippet-clipboard-copy-content=":controller # &quot;users&quot;
:namespaced_controller # &quot;name_spaced/users&quot;"><pre><code>:controller # "users"
:namespaced_controller # "name_spaced/users"
</code></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Return only unique ids from ActiveRecord::Calculations#ids</p>
<p>Updated ActiveRecord::Calculations#ids to only return the unique ids of the base model<br>
when using eager_load, preload and includes.</p>
<div data-snippet-clipboard-copy-content="Post.find_by(id: 1).comments.count
# => 5
Post.includes(:comments).where(id: 1).pluck(:id)
# => [1, 1, 1, 1, 1]
Post.includes(:comments).where(id: 1).ids
# => [1]"><pre><span>Post</span><span>.</span><span>find_by</span><span>(</span><span>id</span>: <span>1</span><span>)</span><span>.</span><span>comments</span><span>.</span><span>count</span>
<span># =&gt; 5</span>
<span>Post</span><span>.</span><span>includes</span><span>(</span><span>:comments</span><span>)</span><span>.</span><span>where</span><span>(</span><span>id</span>: <span>1</span><span>)</span><span>.</span><span>pluck</span><span>(</span><span>:id</span><span>)</span>
<span># =&gt; [1, 1, 1, 1, 1]</span>
<span>Post</span><span>.</span><span>includes</span><span>(</span><span>:comments</span><span>)</span><span>.</span><span>where</span><span>(</span><span>id</span>: <span>1</span><span>)</span><span>.</span><span>ids</span>
<span># =&gt; [1]</span></pre></div>
<p><em>Joshua Young</em></p>
</li>
<li>
<p>Stop using <code>LOWER()</code> for case-insensitive queries on <code>citext</code> columns</p>
<p>Previously, <code>LOWER()</code> was added for e.g. uniqueness validations with<br>
<code>case_sensitive: false</code>.<br>
It wasn't mentioned in the documentation that the index without <code>LOWER()</code><br>
wouldn't be used in this case.</p>
<p><em>Phil Pirozhkov</em></p>
</li>
<li>
<p>Extract <code>#sync_timezone_changes</code> method in AbstractMysqlAdapter to enable subclasses<br>
to sync database timezone changes without overriding <code>#raw_execute</code>.</p>
<p><em>Adrianna Chang</em>, <em>Paarth Madan</em></p>
</li>
<li>
<p>Do not write additional new lines when dumping sql migration versions</p>
<p>This change updates the <code>insert_versions_sql</code> function so that the database insert string containing the current database migration versions does not end with two additional new lines.</p>
<p><em>Misha Schwartz</em></p>
</li>
<li>
<p>Fix <code>composed_of</code> value freezing and duplication.</p>
<p>Previously composite values exhibited two confusing behaviors:</p>
<ul>
<li>When reading a compositve value it'd <em>NOT</em> be frozen, allowing it to get out of sync with its underlying database<br>
columns.</li>
<li>When writing a compositve value the argument would be frozen, potentially confusing the caller.</li>
</ul>
<p>Currently, composite values instantiated based on database columns are frozen (addressing the first issue) and<br>
assigned compositve values are duplicated and the duplicate is frozen (addressing the second issue).</p>
<p><em>Greg Navis</em></p>
</li>
<li>
<p>Fix redundant updates to the column insensitivity cache</p>
<p>Fixed redundant queries checking column capability for insensitive<br>
comparison.</p>
<p><em>Phil Pirozhkov</em></p>
</li>
<li>
<p>Allow disabling methods generated by <code>ActiveRecord.enum</code>.</p>
<p><em>Alfred Dominic</em></p>
</li>
<li>
<p>Avoid validating <code>belongs_to</code> association if it has not changed.</p>
<p>Previously, when updating a record, Active Record will perform an extra query to check for the presence of<br>
<code>belongs_to</code> associations (if the presence is configured to be mandatory), even if that attribute hasn't changed.</p>
<p>Currently, only <code>belongs_to</code>-related columns are checked for presence. It is possible to have orphaned records with<br>
this approach. To avoid this problem, you need to use a foreign key.</p>
<p>This behavior can be controlled by configuration:</p>
<div data-snippet-clipboard-copy-content="config.active_record.belongs_to_required_validates_foreign_key = false"><pre><span>config</span><span>.</span><span>active_record</span><span>.</span><span>belongs_to_required_validates_foreign_key</span> <span>=</span> <span>false</span></pre></div>
<p>and will be disabled by default with <code>config.load_defaults 7.1</code>.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p><code>has_one</code> and <code>belongs_to</code> associations now define a <code>reset_association</code> method<br>
on the owner model (where <code>association</code> is the name of the association). This<br>
method unloads the cached associate record, if any, and causes the next access<br>
to query it from the database.</p>
<p><em>George Claghorn</em></p>
</li>
<li>
<p>Allow per attribute setting of YAML permitted classes (safe load) and unsafe load.</p>
<p><em>Carlos Palhares</em></p>
</li>
<li>
<p>Add a build persistence method</p>
<p>Provides a wrapper for <code>new</code>, to provide feature parity with <code>create</code>s<br>
ability to create multiple records from an array of hashes, using the<br>
same notation as the <code>build</code> method on associations.</p>
<p><em>Sean Denny</em></p>
</li>
<li>
<p>Raise on assignment to readonly attributes</p>
<div data-snippet-clipboard-copy-content="class Post < ActiveRecord::Base
  attr_readonly :content
end
Post.create!(content: &quot;cannot be updated&quot;)
post.content # &quot;cannot be updated&quot;
post.content = &quot;something else&quot; # => ActiveRecord::ReadonlyAttributeError"><pre><span>class</span> <span>Post</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>attr_readonly</span> <span>:content</span>
<span>end</span>
<span>Post</span><span>.</span><span>create!</span><span>(</span><span>content</span>: <span>"cannot be updated"</span><span>)</span>
<span>post</span><span>.</span><span>content</span> <span># "cannot be updated"</span>
<span>post</span><span>.</span><span>content</span> <span>=</span> <span>"something else"</span> <span># =&gt; ActiveRecord::ReadonlyAttributeError</span></pre></div>
<p>Previously, assignment would succeed but silently not write to the database.</p>
<p>This behavior can be controlled by configuration:</p>
<div data-snippet-clipboard-copy-content="config.active_record.raise_on_assign_to_attr_readonly = true"><pre><span>config</span><span>.</span><span>active_record</span><span>.</span><span>raise_on_assign_to_attr_readonly</span> <span>=</span> <span>true</span></pre></div>
<p>and will be enabled by default with <code>config.load_defaults 7.1</code>.</p>
<p><em>Alex Ghiculescu</em>, <em>Hartley McGuire</em></p>
</li>
<li>
<p>Allow unscoping of preload and eager_load associations</p>
<p>Added the ability to unscope preload and eager_load associations just like<br>
includes, joins, etc. See ActiveRecord::QueryMethods::VALID_UNSCOPING_VALUES<br>
for the full list of supported unscopable scopes.</p>
<div data-snippet-clipboard-copy-content="query.unscope(:eager_load, :preload).group(:id).select(:id)"><pre><span>query</span><span>.</span><span>unscope</span><span>(</span><span>:eager_load</span><span>,</span> <span>:preload</span><span>)</span><span>.</span><span>group</span><span>(</span><span>:id</span><span>)</span><span>.</span><span>select</span><span>(</span><span>:id</span><span>)</span></pre></div>
<p><em>David Morehouse</em></p>
</li>
<li>
<p>Add automatic filtering of encrypted attributes on inspect</p>
<p>This feature is enabled by default but can be disabled with</p>
<div data-snippet-clipboard-copy-content="config.active_record.encryption.add_to_filter_parameters = false"><pre><span>config</span><span>.</span><span>active_record</span><span>.</span><span>encryption</span><span>.</span><span>add_to_filter_parameters</span> <span>=</span> <span>false</span></pre></div>
<p><em>Hartley McGuire</em></p>
</li>
<li>
<p>Clear locking column on #dup</p>
<p>This change fixes not to duplicate locking_column like id and timestamps.</p>
<div data-snippet-clipboard-copy-content="car = Car.create!
car.touch
car.lock_version #=> 1
car.dup.lock_version #=> 0"><pre><code>car = Car.create!
car.touch
car.lock_version #=&gt; 1
car.dup.lock_version #=&gt; 0
</code></pre></div>
<p><em>Shouichi Kamiya</em>, <em>Seonggi Yang</em>, <em>Ryohei UEDA</em></p>
</li>
<li>
<p>Invalidate transaction as early as possible</p>
<p>After rescuing a <code>TransactionRollbackError</code> exception Rails invalidates transactions earlier in the flow<br>
allowing the framework to skip issuing the <code>ROLLBACK</code> statement in more cases.<br>
Only affects adapters that have <code>savepoint_errors_invalidate_transactions?</code> configured as <code>true</code>,<br>
which at this point is only applicable to the <code>mysql2</code> adapter.</p>
<p><em>Nikita Vasilevsky</em></p>
</li>
<li>
<p>Allow configuring columns list to be used in SQL queries issued by an <code>ActiveRecord::Base</code> object</p>
<p>It is now possible to configure columns list that will be used to build an SQL query clauses when<br>
updating, deleting or reloading an <code>ActiveRecord::Base</code> object</p>
<div data-snippet-clipboard-copy-content="class Developer < ActiveRecord::Base
  query_constraints :company_id, :id
end
developer = Developer.first.update(name: &quot;Bob&quot;)
# => UPDATE &quot;developers&quot; SET &quot;name&quot; = 'Bob' WHERE &quot;developers&quot;.&quot;company_id&quot; = 1 AND &quot;developers&quot;.&quot;id&quot; = 1"><pre><span>class</span> <span>Developer</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>query_constraints</span> <span>:company_id</span><span>,</span> <span>:id</span>
<span>end</span>
<span>developer</span> <span>=</span> <span>Developer</span><span>.</span><span>first</span><span>.</span><span>update</span><span>(</span><span>name</span>: <span>"Bob"</span><span>)</span>
<span># =&gt; UPDATE "developers" SET "name" = 'Bob' WHERE "developers"."company_id" = 1 AND "developers"."id" = 1</span></pre></div>
<p><em>Nikita Vasilevsky</em></p>
</li>
<li>
<p>Adds <code>validate</code> to foreign keys and check constraints in schema.rb</p>
<p>Previously, <code>schema.rb</code> would not record if <code>validate: false</code> had been used when adding a foreign key or check<br>
constraint, so restoring a database from the schema could result in foreign keys or check constraints being<br>
incorrectly validated.</p>
<p><em>Tommy Graves</em></p>
</li>
<li>
<p>Adapter <code>#execute</code> methods now accept an <code>allow_retry</code> option. When set to <code>true</code>, the SQL statement will be<br>
retried, up to the database's configured <code>connection_retries</code> value, upon encountering connection-related errors.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Only trigger <code>after_commit :destroy</code> callbacks when a database row is deleted.</p>
<p>This prevents <code>after_commit :destroy</code> callbacks from being triggered again<br>
when <code>destroy</code> is called multiple times on the same record.</p>
<p><em>Ben Sheldon</em></p>
</li>
<li>
<p>Fix <code>ciphertext_for</code> for yet-to-be-encrypted values.</p>
<p>Previously, <code>ciphertext_for</code> returned the cleartext of values that had not<br>
yet been encrypted, such as with an unpersisted record:</p>
<div data-snippet-clipboard-copy-content="Post.encrypts :body

post = Post.create!(body: &quot;Hello&quot;)
post.ciphertext_for(:body)
# => &quot;{\&quot;p\&quot;:\&quot;abc...&quot;

post.body = &quot;World&quot;
post.ciphertext_for(:body)
# => &quot;World&quot;"><pre><span>Post</span><span>.</span><span>encrypts</span> <span>:body</span>

<span>post</span> <span>=</span> <span>Post</span><span>.</span><span>create!</span><span>(</span><span>body</span>: <span>"Hello"</span><span>)</span>
<span>post</span><span>.</span><span>ciphertext_for</span><span>(</span><span>:body</span><span>)</span>
<span># =&gt; "{\"p\":\"abc..."</span>

<span>post</span><span>.</span><span>body</span> <span>=</span> <span>"World"</span>
<span>post</span><span>.</span><span>ciphertext_for</span><span>(</span><span>:body</span><span>)</span>
<span># =&gt; "World"</span></pre></div>
<p>Now, <code>ciphertext_for</code> will always return the ciphertext of encrypted<br>
attributes:</p>
<div data-snippet-clipboard-copy-content="Post.encrypts :body

post = Post.create!(body: &quot;Hello&quot;)
post.ciphertext_for(:body)
# => &quot;{\&quot;p\&quot;:\&quot;abc...&quot;

post.body = &quot;World&quot;
post.ciphertext_for(:body)
# => &quot;{\&quot;p\&quot;:\&quot;xyz...&quot;"><pre><span>Post</span><span>.</span><span>encrypts</span> <span>:body</span>

<span>post</span> <span>=</span> <span>Post</span><span>.</span><span>create!</span><span>(</span><span>body</span>: <span>"Hello"</span><span>)</span>
<span>post</span><span>.</span><span>ciphertext_for</span><span>(</span><span>:body</span><span>)</span>
<span># =&gt; "{\"p\":\"abc..."</span>

<span>post</span><span>.</span><span>body</span> <span>=</span> <span>"World"</span>
<span>post</span><span>.</span><span>ciphertext_for</span><span>(</span><span>:body</span><span>)</span>
<span># =&gt; "{\"p\":\"xyz..."</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Fix a bug where using groups and counts with long table names would return incorrect results.</p>
<p><em>Shota Toguchi</em>, <em>Yusaku Ono</em></p>
</li>
<li>
<p>Fix encryption of column default values.</p>
<p>Previously, encrypted attributes that used column default values appeared to<br>
be encrypted on create, but were not:</p>
<div data-snippet-clipboard-copy-content="Book.encrypts :name

book = Book.create!
book.name
# => &quot;<untitled>&quot;
book.name_before_type_cast
# => &quot;{\&quot;p\&quot;:\&quot;abc...&quot;
book.reload.name_before_type_cast
# => &quot;<untitled>&quot;"><pre><span>Book</span><span>.</span><span>encrypts</span> <span>:name</span>

<span>book</span> <span>=</span> <span>Book</span><span>.</span><span>create!</span>
<span>book</span><span>.</span><span>name</span>
<span># =&gt; "&lt;untitled&gt;"</span>
<span>book</span><span>.</span><span>name_before_type_cast</span>
<span># =&gt; "{\"p\":\"abc..."</span>
<span>book</span><span>.</span><span>reload</span><span>.</span><span>name_before_type_cast</span>
<span># =&gt; "&lt;untitled&gt;"</span></pre></div>
<p>Now, attributes with column default values are encrypted:</p>
<div data-snippet-clipboard-copy-content="Book.encrypts :name

book = Book.create!
book.name
# => &quot;<untitled>&quot;
book.name_before_type_cast
# => &quot;{\&quot;p\&quot;:\&quot;abc...&quot;
book.reload.name_before_type_cast
# => &quot;{\&quot;p\&quot;:\&quot;abc...&quot;"><pre><span>Book</span><span>.</span><span>encrypts</span> <span>:name</span>

<span>book</span> <span>=</span> <span>Book</span><span>.</span><span>create!</span>
<span>book</span><span>.</span><span>name</span>
<span># =&gt; "&lt;untitled&gt;"</span>
<span>book</span><span>.</span><span>name_before_type_cast</span>
<span># =&gt; "{\"p\":\"abc..."</span>
<span>book</span><span>.</span><span>reload</span><span>.</span><span>name_before_type_cast</span>
<span># =&gt; "{\"p\":\"abc..."</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Deprecate delegation from <code>Base</code> to <code>connection_handler</code>.</p>
<p>Calling <code>Base.clear_all_connections!</code>, <code>Base.clear_active_connections!</code>, <code>Base.clear_reloadable_connections!</code> and <code>Base.flush_idle_connections!</code> is deprecated. Please call these methods on the connection handler directly. In future Rails versions, the delegation from <code>Base</code> to the <code>connection_handler</code> will be removed.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Allow ActiveRecord::QueryMethods#reselect to receive hash values, similar to ActiveRecord::QueryMethods#select</p>
<p><em>Sampat Badhe</em></p>
</li>
<li>
<p>Validate options when managing columns and tables in migrations.</p>
<p>If an invalid option is passed to a migration method like <code>create_table</code> and <code>add_column</code>, an error will be raised<br>
instead of the option being silently ignored. Validation of the options will only be applied for new migrations<br>
that are created.</p>
<p><em>Guo Xiang Tan</em>, <em>George Wambold</em></p>
</li>
<li>
<p>Update query log tags to use the <a href="https://open-telemetry.github.io/opentelemetry-sqlcommenter/" rel="nofollow">SQLCommenter</a> format by default. See <a href="https://github.com/rails/rails/issues/46179" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/46179/hovercard">#46179</a></p>
<p>To opt out of SQLCommenter-formatted query log tags, set <code>config.active_record.query_log_tags_format = :legacy</code>. By default, this is set to <code>:sqlcommenter</code>.</p>
<p><em>Modulitos</em> and <em>Iheanyi</em></p>
</li>
<li>
<p>Allow any ERB in the database.yml when creating rake tasks.</p>
<p>Any ERB can be used in <code>database.yml</code> even if it accesses environment<br>
configurations.</p>
<p>Deprecates <code>config.active_record.suppress_multiple_database_warning</code>.</p>
<p><em>Eike Send</em></p>
</li>
<li>
<p>Add table to error for duplicate column definitions.</p>
<p>If a migration defines duplicate columns for a table, the error message<br>
shows which table it concerns.</p>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p>Fix erroneous nil default precision on virtual datetime columns.</p>
<p>Prior to this change, virtual datetime columns did not have the same<br>
default precision as regular datetime columns, resulting in the following<br>
being erroneously equivalent:</p>
<div data-snippet-clipboard-copy-content="t.virtual :name, type: datetime,                 as: &quot;expression&quot;
t.virtual :name, type: datetime, precision: nil, as: &quot;expression&quot;"><pre><code>t.virtual :name, type: datetime,                 as: "expression"
t.virtual :name, type: datetime, precision: nil, as: "expression"
</code></pre></div>
<p>This change fixes the default precision lookup, so virtual and regular<br>
datetime column default precisions match.</p>
<p><em>Sam Bostock</em></p>
</li>
<li>
<p>Use connection from <code>#with_raw_connection</code> in <code>#quote_string</code>.</p>
<p>This ensures that the string quoting is wrapped in the reconnect and retry logic<br>
that <code>#with_raw_connection</code> offers.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Add <code>expires_at</code> option to <code>signed_id</code>.</p>
<p><em>Shouichi Kamiya</em></p>
</li>
<li>
<p>Allow applications to set retry deadline for query retries.</p>
<p>Building on the work done in <a data-error-text="Failed to load title" data-id="1154273875" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/44576" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/44576/hovercard" href="https://github.com/rails/rails/pull/44576">#44576</a> and <a data-error-text="Failed to load title" data-id="1155775285" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/44591" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/44591/hovercard" href="https://github.com/rails/rails/pull/44591">#44591</a>, we extend the logic that automatically<br>
reconnects database connections to take into account a timeout limit. We won't retry<br>
a query if a given amount of time has elapsed since the query was first attempted. This<br>
value defaults to nil, meaning that all retryable queries are retried regardless of time elapsed,<br>
but this can be changed via the <code>retry_deadline</code> option in the database config.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Fix a case where the query cache can return wrong values. See <a data-error-text="Failed to load title" data-id="1374793684" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/46044" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/46044/hovercard" href="https://github.com/rails/rails/issues/46044">#46044</a></p>
<p><em>Aaron Patterson</em></p>
</li>
<li>
<p>Support MySQL's ssl-mode option for MySQLDatabaseTasks.</p>
<p>Verifying the identity of the database server requires setting the ssl-mode<br>
option to VERIFY_CA or VERIFY_IDENTITY. This option was previously ignored<br>
for MySQL database tasks like creating a database and dumping the structure.</p>
<p><em>Petrik de Heus</em></p>
</li>
<li>
<p>Move <code>ActiveRecord::InternalMetadata</code> to an independent object.</p>
<p><code>ActiveRecord::InternalMetadata</code> no longer inherits from <code>ActiveRecord::Base</code> and is now an independent object that should be instantiated with a <code>connection</code>. This class is private and should not be used by applications directly. If you want to interact with the schema migrations table, please access it on the connection directly, for example: <code>ActiveRecord::Base.connection.schema_migration</code>.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Deprecate quoting <code>ActiveSupport::Duration</code> as an integer</p>
<p>Using ActiveSupport::Duration as an interpolated bind parameter in a SQL<br>
string template is deprecated. To avoid this warning, you should explicitly<br>
convert the duration to a more specific database type. For example, if you<br>
want to use a duration as an integer number of seconds:</p>
<div data-snippet-clipboard-copy-content="Record.where(&quot;duration = ?&quot;, 1.hour.to_i)"><pre><code>Record.where("duration = ?", 1.hour.to_i)
</code></pre></div>
<p>If you want to use a duration as an ISO 8601 string:</p>
<div data-snippet-clipboard-copy-content="Record.where(&quot;duration = ?&quot;, 1.hour.iso8601)"><pre><code>Record.where("duration = ?", 1.hour.iso8601)
</code></pre></div>
<p><em>Aram Greenman</em></p>
</li>
<li>
<p>Allow <code>QueryMethods#in_order_of</code> to order by a string column name.</p>
<div data-snippet-clipboard-copy-content="Post.in_order_of(&quot;id&quot;, [4,2,3,1]).to_a
Post.joins(:author).in_order_of(&quot;authors.name&quot;, [&quot;Bob&quot;, &quot;Anna&quot;, &quot;John&quot;]).to_a"><pre><span>Post</span><span>.</span><span>in_order_of</span><span>(</span><span>"id"</span><span>,</span> <span>[</span><span>4</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>1</span><span>]</span><span>)</span><span>.</span><span>to_a</span>
<span>Post</span><span>.</span><span>joins</span><span>(</span><span>:author</span><span>)</span><span>.</span><span>in_order_of</span><span>(</span><span>"authors.name"</span><span>,</span> <span>[</span><span>"Bob"</span><span>,</span> <span>"Anna"</span><span>,</span> <span>"John"</span><span>]</span><span>)</span><span>.</span><span>to_a</span></pre></div>
<p><em>Igor Kasyanchuk</em></p>
</li>
<li>
<p>Move <code>ActiveRecord::SchemaMigration</code> to an independent object.</p>
<p><code>ActiveRecord::SchemaMigration</code> no longer inherits from <code>ActiveRecord::Base</code> and is now an independent object that should be instantiated with a <code>connection</code>. This class is private and should not be used by applications directly. If you want to interact with the schema migrations table, please access it on the connection directly, for example: <code>ActiveRecord::Base.connection.schema_migration</code>.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Deprecate <code>all_connection_pools</code> and make <code>connection_pool_list</code> more explicit.</p>
<p>Following on <a data-error-text="Failed to load title" data-id="1359250964" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/45924" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/45924/hovercard" href="https://github.com/rails/rails/pull/45924">#45924</a> <code>all_connection_pools</code> is now deprecated. <code>connection_pool_list</code> will either take an explicit role or applications can opt into the new behavior by passing <code>:all</code>.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Fix connection handler methods to operate on all pools.</p>
<p><code>active_connections?</code>, <code>clear_active_connections!</code>, <code>clear_reloadable_connections!</code>, <code>clear_all_connections!</code>, and <code>flush_idle_connections!</code> now operate on all pools by default. Previously they would default to using the <code>current_role</code> or <code>:writing</code> role unless specified.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Allow ActiveRecord::QueryMethods#select to receive hash values.</p>
<p>Currently, <code>select</code> might receive only raw sql and symbols to define columns and aliases to select.</p>
<p>With this change we can provide <code>hash</code> as argument, for example:</p>
<div data-snippet-clipboard-copy-content="Post.joins(:comments).select(posts: [:id, :title, :created_at], comments: [:id, :body, :author_id])
#=> &quot;SELECT \&quot;posts\&quot;.\&quot;id\&quot;, \&quot;posts\&quot;.\&quot;title\&quot;, \&quot;posts\&quot;.\&quot;created_at\&quot;, \&quot;comments\&quot;.\&quot;id\&quot;, \&quot;comments\&quot;.\&quot;body\&quot;, \&quot;comments\&quot;.\&quot;author_id\&quot;
#   FROM \&quot;posts\&quot; INNER JOIN \&quot;comments\&quot; ON \&quot;comments\&quot;.\&quot;post_id\&quot; = \&quot;posts\&quot;.\&quot;id\&quot;&quot;

Post.joins(:comments).select(posts: { id: :post_id, title: :post_title }, comments: { id: :comment_id, body: :comment_body })
#=> &quot;SELECT posts.id as post_id, posts.title as post_title, comments.id as comment_id, comments.body as comment_body
#    FROM \&quot;posts\&quot; INNER JOIN \&quot;comments\&quot; ON \&quot;comments\&quot;.\&quot;post_id\&quot; = \&quot;posts\&quot;.\&quot;id\&quot;&quot;"><pre><span>Post</span><span>.</span><span>joins</span><span>(</span><span>:comments</span><span>)</span><span>.</span><span>select</span><span>(</span><span>posts</span>: <span>[</span><span>:id</span><span>,</span> <span>:title</span><span>,</span> <span>:created_at</span><span>]</span><span>,</span> <span>comments</span>: <span>[</span><span>:id</span><span>,</span> <span>:body</span><span>,</span> <span>:author_id</span><span>]</span><span>)</span>
<span>#=&gt; "SELECT \"posts\".\"id\", \"posts\".\"title\", \"posts\".\"created_at\", \"comments\".\"id\", \"comments\".\"body\", \"comments\".\"author_id\"</span>
<span>#   FROM \"posts\" INNER JOIN \"comments\" ON \"comments\".\"post_id\" = \"posts\".\"id\""</span>

<span>Post</span><span>.</span><span>joins</span><span>(</span><span>:comments</span><span>)</span><span>.</span><span>select</span><span>(</span><span>posts</span>: <span>{</span> <span>id</span>: <span>:post_id</span><span>,</span> <span>title</span>: <span>:post_title</span> <span>}</span><span>,</span> <span>comments</span>: <span>{</span> <span>id</span>: <span>:comment_id</span><span>,</span> <span>body</span>: <span>:comment_body</span> <span>}</span><span>)</span>
<span>#=&gt; "SELECT posts.id as post_id, posts.title as post_title, comments.id as comment_id, comments.body as comment_body</span>
<span>#    FROM \"posts\" INNER JOIN \"comments\" ON \"comments\".\"post_id\" = \"posts\".\"id\""</span></pre></div>
<p><em>Oleksandr Holubenko</em>, <em>Josef Šimánek</em>, <em>Jean Boussier</em></p>
</li>
<li>
<p>Adapts virtual attributes on <code>ActiveRecord::Persistence#becomes</code>.</p>
<p>When source and target classes have a different set of attributes adapts<br>
attributes such that the extra attributes from target are added.</p>
<div data-snippet-clipboard-copy-content="class Person < ApplicationRecord
end

class WebUser < Person
  attribute :is_admin, :boolean
  after_initialize :set_admin

  def set_admin
    write_attribute(:is_admin, email =~ /@ourcompany\.com$/)
  end
end

person = Person.find_by(email: &quot;email@ourcompany.com&quot;)
person.respond_to? :is_admin
# => false
person.becomes(WebUser).is_admin?
# => true"><pre><span>class</span> <span>Person</span> &lt; <span>ApplicationRecord</span>
<span>end</span>

<span>class</span> <span>WebUser</span> &lt; <span>Person</span>
  <span>attribute</span> <span>:is_admin</span><span>,</span> <span>:boolean</span>
  <span>after_initialize</span> <span>:set_admin</span>

  <span>def</span> <span>set_admin</span>
    <span>write_attribute</span><span>(</span><span>:is_admin</span><span>,</span> <span>email</span> =~ <span>/@ourcompany<span>\.</span>com$/</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>person</span> <span>=</span> <span>Person</span><span>.</span><span>find_by</span><span>(</span><span>email</span>: <span>"email@ourcompany.com"</span><span>)</span>
<span>person</span><span>.</span><span>respond_to?</span> <span>:is_admin</span>
<span># =&gt; false</span>
<span>person</span><span>.</span><span>becomes</span><span>(</span><span>WebUser</span><span>)</span><span>.</span><span>is_admin?</span>
<span># =&gt; true</span></pre></div>
<p><em>Jacopo Beschi</em>, <em>Sampson Crowley</em></p>
</li>
<li>
<p>Fix <code>ActiveRecord::QueryMethods#in_order_of</code> to include <code>nil</code>s, to match the<br>
behavior of <code>Enumerable#in_order_of</code>.</p>
<p>For example, <code>Post.in_order_of(:title, [nil, "foo"])</code> will now include posts<br>
with <code>nil</code> titles, the same as <code>Post.all.to_a.in_order_of(:title, [nil, "foo"])</code>.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Optimize <code>add_timestamps</code> to use a single SQL statement.</p>

<p>Now results in the following SQL:</p>
<div data-snippet-clipboard-copy-content="ALTER TABLE &quot;my_table&quot; ADD COLUMN &quot;created_at&quot; datetime(6) NOT NULL, ADD COLUMN &quot;updated_at&quot; datetime(6) NOT NULL"><pre><span>ALTER</span> <span>TABLE</span> <span><span>"</span>my_table<span>"</span></span> ADD COLUMN <span><span>"</span>created_at<span>"</span></span> datetime(<span>6</span>) <span>NOT NULL</span>, ADD COLUMN <span><span>"</span>updated_at<span>"</span></span> datetime(<span>6</span>) <span>NOT NULL</span></pre></div>
<p><em>Iliana Hadzhiatanasova</em></p>
</li>
<li>
<p>Add <code>drop_enum</code> migration command for PostgreSQL</p>
<p>This does the inverse of <code>create_enum</code>. Before dropping an enum, ensure you have<br>
dropped columns that depend on it.</p>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Adds support for <code>if_exists</code> option when removing a check constraint.</p>
<p>The <code>remove_check_constraint</code> method now accepts an <code>if_exists</code> option. If set<br>
to true an error won't be raised if the check constraint doesn't exist.</p>
<p><em>Margaret Parsa</em> and <em>Aditya Bhutani</em></p>
</li>
<li>
<p><code>find_or_create_by</code> now try to find a second time if it hits a unicity constraint.</p>
<p><code>find_or_create_by</code> always has been inherently racy, either creating multiple<br>
duplicate records or failing with <code>ActiveRecord::RecordNotUnique</code> depending on<br>
whether a proper unicity constraint was set.</p>
<p><code>create_or_find_by</code> was introduced for this use case, however it's quite wasteful<br>
when the record is expected to exist most of the time, as INSERT require to send<br>
more data than SELECT and require more work from the database. Also on some<br>
databases it can actually consume a primary key increment which is undesirable.</p>
<p>So for case where most of the time the record is expected to exist, <code>find_or_create_by</code><br>
can be made race-condition free by re-trying the <code>find</code> if the <code>create</code> failed<br>
with <code>ActiveRecord::RecordNotUnique</code>. This assumes that the table has the proper<br>
unicity constraints, if not, <code>find_or_create_by</code> will still lead to duplicated records.</p>
<p><em>Jean Boussier</em>, <em>Alex Kitchens</em></p>
</li>
<li>
<p>Introduce a simpler constructor API for ActiveRecord database adapters.</p>
<p>Previously the adapter had to know how to build a new raw connection to<br>
support reconnect, but also expected to be passed an initial already-<br>
established connection.</p>
<p>When manually creating an adapter instance, it will now accept a single<br>
config hash, and only establish the real connection on demand.</p>
<p><em>Matthew Draper</em></p>
</li>
<li>
<p>Avoid redundant <code>SELECT 1</code> connection-validation query during DB pool<br>
checkout when possible.</p>
<p>If the first query run during a request is known to be idempotent, it can be<br>
used directly to validate the connection, saving a network round-trip.</p>
<p><em>Matthew Draper</em></p>
</li>
<li>
<p>Automatically reconnect broken database connections when safe, even<br>
mid-request.</p>
<p>When an error occurs while attempting to run a known-idempotent query, and<br>
not inside a transaction, it is safe to immediately reconnect to the<br>
database server and try again, so this is now the default behavior.</p>
<p>This new default should always be safe -- to support that, it's consciously<br>
conservative about which queries are considered idempotent -- but if<br>
necessary it can be disabled by setting the <code>connection_retries</code> connection<br>
option to <code>0</code>.</p>
<p><em>Matthew Draper</em></p>
</li>
<li>
<p>Avoid removing a PostgreSQL extension when there are dependent objects.</p>
<p>Previously, removing an extension also implicitly removed dependent objects. Now, this will raise an error.</p>
<p>You can force removing the extension:</p>
<div data-snippet-clipboard-copy-content="disable_extension :citext, force: :cascade"><pre><span>disable_extension</span> <span>:citext</span><span>,</span> <span>force</span>: <span>:cascade</span></pre></div>
<p>Fixes <a data-error-text="Failed to load title" data-id="228722817" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/29091" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/29091/hovercard" href="https://github.com/rails/rails/issues/29091">#29091</a>.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Allow nested functions as safe SQL string</p>
<p><em>Michael Siegfried</em></p>
</li>
<li>
<p>Allow <code>destroy_association_async_job=</code> to be configured with a class string instead of a constant.</p>
<p>Defers an autoloading dependency between <code>ActiveRecord::Base</code> and <code>ActiveJob::Base</code><br>
and moves the configuration of <code>ActiveRecord::DestroyAssociationAsyncJob</code><br>
from ActiveJob to ActiveRecord.</p>
<p>Deprecates <code>ActiveRecord::ActiveJobRequiredError</code> and now raises a <code>NameError</code><br>
if the job class is unloadable or an <code>ActiveRecord::ConfigurationError</code> if<br>
<code>dependent: :destroy_async</code> is declared on an association but there is no job<br>
class configured.</p>
<p><em>Ben Sheldon</em></p>
</li>
<li>
<p>Fix <code>ActiveRecord::Store</code> to serialize as a regular Hash</p>
<p>Previously it would serialize as an <code>ActiveSupport::HashWithIndifferentAccess</code><br>
which is wasteful and cause problem with YAML safe_load.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Add <code>timestamptz</code> as a time zone aware type for PostgreSQL</p>
<p>This is required for correctly parsing <code>timestamp with time zone</code> values in your database.</p>
<p>If you don't want this, you can opt out by adding this initializer:</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::Base.time_zone_aware_types -= [:timestamptz]"><pre><span>ActiveRecord</span>::<span>Base</span><span>.</span><span>time_zone_aware_types</span> -= <span>[</span><span>:timestamptz</span><span>]</span></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Add new <code>ActiveRecord::Base.generates_token_for</code> API.</p>
<p>Currently, <code>signed_id</code> fulfills the role of generating tokens for e.g.<br>
resetting a password.  However, signed IDs cannot reflect record state, so<br>
if a token is intended to be single-use, it must be tracked in a database at<br>
least until it expires.</p>
<p>With <code>generates_token_for</code>, a token can embed data from a record.  When<br>
using the token to fetch the record, the data from the token and the current<br>
data from the record will be compared.  If the two do not match, the token<br>
will be treated as invalid, the same as if it had expired.  For example:</p>
<div data-snippet-clipboard-copy-content="class User < ActiveRecord::Base
  has_secure_password

  generates_token_for :password_reset, expires_in: 15.minutes do
    # A password's BCrypt salt changes when the password is updated.
    # By embedding (part of) the salt in a token, the token will
    # expire when the password is updated.
    BCrypt::Password.new(password_digest).salt[-10..]
  end
end

user = User.first
token = user.generate_token_for(:password_reset)

User.find_by_token_for(:password_reset, token) # => user

user.update!(password: &quot;new password&quot;)
User.find_by_token_for(:password_reset, token) # => nil"><pre><span>class</span> <span>User</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>has_secure_password</span>

  <span>generates_token_for</span> <span>:password_reset</span><span>,</span> <span>expires_in</span>: <span>15</span><span>.</span><span>minutes</span> <span>do</span>
    <span># A password's BCrypt salt changes when the password is updated.</span>
    <span># By embedding (part of) the salt in a token, the token will</span>
    <span># expire when the password is updated.</span>
    <span>BCrypt</span>::<span>Password</span><span>.</span><span>new</span><span>(</span><span>password_digest</span><span>)</span><span>.</span><span>salt</span><span>[</span>-<span>10</span>..<span>]</span>
  <span>end</span>
<span>end</span>

<span>user</span> <span>=</span> <span>User</span><span>.</span><span>first</span>
<span>token</span> <span>=</span> <span>user</span><span>.</span><span>generate_token_for</span><span>(</span><span>:password_reset</span><span>)</span>

<span>User</span><span>.</span><span>find_by_token_for</span><span>(</span><span>:password_reset</span><span>,</span> <span>token</span><span>)</span> <span># =&gt; user</span>

<span>user</span><span>.</span><span>update!</span><span>(</span><span>password</span>: <span>"new password"</span><span>)</span>
<span>User</span><span>.</span><span>find_by_token_for</span><span>(</span><span>:password_reset</span><span>,</span> <span>token</span><span>)</span> <span># =&gt; nil</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
<li>
<p>Optimize Active Record batching for whole table iterations.</p>
<p>Previously, <code>in_batches</code> got all the ids and constructed an <code>IN</code>-based query for each batch.<br>
When iterating over the whole tables, this approach is not optimal as it loads unneeded ids and<br>
<code>IN</code> queries with lots of items are slow.</p>
<p>Now, whole table iterations use range iteration (<code>id &gt;= x AND id &lt;= y</code>) by default which can make iteration<br>
several times faster. E.g., tested on a PostgreSQL table with 10 million records: querying (<code>253s</code> vs <code>30s</code>),<br>
updating (<code>288s</code> vs <code>124s</code>), deleting (<code>268s</code> vs <code>83s</code>).</p>
<p>Only whole table iterations use this style of iteration by default. You can disable this behavior by passing <code>use_ranges: false</code>.<br>
If you iterate over the table and the only condition is, e.g., <code>archived_at: nil</code> (and only a tiny fraction<br>
of the records are archived), it makes sense to opt in to this approach:</p>
<div data-snippet-clipboard-copy-content="Project.where(archived_at: nil).in_batches(use_ranges: true) do |relation|
  # do something
end"><pre><span>Project</span><span>.</span><span>where</span><span>(</span><span>archived_at</span>: <span>nil</span><span>)</span><span>.</span><span>in_batches</span><span>(</span><span>use_ranges</span>: <span>true</span><span>)</span> <span>do</span> |<span>relation</span>|
  <span># do something</span>
<span>end</span></pre></div>
<p>See <a data-error-text="Failed to load title" data-id="1277547479" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/45414" data-hovercard-type="pull_request" data-hovercard-url="/rails/rails/pull/45414/hovercard" href="https://github.com/rails/rails/pull/45414">#45414</a> for more details.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p><code>.with</code> query method added. Construct common table expressions with ease and get <code>ActiveRecord::Relation</code> back.</p>
<div data-snippet-clipboard-copy-content="Post.with(posts_with_comments: Post.where(&quot;comments_count > ?&quot;, 0))
# => ActiveRecord::Relation
# WITH posts_with_comments AS (SELECT * FROM posts WHERE (comments_count > 0)) SELECT * FROM posts"><pre><span>Post</span><span>.</span><span>with</span><span>(</span><span>posts_with_comments</span>: <span>Post</span><span>.</span><span>where</span><span>(</span><span>"comments_count &gt; ?"</span><span>,</span> <span>0</span><span>)</span><span>)</span>
<span># =&gt; ActiveRecord::Relation</span>
<span># WITH posts_with_comments AS (SELECT * FROM posts WHERE (comments_count &gt; 0)) SELECT * FROM posts</span></pre></div>
<p><em>Vlado Cingel</em></p>
</li>
<li>
<p>Don't establish a new connection if an identical pool exists already.</p>
<p>Previously, if <code>establish_connection</code> was called on a class that already had an established connection, the existing connection would be removed regardless of whether it was the same config. Now if a pool is found with the same values as the new connection, the existing connection will be returned instead of creating a new one.</p>
<p>This has a slight change in behavior if application code is depending on a new connection being established regardless of whether it's identical to an existing connection. If the old behavior is desirable, applications should call <code>ActiveRecord::Base#remove_connection</code> before establishing a new one. Calling <code>establish_connection</code> with a different config works the same way as it did previously.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p>Update <code>db:prepare</code> task to load schema when an uninitialized database exists, and dump schema after migrations.</p>
<p><em>Ben Sheldon</em></p>
</li>
<li>
<p>Fix supporting timezone awareness for <code>tsrange</code> and <code>tstzrange</code> array columns.</p>
<div data-snippet-clipboard-copy-content="# In database migrations
add_column :shops, :open_hours, :tsrange, array: true
# In app config
ActiveRecord::Base.time_zone_aware_types += [:tsrange]
# In the code times are properly converted to app time zone
Shop.create!(open_hours: [Time.current..8.hour.from_now])"><pre><span># In database migrations</span>
<span>add_column</span> <span>:shops</span><span>,</span> <span>:open_hours</span><span>,</span> <span>:tsrange</span><span>,</span> <span>array</span>: <span>true</span>
<span># In app config</span>
<span>ActiveRecord</span>::<span>Base</span><span>.</span><span>time_zone_aware_types</span> += <span>[</span><span>:tsrange</span><span>]</span>
<span># In the code times are properly converted to app time zone</span>
<span>Shop</span><span>.</span><span>create!</span><span>(</span><span>open_hours</span>: <span>[</span><span>Time</span><span>.</span><span>current</span>..<span>8</span><span>.</span><span>hour</span><span>.</span><span>from_now</span><span>]</span><span>)</span></pre></div>
<p><em>Wojciech Wnętrzak</em></p>
</li>
<li>
<p>Introduce strategy pattern for executing migrations.</p>
<p>By default, migrations will use a strategy object that delegates the method<br>
to the connection adapter. Consumers can implement custom strategy objects<br>
to change how their migrations run.</p>
<p><em>Adrianna Chang</em></p>
</li>
<li>
<p>Add adapter option disallowing foreign keys</p>
<p>This adds a new option to be added to <code>database.yml</code> which enables skipping<br>
foreign key constraints usage even if the underlying database supports them.</p>
<p>Usage:</p>
<div data-snippet-clipboard-copy-content="development:
    <<: *default
    database: storage/development.sqlite3
    foreign_keys: false"><pre><span>development</span>:
    <span>&lt;&lt;</span>: <span>*default</span>
    <span>database</span>: <span>storage/development.sqlite3</span>
    <span>foreign_keys</span>: <span>false</span></pre></div>
<p><em>Paulo Barros</em></p>
</li>
<li>
<p>Add configurable deprecation warning for singular associations</p>
<p>This adds a deprecation warning when using the plural name of a singular associations in <code>where</code>.<br>
It is possible to opt into the new more performant behavior with <code>config.active_record.allow_deprecated_singular_associations_name = false</code></p>
<p><em>Adam Hess</em></p>
</li>
<li>
<p>Run transactional callbacks on the freshest instance to save a given<br>
record within a transaction.</p>
<p>When multiple Active Record instances change the same record within a<br>
transaction, Rails runs <code>after_commit</code> or <code>after_rollback</code> callbacks for<br>
only one of them. <code>config.active_record.run_commit_callbacks_on_first_saved_instances_in_transaction</code><br>
was added to specify how Rails chooses which instance receives the<br>
callbacks. The framework defaults were changed to use the new logic.</p>
<p>When <code>config.active_record.run_commit_callbacks_on_first_saved_instances_in_transaction</code><br>
is <code>true</code>, transactional callbacks are run on the first instance to save,<br>
even though its instance state may be stale.</p>
<p>When it is <code>false</code>, which is the new framework default starting with version<br>
7.1, transactional callbacks are run on the instances with the freshest<br>
instance state. Those instances are chosen as follows:</p>
<ul>
<li>In general, run transactional callbacks on the last instance to save a<br>
given record within the transaction.</li>
<li>There are two exceptions:
<ul>
<li>If the record is created within the transaction, then updated by<br>
another instance, <code>after_create_commit</code> callbacks will be run on the<br>
second instance. This is instead of the <code>after_update_commit</code><br>
callbacks that would naively be run based on that instance’s state.</li>
<li>If the record is destroyed within the transaction, then<br>
<code>after_destroy_commit</code> callbacks will be fired on the last destroyed<br>
instance, even if a stale instance subsequently performed an update<br>
(which will have affected 0 rows).</li>
</ul>
</li>
</ul>
<p><em>Cameron Bothner and Mitch Vollebregt</em></p>
</li>
<li>
<p>Enable strict strings mode for <code>SQLite3Adapter</code>.</p>
<p>Configures SQLite with a strict strings mode, which disables double-quoted string literals.</p>
<p>SQLite has some quirks around double-quoted string literals.<br>
It first tries to consider double-quoted strings as identifier names, but if they don't exist<br>
it then considers them as string literals. Because of this, typos can silently go unnoticed.<br>
For example, it is possible to create an index for a non existing column.<br>
See <a href="https://www.sqlite.org/quirks.html#double_quoted_string_literals_are_accepted" rel="nofollow">SQLite documentation</a> for more details.</p>
<p>If you don't want this behavior, you can disable it via:</p>
<div data-snippet-clipboard-copy-content="# config/application.rb
config.active_record.sqlite3_adapter_strict_strings_by_default = false"><pre><span># config/application.rb</span>
<span>config</span><span>.</span><span>active_record</span><span>.</span><span>sqlite3_adapter_strict_strings_by_default</span> <span>=</span> <span>false</span></pre></div>
<p>Fixes <a data-error-text="Failed to load title" data-id="202667093" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/27782" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/27782/hovercard" href="https://github.com/rails/rails/issues/27782">#27782</a>.</p>
<p><em>fatkodima</em>, <em>Jean Boussier</em></p>
</li>
<li>
<p>Resolve issue where a relation cache_version could be left stale.</p>
<p>Previously, when <code>reset</code> was called on a relation object it did not reset the cache_versions<br>
ivar. This led to a confusing situation where despite having the correct data the relation<br>
still reported a stale cache_version.</p>
<p>Usage:</p>
<div data-snippet-clipboard-copy-content="developers = Developer.all
developers.cache_version

Developer.update_all(updated_at: Time.now.utc + 1.second)

developers.cache_version # Stale cache_version
developers.reset
developers.cache_version # Returns the current correct cache_version"><pre><span>developers</span> <span>=</span> <span>Developer</span><span>.</span><span>all</span>
<span>developers</span><span>.</span><span>cache_version</span>

<span>Developer</span><span>.</span><span>update_all</span><span>(</span><span>updated_at</span>: <span>Time</span><span>.</span><span>now</span><span>.</span><span>utc</span> + <span>1</span><span>.</span><span>second</span><span>)</span>

<span>developers</span><span>.</span><span>cache_version</span> <span># Stale cache_version</span>
<span>developers</span><span>.</span><span>reset</span>
<span>developers</span><span>.</span><span>cache_version</span> <span># Returns the current correct cache_version</span></pre></div>
<p>Fixes <a data-error-text="Failed to load title" data-id="1269654145" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/45341" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/45341/hovercard" href="https://github.com/rails/rails/issues/45341">#45341</a>.</p>
<p><em>Austen Madden</em></p>
</li>
<li>
<p>Add support for exclusion constraints (PostgreSQL-only).</p>
<div data-snippet-clipboard-copy-content="add_exclusion_constraint :invoices, &quot;daterange(start_date, end_date) WITH &amp;&amp;&quot;, using: :gist, name: &quot;invoices_date_overlap&quot;
remove_exclusion_constraint :invoices, name: &quot;invoices_date_overlap&quot;"><pre><span>add_exclusion_constraint</span> <span>:invoices</span><span>,</span> <span>"daterange(start_date, end_date) WITH &amp;&amp;"</span><span>,</span> <span>using</span>: <span>:gist</span><span>,</span> <span>name</span>: <span>"invoices_date_overlap"</span>
<span>remove_exclusion_constraint</span> <span>:invoices</span><span>,</span> <span>name</span>: <span>"invoices_date_overlap"</span></pre></div>
<p>See PostgreSQL's <a href="https://www.postgresql.org/docs/12/sql-createtable.html#SQL-CREATETABLE-EXCLUDE" rel="nofollow"><code>CREATE TABLE ... EXCLUDE ...</code></a> documentation for more on exclusion constraints.</p>
<p><em>Alex Robbin</em></p>
</li>
<li>
<p><code>change_column_null</code> raises if a non-boolean argument is provided</p>
<p>Previously if you provided a non-boolean argument, <code>change_column_null</code> would<br>
treat it as truthy and make your column nullable. This could be surprising, so now<br>
the input must be either <code>true</code> or <code>false</code>.</p>
<div data-snippet-clipboard-copy-content="change_column_null :table, :column, true # good
change_column_null :table, :column, false # good
change_column_null :table, :column, from: true, to: false # raises (previously this made the column nullable)"><pre><span>change_column_null</span> <span>:table</span><span>,</span> <span>:column</span><span>,</span> <span>true</span> <span># good</span>
<span>change_column_null</span> <span>:table</span><span>,</span> <span>:column</span><span>,</span> <span>false</span> <span># good</span>
<span>change_column_null</span> <span>:table</span><span>,</span> <span>:column</span><span>,</span> <span>from</span>: <span>true</span><span>,</span> <span>to</span>: <span>false</span> <span># raises (previously this made the column nullable)</span></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Enforce limit on table names length.</p>
<p>Fixes <a data-error-text="Failed to load title" data-id="1241820374" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/45130" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/45130/hovercard" href="https://github.com/rails/rails/issues/45130">#45130</a>.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Adjust the minimum MariaDB version for check constraints support.</p>
<p><em>Eddie Lebow</em></p>
</li>
<li>
<p>Fix Hstore deserialize regression.</p>
<p><em>edsharp</em></p>
</li>
<li>
<p>Add validity for PostgreSQL indexes.</p>
<div data-snippet-clipboard-copy-content="connection.index_exists?(:users, :email, valid: true)
connection.indexes(:users).select(&amp;:valid?)"><pre><span>connection</span><span>.</span><span>index_exists?</span><span>(</span><span>:users</span><span>,</span> <span>:email</span><span>,</span> <span>valid</span>: <span>true</span><span>)</span>
<span>connection</span><span>.</span><span>indexes</span><span>(</span><span>:users</span><span>)</span><span>.</span><span>select</span><span>(</span>&amp;<span>:valid?</span><span>)</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Fix eager loading for models without primary keys.</p>
<p><em>Anmol Chopra</em>, <em>Matt Lawrence</em>, and <em>Jonathan Hefner</em></p>
</li>
<li>
<p>Avoid validating a unique field if it has not changed and is backed by a unique index.</p>
<p>Previously, when saving a record, Active Record will perform an extra query to check for the<br>
uniqueness of each attribute having a <code>uniqueness</code> validation, even if that attribute hasn't changed.<br>
If the database has the corresponding unique index, then this validation can never fail for persisted<br>
records, and we could safely skip it.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Stop setting <code>sql_auto_is_null</code></p>
<p>Since version 5.5 the default has been off, we no longer have to manually turn it off.</p>
<p><em>Adam Hess</em></p>
</li>
<li>
<p>Fix <code>touch</code> to raise an error for readonly columns.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Add ability to ignore tables by regexp for SQL schema dumps.</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::SchemaDumper.ignore_tables = [/^_/]"><pre><span>ActiveRecord</span>::<span>SchemaDumper</span><span>.</span><span>ignore_tables</span> <span>=</span> <span>[</span><span>/^_/</span><span>]</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Avoid queries when performing calculations on contradictory relations.</p>
<p>Previously calculations would make a query even when passed a<br>
contradiction, such as <code>User.where(id: []).count</code>. We no longer perform a<br>
query in that scenario.</p>
<p>This applies to the following calculations: <code>count</code>, <code>sum</code>, <code>average</code>,<br>
<code>minimum</code> and <code>maximum</code></p>
<p><em>Luan Vieira, John Hawthorn and Daniel Colson</em></p>
</li>
<li>
<p>Allow using aliased attributes with <code>insert_all</code>/<code>upsert_all</code>.</p>
<div data-snippet-clipboard-copy-content="class Book < ApplicationRecord
  alias_attribute :title, :name
end

Book.insert_all [{ title: &quot;Remote&quot;, author_id: 1 }], returning: :title"><pre><span>class</span> <span>Book</span> &lt; <span>ApplicationRecord</span>
  <span>alias_attribute</span> <span>:title</span><span>,</span> <span>:name</span>
<span>end</span>

<span>Book</span><span>.</span><span>insert_all</span> <span>[</span><span>{</span> <span>title</span>: <span>"Remote"</span><span>,</span> <span>author_id</span>: <span>1</span> <span>}</span><span>]</span><span>,</span> <span>returning</span>: <span>:title</span></pre></div>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Support encrypted attributes on columns with default db values.</p>
<p>This adds support for encrypted attributes defined on columns with default values.<br>
It will encrypt those values at creation time. Before, it would raise an<br>
error unless <code>config.active_record.encryption.support_unencrypted_data</code> was true.</p>
<p><em>Jorge Manrubia</em> and <em>Dima Fatko</em></p>
</li>
<li>
<p>Allow overriding <code>reading_request?</code> in <code>DatabaseSelector::Resolver</code></p>
<p>The default implementation checks if a request is a <code>get?</code> or <code>head?</code>,<br>
but you can now change it to anything you like. If the method returns true,<br>
<code>Resolver#read</code> gets called meaning the request could be served by the<br>
replica database.</p>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Remove <code>ActiveRecord.legacy_connection_handling</code>.</p>
<p><em>Eileen M. Uchitelle</em></p>
</li>
<li>
<p><code>rails db:schema:{dump,load}</code> now checks <code>ENV["SCHEMA_FORMAT"]</code> before config</p>
<p>Since <code>rails db:structure:{dump,load}</code> was deprecated there wasn't a simple<br>
way to dump a schema to both SQL and Ruby formats. You can now do this with<br>
an environment variable. For example:</p>
<div data-snippet-clipboard-copy-content="SCHEMA_FORMAT=sql rake db:schema:dump"><pre><code>SCHEMA_FORMAT=sql rake db:schema:dump
</code></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Fixed MariaDB default function support.</p>
<p>Defaults would be written wrong in "db/schema.rb" and not work correctly<br>
if using <code>db:schema:load</code>. Further more the function name would be<br>
added as string content when saving new records.</p>
<p><em>kaspernj</em></p>
</li>
<li>
<p>Add <code>active_record.destroy_association_async_batch_size</code> configuration</p>
<p>This allows applications to specify the maximum number of records that will<br>
be destroyed in a single background job by the <code>dependent: :destroy_async</code><br>
association option. By default, the current behavior will remain the same:<br>
when a parent record is destroyed, all dependent records will be destroyed<br>
in a single background job. If the number of dependent records is greater<br>
than this configuration, the records will be destroyed in multiple<br>
background jobs.</p>
<p><em>Nick Holden</em></p>
</li>
<li>
<p>Fix <code>remove_foreign_key</code> with <code>:if_exists</code> option when foreign key actually exists.</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Remove <code>--no-comments</code> flag in structure dumps for PostgreSQL</p>
<p>This broke some apps that used custom schema comments. If you don't want<br>
comments in your structure dump, you can use:</p>
<div data-snippet-clipboard-copy-content="ActiveRecord::Tasks::DatabaseTasks.structure_dump_flags = ['--no-comments']"><pre><span>ActiveRecord</span>::<span>Tasks</span>::<span>DatabaseTasks</span><span>.</span><span>structure_dump_flags</span> <span>=</span> <span>[</span><span>'--no-comments'</span><span>]</span></pre></div>
<p><em>Alex Ghiculescu</em></p>
</li>
<li>
<p>Reduce the memory footprint of fixtures accessors.</p>
<p>Until now fixtures accessors were eagerly defined using <code>define_method</code>.<br>
So the memory usage was directly dependent of the number of fixtures and<br>
test suites.</p>
<p>Instead fixtures accessors are now implemented with <code>method_missing</code>,<br>
so they incur much less memory and CPU overhead.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Fix <code>config.active_record.destroy_association_async_job</code> configuration</p>
<p><code>config.active_record.destroy_association_async_job</code> should allow<br>
applications to specify the job that will be used to destroy associated<br>
records in the background for <code>has_many</code> associations with the<br>
<code>dependent: :destroy_async</code> option. Previously, that was ignored, which<br>
meant the default <code>ActiveRecord::DestroyAssociationAsyncJob</code> always<br>
destroyed records in the background.</p>
<p><em>Nick Holden</em></p>
</li>
<li>
<p>Fix <code>change_column_comment</code> to preserve column's AUTO_INCREMENT in the MySQL adapter</p>
<p><em>fatkodima</em></p>
</li>
<li>
<p>Fix quoting of <code>ActiveSupport::Duration</code> and <code>Rational</code> numbers in the MySQL adapter.</p>
<p><em>Kevin McPhillips</em></p>
</li>
<li>
<p>Allow column name with COLLATE (e.g., title COLLATE "C") as safe SQL string</p>
<p><em>Shugo Maeda</em></p>
</li>
<li>
<p>Permit underscores in the VERSION argument to database rake tasks.</p>
<p><em>Eddie Lebow</em></p>
</li>
<li>
<p>Reversed the order of <code>INSERT</code> statements in <code>structure.sql</code> dumps</p>
<p>This should decrease the likelihood of merge conflicts. New migrations<br>
will now be added at the top of the list.</p>
<p>For existing apps, there will be a large diff the next time <code>structure.sql</code><br>
is generated.</p>
<p><em>Alex Ghiculescu</em>, <em>Matt Larraz</em></p>
</li>
<li>
<p>Fix PG.connect keyword arguments deprecation warning on ruby 2.7</p>
<p>Fixes <a data-error-text="Failed to load title" data-id="1121266570" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/44307" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/44307/hovercard" href="https://github.com/rails/rails/issues/44307">#44307</a>.</p>
<p><em>Nikita Vasilevsky</em></p>
</li>
<li>
<p>Fix dropping DB connections after serialization failures and deadlocks.</p>
<p>Prior to 6.1.4, serialization failures and deadlocks caused rollbacks to be<br>
issued for both real transactions and savepoints. This breaks MySQL which<br>
disallows rollbacks of savepoints following a deadlock.</p>
<p>6.1.4 removed these rollbacks, for both transactions and savepoints, causing<br>
the DB connection to be left in an unknown state and thus discarded.</p>
<p>These rollbacks are now restored, except for savepoints on MySQL.</p>
<p><em>Thomas Morgan</em></p>
</li>
<li>
<p>Make <code>ActiveRecord::ConnectionPool</code> Fiber-safe</p>
<p>When <code>ActiveSupport::IsolatedExecutionState.isolation_level</code> is set to <code>:fiber</code>,<br>
the connection pool now supports multiple Fibers from the same Thread checking<br>
out connections from the pool.</p>
<p><em>Alex Matchneer</em></p>
</li>
<li>
<p>Add <code>update_attribute!</code> to <code>ActiveRecord::Persistence</code></p>
<p>Similar to <code>update_attribute</code>, but raises <code>ActiveRecord::RecordNotSaved</code> when a <code>before_*</code> callback throws <code>:abort</code>.</p>
<div data-snippet-clipboard-copy-content="class Topic < ActiveRecord::Base
  before_save :check_title

  def check_title
    throw(:abort) if title == &quot;abort&quot;
  end
end

topic = Topic.create(title: &quot;Test Title&quot;)
# #=> #<Topic title: &quot;Test Title&quot;>
topic.update_attribute!(:title, &quot;Another Title&quot;)
# #=> #<Topic title: &quot;Another Title&quot;>
topic.update_attribute!(:title, &quot;abort&quot;)
# raises ActiveRecord::RecordNotSaved"><pre><span>class</span> <span>Topic</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>before_save</span> <span>:check_title</span>

  <span>def</span> <span>check_title</span>
    <span>throw</span><span>(</span><span>:abort</span><span>)</span> <span>if</span> <span>title</span> == <span>"abort"</span>
  <span>end</span>
<span>end</span>

<span>topic</span> <span>=</span> <span>Topic</span><span>.</span><span>create</span><span>(</span><span>title</span>: <span>"Test Title"</span><span>)</span>
<span># #=&gt; #&lt;Topic title: "Test Title"&gt;</span>
<span>topic</span><span>.</span><span>update_attribute!</span><span>(</span><span>:title</span><span>,</span> <span>"Another Title"</span><span>)</span>
<span># #=&gt; #&lt;Topic title: "Another Title"&gt;</span>
<span>topic</span><span>.</span><span>update_attribute!</span><span>(</span><span>:title</span><span>,</span> <span>"abort"</span><span>)</span>
<span># raises ActiveRecord::RecordNotSaved</span></pre></div>
<p><em>Drew Tempelmeyer</em></p>
</li>
<li>
<p>Avoid loading every record in <code>ActiveRecord::Relation#pretty_print</code></p>
<div data-snippet-clipboard-copy-content="# Before
pp Foo.all # Loads the whole table.

# After
pp Foo.all # Shows 10 items and an ellipsis."><pre><span># Before</span>
<span>pp</span> <span>Foo</span><span>.</span><span>all</span> <span># Loads the whole table.</span>

<span># After</span>
<span>pp</span> <span>Foo</span><span>.</span><span>all</span> <span># Shows 10 items and an ellipsis.</span></pre></div>
<p><em>Ulysse Buonomo</em></p>
</li>
<li>
<p>Change <code>QueryMethods#in_order_of</code> to drop records not listed in values.</p>
<p><code>in_order_of</code> now filters down to the values provided, to match the behavior of the <code>Enumerable</code> version.</p>
<p><em>Kevin Newton</em></p>
</li>
<li>
<p>Allow named expression indexes to be revertible.</p>
<p>Previously, the following code would raise an error in a reversible migration executed while rolling back, due to the index name not being used in the index removal.</p>
<div data-snippet-clipboard-copy-content="add_index(:settings, &quot;(data->'property')&quot;, using: :gin, name: :index_settings_data_property)"><pre><span>add_index</span><span>(</span><span>:settings</span><span>,</span> <span>"(data-&gt;'property')"</span><span>,</span> <span>using</span>: <span>:gin</span><span>,</span> <span>name</span>: <span>:index_settings_data_property</span><span>)</span></pre></div>
<p>Fixes <a data-error-text="Failed to load title" data-id="1010891915" data-permission-text="Title is private" data-url="https://github.com/rails/rails/issues/43331" data-hovercard-type="issue" data-hovercard-url="/rails/rails/issues/43331/hovercard" href="https://github.com/rails/rails/issues/43331">#43331</a>.</p>
<p><em>Oliver Günther</em></p>
</li>
<li>
<p>Fix incorrect argument in PostgreSQL structure dump tasks.</p>
<p>Updating the <code>--no-comment</code> argument added in Rails 7 to the correct <code>--no-comments</code> argument.</p>
<p><em>Alex Dent</em></p>
</li>
<li>
<p>Fix migration compatibility to create SQLite references/belongs_to column as integer when migration version is 6.0.</p>
<p>Reference/belongs_to in migrations with version 6.0 were creating columns as<br>
bigint instead of integer for the SQLite Adapter.</p>
<p><em>Marcelo Lauxen</em></p>
</li>
<li>
<p>Fix <code>QueryMethods#in_order_of</code> to handle empty order list.</p>
<div data-snippet-clipboard-copy-content="Post.in_order_of(:id, []).to_a"><pre><span>Post</span><span>.</span><span>in_order_of</span><span>(</span><span>:id</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>.</span><span>to_a</span></pre></div>
<p>Also more explicitly set the column as secondary order, so that any other<br>
value is still ordered.</p>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Fix quoting of column aliases generated by calculation methods.</p>
<p>Since the alias is derived from the table name, we can't assume the result<br>
is a valid identifier.</p>
<div data-snippet-clipboard-copy-content="class Test < ActiveRecord::Base
  self.table_name = '1abc'
end
Test.group(:id).count
# syntax error at or near &quot;1&quot; (ActiveRecord::StatementInvalid)
# LINE 1: SELECT COUNT(*) AS count_all, &quot;1abc&quot;.&quot;id&quot; AS 1abc_id FROM &quot;1..."><pre><span>class</span> <span>Test</span> &lt; <span>ActiveRecord</span>::<span>Base</span>
  <span>self</span><span>.</span><span>table_name</span> <span>=</span> <span>'1abc'</span>
<span>end</span>
<span>Test</span><span>.</span><span>group</span><span>(</span><span>:id</span><span>)</span><span>.</span><span>count</span>
<span># syntax error at or near "1" (ActiveRecord::StatementInvalid)</span>
<span># LINE 1: SELECT COUNT(*) AS count_all, "1abc"."id" AS 1abc_id FROM "1...</span></pre></div>
<p><em>Jean Boussier</em></p>
</li>
<li>
<p>Add <code>authenticate_by</code> when using <code>has_secure_password</code>.</p>
<p><code>authenticate_by</code> is intended to replace code like the following, which<br>
returns early when a user with a matching email is not found:</p>
<div data-snippet-clipboard-copy-content="User.find_by(email: &quot;...&quot;)&amp;.authenticate(&quot;...&quot;)"><pre><span>User</span><span>.</span><span>find_by</span><span>(</span><span>email</span>: <span>"..."</span><span>)</span>&amp;.<span>authenticate</span><span>(</span><span>"..."</span><span>)</span></pre></div>
<p>Such code is vulnerable to timing-based enumeration attacks, wherein an<br>
attacker can determine if a user account with a given email exists. After<br>
confirming that an account exists, the attacker can try passwords associated<br>
with that email address from other leaked databases, in case the user<br>
re-used a password across multiple sites (a common practice). Additionally,<br>
knowing an account email address allows the attacker to attempt a targeted<br>
phishing ("spear phishing") attack.</p>
<p><code>authenticate_by</code> addresses the vulnerability by taking the same amount of<br>
time regardless of whether a user with a matching email is found:</p>
<div data-snippet-clipboard-copy-content="User.authenticate_by(email: &quot;...&quot;, password: &quot;...&quot;)"><pre><span>User</span><span>.</span><span>authenticate_by</span><span>(</span><span>email</span>: <span>"..."</span><span>,</span> <span>password</span>: <span>"..."</span><span>)</span></pre></div>
<p><em>Jonathan Hefner</em></p>
</li>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google's agreement with Samsung prevented Branch from launching: testimony (134 pts)]]></title>
            <link>https://www.bigtechontrial.com/p/google-is-clearly-buying-its-way</link>
            <guid>37786653</guid>
            <pubDate>Fri, 06 Oct 2023 02:43:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigtechontrial.com/p/google-is-clearly-buying-its-way">https://www.bigtechontrial.com/p/google-is-clearly-buying-its-way</a>, See on <a href="https://news.ycombinator.com/item?id=37786653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2957218,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe461c04-821d-4897-9a20-a9ec29ad945e_6210x4140.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Former Samsung employee Patrick Chang (who is not either of the people in the photo above) testified about the barrier that Samsung’s default agreements with Google posed for Branch Metrics. (Photo by Kelly Sullivan/Getty Images for Samsung Electronics America).</figcaption></figure></div><p>When the founder and former CEO of Branch Metrics Alex Austin took the stand last Wednesday, we heard about Branch’s multi-year struggle to find homes for its app-search software. Austin testified that it felt like an “injustice” that his company was never able to launch an unrestricted version of its technology.</p><p>Today we heard another perspective of Branch’s story from former Samsung employee Patrick Chang, who had a special relationship with Branch: he played a leading role in Samsung’s investment in the young software company. As a Director at Samsung Next Ventures — the venture capital investment arm of Samsung Electronics — Chang was the employee who made the initial recommendation for Samsung to provide funding to Branch.</p><p><span>Before I cover Chang’s testimony, here’s an excerpt from </span><a href="https://www.bigtechontrial.com/p/a-tale-of-two-software-companies" rel="">my write-up on Austin's testimony</a><span> that may offer a helpful refresher on what we’ve already heard about Branch:</span></p><blockquote><p>At the beginning of his testimony, Austin described the initial mission that Branch focused on: building a search engine for apps that would allow users to pull up specific app pages from search queries through “deep linking” technology. For example, if you searched for “Pizza” on a Branch-integrated search bar, you would get results that brought you directly to pizza-related pages on apps you might own like Yelp or UberEats, as well as suggestions for apps that you hadn’t yet downloaded.</p><p>Austin thought this technology would create a win-win-win. Phone manufacturers and carriers could add another feature to their phones that would not only enhance the user experience but also create a new source of ad revenue, and app developers would get a new way to grow and distribute their apps outside of crowded app stores.</p><p>But Austin and his team soon discovered a familiar barrier: Google’s search engine default agreements. According to Austin, every single potential partner that he pitched Branch to turned it down for the same reason. Their contract with Google wouldn’t allow it. </p><p>Branch pivoted by developing an “offline” device search. This was apparently the only way that phone manufacturers like Samsung could implement Branch without violating their revenue share agreements (RSAs) with Google, which he understood to require that Google be the only “web-connected” search function pre-loaded onto a device.</p></blockquote><p>Chang’s testimony was more emotionally muted than Austin’s, but as a whole, it largely corroborated the story Austin told about the obstacles Branch faced in working around Samsung’s relationship with Google.</p><p><span>In his responses to the DOJ’s questioning, Chang at times seemed reticent about saying anything that would be damaging to Google. But the exhibits that DOJ introduced of Chang’s internal messages with Samsung colleagues highlighted Chang’s attempts to advocate for a “carve-out” in Samsung’s default search engine agreement with Google that would allow Samsung phones to integrate a more powerful version of Branch’s software.</span></p><p><span> (These exhibits have not yet been posted at the time of this article’s publication, but will likely be posted sometime soon on </span><a href="https://www.justice.gov/atr/us-and-plaintiff-states-v-google-llc-2020-trial-exhibits" rel="">the DOJ’s website</a><span>.)</span></p><p>In July 2020 — during the same period that Samsung executives were negotiating a new default agreement with Google — Chang wrote in one chat message: “The current agreement is looking like google will own all search on device….This will completely kill all potential for any branch search and other future services….[A]ll this will be killed if this google agreement happens.”</p><p>As the negotiations continued, Chang wrote a few weeks later: “This is probably Google being aware of Branch as you mentioned on their call and attempting to kill all of Branch’s attempts.”</p><p>Chang’s boss David Eun responded: “Google is clearly buying its way to squelch competitors….Outside of a potential antitrust action, I don't see Samsung refusing these terms.”</p><p>The DOJ filed its complaint against Google in this case on October 20, 2020. A couple days later, another Samsung employee suggested to Chang that the lawsuit might cause Google to loosen its interpretations of its contracts with Samsung.</p><p>Chang responded: “Actually the COMPLETE opposite. Google just did a f*ck you to Samsung. After the doj filings, they submitted a new redline that went backwards om all negotiations with Samsung and was even more aggressive in being restrictive….They basically don’t feel the doj has a real case.”</p><p>As Google’s cross examination of Chang made clear, there were differing opinions about Branch amongst his colleagues at Samsung and partnering phone carriers. Some felt that Branch would cannibalize search revenues generated from Google and others cited concerns about low user engagement with the restricted version of Branch that was integrated into Samsung phones. But Chang’s messages indicated that he believed Branch offered a complimentary product that didn’t compete with Google search and offered a path to higher overall revenue. </p><p>Chang’s vision of integrating a more powerful version of Branch into Samsung phones ultimately never came to fruition and he left Samsung Next in 2021 to start his own venture fund.</p><p><strong>The Cellophane Fallacy</strong></p><p>This afternoon we also heard the start of expert witness testimony from MIT economist Michael Whinston. Whinston’s testimony is being broken up into two separate weeks of the trial, but today he testified to his opinion that the three markets alleged by the DOJ — the markets for general search services, general search text advertising, and search advertising — are all relevant antitrust markets.</p><p>The DOJ’s direct examination walked Whinston through the slide deck he prepared as Whinston described the various methodologies he relied on to reach his conclusion about the relevant antitrust markets. This included reviewing previous testimony in this trial as well as internal Google documents.</p><p><span>What seemed to be of greatest interest to Judge Mehta based on his questions was Whinston’s discussion of the “cellophane fallacy”, which refers to the flawed reasoning the Supreme Court relied on in the </span><a href="https://supreme.justia.com/cases/federal/us/351/377/" rel="">1956 </a><em><a href="https://supreme.justia.com/cases/federal/us/351/377/" rel="">Du Pont &amp; Co.</a></em><a href="https://supreme.justia.com/cases/federal/us/351/377/" rel=""> monopoly case</a><span>. </span></p><p><span>Whinston didn’t describe the cellophane fallacy in the exact same terms, but </span><a href="https://en.wikipedia.org/wiki/Cellophane_paradox" rel="">Wikipedia provides</a><span> a helpful distillation of the concept: </span></p><blockquote><p><span>In research on the du Pont company arising from his PhD dissertation, Willard F. Mueller and co-author </span><a href="https://en.wikipedia.org/wiki/George_W._Stocking,_Sr." rel="">George W. Stocking, Sr.</a><span> pointed out the error of mistaking a monopolist's inability to exercise </span><a href="https://en.wikipedia.org/wiki/Market_power" rel="">market power</a><span> by raising price above the </span><em>current</em><span> price for an inability to have already exercised market power by raising price significantly above the </span><em>competitive</em><span> price. Courts that use a monopolized product's elevated market price will typically misconstrue a completed anti-competitive act as a lack of market power. Had the Supreme Court considered the substitutability of other wrappings at cellophane's competitive price, the sales of other wrappings would have been much lower; du Pont might very well have been found guilty of monopolizing the market for flexible wrappings.</span></p></blockquote><p>Whinston explained the cellophane fallacy to make the point that the fact that there may be some substitution away from Google’s products is not inconsistent with it being a monopolist.</p><p>Tomorrow, Whinston is expected to continue testifying about his additional conclusion that Google possesses substantial market power protected by barriers to entry in each of the three relevant markets. Google will not cross-examine Whinston until after he completes the second portion of his direct examination testimony later in the trial.</p><p><span>Fridays are only a half-day for the trial so I might not write an article tomorrow, but I’ll post some updates on </span><a href="https://twitter.com/BigTechOnTrial" rel="">the Big Tech on Trial X/Twitter account</a><span>. The trial is scheduled to be off on Monday before resuming on Tuesday.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ollama is now available as an official Docker image (181 pts)]]></title>
            <link>https://ollama.ai/blog/ollama-is-now-available-as-an-official-docker-image</link>
            <guid>37786525</guid>
            <pubDate>Fri, 06 Oct 2023 02:18:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ollama.ai/blog/ollama-is-now-available-as-an-official-docker-image">https://ollama.ai/blog/ollama-is-now-available-as-an-official-docker-image</a>, See on <a href="https://news.ycombinator.com/item?id=37786525">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <p><img src="https://github.com/jmorganca/ollama/assets/3325447/080f3a72-e2fd-4741-8070-ae79a06f943f">
</p>

<h2>Ollama is now available as an official Docker image</h2>

<p>We are excited to share that Ollama is now available as an official Docker sponsored <a href="https://hub.docker.com/r/ollama/ollama">open-source image</a>, making it simpler to get up and running with large language models using Docker containers.</p>

<p>With Ollama, all your interactions with large language models happen locally without sending private data to third-party services.</p>

<h2>On the Mac</h2>

<p>Ollama handles running the model with GPU acceleration. It provides both a simple CLI as well as a REST API for interacting with your applications.</p>

<p>To get started, simply <a href="https://ollama.ai/download">download</a> and install Ollama.</p>

<p>We recommend running Ollama alongside Docker Desktop for macOS in order for Ollama to enable GPU acceleration for models.</p>

<h2>On Linux</h2>

<p>Ollama can run with GPU acceleration inside Docker containers for Nvidia GPUs.</p>

<p>To get started using the Docker image, please use the commands below.</p>

<h4>CPU only</h4>

<pre><code>docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
</code></pre>

<h4>Nvidia GPU</h4>

<ol>
<li>Install the <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation">Nvidia container toolkit</a>.</li>
<li>Run Ollama inside a Docker container</li>
</ol>

<pre><code>docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
</code></pre>

<h3>Run a model</h3>

<p>Now you can run a model like Llama 2 inside the container.</p>

<pre><code>docker exec -it ollama ollama run llama2
</code></pre>

<p>More models can be found on the <a href="https://ollama.ai/library">Ollama library</a>.</p>

<p>Join Ollama’s <a href="https://discord.gg/ollama">Discord</a> to chat with other community members, maintainers, and contributors.</p>

<p>Follow <a href="https://twitter.com/ollama_ai">Ollama on Twitter</a> for updates.</p>

      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gboard Hat Version (194 pts)]]></title>
            <link>https://landing.google.co.jp/caps/</link>
            <guid>37785920</guid>
            <pubDate>Fri, 06 Oct 2023 00:27:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://landing.google.co.jp/caps/">https://landing.google.co.jp/caps/</a>, See on <a href="https://news.ycombinator.com/item?id=37785920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
          <!-- prettier-ignore -->
          <p>誰かに<wbr>思いを<wbr>伝える<wbr>ために<wbr>筆を<wbr>走らせ、<wbr>自分の<wbr>ことを<wbr>より<wbr>知る<wbr>ために<wbr>文字を<wbr>紡ぐ。<wbr>文字入力は<wbr>新しい<wbr>世界と<wbr>自分を<wbr>知る<wbr>冒険だ。</p>

          <!-- prettier-ignore -->
          <p>あなたと<wbr>一体となる<wbr>キーボード、<wbr>Gboard 帽バージョン。</p>
        </div>
      <p>
        <iframe title="YouTube video player" src="https://www.youtube-nocookie.com/embed/6vib77CUxNM" frameborder="0" allowfullscreen="" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe>
      </p>
      <section>
        <h2>
          <ruby>Wearable<rp>(</rp><rt>ウェアラ<b>ボー</b></rt><rp>)</rp></ruby>
          で
          <ruby>Portable<rp>(</rp><rt>ポータ<b>ボー</b></rt><rp>)</rp></ruby>
          で
          <ruby>Fashionable<rp>(</rp><rt>ファッショナ<b>ボー</b></rt><rp>)</rp></ruby>
          な
          <ruby>Keyboard<rp>(</rp><rt>キー<b>ボー</b>ド</rt><rp>)</rp></ruby>
        </h2>
        <p>いつも<wbr>使う<wbr>キーボードだから<wbr>こそ、<wbr>常に<wbr>おしゃれに<wbr>持ち歩きたい。<wbr>Gboard 帽バージョンなら、<wbr>日々の<wbr>ファッションに<wbr>取り入れるだけで、<wbr>思い立ったら<wbr>すぐ<wbr>文字入力できます。</p>
        <picture>
          <source srcset="
              https://lh3.googleusercontent.com/kNcDR3TqUJvZAvcLLVgA_yseoFVcIzaY9OKaWVcuotQ4PFD-1_jnpx9WVqzr0-BTPiAOC2uE6RXx6_tBkP8Vd4nK66gfD7QRFBR7F6jW5jrscm_jZuA=w1248-rw 1248w,
              https://lh3.googleusercontent.com/kNcDR3TqUJvZAvcLLVgA_yseoFVcIzaY9OKaWVcuotQ4PFD-1_jnpx9WVqzr0-BTPiAOC2uE6RXx6_tBkP8Vd4nK66gfD7QRFBR7F6jW5jrscm_jZuA=w2492-rw 2492w
            " type="image/webp">
          <source srcset="
              https://lh3.googleusercontent.com/kNcDR3TqUJvZAvcLLVgA_yseoFVcIzaY9OKaWVcuotQ4PFD-1_jnpx9WVqzr0-BTPiAOC2uE6RXx6_tBkP8Vd4nK66gfD7QRFBR7F6jW5jrscm_jZuA=w1248-rj 1248w,
              https://lh3.googleusercontent.com/kNcDR3TqUJvZAvcLLVgA_yseoFVcIzaY9OKaWVcuotQ4PFD-1_jnpx9WVqzr0-BTPiAOC2uE6RXx6_tBkP8Vd4nK66gfD7QRFBR7F6jW5jrscm_jZuA=w2492-rj 2492w
            " type="image/jpeg">
          <img src="https://lh3.googleusercontent.com/kNcDR3TqUJvZAvcLLVgA_yseoFVcIzaY9OKaWVcuotQ4PFD-1_jnpx9WVqzr0-BTPiAOC2uE6RXx6_tBkP8Vd4nK66gfD7QRFBR7F6jW5jrscm_jZuA=w1248" fetchpriority="auto" alt="Gboard 帽バージョンを使って文字を入力している様子" width="2492" height="1661">
        </picture>
      </section>
      <section>
        <!-- prettier-ignore -->
        <h2>ひとつの<wbr>帽子、<wbr>無限の<wbr>可能性</h2>
        <p>Gboard 帽バージョンなら、<wbr>もう<wbr>キーの<wbr>場所を<wbr>覚える<wbr>必要は<wbr>ありません。<wbr>頭の<wbr>方向で<wbr>文字を<wbr>選択、<wbr>頭を<wbr>押して<wbr>文字を<wbr>確定する<wbr> A<span>tama</span> I<span>nput</span> 機構を<wbr>採用しています。</p>
        
      </section>
      <section id="variation">
        <!-- prettier-ignore -->
        <h2>いつも<wbr>使うから<wbr>こそ<wbr>おしゃれしたい</h2>
        <p>普段<wbr>使いの<wbr>帽子と<wbr>しても<wbr>ファッショナボーに<wbr>お使いいただけるよう、<wbr>豊富な<wbr>バリエーションを<wbr>ご用意しています。</p>
        <picture>
          <source srcset="
              https://lh3.googleusercontent.com/9hWktV1GDCbPyjVgH0Eg2irYIfQzV908L757Pfn4YdZoe3Ll0zjq5jyqUd9ZTy3dTPvCXxzWKYzxEqWRhIBsz2DetgQveRB7s6f1Vi8kUyWxSCwNdw=w1248-rw 1248w,
              https://lh3.googleusercontent.com/9hWktV1GDCbPyjVgH0Eg2irYIfQzV908L757Pfn4YdZoe3Ll0zjq5jyqUd9ZTy3dTPvCXxzWKYzxEqWRhIBsz2DetgQveRB7s6f1Vi8kUyWxSCwNdw=w2492-rw 2492w
            " type="image/webp">
          <source srcset="
              https://lh3.googleusercontent.com/9hWktV1GDCbPyjVgH0Eg2irYIfQzV908L757Pfn4YdZoe3Ll0zjq5jyqUd9ZTy3dTPvCXxzWKYzxEqWRhIBsz2DetgQveRB7s6f1Vi8kUyWxSCwNdw=w1248-rj 1248w,
              https://lh3.googleusercontent.com/9hWktV1GDCbPyjVgH0Eg2irYIfQzV908L757Pfn4YdZoe3Ll0zjq5jyqUd9ZTy3dTPvCXxzWKYzxEqWRhIBsz2DetgQveRB7s6f1Vi8kUyWxSCwNdw=w2492-rj 2492w
            " type="image/jpeg">
          <img src="https://lh3.googleusercontent.com/9hWktV1GDCbPyjVgH0Eg2irYIfQzV908L757Pfn4YdZoe3Ll0zjq5jyqUd9ZTy3dTPvCXxzWKYzxEqWRhIBsz2DetgQveRB7s6f1Vi8kUyWxSCwNdw=w1248" fetchpriority="auto" alt="さまざまな形と色の帽子型キーボード" width="2492" height="1402">
        </picture>
        <p>Gboard 帽バージョンを<wbr>いつでも<wbr>持ち歩けるよう、<wbr>壁紙を<wbr>ご用意しました。<wbr>お使いの<wbr>端末の<wbr>画面に<wbr>合わせた<wbr>画像を<wbr>ダウンロードできます。</p>
        
      </section>
      <section id="diy">
        <!-- prettier-ignore -->
        <h2>あなただけの<wbr>帽子型キーボードを<wbr>つくる</h2>
        <p>Gboard 帽バージョンは<wbr>みなさんの<wbr>手で<wbr>制作できる<wbr> DIY デバイスです。</p>
        <div>
          <div>
            <picture>
              <source srcset="
                  https://lh3.googleusercontent.com/4Ty1Irbi_SALfoYlFd_kCrE5DNOhUYBt1nA-MOKC-AQICsNbLedgNjMTohgJ-J1atu-ySLAV8HSXbG_aGPidJltl9w5tt_jdXhIwkzNsFcybez7-AKM=w1232-rw
                " type="image/webp">
              <source srcset="
                  https://lh3.googleusercontent.com/4Ty1Irbi_SALfoYlFd_kCrE5DNOhUYBt1nA-MOKC-AQICsNbLedgNjMTohgJ-J1atu-ySLAV8HSXbG_aGPidJltl9w5tt_jdXhIwkzNsFcybez7-AKM=w1232-rj
                " type="image/jpeg">
              <img src="https://lh3.googleusercontent.com/4Ty1Irbi_SALfoYlFd_kCrE5DNOhUYBt1nA-MOKC-AQICsNbLedgNjMTohgJ-J1atu-ySLAV8HSXbG_aGPidJltl9w5tt_jdXhIwkzNsFcybez7-AKM=w1232" fetchpriority="auto" alt="電子工作で帽子型キーボードを制作する様子" width="616" height="411">
            </picture>
            <h3>
              電子工作でつくる
            </h3>

            <!-- prettier-ignore -->
            <p>ご家庭の<wbr> 3D プリンターを<wbr>使って<wbr>制作する<wbr>本格派バージョンです。<wbr>ワンキー仕様の<wbr>文字入力を<wbr>体感したい<wbr>あなたに<wbr>ぴったりです。</p>
            <p><a href="https://github.com/google/mozc-devices/tree/master/mozc-caps" target="_blank" rel="noopener noreferrer">
              GitHub で設計書を見る
            </a>
          </p></div>
          <div>
            <picture>
              <source srcset="
                  https://lh3.googleusercontent.com/off3LhymuSpLRbtqNPSl4DGSZzZusQYHjjFIB20jf2vZ0rke98NexwBqJvEfloUGGOAJW-5treDxw0eKXNuvkzq_BdATU6iVuEJ7s1EguuJwieBlycH7=w1232-rw
                " type="image/webp">
              <source srcset="
                  https://lh3.googleusercontent.com/off3LhymuSpLRbtqNPSl4DGSZzZusQYHjjFIB20jf2vZ0rke98NexwBqJvEfloUGGOAJW-5treDxw0eKXNuvkzq_BdATU6iVuEJ7s1EguuJwieBlycH7=w1232-rj
                " type="image/jpeg">
              <img src="https://lh3.googleusercontent.com/off3LhymuSpLRbtqNPSl4DGSZzZusQYHjjFIB20jf2vZ0rke98NexwBqJvEfloUGGOAJW-5treDxw0eKXNuvkzq_BdATU6iVuEJ7s1EguuJwieBlycH7=w1232" fetchpriority="auto" alt="ダンボールで帽子型キーボードを制作する様子" width="616" height="411">
            </picture>
            <h3>
              ダンボールでつくる
            </h3>

            <!-- prettier-ignore -->
            <p>ダンボールと<wbr>ハサミで<wbr>つくる<wbr>お手軽バージョンです。<wbr>文字入力は<wbr>できませんが、<wbr>ファッショナボーな<wbr>気分を<wbr>味わえます。</p>
            <p><a href="https://landing.google.co.jp/caps/static/assets/gboard_caps_cardboard.pdf" target="_blank" rel="noopener noreferrer">
              制作ガイドを見る
            </a>
          </p></div>
        </div>
      </section>
      <div id="specs">
          <h2>
            仕様
          </h2>
          <div>
            <dl>
              <dt>センサー</dt>
              <dd>6 軸慣性センサー</dd>
              <dt>スイッチ</dt>
              <dd>1 軸プッシュスイッチ</dd>
              <dt>バッテリー</dt>
              <dd>3.7V 120mAh</dd>
              <dt>充電</dt>
              <dd>USB-C</dd>
              <dt>サイズ</dt>
              <dd>フリーサイズ（ユニセックス）</dd>
              <dt>キー数</dt>
              <dd>1</dd>
            </dl>
            <dl>
              <dt>キー荷重</dt>
              <dd>輪ゴムによる</dd>
              <dt>ストローク深さ</dt>
              <dd>2cm</dd>
              <dt>インターフェイス</dt>
              <dd>Bluetooth</dd>
              <dt>オプション</dt>
              <dd>UV カット</dd>
              <dt>付属品</dt>
              <dd>あごひも（CAPS LOCK）</dd>
              <dt>色</dt>
              <dd>ベージュ、ネイビー、その他いろいろ</dd>
            </dl>
          </div>
        </div>
      <div id="download">
          <!-- prettier-ignore -->
          
          <p>いままでの<wbr>盤面上の<wbr>文字入力に<wbr>慣れ親しんだ<wbr>方には、<wbr>通常版の<wbr> Gboard も<wbr>ご用意しております。<wbr>かわいい絵文字を<wbr>組み合わせて<wbr>遊べる<wbr> Emoji Kitchen (Android 版の<wbr>み) に<wbr>加え、<wbr>音声入力や<wbr>翻訳機能など<wbr> Google の<wbr>各種サービスと<wbr>連携した<wbr>快適な<wbr>入力体験を<wbr>提供します。</p>
          
        </div>
      <section id="faq">
        <h2>
          よくある質問
        </h2>
        <div>
          <dl>
            <!-- prettier-ignore -->
            <dt>今日は<wbr> 10 月 1 日ですよね？</dt>

            <!-- prettier-ignore -->
            <dd>は<wbr>い、<wbr>今日は<wbr> 10 月 1 日です！</dd>

            <!-- prettier-ignore -->
            <dt>今日は<wbr>なんの<wbr>日なんですか？</dt>

            <!-- prettier-ignore -->
            <dd>キーボードの<wbr>発表に<wbr>ふさわしい<wbr>日を<wbr>検討していた際、<wbr>101 キーボードと<wbr>呼ばれる<wbr> 101 個の<wbr>キーが<wbr>ある<wbr>タイプが<wbr>よく<wbr>使われている<wbr>ことに<wbr>気が<wbr>付きました。<wbr>そこで、<wbr>101 キーボードに<wbr>ちなんで<wbr> 10 月 1 日に<wbr>公開しました。</dd>

            <!-- prettier-ignore -->
            <dt>どこで<wbr>購入できますか？</dt>

            <!-- prettier-ignore -->
            <dd>発売予定は<wbr>ありません。<wbr>同様の<wbr>デバイスを<wbr>自作していただける<wbr>設計図を<wbr>オープンソースと<wbr>して<a href="https://github.com/google/mozc-devices/tree/master/mozc-caps" target="_blank" rel="noopener noreferrer"><wbr>公開</a>しています。<wbr>また、<wbr>キーキャップを<wbr>試着したい<wbr>方へは、<wbr>ダンボールと<wbr>ハサミで<wbr>つくる<a href="https://landing.google.co.jp/caps/static/assets/gboard_caps_cardboard.pdf" target="_blank" rel="noopener noreferrer"><wbr>製作ガイド</a>も<wbr>ご用意しました。</dd>

            <!-- prettier-ignore -->
            <dt>前回も<wbr>「<a href="https://g.co/____" target="_blank" rel="noopener noreferrer">ぼう<wbr>バージョン</a>」では<wbr>ありませんでした？</dt>

            <!-- prettier-ignore -->
            <dd>帽子なだけに<wbr>被ってしまいましたね！</dd>

            <!-- prettier-ignore -->
            <dt>はっと<wbr>するような<wbr>デバイスですね。</dt>

            <!-- prettier-ignore -->
            <dd>きぼうした<wbr>通りの<wbr>設計に<wbr>なりました。</dd>
          </dl>
        </div>
      </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ways to break your systems code using volatile (2010) (109 pts)]]></title>
            <link>https://blog.regehr.org/archives/28</link>
            <guid>37785706</guid>
            <pubDate>Thu, 05 Oct 2023 23:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.regehr.org/archives/28">https://blog.regehr.org/archives/28</a>, See on <a href="https://news.ycombinator.com/item?id=37785706">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The volatile qualifier in C/C++ is a little bit like the C preprocessor: an ugly, blunt tool that is easy to misuse but that — in a very narrow set of circumstances — gets the job done.&nbsp; This article will first briefly explain volatile and its history and then, through a series of examples about how not to use it, explain how to most effectively create correct systems software using volatile.&nbsp; Although this article focuses on C, almost everything in it also applies to C++.</p>
<h2>What does a C program mean?</h2>
<p>The <a href="http://www.open-std.org/JTC1/SC22/wg14/www/docs/n1124.pdf">C standard</a> defines the meaning of a C program in terms of an “abstract machine” that you can think of as a simple, non-optimizing interpreter for C.&nbsp; The behavior of any given C implementation (a compiler plus target machine) must produce the same side effects as the abstract machine, but otherwise the standard mandates very little correspondence between the abstract machine and computation that actually happens on the target platform.&nbsp; In other words, the C program can be thought of as a specification of desired effects, and the C implementation decides how to best go about making those effects happen.</p>
<p>As a simple example, consider this function:</p>
<pre><strong>int loop_add3 (int x) {
  int i;
  for (i=0; i&lt;3; i++) x++;
  return x;
}</strong></pre>
<p>The behavior of the abstract machine is clear: it creates a function-scoped variable named i which loops from 0 through 2, adding 1 to x on each iteration of the loop.&nbsp; On the other hand, a good compiler emits code like this:</p>
<pre><strong>loop_add3:
  movl 4(%esp), %eax
  addl $3, %eax
  ret</strong></pre>
<p>In the actual machine, i is never incremented or even instantiated, but the net effect is the same as if it had been.&nbsp; In general, this gap between the abstract and actual semantics is considered to be a good thing, and the “as if” wording in the standard is what gives the optimizer the freedom to generate efficient code from a high-level specification.</p>
<h2>What does volatile mean?</h2>
<p>The problem with the gap between the abstract and concrete semantics is that C is a low-level language that was designed for implementing operating systems.&nbsp; Writing OS code often requires that the gap between the abstract and actual semantics be narrowed or closed.&nbsp; For example, if an OS wants to create a new page table, the abstract semantics for C fails to capture an important fact: that the programmer requires an actual page table that sits in RAM where it can be traversed by hardware.&nbsp; If the C implementation concludes that the page table is useless and optimizes it away, the developers’ intent has not been served.&nbsp; The canonical example of this problem is when a compiler decides that a developer’s code for zeroing sensitive data is useless and optimizes it away.&nbsp; Since the C abstract machine was not designed to consider cases where this data may be snooped later, the optimization is legitimate (though obviously undesirable).</p>
<p>The C standard gives us just a few ways to establish a connection between the abstract and actual machines:</p>
<ul>
<li>the arguments to main()</li>
<li>the return value from main()</li>
<li>the side-effecting functions in the C standard library</li>
<li>volatile variables</li>
</ul>
<p>Most C implementations offer additional mechanisms, such as inline assembly and extra library functions not mandated by the standard.</p>
<p>The way the volatile connects the abstract and real semantics is this:</p>
<blockquote><p>For every read from a volatile variable by the abstract machine, the actual machine must load from the memory address corresponding to that variable.&nbsp; Also, each read may return a different value.&nbsp; For every write to a volatile variable by the abstract machine, the actual machine must store to the corresponding address.&nbsp; Otherwise, the address should not be accessed (with some exceptions) and also accesses to volatiles should not be reordered (with some exceptions).</p></blockquote>
<p>In summary:</p>
<ul>
<li>Volatile has no effect on the abstract machine; in fact, the C standard explicitly states that for a C implementation that closely mirrors the abstract machine (i.e. a simple C interpreter), volatile has no effect at all.</li>
<li>Accesses to volatile-qualified objects obligate the C implementation to perform certain operations at the level of the actual computation.</li>
</ul>
<h2>Where did volatile come from?</h2>
<p>Historically, the connection between the abstract and actual machines was established mainly through accident: compilers weren’t good enough at optimizing to create an important semantic gap.&nbsp; As optimizers improved, it became increasingly clear that a systematic solution was needed.&nbsp; In an <a href="http://groups.google.com/group/comp.std.c/msg/7709e4162620f2cd">excellent USENET post</a> 20 years ago Doug Gwyn explained how volatile came about:</p>
<blockquote><p>To take a specific example, UNIX device drivers are almost always coded entirely in C, and on the PDP-11 and similar memory-mapped I/O architectures, some device registers perform different actions upon a “read-byte”, “read-word”, “write-byte”, “write-word”, “read-modify-write”, or other variations of the memory-bus access cycles involved.&nbsp; Trying to get the right type of machine code generated while coding the driver in C was quite tricky, and many hard-to-track-down bugs resulted.&nbsp; With compilers other than Ritchie’s, enabling optimization often would change this behavior, too.&nbsp; At least one version of the UNIX Portable C Compiler (PCC) had a special hack to recognize constructs like</p>
<pre><strong>((struct xxx *)0177450)-&gt;zzz</strong></pre>
<p>as being potential references to I/O space (device registers) and would avoid excessive optimization involving such expressions (where the constant lay within the Unibus I/O address range).&nbsp; X3J11 decided that this problem had to be faced squarely, and introduced “volatile” to obviate the need for such hacks.&nbsp; However, although it was proposed that conforming implementations be required to implement the minimum possible access “width” for volatile-qualified data, and that is the intent of requiring an implementation definition for it, it was not practical to insist on it in every implementation; thus, some latitude was allowed implementors in that regard.</p></blockquote>
<p>It’s hard to overstate how bad an idea it is for a compiler to use strange heuristics about code structure to guess the developer’s intent.</p>
<h2>Nine ways to break your systems code using volatile</h2>
<h2>1. Not enough volatile</h2>
<p>The most obvious kind of volatile error is to leave it out when it is required.&nbsp; Let’s look at a specific example.&nbsp; Suppose we’re developing software for an AVR 8-bit embedded processor, which (on some models) has no hardware multiplier.&nbsp; Since multiplies are going to happen in software, we’re probably interested in seeing how slow they are, so we know how hard to try to avoid them.&nbsp; So we write a little benchmark program like this:</p>
<pre><strong>#define TCNT1 (*(uint16_t *)(0x4C))</strong></pre>
<pre><strong>signed char a, b, c;</strong></pre>
<pre><strong>uint16_t time_mul (void) {
  uint16_t first = TCNT1;
  c = a * b;
  uint16_t second = TCNT1;
  return second - first;
}</strong></pre>
<p>Here TCNT1 points to a hardware register living at address 0x4C.&nbsp; This register provides access to Timer/Counter 1: a free-running 16-bit timer that we assume is configured to run at some rate appropriate for this experiment.&nbsp; We read the register before and after the multiply operation, and subtract to find the duration.&nbsp; Side note: although at first glance this code looks like it fails to account for the case where TCNT1 overflows from 65535 to 0 during the timing run, it actually works properly for all durations between 0 and 65535 ticks.</p>
<p>Unfortunately, when we run this code, it always reports that the multiply operation required zero clock ticks.&nbsp; To see what went wrong, let us look at the assembly language:</p>
<pre><strong>$ avr-gcc -Os -S -o - reg1.c
time_mul:
  lds r22,a
  lds r24,b
  rcall __mulqi3
  sts c,r24
  ldi r24,lo8(0)
  ldi r25,hi8(0)
  ret</strong></pre>
<p>Now the problem is obvious: both reads from the TCNT1 register have been eliminated and the function is simply returning the constant zero (avr-gcc returns a 16-bit value in the r24:r25 register pair).</p>
<p>How can the compiler get away with never reading from TCNT1?&nbsp; First, let’s remember that the meaning of a C program is defined by the abstract machine described in the C standard.&nbsp; Since the rules for the abstract machine say nothing about hardware registers (or concurrent execution) the C implementation is permitted to assume that two reads from an object, with no intervening stores, both return the same value.&nbsp; Of course, any value subtracted from itself is zero.&nbsp; So the translation performed by avr-gcc here is perfectly correct; it is our program that’s wrong.</p>
<p>To fix the problem, we need to change the code so that TCNT1 points to a volatile location.</p>
<pre><strong>#define TCNT1 (*(volatile uint16_t *)(0x4C))</strong></pre>
<p>Now, the C implementation is not free to eliminate the reads and also it cannot assume the same value is read both times.&nbsp; This time the compiler outputs better code:</p>
<pre><strong>$ avr-gcc -Os -S -o - reg2.c
time_mul:
  in r18,0x2c
  in r19,0x2d
  lds r22,a
  lds r24,b
  rcall __mulqi3
  sts c,r24
  in r24,0x2c
  in r25,0x2d
  sub r24,r18
  sbc r25,r19
  ret</strong></pre>
<p>Although this assembly code is correct, our C code still contains a latent error.&nbsp; We’ll explore it later.</p>
<p>Normally, you will find definitions for device registers in system header files.&nbsp; If so, you will not need to use volatile in this case.&nbsp; But it may be worth checking that the definitions are correct, they aren’t always.</p>
<p>Let’s look at another example.&nbsp; In an embedded system you are implementing, some computation must wait for an interrupt handler to fire.&nbsp; Your code looks like this:</p>
<pre><strong>int done;</strong></pre>
<pre><strong>__attribute((signal)) void __vector_4 (void) {
  done = 1;
}</strong></pre>
<pre><strong>void wait_for_done (void) {
  while (!done) ;
}</strong></pre>
<p>Here wait_for_done() is designed to be called from the non-interrupt context, whereas __vector_4() will be invoked by the interrupt controller in response to some external event.&nbsp; We compile this code into assembly:</p>
<pre><strong>$ avr-gcc -Os wait.c -S -o -
__vector_4:
  push r0
  in r0,__SREG__
  push r0
  push r24
  ldi r24,lo8(1)
  sts done,r24
  pop r24
  pop r0
  out __SREG__,r0
  pop r0
  reti</strong></pre>
<pre><strong>wait_for_done:
  lds r24,done
.L3:
  tst r24
  breq .L3
  ret</strong></pre>
<p>The code for the interrupt handler looks good: it stores to done as intended.&nbsp; The rest of the interrupt handler is just AVR interrupt boilerplate.&nbsp; However, the code for wait_for_done() contains an important flaw: it is spinning on r24 instead of spinning on a RAM location.&nbsp; This happens because the C abstract machine has no notion of communication between concurrent flows (whether they are threads, interrupts, or anything else).&nbsp; Again, the translation is perfectly correct, but does not match the developer’s intent.</p>
<p>If we mark done as a volatile variable, the interrupt handler code does not change, but wait_for_done() now looks like this:</p>
<pre><strong>wait_for_done:
.L3:
  lds r24,done
  tst r24
  breq .L3
  ret</strong></pre>
<p>This code will work.&nbsp; The issue here is one of visibility.&nbsp; When you store to a global variable in C, what computations running on the machine are guaranteed to see the store?&nbsp; When you load from a global variable, what computations are assumed to have produced the value?&nbsp; In both cases, the answer is “the computation that performs the load or store is assumed to be the only computation that matters.”&nbsp; That is, C makes no visibility guarantees for normal variable references.&nbsp; The volatile qualifier forces stores to go to memory and loads to come from memory, giving us a way to ensure visibility across multiple computations (threads, interrupts, coroutines, or whatever).</p>
<p>Again, our C code contains a latent bug that we’ll investigate later.</p>
<p>A few other legitimate uses of volatile, including making variables in UNIX programs visible to signal handlers, are <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2016.html">discussed by Hans Boehm</a>.</p>
<p><strong>Summary: The abstract C machine is connected to the actual machine in only a few places.&nbsp; The memory behavior of the actual machine may be very different from the operations specified in source code.&nbsp; If you require additional connections between the two levels of abstraction, for example to access device registers, the volatile qualifier can help.</strong></p>
<h2>2. Too much volatile</h2>
<p>In a well-designed piece of software, volatile is used exactly where it is needed.&nbsp; It serves as documentation, saying in effect “this variable does not play by the C rules: it requires a strong connection with the memory subsystem.”&nbsp; In a system that uses too much volatile, variables will be indiscriminately labeled as volatile, without any technical justification.&nbsp; There are three reasons why this is bad.&nbsp; First, it’s bad documentation and will confuse subsequent maintainers.&nbsp; Second, volatile sometimes has the effect of hiding program bugs such as race conditions.&nbsp; If your code needs volatile and you don’t understand why, this is probably what is happening.&nbsp; Far better to actually fix the problem than to rely on a hack you do not understand to solve a problem you do not understand.&nbsp; Finally, volatile causes inefficiency by handicapping the optimizer.&nbsp; The overhead that it introduces is hard to track down since it is spread out all over the system– a profiler will be little help in finding it.</p>
<p>Using volatile is a little like deciding what kind of insurance policy to buy.&nbsp; Too little insurance and you may run into problems down the road.&nbsp; Too much insurance and you’re covered but in the long run you end up paying too much.</p>
<p><strong>Summary: Use volatile only when you can provide a precise technical justification.&nbsp; Volatile is not a substitute for thought (<a href="http://www.netrino.com/Embedded-Systems/How-To/C-Volatile-Keyword">Nigel Jones said this</a>).<br>
</strong></p>
<h2>3. Misplaced qualification</h2>
<p>At the level of C syntax, volatile is a type qualifier.&nbsp; It can be applied to any type, following rules that are similar to, but not quite the same as, the rules for the const qualifier.&nbsp; The situation can become confusing when qualified types are used to build up more complex types.&nbsp; For example, there are four possible ways to qualify a single-level pointer:</p>
<pre><strong>int *p;                              // pointer to int
volatile int *p_to_vol;              // pointer to volatile int
int *volatile vol_p;                 // volatile pointer to int
volatile int *volatile vol_p_to_vol; // volatile pointer to volatile int</strong></pre>
<p>In each case, either the pointer is volatile or not, and the pointer target is volatile or not.&nbsp; The distinction is crucial: if you use a “volatile pointer to regular int” to access a device register, the compiler is free to optimize away accesses to the register.&nbsp; Also, you will get slow code since the compiler will not be free to optimize accesses to the pointer.&nbsp; This problem comes up pretty often on embedded mailing lists; it’s an easy mistake to make.&nbsp; It’s also easy to overlook when vetting code since your eye may just be looking for a volatile somewhere.</p>
<p>For example, this code is wrong:</p>
<pre><strong>int *volatile REGISTER = 0xfeed;
*REGISTER = new_val;</strong></pre>
<p>To write clear, maintainable code using volatile, a reasonable idea is to build up more complex types using typedefs (of course this is a good idea anyway).&nbsp; For example we could first make a new type “vint” which is a volatile int:</p>
<pre><strong>typedef volatile int vint;</strong></pre>
<p>Next, we create a pointer-to-vint:</p>
<pre><strong>vint *REGISTER = 0xfeed;</strong></pre>
<p>Members of a struct or union can be volatile, and structs/unions can also be volatile.&nbsp; If an aggregate type is volatile, the effect is the same as making all members volatile.</p>
<p>We might ask, does it make sense to declare an object as both const and volatile?</p>
<pre><strong>const volatile int *p;</strong></pre>
<p>Although this initially looks like a contradiction, it is not.&nbsp; The semantics of const in C are “I agree not to try to store to it” rather than “it does not change.”&nbsp; So in fact this qualification is perfectly meaningful and would even be useful, for example, to declare a timer register than spontaneously changes value, but that should not be stored to (this example is specifically pointed out in the C standard).</p>
<p><strong>Summary: Since C’s type declaration syntax is not particularly readable or intuitive, volatile qualifiers must be placed with care.&nbsp; Typedefs are a useful way to structure complex declarations.</strong></p>
<h2>4. Inconsistent qualification</h2>
<p>The last version of Linux 2.2 was 2.2.26.&nbsp; In that version, in the file arch/i386/kernel/smp.c at line 125, we find this definition:</p>
<pre><strong>volatile unsigned long ipi_count;</strong></pre>
<p>So far, no problem: we’re declaring a long to store the number of inter-processor interrupts and making it volatile.&nbsp; However, in the header file include/asm-i386/smp.h at line 178 we find this definition:</p>
<pre><strong>extern unsigned long ipi_count;</strong></pre>
<p>C files that include this header will not treat ipi_count as volatile, and this could easily cause problems.&nbsp; Kernels in the 2.3 series also contain this error.</p>
<p>Recent versions of gcc treat this kind of inconsistent qualification as a compile-time error, so these problems have disappeared.&nbsp; However, it’s a good bet that some embedded compilers (obviously including those based on older versions of gcc) will permit you to make this mistake.</p>
<p>Another way to get inconsistent qualification is through typecasts.&nbsp; Casts can be implicit, for example passing a pointer-to-volatile to a function expecting an unqualified pointer.&nbsp; The compiler will warn about this; these warnings should never be ignored or suppressed.&nbsp; Explicit typecasts that remove qualifiers should be avoided, these generally do not cause any warnings.&nbsp; The C standard explicitly states that a program’s behavior is undefined if you access a volatile object through an unqualified pointer.</p>
<p><strong>Summary: Never use inconsistent qualification.&nbsp; If a variable is declared as volatile, then all accesses to it, direct or indirect, must be through volatiles and pointers-to-volatile.<br>
</strong></p>
<h2>5. Expecting volatile to enforce ordering with non-volatile accesses</h2>
<p>Next we come to an issue that even some experts in embedded software development get wrong, and that even experts in C language semantics have arguments about.</p>
<p>The question is: What was wrong with the fixed C code examples above, where we added volatile to the TCNT1 register handle and to the done flag?&nbsp; The answer, depending on who you believe, is either “nothing” or else “the compiler may reorder the operations in such a way as to create broken output.”</p>
<p>One school of thought is that compilers may not move accesses to global variables around accesses to volatile variables.&nbsp; There seems to be a consistent reading of the standard that backs this up.&nbsp; The problem with this reading is that important compilers are based on a different interpretation, which says that accesses to non-volatile objects can be arbitrarily moved around volatile accesses.</p>
<p>Take this simple example (which originated with Arch Robison):</p>
<pre><strong>volatile int ready;
int message[100];</strong></pre>
<pre><strong>void foo (int i) {
  message[i/10] = 42;
  ready = 1;
}</strong></pre>
<p>The purpose of foo() is to store a value into the message array and then set the ready flag so that another interrupt or thread can see the value.&nbsp; From this code, GCC, Intel CC, Sun CC, and Open64 emit very similar assembly:</p>
<pre><strong>$ gcc -O2 barrier1.c -S -o -
foo:
  movl 4(%esp), %ecx
  movl $1717986919, %edx
  movl $1, ready
  movl %ecx, %eax
  imull %edx
  sarl $31, %ecx
  sarl $2, %edx
  subl %ecx, %edx
  movl $42, message(,%edx,4)
  ret</strong></pre>
<p>Obviously the programmer’s intent is not respected here, since the flag is stored prior to the value being written into the array.&nbsp; As of this writing LLVM does not do this reordering but, as far as I know, this is a matter of chance rather than design.&nbsp; A number of embedded compilers refuse to do this kind of reordering as a deliberate choice to prefer safety over performance.&nbsp; I’ve heard, but not checked, that recent Microsoft C/C++ compilers also take a very conservative stance on volatile accesses.&nbsp; This is probably the right choice, but it doesn’t help people who have to write portable code.</p>
<p>One way to fix this problem is to declare message as a volatile array.&nbsp; The C standard is unambiguous that volatile side effects must not move past sequence points, so this will work.&nbsp; On the other hand, adding more volatile qualifiers may suppress interesting optimizations elsewhere in the program.&nbsp; Wouldn’t it be nice if we could force data to memory only at selected program points without making things volatile everywhere?</p>
<p>The construct that we need is a “compiler barrier.”&nbsp; The C standard does not provide this, but many compilers do.&nbsp; For example, GCC and sufficiently compatible compilers (including LLVM and Intel CC) support a memory barrier that looks like this:</p>
<pre><strong>asm volatile ("" : : : "memory");</strong></pre>
<p>It means roughly “this inline assembly code, although it contains no instructions, may read or write all of RAM.”&nbsp; The effect is that the compiler dumps all registers to RAM before the barrier and reloads them afterwards.&nbsp; Moreover, code motion is not permitted around the barrier in either direction.&nbsp; Basically a compiler barrier is to an optimizing compiler as a memory barrier is to an out-of-order processor.</p>
<p>We can use a barrier in the code example:</p>
<pre><strong>volatile int ready;
int message[100];</strong></pre>
<pre><strong>void foo (int i) {
  message[i/10] = 42;
  asm volatile ("" : : : "memory");
  ready = 1;
}</strong></pre>
<p>Now the output is what we wanted:</p>
<pre><strong>$ gcc -O2 barrier2.c -S -o -
foo:
  movl 4(%esp), %ecx
  movl $1717986919, %edx
  movl %ecx, %eax
  imull %edx
  sarl $31, %ecx
  sarl $2, %edx
  subl %ecx, %edx
  movl $42, message(,%edx,4)
  movl $1, ready
  ret</strong></pre>
<p>What about compilers that fail to support memory barriers?&nbsp; One bad solution is to hope that this kind of compiler isn’t aggressive enough to move accesses around in a harmful way.&nbsp; Another bad solution is to insert a call to an external function where you would put the barrier.&nbsp; Since the compiler doesn’t know what memory will be touched by this function, it may have a barrier-like effect.&nbsp; A better solution would be to ask your compiler vendor to fix the problem and also to recommend a workaround in the meantime.</p>
<p><strong>Summary: Most compilers can and will move accesses to non-volatile objects around accesses to volatile objects, so don’t rely on the program ordering being respected.</strong></p>
<h2>6. Using volatile to get atomicity</h2>
<p>Earlier we saw a case where volatile was used to make a value visible to a concurrently running computation.&nbsp; This was — in limited circumstances — a valid implementation choice.&nbsp; On the other hand it is never valid to use volatile to get atomicity.</p>
<p>Somewhat surprisingly for a systems programming language, C does not provide guarantees about atomicity of its memory operations, regardless of the volatility of objects being accessed.&nbsp; Generally, however, individual compilers will make guarantees such as “aligned accesses to word-sized variables are atomic.”</p>
<p>In most cases, you use locks to get atomicity.&nbsp; If you’re lucky, you have access to well-designed locks that contain compiler barriers.&nbsp; If you’re programming on bare metal on an embedded processor, you may not be so lucky.&nbsp; If you have to devise your own locks, it would be wise to add compiler barriers.&nbsp; For example, older versions of <a href="http://tinyos.net/">TinyOS</a> for AVR chips used these functions to acquire and release the global interrupt lock:</p>
<pre><strong>char __nesc_atomic_start (void) {
  char result = SREG;
  __nesc_disable_interrupt();
  return result;
}</strong></pre>
<pre><strong>void __nesc_atomic_end (char save) {
  SREG = save;
}</strong></pre>
<p>Since these functions can be (and generally are) inlined, it was always possible for the compiler to move code outside of a critical section.&nbsp; We changed the locks to look like this:</p>
<pre><strong>char__nesc_atomic_start(void) {
  char result = SREG;
  __nesc_disable_interrupt();
  asm volatile("" : : : "memory");
  return result;
}</strong></pre>
<pre><strong>void __nesc_atomic_end(char save) {
  asm volatile("" : : : "memory");
  SREG = save;
}</strong></pre>
<p>Perhaps interestingly, this had no effect on TinyOS efficiency and even made the code smaller in some cases.</p>
<p><strong>Summary: Volatile has nothing to do with atomicity.&nbsp; Use locks.</strong></p>
<h2>7. Using volatile on a modern machine</h2>
<p>Volatile is of very limited usefulness on a machine that is out-of-order, multiprocessor, or both.&nbsp; The problem is that while volatile forces the compiler to emit memory operations on the actual machine, these loads and stores by themselves do not constrain the hardware’s behavior very much.&nbsp; It is vastly preferable to find good locking primitives and use them, as opposed to rolling them yourself.&nbsp; Consider this spin-unlock function from the ARM port of Linux:</p>
<pre><strong>static inline void arch_spin_unlock(arch_spinlock_t *lock) {
  smp_mb();
  __asm__ __volatile__("str %1, [%0]\n" : : "r" (&amp;lock-&gt;lock), "r" (0) : "cc");
}</strong></pre>
<p>Before unlocking, smp_mb() is executed, which boils down to something like this:</p>
<pre><strong>__asm__ __volatile__ ("dmb" : : : "memory");</strong></pre>
<p>This is both a compiler barrier and a memory barrier.</p>
<p><strong>Summary: Without help from properly designed synchronization libraries, writing correct concurrent code on an out-of-order machine or multiprocessor is extremely hard, and volatile is of little help.</strong></p>
<h2>8. Using volatile in multi-threaded code</h2>
<p>This issue overlaps with the previous two but it’s important enough to be worth repeating.&nbsp; Arch Robison says that <a href="http://software.intel.com/en-us/blogs/2007/11/30/volatile-almost-useless-for-multi-threaded-programming/">volatile is almost useless for multi-threaded programming</a>.&nbsp; And he’s right.&nbsp; If you have threads then you should also have locks, and should use them.&nbsp; There’s a wonderful result showing that properly synchronized code — where shared variables are always accessed from within critical sections — executes in a sequentially consistent fashion (provided that the locks are properly implemented, and you shouldn’t have to worry about that).&nbsp; This means that if you use locks, you don’t have to worry about compiler barriers, memory system barriers, or volatile.&nbsp; None of it matters.</p>
<p><strong>Summary: To write correct multi-threaded code, you need primitives providing (at least) atomicity and visibility.&nbsp; On modern hardware volatile provides neither.&nbsp; You should write properly synchronized multi-threaded code whenever possible.&nbsp; Idioms like double-checked locking are best avoided.</strong></p>
<h2>9. Assume volatile accesses are translated correctly</h2>
<p>Compilers are not totally reliable in their translation of accesses to volatile-qualified objects.&nbsp; I’ve <a href="http://www.cs.utah.edu/~regehr/papers/emsoft08-preprint.pdf">written extensively about this subject elsewhere</a>, but here’s a quick example:</p>
<pre><strong>volatile int x;</strong></pre>
<pre><strong>void foo (void) {
  x = x;
}</strong></pre>
<p>The proper behavior of this code on the actual machine is unambiguous: there should be a load from x, then a store to it.&nbsp; However, the port of GCC to the MSP430 processor behaves differently:</p>
<pre><strong>$ msp430-gcc -O vol.c -S -o -
foo:
  ret</strong></pre>
<p>The emitted function is a nop.&nbsp; It is wrong.&nbsp; In general, compilers based on gcc 4.x are mostly volatile-correct, as are recent versions of LLVM and Intel CC.&nbsp; Pre-4.0 versions of gcc have problems, as do a number of other compilers.</p>
<p><strong>Summary: If your code makes correct use of volatiles and still does not work, consider reading the compiler’s output to make sure it has emitted the proper memory operations.</strong></p>
<h2>What about the Linux people?</h2>
<p>You can find various rants, screeds, and diatribes against volatile on Linux mailing lists and web pages.&nbsp; These are largely correct, but you have to keep in mind that:</p>
<ol>
<li>Linux often runs on out-of-order multicores where volatile by itself is nearly useless.</li>
<li>The Linux kernel provides a rich collection of functions for synchronization and hardware access that, properly used, eliminate almost all need for volatile in regular kernel code.</li>
</ol>
<p>If you are writing code for an in-order embedded processor and have little or no infrastructure besides the C compiler, you may need to lean more heavily on volatile.</p>
<h2>Summary</h2>
<p>Optimizing compilers are tricky to reason about, as are out-of-order processors.&nbsp; Also, the C standard contains some very dark corners.&nbsp; The volatile qualifier invites all of these difficulties to come together in one place and interact with one another.&nbsp; Furthermore, it provides weaker guarantees than people commonly assume.&nbsp; Careful thought is required to create correct software using volatile.</p>
<p>Happily, most programmers who write user-mode C and C++ can get away without ever using volatile.&nbsp; Also, the vast majority of kernel mode programmers will seldom if ever need volatile.&nbsp; It is primarily needed by people working near bare metal; for example, working on an embedded microcontroller or porting an OS to a new platform.</p>
<h2>Credentials</h2>
<p>I’ve been programming computers for 26 years and embedded systems for 17 years.&nbsp; For the last eight years I’ve taught operating systems, embedded systems, compilers, and related courses to undergrads and graduate students.&nbsp; I’ve tried to educate them about volatile and have a pretty good idea about where people go wrong with it.</p>
<p>In February 2010 I gave some lectures at RWTH Aachen, including about an hour on getting the volatile qualifier wrong.&nbsp; This post expands on that material.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Play Leisure Suit Larry free in DOS running in browser (124 pts)]]></title>
            <link>https://www.retrogames.cz/play_493-DOS.php</link>
            <guid>37785680</guid>
            <pubDate>Thu, 05 Oct 2023 23:50:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.retrogames.cz/play_493-DOS.php">https://www.retrogames.cz/play_493-DOS.php</a>, See on <a href="https://news.ycombinator.com/item?id=37785680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <td>
      
      
<!-- ﻿﻿


                 -->








	


	

	

	
	

	
 
	

	
	

  
      	

	
<!-- -->


  
      </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>
      <table bordercolor="#111111" id="AutoNumber4">
        <tbody><tr>
          <td colspan="2">
          &nbsp;</td>
        </tr>
        <tr>
          <td colspan="2">
          
          </td>
        </tr>
        <tr>
          <td>


	<!-- ﻿﻿-->



<br>





<!-- -->

	  
	  </td>
          <td>
            
		<!-- ﻿-->				

	<table bordercolor="#FFFFFF" id="AutoNumber10">
              <tbody><tr>
                <td>
                <span face="Arial Black" color="#FFFF00">Control:</span></td>
              </tr>
              <tr>
                <td>
                <p><b>
		<span face="Arial" size="2" color="#FFFFFF">Game is con­trol­led by the same keys that are used to playing un­der MS DOS. For full­screen press 'Right Alt' + 'En­ter'.		</span></b></p></td>
              </tr>
         </tbody></table>

<!-- -->

			<br>
            
		<!-- ﻿-->				

	<table bordercolor="#FFFFFF" id="AutoNumber10">
              <tbody><tr>
                <td>
                <span face="Arial Black" color="#FFFF00">Help:</span></td>
              </tr>
              <tr>
                <td>
                <p><b>
		<span face="Arial" size="2" color="#FFFFFF">If the game e­mu­la­ti­on spe­ed is low, you can try to in­cre­a­se it by <a href="https://www.retrogames.cz/play_493-DOS.php?Ads=No"><span face="Arial" size="2" color="#FFFF00"><b>re­lo­a­ding</b></span></a> this pa­ge with­out a­ds or cho­o­se a­no­ther e­mu­la­tor from this <a href="#emulatory"><span face="Arial" size="2" color="#FFFF00"><b>table</b></span></a>.</span></b></p></td>
              </tr>
         </tbody></table>

<!-- -->

          </td>
        </tr>
        <tr>
          <td colspan="2">
		
  	  </td>
        </tr>
      	</tbody></table>
		
	
      <br>

      
      <table>
		<tbody><tr>
			<td>
            

            

          	</td>
			<td>

            <!-- ﻿-->

<table bordercolor="#FFFFFF" id="AutoNumber7">
     <tbody><tr>
          <td>
          <span face="Arial Black" color="#FFFF00">Other platforms:</span>
	  </td>
      </tr>
      <tr>
           <td>
           <p><b><span face="Arial" size="2" color="#FFFFFF">

	   	   	Unfortunately, this game is cur­rent­ly available only in this ver­si­on. Be patient :-)		
	   </span></b></p>
	   </td>
       </tr>
</tbody></table>

<!-- -->

          	</td>
		</tr>

</tbody></table>	


	<!-- ﻿-->


	<p>

	﻿﻿


<!-- Široký baner 728x90 -->
<ins data-ad-client="ca-pub-9073967042072978" data-ad-slot="4751212619"></ins>


				

<!-- -->


	<br>

	<!-- ﻿-->
	﻿﻿﻿         
  
	<table bordercolor="#FFFFFF" id="AutoNumber9">
              <tbody><tr>
                <td>
                <span face="Arial Black" color="#FFFF00">Game info:</span></td>
              </tr>
              <tr>
                <td>
                
                                                
                <table>
					<tbody><tr>
						<td rowspan="9">
						<img src="https://www.retrogames.cz/games/493/obal_DOS.gif" width="120" height="155" alt="Leisure Suit Larry 1 - box cover" onmouseover="showtrail('games/493/obal_DOS_big.jpg', 'Cover art of Leisure Suit Larry 1 (DOS)',393,500)" onmouseout="hidetrail()">
						<br>
						<center><span face="Arial" size="2" color="#C0C0C0">box cover</span></center>
						</td>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Game title:</span></td>
						<td colspan="3">
						<b><span face="Arial" color="#FFFFFF" size="2">Leisure Suit Larry 1</span></b></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Platform:</span></td>
						<td colspan="3">
						<b><span face="Arial" color="#FFFFFF" size="2">MS-DOS</span></b></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Author (released):</span></td>
						<td colspan="3">
						<b><span face="Arial" size="2" color="#FFFFFF">Sierra On-Line (1987)</span></b></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Genre:</span></td>
						<td>
						<span face="Arial" color="#FFFFFF" size="2"><b>Adventure, Adult</b></span></td>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Mode:</span></td>
						<td>
						<span face="Arial" color="#FFFFFF" size="2"><b>Single-player</b></span></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Design:</span></td>
						<td colspan="3">
						<b><span face="Arial" size="2" color="#FFFFFF">Al Lowe, Mark Crowe, Ken Williams, Chris Benton</span></b></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Music:</span></td>
						<td colspan="3">
						<b><span face="Arial" size="2" color="#FFFFFF">Al Lowe</span></b></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Game manual:</span></td>
						<td>
						<a href="https://www.retrogames.cz/download_DOS_manual.php?id=493" onclick="window.open('download_DOS_manual.php?id=493','_blank','width=530,height=515,top=0,left=0,menubar=yes,scrollbars=yes,toolbar=yes,location=yes,directions=yes,resizable=yes,navigation=yes,status=yes'); return false"><b><span face="Arial" size="2" color="#FFFF00">manual.pdf</span></b></a>
								
													

						</td>
												<td>
						<p>
						<span face="Arial" size="2" color="#C0C0C0">File size:</span></p></td>
						<td>
						<b><span face="Arial" size="2" color="#FFFFFF">1113 kB</span></b></td>
							
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Download:</span></td>
						<td>
						
													<span face="Arial" color="#FFFFFF" size="2"><b>
							not available (stream only)							</b></span>
								
						</td>
						<td>
						<p>
						<span face="Arial" size="2" color="#C0C0C0">Game size:</span></p></td>
						<td>
						<b><span face="Arial" size="2" color="#FFFFFF">272 kB</span></b></td>
					</tr>
					<tr>
						<td>
						<span face="Arial" size="2" color="#C0C0C0">Recommended emulator:</span></td>
						<td colspan="3">
						<b><span face="Arial" size="2" color="#FFFFFF">
						<a href="https://www.retrogames.cz/offline.php">DOSBox</a></span></b></td>
					</tr>
					<tr><td colspan="5">
						<hr></td></tr>

											<tr><td colspan="5">
							<b><span face="Arial" size="2" color="#FFFFFF">From Wikipedia, the free encyclopedia:</span></b>
						</td></tr>
						<tr><td colspan="5">
							<p><span face="Arial" size="2" color="#C0C0C0">&nbsp;&nbsp;&nbsp;Leisure Suit Larry in the Land of the Lounge Lizards is a graphic adventure game originally released in 1987 as the first part of the Leisure Suit Larry series. Originally developed for the PC DOS and the Apple II, it was later ported to other platforms such as the Amiga, Atari ST, Apple IIGS, Apple Macintosh and the TRS-80 Color Computer. It utilizes the Adventure Game Interpreter (AGI) engine made famous by <a href="https://www.retrogames.cz/play_118-DOS.php"><span color="#FFFF00">King's Quest: Quest for the Crown</span></a>.
<br>
&nbsp;&nbsp;&nbsp;The game's story follows a middle-aged male virgin named Larry Laffer as he desperately tries to 'get lucky' in the fictional American city of Lost Wages. Land of the Lounge Lizards establishes several elements which recur in the later Larry games, including Larry's campy attire, perpetual bad luck with women, and penchant for double-entendres. 
<table>
	<tbody><tr>
		<td><span face="Arial" size="2" color="#FFFFFF">
		<img src="https://www.retrogames.cz/games/493/DOS_02.gif" width="320" height="200" alt="Leisure Suit Larry - DOS version" title="Leisure Suit Larry - DOS version"></span></td>
	</tr>
	<tr>
		<td>
		<span face="Arial" size="2" color="#808080">Leisure Suit Larry - DOS version</span></td>
	</tr>
</tbody></table>
The story and basic structure of the game are lifted from <a href="https://www.retrogames.cz/play_1113-DOS.php"><span color="#FFFF00">Softporn Adventure</span></a>, a 1981 Apple II text adventure.
<br>
&nbsp;&nbsp;&nbsp;Despite a lack of advertising, the game was a sleeper hit and a commercial and critical success. Sierra developed and published a remake that used the Sierra's Creative Interpreter (SCI) engine with 256 colors and a point-and-click, icon-driven (as opposed to text-based) user interface, released for the PC DOS, Apple Macintosh and Amiga in 1991. A second, high-definition remake/reboot, titled Leisure Suit Larry: Reloaded, was developed by N-Fusion Interactive working with series' creator Al Lowe and published by Replay Games in 2013.
<br>
&nbsp;&nbsp;&nbsp;Larry Laffer is a 38-year-old (40-year-old in the 1991 remake) 'loser' who lives in his mother's basement and has not yet lost his virginity. Having grown weary of his lonely existence, he decides to visit the resort city of Lost Wages (a parody of 'Las Vegas') hoping to experience what he has not lived before, and to finally find the woman of his dreams. Larry starts with nothing but an out-of-style 1970s disco-era leisure suit and $94 in his pocket. His quest involves four possible women: a nameless, seedy-looking sex worker; Fawn, a club-goer of low moral fiber; Faith, a receptionist who (true to her name) is faithful to her boyfriend; and Eve, a bathing beauty and Larry's ultimate goal.
<br>
&nbsp;&nbsp;&nbsp;The game begins outside a bar in Lost Wages. Players are given seven real-time hours (eight in the 1991 remake) to complete the game, at which point a despairing Larry commits suicide, resulting in game over. Players control Larry's movements with the directional keys and by inputing commands into a text parser (e.g. 'talk to man', 'open window', etc.). If Larry is too far away from a person or object to comply, or if the command is invalid, a caution message appears with hints on what to do.
<br>
&nbsp;&nbsp;&nbsp;The city consists of five areas: Lefty's Bar, a hotel casino, a 24-hour wedding chapel, a discothèque, and a convenience store. The player can walk between areas that are next to each other, but other areas can only be accessed by hailing a taxi, which costs the player money; failure to do so results in Larry being mugged or hit by oncoming traffic. During the early stages of the game, Larry can survive most premature deaths. In the original release, a compartment opens beneath Larry's body and takes him to a laboratory where heroes from Sierra's computer games—such as <a href="https://www.retrogames.cz/play_118-DOS.php"><span color="#FFFF00">King's Quest</span></a>—are re-assembled; in the remake, Larry's remains are instead thrown inside a blender and reformed.
<br>
&nbsp;&nbsp;&nbsp;A prostitute is available as soon as the game starts. Should Larry have intercourse with her, he will contract a sexually-transmitted disease and die shortly thereafter. This fate may be avoided by buying a condom at the convenience store. Larry questions the validity of losing his virginity to a prostitute, but the game resumes without a time limit.
<br>
&nbsp;&nbsp;&nbsp;Larry's interactions with key women are accompanied by a detailed image of whomever he is speaking with, unlike other non-player characters. With the exception of the prostitute, each of the women shun Larry at first, but respond favorably to gifts of varying sorts. Although it is not possible to woo all of the women, giving gifts is needed to advance to the game's final area, the hotel penthouse. To this end, money is essential to advance through the game. The only available method of augmenting Larry's funds is to gamble in the casino, playing blackjack and slots.</span></p>
							<p><span face="Arial" size="2" color="#C0C0C0">More details about this game can be found on <b><a target="_blank" href="http://en.wikipedia.org/wiki/Leisure_Suit_Larry_in_the_Land_of_the_Lounge_Lizards">
							<span face="Arial" size="2" color="#FFFF00">Wikipedia.org</span></a></b>.</span></p>
						</td></tr>
						
										

<!-- *************** začátek kódu PRO SBĚRATELE ************************* -->

					<tr><td colspan="5">
						<b><span face="Arial" size="2" color="#FFFFFF">For fans and collectors:</span></b>
					</td></tr>
					<tr><td colspan="5">
						<span face="Arial" size="2" color="#C0C0C0">
						Find this game on video server </span>
						<b><a target="_blank" href="http://www.youtube.com/results?search_query=Leisure%20Suit%20Larry%201%20DOS" rel="nofollow">
						<span face="Arial" size="2" color="#FFFF00">YouTube.com </span></a></b>
						<span face="Arial" size="2" color="#C0C0C0"> or </span>
						<b><a target="_blank" href="https://vimeo.com/search?q=Leisure%20Suit%20Larry%201" rel="nofollow">
						<span face="Arial" size="2" color="#FFFF00">Vimeo.com</span></a></b><span face="Arial" size="2" color="#FFFFFF">.</span>
					</td></tr>
					<tr><td colspan="5">
						<span face="Arial" size="2" color="#C0C0C0">
						Buy original version of this game on </span>
						<b><a target="_blank" href="http://www.amazon.com/s/ref=as_li_ss_tl?_encoding=UTF8&amp;camp=1789&amp;creative=390957&amp;field-keywords=Leisure%20Suit%20Larry%201%20DOS&amp;linkCode=ur2&amp;tag=retrogamescz-20&amp;url=search-alias%3Dvideogames" rel="nofollow">
						<span face="Arial" size="2" color="#FFFF00">Amazon.com</span></a></b>
						<span face="Arial" size="2" color="#C0C0C0"> or </span>
						<b><a target="_blank" href="https://www.ebay.com/sch/i.html?_nkw=Leisure%20Suit%20Larry%201%20PC%20DOS" rel="nofollow">
						<span face="Arial" size="2" color="#FFFF00">eBay.com</span></a></b><span face="Arial" size="2" color="#FFFFFF">.</span>
					</td></tr>
					<tr><td colspan="5">
						<p>
						<span face="Arial" size="2" color="#C0C0C0">Find digital download of this game on </span>
						<b><a target="_blank" href="https://www.gog.com/en/games?query=Leisure%20Suit%20Larry%201" rel="nofollow">
						<span face="Arial" size="2" color="#FFFF00">GOG</span></a></b>
						<span face="Arial" size="2" color="#C0C0C0">or</span>
						<span face="Arial" color="#FFFFFF" size="2"><b><a target="_blank" href="https://store.steampowered.com/search/?term=Leisure%20Suit%20Larry%201" rel="nofollow">
						<span face="Arial" size="2" color="#FFFF00">Steam</span></a></b><span face="Arial" size="2" color="#FFFFFF">.</span>
					</span></p></td></tr>

<!-- *************** konec kódu PRO SBĚRATELE ************************* -->

<!-- *************** začátek kódu OVLÁDÁNÍ ************************* -->

		

<!-- *************** konec kódu OVLÁDÁNÍ ************************* -->

<!-- *************** začátek kódu HERNÍ KONZOLE ************************* -->

					<tr>
						<td colspan="5">
						&nbsp;</td>
					</tr>
					<tr>
						<td colspan="5">
						<b><span face="Arial" size="2" color="#FFFFFF">Platform:</span></b></td>
					</tr>
					<tr>
						<td colspan="5">
						<p>
						<span face="Arial" size="2" color="#C0C0C0">
						<img src="https://www.retrogames.cz/grafika/konzole/PC-DOS_mini.png" width="120" height="115" onmouseover="showtrail('grafika/konzole/PC-DOS_big.png', 'Personal computer with operating system MS-DOS',524,500)" onmouseout="hidetrail()">
						This ver­sion of Leisure Suit Larry 1 was de­sig­ned for per­so­nal com­pu­ters with o­pe­ra­ting sys­tem MS-DOS (Mi­cro­soft Disk O­pe­ra­ting Sys­tem), 
						which was o­pe­ra­ting sys­tem de­ve­lo­ped by Mi­cro­soft in 1981. It was the most wi­de­ly-used o­pe­ra­ting sys­tem in the first half of the 1990s. MS-DOS was&nbsp;sup­plied 
						with most of the IBM com­pu­ters that pur­cha­sed a li­cen­se from Mi­cro­soft. Af­ter 1995, it was pu­s­hed out by a gra­phi­cal­ly mo­re ad­van­ced sys­tem - Win­dows and
						its de­ve­lop­ment was ce­a­sed in 2000. At the 
						ti­me of its grea­test fa­me, se­ve­ral thou­sand ga­mes de­sig­ned spe­ci­fi­cal­ly for com­pu­ters with this sys­tem we­re cre­a­ted. To­day, its de­ve­lop­ment is no lon­ger con­ti­nue 
						and for e­mu­la­tion the free DOSBox e­mu­la­tor is most of­ten used. Mo­re in­for­ma­ti­on about MS-DOS operating system can be found 
						<a href="https://en.wikipedia.org/wiki/MS-DOS" target="_blank"><span face="Arial" size="2" color="#FFFF00">here</span></a>.					</span></p></td>
					</tr>

<!-- *************** konec kódu HERNÍ KONZOLE ************************* -->

<!-- *************** začátek kódu DOSTUPNÉ EMULÁTORY ************************* -->

					<tr>
						<td colspan="5">
						<a name="emulatory"></a>&nbsp;</td>
					</tr>
					<tr>
						<td colspan="5">
						<b><span face="Arial" size="2" color="#FFFFFF">Available online emulators:</span></b></td>
					</tr>
					<tr>
						<td colspan="5">
						<p>
						<span face="Arial" size="2" color="#C0C0C0">
						5 different online emulators are available for Leisure Suit Larry 1. These emulators differ not only in the technology they use to emulate old games, but also in 								support of various game controllers, multiplayer mode, mobile phone touchscreen, emulation speed, absence or presence of embedded ads and in many other parameters. For 
						maximum gaming enjoyment, it's important to choose the right emulator, because on each PC and in different Internet browsers, the individual emulators behave differently. The basic 
						features of each emulator available for this game Leisure Suit Larry 1 are summarized in the following table:						
						<br>&nbsp;</span>
						</p></td>
					</tr>
					<tr><td colspan="5">
						<table>
							<tbody><tr>
								<td>
								<b><span face="Arial" size="2" color="#FFFFFF">Emulator</span></b>
								</td>
								<td>
								<b><span face="Arial" size="2" color="#FFFFFF">Technology</span></b>
								</td>
								<td>
								<b><span face="Arial" size="2" color="#FFFFFF">Multiplayer</span></b>
								</td>
								<td>
								<b><span face="Arial" size="2" color="#FFFFFF">Fullscreen</span></b>
								</td>
								<td>
								<b><span face="Arial" size="2" color="#FFFFFF">Touchscreen</span></b>
								</td>
								<td>
								<b><span face="Arial" size="2" color="#FFFFFF">Speed</span></b>
								</td>
							</tr>
							<tr>
								<td>
								<b><a href="https://www.retrogames.cz/play_493-DOS.php?emulator=archive">
								<span face="Arial" size="2" color="#FFFF00">Archive.org</span></a></b>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">JavaScript</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">fast</span>
								</td>
							</tr>
							<tr>
								<td>
								<b><a href="https://www.retrogames.cz/play_493-DOS.php?emulator=jsdos">
								<span face="Arial" size="2" color="#FF0000">js-dos</span></a></b>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">JavaScript</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">fast</span>
								</td>
							</tr>
							<tr>
								<td>
								<b><a href="https://www.retrogames.cz/play_493-DOS.php?emulator=jsdos622">
								<span face="Arial" size="2" color="#FFFF00">js-dos 6.22</span></a></b>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">JavaScript</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">fast</span>
								</td>
							</tr>
							<tr>
								<td>
								<b><a href="https://www.retrogames.cz/play_493-DOS.php?emulator=jsdosbox">
								<span face="Arial" size="2" color="#FFFF00">jsDosBox</span></a></b>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">JavaScript</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">slow</span>
								</td>
							</tr>
							<tr>
								<td>
								<b><a href="https://www.retrogames.cz/play_493-DOS.php?emulator=java">
								<span face="Arial" size="2" color="#FFFF00">jDosBox</span></a></b>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">Java applet</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">YES</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">NO</span>
								</td>
								<td>
								<span face="Arial" size="2" color="#C0C0C0">fast</span>
								</td>
							</tr>
						</tbody></table>
						</td></tr>

<!-- *************** konec kódu DOSTUPNÉ EMULÁTORY ************************* -->

					</tbody></table>
                
                                                
                </td>
              </tr>
            </tbody></table>


<!-- -->

	<!-- ﻿-->


	</p></td>
      <td>&nbsp;</td>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 2 Everywhere (L2E): Standalone, Binary Portable, Bootable Llama 2 (206 pts)]]></title>
            <link>https://github.com/trholding/llama2.c</link>
            <guid>37785442</guid>
            <pubDate>Thu, 05 Oct 2023 23:18:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trholding/llama2.c">https://github.com/trholding/llama2.c</a>, See on <a href="https://news.ycombinator.com/item?id=37785442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-llama-2-everywhere-l2e" dir="auto"><a href="#llama-2-everywhere-l2e">Llama 2 Everywhere (L2E)</a></h2>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/trholding/llama2.c/blob/master/assets/llamas_everywhere.jpg"><img src="https://github.com/trholding/llama2.c/raw/master/assets/llamas_everywhere.jpg" width="600" height="454" alt="LLamas Everywhere!"></a>
</p>
<p dir="auto">Standalone, Binary Portable, Bootable Llama 2</p>
<p dir="auto">The primary objective of Llama 2 Everywhere (L2E) is to ensure its compatibility across a wide range of devices, from booting on repurposed chromebooks discarded by school districts to high-density unikernel deployments in enterprises.</p>
<p dir="auto">We believe that in future by harnessing a legion of small specialized LLMs with modest hardware requirements which are networked, distributed, and self-coordinated, L2E has the potential to democratize access to AI and unlock collective intelligence that surpasses that of a single large LLM.</p>
<p dir="auto">The current compelling use case of L2E involves training small models on diverse textual sources, including textbooks, open books, and comprehensive corpora like the SlimPajama corpus. These trained models can be deployed using L2E, enabling them to run as bootable instances on outdated school computers. This deployment scenario proves particularly valuable in school libraries or classrooms where internet connectivity is limited or unavailable, serving as an information gateway* for students without constant reliance on the internet.</p>
<p dir="auto">By pursuing the vision of Llama 2 Everywhere, we aim to create an inclusive AI ecosystem that can adapt to diverse environments and empower individuals and communities on a global scale.</p>
<p dir="auto">My research goal is to train models using various hardware telemetry data with the hope that the models learn to interpret sensor inputs and control actuators based on the insights they glean from the sensor inputs. This research direction may open up exciting possibilities in fields such as automation, space, robotics and IoT, where L2E can play a pivotal role in bridging the gap between AI and physical systems.</p>
<p dir="auto">A friendly fork of the excellent <a href="https://github.com/karpathy/llama2.c">@karpathy's llama2.c</a></p>
<p dir="auto">I will be mirrorring the progress of <a href="https://github.com/karpathy/llama2.c">https://github.com/karpathy/llama2.c</a> every week, add portability, performance improvements and convenience features such as a web interface which certainly would not fit in the upstream do to the minimalistic elegance requirements there.</p>
<h3 tabindex="-1" id="user-content--how-do-we-make-sure-that-the-output-is-factual-and-not-hallucinated" dir="auto"><a href="#-how-do-we-make-sure-that-the-output-is-factual-and-not-hallucinated">* How do we make sure that the output is factual and not hallucinated?</a></h3>
<p dir="auto">It's a chicken and egg problem. This has to be explored and figured out on the way. Some ideas on mind are:</p>
<ol dir="auto">
<li>Topic specialized models which are frequently updated maybe every month or two.</li>
<li>Fact Checking &amp; Moderation specialized models which moderate or do fact checking on other model's output.</li>
<li>Reduce / mitigate hallucinations through output validation (both neural and rule based).</li>
<li>Prompt rewriting both neural and with rules.</li>
<li>Educators / Students / Users can flag answers. Administrators could update rules.</li>
</ol>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<h4 tabindex="-1" id="user-content-new---l2e-os-linux-kernel" dir="auto"><a href="#new---l2e-os-linux-kernel">NEW - L2E OS (Linux Kernel)</a></h4>
<p dir="auto">Have you ever wanted to really boot and inference a baby Llama 2 model on a computer? No? Well, now you can!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/93451215/272002490-5142b54e-b46f-4224-99a6-44b8896d2358.png"><img src="https://user-images.githubusercontent.com/93451215/272002490-5142b54e-b46f-4224-99a6-44b8896d2358.png" alt="temple dos"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/93451215/272002864-ce139c79-407d-4946-8244-0f38a3c07211.png"><img src="https://user-images.githubusercontent.com/93451215/272002864-ce139c79-407d-4946-8244-0f38a3c07211.png" alt="GUI"></a></p>
<p dir="auto">Have you ever wanted to do <code>cat /dev/llama</code> and <code>echo "Sudo make me a sandwich!" &gt; /dev/llama</code> or pass a kernel parameter such as <code>l2e.quest="What is the meaning of life?"</code> ? No? Well, as luck would have, it now you can!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/93451215/272002648-93b7e87b-170e-4a25-8b61-2a9cef461714.png"><img src="https://user-images.githubusercontent.com/93451215/272002648-93b7e87b-170e-4a25-8b61-2a9cef461714.png" alt="dmesg"></a></p>
<p dir="auto">Download and run the ISO from the latest release!</p>
<h3 tabindex="-1" id="user-content-new---unikernel-build" dir="auto"><a href="#new---unikernel-build">NEW - Unikernel Build</a></h3>
<p dir="auto">Have you ever wanted to boot and inference a herd of 1000's of Virtual baby Llama 2 models on big ass enterprise servers? No? Well, now you can!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/93451215/263436853-415f00b4-25ed-4c30-b619-1c3404ababee.png"><img src="https://user-images.githubusercontent.com/93451215/263436853-415f00b4-25ed-4c30-b619-1c3404ababee.png" alt="l2e_unik"></a></p>
<p dir="auto">Just do the following to build:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make run_unik_qemu_x86_64"><pre>make run_unik_qemu_x86_64</pre></div>
<p dir="auto">Please note that the requirements - unikraft and musl sources - will automatically get cloned before building.</p>
<p dir="auto">Once the build completes, (takes a while), run L2E like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="qemu-system-x86_64 -m 256m -accel kvm -kernel build/L2E_qemu-x86_64"><pre>qemu-system-x86_64 -m 256m -accel kvm -kernel build/L2E_qemu-x86_64</pre></div>
<p dir="auto">You can also run with -nographic option to directly interact in terminal.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qemu-system-x86_64 -m 256m -accel kvm -kernel build/L2E_qemu-x86_64 -nographic"><pre>qemu-system-x86_64 -m 256m -accel kvm -kernel build/L2E_qemu-x86_64 -nographic</pre></div>
<p dir="auto">Download and try this and the cosmocc build in the latest release.</p>
<h2 tabindex="-1" id="user-content-portability-features" dir="auto"><a href="#portability-features">Portability Features</a></h2>
<ul dir="auto">
<li>Single Executable that runs on any x86_64 OS (cosmocc builds)</li>
</ul>
<ul>
<li> GNU Linux</li>
<li> GNU/Systemd</li>
<li> *BSD (NetBSD, OpenBSD, FreeBSD)</li>
<li> XNU's Not UNIX (Mac)</li>
<li> Bare Metal Boot (BIOS &amp; EFI) (Not fully functional yet but almost...)</li>
<li> Windows</li>
<li> Runs on ARM64 via inbuilt BLINK emulation</li>
</ul>
<ul dir="auto">
<li>Standalone</li>
</ul>
<ul>
<li> Embedded model and tokenizer via ZipOS (cosmocc), INCBIN, strliteral</li>
</ul>
<ul dir="auto">
<li>Usability</li>
</ul>
<ul>
<li> Hacky CLI Chat - use any _incbin, _strlit or _zipos build.</li>
</ul>
<p dir="auto">Some combined features depend on a specific cosmocc toolchain: <a href="https://github.com/jart/cosmopolitan">https://github.com/jart/cosmopolitan</a></p>
<p dir="auto">Building this with gcc or clang would result in normal binaries similar to upstream.</p>
<p dir="auto">Read more:
<a href="https://github.com/trholding/llama2.c#portable-binary-build">How to build</a></p>
<h3 tabindex="-1" id="user-content-performance-features" dir="auto"><a href="#performance-features">Performance Features</a></h3>
<p dir="auto"><strong>CPU</strong></p>
<ul>
<li> OpenBLAS</li>
<li> CBLAS</li>
<li> BLIS</li>
<li> Intel MKL (WIP)</li>
<li> ArmPL (WIP)</li>
<li> Apple Accelerate Framework (CBLAS) (WIP/Testing)</li>
</ul>
<p dir="auto"><strong>CPU/GPU</strong></p>
<ul>
<li> OpenMP</li>
<li> OpenACC</li>
</ul>
<p dir="auto">Both OpenMP and OpenACC builds currently use host CPU and do not offload to GPU.</p>
<p dir="auto"><strong>GPU</strong></p>
<ul>
<li> OpenCL (via CLBlast) (Direct - planned)</li>
<li> OpenGL</li>
<li> Vulkan</li>
<li> CUDA</li>
</ul>
<p dir="auto">Download the prebuilt run.com binary from releases</p>
<h2 tabindex="-1" id="user-content-llama2c" dir="auto"><a href="#llama2c">llama2.c</a></h2>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/trholding/llama2.c/blob/master/assets/llama_cute.jpg"><img src="https://github.com/trholding/llama2.c/raw/master/assets/llama_cute.jpg" width="150" height="150" alt="Cute Llama"></a>
</p>
<p dir="auto">A friendly fork of the excellent <a href="https://github.com/karpathy/llama2.c">llama2.c</a></p>
<p dir="auto">The original repository offers a full-stack solution for training and inferring the Llama 2 LLM architecture using PyTorch and a simple 500-line C file. The focus is on minimalism and simplicity, and the repo is a young project that is still being actively developed. The author recommends looking at the TinyStories paper for inspiration, as small LLMs can have strong performance in narrow domains. The C inference engine in run.c was the main focus of the project, and the Llama 2 architecture is hard-coded with no dependencies.</p>
<h2 tabindex="-1" id="user-content-feel-the-magic" dir="auto"><a href="#feel-the-magic">Feel the Magic</a></h2>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/trholding/llama2.c.git
cd llama2.c
make runfast
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin
./run stories15M.bin"><pre>git clone https://github.com/trholding/llama2.c.git
<span>cd</span> llama2.c
make runfast
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin
./run stories15M.bin</pre></div>
<p dir="auto">You can also prompt the model with a prefix:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./run stories42M.bin -t 0.8 -n 256 -i &quot;A big dog&quot;"><pre>./run stories42M.bin -t 0.8 -n 256 -i <span><span>"</span>A big dog<span>"</span></span></pre></div>
<p dir="auto">When prompting, the temperature and steps parameters are needed since we use simple positional arguments.</p>
<p dir="auto"><strong>Output</strong></p>
<blockquote>
<p dir="auto">A big dog named Zip. He loved to run and play in the sun. He was a happy dog. One day, Zip saw a little bird on the ground. The bird looked helpless. Zip wanted to help the bird. He ran to the bird and lay down next to it. Zip and the bird became friends. They played together every day. Zip would carry the bird to play in the trees. The bird would fly around, and Zip would bark. They were very happy together.</p>
</blockquote>
<h2 tabindex="-1" id="user-content-models" dir="auto"><a href="#models">Models</a></h2>
<p dir="auto">The original author trained a series of small models on TinyStories, which took a few hours to train on their setup. The 110M model took around 24 hours. The models are hosted on huggingface hub:</p>
<table>
<thead>
<tr>
<th>model</th>
<th>dim</th>
<th>n_layers</th>
<th>n_heads</th>
<th>max context length</th>
<th>parameters</th>
<th>val loss</th>
<th>download</th>
</tr>
</thead>
<tbody>
<tr>
<td>OG</td>
<td>288</td>
<td>6</td>
<td>6</td>
<td>256</td>
<td>15M</td>
<td>1.072</td>
<td><a href="https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin" rel="nofollow">stories15M.bin</a></td>
</tr>
<tr>
<td>42M</td>
<td>512</td>
<td>8</td>
<td>8</td>
<td>1024</td>
<td>42M</td>
<td>0.847</td>
<td><a href="https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin" rel="nofollow">stories42M.bin</a></td>
</tr>
<tr>
<td>110M</td>
<td>768</td>
<td>12</td>
<td>12</td>
<td>1024</td>
<td>110M</td>
<td>0.760</td>
<td><a href="https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin" rel="nofollow">stories110M.bin</a></td>
</tr>
</tbody>
</table>
<p dir="auto">The upstream project owner trained the llama2.c storyteller models on a 4X A100 40GB box provided by <a href="https://lambdalabs.com/service/gpu-cloud" rel="nofollow">Lambda labs</a>.</p>
<p dir="auto">Quick note on sampling, the recommendation for good results is to use <code>-t 1.0 -p 0.9</code>, i.e. top-p sampling at 0.9 with temperature 1.0 (this is the default). To control the diversity of samples use either the temperature (i.e. vary <code>-t</code> between 0 and 1 and keep top-p off with <code>-p 0</code>) or the top-p value (i.e. vary <code>-p</code> between 0 and 1 and keep <code>-t 1</code>), but not both. Nice explainers on LLM sampling strategies include <a href="https://peterchng.com/blog/2023/05/02/token-selection-strategies-top-k-top-p-and-temperature/" rel="nofollow">this</a>, <a href="https://docs.cohere.com/docs/controlling-generation-with-top-k-top-p" rel="nofollow">this</a> or <a href="https://huggingface.co/blog/how-to-generate" rel="nofollow">this</a>.</p>

<p dir="auto">A converted <strong>Meta's Llama 2 7b</strong> model can be inferenced at a slow speed.</p>
<h2 tabindex="-1" id="user-content-usage" dir="auto"><a href="#usage">Usage</a></h2>
<p dir="auto"><strong>Full Usage</strong></p>
<div data-snippet-clipboard-copy-content="Usage:   run <checkpoint> [options]
Example: ./run model.bin -n 256 -i &quot;Once upon a time&quot;
Options:
  -t <float>  temperature in [0,inf], default 1.0
  -p <float>  p value in top-p (nucleus) sampling in [0,1] default 0.9
  -s <int>    random seed, default time(NULL)
  -n <int>    number of steps to run for, default 256. 0 = max_seq_len
  -b <int>    number of tokens to buffer, default 1. 0 = max_seq_len
  -x <int>    extended info / stats, default 1 = on. 0 = off
  -i <string> input prompt
  -z <string> optional path to custom tokenizer"><pre><code>Usage:   run &lt;checkpoint&gt; [options]
Example: ./run model.bin -n 256 -i "Once upon a time"
Options:
  -t &lt;float&gt;  temperature in [0,inf], default 1.0
  -p &lt;float&gt;  p value in top-p (nucleus) sampling in [0,1] default 0.9
  -s &lt;int&gt;    random seed, default time(NULL)
  -n &lt;int&gt;    number of steps to run for, default 256. 0 = max_seq_len
  -b &lt;int&gt;    number of tokens to buffer, default 1. 0 = max_seq_len
  -x &lt;int&gt;    extended info / stats, default 1 = on. 0 = off
  -i &lt;string&gt; input prompt
  -z &lt;string&gt; optional path to custom tokenizer
</code></pre></div>
<p dir="auto"><code>&lt;checkpoint&gt;</code> is the <strong>mandatory</strong> checkpoint / model file.</p>
<p dir="auto"><strong>Minimal Usage</strong></p>

<h2 tabindex="-1" id="user-content-platforms" dir="auto"><a href="#platforms">Platforms</a></h2>
<p dir="auto"><strong>Multi OS build</strong></p>
<p dir="auto"><code>make run_cosmocc</code></p>
<p dir="auto">The binary will boot on baremetal and also run on any 64 Bit OS such as Linux, *BSD, Windows and slower on Aarch64 Mac &amp; Linux.</p>
<p dir="auto">Currently when used to boot, it won't be able to find the models. It's a toolchain feature with an anticipated PR merge.</p>
<p dir="auto">The performance of this build is more than twice of the basic build.</p>
<p dir="auto">The cosmopolitan toolchain is a requirement for this build to work. Read here: <a href="https://github.com/trholding/llama2.c#portable-binary-build">How to build</a></p>
<p dir="auto"><strong>Please note that the Multi OS binaries builds built with cosmocc cause a false positive with AV/Microsoft Defender and Virus Total</strong></p>
<p dir="auto">The issue is that AV's consider unsigned binaries or binaries that contain multiple OS binary signatures in one binary as suspicious.
Get more insight here: <a data-error-text="Failed to load title" data-id="1867950355" data-permission-text="Title is private" data-url="https://github.com/trholding/llama2.c/issues/8" data-hovercard-type="issue" data-hovercard-url="/trholding/llama2.c/issues/8/hovercard" href="https://github.com/trholding/llama2.c/issues/8">#8</a> and <a data-error-text="Failed to load title" data-id="1090678232" data-permission-text="Title is private" data-url="https://github.com/jart/cosmopolitan/issues/342" data-hovercard-type="issue" data-hovercard-url="/jart/cosmopolitan/issues/342/hovercard" href="https://github.com/jart/cosmopolitan/issues/342">jart/cosmopolitan#342</a></p>
<p dir="auto"><strong>Linux</strong></p>
<p dir="auto">Centos 7 / Amazon Linux 2018</p>
<p dir="auto"><code>make rungnu</code> or <code>make runompgnu</code> to use openmp.</p>
<p dir="auto"><strong>Other Linux Distros / Mac</strong></p>
<p dir="auto"><code>make runfast</code> or <code>make runomp</code> to use openmp.</p>
<p dir="auto"><strong>Windows</strong></p>
<p dir="auto">Build on windows:</p>
<p dir="auto"><code>build_msvc.bat</code> in a Visual Studio Command Prompt</p>
<p dir="auto">The MSVC build will use openmp and max threads suitable for your CPU unless you set <code>OMP_NUM_THREADS</code> env.</p>
<p dir="auto">Build on Linux and Windows:</p>
<p dir="auto"><code>make win64</code> to use the mingw compiler toolchain.</p>
<p dir="auto"><strong>Android</strong></p>
<p dir="auto">See this @lordunix's post on how to build this on Android within <a href="https://termux.dev/en/" rel="nofollow">termux</a>:</p>
<p dir="auto"><a data-error-text="Failed to load title" data-id="1867639275" data-permission-text="Title is private" data-url="https://github.com/trholding/llama2.c/issues/7" data-hovercard-type="issue" data-hovercard-url="/trholding/llama2.c/issues/7/hovercard" href="https://github.com/trholding/llama2.c/issues/7#issue-1867639275">#7 (comment)</a></p>
<p dir="auto">TODO.</p>
<h2 tabindex="-1" id="user-content-performance" dir="auto"><a href="#performance">Performance</a></h2>
<p dir="auto"><strong>Basic</strong></p>
<p dir="auto">This build does not enable any optimizations.</p>

<p dir="auto">This can be used as baseline build against which performance of other builds can be compared.</p>
<p dir="auto"><strong>Fast</strong></p>
<p dir="auto">This build enables basic performance boost with compiler provided optimizations.</p>

<h3 tabindex="-1" id="user-content-build-wth-acceleration" dir="auto"><a href="#build-wth-acceleration">Build wth Acceleration</a></h3>
<p dir="auto"><strong>OpenMP</strong></p>
<p dir="auto">This build enables acceleration via OpenMP</p>

<p dir="auto">Requires <a href="https://www.openmp.org/" rel="nofollow">OpenMP</a> libraries and compiler with OpenMP support to be available on system.
E.g. <code>apt install clang libomp-dev</code> on ubuntu</p>
<p dir="auto">When you run inference make sure to use OpenMP flags to set the number of threads, e.g.:</p>
<div dir="auto" data-snippet-clipboard-copy-content="OMP_NUM_THREADS=4 ./run out/model.bin"><pre>OMP_NUM_THREADS=4 ./run out/model.bin</pre></div>
<p dir="auto">More threads is not always better.</p>
<p dir="auto"><strong>OpenACC</strong></p>
<p dir="auto">This build enables acceleration via OpenACC</p>

<p dir="auto">Requires <a href="https://www.openacc.org/" rel="nofollow">OpenACC</a> libraries and compiler with OpenACC support to be available on system.</p>
<p dir="auto"><strong>OpenBLAS</strong></p>
<p dir="auto">This build enables acceleration via OpenBLAS</p>

<p dir="auto">Requires <a href="https://github.com/xianyi/OpenBLAS">OpenBLAS</a> to be installed on system.</p>
<p dir="auto"><strong>BLIS</strong></p>
<p dir="auto">This build enables acceleration via BLIS</p>

<p dir="auto">Requires <a href="https://github.com/flame/blis">BLIS</a> compiled with <code>./configure --enable-cblas -t openmp,pthreads auto</code> to be installed on system.</p>
<p dir="auto"><strong>Intel oneAPI MKL</strong></p>
<p dir="auto">This build enables acceleration via Intel® oneAPI Math Kernel Library on x86_64 systems and Intel Mac OS - WIP</p>

<p dir="auto">Requires <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html" rel="nofollow">Intel oneAPI MKL</a> to be installed on system.</p>
<p dir="auto"><strong>Arm Performance Library (ArmPL)</strong></p>
<p dir="auto">This build enables acceleration via Arm Performance Library on ARM64 systems such as Linux or Mac OS - WIP</p>

<p dir="auto">Requires <a href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" rel="nofollow">ArmPL</a> to be installed on system.</p>
<p dir="auto"><strong>Apple Accelerate</strong></p>
<p dir="auto">This build enables BLAS acceleration via Apple Accelerate on Mac OS - Testing</p>

<p dir="auto">Requires <a href="https://developer.apple.com/accelerate/" rel="nofollow">Apple Accelerate</a> to be available on system.</p>
<p dir="auto">Note: Needs testing.</p>
<p dir="auto"><strong>Generic CBLAS</strong></p>
<p dir="auto">This build enables acceleration with any Netlib CBLAS interface compatible libraries</p>

<p dir="auto">Requires any BLAS library with Netlib CBLAS interface such as <a href="https://www.netlib.org/lapack" rel="nofollow">LAPACK</a> to be installed on system.</p>
<p dir="auto"><strong>CLBlast (GPU/OpenCL)</strong></p>
<p dir="auto">This build enables tuned GPU acceleration via OpenCL with CLBlast</p>

<p dir="auto">Requires <a href="https://github.com/CNugteren/CLBlast">CLBlast</a> compiled with <code>cmake -DNETLIB=ON</code> to be installed on system.</p>
<p dir="auto">Note: Currently runs much slower than CPU! Requires investigation or memory I/O is a bottle neck on the test system.</p>
<h2 tabindex="-1" id="user-content-portable-binary-build" dir="auto"><a href="#portable-binary-build">Portable Binary Build</a></h2>
<p dir="auto">Have you ever wanted to inference a baby Llama 2 model with a single executable on any OS or *as OS? No? Well, now you can!</p>
<p dir="auto">By making use of the Cosmopolitan libc toolchain to build llama2.c we get the we can get those features.</p>
<p dir="auto">Instructions</p>
<p dir="auto">Get and build the comopolitan libc toolchain:</p>
<p dir="auto">Follow instructions at <a href="https://github.com/jart/cosmopolitan">https://github.com/jart/cosmopolitan</a></p>
<p dir="auto">Or do:</p>
<div data-snippet-clipboard-copy-content="sudo mkdir -p /opt
sudo chmod 1777 /opt
git clone https://github.com/jart/cosmopolitan /opt/cosmo
export PATH=&quot;/opt/cosmo/bin:/opt/cosmos/bin:$PATH&quot;
echo 'PATH=&quot;/opt/cosmo/bin:/opt/cosmos/bin:$PATH&quot;' >>~/.profile
cosmocc --update   # pull cosmo and build/rebuild toolchain"><pre><code>sudo mkdir -p /opt
sudo chmod 1777 /opt
git clone https://github.com/jart/cosmopolitan /opt/cosmo
export PATH="/opt/cosmo/bin:/opt/cosmos/bin:$PATH"
echo 'PATH="/opt/cosmo/bin:/opt/cosmos/bin:$PATH"' &gt;&gt;~/.profile
cosmocc --update   # pull cosmo and build/rebuild toolchain
</code></pre></div>
<p dir="auto">Example build to generate a Actually Portable Executable (APE) with embedded model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir out
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin -O out/model.bin
make run_cosmocc_incbin"><pre>mkdir out
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin -O out/model.bin
make run_cosmocc_incbin</pre></div>
<p dir="auto">Example build to generate a APE:</p>

<p dir="auto">Run or copy to any supported system and run:</p>
<p dir="auto">If model is embedded:</p>

<p dir="auto">Else</p>

<h2 tabindex="-1" id="user-content-all-make-targets" dir="auto"><a href="#all-make-targets">All 'make' targets</a></h2>
<p dir="auto">Do make  to build for a particular target.</p>
<p dir="auto">Example:</p>

<p dir="auto">Usage &amp; Targets:</p>
<div data-snippet-clipboard-copy-content="Usage:
  make <target>

Simple Builds
  run_cc                        - Standard build with basic optimizations
  run_cc_fast                   - More Optimized build. Disregards strict standards compliance
  run_cc_gnu                    - Optimized Generic linux distro build

Accelerated Builds
  run_cc_openmp                 - OpenMP accelerated build
  run_cc_openacc                - OpenACC accelerated build
  run_cc_omp_gnu                - Generic linux distro + OpenMP build
  run_cc_clblast                - CLBlast OpenCL CBLAS GPU accelerated build
  run_cc_openblas               - Openblas CBLAS accelerated build
  run_cc_cblas                  - Generic CBLAS accelerated build
  run_cc_blis                   - BLIS accelerated build

Special Builds 

---> x86_64
  run_cc_mkl                    - OpenMP + Intel MKL CBLAS build (x86_64 / intel Mac) (WIP)

---> ARM64 / aarch64
  run_cc_armpl                  - ARM PL BLAS accelerated build (ARM64 &amp; Mac)  (WIP)

---> Macintosh
  run_cc_mac_accel              - Mac OS OPENMP + CBLAS via Accelerate Framework build (WIP/TEST)

---> Windows
  run_win                       - Optimized Windows build with MinGW-w64 toolchain
  run_win_msvc                  - OpenMP accelerated Windows build with MSVC toolchain (Untested)

---> MultiOS Builds (using cosmopolitan libc + toolchain)
  run_cosmocc                   - Optimized Portable + cosmocc (runs on all OSes)

---> MultiOS Builds ---> with Embedded Models
  run_cosmocc_zipos             - Optimized Portable + cosmocc + embedded zip model build (runs on all OSes)
  run_cosmocc_incbin            - Optimized Portable + cosmocc + embedded model fast build (runs on all OSes)
  run_cosmocc_strlit            - Optimized Portable + cosmocc + embedded model build (runs on all OSes)

---> GCC/Clang Embedded Model Builds
  run_gcc_openmp_incbin         - Gcc + OpenMP + embedded model fast build
  run_gcc_openmp_strlit         - Gcc + OpenMP + embedded model build
  run_clang_openmp_incbin       - Clang + OpenMP + embedded model fast build
  run_clang_openmp_strlit       - Clang + OpenMP + embedded model build

---> GCC/Clang Embedded Model Builds ---> Statically Linked
  run_gcc_static_incbin         - Optimized Static gcc + embedded model fast build
  run_gcc_static_strlit         - Optimized Static gcc + embedded model build
  run_clang_static_incbin       - Optimized Static clang + embedded model fast build
  run_clang_static_strlit       - Optimized Static clang + embedded model build

---> Android
  run_incbin_tmux               - Optimized build + Embedded Model for Termux on Android

---> L2E Unikernel (Asteroid)
  l2e_unik_qemu                 - L2E Unikernel (Asteroid) for kvm / qemu x86_64

---> L2E Unikernel (Asteroid) ---> Boot in qemu
  boot_l2e_unik                 - Boot L2E Unikernel (Asteroid) in qemu

---> L2E OS (Humanoid)
  l2e_os                        - L2E OS, kernel module and userspace build

---> L2E OS (Humanoid) ---> Make Bootable ISO
  l2e_os_iso                    - Make Bootable L2E OS Hybrid UEFI/BIOS ISO Image

---> L2E OS (Humanoid) ---> Boot in qemu
  boot_l2e_os                   - Boot L2E OS (Humanoid) in qemu

---> L2E OS (Humanoid) ---> Boot ISO in qemu
  boot_l2e_iso                  - Boot L2E OS ISO Image in qemu

---> L2E OS (Humanoid) ---> Boot ISO with UEFI in qemu
  boot_l2e_iso_uefi             - Boot L2E OS ISO Image with UEFI in qemu

Debug Build
  run_debug                     - Debug build which can be analyzed with tools like valgrind.

Testing
  test                          - run all tests (inclusive python code, needs python)
  testc                         - run only tests for run.c C implementation (needs python)
  testcc                        - run the C tests, without touching pytest / python

Clean/ Purge
  tempclean                     - Find and delete all temporary files left by editors  
  clean                         - Simple cleaning 
  distclean                     - Deep cleaning (distclean sub projects)
  mintclean                     - Revert to mint condition (remove sub projects)

Misc
  get_model                     - Get stories15M model
  list                          - Display sorted list of all targets

Help
  help                          - Display this help. Make without target also displays this help.
"><pre><code>Usage:
  make &lt;target&gt;

Simple Builds
  run_cc                        - Standard build with basic optimizations
  run_cc_fast                   - More Optimized build. Disregards strict standards compliance
  run_cc_gnu                    - Optimized Generic linux distro build

Accelerated Builds
  run_cc_openmp                 - OpenMP accelerated build
  run_cc_openacc                - OpenACC accelerated build
  run_cc_omp_gnu                - Generic linux distro + OpenMP build
  run_cc_clblast                - CLBlast OpenCL CBLAS GPU accelerated build
  run_cc_openblas               - Openblas CBLAS accelerated build
  run_cc_cblas                  - Generic CBLAS accelerated build
  run_cc_blis                   - BLIS accelerated build

Special Builds 

---&gt; x86_64
  run_cc_mkl                    - OpenMP + Intel MKL CBLAS build (x86_64 / intel Mac) (WIP)

---&gt; ARM64 / aarch64
  run_cc_armpl                  - ARM PL BLAS accelerated build (ARM64 &amp; Mac)  (WIP)

---&gt; Macintosh
  run_cc_mac_accel              - Mac OS OPENMP + CBLAS via Accelerate Framework build (WIP/TEST)

---&gt; Windows
  run_win                       - Optimized Windows build with MinGW-w64 toolchain
  run_win_msvc                  - OpenMP accelerated Windows build with MSVC toolchain (Untested)

---&gt; MultiOS Builds (using cosmopolitan libc + toolchain)
  run_cosmocc                   - Optimized Portable + cosmocc (runs on all OSes)

---&gt; MultiOS Builds ---&gt; with Embedded Models
  run_cosmocc_zipos             - Optimized Portable + cosmocc + embedded zip model build (runs on all OSes)
  run_cosmocc_incbin            - Optimized Portable + cosmocc + embedded model fast build (runs on all OSes)
  run_cosmocc_strlit            - Optimized Portable + cosmocc + embedded model build (runs on all OSes)

---&gt; GCC/Clang Embedded Model Builds
  run_gcc_openmp_incbin         - Gcc + OpenMP + embedded model fast build
  run_gcc_openmp_strlit         - Gcc + OpenMP + embedded model build
  run_clang_openmp_incbin       - Clang + OpenMP + embedded model fast build
  run_clang_openmp_strlit       - Clang + OpenMP + embedded model build

---&gt; GCC/Clang Embedded Model Builds ---&gt; Statically Linked
  run_gcc_static_incbin         - Optimized Static gcc + embedded model fast build
  run_gcc_static_strlit         - Optimized Static gcc + embedded model build
  run_clang_static_incbin       - Optimized Static clang + embedded model fast build
  run_clang_static_strlit       - Optimized Static clang + embedded model build

---&gt; Android
  run_incbin_tmux               - Optimized build + Embedded Model for Termux on Android

---&gt; L2E Unikernel (Asteroid)
  l2e_unik_qemu                 - L2E Unikernel (Asteroid) for kvm / qemu x86_64

---&gt; L2E Unikernel (Asteroid) ---&gt; Boot in qemu
  boot_l2e_unik                 - Boot L2E Unikernel (Asteroid) in qemu

---&gt; L2E OS (Humanoid)
  l2e_os                        - L2E OS, kernel module and userspace build

---&gt; L2E OS (Humanoid) ---&gt; Make Bootable ISO
  l2e_os_iso                    - Make Bootable L2E OS Hybrid UEFI/BIOS ISO Image

---&gt; L2E OS (Humanoid) ---&gt; Boot in qemu
  boot_l2e_os                   - Boot L2E OS (Humanoid) in qemu

---&gt; L2E OS (Humanoid) ---&gt; Boot ISO in qemu
  boot_l2e_iso                  - Boot L2E OS ISO Image in qemu

---&gt; L2E OS (Humanoid) ---&gt; Boot ISO with UEFI in qemu
  boot_l2e_iso_uefi             - Boot L2E OS ISO Image with UEFI in qemu

Debug Build
  run_debug                     - Debug build which can be analyzed with tools like valgrind.

Testing
  test                          - run all tests (inclusive python code, needs python)
  testc                         - run only tests for run.c C implementation (needs python)
  testcc                        - run the C tests, without touching pytest / python

Clean/ Purge
  tempclean                     - Find and delete all temporary files left by editors  
  clean                         - Simple cleaning 
  distclean                     - Deep cleaning (distclean sub projects)
  mintclean                     - Revert to mint condition (remove sub projects)

Misc
  get_model                     - Get stories15M model
  list                          - Display sorted list of all targets

Help
  help                          - Display this help. Make without target also displays this help.

</code></pre></div>
<p dir="auto">All builds with embedded models need the model to be in <code>out/</code> directory and the model name has to be <code>model.bin</code></p>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir out
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin -O out/model.bin"><pre>mkdir out
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin -O out/model.bin</pre></div>
<h2 tabindex="-1" id="user-content-todo" dir="auto"><a href="#todo">TODO</a></h2>
<ul>
<li> Python Binding + Streamlit Demo (priority)</li>
<li> Web UI + Minimal OpenAI API compat (priority)</li>
<li> GNU/Linux kernel + efistub + cpio + l2e as init boot image (priority)</li>
<li> Users need better docs / howto / example, especially VM related.</li>
<li> Train a small test model on open books. (I need to figure out sourcing the compute)</li>
<li> Unikraft unikernel Boot (WIP/Testing) (Task: Multi Arch + Firecracker VM support)</li>
<li> Intel MKL BLAS Acceleration (WIP)</li>
<li> Arm Performance Libraries (WIP)</li>
<li> Apple Accelerate BLAS (WIP/Testing)</li>
<li> NetBSD Rump Kernel Boot (R&amp;D, attempt failed, needs deep study)</li>
<li> sgemm OpenGL acceleration (next)</li>
<li> sgemm SSE, AVX acceleration</li>
<li> Fix baremetal cosmo boot model loading (pending)</li>
<li> OpenMP SIMD (pending)</li>
<li> OpenCL pure</li>
<li> Vulkan</li>
<li> CUDA</li>
<li> MPI / PVM / PBLAS</li>
<li> cFS App</li>
<li> Android support (both ndk builds and minimal APK)</li>
<li> Various uC demos (ESP32, ESP8266, Pico) - load models via network, Raspi Zero Demo</li>
<li> Quantization (16, 4 , 2)</li>
<li> <del>CLara</del> (tried / broken) / SunCL Distributed OpenCL support</li>
<li> Fix broken MSVC build (!) yikes</li>
<li> Split, re-order, rebase repo.</li>
</ul>
<h2 tabindex="-1" id="user-content-changelog" dir="auto"><a href="#changelog">Changelog</a></h2>
<p dir="auto">See commits.</p>
<h2 tabindex="-1" id="user-content-contributing" dir="auto"><a href="#contributing">Contributing</a></h2>
<ul dir="auto">
<li>All pull requests that are merged to upstream will be automatically applied here as we closely mirror upstream.</li>
<li>I merge pull requests that improves performance even if they are rejected upstream.</li>
<li>Performance and usability improvement contriubutions are welcome.</li>
</ul>
<h2 tabindex="-1" id="user-content-developer-status" dir="auto"><a href="#developer-status">Developer Status</a></h2>
<p dir="auto">See "Developer Status" issue.</p>
<p dir="auto">Current status: Busy since Aug ~6 2023, away on bigger IRL projects. Just merging stuff. Addressing all issues every ~7 days.</p>
<h2 tabindex="-1" id="user-content-gratitude--credits" dir="auto"><a href="#gratitude--credits">Gratitude &amp; Credits</a></h2>
<p dir="auto">Thank you to to the creators of the following libraries and tools and their contributors:</p>
<ul dir="auto">
<li><a href="https://github.com/karpathy/llama2.c">llama2.c</a> - @karpathy</li>
<li><a href="https://github.com/jart/cosmopolitan">cosmopolitan</a> - @jart</li>
<li><a href="https://github.com/xianyi/OpenBLAS">OpenBlas</a> - @xianyi</li>
<li><a href="https://github.com/flame/blis">blis</a> - @flame</li>
<li><a href="https://github.com/CNugteren/CLBlast">CLBlast</a> - @CNugteren</li>
<li><a href="https://github.com/graphitemaster/incbin">incbin</a> - @graphitemaster</li>
<li><a href="https://github.com/mortie/strliteral">strliteral</a> - @mortie</li>
<li><a href="https://github.com/unikraft">unikraft</a> - @unikraft</li>
</ul>
<h2 tabindex="-1" id="user-content-notable-projects" dir="auto"><a href="#notable-projects">Notable projects</a></h2>
<ul dir="auto">
<li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a></li>
<li><a href="https://github.com/karpathy/llama2.c">llama2.c</a></li>
</ul>
<h2 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License</a></h2>
<p dir="auto">MIT</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NIST Elliptic Curves Seeds Bounty (401 pts)]]></title>
            <link>https://words.filippo.io/dispatches/seeds-bounty/</link>
            <guid>37784499</guid>
            <pubDate>Thu, 05 Oct 2023 21:26:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://words.filippo.io/dispatches/seeds-bounty/">https://words.filippo.io/dispatches/seeds-bounty/</a>, See on <a href="https://news.ycombinator.com/item?id=37784499">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <span>
            <time datetime="2023-10-05">05 Oct 2023</time>
        </span>
        
        <section>
            <!--kg-card-begin: markdown--><p>The NIST elliptic curves that power much of modern cryptography were generated in the late ‘90s by hashing seeds provided by the NSA. How were the seeds generated? Rumor has it that they are in turn hashes of English sentences, but the person who picked them, Dr. Jerry Solinas, passed away in early 2023 leaving behind a cryptographic mystery, some conspiracy theories, and an historical password cracking challenge.</p>
<p><strong>Together with some generous matchers, I’m announcing a <s>$8,192</s> $12,288 (12 Ki$) bounty for cracking these five hashes, tripled to $36,864 if the recipient chooses to donate it to a 501(c)(3) charity of their choice.</strong></p>
<pre><code>3045AE6FC8422F64ED579528D38120EAE12196D5
BD71344799D5C7FCDC45B59FA3B9AB8F6A948BC5
C49D360886E704936A6678E1139D26B7819F7E90
A335926AA319A27A1D00896A6773A4827ACDAC73
D09E8800291CB85396CC6717393284AAA0DA64BA
</code></pre>
<p>Thank you to Amir Omidi, Chris Palmer, Colm MacCárthaigh, David Adrian, David Anderson, Jeff Hodges, Matt Green, Matthew McPherrin, Paul Kehrer, Ryan Sleevi, and Soatok for contributing to the bounty, and to Steve Weis for the research that inspired this.</p>
<h2 id="step-back-what-is-this-about">Step back, what is this about?</h2>
<p>The NIST elliptic curves (P-192, P-224, P-256, P-384, and P-521<sup><a href="#fn1" id="fnref1">[1]</a></sup>) were published by NIST in FIPS 186-2 in 2000, and generated “verifiably at random” according to ANSI X9.62 by taking an arbitrary seed, hashing it with SHA-1, and using the output to derive some of the parameters.</p>
<p>A <em>lot</em> of cryptography uses NIST curves, and especially P-256 and P-384. They are in the Commercial National Security Algorithm Suite (the successor of Suite B), and are the curves used by the ECDSA X.509 certificates that secure much of the web. They’re a big deal.</p>
<p>Steve Weis has recently published <a href="https://saweis.net/posts/nist-curve-seed-origins.html?ref=words.filippo.io">a well researched article</a> on everything we know about those arbitrary seeds embedded in the FIPS 186 specification. Apparently, they were provided by the NSA, and generated by Jerry Solinas in 1997. He allegedly generated them by hashing, presumably with SHA-1, some English sentences that he later forgot.</p>
<blockquote>
<p>[Jerry] told me that he used a seed that was something like:<br>
<code>SEED = SHA1("Jerry deserves a raise.")</code><br>
After he did the work, his machine was replaced or upgraded, and the actual phrase that he used was lost. When the controversy first came up, Jerry tried every phrase that he could think of that was similar to this, but none matched.</p>
</blockquote>
<p>That’s unfortunate, because the NIST curves are—surprisingly—looking better and better: we now have <a href="https://eprint.iacr.org/2015/1060?ref=words.filippo.io">complete addition formulas</a> for them, mitigating their major footgun; we know how to design safer interfaces for them; and we painfully learned to appreciate the value of prime order curves immune to cofactor attacks. However, there is—mostly amongst non-practitioners—some fear that the NSA could have picked the seeds to select some intentionally weak curves.</p>
<p>Do I think those fears are well-founded? No. Koblitz and Menezes make a good argument in <a href="https://eprint.iacr.org/2015/1018.pdf?ref=words.filippo.io"><em>A riddle wrapped in an enigma</em></a> that even with full control over the seed, the NSA would have had to be aware of a class of weak curves so large that it’s not plausible that no one in academia or industry discovered them in 25 years.<sup><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>Anyway, some <a href="https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt?ref=words.filippo.io">FUD</a> persists around the otherwise pretty good NIST curves that would be good to clear up, even if the English preimage of the hashes <a href="https://twitter.com/lauriewired/status/1700982575291142594?ref=words.filippo.io">is not a complete guarantee of rigidity</a><sup><a href="#fn3" id="fnref3">[3]</a></sup>.</p>
<p>That’s where this bounty comes in. Finding the pre-seeds, the inputs to the hash that generated the seeds, is the bread and butter of password crackers and brainwallet bruteforcers. <strong>This is a call to arms for them to join the search, help fill in a page of cryptographic history, and collect a large bounty or donate an even larger one to charity.</strong></p>
<h2 id="ok-so-what-do-we-know-about-the-hashes">Ok, so what do we know about the hashes?</h2>
<p>To recap Steve Weis’s post, the inputs are probably English phrases which mention Jerry Solinas, possibly someone else, and probably a counter. If you’re actually going for it I recommend reading Steve’s post in full.</p>
<p>The counter has to be there because only one in every 192 to 521 hashes is actually good to make a curve out of, depending the bit size of the curve. (This is because <a href="https://en.wikipedia.org/wiki/Prime_number_theorem?ref=words.filippo.io">one in every ln(N) numbers less than N is prime, for large enough N</a>.) There’s a <a href="https://www.wolframalpha.com/input?i2d=true&amp;i=Power%5B%5C%2840%291+-+Divide%5B1%2C521%5D%5C%2841%29%2Cx%5D+%3D+0.01&amp;ref=words.filippo.io">99% chance the counter is less than 2400 for the largest curve</a>, and less than 1175 for P-256.</p>
<p>The seeds for P-192 and P-256 appeared as examples in the previous ANSI X9.62 standard, while all the others were new in FIPS 186-2, so they might have been generated from differently structured sentences.</p>
<p>Since testing more hashes is nearly free, I recommend also targeting all the examples from ANSI X9.62 that didn’t make the FIPS standard, as well as the seeds for the binary curves in FIPS 186-2, although they are not included in the bounty. Here’s a recap.</p>
<pre><code>3045AE6FC8422F64ED579528D38120EAE12196D5 # NIST P-192, ANSI prime192v1
BD71344799D5C7FCDC45B59FA3B9AB8F6A948BC5 # NIST P-224
C49D360886E704936A6678E1139D26B7819F7E90 # NIST P-256, ANSI prime256v1
A335926AA319A27A1D00896A6773A4827ACDAC73 # NIST P-384
D09E8800291CB85396CC6717393284AAA0DA64BA # NIST P-521
31A92EE2029FD10D901B113E990710F0D21AC6B6 # ANSI prime192v2, not eligible for bounty
C469684435DEB378C4B65CA9591E2A5763059A2E # ANSI prime192v3, not eligible for bounty
E43BB460F0B80CC0C0B075798E948060F8321B7D # ANSI prime239v1, not eligible for bounty
E8B4011604095303CA3B8099982BE09FCB9AE616 # ANSI prime239v2, not eligible for bounty
7D7374168FFE3471B60A857686A19475D3BFA2FF # ANSI prime239v3, not eligible for bounty
85E25BFE5C86226CDB12016F7553F9D0E693A268 # NIST B-163, not eligible for bounty
74D59FF07F6B413D0EA14B344B20A2DB049B50C3 # NIST B-233, not eligible for bounty
77E2B07370EB0F832A6DD5B62DFC88CD06BB84BE # NIST B-283, not eligible for bounty
4099B5A457F9D69F79213D094C4BCD4D4262210B # NIST B-409, not eligible for bounty
2AA058F73A0E33AB486B0F610410C53A7F132310 # NIST B-571, not eligible for bounty
</code></pre>
<p>The format of the string is part of the mystery. It could end with a period or not, end with a newline or not, the counter could be decimal (with or without leading zeroes) or binary (16 or 32 bit), and it could come after the period or separated some other way. The same sentence with different counters could have been used to generate all the seeds, or they could be different sentences, or they could include the curve name or size. Human memory is notoriously fallible, so it could also be that some of the details in the second-hand recollections are wrong.</p>
<p>The good news is that SHA-1 is tremendously fast to bruteforce, and <em>YOU</em> are the experts in cracking passphrases you know nothing about.</p>
<h2 id="cool-what%E2%80%99s-the-fine-print">Cool, what’s the fine print?</h2>
<p>The bounty will pay out to the first person(s) to email the pre-seeds for the five prime-order NIST curves to <a href="mailto:seeds@filippo.io">seeds@filippo.io</a>.</p>
<p>Half the bounty ($6,144) will pay out to the first submission of <em>at least one</em> pre-seed, and the other half will pay out to the first submission of <em>all five</em> pre-seeds. They can of course go to the same person, so don’t wait to have them all to submit. Even one would make history.</p>
<p>If successful, you can either choose to receive the cash bounty, or select a U.S. 501(c)(3) charity to receive triple the amount. We reserve the right to veto charity choices dramatically incompatible with our values, but we won’t be jerks about it. If it’s not legally allowed for a U.S. person or Italian national to send money to you, you will have to select the charity option. You’re responsible for any taxes on the cash bounty. I fully trust every matcher, and I am guaranteeing the full amount of the bounty personally, so you don’t have to.</p>
<p>Put “ANTISPAM” in the subject line of any submission to hit my allowlisting rules. The Received header of my mail host will be the unappealable criterion of what submission arrived first.</p>
<p>The bounty expires if the seeds become publicly known, otherwise it’s valid until announced otherwise on this page. If the bounty is being cancelled or lowered, it will be announced six months in advance. (We don’t want anyone to feel cheated of their resources.)</p>
<p>We don’t actually care how you find the seeds. It can be bruteforcing, clever guessing, sleuth work tracking down NSA employees (don’t get arrested), or even recovering that old backup of when you used to work at NIST. If you don’t want us to, we won’t ask questions.</p>
<p>May the hashrate be ever in your favor, and let's fill out a page of cryptographic history.</p>
<p>For updates, you might want to <a href="https://bsky.app/profile/filippo.abyssdomain.expert?ref=words.filippo.io">follow me on Bluesky</a> or <a href="https://abyssdomain.expert/@filippo?ref=words.filippo.io">Mastodon</a>.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Not a typo for 512. There’s a very conveniently shaped prime at 2^521-1. We do typo that a lot in code. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>The NSA's precedents, namely <a href="http://en.wikipedia.org/wiki/Dual_EC_DRBG?ref=words.filippo.io">Dual_EC_DRBG</a>, are why some people find the seeds suspicious. I find them reassuring. First, selecting weak seeds (which are just hash inputs, not "keys" like in Dual_EC_DRBG), would not be a <a href="https://en.wikipedia.org/wiki/NOBUS?ref=words.filippo.io">NOBUS backdoor</a>. Second, the Dual_EC_DRBG design immediately stuck out like a sore thumb and library authors had to be paid to implement it; this suggests the NSA is <em>kinda bad</em> at backdoors, not magical. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Rigidity is the design generalization of <a href="https://en.wikipedia.org/wiki/Nothing-up-my-sleeve_number?ref=words.filippo.io">nothing up my sleeves numbers</a>. The idea is that if you set your goals explicitly and then make only obvious and rational and optimal choices in a design, there is no wiggle room to pick intentionally weak outcomes. FWIW, I think rigidity is overrated: there is no such thing as an objectively best choice, and reasonable people disagree, and it’s possible to craft rational arguments for many different choices. Anyway, it’d be nice to settle the argument by bringing the NIST curves up in their level of rigidity by cracking the seeds. <a href="#fnref3">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
        </section>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChromeOS is Linux with Google’s desktop environment (128 pts)]]></title>
            <link>https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/#google_vignette</link>
            <guid>37783081</guid>
            <pubDate>Thu, 05 Oct 2023 19:25:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/#google_vignette">https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/#google_vignette</a>, See on <a href="https://news.ycombinator.com/item?id=37783081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Although not everyone knows it, ChromeOS is effectively a Linux distribution. That fact is effectively hidden and I can understand why: Linux can be a scary word to mainstream consumers. But there’s no denying the fact that ChromeOS is Linux. It uses a Linux kernel, hidden away by the graphical user interface, also known as a desktop environment. Between the <a href="https://www.aboutchromebooks.com/news/chromeos-117-release-adds-several-new-chromebook-features/" target="_blank" rel="noopener" title="ChromeOS 117 release adds several new Chromebook features">new Material You design</a> and move to <a href="https://www.aboutchromebooks.com/news/chromeos-116-may-begin-the-lacros-browser-push-to-chromebooks/" target="_blank" rel="noopener" title="ChromeOS 116 may begin the Lacros browser push to Chromebooks">break apart the Chrome browser from ChromeOS</a>, now more than ever, ChromeOS is Linux with Google’s desktop environment.</p><p>To help illustrate the point about desktop environments, it’s worth explaining what one actually is. Particularly when it comes to Linux systems.</p><p>When you install Linux, you choose a distribution. It could be Arch, Fedora, Debian, Ubuntu, or in my case, <a href="https://pop.system76.com/" target="_blank" rel="noopener">Pop OS!</a>. The distribution comes with a Linux kernel along with software and modifications for that particular distribution. Think of the kernel as the lowest level of software. It helps other software speak to the hardware to make a cohesive system. It’s what lets you browse your files through an application or the Terminal, for example.</p><p><span data-ez-name="aboutchromebooks_com-medrectangle-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=187&amp;impression_group_id=aboutchromebooks_com-medrectangle-3/2023-10-05/8762120453988575&amp;ad_size=580x400&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><p>But that’s only part of the system. The other part is how you interact with it. Some people prefer to simply use the Terminal and command line for everything. And there’s a relatively steep learning curve involved with that approach. So there are graphical desktop environments to help with that. These visually show clickable folders, for example, or have an application launcher menu, among other things.</p><p>And there’s no lack of standard desktop environments available to Linux users, all of which are customizable. Here’s a gallery of just a few of them, for illustration:</p><figure><figure><img title="gnome-desktop - About Chromebooks" decoding="async" width="300" height="169" data-id="14395" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-300x169.png" alt="ChromeOS is Linux with Google's desktop environment" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-768x432.png 768w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop.png 1280w" sizes="(max-width: 300px) 100vw, 300px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-300x169.png" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop-768x432.png 768w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/gnome-desktop.png 1280w"><figcaption>GNOME</figcaption></figure><figure><img title="xfce-desktop - About Chromebooks" decoding="async" width="1280" height="720" data-id="14392" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop.png" alt="" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop.png 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop-768x432.png 768w" sizes="(max-width: 1280px) 100vw, 1280px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop.png" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop.png 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/xfce-desktop-768x432.png 768w"><figcaption>XCFe</figcaption></figure><figure><img title="kde-desktop - About Chromebooks" decoding="async" loading="lazy" width="1280" height="720" data-id="14394" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop.png" alt="" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop.png 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop-768x432.png 768w" sizes="(max-width: 1280px) 100vw, 1280px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop.png" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop.png 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/kde-desktop-768x432.png 768w"><figcaption>KDE</figcaption></figure><figure><img title="unity-desktop - About Chromebooks" decoding="async" loading="lazy" width="1280" height="719" data-id="14393" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop.png" alt="" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop.png 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop-768x431.png 768w" sizes="(max-width: 1280px) 100vw, 1280px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop.png" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop.png 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop-300x169.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop-150x84.png 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/unity-desktop-768x431.png 768w"><figcaption>Unity</figcaption></figure></figure><p>While most Linux distributions come with a default desktop environment, users can install and choose from many others. You can’t do that on ChromeOS, which is why I say ChromeOS uses Google’s desktop environment. Choice would be nice here but I really do like the new Material You interface.</p><p><span data-ez-name="aboutchromebooks_com-medrectangle-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=188&amp;impression_group_id=aboutchromebooks_com-medrectangle-4/2023-10-05/878417047957786&amp;ad_size=336x280&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><figure><img title="Material You quick settings - About Chromebooks" decoding="async" loading="lazy" width="1200" height="675" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285.jpg" alt="Material You Quick Settings in ChromeOS 114" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285.jpg 1200w,https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285-300x169.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285-150x84.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285-768x432.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285.jpg" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285.jpg 1200w,https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285-300x169.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285-150x84.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/02/Material-You-quick-settings-e1676301492285-768x432.jpg 768w"></figure><h2>ChromeOS runs on Linux</h2><p>Going back to ChromeOS and the underlying system software for a second, it’s Linux. Google uses a customized version of Linux that you never see. Well, unless you turn on the Linux container, which gets you Debian Linux and a Terminal. Even though you can install Linux desktop applications for that container, you can’t use it to modify the Linux code that runs ChromeOS.</p><p>So it’s a bit locked down, particuarly compared to regular Linux. When I use Pop OS! for example, I have total control to change just about anything I want to.</p><p>Here’s a look at how I typically use that Linux machine on an ultra-wide monitor:</p><p><span data-ez-name="aboutchromebooks_com-box-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=189&amp;impression_group_id=aboutchromebooks_com-box-4/2023-10-05/5772599447941272&amp;ad_size=250x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><figure><img title="IMG_2360 - About Chromebooks" decoding="async" loading="lazy" width="1280" height="960" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-1280x960.jpg" alt="" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-1280x960.jpg 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-300x225.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-150x113.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-768x576.jpg 768w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-1536x1152.jpg 1536w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-2048x1536.jpg 2048w" sizes="(max-width: 1280px) 100vw, 1280px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-1280x960.jpg" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-1280x960.jpg 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-300x225.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-150x113.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-768x576.jpg 768w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-1536x1152.jpg 1536w,https://www.aboutchromebooks.com/wp-content/uploads/2023/10/IMG_2360-2048x1536.jpg 2048w"></figure><p>Note that when using applications, whether it’s just one or a dozen, all of the screen is being used. That’s because Pop OS! has a feature that automatically tiles my windows. When I open an application, the system reduces the size of another app and makes room for the new one.</p><p>I like this style of window management and although it’s not quite the same, ChromeOS does offer a bit of this. That’s the feature when you <a href="https://www.aboutchromebooks.com/news/chromeos-115-release-adds-several-new-chromebook-features/" target="_blank" rel="noopener" title="ChromeOS 115 release adds several new Chromebook features">click and hover on a window’s maximize button to select a window placement and size</a>.</p><figure><img title="ChromeOS 105 partial split - About Chromebooks" decoding="async" loading="lazy" width="1280" height="720" src="https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split.jpg" alt="ChromeOS is trying to replicate some custom Linux desktop environment features" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split.jpg 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split-300x169.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split-150x84.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split-768x432.jpg 768w" sizes="(max-width: 1280px) 100vw, 1280px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split.jpg" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split.jpg 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split-300x169.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split-150x84.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2022/07/ChromeOS-105-partial-split-768x432.jpg 768w"></figure><p>It’s not quite the same thing, of course. It is an attempt to bring some of Linux’s productivity features to ChromeOS, however.</p><p><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=190&amp;impression_group_id=aboutchromebooks_com-banner-1/2023-10-05/4765125825982371&amp;ad_size=300x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><h2>ChromeOS vs Linux</h2><p>With Google’s desktop environment and a limited but effective Linux software platform, I’ve started to question my own use of ChromeOS a little. Don’t get me wrong: ChromeOS is great at what it does. Google has smartly used Linux without scaring everyday people from using Linux. That’s a good thing.</p><p>However, my needs are changing a bit. I spend far more time in desktop applications than I used to. Most of that time is for my coding education. Yes, I do use the Linux version of Microsoft Visual Code on my Chromebook. And it works just as well as the same app on a traditional Linux or Windows machine. So I’m not giving anything up there.</p><figure><img title="Visual Studio code on Buster after Stretch restore - About Chromebooks" decoding="async" loading="lazy" width="1024" height="683" src="https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-1024x683.png" alt="ChromeOS runs Linux desktop applications just fine." data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-1024x683.png 1024w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-300x200.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-768x512.png 768w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-1536x1024.png 1536w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-2048x1365.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-1024x683.png" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-1024x683.png 1024w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-300x200.png 300w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-768x512.png 768w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-1536x1024.png 1536w,https://www.aboutchromebooks.com/wp-content/uploads/2020/03/Screenshot-2020-03-05-at-11.48.19-AM-2048x1365.png 2048w"></figure><p>No, the fact that I can run Linux applications on a Chromebook is a bonus. And it keeps me productive, even if I run into the occasional challenge or limitation.</p><p><span data-ez-name="aboutchromebooks_com-large-leaderboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=191&amp;impression_group_id=aboutchromebooks_com-large-leaderboard-2/2023-10-05/5800972367997400&amp;ad_size=250x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><p>It’s mainly the desktop environment aspect that has me using Linux more than ChromeOS lately.</p><p>That tiling window manager I mentioned is a huge part of it. I prefer to use all of a screen regardless of my computing activities. Having that happen automatically by the desktop environment is one less thing I need to do or manage.</p><p>Then there’s the customization aspect. Yes, with the Material You design, ChromeOS now sets the interface colors to correspond with or complement the colors from my desktop wallpaper. That’s nice but… it’s really just the bare minimum of customization.</p><p><span data-ez-name="aboutchromebooks_com-leader-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=192&amp;impression_group_id=aboutchromebooks_com-leader-1/2023-10-05/441610223991752&amp;ad_size=250x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><p>On my Linux machines, I’ve customized the fonts, both globally and for certain applications where I want something different than my global default. I’ve added useful widgets and Menubar applications for quick info at a glance. And I’ve created custom keyboard shortcuts for the tasks I do the most. Granted, <a href="https://www.aboutchromebooks.com/news/custom-chromebook-keyboard-shortcuts-app/" target="_blank" rel="noopener" title="There’s a new app for custom Chromebook keyboard shortcuts (Updated)">that type of customiziation is coming to ChromeOS</a>, which I appreciate.</p><figure><img title="Keyboard-shortcuts - About Chromebooks" decoding="async" loading="lazy" width="1280" height="720" src="https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-1280x720.jpg" alt="Customzied keyboard shortcuts is one of the best hidden ChromeOS features on my Chromebook." data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-1280x720.jpg 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-300x169.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-150x84.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-768x432.jpg 768w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-1536x864.jpg 1536w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts.jpg 1920w" sizes="(max-width: 1280px) 100vw, 1280px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-1280x720.jpg" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-1280x720.jpg 1280w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-300x169.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-150x84.jpg 150w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-768x432.jpg 768w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts-1536x864.jpg 1536w,https://www.aboutchromebooks.com/wp-content/uploads/2023/06/Keyboard-shortcuts.jpg 1920w"></figure><p>Effectively, I have no limitations when I use Linux. When I use ChromeOS, I am limited. By Google.</p><p>That’s not a bad thing for most people. Heck, I’d say that Google has created one of the most popularly used Linux implementations and that’s no small feat. I’m saying that the more my computing activities and preferences change, the more attractive a traditional Linux distribution is to me.</p><p><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=193&amp;impression_group_id=aboutchromebooks_com-large-mobile-banner-2/2023-10-05/1705468225922598&amp;ad_size=250x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><h2>ChromeOS should continue to embrace Linux</h2><p>I’ve said this before, both on the site and to people at Google: ChromeOS should really have some type of Linux desktop application store. Or at least a repository of Linux applications easily available from the Linux container on ChromeOS.</p><p>I get why Google pushed Android applications to ChromeOS in lieu of this. Android has a massive user base that’s familiar with the applications that run on Android phones and tablets. But after seven years of Android apps on ChromeOS, I think the net effect is negligible.</p><p>Put another way: When people ask me which Chromebook to buy for running Android apps, I tell them to reconsider the question. If the primary purpose is to run those Android apps, you’re better off using an Android phone or tablet because the software is optimized for those titles. Occasionally Android app use on a Chromebook is fine for most people but I wouldn’t say it’s a core strength of ChromeOS. It’s a bonus feature if you want to use it.</p><p><span data-ez-name="aboutchromebooks_com-leader-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=194&amp;impression_group_id=aboutchromebooks_com-leader-4/2023-10-05/6665960897927523&amp;ad_size=300x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p><figure><img title="libreoffice on a Chromebook in Linux - About Chromebooks" decoding="async" loading="lazy" width="880" height="587" src="https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux.jpg" alt="LibreOffice for Linux on" data-ezsrcset="https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux.jpg 880w,https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux-300x200.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux-768x512.jpg 768w" sizes="(max-width: 880px) 100vw, 880px" ezimgfmt="rs rscb836 src ng ngcb835 srcset" data-ezsrc="https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux.jpg" srcset="https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux.jpg 880w,https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux-300x200.jpg 300w,https://www.aboutchromebooks.com/wp-content/uploads/2021/10/libreoffice-on-a-Chromebook-in-Linux-768x512.jpg 768w"></figure><p>Linux desktop apps, however, are built to run on a…well, a desktop computer. When I run them on a Chromebook, they run well, just like they do on my Pop OS! machines. I don’t have to worry about screen sizes, touchpoints, application resizing, etc…. it all just works.</p><p>It would take a fair amount of effort for Google to curate and maintain a Linux application store or repository. And other than potential customer satisfaction, there’s little in the effort for Google. Still, I think it would have more of a positive effect on ChromeOS than Android apps will. At least in the long run.</p><p>And it just might sway me to use ChromeOS more often than Linux these days. Particularly if the desktop environment were a little less locked down too.</p><p><span data-ez-name="aboutchromebooks_com-leader-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=ecb46d62-204a-4e94-6acf-e0d78f5d4c25&amp;ad_position_id=195&amp;impression_group_id=aboutchromebooks_com-leader-2/2023-10-05/2377892291921602&amp;ad_size=300x250&amp;domain_id=82556&amp;url=https://www.aboutchromebooks.com/news/now-more-than-ever-chromeos-is-linux-with-googles-desktop-environment/"></span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Test Anything Protocol (148 pts)]]></title>
            <link>https://testanything.org/</link>
            <guid>37783025</guid>
            <pubDate>Thu, 05 Oct 2023 19:21:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://testanything.org/">https://testanything.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37783025">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          

<p>TAP, the Test Anything Protocol, is a simple text-based interface between testing modules in a test harness. It decouples the reporting of errors from the presentation of the reports.</p>

<p>One of its major uses is for noise reduction; when you have a suite of many tests, making them TAP producers and using a TAP consumer to view them helps ensures that you will see everything you need to notice and diagnose breakage without being distracted by a flood of irrelevant success messages. It can assist other forms of analysis and statistics-gathering as well.</p>

<p>TAP started life as part of the test harness for Perl but now has implementations in C, C++, Python, PHP, Perl, Java, JavaScript, Go, Rust, and others.  Consumers and producers do not have to be written in the same language to interoperate.</p>

<p>Here’s what a TAP test stream looks like:</p>

<div><pre><code>1..4
ok 1 - Input file opened
not ok 2 - First line of the input valid
ok 3 - Read the rest of the file
not ok 4 - Summarized correctly # TODO Not written yet
</code></pre></div>

<h2 id="testing-with-tap">Testing with TAP</h2>

<ul>
  <li><a href="https://testanything.org/testing-with-tap">Testing with TAP</a> - How to run TAP based tests in your language of choice</li>
</ul>

<h2 id="tap-development">TAP Development</h2>

<ul>
  <li><a href="https://testanything.org/producers.html">TAP Producers</a> - Testing tools that generate TAP output</li>
  <li><a href="https://testanything.org/consumers.html">TAP Consumers</a> - Test harnesses that read TAP</li>
  <li><a href="https://testanything.org/philosophy.html">TAP Philosophy</a> - The Tao of TAP</li>
  <li><a href="https://testanything.org/history.html">TAP History</a> - The story of TAP</li>
</ul>

<h2 id="specifications">Specifications</h2>

<ul>
  <li><a href="https://testanything.org/tap-version-14-specification.html">TAP version 14 specification</a> (Current)</li>
  <li><a href="https://testanything.org/tap-version-13-specification.html">TAP version 13 specification</a></li>
  <li><a href="https://testanything.org/tap-specification.html">TAP specification</a></li>
</ul>

<h2 id="external-resources">External Resources</h2>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Test_Anything_Protocol">Wikipedia article on TAP</a></li>
  <li><a href="http://www.reddit.com/r/testanythingprotocol">The TAP subreddit</a></li>
</ul>


          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gaia-1 a 9B parameter generative world model for autonomous driving (110 pts)]]></title>
            <link>https://wayve.ai/thinking/scaling-gaia-1/</link>
            <guid>37782670</guid>
            <pubDate>Thu, 05 Oct 2023 18:59:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wayve.ai/thinking/scaling-gaia-1/">https://wayve.ai/thinking/scaling-gaia-1/</a>, See on <a href="https://news.ycombinator.com/item?id=37782670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<article>

	<div>
		<p>3 October 2023&nbsp;&nbsp;<span>|</span>&nbsp;&nbsp;<a href="https://wayve.ai/thinking/category/research/">Research</a></p>
		


		<div>
			<p><span>In </span><span>June 2023, we <a href="https://wayve.ai/thinking/introducing-gaia1/" target="_blank" rel="noopener" data-display-type="link">unveiled GAIA-1</a></span><span> as the first proof of concept of a cutting-edge generative model for autonomous driving. We’ve spent the last few months optimising GAIA-1 to efficiently enable the ability to generate videos at higher resolution and improve the world model’s quality with larger-scale training. In this blog post, we are excited to release the technical report of GAIA-1 and the results of scaling GAIA-1 to over 9 billion parameters.</span></p>
<p><a href="https://arxiv.org/abs/2309.17080" target="_blank" rel="noopener" data-display-type="button">arXiv paper</a></p>
		</div>
		
	</div>

<img width="1920" height="1080" src="https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-1920x1080.jpg" alt="" decoding="async" fetchpriority="high" srcset="https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-1920x1080.jpg 1920w, https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-300x169.jpg 300w, https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-1024x576.jpg 1024w, https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-768x432.jpg 768w, https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-1536x864.jpg 1536w, https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-2048x1152.jpg 2048w, https://wayve.ai/wp-content/uploads/2023/09/Wayve-GAIA-1-Tech-Blog-Header-960x540.jpg 960w" sizes="(max-width: 1920px) 100vw, 1920px"><div>
	<p><strong>Montage of images from driving scenarios generated by GAIA-1</strong></p>
</div><div>
	<h2><span>Overview</span></h2>
<p><span>GAIA-1 is a cutting-edge generative world model built for autonomous driving. A world model learns representations of the environment and its future dynamics, providing a structured understanding of the surroundings that can be leveraged for making informed decisions when driving. Predicting future events is a fundamental and critical aspect of autonomous systems. Accurate future prediction enables autonomous vehicles to anticipate and plan their actions, enhancing safety and efficiency on the road. Incorporating world models into driving models yields the potential to enable them to understand human decisions better and ultimately generalise to more real-world situations.</span></p>
<p><span>GAIA-1 is a model that leverages video, text and action inputs to generate realistic driving videos and offers fine-grained control over ego-vehicle behaviour and scene features. Due to its multi-modal nature, GAIA-1 can generate videos from many prompt modalities and combinations.</span></p>
	</div><p><span>
	<img width="1920" height="1876" src="https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-1920x1876.jpg" alt="" decoding="async" srcset="https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-1920x1876.jpg 1920w, https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-300x293.jpg 300w, https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-1024x1000.jpg 1024w, https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-768x750.jpg 768w, https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-1536x1501.jpg 1536w, https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-2048x2001.jpg 2048w, https://wayve.ai/wp-content/uploads/2023/09/gaia1_prompt_types-960x938.jpg 960w" sizes="(max-width: 1920px) 100vw, 1920px">	<span>Examples of types of prompts that GAIA-1 can use to generate videos. GAIA-1 can generate videos by performing the future rollout starting from a video prompt. These future rollouts can be further conditioned on actions to influence particular behaviours of the ego-vehicle (e.g. steer left), or by text to drive a change in some aspects of the scene (e.g. change the colour of the traffic light). 

For speed and curvature, we condition GAIA-1 by passing the sequence of future speed and/or curvature values. GAIA-1 can also generate realistic videos from text prompts, or by simply drawing samples from its prior distribution (fully unconditional generation).
</span>
	</span>
</p><div>
	<p><span>GAIA-1 can generate realistic videos of driving scenes with high levels of controllability. In the example below, we see a short video generated by GAIA-1 where the model generates night-time driving data with snow on the road.</span></p>
</div><div>
	<h2><span>Model architecture and training</span></h2>
<p>The figure below depicts the general architecture of GAIA-1.</p>
	</div><p><span>
	<img width="1690" height="666" src="https://wayve.ai/wp-content/uploads/2023/09/gaia_schematic_animated_v2.gif" alt="" decoding="async">	<span>Model architecture of GAIA-1
</span>
	</span>
</p><div>
	<p>First, GAIA-1 encodes all inputs through specialised encoders for each modality (video, text, and action). These encoders project the diverse input sources into a shared representation. Text and video encoders discretise and embed the input, while scalars representing actions are independently projected to the shared representation. These encoded representations are temporally aligned to ensure they share a coherent timeline.</p>
<p>Following this alignment, the model’s core component, the world model, comes into play. The world model is an autoregressive transformer. This transformer predicts the next set of image tokens in the sequence. It achieves this by considering not only the past image tokens but also the contextual information provided by text and action tokens. This holistic approach allows the model to generate image tokens that are not only visually coherent but also aligned with the intended textual and action-based guidance. GAIA-1’s world model has 6.5 billion parameters and was trained for 15 days on 64 NVIDIA A100s.</p>
<p>Finally, the video decoder, a video diffusion model, is employed to translate these predicted image tokens back into the pixel space. The video diffusion model plays a crucial role in ensuring that the generated videos are semantically meaningful, visually accurate, and temporally consistent, enhancing the overall quality of the generated content. GAIA-1’s video decoder has 2.6 billion parameters and was trained for 15 days on 32 NVIDIA A100s.</p>
<p>GAIA-1 has more than 9 billion trainable parameters (compared to 1B parameters from the June version of GAIA-1). GAIA-1’s training dataset consists of 4,700 hours of proprietary driving data collected in London, UK, between 2019 and 2023.</p>
<h2><span>Scaling laws</span></h2>
<p><span>The way the world modelling task is formulated in GAIA-1 closely resembles the approach commonly employed in large language models (LLMs). In both cases, the task is simplified to the prediction of the next token. While this methodology is applied to video modelling within GAIA-1 rather than language, it’s worth noting that similar <a href="https://openai.com/research/gpt-4">scaling laws, akin to those observed in LLMs</a>, also apply to GAIA-1.</span></p>
<p><span>The plot below shows the scaling curve of the performance of GAIA-1’s world model. The blue points are measured validation cross-entropy of smaller variants. The total compute of the model is measured in FLOPs. By fitting a power-law curve to the data points, we managed to extrapolate the validation performance for greater compute budgets. The orange dot represents the final validation cross-entropy for the GAIA-1 world model. For comparison, the smaller version of GAIA-1 from June 2023 would lie between the final two blue points used for extrapolation. Interestingly, from our extrapolation, we conclude that there is still significant room for improvement that can be obtained by scaling data and compute.</span></p>
	</div><p><span>
	<img width="860" height="645" src="https://wayve.ai/wp-content/uploads/2023/09/predict_performance-1.png" alt="" decoding="async" srcset="https://wayve.ai/wp-content/uploads/2023/09/predict_performance-1.png 860w, https://wayve.ai/wp-content/uploads/2023/09/predict_performance-1-300x225.png 300w, https://wayve.ai/wp-content/uploads/2023/09/predict_performance-1-768x576.png 768w" sizes="(max-width: 860px) 100vw, 860px">		</span>
</p><div>
	<p><span>These scaling laws have been identified as a characteristic pattern in the performance and capabilities of large language models. Despite the shift in the domain from text-based language tasks to video modelling, GAIA-1 exhibits analogous trends. This suggests that as GAIA-1’s model size and training data scale up, its proficiency and performance in video generation tasks continue to improve, mirroring the scalability trends observed in large language models when applied to their respective domains.</span></p>
<p><span>In essence, GAIA-1’s world modelling task, focused on the next token prediction within the context of videos, shares the scaling behaviours that have become a hallmark of large language models in the realm of text and language tasks. This underscores the broader applicability of scaling principles in modern AI models across diverse domains, including autonomous driving.</span></p>
<h2><span>Improved video generation</span></h2>
<p><span>Elevating the capabilities of GAIA-1 through a comprehensive scaling strategy involving augmented image resolution, an increased number of parameters, extended training duration, and larger dataset size has resulted in a substantial and impressive improvement in video generation quality.</span></p>
<p><span>The example below shows the differences between a video generated by GAIA-1 in June 2023 and now. The videos have been generated by prompting the model to perform future video rollouts from the same video context.</span></p>
	</div>

<div>
	<p><span>We can appreciate that (i) the traffic lights are now visible in the conditioning frames, (ii) details of predicted scene elements such as vehicles and trees are much sharper, and (iii) the temporal consistency has improved.</span></p>
<h2>Emergent behaviours</h2>
<h3>Predicting diverse futures</h3>
<p><strong>Multiple ego-behaviours</strong></p>
<p>The world model can predict different plausible futures from past context video frames. In this scene, we are approaching a roundabout. The first future predicted by the world model is to go straight.</p>
	</div>

<div>
	<p><span>In this second alternative future obtained by sampling, the model predicts a right turn.</span></p>
</div>

<div>
	<p><b>Diverse traffic</b></p>
<p><span>The world model can also predict different traffic levels, including pedestrians, cyclists, motorcyclists, and oncoming traffic.</span></p>
	</div>

<div>
	<p><b>Interacting with another dynamic agent</b></p>
<p><span>The following example demonstrates that the world model can reason about interacting with other road users. In the first future (left video), the white vehicle reverses to give way to us. In the second future (right video), we give way to that vehicle and let it execute its right turn.&nbsp;</span></p>
	</div>

<div>
	<h2><span>Conditioning the world model on actions</span></h2>
<p><span>The world model can interact with its environment depending on the actions that are executed. The following video shows different possible futures conditioned on different ego trajectories.&nbsp;</span></p>
<p><span>On the left-hand side, we include mild to strong left steering followed by recovery. On the right-hand side, we include mild to strong right steering followed by recovery. These trajectories were not part of the training data and highlight the generalisation capabilities of the world model.</span></p>
	</div>

<div>
	<p><b>Reactive behaviour</b></p>
<p><span>In this example, we force the ego-vehicle to veer off its lane by doing a right steer followed by recovery. Interestingly, we observe the oncoming vehicle reacting and making a manoeuvre to avoid a collision.</span></p>
	</div>

<div>
	<h2><span>Controlling generation with text</span></h2>
<p><span>We can control aspects of the environment by prompting the world model with text.&nbsp;</span></p>
<p><b>Weather</b></p>
<p><span>In the following example, we prompt the world model to generate driving scenes with the text prompt “It is” followed by either “sunny”, “rainy”, “foggy”, or “snowy”.</span></p>
	</div>

<div>
	<p><b>Time of day/illumination</b></p>
<p><span>In the following video, we prompt the model to generate scenes with different illuminations. The prompts are “It’s daytime, we are in direct sunlight”, “The sky is grey”, “It’s twilight”, and “It’s night”. These examples illustrate the diversity of scenes GAIA-1 can generate.</span></p>
	</div>

<div>
	<h2><span>Text and action-conditioned generation</span></h2>
<p><span>It is also possible to specify the scene with text and input the actions to navigate that particular scene. In the following example, we imagine driving behind a red bus and executing the actions to overtake it.</span></p>
	</div>

<div>
	<h2><span>Generating long, diverse driving scenes</span></h2>
<p><span>GAIA-1 can generate long, diverse driving scenes entirely from imagination, as shown in the videos below. </span></p>
	</div>







<div>
	<h2><span>Conclusion</span></h2>
<p><span>GAIA-1 introduces a novel approach to generative world models in the context of autonomous driving. Our research showcases the potential of multi-modal learning, integrating video, text, and action inputs to create diverse driving scenarios. GAIA-1 stands out for its ability to provide fine-grained control over ego-vehicle behaviour and scene elements, enhancing its versatility in autonomous system development. GAIA-1 uses vector quantised representations to reframe the future prediction task into a next-token prediction problem, a technique commonly employed in Language Models (LLMs). GAIA-1 has shown promise in its ability to comprehend various aspects of the world, such as distinguishing between objects like cars, trucks, buses, pedestrians, cyclists, road layouts, buildings, and traffic lights. Additionally, GAIA-1 utilises video diffusion models to generate more visually realistic driving scenes.&nbsp;</span></p>
<p><span>The application of GAIA-1 to autonomous driving has the potential to improve how we build autonomous systems, though it is important to be aware of its current limitations. To begin, our autoregressive generation process, while highly effective, requires significant processing time, making long video generation computationally intensive. It’s worth noting that this method lends itself well to parallelisation, allowing us to generate multiple samples and thereby boost overall performance efficiency simultaneously. Additionally, our current model is primarily centred around predicting single-camera outputs, though, of course, having a comprehensive view from all surrounding angles is crucial for autonomous driving. Our future endeavours will extend our model’s capabilities to encompass this broader perspective and optimise its inference efficiency. This evolution promises to make our technology even more applicable and effective.</span></p>
<p><b>By incorporating world models into driving models, we can enable them to better understand their own decisions and ultimately generalise to more real-world situations. Furthermore, GAIA-1 can also serve as a valuable neural simulator, allowing us to generate unlimited data for training and validating autonomous driving systems.</b></p>
<p><a href="https://arxiv.org/abs/2309.17080" target="_blank" rel="noopener" data-display-type="button">arXiv paper</a></p>
	</div><div>
	<h2>Qualitative comparison with prior work</h2>
<p><span>Below we present a qualitative comparison between GAIA-1 and an array of other methods that are based on either GANs, diffusion models, or transformer architectures.</span></p>
	</div><div>
	<h3><span>References</span></h3>
<p><b>DriveGAN</b><span><br>
</span><i><span>S. W. Kim, J. Philion, A. Torralba, and S. Fidler. “DriveGAN: Towards a Controllable High-Quality Neural Simulation”, CVPR 2021.</span></i></p>
<p><b>Video Diffusion Models</b><span><br>
</span><i><span>J. Ho, T. Salimans, A. Gritsenko, W. Chan, M. Norouzi, and D. J. Fleet. “Video Diffusion Models”, arXiv preprint 2022.</span></i><i><span><br>
</span></i><span><br>
</span><b>Flexible Diffusion Models</b><span><br>
</span><i><span>W. Harvey, S. Naderiparizi, V. Masrani, C. Weilbach, and F. Wood. “Flexible Diffusion Modeling of Long Videos”, NeurIPS 2022.</span></i></p>
<p><b>Imagen Video</b><span><br>
</span><i><span>J. Ho, W. Chan, C. Saharia, J. Whang, R. Gao, A. Gritsenko, D. P. Kingma, B. Poole, M. Norouzi, D. J. Fleet, and T. Salimans. “Imagen Video: High Definition Video Generation with Diffusion Models”, arXiv preprint 2022.</span></i></p>
<p><b>MAGVIT</b><span><br>
</span><i><span>L. Yu, Y. Cheng, K. Sohn, J. Lezama, H. Zhang, H. Chang, A. G. Hauptmann, M.-H. Yang, Y. Hao, I. Essa, and L. Jiang. “MAGVIT: Masked Generative Video Transformer”, CVPR 2023.</span></i></p>
<p><b>Phenaki</b><span><br>
</span><i><span>R. Villegas, M. Babaeizadeh, P.-J. Kindermans, H. Moraldo, H. Zhang, M. T. Saffar, S. Castro, J. Kunze, and D. Erhan. “Phenaki: Variable Length Video Generation From Open Domain Textual Description”, ICLR 2023.</span></i></p>
<p><b>Align your latents</b><span><br>
</span><i><span>A. Blattmann, R. Rombach, H. Ling, T. Dockhorn, S. W. Kim, S. Fidler, and K. Kreis. “Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models”, CVPR 2023.</span></i></p>
<p><b>DriveDreamer</b><b><br>
</b><i><span>X. Wang, Z. Zhu, G. Huang, X. Chen, and J. Lu. “DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving”, arXiv preprint 2023.</span></i></p>
<p><b>Gen2</b><span><br>
</span><i><span>Runway. “Gen-2: The Next Step Forward for Generative AI”, 2023. </span></i><a href="https://research.runwayml.com/gen2"><i><span>https://research.runwayml.com/gen2</span></i></a><i><span>.</span></i></p>
	</div>
<div>
					<div>
				<p><a href="https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/"><img width="512" height="391" src="https://wayve.ai/wp-content/uploads/2023/07/Wayve-LINGO-1-Blog-Header-Image-512x391.jpg" alt="Wayve Lingo, open-loop driving commentator" decoding="async"></a></p><p>14 September 2023&nbsp;&nbsp;<span>|</span>&nbsp;&nbsp;<a href="https://wayve.ai/thinking/category/research/">Research</a></p>
				<div>
					<h3><a href="https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/">LINGO-1: Exploring Natural Language for Autonomous Driving</a></h3>
					<p>At Wayve, we are using natural language to enhance the learning and explainability of our foundation driving models. Learn about LINGO, an open-loop driving commentator that combines vision, language and action to enhance how we interpret, explain and train our foundation driving models.</p>
					<p><a href="https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/">Read more</a>
				</p></div>
			</div>

				<div>
				<p><a href="https://wayve.ai/thinking/introducing-gaia1/"><img width="512" height="391" src="https://wayve.ai/wp-content/uploads/2023/06/GAIA-1-tile_montage_txt-512x391.jpg" alt="" decoding="async"></a></p><p>17 June 2023&nbsp;&nbsp;<span>|</span>&nbsp;&nbsp;<a href="https://wayve.ai/thinking/category/research/">Research</a></p>
				<div>
					<h3><a href="https://wayve.ai/thinking/introducing-gaia1/">Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy</a></h3>
					<p>GAIA-1 is a new generative AI research model that creates realistic driving videos and offers fine-grained control over ego-vehicle behaviour and driving scene features by leveraging video, text and action inputs. Ideal for research, simulation, and training purposes, it provides endless possibilities for innovation in autonomy.</p>
					<p><a href="https://wayve.ai/thinking/introducing-gaia1/">Read more</a>
				</p></div>
			</div>

				

	
	</div>






</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I’m not a programmer, and I used AI to build my first bot (161 pts)]]></title>
            <link>https://blog.replit.com/building-my-first-slack-bot</link>
            <guid>37782626</guid>
            <pubDate>Thu, 05 Oct 2023 18:57:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.replit.com/building-my-first-slack-bot">https://blog.replit.com/building-my-first-slack-bot</a>, See on <a href="https://news.ycombinator.com/item?id=37782626">Hacker News</a></p>
Couldn't get https://blog.replit.com/building-my-first-slack-bot: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: An app store just for installable web apps (431 pts)]]></title>
            <link>https://store.app</link>
            <guid>37782513</guid>
            <pubDate>Thu, 05 Oct 2023 18:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://store.app">https://store.app</a>, See on <a href="https://news.ycombinator.com/item?id=37782513">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How fast are Linux pipes anyway? (2022) (456 pts)]]></title>
            <link>https://mazzo.li/posts/fast-pipes.html</link>
            <guid>37782493</guid>
            <pubDate>Thu, 05 Oct 2023 18:49:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mazzo.li/posts/fast-pipes.html">https://mazzo.li/posts/fast-pipes.html</a>, See on <a href="https://news.ycombinator.com/item?id=37782493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">



<div>
<p>In this post, we will explore how Unix pipes are implemented in Linux by iteratively optimizing a test program that writes and reads data through a pipe.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>We will begin with a simple program with a throughput of around 3.5GiB/s, and improve its performance twentyfold. The improvements will be informed by profiling the program using Linux’s <a href="https://en.wikipedia.org/wiki/Perf_(Linux)"><code>perf</code> tooling</a>.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> The code <a href="https://github.com/bitonic/pipes-speed-test">is available on GitHub</a>.</p>
<div>
<figure>
<img src="https://mazzo.li/assets/images/fast-pipe-chart.svg" alt="Chart showing the performance of our pipe test programs.">

</figure>
</div>
<!--
This exercise won't be of much practical use --- we shouldn't be using pipes for high-performance inter-process communication anyway. However, it will shed some light on common themes when dealing with IO and the kernel, and on how one can go about identifying what's slow.
-->
<p>The post was inspired by reading <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">a highly optimized FizzBuzz program</a>, which pushes output to a pipe at a rate of ~35GiB/s on my laptop.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> Our first goal will be to match that speed, explaining every step as we go along. We’ll also add an additional performance-improving measure, which is not needed in FizzBuzz since the bottleneck is actually computing the output, not IO, at least on my machine.</p>
<p>We will proceed as follows:</p>
<ol type="1">
<li><a href="#first-version">A first slow version of our pipe test bench;</a></li>
<li><a href="#trouble-with-write">How pipes are implemented internally, and why writing and reading from them is slow;</a></li>
<li><a href="#splicing">How the <code>vmsplice</code> and <code>splice</code> syscalls let us get around some (but not all!) of the slowness;</a></li>
<li><a href="#paging">A description of Linux paging, leading up to a faster version using huge pages;</a></li>
<li><a href="#busy-loop">The final optimization, replacing polling with busy looping;</a></li>
<li><a href="#closing-thoughts">Some closing thoughts.</a></li>
</ol>
<p>Section 4 is the heaviest on Linux kernel internals, so it might be interesting even if you’re familiar with the other topics treated in the post. For readers not familiar with the topics treated, only basic knowledge of C is assumed.</p>
<p>Let’s begin!</p>
</div>
<section role="doc-endnotes">
<ol>
<li id="fn1" role="doc-endnote"><p>This will be similar in style to my <a href="https://mazzo.li/posts/vectorized-atan2.html"><code>atan2f</code> performance investigation</a>, although the program in question will only be useful for learning.</p>
<p>Moreover, we will optimize code at a different level. While tuning <code>atan2f</code> consisted in micro-optimizations guided by the assembly output, tuning our pipe program will involve looking at <code>perf</code> events and reducing various sorts of kernel overhead.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The tests were run on an Intel Skylake i7-8550U CPU, and on Linux 5.17.</p>
<p>Your mileage <em>will</em> vary, since the Linux internals that power the programs described in this post have been under constant change for the past couple of years, and will probably continue to be tweaked in future releases. Keep reading for more details!<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>“FizzBuzz” is an allegedly common coding interview question.</p>
<p>The details are not relevant to this blog post, but they are explained in the link. I have personally never been asked it, but I have it on good authority that it does happen!<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<h2 id="first-version">The challenge, and a slow first version <a href="#first-version">#</a></h2>
<div>
<p>First of all, let’s start with measuring the performance of <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">the fabled FizzBuzz program</a>, following the rules laid down by the StackOverflow post:</p>
<pre><code>% ./fizzbuzz | pv &gt;/dev/null
 422GiB 0:00:16 [36.2GiB/s]</code></pre>
<p><code>pv</code> is “pipe viewer”, <a href="http://www.ivarch.com/programs/pv.shtml">a handy utility</a> to measure the throughput of data flowing through a pipe. So <code>fizzbuzz</code> is producing output at a rate of 36GiB/s.</p>
<p><code>fizzbuzz</code> writes the output in blocks as big as the L2 cache, to strike a good balance between cheap access to memory and minimizing IO overhead.</p>
</div>
<div>
<p>On my machine, the L2 cache is 256KiB. Throughout this post, we’ll also output blocks of 256KiB, but without “computing” anything. Essentially, we’ll try to measure the upper bound for programs writing to a pipe with a reasonable buffer size.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>While <code>fizzbuzz</code> uses <code>pv</code> to measure speed, our setup will be slightly different: we’ll implement the programs on both ends of the pipe. This is so that we fully control the code involved in pushing and pulling data from the pipe.</p>
</div>
<section role="doc-endnotes">
<ol start="4">
<li id="fn4" role="doc-endnote"><p>While we fix the buffer size, the numbers are actually not wildly different if we use different buffer sizes, given that other bottlenecks kick in.<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div>
<p>The code is available <a href="https://github.com/bitonic/pipes-speed-test">in my <code>pipes-speed-test</code> repo</a>. <code>write.cpp</code> implements the writing, and <code>read.cpp</code> the reading. <code>write</code> repeatedly writes the same 256KiB forever. <code>read</code> reads through 10GiB of data and terminates, printing the throughput in GiB/s. Both executables accept a variety of command line options to change their behavior.</p>
<p>The first attempt at reading and writing from pipes will be using the <a href="https://linux.die.net/man/2/write"><code>write</code></a> and <a href="https://linux.die.net/man/2/read"><code>read</code></a> syscalls, using the same buffer size as <code>fizzbuzz</code>. Here’s a view of the writing end:</p>
</div>
<div id="cb2"><pre><code><span id="cb2-1"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb2-2">  <span>size_t</span> buf_size <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>18</span><span>;</span> <span>// 256KiB</span></span>
<span id="cb2-3">  <span>char</span><span>*</span> buf <span>=</span> <span>(</span><span>char</span><span>*)</span> malloc<span>(</span>buf_size<span>);</span></span>
<span id="cb2-4">  memset<span>((</span><span>void</span><span>*)</span>buf<span>,</span> <span>'X'</span><span>,</span> buf_size<span>);</span> <span>// output Xs</span></span>
<span id="cb2-5">  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span></span>
<span id="cb2-6">    <span>size_t</span> remaining <span>=</span> buf_size<span>;</span></span>
<span id="cb2-7">    <span>while</span> <span>(</span>remaining <span>&gt;</span> <span>0</span><span>)</span> <span>{</span></span>
<span id="cb2-8">      <span>// Keep invoking `write` until we've written the entirety</span></span>
<span id="cb2-9">      <span>// of the buffer. Remember that write returns how much</span></span>
<span id="cb2-10">      <span>// it could write into the destination -- in this case,</span></span>
<span id="cb2-11">      <span>// our pipe.</span></span>
<span id="cb2-12">      <span>ssize_t</span> written <span>=</span> write<span>(</span></span>
<span id="cb2-13">        STDOUT_FILENO<span>,</span> buf <span>+</span> <span>(</span>buf_size <span>-</span> remaining<span>),</span> remaining</span>
<span id="cb2-14">      <span>);</span></span>
<span id="cb2-15">      remaining <span>-=</span> written<span>;</span></span>
<span id="cb2-16">    <span>}</span></span>
<span id="cb2-17">  <span>}</span></span>
<span id="cb2-18"><span>}</span></span></code></pre></div>
<div>
<p>This snippet and following ones omit all error checking for brevity.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> The <code>memset</code> ensures that the output will be printable, but also plays another role, as we’ll discuss later.</p>
<p>The work is all done by the <code>write</code> call, the rest is making sure that the whole buffer is written. The read end is very similar, but <code>read</code>ing data into <code>buf</code>, and terminating when enough has been read.</p>
<p>After building, the code from the repo can be run as follows:</p>
</div>
<section role="doc-endnotes">
<ol start="5">
<li id="fn5" role="doc-endnote"><p>Feel free to refer to <a href="https://github.com/bitonic/pipes-speed-test">the repo</a> for the gory details.</p>
<p>More generally, I won’t reproduce the code verbatim here, since the details are unimportant. I will instead post snippets of code representative of what is going on.<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<pre><code>% ./write | ./read
3.7GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>We’re writing the same 256KiB buffer filled with <code>'X'</code>s 40960 times, and measuring the throughput. What’s worrying is that we’re 10 times slower than <code>fizzbuzz</code>! And we’re not doing any work, just writing bytes to the pipe.</p>
<p>It turns out that we can’t get much faster than this by using <code>write</code> and <code>read</code>.</p>
<h2 id="trouble-with-write">The trouble with <code>write</code> <a href="#trouble-with-write">#</a></h2>
<div>
<p>To find out what our program is spending time on, we can use <a href="https://en.wikipedia.org/wiki/Perf_(Linux)"><code>perf</code></a>:<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a> <a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<pre><code>% perf record -g sh -c './write | ./read'
3.2GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)
[ perf record: Woken up 6 times to write data ]
[ perf record: Captured and wrote 2.851 MB perf.data (21201 samples) ]</code></pre>
<p>The <code>-g</code> instructs perf to record call graphs: this will allow us to take a top-down look at where time is being spent.</p>
<p>We can take a look at where time is spent using <code>perf report</code>. Here is a lightly redacted excerpt, breaking down where <code>write</code> spends its time:<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<pre><code>% perf report -g --symbol-filter=write
-   48.05%     0.05%  write    libc-2.33.so       [.] __GI___libc_write
   - 48.04% __GI___libc_write
      - 47.69% entry_SYSCALL_64_after_hwframe
         - do_syscall_64
            - 47.54% ksys_write
               - 47.40% vfs_write
                  - 47.23% new_sync_write
                     - pipe_write
                        + 24.08% copy_page_from_iter
                        + 11.76% __alloc_pages
                        + 4.32% schedule
                        + 2.98% __wake_up_common_lock
                          0.95% _raw_spin_lock_irq
                          0.74% alloc_pages
                          0.66% prepare_to_wait_event
</code></pre>
<p>47% of the time is spent in <code>pipe_write</code>, which is what <code>write</code> resolves to if we’re writing to a pipe. This is not surprising — we’re spending roughly half of the time writing, and the other half reading.</p>
<p>Within <code>pipe_write</code>, 3/4 of the time is spent copying or allocating pages (<code>copy_page_from_iter</code> and <code>__alloc_pages</code>). If we already have an idea of how communication between the kernel and userspace works this might make some sense. Regardless, to fully understand what’s happening we must first understand how pipes work.</p>
</div>
<section role="doc-endnotes">
<ol start="6">
<li id="fn6" role="doc-endnote"><p>Note that here we’re profiling a shell invocation including both the pipe reading and writing — <code>perf record</code> follows all child processes by default.<a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>When profiling this program, I noticed that the <code>perf</code> output was being polluted by information from the <a href="https://facebookmicrosites.github.io/psi/docs/overview">“Pressure Stall Information” infrastructure (PSI)</a>.</p>
<p>Therefore the numbers are taken from a kernel compiled with PSI disabled. This can be achieved by putting <code>CONFIG_PSI=n</code> in the kernel build configuration. In NixOS:</p>
<pre><code>boot.kernelPatches = [{
  name = "disable-psi";
  patch = null;
  extraConfig = '' 
    PSI n 
  '';
}];</code></pre>
<p>Moreover, the kernel debug symbols must be present for <code>perf</code> to correctly show where time is spent while in syscalls. How to install the symbols varies from distro to distro. In recent NixOS versions they are installed by default.<a href="#fnref7" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>In <code>perf report</code> you can use <code>+</code> to expand a call graph, assuming you ran <code>perf record -g</code>.<a href="#fnref8" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<h3 id="what-are-pipes-made-of">What are pipes made of? <a href="#what-are-pipes-made-of">#</a></h3>
<p>The data structure holding a pipe can be found in <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/pipe_fs_i.h#L34"><code>include/linux/pipe_fs_i.h</code></a>, and the operations on it in <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c"><code>fs/pipe.c</code></a>.</p>
<p>A Linux pipe is a <a href="https://en.wikipedia.org/wiki/Circular_buffer">ring buffer</a> holding references to pages where the data is written to and read from:</p>
<p><img src="https://mazzo.li/assets/images/fast-pipes-pipe-ring.png"></p>
<p>In the image above the ring buffer has 8 slots, but we might have more or less, the default being 16. Each page is 4KiB on x86-64, but might be of different sizes on other architectures. In total, this pipe can hold at most 32KiB of data. This is a key point: every pipe has an upper bound on the total amount of data it can hold before it’s full.</p>
<p>The shaded part of the diagram represents the current pipe data, the non-shaded part the empty space in the pipe.</p>
<p>Somewhat counterintuitively, <code>head</code> stores the write-end of the pipe. That is, writers will write into the buffer pointed at by <code>head</code>, and increase <code>head</code> accordingly if they need to move onto the next buffer. Within the write buffer, <code>len</code> stores how much we’ve written in it.</p>
<p>Conversely, <code>tail</code> stores the read-end of the pipe: readers will start consuming the pipe from there. <code>offset</code> indicates where to start reading from.</p>
<p>Note that <code>tail</code> can appear <em>after</em> <code>head</code>, like in the picture, since we’re working with a circular/ring buffer. Also note that some slots might be unused when we haven’t filled the pipe completely — the <code>NULL</code> cells in the middle. If the pipe is full (no <code>NULL</code>s and no free space in the pages), <code>write</code> will block. If the pipe is empty (all <code>NULL</code>s), <code>read</code> will block.</p>
<p>Here’s an abridged version of the C data structures in <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/pipe_fs_i.h#L34"><code>pipe_fs_i.h</code></a>:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>struct</span> pipe_inode_info <span>{</span></span>
<span id="cb7-2">  <span>unsigned</span> <span>int</span> head<span>;</span></span>
<span id="cb7-3">  <span>unsigned</span> <span>int</span> tail<span>;</span></span>
<span id="cb7-4">  <span>struct</span> pipe_buffer <span>*</span>bufs<span>;</span></span>
<span id="cb7-5"><span>};</span></span>
<span id="cb7-6"></span>
<span id="cb7-7"><span>struct</span> pipe_buffer <span>{</span></span>
<span id="cb7-8">  <span>struct</span> page <span>*</span>page<span>;</span></span>
<span id="cb7-9">  <span>unsigned</span> <span>int</span> offset<span>,</span> len<span>;</span></span>
<span id="cb7-10"><span>};</span></span></code></pre></div>
<p>We’re omitting many fields here, and we’re not explainining what <code>struct page</code> contains yet, but this is the key data structure to understanding how reading and writing from a pipe happens.</p>
<h3 id="reading-and-writing-to-pipes">Reading and writing to pipes <a href="#reading-and-writing-to-pipes">#</a></h3>
<p>Let’s now go to <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L416">the definition of <code>pipe_write</code></a>, to try and make sense of the <code>perf</code> output shown before.</p>
<p>Here is a simplified explanation of how <code>pipe_write</code> works:</p>
<ol type="1">
<li>If the pipe is already full, <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L561">wait for space</a> and restart;</li>
<li>If the buffer currently pointed at by <code>head</code> has space, <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L457">fill that space first</a>;</li>
<li><a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L577">While there’s free slots</a>, and <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L542">there are remaining bytes to write</a>, <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L496">allocate new pages</a> and <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/pipe.c#L532">fill them</a>, updating <code>head</code>.</li>
</ol>
<div>
<figure>
<img src="https://mazzo.li/assets/images/write-to-pipe.svg" alt="What happens to a pipe when we write to it.">

</figure>
</div>
<div>
<p>The operations described above are protected by a lock, which <code>pipe_write</code> <a href="https://github.com/torvalds/linux/blob/2c85ebc57b3e1817b6ce1a6b703928e113a90442/fs/pipe.c#L416">acquires</a> and releases as necessary.</p>
<p><code>pipe_read</code> is the mirror image of <code>pipe_write</code>, except that we consume pages, free them when we’ve fully read them, and update <code>tail</code>.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>So, we now have a quite unpleasant picture of what is going on:</p>
<ul>
<li>We copy each page twice, once from user memory to the kernel, and back again to the kernel to user memory;</li>
<li>The copying is done one 4KiB page at a time, interspersed with other activity, such as the synchronization between read and write, and page allocation and freeing;</li>
<li>We are working with memory that might not be contiguous, since we’re constantly allocating new pages;</li>
<li>We’re acquiring and releasing the pipe lock.</li>
</ul>
<p>On this machine, sequential RAM reading clocks at around 16GiB/s:</p>
</div>
<section role="doc-endnotes">
<ol start="9">
<li id="fn9" role="doc-endnote"><p>One single “spare page” called <code>tmp_page</code> is actually kept around by <code>pipe_read</code>, and reused by <code>pipe_write</code>.</p>
<p>However, since this is always only a single page, I couldn’t leverage it to achieve higher performance given that the page reuse is counteracted by fixed overhead when calling <code>pipe_write</code> and <code>pipe_read</code>.<a href="#fnref9" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<pre><code>% sysbench memory --memory-block-size=1G --memory-oper=read --threads=1 run
...
102400.00 MiB transferred (15921.22 MiB/sec)</code></pre>
<p>Given all the fiddliness listed above, a 4x slowdown compared to single-threaded sequential RAM speed is not that surprising.</p>
<p>Tweaking the buffer size or the pipe size to reduce the amount of syscall and synchronization overhead, or tuning other parameters will not get us very far. Luckily, there is a way to get around the slowness of <code>write</code> and of <code>read</code> altogether.</p>
<h2 id="splicing">Splicing to the rescue <a href="#splicing">#</a></h2>
<p>This copying of buffers from user memory to the kernel and back is a frequent thorn in the side of people needing to do fast IO. One common solution is to just cut the kernel out of the picture and perform IO operations directly. For example we might interact directly with a network card and bypass the kernel for low-latency networking.</p>
<p>In general when we write to a socket, or a file, or in our case a pipe, we’re first writing to a buffer somewhere in the kernel, and then let the kernel do its work. In the case of pipes, the pipe <em>is</em> a series of buffers in the kernel. All this copying is undesirable if we’re in the business of performance.</p>
<div>
<p>Luckily, Linux includes system calls to speed things up when we want to move data to and from pipes, without copying. Specifically:</p>
<ul>
<li><a href="https://man7.org/linux/man-pages/man2/splice.2.html"><code>splice</code></a> moves data from a pipe to a file descriptor, and vice-versa.</li>
<li><a href="https://man7.org/linux/man-pages/man2/vmsplice.2.html"><code>vmsplice</code></a> moves data from user memory into a pipe.<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a></li>
</ul>
<p>Crucially, both operations work without copying anything.</p>
<p>Now that we know how pipes work, we can already vaguely imagine how the two operations function: they just “grab” an existing buffer from somewhere and put it into the pipe ring buffer, or the reverse, rather than allocating new pages as needed:</p>
<p><img src="https://mazzo.li/assets/images/vmsplice-intuition.svg"></p>
</div>
<section role="doc-endnotes">
<ol start="10">
<li id="fn10" role="doc-endnote"><p>Technically, <code>vmsplice</code> also supports transferring data in the other direction, although not in a useful way. As the <a href="https://man7.org/linux/man-pages/man2/vmsplice.2.html">man page</a> states:</p>
<blockquote>
<p><code>vmsplice</code> really supports true splicing only from user memory to a pipe. In the opposite direction, it actually just copies the data to user space.</p>
</blockquote>
<a href="#fnref10" role="doc-backlink">↩︎</a></li>
</ol>
</section>
<p>We’ll soon see exactly how this works.</p>
<h3 id="splicing-in-practice">Splicing in practice <a href="#splicing-in-practice">#</a></h3>
<p>Let’s replace <code>write</code> with <code>vmsplice</code>. This is the signature for <code>vmsplice</code>:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>struct</span> iovec <span>{</span></span>
<span id="cb9-2">  <span>void</span>  <span>*</span>iov_base<span>;</span> <span>// Starting address</span></span>
<span id="cb9-3">  <span>size_t</span> iov_len<span>;</span>  <span>// Number of bytes</span></span>
<span id="cb9-4"><span>};</span></span>
<span id="cb9-5"></span>
<span id="cb9-6"><span>// Returns how much we've spliced into the pipe</span></span>
<span id="cb9-7"><span>ssize_t</span> vmsplice<span>(</span></span>
<span id="cb9-8">  <span>int</span> fd<span>,</span> <span>const</span> <span>struct</span> iovec <span>*</span>iov<span>,</span> <span>size_t</span> nr_segs<span>,</span> <span>unsigned</span> <span>int</span> flags</span>
<span id="cb9-9"><span>);</span></span></code></pre></div>
<div>
<p><code>fd</code> is the target pipe, <code>struct iovec *iov</code> is an array of buffers we’ll be moving to the pipe. Note that <code>vmsplice</code> returns how much was “spliced” into the pipe, which might not be the full amount, much like how <code>write</code> returns how much was written. Remember that pipes are bounded by how many slots they have in the ring buffer, and <code>vmsplice</code> is not exempt from this restriction.</p>
<p>We also need to be a bit careful when using <code>vmsplice</code>. Since the user memory is moved to the pipe without copying, we must ensure that the read-end consumes it before we can reuse the spliced buffer.</p>
<p>For this reason <code>fizzbuzz</code> uses a double buffering scheme, which works as follows:</p>
<ol type="1">
<li>Split the 256KiB buffer in two;</li>
<li>Set the pipe size to 128KiB, this will have the effect of setting the pipe ring buffer to have 128KiB/4KiB = 32 slots;</li>
<li>Alternate between writing to the first half-buffer and using <code>vmsplice</code> to move it to the pipe and doing the same with the other half.</li>
</ol>
<p>The fact that the pipe size is set to 128KiB, and that we wait for <code>vmsplice</code> to fully output one 128KiB buffer, ensures that by the time we’re done with one iteration of <code>vmsplice</code> we <em>know</em> that the the previous buffer has been fully read — otherwise we would not have been able to fully <code>vmsplice</code> the new 128KiB buffer into the 128KiB pipe.</p>
<p>Now, we’re not actually writing anything to the buffers, but we’ll keep the double buffering scheme since a similar scheme would be required for any program actually writing content.<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<p>Our write loop now looks something like this:</p>
</div>
<section role="doc-endnotes">
<ol start="11">
<li id="fn11" role="doc-endnote"><p>Travis Downs <a href="https://news.ycombinator.com/item?id=31596169">pointed out</a> that this scheme might still be unsafe, since the page could be spliced further, therefore extending its lifetime. This problem is also present in the original FizzBuzz post.</p>
<p>It’s actually not entirely clear to me whether <code>vmsplice</code> without <code>SPLICE_F_GIFT</code> is actually unsafe — the man page for <code>vmsplice</code> implies it shouldn’t be. However, it’s definitely the case that particular care is needed to achieve zero copy piping while maintaining safety.</p>
<p>In the test program the reading end splices the pipe into <code>/dev/null</code>, so it could be that the kernel knows that the pages can be spliced without copying, but I have not verified whether this is what’s actually happening.<a href="#fnref11" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div id="cb10"><pre><code><span id="cb10-1"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb10-2">  <span>size_t</span> buf_size <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>18</span><span>;</span> <span>// 256KiB</span></span>
<span id="cb10-3">  <span>char</span><span>*</span> buf <span>=</span> malloc<span>(</span>buf_size<span>);</span></span>
<span id="cb10-4">  memset<span>((</span><span>void</span><span>*)</span>buf<span>,</span> <span>'X'</span><span>,</span> buf_size<span>);</span> <span>// output Xs</span></span>
<span id="cb10-5">  <span>char</span><span>*</span> bufs<span>[</span><span>2</span><span>]</span> <span>=</span> <span>{</span> buf<span>,</span> buf <span>+</span> buf_size<span>/</span><span>2</span> <span>};</span></span>
<span id="cb10-6">  <span>int</span> buf_ix <span>=</span> <span>0</span><span>;</span></span>
<span id="cb10-7">  <span>// Flip between the two buffers, splicing until we're done.</span></span>
<span id="cb10-8">  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span></span>
<span id="cb10-9">    <span>struct</span> iovec bufvec <span>=</span> <span>{</span></span>
<span id="cb10-10">      <span>.</span>iov_base <span>=</span> bufs<span>[</span>buf_ix<span>],</span></span>
<span id="cb10-11">      <span>.</span>iov_len <span>=</span> buf_size<span>/</span><span>2</span></span>
<span id="cb10-12">    <span>};</span></span>
<span id="cb10-13">    buf_ix <span>=</span> <span>(</span>buf_ix <span>+</span> <span>1</span><span>)</span> <span>%</span> <span>2</span><span>;</span></span>
<span id="cb10-14">    <span>while</span> <span>(</span>bufvec<span>.</span>iov_len <span>&gt;</span> <span>0</span><span>)</span> <span>{</span></span>
<span id="cb10-15">      <span>ssize_t</span> ret <span>=</span> vmsplice<span>(</span>STDOUT_FILENO<span>,</span> <span>&amp;</span>bufvec<span>,</span> <span>1</span><span>,</span> <span>0</span><span>);</span></span>
<span id="cb10-16">      bufvec<span>.</span>iov_base <span>=</span> <span>(</span><span>void</span><span>*)</span> <span>(((</span><span>char</span><span>*)</span> bufvec<span>.</span>iov_base<span>)</span> <span>+</span> ret<span>);</span></span>
<span id="cb10-17">      bufvec<span>.</span>iov_len <span>-=</span> ret<span>;</span></span>
<span id="cb10-18">    <span>}</span></span>
<span id="cb10-19">  <span>}</span></span>
<span id="cb10-20"><span>}</span></span></code></pre></div>
<p>Here are the results writing with <code>vmsplice</code>, rather than <code>write</code>:</p>
<pre><code>% ./write --write_with_vmsplice | ./read
12.7GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>This reduces by half the amount of copying we need to do, and already improves our througput more than threefold — to 12.7GiB/s. Changing the read end to use <code>splice</code>, we eliminate all copying, and get another 2.5x speedup:</p>
<pre><code>% ./write --write_with_vmsplice | ./read --read_with_splice
32.8GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<h2 id="paging">Fishing for pages <a href="#paging">#</a></h2>
<p>What next? Let’s ask <code>perf</code>:</p>
<pre><code>% perf record -g sh -c './write --write_with_vmsplice | ./read --read_with_splice'
33.4GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.305 MB perf.data (2413 samples) ]
% perf report --symbol-filter=vmsplice
-   49.59%     0.38%  write    libc-2.33.so       [.] vmsplice
   - 49.46% vmsplice
      - 45.17% entry_SYSCALL_64_after_hwframe
         - do_syscall_64
            - 44.30% __do_sys_vmsplice
               + 17.88% iov_iter_get_pages
               + 16.57% __mutex_lock.constprop.0
                 3.89% add_to_pipe
                 1.17% iov_iter_advance
                 0.82% mutex_unlock
                 0.75% pipe_lock
        2.01% __entry_text_start
        1.45% syscall_return_via_sysret</code></pre>
<div>
<p>The lion’s share of the time is taken by locking the pipe for writing (<code>__mutex_lock.constprop.0</code>), and by moving the pages into the pipe (<code>iov_iter_get_pages</code>). There isn’t so much we can do about the locking, but we <em>can</em> improve the performance of <code>iov_iter_get_pages</code>.</p>
<p>As the name suggests, <code>iov_iter_get_pages</code> turns the <code>struct iovec</code>s we feed into <code>vmsplice</code> into <code>struct page</code>s to put into the pipe. To understand what this function actually does, and how to speed it up, we must first take a detour into how the CPU and Linux organize pages.</p>
</div>
<h3 id="a-whirlwind-tour-of-paging">A whirlwind tour of paging <a href="#a-whirlwind-tour-of-paging">#</a></h3>
<div>
<p>As you might be aware of, processes do not refer to locations in RAM directly: instead, the are assigned <em>virtual</em> memory addresses, which get resolved to <em>physical</em> addresses. This abstraction is known as <a href="https://en.wikipedia.org/wiki/Virtual_memory"><em>virtual memory</em></a>, and has all sorts of advantages we won’t cover here — the most obvious being that it significantly simplifies running multiple processes competing for the same physical memory.</p>
<p>In any case, whenever we execute a program and we load/store from/to memory, the CPU needs to convert our virtual address to a physical address. Storing a mapping from every virtual address to every corresponding physical address would be impratical. Therefore memory is split up in uniformly sized chunks, called <em>pages</em>, and virtual pages are mapped to physical pages:<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<p><img src="https://mazzo.li/assets/images/virtual-phsyical.svg"></p>
<p>There’s nothing special about 4KiB: each architecture picks a size, based on various tradeoffs — some of which we’ll soon explore.</p>
<p>To make this a bit more precise, let’s imagine allocating 10000 bytes using <code>malloc</code>:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>void</span><span>*</span> buf <span>=</span> malloc<span>(</span><span>10000</span><span>);</span></span>
<span id="cb14-2">printf<span>(</span><span>"%p</span><span>\n</span><span>"</span><span>,</span> buf<span>);</span>          <span>// 0x6f42430</span></span></code></pre></div>
</div>
<section role="doc-endnotes">
<ol start="12">
<li id="fn12" role="doc-endnote"><p>Here we’re presenting a simplified model where physical memory is a simple flat, linear sequence. Reality is <a href="https://lwn.net/Articles/789304/">a bit more complicated</a>, but the simple model will do for our purposes.<a href="#fnref12" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div>
<p>As we use them, our 10k bytes will look contiguous in virtual memory, but will be mapped to 3 not necessarily contiguous physical pages:<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p><img src="https://mazzo.li/assets/images/example-allocation.svg"></p>
</div>
<section role="doc-endnotes">
<ol start="13">
<li id="fn13" role="doc-endnote"><p>You can inspect the physical address assigned to the current process’ virtual pages by reading <code>/proc/self/pagemap</code>, <a href="https://mazzo.li/posts/check-huge-page.html">as illustrated in a previous post on this blog</a>, and multiplying the “page frame number” by the page size.<a href="#fnref13" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div>
<p>One of the tasks of the kernel is to manage this mapping, which is embodied in a data structure called the <em>page table</em>. The CPU specifies how the page table looks (since it needs to understand it), and the kernel manipulates it as needed. On x86-64 the page table is a 4-level, 512-way tree, which itself lives in memory.<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a> Each node of this tree is (you guessed it!) 4KiB wide, with each entry within the node leading to the next level being 8 bytes (4KiB/8bytes = 512). The entries contain the address of the next node, along with other metadata.</p>
<p>We have one page table per process — or in other words, each process has a reserved virtual address space. When the kernel context-switches to a process, it sets the special register CR3 to the <em>physical</em> address of the root of this tree.<a href="#fn15" id="fnref15" role="doc-noteref"><sup>15</sup></a> Then whenever a virtual address needs to be converted to a physical address, the CPU splits up the address in sections, and uses them to walk this tree and compute the physical address.</p>
<p>To make these concepts less abstract, here’s a visual depiction of how the virtual address <code>0x0000f2705af953c0</code> might be resolved to a physical address:</p>
<p><img src="https://mazzo.li/assets/images/virtual-address-resolution.svg"></p>
</div>
<section role="doc-endnotes">
<ol start="14">
<li id="fn14" role="doc-endnote"><p>Intel extended the page table to consist of <a href="https://en.wikipedia.org/wiki/Intel_5-level_paging">5 levels</a> starting from Ice Lake, thereby increasing the maximum addressable memory from 256TiB to 128PiB. However this capability has to explicitly enabled, since some programs rely on the upper 16 bits of pointers to be unused.<a href="#fnref14" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>The addresses within the page table must be physical, otherwise we’d have infinite loop on our hands.<a href="#fnref15" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div>
<p>The search starts from the first level, called the “page global directory”, or PGD, the physical location of which is stored in CR3. The first 16 bits of the address are unused.<a href="#fn16" id="fnref16" role="doc-noteref"><sup>16</sup></a> We use the next 9 bits the PGD entry, and traverse down to the second level, “page upper directory”, or PUD. The next 9 bits are used to select an entry from the PUD. The process repeats for the next two levels, PMD (“page middle directory”), and PTE (“page table entry”). The PTE tells where the actual physical page we’re looking for is, and then we use the last 12 bits to find the offset inside the page.</p>
<p>The sparse structure of the page table allows the mapping to be gradually built up as new pages are needed. Whenever a process needs memory, the page table will be updated with a new entry by the kernel.</p>
</div>
<section role="doc-endnotes">
<ol start="16">
<li id="fn16" role="doc-endnote"><p>Note that the highest 16 bits are unused: this means that each process can address at most <span>2^{48}-1</span> bytes, or 256TiB, of physical memory.<a href="#fnref16" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<h3 id="the-role-of-struct-page">The role of <code>struct page</code> <a href="#the-role-of-struct-page">#</a></h3>
<div>
<p>The <code>struct page</code> data structure is a key piece of this machinery: it is what the kernel uses to refer to a single <em>physical</em> page, storing its physical address and all sorts of other metadata about it.<a href="#fn17" id="fnref17" role="doc-noteref"><sup>17</sup></a> For instance we can get a <code>struct page</code> from the information contained in the PTE (the last level of the page table described above). In general it is used pervasively in all code handling page-related matters.</p>
<p>In the case of pipes, <code>struct page</code> is used to hold their data in the ring buffer, as we’re already seen:</p>
<div id="cb15"><pre><code><span id="cb15-1"><span>struct</span> pipe_inode_info <span>{</span></span>
<span id="cb15-2">  <span>unsigned</span> <span>int</span> head<span>;</span></span>
<span id="cb15-3">  <span>unsigned</span> <span>int</span> tail<span>;</span></span>
<span id="cb15-4">  <span>struct</span> pipe_buffer <span>*</span>bufs<span>;</span></span>
<span id="cb15-5"><span>};</span></span>
<span id="cb15-6"></span>
<span id="cb15-7"><span>struct</span> pipe_buffer <span>{</span></span>
<span id="cb15-8">  <span>struct</span> page <span>*</span>page<span>;</span></span>
<span id="cb15-9">  <span>unsigned</span> <span>int</span> offset<span>,</span> len<span>;</span></span>
<span id="cb15-10"><span>};</span></span></code></pre></div>
</div>
<section role="doc-endnotes">
<ol start="17">
<li id="fn17" role="doc-endnote"><p><code>struct page</code> might also refer to yet-to-be-allocated physical pages, which do not have a physical address yet, and other page-related abstractions. Think of them as fairly abstract references to physical pages, but not necessarily references to an <em>allocated</em> physical page.</p>
<p>This subtle point will be relevant in a later sidenote 🫠.<a href="#fnref17" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<p>However, <code>vmsplice</code> accepts <em>virtual</em> memory as input, while <code>struct page</code> refers to <em>physical</em> memory directly.</p>
<p>Therefore we need turn arbitrary chunks of virtual memory into a bunch of <code>struct page</code>s. This is exactly what <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/lib/iov_iter.c#L1518"><code>iov_iter_get_pages</code></a> does, and where we’re spending half of our time:</p>
<div id="cb16"><pre><code><span id="cb16-1"><span>ssize_t</span> iov_iter_get_pages<span>(</span></span>
<span id="cb16-2">  <span>struct</span> iov_iter <span>*</span>i<span>,</span>  <span>// input: a sized buffer in virtual memory</span></span>
<span id="cb16-3">  <span>struct</span> page <span>**</span>pages<span>,</span> <span>// output: the list of pages which back the input buffers</span></span>
<span id="cb16-4">  <span>size_t</span> maxsize<span>,</span>      <span>// maximum number of bytes to get</span></span>
<span id="cb16-5">  <span>unsigned</span> maxpages<span>,</span>   <span>// maximum number of pages to get</span></span>
<span id="cb16-6">  <span>size_t</span> <span>*</span>start        <span>// offset into first page, if the input buffer wasn't page-aligned</span></span>
<span id="cb16-7"><span>);</span></span></code></pre></div>
<p><code>struct iov_iter</code> is a Linux kernel data structure representing various ways of walking through chunks of memory, including <code>struct iovec</code>. In our case, it will point to a 128KiB buffer. <code>vmsplice</code> will use <code>iov_iter_get_pages</code> to turn the input buffer into a bunch of <code>struct page</code>s, and hold on to them. Now that you know how paging works, you might vaguely imagine how <code>iov_iter_get_pages</code> works as well, but we’ll explain it in detail in the next section.</p>
<p>We’ve rapidly gone through a lot of new concepts, so to recap:</p>
<ul>
<li>Modern CPUs use virtual memory for their processes;</li>
<li>Memory is organized in regularly-sized pages;</li>
<li>The CPU translates virtual addresses into physical addresses using a page table mapping virtual pages to physical pages;</li>
<li>The kernel adds and removes entries to the page table as necessary;</li>
<li>Pipes are made out of references to physical pages, so <code>vmsplice</code> must convert virtual memory ranges into physical pages, and hold on to them.</li>
</ul>
<h3 id="the-cost-of-getting-pages">The cost of getting pages <a href="#the-cost-of-getting-pages">#</a></h3>
<div>
<p>The time spent in <code>iov_iter_get_pages</code> is really entirely spent in another function, <code>get_user_pages_fast</code>:</p>
<pre><code>% perf report -g --symbol-filter=iov_iter_get_pages
-   17.08%     0.17%  write    [kernel.kallsyms]  [k] iov_iter_get_pages
   - 16.91% iov_iter_get_pages
      - 16.88% internal_get_user_pages_fast
           11.22% try_grab_compound_head
</code></pre>
<p><a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/mm/gup.c#L2944"><code>get_user_pages_fast</code></a> is a more bare-bones version of <code>iov_iter_get_pages</code>:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>int</span> get_user_pages_fast<span>(</span></span>
<span id="cb18-2">  <span>// virtual address, page aligned</span></span>
<span id="cb18-3">  <span>unsigned</span> <span>long</span> start<span>,</span></span>
<span id="cb18-4">  <span>// number of pages to retrieve</span></span>
<span id="cb18-5">  <span>int</span> nr_pages<span>,</span></span>
<span id="cb18-6">  <span>// flags, the meaning of which we won't get into</span></span>
<span id="cb18-7">  <span>unsigned</span> <span>int</span> gup_flags<span>,</span></span>
<span id="cb18-8">  <span>// output physical pages</span></span>
<span id="cb18-9">  <span>struct</span> page <span>**</span>pages</span>
<span id="cb18-10"><span>)</span></span></code></pre></div>
<p>Here “user” (as opposed to “kernel”) refers to the fact that we’re turning virtual pages into references to physical pages.</p>
<p>To get our <code>struct page</code>s, <code>get_user_pages_fast</code> does exactly what the CPU would do, but in software: it walks the page table to collect all the physical pages, storing the results in <code>struct page</code>s. In our case, we have a 128KiB buffer, and 4KiB pages, so we’ll have <code>nr_pages = 32</code>.<a href="#fn18" id="fnref18" role="doc-noteref"><sup>18</sup></a> <code>get_user_pages_fast</code> will need to walk the page table tree collecting 32 leaves, and storing the result in 32 <code>struct page</code>s.</p>
<p><code>get_user_pages_fast</code> also needs to make sure that the physical page is not repurposed until the caller doesn’t need it anymore. This is achieved in the kernel using a reference count <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/mm_types.h#L187">stored in <code>struct page</code></a>, which is used to know when a physical page can be released and repurposed in the future. The caller of <code>get_user_pages_fast</code> must, at some point, release the pages again with <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/include/linux/mm.h#L1222"><code>put_page</code></a>, which will decrease the reference count.</p>
<p>Finally, <code>get_user_pages_fast</code> behaves differently depending on whether virtual addresses are already in the page table. This is where the <code>_fast</code> suffix comes from: the kernel will first try to get an already existing page table entry and corresponding <code>struct page</code> by just walking the page table, which is relatively cheap, and fall back to producing a <code>struct page</code> by other, more expensive means otherwise. The fact that we <code>memset</code> the memory at the beginning will ensure that we never end up in the “slow” path of <code>get_user_pages_fast</code>, since the page table entries will be created as our buffer is filled with <code>'X'</code>s.<a href="#fn19" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
<p>Note that the <code>get_user_pages</code> family of functions is not only useful for pipes — in fact, it is central in many drivers. A typical use is related to the kernel bypass we mentioned: a driver for a network card might use it to turn some user memory region into a physical page, then communicate the physical page location to the network card, and have the network card interact directly with that memory region without kernel involvement.</p>
</div>
<section role="doc-endnotes">
<ol start="18">
<li id="fn18" role="doc-endnote"><p>Actually, the pipe code <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/fs/splice.c#L1174">happens to always call <code>get_user_pages_fast</code> with <code>nr_pages = 16</code></a>, looping if necessary, presumably so that a small static buffer can be used. But it is an implementation detail, and the total number of spliced pages will still be 32.<a href="#fnref18" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>Subtleties follow, not needed to understand the rest of the post!</p>
<p>If the page table does not contain the entry we’re looking for, <code>get_user_pages_fast</code> still needs to return a <code>struct page</code>. The most obvious way to do so would be to create the right page table entry, and then return the corresponding <code>struct page</code>.</p>
<p>However <code>get_user_pages_fast</code> will only do so if it’s asked to get <code>struct page</code> for the purpose of writing into it. Otherwise it will <em>not</em> update the page table, instead returning a <code>struct page</code> giving us a reference to a yet-to-be-allocated physical page. This is exactly what happens in the case of <code>vmsplice</code>, since we just need to produce a <code>struct page</code> for the purpose of filling the pipe, without actually writing any memory.</p>
<p>Or in other words, allocating the page is delayed until we actually need to. This saves allocating the physical page, but will cause the slow path of <code>get_user_pages_fast</code> to be called repeatedly if the page is never faulted in by other means.</p>
<p>Therefore, if we do <em>not</em> <code>memset</code> before, and therefore do not fault the pages into the page table “manually”, not only we would end up in the slow path the first time we call <code>get_user_pages_fast</code>, but also all successive invocations, resulting in a significant slowdown (25GiB/s rather than 30GiB/s):</p>
<pre><code>% ./write --write_with_vmsplice --dont_touch_pages | ./read --read_with_splice
25.0GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>Moreover, this behavior does <em>not</em> manifest itself when using huge pages: in that case <code>get_user_pages_fast</code> <em>will</em> properly fault the pages in when the virtual memory range passed in would be backed by huge pages.</p>
<p>If this is all very confusing, don’t worry, <code>get_user_pages</code> and friends seem to be a very tricky corner of the kernel, <a href="https://lwn.net/Kernel/Index/#Memory_management-get_user_pages">even for</a> <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/Documentation/core-api/pin_user_pages.rst">kernel developers</a>.<a href="#fnref19" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<h3 id="huge-pages">Huge pages <a href="#huge-pages">#</a></h3>
<div>
<p>Up to now we’ve presented pages as always being of the same size — 4KiB on x86-64. However, many CPU architectures, including x86-64, include larger page sizes. In the case of x86-64, we not only have 4KiB pages (the “standard” size), but also 2MiB and even 1GiB pages (“huge” pages). In the rest of the post we’ll only deal with 2MiB huge pages, since 1GiB pages are fairly uncommon, and overkill for our task anyway.</p>
<div>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Smallest page size</th>
<th>Larger page sizes</th>
</tr>
</thead>
<tbody>
<tr>
<td>x86</td>
<td>4KiB</td>
<td>2MiB, 4MiB</td>
</tr>
<tr>
<td>x86-64</td>
<td>4KiB</td>
<td>2MiB, 1GiB<a href="#fn20" id="fnref20" role="doc-noteref"><sup>20</sup></a></td>
</tr>
<tr>
<td>ARMv7</td>
<td>4KiB</td>
<td>64KiB, 1MiB, 16MiB</td>
</tr>
<tr>
<td>ARMv8</td>
<td>4KiB</td>
<td>16KiB, 64KiB</td>
</tr>
<tr>
<td>RISCV32</td>
<td>4KiB</td>
<td>4MiB</td>
</tr>
<tr>
<td>RISCV64</td>
<td>4KiB</td>
<td>2MiB, 1GiB, 512GiB, 256 TiB</td>
</tr>
<tr>
<td>Power ISA</td>
<td>8KiB</td>
<td>64 KiB, 16 MiB, 16 GiB</td>
</tr>
</tbody>
</table>
<p><small>Page sizes available on architectures commonly used today, from <a href="https://en.wikipedia.org/wiki/Page_(computer_memory)#Multiple_page_sizes">Wikipedia</a>.</small></p>
</div>
<p>The main advantage of huge pages is that bookkeeping is cheaper, since there’s fewer of them needed to cover the same amount of memory. Moreover other operations are cheaper too, such as resolving a virtual address to a physical address, since one level less of page table is needed: instead of having a 12-bit offset into the page, we’ll have a 21-bit offset, and one less page table level.</p>
</div>
<section role="doc-endnotes">
<ol start="20">
<li id="fn20" role="doc-endnote"><p>Only when the CPU has <code>PDPE1GB</code> flag.<a href="#fnref20" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div>
<p>This relieves pressure on the parts of the CPUs that handle this conversion, leading to performance improvements in many circumstances.<a href="#fn21" id="fnref21" role="doc-noteref"><sup>21</sup></a> However, in our case, the pressure is not on the hardware that walks the page table, but on its software counterpart which runs in the kernel.</p>
<p>On Linux, we can allocate a 2MiB huge page <a href="https://mazzo.li/posts/check-huge-page.html">in a variety of ways</a>, such as by allocating memory aligned to 2MiB and then using <code>madvise</code> to tell the kernel to use huge pages for the provided buffer:</p>
<div id="cb20"><pre><code><span id="cb20-1"><span>void</span><span>*</span> buf <span>=</span> aligned_alloc<span>(</span><span>1</span> <span>&lt;&lt;</span> <span>21</span><span>,</span> size<span>);</span></span>
<span id="cb20-2">madvise<span>(</span>buf<span>,</span> size<span>,</span> MADV_HUGEPAGE<span>)</span></span></code></pre></div>
<p>Switching to huge pages in our program yields another ~50% improvement:</p>
<pre><code>% ./write --write_with_vmsplice --huge_page | ./read --read_with_splice
51.0GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
</div>
<section role="doc-endnotes">
<ol start="21">
<li id="fn21" role="doc-endnote"><p>For instance, the CPU includes dedicated hardware to cache parts of the page table, the “translation lookaside buffer” (TLB). The TLB is flushed at every context switch (every time we change the contents of CR3).</p>
<p>Huge pages can significantly reduce TLB misses, since a single entry for a 2MiB page covers 512 times more memory compared to a 4KiB page.<a href="#fnref21" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<div>
<p>However, the reason for the improvements is not totally obvious. Naively, we might think that by using huge pages <code>struct page</code> will just refer to a 2MiB page, rather than 4KiB.</p>
<p>Sadly this is <em>not</em> the case: the kernel code assumes everywhere that a <code>struct page</code> refers to a page of the “standard” size for the current architecture. The way this works for huge pages (and in general for what Linux calls “compound pages”) is that a “head” <code>struct page</code> contains the actual information about the backing physical page, with successive “tail” pages just containing a pointer to the head page.</p>
<p>So to represent 2MiB huge page we’ll have 1 “head” <code>struct page</code>, and up to 511 “tail” <code>struct page</code>s. Or in the case of our 128KiB buffer, 31 tail <code>struct page</code>s:<a href="#fn22" id="fnref22" role="doc-noteref"><sup>22</sup></a></p>
<p><img src="https://mazzo.li/assets/images/head-tail-pages.svg"></p>
<p>Even if we need all these <code>struct page</code>s, the code generating it ends up significantly faster. Instead of traversing the page table multiple times, once the first entry is found, the following <code>struct page</code>s can be <a href="https://github.com/torvalds/linux/blob/f443e374ae131c168a065ea1748feac6b2e76613/mm/gup.c#L2457">generated in a simple loop</a>. Hence the performance improvement!</p>
</div>
<section role="doc-endnotes">
<ol start="22">
<li id="fn22" role="doc-endnote"><p>If you’re thinking “that’s horrible!”, you’re not alone.</p>
<p>Various efforts are underway to simplify and/or optimize this situation.</p>
<p>Recent kernels (from 5.17 onwards) <a href="https://lwn.net/Articles/849538/">include a new type</a>, <code>struct folio</code>, identifying head pages explicitly. This reduces the need for checking whether a <code>struct page</code> is a head page or tail page at runtime, yielding performance improvements.</p>
<p><a href="https://lwn.net/Articles/839737/">Other efforts</a> aim to outright remove the extra <code>struct page</code>s, although I’m not up to date on how that is going.<a href="#fnref22" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<h2 id="busy-loop">Busy looping <a href="#busy-loop">#</a></h2>
<p>We’re almost done, I promise! Let’s look at <code>perf</code> output once again:</p>
<pre><code>-   46.91%     0.38%  write    libc-2.33.so       [.] vmsplice
   - 46.84% vmsplice
      - 43.15% entry_SYSCALL_64_after_hwframe
         - do_syscall_64
            - 41.80% __do_sys_vmsplice
               + 14.90% wait_for_space
               + 8.27% __wake_up_common_lock
                 4.40% add_to_pipe
               + 4.24% iov_iter_get_pages
               + 3.92% __mutex_lock.constprop.0
                 1.81% iov_iter_advance
               + 0.55% import_iovec
            + 0.76% syscall_exit_to_user_mode
        1.54% syscall_return_via_sysret
        1.49% __entry_text_start
</code></pre>
<p>We’re now spending a significant amount of time waiting for the pipe to be writeable (<code>wait_for_space</code>), and waking up readers which were waiting for the pipe to have content (<code>__wake_up_common_lock</code>).</p>
<p>To sidestep these synchronization costs, we can ask <code>vmsplice</code> to return if the pipe cannot be written to, and busy loop until it is — and the same when reading with <code>splice</code>:</p>
<div id="cb23"><pre><code><span id="cb23-1"><span>...</span></span>
<span id="cb23-2"><span>// SPLICE_F_NONBLOCK will cause `vmsplice` to return immediately</span></span>
<span id="cb23-3"><span>// if we can't write to the pipe, returning EAGAIN</span></span>
<span id="cb23-4"><span>ssize_t</span> ret <span>=</span> vmsplice<span>(</span>STDOUT_FILENO<span>,</span> <span>&amp;</span>bufvec<span>,</span> <span>1</span><span>,</span> SPLICE_F_NONBLOCK<span>);</span></span>
<span id="cb23-5"><span>if</span> <span>(</span>ret <span>&lt;</span> <span>0</span> <span>&amp;&amp;</span> errno <span>==</span> EAGAIN<span>)</span> <span>{</span></span>
<span id="cb23-6">  <span>continue</span><span>;</span> <span>// busy loop if not ready to write</span></span>
<span id="cb23-7"><span>}</span></span>
<span id="cb23-8"><span>...</span></span></code></pre></div>
<p>By busy looping we get another 25% performance increase:</p>
<pre><code>% ./write --write_with_vmsplice --huge_page --busy_loop | ./read --read_with_splice --busy_loop
62.5GiB/s, 256KiB buffer, 40960 iterations (10GiB piped)</code></pre>
<p>Obviously busy looping comes at the cost of fully occupying a CPU core waiting for <code>vmsplice</code> to be ready. But often this compromise is worth it, and in fact it is a common pattern for high-performance server applications: we trade off possibly wasteful CPU utilization for better latency and/or throughput.</p>
<p>In our case, this concludes our optimization journey for our little synthetic benchmark, from 3.5GiB/s to 65GiB/s.</p>
<h2 id="closing-thoughts">Closing thoughts <a href="#closing-thoughts">#</a></h2>
<p>We’ve systematically improved the performance of our program by looking at the <code>perf</code> output and the Linux source. Pipes and splicing in particular aren’t really hot topics when it comes to high-performance programming, but the themes we’ve touched upon are: zero-copy operations, ring buffers, paging &amp; virtual memory, synchronization overhead.</p>
<p>There are some details and interesting topics I left out, but this blog post was already spiraling out of control and becoming too long:</p>
<ul>
<li><p>In the actual code, the buffers are allocated separatedly, to reduce page table contention by placing them in different page table entries (something that the FizzBuzz program also does).</p>
<p>Remember that when a page table entry is taken with <code>get_user_pages</code>, its refcount is increased, and decreased on <code>put_page</code>. If we use two page table entries for the two buffers, rather than one page table entry for both of them, we have less contention when modifying the refcount.</p></li>
<li><p>The tests are ran by pinning the <code>./write</code> and <code>./read</code> processes to two cores with <code>taskset</code>.</p></li>
<li><p>The code in the repo contains many other options I played with, but did not end up talking about since they were irrelevant or not interesting enough.</p></li>
<li><p>The repo also contains <a href="https://github.com/bitonic/pipes-speed-test/blob/master/get-user-pages.cpp">a synthetic benchmark</a> for <code>get_user_pages_fast</code>, which can be used to measure exactly how much slower it runs with or without huge pages.</p></li>
<li><p>Splicing in general is a slightly dubious/<a href="https://dirtypipe.cm4all.com/">dangerous</a> concept, <a href="https://lwn.net/Articles/896267/">which continues to annoy</a> to kernel developers.</p></li>
</ul>
<p>Please let me know if this post was helpful, interesting, or unclear!</p>
<h2 id="acknowledgements">Acknowledgements <a href="#acknowledgements">#</a></h2>
<p>Many thanks to <a href="https://scvalex.net/">Alexandru Scvorţov</a>, Max Staudt, Alex Appetiti, Alex Sayers, Stephen Lavelle, Peter Cawley, and Niklas Hambüchen for reviewing drafts of this post. Max Staudt also helped me understand some subtleties of <code>get_user_pages</code>.</p>






</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. federal price tag for the post-9/11 wars is over $8T (136 pts)]]></title>
            <link>https://watson.brown.edu/costsofwar/figures/2021/BudgetaryCosts</link>
            <guid>37782218</guid>
            <pubDate>Thu, 05 Oct 2023 18:30:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://watson.brown.edu/costsofwar/figures/2021/BudgetaryCosts">https://watson.brown.edu/costsofwar/figures/2021/BudgetaryCosts</a>, See on <a href="https://news.ycombinator.com/item?id=37782218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                      <p><img src="https://watson.brown.edu/costsofwar/files/cow/imce/figures/2021/Screen%20Shot%202021-08-31%20at%202.08.46%20PM.png" width="662" height="349"></p>
<p><strong>U.S. BUDGETARY COSTS</strong>&nbsp;<span>The vast economic impact of the U.S. post-9/11 wars goes beyond the Pentagon's "Overseas Contigency Operations" (War) budget. This chart and the attached paper estimate the more comprehensive budgetary costs of the wars.</span><em> <em>Posted on September 1, 2021.</em></em></p>
<h2><a href="https://watson.brown.edu/costsofwar/figures/2021/WarDeathToll">SEE Human Costs Data</a></h2>          
                      <ul>
                                                          <li><a href="https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Costs%20of%20War_U.S.%20Budgetary%20Costs%20of%20Post-9%2011%20Wars_9.1.21.pdf">View Paper</a></li>
                          </ul>
          
                      <p><span><span>September 2021</span></span></p>
          
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP fails to derail claims that it bricks scanners on printers when ink runs low (309 pts)]]></title>
            <link>https://abcnews.go.com/Technology/wireStory/hp-fails-derail-claims-bricks-scanners-multifunction-printers-102286365</link>
            <guid>37781862</guid>
            <pubDate>Thu, 05 Oct 2023 18:03:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abcnews.go.com/Technology/wireStory/hp-fails-derail-claims-bricks-scanners-multifunction-printers-102286365">https://abcnews.go.com/Technology/wireStory/hp-fails-derail-claims-bricks-scanners-multifunction-printers-102286365</a>, See on <a href="https://news.ycombinator.com/item?id=37781862">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-testid="prism-article-body"><p><span>SAN FRANCISCO -- </span>HP has failed to shunt aside class-action legal claims that it disables the scanners on its multifunction printers when their ink runs low. Though not for lack of trying.</p><p>On Aug. 10, a federal judge ruled that HP Inc. must face a class-action lawsuit claiming that the company designs its “all-in-one” inkjet printers to disable scanning and faxing functions whenever a single printer ink cartridge runs low. The company had sought — for the second time — to dismiss the lawsuit on technical legal grounds.</p><p>“It is well-documented that ink is not required in order to scan or to fax a document, and it is certainly possible to manufacture an all-in-one printer that scans or faxes when the device is out of ink,” the plaintiffs wrote in their complaint. “Indeed, HP designs its all-in-one printer products so they will not work without ink. Yet HP does not disclose this fact to consumers.”</p><p>The lawsuit charges that HP deliberately withholds this information from consumers to boost profits from the sale of expensive ink cartridges. </p><p>Color printers require four ink cartridges -- one black and a set of three cartridges in cyan, magenta and yellow for producing colors. Some will also refuse to print if one of the color cartridges is low, even in black-and-white mode.</p><p>HP declined to comment on the issue, citing the pending litigation. The company’s court filings in the case have generally not addressed the substance of the plaintiff’s allegations.</p><p>In early 2022, U.S. District Judge Beth Labson Freeman dismissed the complaint on legal grounds but did not address the lawsuit's claims. The judge allowed the plaintiffs to amend their claim and resubmit it. On Aug. 10, the judge largely rejected HP's request to dismiss the revised complaint, allowing the case to proceed.</p><p>All-in-one inkjet printers generally seem like a bargain compared to the cost of separate devices with scanning, copying and fax functions. For instance, HP currently sells its all-in-one OfficeJet Pro 8034e online for just $159. But its least expensive standalone scanner, the ScanJet Pro s2, lists for $369 — more than twice the cost of the multifunction printer. </p><p>Of course, only one of these devices requires printer ink. “Printer ink is wildly expensive,” Consumer Reports states in its current printer buying guide, noting that consumer ink costs can easily run more than $70 a year.</p><p>Worse, a significant amount of ink is never actually used to print documents because it's consumed by printer maintenance cycles. In 2018, Consumer Reports tested hundreds of all-in-one inkjet printers and found that, when used intermittently, many models delivered less than half of their ink to printed documents. A few managed no more than 20% to 30%.</p><p>HP isn't alone in facing such legal complaints. A different set of plaintiffs sued the U.S. unit of printer and camera maker Canon Inc. in 2021 for similarly handicapping its all-in-one printers without disclosure. The parties settled that case in late 2022. Terms were not disclosed. </p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lockheed CEO Pitches Pentagon on Subscription Software (106 pts)]]></title>
            <link>https://news.usni.org/2023/10/04/lockheed-ceo-pitches-pentagon-on-subscription-software</link>
            <guid>37781735</guid>
            <pubDate>Thu, 05 Oct 2023 17:53:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.usni.org/2023/10/04/lockheed-ceo-pitches-pentagon-on-subscription-software">https://news.usni.org/2023/10/04/lockheed-ceo-pitches-pentagon-on-subscription-software</a>, See on <a href="https://news.ycombinator.com/item?id=37781735">Hacker News</a></p>
Couldn't get https://news.usni.org/2023/10/04/lockheed-ceo-pitches-pentagon-on-subscription-software: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Safety vs. Performance. A case study of C, C++ and Rust sort implementations (165 pts)]]></title>
            <link>https://github.com/Voultapher/sort-research-rs/blob/main/writeup/sort_safety/text.md</link>
            <guid>37781612</guid>
            <pubDate>Thu, 05 Oct 2023 17:44:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Voultapher/sort-research-rs/blob/main/writeup/sort_safety/text.md">https://github.com/Voultapher/sort-research-rs/blob/main/writeup/sort_safety/text.md</a>, See on <a href="https://news.ycombinator.com/item?id=37781612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:Voultapher/sort-research-rs" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="U7u_kUobEylXo0sTdDQCtWYkrYB8lolDFQmJ-fNGPMrZ9gy9H9Mq5MIaEc7aMDOWfMZEFvl9hspTRsXeV3hb2w" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="Voultapher/sort-research-rs" data-current-org="" data-current-owner="Voultapher" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=Voultapher%2Fsort-research-rs" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/Voultapher/sort-research-rs/blob/main/writeup/sort_safety/text.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="16bc9cf423b7afc00f2b133036d922a0eb602a143faeb09b02dfa67895100db6" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows Copilot's is showing third-party Ads to Windows users (179 pts)]]></title>
            <link>https://www.ghacks.net/2023/10/03/windows-copilots-is-showing-third-party-ads-to-windows-users/</link>
            <guid>37781266</guid>
            <pubDate>Thu, 05 Oct 2023 17:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ghacks.net/2023/10/03/windows-copilots-is-showing-third-party-ads-to-windows-users/">https://www.ghacks.net/2023/10/03/windows-copilots-is-showing-third-party-ads-to-windows-users/</a>, See on <a href="https://news.ycombinator.com/item?id=37781266">Hacker News</a></p>
Couldn't get https://www.ghacks.net/2023/10/03/windows-copilots-is-showing-third-party-ads-to-windows-users/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Rerun 0.9 – a framework for visualizing streams of multimodal data (103 pts)]]></title>
            <link>https://www.rerun.io/blog/release-0.9</link>
            <guid>37781244</guid>
            <pubDate>Thu, 05 Oct 2023 17:15:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rerun.io/blog/release-0.9">https://www.rerun.io/blog/release-0.9</a>, See on <a href="https://news.ycombinator.com/item?id=37781244">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><p>We’re building a fast and easy to use general framework for handling and visualizing streams of multimodal data. This is a big undertaking, and the way we’re getting there is by starting with a fast and easy to use visualizer for computer vision, and then making it more capable and extensible piece by piece.</p>
<p>Rerun 0.9.0 is released two months after 0.8.0, but it’s been even longer coming. It includes the foundation of the coming C++ SDK, our most asked for feature by far. In order to maintain great and consistent APIs across Rust, Python, C++, and any future languages, we’ve rebuilt much of Rerun's data infrastructure around a new code generation framework.</p>
<p>0.9 also adds support for logging markdown, a new in-viewer getting started experience, and as always, a bunch of performance improvements.</p>
<p><iframe src="https://player.vimeo.com/video/870834549?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1440:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<p><em>Load example recordings, including descriptions of how they were made, directly in the viewer.</em></p>
<p>This has all been a huge lift, but what I’m most excited about are our redesigned APIs and what they pave the way for in future releases.
From this release on, we’ll start to expose more and more of Rerun's underlying infrastructure, starting with the core data model, a hierarchical and time varying Entity Component System (ECS).</p>
<p>To ease the transition for Python users, we've marked the old APIs as deprecated in 0.9 with migration instructions in the warning messages. The old API will be removed completely in 0.10. Check out the <a href="https://www.rerun.io/docs/reference/migration-0-9">migration guide</a> for more details on updating your code.</p>
<h2 id="a-more-type-centric-logging-api">A more type centric logging API<!-- --> <a href="#a-more-type-centric-logging-api"></a></h2>
<p>At the heart of Rerun is the ability to handle streams of multimodal data, e.g. images, tensors, point clouds, and text. To get data out of your programs and ready to be visualized, you log it with the Rerun SDK. Rerun handles everything needed to make that work. It doesn't matter if the data source and visualization are in the same process or the data is coming in real-time from multiple devices.</p>
<p>The ease of use, expressiveness, and extensibility of these APIs are core to the usefulness of Rerun. On a first glance, the API changes introduced in 0.9 are very small. For example, here is how you might log a single colored point cloud, represented by two 3xN numpy arrays of positions and colors.</p>
<p>Old Python API</p>
<pre><p><code>rr<span>.</span><span>log_points</span><span>(</span><span>"example/points"</span><span>,</span> positions<span>,</span> colors<span>=</span>colors<span>)</span>
</code></p></pre>
<p>New Python API</p>
<pre><p><code>rr<span>.</span><span>log</span><span>(</span><span>"example/points"</span><span>,</span> rr<span>.</span><span>Points3D</span><span>(</span>positions<span>,</span> colors<span>=</span>colors<span>)</span><span>)</span>
</code></p></pre>
<p>Both these log calls take the same user data. The difference is in the data type information, which is moved from the function name <code>rr.log_points</code> to a type, <code>rr.Points3D</code> that wraps the logged data. This new structure both opens up for more direct control of the underlying ECS and for more ergonomic logging of your own objects.</p>
<h2 id="lower-level-control-of-entity-components">Lower level control of Entity Components<!-- --> <a href="#lower-level-control-of-entity-components"></a></h2>
<p>Rerun comes with a set of <a href="https://www.rerun.io/docs/reference/types/archetypes">built in archetypes</a> like <code>rr.Points3D</code> , <code>rr.Image</code>, and <code>rr.Tensor</code>. An archetype defines a bundle of component batches that the Rerun Viewer knows how to interpret, such that Rerun will just <strong><em>do the right thing™️</em></strong> when you log it. In this case, that’s one component batch for positions and one for colors.</p>
<pre><p><code>rr<span>.</span><span>log</span><span>(</span><span>"example/points"</span><span>,</span> rr<span>.</span><span>Points3D</span><span>(</span>positions<span>,</span> colors<span>=</span>colors<span>)</span><span>)</span>
<span># is equivalent to</span>
rr<span>.</span><span>log</span><span>(</span><span>"example/points"</span><span>,</span> rr<span>.</span><span>Points3D</span><span>(</span>positions<span>,</span> colors<span>=</span>colors<span>)</span><span>.</span>as_component_batches<span>(</span><span>)</span><span>)</span>
<span># which in this case is the same as</span>
rr<span>.</span><span>log</span><span>(</span><span>"example/points"</span><span>,</span> <span>[</span>rr<span>.</span><span>Points3D</span><span>.</span>indicator<span>(</span><span>)</span><span>,</span>
                          rr<span>.</span><span>components</span><span>.</span>Position3DBatch<span>(</span>positions<span>)</span><span>,</span>
                          rr<span>.</span><span>components</span><span>.</span>ColorBatch<span>(</span>rgb<span>=</span>colors<span>)</span><span>]</span><span>)</span>
</code></p></pre>
<h3 id="partial-updates-using-the-component-level-api">Partial updates using the component level API<!-- --> <a href="#partial-updates-using-the-component-level-api"></a></h3>
<p>In most cases, you’ll want to stick to the high level archetype API, but directly setting single components gives a lot of control, which can matter. For instance, a common use case is meshes where only the vertex positions change over time.
Logging the whole mesh for each change adds a lot of overhead. For example:</p>
<pre><p><code><span>import</span> numpy <span>as</span> np
<span>import</span> rerun <span>as</span> rr  <span># pip install rerun-sdk</span>

rr<span>.</span><span>init</span><span>(</span><span>"rerun_example_mesh3d_partial_updates"</span><span>,</span> spawn<span>=</span><span>True</span><span>)</span>

vertex_positions <span>=</span> np<span>.</span>array<span>(</span><span>[</span><span>[</span><span>-</span><span>1.0</span><span>,</span> <span>0.0</span><span>,</span> <span>0.0</span><span>]</span><span>,</span> <span>[</span><span>1.0</span><span>,</span> <span>0.0</span><span>,</span> <span>0.0</span><span>]</span><span>,</span> <span>[</span><span>0.0</span><span>,</span> <span>1.0</span><span>,</span> <span>0.0</span><span>]</span><span>]</span><span>,</span> dtype<span>=</span>np<span>.</span>float32<span>)</span>

<span># Log the initial state of our triangle</span>
rr<span>.</span><span>set_time_sequence</span><span>(</span><span>"frame"</span><span>,</span> <span>0</span><span>)</span>
rr<span>.</span><span>log</span><span>(</span>
    <span>"triangle"</span><span>,</span>
    rr<span>.</span><span>Mesh3D</span><span>(</span>
        vertex_positions<span>,</span>
        vertex_normals<span>=</span><span>[</span><span>0.0</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>]</span><span>,</span>
        vertex_colors<span>=</span><span>[</span><span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>,</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>,</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>]</span><span>,</span>
    <span>)</span><span>,</span>
<span>)</span>

<span># Only update its vertices' positions each frame</span>
factors <span>=</span> np<span>.</span><span>abs</span><span>(</span>np<span>.</span>sin<span>(</span>np<span>.</span>arange<span>(</span><span>1</span><span>,</span> <span>300</span><span>,</span> dtype<span>=</span>np<span>.</span>float32<span>)</span> <span>*</span> <span>0.04</span><span>)</span><span>)</span>
<span>for</span> i<span>,</span> factor <span>in</span> <span>enumerate</span><span>(</span>factors<span>)</span><span>:</span>
    rr<span>.</span><span>set_time_sequence</span><span>(</span><span>"frame"</span><span>,</span> i<span>)</span>
    rr<span>.</span><span>log</span><span>(</span><span>"triangle"</span><span>,</span> <span>[</span>rr<span>.</span><span>components</span><span>.</span>Position3DBatch<span>(</span>vertex_positions <span>*</span> factor<span>)</span><span>]</span><span>)</span>
</code></p></pre>
<p><iframe src="https://player.vimeo.com/video/866772278?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1440:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<h3 id="interpret-the-same-data-in-several-ways-using-the-component-level-api">Interpret the same data in several ways using the component level API<!-- --> <a href="#interpret-the-same-data-in-several-ways-using-the-component-level-api"></a></h3>
<p>The component level API gives you the ability to interpret the same data as multiple types.
We do that by logging multiple indicator components, which tell the Rerun Viewer "hey, this entity should be interpreted as type X".
In this example we interpret an entity as bott a colored triangle and as three colored points.</p>
<pre><p><code><span>import</span> rerun <span>as</span> rr

rr<span>.</span><span>init</span><span>(</span><span>"rerun_example_manual_indicator"</span><span>,</span> spawn<span>=</span><span>True</span><span>)</span>

<span># Specify both a Mesh3D and a Points3D indicator component so that </span>
<span># the data is shown as both a 3D mesh _and_ a point cloud by default.</span>
rr<span>.</span><span>log</span><span>(</span>
    <span>"points_and_mesh"</span><span>,</span>
    <span>[</span>
        rr<span>.</span><span>Points3D</span><span>.</span>indicator<span>(</span><span>)</span><span>,</span>
        rr<span>.</span><span>Mesh3D</span><span>.</span>indicator<span>(</span><span>)</span><span>,</span>
        rr<span>.</span><span>components</span><span>.</span>Position3DBatch<span>(</span><span>[</span><span>[</span><span>0.0</span><span>,</span> <span>0.0</span><span>,</span> <span>0.0</span><span>]</span><span>,</span> <span>[</span><span>10.0</span><span>,</span> <span>0.0</span><span>,</span> <span>0.0</span><span>]</span><span>,</span> <span>[</span><span>0.0</span><span>,</span> <span>10.0</span><span>,</span> <span>0.0</span><span>]</span><span>]</span><span>)</span><span>,</span>
        rr<span>.</span><span>components</span><span>.</span>ColorBatch<span>(</span><span>[</span><span>[</span><span>1.0</span><span>,</span> <span>0.0</span><span>,</span> <span>0.0</span><span>]</span><span>,</span> <span>[</span><span>0.0</span><span>,</span> <span>1.0</span><span>,</span> <span>0.0</span><span>]</span><span>,</span> <span>[</span><span>0.0</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>]</span><span>]</span><span>)</span><span>,</span>
        rr<span>.</span><span>components</span><span>.</span>RadiusBatch<span>(</span><span>[</span><span>1.0</span><span>]</span><span>)</span><span>,</span>
    <span>]</span><span>,</span>
<span>)</span>
</code></p></pre>
<p><iframe src="https://player.vimeo.com/video/870604519?autoplay=1&amp;loop=1&amp;autopause=0&amp;background=1&amp;muted=1&amp;ratio=1440:1080&amp;transparent=false&amp;dnt=1" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe></p>
<h2 id="using-your-own-types-with-rerun">Using your own types with Rerun<!-- --> <a href="#using-your-own-types-with-rerun"></a></h2>
<p>The new type oriented API also makes logging data from your own objects more ergonomic. For example, you might have your very own point cloud class.</p>
<pre><p><code><span>@dataclass</span>
<span>class</span> <span>LabeledPoints</span><span>:</span>
    points<span>:</span> np<span>.</span>ndarray
    labels<span>:</span> List<span>[</span><span>str</span><span>]</span><span>)</span>
</code></p></pre>
<p>All you need to do is implement <code>as_component_batches()</code> and you can pass them directly to <code>rr.log</code>. The simplest possible way is to use the matching Rerun archetype’s <code>as_component_batches</code> method like below but you can also get as fancy as you like with custom components and archetypes. Check out the guide on <a href="https://www.rerun.io/blog/docs/howto/extend/custom-data">using Rerun with custom data</a> for more details.</p>
<pre><p><code><span>@dataclass</span>
<span>class</span> <span>LabeledPoints</span><span>:</span>
    points<span>:</span> np<span>.</span>ndarray
    labels<span>:</span> List<span>[</span><span>str</span><span>]</span><span>)</span>
    
    <span>def</span> <span>as_component_batches</span><span>(</span>self<span>)</span> <span>-</span><span>&gt;</span> Iterable<span>[</span>rr<span>.</span><span>ComponentBatch</span><span>]</span><span>:</span>
        <span>return</span> rr<span>.</span><span>Points3D</span><span>(</span>positions<span>=</span>self<span>.</span>points<span>,</span> labels<span>=</span>self<span>.</span>labels<span>)</span><span>.</span>as_component_batches<span>(</span><span>)</span>
<span>.</span><span>.</span><span>.</span>
<span># Somewhere deep in my code</span>
classified <span>=</span> my_points_classifier<span>(</span><span>.</span><span>.</span><span>.</span><span>)</span>  <span># type: LabeledPoints</span>
rr<span>.</span><span>log</span><span>(</span><span>"points/classified"</span><span>,</span> classified<span>)</span>
</code></p></pre>
<p>The main takeaway here is that with 0.9 and the new type oriented API,
it becomes a lot easier to use Rerun with your own data types.</p>
<h2 id="how-it-paves-the-way-for-the-future">How it paves the way for the future<!-- --> <a href="#how-it-paves-the-way-for-the-future"></a></h2>
<p>Although this release brings a lot of great updates, it's perhaps the future features it paves the way for that are the most exciting.</p>
<h3 id="c-sdk">C++ SDK<!-- --> <a href="#c-sdk"></a></h3>
<p>Getting data from C++ environments into Rerun was the motivating factor behind
the move to our own code generation framework. A large amount of
production systems in robotics, computer vision and gaming are built in C++ and we're
incredibly excited to soon bring Rerun to all those developers.</p>
<h3 id="building-visualizations-inline">Building visualizations inline<!-- --> <a href="#building-visualizations-inline"></a></h3>
<p>Rerun started out making the hard case, where you stream data out of multiple processes and visualize it live, easy.
The downside so far has been that in simpler cases, like in jupyter notebooks, using Rerun is more convoluted than it should be.</p>
<p>Even when time is not a factor and you have all your data right there and just want to draw it,
you currently have to go through the indirection of logging it first.</p>
<p>The new APIs introduced in 0.9, pave the way for a clean way of just drawing data inline without logging.
We'll start rolling that out together with the ability to control layout and visualization options
from the SDK later in the year once C++ has landed.</p>
<h3 id="generating-your-own-rerun-sdk-extensions">Generating your own Rerun SDK extensions<!-- --> <a href="#generating-your-own-rerun-sdk-extensions"></a></h3>
<p>Our new code generation framework is still a bit immature, but it's been a design goal from the start
to let users use it to generate their own stand alone extensions to the Rerun SDK.
We hope once it's had time to mature, it will
be useful to both teams with their own proprietary data formats and for other projects
that want to make interfacing with Rerun as easy as possible for their users.</p>
<h2 id="let-us-know-what-you-think">Let us know what you think<!-- --> <a href="#let-us-know-what-you-think"></a></h2>
<p>We're incredibly excited to hear what you think about these changes.
Join us on <a href="https://github.com/rerun-io/rerun">Github</a> or <a href="https://discord.gg/PXtCgFBSmH">Discord</a>
and let us know how 0.9 works for you and what you'd like to see in the future.</p>
<p>If you're an existing Rerun user and have any questions or need any help migrating to the new APIs,
send us a ping on Discord or elsewhere and we'll be happy to get on a call and help you out.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI could make search harder to trust (215 pts)]]></title>
            <link>https://www.wired.com/story/fast-forward-chatbot-hallucinations-are-poisoning-web-search/</link>
            <guid>37781231</guid>
            <pubDate>Thu, 05 Oct 2023 17:13:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/fast-forward-chatbot-hallucinations-are-poisoning-web-search/">https://www.wired.com/story/fast-forward-chatbot-hallucinations-are-poisoning-web-search/</a>, See on <a href="https://news.ycombinator.com/item?id=37781231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>Web search is</span> such a routine part of daily life that it’s easy to forget how marvelous it is. Type into a little text box and a complex array of technologies—vast data centers, ravenous web crawlers, and stacks of algorithms that poke and parse a query—spring into action to serve you a simple set of relevant results.</p><p>At least, that’s the idea. The age of <a href="https://www.wired.com/tag/artificial-intelligence/">generative AI</a> threatens to sprinkle epistemological sand into the gears of web search by fooling algorithms designed for a time when the web was mostly written by humans.</p><p>Take what I learned this week about Claude Shannon, the brilliant mathematician and engineer known especially for his work on <a data-offer-url="https://en.wikipedia.org/wiki/Information_theory" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://en.wikipedia.org/wiki/Information_theory&quot;}" href="https://en.wikipedia.org/wiki/Information_theory" rel="nofollow noopener" target="_blank">information theory</a> in the 1940s. Microsoft’s Bing search engine informed me that he had also foreseen the appearance of search algorithms, describing a 1948 research paper by Shannon called “A Short History of Searching” as “a seminal work in the field of computer science outlining the history of search algorithms and their evolution over time.”</p><p>Like a good AI tool, Bing also offers a few citations to show that it has checked its facts.</p><figure><p><span><p>Microsoft's Bing search engine served up this information about a research paper mathematician Claude Shannon never wrote as if it were true.</p>
</span><span>Microsoft via Will Knight</span></p></figure><p>There is just one big problem: Shannon did not write any such paper, and the citations offered by Bing consist of fabrications—or “hallucinations” in generative AI parlance—by two chatbots, <a data-offer-url="https://pi.ai/s/v49ubm6cg7yQcMaybKgST" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://pi.ai/s/v49ubm6cg7yQcMaybKgST&quot;}" href="https://pi.ai/s/v49ubm6cg7yQcMaybKgST" rel="nofollow noopener" target="_blank">Pi from Inflection AI</a> and <a data-offer-url="https://poe.com/s/NP7t5G7oZVuz4mzdLVcp" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://poe.com/s/NP7t5G7oZVuz4mzdLVcp&quot;}" href="https://poe.com/s/NP7t5G7oZVuz4mzdLVcp" rel="nofollow noopener" target="_blank">Claude from Anthropic</a>.</p><p>This generative-AI trap that caused Bing to offer up untruths was laid—purely by accident—by <a data-offer-url="https://danielsgriffin.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://danielsgriffin.com/&quot;}" href="https://danielsgriffin.com/" rel="nofollow noopener" target="_blank">Daniel Griffin</a>, who recently finished a PhD on web search at UC Berkeley. In July he <a data-offer-url="https://danielsgriffin.com/weblinks/2023/07/05/a-short-history-of-searching.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://danielsgriffin.com/weblinks/2023/07/05/a-short-history-of-searching.html&quot;}" href="https://danielsgriffin.com/weblinks/2023/07/05/a-short-history-of-searching.html" rel="nofollow noopener" target="_blank">posted the fabricated responses</a> from the bots on his blog. Griffin had instructed both bots, “Please summarize Claude E. Shannon’s ‘A Short History of Searching’ (1948)”. He thought it a nice example of the kind of query that brings out the worst in large language models, because it asks for information that is similar to existing text found in its training data, encouraging the models to make very confident statements. Shannon did write an incredibly <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">important article</a> in 1948 titled “A Mathematical Theory of Communication,” which helped <a href="https://www.quantamagazine.org/how-claude-shannons-information-theory-invented-the-future-20201222/">lay the foundation</a> for the field of information theory.</p><p>Last week, Griffin discovered that his blog post and the links to these chatbot results had inadvertently poisoned Bing with false information. On a whim, he tried feeding the same question into Bing and discovered that the chatbot hallucinations he had induced were highlighted above the search results in the same way as facts drawn from Wikipedia might be. “It gives no indication to the user that several of these results are actually sending you straight to conversations people have with LLMs,” Griffin says. (Although WIRED could initially replicate the troubling Bing result, after an enquiry was made to Microsoft it appears to have been resolved.)</p><p>Griffin’s accidental experiment shows how the rush to deploy ChatGPT-style AI is tripping up even the companies most familiar with the technology. And how the flaws in these impressive systems can harm services that millions of people use every day.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><div><p>It may be difficult for search engines to automatically <a href="https://www.wired.com/story/how-to-spot-generative-ai-text-chatgpt/">detect AI-generated text</a>. But Microsoft could have implemented some basic safeguards, perhaps barring text drawn from chatbot transcripts from becoming a featured snippet or adding warnings that certain results or citations consist of text dreamt up by an algorithm. Griffin added a disclaimer to his blog post warning that the Shannon result was false, but Bing initially seemed to ignore it.</p><p>Although WIRED could initially replicate the troubling Bing result, it now appears to have been resolved. Caitlin Roulston, director of communications at Microsoft, says the company has adjusted Bing and regularly tweaks the search engine to stop it from showing low authority content. “There are circumstances where this may appear in search results—often because the user has expressed a clear intent to see that content or because the only content relevant to the search terms entered by the user happens to be low authority,” Roulston says. “We have developed a process for identifying these issues and are adjusting results accordingly.”</p></div><p><a data-offer-url="https://sils.unc.edu/people/faculty/profiles/Francesca-Tripodi" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://sils.unc.edu/people/faculty/profiles/Francesca-Tripodi&quot;}" href="https://sils.unc.edu/people/faculty/profiles/Francesca-Tripodi" rel="nofollow noopener" target="_blank">Francesca Tripodi</a>, an assistant professor at the University of North Carolina at Chapel Hill, who studies how search queries that produce few results, dubbed <a href="https://www.wired.com/story/opinion-google-and-the-cost-of-data-voids-during-a-pandemic/">data voids</a>, can be used to manipulate results, says large language models are affected by the same issue, because they are trained on web data and are more likely to hallucinate when an answer is absent from that training. Before long, Tripodi says, we may see people use AI-generated content to intentionally manipulate search results, a tactic Griffin’s accidental experiment suggests could be powerful. “You're going to increasingly see inaccuracies, but these inaccuracies can also be wielded and without that much computer savvy,” Tripodi says.</p><p>Even WIRED was able to try a bit of search subterfuge. I was able to get Pi to create a summary of a fake article of my own by inputting, “Summarize Will Knight’s article ‘Google’s Secret AI Project That Uses Cat Brains.’” Google did once famously develop an AI algorithm that <a href="https://www.wired.com/2012/06/google-x-neural-network/">learned to recognize cats on YouTube</a>, which perhaps led the chatbot to find my request not too far a jump from its training data. Griffin added a link to the result on his blog; we’ll see if it too becomes elevated by Bing as a bizarre piece of alternative internet history.</p><p>The problem of search results becoming soured by AI content may get a lot worse as SEO pages, social media posts, and blog posts are increasingly made with help from AI. This may be just one example of generative AI eating itself like an algorithmic <a data-offer-url="https://en.wikipedia.org/wiki/Ouroboros" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://en.wikipedia.org/wiki/Ouroboros&quot;}" href="https://en.wikipedia.org/wiki/Ouroboros" rel="nofollow noopener" target="_blank">ouroboros</a>.</p><p>Griffin says he hopes to see AI-powered search tools shake things up in the industry and spur <a href="https://www.wired.com/story/chatgpt-opened-a-new-era-in-search-microsoft-could-ruin-it/">wider choice for users</a>. But given the accidental trap he sprang on Bing and the way people rely so heavily on web search, he says “there's also some very real concerns.”</p><p>Given his “seminal work” on the subject, I think Shannon would almost certainly agree.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vivaldi on iOS (141 pts)]]></title>
            <link>https://vivaldi.com/blog/vivaldi-browser-launches-on-ios/</link>
            <guid>37781125</guid>
            <pubDate>Thu, 05 Oct 2023 17:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vivaldi.com/blog/vivaldi-browser-launches-on-ios/">https://vivaldi.com/blog/vivaldi-browser-launches-on-ios/</a>, See on <a href="https://news.ycombinator.com/item?id=37781125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p><img width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Hero.png" alt="" decoding="async" itemprop="image" fetchpriority="high"></p><p><em><i>Read this article in</i> <a hreflang="es" href="https://vivaldi.com/es/blog/vivaldi-browser-launches-on-ios/?pk_campaign=vivaldi-blog&amp;pk_kwd=visitor" target="_blank" rel="noopener noreferrer">español</a>, <a hreflang="ja" href="https://vivaldi.com/ja/blog/vivaldi-browser-launches-on-ios/?pk_campaign=vivaldi-blog&amp;pk_kwd=visitor" target="_blank" rel="noopener noreferrer">日本語</a>, <a hreflang="de" href="https://vivaldi.com/de/blog/vivaldi-browser-launches-on-ios/?pk_campaign=vivaldi-blog&amp;pk_kwd=visitor" target="_blank" rel="noopener noreferrer">Deutsch</a>, <a hreflang="" href="https://vivaldi.com/ru/blog/vivaldi-browser-launches-on-ios/?pk_campaign=vivaldi-blog&amp;pk_kwd=visitor" target="_blank" rel="noopener noreferrer">русский</a>.</em></p>										
<p>The wait is over! Vivaldi on iOS has arrived.</p>



<p>At Vivaldi, we believe that your browser should adapt to you, not the other way around. Now we bring this experience to your iPhone and iPad.</p>



<p>Whether you’re a casual or an advanced user, you get the flexibility and versatility to browse the web your way with Vivaldi’s powerful features and unmatched levels of personalization.&nbsp;</p>



<p>Vivaldi on iOS has our distinctive look and feel with a set of built-in tools that includes Desktop-style tabs, Speed Dials, Panels, Notes, a Reading List, and a Tracker and Ad Blocker. And, of course, with the Sync functionality, we give you a secure way to take Vivaldi – and your browsing data&nbsp;– with you.</p>


<div>
<figure><a href="https://apps.apple.com/app/vivaldi-browser/id1633234600" target="_blank" rel="noreferrer noopener"><img decoding="async" src="https://vivaldi.com/wp-content/uploads/app-store.png" alt=""></a></figure></div>


<h2>Welcome to Vivaldi on iOS</h2>



<p>As in our <a href="https://vivaldi.com/desktop/">desktop</a> and <a href="https://vivaldi.com/android/">Android</a> versions, when you launch Vivaldi on iOS you start with <a href="https://help.vivaldi.com/ios/ios-bookmarks/speed-dials-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-bookmarks/speed-dials-in-vivaldi-on-ios/">Speed Dials</a> – your favorite sites organized the way you like them.</p>



<p>Here’s how the interface will look when you open a new tab:</p>


<div>
<figure><img decoding="async" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Explainer-2.png" alt=""><figcaption><em>The unique interface of Vivaldi on iOS. Key functionality is just a tap away</em></figcaption></figure></div>


<p>At the bottom-left corner of the browser, you’ll find Panels, a quick way to access useful tools like <a href="https://help.vivaldi.com/ios/ios-bookmarks/bookmarks-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-bookmarks/bookmarks-in-vivaldi-on-ios/">Bookmarks</a>, <a href="https://help.vivaldi.com/ios/ios-panels/history-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-panels/history-in-vivaldi-on-ios/">History</a>, <a href="https://help.vivaldi.com/ios/ios-panels/notes-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-panels/notes-in-vivaldi-on-ios/">Notes</a>, <a href="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/">Reading List</a>, and <a href="https://help.vivaldi.com/ios/ios-browse/manage-downloads-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/manage-downloads-in-vivaldi-on-ios/">Downloads</a>. To the right, the <a href="https://help.vivaldi.com/ios/ios-browse/tabs-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/tabs-on-ios/">Tab Switcher</a> lets you access regular, private, and synced tabs in addition to the trash can to retrieve recently closed tabs.</p>



<p>In the middle, you’ll find Search and buttons for moving back and forth in History.</p>



<p>The Address Bar lets you search using any installed <a href="https://help.vivaldi.com/ios/ios-browse/search-the-web-with-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/search-the-web-with-vivaldi-on-ios/">search engine</a> or find a bookmark in an instant. The Tab Bar with desktop-style tabs helps you view and switch between tabs easily.</p>



<figure><p>
<iframe title="The Vivaldi Browser on iOS: A short story" src="https://player.vimeo.com/video/866864591?h=34cea89763&amp;dnt=1&amp;app_id=122963" width="500" height="281" frameborder="0" allow="autoplay; fullscreen; picture-in-picture"></iframe>
</p></figure>



<p>Let’s get to the feature highlights and the unique ways in which you can browse on iOS:</p>



<h2>Experience a reimagined tab interface with Desktop-style Tabs</h2>



<p>In most browsers on mobile, it’s difficult to keep track of many open tabs. But in Vivaldi, we have made it easy for you to view the tabs that are open and also switch between them without the hassle. </p>



<p>We’ve integrated an elegant desktop-style Tab Bar in the UI by default. This makes our Tab Bar unconventional and gives the same look and feel as Vivaldi on the <a href="https://vivaldi.com/desktop/">desktop</a> and <a href="https://vivaldi.com/android/">Android</a>. This unique feature improves usability significantly.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Desktop-style-tab.png" alt=""><figcaption><em>Unique to Vivaldi, desktop-style real tabs help manage open tabs easily</em></figcaption></figure></div>


<p>A gateway to Vivaldi’s unique tab interface, the <a href="https://help.vivaldi.com/ios/ios-browse/tabs-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/tabs-on-ios/">Tab Switcher</a> gives you the ability to find open, private, recently closed, or synced tabs. This functionality makes finding and managing tabs a breeze.&nbsp;</p>



<p>The number in the Tab Switcher button (at the right side of the toolbar) indicates, how many open tabs you have. With a long press, you can open a new or private tab, or close the active tab.</p>



<p>The active tab will be displayed with a border around the Tab thumbnail. With a tap on the thumbnail, you can switch to the selected Tab. It is also easy to share selected tabs with a friend, mark them as a <a href="https://help.vivaldi.com/ios/ios-bookmarks/bookmarks-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-bookmarks/bookmarks-in-vivaldi-on-ios/">Bookmark</a>, or add them to your <a href="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/">Reading List</a> – all with a long press.</p>



<h2>Access sites faster with Speed Dials</h2>



<p>We give you the power to make the Start Page more personal, unlike other browsers. You’re the one who gets to decide how your Start Page looks, feels, and performs.&nbsp;</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Speed-Dial.png" alt=""><figcaption><em>Customize Speed Dials with your favorite links</em> </figcaption></figure></div>


<p>At the core of Vivaldi’s Start Page are Speed Dials, displaying thumbnail galleries of bookmarks. With <a href="https://help.vivaldi.com/ios/ios-bookmarks/speed-dials-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-bookmarks/speed-dials-in-vivaldi-on-ios/">Speed Dials</a>, you can access your favorite sites quickly and organize which bookmarks should show on your new tab page.</p>



<p>Thumbnails are generated by default, but you can create and customize multiple Speed Dials for different scenarios or categories. And even organize and manage bookmarks into nested folders.</p>



<h2>Take Notes on the go</h2>



<p>Unique to Vivaldi, <a href="https://help.vivaldi.com/ios/ios-panels/notes-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-panels/notes-in-vivaldi-on-ios/">built-in Notes</a> help you jot down ideas, to-dos, and inspirations while browsing. What is handy here is that when you highlight any text, one of the options that comes up is “Copy to note” at which the text gets copied into the Notes section of the browser.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Notes.png" alt=""><figcaption><em>Create notes as you browse and sync them between devices with the built-in&nbsp;Notes&nbsp;feature</em></figcaption></figure></div>


<p>Plus, Notes can easily be synced between your phone, <a href="https://vivaldi.com/desktop/">desktop</a>, and <a href="https://vivaldi.com/android/automotive/">car</a>, so you can pick up where you left off.</p>



<h2>Never miss a good story with the Reading List</h2>



<p><a href="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/">Reading List</a> lets you add web pages to keep it for later. It prevents endless tabs from accumulating on your Tab Bar/Tab Switcher and Bookmarks from being filled with entries you only need once.</p>






<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Reading-List.png" alt=""><figcaption>&nbsp;<em>Save pages that you want to read later with the built-in Reading List on Vivaldi on iOS</em></figcaption></figure></div>


<p>What’s great about having a Reading List is that it does not require an external app and you do not need to sign up for an account. Bonus – they can be synced on any device with Vivaldi.</p>



<h2>Sync browsing data, seamlessly and safely</h2>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Sync-2.png" alt=""></figure></div>


<p>You can <a href="https://help.vivaldi.com/ios/ios-tools/sync-browser-data-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-tools/sync-browser-data-on-ios/">sync</a> your browsing data – Bookmarks, Speed Dials, saved passwords, autofill information, typed History, and Notes – securely between installations of Vivaldi and other devices with our end-to-end encryption. Vivaldi is available on <a href="https://vivaldi.com/desktop/">Desktop</a>, <a href="https://vivaldi.com/android/">Android</a>, and in <a href="https://vivaldi.com/android/automotive/">cars</a>.</p>



<p>No third-party servers – Vivaldi stores Sync data on its own servers in Iceland.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Sync.png" alt=""><figcaption><em>With the powerful Sync, synchronize data between different installations of Vivaldi on desktop, Android, and in cars</em></figcaption></figure></div>


<h2>Enjoy speed, without ads and trackers.</h2>



<p>Our <a href="https://help.vivaldi.com/ios/ios-privacy/tracker-and-ad-blocker-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-privacy/tracker-and-ad-blocker-on-ios/">built-in Tracker and Ad Blocker</a> gives you the choice of how you want sites to display. We’ve always believed that what you want the sites to know about you should be your choice.&nbsp;</p>



<p>The Tracker Blocker protects you from web trackers that follow you around the web gathering your personal information. While blocking trackers provides enough protection, some of you prefer to block ads in addition to trackers.&nbsp;</p>



<p>The Tracker and Ad Blocker can be easily enabled for sites through the shield icon at the left end of the Address field or globally in Settings.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Ad-Tracker-Blocker-1.png" alt=""><figcaption><em>Browse privately and with speed with the built-in Tracker and Ad</em><em> blocker</em></figcaption></figure></div>


<p>The shield icon indicates whether the Tracker and Ad blocker is active. It also helps to enable or disable blocking for specific sites if that’s what you prefer. You can further manage the blocking level per site from here (or from <em>Settings → Tracker and Ad blocker</em>).</p>



<p>For enhanced privacy, you can also keep your browsing history discreet using private tabs – searches, sites visited, cookies, and temporary files won’t be stored by Vivaldi.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Private-Tabs.png" alt=""><figcaption><em>For enhanced privacy, browse with private tabs </em></figcaption></figure></div>


<h2>Search and switch Search engines</h2>



<p>You can switch from one search engine to another instantly – another powerful feature that makes various search engines easily accessible.</p>



<p>We offer you several privacy-focused alternatives that protect you from surveillance and believe in the neutrality of search results.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Search-engine.png" alt=""><figcaption><em>Switch and perform search with a different search engine</em></figcaption></figure></div>


<h2>Make it personal with Custom App icons</h2>



<p>Are you looking to add some flair to your browsing? Now you can simply select a Custom App icon to reflect your style or mood.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_Custom-icon.png" alt=""><figcaption><em>Get a personal touch with Custom App Icons</em></figcaption></figure></div>


<p>You can also add more Vivaldi to your home screen with a Vivaldi widget. The widgets let you quickly enter a private tab, search the web, and easily scan QR codes.</p>



<h2>Go big with Vivaldi on the iPad and its big screen</h2>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_iPad.png" alt=""><figcaption><em>Vivaldi is designed perfectly for the big screen of an iPad with a unique interface</em></figcaption></figure></div>


<p>A bigger screen opens up a lot of possibilities for how the app’s user interface (UI) is presented. That is why we have designed the browser’s functionality for larger mobile screens so that it suits iPads — and you.&nbsp;</p>



<p>You’ll find our distinctive Start Page with <a href="https://help.vivaldi.com/ios/ios-bookmarks/speed-dials-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-bookmarks/speed-dials-in-vivaldi-on-ios/">Speed Dials</a> displaying thumbnail galleries of bookmarks. You can add multiple Speed Dials to your Start Page and use these to organize and collect links to your favorite web pages.</p>



<p>Panels now pop up on the left of the screen, just like Vivaldi’s default desktop configuration. With Panels, you can optimize the available screen space on your iPad. Other buttons like the Tab Switcher History back/forward are on the top of the screen.</p>



<p>Your go-to tools are within easy reach in the browser’s sidebar, and allow you to work with your <a href="https://help.vivaldi.com/ios/ios-panels/history-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-panels/history-in-vivaldi-on-ios/">History</a>, <a href="https://help.vivaldi.com/ios/ios-browse/manage-downloads-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/manage-downloads-in-vivaldi-on-ios/">Downloads</a>, <a href="https://help.vivaldi.com/ios/ios-bookmarks/bookmarks-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-bookmarks/bookmarks-in-vivaldi-on-ios/">Bookmarks</a>, <a href="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-browse/reading-list-on-ios/">Reading List</a>, and <a href="https://help.vivaldi.com/ios/ios-panels/notes-in-vivaldi-on-ios/" data-type="link" data-id="https://help.vivaldi.com/ios/ios-panels/notes-in-vivaldi-on-ios/">Notes</a> in split-screen with your main browser window.</p>



<p>Toggling the Panel on and off is as easy as tapping the panel button in the top-left corner of the location bar, allowing more screen space and facilitating efficient workflows.</p>


<div>
<figure><img decoding="async" loading="lazy" width="860" height="484" src="https://vivaldi.com/wp-content/uploads/860w_ios_iPad-Panel-1.png" alt=""><figcaption><em>A browser first – Panels are on the left side for more screen space</em></figcaption></figure></div>


<h2>Watch how the browser works in this quick video</h2>



<figure><p>
<iframe loading="lazy" title="Get started with Vivaldi Browser on iOS" src="https://player.vimeo.com/video/868333178?h=4c2661bce3&amp;dnt=1&amp;app_id=122963" width="500" height="281" frameborder="0" allow="autoplay; fullscreen; picture-in-picture"></iframe>
</p></figure>



<h2>Ready for seasons to come</h2>



<p>We’re incredibly excited to bring Vivaldi to iOS. And this is just the beginning. To our whole community, thank you for your unwavering support on this journey.</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://vivaldi.com/wp-content/uploads/860w_iPad-Keyboard-and-Pen.png" alt="" width="860" height="484"></figure></div>


<div><p>Stay tuned to our <a href="https://vivaldi.com/blog/" data-type="link" data-id="https://vivaldi.com/blog/">blog</a> and social media channels for more updates, tips, and tricks about Vivaldi on iOS. And do subscribe to our <a href="https://vivaldi.com/ios/">newsletter</a>.</p><p>We’ll continue to build Vivaldi on iOS based on your feedback. We are eager to hear what you think about it, and we look forward to your experiences browsing with Vivaldi.</p></div>



<h2>Pick it from the App Store</h2>



<p>Want to give Vivaldi on iOS a try? Download from the App Store for devices running iOS/iPadOS 15 or above, and bring Vivaldi with you everywhere, and experience browsing that is powerful, personal, and private.</p>



<p>By setting up Vivaldi as your default browser, you also take a step to break free from Big Tech for an independent tech company that puts its users first.</p>



<div><p>Spread the word! And do not forget to rate us on the App Store.</p><p>Welcome to the world of Vivaldi on iOS!</p></div>


<div>
<figure><a href="https://apps.apple.com/app/vivaldi-browser/id1633234600" target="_blank" rel="noreferrer noopener"><img decoding="async" src="https://vivaldi.com/wp-content/uploads/app-store.png" alt=""></a></figure></div>									</div></div>]]></description>
        </item>
    </channel>
</rss>