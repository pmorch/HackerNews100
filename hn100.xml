<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 10 Oct 2023 11:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Chuck Feeney has died (111 pts)]]></title>
            <link>https://www.cnn.com/2023/10/09/business/billionaire-duty-free-shoppers-founder-charles-feeney-dead/index.html</link>
            <guid>37828322</guid>
            <pubDate>Tue, 10 Oct 2023 03:46:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/10/09/business/billionaire-duty-free-shoppers-founder-charles-feeney-dead/index.html">https://www.cnn.com/2023/10/09/business/billionaire-duty-free-shoppers-founder-charles-feeney-dead/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37828322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/lede-71eef364df43f494b83a2840318aa520@published" data-name="Charles Feeney 2014 FILE RESTRICTED" data-component-name="image" data-observe-resizes="" data-original-ratio="0.66625" data-original-height="1066" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="Charles Feeney, founder of the Atlantic Philanthropies, in San Francisco on Oct. 30, 2014. " onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1066" width="1600"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">Los Angeles</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_5C5CDF17-8F2C-6AFA-881D-160B0D81DAA1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Charles “Chuck” Feeney, a retail entrepreneur and investor who amassed a multibillion-dollar fortune and then gave it all away, has died. He was 92.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_F0CAE2EF-B2E0-D023-AF06-165502A0E565@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      He died peacefully in San Francisco on Monday, the Atlantic Philanthropies, Feeney’s foundation, said on <a href="https://www.atlanticphilanthropies.org/news/the-atlantic-philanthropies-community-mourn-the-loss-of-founder-charles-f-feeney" target="_blank">its website</a>.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_8EF97CE7-3A0F-ED22-BFE6-161AF1D7FB79@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney made much of his fortune after co-founding Duty Free Shoppers, a chain of duty-free airport stores specializing in luxury goods, in 1960 with an undergraduate classmate from Cornell University. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_7D260FD5-DE02-DF84-EC30-16706895B183@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In 1996, Feeney sold his shares in DFS to French luxury goods conglomerate LVMH, which now owns a majority stake in the retailer. DFS has more than 850 boutiques spanning multiple continents, <a href="https://www.dfs.com/en/los-angeles/who-we-are" target="_blank">according</a> to the brand’s website.  
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_40DE81D7-8F8F-E4E6-CAF1-162A69E92234@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney was a proponent of “Giving While Living,” believing he could make more of a difference in causes he cared about while he was alive, rather than setting up a foundation after he died, according to the Atlantic Philanthropies. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_6527BDC2-1C0C-F13C-46AD-162D524D6D3D@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “It’s much more fun to give while you are alive than to give when you are dead,” Feeney said in a biography about him, “The Billionaire Who Wasn’t.” 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_15217409-D73D-8899-A15D-1630C1C2643E@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney set up the Atlantic Philanthropies in 1982, transferring all of his business assets to it two years later, according to the foundation. In 2020, the foundation closed its doors after it said it had successfully given away all of its funds.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_0FDA56F0-7636-1733-F4E8-16338AD94049@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In total, the Atlantic Philanthropies made grants totaling $8 billion across five continents — much of it anonymously, the foundation said. Donations supported education, health care, human rights and more. Feeney’s foundation donated to infrastructure in Vietnam, universities in Ireland and medical centers devoted to finding cures for cancer and cardiovascular disease, according to the foundation’s<a href="https://www.atlanticphilanthropies.org/our-story" target="_blank"> website</a>. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_0DE1396B-6D43-D2A4-44C8-163AE3988F11@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney chose to live the last three decades of his life frugally, his foundation said: He did not own a car or home, preferring to live in a rented apartment in San Francisco, according to the foundation.  
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_7819CCB1-3D95-F319-5C8D-164200775F08@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney was born into a working-class Irish-American family during the Great Depression in Elizabeth, New Jersey, enrolling in Cornell University in 1952 with support from the GI Bill. He was the first in his family to go to college. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_582BA497-208A-B777-C7B0-163F75D68077@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney has been referred to as Cornell’s “third founder” due to the magnitude of his investment in the university. He gave nearly $1 billion to Cornell through his foundation since 1982, according to an obituary on <a href="https://news.cornell.edu/stories/2023/10/chuck-feeney-cornells-third-founder-dies-92" target="_blank">Cornell’s website</a>. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_4E007A90-D1B2-1AD2-0F01-16412525956C@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In 2011, Feeney signed the “Giving Pledge,” a commitment started by Bill and Melinda Gates and Warren Buffett that encourages America’s wealthiest families and individuals to dedicate their wealth to philanthropic endeavors. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_4E3BB549-6ECC-CBE4-28A2-164574EB118A@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “I cannot think of a more personally rewarding and appropriate use of wealth than to give while one is living — to personally devote oneself to meaningful efforts to improve the human condition,” Feeney <a href="https://givingpledge.org/pledger?pledgerId=195" target="_blank">wrote</a> in his pledge letter. 
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox tooltip bug fixed after 22 years (532 pts)]]></title>
            <link>https://bugzilla.mozilla.org/show_bug.cgi?id=148624</link>
            <guid>37827995</guid>
            <pubDate>Tue, 10 Oct 2023 02:43:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=148624">https://bugzilla.mozilla.org/show_bug.cgi?id=148624</a>, See on <a href="https://news.ycombinator.com/item?id=37827995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">

 


<main id="bugzilla-body" tabindex="-1">



<div id="main-inner">










<div id="summary-container">


  
    <p><span id="field-value-status_summary">
      <span data-status="closed">Closed</span>
      <span id="field-value-bug_id">
        <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=148624">Bug 148624</a>
      </span>
      <span>
        <span>Opened <span title="2002-06-02 08:27 PDT" data-time="1023031675">22 years ago</span></span>
          <span>Closed <span title="2023-09-07 14:35 PDT" data-time="1694122541">1 month ago</span></span>
      </span>
        </span>
    </p>

  
</div>





<div id="module-tracking">
    <table>
        <tbody><tr>
          <th></th>
          <th>Tracking</th>
          <th>Status</th>
        </tr>
        <tr>
          <td>firefox119</td>
            <td>---
            </td>
          <td>
              <a href="https://bugzilla.mozilla.org/buglist.cgi?f1=cf_status_firefox119&amp;o1=equals&amp;v1=fixed">fixed</a>
          </td>
        </tr>
    </tbody></table>
  </div>


























<div id="module-attachments"><table role="table" id="attachments">
    <tbody><tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=101434" title="Tooltip over another app, Mozilla minimized">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Tooltip over another app, Mozilla minimized
            </a>
        </p></div>
        <div>
            <p><a href="#c3"><span title="2002-10-02 12:27 PDT" data-time="1033586863">21 years ago</span></a>
          
        </p></div>
        <p>1.90 KB,
          image/png        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=101434&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=342606" title="Task tooltip over reminder window, which was focused">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Task tooltip over reminder window, which was focused
            </a>
        </p></div>
        <div>
            <p><a href="#c24"><span title="2008-10-10 12:03 PDT" data-time="1223665415">15 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=268633"> <span>Emerson Prado</span></a>
</p></div></span>
        </p></div>
        <p>64.50 KB,
          image/gif        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=342606&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=495197" title="Still happens in Fx4 nightly.">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Still happens in Fx4 nightly.
            </a>
        </p></div>
        <div>
            <p><a href="#c27"><span title="2010-12-03 17:52 PST" data-time="1291427540">13 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=396243"> <span>Richard Newman [:rnewman]</span></a>
</p></div></span>
        </p></div>
        <p>20.46 KB,
          image/png        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=495197&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=548429" title="Screenshot showing Firefox 5.0.1 tooltip intruding into foreground">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Screenshot showing Firefox 5.0.1 tooltip intruding into foreground
            </a>
        </p></div>
        <div>
            <p><a href="#c32"><span title="2011-07-26 05:53 PDT" data-time="1311684834">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>55.82 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=548429&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=550978" title="Adblock Plus tooltip intrudes into Transmission.">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Adblock Plus tooltip intrudes into Transmission.
            </a>
        </p></div>
        <div>
            <p><a href="#c34"><span title="2011-08-05 02:08 PDT" data-time="1312535302">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>76.35 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=550978&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=550980" title="Google search tooltip intrudes into Transmission">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Google search tooltip intrudes into Transmission
            </a>
        </p></div>
        <div>
            <p><a href="#c35"><span title="2011-08-05 02:11 PDT" data-time="1312535500">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>66.90 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=550980&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=550986" title="Bookmark tool bar item's &quot;mouse over&quot; state has been triggered">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Bookmark tool bar item's "mouse over" state has been triggered
            </a>
        </p></div>
        <div>
            <p><a href="#c36"><span title="2011-08-05 02:39 PDT" data-time="1312537194">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>70.14 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=550986&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511">Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin</a>
        </p></div>
        <div>
            <p><a href="#c46"><span title="2023-09-04 21:22 PDT" data-time="1693887740">1 month ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=733734"> <span>fanzhuyifan+github</span></a>
</p></div></span>
        </p></div>
        <p>48 bytes,
          text/x-phabricator-request        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511&amp;action=edit">Details</a>  |
  <a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511">Review</a>
    </td></tr>
</tbody></table>


  </div>







<meta name="firefox-versions" content="{&quot;FIREFOX_AURORA&quot;:&quot;&quot;,&quot;FIREFOX_DEVEDITION&quot;:&quot;119.0b7&quot;,&quot;FIREFOX_ESR&quot;:&quot;115.3.1esr&quot;,&quot;FIREFOX_ESR_NEXT&quot;:&quot;&quot;,&quot;FIREFOX_NIGHTLY&quot;:&quot;120.0a1&quot;,&quot;LAST_MERGE_DATE&quot;:&quot;2023-09-25&quot;,&quot;LAST_RELEASE_DATE&quot;:&quot;2023-09-26&quot;,&quot;LAST_SOFTFREEZE_DATE&quot;:&quot;2023-09-21&quot;,&quot;LAST_STRINGFREEZE_DATE&quot;:&quot;2023-09-22&quot;,&quot;LATEST_FIREFOX_DEVEL_VERSION&quot;:&quot;119.0b7&quot;,&quot;LATEST_FIREFOX_OLDER_VERSION&quot;:&quot;3.6.28&quot;,&quot;LATEST_FIREFOX_RELEASED_DEVEL_VERSION&quot;:&quot;119.0b7&quot;,&quot;LATEST_FIREFOX_VERSION&quot;:&quot;118.0.1&quot;,&quot;NEXT_MERGE_DATE&quot;:&quot;2023-10-23&quot;,&quot;NEXT_RELEASE_DATE&quot;:&quot;2023-10-24&quot;,&quot;NEXT_SOFTFREEZE_DATE&quot;:&quot;2023-10-19&quot;,&quot;NEXT_STRINGFREEZE_DATE&quot;:&quot;2023-10-20&quot;}">



<div id="c1"><p>Assignee: Matti → jaggernaut</p><p>Status: UNCONFIRMED → NEW</p><p>Component: Browser-General → XP Toolkit/Widgets</p><p>Ever confirmed: true</p><p>QA Contact: imajes-qa → jrgm</p></div><div id="c2"><p>OS: MacOS X → All</p><p>Hardware: Macintosh → All</p></div><div id="c39"><div id="ct-39" data-comment-id="16115496" data-ismarkdown="true"><p>The severity field for this bug is relatively low, S3. However, the bug has 8 duplicates and 15 votes.<br>
:enndeakin, could you consider increasing the bug severity?</p>
<p>For more information, please visit <a href="https://wiki.mozilla.org/Release_Management/autonag#severity_underestimated.py" rel="nofollow">auto_nag documentation</a>.</p>
</div><div><p>Flags: needinfo?(enndeakin)</p></div></div><div id="c40"><p>The last needinfo from me was triggered in error by recent activity on the bug. I'm clearing the needinfo since this is a very old bug and I don't know if it's still relevant.</p><div><p>Flags: <span>needinfo?(enndeakin)</span></p></div></div><div id="c41" data-comment-id="16134528" data-ismarkdown="true"><p>Still reproducible (and still extremely annoying) with Thunderbird 102.4.1 (64-bit) and Firefox 106.0.1 (64-bit) on GNU/Linux.  When I'm multitasking, I need to manually minimize Thunderbird in order to prevent its tooltips from interfering from my work in other windows.</p>
<p>Not reproducible with SeaMonkey 2.53.14, so maybe this isn't a Core product issue after all, or maybe SeaMonkey has done something to override the bad behaviour.  Maybe the Firefox and Thunderbird developers can see what SeaMonkey has done to fix the issue and implement the same fix.</p>
</div><div id="c42" data-comment-id="16209122" data-ismarkdown="true"><p>This 21 year old bug is still open. It is quite annoying, to be frank -- happens to me at least once per day.</p>
<p>That said, given its longevity, I'm kinda partial to let it be forever. It feels like a relic from the past.</p>
</div><div id="c43"><p>Hi, still happening to me too (OS: KDE Neon 22.04).<br>
Firefox v113.0.2</p></div><div id="c44" data-comment-id="16513999" data-ismarkdown="true"><p>Still happening on Firefox 115.0.2 + GNOME 44.</p>
<p>I just browser-hopped back to firefox this week and this was one of the larger annoyances, as I trigger it constantly.</p>
<p>For people who find this page via search engine, like me, the solution I'm using is to disable tooltips entirely, with the setting <code>browser.chrome.toolbar_tips</code>. It's a weird thing to have to resort to, but I don't think there's really any situation where I'll miss them.</p>
</div><div id="c45" data-comment-id="16560274" data-ismarkdown="true"><p>I am also experiencing this bug.</p>
<p>Version: firefox 117.0, clean profile; also thunderbird 115.2.0. Using xfce with xfwm.</p>
<p>Steps to reproduce:</p>
<pre><code>Hover mouse over element that will generate tooltip.
Just as the tooltip is a about to appear, but before the tooltip appears, use hotkey to switch to another workspace.
</code></pre>
<p>Symptoms:<br>
The tooltip will appear in the other workspace, and will not disappear until I switch back to firefox and move my mouse.</p>
</div><div id="a670856065_600971"><p>Assignee: nobody → fanzhuyifan+github</p><p>Status: NEW → ASSIGNED</p></div><div id="c47" data-comment-id="16563191" data-ismarkdown="true"><p>(In reply to fanzhuyifan+github from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=148624#c45" title="RESOLVED FIXED - Tooltips persist in foreground when Firefox is in background">comment #45</a>)</p>
<blockquote>
<p>I am also experiencing this bug.</p>
<p>Version: firefox 117.0, clean profile; also thunderbird 115.2.0. Using xfce with xfwm.</p>
<p>Steps to reproduce:</p>
<pre><code>Hover mouse over element that will generate tooltip.
Just as the tooltip is a about to appear, but before the tooltip appears, use hotkey to switch to another workspace.
</code></pre>
<p>Symptoms:<br>
The tooltip will appear in the other workspace, and will not disappear until I switch back to firefox and move my mouse.</p>
</blockquote>
<p>Reproducing the bug on firefox-nightly, on linux, xorg, xfce with xfwm.</p>
<p>Updated Steps to reproduce:</p>
<ul>
<li>Hover mouse over browser element that will generate tooltip (e.g., task bar. not webpage elements with tooltips)</li>
<li>alt-tab to another window or use quick key to switch to another workspace</li>
</ul>
</div><div id="c48"><p>I think a better fix would be for widget to send a window-level mouse exit event when the workspace switch happens. But I'm not sure where that code would go or how we would detect this situation.</p></div><div id="c49"><p>The nodes are already getting focusout events when workspace switches. This means some part of the code must already be detecting this situation, right?</p></div><div id="a671069636_600971"><p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511&amp;action=edit" title="Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin">Attachment #9351511</a> -
        Attachment description: Bug 148624 - cancel tooltip timer on focusout. r=mstange,cmartin → Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin</p></div><div id="c52"><p>Status: ASSIGNED → RESOLVED</p><p>Closed: <span title="2023-09-07 14:35 PDT" data-time="1694122541">1 month ago</span></p><p>Resolution: --- → FIXED</p><p>Target Milestone: --- → 119 Branch</p></div><div id="c53"><p>For me the bug only shows up when <code>MOZ_ENV_XINPUT2</code> is set to 1. The bug disappears as soon as <code>MOZ_ENV_XINPUT2</code> is set to 0.</p></div><div id="a673661673_495955"><p>Summary: Tooltips persist in foreground when Mozilla is in background → Tooltips persist in foreground when Firefox is in background</p></div>



</div> 
</main> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTX – The fraud was in the code (101 pts)]]></title>
            <link>https://newsletter.mollywhite.net/p/the-fraud-was-in-the-code</link>
            <guid>37827070</guid>
            <pubDate>Tue, 10 Oct 2023 00:14:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.mollywhite.net/p/the-fraud-was-in-the-code">https://newsletter.mollywhite.net/p/the-fraud-was-in-the-code</a>, See on <a href="https://news.ycombinator.com/item?id=37827070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>We got our first glance at the FTX codebase on Friday. The prosecution brought out Github screenshots as they questioned cooperating witness </span><a href="https://newsletter.mollywhite.net/i/137602559/gary-wang" rel="">Gary Wang</a><span>, the former CTO of FTX who at various times was responsible for the codebases powering both FTX and Alameda Research. Wang has pleaded guilty to four charges.</span></p><p><span>Although there is some risk of confusing the jury when presenting them with code snippets, prosecutors had Wang step through what the code is doing in a way that seemed pretty clear to me.</span></p><p><span> It probably helped that FTX’s engineers wrote decently clean code, with descriptive variable names and concise functions, and chose a very human-readable language (Python).</span></p><p>Note to self: if you’re going to write code to do fraud, make it messy and unreadable to reduce the chances it’s later put in front of a jury as evidence.</p><p><span>Much of the conversation revolved around the </span><code>allow_negative</code><span> flag that was introduced to the FTX codebase on August 1, 2019. Wang testified that Sam Bankman-Fried had asked him and </span><a href="https://newsletter.mollywhite.net/i/137602559/nishad-singh" rel="">Nishad Singh</a><span> (former FTX engineering director, who has also pleaded guilty) to add the flag. Github screenshots show Singh making a code change to add the column in the database, and adding logic to exempt accounts with the flag from checks that would otherwise determine if they had sufficient funds to withdraw.</span></p><p> A later change by Wang himself also exempted accounts with this flag from ever being liquidated.</p><p>Prosecutors took this opportunity to point out that practically the same day this change was being made at Bankman-Fried’s direction, Bankman-Fried was out on Twitter claiming that “[Alameda’s] account is just like everyone else’s”.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png" width="1022" height="1168" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1168,&quot;width&quot;:1022,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:284475,&quot;alt&quot;:&quot;Tweet conversation:  Bitshine @bitshine_ Jul 31, 2019 @SBF_Alameda How are you going to resolve the conflict of interest of running your own derivative exchange, AND actively trading against the market at the same time?  People complain that @CryptoHayes trades against the market, yet FTX and your shop is out there.  SBF @SBF_FTX Jul 31, 2019 Alameda is a liquidity provider on FTX but their account is just like everyone else's.  Alameda's incentive is just for FTX to do as well as possible; by far the dominant factor is helping to make the trading experience as good as possible.  Bitshine @bitshine_ I guess we're just suppose to trust that you wont get preferential treatment on your own platform. Don't get me wrong, as a semi quant trader, I enjoyed your videos and FTX is a step in the right direction. BUT, i think there needs to be a bigger discussion about this issue.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Tweet conversation:  Bitshine @bitshine_ Jul 31, 2019 @SBF_Alameda How are you going to resolve the conflict of interest of running your own derivative exchange, AND actively trading against the market at the same time?  People complain that @CryptoHayes trades against the market, yet FTX and your shop is out there.  SBF @SBF_FTX Jul 31, 2019 Alameda is a liquidity provider on FTX but their account is just like everyone else's.  Alameda's incentive is just for FTX to do as well as possible; by far the dominant factor is helping to make the trading experience as good as possible.  Bitshine @bitshine_ I guess we're just suppose to trust that you wont get preferential treatment on your own platform. Don't get me wrong, as a semi quant trader, I enjoyed your videos and FTX is a step in the right direction. BUT, i think there needs to be a bigger discussion about this issue." title="Tweet conversation:  Bitshine @bitshine_ Jul 31, 2019 @SBF_Alameda How are you going to resolve the conflict of interest of running your own derivative exchange, AND actively trading against the market at the same time?  People complain that @CryptoHayes trades against the market, yet FTX and your shop is out there.  SBF @SBF_FTX Jul 31, 2019 Alameda is a liquidity provider on FTX but their account is just like everyone else's.  Alameda's incentive is just for FTX to do as well as possible; by far the dominant factor is helping to make the trading experience as good as possible.  Bitshine @bitshine_ I guess we're just suppose to trust that you wont get preferential treatment on your own platform. Don't get me wrong, as a semi quant trader, I enjoyed your videos and FTX is a step in the right direction. BUT, i think there needs to be a bigger discussion about this issue." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1456w" sizes="100vw"></picture></div></a><figcaption><span>Only the first tweet and Bankman-Fried’s reply were included in the government’s exhibit, but I think the reply is worth including too. (</span><a href="https://twitter.com/SBF_FTX/status/1156696100729806849" rel="">Tweets</a><span>)</span></figcaption></figure></div><p><span>Wang testified that this </span><code>allow_negative</code><span> flag was a special privilege given only to Alameda Research’s trading accounts, and a database screenshot also showed the effectively unlimited line of credit that Alameda Research could dip into:</span></p><p><span>Wang explained that Alameda had not started out with such a high credit limit, but that periodically the trading firm had run into issues placing trades because they didn’t have enough collateral, and Sam Bankman-Fried kept asking him to increase their credit limit to prevent it from happening. According to Wang, the limit was originally set to “a few million dollars”, but was then increased to $1 billion. After they ran up against that limit, too, Bankman-Fried asked him to set it to a number so large that they wouldn’t likely hit the limit. At that point, Wang set it to around $65 billion.</span></p><p>Finally, prosecutors questioned Wang about the FTX “insurance fund”, which was ostensibly supposed to protect both FTX and its customers from trades that went badly even more quickly than the exchange’s risk engine could account for. FTX published the fund’s supposed balance on their website, and bragged widely about its existence, including in testimony to U.S. Congress. However, according to Wang, the number shown on the website was falsified.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png" width="514" height="314.3883495145631" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b6448891-80fd-446a-b739-bb72b186f84c_1030x630.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:630,&quot;width&quot;:1030,&quot;resizeWidth&quot;:514,&quot;bytes&quot;:138239,&quot;alt&quot;:&quot;Tweet: FTX @FTX_Official The 5.25 million FTT we put in our insurance fund in 2019 now makes the fund worth over 100 million USD  Screenshot: Backstop Fund Size: 5,478,274.51613972 USD, 5,250,000.00000000 FTT Last updated: 14/02/2021, 08:05:00&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Tweet: FTX @FTX_Official The 5.25 million FTT we put in our insurance fund in 2019 now makes the fund worth over 100 million USD  Screenshot: Backstop Fund Size: 5,478,274.51613972 USD, 5,250,000.00000000 FTT Last updated: 14/02/2021, 08:05:00" title="Tweet: FTX @FTX_Official The 5.25 million FTT we put in our insurance fund in 2019 now makes the fund worth over 100 million USD  Screenshot: Backstop Fund Size: 5,478,274.51613972 USD, 5,250,000.00000000 FTT Last updated: 14/02/2021, 08:05:00" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Tweet, exhibit GX-751</figcaption></figure></div><blockquote><p>AUSA: Is it a real number?</p><p>Wang: No.</p><p>AUSA: So it’s a fake number?</p><p>Wang: Yes.</p><p>AUSA: Was the real number higher or lower than the fake number?</p><p>Wang: Lower.</p></blockquote><p>Code snippets shown to the jury demonstrated how Nishad Singh wrote some code that would update the insurance fund amount by adding to it the daily trading volume, multiplied by a randomish number around 7,500, and dividing it by a billion, thus making it appear as though the website was referencing a real account balance that was fluctuating as the exchange added funds or withdrew from it to cover losses. In reality, it was all made up.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png" width="1444" height="1146" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1146,&quot;width&quot;:1444,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1087068,&quot;alt&quot;:&quot;Github diff showing addition of code:  def _get_change()-> Decimal:     daily_volume = current_session().query(func.sum(Trade.size * Trade.price)).filter(         Trade.created_at > datetime.now() - timedelta(days=1)).scalar() or Decimal()         return f2d(numpy.random.normal(7500, 3000))* daily_volume / Decimal('1e9')  @always_run_in_transaction(ro=False) def update_public_insurance_fund():     change = _get_change() sess = current_session() +     public_insurance_fund = Public InsuranceFund.get(sess)  sess.add(Public InsuranceFundChange(public_insurance_fund-public_insurance_fund, size-change))     public_insurance_fund.size += change     sess.commit()&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Github diff showing addition of code:  def _get_change()-> Decimal:     daily_volume = current_session().query(func.sum(Trade.size * Trade.price)).filter(         Trade.created_at > datetime.now() - timedelta(days=1)).scalar() or Decimal()         return f2d(numpy.random.normal(7500, 3000))* daily_volume / Decimal('1e9')  @always_run_in_transaction(ro=False) def update_public_insurance_fund():     change = _get_change() sess = current_session() +     public_insurance_fund = Public InsuranceFund.get(sess)  sess.add(Public InsuranceFundChange(public_insurance_fund-public_insurance_fund, size-change))     public_insurance_fund.size += change     sess.commit()" title="Github diff showing addition of code:  def _get_change()-> Decimal:     daily_volume = current_session().query(func.sum(Trade.size * Trade.price)).filter(         Trade.created_at > datetime.now() - timedelta(days=1)).scalar() or Decimal()         return f2d(numpy.random.normal(7500, 3000))* daily_volume / Decimal('1e9')  @always_run_in_transaction(ro=False) def update_public_insurance_fund():     change = _get_change() sess = current_session() +     public_insurance_fund = Public InsuranceFund.get(sess)  sess.add(Public InsuranceFundChange(public_insurance_fund-public_insurance_fund, size-change))     public_insurance_fund.size += change     sess.commit()" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>From exhibit </span><a href="https://mollywhite.net/storage/sbf-trial/GX-600.pdf" rel="">GX-600</a><span>. The falsified account balance change is primarily calculated in line 19.</span></figcaption></figure></div><p><span>This is pretty damning. One could possibly explain away an inaccurate number — say, one that was hardcoded into the website and never changed to reflect the true fund balance — by saying that they had   correctly represented it at one point in time and forgot to change it. But it’s really hard to come up with a good explanation for why the fund was being incremented by a </span><em>random</em><span> fluctuating number that was in no way tied to any actual account balance, besides the obvious: that FTX was trying to present a falsified but convincing number to customers. That would be fraud.</span></p><p>Elsewhere in the code, it’s possible to observe that the amount of FTT in the fund was actually represented by a hardcoded value in the user interface, and was not pulling from an external datasource to get a real number. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png" width="1414" height="1742" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1742,&quot;width&quot;:1414,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1363503,&quot;alt&quot;:&quot;function InsuranceFundInformation() {   let insuranceFund = useData('/stats/insurance_fund');   let classes = useStyles();   if (!insuranceFund) {     return null;   }   return (     <Card className={classes.card}>       <CardContent>         <Typography variant=\&quot;h5\&quot; gutterBottom>           <Trans>Insurance Fund</Trans>         </Typography>         <Typography>           <Trans>             Size: {{ usdSize: coinSizeFormat.format(insuranceFund.size) }} USD,{' '} {{ fttSize: coinSizeFormat.format(5250000) }} FTT           </Trans>         </Typography>       <Typography>         <Trans>           Last updated: {{ lastUpdated: new Date(insuranceFund.updatedAt).toLocaleString() }}         </Trans>       </Typography>       </CardContent>     </Card>   ); }&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="function InsuranceFundInformation() {   let insuranceFund = useData('/stats/insurance_fund');   let classes = useStyles();   if (!insuranceFund) {     return null;   }   return (     <Card className={classes.card}>       <CardContent>         <Typography variant=&quot;h5&quot; gutterBottom>           <Trans>Insurance Fund</Trans>         </Typography>         <Typography>           <Trans>             Size: {{ usdSize: coinSizeFormat.format(insuranceFund.size) }} USD,{' '} {{ fttSize: coinSizeFormat.format(5250000) }} FTT           </Trans>         </Typography>       <Typography>         <Trans>           Last updated: {{ lastUpdated: new Date(insuranceFund.updatedAt).toLocaleString() }}         </Trans>       </Typography>       </CardContent>     </Card>   ); }" title="function InsuranceFundInformation() {   let insuranceFund = useData('/stats/insurance_fund');   let classes = useStyles();   if (!insuranceFund) {     return null;   }   return (     <Card className={classes.card}>       <CardContent>         <Typography variant=&quot;h5&quot; gutterBottom>           <Trans>Insurance Fund</Trans>         </Typography>         <Typography>           <Trans>             Size: {{ usdSize: coinSizeFormat.format(insuranceFund.size) }} USD,{' '} {{ fttSize: coinSizeFormat.format(5250000) }} FTT           </Trans>         </Typography>       <Typography>         <Trans>           Last updated: {{ lastUpdated: new Date(insuranceFund.updatedAt).toLocaleString() }}         </Trans>       </Typography>       </CardContent>     </Card>   ); }" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>From exhibit </span><a href="https://mollywhite.net/storage/sbf-trial/GX-600.pdf" rel="">GX-600</a><span>. The hardcoded FTT value is in line 64.</span></figcaption></figure></div><p>This wasn’t highlighted to jurors, though, probably because the randomized number is far more damning.</p><p>As prosecutors continued to question Wang, he explained that there were repeated incidents in which FTX suffered losses that exceeded the real, smaller amount of assets that had been set aside in an insurance fund. One such example was in 2021, when a trader was able to exploit a bug in FTX’s margin system that allowed them to take out a massive position in the MobileCoin cryptocurrency. They were eventually liquidated, and FTX suffered a loss of “several hundred million dollars,” according to Wang.</p><p>Prosecutors haven’t mentioned it, but Sam Bankman-Fried would go on to testify under oath in front of the U.S. Congress in May 2022 that “the insurance fund has paid out a net total of $9.5 million” in the preceding three years, and that “the single biggest daily drawdown from the FTX.com insurance fund was $4.7 million.”</p><p><span>They did, however, play a clip from the </span><em>Odd Lots</em><span> podcast in which Sam Bankman-Fried lied to interviewer Matt Levine, saying that FTX’s risk management engine was so good that they had “never had a day … where there’s more money that we lost in blowouts to revenue that we made just from trading fees”.</span></p><p><audio src="https://newsletter.mollywhite.net/api/v1/audio/upload/7d7885a6-92ae-42b7-89ba-22ea6dfbaa12/src">Audio playback is not supported on your browser. Please upgrade.</audio></p><p>Wang went on to testify that the MobileCoin losses, and other similar losses that exceeded the amounts available in the insurance fund, were “taken on” by Alameda — that is, Alameda took over the account’s positions and collateral, effectively absorbing the loss as its own. Wang said that Bankman-Fried reasoned “that FTX’s balance sheets are more public than Alameda’s balance sheets, that investors have access to FTX’s finances but not Alameda’s finances.”</p><p>Indeed, just the previous day we had heard testimony from Paradigm venture capitalist Matt Huang, during which balance sheets were shown to the jury that showed $63 million in estimated trading expenses and $63 million in estimated other expenses for all of 2021 — clearly omitting the “several hundred million dollars” lost to the MobileCoin incident.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png" width="1200" height="20" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:20,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5633,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The defense team only briefly questioned Wang before the court session ended, but began by suggesting to the jury that he might be saying what the government wants to hear in the hopes of receiving a lighter sentence (he faces a maximum of 50 years in prison, but will likely receive a substantially shorter or even no custodial sentence due to his cooperation). They also tried to offer an alternative explanation for the </span><code>allow_negative</code><span> flag: that Alameda was in charge of doing conversions from US dollars to stablecoins, and for a brief period in this transaction they needed to borrow the funds from FTX before returning them in stablecoin form. Why they would need a $65 billion ceiling to do so, however, was not addressed, and seems likely to come up in redirect when court resumes on Tuesday.</span></p><p><span>Tuesday will also bring the testimony of </span><a href="https://newsletter.mollywhite.net/i/137602559/caroline-ellison" rel="">Caroline Ellison</a><span>, former Alameda Research CEO and on-and-off girlfriend of Sam Bankman-Fried. She is expected to be a star witness in this case, and the defense team has already teased their “blame Caroline” defense in opening statements.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ECC RAM on AMD Ryzen 7000 Desktop CPUs (265 pts)]]></title>
            <link>https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/</link>
            <guid>37826842</guid>
            <pubDate>Mon, 09 Oct 2023 23:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/">https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/</a>, See on <a href="https://news.ycombinator.com/item?id=37826842">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction<a href="#introduction" arialabel="Anchor">⌗</a></h2><p>One of the coolest features of AMD’s Ryzen desktop CPUs, and historically a great reason to get them
over the competition, was the official support for error-corrected memory (ECC RAM)<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. With most Ryzen
1000 through 5000 series CPUs and the right motherboards, ordinary users could get ECC RAM going
without having to spring for more expensive workstation-grade CPUs.</p><figure><a href="https://sunshowers.io/images/b550-specs.png"><img src="https://sunshowers.io/images/b550-specs.png" alt="Screenshot of B550 Steel Legend specification page, showing support for ECC &amp; non-ECC, unbuffered memory"></a><figcaption>Specification page for the B550 Steel Legend motherboard.</figcaption></figure><p>For example, here’s the <a href="https://www.asrock.com/mb/AMD/B550%20Steel%20Legend/index.asp#Specification">specification
page</a> for the ASRock
B550 Steel Legend motherboard. This is a mainstream “B” series motherboard which lists detailed
compatibility information for ECC RAM by processor generation.</p><p>(To my knowledge ASRock has had the best support for ECC RAM in Ryzen motherboards, and I’ve been
very happy with their motherboards in general.)</p><hr><figure><a href="https://sunshowers.io/images/x670e-specs.png"><img src="https://sunshowers.io/images/x670e-specs.png" alt="Screenshot of X670E Taichi specification page, without support for ECC memory"></a><figcaption>Specification page for the X670E Taichi motherboard, with no mention of ECC support.</figcaption></figure><p>Unfortunately, when the AMD Ryzen 7000 “Raphael” CPUs were launched along with the brand new <a href="https://en.wikipedia.org/wiki/Socket_AM5">Socket
AM5</a>, all mention of ECC support was gone. The
<a href="https://www.asrock.com/mb/AMD/X670E%20Taichi/index.asp#Specification">specification page</a> for the
ASRock X670E Taichi, one of the most expensive AM5 motherboards you can buy, has <strong>no mention of ECC
support</strong> as of the date of writing this.</p><p>I still decided to upgrade to a Ryzen 7950X, and overall I’ve been happy with the performance of the new processor. But the lack of ECC was a huge bummer at the time of purchasing my system.</p><h2 id="finding-a-forum-link">Finding a forum link<a href="#finding-a-forum-link" arialabel="Anchor">⌗</a></h2><p>A couple months ago I came across <a href="https://forum.asrock.com/forum_posts.asp?TID=24901">a topic on the ASRock
forums</a> talking about ECC support on AM5
motherboards, in which a user called ApplesOfEpicness said that they’d worked with an AMD engineer
to get ECC RAM going within AMD’s AGESA firmware. They’d claimed to have tested it on an ASRock
motherboard with an updated UEFI, by shorting ground and data pins, and seeing errors be reported up
to the OS.</p><p>I was intrigued by this! Even though I didn’t have the same motherboard that ApplesOfEpicness did, I
had chosen an ASRock board (the <a href="https://pg.asrock.com/mb/AMD/B650E%20PG%20Riptide%20WiFi/index.asp">B650E PG
Riptide</a>)—I had figured that
if ECC was possible on any AM5 board at all, it would be supported on ASRock. So based on the forum
post, last week I ordered <a href="https://v-color.net/products/ddr5-ecc-udimm-servermemory?variant=43445581906087">a pair of 32 GB server-grade ECC sticks from
v-color</a>.</p><p>I updated my motherboard’s UEFI to the latest version (version 1.28 with AGESA 1.0.0.7b), and then
replaced my existing RAM with the new sticks. I started up the system, and after a very long <a href="https://www.allaboutcircuits.com/news/boosing-memory-performance-age-ddr5-introduction-ddr-training-modes/">link
training</a>
process<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>… it booted up!</p><h2 id="does-the-os-recognize-ecc">Does the OS recognize ECC?<a href="#does-the-os-recognize-ecc" arialabel="Anchor">⌗</a></h2><p>On the Linux side, all indications were that the ECC memory was functioning correctly. <code>sudo dmidecode -t memory</code> reported:</p><pre tabindex="0"><code>% sudo dmidecode -t memory
Physical Memory Array
	Location: System Board Or Motherboard
	Use: System Memory
	Error Correction Type: Multi-bit ECC

... &lt;snip&gt; ...

Handle 0x0033, DMI type 17, 92 bytes
Memory Device
        Array Handle: 0x002E
        Error Information Handle: 0x0032
        Total Width: 72 bits
        Data Width: 64 bits
</code></pre><p>(The “Total Width” field is the important one here. For non-ECC RAM it read 64 bits, but in my case it was 72 bits because 64-bit ECC RAM has an <a href="https://www.anandtech.com/show/43/6">extra 8 bits</a> of parity data.)</p><p>Also, the Linux kernel reported that its error detection and correction subsystem,
<a href="https://docs.kernel.org/driver-api/edac.html">EDAC</a>, was enabled:</p><pre tabindex="0"><code>% sudo dmesg | grep -i EDAC
[    0.444842] EDAC MC: Ver: 3.0.0
[   25.042690] EDAC MC0: Giving out device to module amd64_edac controller F19h_M60h: DEV 0000:00:18.3 (INTERRUPT)
[   25.042693] EDAC amd64: F19h_M60h detected (node 0).
[   25.042696] EDAC MC: UMC0 chip selects:
[   25.042697] EDAC amd64: MC: 0:     0MB 1:     0MB
[   25.042699] EDAC amd64: MC: 2: 16384MB 3: 16384MB
[   25.042702] EDAC MC: UMC1 chip selects:
[   25.042703] EDAC amd64: MC: 0:     0MB 1:     0MB
[   25.042704] EDAC amd64: MC: 2: 16384MB 3: 16384MB
</code></pre><p>Looking good so far!</p><h2 id="wheres-this-data-coming-from">Where’s this data coming from?<a href="#wheres-this-data-coming-from" arialabel="Anchor">⌗</a></h2><p>At this point it’s worth asking about the source of these messages. Where is the data coming from
and why should we believe it?</p><p>Let’s look at <code>dmidecode</code> first. <code>man dmidecode</code> <a href="https://linux.die.net/man/8/dmidecode">starts with</a>:</p><blockquote><p>dmidecode is a tool for dumping a computer’s DMI (some say SMBIOS) table contents in a human‐readable format. This table contains a description of the system’s hardware components, as well as other useful pieces of information such as serial numbers and BIOS revision. Thanks to this table, you can retrieve this information without having to probe for the actual hardware. While this is a good point in terms of report speed and safeness, this also makes the presented information possibly unreliable.</p></blockquote><p>Oh, interesting, “possibly unreliable” is a little concerning! What is this SMBIOS thing anyway? <a href="https://en.wikipedia.org/wiki/System_Management_BIOS">Wikipedia says</a>:</p><blockquote><p>In computing, the System Management BIOS (SMBIOS) specification defines data structures (and access methods) that can be used to read management information produced by the BIOS of a computer. This eliminates the need for the operating system to probe hardware directly to discover what devices are present in the computer.</p></blockquote><p>So the data presented by <code>dmidecode</code> is coming from the <em>UEFI</em>, not from the processor<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. What this means is that the memory is ECC-<em>capable</em>, but not necessarily that it is <em>active</em>. Whether ECC is active is ultimately determined by the <a href="https://en.wikipedia.org/wiki/Memory_controller">memory controller</a> on the system.</p><h2 id="querying-the-memory-controller">Querying the memory controller<a href="#querying-the-memory-controller" arialabel="Anchor">⌗</a></h2><p>When I mentioned setting up ECC at <a href="https://oxide.computer/">work</a>, <a href="https://fingolfin.org/blog/">Robert
Mustacchi</a> pointed me to the excellent <a href="https://github.com/oxidecomputer/illumos-gate/blob/5f01ecd8941eadb64bc15b1a02c468604c1a503e/usr/src/uts/intel/sys/amdzen/umc.h#L22">illumos documentation about
AMD’s Unified Memory
Controller</a>.
I did some reading and learned that essentially, AMD processors expose a bus called the System
Management Network (SMN). Among other things, this bus can be used to query and configure the AMD
Unified Memory Controller (UMC).</p><div><p><strong>NOTE:</strong> The information in the rest of this section is not part of the public AMD Processor
Programming Reference, but can be gleaned from the source code for the open-source Linux and
illumos kernels.</p><p><strong>WARNING:</strong> Accessing the SMN directly, and especially sending write commands to it, is dangerous
and can <strong>severely damage</strong> your computer. Do not write to the SMN unless you know what you’re
doing.</p></div><p>The idea is that we can ask the UMC the question “is ECC enabled” directly, by sending a read
request over the SMN to what is called the <code>UmcCapHi</code> register. The exact addresses involved are a
little bit magical, but on illumos with a Ryzen 7000 processor, here’s how you would query the UMC
over the SMN bus (channel 0 and channel 1 are the two memory channels on the system, and each
channel has one of the 32GB sticks plugged into it.)</p><div><pre tabindex="0"><code data-lang="sh"><span><span><span># Query the UMC at address 0x50df4, representing channel 0</span>
</span></span><span><span>$ pfexec /usr/lib/usmn -d /devices/pseudo/amdzen@0/usmn@2:usmn.0 0x50df4
</span></span><span><span>0x50df4: 0x40000030
</span></span><span><span>
</span></span><span><span><span># Query the UMC at address 0x150df4, representing channel 1</span>
</span></span><span><span>$ pfexec /usr/lib/usmn -d /devices/pseudo/amdzen@0/usmn@2:usmn.0 0x150df4
</span></span><span><span>0x150df4: 0x40000030
</span></span></code></pre></div><p>(<code>pfexec</code> is the illumos equivalent to <code>sudo</code>.)</p><p>Also, illumos comes with a really nice way to break up a hex value into bits:</p><pre tabindex="0"><code>$ mdb -e '0x40000030=j'
                1000000000000000000000000110000
                |                        ||
                |                        |+------ bit 4  mask 0x00000010
                |                        +------- bit 5  mask 0x00000020
                +-------------------------------- bit 30 mask 0x40000000
</code></pre><p>The bit we’re interested in here is bit 30. If it’s set, then ECC is enabled in the memory controller.</p><h2 id="accessing-the-smn-on-linux-with-the-ryzen_smu-driver">Accessing the SMN on Linux with the <code>ryzen_smu</code> driver<a href="#accessing-the-smn-on-linux-with-the-ryzen_smu-driver" arialabel="Anchor">⌗</a></h2><p>Can we replicate this query on Linux? Turns out we can! There’s a neat little driver called
<a href="https://gitlab.com/leogx9r/ryzen_smu"><code>ryzen_smu</code></a> which provides access to the SMN bus. It’s easy
to download and install (though on my system I needed to <a href="https://gitlab.com/leogx9r/ryzen_smu/-/merge_requests/10">apply a
patch</a>).</p><p>The driver exposes a <a href="https://gitlab.com/leogx9r/ryzen_smu#syskernelryzen_smu_drvsmn">file called
<code>/sys/kernel/ryzen_smu_drv/smn</code></a>
which can be used to perform a query over the SMN bus. The documentation says that to perform a
query, we must write 4 bytes to the file in <a href="https://www.section.io/engineering-education/what-is-little-endian-and-big-endian/">little-endian
format</a>, and
then read 4 bytes from the output in little-endian format. This isn’t convenient to do via the
command line, so let’s write a small Python script:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># smn-query-ecc.py</span>
</span></span><span><span><span># Licensed under CC0-1.0</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>query</span>(hex_str):
</span></span><span><span>    <span># Convert hex string to bytes in little-endian</span>
</span></span><span><span>    decoded <span>=</span> int(hex_str, <span>16</span>)<span>.</span>to_bytes(<span>4</span>, byteorder<span>=</span><span>'little'</span>)
</span></span><span><span>    <span>assert</span> len(decoded) <span>==</span> <span>4</span>
</span></span><span><span>
</span></span><span><span>    <span># Write 4 bytes to the SMN file</span>
</span></span><span><span>    open(<span>"/sys/kernel/ryzen_smu_drv/smn"</span>, <span>"wb"</span>)<span>.</span>write(decoded)
</span></span><span><span>
</span></span><span><span>    <span># Read 4 bytes from the SMN file, representing the return value</span>
</span></span><span><span>    ret <span>=</span> open(<span>"/sys/kernel/ryzen_smu_drv/smn"</span>, <span>"rb"</span>)<span>.</span>read(<span>4</span>)
</span></span><span><span>
</span></span><span><span>    <span># Print ret as a hex string in little-endian order</span>
</span></span><span><span>    ret_hex_str <span>=</span> hex(int<span>.</span>from_bytes(ret, byteorder<span>=</span><span>'little'</span>))
</span></span><span><span>    print(<span>f</span><span>"returned value for </span><span>{</span>hex_str<span>}</span><span> is </span><span>{</span>ret_hex_str<span>}</span><span>"</span>)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    hex_str <span>=</span> <span>"0x00050df4"</span>
</span></span><span><span>    query(<span>"0x00050df4"</span>)  <span># channel 0</span>
</span></span><span><span>    query(<span>"0x00150df4"</span>)  <span># channel 1</span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><p>Running this script, I got:</p><pre tabindex="0"><code>$ sudo python3 smn-query-ecc.py
return value for 0x00050df4 is 0x40000000
return value for 0x00150df4 is 0x40000000
</code></pre><p>Bit 30 (the first nibble’s <code>4</code>) is set, which means the memory controller is reporting that ECC is
enabled.</p><p>This query should also be possible on Windows, perhaps using <a href="https://github.com/irusanov/SMUDebugTool">this
tool</a>, though I can’t vouch for it.</p><div><h2 id="but-is-ecc-_really_-working">But is ECC <em>really</em> working?<a href="#but-is-ecc-_really_-working" arialabel="Anchor">⌗</a></h2><p>The most foolproof way to test whether ECC is working is to introduce an error somehow.</p><ul><li>ApplesOfEpicness did so by shorting a data and ground pin on their motherboard.</li><li>Another way would be to try and overclock the RAM until it gets to an unstable point.</li></ul><p>I don’t quite have the courage to physically short pins, nor the patience to slowly overclock my
RAM, waiting multiple minutes for DDR5 link training each time. So instead, I’m content with knowing that the memory controller is reporting that ECC is enabled.</p><p>Organically, I haven’t seen any errors so far. If a correctable or uncorrectable error does occur at
some point, I’ll update this post with that information.</p></div><h2 id="about-those-edac-messages">About those EDAC messages<a href="#about-those-edac-messages" arialabel="Anchor">⌗</a></h2><p>Earlier in this post I’d mentioned that the Linux kernel reported that EDAC was enabled. I was
curious what the data source for <em>that</em> was, so I dug into the Linux kernel source code.</p><p>Being generally unfamiliar with the Linux codebase, I used the tried and tested strategy of
searching for strings that get logged. In this case:</p><ul><li>Searching for <code>Giving out device to module</code> led me to find <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/edac_mc.c#L665-L668">this line</a> inside <code>edac_mc_add_mc_with_groups</code>.</li><li>This function is called <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L4212">here</a> inside <code>init_one_instance</code>.</li><li><code>init_one_instance</code> <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L4285">is only called</a> if <code>pvt-&gt;ops-&gt;ecc_enabled</code> returns true.</li><li>What is <code>ecc_enabled</code>? It is set to a function called <code>umc_ecc_enabled</code> in <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L3985-L3991">this code</a>. And <code>pvt-&gt;ops</code> is set to <code>umc_ops</code> <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L4023-L4024">when the processor family is &gt;= 0x17</a>. Ryzen 7000 (Zen 4) is <a href="https://en.wikipedia.org/wiki/List_of_AMD_CPU_microarchitectures#Nomenclature">family 0x19</a>.</li></ul><p>Going by just the name, <code>umc_ecc_enabled</code> sounds like it would be querying the UMC. So let’s look at <a href="https://github.com/torvalds/linux/blob/94f6f0550c625fab1f373bb86a6669b45e9748b3/drivers/edac/amd64_edac.c#L3619C51-L3619C51">what it does</a>. It looks like it’s checking that <code>umc_cap_hi</code>’s <code>UMC_ECC_ENABLED</code> bit is set.</p><p>And what is <code>UMC_ECC_ENABLED</code>? It’s <a href="https://github.com/torvalds/linux/blob/94f6f0550c625fab1f373bb86a6669b45e9748b3/drivers/edac/amd64_edac.h#L272">bit 30</a>!</p><p>So it looks like the <code>EDAC</code> messages are only shown if the UMC reports that ECC is enabled. This
means that, at least on AMD processors, the Linux kernel message <code>EDAC MC0: Giving out device to module amd64_edac</code> is a reliable indicator that ECC is enabled.</p><h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">⌗</a></h2><p>ECC RAM is great, and you can easily get it working on Ryzen 7000 desktop CPUs, at least with ASRock
motherboards. I learned a ton of low-level processor interface details along the way.</p><h2 id="acknowledgements">Acknowledgements<a href="#acknowledgements" arialabel="Anchor">⌗</a></h2><p>Thanks again to <a href="https://fingolfin.org/blog/">Robert</a> for teaching me about a lot of the details here!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop EU Chat Control (159 pts)]]></title>
            <link>https://stopchatcontrol.eu/</link>
            <guid>37826775</guid>
            <pubDate>Mon, 09 Oct 2023 23:31:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stopchatcontrol.eu/">https://stopchatcontrol.eu/</a>, See on <a href="https://news.ycombinator.com/item?id=37826775">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

		
					<main id="main">
				<article class="page" id="post-11" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
	
	
	 <!-- .entry-header -->


<div ast-blocks-layout="true" itemprop="text">

	
	
<div><div>




<p>In order to put pressure on the policy makers we need to come together and contact all of our European friends and our national members of the European Parliament to convince them that the chat control contradicts our fundamental rights. <br>With the help of GPT-3 we will support you in your political opposition.</p>




</div><figure><img decoding="async" fetchpriority="high" width="251" height="260" src="https://stopchatcontrol.eu/wp-content/uploads/2023/05/uberwachung.svg" alt=""></figure></div>



<div id="about">
<h2 id="arguments">Our Arguments</h2>



<figure><video controls="" poster="https://stopchatcontrol.eu/wp-content/uploads/2023/07/WhatsApp-Image-2023-07-03-at-15.28.30.jpeg" src="https://stopchatcontrol.eu/wp-content/uploads/2023/07/30F154C9-067E-4FAB-8EB7-DBF98ABF529F.mov"></video></figure>



<p>Ursula von der Leyen and the European Commission 🇪🇺 launch an <strong>attack on our civil rights</strong> with chat control.🚩🚩🚩 </p>



<p>With the chat control, the European Commission wants to prevent the spread of child abuse depictions and grooming. You can find out <strong>why chat control</strong> is unfortunately <strong>the wrong tool</strong> here:</p>



<p>If the chat control detects suspicious content 🚨 – it will be forwarded to an authority. The two problems here:</p>



<p>1️⃣ Completely normal photos, such as holiday pictures 🏞️ are considered suspicious. The chat control therefore produces too <strong>many false results and overloads the authorities</strong>. This will lead to fewer investigation successes.</p>



<p>2️⃣ So our <strong>private family photos or the chats </strong>and pictures from your sexting yesterday 🍑🍆 also end up on an official table. So we can throw privacy in the bin 🚮</p>



<hr>



<div>
<p>The chat control is not in line with the Charter of Fundamental Rights⛔️ The digital secrecy of letters is thus going into the digital wastebasket 🚮 The chat control would read and screen all our WhatsApp messages, emails, photos and videos on our cell phone in real time 🔦</p>



<p>Minors are <strong>prohibited from accessing apps</strong> where there is a risk that adults could write to children illegally. So basically all common social media apps. Look for a leisure activity without an app 🙃</p>
</div>



<hr>



<div>
<p>WhatsApp, Snapchat etc. are forced to <strong>check the age</strong> of their users with chat control. The apps will have to do this with a photo and proof of <strong>passport</strong>. So you can forget about being anonymous on a dating app 🙅🙅‍♂️</p>



<div>
<p>The EU Data Protection Board, the European Parliament’s Research Service and the EU Council’s Legal Service say they are warning of chat controls. Ursula von der Leyen is not interested in these opinions </p>



<p>🤡 🚩</p>
</div>



<div>
<p>The <strong>chat control destroys the encryption infrastructure</strong> 🔐 Because it must always be possible to read the encrypted messages unencrypted. That’s the only way to check what’s inside. This means full monitoring of all news, including journalists, lawyers and political opponents in exile.</p>
</div>
</div>



<hr>



<div>
<p>Child protection can also be improved without chat control. Instead, investments must be made in equipping and training the judiciary, the police, Europol and in cooperation between the authorities 💶⚖️</p>



<p>EU member states already have sufficient powers to monitor criminal suspects on a case-by-case basis and to secure evidence 🚔</p>



<p>A general surveillance of our digital communication is more reminiscent of China than European values 👁️</p>
</div>
</div>



<div id="reviews">
<h2 id="testimonials">testimonials</h2>



<figure><img decoding="async" src="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-1024x1024.jpeg" alt="" width="200" height="200" srcset="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-1024x1024.jpeg 1024w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-300x300.jpeg 300w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-150x150.jpeg 150w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-768x768.jpeg 768w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-1536x1536.jpeg 1536w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15.jpeg 1600w" sizes="(max-width: 200px) 100vw, 200px"></figure>



<p>“Commission President Von der Leyen’s planned chat control is a Big Brother agency that would monitor EU citizens’ private communications. We must prevent this massive state surveillance.”</p>



<p><strong>Moritz Körner</strong> <br>Member of the European Parliament</p>



<hr>



<figure><img decoding="async" src="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited.jpeg" alt="" width="200" height="200" srcset="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited.jpeg 1066w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-300x300.jpeg 300w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-1024x1024.jpeg 1024w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-150x150.jpeg 150w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-768x768.jpeg 768w" sizes="(max-width: 200px) 100vw, 200px"></figure>



<p>“Chat control is dangerous for us as it threatens our privacy and freedom of expression. Through the monitoring and censorship of our online communication, we are restricted in our freedom to form opinions. It also opens the door to abuse and manipulation by governments and authoritarian organizations. It is important that we defend our rights to privacy and freedom of expression in order to maintain an open and democratic society.”</p>



<p><strong>Franziska Brandmann</strong><br>Federal Chair of the Young Liberals Germany</p>
</div>



<div id="mitmachen">
<h2 id="contact-mep">Now it’s your turn! </h2>



<p>Send your local member of the European Parliament an e-mail with the drafting help of GPT-3!</p>



<p>All you need to do is to choose your country of origin:</p>




    
    
    
    



<p><strong>Please note that the drafts generated by Large Language Models can still contain errors. Read the draft carefully and eventually correct mistakes prior to sending your e-Mail!</strong></p>
</div>



<div id="whyus">
<h2 id="contact-friends">Contact your european friends</h2>



<p>Chances are high that most of your <span>European </span>friends have never heard of chat control. So let them know about the danger and what you think about the chat control proposal.</p>



<div>
<div>
<h3>Messenger services</h3>



<pre><code>Hey, 
the European Commission launched an attack on our civil rights with chat control. But we can still stop the proposal. Let us contact all our friends and also the members of the European Parliament to make sure that they vote against it.
This Website I found will help you do that using A.I.:
www.Stop-Chat-Control.eu
Check it out!</code></pre>








</div>



<div>
<h3>Twitter &amp; Facebook</h3>



<pre><code>The European Commission launched an attack on our civil rights with chat control. I contacted my local MEP to tell him that I oppose the proposal. You can do so too! This Website I found will help you write an e-mail to an MEP using A.I.: www.Stop-Chat-Control.eu #StopChatControl</code></pre>








</div>



<div>
<h3>Instagram<br> </h3>







<figure>
<figure><a href="https://www.instagram.com/moritz_koerner/"><img decoding="async" loading="lazy" width="565" height="903" src="https://stopchatcontrol.eu/wp-content/uploads/2023/07/mk_insta_eu.png" alt="" srcset="https://stopchatcontrol.eu/wp-content/uploads/2023/07/mk_insta_eu.png 565w, https://stopchatcontrol.eu/wp-content/uploads/2023/07/mk_insta_eu-188x300.png 188w" sizes="(max-width: 565px) 100vw, 565px"></a></figure>
</figure>
</div>
</div>
</div>







<div id="reviews">
<h2 id="petition">Sign our Petition!</h2>



<p>Using petitions we can put further pressure onto the lawmakers. Support us by signing our petition today! </p>




</div>

	
	
</div><!-- .entry-content .clear -->

	
	
</article><!-- #post-## -->

			</main><!-- #main -->
			
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DSLinux – Linux for the Nintendo DS (243 pts)]]></title>
            <link>https://www.dslinux.org/</link>
            <guid>37826357</guid>
            <pubDate>Mon, 09 Oct 2023 22:41:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dslinux.org/">https://www.dslinux.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37826357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p>The DSLinux project has ported the
	<a href="http://en.wikipedia.org/wiki/Linux">Linux</a>
	operating system to the
	<a href="http://en.wikipedia.org/wiki/Nintendo_DS">Nintendo DS</a>
        and
	<a href="http://en.wikipedia.org/wiki/Nintendo_DS_Lite">Nintendo DS Lite</a>.
	Newer models such as DSi and 3DS might work in DS-compatibility mode.
	Apart from real hardware, DSLinux also runs on some NDS emulators,
	like <a href="http://desmume.org/">desmume</a>.
	</p>

	<p>DSLinux is functional, has excellent
	<a href="https://www.dslinux.org/wiki/UsingDSLinux.html">documentation</a>,
	and brings a <a href="https://www.dslinux.org/wiki/AppDir.html">wealth of useful
	Linux programs</a> to the DS.
	See the <a href="https://www.dslinux.org/wiki/DSLinuxFAQ.html">FAQ</a> to get started.
	</p>
	<p>There are no active
	<a href="https://www.dslinux.org/wiki/ContactingDevelopers.html">developers</a>
	at the moment.
	New <a href="https://www.dslinux.org/wiki/HowToHelp.html">contributors</a> are welcome
	to pick up the ball and make use of resources provided here.
	There is plenty of documentation for new developers in the
	<a href="https://www.dslinux.org/wiki">wiki</a>.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of CSS: Easy Light-Dark Mode Color Switching with Light-Dark() (104 pts)]]></title>
            <link>https://www.bram.us/2023/10/09/the-future-of-css-easy-light-dark-mode-color-switching-with-light-dark/</link>
            <guid>37826082</guid>
            <pubDate>Mon, 09 Oct 2023 22:08:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bram.us/2023/10/09/the-future-of-css-easy-light-dark-mode-color-switching-with-light-dark/">https://www.bram.us/2023/10/09/the-future-of-css-easy-light-dark-mode-color-switching-with-light-dark/</a>, See on <a href="https://news.ycombinator.com/item?id=37826082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><img decoding="async" fetchpriority="high" src="https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark.png" alt="" width="4162" height="1996" srcset="https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark.png 4162w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-560x269.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-1120x537.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-768x368.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-1536x737.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-2048x982.png 2048w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-1568x752.png 1568w" sizes="(max-width: 4162px) 100vw, 4162px"></p>
<p>To change a color based on whether Light Mode or Dark Mode used, you’d typically use a <code>prefers-color-scheme</code> Media Query. To make things easier, CSS now comes with a utility function named <code>light-dark()</code>. The function accepts two color values as its arguments. Based on which color scheme you are actively using, it will output the first or the second argument.</p>
<p>~</p>
<h3><a name="mq" href="#mq">#</a> Responding to Light or Dark Mode</h3>
<p>To change a color value – or any other value for that matter – based on Light Mode or Dark Mode being used, you’d typically use a <code>prefers-color-scheme</code> Media Query to change the value of a Custom Property:</p>
<pre><code>:root {
  --text-color: #333; /* Value for Light Mode */
}

@media (prefers-color-scheme: dark) {
  --text-color: #ccc; /* Value for Dark Mode */
}</code></pre>
<p>When <a href="https://www.bram.us/2019/12/10/how-to-add-dark-mode-to-a-javascript-app-react-angular-vue-etc/">implementing Dark Mode</a>, you typically end up with a bunch of duplicated CSS variables that set the values for each mode. The rest of your CSS then uses these custom properties for the actual declarations.</p>
<pre><code>body {
  color: var(--text-color);
}</code></pre>
<p>~</p>
<h3><a name="light-dark" href="#light-dark">#</a> Responding to Light or Dark Mode with <code>light-dark()</code></h3>
<p>A new addition to the <a href="https://drafts.csswg.org/css-color-5/">CSS Color Module Level 5 Specification</a> is the <code>light-dark()</code> function. The function accepts two color values as its arguments. Based on which color scheme you are actively using, it will output the first or the second color argument.</p>
<pre><code>light-dark(&lt;color&gt;, &lt;color&gt;);</code></pre>
<p>As <a href="https://drafts.csswg.org/css-color-5/#light-dark">per spec</a>:</p>
<blockquote><p>This function computes to the computed value of the first color, if the used color scheme is <code>light</code> or unknown, or to the computed value of the second color, if the used color scheme is <code>dark</code>.</p></blockquote>
<p>The used color scheme is not only based on the users Light/Dark Mode setting, but also on the value of the <code>color-scheme</code> property. This similar to how <a href="https://blog.jim-nielsen.com/2021/css-system-colors/">System Colors</a> get computed.</p>
<blockquote><p>The <code>color-scheme</code> property allows an element to indicate which color schemes it is designed to be rendered with. These values are negotiated with the user’s preferences, resulting in a used color scheme […].</p></blockquote>
<p>That means, for <code>light-dark()</code> to work, you <strong>must</strong> also include a <code>color-scheme</code> declaration.</p>
<pre><code>:root {
  color-scheme: light dark;
}

:root {
  --text-color: light-dark(#333, #ccc); /* In Light Mode = return 1st value. In Dark Mode = return 2nd value. */
}</code></pre>
<p>Because <code>color-scheme</code> is taken into account, that also means that you can override its value per element, to force it into a certain mode:</p>
<pre><code>.dark {
  color-scheme: dark; /* light-dark() on this element and its children will always return dark */
}</code></pre>
<div>
<p>🤔 If this <code>light-dark()</code> seems familiar: Chromium internally sports a <code>-internal-light-dark()</code> which <a href="https://www.bram.us/2022/01/11/customize-the-password-hide-reveal-button-in-microsoft-edge/#light-dark">I wrote about before</a>. Based on this functionality, <a href="https://github.com/w3c/csswg-drafts/issues/7561">the proposal was made within the CSS Working Group</a> to expose a similar function to authors. The result is <code>light-dark()</code>.</p>
<p>Unlike <code>-internal-light-dark()</code> which is for any type of value, <code>light-dark()</code> can only be used for colors.</p></div>
<p>~</p>
<h3><a name="schemed-value" href="#schemed-value">#</a> What about other non-<code>&lt;color&gt;</code> values and responding to other color schemes?</h3>
<p>Yes, <code>light-dark()</code> is fairly limited in what it can do: it can only do light/dark and only return <code>&lt;color&gt;</code> values. But that’s intentional, as it is an intermediary step towards a final solution.</p>
<p>As proposed in <a href="https://github.com/w3c/csswg-drafts/issues/7561">the CSS Working Group issue</a>, the end goal is to have a function <em>(tentatively)</em> named <code>schemed-value()</code> in the future. That function can:</p>
<ul>
<li>Respond to any value of <code>color-scheme</code>.</li>
<li>Return more than <code>&lt;color&gt;</code> values</li>
</ul>
<p>It <em>could</em> look something like this:</p>
<pre><code>:root {
  color-scheme: dark light custom;
}

body {
  color: schemed-value(light hotpink, dark lime, custom rebeccapurple);
}</code></pre>
<p>But, for now, we “only” have <code>light-dark()</code> and I personally think that’s fine, as it rhymes with today’s reality of what browsers can do:</p>
<ul>
<li>It only supports <code>light</code> or <code>dark</code> because browsers right now <a href="https://drafts.csswg.org/css-color-adjust/#color-scheme-prop:~:text=%3Ccustom%2Dident%3E%20values%20are%20meaningless%2C%20and%20exist%20only%20for%20future%20compatibility%2C%20so%20that%20future%20added%20color%20schemes%20do%20not%20invalidate%20the%20color%2Dscheme%20declaration%20in%20legacy%20user%20agents">don’t support <code>&lt;custom-ident&gt;</code> in <code>color-scheme</code></a>, so there’s no use in supporting other values right now.</li>
<li>It can only do <code>&lt;color&gt;</code> values because <a href="https://www.w3.org/TR/css-syntax-3/#parse-grammar">the parser needs to know the value type of what it is parsing</a> ahead of time. <code>light-dark()</code> is <a href="https://drafts.csswg.org/css-color-5/#color-syntax">explicitly defined to be a <code>&lt;color&gt;</code></a>.</li>
</ul>
<p>Narrowing things down in scope/things it can do, allowed <code>light-dark()</code> to be defined now, instead of putting it on the long track. The name and syntax of <code>light-dark()</code> that was resolved on is very memorable, easy to use, and offers a solution to a common use-case.</p>
<div>
<p>When <code>schemed-value()</code> ever becomes a thing, <code>light-dark()</code> would become <a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntactic sugar</a> for it.</p>
<pre><code>light-dark(&lt;color&gt;, &lt;color&gt;); = schemed-value(light &lt;color&gt;, dark &lt;color&gt;);</code></pre>
</div>
<p>~</p>
<h3><a href="#browser-support" name="browser-support">#</a> Browser Support</h3>
<p>💡 Although this post was originally published in October 2023, the section below is constantly being updated. <em>Last update: October 09, 2023</em>.</p>
<p>Here is an up-to-date list of browser support for CSS <code>light-dark()</code>:</p>
<dl>
<dt>Chromium <em>(Blink)</em></dt>
<dd>
<p>❌ No support</p>
</dd>
<dt>Firefox <em>(Gecko)</em></dt>
<dd>
<p>✅ Supported in Firefox 120.</p>
</dd>
<dt>Safari <em>(WebKit)</em></dt>
<dd>
<p>❌ No support</p>
</dd>
</dl>
<p>The pen embedded below will indicate if the browser you are currently using supports CSS <code>light-dark()</code> or not:</p>
<p data-height="470" data-default-tab="result" data-slug-hash="ExGrNVx" data-user="bramus" data-token="8087f9a9706b4efd52ef87f16f504ef2">
  <span>See the Pen <a href="https://codepen.io/bramus/pen/ExGrNVx/8087f9a9706b4efd52ef87f16f504ef2"><br>
  CSS light-dark() Support test</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>To stay up-to-date regarding browser support, you can follow these tracking issues:</p>
<ul>
<li>Chromium/Blink: <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1490618">Issue #1490618</a> — Assigned (Open)</li>
<li>Firefox/Gecko: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1856999">Issue #1856999</a> — RESOLVED FIXED</li>
<li>Safari/WebKit: <a href="https://bugs.webkit.org/show_bug.cgi?id=262914">Issue #262914</a> — NEW</li>
</ul>
<p>~</p>
<h3><a href="#demo" name="demo">#</a> Demo</h3>
<p>If your browser supports <code>light-dark()</code>, the demo below will show a few <code>&lt;div&gt;</code>s labeled <code>.auto</code> that respond to Light/Dark mode being toggled. The <code>&lt;div&gt;</code>s with the class <code>.light</code> or <code>.dark</code> are forced into their proper mode.</p>
<p data-height="700" data-default-tab="result" data-slug-hash="LYMqRqV" data-user="bramus" data-token="8704297cfbc9e0a6bf843726a928c0e2">
  <span>See the Pen <a href="https://codepen.io/bramus/pen/LYMqRqV/8704297cfbc9e0a6bf843726a928c0e2"><br>
  light-dark() Demo</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>~</p>
<h3><a href="#spread-the-word name=" spread-the-word"="">#</a> Spread the word</h3>
<p>To help spread the contents of this post, feel free to retweet its announcement <del>tweet</del><ins>post</ins>/<del>toot</del><ins>post</ins>:</p>
<blockquote>
<p lang="en" dir="ltr">To change a color based on Light Mode or Dark Mode, you’d typically use a `prefers-color-scheme` Media Query.</p>
<p>To make things easier, CSS now comes with a `light-dark()` utility function.</p>
<p>Read <a href="https://t.co/uzcTGPo8dY">https://t.co/uzcTGPo8dY</a> to get to know the details.</p>
<p>Browser Support: Firefox 120. <a href="https://t.co/1rmGkKy2yl">pic.twitter.com/1rmGkKy2yl</a></p>
<p>— Bramus (@bramus) <a href="https://twitter.com/bramus/status/1711488907014021267?ref_src=twsrc%5Etfw">October 9, 2023</a></p></blockquote>


<p>~</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Brother printers sending ink data to Amazon? (130 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37825653</link>
            <guid>37825653</guid>
            <pubDate>Mon, 09 Oct 2023 21:19:51 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37825653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37826099"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826099" href="https://news.ycombinator.com/vote?id=37826099&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>If you have the printer on your network, and any Amazon device on your network, the Amazon device could easily query the printer for ink levels. My Home Assistant does this and I never connected HA to the printer. It’s just part of the status information the printer seems to make available on the network.<p>It’s not surprising to me that Amazon would do this using one of their devices, as everyone seems to be grabbing as much data as they can. It’s probably described in the T&amp;Cs somewhere (that they can scan your network and use data from it).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826498"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826498" href="https://news.ycombinator.com/vote?id=37826498&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>This is why IoT devices on my network get their own subnet and they are blocked from communicating with anything but what I allow them to communicate with, including the Internet.<p>Also I want to make it clear, it shouldn't have to be this way.  Devices should be transparent about how they function, but sadly they are not.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826672"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826672" href="https://news.ycombinator.com/vote?id=37826672&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Is your printer an IoT device? Is your Echo an IoT device?<p>I'd say yes to both, and so the problem would persist.</p><p>One way to solve this would be to put every single device on a separate vlan (like some public networks do). Just like NAT, that approach certainly has its advantages for the average user from a security perspective, but forces centralization and usage of third-party servers where it shouldn't be required.</p><p>Maybe what we need is a "network administration protocol" that would give you pop-ups on your phone when devices tried to discover what's on your network.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826984"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826984" href="https://news.ycombinator.com/vote?id=37826984&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>&gt; Is your printer an IoT device? Is your Echo an IoT device?<p>&gt;I'd say yes to both, and so the problem would persist.</p><p>My IoT LAN is configured to keep each device within the subnet isolated from one another.  So while they might share a subnet, they aren't able to snoop on each other.  They also do not share the same switch.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37827746"><td></td></tr>
                  <tr id="37826829"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826829" href="https://news.ycombinator.com/vote?id=37826829&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I keep seeing this suggestion (put devices on a subnet, lock them out of everything else)...<p>Do you have a link or guide to help me understand how to set this up. It seems like a great idea!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826869"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826869" href="https://news.ycombinator.com/vote?id=37826869&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>The cheapest way would be to go to your WiFi router and look for "Guest WiFi" settings, hope it's not too cheap that this functionality isn't included, activate said network, and put the devices on the guest WiFi.<p>More complicated settings involve the keyword "VLAN", afaik most home routers don't have this.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37827007"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37827007" href="https://news.ycombinator.com/vote?id=37827007&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Unfortunately I do not have a guide, perhaps this would be a good idea for a blog post?  I'll write something up when I have a free weekend.<p>Keep in mind that a lot of this will be heavily dependent on what kind of router and LAN configuration you have.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37827392"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37827392" href="https://news.ycombinator.com/vote?id=37827392&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>This is a good idea that’s inaccessible to &gt;99% of customers. That’s the part that frustrates me. We save ourselves but these companies just couldn’t care less about our teeny tiny slice of the pie.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37827366"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37827366" href="https://news.ycombinator.com/vote?id=37827366&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>This is a smart idea now you mention it. Those internet of sh!t devices are back doors onto your network.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826456"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826456" href="https://news.ycombinator.com/vote?id=37826456&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Whilst it might be in the T&amp;Cs somewhere, it’s the not-good variety of surprise that a company should really try to avoid.<p>I don’t have Alexa devices on my network, and I’m glad. I do have other vendor smart things, and I’d absolutely expect a notification if they were going to be poking around at my other devices to send information off to a company for <i>their</i> benefit.</p><p>Poor play, Amazon
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826141"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826141" href="https://news.ycombinator.com/vote?id=37826141&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span><i>It’s probably described in the T&amp;Cs somewhere</i><p>Which.. I never read but I concur with your theory.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826123"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826123" href="https://news.ycombinator.com/vote?id=37826123&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Time to learn everything they scan for, and set up a honeypot that makes people's Amazon devices fill with dummy devices.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826175"><td></td></tr>
                <tr id="37826631"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826631" href="https://news.ycombinator.com/vote?id=37826631&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Or disconnect the printer completely, attach a rpi to the printer's USB port, and install CUPS.<p>Network level security is already difficult enough even for professionals, it's nearly impossible to really "secure" consumer grade home networks with tons of random consumer grade devices by trusting one brand and distrusting another.</p><p>Personally, I don't see my printer's ink level as some sensitive information. But if I do, I would put it behind auth/encryption.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37827629"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37827629" href="https://news.ycombinator.com/vote?id=37827629&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I connect my printer via USB for this exact reason. Connecting it to Wifi is convenient but just poses too many potential attack vectors.  I agree that ink levels are not sensitive information, but a lot of things that you print (or scan if your printer has a scanner too) is sensitive.  Given that so many printers are inadvertently accessible on the Internet [1], I'd rather just connect my printer via USB and avoid that issue entirely.<p>[1] <a href="https://darknetdiaries.com/episode/31/" rel="nofollow noreferrer">https://darknetdiaries.com/episode/31/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826195"><td></td></tr>
                <tr id="37826453"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826453" href="https://news.ycombinator.com/vote?id=37826453&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>That should be the solution for everything but unfortunately I'm dealing with containers that advertise their IP via Bonjour (or whatever the new thing is). But since they run in a container they get their 172.19.0.0/24 IP, so they broadcast the wrong one.<p>Then there is the issue of certain devices only accepting things like HomeKit via a barcode and/or discovery, and not via IP addresses.</p><p>If I could just do IP addresses it would be so much more easy to cordon off things. IPs can talk across networks with ease, no hacks required, but at least I control it.</p><p>Inside of a network it's very hard to selectively allow / deny traffic.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826234"><td></td></tr>
                <tr id="37826696"><td></td></tr>
                <tr id="37826901"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37826901" href="https://news.ycombinator.com/vote?id=37826901&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>SNMP is completely different than SNTP. SNTP is basically just a minimal NTP client that just queries the time and doesn't attempt to do anything like compensate for network latency or use multiple NTP servers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826531"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826531" href="https://news.ycombinator.com/vote?id=37826531&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>This is the real solution. Pretty much all printers accept read/write from public by default and share a lot of info about themselves. Any program on your computer could do this if it wants, the only surprise here is that it took this long for anyone to bother.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826213"><td></td></tr>
                <tr id="37826704"><td></td></tr>
                              <tr id="37826217"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826217" href="https://news.ycombinator.com/vote?id=37826217&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I've recently changed my home network to ensure all IoT devices are on their own VLAN where they can't talk to each-other and only have access to the internet.<p>I see my paranoia was not unwarranted.</p><p>That being said, if I had a network printer, I would've connected it to yet another VLAN I have set up which does not even have access to the internet.</p><p>Setting all this up required quite a bit of time, effort and networking/firewall knowledge. I wonder if there's a market for providing such capabilities out of the box for the less tech-inclined privacy-conscious consumers.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826620"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826620" href="https://news.ycombinator.com/vote?id=37826620&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>&gt; less tech-inclined privacy-conscious consumers<p>That group is much smaller than most tech-conscious people imagine (at least outside of Germany).</p><p>My experience with people outside of the tech bubble is that people care a lot more about privacy from their bosses / exes / partners / parents (and very occasionally law enforcement), but almost never about privacy from big companies.</p><p>The only thing that actually makes people scared is seeing ads for products that they were recently discussing in person, and that's actually due to coincidence and search history, not, as they think, devices listening on them. I keep pointing this out every time the same thing happens on (linear) TV.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826885"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826885" href="https://news.ycombinator.com/vote?id=37826885&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>What makes you so sure that devices aren't listening?  Apparently there used to be (maybe still is) a loophole where apps can listen for specific keywords the same way the phone listens for "hey siri" or "ok google" ... apps can stuff a whole bunch of keywords into the list and listen for them that way without explicitly processing all of the audio from your device.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37826896"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826896" href="https://news.ycombinator.com/vote?id=37826896&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Sorry I can't remember where I read it, I think it was actually in a comment thread here on hacker news.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37826444"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826444" href="https://news.ycombinator.com/vote?id=37826444&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>I for one would pay for such a thing. I hate spending hours tinkering with network/firewall rules. It's dull as hell and a huge time sink to get everything right. And I have three decades of Linux knowledge. How is man-on-the-street supposed to do any of this stuff? :(</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826426"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826426" href="https://news.ycombinator.com/vote?id=37826426&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Amazon does the same thing if you link a Samsung Smartthings hub and those little sensors have a low battery.<p>This is basically the 'promise' of all this smart home junk: your fridge automatically adds milk to your Amazon cart when it scans the contents and sees the level is low. A dubious convenience for users, but an excellent way for companies to ensure you keep buying things from them.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826831"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826831" href="https://news.ycombinator.com/vote?id=37826831&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I have an HP multi-function laster printer and got a similar message yesterday about my black toner running low.  Got the same email with the same useless instructions to opt-out.  I have and would never opt-into this feature.<p>I have a feeling this is alexa searching your network and helping itself to your devices.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826033"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826033" href="https://news.ycombinator.com/vote?id=37826033&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>The feature seems perfectly fine for those who want it, but the idea that you never opted in is troubling.<p>So the question is, how did your printer get linked to your Amazon account?</p><p>Possibilities:</p><p>1) You registered your printer with Brother (possibly when setting up wireless or cloud services) and put in your email address which is also the one associated with Amazon. Did you opt in without realizing (via a dark pattern? hidden in TOS?)? Or did they opt you in without any consent at all?</p><p>2) You bought the printer from Amazon and they already knew the printer serial number (common with certain electronics brands) and that's how it got associated. Perhaps there's a notice on the add-to-cart or checkout page that you'll be enrolled, or an opt-in checkbox? Or maybe it is without consent?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826070"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826070" href="https://news.ycombinator.com/vote?id=37826070&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>See my other comment on this. I did not register it with Brother, and have no account with Brother. Given this is Amazon, I cannot help but feel pessimistic that this was done without consent.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37826121"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826121" href="https://news.ycombinator.com/vote?id=37826121&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Ah ha, it turns out there's a third option -- Alexa automatically finds printers on your network and checks their ink levels:<p><a href="https://www.amazon.com/b?ie=UTF8&amp;node=19820259011" rel="nofollow noreferrer">https://www.amazon.com/b?ie=UTF8&amp;node=19820259011</a></p><p>So it doesn't seem to have anything to do specifically with Brother at all.</p><p>Mystery solved. It's an Alexa feature ("feature").</p><p>So feel free to be angry at Amazon, but it's not Brother doing anything wrong. It's just reporting ink levels to anybody on your local network who asks, just like every other printer.</p><p>You might want to change your headline since it accuses Brother rather than Amazon.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826305"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826305" href="https://news.ycombinator.com/vote?id=37826305&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>You can turn this off in the Alexa app.  I went looking for it after reading that page.<p>It's under Settings &gt; Device Discovery (near the bottom of the settings).  It's on by default of course.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37826012"><td></td></tr>
                <tr id="37826187"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826187" href="https://news.ycombinator.com/vote?id=37826187&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span><i>removes glasses</i>... MOG... That is INTERESTING.<p>Here is an image of the email I received</p><p><a href="https://imgur.com/a/fhvZlsd" rel="nofollow noreferrer">https://imgur.com/a/fhvZlsd</a></p><p>and the current status of the web page:</p><p><a href="https://imgur.com/jkTD4Xp" rel="nofollow noreferrer">https://imgur.com/jkTD4Xp</a></p><p>I am speechless. This link brought up a narrow page of blue. Is there any way to recover that? Firefox browser. I would love to capture that .. oh I kick myself now for not grabbing a SS.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826461"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826461" href="https://news.ycombinator.com/vote?id=37826461&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>When you found that page originally you must have either got there from a POST from another page, or a prior page set a cookie which this page gobbled.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37826372"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826372" href="https://news.ycombinator.com/vote?id=37826372&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>"You are receiving this message because you connected your Brother MFC-J485DW to Alexa on 5/4/21"<p>What happened on 5/4/21?  You say you bought the printer after July 2019, so it probably wasn't the printer purchase date.  Does that line up with the date you bought or installed an ink cartridge from Amazon, or set up Alexa?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37826140"><td></td></tr>
                <tr id="37827353"><td></td></tr>
                  <tr id="37826548"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826548" href="https://news.ycombinator.com/vote?id=37826548&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Related is that Alexa seems to like to add any HP printers nearby with WiFi direct still on, and relentlessly remind you when the neighbor's printer ink is low. I have ~20 random printers in my Alexa account that I don't own and keep reappearing whenever Alexa scans for new devices.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37825967"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37825967" href="https://news.ycombinator.com/vote?id=37825967&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>How has it linked with your Amazon account then? Just because you bought the printer from Amazon? (As they do with their own devices, e.g. Fire TV Sticks, of course.)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37826055"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826055" href="https://news.ycombinator.com/vote?id=37826055&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>The printer was purchased at a store called Best Buy.<p>The only interaction that it has ever had with my Amazon account was that I ordered a single purchase of replacement ink cartridges. The idea of it monitoring their status is abhorrent to me and I don't think I would have ever opted in for such thing. Perhaps there was something requiring me to opt out, but ...it was not apparent.</p><p>When my Alexa searched for devices connected to my network, it must have noted this printer, then compared it to the fact I ordered ink for it, and <i>just to be extra helpful</i> decided to monitor its levels for me. I can think of no other way...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826330"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826330" href="https://news.ycombinator.com/vote?id=37826330&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Maybe Amazon tags the serial number of the cartridge and correlates it to your printer with the data Brother gives them. Fucking crazy.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37826162"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826162" href="https://news.ycombinator.com/vote?id=37826162&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>I would not rule out some connection via the credit/debit card, like how every shop now emails you even though you never gave them your email.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37825691"><td></td></tr>
                <tr id="37825719"><td></td></tr>
                <tr id="37825842"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37825842" href="https://news.ycombinator.com/vote?id=37825842&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>What year was it manufactured? Manuals seem to be from 2016. That's a bit earlier than I'd expect this kind of behavior (not conclusive of anything. Just an observation).<p>Do you have a firmware date?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826030"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826030" href="https://news.ycombinator.com/vote?id=37826030&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Current firmware is N1901041316<p>I do not have a manufacturer date but it would have been purchased in 2019 or later.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37826185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826185" href="https://news.ycombinator.com/vote?id=37826185&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>You backdoored your own network by putting an Alexa on it.  I wouldn't be surprised if Ring cameras pulled the same shit.<p>If you really must have this trash on your lan, you have to isolate it at the network level.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826249"><td></td></tr>
            <tr id="37826607"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826607" href="https://news.ycombinator.com/vote?id=37826607&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>People realizing shit in their homes has an API because smart devices started poking it will never not be funny.</span></p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Riccitiello steps down as CEO of Unity after pricing battle (814 pts)]]></title>
            <link>https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/</link>
            <guid>37825292</guid>
            <pubDate>Mon, 09 Oct 2023 20:46:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/">https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/</a>, See on <a href="https://news.ycombinator.com/item?id=37825292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<section>
			
			<p><time title="2023-10-09T20:37:01+00:00" datetime="2023-10-09T20:37:01+00:00">October 9, 2023 1:37 PM</time>
			</p>
			
		</section>
		<div>
					<p><img width="750" height="563" src="https://venturebeat.com/wp-content/uploads/2019/03/jr-3.jpg?fit=750%2C563&amp;strip=all" alt="John Riccitiello, CEO of Unity Technologies, has nearly 7 million developers for the Unity  3D engine."></p><div><p><span>John Riccitiello, CEO of Unity Technologies.</span></p><p><em>Image Credit: Dean Takahashi</em></p></div>		</div><!-- .article-media-header -->
	</div><div id="primary" role="main">

			<article id="post-2902288">
				<div>
					<div id="boilerplate_2567078"><div dir="auto" data-qa="virtual-list-item" role="listitem" data-qa-hover="true" data-qa-unprocessed="false" data-qa-placeholder="false" id="1695760337.229209" data-item-key="1695760337.229209">
<p><em>GamesBeat Next unites gaming industry leaders for exceptional content, networking, and deal-making opportunities. Join us on Oct 23-24 in San Francisco.&nbsp; <a href="https://gamesbeatnext.com/"><strong>Register Now</strong></a></em></p>
</div>
<hr>



</div><p>John Riccitiello, CEO of <a href="https://venturebeat.com/games/unity-adds-fee-for-installs-for-successful-developers-triggering-a-backlash/">Unity</a>, has resigned from the company in the wake of a pricing controversy that left developers in open revolt. </p>



<p>Unity said in a press release that James M. Whitehurst has been appointed interim CEO and president of the company. </p>



<p>Meanwhile, hoping to avoid a stock panic, Unity said that it is reaffirming its previous guidance for its fiscal third quarter financial results, which will be reported on November 9. </p>



<p>Roelof Botha, lead independent director of the Unity board, has been appointed chairman. Riccitiello will continue to advise Unity to ensure a smooth transition, the company said. The news isn’t a surprise as Unity angered a lot of its loyal game developers a few weeks ago after pushing through a price increase based on numbers of downloads — and then retracted it after an uproar.</p>



<div id="boilerplate_2707617">
        <h3>Event</h3>
                <div><p>GamesBeat Next 2023</p>
<p>Join the GamesBeat community in San Francisco this October 24-25. You’ll hear from the brightest minds within the gaming industry on latest developments and their take on the future of gaming.</p>
</div>
                        
                                        <p><a href="https://gamesbeatnext.com/">
                Learn More            </a>
                        </p></div><p>Unity said the board will initiate a comprehensive search process, with the assistance of a leading executive search firm, to identify a permanent CEO.</p>



<p>“Working with Unity under John’s leadership has been one of the highlights of my career. John joined the Unity Board in 2013 and stepped in to lead the company in 2014, at a time when we faced significant challenges,” Botha said, in a statement. “John has led Unity through incredible growth over the last nearly 10 years, helping us transition from a perpetual license to a subscription model, enabling developers to monetize, building other game services to serve our creator community, leading us through an IPO and positioning us as a pioneer in the developer community. Unity would not be where it is today without the impact of his contributions. I remain excited for the future of Unity.”</p>



<p>“It’s been a privilege to lead Unity for nearly a decade and serve our employees, customers, developers and partners, all of whom have been instrumental to the company’s growth,” Riccitiello said in a statement. “I look forward to supporting Unity through this transition and following the company’s future success.”</p>



<p>Whitehurst is a seasoned technology and public company executive. He previously served as senior advisor and president at IBM, after joining through IBM’s acquisition of Red Hat, a leading provider of open-source enterprise IT products and services, where he served as president and CEO from 2008 to 2020.</p>



<p>“I am honored to join Unity as interim CEO and President at this important time in its evolution,” Whitehurst said in a statement. “With the company’s experienced leadership and passionate employees, I am confident that Unity is well-positioned to continue enhancing its platform, strengthening its community of customers, developers and partners, and focusing on its growth and profitability goals. I look forward to working closely with the Board and our talented global team to execute on our strategy, and I anticipate a seamless transition.”</p>



<p>Unity will release third quarter 2023 financial results after the market close on Thursday, November 9, 2023, with a webcast to follow at 2 p.m. PT. </p>
<p><strong>GamesBeat's creed</strong> when covering the game industry is "where passion meets business." What does this mean? We want to tell you how the news matters to you -- not just as a decision-maker at a game studio, but also as a fan of games. Whether you read our articles, listen to our podcasts, or watch our videos, GamesBeat will help you learn about the industry and enjoy engaging with it. <a href="https://venturebeat.com/newsletters/?utm_source=VBsite&amp;utm_medium=bottomBoilerplate">Discover our Briefings.</a></p><!-- Boilerplate CSS for "after" -->				</div><!-- .article-content -->

									
				
			</article><!-- #post-2902288 .article-wrapper -->


		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RAG at scale: Synchronizing and ingesting billions of text embeddings (137 pts)]]></title>
            <link>https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521</link>
            <guid>37824547</guid>
            <pubDate>Mon, 09 Oct 2023 19:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521">https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521</a>, See on <a href="https://news.ycombinator.com/item?id=37824547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@neum_ai?source=post_page-----eaa29162521--------------------------------"><div aria-hidden="false"><p><img alt="Neum AI" src="https://miro.medium.com/v2/resize:fill:88:88/1*dmbNkD5D-u45r44go_cf0g.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="f3de"><em>Disclaimer: We will go into some technical and architectural details of how we do this at </em><a href="https://neum.ai/" rel="noopener ugc nofollow" target="_blank"><em>Neum AI</em></a><em> — A data platform for embeddings management, optimization, and synchronization at large scale, essentially helping with large-scale RAG.</em></p><p id="a98c">As we’ve shared in other blogs in the past, getting a <a href="https://research.ibm.com/blog/retrieval-augmented-generation-RAG" rel="noopener ugc nofollow" target="_blank">Retrieval Augmented Generation (RAG)</a> application started is pretty straightforward. The problem comes when trying to scale it and making it production-ready. In this blog we will go into some technical and architectural details of how we do this at Neum AI, specifically on how we did this for a pipeline syncing 1 billion vectors.</p><p id="84c5">First off, What exactlty is RAG?</p><p id="bd83">RAG helps finding data quickly by performing search in a “natural way” and use that information/knowledge to power a more accurate AI application that needs such information! It is a recent methodology employed by lots of people when building accurate and up-to-date AI applications!</p><p id="8477">This is what a typical RAG system looks like</p><figure><figcaption><em>Fig. 1 — High level RAG — both ingestion and application layer</em></figcaption></figure><ol><li id="1284">Data is extracted, processed, embedded and stored in a vector database for fast semantic search lookup</li><li id="e710">User submits input, generate embeddings of input, searches across vector database to find most relevant information and passes that down as context to an AI application for accurate responses.</li></ol><p id="985c">Now, let’s talk about the problem at hand — how to effectively ingest and synchronize billions of text embeddings to be used in a RAG workflow?</p><h2 id="8f91">Problem</h2><p id="a21d">RAG is straightforward, but when dealing with lots of source data a couple of complex problems arise.</p><ol><li id="f15d">Ingestion at large scale — One thing is to ingest a couple of PDFs, chunk them, embed and store in a vector db. When you have billions of records, general data infrastructure and engineering problems arise. How to effectively parallelize requests, how to handle retry mechanisms, how to spin up the right infrastructure and distributed systems, and more. It is also very important to understand the volume of data, ingestion time requirement, search latency, cost, and more to properly plan and deploy the right infra/compute. All of these are core engineering problems that, albeit solved, are daunting to implement.</li><li id="b237">Embedding (transforming it into vector format for low-latency semantic search) — generating embeddings is not a problem except when you have large data and have to deal with rate limits, retry logic, self hosted models, and more. Not to mention, but <strong>syncing data</strong> becomes crucial here. If something changed at the source and not at the downstream vector database — where the AI application typically queries from — then the response from the AI application will be stale and inaccurate. Embeddings can be costly if not done efficiently. There will always be a one-time cost of embedding all the data, but for an application that relies on new/changed data, embedding all of the source data can be very expensive, and so, there has to be a mechanism to detect whether or not data needs to be re-embedded.</li></ol><p id="adfc">In this specific case, our data pipeline is responsible for 3 operations.</p><p id="e1f2">a) Reading data</p><p id="2f15">b) Processing data</p><p id="ac67">c) Embedding data</p><p id="1c73">d) Storing data in a vector database — in this case Weaviate!</p><p id="89f4">Each of the points above have their own challenges.</p><ol><li id="5c91">Reading data needs to be done efficiently and attempt to maximize parallelization to meet ingestion time requirements</li><li id="b5a3">Once data is read, it needs to be processed, we can’t just dump everything to an embedding model. It needs to carefully be chunked depending on the source type, extract the relevant metadata fields, and clean any anomalies.</li><li id="bd7b">Embedding data as mentioned on #1 needs to be done only if required and parallelized in terms of requests/compute as per the constraints of the system and external api limits if applicable.</li><li id="3ae1">Storing in the vector database has its own limitations<br>What are the compute resources in the Vector Database?<br>Is it self hosted, managed? is there monitoring?<br>Is data sharded, what is the latency? What about compression?<br>Did you know that HNSW algorithm is pretty inefficient when trying to store identical vectors? (more on this later)<br>Could the ingestion into the database be the bottleneck of our system?</li></ol><p id="fd32">In addition to that, the system itself must have great monitoring, cancellation options, logging and alerting in place, all of the things you would expect from a robust distributed system.</p><p id="6407">For the rest of the blog we will explore solutions and share a bit into our architectural diagram for how we tested, benchmarked and ran the pipeline moving 1 billion vectors.</p><h2 id="fd1b">High-level architecture</h2><p id="b378">Let’s talk about the high level architecture and break down each of the components.</p><p id="2922">As mentioned before, this distributed system has the responsibility of four main tasks, and each of them dance together in harmony.</p><figure><figcaption><em>Fig. 2 — Distributed RAG pipeline— A bit more complex than the diagram we showed, and this is only point #1 on our first diagram!</em></figcaption></figure><p id="8702">In plain English, this is what’s happening when a user request comes in through our FastAPI service:</p><ol><li id="120e">Create a pipeline and store its metadata in our system, immediately return to the user to acknowledge their request.</li><li id="64a0">Send an event to our first processing queue — <code>requests</code> where workers will be dequeuing events from. This queue is responsible for taking in the request, figuring out the source type, in this specific case we were processing lots of files from an S3 bucket.</li><li id="418f">For each of the file in the S3 bucket, send an event to <code>process_document</code> queue with the file name where other consumers will read messages from. These workers will read the file and start processing it.</li><li id="19ea">For each of the processed files we will split it into chunks (if the file is large) so that we can fit within memory and other resource constraints. Each of these chunks will be sent to <code>embed_store</code> - our final one queue, promise ;) - where other consumers will be dequeuing.</li><li id="7a80">Of course we have set up logs and monitoring in place for us to detect issues and be able to surface any important status messages/codes to the user upon requested. Additionally, we care about analytics and metrics such as average time taken, number of tasks, etc. and we display those as well upon request.</li></ol><h2 id="f051">A note on distributed queueing in Python</h2><p id="f736">While FastAPI has support for <a href="https://fastapi.tiangolo.com/tutorial/background-tasks/" rel="noopener ugc nofollow" target="_blank">BackgroundTasks</a>, we chose <a href="https://docs.celeryq.dev/en/stable/getting-started/introduction.html" rel="noopener ugc nofollow" target="_blank">Celery</a> to help us handle the abstractions between our Message Broker and our workers because this is a more intense-heavy operation which requires distributed logging, monitoring, and further parallelization. Because the work is distributed across multiple machines, having a message broker and an event-driven system is vital for the processing and monitoring of tasks.</p><figure><figcaption>Celery Task Queue — great intro <a rel="noopener" href="https://medium.com/analytics-vidhya/python-celery-distributed-task-queue-demystified-for-beginners-to-professionals-part-1-b27030912fea">here</a></figcaption></figure><p id="219b">Celery is a vegetable ;), and it’s also an asynchronous task queue written in Python. It provides great abstractions from dealing with message brokers, producers, and consumers in a distributed system. There’s a lot of inner things about Celery that we could spend time talking about but we will leave those for another post. For example, took us a couple of debugging sessions to understand that our consumers were picking up jobs even though our message broker was empty… and it’s because Celery’s <code>prefetch_count</code>.</p><h2 id="18d3">Let’s go a bit in depth</h2><h2 id="4a41">Reading</h2><p id="4da5">As mentioned above, the first part of our system is the one in charge of determining the source type and distributing the files in this case for parallel reading. These tasks are sent to the <code>process_document</code> queue. Then, because the files might be large, we process each of them individually and sub divide it into chunks. These per-file chunks are then sent to the <code>embed_store</code> .</p><p id="395c">There’s a couple of important aspects here</p><ol><li id="b991">Because we process lots of data and files, our distributed queueing system built with Celery allows us to properly distribute tasks, monitor and retry them if needed. Along the way we have checkpointing mechanisms to understand what has been processed, which worker has picked up a task, what’s left, what succeeded and what failed.</li><li id="b3d8">Second, we need to be smart about how we chunk, how we assign metadata, and more. We give the user the ability to select how they want to chunk and assign metadata to their source data, but we also have incorporated smart chunking mechanisms to properly split the data accordingly. The data for this pipeline is json-based and so chunking is based on property field, same with the metadata to be used in the vector database for each of the vectors.</li></ol><p id="3f1b">Once we have finished distributing all the files and their respective subtasks we are ready for our final list of “heavy-consumers” to dequeue messages from our last queue depicted above and perform the <code>embeddings</code> and the <code>vector db storing</code></p><h2 id="a8c1">Embeddings and Vector DB storing</h2><p id="a886">Our final stage (which runs for every subtask mentioned above) is the one that will embed our chunks of data and store them into the vector database.</p><p id="2e47">For the case study we are talking about here, we chose two main technologies to assist with this.</p><ol><li id="2a18"><a href="https://replicate.com/" rel="noopener ugc nofollow" target="_blank">Replicate</a> for embeddings</li><li id="397f"><a href="https://weaviate.io/" rel="noopener ugc nofollow" target="_blank">Weaviate</a> for Vector Database</li></ol><p id="6f54">While we ended up using Replicate — specifically <a href="https://replicate.com/replicate/all-mpnet-base-v2" rel="noopener ugc nofollow" target="_blank">mpnet’s embedding model </a>— it is important to note that we did start with OpenAI embeddings and their <code>text-ada-002</code> model. This worked seamlessly and it took about 3-5 seconds to embed about 1500 different documents each with about 30 tokens each. Also, their <a href="https://openai.com/pricing" rel="noopener ugc nofollow" target="_blank">cost</a> was acceptable as well.</p><p id="4971">One thing to note is that storing vectors in a vector database has implications on a lot of things like latency for querying, storing, memory needed to manage it, and more. Because we are dealing with a large scale number of vectors, it was imperative to try and reduce the 1536 dimensions into a smaller dimensional model to avoid unnecessary memory storage and usage in the Weaviate cluster. Reducing the dimensions in half leads to huge $$ savings. While there are techniques to do <a href="https://elitedatascience.com/dimensionality-reduction-algorithms" rel="noopener ugc nofollow" target="_blank">Dimensionality Reduction algorithms</a>, Neum also offers integration with Replicate where customers can choose their embeddings model of their choice to be hosted and we simply connect to it, which is what we did for this run. Replicate has great customer support and were able to handle this load seamlessly.</p><p id="683a">We need a powerful and efficient vector database capable of storing <strong>b</strong>illions of vectors. Weaviate is a popular one that has great support and very technical capabilities, for those who are interested and know, Weaviate is also built using Cassandra’s architecture for sharding and replication. Having had experience with this in the past and it being open-source, it was a good choice as we needed a lot of deep customization and integration like being able to deploy on a kubernetes cluster and choose the number of nodes and shards, adjust the number of workers and ingestion batch size, and more. There’s tons of great documentation on Weaviate <a href="https://weaviate.io/developers/weaviate" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="128e">The core here is to have a vector database that will be fast upon doing semantic search and also allowing parallelization of ingestion requests via multi-node cluster while offering logging and retry capabilities.</p><h2 id="3773">Storing in-depth</h2><p id="405e">So, going back to the beginning of this section, we had our chunks that needed to be embedded, we used Replicate to do so, with Dead-Letter-Queue and retry mechanisms in place. After we got our embeddings, we used Weaviate to store the data with all the configurations mentioned above and more. Again, logging and handling errors accordingly.</p><p id="4d72">To share some numbers, we ran benchmarks with different levels of parallelization from both our infra and Weaviate’s, as well as played with the number of CPUs in the Weaviate cluster. This is not a super extensive benchmark and was done at the beginning with OpenAI where the dimensions would be greater so as to plan for a “worst case” scenario. Also, there’s some other improvements we are in the process of trying out as well like using Weaviate’s <a href="https://github.com/weaviate/weaviate/tree/master/grpc" rel="noopener ugc nofollow" target="_blank">GRPC client</a> — which claims to have significantly faster ingestion times.</p><figure><figcaption>Fig 3 - some raw quick benchmarks of Neum and Weaviate ingestion</figcaption></figure><p id="6ab1">One key insight we had to pay attention to was on how to parallelize the writes to Weaviate.</p><p id="8091">So far we shared how we parallelized the requests, the files, the chunking and the embeddings, but when we get to the storing we have a choice of how much further to parallelize ingestion, specifically for Weaviate, as they have an option for users to specify <code>num_workers</code> when ingesting data, which essentially parallelizes the request on their end further.</p><p id="ce7b">Because we had a number of consumers dequeuing from <code>embed_store</code> (remember our queues and consumers ;) I know, lots of moving pieces, it isn’t trivial!) we were already parallelizing the ingestion requests to Weaviate, and so, we had to do benchmarks to understand the “magic number” of ingestion threads from our end and worker parallelization from Weaviate’s end.</p><p id="3386">The most important thing was to understand how many CPU cores does the Weaviate cluster have and how many parallel threads/number of workers are you actively using. We got hit initially by a number of “connection errors” and large ingestion times because we were over-parallelizing the requests. As long as you maximize but don’t go over your Weaviate cluster’s resources limits, you should be good.</p><p id="1115">There’s a lot of other learnings from the Weaviate side of things like Product Quantization, increased latency because identical vectors and how HNSW stores data, parallelization of Weaviate workers via sharding, and more. Let us know if you are interested in such an analysis and we’ll share some of those learnings in another post!</p><p id="2f62">As a side note, Neum’s platform works great with Weaviate with its deep integration but we support other vector DBs as well if the user prefers it.</p><h2 id="35f9">Conclusion</h2><p id="c772">Building distributed data pipelines have lots of moving pieces, and now with the rise of Generative AI and RAG-based applications, things can get complicated very fast. We keep learning and keep delving ourselves into all these new ideas and technologies popping up to ensure we stay up to date with the latest trends. However, having a robust system with retry, logging, monitoring and ease-of-use remains top priorities for us when supporting large-scale data pipelines for embeddings.</p><p id="ac6e">There’s a bunch of moving pieces as you probably figured out. The beautiful thing about this is that all of this happens within a single API request to our Neum AI platform :). If you are interested and have large-scale data requirements, sign up <a href="https://www.neum.ai/" rel="noopener ugc nofollow" target="_blank">here</a> or <a href="mailto:founders@tryneum.com" rel="noopener ugc nofollow" target="_blank">contact us</a>!</p><p id="beb7">As mentioned, let us know if you are interested in going even more in depth to some of our Weaviate and embeddings learnings!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs can't self-correct in reasoning tasks, DeepMind study finds (160 pts)]]></title>
            <link>https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/</link>
            <guid>37823543</guid>
            <pubDate>Mon, 09 Oct 2023 18:28:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/">https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/</a>, See on <a href="https://news.ycombinator.com/item?id=37823543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
<figure><a href="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17440" data-permalink="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/confused-robot-2/" data-orig-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?fit=1024%2C968&amp;ssl=1" data-orig-size="1024,968" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Confused robot" data-image-description="" data-image-caption="<p>Image generated with Bing Image Creator</p>
" data-medium-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?fit=300%2C284&amp;ssl=1" data-large-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?fit=696%2C658&amp;ssl=1" decoding="async" fetchpriority="high" width="696" height="658" src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;ssl=1" alt="Confused robot" srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=300%2C284&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=768%2C726&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=444%2C420&amp;ssl=1 444w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=300%2C284&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=768%2C726&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=444%2C420&amp;ssl=1 444w" data-lazy-src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Image generated with Bing Image Creator</figcaption></figure>



<p><em>This article is part of our&nbsp;coverage of the latest in&nbsp;<a href="https://bdtechtalks.com/tag/ai-research-papers/" target="_blank" rel="noreferrer noopener">AI research</a>.</em></p>



<p>Scientists are inventing various strategies to enhance the accuracy and reasoning abilities of large language models (<a href="https://bdtechtalks.com/tag/large-language-models/">LLM</a>) such as <a href="https://bdtechtalks.com/2023/04/03/augmented-language-models/" title="">retrieval augmentation</a> and chain-of-thought reasoning.</p>



<p>Among these, “self-correction”—a technique where an LLM refines its own responses—has gained significant traction, demonstrating efficacy across numerous applications. However, the mechanics behind its success remain elusive.&nbsp;</p>



<p>A <a href="https://arxiv.org/abs/2310.01798">recent study</a> conducted by Google DeepMind in collaboration with the University of Illinois at Urbana-Champaign reveals that LLMs often falter when self-correcting their responses without external feedback. In fact, the study suggests that self-correction can sometimes impair the performance of these models, challenging the prevailing understanding of this popular technique.</p>



<h2>What is self-correction?</h2>



<div>




<p>Self-correction is predicated on the idea that LLMs can assess the accuracy of their outputs and refine their responses. For instance, an LLM might initially fail a math problem but correct its answer after reviewing its own output and reasoning.</p>
</div>



<p>Several studies have observed this process, also known as “self-critique,” “self-refine,” or “self-improve.”</p>



<p>However, the effectiveness of self-correction is not universal across all tasks. The paper from DeepMind and University of Illinois reveals that the success of self-correction is largely contingent on the nature of the task at hand. In reasoning tasks, self-correction techniques typically succeed only when they can leverage external sources, such as human feedback, an external tool like a calculator or code executor, or a knowledge base.</p>



<p>The researchers underscore the fact that high-quality feedback is not always accessible in many applications. This makes it crucial to understand the inherent capabilities of LLMs and to discern how much of the self-correction can be attributed to the model’s internal knowledge. They introduce the concept of “intrinsic self-correction,” which refers to a scenario where the model attempts to correct its initial responses based solely on its built-in capabilities, without any external feedback.&nbsp;</p>


<div>
<figure><a href="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17437" data-permalink="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/llm-self-correction-techniques/" data-orig-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?fit=1762%2C776&amp;ssl=1" data-orig-size="1762,776" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LLM self-correction techniques" data-image-description="<p>Different LLM self-correction techniques (source: <a href=&quot;https://github.com/teacherpeterpan/self-correction-llm-papers&quot;>GitHub</a>)</p>
" data-image-caption="<p>Different LLM self-correction techniques (source: <a href=&quot;https://github.com/teacherpeterpan/self-correction-llm-papers&quot;>GitHub</a>)</p>
" data-medium-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?fit=300%2C132&amp;ssl=1" data-large-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?fit=696%2C307&amp;ssl=1" decoding="async" width="696" height="307" src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;ssl=1" alt="LLM self-correction techniques" srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1024%2C451&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=300%2C132&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=768%2C338&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1536%2C676&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1068%2C470&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=954%2C420&amp;ssl=1 954w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1762&amp;ssl=1 1762w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1392&amp;ssl=1 1392w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1024%2C451&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=300%2C132&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=768%2C338&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1536%2C676&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1068%2C470&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=954%2C420&amp;ssl=1 954w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1762&amp;ssl=1 1762w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1392&amp;ssl=1 1392w" data-lazy-src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Different LLM self-correction techniques (source: <a href="https://github.com/teacherpeterpan/self-correction-llm-papers">GitHub</a>)</figcaption></figure></div>


<h2>Testing self-correction on reasoning tasks</h2>



<p>The researchers put self-correction to the test on several benchmarks that measure model performance in solving math word problems, answering multiple-choice questions, and tackling question-answering problems that require reasoning. They employed a three-step process for self-correction. First, they prompt the model for an answer. Next, they prompt it to review its previous response. Finally, they prompt it a third time to answer the original question based on its self-generated feedback.</p>



<p>Their findings reveal that self-correction works effectively when the models have access to the ground-truth labels included in the benchmark datasets. This is because the algorithm can accurately determine when to halt the reasoning process and avoid changing the answer when it is already correct. As the researchers state, “These results use ground-truth labels to prevent the model from altering a correct answer to an incorrect one. However, determining how to prevent such mischanges is, in fact, the key to ensuring the success of self-correction.”</p>



<p>However, this assumption does not reflect real-world scenarios, where access to the ground truth is not always available. If the ground truth were readily accessible, there would be no need to employ a machine learning model to predict it. The researchers demonstrate that when they remove the labels from the self-correction process, the performance of the models begins to decline significantly.</p>



<p>Interestingly, the models often produce the correct answer initially, but switch to an incorrect response after self-correction. For instance, in GPT-3.5-Turbo (the model used in the free version of <a href="https://bdtechtalks.com/2022/12/05/openai-chatgpt/">ChatGPT</a>), the performance dropped by almost half on the CommonSenseQA question-answering dataset when self-correction was applied. <a href="https://bdtechtalks.com/2023/03/20/gpt-4-applications-limits/">GPT-4</a> also exhibited a performance drop, albeit by a smaller margin.</p>


<div>
<figure><a href="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17432" data-permalink="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/llm-self-correction-errors/" data-orig-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?fit=2798%2C972&amp;ssl=1" data-orig-size="2798,972" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LLM self-correction errors" data-image-description="<p>In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer</p>
" data-image-caption="<p>In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer</p>
" data-medium-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?fit=300%2C104&amp;ssl=1" data-large-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?fit=696%2C242&amp;ssl=1" decoding="async" loading="lazy" width="696" height="242" src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors-1024x356.jpg?resize=696%2C242&amp;ssl=1" alt="LLM self-correction errors" srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1024%2C356&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=300%2C104&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=768%2C267&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1536%2C534&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=2048%2C711&amp;ssl=1 2048w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=696%2C242&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1068%2C371&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1209%2C420&amp;ssl=1 1209w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1920%2C667&amp;ssl=1 1920w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?w=1392&amp;ssl=1 1392w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1024%2C356&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=300%2C104&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=768%2C267&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1536%2C534&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=2048%2C711&amp;ssl=1 2048w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=696%2C242&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1068%2C371&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1209%2C420&amp;ssl=1 1209w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1920%2C667&amp;ssl=1 1920w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?w=1392&amp;ssl=1 1392w" data-lazy-src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors-1024x356.jpg?resize=696%2C242&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer</figcaption></figure></div>


<p>According to the researchers, if the model is well-aligned and paired with a thoughtfully designed initial prompt, “the initial response should already be optimal given the conditions of the prompt and the specific decoding algorithm.” In this case, introducing feedback can be viewed as adding an additional prompt, potentially skewing the model’s response away from the optimal prompt. “In an intrinsic self-correction setting, on the reasoning tasks, this supplementary prompt may not offer any extra advantage for answering the question. In fact, it might even bias the model away from producing an optimal response to the initial prompt, resulting in a decrease in performance,” the researchers write.</p>



<p>Self-correction is also prevalent in multi-agent LLM applications. In these scenarios, multiple instances of an LLM, such as ChatGPT, are given different instructions to perform distinct roles in a multi-sided debate. For instance, one agent might be tasked with generating code, while another is instructed to review the code for errors.</p>



<p>In these applications, self-correction is implemented by instructing agents to critique each other’s responses. However, the researchers found that this multi-agent critique does not lead to any form of improvement through debate. Instead, it results in a form of “self-consistency,” where the different agents generate multiple responses and then engage in a form of majority voting to select an answer.&nbsp;</p>



<p>“Rather than labeling the multi-agent debate as a form of “debate” or “critique”, it is more appropriate to perceive it as a means to achieve “consistency” across multiple model generations,” the researchers write.</p>



<h2>Post-hoc vs pre-hoc prompting</h2>



<p>While self-correction may not enhance reasoning, the researchers found that it can be effective in tasks such as modifying the style of the LLM’s output or making the response safer. They refer to these tasks as “post-hoc prompting,” where the prompting is applied after the responses have been generated. They write, “Scenarios in which self-correction enhances model responses occur when it can provide valuable instruction or feedback that pre-hoc prompting cannot.”</p>



<p>Another key finding of the paper is that the improvement attributed to self-correction in certain tasks may be due to an inadequately crafted initial instruction that is outperformed by a carefully constructed feedback prompt. In such cases, incorporating the feedback into the initial instruction, referred to as the “pre-hoc prompt,” can yield better results and reduce inference costs. The researchers state, “It is meaningless to employ a well-crafted post-hoc prompt to guide the model in ‘self-correcting’ a response generated through a poorly constructed pre-hoc prompt. For a fair comparison, equal effort should be invested in both pre-hoc and post-hoc prompting.”</p>



<p>The researchers conclude by urging the community to approach the concept of self-correction with skepticism and to apply it judiciously.&nbsp;</p>



<p>“It is imperative for researchers and practitioners to approach the concept of self-correction with a discerning perspective, acknowledging its potential and recognizing its boundaries,” the researchers write. “By doing so, we can better equip this technique to address the limitations of LLMs, steering their evolution towards enhanced accuracy and reliability.”</p>




        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Extreme Parkour with Legged Robots (131 pts)]]></title>
            <link>https://extreme-parkour.github.io/</link>
            <guid>37823440</guid>
            <pubDate>Mon, 09 Oct 2023 18:19:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://extreme-parkour.github.io/">https://extreme-parkour.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37823440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Abstract</h2>
        <p>
            Humans can perform parkour by traversing obstacles in a highly dynamic fashion requiring precise eyemuscle coordination and movement. Getting robots to do the same task requires overcoming similar challenges. Classically, this is done by independently engineering perception, actuation, and control systems to very low tolerances. This restricts them to tightly controlled settings such as a predetermined obstacle course in labs. In contrast, humans are able to learn parkour through practice without significantly changing their underlying biology. In this paper, we take a similar approach to developing robot parkour on a small low-cost robot with imprecise actuation and a single front-facing depth camera for perception which is low-frequency, jittery, and prone to artifacts. We show how a single neural net policy operating directly from a camera image, trained in simulation with largescale RL, can overcome imprecise sensing and actuation to output highly precise control behavior end-to-end. We show our robot can perform a high jump on obstacles 2x its height, long jump across gaps 2x its length, do a handstand and run across tilted ramps, and generalize to novel obstacle courses with different physical properties.
          </p>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bare-metal Rust in Android (253 pts)]]></title>
            <link>https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html</link>
            <guid>37823377</guid>
            <pubDate>Mon, 09 Oct 2023 18:13:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html">https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html</a>, See on <a href="https://news.ycombinator.com/item?id=37823377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Video streaming at scale with Kubernetes and RabbitMQ (253 pts)]]></title>
            <link>https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb</link>
            <guid>37823160</guid>
            <pubDate>Mon, 09 Oct 2023 17:51:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb">https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb</a>, See on <a href="https://news.ycombinator.com/item?id=37823160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="7967" aria-label="kicker paragraph">Architecture Deep Dive</h2><div><h2 id="d0b0">Deep dive into the problems video streaming sites face and how they can architect their infrastructure to manage the load.</h2><div><a rel="noopener follow" href="https://alexandreolive.medium.com/"><div aria-hidden="false"><p><img alt="Alexandre Olive" src="https://miro.medium.com/v2/resize:fill:88:88/1*gAvdsn07JpXS8dvJsfPFhw.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><figure><figcaption>Photo by <a href="https://unsplash.com/@popcornmatch?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Marques Kaspbrak</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8f42"><span>S</span>treaming. That’s a word we hear a lot nowadays. Most of us use Netflix or YouTube daily. So much it has become part of everyone’s life, maybe too much for our own sake.</p><p id="5f2e">But people rarely stop and wonder: how does it even work? From my developer’s point of view, it’s pure madness. There’s so much data to store and pass through the network, people worldwide should be able to access it without lag or issues, and it needs to work on all devices.</p><p id="1309">I will not pretend I know how those apps work internally. They probably use concepts I never dreamed of to optimize every inch possible.</p><p id="06f6">But don’t leave just yet; there’s still a reason I’m writing this article. I want to use my direct experience working as a technical lead on a streaming solution at <a href="https://skeepers.io/fr/" rel="noopener ugc nofollow" target="_blank">Skeepers</a> to explain how we manage to produce high-quality videos and stream those videos directly onto our client’s website, just like you would watch a video on YouTube.</p><p id="1e78">I will discuss technical subjects like <a href="https://kubernetes.io/docs/concepts/overview/" rel="noopener ugc nofollow" target="_blank">Kubernetes</a>, <a href="https://www.rabbitmq.com/" rel="noopener ugc nofollow" target="_blank">RabbitMQ</a>, and <a href="https://www.nginx.com/resources/glossary/load-balancing/" rel="noopener ugc nofollow" target="_blank">load balancers</a>. A basic knowledge of those topics is necessary to follow the article.</p><p id="b6c3"><em>To clarify, I’m talking about streaming as watching a video online that is not a live stream. A regular video on YouTube is still called video streaming.</em></p></div><div><h2 id="39ab">The video’s life: from upload to playback</h2><p id="a81b">I will take you on a journey from when a user uploads a video on our site to when you play it on your device and the challenges that come with it.</p><figure><figcaption>Photo by <a href="https://unsplash.com/@jakobowens1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jakob Owens</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="6549">First step: Video upload</h2><p id="cfac">Alright, the first step is when the video is uploaded. We have yet to determine what format, codec, or even which resolution the video will be.</p><p id="c6cd">First, it will be normalized, which means we will transform all the videos in the same format (first mp4), <a href="https://github.com/georgmartius/vid.stab" rel="noopener ugc nofollow" target="_blank">stabilize the video</a>, and <a href="http://ffmpeg.org/ffmpeg-filters.html#loudnorm" rel="noopener ugc nofollow" target="_blank">harmonize the sound</a> to mitigate shaking or loud sounds.</p><p id="4c80">We then break the video into multiple small chunks; the resulting format will be an adaptive bitrate streaming format called MPEG-Dash or HLS.</p><p id="ae70"><em>You can read more about Adaptative bitrate streaming here.</em></p><p id="d519">This task is time-consuming, so the user cannot just wait for the API’s response synchronously. It needs to be asynchronous.</p><figure><figcaption>Custom-made schema representing the simplified architecture.</figcaption></figure><p id="0444">You can see the asynchronous implementation using RabbitMQ on this schema. When a user uploads a new video, it first gets uploaded to a cloud storage. We use Google Cloud Storage, but it could be any storage. Once the upload finishes, we create a processing task in the database and send the task ID to the queue. The user screens update with a message that says the processing is ongoing and please wait a few minutes.</p><p id="0401">A NodeJS worker is constantly polling the queue, waiting for new tasks like a good soldier. When a new one is available, it gets the processing task information from the database. It uses <a href="https://ffmpeg.org/" rel="noopener ugc nofollow" target="_blank">FFmpeg</a> under the hood to do the required job (normalization or adaptative bitrate streaming format creation, for example), store the resulting files in storage, and update the task’s status in the database.</p><p id="96b6">You’re probably thinking: “Hang on, there’s <strong>Kubernetes </strong>in your article title but not in the schema”, or “It’s not scalable as is. If there are a lot of videos, it will crash.”</p><p id="fe39">I’m getting there! The schema I presented was just an introduction. I am gradually introducing each concept.</p><p id="0e6c">There are indeed a couple of issues here. If there is only one API and one worker, it will quickly overload. Primarily since FFmpeg requires a lot of resources. Let’s<strong> spice it up!</strong></p><figure><figcaption>Custom-made schema representing the more complex architecture with Kubernetes.</figcaption></figure><p id="42ce">Alright, we introduced <strong>Kubernetes</strong> in the mix. The NodeJS API handling user calls will receive many HTTP calls with user files. So, instead of having one API instance, it’s now an unlimited number of Kubernetes pods. We have set it up to auto-scale in a way that if the RAM or CPU of the pods reaches a specific limit (70% of their capacity), it will launch a new pod for this same API.</p><p id="1eed">There is no “Kubernetes node“ reference to simplify the schema, but it can also scale across nodes. If the number of pods (<a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/" rel="noopener ugc nofollow" target="_blank">actually the required capacity of the pods</a>) reaches the capacity limit for the current node, it will auto-scale a new node and start launching new pods inside that node.</p><p id="843d">The load balancer in front of the API will share the HTTP calls randomly between all the existing pods to split the load.</p><p id="65a7">The worker polling the RabbitMQ is also auto-scaling, but it’s not on resources; it is scaling on the number of messages waiting in the queue. The more messages await, the faster we need to process them, so launching new workers is the way to go.</p><p id="181c">It’s much better, but we want to save costs when possible, so let me introduce <em>preemptible nodes</em>!</p><blockquote><p id="e0c7">Preemptible VMs are Compute Engine <a href="https://cloud.google.com/compute/docs/instances/preemptible" rel="noopener ugc nofollow" target="_blank">VM instances</a> that are priced lower than standard VMs and provide no guarantee of availability — <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms" rel="noopener ugc nofollow" target="_blank">Google Cloud documentation</a>.</p></blockquote><figure><figcaption>Custom-made schema representing the more complex architecture with Kubernetes and preemptible nodes.</figcaption></figure><p id="7098">We want our user to have the best experience, but it’s perfectly fine for us if they don’t have access to the best video quality in adaptative bitrate streaming format right as they upload their content. It can take a few minutes for a preemptible node to be available, but they are cheaper than a normal node.</p><p id="c20f">In this new schema, we transformed our NodeJS worker with FFmpeg to what we call internally a “spawner”. It still polls the RabbitMQ queue, but instead of processing the video itself, it will launch a new Kubernetes pod in a preemptible node, and this new pod will do the processing.</p><p id="bd2e">This way is cheaper. We switched all our resource-intensive tasks in a preemptible node, so we don’t need to scale our spawner as much in a normal-priced node.</p><p id="e538">Google Cloud can kill preemptible nodes if a normal node needs the resources. We must ensure a failed task goes back to the queue and starts again by another node later.</p><blockquote><p id="6026">Terminated when Compute Engine requires the resources to run standard VMs — <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms#comparison_to" rel="noopener ugc nofollow" target="_blank">Google cloud documentation</a></p></blockquote><p id="87f2">This new setup with preemptible nodes brings more overhead in the implementation but a significant price improvement. We reached a point where we could scale vertically indefinitely.</p></div><div><h2 id="6d42">Second step: Video playback</h2><p id="7539">Alright, at this point in the process, we uploaded and transformed our user video to stream it on our site. A video could be hundreds of megabytes split into thousands of chunks.</p><p id="eeed">The video HTML tag does not support adaptative bitrate streaming formats like HLS or MPEG-Dash by default, so we must use a custom player. The two most used players to handle streaming are <a href="https://github.com/video-dev/hls.js" rel="noopener ugc nofollow" target="_blank">HLS.js</a> and <a href="https://github.com/shaka-project/shaka-player" rel="noopener ugc nofollow" target="_blank">Skaka Player</a>. They both use <a href="https://www.w3.org/TR/media-source/" rel="noopener ugc nofollow" target="_blank">Media Source Extension</a> to be able to handle this format. <em>I won’t go into more detail about players and MSE as it’s not the goal of this article; you can read more by clicking on the link I provided.</em></p><p id="476c">To prevent loading the video files from the cloud storage each time someone tries to play the video, and therefore pay a lot of money to the cloud provider, we use a <a href="https://www.cloudflare.com/learning/cdn/what-is-a-cdn/" rel="noopener ugc nofollow" target="_blank">Content Delivery Network (CDN)</a>.</p><figure><figcaption>Custom schema showing the process of using a CDN</figcaption></figure><p id="3bcd">The user lands on the site to stream the video. All calls to retrieve the video go through our CDN provider, Cloudflare. A CDN will cache the content at the edges, which means if the content you are requesting is not present in their cache, it will demand it to the URL you provided.</p><p id="7437">The “edge” part means that depending on where you are in the world, it will store it in a server close to you (regionally) so that if a user in your region asks for the same content, he gets it blazingly fast. If a user from another side of the world asks for the same content, it will do the same process and store it close to that user.</p><p id="6d56">Each video chunk is a separate file, so the waiting time for the unlucky user who has to create the cache is still relatively low. Not thousands of megabytes to download at once.</p></div><div><p id="beb3">I skipped some essential parts of our architecture like micro-services, WebSockets, Redis pub/sub, or webhooks to keep the focus on Kubernetes’ auto-scaling capabilities in combination with RabbitMQ asynchronous queues. I’ll probably write another article about “communication” in our architecture soon.</p><p id="23bd">YouTube probably has an implementation that differs significantly from ours, but it’s already a good look into what a complex system with Kubernetes might look like.</p><p id="25aa">I would love to be a little mouse and peek at YouTube’s complete architecture to see how far we are from them. I might want to contact Ratatouille’s movie creator to do so; it’s a real story right?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feds find "substantial'' safety issue at SC nuclear plant (114 pts)]]></title>
            <link>https://www.thestate.com/news/local/environment/article280228714.html</link>
            <guid>37823141</guid>
            <pubDate>Mon, 09 Oct 2023 17:49:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thestate.com/news/local/environment/article280228714.html">https://www.thestate.com/news/local/environment/article280228714.html</a>, See on <a href="https://news.ycombinator.com/item?id=37823141">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="primary-content"><!----><!----><!----><figure><div>
        
                








    
        <div>
            <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_1140/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 992px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_960/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 768px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_768/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 601px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_640/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 441px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_480/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 320px)">
                <!--[if IE 9]></video><![endif]-->
                
                <img srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_1140/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" alt="V.C. Summer nuclear site in Fairfield County. SCANA abandoned plans to build two new reactors in 2017. They would have complemented the existing reactor." title="V.C. Summer nuclear site in Fairfield County. SCANA abandoned plans to build two new reactors in 2017. They would have complemented the existing reactor." loading="lazy">
                
            </picture>

            
        </div>
    

            
        

                 
                
                    
                        <figcaption>
                            
    
        V.C. Summer nuclear site in Fairfield County. SCANA abandoned plans to build two new reactors in 2017. They would have complemented the existing reactor.
    
    
        
            
        
        
    

                        </figcaption>
                    
                
        
    </div></figure><!----><!----><!----><!----><!--[--><!--[--><p>Federal regulators have cited Dominion Energy for what they say is a substantial safety violation after finding that utility workers failed for 20 years to resolve cracking problems at the company’s V.C. Summer nuclear power plant northwest of Columbia.</p><!----><!--]--><!--[--><p>This past week, the U.S. Nuclear Regulatory Commission issued what’s known as a preliminary “yellow’’ safety assessment, a measure of how serious an atomic safety problem is considered at a power plant. Yellow assessments are the second most serious on an NRC scale of severity.</p><!----><!--]--><!--[--><p>The NRC, which rarely issues yellow findings, said nuclear plant operators <a href="https://www.thestate.com/news/local/environment/article279283589.html" target="_blank" rel="Follow">did not resolve cracking </a>problems from 2003 to 2022 in V.C. Summer’s diesel generator system, one of the most important backup safety systems at an atomic power plant.</p><!--]--><!--[--><p>NRC officials were not available Friday to explain their concerns with the backup diesel generator system, but an Oct. 4 enforcement letter to Dominion nuclear operations president Eric Carr said the utility violated an atomic safety standard that could result in more scrutiny of the power plant. </p><!----><!--]--><!--[--><p>“We are considering escalated enforcement for the apparent violation,’’ according to the letter signed by LaDonna Suggs, acting director of the NRC’s division of reactor projects.</p><!--]--><!--[--><p>That’s no surprise to one nuclear safety advocate. Yellow designations often spark additional investigation and scrutiny of atomic power plants like the one in Fairfield County, said David Lochbaum, a national expert on the inner workings of nuclear plants and NRC oversight.</p><!----><!--]--><!--[--><p>“The NRC feels this was avoidable,’’ Lochbaum said, when asked why the agency issued a yellow finding. “There were signs of problems that were overlooked. Because of that, the problem grew to a point where the diesel generator’’ system did not work during testing.</p><!----><!--]--><!--[--><p>“You’re supposed to find and fix problems that occur,’’ he said.</p><!--]--><!--[--><p>Since 2009, the NRC has issued seven yellow findings against the nation’s nuclear power plants, Lochbaum said, after reviewing agency records. Only a red designation is considered worse, with white and green findings less significant. The United States has nearly 100 nuclear plants.</p><!----><!--]--><!--[--><p>The NRC’s determination is not final and is listed as an “apparent’’ violation. Dominion will have an opportunity to explain more about the diesel generator system issues, according to the NRC. Dominion spokesman Darryl Huger said the company “has implemented a plan to improve the system’s reliability.’’</p><!----><!--]--><!--[--><p>Huger, in an email to The State, said V.C. Summer has a history of operating safely, maintaining what he said was an “exemplary’’ record. The recent NRC concern centers on a pipe that delivers fuel to one of the power plant’s two emergency diesel generators, he said. Dominion found problems after testing the piping system, according to the NRC. </p><!--]--><!--[--><p>The power company, which acquired former V.C. Summer plant owner SCE&amp;G after a failed effort to build two additional reactors at the site, plans to install thicker piping in the generator system, Huger said.</p><!----><!--]--><!--[--><figure>                      <div>            <picture>                <!--[if IE 9]><video style="display: none;"><![endif]-->                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_1140/ReactorsFretwellPix5x2.8" media="(min-width: 992px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_960/ReactorsFretwellPix5x2.8" media="(min-width: 768px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_768/ReactorsFretwellPix5x2.8" media="(min-width: 601px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_640/ReactorsFretwellPix5x2.8" media="(min-width: 441px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_480/ReactorsFretwellPix5x2.8" media="(min-width: 320px)">                <!--[if IE 9]></video><![endif]-->                                <img srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_1140/ReactorsFretwellPix5x2.8" alt="V.C. Summer nuclear plant in Fairfield County, S.C. The site has one reactor. Two other reactors planned for the site were never completed." title="ReactorsFretwellPix5x2.8" loading="lazy">                            </picture>                            <figcaption>                                            V.C. Summer nuclear plant in Fairfield County, S.C. The site has one reactor. Two other reactors planned for the site were never completed.                                                                                            Sammy Fretwell/The State                                                                                    </figcaption>                    </div>        </figure><!----><!--]--><!--[--><p>Dominion’s backup diesel generator system, like those at other nuclear plants, is designed to provide power to parts of the plant that need electricity in the event power is knocked out during an emergency, such as a storm or earthquake.</p><!--]--><!--[--><p>That’s important because power is needed to keep water running through the nuclear reactor core to prevent it from overheating. If power is lost, the nuclear fuel can melt, causing radiation to be released into the surrounding community.</p><!----><!--]--><!--[--><p>In this case, officials at the V.C. Summer plant learned about cracks in fuel pipes in the facility’s diesel generator system in 2003. Utility workers fixed the initial crack, as well as other cracks four different times in the years after the initial work was done. </p><!----><!--]--><!--[--><p>But the NRC says the utility never adequately assessed what could be done to make sure the diesel piping system did not experience more cracking. The most recent cracks were identified in November 2022 during a 24-hour test of the system. Workers found a small leak on one of two diesel generator systems. The leak increased over time and workers discovered a 140-degree crack around a pipe, records show.</p><!--]--><!--[--><p>The cracking occurred mostly in the power plant’s “A” diesel generator system, although one problem occurred in the plant’s “B” generator system. The plant has two backup diesel generators. </p><!----><!--]--><!--[--><p>The cracking that led to the yellow safety finding follows separate, electrical problems with the plant’s diesel generator system in 2022. The NRC said the company, in that case, also <a href="https://www.thestate.com/news/local/environment/article268772222.html" target="_blank" rel="Follow">failed to promptly resolve</a> problems, issuing a white finding last year. White is lower in safety significant than yellow, but still considered notable.</p><!----><!--]--><!--[--><p>Tom Clements, a long-time nuclear safety advocate, said the NRC’s recent yellow safety assessment reveals a violation “too egregious to ignore.’’ He called for a “severe monetary fine’’ against Dominion, which he said ignored preventative maintenance through the years.</p><!--]--><!--[--><p>Dominion’s problems are noteworthy in light of the company’s recent request to renew its V.C. Summer operating license another 40 years, Clements said. The power plant, which cranked up operations in the early 1980s, is about 25 miles northwest of Columbia in rural Fairfield County.</p><!----><!--]--><!--[--><p>“Hopefully, serious safety problems don’t lurk in other reactor safety systems at the reactor,’’ Clements said in an email to The State. “This incident serves as a wake-up call to fully analyze all such systems prior to a license-renewal determination.’’</p><!----><!--]--><!--[--><figure>                      <div>            <picture>                <!--[if IE 9]><video style="display: none;"><![endif]-->                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_1140/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 992px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_960/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 768px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_768/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 601px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_640/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 441px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_480/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 320px)">                <!--[if IE 9]></video><![endif]-->                                <img srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_1140/photo-plant-nuclear,%20from%20SCEG.jpg" alt="The V.C. Summer Nuclear power plant is in Fairfield County, SC. It is operated by Dominion Energy." title="photo-plant-nuclear, from SCEG.jpg" loading="lazy">                            </picture>                            <figcaption>                                            The V.C. Summer Nuclear power plant is in Fairfield County, SC. It is operated by Dominion Energy.                                                                                                                                                                        <span>Dominion Energy photo</span>                                                            </figcaption>                    </div>        </figure><!--]--><!--]--><!----><p>This story was originally published <span>October 7, 2023, 10:17 AM.</span></p><!----><!----><div><article> 
        
            
    
    

<div>
    <p><a href="https://www.thestate.com/profile/218308580">
                <img src="https://www.thestate.com/latest-news/kbyrpl/picture222581940/alternates/FREE_480/FretwellMug.jpg" alt="Profile Image of Sammy Fretwell" loading="lazy">
            </a>
    </p>

    

    
    
        <p><span>Sammy Fretwell has covered the environment beat for The State since 1995. He writes about an array of issues, including wildlife, climate change, energy, state environmental policy, nuclear waste and coastal development. He has won numerous awards, including Journalist of the Year by the S.C. Press Association in 2017. Fretwell is a University of South Carolina graduate who grew up in Anderson County. Reach him at 803 771 8537.</span>
        <a href="https://account.thestate.com/subscribe/create?param=f3JBCko=&amp;offer=NmEfaxcUb3lSCUJAfRIiaSA8CncoYyc3BA9BG15QPgoUG0hQeHNFCkBKb29STx0HLisVS1BIbwA%2FdUtLAAxCdD1QMA%3D%3D&amp;cid=news_author-card_fretwell-.99mo-2mo-15.99_202007">Support my work with a digital subscription</a></p>
</div>

        
    </article></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linuxatemyram.com (234 pts)]]></title>
            <link>https://www.linuxatemyram.com/</link>
            <guid>37822927</guid>
            <pubDate>Mon, 09 Oct 2023 17:31:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linuxatemyram.com/">https://www.linuxatemyram.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37822927">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

      <center>
        <img src="https://www.linuxatemyram.com/atemyram.png" alt="Linux ate my RAM!">
        <p id="blinkyblink">
          <h2>
            Don't Panic!<br>Your ram is fine!
          </h2>
        </p>
      </center>

        <h2>What's going on?</h2>
        <p>Linux is borrowing unused memory for disk caching. This makes it look like you are low on memory, but you are not! Everything is fine!</p>

        <h2>Why is it doing this?</h2>
        <p>Disk caching makes the system much faster and more responsive! There are no downsides, except for confusing newbies. It does not take memory away from applications in any way, ever!</p>

        <h2>What if I want to run more applications?</h2>
        <p>If your applications want more memory, they just take back a chunk that the disk cache borrowed. Disk cache can always be given back to applications immediately! You are not low on ram!</p>

        <h2>Do I need more swap?</h2>
        <p>No, disk caching only borrows the ram that applications don't currently want. It will not use swap. If applications want more memory, they just take it back from the disk cache. They will not start swapping.</p>

        <h2>How do I stop Linux from doing this?</h2>
        <p>You can't disable disk caching. The only reason anyone ever wants to disable disk caching is because they think it takes memory away from their applications, which it doesn't! Disk cache makes applications load faster and run smoother, but it NEVER EVER takes memory away from them! Therefore, there's absolutely no reason to disable it!</p>
        <p>If, however, you find yourself needing to clear some RAM quickly to workaround another issue, like a VM misbehaving, you can force linux to nondestructively <a href="https://linux-mm.org/Drop_Caches">drop caches</a> using <code>echo 3 | sudo tee /proc/sys/vm/drop_caches</code>.</p>

        <h2>Why does top and free say all my ram is used if it isn't?</h2>
        <p>This is just a difference in terminology. Both you and Linux agree that memory taken by applications is "used", while memory that isn't used for anything is "free".</p>
        <p>But how do you count memory that is currently used for something, but can still be made available to applications?</p>
        <p>You might count that memory as "free" and/or "available". Linux instead counts it as "used", but also "available":</p>
        <table>
          <thead>
            <tr>
              <th>Memory that is</th>
              <th>You'd call it</th>
              <th>Linux calls it</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>used by applications</td>
              <td>Used</td>
              <td>Used</td>
            </tr>
            <tr>
              <td>used, but can be made available</td>
              <td>Free (or Available)</td>
              <td>Used (and Available)</td>
            </tr>
            <tr>
              <td>not used for anything</td>
              <td>Free</td>
              <td>Free</td>
            </tr>
          </tbody>
        </table>
        <p>This "something" is (roughly) what top and free calls "buffers" and "cached". Since your and Linux's terminology differs, you might think you are low on ram when you're not.</p>

        <h2>How do I see how much free ram I really have?</h2>
        <p>To see how much ram your applications could use without swapping, run <code>free -m</code> and look at the "available" column:</p>
        <pre>  $ free -m
                total        used        free      shared  buff/cache   available
  Mem:           1504        1491          13           0         855      <span><strong>792</strong></span>
  Swap:          2047           6        2041
</pre>
        <p><small>(On installations from before 2016, look at "free" column in the "-/+ buffers/cache" row instead.)</small></p>
        <p>This is your answer in MiB. If you just naively look at "used" and "free", you'll think your ram is 99% full when it's really just 47%!</p>
        <p>For a more detailed and technical description of what Linux counts as "available", see <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=34e431b0ae398fc54ea69ff85ec700722c9da773">the commit that added the field</a>.</p>

        <h2>When should I start to worry?</h2>
        <p>A <strong>healthy Linux system</strong> with more than enough memory will, after running for a while, show the following expected and harmless behavior:</p>
        <ul>
          <li><code>free</code> memory is close to <code>0</code> </li>
          <li><code>used</code> memory is close to <code>total</code> </li>
          <li><code>available</code> memory (or "free + buffers/cache") has enough room (let's say, 20%+ of total)</li>
          <li><code>swap used</code> does not change</li>
        </ul>
        <p><strong>Warning signs</strong> of a genuine low memory situation that you may want to look into:</p>
        <ul>
          <li><code>available</code> memory (or "free + buffers/cache") is close to zero</li>
          <li><code>swap used</code> increases or fluctuates</li>
          <li><code>dmesg | grep oom-killer</code> shows the OutOfMemory-killer at work</li>
        </ul>

        <h2>How can I verify these things?</h2>
        <p>See <a href="https://www.linuxatemyram.com/play.html">this page</a> for more details and how you can experiment with disk cache to show the effects described here. Few things make you appreciate disk caching more than measuring an order-of-magnitude speedup on your own hardware!</p>

        <small><strong>LinuxAteMyRam.com was presented by <a href="http://www.vidarholen.net/">VidarHolen.net</a>. This site is available <a href="https://github.com/koalaman/linuxatemyram.com">on GitHub</a> for comments and PRs.</strong></small>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Medieval staircases were not built going clockwise for the defender's advantage (285 pts)]]></title>
            <link>https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/</link>
            <guid>37822774</guid>
            <pubDate>Mon, 09 Oct 2023 17:20:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/">https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/</a>, See on <a href="https://news.ycombinator.com/item?id=37822774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

	<main id="main" role="main">

		
			
<article id="post-3655">

	<!-- .entry-header -->

	<div>
		
<p>This story has been making the rounds on the internet with a claim that you’ve probably been told during visits to castles, but, it’s not true.</p>


<div>
<figure><img data-attachment-id="3661" data-permalink="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png" data-orig-size="601,1139" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2023-10-09-at-14-55-37-historic-vids-on-x" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=158" data-large-file="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=540" width="601" height="1139" src="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=540" alt="" srcset="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png 601w, https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=79 79w, https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=158 158w" sizes="(max-width: 601px) 100vw, 601px"></figure></div>


<p>In short the idea is that it’s easier for a soldier or right-handed knight to fight in a spiral staircase that is built clockwise when they were defending the castle as they had space to swing their weapon while the attacker would find this more difficult.</p>



<p>Like many myths that stick, the story at first makes sense.<br>So when we hear it from a guide during a castle tour, from our history teacher, or even on television documentaries, why would we doubt it?</p>



<p>But if you think about it a bit longer and start looking for evidence, you soon realise something is a bit iffy here.<br>For starters, there is no primary evidence, whatsoever, that the people who built, lived and fought in these castles built staircases in that way for that reason. During the Middle Ages, nobody wrote down that you should build staircases like this and why.<br>If it had been common knowledge among castle builders, then why are there still quite a lot (about 30%) of castles with counter-clockwise staircases?<br>And no, before you start, there’s no evidence of the Kerrs being left handed, that’s probably an 19th century (yes, them again) <a href="https://triskeleheritage.triskelepublishing.com/2023/08/15/mediaeval-mythbusting-blog-24-the-left-handed-kerrs/">myth</a>.<br>The Tower of London, one of the most important castles in England, where royalty live(d) has counter-clockwise stairs!<br>If medieval people thought this would give the defenders not an advantage, surely they would have fixed it, especially in this castle!</p>


<div>
<figure><img data-attachment-id="3666" data-permalink="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/both-stairs-at-cliffords-tower/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg" data-orig-size="921,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="both-stairs-at-cliffords-tower" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=300" data-large-file="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=748" width="921" height="640" src="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=921" alt="" srcset="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg 921w, https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=150 150w, https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=300 300w, https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption>Both these staircases are at Clifford’s Tower in York, two in the same building!<br>So the defenders didn’t mind if they weren’t at an advantage when the enemy took the right stairs?</figcaption></figure></div>


<p>Another reason why we know this story is a myth is that it also doesn’t make a lot of sense when you study medieval combat involving castles.<br>Castle builders knew that it didn’t really make a huge difference which way the stairs go, they’re not suitable for fighting at all, neither party has a lot of space to wield those long,<br>pointy, sharp weapons.<br>The person below you has the advantage of jabbing at your legs and feet while they can protect their head with their helmet and shield.<br>Of course the only way to win would be by pushing your enemy back down the stairs and then with whoever is left above you, retake the entire castle.<br>Yeah, that’s unlikely to work out.<br>Frankly, if you find yourself in this position the castle is probably already lost.<br>A better way to stop your enemy might be to block the stairs by throwing heavy furniture and everything else you can find down it while you then wait at the top of the stairs where you have more space to fight and where your enemy really is at a disadvantage as they’re still on the stairs below you.</p>



<p>For attackers it’s also not a very tempting scenario.<br>If you’ve already breached all the outer walls and defeated all the soldiers there, who would want to risk their life crawling up some stairs where the defenders are waiting for you?<br>Sieges often didn’t involve much fighting at all, as simply waiting outside the castle till the people inside ran out of water and food was a much easier and less bloody way to win.<br>In many cases simply realising the enemy was going to sit outside and wait was enough to surrender.</p>





<p>So in conclusion: there’s no evidence for this claim and it also doesn’t make a lot of sense.<br>This, like SO MANY myths about the middle ages can very likely be <a href="https://archive.org/details/spiralsinnaturea00cook/page/144/mode/2up">credited to the Victorians</a>.<br>For more research &amp; the opinions of historians, archaeologists &amp; other experts check the sources below.</p>



<p>Stairs were used to go up and down floors, they were not dimly lit or built to be uneven on purpose as you wouldn’t want servants, soldiers but also the lords and ladies themselves falling down them all the time.<br>“Oh no Lord Dave has fallen down the stairs and broken his neck because we have no lights and dodgy steps in the tower just in case there’s a siege even though we haven’t had one in generations….”</p>



<p>And if you’re trained in medieval combat and have access to some castle stairs, please do some experimenting, try if you can fight there and make a video of it, I’ll share it here!<br>Do be careful &amp; responsible though, I won’t take responsibility for you damaging yourself or worse, the castle 😉</p>



<p><strong>Sources:</strong></p>



<ul>
<li><a href="https://fakehistoryhunter.net/2023/09/08/ive-written-a-book/">Fake History, 101 things that never happened, by J.H.Teeuwisse</a></li>



<li><a href="http://www.castlestudiesgroup.org.uk/CSGJournal2011-12X5Stairs-low-res.pdf">‘The Rise of the Anti-clockwise Newel Stairs’, research by the Castle Studies Group (pdf link)</a></li>



<li><a href="https://www.medievalists.net/2012/08/the-rise-of-the-anti-clockwise-newel-stair/">Medievalists.net</a></li>



<li><a href="https://triskeleheritage.triskelepublishing.com/mediaeval-mythbusting-blog-2-the-man-who-invented-the-spiral-staircase-myth/">Triskele Heritage</a></li>



<li><a href="https://talesoftimesforgotten.com/2019/12/18/no-medieval-staircases-werent-designed-to-give-right-handed-defenders-an-advanta">Tales of times forgotten</a></li>



<li><a href="https://www.reddit.com/r/AskHistorians/comments/406sa5/were_castle_stairs_designed_to_impede_sword_use/">r/AskHistorians</a></li>
</ul>



<p>If you like my work, please consider supporting me on <a href="https://www.patreon.com/fakehistoryhunter">Patreon</a>;</p>


<div>
<figure><a href="https://www.patreon.com/fakehistoryhunter"><img data-attachment-id="1998" data-permalink="https://fakehistoryhunter.net/become_a_patron_button2x/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp" data-orig-size="434,102" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="patreon" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=300" data-large-file="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=434" loading="lazy" width="434" height="102" src="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=434" alt="Become a patron" srcset="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp 434w, https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=150 150w, https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=300 300w" sizes="(max-width: 434px) 100vw, 434px"></a></figure></div>


<p>Disclaimer;<br>Picture(s) found online, used for (re-)educational purposes only.<br>I do not own the copyrights to these images, I only share them here for educational purposes to try and make sure the real story behind it becomes known and people will stop spreading false information.<br>If the copyright owner objects to the sharing here, kindly contact me and I shall alter the article.<br>If you’re interested in using any of the images here get in touch with the copyright owners mentioned in the article.<br>Feel free to contact me with questions.</p>


<div>
<figure><img data-attachment-id="3673" data-permalink="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/clockwise-staircases/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg" data-orig-size="4203,2500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="clockwise-staircases" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=300" data-large-file="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=748" loading="lazy" width="4203" height="2500" src="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=1024" alt="" srcset="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=1024 1024w, https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=150 150w, https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=300 300w, https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=768 768w" sizes="(max-width: 4203px) 100vw, 4203px"></figure></div>



			</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->
			
	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
			<hr>

			
<!-- #comments -->

		
	</main><!-- #main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lensm, a tool for viewing disassembly (135 pts)]]></title>
            <link>https://www.storj.io/blog/lensm</link>
            <guid>37822284</guid>
            <pubDate>Mon, 09 Oct 2023 16:45:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.storj.io/blog/lensm">https://www.storj.io/blog/lensm</a>, See on <a href="https://news.ycombinator.com/item?id=37822284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I couldn’t find a great tool for viewing disassembly, so I <a href="https://github.com/loov/lensm">wrote it myself over the weekend</a>.</p><p>At Storj, we are constantly looking for ways to accelerate our team’s efficiency, and one of those is building the tools we need.</p><p>One of the major things you will rub against when you delve into performance optimization is viewing the assembly that the compiler generates. It's usually not efficient to write assembly yourself, and it's better to try to coerce the compiler to produce the assembly you want. Here's my story of writing a little tool for viewing disassembly.</p><h2>Getting Annoyed</h2><p>My story starts on a weekend when I was doing a bunch of tiny optimizations to the <a href="https://gioui.org/">Gio UI</a> project. There are ways to view the assembly; one is to use <strong>go tool objdump -s funcname</strong> from the command line. However, it's rather difficult to see how the source code and assembly are related.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cb12919477d388915cc_t8ODK_OCt9V0GN9lHO1jcjyu9RUAPpIP9cEvOgvmPiucYhk_aMd-UloDUGJJkcEA1oesZN22AuBJTFu__jToyjt6-GIE7cmVmh76yTpzEEBA2AP5-qIqdz_5B5D444i8BtXaRnM-rc_nGXo9NGE.png" alt=""></p></figure><p>There is an excellent online tool for writing code and seeing the output <a href="https://go.godbolt.org/">https://go.godbolt.org</a>. The visuals are much clearer.</p><p>The corresponding lines of code have the same color. When you hover over the specific lines of code, the corresponding assembly is also highlighted.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc602e1d3ed86d1b95e_DMf8jw43xXtFI9VfW3Hj17WssFpJzHrR5lDCejh-3X7phoUaeKtkl3lAHFPvBcgT-gPKgSSj6nCPFXPhi2purUPZsCrZ2SiTZursoz4K6kEUt6Zw1tUzFA3J-hjCQFtqtkrw7MkfPMXuW7X3RQM.png" alt=""></p></figure><p>Compiler Explorer has many other nice features as well: sharing the result, compiling with different versions, diffing output from different compilers, and description of assembly instructions. The amount of different languages and compilers is staggering.</p><p>Despite how nice Compiler Explorer is, it's still an online tool, and you need to copy-paste your relevant code to the explorer.</p><p>After trying many times, my annoyance finally kicked in:</p><p><em>"Someone should've written this tool already–it shouldn't be too difficult."</em></p><p>Over the years of developing, I've found that getting annoyed is a rather excellent way to start a new project.</p><p>The first step in the project was to have access to the disassembly. It would be wasteful to start a disassembler from scratch. I knew that <strong>go tool objdump</strong> could already do it, so maybe they have some library they are using.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc668b49010e1da87a0_9ZumolrPy31nqggaq6bmyW8SM52RXE8nu1UPccpx8b2swsXLZgCsZ2Zk9RPHOs_b1tfTRiyktO4-ICAZjlVFoujbwMHEvT1RBLPk7ozIchhTGEjpOrvJx8K5MUSLUkIKvku1kPOx89EZ6c0RI2Q.png" alt=""></p></figure><p>Indeed, they are using a library, but it's internal to the compiler. The internal library looks pretty nice to use as well. I guess I need to extract it for my own needs. Copying the relevant code and adjusting the import paths was grunt work, but I got it extracted. Luckily the license for the Go code is open-source.</p><p>I needed to expose a little bit more information from the API to access the <a href="https://github.com/loov/lensm/commit/5bb596225accd3d6c0b4dbc13c4e6189c558c879#diff-1596bd8ceb74246828aacab827b39a33075c86baa627fbbeb7491bd31eef1169">necessary details</a>, but I got it working. Here's the debug print from the initial output:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc6a3af67247e7df4fb_qb8O0Gzs-OGv1nnBklsfecHlKD6x7JpTrPfCW_N7KKQi9rcC95pGDTMootqeXThAIVxyViremLEKkBZljKxOEEqROCnD89s3VYdyU6rV9lJQyXQgLK2UtNrEjtmjuBBWJL8QFAcpdAACqhQZOkU.png" alt=""></p></figure><p>Of course, extracting the internals means needing to keep it manually updated. I'm sure there was a tool to rewrite the paths and keep them automatically updated. Alternatively, maybe the Go project would accept a patch that exposes the information in some JSON format so the visualizer can call the appropriate Go compiler. But all of that is a project for another day.</p><h2>Extracting Source Code</h2><p>The first important step was to figure out the relevant source code that needed to be loaded. This seems a relatively easy thing in concept. It's mainly "Collect the list of lines per source file". However, the gotcha is how to represent the data, and similarly, you probably don't want just the lines but also some of the surrounding code.</p><p>This is the basic structure for representing source:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55d48d4896058b5eb6965_BJUkF2Uiv10IYKczczPkzefpWBzNt4QzGDlC7cJU9OA670QO25JLlNpojNqynyJHwMk3aFuRN1fytiEEvlIeuRcw9qu88diNKMX8g4QtY08nAWBKf_JaELPFRpRNgh0REC_767Sbbp75D6cVPlQ.png" alt=""></p></figure><p>Every assembly function can have multiple associated <strong>Source</strong> files due to inlining. Similarly, the code needed from different files isn't contiguous, and you wouldn't want to show more than is required.</p><p>Most of the data munging is: collect all the source lines, convert them into ranges, expand the ranges (for the surrounding context). We also need to do it in reverse: figure out which lines in disassembly correspond to the source code. Note that each source line can correspond to multiple disassembly lines, and they might not be contiguous.</p><p>Once I got it working, I did a debug print of the relevant source lines:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc768b4902b80da87ec_EpbrIxhdW9F6YPsgVzttahc-6E1a9K4K3NuhkZoQbBRHcAf10iM2AHwdNnmF4aOyvtj0Atj7TuihVvPExnRym8JaB2o5G-AnfxKhg7OA8YBGNVQBSSWUncArrpf05OjKJt0dD4K0Iu804GtrXvo.png" alt=""></p></figure><h2>Drawing Code</h2><p>I was trying to optimize the code for <a href="https://gioui.org/">Gio UI</a>, so of course, it was a natural choice for building a tool such as this. It has pretty lovely drawing capabilities that I'll need.</p><p>The question was then, how should it be visualized. Compiler Explorer visualization is a great starting point. However, it's not as clear as I would like it to be. When starting the project, I already had a design in mind. There are many source diffing tools that offer visualizing related lines. For example, here is what Meld tool looks like:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc66767e74611aa360e_m0noVeRrYWM5IJkJhVOzigPqft8IKGueEubr3DLK4Ai0nzTPHXWvg70UdRclyZruohGiEnLkhU04GSTV1WOprOcoQzvROVf8qVqLKzKNhgny7_nKuK4nPERBTSUy_fE6cmaCb5lL18Sq6Z0qhDI.png" alt=""></p></figure><p>There are other tools such as Kompare, CodeCompare, Oxygen Compare that offer similar visualization. I really like how it shows how one side is related to the other. To draw the shape, we can use the following idea:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc7382d3335e050c095_usrJMIUtSESOyvB0GzlSs6yR1x0Uh6OUe9Sd_KaA12uAdnqSbL3ETP46qLbYAvNS1-OV2o9xAceE1QXyHa2hr911wUwVNm5FXYXhm9yr5WvmNWnCR0sPH77iB1t0IGr0Wjs2nl1Tk3xVd5nozLo.png" alt=""></p></figure><p><em>The purple lines show the final relation shape. The orange arrows show bezier curve handles.</em></p><p>Drawing the visuals seemed then straightforward:</p><ol role="list"><li>figure out the location of each line of the source and assembly;</li><li>draw the relation shape for each line of source and related assembly lines;</li><li>draw the text on top of the relation shapes.</li></ol><p>One difficult thing people encounter with such projects is: how to choose a random color such that they are distinct, visually pleasing, and code is easy to write. One nice trick I've picked up over time is this formula:</p><p><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hue: index * phi * 2 * PI, saturation: 60%, lightness: 60%</em></p><p>You can adjust the saturation and lightness between 50% to 90% to get different lightness and saturation. If you want a more pastel color look, you would use a lower saturation and higher lightness. For dark mode, you would use lightness below 30%. (The color selection assumes that hue is defined with the range 0 .. 2*PI). There are a few variations of the hue selection:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc6291947aee6891f09_jDepN774WglSl6bMQnycbS9HX-BDsvx5RS_fY1vEsyZmiaviZOl2BUvMeBf2_tPJ2Obil58YigtEhxVa2nzz7m2zP6BAOo6YariH3C9_nwyw_bWW-vLphnx9vJFfTvpab7StlD0F1XdDVgIrKts.png" alt=""></p></figure><p>As you can see, the 𝜑 = 1.618033988749… constant allows selecting values on a hue circle such that sequential numbers are different and won't repeat. If you want a smoother transition, then using i × 1/𝜑 works a treat. If you want more contrast, then i × 𝜑 × 2𝜋 is nicer.</p><p>Once you put all these ideas together, you get the first output:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc792d7842017b7cca1_vj_GRqrXEcs_dWwyk7qZ-cbU6QwULj0sNybAArPdZn4QX0f5N8GoKcmkw0IxCgwc8NKetA5QXiC_qSa9BRWNqqZuaD5uuhpJpPBIPZu6BuN8h8I1w-WD8zKr8IltoyiPjfp28-ULlCUXv6wGOfM.png" alt=""></p></figure><p>I also added a small interaction – when you hover the mouse over a line of code, it highlights the relation shape.</p><h2>Drawing Jumps</h2><p>The next thing I wanted to visualize was drawing jumps in the code. They are important from a performance perspective. It's relatively common for disassemblers to draw an arrow from the jump location to the destination. This brings up two problems, detecting the jumps, and figuring out how to draw the lines.</p><p>Unfortunately, the objfile library disassembler doesn't expose the information whether the instruction is a jump and when it jumps, then where to. I didn't want to dig too deep into this, so I reached for the usual tool for this – regular expression matching. It seemed that all the jumps ended with a hex number, such as <strong>JMP 0x123</strong>... of course, that approach broke. On arm processors, they look like <strong>BLS 38(PC)</strong>. I added a special case for it for now, but it'll probably break again on some other platform.</p><p>To draw the jumps initially, I just drew them like a stack. In other words, push the jump line to the sidebar when you encounter one and then pop it when it ends. Of course, that didn't look great due to overlapping lines:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc7382d33da3a50c09c__vBqyuDL7Iwp3ZxyvZRiUyK-FoWL5JpH8PR7-UgVOr1Iw2vE6RFeM6syPPmhbeDfPLzoEWFEPzZYnA3k-X_6400rJYVj8BYQbIT66K-ITM3p9O61nnlzBK-LDwT-_z9Bs_HDhByCaFBuytRNe7s.png" alt=""></p></figure><p>In some cases it even caused the lines to be on top of each other. I searched for a nice algorithm for drawing them; however, I came up empty. Finally, I decided to go with the following approach, sort all the jump ranges based on their starting and ending point. If multiple ranges start from the same location, the larger range is sorted first. Then divide the sidebar into lanes; every new range picks the first lane that is free – starting from the left. This ends up minimizing crossings.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc733365697a909185c_PGA8v7YrP_F3LQKUIGUH9PZ8XpRfsEHP_Qyc6sKvZNavb-xgdPOWrquHLk1oaLEDEx00aBkwdrCLdm152__r96IX9HTiUqEfExezajtIZV_oVZNVu6fM89Xdu4JcG8w64ueUPFl30ILIdZQlQJ4.png" alt=""></p></figure><p>It's by no means ideal. It can still draw the jump line too far from the code.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc7557a628d36655417_cOlVg7oIrOA5VJ-IPJujha90ug3CYdF9ENhcbtkQekQhn-RhI-3ry2gMUo9HZBMPfmOLTgZjcJK2zbCrucMUf1IYYU9cZDdQzQmRBHkSjkIJzxEWsuKNuC16mzuS_FGweaQK0Q7jAl_53bio3S4.png" alt=""></p></figure><p>Or do this thing here:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc74d138d629ee5bd63_oFJWLa1Kq1CQiIR9t4Uw0VRB4VJ5M1DAzUGp5fsxky3zNkmb0EM6LERZ_eZJSC01cV_ar1JVESdMP4PSZY2n6k946gE2jSVlWUU-JYSQqiLTFNVhlt2s0y3ujeqBhRhDPECjMJL6b2N5MS5yVl4.png" alt=""></p></figure><p>But, these are things someone will fix some other day.</p><h2>Summary</h2><p>After a few days of work, I have a nice tool for viewing disassembly. </p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc724fc82ab5179a8e9_nn9EQG2KhJKrJqL0g9OwAKDzdb5-N9OcWcWKsKNbFs3GoOlsqPdbEEvGWPE5Ncnq0qd1og8yMFVgTvmx2QkKwo7suFvnHJCXVEx1iTAmGddNDUumhTB-ugVIZfbT9nuJWka92IvIp6MQFT3x5jU.png" alt=""></p></figure><p>Choosing a name was also a struggle. I wanted it to be easily recognizable and searchable. I asked in Gophers #performance channel and Jan Mercl suggested "lensm," which is "lens" and "asm" smushed together.</p><p>When you look at the code and think: "For a performance-conscious project, it doesn't look very efficient – allocations and suboptimal algorithms everywhere. Also, the code looks very messy."</p><p>That's all true, but the goal was to get it done quickly. And, if I do need to optimize, then I have an extra tool in my toolbelt to optimize it.</p><p>I'll still have a few things I want to add before I can call it sufficiently complete. Nevertheless, it's already functional, so give it a test run at <a href="https://github.com/loov/lensm">https://github.com/loov/lensm</a>. If you feel like something is missing, then come along for the ride and submit a patch; there have already been a few contributors.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[789 KB Linux Without MMU on RISC-V (151 pts)]]></title>
            <link>https://popovicu.com/posts/789-kb-linux-without-mmu-riscv/</link>
            <guid>37822082</guid>
            <pubDate>Mon, 09 Oct 2023 16:28:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://popovicu.com/posts/789-kb-linux-without-mmu-riscv/">https://popovicu.com/posts/789-kb-linux-without-mmu-riscv/</a>, See on <a href="https://news.ycombinator.com/item?id=37822082">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" role="article">
      <p><a href="https://twitter.com/popovicu94?ref_src=twsrc%5Etfw" data-show-count="false">Follow @popovicu94</a></p>
<p>In this guide, we’ll build a very tiny Linux kernel, weighing in at 789 K, and requiring <strong>no MMU support</strong>. We’ll write some userspace code and this will be deployed on a virtual RISC-V 64-bit machine, without MMU, and we’ll run some tiny programs of our own.</p>
<p>As a reminder, please go through <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">the guide for a micro Linux distro</a> to understand the concepts behind what we’re doing today: building the kernel, <code>initramfs</code>, etc. This guide is basically a continuation of that one and an exercise in making an absolutely minimal Linux deployment for (in theory) extremely cheap hardware.</p>
<p>Like before, there’s very little here that is specific to RISC-V, I just want to stay consistent with my previous guides. This exercise should be easily repeatable for other architectures too (though <code>x86</code> may be somewhat sticky).</p>
<h2 id="table-of-contents">Table of contents</h2>
<details><summary>Open Table of contents</summary>
<ul>
<li>
<p><a href="#mmu-and-linux">MMU and Linux</a></p>
<ul>
<li><a href="#brief-history-of-uclinux">Brief history of uClinux</a></li>
</ul>
</li>
<li>
<p><a href="#challenges-with-mmu-less-linux">Challenges with MMU-less Linux</a></p>
<ul>
<li><a href="#executable-file-format">Executable file format</a></li>
<li><a href="#pointers-are-dangerous-obviously">Pointers are dangerous (obviously!)</a></li>
<li><a href="#vfork-instead-of-fork"><code>vfork</code> instead of <code>fork</code></a></li>
</ul>
</li>
<li>
<p><a href="#building-binaries-for-an-mmu-less-kernel">Building binaries for an MMU-less kernel</a></p>
<ul>
<li><a href="#getting-the-toolchain">Getting the toolchain</a></li>
<li><a href="#building-the-toolchain">Building the toolchain</a></li>
<li><a href="#building-bflt-files">Building bFLT files</a></li>
</ul>
</li>
<li>
<p><a href="#building-an-extremely-tiny-linux-kernel">Building an extremely tiny Linux kernel</a></p>
</li>
<li>
<p><a href="#building-an-initramfs-image-for-the-tiny-mmu-less-kernel">Building an <code>initramfs</code> image for the tiny MMU-less kernel</a></p>
</li>
<li>
<p><a href="#slightly-more-complicated-build-verifying-system-calls-and-multiprocessing">Slightly more complicated build: verifying system calls and multiprocessing</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
<li>
<p><a href="#github-repo">GitHub repo</a></p>
</li>
</ul>
</details>
<h2 id="mmu-and-linux">MMU and Linux</h2>
<p>An important piece of hardware when running an operating system is an <strong>MMU: memory management unit</strong>. This unit oversees memory accesses from a running CPU and translates them to different physical addresses. The reason why this is hugely important is because that is how the memory is <strong>virtualized</strong>, and the MMU is heavily used by the operating systems to implement a <strong>virtual address space</strong>. What this means is that the kernel typically enables the applications to not worry about how other running applications occupy the memory on a machine. Each process has an illusion of complete ownership of the memory, and the kernel facilitates that by virtualizing the memory. In other words, 2 processes on the same machine may use a memory location <code>0x12345678</code> and what they’d really be hitting inside the physical memory could be locations <code>0xAABBCCDD</code> and <code>0xDDCCBBAA</code>, respectively. The MMU, once set up by the kernel, will route the <code>0x12345678</code> accesses from each one of these applications to the relevant end physical address.</p>
<p>Your typical Linux build virtualizes the address space and uses the MMU for this, and while we didn’t explicitly set it in <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">the previous guide</a>, MMU was used and the memory contents of one process were insulated from the other processes.</p>
<p>Now, as useful as MMU is, not all machines have it. The super simple budget-friendly microcontrollers typically do not have it, and the memory addresses coming out of the program running are actually what is used to access the memory. In this case, if a process accesses <code>0x12345678</code>, it will go to the address <code>0x12345678</code> indeed.</p>
<h3 id="brief-history-of-uclinux">Brief history of uClinux</h3>
<p>As Linux has been rising in popularity since its inception, there have been attempts to run it on pretty much any digital device. This includes popular <a href="https://en.wikipedia.org/wiki/Microcontroller">microcontrollers</a> that do not have an MMU attached. Enter <strong>uClinux</strong>.</p>
<p>The proper name for uClinux is actually μClinux, with a Greek ‘mu’, and so μC stands for ‘microcontroller’. We spell it as uClinux for ASCII-friendly simplicity.</p>
<p>The uClinux effort, per my understanding, was running independently for some time, before the decision has been made to <strong>mainline</strong> it, meaning it is now part of the Linux source code itself. Basically, what this means for us is that uClinux is now a set of configurations in the kernel build config, and we’ll get our MMU-less build easily.</p>
<h2 id="challenges-with-mmu-less-linux">Challenges with MMU-less Linux</h2>
<p>Before we get our hands dirty, I would like to highlight a few challenges with running Linux in this way. I will from this point refer to our Linux as MMU-less Linux, rather than uClinux to avoid confusion with the old project that has since been mainlined.</p>
<h3 id="executable-file-format">Executable file format</h3>
<p>First, ELF binaries will not work anymore. I have not been able to build a MMU-less flavor of Linux for ELF, and I strongly believe it is impossible. I’m not sure if something about the ELF format explicitly assumes a virtual address space necessarily, I don’t think it does, but it just seems impossible to load an ELF binary for running.</p>
<p>What MMU-less Linux likes are the <strong>bFLT</strong> binaries. FLT stands for <em>flat</em>, and this initially made me believe that there really is no file format here, that we’re supposed to just dump the machine instructions into a bare file, but this really isn’t the case. bFLT has some structure, which is far simpler than ELF, but it’s structured nonetheless. I personally found it very difficult to find any good documentation on what this file format really looks like, and really the only useful page I have found on the Internet around it is <a href="https://myembeddeddev.blogspot.com/2010/02/uclinux-flat-file-format.html">this page</a> from someone’s personal blog. It’s a bit interesting to think that if this blog goes offline, there really isn’t anything out there left except the actual source code in the Linux codebase, and I’m sure you agree that’s not the most elegant way to learn.</p>
<h3 id="pointers-are-dangerous-obviously">Pointers are dangerous (obviously!)</h3>
<p>It should be obvious, but I’ll still call it out — MMU is not routing our memory accesses now; whatever we access is really what we hit in the physical memory and this means that bad pointers are now very dangerous. You could easily corrupt the memory contents of another process or even the kernel itself.</p>
<p>This would be a great place to introduce something like Rust programming, but given that it was tricky to build bare C programs for this kind of a platform (more about it below), I would now just say it’s too early for that.</p>
<h3 id="vfork-instead-of-fork"><code>vfork</code> instead of <code>fork</code></h3>
<p>The <code>fork</code> system call does not work on an MMU-less Linux since that heavily depends on virtualizing the memory, and this may lead some people to believe that you can run only one process on a MMU-less Linux, but that is not correct, and we will show it later — multiprocessing is definitely possible.</p>
<p>The way you achieve multiprocessing is by simply using <code>vfork</code> instead of <code>fork</code>. I’ll keep things simple here and say that the difference between <code>vfork</code> and <code>fork</code> is that the parent process is sleeping until the child exits or calls <code>execve</code>. Please note that unless you <code>exec</code> into another binary from the child process, the child is running in <strong>the same memory space</strong>. Again, there is no MMU to help us out here.</p>
<h2 id="building-binaries-for-an-mmu-less-kernel">Building binaries for an MMU-less kernel</h2>
<p>As we mentioned before, we need to build bFLT binaries rather than ELFs. Figuring out how to exactly do this is what took most of my time in this exercise.</p>
<p>I’ll skip a lot of details and give you the end result, and I’m sure if you dig around why this is the end result, you’ll be able to quickly figure out what’s going on. Here it is: <strong>the simplest way to build bFLT binaries is with a uClibc toolchain</strong>.</p>
<p><code>uClibc</code> is basically a very slimmed down version of the C standard library, suitable for embedded systems. Of course, nothing is stopping you from using it outside of this context, for example, in a full blown desktop Linux distrbution.</p>
<p>Quick note: which flavor of the standard C library is the best is another frequent topic of debate.</p>
<h3 id="getting-the-toolchain">Getting the toolchain</h3>
<p>I strongly suggest building the <code>uClibc</code> toolchain from source. It’s very easy, since it is based on Buildroot.</p>
<p>Therefore, let’s head over to the <a href="https://buildroot.org/download.html">Buildroot download page</a>, fetch the latest release and unpack it. You can <code>cd</code> into the unpacked directory.</p>
<p>tl;dr on what Buildroot is: it is a massive collection of <code>Makefile</code>s that is typically used to build a Linux distribution for an embedded system. You can use it to drive the kernel download + build as well, though I personally prefer to do it separately. What I typically use Buildroot for is to fetch the sources of common tools and build the <code>initramfs</code> <code>cpio</code> archive containing them. If you don’t know what this means, please check the <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">previous guide on making a micro Linux distro</a>. You configure the Buildroot flow almost the same as you configure the Linux kernel build flow: you run <code>make menuconfig</code>, toggle a bunch of options and you’re good to go. Buildroot is great because it has the scripts to pull and build a super wide range of common Linux tools and applications: <code>busybox</code>, <code>ip</code>, <code>vi</code>, <code>python</code>, <code>Xorg server</code> you name it.</p>
<p>Sadly, this is as much as the <a href="https://www.uclibc.org/toolchains.html">uClibc toolchain page</a> says. Personally, I was a bit puzzled after reading it: how do I use the toolchain and how do I build the binaries for <code>uClinux</code>? I’ll cover that part right now.</p>
<h3 id="building-the-toolchain">Building the toolchain</h3>
<p>Now that you have Buildroot downloaded, you can build the <code>uClibc</code> toolchain, which basically means you’ll have a GCC set of tools to compile with against it. I was always under the impression that changing which standard library you want is a matter of just providing a different standard library to any GCC compiler, but after some digging online, my understanding now is that the GCC needs to be specifically compiled against it somehow. It’s a bit beyond my understanding at the moment, to be perfectly honest.</p>
<ol>
<li>As mentioned above, you can do <code>make menuconfig</code> from your unpacked Buildroot directory.</li>
<li>Go to <code>Target options</code>, and select <code>RISCV</code> as the architecture.</li>
<li><code>Target architecture size</code> should be 64-bit.</li>
<li><strong>Unselect the MMU support</strong> option.</li>
<li><code>Target Binary Format</code> should be <strong>FLAT</strong>.</li>
<li><code>Target ABI</code> is fine as <code>lp64d</code>.</li>
<li>Go back to the main menu and head over to the <code>Toolchain</code> section.</li>
<li>C library should be <code>uClibc-ng</code>.</li>
<li>Select <code>Compile and install uClibc utilities</code>.</li>
<li>Save and exit.</li>
</ol>
<p>You should be all set up to build the toolchain. From the Buildroot directory, run the following:</p>
<pre is:raw="" tabindex="0"><code><span><span>make sdk</span></span></code></pre>
<p>This could take a while. Once it’s done, you should have your new toolchain under <code>output/host/bin/</code> within the Buildroot directory. Go ahead and <code>ls</code> that directory and you’ll see a bunch of stuff built in there, including your well known GCC tools. All we’ll be using is <code>riscv64-buildroot-linux-uclibc-gcc</code>, so make sure you hold on to that one.</p>
<h3 id="building-bflt-files">Building bFLT files</h3>
<p>bFLT files are, per my understanding, derived from the ELF files, actually. You use your GCC to get an ELF file, and then you use a tool called <code>elf2flt</code> to construct the bFLT file.</p>
<p>I have tried building <code>elf2flt</code> from source and using it, but I had a hard time getting the build to work in the first place. After many attempts, I gave up, but I was happy to realize that Buildroot provides <code>elf2flt</code>. In fact, when you <code>ls</code>‘ed the directory for your toolchain just a minute ago, you could see something like <code>riscv64-buildroot-linux-uclibc-elf2flt</code> in that directory. Once I realized this, I thought it was easy and I could just build a regular RISC-V ELF and convert it to bFLT with this tool — turns out it’s not that straightforward.</p>
<p>I lost hope I’d ever get this done, and then I tried having Buildroot build the whole <code>initramfs</code> for me. I was skeptical it would run properly with the MMU-less Linux, but it did, so that means there really is a way to do this properly and quickly. My hack was to look at the Buildroot logs for how it built some of the packages an observe what are the GCC flags it uses.</p>
<p>It turns out that I was missing the linker flag <code>-Wl,-elf2flt=-r</code> to make things work. This makes sure that the <code>elf2flt</code> is involved during the linking process and in the end, I got my bFLT file. I never had to run <code>elf2flt</code> myself. We’ll see a concrete detailed example later as we build a sample application.</p>
<p>First, let’s build a MMU-less kernel that we have something to run against.</p>
<h2 id="building-an-extremely-tiny-linux-kernel">Building an extremely tiny Linux kernel</h2>
<p>As this is an exercise in minimalism, we’ll build an extremely minimal Linux kernel. It will offer little more than a basic filesystem and running binaries on top of the kernel.</p>
<p><em>At this point, I assume you know how to build a Linux kernel in general. If you don’t, please look at the <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">micro Linux distro guide</a> and familiarize yourself with the basic concepts before proceeding.</em></p>
<p>For simplicity, I’ll simply get the <code>tar</code> file from <code>kernel.org</code> for stable version <code>6.5.5</code>, though I believe if you see something newer as the latest, you can just go for it and nothing should change. Let’s download and unpack that.</p>
<p><strong>Here and below: my <code>CROSS_COMPILE</code> prefix may be different from what you need on your machine to invoke the build tools.</strong></p>
<p>Let’s begin by setting up a super minimal Linux configuration:</p>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- tinyconfig</span></span></code></pre>
<p>This <code>tinyconfig</code> really strips down the build to the most basic things. It doesn’t even have <code>printk</code> support, so you won’t be getting a whole lot of output by booting this. More accurately, it doesn’t even have the TTY support, so you really can’t even output anything through the standard methods like <code>printk</code>, and you wouldn’t be able to display something through UART or otherwise via standard output in the user space.</p>
<p>Let’s, however, build this (I run <code>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- -j16</code>) and see what we get out of it. I’m getting the following:</p>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 943 K.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 559 K.</li>
</ul>
<p>This is good to know and we’ll use it as the baseline as we make the changes. Let’s do the following and make some changes to our build:</p>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- menuconfig</span></span></code></pre>
<p>The most important change we want to make is we want to disable the MMU facilities in the kernel. I’ve seen guides that say you can just drop a config line into the <code>.config</code> file because they don’t see the option to disable the MMU from <code>menuconfig</code>, but I would advise against it. I was able to get the option to appear, and I’m not sure if what they’re expericing is architecture specific, but for RISC-V, I was definitely able to get the option to disable the MMU stuff.</p>
<ol>
<li><code>CONFIG_NONPORTABLE</code> should be set to <code>y</code>. We are building for a specific machine and we want to enable non-portable builds as we know exactly what are the memory addresses we’d be deploying to.</li>
<li><code>CONFIG_MMU</code>: <code>n</code>. It should be obvious what this does. Note, we were unable to flip this to <code>n</code> before doing the step 1; we should be all good now.</li>
<li><code>PHYS_RAM_BASE_FIXED</code>: <code>y</code>. This means we’ll be deploying the kernel to a specific address in the memory.</li>
<li>Once you flip that, you can set <code>CONFIG_PHYS_RAM_BASE</code> to <code>0x80000000</code>. This makes perfect sense for us as this is where our execution will begin on the QEMU virtual machine. If you want to know more about it, please read the <a href="https://popovicu.com/posts/bare-metal-programming-risc-v/">bare metal guide</a> and the <a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/">SBI and boot process guide</a>. Those guides are lengthy, but they will enable you to fully understand what’s going on. That said, for the latter guide, please note that <strong>we are not</strong> using OpenSBI to boot here. We’re running a very light Linux, and we are not relying on the SBI infrastructure. This is much closer to bare metal programming than running Linux as you’re used to it.</li>
</ol>
<p>Let’s build this really quick and see if there are any changes. Save and exit, and run:</p>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- -j16</span></span></code></pre>
<p>Let’s weigh our kernel again:</p>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 789 K.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 472 K.</li>
</ul>
<p>Wow, it’s significantly lighter! However, even though we disabled the MMU smartness from it, we still haven’t enabled any features and again, the <code>tinyconfig</code> is so tiny that it barely does anything. Let’s flip some more configurations:</p>
<ol>
<li><code>CONFIG_BLK_DEV_INITRD</code>: <code>y</code>. We need an <code>initramfs</code> image to be able to run our <code>init</code> process and start off some magic in the user space. Flip that to <code>y</code>.</li>
<li>The above will by default enable various compression support for the <code>initramfs</code>, but you can go ahead and disable them all. I will not list out all of them one by one (a single example is <code>CONFIG_RD_GZIP</code>), they should expand in <code>menuconfig</code> as <code>y</code> right under the option for enabling <code>initramfs</code>. You can flip them all to <code>n</code>, we don’t want to beef up our kernel image with compression algorithms now.</li>
<li><code>CONFIG_BINFMT_FLAT</code>: <code>y</code>. We need to add support for bFLT binaries. If you look at the same menu, there’s no mention of ELF: as soon as you disabled the MMU support, you lost the ELF binary support as well. We already knew this, so it’s not an issue, and as promised, we’ll talk about how to build bFLTs below on a concrete example. Let’s save and exit and build again:</li>
</ol>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- -j16</span></span></code></pre>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 789 K.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 476 K.</li>
</ul>
<p>The only difference from the previous step is that the compressed image is slightly thicker, but it’s still tiny!</p>
<p>At this point, we have what we need to run an <code>init</code> process in user space!</p>
<h2 id="building-an-initramfs-image-for-the-tiny-mmu-less-kernel">Building an <code>initramfs</code> image for the tiny MMU-less kernel</h2>
<p>We’ll have a useless <code>init</code> that prints a message to UART and just goes to sleep. Notice an inconsistency? I said we’ll print to UART, but our <code>tinyconfig</code> has no UART drivers, no TTY, nothing. So how could this possibly work? Well, since we’re without an MMU, we can really target any physical address on the system. If you go through the <a href="https://popovicu.com/posts/bare-metal-programming-risc-v/">bare metal guide</a>, you’ll learn that the QEMU system we’ll be using to run this image has an UART device mapped out at <code>0x10000000</code>. We’ll be printing to UART through this address for two reasons:</p>
<ol>
<li>Most importantly, to illustrate that on MMU-less kernel you can access any physical address. This can be both good and bad, probably more bad and not only in terms of stability and being resilient to bugs, but also in terms of security if your system accepts any sort of user input.</li>
<li>We want to achieve extreme minimalism here in terms of the size of the build and see how far we can push the boundaries on how much we can slim the kernel down. Right now, it’s under 800 K, which is pretty cool. Bringing in drivers for TTY, UART, etc. would certaily add some weight to the size of our image.</li>
</ol>
<p>That said, here’s our C program:</p>
<pre is:raw="" tabindex="0"><code><span><span>#include</span><span> </span><span>&lt;string.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;unistd.h&gt;</span></span>
<span></span>
<span><span>volatile</span><span> </span><span>char</span><span> </span><span>*</span><span>UART </span><span>=</span><span> (</span><span>char*</span><span>) </span><span>0x</span><span>10000000</span><span>;</span></span>
<span></span>
<span><span>void</span><span> </span><span>print_to_uart</span><span>(</span><span>char</span><span> </span><span>*</span><span>message</span><span>) {</span></span>
<span><span>  </span><span>for</span><span> (</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>; i </span><span>&lt;</span><span> </span><span>strlen</span><span>(message); i</span><span>++</span><span>) {</span></span>
<span><span>    </span><span>*</span><span>UART </span><span>=</span><span> </span><span>message</span><span>[i];</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>int</span><span> </span><span>main</span><span>() {</span></span>
<span><span>  </span><span>print_to_uart</span><span>(</span><span>"Hello world! Welcome to the Tiny Linux MMU-less kernel!</span><span>\n</span><span>"</span><span>);</span></span>
<span></span>
<span><span>  </span><span>while</span><span> (</span><span>1</span><span>) {</span></span>
<span><span>    </span><span>sleep</span><span>(</span><span>1000</span><span>);</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>return</span><span> </span><span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>Notice that we have an infinite loop: the <code>init</code> process is not supposed to ever really exit or the kernel falls into a panic (not that you would see it without <code>printk</code>, though).</p>
<p>Now is the time to compile this <code>init</code> to a bFLT file. This is where we’ll invoke the <code>uClibc</code> toolchain we had previously built. I run the following on my machine, and you only need to adjust the relevant paths to reproduce:</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/tiny/init$ /tmp/buildroot/buildroot-2023.02.5/output/host/bin/riscv64-buildroot-linux-uclibc-gcc -fPIC -Wl,-elf2flt=-r -Wall -static -o init init.c</span></span></code></pre>
<ul>
<li><code>-fPIC</code> is used to produce <strong>position independent code</strong>. This is crucial for understanding how bFLT binaries work on an MMU-less Linux. Since we’re directly going for the physical addresses, but we don’t know where exactly in memory our binary would be loaded, we can’t depend on any absolute address in our binary. If we did, we risk (and most likely will) hurting the memory of another process or the kernel itself. We simply can’t make any assumptions about the end memory addresses. Therefore, everything needs to be PC-relative in our code. If you don’t know what this means, please look this up online as it’s extremely important. tl;dr is that every memory access must be made with an offset relative to the CPU’s pointer to the current machine instruction, instead of accessing a hardcoded address. In other words, instead of accessing <code>0x1001</code> directly, we access with an offset of <code>1</code> if our program counter is at <code>0x1000</code>. This will still work if the binary loader places us at <code>0x2000</code> instead of <code>0x1000</code>; the former wouldn’t! Again, if you do not understand this concept, please review CPU addressing modes.</li>
<li><code>-Wl,-elf2flt=-r</code> is the magic flag we really needed from the toolchain. This ensures that <code>elf2flt</code> is invoked and that the end binary is able to relocate, meaning the loader can place it somewhere differently in memory and the binary should still work (owing to the <code>-fPIC</code> flag as well).</li>
<li>The rest of the flags should be familiar.</li>
</ul>
<p>This binary weighs in at onl 3.3 K, which is pretty light, especially for a statically linked binary. <code>uClibc</code> delivered on its promise of being light. Quick note here is that <code>elf2flt</code> also dropped a file called <code>init.gdb</code> which is an ELF file that you can use to do your <code>objdump</code> and whatnot with it to debug.</p>
<p>If you run <code>file init</code>, you should see something like this:</p>
<pre is:raw="" tabindex="0"><code><span><span>init: BFLT executable - version 4 ram gotpic</span></span></code></pre>
<p>This is what we needed. Let’s make a file called <code>file_list.txt</code> with a single line saying <code>init</code> and let’s make the <code>initramfs</code> image for this setup.</p>
<pre is:raw="" tabindex="0"><code><span><span>cpio -o -H newc &lt; file_list.txt &gt; initramfs.cpio</span></span></code></pre>
<p>Now that we have the kernel image and the <code>initramfs.cpio</code> file, we can fire this up in QEMU and see what we get.</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/linux/linux-6.5.5$ qemu-system-riscv64 -machine virt -cpu rv64,mmu=false -kernel /tmp/tiny/linux-6.5.5/arch/riscv/boot/Image -bios none -initrd /tmp/tiny/init/initramfs.cpio -nographic</span></span>
<span><span>Hello world! Welcome to the Tiny Linux MMU-less kernel!</span></span></code></pre>
<p>Awesome, we ran userspace code and even depended on a dangerous pointer to do something useful.</p>
<h2 id="slightly-more-complicated-build-verifying-system-calls-and-multiprocessing">Slightly more complicated build: verifying system calls and multiprocessing</h2>
<p>Instead of starting from a <code>tinyconfig</code> and working my way up, this time I start with the typical <code>defconfig</code>. From that point, I disabled a bunch of things like MMU (of course), networking, virtualization, etc. while retaining TTY, UART drivers and other useful goodies. Of course, nothing stops you from beginning with <code>tinyconfig</code> and adding incrementally, I just wanted to save myself some time. This time I ended up with images of these sizes:</p>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 4.1 M.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 2.1 M.</li>
</ul>
<p>This is all much heavier than previously, but it comes with a bunch of cool features like ability to dump core, UART drivers, filesystem support, etc. The message I’m trying to send here is that kernel is full of amazing drivers and features that you can start taking advantage of by only adjusting your kernel build configuration. I ran the same <code>initramfs</code> image as above, and got much richer output with a lot of debug messages from the kernel:</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/linux/linux-6.5.5$ qemu-system-riscv64 -machine virt -cpu rv64,mmu=false -kernel /tmp/linux/linux-6.5.5/arch/riscv/boot/Image -bios none -initrd /tmp/tiny/init/initramfs.cpio -nographic</span></span></code></pre>
<pre is:raw="" tabindex="0"><code><span><span>[    0.000000] Linux version 6.5.5 (uros@uros-debian-desktop) (riscv64-linux-gnu-gcc (Debian 10.2.1-6) 10.2.1 20210110, GNU ld (GNU Binutils for Debian) 2.35.2) #9 Wed Oct  4 00:07:07 PDT 2023</span></span>
<span><span>[    0.000000] Machine model: riscv-virtio,qemu</span></span>
<span><span>[    0.000000] Zone ranges:</span></span>
<span><span>[    0.000000]   DMA32    [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000]   Normal   empty</span></span>
<span><span>[    0.000000] Movable zone start for each node</span></span>
<span><span>[    0.000000] Early memory node ranges</span></span>
<span><span>[    0.000000]   node   0: [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] Initmem setup node 0 [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] riscv: base ISA extensions acdfim</span></span>
<span><span>[    0.000000] riscv: ELF capabilities acdfim</span></span>
<span><span>[    0.000000] Kernel command line:</span></span>
<span><span>[    0.000000] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)</span></span>
<span><span>[    0.000000] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)</span></span>
<span><span>[    0.000000] Built 1 zonelists, mobility grouping on.  Total pages: 32320</span></span>
<span><span>[    0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off</span></span>
<span><span>[    0.000000] Memory: 124576K/131072K available (2526K kernel code, 684K rwdata, 809K rodata, 141K init, 276K bss, 6496K reserved, 0K cma-reserved)</span></span>
<span><span>[    0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1</span></span>
<span><span>[    0.000000] NR_IRQS: 64, nr_irqs: 64, preallocated irqs: 0</span></span>
<span><span>[    0.000000] riscv-intc: 64 local interrupts mapped</span></span>
<span><span>[    0.000000] plic: plic@c000000: mapped 53 interrupts with 1 handlers for 2 contexts.</span></span>
<span><span>[    0.000000] clint: clint@2000000: timer running at 10000000 Hz</span></span>
<span><span>[    0.000000] clocksource: clint_clocksource: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns</span></span>
<span><span>[    0.000062] sched_clock: 64 bits at 10MHz, resolution 100ns, wraps every 4398046511100ns</span></span>
<span><span>[    0.003318] Console: colour dummy device 80x25</span></span>
<span><span>[    0.003525] printk: console [tty0] enabled</span></span>
<span><span>[    0.006416] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)</span></span>
<span><span>[    0.006531] pid_max: default: 32768 minimum: 301</span></span>
<span><span>[    0.007085] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.007131] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.019370] RCU Tasks Trace: Setting shift to 0 and lim to 1 rcu_task_cb_adjust=1.</span></span>
<span><span>[    0.024447] devtmpfs: initialized</span></span>
<span><span>[    0.028181] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns</span></span>
<span><span>[    0.028380] futex hash table entries: 256 (order: 1, 12288 bytes, linear)</span></span>
<span><span>[    0.045655] clocksource: Switched to clocksource clint_clocksource</span></span>
<span><span>[    0.060880] Unpacking initramfs...</span></span>
<span><span>[    0.064002] workingset: timestamp_bits=62 max_order=15 bucket_order=0</span></span>
<span><span>[    0.066160] io scheduler mq-deadline registered</span></span>
<span><span>[    0.066228] io scheduler kyber registered</span></span>
<span><span>[    0.113049] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled</span></span>
<span><span>[    0.119589] 10000000.uart: ttyS0 at MMIO 0x10000000 (irq = 4, base_baud = 230400) is a 16550A</span></span>
<span><span>[    0.120520] printk: console [ttyS0] enabled</span></span>
<span><span>[    0.134884] goldfish_rtc 101000.rtc: registered as rtc0</span></span>
<span><span>[    0.135476] goldfish_rtc 101000.rtc: setting system clock to 2023-10-04T19:51:49 UTC (1696449109)</span></span>
<span><span>[    0.148278] sysfs: cannot create duplicate filename '/kernel/slab/:a-0000016'</span></span>
<span><span>[    0.148656] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.148979] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.149245] Call Trace:</span></span>
<span><span>[    0.149490] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.150053] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.150297] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.150546] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.150784] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.151040] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.151331] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.151638] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.151937] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.152216] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.152451] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.152736] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.153051] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.153319] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.153728] kobject: kobject_add_internal failed for :a-0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.154345] SLUB: Unable to add boot slab kmalloc-rcl-8 to sysfs</span></span>
<span><span>[    0.156569] sysfs: cannot create duplicate filename '/kernel/slab/:0000016'</span></span>
<span><span>[    0.156885] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.157159] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.157378] Call Trace:</span></span>
<span><span>[    0.157500] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.157809] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.158071] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.158354] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.158620] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.158899] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.159212] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.159518] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.159815] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.160101] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.160399] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.160693] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.161010] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.161278] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.161598] kobject: kobject_add_internal failed for :0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.162289] SLUB: Unable to add boot slab kmalloc-8 to sysfs</span></span>
<span><span>[    0.162761] SLUB: Unable to add boot slab alias ep_head to sysfs</span></span>
<span><span>[    0.163061] SLUB: Unable to add boot slab alias blkdev_ioc to sysfs</span></span>
<span><span>[    0.164939] Legacy PMU implementation is available</span></span>
<span><span>[    0.165494] clk: Disabling unused clocks</span></span>
<span><span>[    0.178717] Freeing unused kernel image (initmem) memory: 140K</span></span>
<span><span>[    0.178974] This architecture does not have kernel memory protection.</span></span>
<span><span>[    0.179296] Run /init as init process</span></span>
<span><span>Hello world! Welcome to the Tiny Linux MMU-less kernel!</span></span></code></pre>
<p>Let’s write an <code>init</code> that starts a bunch of other processes and verifies that multiprocessing keeps working after they’re spawned.</p>
<p><code>init.c</code> below:</p>
<pre is:raw="" tabindex="0"><code><span><span>#include</span><span> </span><span>&lt;stdio.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;stdlib.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;unistd.h&gt;</span></span>
<span></span>
<span><span>int</span><span> </span><span>main</span><span>(</span><span>int</span><span> </span><span>argc</span><span>,</span><span> </span><span>char</span><span> </span><span>*</span><span>argv</span><span>[]</span><span>) {</span></span>
<span><span>  </span><span>printf</span><span>(</span><span>"Hello world</span><span>\n</span><span>"</span><span>);</span></span>
<span></span>
<span><span>  </span><span>for</span><span> (</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>; i </span><span>&lt;</span><span> </span><span>3</span><span>; i</span><span>++</span><span>) {</span></span>
<span><span>    </span><span>pid_t</span><span> pid;</span></span>
<span></span>
<span><span>    </span><span>if</span><span> ((pid </span><span>=</span><span> </span><span>vfork</span><span>()) </span><span>&lt;</span><span> </span><span>0</span><span>) {</span></span>
<span><span>      </span><span>fprintf</span><span>(stderr, </span><span>"Could not fork a worker at iteration </span><span>%d</span><span>\n</span><span>"</span><span>, i);</span></span>
<span><span>      </span><span>exit</span><span>(</span><span>1</span><span>);</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    </span><span>if</span><span> (pid </span><span>==</span><span> </span><span>0</span><span>) {</span></span>
<span><span>      </span><span>// Child process</span></span>
<span><span>      </span><span>char</span><span> </span><span>*</span><span>args</span><span>[</span><span>2</span><span>] </span><span>=</span><span> { </span><span>"worker"</span><span>, </span><span>NULL</span><span> };</span></span>
<span><span>      </span><span>execv</span><span>(</span><span>"/worker"</span><span>, args);</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>while</span><span> (</span><span>1</span><span>) {</span></span>
<span><span>    </span><span>sleep</span><span>(</span><span>5</span><span>);</span></span>
<span><span>    </span><span>printf</span><span>(</span><span>"Hello from init</span><span>\n</span><span>"</span><span>);</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>return</span><span> </span><span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p><code>worker.c</code> below:</p>
<pre is:raw="" tabindex="0"><code><span><span>#include</span><span> </span><span>&lt;stdio.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;unistd.h&gt;</span></span>
<span></span>
<span><span>int</span><span> </span><span>main</span><span>(</span><span>int</span><span> </span><span>argc</span><span>,</span><span> </span><span>char</span><span> </span><span>*</span><span>argv</span><span>[]</span><span>) {</span></span>
<span><span>  </span><span>while</span><span> (</span><span>1</span><span>) {</span></span>
<span><span>    </span><span>printf</span><span>(</span><span>"Hello from worker!</span><span>\n</span><span>"</span><span>);</span></span>
<span><span>    </span><span>sleep</span><span>(</span><span>3</span><span>);</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>return</span><span> </span><span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>We build them the same way as the <code>init</code> we built before and package them into a <code>cpio</code> archive. Running this in QEMU for some time gives the following:</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/linux/linux-6.5.5$ qemu-system-riscv64 -machine virt -cpu rv64,mmu=false -kernel /tmp/linux/linux-6.5.5/arch/riscv/boot/Image -bios none -initrd /tmp/linux/init/initramfs.cpio -nographic</span></span></code></pre>
<pre is:raw="" tabindex="0"><code><span><span>[    0.000000] Linux version 6.5.5 (uros@uros-debian-desktop) (riscv64-linux-gnu-gcc (Debian 10.2.1-6) 10.2.1 20210110, GNU ld (GNU Binutils for Debian) 2.35.2) #9 Wed Oct  4 00:07:07 PDT 2023</span></span>
<span><span>[    0.000000] Machine model: riscv-virtio,qemu</span></span>
<span><span>[    0.000000] Zone ranges:</span></span>
<span><span>[    0.000000]   DMA32    [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000]   Normal   empty</span></span>
<span><span>[    0.000000] Movable zone start for each node</span></span>
<span><span>[    0.000000] Early memory node ranges</span></span>
<span><span>[    0.000000]   node   0: [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] Initmem setup node 0 [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] riscv: base ISA extensions acdfim</span></span>
<span><span>[    0.000000] riscv: ELF capabilities acdfim</span></span>
<span><span>[    0.000000] Kernel command line:</span></span>
<span><span>[    0.000000] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)</span></span>
<span><span>[    0.000000] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)</span></span>
<span><span>[    0.000000] Built 1 zonelists, mobility grouping on.  Total pages: 32320</span></span>
<span><span>[    0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off</span></span>
<span><span>[    0.000000] Memory: 124544K/131072K available (2526K kernel code, 684K rwdata, 809K rodata, 141K init, 276K bss, 6528K reserved, 0K cma-reserved)</span></span>
<span><span>[    0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1</span></span>
<span><span>[    0.000000] NR_IRQS: 64, nr_irqs: 64, preallocated irqs: 0</span></span>
<span><span>[    0.000000] riscv-intc: 64 local interrupts mapped</span></span>
<span><span>[    0.000000] plic: plic@c000000: mapped 53 interrupts with 1 handlers for 2 contexts.</span></span>
<span><span>[    0.000000] clint: clint@2000000: timer running at 10000000 Hz</span></span>
<span><span>[    0.000000] clocksource: clint_clocksource: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns</span></span>
<span><span>[    0.000059] sched_clock: 64 bits at 10MHz, resolution 100ns, wraps every 4398046511100ns</span></span>
<span><span>[    0.003249] Console: colour dummy device 80x25</span></span>
<span><span>[    0.003442] printk: console [tty0] enabled</span></span>
<span><span>[    0.006336] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)</span></span>
<span><span>[    0.006447] pid_max: default: 32768 minimum: 301</span></span>
<span><span>[    0.007026] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.007070] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.019398] RCU Tasks Trace: Setting shift to 0 and lim to 1 rcu_task_cb_adjust=1.</span></span>
<span><span>[    0.024599] devtmpfs: initialized</span></span>
<span><span>[    0.028455] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns</span></span>
<span><span>[    0.028661] futex hash table entries: 256 (order: 1, 12288 bytes, linear)</span></span>
<span><span>[    0.046105] clocksource: Switched to clocksource clint_clocksource</span></span>
<span><span>[    0.061575] Unpacking initramfs...</span></span>
<span><span>[    0.064941] workingset: timestamp_bits=62 max_order=15 bucket_order=0</span></span>
<span><span>[    0.066491] io scheduler mq-deadline registered</span></span>
<span><span>[    0.066556] io scheduler kyber registered</span></span>
<span><span>[    0.073683] Freeing initrd memory: 32K</span></span>
<span><span>[    0.114913] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled</span></span>
<span><span>[    0.121398] 10000000.uart: ttyS0 at MMIO 0x10000000 (irq = 4, base_baud = 230400) is a 16550A</span></span>
<span><span>[    0.122456] printk: console [ttyS0] enabled</span></span>
<span><span>[    0.134615] goldfish_rtc 101000.rtc: registered as rtc0</span></span>
<span><span>[    0.135109] goldfish_rtc 101000.rtc: setting system clock to 2023-10-04T21:01:14 UTC (1696453274)</span></span>
<span><span>[    0.147392] sysfs: cannot create duplicate filename '/kernel/slab/:a-0000016'</span></span>
<span><span>[    0.147670] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.147955] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.148164] Call Trace:</span></span>
<span><span>[    0.148375] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.148861] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.149056] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.149257] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.149435] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.149626] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.149837] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.150048] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.150284] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.150502] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.150695] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.150887] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.151102] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.151291] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.151561] kobject: kobject_add_internal failed for :a-0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.152043] SLUB: Unable to add boot slab kmalloc-rcl-8 to sysfs</span></span>
<span><span>[    0.153186] sysfs: cannot create duplicate filename '/kernel/slab/:0000016'</span></span>
<span><span>[    0.153443] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.153632] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.153778] Call Trace:</span></span>
<span><span>[    0.153873] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.154056] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.154247] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.154440] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.154614] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.154816] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.155035] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.155256] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.155481] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.155691] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.155906] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.156119] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.156342] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.156525] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.156744] kobject: kobject_add_internal failed for :0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.157236] SLUB: Unable to add boot slab kmalloc-8 to sysfs</span></span>
<span><span>[    0.157663] SLUB: Unable to add boot slab alias ep_head to sysfs</span></span>
<span><span>[    0.157902] SLUB: Unable to add boot slab alias blkdev_ioc to sysfs</span></span>
<span><span>[    0.159238] Legacy PMU implementation is available</span></span>
<span><span>[    0.159650] clk: Disabling unused clocks</span></span>
<span><span>[    0.172328] Freeing unused kernel image (initmem) memory: 140K</span></span>
<span><span>[    0.172645] This architecture does not have kernel memory protection.</span></span>
<span><span>[    0.172948] Run /init as init process</span></span>
<span><span>Hello world</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from init</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from init</span></span></code></pre>
<p>Hopefully this clears up the confusion about whether multiprocessing is possible on a no-MMU kernel build. Additionally, we verified that the system calls work properly.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We managed to build a very light Linux kernel for a system without an MMU. By building a custom <code>uClibc</code> toolchain we also managed to build bFLT binaries to run in the userspace. System calls and multiprocessing worked well and so we have a fully functional system.</p>
<p>We pushed the boundaries of a lightweight deployment through <code>tinyconfig</code>, and ended up running a userspace process that writes to UART by directly writing to the UART device, bypassing the kernel.</p>
<p>If all we want is to multi-task a bit on our device, Linux is likely an overkill, even in a tiny deployment like this. Additionally, if we’re not leveraging any drivers from the kernel code base, it’s probably another indicator we’re going too heavy. I leave it to you to decide if this lightweight Linux deployment makes sense for your usecase or not.</p>
<p>We could use Buildroot to add some of the well known tools to our system, potentially even make something interactive. I’ll stop here, however, as my goal was to bring up the absolutely minimal set up. Please connect with me and let me know if there is a way to make the set up I described above even lighter from the <code>tinyconfig</code>-based one.</p>
<p>I think this finally answers my question that I’ve had for a long time which is: what is the absolutely minimal Linux kernel? Something that runs on a single core, extremely simple, with as little cruft as possible, but that can still process some system calls and provide some sort of a filesystem. If anyone has been looking for this answer as well, I hope I am providing it correctly here.</p>
<p>The way I initially got to this question was I wanted to implement a minimal machine (in simulation or otherwise in FPGA) that can run something useful like some sort of a minimal Linux, and that I can program with at least some standard tooling like GCC. After studying my options, I think RISC-V and Linux are the answer, and the last few guides I have written are the summary of my studies.</p>
<h2 id="github-repo">GitHub repo</h2>
<p>As always, I’ll be posting the code from above to GitHub as well. There won’t be <code>Makefile</code>s due to the need for a custom toolchain, and I’d really like the readers to go through this writeup and understand what’s going on exactly in order to build bFLT libraries. It stumped me for a few days and I hope this helps anyone with the same questions. The repo can be found <a href="https://github.com/popovicu/linux-no-mmu-userspace-example">here</a>.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make your own pyramid salt crystals (217 pts)]]></title>
            <link>https://crystalverse.com/pyramid-salt-crystals/</link>
            <guid>37821994</guid>
            <pubDate>Mon, 09 Oct 2023 16:21:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crystalverse.com/pyramid-salt-crystals/">https://crystalverse.com/pyramid-salt-crystals/</a>, See on <a href="https://news.ycombinator.com/item?id=37821994">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="How to Easily Make Your Own Pyramid Salt Crystals" itemref="hero-page-title"><div><p><em>Here’s how you can transform regular table salt into gorgeous pyramid salt crystals at home.</em></p><!-- End Ezoic - gen_under_first_paragraph - under_first_paragraph --><!-- Ezoic - gen_under_first_paragraph - under_first_paragraph --><!-- Ezoic - wp_under_page_title - under_page_title --><!-- End Ezoic - wp_under_page_title - under_page_title -->
<p><img decoding="async" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2.jpg" alt="how to make pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Regular salt looks like a fine white powder. Sure, it tastes good, but it’s not very interesting to look at.</p>
<p>But what if I told you that you could transform the salt sitting in your kitchen into a work of art?</p><!-- End Ezoic - gen_under_second_paragraph - under_second_paragraph --><!-- Ezoic - gen_under_second_paragraph - under_second_paragraph --><!-- Ezoic - wp_under_first_paragraph - under_first_paragraph --><!-- End Ezoic - wp_under_first_paragraph - under_first_paragraph -->
<p>What if I told you that within a few hours, you could turn white, powdery salt into premium salt crystals shaped like pyramids, flowers and Eiffel towers?</p>
<p>Plus, you don’t need to be good at art. You don’t need to carve those pyramids yourself. Just sit beside the stove, and watch as pyramid salt crystals <em>grow</em> from a dish of salt water right before your eyes.</p>
<p>Let me show you how to do just that.</p><!-- Ezoic - wp_under_second_paragraph - under_second_paragraph --><p><span data-ez-name="crystalverse_com-medrectangle-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=111&amp;impression_group_id=crystalverse_com-medrectangle-4/2023-10-09/1344179903208687&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_under_second_paragraph - under_second_paragraph -->
<p>To my knowledge, it’s the only such guide on the Internet.</p><!-- End Ezoic - gen_mid_content - mid_content --><!-- Ezoic - gen_mid_content - mid_content -->
<p>First, let’s answer a question.</p>
<h3>What is pyramid salt?</h3>
<p>Pyramid salt crystals are made of the same stuff as regular salt. But these crystals look different because they formed in a different way.</p>
<p>In nature, these elusive crystals grow on the surface of quiet, undisturbed pools of salt water that evaporate under the hot sun.</p><!-- Ezoic - wp_mid_content - mid_content --><p><span data-ez-name="crystalverse_com-box-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=112&amp;impression_group_id=crystalverse_com-box-4/2023-10-09/1667659185236566&amp;ad_size=728x90&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_mid_content - mid_content -->
<p>Pyramid salt is more expensive than regular salt, because they taste saltier. Pyramid salt is hollow, and gram for gram, it dissolves in your mouth faster than regular salt. So the saltiness comes at your taste buds all at once.</p>
<p>Plus, they also look awesome.</p>
<p><img decoding="async" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro.jpg" alt="what are pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Now, it’s easy to make regular salt crystals at home. Just leave a dish of salt water to evaporate, and you’ll get white powdery salt inside after a few hours.</p><!-- End Ezoic - gen_long_content - long_content --><p><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=912&amp;impression_group_id=crystalverse_com-banner-1/2023-10-09/8617102485236414&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_long_content - long_content -->
<p>However, it’s much harder to make pyramid salt.</p><!-- Ezoic - wp_long_content - long_content --><!-- End Ezoic - wp_long_content - long_content -->
<p>True, you can buy them online. Maldon Sea Salt, for instance, contains crunchy pyramidal salt crystals. They are made by evaporating sea water in large heated pans, mimicking nature.</p>
<p>But that kind of salt is produced industrially, with special equipment and mineral rich seawater.</p>
<p>I’ve always wondered whether you could grow pyramids at home using a hot plate, a glass dish and some regular table salt.</p>
<p>It took over 100 experiments and some sleepless nights, but here are the results.</p><!-- End Ezoic - gen_longer_content - longer_content --><!-- Ezoic - gen_longer_content - longer_content --><!-- Ezoic - wp_longer_content - longer_content --><!-- End Ezoic - wp_longer_content - longer_content -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt.jpg" alt="homemade pyramid salt recipe" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<h3>How to make pyramid salt crystals</h3>
<p>This guide will consist of the following parts:</p><p><span></span><span id="ez-clearholder-medrectangle-3"></span><span data-ez-name="crystalverse_com-medrectangle-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=21&amp;impression_group_id=crystalverse_com-medrectangle-3/2023-10-09/1751908139167726&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><ol>
<li><a href="#materials">Materials</a></li>
<li><a href="#preparing-the-salt-solution">Preparing the salt solution</a></li>
<li><a href="#growing-the-pyramid-salt-crystals">Growing the pyramid salt crystals</a></li>
<li><a href="#harvesting-the-pyramid-salt-crystals">Harvesting the pyramid salt crystals</a></li>
<li><a href="#storing-the-pyramid-salt-crystals">Storing the pyramid salt crystals</a></li>
<li><a href="#tasting-the-pyramid-salt-crystals">Tasting the pyramid salt crystals</a></li>
<li><a href="#types-of-pyramid-salt-crystals">8 types of pyramid salt crystals</a></li>
<li><a href="#some-more-information">Some more information</a></li>
<li><a href="#summary">Summary</a></li>
</ol>
<h3 id="materials">Materials</h3>
<p>To make pyramid salt crystals, you’ll need:</p>
<ul>
<li>A bag of salt</li>
<li>Alum powder</li>
<li>A stove/hot plate</li>
<li>A heat resistant glass dish</li>
<li>A pair of tweezers</li>
<li>A thermometer (optional)</li>
</ul>
<p>I have tried table salt, sea salt, and Himalayan rock salt, and they all work. Sea salt seems to give better results.</p><!-- Ezoic - wp_longest_content - longest_content --><!-- End Ezoic - wp_longest_content - longest_content -->
<p>I’ve used both tap and deionized water. Both are fine.</p>
<p>Also, in this experiment, we’ll be heating some very concentrated salt water. This solution will damage metallic objects, so you can’t use a stainless steel pot.</p>
<p>Instead, I suggest using a heat resistant glass dish. The exact type doesn’t matter. You can use a Pyrex dish or an enameled cast iron pot, which won’t get corroded.</p>
<p>I used a glass casserole.</p><!-- Ezoic - wp_incontent_5 - incontent_5 --><!-- End Ezoic - wp_incontent_5 - incontent_5 -->
<p><a href="https://amzn.to/3RARFBA" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/product-glass-casserole.jpg" alt="" width="400" height="364" srcset="https://crystalverse.com/wp-content/uploads/2022/09/product-glass-casserole.jpg 400w, https://crystalverse.com/wp-content/uploads/2022/09/product-glass-casserole-300x273.jpg 300w" sizes="(max-width: 400px) 100vw, 400px"></a></p>
<h3 id="preparing-the-salt-solution">Preparing the salt solution</h3>
<p>Dissolve 165 g of salt in 500 mL of hot water. If you want to make a bigger batch, just use the same ratio (e.g. 330 g of salt per 1 L of water).</p><!-- End Ezoic - gen_longest_content - longest_content --><!-- Ezoic - gen_longest_content - longest_content -->
<p>Stir the solution gently until all of it dissolves.</p>
<p>Depending on whether the salt is dirty, you can choose to filter it. I filtered mine.</p><!-- Ezoic - wp_incontent_6 - incontent_6 --><p><span data-ez-name="crystalverse_com-square-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=117&amp;impression_group_id=crystalverse_com-square-2/2023-10-09/795413405248367&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_6 - incontent_6 -->
<p>In my setup, I poured my filtered salt solution into a glass casserole sitting on top of a hot plate.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/growing-setup.jpg" alt="growing setup" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/growing-setup.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/growing-setup-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/growing-setup-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p>A hot plate is fine. But don’t put the glass dish directly on the gas stove – the glass might break due to strong, uneven heating, even though it is <em>technically</em>&nbsp;heat resistant. Use a water bath instead.</p>
<h3 id="growing-the-pyramid-salt-crystals">Growing the pyramid salt crystals</h3>
<p>Now, heat the solution to 60-70°C and keep it there throughout the growing process.</p><!-- End Ezoic - gen_incontent_5 - incontent_5 --><!-- Ezoic - gen_incontent_5 - incontent_5 -->
<p>When the solution warms up, convection currents start forming, causing the surface of the solution to swirl around.</p><!-- Ezoic - wp_incontent_7 - incontent_7 --><!-- End Ezoic - wp_incontent_7 - incontent_7 -->
<p>This is bad news, because when our pyramids form, they will also move around the surface of the solution. And they will bump into each other, stick together and fall to the bottom of the dish.</p>
<p>The key is to add an ingredient called potassium alum. Alum calms the surface and helps the pyramids form. It is normally used in baking and pickling. You can find it at the grocery store, or buy it online.</p>
<p><a href="https://amzn.to/3U3mHUq" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/02/product2.jpg" alt="" width="400" height="364" srcset="https://crystalverse.com/wp-content/uploads/2022/02/product2.jpg 400w, https://crystalverse.com/wp-content/uploads/2022/02/product2-300x273.jpg 300w" sizes="(max-width: 400px) 100vw, 400px"></a><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/adding-alum.jpg" alt="adding potassium alum to the solution" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/adding-alum.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/adding-alum-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/adding-alum-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"><em>Add 0.5 g of alum per 500 mL of salt solution. No need to measure – just drop a few pea-sized pieces of alum/two pinches of alum powder into the solution and let it dissolve.</em></p><!-- End Ezoic - gen_incontent_6 - incontent_6 --><!-- Ezoic - gen_incontent_6 - incontent_6 --><p>Several minutes after the alum has dissolved, the surface of the solution should start to settle down. Check out this GIF:</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/drifting.gif" alt="the effect of adding alum to the salt solution" width="600" height="360">I placed a cork on the surface of the solution to visualize the movement on the surface. Before adding alum, the cork swirled around. After adding alum, the cork was completely motionless.</em></p><!-- Ezoic - wp_incontent_8 - incontent_8 --><!-- End Ezoic - wp_incontent_8 - incontent_8 -->
<p>Good. Now you just need to wait.</p>
<p>It takes about 30 minutes for the salt solution to reach saturation, which is the point where salt crystals start to form.</p>
<p>Eventually, small white squares will appear on the surface of the solution.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Those are baby pyramid salt crystals.</p>
<p>They’ll keep growing, and within 15 minutes they’ll look like this:</p><!-- End Ezoic - gen_incontent_7 - incontent_7 --><!-- Ezoic - gen_incontent_7 - incontent_7 --><!-- Ezoic - wp_incontent_9 - incontent_9 --><!-- End Ezoic - wp_incontent_9 - incontent_9 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals.jpg" alt="growing pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">The crystals are actually upside down pyramids, suspended on the surface of the solution due to surface tension. It’s the same principle that lets some insects walk on water.</p><p><span></span><span id="ez-clearholder-large-leaderboard-2"></span><span data-ez-name="crystalverse_com-large-leaderboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=36&amp;impression_group_id=crystalverse_com-large-leaderboard-2/2023-10-09/5772296549169062&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>Here’s what they look like from the side:</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2.jpg" alt="growing pyramid salt crystals side view" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">As the pyramid salt crystals get heavier, they sink lower into the solution. But evaporation on the surface causes the base of the pyramids to grow outwards, widening it and forming a staircase pattern in the process.</p>
<p>Super cool.</p>
<p>Here’s a time lapse of the growing process over 1 hour:</p><!-- Ezoic - wp_incontent_10 - incontent_10 --><p><span data-ez-name="crystalverse_com-portrait-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=121&amp;impression_group_id=crystalverse_com-portrait-1/2023-10-09/3006809575214744&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_10 - incontent_10 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-growth-timelapse.gif" alt="growing pyramid salt crystals timelapse" width="1000" height="563">As the pyramids get larger, they risk bumping into their neighbors.</p><p><span></span><span id="ez-clearholder-leader-1"></span><span data-ez-name="crystalverse_com-leader-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=37&amp;impression_group_id=crystalverse_com-leader-1/2023-10-09/1041402029238281&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>Usually, it isn’t a big problem – unless your solution is too hot. If you heat it beyond 80°C, the pyramids quickly join together to form a layer of crust.</p><!-- End Ezoic - gen_incontent_8 - incontent_8 --><p><span data-ez-name="crystalverse_com-leader-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=918&amp;impression_group_id=crystalverse_com-leader-4/2023-10-09/2721672241229637&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_8 - incontent_8 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/salt-crust.jpg" alt="salt crust" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/salt-crust.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/salt-crust-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/salt-crust-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">But even at 60°C, you shouldn’t leave them there, because they might get too heavy and fall to the bottom to the dish.</p>
<p>So it’s time to harvest the pyramids.</p>
<h3 id="harvesting-the-pyramid-salt-crystals">Harvesting the pyramid salt crystals</h3>
<p>Using a pair of tweezers, carefully remove the pyramid that you want, and place it on a piece of tissue paper. The paper will soak up excess salt solution.</p><!-- Ezoic - wp_incontent_11 - incontent_11 --><p><span data-ez-name="crystalverse_com-netboard-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=122&amp;impression_group_id=crystalverse_com-netboard-1/2023-10-09/7495419673188588&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_11 - incontent_11 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals.jpg" alt="harvesting salt pyramids" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Before you remove the second pyramid, dip the tweezers in a cup of water. This step ensures that there are no powdery salt grains sticking to your tweezers – which will cause thousands of tiny crystals to form in the dish.</p><p><span></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=700&amp;impression_group_id=crystalverse_com-large-mobile-banner-2/2023-10-09/6206741729208347&amp;ad_size=580x400&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>Then, dry the tweezers with a tissue, and remove your second pyramid. Rinse and repeat.</p>
<p>Instead of using tweezers, you can also use a sieve to scoop up those pyramids. Remember to dip the sieve in water after every run.</p><!-- End Ezoic - gen_incontent_9 - incontent_9 --><!-- Ezoic - gen_incontent_9 - incontent_9 -->
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/nucleation.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/nucleation.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/nucleation-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/nucleation-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Wash your tweezers after every run to prevent powdery salt grains from forming.</em></p>
<p>You can keep doing this until the salt water starts to dry out. By this time, you should have quite a few pyramids.</p><!-- Ezoic - wp_incontent_12 - incontent_12 --><p><span data-ez-name="crystalverse_com-small-square-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=123&amp;impression_group_id=crystalverse_com-small-square-2/2023-10-09/3989411035204644&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_12 - incontent_12 -->
<p>And that’s it!</p>
<p>You’ve just made the fabled pyramid salt, also known as <em>fleur de sel</em>, flower of salt, at home.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid.jpg" alt="a large salt pyramid i grew" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">If you want to make more pyramids, just add some water to the dish and wait for all the salt to re-dissolve. Then repeat the process. This time, you don’t need to add alum.</p><p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/redissolving.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/redissolving.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/redissolving-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/redissolving-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Re-dissolving the salt to make more pyramids.</em></p>
<h3 id="storing-the-pyramid-salt-crystals">Storing the pyramid salt crystals</h3>
<p>Just store them like regular salt.</p><!-- Ezoic - wp_incontent_13 - incontent_13 --><!-- End Ezoic - wp_incontent_13 - incontent_13 -->
<p>If you live somewhere humid, the crystals will absorb moisture from the air and get slightly wet. This will cause part of the pyramid’s base to dissolve.</p><!-- End Ezoic - gen_incontent_10 - incontent_10 --><!-- Ezoic - gen_incontent_10 - incontent_10 -->
<p>It’s no big deal, but if you want to prevent this, store the pyramid salt crystals with a desiccant.</p>
<h3 id="tasting-the-pyramid-salt-crystals">Tasting the pyramid salt crystals</h3>
<p>What do you mean?</p>
<p>Of course I’ve licked the pyramids.</p>
<p>They taste a bit saltier than regular salt. And crunchier.</p><!-- Ezoic - wp_incontent_14 - incontent_14 --><p><span data-ez-name="crystalverse_com-portrait-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=125&amp;impression_group_id=crystalverse_com-portrait-2/2023-10-09/1700991509187471&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_14 - incontent_14 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">You might also wonder if the alum added to the solution changes the taste of the salt, or if it’s unhealthy.</p>
<p>First, we added an extremely small amount of alum to the salt solution. So the pyramids taste like pure salt.</p>
<p>And since potassium alum is used in baking powder and considered safe by the FDA, it’s alright to bite a pyramid or two.</p>
<p>However, I would discourage you from eating pyramid salt grown with this method regularly. I’m no dietician, and it’s best to look for an expert before adding something new to your diet.</p><!-- End Ezoic - gen_incontent_11 - incontent_11 --><!-- Ezoic - gen_incontent_11 - incontent_11 -->
<h3 id="types-of-pyramid-salt-crystals">8 types of pyramid salt crystals</h3>
<p>At the start, I promised you’d see all sorts of pyramid salt crystals, some narrow, others wide. I told tales of Mayan pyramids, flowers and Eiffel Towers.</p><!-- Ezoic - wp_incontent_15 - incontent_15 --><!-- End Ezoic - wp_incontent_15 - incontent_15 -->
<p>Below you will find pictures of 8 different types of pyramid salt crystals and how I grew them.</p>
<h4>1. Regular pyramids</h4>
<p>Regular pyramids are the most common type of salt crystal. They form from a solution heated to 60-70°C at low to medium humidity.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals.jpg" alt="regular pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">They look like the typical right pyramid, with a square base, and straight edges that meet at the top. The edges have small crystals on them.</p>
<p>Remember, pyramids form upside down – hence, they grow from the top to the bottom. Since salt crystals get larger the longer they stay in the solution, the crystals near the top are bigger than the ones at the bottom.</p><!-- End Ezoic - gen_incontent_12 - incontent_12 --><!-- Ezoic - gen_incontent_12 - incontent_12 -->
<h4>2. Thick pyramids</h4>
<p>Now, regular pyramids are thin and fragile. But if they drop into the solution and are left there, more crystals will deposit on their surface, thickening the faces of the pyramid.</p><!-- Ezoic - wp_incontent_16 - incontent_16 --><!-- End Ezoic - wp_incontent_16 - incontent_16 -->
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals.jpg" alt="thick pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Compare the regular pyramid, grown on the surface of the solution, vs the pyramid that fell to the bottom of the dish and left to thicken as more crystals formed on its surface.</em></p><p><span></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=702&amp;impression_group_id=crystalverse_com-large-mobile-banner-1/2023-10-09/8227365365215580&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>These “thick” pyramids might look less elegant, but they are also less fragile.</p>
<h4>3. Two sided pyramids</h4>
<p>Once, I tried to pick up a pyramid with my tweezers, but by accident, it fell back into the solution. Instead of sinking, it continued to float – but with the tip of the pyramid facing up, and the base facing down.</p>
<p>I let it grow for another 15 minutes, and the pyramid turned into this magnificent hourglass shaped crystal:</p><!-- End Ezoic - gen_incontent_13 - incontent_13 --><p><span data-ez-name="crystalverse_com-square-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=923&amp;impression_group_id=crystalverse_com-square-1/2023-10-09/6230693317183869&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_13 - incontent_13 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal.jpg" alt="a pyramid salt crystal shaped like an hourglass" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<h4>4. Narrow pyramids</h4>
<p>Pyramid growth is a balancing act between gravity and how fast the base of the pyramid can widen. Sometimes, the base of the pyramid grows very slowly, while gravity keeps pulling it downwards.</p><!-- Ezoic - wp_incontent_17 - incontent_17 --><!-- End Ezoic - wp_incontent_17 - incontent_17 -->
<p>As a result, we get narrow salt crystals that look less like pyramids and more like Eiffel towers, or chess pieces, if you will.</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals.jpg" alt="narrow pyramid salt crystals shaped like chess pieces" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Salty chess. When you capture a piece, you eat it.</em></p>
<p>These narrow pyramids like to form when the temperature of the solution is below 60°C.</p>
<p>My theory is that when the temperature is low, less evaporation occurs, and so less crystal growth occurs at the surface. Thus, the pyramids sink faster than they widen – hence the narrower shape.</p><!-- Ezoic - wp_incontent_18 - incontent_18 --><p><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=129&amp;impression_group_id=crystalverse_com-vertical-banner-1/2023-10-09/2871160131219933&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_18 - incontent_18 -->
<p>If you increase the temperature while these salt crystals are forming, the base will get wider, curving outwards. The resulting pyramids look like trumpets.</p><!-- End Ezoic - gen_incontent_14 - incontent_14 --><!-- Ezoic - gen_incontent_14 - incontent_14 -->
<h4>5. Big headed pyramids</h4>
<p>If you look closely at the pyramids, you’ll find that each pyramid has a “head” at its tip. Sometimes the head is small, sometimes it is big.</p>
<p>Below are some big headed pyramids.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals.jpg" alt="big headed pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">The so-called “head” is actually a large salt cube. When it starts forming, it looks like a tiny square on the surface of the solution.</p>
<p>Then, as the crystal gets heavier, it sinks a little into the solution. As it sinks, layers of salt crystals grow on the face of the cube facing the sky, forming a pyramid. But the other sides of the crystal cube (that are underwater) also keep growing. Eventually, they form the “head” of the pyramid.</p><!-- Ezoic - wp_incontent_19 - incontent_19 --><!-- End Ezoic - wp_incontent_19 - incontent_19 -->
<p>Sometimes, the head is tiny. Sometimes the head is much larger, and you can see interesting patterns on the hopper crystal.</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers.jpg" alt="flowers made of salt" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">If you place the pyramids upside down, they look remarkably like flowers. You might be able to serve some ketchup in them.</em></p><!-- End Ezoic - gen_incontent_15 - incontent_15 --><p><span data-ez-name="crystalverse_com-sky-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=925&amp;impression_group_id=crystalverse_com-sky-3/2023-10-09/2581966311209185&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_15 - incontent_15 -->
<p>Despite having spent an unhealthy amount of time on this project at home, I confess that there was one secret that escaped me: how to control the size of the heads.</p>
<p>At first, I thought it was due to different types of salt. So I tried comparing two types of salt – sea salt and rock salt. I found that the batch with sea salt gave big heads and rock salt gave small heads.</p>
<p>I thought I had my answer.</p><!-- Ezoic - wp_incontent_20 - incontent_20 --><p><span data-ez-name="crystalverse_com-narrow-sky-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=131&amp;impression_group_id=crystalverse_com-narrow-sky-2/2023-10-09/7652709461229354&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_20 - incontent_20 -->
<p>After a few days, out of curiosity, I ran the two experiments again, side by side. This time, it was the opposite – sea salt gave small heads and rock salt gave big heads.</p>
<p>I was equal parts surprised and confused.</p>
<p>And we haven’t even gotten to the scary part yet.</p>
<p>After 15 minutes, the heads on the sea salt pyramids started growing bigger, until they were just as big as the heads of the rock salt pyramids!</p>
<p>Such was my hunt for the reason behind different head sizes. I tried changing the temperature and the type of container. I tried using deionized water. I even tried adding impurities such as vinegar and baking soda to the solution.</p><!-- End Ezoic - gen_incontent_16 - incontent_16 --><p><span data-ez-name="crystalverse_com-square-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=926&amp;impression_group_id=crystalverse_com-square-3/2023-10-09/5737811381184322&amp;ad_size=728x90&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_16 - incontent_16 --><!-- Ezoic - wp_incontent_21 - incontent_21 --><!-- End Ezoic - wp_incontent_21 - incontent_21 -->
<p>But my efforts were mostly frustrating and fruitless. It was full of contradictions. I was as salty as the saturated salt solution and my mood as sour as the vinegar I added to it.</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Top and side view of big headed pyramid salt crystals.</em></p>
<p>My last hope was the effect of humidity. But I didn’t have a device to measure humidity. So I had to rely on a crude technique – obsessively checking the weather station reports. Based on the several experiments I did, there seemed to be some relationship:</p>
<p><strong>The lower the humidity, the smaller the pyramid head.</strong></p>
<p>My tests were not conclusive, as occasionally large heads still formed on hot sunny days. But generally, drier days yielded smaller heads.</p><!-- Ezoic - wp_incontent_22 - incontent_22 --><p><span data-ez-name="crystalverse_com-small-rectangle-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=133&amp;impression_group_id=crystalverse_com-small-rectangle-2/2023-10-09/3304111503200098&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_22 - incontent_22 -->
<p>I’ll discuss this later. For now, let’s look at 3 other types of pyramids.</p>
<p>They were grown from the exact same salt solution – in which I had added a teaspoon of Epsom salt.</p><!-- End Ezoic - gen_incontent_17 - incontent_17 --><p><span data-ez-name="crystalverse_com-leader-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=927&amp;impression_group_id=crystalverse_com-leader-3/2023-10-09/5545226655187678&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_17 - incontent_17 -->
<h4>6. Monster pyramids</h4>
<p>The first pyramid salt crystal that grew from this solution was an absolute beast. The humongous head was covered with all sorts of intricate formations that reminded me of bismuth crystals.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal.jpg" alt="a massive salt hopper crystal" width="1000" height="1333" srcset="https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal-225x300.jpg 225w, https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal-768x1024.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">After half an hour, I extracted this crystal with tweezers and dried it. Then, from the same solution, a different type of pyramid started forming:</p>
<h4>7. Slanted pyramids</h4>
<p>At first, it looked like a regular, small-headed pyramid. Then, it tilted over to one side and continued growing, until it looked like this:</p><!-- Ezoic - wp_incontent_23 - incontent_23 --><p><span data-ez-name="crystalverse_com-netboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=134&amp;impression_group_id=crystalverse_com-netboard-2/2023-10-09/4274464571177895&amp;ad_size=580x400&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_23 - incontent_23 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal.jpg" alt="a large slanted pyramid salt crystal" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<h4>8. Ultra wide pyramids</h4>
<p>After removing the slanted crystal, more pyramids continued to form. These were regular symmetrical pyramids with small heads. But they were also very flat – the flattest I have ever seen:</p><p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals.jpg" alt="ultra wide pyramidal salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">3 different types of salt crystals forming from the same solution, barely an hour apart.</p><!-- End Ezoic - gen_incontent_18 - incontent_18 --><!-- Ezoic - gen_incontent_18 - incontent_18 --><p><span></span><span id="ez-clearholder-mobile-leaderboard-2"></span><span data-ez-name="crystalverse_com-mobile-leaderboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=704&amp;impression_group_id=crystalverse_com-mobile-leaderboard-2/2023-10-09/5619997869225204&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>I was reminded once again that the art of crystal growing is both mysterious and wonderful.</p>
<h3><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals.jpg" alt="pyramid salt hopper crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></h3>
<h3 id="some-more-information">Some more information</h3>
<p>Before writing this article, I have looked online for guides on how to grow pyramidal salt at home, and found nothing.</p><!-- Ezoic - wp_incontent_24 - incontent_24 --><p><span data-ez-name="crystalverse_com-leader-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=135&amp;impression_group_id=crystalverse_com-leader-2/2023-10-09/5777086383174099&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_24 - incontent_24 -->
<p>But I did find <a href="https://www.jstage.jst.go.jp/article/swsj/73/2/73_81/_pdf" target="_blank" rel="noopener">a study</a> published in the World Salt Symposium where researchers successfully grew pyramid salt from waste salt water in large, steel crystallizers.</p>
<p>They claim that calcium ions in seawater help pyramids form by allowing more salt to dissolve in water. I tried adding various amounts of calcium chloride to my solutions, and it had no noticeable effect.</p>
<p>They also claim that a pH of 4, and a temperature of 55-65°C was good for pyramid growth. My experiments agree.</p><!-- End Ezoic - gen_incontent_19 - incontent_19 --><p><span data-ez-name="crystalverse_com-sky-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=929&amp;impression_group_id=crystalverse_com-sky-4/2023-10-09/5371588283228848&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_19 - incontent_19 -->
<p>Since alum is mildly acidic, dissolving some alum in water would indeed yield a pH of around 4. But I have tried using other acids like vinegar and cream of tartar. Neither yielded pyramids. I suspect it has something to do with aluminum ions, because replacing potassium alum with aluminum sulfate worked.</p>
<p>Finally, according to the authors, sulfate ions were bad for pyramid growth because they encouraged hopper cubes (we know them as “heads”) to form. After removing the sulfates, the researchers managed to grow nice regular pyramids.</p><!-- Ezoic - wp_incontent_25 - incontent_25 --><!-- End Ezoic - wp_incontent_25 - incontent_25 -->
<p>I knew that sulfates were not the only factor that affects head size, because in my experiments, the same solution could form both big and small heads.</p>
<p>Nevertheless, I decided to try this hypothesis. I had no easy way to <em>remove</em> the sulfates, but I could <em>add</em> Epsom salt (magnesium sulfate) to my solutions.</p>
<p>You have seen the results in the previous section. The same solution formed monster pyramids, slanted pyramids and ultra wide pyramids, 1 hour apart. Maybe magnesium sulfate indeed makes the heads bigger, but then, it must be quickly used up, causing subsequent pyramids to have very small heads. But it’s hardly conclusive.</p><!-- End Ezoic - gen_incontent_20 - incontent_20 --><!-- Ezoic - gen_incontent_20 - incontent_20 -->
<p>What do you think?</p>
<p>How do you control head size? Whether you’re a science loving kid or a research chemist, I leave it to you.</p><!-- Ezoic - wp_incontent_26 - incontent_26 --><p><span data-ez-name="crystalverse_com-small-rectangle-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=137&amp;impression_group_id=crystalverse_com-small-rectangle-1/2023-10-09/218855441170946&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_26 - incontent_26 -->
<h3 id="summary">Summary</h3>
<p>That’s all for now. I have been trying to grow pyramid salt crystals for a very long time, and I’m glad to share what I’ve learnt with you. Hopefully you found the guide useful.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4.jpg" alt="growing salt pyramids at home" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Here’s a super short summary of what we’ve covered.</p><p>To grow pyramid salt crystals, you’ll need:</p>
<ul>
<li>A bag of salt</li>
<li><a href="https://amzn.to/3U3mHUq" target="_blank" rel="noopener">Alum powder</a></li>
<li><a href="https://amzn.to/3QNa90B" target="_blank" rel="noopener">A stove/hot plate</a></li>
<li><a href="https://amzn.to/3RARFBA" target="_blank" rel="noopener">A heat resistant glass dish</a></li>
<li>A pair of tweezers</li>
<li>A thermometer (optional)</li>
</ul>
<ol>
<li>Dissolve 165 g salt per 500 mL of water.</li>
<li>Heat the solution to 60°C.</li>
<li>Add 0.5 g alum per 500 mL of solution.</li>
<li>Wait for pyramids to form.</li>
<li>Remove the pyramids with tweezers.</li>
<li>Dry and store them with a desiccant.</li>
<li>Enjoy your pyramid salt.</li>
</ol>
<p>***</p>
<p>Thank you for reading.</p><!-- Ezoic - wp_incontent_27 - incontent_27 --><p><span data-ez-name="crystalverse_com-square-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=138&amp;impression_group_id=crystalverse_com-square-4/2023-10-09/8658461997180016&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_27 - incontent_27 -->
<p>Maybe you found a new hobby today. Maybe you’ll find a few hours of joy with your kids. Or maybe it simply put a small smile on your face.</p>
<p>I grow crystals because it makes me happy, and I hope it made you happy too.</p>
<p>If you want to start crystal growing, I also recommend <a href="https://crystalverse.com/grow-alum-crystals-at-home/">making alum crystals</a>. They are large, transparent and easy to grow.</p><!-- End Ezoic - gen_incontent_21 - incontent_21 --><p><span data-ez-name="crystalverse_com-narrow-sky-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=931&amp;impression_group_id=crystalverse_com-narrow-sky-1/2023-10-09/5562498227237401&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_21 - incontent_21 -->
<p><a href="https://crystalverse.com/grow-alum-crystals-at-home/"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals.jpg" alt="alum crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>And if you enjoyed this guide, consider subscribing to <a href="https://crystalverse.com/#newsletter">my newsletter</a>. Let’s keep in touch. I’ll share more crystal growing guides with you when they come out.</p>
<p>As always, happy growing.</p><!-- Ezoic - wp_incontent_28 - incontent_28 --><p><span data-ez-name="crystalverse_com-mobile-leaderboard-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=139&amp;impression_group_id=crystalverse_com-mobile-leaderboard-1/2023-10-09/5327963983219860&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_28 - incontent_28 -->
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://crystalverse.com/pyramid-salt-crystals/"
    dc:identifier="https://crystalverse.com/pyramid-salt-crystals/"
    dc:title="How to Easily Make Your Own Pyramid Salt Crystals"
    trackback:ping="https://crystalverse.com/pyramid-salt-crystals/trackback/" />
</rdf:RDF>-->
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DNS record "hn.algolia.com" is gone (254 pts)]]></title>
            <link>https://www.nslookup.io/domains/hn.algolia.com/dns-records/</link>
            <guid>37821821</guid>
            <pubDate>Mon, 09 Oct 2023 16:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nslookup.io/domains/hn.algolia.com/dns-records/">https://www.nslookup.io/domains/hn.algolia.com/dns-records/</a>, See on <a href="https://news.ycombinator.com/item?id=37821821">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[To Fight Big Tech, We Must Seize the Means of Computation (108 pts)]]></title>
            <link>https://truthout.org/audio/to-fight-big-tech-we-must-seize-the-means-of-computation/</link>
            <guid>37821557</guid>
            <pubDate>Mon, 09 Oct 2023 15:40:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://truthout.org/audio/to-fight-big-tech-we-must-seize-the-means-of-computation/">https://truthout.org/audio/to-fight-big-tech-we-must-seize-the-means-of-computation/</a>, See on <a href="https://news.ycombinator.com/item?id=37821557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="articleContent">
<figure itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><img width="1200" height="771" src="https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-1200x771.jpg" alt="Movement Memos - a Truthout podcast - featuring guest Cory Doctorow and host Kelly Hayes" decoding="async" itemprop="url" loading="eager" fetchpriority="high" srcset="https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-1200x771.jpg 1200w, https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-400x257.jpg 400w, https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-200x128.jpg 200w, https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-800x514.jpg 800w, https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-1536x987.jpg 1536w, https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a-2048x1316.jpg 2048w, https://truthout.org/app/uploads/2023/09/2023_0925-movement-memos-doctorow-hayes-a.jpg 2377w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>

<section>
<header>
<h4>Part of the Series</h4>
</header>
<article>
<h5><a href="https://truthout.org/series/movement-memos/">Movement Memos</a></h5>
</article>
</section>

<p>“If you’ve never tried to organize a movement without the internet, I’m here to tell you, it’s really hard. We need to seize the means of computation, because while the internet isn’t the most important thing that we have to worry about right now, all the things that are more important, gender and racial justice, inequality, the climate emergency, those are struggles that we’re going to win or lose by organizing on the internet,” says author and activist Cory Doctorow. In this episode of “Movement Memos,” host Kelly Hayes talks with Doctorow about the lessons of his book <em>The Internet Con: How to Seize the Means of Computation</em>.</p>
<p><em>Music by Son Monarcas &amp; David Celeste</em></p>
<h2>TRANSCRIPT</h2>
<p><em>Note: This a rush transcript and has been lightly edited for clarity. Copy may not be in its final form.</em></p>
<p><strong>Kelly Hayes</strong>: Welcome to “Movement Memos,” a <em>Truthout</em> podcast about organizing, solidarity and the work of making change. I’m your host, writer and organizer Kelly Hayes. Today, we are talking about how Big Tech wrecked the internet and what we can do about it. I think we all know what it’s like to want to be done with an app or a website. Whether we’re fed up with unchecked harassment, deceptive marketing, the drain on our time or attention, or the sheer number of Nazis on a platform, I think most of us know what it’s like to want out, yet still feel walled in. We may worry that we’ll lose touch with family and friends if we permanently log off, or we may need our social media reach to facilitate our activism or careers. Some of us have deleted social media apps from our phones, in an effort to curb our scrolling time, only to download them again in short order, because we just can’t kick the habit. If, like me, you continue to use platforms whose owners you despise or that you honestly don’t believe should exist, this episode is for you. Because today, we are talking to author Cory Doctorow about his new book <a href="https://www.versobooks.com/products/3035-the-internet-con"><em>The Internet Con: How to Seize the Means of Computation</em></a><em>. </em>Cory Doctorow is a science fiction author, activist and journalist. He is the author of many books, most recently <em>The Internet Con</em>, which he has characterized as a “Big Tech disassembly manual.” Cory’s other recent works include <em>Red Team Blues</em>, a science fiction crime thriller; <em>Chokepoint Capitalism</em>, a nonfiction book about monopoly and creative labor markets; and the <em>Little Brother</em> series for young adults. In 2020, Cory was inducted into the Canadian Science Fiction and Fantasy Hall of Fame.</p>
<p>We have been talking a lot this season on the show about how Big Tech is shaping our lives and our world, and I was really grateful for the opportunity to discuss these issues with Cory, whose book offers an invaluable resource to people who want to push back against Big Tech. As Cory writes in the book’s introduction:</p>

<blockquote>
<p>This is a shovel-ready book. It explains, in nontechnical language, how to dismantle Big Tech’s control over our digital lives and devolve control to the people who suffer most under Big Tech’s hegemony: marginalized users, low-level tech workers and the people who live downstream of tech’s exhaust plume: people choking on toxic waste from the tech industry and people living under dictatorships where control is maintained with off-the-shelf cyberweapons used to hunt opposition figures.</p>
</blockquote>
<p>If we want to push back against the dystopian dynamics of the tech world, we have to understand how we got here. We need to know what we’re dealing with and what changes might upend the dynamics that currently define our experience of the internet. We have been discussing tech issues a lot this season on “Movement Memos” because I think there is a serious need for political education on this topic in our movements. With this podcast, we try to make every episode a resource for people who want to take action and change the world. I have been grateful to hear from folks who have used the podcast in their classrooms, for popular education in their organizing groups, or to help shape their own analysis. Your support and your feedback mean the world to us. If you believe in what we are doing and want to support the show, you can help sustain our work by <a href="https://truthout.org/subscribe/">subscribing</a> to <em>Truthout</em>’s newsletter or by <a href="https://truthout.org/?form=donate">making a donation</a> at truthout.org. You can also support “Movement Memos” by subscribing to the podcast on Apple or Spotify, or wherever you get your podcasts, or by leaving a positive review on those platforms. Sharing episodes that you find useful with your friends and co-strugglers is also a big help, so if you are doing any of those things in support of the show, I want to extend our warmest thanks. I love this work, and we couldn’t do it without you, so thanks for believing in us and for all that you do. And with that, I hope you enjoy the show.</p>
<p><em>(musical interlude)</em></p>
<p><strong>Cory Doctorow</strong>: My name is Cory Doctorow. I’m a science fiction writer and an activist, and I spent more than 20 years working on tech policy and digital human rights, mostly with an organization called the Electronic Frontier Foundation, where I’m now a special advisor, but I was formerly the European Director. <em>The Internet Con</em> is my latest book. I write when I’m anxious and I mostly write science fiction novels. I came out of the pandemic with eight books. This is one of the two nonfiction books that I came out of pandemic with, and this one’s from Verso. It’s called <em>The Internet Con: How to Seize the Means of Computation</em>. And it explains how the internet became what Tom Eastman calls five giant websites full of screenshots of text from the other four, and lays out a plan for actually doing something about it. Not just things that we think will make the tech company sad, but things that might make us happy by giving us an internet that we deserve and indeed need.</p>
<p><strong>KH</strong>: So, how did the internet become such a mess? Given that the internet as we know it has only existed for a few decades, it’s easy to zero in on regulatory failures and other major events during that time when trying to understand how we got here. But to really get our heads around what Cory calls the internet con, we have to rewind further and talk about the nature of monopolies and the gutting of antitrust laws.</p>
<p><strong>CD: </strong>So antitrust law begins in the late 19th century, the kind of Robber Baron era. The first antitrust law was passed by a guy called Senator John Sherman, who’s better known brother was Tecumseh Sherman. And he really summed up the case for antitrust in a speech he gave in 1890 on the floor of the Senate where he was stumping for his bill where he said, “we got rid of kings, but now we have these kings of trade. If we would not allow a king over the daily lives that we live, we shouldn’t allow an autocrat of trade to decide how we live.”</p>
<p>So Sherman, he was worried about companies that would get too big to fail and too big to jail. Companies that would be so big that it would be impossible to hold them to account, because even if they were bank to rights, and even if you could muster the political will to do something about them, if you got rid of them, you would leave such a giant hole in society because of all the important services they provided that they’d still get away with it. And that was the basis on which we enforced antitrust law for the next 80 years until the mid 1970s. We passed lots of other antitrust laws, the Clayton Act and the Federal Trade Commission Act and so on.</p>
<p>But when you get to the mid-seventies and Jimmy Carter, he starts to toy with this idea that comes from this fringe character called Robert Bork, best known for the adjective “borked,” which comes from how badly he bungled his presentation when Reagan tried to put him on the Supreme Court and the Senate just shredded him for having been Nixon’s solicitor general. And Bork was a conspiracy theorist who said that, like, John Sherman and all these other people who wrote antitrust laws, actually loved monopolies, and they thought they were really powerful and really efficient and that they benefited all of us as consumers, and that the last thing that we should do to enforce these laws that were written by people who were very clear about what they wanted, is to use them against monopolies.</p>
<p>And so as a result, we then spent the last 40 years… It started with Carter and accelerated under Reagan, and then every administration up to the current one has piled onto this. We spent the last 40 years tolerating monopolies, allowing these autocrats of trade to spring up so that in every sector, not just tech, we now have between one and five companies running everything that’s important to our lives.</p>
<p>Computers have historically been very resistant to monopolization because they have this intrinsic characteristic that is almost mystical, it’s certainly very technical, which is this thing called universality. Like the only computer that we know how to make is something technically called the Universal Turing Complete von Neumann Machine, which is a lot of words. That just means that the only computer we can make is a computer that can run every valid program. And so every program that can run on your desktop computer could also run on your printer and could also run on your thermostat, and could also run on that little system on a chip in your singing greeting card.</p>
<p>And what that means is that historically, if you designed a computer like say an IBM Mainframe, and you were charging 10,000% margins for hard drives for your IBM Mainframe, someone could make what was called then a plug compatible hard drive, one that would just plug in, a company like Fujitsu say, and only charge a 100% margin or even a 10% margin. And as a result, tech was very dynamic. Companies would come and companies would go, and when a new company came on the scene, they could take all of the things that the old company was using to hold you prisoner, the proprietary formats for your data, the proprietary formats for storage, the proprietary architecture that the program ran on, and they could make conversion layers and tools and utilities and plug compatible devices, and they could just set you free, that you would always have these low switching costs to go from one technology to another.</p>
<p>And that meant that tech companies, even though they weren’t run by people who were any better than anyone else, were always keenly aware that their customers were, as The Google Boys used to say, “one click away from going somewhere else.” And they put a lot of energy into making sure that their customers were happy, because they really understood that if their customers were sad, that those customers had a lot of options. And as tech got bigger… And the way it got bigger was by buying its competitors. Google is a company that made one good product 25 years ago, a really good search engine, and then proceeded to fail at everything else they tried to make in-house, from multiple social media platforms, to a video platform, to a smart cities tool, to wifi balloons. Even their RSS reader, they all went down in flames. Google just went out and they bought other companies, right? They went out and bought a video stack and an ad tech stack and a mobile stack and a server management stack.</p>
<p>Docs, maps, collaborations, satellite photos, you name it. It’s someone else’s idea that they bought and operationalized, and operationalizing things is very important. I’m all about the care work, but to call them innovators is a stretch. And so the way that they grew was just by buying out everyone who might someday do to them what they did to the companies that came before them.</p>
<p>And that’s what everyone else did too. Tim Cook in 2019 told Kara Swisher that Apple had bought 90 companies the year before, Apple’s coming home with a new company more often than you’re coming home with a bag of groceries. And as a result, we got this massive concentration in tech, which left us not only with few places to go, but also a sector that was so concentrated in chummy that it found it quite easy to capture its regulators, so that the things that other companies used to do that those companies did to attain scale, to enter the market, to take customers from the incumbents, reverse engineering bots, scraping, making compatible products, all of those things became illegal. The pirates became admirals and they said, “When we did it, that was progress. And when you do it to us, that’s theft.” And they managed to create something that we can think of, as Jay Freeman says, as felony contempt of business model.</p>
<p>We’re doing things that aren’t illegal, but that make their shareholders sad. Can be made illegal by mobilizing different parts of IP law that have been distorted beyond all recognition, into a charter that allows these companies to control the conduct of their competitors, their critics, and us, their customers.</p>
<p><strong>KH</strong>: In <em>The Internet Con</em>, Cory writes: </p>
<blockquote>
<p>The history of technology is one long guerilla fight where the established giants wield network effects against scrappy up starts, whose asymmetrical warfare weapon of choice is low switching costs.</p>
</blockquote>
<p>There is perhaps no better example of a company whose dominance is propped up by high switching costs than Facebook, a platform that many of us loathe but use anyway.</p>
<p><strong>CD</strong>: So when Facebook started, well first they made themselves available just to American college kids, right? You had to have a .edu address to be a Facebook user. But eventually they ran out of worlds to conquer there and they decided they were going to welcome the general public to Facebook, and they went to everyone who had a social media account and they said, “you should come over to Facebook.” But there’s a problem with leaving social media, which is that as good as a rival service might be, if your friends aren’t there, it’s not good enough. You don’t use social media because the user interface is nice or you like the graphics or it has a great app. You use social media because of the people who are there. And when a lot of people gather in one place, they get a kind of inertia. I mean, anyone who’s ever, I don’t know, tried to figure out what movie to go to with all of their friend group on a Friday night knows what this is like, right? You could be arguing for hours and still never pick a movie.</p>
<p>And so when you’ve got a couple of hundred friends of yours on one social media platform and you want to go to another, well, maybe everyone’s dissatisfied with the one you’re on, but they’re not all ready to leave at the same time and they don’t always agree on where they should go next. So Facebook said, “hey, we’re going to solve this collective action problem for you. We’re going to lower the switching cost of leaving the major platform.” Which was not good, right? The major platform was this decaying social media platform owned by a crapulent, evil, senescent Australian billionaire whose name was Rupert Murdoch. And the platform is called MySpace, and most people who used it hated it, but they love their friends, and so they stayed there.</p>
<p>And Facebook said, “okay, well here you go. Here’s a bot. You give that bot your login and your password and it will log into MySpace and pretend to be you, and it will grab any messages that are waiting for you there and it’ll stick them in your Facebook inbox, and you can reply to them there and it will push them back out to MySpace. And back and forth and back and forth you can go so that you don’t all have to agree to leave at once. You can go when you’re ready and your friends can go when they’re ready. And if they’re never ready, well that’s fine. They can still be your friends and you can still stay in touch with them.”</p>
<p>Now, if you tried to do that to Facebook today, they would destroy you. They would say that you’d violated Section 1201 of the Digital Millennium Copyright Act, a 1998 law that makes it a crime to reverse engineer copyright access control systems. They would say that you had engaged in tortious interference with contract, an obscure part of contract law that has now become a weapon of choice for stopping people from making interoperable products. They’d say that you violated their patents and their copyrights and their trademarks and their trade secrets. If the person who helped build it used to work at Facebook, they’d say they violated their non-compete and their non-disclosure. So up and down the stack, they would mobilize this kind of weird gnarly hairball that we call IP [intellectual property] law to destroy you before you could even get started, because the pirates all want to become admirals. And when Facebook did it to MySpace, that was progress. But if you try to do that to Facebook, that’s theft.</p>
<p><strong>KH</strong>: Under capitalism, all the wrong people tend to decide what does and doesn’t constitute theft. This is a problem that comes up a lot on the internet around copyright law and intellectual property. A system called “notice and takedown” is supposed to allow people to notify a platform when their copyright has been violated so that the platform can remove the offending material or monetize it in favor of the copyright holder. But like so many features of the internet, this mechanism has often been weaponized to enact censorship and harm platform users.</p>
<p><strong>CD</strong>: When the internet started, it wasn’t clear what rule there should be for intermediaries who host other people’s speech, what we call content, but which we should really think of as speech. The things that you post that are expressive and matter to you, and that we have in mind when we talk about free speech and free expression and the first amendment and charter rights in Canada, and all that good stuff. It was pretty clear early on that most people, at least then, were not going to be in a position to host their own speech. That you weren’t going to run your own server and your own service that other people can log into in order to talk to you.</p>
<p>And even today, where technically that’s much simpler, because so many people are corralled within very large platforms, standing up your own server doesn’t really matter because no one’s going to be able to hear you or see what you have to say or speak back to you unless you’re on one of the big platforms. And so Congress in 1998, they passed the Digital Millennium Copyright Act. That’s the same law that has this anti-circumvention provision, section 1201. It also has this other provision, section 5-12 that says, “If a platform, an intermediary hosts a user’s speech, and that speech is later accused of infringing copyright, that that intermediary will not be a party to the copyright infringement, won’t be liable for damages, won’t have to go to court.” And the damages are crazy, right? The statutory damages for that kind of copyright infringement are $150,000 per download for a civil infraction and $250,000 for criminal infractions.</p>
<p>So even for a company the size of Facebook, it could quickly put the company out of business. And they said, “Instead of making you jointly liable for everything your users post, which would then lead to the circumstance where anyone who wanted to host speech for third parties would have to somehow discover whether or not that message that you posted saying, ‘hey guys, what movie should we see this Friday?’” Infringed copyright before they made it public, which is sort of full employment for every copyright lawyer that ever lived or could be trained. They would just say, “Look, if someone ever calls you out or sends you an email, and accuses one of your users of infringing their copyright, provided that you expeditiously remove that content, you won’t be a party to the copyright infringement.” And that may seem like a happy medium. And there are some ways in which it’s okay, it has ended up turning into a kind of thermonuclear weapon that can be used against speech.</p>
<p>So you have things like reputation management firms, who are really reputation launderers who work for torturers and murderers and corporate criminals, and they scrub the reputations of these people in part by writing to the search engines and saying, “The material that you’ve indexed that contains a truthful account of my client’s misdeeds, infringes my copyright, and I require you to de-list it from the search engine.” Often the newspaper or the blogger or whoever has written the thing that they’re objecting to never even finds out that one of their many articles has been de-listed from Google, so that material just goes down the memory hole.</p>
<p>When it comes to creative workers, it’s very bad indeed. So YouTube operates a kind of notice and take down service on steroids, what’s sometimes called a notice and stay down service, where a notification that something infringes copyright can result in all copies of it being taken down immediately and all future copies being prevented from being posted.</p>
<p>This system that Google runs for YouTube is called Content ID, and the way that it works is you upload some sound file and you say, “If this sound file is contained in any video that anyone posts to YouTube, I require you to remove it.” Or alternatively, you can say, “I require you to demonetize it,” or, “I require you to put ads on it and give the ad revenue to me. I’m going to take the ad revenue.” And so this has been a disaster for all kinds of performers. Obviously people who make documentary films that include excerpts from other films or music that they’re talking about, if they’re musicologists, this is very hard on them. A scholarly conference that live-streamed an eight-hour live stream, and during the lunch break, there was some licensed music played in the hall that was licensed to play in the hall, but not live stream, resulted in the entire video’s audio being removed permanently so that no one can hear anything that happened in this learning conference.</p>
<p>And if you’re a classical music player or performer, you have a very good chance of Sony Records taking down your performance, because Sony owns this giant library of classical music performances, and to the YouTube algorithm, anything that you play on your piano or cello or whatever is going to sound enough like a Sony recording that it will be taken down. And Sony has been prone in past and today to, when someone contests that take down, to insist no, that this really does infringe their copyright even when it doesn’t.</p>
<p>And then the worst of all is where you have creative workers who rely on YouTube for their income, either directing people to their Patreon or collecting ad revenue or doing something else like music teachers who drum up students by offering free lessons online. And you have predators who will send in bogus copyright claims against that person. And on YouTube, if you get three copyright claims, your account is removed permanently and you can’t open a new one. And they send two of these bogus claims so that you are one claim away from losing your livelihood on YouTube forever. And then they privately message you and demand ransom, and they say, “If you don’t pay them, they will send in that third claim, and the giant machine that is YouTube customer service will never hear your pleas, and you’ll be out of business.”</p>
<p>Authoritarians would like an internet where disfavored speech is not permitted, and where people who say disfavored things can be identified and punished. And this has, broadly speaking, been the goal of the entertainment companies since 1996. And that’s when Bill Clinton’s copyright czar, a guy called Bruce Lehman who’d been the head of copyright for Microsoft and then rotated into government service, went to Al Gore’s information superhighway hearings, the National Information Infrastructure hearings, and proposed something very similar to this. Gore laughed him out of the room. Gore’s a kind of a mixed bag politically. I think his environmental message is fine, but there are other areas I disagree with him with. But this was a good deed he did in laughing Bruce Lehman out of the room.</p>
<p>And after he laughed Bruce Lehman out of the room, Bruce Leman got the last laugh. He went to Geneva where the UN World Intellectual Property Organization meets. This is a thoroughly captured technical agency of the UN that has the same relationship to stupid internet law that Mordor has to evil and Middle Earth. It’s where it all originates from. And he got them to pass the internet treaties, the WIPO Copyright Treaties and the WIPO Performances and Phonograms Treaties, that were then brought back to the US as a treaty obligation and turned into the Digital Millennium Copyright Act, that law that we’ve been talking about where we find the prohibition on reverse engineering, and the notice and takedown system.</p>
<p><strong>KH</strong>: One of the reasons I really appreciated Cory’s book is that, while I am very concerned about the tech industry and how it’s shaping our world, I am not a tech person. It’s a subject that interests me, but when well-meaning people try to explain particular problems or concepts to me, I can easily get lost. Books have been my greatest resource in trying to understand the tech industry, and the books I have found most useful come from authors who make tech speak legible to people like me, who are nerds of a different variety. In <em>The Internet Con</em>, Cory talks about how most of us aren’t really wired to process the ins and outs of internet standards and regulations, and how companies exploit that disconnect. Cory writes:</p>
<blockquote>
<p>All this stuff — standardization meetings and forensic examinations of firewall errors — is <em>supremely </em>dull. It combines the thrill of bookkeeping with the excitement of Robert’s <em>Rules of Order</em>. Merely paying attention to it is a trial, and many of us are literally cognitively incapable of tuning into it for more than a few minutes before our minds start to wander.</p>
<p>It is <em>precisely </em>because this stuff is so dull that it is so dangerous.</p>
</blockquote>
<p>Cory calls the insulation from scrutiny that all of this dull content creates for tech companies a “shield of boringness.”</p>
<p><strong>CD</strong>: That’s a phrase I stole from the wonderful comics artist Dana Claire, who writes this great series of comic books about a little girl and her unicorn. And the unicorn can be seen by grownups, but grownups don’t notice the unicorn because the unicorn exudes a thing that she calls the shield of boringness. And the shield of boringness is just this thing that makes your eyes glaze over when you contemplate it. And as a result, nobody finds it remarkable that the unicorn is there. And so much of tech policy is so eye watering and dull and technical, and difficult to understand, that over and over again, these things that are incredibly powerful and important and will have a profound impact on how you live your life, just get turned into these dull technical debates that disappear into the halls of the most technocratic weirdos and freaks like me, and normies never get to hear about it until it’s making their life miserable.</p>
<p>So since the earliest days of the internet and even today, there have been proposals to ban working encryption. And encryption is a subject that’s boring even on its own, right? It’s a very abstract branch of mathematics. It’s hard to understand how it works. It’s full of all these technical terms like keys and ciphers and hashing and so on, asymmetric key exchanges, all of this stuff that’s very hard to understand to begin with, but encryption is incredibly important. For one thing, it’s like how you and your friends can talk to each other without being eavesdropped on. It’s how you can talk to your bank without having that information leak. It’s how you can protect the data on your computer, so if someone steals your computer, they can’t access your data. And it’s even how things like software updates for your pacemaker or your car’s anti-lock braking system can be transmitted from a server to the device, and the device can verify that it actually came from the real manufacturer and not from a third party who wanted to do something very bad and potentially lethal to you.</p>
<p>The problem with encryption is that it works. The little distraction rectangle you have in your pocket, when you take it out and aim your camera at something and press the shutter button, if you’ve got full disc encryption turned on, in the time it takes for your phone to play that little click, click sound, that photo is scrambled so thoroughly that if every hydrogen atom in the universe were turned into a computer and it did nothing until the end of the universe but try to guess what the key was that was needed to de-scramble it, that we would run out of universe long, long before we ran out of possible keys for you to have used for your phone to have generated and to scramble that photo.</p>
<p>And so this is very good if you’re trying to keep a secret, but it’s very bad if you’re trying to find out what a secret is, like if you’re a cop who wants to spy on someone, or if you’re a spy who wants to spy on someone. And so since the Clinton years, there has been this proposal that we should make encryption illegal, or that we should make encryption legal, but only broken kinds of encryption that we are assured by the authorities that only they can break into, and that they will only break into when they have a darn good reason. This is the first important case that the Electronic Frontier Foundation took on was over this.</p>
<p>In 1992, we represented a cryptographer who was then a grad student at UC Berkeley called Daniel J. Bernstein. Bernstein was publishing on the early internet something called Usenet computer programs that were stronger than the one that the NSA said was all that any civilian should ever need, that no bad guy would ever be able to break, but that they could break if bad guys were using it. Bernstein argued, and we argued on his behalf, that the First Amendment protected his right to publish that source code, that computer code, and the Ninth Circuit and the Ninth Circuit appellate division agreed.</p>
<p>But in that debate, normies were far from the action because it is such a genuinely weird and difficult to understand technical discussion. We tried to make it clear. One of the founders of EFF, an early technologist called John Gilmore, he built a computer called Deep Crack that could brute force all the possible keys that this NSA encryption allowed and therefore read everything scrambled with this NSA encryption. It cost him a quarter million dollars and it could brute force all the keys in two and a half hours. And fun fact, as I record this with you, Deep Crack is sitting about three feet to my left because John got tired of having it in his garage and made me custodian of it. It’s a thing the size of a beer fridge. And so we tried to explain to judges how this stuff worked, but their eyes glazed over.</p>
<p>The First Amendment argument carried the day, but to this day, and even now, there are laws all over the world, including in the United Kingdom, that are pending, that say that it should be illegal to make working encryption, and you should only be allowed to make broken encryption. And explaining the nuance between encryption that works and encryption that’s broken is very hard, and yet nobody wants to get a bad software update for their pacemaker. And so it’s very salient that this stuff works, and it works as well as possible. And by cloaking this discussion in the shield of boringness, something that should be of urgent technical debate in public society in every area of our world, becomes something that is banished to the back rooms where hobgoblins like me argue about it, and you only find out about it when someone ships a bum update to your anti-lock braking system and you die in a car wreck. </p>
<p><strong>KH</strong>: Between the “shield of boringness” and the seemingly inescapable dominance of platforms we hate, it’s easy to throw our hands up and give up on understanding the specifics of how and why tech companies have screwed us over. But if we are going to fight for the world we want, confrontations with Big Tech are inescapable, and while most of us will never understand as much as an expert like Cory does about that world, we need to know enough to craft demands that make sense.</p>
<p><strong>CD</strong>: People who say that tech is busted, I agree with them a hundred percent, but oftentimes if all you understand is that tech is busted but you don’t understand how it got that way, which is a mix of policy and technology, then you don’t know how to make it better. And so you end up with these solutions that aren’t solutions. You may have heard people talk about reforming something called Section 2-30 another. Another, my eyes glaze over initials with a number at the end, because it’s technically CDA 2-30, and then no one can make any sense of. And they’ll say, “the tech platforms are publishers, and yet they get something no publisher gets, which is that they’re immunized when their users post unlawful material, and therefore we should have that taken away, and then we can hold them to account for all the harassment and Nazis and whatever that are using their platforms.”</p>
<p>And this is just wrong. Most of the stuff that we’re worried about, racism and harassing content and so on, most of that stuff is legal to post. Making the platforms jointly liable for it won’t stop people from posting it. You’d have to change the first amendment for that. What it will do is make platforms extremely gun shy about stuff like Me Too, because they’ll be worried about being made jointly liable for libelous accusations of sexual harassment and assault. And what it will also do is stop sex workers or other marginalized groups from standing up their own servers where they can have discussions that aren’t moderated by Mark Zuckerberg and Elon Musk, and decide what is fair and not fair in their own spaces because they will never be able to manage the liability that’s associated with it.</p>
<p><strong>KH</strong>: So all of this begs the question, how can we challenge or break up Big Tech?</p>
<p><strong>CD</strong>: So Big Tech is distinctive. It’s not the only concentrated industry. There are plenty of those. But it is the only concentrated industry where we can use interoperability to affect the power of big tech. Now, big tech has used network effects to grow. Big tech platforms get more valuable when more people use them. So every seller that’s on Amazon is a reason for a buyer to be there, and every buyer that’s on Amazon is a reason for a seller to be there. Every Uber driver is a reason to become an Uber rider, and every Uber rider is a reason to become an Uber driver. Every friend on Facebook has a reason to join Facebook. When you join Facebook, you’re a reason for someone else to join Facebook. And network effects have driven explosive growth for all of these platforms.</p>
<p>But historically in tech, those network effects were countered by the low switching costs of interoperability. That anyone could make a product or a tool or a service that would make it easy to leave. You could make a tool that allowed Uber drivers and Uber riders to sense when both of them had a third party rideshare app installed that didn’t rip off the drivers, say one that was owned and maintained by a driver co-op. And after you set up the call with Uber, it would automatically cancel that Uber ride and rebuild it as a driver’s rideshare version. Or you could have a thing that when you left Facebook, you would go back and scrape Facebook for all the messages that your friends were sending you, put them in your inbox on a Mastodon server where you didn’t have to worry about being spied on by Mark Zuckerberg, and let you to reply to those and send them back to Facebook. All of that stuff is possible, and it means that you can leave these platforms without enduring high costs. All we have to do is clear the way, legally, for people to do this.</p>
<p>And so in the book I sketch out a shovel-ready, two-pronged approach to making it easy for people to leave the big tech platforms, to evacuate the big tech platforms. The first is to force the tech platforms to support interoperability. In Europe, the Digital Markets Act is going to do this. It’s going to force the biggest platforms to create these automatic gateways that new market entrants, cooperatives, nonprofits, startups, community groups, government agencies and even large tech companies can set up and connect to so that you can leave a platform but continue to talk to your friends or continue to enjoy the files that you bought, or whatever it is that the platform’s using to lock you in.</p>
<p>But that’s really easy to cheat on. The platform can slow walk it, they can break it selectively. They can shut it down and say later, “oh, we shut it down because we thought someone was hacking into it and stealing our users’ data.” And figuring out whether they’re telling the truth is really hard, because those things all do happen, right? There are hackers and people who steal users’ data, and we don’t want them to not shut down the gateway if they think some harm is coming to their users. But because everyone who understands how Facebook works is a Facebook employee, it’s going to take years to get to the bottom of those questions. And by that time, everyone who’d left for a new platform because they could continue to enjoy the stuff that they had in the old one, they’re going to have gone back because no one wants to wait years for that stuff to work.</p>
<p>So the second part of this is immunizing all of these new market entrants, these reverse engineers, these bot masters and scrapers, from liability, both criminal and civil, for allowing users to leave the platforms provided that they don’t violate privacy law, consumer protection law, or labor law.</p>
<p>And so we need to create these interoperator’s defenses that say that when the platform shuts down the official route, you can blast an unofficial route in there. Now, I think that that’s going to stay the platform’s hands in many cases. I think the platforms are very sensitive to how grueling and how potentially damaging it is to have to engage in guerrilla warfare with reverse engineers. It represents the kind of unquantifiable risk that leaves you doing your quarterly shareholder report and announcing that things are worse than you thought they would be, which is the kind of thing that causes Facebook to lose a quarter of a trillion dollars in one day, and for the stock portfolios of the managers who made those decisions to be absolutely devastated since they have mostly Facebook and their stock portfolios.</p>
<p>But if it doesn’t stay their hand, if they’re reckless, and of course no one ever lost money betting on the hubris of tech leaders, then we’ll have access to reverse engineering, to adversarial interoperability. And to put some concrete flesh on those bones there, in 2012, the people of Massachusetts went to the ballot box and they passed an automotive right to repair bill that said that the big three automakers were going to have to expose their error codes to independent mechanics so you could take your car to any mechanic and get your car fixed. And that passed with a 78% majority. People really wanted it, and it had huge participation. Normally ballot initiatives get low numbers. This was a big one. Nobody wants their auto manufacturer to decide who can fix their car.</p>
<p>So the law that was passed eventually as a result of this ballot initiative, it had a weird loophole, which is that it said that the automakers had to give error codes that traveled on the wired network within the car. And so the big three automakers immediately retooled to send all their error messages on a wireless network in the car so that it wasn’t subject to the law. Now in 2020, Bay Staters went back to the ballot box, and with a similar commanding majority passed a new ballot initiative that said basically, “For avoidance of doubt, we meant wireless too.”</p>
<p>Now in the intervening eight years, independent mechanics would have their customers come in, they put the car up on a lift and they would say, “You know what? It turns out that this is one I can’t fix.” And customers learned that they should just go to the dealer. And bankers learned that they shouldn’t loan money to mechanics. And mechanics learned that either they worked for the big three automakers or they should change jobs. Now, Boston and Massachusetts, home to some pretty good technical universities. Cambridge has got MIT where I’m a research affiliate. If it had been legal to reverse engineer car diagnostic systems, then a couple of smart kids from MIT could have just designed a dongle with a bill of goods of like, three bucks, had them manufactured by the container load in Guang Jo, fire them at the Port of Los Angeles, truck them across the United States and sold them in Boston and across the state from which they would’ve leaked into every other state in America.</p>
<p>They could have used them as a platform to offer all kinds of other services like warranties and parts, and things that are very high margin for the automakers, and maybe that would’ve stopped the automakers from engaging in all this skullduggery in the first place. But if it didn’t, then everyone in the Bay States and eventually everyone would’ve had access to a tool that allowed you to fix a car even if you weren’t blessed by the manufacturer. And so that’s the way that a mandate and the safety and freedom for people who want to go in on their own and do their own reverse engineering work hand in hand to produce something that’s quite durable. It’s like a two-part epoxy, right? The mandate is strong, but it’s brittle. And the reverse engineering, the adversarial interoperability, it fills all the cracks, but it’s gooey and it bends a lot. And so you put the two together and you get something that is strong and resilient.</p>
<p><strong>KH</strong>: Circling back to the problem of continuing to use platforms that are run by terrible people whose unethical policies and practices make us increasingly miserable, I wanted to take a moment to acknowledge what’s happening at Twitter, which Elon Musk has recently renamed after his favorite letter of the alphabet. A site that had become one of the most important hubs for news and information sharing among journalists and activists alike has been devastated by a fascistic billionaire, whose actions continue to erode the platform’s utility for individuals and communities who have grown to rely on it. Many of you probably never would have found my work if it weren’t for Twitter. And yet, as important as that site has been for my organizing, my journalism, and my popular education work, I desperately want out. And I know I’m not alone, but many of us who depend on the app to reach our audiences feel unable to leave.</p>
<p><strong>CD</strong>: I think Elon Musk is a demonstration of the problems of collective action on social media platforms, because people are still on Twitter even though they don’t like Twitter, and they’re on Twitter because they like their friends. Now, Twitter was actually developed to be API first, to be interoperable, and the original API for Twitter is designed to allow people to leave Twitter and continue to talk to Twitter from wherever they are. We could order Elon Musk as a settlement for one of the many infractions he’s made to his existing consent decrees under the Federal Trade Commission to simply open up those gateways that are already latent in Twitter, modernizing them as necessary, and then you could go to Mastodon or any other service and you could send messages to people on Twitter and they could send messages to you. And then every time Elon Musk did something that made his users angry, they could bolt for the exits.</p>
<p>Musk is kind of an unsubtle example of the problem with Tech Bros. But he’s just doing more bluntly what more cultured versions do in the shadows, in the same way that there’s not a lot of difference between Mitt Romney and Donald Trump, it’s just that Donald Trump speaks his mind, and Mitt Romney only says that 46% of the population are socially useless when he thinks he’s talking to fellow ghoulish plutocrats.</p>
<p><strong>KH</strong>: In addition to not wanting to part with friends who are not leaving the platform, I have also found the reach that my Twitter account affords difficult to part with, and I know this has been a major concern for a lot of journalists, educators, and activists, who have long relied on Twitter to get the word out about their work and projects. Personally, I have started a newsletter, and I have also dabbled with Mastodon and Bluesky in an effort to become less reliant on Twitter, because I believe our days on that website are numbered, or at least should be, but it is a struggle. Some people who have experimented with alternatives to Twitter have complained that moving from a walled garden like Twitter to a federated system like Mastodon, can be confusing – and I will admit to being one of those people. I did wind up setting up a Mastodon account after someone helped simplify the process for me, but initially, when I was approaching it on my own, I did find the complexity of the Fediverse intimidating. </p>
<p><strong>CD</strong>: I don’t think that Federation is intrinsically confusing. The idea that I might have an email server account at Gmail, and you might have one at Yahoo and that we can send each other email is just Federation. And it’s the same thing for social media on the Fediverse, which is, I have an account at one Mastodon server and you have an account on another Mastodon server, and we can exchange messages that way too. We can be part of a group or individuals and what have you. So it’s not that confusing, it’s just unfamiliar. And I think we should distinguish between confusing and unfamiliar.</p>
<p>Federation I think offers enormous benefits. You’re right that there are drawbacks in terms of reach. The reach that you can get from an algorithm and algorithmic suggestions can be very powerful for freelancers and for activists. But it’s also a devil’s bargain because that reach is not guaranteed to you, and it’s often the case that platforms will give you a little of it and then take it away, and then ask you for money to boost your content. And so that’s a kind of reach that I call the giant teddy bear approach where if you’ve ever been to a carnie in the morning, you’ll see some guy wandering around with a giant teddy bear he’s won by tossing five balls in a peach basket. And he didn’t actually get the five balls in. What’s happened is the carney has said, “Hey buddy, I like your face. Tell you what, you get one ball in, I’ll give you this little key chain. You do that twice. I’ll let you trade your two key chains for a giant teddy bear.”</p>
<p>And then that guy lugs around the giant teddy bear all day and makes people think that it’s possible to win one of their own. And the same is true when Spotify gives Joe Rogan a hundred million dollars or when TikTok uses what they call their heating tool to pick an individual influencer or person whom they want to make the platform attractive to and just send tens of millions of users their way. Rather than having those users see the content because the recommendation algorithm predicts that they like it, those users see the content because the thumb has been put on the scales by someone who works at TikTok. And the idea here is to convince some random sports bro, say, that he is the Louis Pasteur of TikTok, and that the best place in the world to be a sports bro and monetize your content is TikTok.</p>
<p>And then he runs around like a Judas goat and he tells everyone else, “Look at this giant teddy bear I got. It’s so easy. You should come be a sports bro on TikTok too.” So yeah, those algorithmic recommendation systems can do you good, but they’re a pretty limited utility and there are lots of failure modes for them. Meanwhile, there’s nothing that says that you couldn’t have an algorithmic recommendation system for Mastodon or other Fediverse or federated products, but it’ll be separate from the product itself. So it would be something that would go off and look at all the things that it could find either on your own server or on lots of servers, and then acting for you, it would make a choice or a guess about what it thinks you would like, and put that in front of you.</p>
<p>And some of that’s going to work well, and some of it’s going to work poorly. But what is also available to people in federated networks that don’t have recommendation systems is the old-fashioned kind of recommendation system, which is saying to the people who follow you, “please tell your friends about this.” And that is an organic, social, authentic way of making these things work. It eliminates influencer as a job and replaces it with people who other people trust. And when those other people are trustworthy and they tell you that you might like something, like I post book reviews to my Fediverse feed, and lots of people read those books and they forward those book reviews around, they retoot them in order to get them to other places. And that’s a really exciting and powerful way to reach people, and it makes for a much deeper connection. And it’s one that’s more durable and less intermediatable by the people who want to step between you and the people who follow you and take your money.</p>
<p>Bluesky technically looks pretty interesting, but it’s not federated. It is Federateable. And so this is like someone saying, “I have this service. It has all kinds of features that will stop me from abusing you, and I promise that I’ll turn them on later.” “Well, okay, but I prefer that you turn them on now. Or how about you tell me when you’ve turned them on and then I’ll come back and start using your service?” In the meantime, the board of directors of that one Bluesky service that exists, the one that is the only one you can join, the Federation of one, that board of directors includes the guy who sold Twitter to Elon Musk.</p>
<p>And so if the idea is Bluesky is preferable to Twitter because you are not subject to the foolish decisions of individuals who run the service because you can always go elsewhere. Bluesky is a service that is actually owned or managed or overseen by the same fool who made the worst decision in Twitter’s history, and there’s nowhere else you can go if you don’t like it.</p>
<p><strong>KH</strong>: One of the problems that many of us have encountered when trying to lure people toward alternatives to Facebook and Twitter, so that we can keep our digital communities intact, is that we simply cannot get around the problem of switching costs. Sure, the alternatives themselves often have problems, but in my experience, few of those problems are worse than what’s presently happening at Twitter, where Elon Musk’s fascistic, sycophantic fan base is being algorithmically amplified at the expense of content that most of us actually want to see and engage with. So when we name the various frustrations that are keeping us from fully engaging with other platforms, it’s not that those problems aren’t real, but I think the bigger issue is that those problems are not offset by the presence of the communities we have come to rely on, many of whom are still holding on at Twitter, even as the site’s deterioration makes us all miserable.</p>
<p><strong>CD</strong>: This was one of the problems with the Web3 people is that in addition to being kind of grounded in this speculative, hypercapitalist cryptocurrency nonsense, they also thought that the reason that people kept using Facebook or Twitter is because they didn’t know about better alternatives. Not that they understood that there were better alternatives, but as good as those were, they weren’t better than being around the people that they cared about. And they thought, “Okay, if we just show them something better, they will walk away from the people they love and go to the better thing and wait for the people they love to show up.” And no one’s going to do that. It’s a bridge too far. And no one ever did do it. The way that our technology grew historically was by people making interoperable layers so that the switching costs were as low as possible, not by having this kind of holus bolus exodus.</p>
<p>My grandmother’s story is kind of relevant here. So my grandmother was a Soviet refugee, a child soldier in the siege of Leningrad who was evacuated across the winter ice when she was two years in, when she was 15, and then got inducted into the Red Army and then got knocked up by my grandfather. And then after the war, they fled to Canada via a displaced person’s boat out of Frankfurt. And she was the only person in her family who left the Soviet Union, although all of them suffered under Soviet mismanagement and authoritarianism. And the reason for that is that in order to leave, she had to give up everything.</p>
<p>She didn’t know if her family were alive or dead for 15 years. She didn’t know. She didn’t have anything she’d grown up with, not a photo, not anything but the clothes on her back. She gave it all up, and that cost was too high for her family members to give up, and they stayed. And it was and remains a problem. My family in St. Petersburg are in a really bad place because they or their ancestors didn’t follow my grandmother to Canada, but they didn’t because the switching costs were too high. It wasn’t because the situation wasn’t bad, it was because the switching costs were too high.</p>
<p>If we want to make it easier, if we want people to go somewhere better, we have to make it easier for them to leave.</p>
<p><strong>KH</strong>: Given Cory’s expertise in computers, I couldn’t pass up the opportunity to get his take on a couple of the big topics we have discussed this season: AI and long-termism.</p>
<p><strong>CD</strong>: Well, I think AI is wildly over-hyped. I think if you add up all the things that AI is good for… And it’s good at some things, I just saw my friend Patrick Ball from the Human Rights Data Analysis Group talk about how they use large language models during the Truth and Reconciliation hearings in Colombia to assemble the largest dataset, human rights dataset ever, and to assign probabilities that individual accounts of murders were carried out by either right-wing militias, the FARC, or the government, or were unrelated to the Civil War and how this has been very important and holding responsible parties to account in Colombia’s Truth and Reconciliation.</p>
<p>That’s amazing, but the idea that we are going to have a multi-trillion dollar industry by automating some of the process of characterizing accounts of murder in a war zone, or that we are going to somehow make it all worthwhile by eliminating all the lowliest, most automated illustration jobs that are total wage bill is in the single digit millions of dollars, then you know that they’re just lying, right? On the one hand, it’s wildly immoral to want to destroy the livelihood of every commercial illustrator, but on the other hand, if you manage it, you won’t even accomplish the 10th of a percent of the savings that would justify the valuation that your company has gotten.</p>
<p>And for most everything else, it’s basically nonsense. All the decision support applications where it’s like, “Oh, we’re going to use it to find cancer, but we’re going to have a human in the loop, a radiographer who reviews the x-rays and makes a call about the judgment that the machine has made.” Well, if that person is actually going to investigate the machine judgment in depth and make a real call about it, then it’s going to be just as slow as not using the machine. And so nobody is going to buy a machine to use it that way. The only point of having such a machine is to allow decisions to be made faster than any human could review them. And that’s really the intent. And so the only way that this can possibly be worth the valuation that’s been assigned to it is if it’s used in incredibly harmful ways.</p>
<p>As to long-termism and TESCREAL and so on. Look, I’m a cyberpunk writer. It was meant as a warning, not a suggestion. The fact that these people can’t tell the difference means that they’re both very stupid and very frightening.</p>
<p><strong>KH</strong>: Well, I am so grateful for this conversation and for Cory’s book, which I think is a tremendous resource for people who want to reclaim the internet’s potential and leverage our connectivity to do great things. If you’re like me, you won’t agree with everything in <em>The Internet Con</em>, but I think we should welcome that, and that we should be open to engaging with our disagreements constructively, to see what we might learn. I definitely learned a lot from this book and I think every activist and organizer should give it a read. Given that I think everyone who listens to this show wants to make the world a better place, I also appreciated Cory’s parting message for our listeners.</p>
<p><strong>CD</strong>: So I would urge us all to be Luddites in the best sense of the word. So you know that Luddite is a term that is used as a synonym for a technophobe, but the Luddites weren’t technophobes. To be a textile worker in the dawn of the industrial revolution, you needed to complete a seven-year apprenticeship using the most technically advanced machines of the day. A textile worker was like someone with a master’s degree in engineering from MIT. And what they were angry about was not the machines. They were angry about the social arrangements of the machines. It wasn’t what the machines did, it was who they did it for and who it did it to. They were angry because their bosses had these machines that they said were so easy children could use them, and they were kidnapping children from the Napoleonic War orphanages in London and forcing them to work in the mills, in periods of 10 years of indenture during which they would be beaten and starved, maimed and often killed.</p>
<p>Robert Blincoe survived the mills, wrote a memoir that became a bestseller and inspired Charles Dickens to write <em>Oliver Twist</em>, which is really best understood as Luddite fanfic. The Luddites wanted the machinery to be accountable to the workforce and the people they served, and not to the forces of capital. Computers are incredibly powerful tools for activists. I cut my teeth riding a bicycle all night around the streets of Toronto, wheat-pasting posters to telephone poles to get people to turn out for demonstrations. And if you’ve never tried to organize a movement without the internet, I’m here to tell you, it’s really hard. We need to seize the means of computation, because while the internet isn’t the most important thing that we have to worry about right now, all the things that are more important, gender and racial justice, inequality, the climate emergency, those are struggles that we’re going to win or lose by organizing on the internet.</p>
<p>And the internet has these foundational characteristics, the interoperability, the universality, working encryption that lets us keep secrets, that allow us to organize mass movements in ways that our forebears could only have dreamt of. And it’s up to us to take control of that technology and make it work for us.</p>
<p><strong>KH</strong>: I appreciate Cory’s argument that while there are struggles of greater moral importance than what happens to the internet, we cannot win those struggles without taking on Big Tech. I wholeheartedly agree with that sentiment, which is why we will keep circling back to tech issues on this season of the show. I hope these discussions leave us all better informed and better prepared to seize the means of computation, and to wage our struggles for liberation. I want to thank Cory Doctorow for joining us today. I learned a lot from talking to Cory and from reading his book, and I am looking forward to checking out some of his sci-fi titles as well. </p>
<p>I also want to thank our listeners for joining us today, and remember, our best defense against cynicism is to do good and to remember that the good we do matters. Until next time, I’ll see you in the streets.</p>
<p><strong><em>Show Notes</em></strong></p>
<ul>
<li>Be sure to check out Cory’s book <a href="https://www.versobooks.com/products/3035-the-internet-con"><em>The Internet Con: How to Seize the Means of Computation</em></a>.</li>
<li>You can also check out Cory’s blog <a href="https://pluralistic.net/"><em>Pluralistic</em></a> and follow him on <a href="https://twitter.com/doctorow">Twitter</a> (aka X), <a href="https://mamot.fr/@pluralistic">Mastodon</a> and <a href="https://mostlysignssomeportents.tumblr.com/">Tumblr</a>. </li>
<li>To hear more from Kelly, you can sign up for her newsletter <a href="https://mskellymhayes.substack.com/">Organizing My Thoughts</a> or check out her book with Mariame Kaba, <a href="https://www.haymarketbooks.org/books/1922-let-this-radicalize-you"><em>Let This Radicalize You</em></a>.</li>
</ul>
<div id="truth-441503335" data-callout-id="311402" data-callout-theme="white" data-callout-placement="Post Content - After" data-callout-title="2023-10 (FRU) October Mini - Thank you for reading. Spare just a few seconds?" data-truth-trackid="311402" data-truth-trackbid="1">
<h5>Thank you for reading. Spare just a few seconds?</h5>
<p><span>Whether you’re a first-time visitor or a long-time reader, we appreciate you taking the time to read <em>Truthout</em>. <strong>If you found value in what you read today, we need your help.</strong></span></p>
<p><span><em>Truthout</em> is going through a challenging time as nonprofit donations have declined across the board in 2023. News media organizations across the country are closing or laying off staff almost every week. <strong>But we’re absolutely determined to make it through this painful moment – because without <em>Truthout</em>, who else would publish the piece you read today?</strong></span></p>
<p><span>Please consider making a tax-deductible gift to <em>Truthout</em>. If you want to take your support further, a monthly gift is one of the best ways to strengthen our work. Thank you in advance for anything you can do.</span></p>

</div>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The pivot table, the spreadsheet's most powerful tool (2020) (295 pts)]]></title>
            <link>https://qz.com/1903322/why-pivot-tables-are-the-spreadsheets-most-powerful-tool</link>
            <guid>37820877</guid>
            <pubDate>Mon, 09 Oct 2023 14:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qz.com/1903322/why-pivot-tables-are-the-spreadsheets-most-powerful-tool">https://qz.com/1903322/why-pivot-tables-are-the-spreadsheets-most-powerful-tool</a>, See on <a href="https://news.ycombinator.com/item?id=37820877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Pivot tables are the quickest and most powerful way for the average person to analyze large datasets. No coding skills or mathematical brilliance are necessary—just the ability to point and click your mouse.</p><p>But don’t take our word for it. Pivot tables had a superfan in none other than Apple founder Steve Jobs, who immediately saw their genius.</p><figure data-id="05c084e86eecf6b6ba94630ac78d70ec" data-recommend-id="image://05c084e86eecf6b6ba94630ac78d70ec" data-format="jpg" data-width="1240" data-height="100" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="other-license" data-notes="" data-hide="false" data-hidecredit="false"><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg"><img alt="Image for article titled The history of the pivot table, the spreadsheet’s most powerful tool" data-chomp-id="05c084e86eecf6b6ba94630ac78d70ec" data-format="jpg" data-alt="Image for article titled The history of the pivot table, the spreadsheet’s most powerful tool" data-anim-src="" data-src="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg" src="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg"></picture></div><span data-id="05c084e86eecf6b6ba94630ac78d70ec" data-recommend-id="image://05c084e86eecf6b6ba94630ac78d70ec" data-format="jpg" data-width="1240" data-height="100" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>In 1985, Jobs was forced out of his role as chairman of the board at Apple after failing to beat IBM in the business computer market. Fortunately, he was a stubborn man. Jobs immediately started the company NeXT, with the idea of taking on IBM once again.</p><p>As he developed the NeXT computer, which would launch in 1988, Jobs was looking for killer software programs to create demand for the product. From his experience at Apple, he knew that a good spreadsheet program could drive sales. Jobs credited VisiCalc, the first widely used spreadsheet software, for the <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://qz.com/1103867/visicalc-and-apple-aapl-steve-jobs-said-that-the-spreadsheet-was-key-to-apples-early-success/?utm_source=email&amp;utm_medium=quartz-obsession&amp;utm_content=&quot;,{&quot;metric25&quot;:1}]]" href="https://qz.com/1103867/visicalc-and-apple-aapl-steve-jobs-said-that-the-spreadsheet-was-key-to-apples-early-success/?utm_source=email&amp;utm_medium=quartz-obsession&amp;utm_content=" target="_blank" rel="noopener noreferrer">huge success of the Apple II computer</a></span>, released in 1979.</p><p>In his search for that need-to-have product, Jobs met with software company Lotus. The organization had already developed Lotus 1-2-3, a popular spreadsheet program that ran on IBM computers. It was in these meetings that Jobs would first stumble upon the “pivot table.”</p><p>Software developer Pito Salas was at the time working in research and development for Lotus, looking into how people typically utilize spreadsheets. Salas saw that users would often use spreadsheets to try to calculate summary statistics by categories (often referred to as <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.displayr.com/what-is-a-crosstab/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.displayr.com/what-is-a-crosstab/" target="_blank" rel="noopener noreferrer">crosstabs</a></span>). For example, a company selling bicycles might want to examine their data to find unit sales by month or revenue by country. The way people did that at the time was cumbersome and error-prone because it involved writing complicated formulas.</p><p>Salas decided the world needed software that would make those calculations simple. Rather than enter formulas, users would be able to point and click to get those summary statistics. The Lotus team called this tool “flexible views,” but today similar tools are called “pivot tables” in both Microsoft Excel and Google Sheets.</p><p>The Lotus team showed Jobs an early prototype. “Steve Jobs thought it was the coolest thing ever,” Salas, now a professor at Brandeis University, tells Quartz. Jobs then convinced Lotus to develop the pivot table software exclusively for the NeXT computer. The software came out as <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.rittmanmead.com/blog/2005/10/looking-back-at-lotus-improv/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.rittmanmead.com/blog/2005/10/looking-back-at-lotus-improv/" target="_blank" rel="noopener noreferrer">Lotus Improv</a></span>, and though the NeXT computer was a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://appleinsider.com/articles/18/09/12/looking-back-at-steve-jobss-next-inc----the-most-successful-failure-ever&quot;,{&quot;metric25&quot;:1}]]" href="https://appleinsider.com/articles/18/09/12/looking-back-at-steve-jobss-next-inc----the-most-successful-failure-ever" target="_blank" rel="noopener noreferrer">commercial failure</a></span>, Lotus Improv would be hugely influential. The “flexible views” aspect of Improv would be built into both Lotus 1-2-3 and Excel (the latter was the first to actually use the term “pivot table”).</p><p>Bill Jelen, <span><a data-ga="[]" href="https://www.amazon.com/Pivot-Table-Data-Crunching-Jelen/dp/0789734354?asc_campaign=kinjaquartzlink-20&amp;asc_refurl=https://qz.com/1903322/why-pivot-tables-are-the-spreadsheets-most-powerful-tool&amp;asc_source=&amp;tag=kinjaquartzlink-20" target="_blank" rel="sponsored noopener noreferrer nofollow noskim" data-amazonasin="0789734354" data-amazontag="kinjaquartzlink-20">Excel evangelist</a></span> and co-author of <span><a data-ga="[]" href="https://www.amazon.com/Pivot-Table-Data-Crunching-Jelen/dp/0789734354?asc_campaign=kinjaquartzlink-20&amp;asc_refurl=https://qz.com/1903322/why-pivot-tables-are-the-spreadsheets-most-powerful-tool&amp;asc_source=&amp;tag=kinjaquartzlink-20" target="_blank" rel="sponsored noopener noreferrer nofollow noskim" data-amazonasin="0789734354" data-amazontag="kinjaquartzlink-20"><em>Pivot Table Data Crunching</em></a></span>, credits Salas as the “father of pivot tables.” Salas says his contribution to pivot tables is one of his life’s most gratifying accomplishments, though he believes he was just building on the foundations of many others.</p><p>Today, pivot tables are among the most important and commonly used tools in the spreadsheet wizard’s toolbox. “A pivot table lets you create a one-page summary report from hundreds of thousands of rows of data, often in four, five, or six clicks,” says Jelen. “It is the fastest way to get answers from large datasets.”</p><p> It’s hard to know exactly how many people use Excel in their day-to-day work, but there are <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.computerworld.com/article/3315737/use-microsoft-excel-to-learn-about-data-analytics.html&quot;,{&quot;metric25&quot;:1}]]" href="https://www.computerworld.com/article/3315737/use-microsoft-excel-to-learn-about-data-analytics.html" target="_blank" rel="noopener noreferrer">hundreds of millions of Excel users worldwide</a></span> and it stands to reason that many have picked up the software’s most powerful tool. Pivot tables are generally listed at, or near, the top of <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://analystcave.com/excel-10-top-excel-features/&quot;,{&quot;metric25&quot;:1}]]" href="https://analystcave.com/excel-10-top-excel-features/" target="_blank" rel="noopener noreferrer">lists</a></span> of the <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.pcworld.com/article/2109084/real-excel-power-users-know-these-11-tricks.html&quot;,{&quot;metric25&quot;:1}]]" href="https://www.pcworld.com/article/2109084/real-excel-power-users-know-these-11-tricks.html" target="_blank" rel="noopener noreferrer">most</a></span> <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://excelwithbusiness.com/blog/top-10-excel-features/&quot;,{&quot;metric25&quot;:1}]]" href="https://excelwithbusiness.com/blog/top-10-excel-features/" target="_blank" rel="noopener noreferrer">useful</a></span> features in Excel.&nbsp;Data analysts use pivot tables to understand <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://sphweb.bumc.bu.edu/otlt/MPH-Modules/Excel/Excel_print.html&quot;,{&quot;metric25&quot;:1}]]" href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/Excel/Excel_print.html" target="_blank" rel="noopener noreferrer">public health</a></span>, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.oxfordeconomics.com/techlabs/dashboards-for-excel-data-workstation-aka-mondrian&quot;,{&quot;metric25&quot;:1}]]" href="https://www.oxfordeconomics.com/techlabs/dashboards-for-excel-data-workstation-aka-mondrian" target="_blank" rel="noopener noreferrer">economic growth</a></span> and <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://neilpatel.com/blog/pivot-table-for-marketing-data/&quot;,{&quot;metric25&quot;:1}]]" href="https://neilpatel.com/blog/pivot-table-for-marketing-data/" target="_blank" rel="noopener noreferrer">advertising effectiveness</a></span>, among many other uses.&nbsp; &nbsp;</p><p>“That’s my life,” says Justine Shakespeare, a senior program manager at nonprofit labor rights organization Verité. “All I do is make pivot tables.” In her case, the pivot tables are to analyze survey data from interviews with migrant workers in global supply chains<strong>.&nbsp;</strong></p><figure data-id="05c084e86eecf6b6ba94630ac78d70ec" data-recommend-id="image://05c084e86eecf6b6ba94630ac78d70ec" data-format="jpg" data-width="1240" data-height="100" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="other-license" data-notes="" data-hide="false" data-hidecredit="false"><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg"><img alt="Image for article titled The history of the pivot table, the spreadsheet’s most powerful tool" data-chomp-id="05c084e86eecf6b6ba94630ac78d70ec" data-format="jpg" data-alt="Image for article titled The history of the pivot table, the spreadsheet’s most powerful tool" data-anim-src="" data-src="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg" src="https://i.kinja-img.com/image/upload/c_fit,f_auto,g_center,q_60,w_645/05c084e86eecf6b6ba94630ac78d70ec.jpg"></picture></div><span data-id="05c084e86eecf6b6ba94630ac78d70ec" data-recommend-id="image://05c084e86eecf6b6ba94630ac78d70ec" data-format="jpg" data-width="1240" data-height="100" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>Here’s an example of the pivot table in action. Recently, a reporter at Quartz got access to data on remittances sent from the US to Mexico by month going back to 1995. But what the reporter really needed was a summary of the total remittances in the first six months of each year. Pivot tables were the way to go. Getting the numbers she needed involved inserting a pivot table, making a few selections to choose the data she needed, and filtering out the months she wanted to exclude. The video below shows those steps:</p><p><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.loom.com/share/7b94e256e3a7424eb0b023c9dc0f7555&quot;,{&quot;metric25&quot;:1}]]" href="https://www.loom.com/share/7b94e256e3a7424eb0b023c9dc0f7555" target="_blank" rel="noopener noreferrer">See on Loom</a></span></p><p>If you want to learn more about how to use pivot tables, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.youtube.com/watch?v=qu-AK0Hv0b4&quot;,{&quot;metric25&quot;:1}]]" href="https://www.youtube.com/watch?v=qu-AK0Hv0b4" target="_blank" rel="noopener noreferrer">try this video</a></span> from “Excel ninja” Cody Baldwin. For those who prefer Google Sheets, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.benlcollins.com/spreadsheets/pivot-tables-google-sheets/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.benlcollins.com/spreadsheets/pivot-tables-google-sheets/" target="_blank" rel="noopener noreferrer">try this introduction</a></span> from Sheets expert Ben Collins.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chapel 1.32 (117 pts)]]></title>
            <link>https://chapel-lang.org/blog/posts/announcing-chapel-1.32/</link>
            <guid>37820617</guid>
            <pubDate>Mon, 09 Oct 2023 14:09:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chapel-lang.org/blog/posts/announcing-chapel-1.32/">https://chapel-lang.org/blog/posts/announcing-chapel-1.32/</a>, See on <a href="https://news.ycombinator.com/item?id=37820617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <div>
            <p><em>Table of Contents</em></p><nav id="TableOfContents">
  <ul>
    <li><a href="#highlights-of-chapel-132">Highlights of Chapel 1.32</a>
      <ul>
        <li><a href="#chapel-20-release-candidate">Chapel 2.0 Release Candidate</a></li>
        <li><a href="#gpu-improvements">GPU Improvements</a></li>
        <li><a href="#support-for-co-locales">Support for Co-Locales</a></li>
        <li><a href="#io-serialization-framework">IO Serialization Framework</a></li>
        <li><a href="#improved-arm64-support">Improved ARM64 Support</a></li>
        <li><a href="#and-much-more">And much more…</a></li>
      </ul>
    </li>
    <li><a href="#for-more-information">For More Information</a></li>
  </ul>
</nav>
        </div>
    

    

    <p>The Chapel developer community is excited to announce the release of
Chapel version 1.32!  To obtain a copy, please refer to the
<a href="https://chapel-lang.org/download.html">Downloading Chapel</a> page on
the Chapel website.</p>
<h3 id="highlights-of-chapel-132">Highlights of Chapel 1.32</h3>
<h4 id="chapel-20-release-candidate">Chapel 2.0 Release Candidate</h4>
<p>The main highlight of Chapel 1.32 is that it is a release candidate
for our forthcoming Chapel 2.0 release!  If you’re not familiar with
the concept of Chapel 2.0, it is intended to be a release that
declares a core subset of the language and library features as
‘stable’.  These features are ones that we intend to support in
their current form going forward, such that code relying on them
will not break across releases.  Meanwhile, other features will be
considered ‘unstable’, implying that they are ones where we are
still learning from user experiences and refining interfaces before
considering them to be stabilized.  Unstable features may continue
evolving after the 2.0 release, either by improving them until they
too are stable, or replacing them with other, more stable features.</p>
<p>Chapel 1.32 being a 2.0 release candidate means that this is a key
time for Chapel users to give us feedback about aspects of our
design that they would like to see change prior to the 2.0 release.
Users may also want to compile their programs with the
<code>--warn-unstable</code> flag in order to identify any unstable features
that they are currently relying upon.  Reliance on such features
could motivate you to advocate for stabilizing those features sooner,
or you could simply view it as an opportunity to be aware that those
features may continue to evolve over time.  We are generally
interested in hearing about which unstable features user code is
currently relying upon, to help with our own prioritization efforts.</p>
<p>Users with feedback about 2.0 readiness or the stability of current
features are encouraged to share it with us on <a href="https://chapel.discourse.group/c/users/">Chapel’s Discourse
user forum</a> or as a <a href="https://github.com/chapel-lang/chapel/issues">GitHub
issue</a>.</p>
<p>As part of the team’s push to make this a worthy Chapel 2.0 release
candidate, Chapel 1.32 contains a large number of improvements to
the language, compiler, and libraries.  Some of these changes
include:</p>
<ul>
<li>
<p>new warnings to encourage a programming style in which generic
types are more clearly visible in a program’s source code</p>
</li>
<li>
<p>a change in the default intent for arrays and record receivers
(i.e., <code>this</code>) to <code>const</code> for greater uniformity with other types</p>
</li>
<li>
<p>revised definitions of the compiler’s interpretation of <code>const</code>
intents and default return/yield intents</p>
</li>
<li>
<p>significant improvements to ranges, domains, and distributions,
including converting distribution types to records, obviating the
need for the <code>dmap</code> type</p>
</li>
<li>
<p>major improvements to the <code>IO</code>, <code>Math</code>, <code>BigInteger</code>, and <code>Time</code>
modules, including a new IO serialization framework for specifying
how to read and write types to files orthogonally from the file’s
format (see <a href="#io-serialization-framework">below</a> for more detail)</p>
</li>
</ul>
<p>For more information about these changes, and many others not
summarized here, refer to the
<a href="https://github.com/chapel-lang/chapel/blob/release/1.32/CHANGES.md">CHANGES.md</a>
file, <a href="https://chapel-lang.org/docs/1.32/">documentation</a> for Chapel
1.32, or forthcoming <a href="https://chapel-lang.org/releaseNotes.html">release note
slides</a>.</p>
<h4 id="gpu-improvements">GPU Improvements</h4>
<p>Version 1.32 includes significant improvements to Chapel’s support
for vendor-neutral GPU programming, both in terms of performance and
capabilities.</p>
<p>Key performance improvements include:</p>
<ul>
<li>
<p>compiler optimizations to reduce the number of pointer
dereferences when accessing arrays within GPU kernels</p>
</li>
<li>
<p>switching the default memory allocation scheme for arrays to
‘array_on_device’ mode, in which an array’s data is stored
directly on the GPU rather than in managed memory</p>
</li>
<li>
<p>a reduction in overheads when invoking math routines within GPU
kernels by eliminating unnecessary boilerplate wrapper code</p>
</li>
<li>
<p>using per-task GPU streams, which can enable
communication-computation overlap to improve performance</p>
</li>
</ul>
<p>The non-trivial impact of these optimizations can be seen in the
following graphs, which show the improvements that have occurred in
a Chapel port of the SHOC Sort benchmark on both NVIDIA and AMD
GPUs.  Note that the second graph includes data transfer times while
the first does not.</p>
<figure><img src="https://chapel-lang.org/blog/posts/announcing-chapel-1.32/SHOC-sort-combined.png">
</figure>

<p>Chapel’s support for AMD effectively reaches feature parity with
NVIDIA in this release, largely due to the addition of a number of
math routines that had not been supported for AMD in
Chapel&nbsp;1.31.  In addition, the Chapel compiler’s <code>--savec</code> flag
can now be used to inspect the assembly code generated when
targeting AMD GPUs.</p>
<p>Meanwhile, when targeting NVIDIA GPUs, Chapel 1.32 adds support for
generating multi-architecture binaries by setting <code>CHPL_GPU_ARCH</code> to
a comma-separated list of target architectures.</p>
<p>See the latest <a href="https://chapel-lang.org/docs/1.32/technotes/gpu.html">GPU
Programming</a>
technical note for additional details about these changes and
Chapel’s overall support for GPUs in 1.32.</p>
<h4 id="support-for-co-locales">Support for Co-Locales</h4>
<p>Since its inception, Chapel has preferred to represent each compute
node as a single top-level locale, using multitasking to implement
any intra-node parallelism.  This approach has been beneficial in
many problem domains where running a process per core could result
in larger memory requirements or poor surface-to-volume effects due
to the amount of <span>
<label for="SPMD definition">SPMD</label>

<span>
<span>[note:</span>
SPMD = Single Program, Multiple Data, a static and coarse-grained
style of parallelism in which multiple copies of the same program
are executed, e.g. one per processor core 
<span>]</span>
</span>
</span>

parallelism.</p>
<p>However, as modern compute nodes have begun to support multiple <span>
<label for="NIC definition">NICs,</label>

<span>
<span>[note:</span>
NICs = Network Interface
Chips, which permit processes to communicate with remote nodes 
<span>]</span>
</span>
</span>
 this traditional approach has faced challenges.
Specifically, it is unduly complicated to have a single locale (UNIX
process) leverage multiple NICs effectively; yet using just one NIC
leaves potential performance benefits on the floor by not exercising
the network to its full capacity.</p>
<p>To address this, Chapel 1.32 introduces user-facing support for
<em>co-locales</em>, in which multiple locales can be mapped to a single
compute node.  Using co-locales can lead to performance improvements
by making better use of the network and/or reducing the number of
memory references that cross between sockets.  For example, the
following charts show improvements to a pair of benchmarks when run
using two locales per node on a dual-NIC HPE Cray EX system using
Slingshot 11:</p>
<figure><img src="https://chapel-lang.org/blog/posts/announcing-chapel-1.32/co-locales-perf.png">
</figure>

<p>Current support is limited to running a locale per socket on a given
compute node, and is also limited to certain platforms and
configurations:</p>
<ul>
<li>
<p>HPE Cray EX platforms with Slingshot 11 when using <code>CHPL_COMM=ofi</code></p>
</li>
<li>
<p>InfiniBand-based systems when using <code>CHPL_COMM=gasnet</code> with
<code>CHPL_COMM_SUBSTRATE=ibv</code></p>
</li>
<li>
<p>Configurations using <code>CHPL_LAUNCHER=slurm-srun</code> or <code>pbs-gasnetrun_ibv</code></p>
</li>
</ul>
<p>To opt-in to using co-locales, specify the number of locales for your
Chapel program using a product of nodes and locales per node.  For
example, the following invocation:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./myChapelProgram -nl 8x2
</span></span></code></pre></div><p>says to run the Chapel program on 8 nodes with 2 locales per node,
for a total of 16 locales.</p>
<p>For more information on using co-locales with Chapel, please refer
to <a href="https://chapel-lang.org/docs/1.32/usingchapel/multilocale.html#co-locales">the online
documentation</a>.</p>
<h4 id="io-serialization-framework">IO Serialization Framework</h4>
<p>The IO serialization framework <a href="https://chapel-lang.org/blog/posts/announcing-chapel-1.31/#prototypical-support-for-io-serializers">that was prototyped in Chapel
1.31</a>
is now used by default for calls like <code>writeln()</code> and <code>read()</code>, and
it is also available for use with types written by end-users.</p>
<p>As an illustration, consider the following example that prints an
array in a couple of different formats:</p>
<div data-code-type="main" data-code-section="only">
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="Chapel"><span><span><span>use</span><span> </span><span>IO</span><span>,</span><span> </span><span>JSON</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>var</span><span> </span><span>A</span><span> </span><span>=</span><span> </span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>];</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>writeln</span><span>(</span><span>A</span><span>);</span><span>             </span><span>// prints '1 2 3 4'  
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>var</span><span> </span><span>jsonWriter</span><span> </span><span>=</span><span> </span><span>stdout</span><span>.</span><span>withSerializer</span><span>(</span><span>jsonSerializer</span><span>);</span><span>  
</span></span></span><span><span><span></span><span>jsonWriter</span><span>.</span><span>writeln</span><span>(</span><span>A</span><span>);</span><span>  </span><span>// prints '[1, 2, 3, 4]'  
</span></span></span></code></pre></td></tr></tbody></table>
</div>
<p>Line 5
 uses a normal
<code>writeln()</code> to print the array of integers to the standard console
output&nbsp;(<code>stdout</code>) using Chapel’s traditional format—one element
at a time, separated by spaces.  Then, in line 7, we create a
variant of <code>stdout</code> that uses the <a href="https://chapel-lang.org/docs/1.32/modules/standard/JSON.html">JSON
serializer</a>
for all <code>write()</code>s called on it.  The result is that when we write
the array to this output stream in line 8, it is printed using
standard JSON formatting.  Other current serializers support
<a href="https://chapel-lang.org/docs/1.32/modules/standard/IO.html#IO.binarySerializer">binary</a>,
<a href="https://chapel-lang.org/docs/1.32/modules/packages/YAML.html">YAML</a>,
and <a href="https://chapel-lang.org/docs/1.32/modules/packages/ChplFormat.html">Chapel
syntax</a>
as alternate formats.</p>
<p>The new serialization framework also includes deserializers, which
support reading values back in from the given format.  And most
importantly, users can now define their own methods specifying how
their types should be written or read.  This can be done in a
format-neutral manner for simplicity, or in a way that’s sensitive
to the output format when needed.  For more information on defining
these methods, please refer to <a href="https://chapel-lang.org/docs/1.32/modules/standard/ChapelIO.html#the-serialize-and-deserialize-methods">their online
documentation</a>.</p>
<h4 id="improved-arm64-support">Improved ARM64 Support</h4>
<p>Thanks to our colleagues on the
<a href="https://www.sandia.gov/qthreads/">Qthreads</a> team at Sandia National
Laboratories, support for ARM64 chips is significantly improved in
Chapel 1.32.  Specifically, this release bundles version 1.19 of
Qthreads, in which task creation and switching have been
re-implemented using assembly code for ARM64 chips.  This can
dramatically reduce multitasking overheads when using Chapel’s
preferred <code>CHPL_TASKS=qthreads</code> mode.</p>
<p>As a simple illustration, the following table shows the impact of
this fast task switching on a 16-node run of
<a href="https://github.com/jdevinney/bale">Bale</a> Index Gather using various
implementation strategies:</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>w/out fast tasks</th>
<th>with fast tasks</th>
<th>improvement</th>
</tr>
</thead>
<tbody>
<tr>
<td>ordered</td>
<td>70.7 MB/s/node</td>
<td>84.7 MB/s/node</td>
<td>1.20x</td>
</tr>
<tr>
<td>ordered, oversubscribed</td>
<td>86.3 MB/s/node</td>
<td>140.4 MB/s/node</td>
<td>1.63x</td>
</tr>
<tr>
<td>unordered</td>
<td>147.5 MB/s/node</td>
<td>152.3 MB/s/node</td>
<td>1.03x</td>
</tr>
<tr>
<td>aggregated</td>
<td>1352.0 MB/s/node</td>
<td>1448.5 MB/s/node</td>
<td>1.07x</td>
</tr>
</tbody>
</table>
<p>In addition, Qthreads 1.19 also improved portability for ARM64-based
platforms.  This enables the use of <code>CHPL_TASKS=qthreads</code> on a wider
variety of systems, such as M1/M2 Macs, where it is now the default.</p>
<h4 id="and-much-more">And much more…</h4>
<p>Beyond the highlights mentioned here, Chapel 1.32 contains numerous
other improvements to Chapel’s features and interfaces, such as:</p>
<ul>
<li>
<p>initial support for array allocations that will throw if the
system is out of memory</p>
</li>
<li>
<p>a more robust set of types and routines for dealing with C pointer
types, particularly with respect to <code>const</code>-ness</p>
</li>
<li>
<p>initial support for interface declarations, to opt-in to special
methods like the serialization methods mentioned above</p>
</li>
<li>
<p>features for power users to better understand the vectorization
and transformation of their Chapel programs</p>
</li>
<li>
<p>support for selecting between processor types on chips with
heterogeneous processing units</p>
</li>
</ul>
<p>For a more complete list of changes in Chapel 1.32, please refer
to its
<a href="https://github.com/chapel-lang/chapel/blob/release/1.32/CHANGES.md">CHANGES.md</a>
file.</p>
<h3 id="for-more-information">For More Information</h3>
<p>For questions about any of the changes in this release, please reach
out to the developer community on <a href="https://chapel.discourse.group/">Discourse</a>.</p>
<p>As always, we’re interested in feedback on how we can help make the
Chapel language, libraries, implementation, and tools more useful to
you in your work.</p>
<p>And always, thanks to <a href="https://github.com/chapel-lang/chapel/blob/release/1.32/CONTRIBUTORS.md">everyone who
contributed</a>
to the Chapel 1.32 release!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Text Showdown: Gap Buffers vs. Ropes (228 pts)]]></title>
            <link>https://coredumped.dev/2023/08/09/text-showdown-gap-buffers-vs-ropes/</link>
            <guid>37820532</guid>
            <pubDate>Mon, 09 Oct 2023 14:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://coredumped.dev/2023/08/09/text-showdown-gap-buffers-vs-ropes/">https://coredumped.dev/2023/08/09/text-showdown-gap-buffers-vs-ropes/</a>, See on <a href="https://news.ycombinator.com/item?id=37820532">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>I have been working on a hobby project to reimagine the C core of <a href="https://coredumped.dev/tags/rust/">Emacs in Rust</a>. On this journey, I reached the point where I needed some way to represent the text of a buffer. The simplest approach is to just use a large string or array of lines. However these each suffer from poor performance as either the size or line length of text increases.</p>
<p>GNU Emacs has famously used a gap buffer to represent editable text. It’s even mentioned by name on the <a href="https://en.wikipedia.org/wiki/Gap_buffer">wikipedia</a> entry for it. Gap buffers have the advantage of allowing fast local edits with a fairly simple design. Essentially you hold the text in a giant array with a gap of unused bytes in the middle. When you insert text, you replace some of the bytes with text, making the gap smaller. When you want to insert somewhere else in the text, you move the gap to that location and do the same operation. Delete performs the opposite operation, expanding the gap. With this simple mechanism, you can efficiently represent editable text.</p>
<p>I see it as analogous to the more general data structure, the “array”. A gap buffer is just an array that is optimized for inserting at a “cursor” instead of at the end. Using a gap buffer has served Emacs well over many decades.</p>
<p>Despite this, Emacs seems largely alone in its choice in the modern world. Most popular editors today use some variation of either a <a href="https://code.visualstudio.com/blogs/2018/03/23/text-buffer-reimplementation">piece table</a> or a <a href="https://blog.jetbrains.com/fleet/2022/02/fleet-below-deck-part-ii-breaking-down-the-editor/">rope</a>. Rather than storing data as a large contiguous array, these data structures chop the buffer into small chunks and operate on those. This enables them to avoid the O(n) penalty of moving the cursor when doing edits far away and the latency of resizing the buffer.</p>
<p>Rust has <a href="https://crates.io/search?q=ropey">many rope crates</a> that have had a lot of optimization work put in. The obvious thing to do was to just pick one and move on. But I wanted to see for myself how the gap buffer holds up to these more “advanced” data structures. Modern computers can operate very quickly over linear memory. So I built a gap buffer and stacked it up against the competition.</p>
<h2 id="design">
    <a href="#design">
      Design
    </a>
</h2>
<p>My gap buffer (<a href="https://github.com/CeleritasCelery/rune/tree/master/crates/text-buffer">link</a>) is fairly true to the original design, with one big change; I store <a href="https://github.com/CeleritasCelery/rune/blob/master/crates/text-buffer/src/metric.rs">metrics</a> about the buffer in a separate tree. These metrics include things like char and line position, but could, in theory, include anything you want (like UTF-16 <a href="https://docs.rs/ropey/latest/ropey/struct.Rope.html#method.char_to_utf16_cu">code units</a>). This means that <em>finding</em> an arbitrary position in the buffer becomes at worse O(logn), but we still have to pay the cost of moving the gap.</p>
<p>The ropes that I will be comparing against are <a href="https://docs.rs/ropey/latest/ropey/index.html">Ropey</a>, <a href="https://docs.rs/crop/0.3.0/crop/index.html">Crop</a>, and <a href="https://docs.rs/jumprope/latest/jumprope/index.html">Jumprope</a>. The last one is technically implemented via <a href="https://en.wikipedia.org/wiki/Skip_list">skip lists</a>, but that’s an implementation detail and the performance should be similar.</p>
<h2 id="gap-buffer-costs">
    <a href="#gap-buffer-costs">
      Gap buffer costs
    </a>
</h2>
<p>Before we jump into <a href="https://github.com/CeleritasCelery/rope-benches">benchmarks</a> comparing ropes and gap buffers. Let’s look at the time it takes to complete the two highest latency operations on gap buffers: resizing and moving the gap. This is a cost that ropes don’t share because their worst case for an editing operation is O(logn).</p>
<h3 id="resize">
    <a href="#resize">
      Resize
    </a>
</h3>
<p>Insertion in a gap buffer is O(1), just like an appending to a vector. But also like vectors, they only achieve this in the amortized case. Vectors need to resize once they get full, and this is a O(N) operation. But since the time between resizing is N appends, it averages out to O(1). Gap buffers are similar, except that we don’t usually continue to grow the gap as the text gets larger (that would lead to more overhead). In this sense, it isn’t truly O(1) insertion time, but even if it was, we generally care about the latency in interactive applications more than we care about the average case.</p>
<figure><img src="https://coredumped.dev/images/buffer_resize.png">
</figure>

<p>Note that both axes are logarithmic. We can see that the cost to resize grows linearly with the size of the buffer, which is what we would expect. With a 1GB<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> file, it takes a little over 100ms to resize, which is starting to be perceptible.</p>
<h3 id="moving-the-gap">
    <a href="#moving-the-gap">
      Moving the gap
    </a>
</h3>
<p>How long does it take to slide the gap a given distance? This delay is added anytime we edit a different part of the buffer than we are currently in. The farther the move, the longer it takes. Unlike resizing which (from a user’s perspective) strikes randomly, this latency is easier to predict. You generally know when you are editing something farther than where you are currently at.</p>
<figure><img src="https://coredumped.dev/images/buffer_move_gap.png">
</figure>

<p>Moving the gap 1GB is significantly faster than resizing 1GB, taking only 22ms. This isn’t nothing, but is small enough to be imperceptible. Of course, since this is a O(n) relationship, moving the gap even farther will have a proportionally higher cost.</p>
<p>In practice, these latencies will be less of an issue, because giant files tend to be log files and auto-generated output, which are rarely edited. However, it is still an unavoidable cost of storing data in a contiguous fixed-sized structure.</p>
<h2 id="memory-overhead">
    <a href="#memory-overhead">
      Memory overhead
    </a>
</h2>
<p>For our comparisons, let’s start with memory overhead. The way to read this is if something has 50% overhead, that means you need 1.5GB of memory to open a 1GB file.</p>
<figure><img src="https://coredumped.dev/images/buffer_overhead.png">
</figure>

<p>Woah! Jumprope is way outside the norm here, almost doubling the memory needed to open a file<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. Crop and Ropey are much closer to what you would expect. However, this is the ideal case of opening a new file. Each rope node will be perfectly filled and the tree properly balanced.</p>
<h3 id="edit-overhead">
    <a href="#edit-overhead">
      Edit overhead
    </a>
</h3>
<p>Let’s look at the overhead when edits are applied to the text. These could be things like large search and replace or multiple cursors. This tends to leave the ropes in a less ideal state, and hence have higher overhead.</p>
<figure><img src="https://coredumped.dev/images/buffer_edit_overhead.png">
</figure>

<p>Fairly significant change for all ropes. Jumprope has gone through the roof, jumping so high that I didn’t even bother expanding the plot to show it. Even crop, which had the lowest rope overhead in ideal conditions, has jumped almost 20x. The gap buffer on the other hand has barely moved. Unlike ropes, a gap buffer is always in ideal state with regards to layout. This unique property will show up later in the searching benchmarks.</p>
<h2 id="real-world">
    <a href="#real-world">
      Real world
    </a>
</h2>
<p>To compare editing performance we have a set of 5 <a href="https://github.com/josephg/editing-traces">real world</a> benchmarks from the author of Jumprope. These are recordings or “traces” of actual people editing some text in an editor. Each benchmark starts empty, then replays thousands of edits and arrives at the end text.</p>
<p><img src="https://coredumped.dev/images/realworld1.png" alt="">
<img src="https://coredumped.dev/images/realworld2.png" alt="">
<img src="https://coredumped.dev/images/realworld3.png" alt=""></p>
<p>Aside from Ropey, all the containers have comparable performance. In all benchmarks but one, the gap buffer is the fastest, but not by any meaningful amount. This demonstrates that in the average case, insert and delete performance is fairly comparable between the different data structures. Let’s zoom in on some specialized use cases.</p>
<h2 id="creating">
    <a href="#creating">
      Creating
    </a>
</h2>
<p>So we have a sense of the memory overhead and average performance for the different containers. Here we will compare the time to load and save the text from the data structures.</p>
<h3 id="creating-from-a-string">
    <a href="#creating-from-a-string">
      Creating from a String
    </a>
</h3>
<p>How long does it take to create a new data structure from a <code>String</code>? The string below is 1GB in size.</p>
<figure><img src="https://coredumped.dev/images/from_string.png">
</figure>

<p>The gap buffer is significantly faster than the rest, but it’s not really a fair comparison. A <code>String</code> is essentially already a gap buffer. It has the string text, followed by some amount of unused capacity which can be used as a gap. So in this case we don’t need to copy or allocate at all, instead reusing the allocation from the string. That won’t always be the case, so how do things compare if we force them all to copy the source text? This would be the case when loading from a file.</p>
<figure><img src="https://coredumped.dev/images/from_str.png">
</figure>

<p>Forcing a copy makes the gap buffer take about three times as long, but it is still faster than the rope implementations.</p>
<h3 id="saving">
    <a href="#saving">
      Saving
    </a>
</h3>
<p>What about saving a file? Here we are not going to benchmark the actual file system overhead, but instead use “writing the contents of 1GB to a string” as a proxy.</p>
<figure><img src="https://coredumped.dev/images/save.png">
</figure>

<p>All containers are pretty comparable on this front.</p>
<h2 id="multiple-cursors">
    <a href="#multiple-cursors">
      Multiple cursors
    </a>
</h2>
<p>Back in 2017, Chris Wellons wrote a <a href="https://nullprogram.com/blog/2017/09/07/">blog post</a> titled “Gap Buffers Are Not Optimized for Multiple Cursors”. It makes the case that since gap buffers have to move the gap buffer back to the first cursor for each edit (a O(n) operation), they don’t scale well with multiple cursors. So instead of using multiple cursors, you should use some other editing operation like macros. <a href="https://github.com/hauleth/sad.vim#why-not-multiple-cursors">This</a> idea <a href="https://cdacamar.github.io/data%20structures/algorithms/benchmarking/text%20editors/c++/editor-data-structures/">has</a> now <a href="https://github.com/emacs-ng/emacs-ng/issues/378#issuecomment-907577662">become</a> part <a href="https://vms.wwwtech.de/notes/360">of</a> Internet <a href="https://vuink.com/post/ahyycebtenz-d-dpbz/blog/2017/09/07">lore</a>.</p>
<p>I was not convinced by this argument. For one thing, there are no benchmarks, and many things that make sense intuitively don’t play out that way in the real world. Also, I realized you can avoid the overhead of moving the gap back to the first cursor with this one weird trick (computer scientists hate him!): Every time you do an edit, you reverse the direction you iterate through the cursors. If in one edit you go from the first cursor to the last, then in the next edit you go from the last cursor to the first. This saves the overhead of moving the gap back to the first cursor each time. Essentially you just sweep the gap back and forth as you make edits. Let’s benchmark this and see how well it works.</p>
<figure><img src="https://coredumped.dev/images/smart_diff.png">
</figure>

<p>It looks like this trick works. Let’s zoom in on the percent overhead of the naive version.</p>
<figure><img src="https://coredumped.dev/images/smart_diff_percent.png">
</figure>

<p>Once the distance gets large enough we have about 20-30% overhead. This shows that even in the naive case, most of the time is dominated by performing the actual edits, not moving the cursor back. Also, The overhead doesn’t grow linearly with the distance between the cursors.</p>
<h3 id="compared-to-ropes">
    <a href="#compared-to-ropes">
      Compared to ropes
    </a>
</h3>
<p>How does this compare to the rope implementations? We will start with cursors 100 bytes apart and increase the total cursor count.</p>
<figure><img src="https://coredumped.dev/images/cursor_count.png">
</figure>

<p>The relationship is almost perfectly linear, with Crop and Jumprope about twice as fast as Ropey but 50% slower than the gap buffer. This relationship continues as we move beyond 10,000 cursors. So having high numbers of cursors doesn’t impact gap buffers.</p>
<p>But one thing that might cause trouble is the distance <em>between</em> the cursors. Let’s benchmark 100 cursors while varying the average distance between them:</p>
<figure><img src="https://coredumped.dev/images/cursor_distance.png">
</figure>

<p>Now the weakness of gap buffers starts to show. The distance between cursors does not matter to ropes, because every edit is O(logn), however, it matters a lot to gap buffers. You can see that the ropes are all roughly flat, but the gap buffer has a positive slope. After about 1K Jumprope and Crop start to beat it, and after about 4K it falls behind Ropey.</p>
<p>However, there is nothing special about multiple cursors with this relationship. Gap buffers struggle with long-distance edits no matter what mechanism is used. It would be the same with macros, search and replace, etc. Given that, I would claim that gap buffers are optimized for multiple cursors just fine, it is non-local edits that are the source of the issue.</p>
<h2 id="searching">
    <a href="#searching">
      Searching
    </a>
</h2>
<p>People don’t only edit text, they also analyze it. One of the most common ways to do this is via searching. Rust has a highly optimized regex crate, but it only operates on slices. This is <a href="https://github.com/xi-editor/xi-editor/issues/1192">problematic</a> for <a href="https://github.com/helix-editor/helix/pull/211">ropes</a> since they store the buffer in many small allocations. Currently, the best way to do a regex search over a rope is to copy all the chunks out into a separate allocation and perform your search over that<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. There is some work to create a <a href="https://github.com/rust-lang/regex/issues/425">streaming API version</a> of regex based on <code>regex-automata</code>, but it still has not been developed and may never prove to be as fast as slice searching.</p>
<p>Given that, I wanted to test out how the different containers do when performing a full-text search. We would expect the gap buffer to have a significant advantage here because it is already in slice format.</p>
<figure><img src="https://coredumped.dev/images/search.png">
</figure>

<p>We can see that the buffer is a near-perfect line because we are essentially only benchmarking the speed of the regex engine. The ropes on the other hand have significantly higher overhead and more variability. Searching 1 GB text, the gap buffer runs in 35ms, which is around 7x faster than the next fastest rope (~250ms).</p>
<p>You might object that we are making things too easy for the gap buffer because the gap is at the start. If the gap was anywhere else we would need to move to before searching. Fair enough, but most of the time we wouldn’t need to move the gap all the way to the beginning or end. If the search is not multi-line, then you just need to move the gap to the nearest line boundary. But for the sake of analysis, let’s pretend we are doing a multi-line search. We will run the benchmark again with the gap in the middle of the text; the worst-case scenario. This will mean we need to move the gap 50% of the way across the text before we can begin searching.</p>
<figure><img src="https://coredumped.dev/images/search_move.png">
</figure>

<p>It adds about 30% overhead to the gap search. This still doesn’t put it anywhere near the ropes. Ultimately, the speed of search was one of the reasons that I chose gap buffer over ropes for my project. Emacs does a lot of searching.</p>
<p>That being said, many new parser libraries like Tree-sitter are already designed to operate on non-contiguous chunks, so the need for search becomes less important. We will see how this plays out in the future.</p>
<h2 id="what-should-you-use">
    <a href="#what-should-you-use">
      What should you use?
    </a>
</h2>
<p>So is this to say that everyone should switch over and start using gap buffers? Not quite. Ropes are really powerful data structures, and they never have the latency spikes associated with resizing or moving the gap. In real-world editing scenario’s it isn’t the best case or even the average case, it’s the worst-case tail latency that really matters. With ropes, you get worse case O(logn) behavior for all editing operations. As files get larger the extra latency associated with gap buffers starts to show itself. On the flip side, in my experience the larger a file is the less likely I am to be editing it, but the more likely I am to be searching it. These trade-offs work well in favor of gap buffers.</p>
<p>Ropes have <a href="https://github.com/emacs-ng/emacs-ng/issues/378#issuecomment-907680382">other benefits</a> besides good performance. Both Crop and Ropey support concurrent access from multiple threads. This lets you take snapshots to do <a href="https://web.archive.org/web/20171220080405/https://blog.atom.io/2017/10/12/atoms-new-buffer-implementation.html">asynchronous saves</a>, backups, or multi-user edits. This isn’t something you could easily do with a gap buffer.</p>
<p>Despite all that, gap buffers showed they can do quite well when placed against more “advanced” data structures. One of their key advantages is that gap buffers are always in an ideal state. They never need to worry about fragmentation or being unbalanced like trees do. The way I see it, gap buffers are better for searching and memory usage, but ropes are better at non-local editing patterns. Despite their simplicity, gap buffers can hold their own in the modern world. Maybe Emacs was on to something.</p>

<p>Join the <a href="https://discu.eu/?q=https%3A%2F%2Fcoredumped.dev%2F2023%2F08%2F09%2Ftext-showdown-gap-buffers-vs-ropes%2F&amp;submit_title=Text%20showdown%3A%20Gap%20Buffers%20vs%20Ropes%20%E2%80%A2%20Core%20Dumped">discussion</a> or send me an <a href="mailto:troy.hinckley@dabrev.com">email</a>. Benchmarks can be found <a href="https://github.com/CeleritasCelery/rope-benches">here</a>.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>GB here means 2^30, as it should when <a href="https://www.merriam-webster.com/dictionary/kilobyte">talking about base-2 memory</a>. The only people who think it should be 10^9 are hard drive salesmen and the type of people who like to correct all their friends by saying “It’s centripetal, not centrifugal force!”. Also “gibibyte” sounds like Pokémon invented by a first grader.&nbsp;<a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://github.com/josephg/jumprope-rs/issues/5">github.com/josephg/jumprope-rs/issues/5</a>&nbsp;<a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>You may think this unnecessary, and instead you only run the regex one line at a time. If the line is completely contained within a chunk you don’t need to allocate anything. And indeed both crop and ropey provide an iterator over the lines of text. But in my testing, this was about an order of magnitude slower than just copying the whole allocation and searching. I am not sure if that mostly comes from the iteration overhead, or if small regex runs are inefficient.&nbsp;<a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Made Billions with Secret Change to Ad-Auction Algorithm (158 pts)]]></title>
            <link>https://finance.yahoo.com/news/google-changed-ad-auctions-raising-191333390.html</link>
            <guid>37820192</guid>
            <pubDate>Mon, 09 Oct 2023 13:20:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/google-changed-ad-auctions-raising-191333390.html">https://finance.yahoo.com/news/google-changed-ad-auctions-raising-191333390.html</a>, See on <a href="https://news.ycombinator.com/item?id=37820192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Alphabet Inc.’s Google changed its advertising auction formula in 2017, raising prices by 15% and likely making the company billions of dollars in additional revenue, according to an economist testifying for the US Justice Department in the antitrust case against the search giant.</p><p>Most Read from Bloomberg</p><ul><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-08/israel-latest-fighting-continues-in-the-south-mortars-in-north?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Israel Latest: Over 1,100 Dead; US Sends Warships to Region;elm:context_link;itc:0">Israel Latest: Over 1,100 Dead; US Sends Warships to Region</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-09/israel-latest-over-1-100-dead-oil-soars-on-fears-of-proxy-war?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Israel Latest: Army Reserves Called Up, Chevron Shuts Gas Field;elm:context_link;itc:0">Israel Latest: Army Reserves Called Up, Chevron Shuts Gas Field</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-08/oil-rallies-by-more-than-3-after-hamas-attacks-against-israel?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Oil Surges as Israel Conflict Reignites Middle East Volatility;elm:context_link;itc:0">Oil Surges as Israel Conflict Reignites Middle East Volatility</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-08/as-israel-war-rages-oil-traders-are-focused-on-iran?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:As Israel-Hamas War Rages, Oil Traders Focus on Iran;elm:context_link;itc:0">As Israel-Hamas War Rages, Oil Traders Focus on Iran</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-08/israeli-hostages-held-by-hamas-in-gaza-strip-include-families-elderly?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Israelis Taken Hostage Were Ripped From Everyday Activities;elm:context_link;itc:0">Israelis Taken Hostage Were Ripped From Everyday Activities</a></p></li></ul><p>Michael Whinston, a professor of economics at the Massachusetts Institute of Technology, said Friday that Google modified the way it sold text ads via “Project Momiji” – named for the wooden Japanese dolls that have a hidden space for friends to exchange secret messages. The shift sought “to raise the prices against the highest bidder,” Whinston told Judge Amit Mehta in federal court in Washington.</p><p>Google’s advertising auctions require the winner to pay only a penny more than the runner-up. In 2016, the company discovered that the runner-up had often bid only 80% of the winner’s offer. To help eliminate that 20% between the runner-up and what the winner was willing to pay, Google gave the second-place bidder a built-in handicap to make their offer more competitive, Whinston said, citing internal emails and sealed testimony by Google finance executive Jerry Dischler earlier in the case.</p><p>“It’s really easy to slip into the thought that it’s an auction and an auction is competition,” Whinston said, explaining how Google’s ability to tweak the rules demonstrates its monopoly over online advertising. But “it’s the advertisers who are running in this race. It’s Google setting the rules.”</p><p>The Justice Department alleges that Google has illegally maintained a monopoly over online search by paying billions of dollars to web browsers and smartphone manufacturers to ensure it’s the preselected option for users accessing the web. As part of those deals, Google pays Apple Inc., Samsung Electronics Co. and others a share of the revenue it earns from search advertising.</p><p>About two-thirds, more than 60%, of Google’s total revenue comes from search ads, Dischler said previously, amounting to more than $100 billion in 2020. Every year since 2012, the company’s search ad revenue growth has been in the “high teens,” according to documents shown by the Justice Department.</p><p>Dischler testified on Sept. 19 that Google sometimes tweaked its advertising auctions to ensure it met revenue targets, but most of his testimony occurred in a sealed session. Whinston’s comments Friday described Google’s technique, called “squashing,” that seeks to make the runner-up’s bid more competitive. Google estimated that technique along with charging more for ads that used more words in their text would increase revenues by 15%.</p><p>“Google has not been transparent about what they are doing” with pricing, Whinston said. But advertisers “do have ways of finding out even if they don’t know exactly what Google is doing.”</p><p>Most Read from Bloomberg Businessweek</p><ul><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-08/bond-market-pain-is-a-sign-of-interest-rates-returning-to-normal?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:The Free-Money Experiment Is Over;elm:context_link;itc:0">The Free-Money Experiment Is Over</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-03/can-ai-pick-stocks-better-than-wall-street-firms-are-trying?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Can AI Beat the Market? Wall Street Is Desperate to Try;elm:context_link;itc:0">Can AI Beat the Market? Wall Street Is Desperate to Try</a></p></li><li><p><a href="https://www.bloomberg.com/news/features/2023-10-05/india-canada-fraying-ties-how-sikh-leader-s-killing-sparked-crisis?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Aftermath of an Assassination: Inside the India-Canada Crisis;elm:context_link;itc:0">Aftermath of an Assassination: Inside the India-Canada Crisis</a></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2023-10-02/5-returns-at-banks-has-financial-advisers-fighting-irrelevance?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:With Banks Offering 5% Returns, Financial Advisers Fight Irrelevance;elm:context_link;itc:0">With Banks Offering 5% Returns, Financial Advisers Fight Irrelevance</a></p></li><li><p><a href="https://www.bloomberg.com/news/features/2023-10-05/why-child-care-is-so-hard-to-afford-in-america?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:These 10 Graphics Show Just How Broken America’s Child-Care System Is;elm:context_link;itc:0">These 10 Graphics Show Just How Broken America’s Child-Care System Is</a></p></li></ul><p>©2023 Bloomberg L.P.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Safe AI Image Generation (228 pts)]]></title>
            <link>https://www.smbc-comics.com/comic/generation</link>
            <guid>37819855</guid>
            <pubDate>Mon, 09 Oct 2023 12:43:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smbc-comics.com/comic/generation">https://www.smbc-comics.com/comic/generation</a>, See on <a href="https://news.ycombinator.com/item?id=37819855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="comicleft">		<div id="navtop"><nav role="navigation"><a title="First" rel="first" href="https://www.smbc-comics.com/comic/2002-09-05"></a><a rel="prev" title="Previous" href="https://www.smbc-comics.com/comic/history-4"></a><a href="https://www.smbc-comics.com/comic/rss"></a></nav>		</div>
					
		<p><img title="I'm even into heterocyclic compounds." src="https://www.smbc-comics.com/comics/1696814561-20231007.png" id="cc-comic">					
					</p><div id="navbottom"><nav role="navigation"><a title="First" rel="first" href="https://www.smbc-comics.com/comic/2002-09-05"></a><a rel="prev" title="Previous" href="https://www.smbc-comics.com/comic/history-4"></a><a href="https://www.smbc-comics.com/comic/rss"></a></nav>			
		</div>
		
		<p><a href="https://hivemill.com/products/smbc-print-pages?&amp;podurl=%2F%2Fwww.smbc-comics.com%2Fcomic%2Fgeneration"><img id="buythisimg" src="https://www.smbc-comics.com/images/printme.png"></a>
		</p>

				

				<p><label>Permalink for sharing!</label></p>


	    <p>Rotate phone to read blog</p>

		<div id="sharemob">
			<p><img src="https://www.smbc-comics.com/images/mobshare.png"></p>
			<p><a id="facebookshare" onclick="window.open('https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fwww.smbc-comics.com%2Fcomic%2Fgeneration&amp;t=Saturday+Morning+Breakfast+Cereal','name','width=600,height=400')"><img src="https://www.smbc-comics.com/images/mobfacebookshare.png"></a>
			<a id="twittershare" onclick="window.open('https://twitter.com/share?url=http://smbc-comics.com/comic/generation&amp;text=Saturday Morning Breakfast Cereal%20%23smbc%20%23hiveworks','name','width=600,height=400')"><img src="https://www.smbc-comics.com/images/mobtwittershare.png"></a>
			<a id="redditshare" onclick="window.location = 'http://www.reddit.com/submit?url=www.smbc-comics.com%2Fcomic%2Fgeneration'; return false"><img src="https://www.smbc-comics.com/images/mobredditshare.png"></a>
			<a id="pinterestshare" onclick="window.open('http://www.pinterest.com/pin/create/button/?url=http%3A%2F%2Fwww.smbc-comics.com%2Fcomic%2Fgeneration&amp;media=http%3A%2F%2Fwww.smbc-comics.com%2Fcomics%2F1696814561-20231007.png&amp;description=Saturday%20Morning%20Breakfast%20Cereal','name','width=600,height=400')"><img src="https://www.smbc-comics.com/images/mobpinterestshare.png"></a>
			<a id="stumbleuponshare" onclick="window.open('http://www.stumbleupon.com/badge/?url=http%3A%2F%2Fwww.smbc-comics.com%2Fcomic%2Fgeneration%23comic','name','width=600,height=400')"><img src="https://www.smbc-comics.com/images/mobstumbleuponshare.png"></a><a id="extracomic" onclick="toggleBlock(&quot;mobaftercomic&quot;)"><img src="https://www.smbc-comics.com/images/mobbutton.png"></a>
		</p></div>
		

		
			
				
            	

            <div id="blogarea">
			<div><p>Generation</p><p>Posted October 8, 2023 at 09:22 pm</p></div><div><p>Tags: <a href="https://www.smbc-comics.com/comic/search/science">science</a>, <a href="https://www.smbc-comics.com/comic/search/ai">ai</a>, <a href="https://www.smbc-comics.com/comic/search/sex">sex</a></p></div>							</div>
			
			<div id="commentarea">
							
						
				<p>Comments</p>			</div>
				
			<div id="mobilemenu">
            
            			
			<p><a href="http://www.hiveworkscomics.com/" id="mobhiveworks"><img src="https://www.smbc-comics.com/images/mobhiveworks.png"></a>
        	<a href="https://www.patreon.com/ZachWeinersmith?ty=h" id="mobpatreon"><img src="https://www.smbc-comics.com/images/mobpatreon.png"></a>
            <a href="https://www.smbc-comics.com/comic/archive" id="mobarchive"><img src="https://www.smbc-comics.com/images/mobarchive.png"></a>
			<a href="http://hivemill.com/collections/smbc" id="mobstore"><img src="https://www.smbc-comics.com/images/mobstore.png"></a></p><!-- mobile email form button -->
<p><a href="https://smbc-comics.us15.list-manage.com/subscribe/post?u=c196cb2377d2d5462fdfa5dbf&amp;id=77be344bfa" target="_blank">
    <img src="https://www.smbc-comics.com/emailform/header-trans4-2.png" alt="">
  </a>
</p>
<!-- end of mobile email form button -->
            
        </div>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leantime: Open-Source Jira Alternative (150 pts)]]></title>
            <link>https://github.com/Leantime/leantime</link>
            <guid>37819693</guid>
            <pubDate>Mon, 09 Oct 2023 12:25:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Leantime/leantime">https://github.com/Leantime/leantime</a>, See on <a href="https://news.ycombinator.com/item?id=37819693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div dir="auto">
<p><a href="https://leantime.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/ab41a189ebe3ae3548b8b5d56aee3bf3a6281575d995527db075bfd82fe0a31a/68747470733a2f2f6c65616e74696d652e696f2f77702d636f6e74656e742f75706c6f6164732f323032332f30332f6c65616e74696d655f6c6f676f2e706e67" alt="Leantime Logo" width="300" data-canonical-src="https://leantime.io/wp-content/uploads/2023/03/leantime_logo.png"></a></p><h3 tabindex="-1" id="user-content-leantime" dir="auto"><a href="#leantime">Leantime®</a></h3>
<p dir="auto">Leantime is an open source project management system for non-project manager.<br>We combine strategy, planning and executing while making it easy for everyone on the team to use.<br>It's an alternative to ClickUp, Monday, or Asana. As simple as Trello but as feature rich as Jira.<br><a href="https://leantime.io/" rel="nofollow">https://leantime.io</a><br></p>
<p dir="auto"><a href="https://www.gnu.org/licenses/agpl-3.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/4807337c2658c1024d36ab255607cf4f393b0244a101204dcdae8084ae09e322/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c65616e74696d652f6c65616e74696d653f7374796c653d666c61742d737175617265" alt="License Badge" data-canonical-src="https://img.shields.io/github/license/leantime/leantime?style=flat-square"></a>
<a href="https://hub.docker.com/r/leantime/leantime" rel="nofollow"><img src="https://camo.githubusercontent.com/692fa2a74719f6c6271b5e99c0697bc4c10a939902fa775af29f72fffb9a6aa8/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f6c65616e74696d652f6c65616e74696d653f7374796c653d666c61742d737175617265" alt="Docker Hub Badge" data-canonical-src="https://img.shields.io/docker/pulls/leantime/leantime?style=flat-square"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/49e0c7b5dbd82d8dae1a8564fa5e92bdce23b50affe62d82c40602113f33d072/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f6c65616e74696d652f6c65616e74696d652f746f74616c"><img src="https://camo.githubusercontent.com/49e0c7b5dbd82d8dae1a8564fa5e92bdce23b50affe62d82c40602113f33d072/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f6c65616e74696d652f6c65616e74696d652f746f74616c" alt="Github Downloads" data-canonical-src="https://img.shields.io/github/downloads/leantime/leantime/total"></a>
<a href="https://discord.gg/4zMzJtAq9z" rel="nofollow"><img src="https://camo.githubusercontent.com/49db8e82f9b6a3d98eab858c71aa35aab41c3d3111b2d42510ea4421ea5966e2/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3939303030313238383032363637373331383f6c6162656c3d446973636f7264267374796c653d666c61742d737175617265" alt="Discord Badge" data-canonical-src="https://img.shields.io/discord/990001288026677318?label=Discord&amp;style=flat-square"></a>
<a href="https://crowdin.com/project/leantime" rel="nofollow"><img src="https://camo.githubusercontent.com/bcc51221f07ed79b9a527b8f472f32dfc7cc88ad437e6c3aa0e0624257c63220/68747470733a2f2f6261646765732e63726f7764696e2e6e65742f6c65616e74696d652f6c6f63616c697a65642e737667" alt="Crowdin" data-canonical-src="https://badges.crowdin.net/leantime/localized.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0a684f0f087d59d76d5c8d01fa7d175bcd7a043fecff5ced239aff682614848b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73706f6e736f72732f6c65616e74696d65"><img src="https://camo.githubusercontent.com/0a684f0f087d59d76d5c8d01fa7d175bcd7a043fecff5ced239aff682614848b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73706f6e736f72732f6c65616e74696d65" alt="GitHub Sponsors" data-canonical-src="https://img.shields.io/github/sponsors/leantime"></a>
<br></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Home.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Home.png" alt="alt text" title="Home Screen"></a></p>
</div>
<h2 tabindex="-1" id="user-content--features" dir="auto"><a href="#-features">🚀 Features*</a></h2>
<table>
<thead>
<tr>
<th>Task Management</th>
<th>Project Planning</th>
<th>Information/Knowledge Management</th>
<th>Administration</th>
</tr>
</thead>
<tbody>
<tr>
<td>Task management via<br>kanban boards, gantt, table, list and calendar views</td>
<td>Project Dashboards, reports &amp; status updates</td>
<td>Wikis / Docs</td>
<td>Easy installation</td>
</tr>
<tr>
<td>Unlimited subtasks and dependencies</td>
<td>Goal &amp; metrics tracking</td>
<td>Idea Boards</td>
<td>Multiple user roles and per project permissions</td>
</tr>
<tr>
<td>Milestone management</td>
<td>Lean &amp; Business Model Canvas</td>
<td>Retrospectives</td>
<td>Two factor authentication</td>
</tr>
<tr>
<td>Sprint Management</td>
<td>SWOT Analysis canvas</td>
<td>File Storage via S3 or local filesystem</td>
<td>LDAP, OIDC integration</td>
</tr>
<tr>
<td>Timetracking &amp; timesheets</td>
<td>Risk Analysis</td>
<td>Screen &amp; webcam recording</td>
<td>Integration with mattermost, slack, discord and zulip (more coming soon)</td>
</tr>
<tr>
<td></td>
<td>... and more</td>
<td>Comments/discussions on everything</td>
<td>Available in 19 languages</td>
</tr>
</tbody>
</table>
<div dir="auto"><p>*yes, all of theses features are included in the OSS version
</p></div>
<h3 tabindex="-1" id="user-content--screenshots" dir="auto"><a href="#-screenshots">📸 Screenshots</a></h3>
<table>
<thead>
<tr>
<th><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/ProjectDashboard.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/ProjectDashboard.png" alt="alt text" title="Project Dashboard"></a></th>
<th><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Kanban2.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Kanban2.png" alt="alt text" title="Kanban Board"></a></th>
<th><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Tasks-table.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Tasks-table.png" alt="alt text" title="Grouped To-Dos"></a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Tasks-list.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Tasks-list.png" alt="alt text" title="Task Lists"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Tasks-timeline.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Tasks-timeline.png" alt="alt text" title="Tasks on timeline"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Tasks-calendar.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Tasks-calendar.png" alt="alt text" title="Project Calendar"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Goals.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Goals.png" alt="alt text" title="Goals"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Leancanvas.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Leancanvas.png" alt="alt text" title="Lean Canvas"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Reports.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Reports.png" alt="alt text" title="Report Screens"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Docs.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Docs.png" alt="alt text" title="Documents &amp; Wikis"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Blueprints.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Blueprints.png" alt="alt text" title="Blueprints"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Confetti.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Confetti.png" alt="alt text" title="Confetti"></a></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Files.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Files.png" alt="alt text" title="Files &amp; Screenrecording"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Timesheets.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Timesheets.png" alt="alt text" title="Timsheets"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/Leantime/leantime/blob/master/public/assets/images/Screenshots/Task.png"><img src="https://github.com/Leantime/leantime/raw/master/public/assets/images/Screenshots/Task.png" alt="alt text" title="Task details"></a></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" id="user-content-system-requirements" dir="auto"><a href="#system-requirements">❗System Requirements</a></h3>
<ul dir="auto">
<li>PHP 8.1+</li>
<li>MySQL 5.7+</li>
<li>Apache or Nginx (IIS works with some modifications)</li>
<li>PHP Extensions:</li>
<li>
<ul dir="auto">
<li>mysql, mbstring, GD, exif, pcntl, bcmath, opcache, ldap
</li>
</ul>
</li>
</ul>
<h3 tabindex="-1" id="user-content-️️-installation-production" dir="auto"><a href="#️️-installation-production">️⚡️ Installation (Production)</a></h3>
<p dir="auto">There are two main ways to install LeanTime for production. The first of which is to install all needed pieces of the system locally. The second is to use the offically supported Docker image.</p>
<h4 tabindex="-1" id="user-content-local-production-installation" dir="auto"><a href="#local-production-installation">Local Production Installation</a></h4>
<ul dir="auto">
<li>Download latest release package from our <a href="https://leantime.io/download-leantime/" rel="nofollow">Website</a> or <a href="https://github.com/Leantime/docker-leantime/releases">Github</a></li>
<li>Create an empty MySQL database</li>
<li>Upload entire directory to your server</li>
<li>Point your domain root to the <code>public/</code> directory</li>
<li>Rename <code>config/.env.sample</code> to <code>config/.env</code></li>
<li>Fill in your database credentials (username, password, host, dbname) in <code>config/.env</code></li>
<li>Navigate to <code>&lt;yourdomain.com&gt;/install</code></li>
<li>Follow instructions to install database and set up first user account</li>
</ul>
<h4 tabindex="-1" id="user-content-production-installation-via-docker" dir="auto"><a href="#production-installation-via-docker">Production Installation via Docker</a></h4>
<p dir="auto">We maintain an official <a href="https://hub.docker.com/r/leantime/leantime" rel="nofollow">Docker image on dockerhub</a>.
To run the image enter your MySQL credentials and execute. You can pass in all the configuration variables from .env</p>
<div data-snippet-clipboard-copy-content="docker run -d --restart unless-stopped -p 80:80 --network leantime-net \
-e LEAN_DB_HOST=mysql_leantime \
-e LEAN_DB_USER=admin \
-e LEAN_DB_PASSWORD=321.qwerty \
-e LEAN_DB_DATABASE=leantime \
-e LEAN_EMAIL_RETURN=changeme@local.local \
--name leantime leantime/leantime:latest"><pre><code>docker run -d --restart unless-stopped -p 80:80 --network leantime-net \
-e LEAN_DB_HOST=mysql_leantime \
-e LEAN_DB_USER=admin \
-e LEAN_DB_PASSWORD=321.qwerty \
-e LEAN_DB_DATABASE=leantime \
-e LEAN_EMAIL_RETURN=changeme@local.local \
--name leantime leantime/leantime:latest
</code></pre></div>
<p dir="auto">Unless you have a database defined somewhere else you should use our <a href="https://github.com/Leantime/docker-leantime/blob/master/docker-compose.yml">docker-compose file</a>.</p>
<div dir="auto"><p>Once started you can go to <code>&lt;yourdomain.com&gt;/install</code> and run the installation script.
</p></div>
<h3 tabindex="-1" id="user-content--installation-development" dir="auto"><a href="#-installation-development">🤓 Installation (Development)</a></h3>
<p dir="auto">There are two ways to install a development setup of LeanTime. The first (but most techical) is to install all pieces of the system locally. The second (and prefered method) is to use a docker containerized development environment.</p>
<h4 tabindex="-1" id="user-content-local-development-installation" dir="auto"><a href="#local-development-installation">Local Development Installation</a></h4>
<ul dir="auto">
<li>Clone repository to your local server</li>
<li>Create MySQL database</li>
<li>Run wbepack builder via <code>make build-dev</code></li>
<li>Point your local domain to the <code>public/</code> directory</li>
<li>Rename <code>config/.env.sample</code> to <code>config/.env</code></li>
<li>Fill in your database credentials (username, password, host, dbname) in <code>config/.env</code></li>
<li>Navigate to <code>&lt;localdomain&gt;/install</code></li>
<li>Follow instructions to install database and user account</li>
</ul>
<h4 tabindex="-1" id="user-content-development-installation-via-docker" dir="auto"><a href="#development-installation-via-docker">Development Installation via Docker</a></h4>
<p dir="auto">For development, we use a dockerized development environment. You will need to have <code>docker</code>, <code>docker compose</code>, <code>make</code>, <code>composer</code>, <code>git</code> and <code>npm</code> installed.</p>
<ul dir="auto">
<li>Notes for Windows Environments:
<ul dir="auto">
<li>Run all commands within the git bash terminal in order to utilize unix specific commands</li>
<li>If installing php from a zip file, make sure to configure php.ini
It does not exist initially, so copy C:\php\php.ini-development to C:\php\php.ini. You will also need to edit php.ini in a text editor and enable all needed extentions for the build process. You can find these by running the make commands and looking for any extensions that error out as missing. You can enable them by seaching php.ini for the extension that will look like: <code>;extension=gd</code> and removing the semicolon.</li>
</ul>
</li>
</ul>
<p dir="auto">In order to build the development docker image, in the root of this repository, run a primer with</p>
<p dir="auto"><code>make clean build</code></p>
<p dir="auto">afterwards, run</p>
<p dir="auto"><code>make run-dev</code></p>
<p dir="auto">this will start the development server on port 8080.</p>
<p dir="auto">The dev environment provides a mysql server, mail server, s3 server, and should be good to go for your needs out of the box. The configuration of the development environment is found in <code>.dev/.env</code>, and is already seeded with the appropriate values. <strong>You should probably not be modifying this unless you plan to work on a feature for a specific integration</strong>. the applications you get are as follows</p>
<ul dir="auto">
<li><a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a> : leantime</li>
<li><a href="http://localhost:8081/" rel="nofollow">http://localhost:8081</a> : maildev - to check emails sent</li>
<li><a href="http://localhost:8082/" rel="nofollow">http://localhost:8082</a> : phpmyadmin(authentication <code>leantime:leantime</code>) to check the DB schema and data</li>
<li><a href="http://localhost:8083/" rel="nofollow">http://localhost:8083</a> : s3ninja - to check s3 uploads. You need to enable this in the <code>.dev/.env</code> file by enabling s3</li>
</ul>
<div dir="auto"><p>Additionally, XDebug is enabled, but you will have to modify your
IDE key in the <code>.dev/xdebug.ini</code> file(or alternatively, on your IDE). You also need to have port 9003 temporarily open on your firewall so you can utilize it effectively. This is because connections from docker to the host will count as external inbound connection
</p></div>
<h3 tabindex="-1" id="user-content--update" dir="auto"><a href="#-update">🏗 Update</a></h3>
<h4 tabindex="-1" id="user-content-manual" dir="auto"><a href="#manual">Manual</a></h4>
<ul dir="auto">
<li>Make sure to take a backup of your database and files</li>
<li>Replace all files in your directory with the updated version</li>
<li>If there were any database changes, the system will redirect you to <code>&lt;yourdomain.com&gt;/update</code></li>
</ul>
<h4 tabindex="-1" id="user-content-script" dir="auto"><a href="#script">Script</a></h4>
<ul dir="auto">
<li>Execute ./updateLeantime.sh in the root of your leantime application</li>
</ul>
<h4 tabindex="-1" id="user-content-docker" dir="auto"><a href="#docker">Docker</a></h4>
<ul dir="auto">
<li>Before updating, make sure your mysql container was started using a mounted volume, otherwise your content will be deleted</li>
<li>Delete/Stop existing container</li>
<li>Pull the latest docker image and rebuild using your compose file</li>
</ul>
<h2 tabindex="-1" id="user-content-️-not-interested-in-hosting-yourself-let-us-do-it-for-you" dir="auto"><a href="#️-not-interested-in-hosting-yourself-let-us-do-it-for-you">☁️ Not interested in hosting yourself? Let us do it for you</a></h2>

<h2 tabindex="-1" id="user-content--need-technical-support" dir="auto"><a href="#-need-technical-support">🤙 Need technical support?</a></h2>
<p dir="auto">We can help you set up Leantime in your environment and customize it to your needs. Our support plans are <a href="https://leantime.io/priority-support/" rel="nofollow">outlined on our website</a></p>
<h3 tabindex="-1" id="user-content-community-support" dir="auto"><a href="#community-support">Community Support</a></h3>
<ul dir="auto">
<li>Documentation <a href="https://docs.leantime.io/" rel="nofollow">https://docs.leantime.io</a></li>
<li>Community Chat <a href="https://discord.gg/4zMzJtAq9z" rel="nofollow">Discord</a></li>
<li>File a bug report <a href="https://github.com/Leantime/leantime/issues/new">https://github.com/Leantime/leantime/issues/new</a></li>
<li>Translations <a href="https://crowdin.com/project/leantime" rel="nofollow">https://crowdin.com/project/leantime</a>
</li>
</ul>
<h2 tabindex="-1" id="user-content-️-license-exceptions" dir="auto"><a href="#️-license-exceptions">⚖️ LICENSE Exceptions</a></h2>
<p dir="auto">Leantime is licensed under AGPLv3.
This file forms part of the Leantime Software for which the following exception is added: Plugins within the <code>/app/plugins</code> directory which may contain plugins licensed under other licenses including our enterprise license.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modeling CRDTs in Alloy – the importance of idempotence (104 pts)]]></title>
            <link>https://bytes.zone/posts/modeling-crdts-in-alloy-introduction-and-the-importance-of-idempotence/</link>
            <guid>37819683</guid>
            <pubDate>Mon, 09 Oct 2023 12:23:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bytes.zone/posts/modeling-crdts-in-alloy-introduction-and-the-importance-of-idempotence/">https://bytes.zone/posts/modeling-crdts-in-alloy-introduction-and-the-importance-of-idempotence/</a>, See on <a href="https://news.ycombinator.com/item?id=37819683">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p><em>Brian Hicks, October 9, 2023</em></p><p>I've been interested in <a href="https://www.inkandswitch.com/local-first/">local-first software</a> for a long time, and recently attended an event about it with a bunch of luminaries from various research groups. I learned a lot, and it rekindled my interest in syncable data structures.</p><p>I've tried to sync data over the years with varying degrees of success. For example, I've known about <a href="https://en.wikipedia.org/wiki/Operational_transformation">operational transformations (OT)</a> for a while (via <a href="https://quilljs.com/">Quill</a>, but I have never been able to get the syncing operations working to my satisfaction. Message ordering is crucially important in OT, and it's hard to get right. I get the impression that the engineers who worked on Google Wave (which also used OT) also struggled with this…&nbsp;I remember reading a quote a while back that said something along the lines of "I wish I could have those years of my life back, and I wouldn't recommend anyone else try syncing this way." Ouch!</p><p>In contrast to OT, conflict-free replicated data types (CRDTs) seem really promising! <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">Wikipedia has a good summary</a>, which I'll quote:</p><blockquote><p>In distributed computing, a conflict-free replicated data type (CRDT) is a data structure that is replicated across multiple computers in a network, with the following features:</p><ol><li>The application can update any replica independently, concurrently and without coordinating with other replicas.</li><li>An algorithm (itself part of the data type) automatically resolves any inconsistencies that might occur.</li><li>Although replicas may have different state at any particular point in time, they are guaranteed to eventually converge.</li></ol></blockquote><p>These properties appeal to me! If CRDTs can automatically and independently converge, no matter how far apart they drift, then you could store them wherever and however you like. Offline support should be simple, and adding live collaboration features should not mean spending years figuring out edge cases. Sign me up!</p><p>What are CRDTs made from, though? It looks like typically it's some internal stuff, a function to resolve the internal stuff to a <code>value</code>, and a function to <code>merge</code> two of the data structure together. The merge function is the number-one-most-important thing about this whole arrangement, and has to satisfy<sup><a href="#1">1</a></sup> these three laws:</p><ul><li>commutative (so <code>merge(a, b)</code> must be the same as <code>merge(b, a)</code>)</li><li>associative (so <code>merge(merge(a, b), c)</code> must be the same as <code>merge(a, merge(b, c))</code>)</li><li>idempotent (so <code>merge(a, b)</code> must be the same as <code>merge(merge(a, b), b)</code>.<sup><a href="#2">2</a></sup>)</li></ul><p>If all these are true, we can always merge two states, regardless of how many changes have been made since we last merged, and get the same result on both sides of the sync. Cool!</p><p>These seem like the kinds of things that <a href="https://bytes.zone/projects/learning-alloy/">Alloy</a> would be good at modeling, so let's try it! Over the next couple of posts, I'm going to build a handful of data structures that follow these three rules and compose them into data structures we could build an application on top of.</p><p>Let's get a taste for this with <code>OR(bool, bool)</code>. First off, does it satisfy our three properties?</p><ul><li>commutative: <code>OR(True, False)</code> is the same as <code>OR(False, True)</code></li><li>associative: <code>OR(OR(True, False), True)</code> is the same as <code>OR(True, OR(False, True))</code></li><li>idempotent: calling <code>OR(x, True)</code> gives the same result as <code>OR(OR(x, True), True)</code>.</li></ul><p>So it looks like <code>OR</code> might be fine, but let's be sure. We can check this in Alloy by first defining<sup><a href="#3">3</a></sup> a boolean:</p><pre data-lang="alloy"><code data-lang="alloy"><span>enum</span><span> Bool { True, False }
</span></code></pre><p>Then a merge function, which we check is correct:</p><pre data-lang="alloy"><code data-lang="alloy"><span>fun </span><span>merge[</span><span>a, b: Bool</span><span>]</span><span>:</span><span> Bool {
</span><span>  </span><span>// OR
</span><span>  a </span><span>=</span><span> True </span><span>implies</span><span> a </span><span>else</span><span> b
</span><span>}
</span><span>
</span><span>check</span><span> MergeIsCorrect {
</span><span>  </span><span>// read as: given `a` and `b`, which are `Bool`, the
</span><span>  </span><span>// following condition must hold.
</span><span>  </span><span>all</span><span> a, b</span><span>:</span><span> Bool </span><span>|
</span><span>    (a </span><span>=</span><span> True </span><span>or</span><span> b </span><span>=</span><span> True) </span><span>implies </span><span>merge[</span><span>a, b</span><span>] </span><span>=</span><span> True
</span><span>}
</span></code></pre><p>And finally, our three properties:</p><pre data-lang="alloy"><code data-lang="alloy"><span>check</span><span> MergeIsCommutative {
</span><span>  </span><span>all</span><span> a, b</span><span>:</span><span> Bool </span><span>| </span><span>merge[</span><span>a, b</span><span>] </span><span>= </span><span>merge[</span><span>b, a</span><span>]
</span><span>}
</span><span>
</span><span>check</span><span> MergeIsAssociative {
</span><span>  </span><span>all</span><span> a, b, c</span><span>:</span><span> Bool </span><span>| </span><span>merge[</span><span>merge[a, b</span><span>]</span><span>, c] </span><span>= </span><span>merge[</span><span>a, merge[b, c</span><span>]</span><span>]
</span><span>}
</span><span>
</span><span>check</span><span> MergeIsIdempotent {
</span><span>  </span><span>all</span><span> a, b</span><span>:</span><span> Bool </span><span>| </span><span>merge[</span><span>a, b</span><span>] </span><span>= </span><span>merge[</span><span>merge[a, b</span><span>]</span><span>, b]
</span><span>}
</span></code></pre><p>Great! Alloy can't find any errors with <code>OR</code>.<sup><a href="#4">4</a></sup> We expected that, so let's break it in interesting ways. What if the merge function was <code>XOR(bool, bool)</code><sup><a href="#5">5</a></sup> instead?</p><pre data-lang="alloy"><code data-lang="alloy"><span>fun </span><span>merge[</span><span>a, b: Bool</span><span>]</span><span>:</span><span> Bool {
</span><span>  a </span><span>=</span><span> b </span><span>implies</span><span> False </span><span>else</span><span> True
</span><span>}
</span></code></pre><p>Now Alloy finds that we've broken idempotency: <code>merge[False, True]</code> is <code>True</code>, but <code>merge[merge[False, True], True]</code> is <code>False</code>. This would cause big problems if we used <code>XOR</code> as a merge function: the act of syncing could change our values! We can imagine this sequence of events:</p><ol><li>Node A sets the value to <code>True</code></li><li>Node B sets the value to <code>False</code></li><li>The nodes sync, both resolving to <code>True</code> (since <code>XOR(True, False)</code> is <code>True</code>)</li><li>The nodes sync again, both resolving to <code>False</code> (since <code>XOR(True, True)</code> is <code>False</code>)</li><li>Further syncs would stay at <code>False</code> until someone changed the value to <code>True</code>, at which point we'd repeat from step 3.</li></ol><p>But in a fun twist of fate, we don't <em>have</em> to imagine this; we can ask Alloy to generate these traces for us. First we'll make a document that contains a changeable value:</p><pre data-lang="alloy"><code data-lang="alloy"><span>sig</span><span> Document {
</span><span>  var value</span><span>: one</span><span> Bool,
</span><span>}
</span></code></pre><p>Then we'll define a <code>not</code> for our boolean and a couple of operations (flipping an arbitrary value and syncing two documents):</p><pre data-lang="alloy"><code data-lang="alloy"><span>fun </span><span>bool_not[</span><span>b: Bool</span><span>]</span><span>:</span><span> Bool {
</span><span>  b </span><span>=</span><span> True </span><span>implies</span><span> False </span><span>else</span><span> True
</span><span>}
</span><span>
</span><span>// intent: when `flip` is true, the provided document will go
</span><span>// from True to False or False to True in the next time step. 
</span><span>// This serves as our proxy for someone clicking a button in
</span><span>// a UI or whatever.
</span><span>pred </span><span>flip[</span><span>d: Document</span><span>]</span><span> {
</span><span>  </span><span>// implementation: `value` is actually a set of tuples from
</span><span>  </span><span>// documents to booleans, and `value'` is the same but in the
</span><span>  </span><span>// next time step. We set the entire value explicitly
</span><span>  </span><span>// (instead of just saying like `d'.value = False`) because
</span><span>  </span><span>// otherwise Alloy could say "and what if something changes
</span><span>  </span><span>// that you weren't expecting?"
</span><span>  </span><span>//
</span><span>  </span><span>// Syntax: `-&gt;` creates a tuple, and `++` replaces all
</span><span>  </span><span>// existing tuples referencing `d` in the set.
</span><span>  value' </span><span>=</span><span> value </span><span>++</span><span> d</span><span>-&gt;</span><span>bool_not[</span><span>d.value</span><span>]
</span><span>}
</span><span>
</span><span>// intent: merge two documents together in a way that all the
</span><span>// `merge` rules hold. Maybe imagine we have `d1` locally and
</span><span>// are getting `d2` over the network (but remember that order
</span><span>// should not matter!)
</span><span>pred </span><span>sync[</span><span>d1, d2: Document</span><span>]</span><span> {
</span><span>  </span><span>let</span><span> merged </span><span>= </span><span>merge[</span><span>d1.value, d2.value</span><span>]</span><span> {
</span><span>    value' </span><span>=</span><span> value </span><span>++</span><span> (d1</span><span>-&gt;</span><span>merged </span><span>+</span><span> d2</span><span>-&gt;</span><span>merged)
</span><span>  }
</span><span>}
</span></code></pre><p>Now wire them up so these events can happen over time:<sup><a href="#6">6</a></sup></p><pre data-lang="alloy"><code data-lang="alloy"><span>pred</span><span> init {
</span><span>  </span><span>// `Document` is a set of documents, and `-&gt;` will apply pairwise
</span><span>  </span><span>// for the sets in its arguments, so this means this says "all
</span><span>  </span><span>// documents start at `False`"
</span><span>  value </span><span>=</span><span> Document </span><span>-&gt;</span><span> False
</span><span>}
</span><span>
</span><span>fact</span><span> traces {
</span><span>  </span><span>// this says "start with `init`, then pick one of these things to
</span><span>  </span><span>// happen at each time step." Putting it in a `fact` means that
</span><span>  </span><span>// any assertions we make from now on assume that we want these
</span><span>  </span><span>// instructions.
</span><span>  init
</span><span>  always {
</span><span>    (</span><span>one</span><span> d</span><span>:</span><span> Document </span><span>| </span><span>flip[</span><span>d</span><span>]</span><span>)
</span><span>    </span><span>or</span><span> (</span><span>some</span><span> d1, d2</span><span>:</span><span> Document </span><span>| </span><span>sync[</span><span>d1, d2</span><span>]</span><span>)
</span><span>  }
</span><span>}
</span></code></pre><p>We can now check that our sync is idempotent:<sup><a href="#7">7</a></sup></p><pre data-lang="alloy"><code data-lang="alloy"><span>check</span><span> SyncIsIdempotent {
</span><span>  </span><span>// at all times, if sync happens twice in a row (the `;` syntax) then
</span><span>  </span><span>// the next value (`value'`) and the one after that (`value''`) should
</span><span>  </span><span>// be the same.
</span><span>  always </span><span>all</span><span> d1, d2</span><span>:</span><span> Document </span><span>|
</span><span>    (</span><span>sync[</span><span>d1, d2</span><span>]</span><span>; </span><span>sync[</span><span>d1, d2</span><span>]</span><span>) </span><span>implies</span><span> value' </span><span>=</span><span> value''
</span><span>}
</span></code></pre><p>If we make <code>OR</code> our <code>merge</code> function, this works fine and Alloy can't find any counterexamples. If we use <code>XOR</code> for <code>merge</code>, though, Alloy finds the trace I mentioned could show up earlier. Here's what it shows us.</p><table><thead><tr><th>Step</th><th>Description</th><th>Image</th></tr></thead><tbody><tr><td>1.</td><td>We start off with all documents at <code>False</code>.</td><td><img src="https://bytes.zone/images/xor-trace-step-1-and-4.png" alt="an Alloy instance showing two documents both set to False"></td></tr><tr><td>2.</td><td>One of the documents flips to <code>True</code>.</td><td><img src="https://bytes.zone/images/xor-trace-step-2.png" alt="the previous instance, but with one document now set to True"></td></tr><tr><td>3.</td><td>The documents sync, converging to <code>True</code>.</td><td><img src="https://bytes.zone/images/xor-trace-step-3.png" alt="the previous instance, but with both documents now set to True"></td></tr><tr><td>4.</td><td>The documents sync again, converging to <code>False</code> because <code>XOR(True, True)</code> (the previously synced state) is <code>False</code>.</td><td><img src="https://bytes.zone/images/xor-trace-step-1-and-4.png" alt="the previous instance, but with both documents now set to False"></td></tr><tr><td>5.</td><td>Stay here forever or return to 2.</td><td></td></tr></tbody></table><p>In case you're encountering them for the first time, these diagrams are generated by Alloy—they're pretty fantastic for showing other people exactly what can happen in a system. (That's also why <code>Document 0</code> is <code>d1</code> and so on. The documents are defined separately, and the <code>d1</code> and <code>d2</code> labels come from our <code>check</code> so we can see what's doing what.)</p><p>Alloy can do more than this, too. If we modify our condition to have 3 distinct documents like this:</p><pre data-lang="alloy"><code data-lang="alloy"><span>check</span><span> SyncIsIdempotent {
</span><span>  always </span><span>all disj</span><span> d1, d2, d3</span><span>:</span><span> Document </span><span>|
</span><span>    (</span><span>sync[</span><span>d1, d2</span><span>]</span><span>; </span><span>sync[</span><span>d2, d3</span><span>]</span><span>) </span><span>implies</span><span> value' </span><span>=</span><span> value''
</span><span>}
</span></code></pre><p>Then Alloy shows the situation getting even sillier. You only need one of the nodes to be <code>False</code>, at which point it's possible that the documents as a whole could never converge again and just flap back and forth randomly forever. It all depends on which documents sync with which other documents. Turns out idempotency is pretty important!</p><p>That's it for today. Next time we'll go from booleans-of-dubious-usefulness to counters!</p><hr><p>Big thanks to <a href="https://jakelazaroff.com/">Jake Lazaroff</a> for his help reviewing this post. If you're interested in this stuff, he also recently published <a href="https://jakelazaroff.com/words/an-interactive-intro-to-crdts/">an interactive intro to CRDTs</a> that you may enjoy!</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ZeroMQ – Relicense from LGPL3 and exceptions to MPL 2.0 (244 pts)]]></title>
            <link>https://github.com/zeromq/libzmq/pull/4555</link>
            <guid>37819566</guid>
            <pubDate>Mon, 09 Oct 2023 12:06:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zeromq/libzmq/pull/4555">https://github.com/zeromq/libzmq/pull/4555</a>, See on <a href="https://news.ycombinator.com/item?id=37819566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>
  <strong>Have a question about this project?</strong> Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
  </p>

  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" autocomplete="off" action="/join?return_to=%2Fzeromq%2Flibzmq%2Fissues%2Fnew" accept-charset="UTF-8" method="post">    <auto-check src="/signup_check/username">
      <dl><dt><label name="user[login]" autocapitalize="off" autofocus="autofocus" for="user_login_issues">Pick a username</label></dt><dd></dd></dl>
      
    </auto-check>

    <auto-check src="/signup_check/email">
      <dl><dt><label name="user[email]" autocapitalize="off" for="user_email_issues">Email Address</label></dt><dd></dd></dl>
      
    </auto-check>

    <auto-check src="/users/password"><dl><dt><label name="user[password]" for="user_password_issues">Password</label></dt><dd></dd></dl></auto-check>

    
    




      
</form>
  <p>By clicking “Sign up for GitHub”, you agree to our <a href="https://docs.github.com/terms" target="_blank">terms of service</a> and
  <a href="https://docs.github.com/privacy" target="_blank">privacy statement</a>. We’ll occasionally send you account related emails.</p>

  <p>
    Already on GitHub?
    <a data-ga-click="(Logged out) New issue modal, clicked Sign in, text:sign-in" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;new issue modal&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/zeromq/libzmq/pull/4555&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="b6221d85f0935ecfe3765e0414c5a581a395defb7e36de706d9ee492e6ee66d0" href="https://github.com/login?return_to=%2Fzeromq%2Flibzmq%2Fissues%2Fnew%2Fchoose">Sign in</a>
    to your account
  </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Explore Doctors' Disciplinary History (123 pts)]]></title>
            <link>https://www.physician.fyi/</link>
            <guid>37819234</guid>
            <pubDate>Mon, 09 Oct 2023 11:28:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.physician.fyi/">https://www.physician.fyi/</a>, See on <a href="https://news.ycombinator.com/item?id=37819234">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://chng.it/vKhKQKx9T9" target="_blank" rel="noreferrer">Sign our petition</a></p><!-- --><p>to make the National Practitioner Databank public. It's a federal repository of medical malpractice payments and adverse actions related to doctors. It purports to have a mission "to improve health care quality, protect the public, and reduce health care fraud and abuse in the U.S.", but it explicitly excludes the very patients who would benefit most from seeing findings against doctors from gaining access.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zimaboard: The closest thing to my dream home server setup (290 pts)]]></title>
            <link>https://ounapuu.ee/posts/2023/10/09/zimaboard/</link>
            <guid>37819114</guid>
            <pubDate>Mon, 09 Oct 2023 11:10:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/">https://ounapuu.ee/posts/2023/10/09/zimaboard/</a>, See on <a href="https://news.ycombinator.com/item?id=37819114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>I stumbled upon <a href="https://youtu.be/V_ZdvrIMKEQ">this Hardware Haven video about the Zimaboard recently.</a></p>
<p>I liked it a lot.</p>
<p>I finally bought one.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/cover.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/cover_hu2c08a0a24f9b2677477296053ae56db2_2448960_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
</figure>

<p>In short, <a href="https://www.zimaboard.com/zimaboard/product">Zimaboard</a> is a small single-board computer that is relatively affordable and comes
with an interesting selection of ports, which includes an exposed PCI Express port.</p>
<p>Before we get down to the build, here’s a list of aspects that I want to see in my dream home server:</p>
<ul>
<li>low power usage (2-15W typical power usage)</li>
<li>8GB of RAM or better</li>
<li>enough performance to run my workloads, most of which are containerized</li>
<li>2x SATA or NVMe SSD slots, plus option for a third drive for the OS</li>
<li>passively cooled and completely silent</li>
<li>compact size</li>
<li>gigabit Ethernet or better</li>
</ul>
<p>You might be thinking, “<em>Wait, that’s your <strong>dream setup</strong>? No clusters of machines, Threadrippers, 10 Gigabit networking, crazy number of disks?</em>”.
Well, yes. After years of trying all sorts of setups and learning about my home server usage patterns, this is the set of requirements that finds a balance between performance, efficiency
and silence.</p>
<h3 id="basics">Basics</h3>
<p>I recommend checking <a href="https://www.zimaboard.com/zimaboard/product">the product page</a> to see the exact specifications.
The configuration I bought was the 832 model: 8GB of RAM, 32GB of eMMC storage and a quad-core Intel Celeron N3450 CPU.
It’s not the most powerful setup or even a recent one with the CPU being from 2016, but it’s just powerful enough to fit
my needs.</p>
<p>This variant of the board costs 200 USD, but other configurations cost much less
than that, I just needed the extra memory to be on the safe side. If you don’t
care about the noise and size aspect of home servers, then you can get a better
deal on the used market (<a href="https://www.servethehome.com/introducing-project-tinyminimicro-home-lab-revolution/">see the TinyMiniMicro project for inspiration)</a>,
but as you know by this point, I care about those aspects a lot.</p>
<h3 id="the-package">The package</h3>
<p>What sets the Zimaboard apart from other single board computers is how polished the product feels.
Unlike a board like the Raspberry Pi, this one comes with a case and a cooling setup
already attached to it. I suspect that a similarily configured Raspberry Pi 4/5
with all the accessories added on top would result in a price that’s quite
similar to the cost of a top-of-the-line Zimaboard.</p>
<p>The heatsink looks great and is practical at the same time.
Under the most torturous loads I could only see the CPU being around 72°C and due
to it being passively cooled it made absolutely no noise. With the case being
present, I do not have to worry about placing the board on my desk and scratching
the table or shorting something out.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/theboard.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/theboard_hu6c1b6a830bf3d559150de9b4726aa27f_3498380_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
Just plop it wherever.

    </figcaption>
	
</figure>

<p>The board does not seem to have a power button, but by default it’s configured
to power on as soon as you connect the power supply, which is great if you’re
going to use this as a home server.</p>
<p>The box that the board was shipped survived and overall I’d say that the packaging
is good. The board comes with some stickers and a single SATA data+power cable.
The included power adapter comes with EU, US and UK plugs all included.</p>
<p>Shipping to Estonia was quite fast, taking just 10 days. The shipping costs were
18 USD.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/box.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/box_hu76da91a855cec7efe7cc445c706070f2_2144401_1024x0_resize_q80_box.jpg" width="1024" height="768">
    </a>
    
    <figcaption>
      
The box did its job.

    </figcaption>
	
</figure>

<h3 id="storage">Storage</h3>
<p>The included 32GB eMMC storage is fine for hosting your operating system. The
read speeds cap out at around 175 MB/s and the typical write speeds I observed
were around 50-100 MB/s. The storage is identified as <code>mmc-BJTD4R_0xc7d04e40</code> under
<code>/dev/disk/by-id/</code>, and searching online suggests that it’s a Samsung chip.</p>
<p>Because this board offers two SATA ports, I also added a SATA Y-cable to my order
(4 USD) so that I can take my existing Samsung 870 QVO 4TB SATA drives and move
my home server setup to this board.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/ycable.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/ycable_hu274ae1922594f3b973c5b875085287a1_3577750_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
SATA Y-cable in action.

    </figcaption>
	
</figure>

<p>Allegedly this cable can also be used to drive
two 3.5" hard drives powered by the board itself according to <a href="https://shop.zimaboard.com/products/sata-y-cable-for-zimaboard-2-5-inch-hdd-3-5-inch-hdd-raid-free-nas-unraid">the shop page
for the Y-cable</a>, but I suspect that at that point you’ll be pushing the limits of
the 12V/3A power adapter.</p>
<p>There is also a white drive activity LED
placed near the SATA power connector on the board. Perhaps not for everyone, but I
like the aesthetic and the sight of the server doing server things.</p>
<p>The performance of the SATA ports is what you would expect. When performing
read operations on both SSD-s I saw the maximum total transfer rates hover around
900-950MB/s, which is pretty close to the SATA III transfer speed limit.</p>
<p>There is no native way to mount the two SATA drives to the Zimaboard. The creators
of the board do sell a metal bracket, but it doesn’t seem to integrate that well
to the board. However, <a href="https://www.printables.com/model/224057-zimaboard-dual-hdd-stand">there exists a 3D printable design that houses two
2.5" drives, even 15mm ones</a>, and
that’s how I ended up using a 3D printer for the first time in my life.
The print was done using a <a href="https://wiki.k-space.ee/en/utilities/3D-Printer">Voron v2 Afterburner printer hosted at k-space</a>
and it came out pretty well.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-1.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-1_huf70380e185f90e159fc776b2831d9896_3078409_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
Print in progress.

    </figcaption>
	
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-2.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-2_hu752c37d1e17753c6e343ccb4b873a65f_2168377_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
The final product

    </figcaption>
	
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-3.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-3_hu10c2dc0a06747a74e577cc516acca8dd_2202245_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
Another angle.

    </figcaption>
	
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-4.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/3dprint-4_huf319adc4e48cc6a298722bcfb2e7e1c5_2316941_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
Some 3D printing related inconsistencies, but nothing serious.

    </figcaption>
	
</figure>

<p>The SSD mounting holes were a bit finicky due
to slight printing errors, and during my first installation attempt I forgot to
put in the plastic middle layer of the case that’s between the PCB and the stock
bottom cover, but other than that the installation was a breeze.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/board-backside.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/board-backside_hu274ae1922594f3b973c5b875085287a1_3220963_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
Installation of the caddy requires removing the stock backplate and splitting it.

    </figcaption>
	
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-1.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-1_hua9184edc251c38c0f11832201baa618f_2992666_1024x0_resize_q80_box.jpg" width="1024" height="768">
    </a>
    
    <figcaption>
      
The finished result.

    </figcaption>
	
</figure>

<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-2.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-2_hu06f0f4a327e982253f04ee2e79d40f70_1943488_1024x0_resize_q80_box.jpg" width="1024" height="768">
    </a>
    
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-3.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-3_huee34d1e5685f5eec5ce4dd6fd718bd5e_1955399_1024x0_resize_q80_box.jpg" width="1024" height="768">
    </a>
    
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-4.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-4_huc3f76dc845f779b66651336a37be1923_2389369_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-5.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-5_huaae2ce206b36cbc8496a7ca6fb8df953_2182946_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-6.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-6_hu274ae1922594f3b973c5b875085287a1_2559258_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-7.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/caddy-7_hu6005690906979ff4f13657485fce192e_1574253_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
</figure>

<p>The drives never hit above 64°C, which is absolutely okay for these SSD-s. I’m not
sure how actual spinning hard drives might fare in this environment, but I don’t
think that it’s going to be that serious because 2.5" hard drives should not
generate as much heat in the first place.</p>
<h3 id="power-consumption">Power consumption</h3>
<p>What I love about this board is the power usage. At this point my home server
is not even the most power hungry component of my setup, that honor now goes
to the ISP-provided router/modem combo box that always draws at least 12W, even
when it’s in bridge mode.</p>
<p>Here are my power usage measurements (measured with a simple power meter):</p>
<ul>
<li>idle: 2.5W</li>
<li>no drives attached, CPU stress test (<code>stress -c 4</code>): 9.0W</li>
<li>one Samsung 870 QVO 4TB SSD attached, CPU stress test: 13.2W</li>
<li>2 SSD-s attached, typical power draw in my setup (~10-40% CPU usage): ~8-9W</li>
<li>2 SSD-s attached, max load on SSD-s and CPU: ~14W</li>
</ul>
<p>The Zimaboard, ISP modem/router box, my TP-Link router/Wi-Fi AP and my CyberPower
UPS all together use at most around 34W, all combined. That’s even less than
what my Dell monitor uses at reasonably low brightness levels!</p>
<p>These tests are not scientifically accurate, but they should give you an idea on what
power consumption numbers to expect when running this setup.</p>
<h3 id="performance">Performance</h3>
<p>I use a simple Prometheus Node Exporter + Grafana setup to view how much resources
my various servers use. My home server has lately either been an <a href="https://ounapuu.ee/2022/01/17/asrock-x300-future-of-desktops/">ASRock Deskmini X300 based setup</a> or
an <a href="https://ounapuu.ee/posts/2022/05/10/thinkpad-as-a-home-server/">old ThinkPad T430</a>, and something that both had in common was that the CPU usage was
generally very low, mostly at or below the 10% mark. There would be bursty loads
from time to time and backup processes running that bump that up, but not significantly.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/prom-old.png">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/prom-old_huea11d161badcce588cbed615ac1c56a1_132285_1024x0_resize_q80_box_3.png" width="1024" height="539">
    </a>
    
    <figcaption>
      
Typical CPU performance on a ThinkPad T430 acting as a home server.

    </figcaption>
	
</figure>

<p>Memory usage of my setup was also quite low, with all my services and containers
fitting into 2GB during typical usage. With this information and some CPU performance
comparisons done, I knew that the Zimaboard will likely be able to handle my home
server tasks.</p>
<p>This board is not very powerful, but if you mainly rely on containerized workloads
and can rely on Intel QuickSync to accelerate media transcodes, then you’ll be
just fine.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/prom-new.png">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/prom-new_hu9c391d9431a1ac152a2c6a20c90ec904_336307_1024x0_resize_q80_box_3.png" width="1024" height="539">
    </a>
    
    <figcaption>
      
Zimaboard CPU usage, which includes migrating filesystems, creating new multi-TB
backups from scratch and a lot of Jellyfin playback and GPU-accelerated transcoding.
Pretty much the worst case scenario for this board.

    </figcaption>
	
</figure>

<p>I was actually impressed with how well the GPU-accelerated transcode
worked on this machine once you set everything up properly.
If you’re running Linux and Jellyfin,
run <code>vainfo</code> to get a list of supported codecs and make sure that you have hardware
decoding selected for those in Jellyfin settings. Also enable hardware encoding.
I checked with <code>intel_gpu_top</code> to see if work was offloaded to the GPU and saw
activity there, which means that hardware acceleration for Jellyfin worked out great!
<a href="https://jellyfin.org/docs/general/administration/hardware-acceleration/">Check the Jellyfin hardware acceleration for more details on other requirements
that have to be met for all of this to work.</a></p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/jellyfin-qs-conf.png">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/jellyfin-qs-conf_hu43c0581b909067652f5756f1f94a087a_121374_1024x0_resize_q80_box_3.png" width="1024" height="1146">
    </a>
    
    <figcaption>
      
The Jellyfin QuickSync hardware acceleration config that works on my Zimaboard.
May not be 100% correct but so far have not encountered issues.

    </figcaption>
	
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/intel-gpu-top.png">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/intel-gpu-top_huea9f3ca46683dfd1ed036b99d4cb02af_34076_1024x0_resize_q80_box_3.png" width="1024" height="163">
    </a>
    
    <figcaption>
      
intel_gpu_top during Jellyfin transcoded media playback. 

    </figcaption>
	
</figure>

<h3 id="caveats">Caveats</h3>
<p>The Zimaboard does ship with a Linux-based OS called CasaOS. However, I had no
intention of using it as I know what my requirements are and my infrastructure
is already decently documented and set up via Ansible, which is why I can’t say
how good that experience is. I also did not test Windows 10 or 11.</p>
<p>During testing, I noticed that the USB 3 ports can act a bit weird. The Fedora
Server USB stick would not boot properly if connected to one of the USB ports,
and when doing other tests with external USB storage I noticed hiccups from time to time.
Not sure what might be the cause, but I’m writing it down nevertheless. It’s not
a dealbreaker for me luckily since I don’t rely much on the USB ports in typical use anyway.</p>
<p>I did not test the PCI Express port, simply because I don’t need it, yet. It’s
a great addition, though, and opens up plenty of modding capabilities in the
future.</p>
<h3 id="fedora-server-and-btrfs">Fedora Server and btrfs</h3>
<p>The Zimaboard gave me an opportunity to start fresh with my home server.</p>
<p>I made a leap: I’ve ditched ZFS and am now running
Fedora Server with my storage being on a btrfs RAID1 setup, snapshotted
and backed up using <a href="https://ounapuu.ee/posts/2022/07/09/btrbk-is-awesome/">btrbk</a>.
It was a bit tricky to migrate and set everything
up regarding backups and snapshotting, but I got it working.</p>
<p>ZFS is great, but it has always felt like an unwanted guest in the Linux ecosystem.
The kernel developers don’t care much for maintaining compatibility with ZFS since
it’s not in the kernel due to licensing issues, and Ubuntu has been one of the few
distros that actually ships a kernel that includes ZFS built in. I didn’t want
to be tied to Ubuntu forever, especially because of how they try to make <code>snap</code>
a thing. ZFS DKMS builds are generally okay on distros like Debian, but on
others you might find yourself not being able to access your data after a reboot
because of a kernel update.</p>
<p>btrfs has had some issues in the past, especially with the RAID5/6 setup, but
in my single and dual disk setups it has been solid for years, except for that one time around
2018-2019 when I ran btrfs RAID1 over USB storage. To be fair to btrfs, that
was a pretty stupid setup.</p>
<p>Before committing
to btrfs, I used two USB sticks to create a RAID1 setup and created real torture test scenarios.
Tests looked something like this:</p>
<ul>
<li>write a file to the filesystem</li>
<li>use <code>md5sum</code> to calculate a hash of it for verification purposes</li>
<li>completely wipe one USB drive with <code>dd</code></li>
<li>run <code>md5sum</code> to calculate the hash again (it matched every time)</li>
<li>run <code>btrfs scrub</code> on the filesystem to fix all errors</li>
<li>rinse and repeat with variations to this setup</li>
</ul>
<p>After doing all that, I was quite confident that this was going to work.</p>
<p>One thing to note with <code>btrfs</code>: if you’re running any type of multi-disk and
redundant setup like RAID1 or RAID10, then make sure to include the mount option
<code>degraded</code> in <code>/etc/fstab</code> so that you can still mount your filesystem if one or
more of your drives fail. If you lose too many drives then it’s still probably going to fail to boot.</p>
<p>Here’s my <code>/etc/fstab</code> setup to serve as an example:</p>
<pre tabindex="0"><code>LABEL=turbo /turbo      btrfs subvol=turbo,compress-force=zstd:1,ssd,degraded,nofail            0 0
</code></pre><p>When doing the migration I kept all the paths the same, and each ZFS dataset
was recreated using <code>btrfs</code> subvolumes, which is why this filesystem is mounted on a top-level folder.</p>
<h3 id="alternatives">Alternatives</h3>
<p>My notes for the next dream home server setup included a few candidates:</p>
<ul>
<li>the Zimaboard</li>
<li><a href="https://www.asustor.com/en/product?p_id=79">Asustor Flashstor 6</a> or <a href="https://www.asustor.com/en/product?p_id=80">Flashstor 12</a></li>
<li>a TinyMiniMicro style machine with at least two NVMe SSD slots</li>
</ul>
<p>The first two fall nicely into my requirements for the dream home server. I picked
the Zimaboard mainly because it’s much cheaper and I was already running two SATA SSD-s
for my home server storage, so migrating would be really easy and I would not
have to buy any new drives.</p>
<p>If large capacity SATA SSD-s start becoming less common and NVMe SSD-s become
even cheaper than they already are, then I’ll have to look into something like a Flashstor.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Overall, I’m very happy with this purchase. The performance is just enough for
my services to work reasonably fast, the board uses very little power and it’s
silent, and it looks good on my wall.</p>






  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/wallsetup.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/wallsetup_hu147012bd2854d1f9428512f78d118e50_2529969_1024x0_resize_q80_box.jpg" width="1024" height="1365">
    </a>
    
    <figcaption>
      
Oh it's a setup it's a setup it's a setup 🎶

    </figcaption>
	
</figure>







  




<figure>
    <a href="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/cablegore.jpg">
	<img src="https://ounapuu.ee/posts/2023/10/09/zimaboard/media/cablegore_hu31ef052dce3896a81eccf0b787f8cd55_2097261_1024x0_resize_q80_box.jpg" width="1024" height="768">
    </a>
    
    <figcaption>
      
Managing the coax cable like this feels so wrong, and yet it works fine.

    </figcaption>
	
</figure>

<p>My setup is also quite flexible, so in case I need more resources, I can get
more Zimaboards and make them serve different purposes. However, it’s more likely
that I’m going to discover a new toy to experiment and play with by the time
I run out of resources on this one.</p>

<p>If you’re not a spammer,
<a href="mailto:ihavesomethoughtsonyourblog@ounapuu.ee">just send me an e-mail!</a></p>
<p>Places where you can discuss this post:</p>
<ul>
<li><a href="https://news.ycombinator.com/item?id=37819114">Hacker News</a></li>
<li><a href="https://www.linkedin.com/posts/%F0%9F%94%A5-herman-%C3%B5unapuu-600516152_zimaboard-the-closest-thing-to-my-dream-activity-7117104232809345024-p4iP">LinkedIn</a></li>
<li><a href="https://forum.level1techs.com/t/hddhermans-blog/180788/36?u=hddherman">Level1Techs forum</a></li>
</ul>

    </div></div>]]></description>
        </item>
    </channel>
</rss>