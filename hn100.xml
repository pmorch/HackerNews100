<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 03 Dec 2023 16:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[OpenAI Committed to Buying $51M of AI Chips from a Startup Backed by Sam Altman (188 pts)]]></title>
            <link>https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/</link>
            <guid>38506660</guid>
            <pubDate>Sun, 03 Dec 2023 12:42:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/">https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/</a>, See on <a href="https://news.ycombinator.com/item?id=38506660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Sam Altman was reinstated soon after being <a href="https://www.wired.com/story/sam-altman-officially-returns-to-openai-board-seat-microsoft/">fired as OpenAI CEO</a> last month, but still stood to gain had the company continued to develop <a href="https://www.wired.com/tag/chatgpt/">ChatGPT</a> without him. During Altman’s tenure as CEO, OpenAI signed a letter of intent to spend $51 million on AI chips from a startup called Rain AI into which he has also invested personally.</p><p>Rain is based less than a mile from OpenAI’s headquarters in San Francisco and is working on a chip it calls a <a href="https://www.technologyreview.com/2013/12/16/174934/thinking-in-silicon/">neuromorphic</a> processing unit, or NPU, designed to <a data-offer-url="https://johnkoetsier.com/artificial-brain-neuromorphic-chip/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://johnkoetsier.com/artificial-brain-neuromorphic-chip/&quot;}" href="https://johnkoetsier.com/artificial-brain-neuromorphic-chip/" rel="nofollow noopener" target="_blank">replicate features of the human brain</a>. OpenAI in 2019 signed a nonbinding agreement to spend $51 million on the chips when they became available, according to a copy of the deal and Rain disclosures to investors this year seen by WIRED. Rain told investors Altman had personally invested more than $1 million into the company. The letter of intent has not been previously reported.</p><p>The investor documents said that Rain could get its first hardware to customers as early as October next year. OpenAI and Rain declined to comment.</p><div><p>OpenAI’s letter of intent with Rain shows how Altman’s web of personal investments can entangle with his duties as OpenAI CEO. His prior position leading startup incubator Y Combinator helped Altman become one of Silicon Valley’s most prominent dealmakers, investing in dozens of startups and acting as a broker between entrepreneurs and the world’s biggest companies. But the distraction and intermingling of his myriad pursuits played some role in his recent <a href="https://www.wired.com/story/openai-ceo-sam-altman-is-out-after-losing-confidence-of-board/">firing</a> by OpenAI’s board for uncandid communications, according to people involved in the situation but not authorized to discuss it.</p><p>The Rain deal also underscores OpenAI’s willingness to spend large sums to secure supplies of chips needed to underpin pioneering AI projects. Altman has complained publicly of a <a href="https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded">“brutal crunch”</a> for AI chips and their <a data-offer-url="https://twitter.com/sama/status/1599669571795185665" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://twitter.com/sama/status/1599669571795185665&quot;}" href="https://twitter.com/sama/status/1599669571795185665" rel="nofollow noopener" target="_blank">“eye-watering”</a> costs. OpenAI taps the powerful cloud of Microsoft, <a href="https://www.wired.com/story/microsoft-emerges-as-the-winner-in-openai-chaos/">its primary investor</a>, but has regularly shut off access to features of ChatGPT due to hardware constraints. According to a blog post about a closed door meeting he held with developers, Altman <a href="https://finance.yahoo.com/news/blog-post-detailed-sam-altman-142219663.html">has said</a> the pace of AI progress may be dependent on new chip designs and supply chains.</p></div><p>Rain touted its progress to potential investors earlier this year, projecting that as soon as this month it could “tape out” a test chip, a standard milestone in chip development referring to a design ready for fabrication. But the startup also has recently reshuffled its leadership and investors after reportedly an interagency US government body that polices investments for national security risks mandated Saudi Arabia-affiliated fund Prosperity7 Ventures to sell its stake in the company. The fund led a $25 million fundraise <a data-offer-url="https://www.aramco.com/en/news-media/news/2022/aramco-announces-prosperity7-ventures" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.aramco.com/en/news-media/news/2022/aramco-announces-prosperity7-ventures&quot;}" href="https://www.aramco.com/en/news-media/news/2022/aramco-announces-prosperity7-ventures" rel="nofollow noopener" target="_blank">announced</a> by Rain in early 2022.</p><p>The forced removal of the fund, first <a href="https://www.bloomberg.com/news/articles/2023-11-30/us-compels-saudi-fund-to-exit-ai-chip-startup-backed-by-altman">reported by Bloomberg</a> Thursday and described in the documents seen by WIRED, could add to Rain’s challenges of bringing a novel chip technology to market, potentially delaying the day OpenAI can make good on its $51 million advance order. Silicon Valley-based <a data-offer-url="https://www.grepvc.com/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.grepvc.com/&quot;}" href="https://www.grepvc.com/" rel="nofollow noopener" target="_blank">Grep VC</a> acquired the shares; it and the Saudi fund did not respond to requests for comment.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>US concern about Prosperity7’s deal with Rain also raises questions about another effort by Altman to increase the world’s supply of AI chips. He’s talked to investors in the Middle East in recent months about raising money to start a new chip company to help OpenAI and others diversify beyond their current reliance on Nvidia GPUs and specialized chips from Google, Amazon, and a few smaller suppliers, according to two people seeking anonymity to discuss private talks.</p><p>Brain Trust</p><p>Rain, founded in 2017, has claimed that its brain-inspired NPUs will yield potentially 100 times more computing power and, for training, <a href="https://www.linkedin.com/posts/gordonhirschwilson_activity-difference-training-of-deep-neural-activity-7000595097717260288-pF04/">10,000 times</a> greater energy efficiency than GPUs, the graphics chips that are the workhorses for AI developers such as OpenAI and primarily sourced from Nvidia.</p><p>Altman led one of Rain’s seed financings in 2018, the company has said, the year before OpenAI committed to spend $51 million on its chips. Rain now has about 40 employees, including experts in both development of AI algorithms and traditional chip design, according the disclosures.</p><p>The startup appears to have quietly changed its CEO this year and now lists founding CEO Gordon Wilson as executive advisor on its website, with former white-shoe law firm attorney William Passo gaining a promotion to CEO from COO.</p><p>Wilson confirmed his exit in <a href="https://www.linkedin.com/feed/update/urn:li:activity:7135990941244411904/">a LinkedIn post</a> Thursday, but did not provide a reason. “Rain is poised to build a product that will define new AI chip markets and massively disrupt existing ones,” he wrote. “Moving forward I will continue to help Rain in every way I can.” Over 400 LinkedIn users including some whose profiles say they are Rain employees commented on Wilson's post or reacted to it with heart or thumbs up emojis—Passo wasn't among them. Wilson declined to comment for this story.</p><p>The company will search for an industry veteran to permanently replace Wilson, according to an October note to investors seen by WIRED.</p><p>Rain’s initial chips <a data-offer-url="https://rain.ai/approach" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://rain.ai/approach&quot;}" href="https://rain.ai/approach" rel="nofollow noopener" target="_blank">are based</a> on the <a href="https://www.wired.com/story/using-open-source-designs-to-create-more-specialized-chips/">RISC-V open-source architecture</a> endorsed by Google, Qualcomm, and other tech companies and aimed at what the tech industry calls edge devices, located far from data centers, such as phones, drones, cars, and robots. Rain aims to provide a chip capable of both training machine algorithms and running them once they’re ready for deployment. Most edge chip designs today, like <a href="https://www.wired.com/story/how-apple-makes-ai-chip-powering-iphones-fancy-tricks/">those found in smartphones</a>, focus on the latter, known as inference. How OpenAI would use Rain chips could not be learned.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Rain at one point has claimed to investors that it has held advanced talks to sell systems to Google, Oracle, Meta, Microsoft, and Amazon. Microsoft declined to comment, and the other companies did not respond to requests for comment.</p><p>Security Fears</p><p>The funding round led by Prosperity7 announced last year brought Rain’s total funding to $33 million as of April 2022. That was enough to operate through early 2025 and valued the company at $90 million excluding the new cash raised, according to the disclosures to investors. The documents cited Altman’s personal investment and Rain’s letter of intent with OpenAI as reasons to back the company.</p><p>In a Rain <a data-offer-url="https://www.einnews.com/pr_news/562154507/rain-neuromorphics-raises-25m-series-a-to-transform-ai-hardware-landscape" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.einnews.com/pr_news/562154507/rain-neuromorphics-raises-25m-series-a-to-transform-ai-hardware-landscape&quot;}" href="https://www.einnews.com/pr_news/562154507/rain-neuromorphics-raises-25m-series-a-to-transform-ai-hardware-landscape" rel="nofollow noopener" target="_blank">press release</a> for the fundraise last year, Altman applauded the startup for <a data-offer-url="https://www.eetimes.com/rain-neuromorphics-tapes-out-demo-chip-for-analog-ai/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.eetimes.com/rain-neuromorphics-tapes-out-demo-chip-for-analog-ai/&quot;}" href="https://www.eetimes.com/rain-neuromorphics-tapes-out-demo-chip-for-analog-ai/" rel="nofollow noopener" target="_blank">taping out a prototype in 2021</a> and said it “could vastly reduce the costs of creating powerful AI models and will hopefully one day help to enable true artificial general intelligence.”</p><p>Prosperity7’s investment in Rain drew the interest of the interagency Committee on Foreign Investment in the United States, which has the power to scuttle deals deemed to threaten national security.</p><p>CFIUS, as the committee is known, has long been concerned about China gaining access to advanced US semiconductors, and has grown increasingly <a href="https://www.ft.com/content/2a636cee-b0d2-45c2-a815-11ca32371763">worried about China using intermediaries in the Middle East</a> to quietly learn more about critical technology, says Nevena Simidjiyska, a partner at the law firm Fox Rothschild who helps clients with CFIUS reviews. “The government doesn’t care about the money,” she says. “It cares about access and control and the power of the foreign party.”</p><p>Rain received a small seed investment from the venture unit of Chinese search engine Baidu apparently without problems but the larger Saudi investment attracted significant concerns. Prosperity7, a unit of Aramco Ventures, which is part of state-owned Saudi Aramco, possibly could have let the oil giant and other large companies in the Middle East to become customers but also put Rain into close contact with the Saudi government.</p><p>Megan Apper, a spokesperson for CFIUS, says the panel is “committed to taking all necessary actions within its authority to safeguard U.S. national security” but that “consistent with law and practice, CFIUS does not publicly comment on transactions that it may or may not be reviewing.”</p><p>Data disclosed by CFIUS shows it <a data-offer-url="https://home.treasury.gov/system/files/206/CFIUS%20-%20Annual%20Report%20to%20Congress%20CY%202022_0.pdf" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://home.treasury.gov/system/files/206/CFIUS%20-%20Annual%20Report%20to%20Congress%20CY%202022_0.pdf&quot;}" href="https://home.treasury.gov/system/files/206/CFIUS%20-%20Annual%20Report%20to%20Congress%20CY%202022_0.pdf" rel="nofollow noopener" target="_blank">reviews hundreds of deals</a> annually and in the few cases where it has concerns typically works out safeguards, such as barring a foreign investor from taking a board seat. It couldn’t be learned why the committee required full divestment from Rain.</p><p>Three attorneys who regularly work on sensitive deals say they could not recall any previous Saudi Arabian deals fully blocked by CFIUS. “Divestment itself has been quite rare over the past 20 years and has largely been a remedy reserved for Chinese investors,” says Luciano Racco, cochair of the international trade and national security practice at law firm Foley Hoag.</p><p>OpenAI likely needs to find partners with deep-pocketed backers if it is to gain some control over its hardware needs. Competitors Amazon and Google have spent years developing their <a href="https://www.wired.com/story/new-amazon-chips-cloud-computing/">own</a> <a href="https://www.wired.com/story/fit-billions-transistors-chip-let-ai-do/">custom chips</a> for AI projects and can fund them with revenue from their lucrative core businesses. Altman <a href="https://www.businessinsider.com/sam-altman-says-cant-rule-out-openai-making-own-chips-2023-10">has refused to rule out</a> OpenAI making its own chips, but that too would require significant funding.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text (115 pts)]]></title>
            <link>https://arxiv.org/abs/2311.18805</link>
            <guid>38506140</guid>
            <pubDate>Sun, 03 Dec 2023 10:48:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.18805">https://arxiv.org/abs/2311.18805</a>, See on <a href="https://news.ycombinator.com/item?id=38506140">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.18805.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear. In this study, we present novel experimental insights into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations. To investigate this, we first propose the Scrambled Bench, a suite designed to measure the capacity of LLMs to handle scrambled input, in terms of both recovering scrambled sentences and answering questions given scrambled context. The experimental results indicate that most powerful LLMs demonstrate the capability akin to typoglycemia, a phenomenon where humans can understand the meaning of words even when the letters within those words are scrambled, as long as the first and last letters remain in place. More surprisingly, we found that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even under the extreme condition, a task that poses significant challenges for other LLMs and often even for humans. Specifically, GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by 95%, even when all letters within each word are entirely scrambled. It is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Qi Cao [<a href="https://arxiv.org/show-email/8edf2a0c/2311.18805">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 30 Nov 2023 18:51:38 UTC (246 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Mobile Tools suite to be acquired by Israeli adware company (127 pts)]]></title>
            <link>https://github.com/SimpleMobileTools/General-Discussion/issues/241</link>
            <guid>38505229</guid>
            <pubDate>Sun, 03 Dec 2023 06:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SimpleMobileTools/General-Discussion/issues/241">https://github.com/SimpleMobileTools/General-Discussion/issues/241</a>, See on <a href="https://news.ycombinator.com/item?id=38505229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <blockquote>
<p dir="auto">not really, thats not how it works</p>
</blockquote>
<p dir="auto">First of all, lemme prepend this by saying that I Am Not A Lawyer, meaning I may miss a detail and be wrong.</p>
<p dir="auto">I have looked around and I was not able to find a CLA or similar, meaning that any contributions to this project has not resulted in any of the contributors waving their rights to the legal owner of the project. Though, if there was indeed a CLA to sign before contributing and it stated that you waved your rights, then the following paragraphs won't be true.</p>
<p dir="auto">Once the sale is complete, if zipoapps decides to go closed source <em>and</em> keep the external contributions, any contributors will have the ability to claim license infringement and ask zipoapps to comply under the terms of the license: either by removing every of your contributions (depending on how big of a contributor you are this might be a big blow to them), or by forcing them to keep the project open-source as defined by the GPLv3 license.</p>
<p dir="auto">If zipoapps do make those apps closed source, and you're a contributor for whom it is uncomfortable, I'd recommend to consult a lawyer first to inform yourself of what you can do and the proper steps to take.<br>
Though, there's also the question of is it worth it to go after them? Maybe energy is better spent working on the fork, given who this project panders to, I don't think zipoapps will inherit much of the userbase if they go down the bad road.</p>
<p dir="auto">While I am mostly an external observer in this story, I wish a good continuation to the original author of this project, I can see how bailing out can become a desirable option when things get bad. I do find it weird it has been chosen to sell the project instead of giving it to another maintainer who could have continued the project's legacy. I guess there's some personal things that pushed to the sale, so I wouldn't hold it too much against the author. I also wish a good continuation to the fork as well.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new approach to domain ranking (149 pts)]]></title>
            <link>https://www.marginalia.nu/log/73-new-approach-to-ranking/</link>
            <guid>38504565</guid>
            <pubDate>Sun, 03 Dec 2023 03:34:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marginalia.nu/log/73-new-approach-to-ranking/">https://www.marginalia.nu/log/73-new-approach-to-ranking/</a>, See on <a href="https://news.ycombinator.com/item?id=38504565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>This is a very brief post announcing a fascinating discovery.</p><p>It appears to be possible to use the cosine similarity approach powering explore2.marginalia.nu as a substitute for the link graph in an eigenvector-based ranking algorithm (i.e. PageRank).</p><p>The original PageRank algorithm can be conceptualized as a simulation of where a random visitor would end up if they randomly clicked links on websites. With this model in mind, the modification replaces the link-clicking with using explore2 for navigation.</p><p>The performance of PageRank has been deteriorating for decades and it’s to a point where it barely is applicable for domain ranking anymore in part due to changes in how websites link to each other, but also a battery of well documented techniques for manipulating the algorithm in order to gain an unfair advantage. You may get decent results at the very top especially with personalized pagerank, but you don’t have to scroll particularly far down in the ranking to find spam earning a conspicuously high ranking using a vanilla pagerank approach.</p><p>This new approach seems remarkably resistant to existing pagerank manipulation techniques. Given a preference-vector, it stays “on topic” remarkably well.</p><ul><li><a href="https://www.marginalia.nu/domains/">Explore Sample Data</a></li></ul><h2 id="see-also">See Also</h2><ul><li><a href="https://www.marginalia.nu/log/69-creepy-website-similarity.gmi">/log/69-creepy-website-similarity.gmi</a></li><li><a href="https://www.marginalia.nu/log/20-dot-com-link-farms.gmi">/log/20-dot-com-link-farms.gmi</a></li><li><a href="https://www.marginalia.nu/log/04-link-farms.gmi">/log/04-link-farms.gmi</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Clang now makes binaries an original Pi B+ can't run (258 pts)]]></title>
            <link>https://rachelbythebay.com/w/2023/11/30/armv6/</link>
            <guid>38504134</guid>
            <pubDate>Sun, 03 Dec 2023 02:07:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2023/11/30/armv6/">https://rachelbythebay.com/w/2023/11/30/armv6/</a>, See on <a href="https://news.ycombinator.com/item?id=38504134">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2023/11/30/armv6/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[UniFi Express (191 pts)]]></title>
            <link>https://ui.com/cloud-gateways/express</link>
            <guid>38504027</guid>
            <pubDate>Sun, 03 Dec 2023 01:44:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ui.com/cloud-gateways/express">https://ui.com/cloud-gateways/express</a>, See on <a href="https://news.ycombinator.com/item?id=38504027">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Not a real engineer (2019) (270 pts)]]></title>
            <link>https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html</link>
            <guid>38503486</guid>
            <pubDate>Sun, 03 Dec 2023 00:05:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html">https://twitchard.github.io/posts/2019-05-29-not-a-real-engineer.html</a>, See on <a href="https://news.ycombinator.com/item?id=38503486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
            <article>
    
    <section>
        <p>You are not a real engineer.</p>
<p>You are a creature with a terrible countenance</p>
<p>the stature of a man</p>
<p>and the head of a lion</p>
<p>with sixteen wings about you</p>
<p>white as fresh snow</p>
<p>hundreds of eyes</p>
<p>that flicker like torches</p>
<p>and dart in all directions</p>
<p>the belt at your waist is a serpent</p>
<p>your breath is the gathering of stormclouds</p>
<p>your voice is the roar of the wind</p>
<p>the grass withers before your footsteps</p>
<p>and your writhing, ponderous tongue</p>
<p>black as the abyss</p>
<p>brings apocalypse upon everything it touches</p>

<p>We regret to inform you</p>
<p>we will not be offering you the role at this time –</p>
<p>we’re looking for somebody more technical</p>
    <hr>

    
    </section>
</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can't sign in with FIDO2 key on office.com (157 pts)]]></title>
            <link>https://bugzilla.mozilla.org/show_bug.cgi?id=1824831</link>
            <guid>38502340</guid>
            <pubDate>Sat, 02 Dec 2023 21:45:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1824831">https://bugzilla.mozilla.org/show_bug.cgi?id=1824831</a>, See on <a href="https://news.ycombinator.com/item?id=38502340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">

 


<main id="bugzilla-body" tabindex="-1">



<div id="main-inner">










<div id="summary-container">


  
    <p><span id="field-value-status_summary">
      <span data-status="open">Open</span>
      <span id="field-value-bug_id">
        <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1824831">Bug 1824831</a>
      </span>
      <span>
        <span>Opened <span title="2023-03-27 12:53 PDT" data-time="1679946799">8 months ago</span></span>
          <span>Updated <span title="2023-12-02 13:43 PST" data-time="1701553423">1 hour ago</span></span>
      </span>
        </span>
    </p>

  
</div>








































<meta name="firefox-versions" content="{&quot;FIREFOX_AURORA&quot;:&quot;&quot;,&quot;FIREFOX_DEVEDITION&quot;:&quot;121.0b6&quot;,&quot;FIREFOX_ESR&quot;:&quot;115.5.0esr&quot;,&quot;FIREFOX_ESR_NEXT&quot;:&quot;&quot;,&quot;FIREFOX_NIGHTLY&quot;:&quot;122.0a1&quot;,&quot;LAST_MERGE_DATE&quot;:&quot;2023-11-20&quot;,&quot;LAST_RELEASE_DATE&quot;:&quot;2023-11-21&quot;,&quot;LAST_SOFTFREEZE_DATE&quot;:&quot;2023-11-16&quot;,&quot;LAST_STRINGFREEZE_DATE&quot;:&quot;2023-11-17&quot;,&quot;LATEST_FIREFOX_DEVEL_VERSION&quot;:&quot;121.0b6&quot;,&quot;LATEST_FIREFOX_OLDER_VERSION&quot;:&quot;3.6.28&quot;,&quot;LATEST_FIREFOX_RELEASED_DEVEL_VERSION&quot;:&quot;121.0b6&quot;,&quot;LATEST_FIREFOX_VERSION&quot;:&quot;120.0.1&quot;,&quot;NEXT_MERGE_DATE&quot;:&quot;2023-12-18&quot;,&quot;NEXT_RELEASE_DATE&quot;:&quot;2023-12-19&quot;,&quot;NEXT_SOFTFREEZE_DATE&quot;:&quot;2023-12-14&quot;,&quot;NEXT_STRINGFREEZE_DATE&quot;:&quot;2023-12-15&quot;}">



<div id="c0">

  <div id="ct-0" data-comment-id="16345428" data-ismarkdown="true"><p>+++ This bug was initially created as a clone of <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1820016" title="RESOLVED FIXED - Cannot assert discoverable credential on login.live.com">Bug #1820016</a> +++</p>
<p>Since #1820016 is fixed, I am able to log in on live.com using my FIDO2 security key.</p>
<p>However, on office.com I still am unable to do so (using a different business/paid account which works when using Chrome).</p>
</div><div><p>Flags: needinfo?(tim.cappalli)</p></div></div><div id="c1"><p>This is not a Firefox issue. A fix for AAD accounts on the Microsoft side is being worked on.</p><div><p>Flags: <span>needinfo?(tim.cappalli)</span></p></div></div><div id="c2"><p>Any chance to follow the progress as an outsider?</p></div><div id="c5"><div id="ct-5" data-comment-id="16370318" data-ismarkdown="true"><p>The severity field is not set for this bug.<br>
:jschanck, could you have a look please?</p>
<p>For more information, please visit <a href="https://wiki.mozilla.org/Release_Management/autonag#workflow.2Fno_severity.py" rel="nofollow">auto_nag documentation</a>.</p>
</div><div><p>Flags: needinfo?(jschanck)</p></div></div><div id="c6" data-comment-id="16443788" data-ismarkdown="true"><p>With Firefox 114.0 on Linux, I am able to log into by business account using a YubiKey on office.com. However, only when in private browsing mode of my day-to-day-profile. Using regular mode or a totally fresh profile (private or regular browsing mode), it does not work either ("We had a problem authenticating you. Please try again.").</p>
<p>Any chance to get an update here? It feels like this is really close to be usable.</p>
</div><div id="c7"><p>My understanding is that office.com is a weird exception because it can use the live.com personal account login flow for business accounts too. office.com works for me too, but I wouldn't say that's an indication of usability. I believe the AAD login flow fix by MSFT is still needed.</p></div><div id="a6993396_689878"><p>Severity: -- → S3</p><p>Flags: <span>needinfo?(jschanck)</span></p><p>Priority: -- → P5</p></div><div id="c9"><p>Is this still an issue, Rahul?</p><div><p>Flags: needinfo?(sergeantsagara)</p></div></div><div id="c10">

  <div id="ct-10" data-comment-id="16691323" data-ismarkdown="true"><p>Hi John,</p>
<p>Unfortunately, it is. Sharing a screenshot to demonstrate. Our company is working internally to push Microsoft to resolve this (it's not an issue with Firefox's implementation. This can be demonstrated by spoofing the useragent as a Chromium-based browser and attempting the same login flow or just using webauthn.io for validation testing). We unfortunately are not having much luck on our end with our support requests. If possible though, I would like to leave this issue open here for both Firefox users and Microsoft's reference.</p>
<p>Thanks,</p>
<p>Rahul Rameshbabu</p>
</div><div><p>Flags: <span>needinfo?(sergeantsagara)</span></p></div></div><div id="c11"><p>I can confirm, still an issue. M$ at its best. :/</p></div>



</div> 
</main> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Retinal cells that help stabilize our world view (109 pts)]]></title>
            <link>https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/</link>
            <guid>38501878</guid>
            <pubDate>Sat, 02 Dec 2023 20:44:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/">https://optometry.berkeley.edu/berkeley-scientists-discover-retinal-cells-that-help-stabilize-our-world-view/</a>, See on <a href="https://news.ycombinator.com/item?id=38501878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
  <div>
      <figure>
        <img width="1010" height="540" src="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery.png" alt="Human Retina" decoding="async" srcset="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery.png 1010w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-300x160.png 300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-768x411.png 768w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-290x155.png 290w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-400x214.png 400w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Human_RGCs_press-copy_Puthussery-684x366.png 684w" sizes="(max-width: 1010px) 100vw, 1010px">                </figure>
    </div>
 
  
<p>The discovery will enable researchers to better understand eye movement disorders that cause significant visual impairment.</p>

<p><em>Article by <a href="https://vision.berkeley.edu/people/emily-ward/">Emily L Ward</a></em></p>

<p><span>H</span>erbert Wertheim School of Optometry &amp; Vision Science researchers have discovered rare neurons in the eye that are crucial for  our visual system to maintain a sharp, steady image of the world. These findings will impact our understanding of the human retina and likely provide insights into the pathology of eye movement disorders.</p>
<p>The study, recently published in <em>Nature</em>, was led by Teresa Puthussery, OD, PhD, an assistant professor at the Herbert Wertheim School of Optometry &amp; Vision Science and the <a href="https://neuroscience.berkeley.edu/">Helen Wills Neuroscience Institute</a>. First author, Anna Yao Mei Wang, PhD, is a postdoctoral scholar in <a href="https://www.retinalab.berkeley.edu/">The Puthussery Lab</a>. </p>

<h2>Gaze Stabilization in a Moving World</h2>
<p>The neurons identified are involved in a fundamental feature of everyday vision. As one walks down a busy street or looks out the window of a train, the gaze stabilization system operates below our conscious awareness causing the eyes to reflexively follow the direction in which the visual scene is moving. This visual mechanism works in concert with the vestibular system to maintain a sharp image of a moving world. Clinical conditions that interfere with gaze stabilization can therefore lead to significant visual impairment.</p>
<p>The new findings demonstrate for the first time that retinal neurons underlying gaze stabilization in other mammals are also present in primates, including humans. Neurons that send visual signals from the eye to the brain are called retinal ganglion cells. In humans, there are around 20 different retinal ganglion cell types, each of which responds to specific features of the visual scene, such as form, color, and motion (1–3).</p>
<p><img decoding="async" fetchpriority="high" src="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-300x300.jpg" alt="Teresa Puthussery" width="400" height="400" srcset="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-300x300.jpg 300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-1024x1024.jpg 1024w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-150x150.jpg 150w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-768x768.jpg 768w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-1536x1536.jpg 1536w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-2048x2048.jpg 2048w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-1300x1300.jpg 1300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-290x290.jpg 290w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-400x400.jpg 400w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Teresa-Puthuserry_Square-684x684.jpg 684w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p>The researchers discovered a highly-specialized retinal ganglion cell type known as direction-selective ganglion cells (DSGCs). They respond to motion in the visual field by increasing their activity when movement occurs in their “preferred” direction, while showing little activity to motion in the opposite direction. Collectively, responses from these neurons tell the gaze stabilization system which way the visual scene is moving.</p>
<p>“This cell type in particular—the direction-selective ganglion cell—had not been discovered previously in primate despite concerted effort, leading the field to conclude it must not be there,” said Marla Feller, PhD, a distinguished professor at UC Berkeley and an elected member of the National Academy of Sciences. Dr. Feller is an expert in retinal circuit development and function. </p>

<h2>Finding the Needle in the Haystack</h2>
<p>DSGCs were discovered in the rabbit retina in 1964 by another Berkeley Optometry faculty member, <a href="https://optometry.berkeley.edu/alumni/hall-of-fame/horace-b-barlow/">Horace Barlow</a>, and his colleagues (4). However, in the decades since, the lack of evidence for DSGCs in higher species led scientists to speculate that primate direction selectivity was computed in the brain. But when new evidence emerged suggesting that some human gaze stabilization disorders could be linked to abnormal activity of DSGCs (5), Puthussery’s lab renewed their efforts to find them. “That was a tipping point. We thought DSGCs had to be there, but that they made up a very low percentage of retinal ganglion cells. Our challenge was to work out how to find the needle in the haystack,” said Dr. Puthussery.</p>
<p>The researchers used a multi-pronged approach to overcome this problem. First, they leveraged data from state-of-the-art genetic tools (2) to track down retinal neurons with molecular features resembling DSGCs in other animals. The researchers then labeled these neurons with fluorescent markers to show that they had the expected anatomical features. Finally, the team built a customized imaging system to track the activity of hundreds of retinal ganglion cells and show that the fluorescently tagged cells responded selectively to images moving in specific directions. This combination of molecular, anatomical, and functional evidence provided unequivocal identification of the long sought-after DSGCs.</p>
<p>“The Puthussery Lab was successful where others failed because of their novel approach,” said Dr. Marla Feller. She continued, “I also cannot overstate the high quality of the data, which is critical for such a breakthrough finding.”</p>

<h2>New Insights into Common Visual Disorders</h2>
<p><img decoding="async" src="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-300x300.jpg" alt="Anna Wang" width="400" height="400" srcset="https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-300x300.jpg 300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-1024x1024.jpg 1024w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-150x150.jpg 150w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-768x768.jpg 768w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-1536x1536.jpg 1536w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-2048x2048.jpg 2048w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-1300x1300.jpg 1300w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-290x290.jpg 290w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-400x400.jpg 400w, https://opt-cdn.berkeley.edu/app/uploads/2023/11/Anna-Wang-684x684.jpg 684w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p>These findings will enable researchers to better understand how retinal mechanisms contribute to gaze stabilization in the normal visual system and in disorders that cause unstable gaze. For example, nystagmus is a repetitive, uncontrolled movement of the eyes that can lead to unsteady and blurry vision. Nystagmus can occur in isolation or can accompany other eye problems such as albinism and certain inherited retinal diseases. While many forms of nystagmus are caused by problems in the brain or inner ear, the results of this study suggest that some forms of nystagmus could originate from abnormal activity of DSGCs in the retina (5).</p>

<h2>Looking Forward: Testing for Blinding Diseases</h2>
<p>Overall, these results provide a vivid demonstration that a rare retinal ganglion cell type may nonetheless have a profound impact on our overall visual experience. The approach used in this study can now be applied to determine the roles of other human ganglion cell types whose functions are unknown. This will be an important step toward designing more sensitive tests for the detection of blinding diseases that cause ganglion cell degeneration such as glaucoma, which afflicts 80 million people worldwide and is the leading cause of irreversible blindness (7,8). For example, if direction-selective ganglion cells are damaged early in glaucoma, changes in eye movements might serve as an objective biomarker for early damage.</p>
<p>Remarkably, half of all individuals with glaucoma are unaware that they have it (7,8). Ultimately, detecting early changes in ganglion cell activity is vital to diagnosing disease and preventing vision loss in our aging population.</p>

<h2>About the Study</h2>
<p>The research was supported by the National Eye Institute (EY024265), Glaucoma Research Foundation (Shaffer Grant) and the Hellman Fellows Fund.</p>
<p>Wang, A.Y.M., Kulkarni, M.M., McLaughlin, A.J., Gayet J, Smith BE, Hauptschein M, McHugh CF, Yao YY, Puthussery T. An ON-type direction-selective ganglion cell in primate retina. Nature (2023).</p>
<p> <a href="https://doi.org/10.1038/s41586-023-06659-4">Read in Nature </a></p>
<h2>Related Information</h2>
<p> <a href="https://www.retinalab.berkeley.edu/">The Puthussery Lab </a></p>
<p><a href="https://vision.berkeley.edu/people/emily-ward/">Emily L Ward</a>, who wrote this web article, is a PhD student at UC Berkeley’s Herbert Wertheim School of Optometry &amp; Vision Science.</p>

  <div>
          <h2>About the Photos</h2>
        <p><strong>Top:</strong> A human retina labeled with a marker for all retinal ganglion cells in magenta. The sparse subset of retinal ganglion cells involved in gaze stabilization are labeled with a selective marker in green. <strong>Center:</strong> Teresa Puthussery, OD, PhD, heads the research group, which studies how retinal neurons process visual information before sending signals to the brain. <strong>Bottom:</strong> Anna Yao Mei Wang, PhD, is a postdoctoral scholar working in the Puthussery lab, and is first author of the study, which was published in <em>Nature</em>. Center and bottom photos by Elena Zhukova    </p>
  </div>
  

      <div id="accordion656c5fb7649ce" aria-labelledby="headingaccordion656c5fb7649e3"><p>
              1. Yan W, Peng YR, van Zyl T, et al. Cell Atlas of The Human Fovea and Peripheral Retina. Scientific Reports. 2020;10(1):9802. </p>
<p>2. Peng YR, Shekhar K, Yan W, et al. Molecular Classification and Comparative Taxonomics of Foveal and Peripheral Cells in Primate Retina. Cell. 2019;176(5):1222-1237.e22.</p>
<p>3. Wensel TG. Chapter 51 - Molecular Biology of Vision. Editor(s): Brady ST, Siegel GJ, Albers RW, Price DL. Basic Neurochemistry (Eighth Edition). Academic Press. 2012:889–903.</p>
<p>4. Barlow, HB, Hill, RM, Levick, WR. Retinal ganglion cells responding selectively to direction and speed of image motion in the rabbit. The Journal of Physiology. 1964;173.</p>
<p>5. Kamermans M, Winkelman BHJ, Hölzel MB, Howlett MHC, Kamermans W, Simonsz HJ, de Zeeuw CI. A retinal origin of nystagmus—a perspective. Frontiers in Ophthalmology. 2023;3.</p>
<p>6. Yonehara K, Fiscella M, Drinnenberg A, Esposti F, Trenholm S, Krol J, et al. Congenital Nystagmus Gene FRMD7 Is Necessary for Establishing a Neuronal Circuit Asymmetry for Direction Selectivity. Neuron. 2016;89:177–193.</p>
<p>7. Heijl A, Bengtsson B, Oskarsdottir SE. Prevalence and severity of undetected manifest glaucoma: results from the early manifest glaucoma trial screening. Ophthalmology. 2013;120(8):1541–1545. </p>
<p>8. “Glaucoma Worldwide: A Growing Concern.” Glaucoma.Org. https://glaucoma.org/glaucoma-worldwide-a-growing-concern/. Accessed October 25, 2023. Reviewed March 23, 2022.            </p></div>
  
  

<h2>Contacts</h2>
<p>Eric Craypo, Chief Communications Officer<br>
<a href="mailto:ecraypo@berkeley.edu"> ecraypo@berkeley.edu</a>
</p><p>Teresa Puthussery, Assistant Professor<br>
<a href="mailto:tputhussery@berkeley.edu"> tputhussery@berkeley.edu </a>
      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Meta patches Linux at hyperscale (124 pts)]]></title>
            <link>https://thenewstack.io/how-meta-patches-linux-at-hyperscale/</link>
            <guid>38501779</guid>
            <pubDate>Sat, 02 Dec 2023 20:32:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/how-meta-patches-linux-at-hyperscale/">https://thenewstack.io/how-meta-patches-linux-at-hyperscale/</a>, See on <a href="https://news.ycombinator.com/item?id=38501779">Hacker News</a></p>
Couldn't get https://thenewstack.io/how-meta-patches-linux-at-hyperscale/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Multifaceted: The linguistic echo chambers of LLMs (110 pts)]]></title>
            <link>https://blog.j11y.io/2023-11-22_multifaceted/</link>
            <guid>38501589</guid>
            <pubDate>Sat, 02 Dec 2023 20:10:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.j11y.io/2023-11-22_multifaceted/">https://blog.j11y.io/2023-11-22_multifaceted/</a>, See on <a href="https://news.ycombinator.com/item?id=38501589">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This is a fun one.&nbsp;</p>
<p>I’ve spent more time than I’d care to admit staring at LLM output. And there’s something that I’ve noticed: LLM-generated prose has a kind of… vibe. It’s difficult to describe, but in this initial era of LLMs, it tends to be fairly obvious when you’re reading an AI-generated piece of prose.</p>
<p>One giveaway I've noticed is this particular turn of phrase:</p>
<blockquote>
<p>“Culture is a <u>complex and multifaceted</u> ...” <br>
“Intelligence is <u>complex and multifaceted</u> ...” <br>
“Technology is a <u>complex and multifaceted</u> ...”</p>
</blockquote>
<p>In the <a href="https://www.britannica.com/topic/meme">true Dawkinsian sense</a>, the phrase <em>'complex and multifaceted'</em> has become a <strong>meme</strong>. I've seen it again and again in outputs from GPT, but to double-check, I did a bunch of GPT-3.5 generations (<a href="https://gist.githubusercontent.com/padolsey/89469513af62b70301a2540bbf5fef7b/raw/9f479453116fcd0336377050eaa9c5b6e040602e/gen_gpt_complex_and_test.py">code here</a>). Here's what I found when generating completions for a prompt of <code>'complex and ...'</code>:</p>
<p><img src="https://blog.j11y.io/post_imgs/multifaceted/gpt_gens.png" alt="x"></p>
<p>There is a bizarre prevalence of the term <em>'multifaceted'</em> specifically. Why?</p>
<p>I wanted to understand whether this phrase and the specific word <em>'multifaceted'</em> was newly popular or had existed for a while. As a first port of call, I had a look at Google Trends. And I observed a very shocking increase within the last year:</p>
<p><img src="https://blog.j11y.io/post_imgs/multifaceted/goog.png" alt="google trends graph showing sharp climb in the last year for the word 'multifaceted'"></p>
<p>At this point I wanted to get an indication of whether this was an online-only trend. It's hard to establish this but I thought I'd try Google Books' N-gram viewer. Maybe it would show me. And, as suspected, we see <a href="https://books.google.com/ngrams/graph?content=multifaceted&amp;year_start=2004&amp;year_end=2019&amp;corpus=en-2019&amp;smoothing=3">no notable inflection</a>, although one can see there's a gentle increase over time.</p>
<p><em>Tangent</em>: For what it's worth, I find it a bit of a weird phrase. It's a tautology, as <em>'complex'</em> and <em>'multifaceted'</em> are almost synonomous. It reminds me of legal doublets like <em>'null and void'</em> and <em>'cease and desist'</em>. It's a rather nice and affirmatory way of saying something. I guess it sounds clever and informed, which is, after all, the vibe LLMs are going for.</p>
<p>Anyway, I wanted to go a bit further in order to ensure this was actually a newly prevalent phrase online. Google Trends isn't very convincing by itself. So I went digging for other places where linguistic trends over time might be queryable. I discovered that <a href="https://web.archive.org/">web archive</a> helpfully retains various PDFs over the years, ranging from whitepapers to general reference material from accross the web. It allows you to search for specific keywords as well.</p>
<p>I carried out a bunch of searches from 2006 to 2022 As well as the word <em>'multifaceted'</em>. Oh and I was also interested in another viral word I'd spotted: <em>'intricate'</em>. To ensure some level of scientific prudence, I compared these words with other terms as experimental controls.</p>
<p><img src="https://blog.j11y.io/post_imgs/multifaceted/webarchive_keyphrases.png" alt="words like 'multifaceted' and 'intricate' increased drastically inline with LLM popularity, unlike control terms like 'efficacious' and 'symbiotic' which have remained stable"></p>
<p>As we see, from 2021 onwards, just around the time when GPT and other LLMs started to take the world by storm, the prevalence of our word <em>'multifaceted'</em> increased significantly, from being in only 0.05% of PDFs to 0.23%.</p>
<hr>
<p>Now, to zoom out a bit. I discovered the entire phrase, <em>'a complex and multifaceted'</em>, exists in around <a href="https://www.google.com/search?q=%22a+complex+and+multifaceted%22">800,000 places</a> online.</p>
<p>If narrowed down, we see it composed of some particular domains ahead of others:</p>
<pre><code>Quora.com:      48,000
LinkedIn.com:   30,700
Facebook.com:   9,500
Instagram.com:  7,330
Medium.com:     6,250
Reddit.com:     1,370
CourseHero.com: 7,340
jstor.org:      1,320
wikipedia.org:  400
twitter.com:    798
classace.io:    842 (*notably an essay bank*)
chegg.com:      930 (*notably an essay bank*)
</code></pre>
<p>Quora has 5.7% of all occurances online! If it isn't the birthplace of this meme, it is definitely its breeding ground.</p>
<p>N.B. FWIW we can see what proportion Quora <em>~should</em> be taking up, all things being equal. An arbitrary word like "systemic" appears <a href="https://www.google.co.uk/search?q=%22systemic%22">445 million</a> online, yet only <a href="https://www.google.co.uk/search?q=%22systemic%22+site%3Aquora.com">272,000</a> times on Quora. That's 0.06% of all occurrances. So Quora's 5.7% share of our meme-phrase is completely disproportionate. Are we even surprised? Quora does have a reputation for its spam-bots. They are, at this point, mere regurgitation machines:</p>
<p><img src="https://blog.j11y.io/post_imgs/multifaceted/quora_shots.png" alt="Tonnes of the same sentence structure repeated like 'philosophy is a complex and multifaceted concept that encompasses.....'"></p>
<p>I also couldn't ignore the fact that Quora has lately been embedding a ChatGPT widget on almost every page, and this widget's content is pre-generated, static and available for crawling. It is thus liable to being used as additional training material for this and other LLMs.</p>
<p><img src="https://blog.j11y.io/post_imgs/multifaceted/quora_chatgpt.png" alt="Screenshot of ChatGPT widget embedded in a quora page"></p>
<p>ChatGPT specifically seems to absolutely adore the phrase, using it at every opportunity to explain higher level concepts. The most prevalent pattern seems to be <em>'[noun] is a complex and multifaceted [concept|theory|process]'</em>. Some common ones and their relative quantities across Quora:</p>
<ul>
<li>"a complex and multifaceted concept" - <code>4590</code></li>
<li>"a complex and multifaceted issue" - <code>4420</code></li>
<li>"a complex and multifaceted process" - <code>3550</code></li>
<li>"a complex and multifaceted phenomenon" - <code>2230</code></li>
<li>"a complex and multifaceted emotion" - <code>1650</code></li>
<li>"a complex and multifaceted trait" - <code>1560</code></li>
</ul>
<p><em>(these values vary across locales)</em></p>
<p>If we pick one of these and do a general search across the web, once again we observe incredibly sharp increases across time. The phrase <em>'a complex and multifaceted phenomenon'</em> has 74,900 occurances across the web according to Google. However, only 73 prior to 2010. That's a 1000x increase in only 13 years.</p>
<p>You get the idea. ChatGPT has taken this meme and and rolled with it. This silly LLM has assumed the phrase a core part of our language when it was only ever a narrowly used and awkward turn of phrase.</p>
<hr>
<p><strong>What's the conclusion to this absurd rabbit hole? Have we learned anything?</strong></p>
<p>We know that initial versions of GPT were trained quite significantly on Reddit, and it's probably also the case that a small selection of other websites have been used since then to build and bolster additional models. </p>
<p>Focusing the training on any particular website will lead to strong biases. For example, fixating too much on academic material or websites like Quora where bots formulaically re-use certain phrases (this occurred even in the era before LLMs).</p>
<p>Furthermore, since these models have taken off in popularity, and people have then been publishing their outputs back onto the internet. As this occurs, it's likely produced a feedback loop. LLMs are unknowingly training on their own regurgitated outputs. It's unavoidable.</p>
<p>So, by those very tiny initial training decisions, just a handful of engineers have begun a unstoppable chain of incestuous linguistic evolution. It is fascinating how powerful these models are becoming in shifting the nature of language itself.</p>
<hr>
<p>Thank you for reading! I hope it you found it interesting. If you want, you can read <a href="https://blog.j11y.io/">more of my posts here</a> or <a href="https://j11y.io/">find out more about me here</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Singing to babies is vital to help them learn language, say scientists (206 pts)]]></title>
            <link>https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists</link>
            <guid>38500906</guid>
            <pubDate>Sat, 02 Dec 2023 18:50:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists">https://www.theguardian.com/science/2023/dec/01/singing-to-babies-is-vital-to-help-them-understand-language-say-scientists</a>, See on <a href="https://news.ycombinator.com/item?id=38500906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P … How many would read this to <em>that</em> tune?</p><p>According to scientists from the University of Cambridge, there’s more to the earworm than infuriating parents across the English-speaking world – they have found that singsong speech is crucial to helping babies learn language.</p><p>The study concluded that infants learn languages from rhythmic information – the rise and fall of tone – as seen in nursery rhymes or songs, such as the ubiquitous alphabet song.</p><p>The team at Cambridge also discovered that babies do not begin to process phonetic information – the smallest sounds of speech – until they are about seven months old.</p><p>The researchers said that the findings, which have been <a href="https://www.nature.com/articles/s41467-023-43490-x" data-link-name="in body link">published in the journal Nature Communications</a>, challenge the view that phonetic information – typically represented by the alphabet – is the key to language learning.</p><p>They said it also suggests that dyslexia and developmental language disorder may be associated with rhythm perception rather than difficulties with processing phonetic information.</p><p>Prof Usha Goswami, a neuroscientist at the University of Cambridge who is the study’s author, said: “Our research shows that the individual sounds of speech are not processed reliably until around seven months, even though most infants can recognise familiar words like ‘bottle’ by this point.</p><p>“From then individual speech sounds are still added in very slowly – too slowly to form the basis of language. We believe that speech rhythm information is the hidden glue underpinning the development of a well-functioning language system.</p><p>“Parents should talk and sing to their babies as much as possible or use infant-directed speech like nursery rhymes because it will make a difference to language outcome.”</p><p>It has previously been thought that infants learn small sound elements and add them together to make words.</p><p>To understand whether that was the case, the researchers recorded the brain activity of 50 infants at four, seven and 11 months old as they watched a video of a primary school teacher singing 18 nursery rhymes.</p><p>The team used special algorithms to interpret how the infants were encoding this information in the brain.</p><p>The scientists found that phonetic encoding in babies emerged gradually over the first year of life, beginning with dental sounds (produced by the upper front teeth) – such as “d” for “daddy” – and nasal sounds (produced when airflow is directed through the nose) – such as “m” for “mummy”.</p><p>Goswami said: “Infants can use rhythmic information like a scaffold or skeleton to add phonetic information on to. For example, they might learn that the rhythm pattern of English words is typically strong-weak, as in ‘daddy’ or ‘mummy’, with the stress on the first syllable.</p><p>“They can use this rhythm pattern to guess where one word ends and another begins when listening to natural speech.”</p><p>She said rhythm is a universal aspect of every language where all babies “are exposed to … a strong beat structure with a strong syllable twice a second”, adding: “We’re biologically programmed to emphasise this when speaking to babies.”</p><p>The study forms part of the BabyRhythm project led by Goswami, which is investigating how language is related to dyslexia and developmental language disorder.</p><p>She said there was a long history of trying to explain these in terms of phonetic problems but the evidence does not add up, and individual differences in children’s language learning skills may originate with rhythm.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Galactic algorithm (115 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Galactic_algorithm</link>
            <guid>38500782</guid>
            <pubDate>Sat, 02 Dec 2023 18:34:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Galactic_algorithm">https://en.wikipedia.org/wiki/Galactic_algorithm</a>, See on <a href="https://news.ycombinator.com/item?id=38500782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">
<p>A <b>galactic algorithm</b> is one with world-beating theoretical (asymptotic) performance, but which is never used in practice. Typical reasons are that the performance gains only appear for problems that are so large they never occur, or the algorithm's complexity outweighs a relatively small gain in performance.  Galactic algorithms were so named by <a href="https://en.wikipedia.org/wiki/Richard_Lipton" title="Richard Lipton">Richard Lipton</a> and Ken Regan,<sup id="cite_ref-seminal_1-0"><a href="#cite_note-seminal-1">[1]</a></sup> because they will never be used on any data sets on Earth.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Possible_use_cases">Possible use cases</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=1" title="Edit section: Possible use cases"><span>edit</span></a><span>]</span></span></h2>
<p>Even if they are never used in practice, galactic algorithms may still contribute to computer science:
</p>
<ul><li>An algorithm, even if impractical, may show new techniques that may eventually be used to create practical algorithms.</li>
<li>Available computational power may catch up to the crossover point, so that a previously impractical algorithm becomes practical.</li>
<li>An impractical algorithm can still demonstrate that conjectured bounds can be achieved, or that proposed bounds are wrong, and hence advance the theory of algorithms. As Lipton states:<sup id="cite_ref-seminal_1-1"><a href="#cite_note-seminal-1">[1]</a></sup><blockquote><p>This alone could be important and often is a great reason for finding such algorithms. For example, if tomorrow there were a discovery that showed there is a factoring algorithm with a huge but provably polynomial time bound, that would change our beliefs about factoring. The algorithm might never be used, but would certainly shape the future research into factoring.</p></blockquote>  Similarly, a hypothetical large but polynomial <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ee39ed087ed9b6a627b1d8e473ce859c1eced56c" aria-hidden="true" alt="{\displaystyle O{\bigl (}n^{2^{100}}{\bigr )}}"></span> algorithm for the <a href="https://en.wikipedia.org/wiki/Boolean_satisfiability_problem" title="Boolean satisfiability problem">Boolean satisfiability problem</a>, although unusable in practice, would settle the <a href="https://en.wikipedia.org/wiki/P_versus_NP_problem" title="P versus NP problem">P versus NP problem</a>, considered the most important open problem in computer science and one of the <a href="https://en.wikipedia.org/wiki/Millennium_Prize_Problems" title="Millennium Prize Problems">Millennium Prize Problems</a>.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></li></ul>
<h2><span id="Examples">Examples</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=2" title="Edit section: Examples"><span>edit</span></a><span>]</span></span></h2>
<h3><span id="Integer_multiplication">Integer multiplication</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=3" title="Edit section: Integer multiplication"><span>edit</span></a><span>]</span></span></h3>
<p>An example of a galactic algorithm is the fastest known way to <a href="https://en.wikipedia.org/wiki/Multiplication_algorithm" title="Multiplication algorithm">multiply two numbers</a>,<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> which is based on a 1729-dimensional <a href="https://en.wikipedia.org/wiki/Fourier_transform" title="Fourier transform">Fourier transform</a>.<sup id="cite_ref-quick_4-0"><a href="#cite_note-quick-4">[4]</a></sup> It needs <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d2320768fb54880ca4356e61f60eb02a3f9d9f1" aria-hidden="true" alt="O(n\log n)"></span> bit operations, but as the constants hidden by the <a href="https://en.wikipedia.org/wiki/Big_O_notation" title="Big O notation">big O notation</a> are large, it is never used in practice. However, it also shows why galactic algorithms may still be useful. The authors state: "we are hopeful that with further refinements, the algorithm might become practical for numbers with merely billions or trillions of digits."<sup id="cite_ref-quick_4-1"><a href="#cite_note-quick-4">[4]</a></sup>
</p>
<h3><span id="Matrix_multiplication">Matrix multiplication</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=4" title="Edit section: Matrix multiplication"><span>edit</span></a><span>]</span></span></h3>
<p>The first improvement over brute-force matrix multiplication (which needs <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b04f5c5cfea38f43406d9442387ad28555e2609" aria-hidden="true" alt="O(n^{3})"></span> multiplications) was the <a href="https://en.wikipedia.org/wiki/Strassen_algorithm" title="Strassen algorithm">Strassen algorithm</a>: a recursive algorithm that needs <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5efdd8558feb6363dbd3fe296b5f757df910e88a" aria-hidden="true" alt="{\displaystyle O(n^{2.807})}"></span>multiplications. This algorithm is not galactic and is used in practice. Further extensions of this, using sophisticated group theory, are the <a href="https://en.wikipedia.org/wiki/Coppersmith%E2%80%93Winograd_algorithm" title="Coppersmith–Winograd algorithm">Coppersmith–Winograd algorithm</a> and its slightly better successors, needing <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b7e9678394c2c1edfe2bbe326ea0c90343eb68b" aria-hidden="true" alt="{\displaystyle O(n^{2.373})}"></span> multiplications. These are galactic – "We nevertheless stress that such improvements are only of theoretical interest, since the huge constants involved in the complexity of fast matrix multiplication usually make these algorithms impractical."<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p>
<h3><span id="Communication_channel_capacity">Communication channel capacity</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=5" title="Edit section: Communication channel capacity"><span>edit</span></a><span>]</span></span></h3>
<p><a href="https://en.wikipedia.org/wiki/Claude_Shannon" title="Claude Shannon">Claude Shannon</a> showed a simple but impractical <a href="https://en.wikipedia.org/wiki/Code" title="Code">code</a> that could reach the capacity of a <a href="https://en.wikipedia.org/wiki/Communication_channel" title="Communication channel">communication channel</a>.  It requires assigning a random code word to every possible <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span>-bit message, then decoding by finding the closest code word.  If <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> is chosen large enough, this beats any existing code and can get arbitrarily close to the capacity of the channel.  Unfortunately, any <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> big enough to beat existing codes is also completely impractical.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> These codes, though never used, inspired decades of research into more practical algorithms that today can achieve rates arbitrarily close to channel capacity.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>
</p>
<h3><span id="Sub-graphs">Sub-graphs</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=6" title="Edit section: Sub-graphs"><span>edit</span></a><span>]</span></span></h3>
<p>The problem of <a href="https://en.wikipedia.org/wiki/Decision_problem" title="Decision problem">deciding</a> whether a graph <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" aria-hidden="true" alt="G"></span> contains <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span> as a <a href="https://en.wikipedia.org/wiki/Graph_minor" title="Graph minor">minor</a> is <a href="https://en.wikipedia.org/wiki/NP-complete" title="NP-complete">NP-complete</a> in general, but where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span> is fixed, it can be solved in polynomial time.  The running time for testing whether <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span> is a minor of <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" aria-hidden="true" alt="G"></span> in this case is <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6cd9594a16cb898b8f2a2dff9227a385ec183392" aria-hidden="true" alt="O(n^{2})"></span>,<sup id="cite_ref-kkr12_8-0"><a href="#cite_note-kkr12-8">[8]</a></sup> where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> is the number of vertices in <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" aria-hidden="true" alt="G"></span> and the <a href="https://en.wikipedia.org/wiki/Big_O_notation" title="Big O notation">big O notation</a> hides a constant that depends superexponentially on <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span>.  The constant is greater than <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/360009b1d76b85fe5141886793eb89e9ad50e825" aria-hidden="true" alt="{\displaystyle 2\uparrow \uparrow (2\uparrow \uparrow (2\uparrow \uparrow (h/2)))}"></span> in <a href="https://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation" title="Knuth's up-arrow notation">Knuth's up-arrow notation</a>, where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" aria-hidden="true" alt="h"></span> is the number of vertices in <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75a9edddcca2f782014371f75dca39d7e13a9c1b" aria-hidden="true" alt="H"></span>.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> Even the case of <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9b3ec3aec2fcc1177dad3a297dfc9060ec07e5a3" aria-hidden="true" alt="{\displaystyle h=4}"></span> cannot be reasonably computed as the constant is greater than <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0d6b4d85f1c6a1949b61be9f5e1bf5504cd03bd5" aria-hidden="true" alt="{\displaystyle {\  \atop {\ }}{{\underbrace {2^{2^{\cdot ^{\cdot ^{2}}}}} } \atop n}}"></span> with <i>n</i> = 65536.
</p>
<h3><span id="Cryptographic_breaks">Cryptographic breaks</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=7" title="Edit section: Cryptographic breaks"><span>edit</span></a><span>]</span></span></h3>
<p>For cryptographers, a cryptographic "break" is anything faster than a brute-force attack – i.e., performing one trial decryption for each possible key. In many cases, even though they are the best known methods,  they are still infeasible with current technology. One example is the best attack known against 128-bit <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" title="Advanced Encryption Standard">AES</a>, which takes only <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/03ba78eeaf0f84e190d7aa90548b82ead88a37c5" aria-hidden="true" alt="2^{126}"></span> operations.<sup id="cite_ref-:0_10-0"><a href="#cite_note-:0-10">[10]</a></sup>  Despite being impractical, theoretical breaks can sometimes provide insight into vulnerability patterns.
</p>
<h3><span id="Traveling_salesman_problem">Traveling salesman problem</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=8" title="Edit section: Traveling salesman problem"><span>edit</span></a><span>]</span></span></h3>
<p>For several decades, the best known approximation to the <a href="https://en.wikipedia.org/wiki/Traveling_salesman_problem" title="Traveling salesman problem">traveling salesman problem</a> in a <a href="https://en.wikipedia.org/wiki/Metric_space" title="Metric space">metric space</a> was the very simple <a href="https://en.wikipedia.org/wiki/Christofides_algorithm" title="Christofides algorithm">Christofides algorithm</a> which produced a path at most 50% longer than the optimum. (Many other algorithms could <i>usually</i> do much better, but could not provably do so.)  In 2020, a newer and much more complex algorithm was discovered that can beat this by <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9cf2b5bceb62956a12c9ce5a253e838aa25c9f11" aria-hidden="true" alt="{\displaystyle 10^{-34}}"></span> percent.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> Although no one will ever switch to this algorithm for its very slight worst-case improvement, it is still considered important because "this minuscule improvement breaks through both a theoretical logjam and a psychological one".<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup>
</p>
<h3><span id="Hutter_search">Hutter search</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=9" title="Edit section: Hutter search"><span>edit</span></a><span>]</span></span></h3>
<p>A single algorithm, "Hutter search", can solve any well-defined problem in an asymptotically optimal time, barring some caveats. It works by searching through all possible algorithms (by runtime), while simultaneously searching through all possible proofs (by length of proof), looking for a proof of correctness for each algorithm.  Since the proof of correctness is of finite size, it "only" adds a constant and does not affect the asymptotic runtime. However, this constant is so big that the algorithm is entirely impractical.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup><sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup>  For example, if the shortest proof of correctness of a given algorithm is 1000 bits long, the search will examine at least 2<sup>999</sup> other potential proofs first.
</p><p>Hutter search is related <a href="https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference" title="Solomonoff's theory of inductive inference">Solomonoff induction</a>, which is a formalization of Bayesian inference.  All <a href="https://en.wikipedia.org/wiki/Computable" title="Computable">computable</a> theories (as implemented by programs) which perfectly describe previous observations are used to calculate the probability of the next observation, with more weight put on the shorter computable theories.  Again, the search over all possible explanations makes this procedure Galactic.
</p>
<h3><span id="Optimization">Optimization</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=10" title="Edit section: Optimization"><span>edit</span></a><span>]</span></span></h3>
<p><a href="https://en.wikipedia.org/wiki/Simulated_annealing" title="Simulated annealing">Simulated annealing</a>, when used with a logarithmic cooling schedule, has been proven to find the global optimum of any optimization problem.  However, such a cooling schedule results in entirely impractical runtimes, and is never used.<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup>  However, knowing this ideal algorithm exists has led to practical variants that are able to find very good (though not provably optimal) solutions to complex optimization problems.<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>
</p>
<h3><span id="Minimum_Spanning_Trees">Minimum Spanning Trees</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=11" title="Edit section: Minimum Spanning Trees"><span>edit</span></a><span>]</span></span></h3>
<p>The <a href="https://en.wikipedia.org/wiki/Expected_linear_time_MST_algorithm" title="Expected linear time MST algorithm">expected linear time MST algorithm</a> is able to discover the <a href="https://en.wikipedia.org/wiki/Minimum_spanning_tree" title="Minimum spanning tree">minimum spanning tree</a> of a graph in <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0922aa919079469e54e4c3affe9b7ab456f1a124" aria-hidden="true" alt="O(m + n)"></span>, where <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" aria-hidden="true" alt="m"></span> is the number of edges and <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" aria-hidden="true" alt="n"></span> is the number of nodes of the graph.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup> However, the constant factor that is hidden by the <a href="https://en.wikipedia.org/wiki/Big_O_notation" title="Big O notation">Big O notation</a> is huge enough to make the algorithm impractical. An implementation is publicly available<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> and given the experimentally estimated implementation constants, it would only be faster than <a href="https://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm" title="Borůvka's algorithm">Borůvka's algorithm</a> for graphs in which <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bc74100999273f6c2d96369163dbb6e20152e8dd" aria-hidden="true" alt="{\displaystyle m+n>9\cdot 10^{151}}"></span>.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup>
</p>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Galactic_algorithm&amp;action=edit&amp;section=12" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-seminal-1"><span>^ <a href="#cite_ref-seminal_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-seminal_1-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFLiptonRegan2013"><a href="https://en.wikipedia.org/wiki/Richard_Lipton" title="Richard Lipton">Lipton, Richard J.</a>; Regan, Kenneth W. (2013). <a rel="nofollow" href="https://books.google.com/books?id=eLC9BAAAQBAJ&amp;pg=PA109">"David Johnson: Galactic Algorithms"</a>. <i>People, Problems, and Proofs: Essays from Gödel's Lost Letter: 2010</i>. Heidelberg: Springer Berlin. pp.&nbsp;109–112. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9783642414220" title="Special:BookSources/9783642414220"><bdi>9783642414220</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=David+Johnson%3A+Galactic+Algorithms&amp;rft.btitle=People%2C+Problems%2C+and+Proofs%3A+Essays+from+G%C3%B6del%27s+Lost+Letter%3A+2010&amp;rft.place=Heidelberg&amp;rft.pages=109-112&amp;rft.pub=Springer+Berlin&amp;rft.date=2013&amp;rft.isbn=9783642414220&amp;rft.aulast=Lipton&amp;rft.aufirst=Richard+J.&amp;rft.au=Regan%2C+Kenneth+W.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DeLC9BAAAQBAJ%26pg%3DPA109&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFFortnow,_L.2009">Fortnow, L. (2009). <a rel="nofollow" href="http://people.cs.uchicago.edu/~fortnow/papers/pnp-cacm.pdf">"The status of the P versus NP problem"</a> <span>(PDF)</span>. <i>Communications of the ACM</i>. <b>52</b> (9): 78–86. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1145%2F1562164.1562186">10.1145/1562164.1562186</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:5969255">5969255</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=The+status+of+the+P+versus+NP+problem&amp;rft.volume=52&amp;rft.issue=9&amp;rft.pages=78-86&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1145%2F1562164.1562186&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A5969255%23id-name%3DS2CID&amp;rft.au=Fortnow%2C+L.&amp;rft_id=http%3A%2F%2Fpeople.cs.uchicago.edu%2F~fortnow%2Fpapers%2Fpnp-cacm.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFDavidHoeven2019">David, Harvey; Hoeven, Joris van der (March 2019). <a rel="nofollow" href="https://hal.archives-ouvertes.fr/hal-02070778/document">"Integer multiplication in time O(n log n)"</a>. <i>HAL</i>. hal-02070778.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=HAL&amp;rft.atitle=Integer+multiplication+in+time+O%28n+log+n%29&amp;rft.volume=hal-02070778&amp;rft.date=2019-03&amp;rft.aulast=David&amp;rft.aufirst=Harvey&amp;rft.au=Hoeven%2C+Joris+van+der&amp;rft_id=https%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-02070778%2Fdocument&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-quick-4"><span>^ <a href="#cite_ref-quick_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-quick_4-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFHarvey2019">Harvey, David (9 April 2019). <a rel="nofollow" href="https://theconversation.com/weve-found-a-quicker-way-to-multiply-really-big-numbers-114923">"We've found a quicker way to multiply really big numbers"</a>. <i>The Conversation</i><span>. Retrieved <span>9 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Conversation&amp;rft.atitle=We%27ve+found+a+quicker+way+to+multiply+really+big+numbers&amp;rft.date=2019-04-09&amp;rft.aulast=Harvey&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Ftheconversation.com%2Fweve-found-a-quicker-way-to-multiply-really-big-numbers-114923&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite id="CITEREFLe_Gall2012">Le Gall, F. (2012), "Faster algorithms for rectangular matrix multiplication", <i>Proceedings of the 53rd Annual IEEE Symposium on Foundations of Computer Science (FOCS 2012)</i>, pp.&nbsp;514–523, <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span title="Freely accessible"><a rel="nofollow" href="https://arxiv.org/abs/1204.1111">1204.1111</a></span>, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FFOCS.2012.80">10.1109/FOCS.2012.80</a>, <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:2410545">2410545</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Faster+algorithms+for+rectangular+matrix+multiplication&amp;rft.btitle=Proceedings+of+the+53rd+Annual+IEEE+Symposium+on+Foundations+of+Computer+Science+%28FOCS+2012%29&amp;rft.pages=514-523&amp;rft.date=2012&amp;rft_id=info%3Aarxiv%2F1204.1111&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A2410545%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FFOCS.2012.80&amp;rft.aulast=Le+Gall&amp;rft.aufirst=F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite id="CITEREFLarry_Hardesty2010">Larry Hardesty (January 19, 2010). <a rel="nofollow" href="https://news.mit.edu/2010/explained-shannon-0115">"Explained: The Shannon limit"</a>. MIT News Office.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Explained%3A+The+Shannon+limit&amp;rft.pub=MIT+News+Office&amp;rft.date=2010-01-19&amp;rft.au=Larry+Hardesty&amp;rft_id=https%3A%2F%2Fnews.mit.edu%2F2010%2Fexplained-shannon-0115&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="https://ocw.mit.edu/courses/6-451-principles-of-digital-communication-ii-spring-2005/1a3ad00d83d1d042da3328a8edd9edc2_chap13.pdf">"Capacity-approaching codes (Chapter 13 of <i>Principles Of Digital Communication II</i>)"</a> <span>(PDF)</span>. <a href="https://en.wikipedia.org/wiki/MIT_OpenCourseWare" title="MIT OpenCourseWare">MIT OpenCourseWare</a>. 2005.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Capacity-approaching+codes+%28Chapter+13+of+Principles+Of+Digital+Communication+II%29&amp;rft.pub=MIT+OpenCourseWare&amp;rft.date=2005&amp;rft_id=https%3A%2F%2Focw.mit.edu%2Fcourses%2F6-451-principles-of-digital-communication-ii-spring-2005%2F1a3ad00d83d1d042da3328a8edd9edc2_chap13.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-kkr12-8"><span><b><a href="#cite_ref-kkr12_8-0">^</a></b></span> <span><cite id="CITEREFKawarabayashiKobayashiReed2012">Kawarabayashi, Ken-ichi; Kobayashi, Yusuke; <a href="https://en.wikipedia.org/wiki/Bruce_Reed_(mathematician)" title="Bruce Reed (mathematician)">Reed, Bruce</a> (2012). <a rel="nofollow" href="https://doi.org/10.1016%2Fj.jctb.2011.07.004">"The disjoint paths problem in quadratic time"</a>. <i><a href="https://en.wikipedia.org/wiki/Journal_of_Combinatorial_Theory" title="Journal of Combinatorial Theory">Journal of Combinatorial Theory</a></i>. Series B. <b>102</b> (2): 424–435. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1016%2Fj.jctb.2011.07.004">10.1016/j.jctb.2011.07.004</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Combinatorial+Theory&amp;rft.atitle=The+disjoint+paths+problem+in+quadratic+time&amp;rft.volume=102&amp;rft.issue=2&amp;rft.pages=424-435&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jctb.2011.07.004&amp;rft.aulast=Kawarabayashi&amp;rft.aufirst=Ken-ichi&amp;rft.au=Kobayashi%2C+Yusuke&amp;rft.au=Reed%2C+Bruce&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252Fj.jctb.2011.07.004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFJohnson,_David_S.1987">Johnson, David S. (1987). "The NP-completeness column: An ongoing guide (edition 19)". <i>Journal of Algorithms</i>. <b>8</b> (2): 285–303. <a href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.3864">10.1.1.114.3864</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1016%2F0196-6774%2887%2990043-5">10.1016/0196-6774(87)90043-5</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Algorithms&amp;rft.atitle=The+NP-completeness+column%3A+An+ongoing+guide+%28edition+19%29&amp;rft.volume=8&amp;rft.issue=2&amp;rft.pages=285-303&amp;rft.date=1987&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.114.3864%23id-name%3DCiteSeerX&amp;rft_id=info%3Adoi%2F10.1016%2F0196-6774%2887%2990043-5&amp;rft.au=Johnson%2C+David+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-:0-10"><span><b><a href="#cite_ref-:0_10-0">^</a></b></span> <span><cite id="CITEREFBiaoshuai_TaoHongjun_Wu2015">Biaoshuai Tao &amp; Hongjun Wu (2015). <i>Information Security and Privacy</i>. Lecture Notes in Computer Science. Vol.&nbsp;9144. pp.&nbsp;39–56. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1007%2F978-3-319-19962-7_3">10.1007/978-3-319-19962-7_3</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-19961-0" title="Special:BookSources/978-3-319-19961-0"><bdi>978-3-319-19961-0</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Information+Security+and+Privacy&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=39-56&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-19962-7_3&amp;rft.isbn=978-3-319-19961-0&amp;rft.au=Biaoshuai+Tao&amp;rft.au=Hongjun+Wu&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFAnna_R._KarlinNathan_KleinShayan_Oveis_Gharan2020">Anna R. Karlin; Nathan Klein; Shayan Oveis Gharan (September 1, 2020). "A (Slightly) Improved Approximation Algorithm for Metric TSP". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span title="Freely accessible"><a rel="nofollow" href="https://arxiv.org/abs/2007.01409">2007.01409</a></span> [<a rel="nofollow" href="https://arxiv.org/archive/cs.DS">cs.DS</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+%28Slightly%29+Improved+Approximation+Algorithm+for+Metric+TSP&amp;rft.date=2020-09-01&amp;rft_id=info%3Aarxiv%2F2007.01409&amp;rft.au=Anna+R.+Karlin&amp;rft.au=Nathan+Klein&amp;rft.au=Shayan+Oveis+Gharan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFKlarreich2020">Klarreich, Erica (8 October 2020). <a rel="nofollow" href="https://www.quantamagazine.org/computer-scientists-break-traveling-salesperson-record-20201008/">"Computer Scientists Break Traveling Salesperson Record"</a>. <i>Quanta Magazine</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Quanta+Magazine&amp;rft.atitle=Computer+Scientists+Break+Traveling+Salesperson+Record&amp;rft.date=2020-10-08&amp;rft.aulast=Klarreich&amp;rft.aufirst=Erica&amp;rft_id=https%3A%2F%2Fwww.quantamagazine.org%2Fcomputer-scientists-break-traveling-salesperson-record-20201008%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFHutter2002">Hutter, Marcus (2002-06-14). "The Fastest and Shortest Algorithm for All Well-Defined Problems". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span title="Freely accessible"><a rel="nofollow" href="https://arxiv.org/abs/cs/0206022">cs/0206022</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+Fastest+and+Shortest+Algorithm+for+All+Well-Defined+Problems&amp;rft.date=2002-06-14&amp;rft_id=info%3Aarxiv%2Fcs%2F0206022&amp;rft.aulast=Hutter&amp;rft.aufirst=Marcus&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite id="CITEREFGagliolo2007">Gagliolo, Matteo (2007-11-20). <a rel="nofollow" href="https://doi.org/10.4249%2Fscholarpedia.2575">"Universal search"</a>. <i>Scholarpedia</i>. <b>2</b> (11): 2575. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" href="https://ui.adsabs.harvard.edu/abs/2007SchpJ...2.2575G">2007SchpJ...2.2575G</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.4249%2Fscholarpedia.2575">10.4249/scholarpedia.2575</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1941-6016">1941-6016</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scholarpedia&amp;rft.atitle=Universal+search&amp;rft.volume=2&amp;rft.issue=11&amp;rft.pages=2575&amp;rft.date=2007-11-20&amp;rft.issn=1941-6016&amp;rft_id=info%3Adoi%2F10.4249%2Fscholarpedia.2575&amp;rft_id=info%3Abibcode%2F2007SchpJ...2.2575G&amp;rft.aulast=Gagliolo&amp;rft.aufirst=Matteo&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.4249%252Fscholarpedia.2575&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite id="CITEREFLiangChengLin2014">Liang, Faming; Cheng, Yichen; Lin, Guang (2014). "Simulated stochastic approximation annealing for global optimization with a square-root cooling schedule". <i>Journal of the American Statistical Association</i>. <b>109</b> (506): 847–863. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1080%2F01621459.2013.872993">10.1080/01621459.2013.872993</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:123410795">123410795</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Simulated+stochastic+approximation+annealing+for+global+optimization+with+a+square-root+cooling+schedule&amp;rft.volume=109&amp;rft.issue=506&amp;rft.pages=847-863&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1080%2F01621459.2013.872993&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A123410795%23id-name%3DS2CID&amp;rft.aulast=Liang&amp;rft.aufirst=Faming&amp;rft.au=Cheng%2C+Yichen&amp;rft.au=Lin%2C+Guang&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFIngber,_Lester1993">Ingber, Lester (1993). <a rel="nofollow" href="https://doi.org/10.1016%2F0895-7177%2893%2990204-C">"Simulated annealing: Practice versus theory"</a>. <i>Mathematical and Computer Modelling</i>. <b>18</b> (11): 29–57. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1016%2F0895-7177%2893%2990204-C">10.1016/0895-7177(93)90204-C</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Mathematical+and+Computer+Modelling&amp;rft.atitle=Simulated+annealing%3A+Practice+versus+theory&amp;rft.volume=18&amp;rft.issue=11&amp;rft.pages=29-57&amp;rft.date=1993&amp;rft_id=info%3Adoi%2F10.1016%2F0895-7177%2893%2990204-C&amp;rft.au=Ingber%2C+Lester&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252F0895-7177%252893%252990204-C&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite id="CITEREFKargerKleinTarjan1995">Karger, David R.; Klein, Philip N.; Tarjan, Robert E. (1995-03-01). <a rel="nofollow" href="https://doi.org/10.1145%2F201019.201022">"A randomized linear-time algorithm to find minimum spanning trees"</a>. <i>Journal of the ACM</i>. <b>42</b> (2): 321–328. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1145%2F201019.201022">10.1145/201019.201022</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/0004-5411">0004-5411</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+ACM&amp;rft.atitle=A+randomized+linear-time+algorithm+to+find+minimum+spanning+trees&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=321-328&amp;rft.date=1995-03-01&amp;rft_id=info%3Adoi%2F10.1145%2F201019.201022&amp;rft.issn=0004-5411&amp;rft.aulast=Karger&amp;rft.aufirst=David+R.&amp;rft.au=Klein%2C+Philip+N.&amp;rft.au=Tarjan%2C+Robert+E.&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1145%252F201019.201022&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite id="CITEREFThiesen">Thiesen, Francisco. <a rel="nofollow" href="https://github.com/FranciscoThiesen/karger-klein-tarjan">"A C++ implementation for an Expected Linear-Time Minimum Spanning Tree Algorithm(Karger-Klein-Tarjan + Hagerup Minimum Spanning Tree Verification as a sub-routine)"</a>. <i><a href="https://en.wikipedia.org/wiki/GitHub" title="GitHub">GitHub</a></i><span>. Retrieved <span>2022-11-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=A+C%2B%2B+implementation+for+an+Expected+Linear-Time+Minimum+Spanning+Tree+Algorithm%28Karger-Klein-Tarjan+%2B+Hagerup+Minimum+Spanning+Tree+Verification+as+a+sub-routine%29&amp;rft.aulast=Thiesen&amp;rft.aufirst=Francisco&amp;rft_id=https%3A%2F%2Fgithub.com%2FFranciscoThiesen%2Fkarger-klein-tarjan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFGeiman_Thiesen">Geiman Thiesen, Francisco. <a rel="nofollow" href="https://franciscothiesen.github.io/Linear-Time-MST/">"Expected Linear-Time Minimum Spanning Trees"</a>. <i>franciscothiesen.github.io</i><span>. Retrieved <span>2022-11-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=franciscothiesen.github.io&amp;rft.atitle=Expected+Linear-Time+Minimum+Spanning+Trees&amp;rft.aulast=Geiman+Thiesen&amp;rft.aufirst=Francisco&amp;rft_id=https%3A%2F%2Ffranciscothiesen.github.io%2FLinear-Time-MST%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGalactic+algorithm"></span></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐8689768cf9‐xbkwc
Cached time: 20231202221053
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.230 seconds
Real time usage: 0.317 seconds
Preprocessor visited node count: 1332/1000000
Post‐expand include size: 39307/2097152 bytes
Template argument size: 1055/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 0/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 58198/5000000 bytes
Lua time usage: 0.122/10.000 seconds
Lua memory usage: 5630519/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  226.073      1 -total
 70.40%  159.151      1 Template:Reflist
 30.30%   68.493      2 Template:Cite_book
 21.25%   48.035      1 Template:Short_description
 13.86%   31.330      8 Template:Cite_journal
 11.41%   25.787      2 Template:Pagetype
  9.93%   22.450      6 Template:Cite_web
  5.62%   12.714      4 Template:Main_other
  4.80%   10.856      1 Template:SDcat
  4.11%    9.281      2 Template:Cite_arXiv
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:60819045-0!canonical and timestamp 20231202221052 and revision id 1188021149. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mundane emotions: Losing yourself in boredom, time and technology (2022) (143 pts)]]></title>
            <link>https://journals.sagepub.com/doi/10.1177/14705931221138617</link>
            <guid>38500681</guid>
            <pubDate>Sat, 02 Dec 2023 18:22:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journals.sagepub.com/doi/10.1177/14705931221138617">https://journals.sagepub.com/doi/10.1177/14705931221138617</a>, See on <a href="https://news.ycombinator.com/item?id=38500681">Hacker News</a></p>
Couldn't get https://journals.sagepub.com/doi/10.1177/14705931221138617: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Cicadas are so loud, fiber optic cables can ‘hear’ them (190 pts)]]></title>
            <link>https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/</link>
            <guid>38500065</guid>
            <pubDate>Sat, 02 Dec 2023 17:11:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/">https://www.wired.com/story/cicadas-are-so-loud-fiber-optic-cables-can-hear-them/</a>, See on <a href="https://news.ycombinator.com/item?id=38500065">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>One of the world’s most peculiar test beds stretches above Princeton, New Jersey. It’s a fiber optic cable strung between three utility poles that then runs underground before feeding into an “interrogator.” This device fires a laser through the cable and analyzes the light that bounces back. It can pick up tiny perturbations in that light caused by seismic activity or even loud sounds, like from a passing ambulance. It’s a newfangled technique known as distributed acoustic sensing, or DAS.</p><figure data-testid="IframeEmbed"></figure><p>Because DAS can track seismicity, other scientists are <a href="https://www.wired.com/story/how-fiber-optic-cables-could-warn-you-of-an-earthquake/">increasingly using it to monitor earthquakes</a> and <a href="https://www.wired.com/story/scientists-spy-on-mount-etna-with-fiber-optic-cables/">volcanic activity</a>. (A buried system is so sensitive, in fact, that it can <a href="https://www.wired.com/story/how-underground-fiber-optics-spy-on-humans-moving-above/">detect people walking and driving above</a>.) But the scientists in Princeton just stumbled upon a rather … noisier use of the technology. In the spring of 2021, Sarper Ozharar—a physicist at NEC Laboratories, which operates the Princeton test bed—noticed <a href="https://academic.oup.com/jinsectscience/article/23/6/3/7425398">a strange signal in the DAS data</a>. “We realized there were some weird things happening,” says Ozharar. “Something that shouldn’t be there. There was a distinct frequency buzzing everywhere.”</p><p>The team suspected the “something” wasn’t a rumbling volcano—not in <em>New Jersey</em>—but the cacophony of the giant swarm of cicadas that had just emerged from underground, a population <a href="https://www.wired.com/story/eating-cicadas-brood-x/">known as Brood X</a>. A colleague suggested reaching out to Jessica Ware, an entomologist and cicada expert at the American Museum of Natural History, to confirm it. “I had been observing the cicadas and had gone around Princeton because we were collecting them for biological samples,” says Ware. “So when Sarper and the team showed that you could actually <em>hear</em> the volume of the cicadas, and it kind of matched their patterns, I was really excited.”</p><p>Add insects to the quickly growing list of things DAS can spy on. Thanks to some specialized anatomy, cicadas are the loudest insects on the planet, but all sorts of other six-legged species make a lot of noise, like crickets and grasshoppers. With fiber optic cables, entomologists might have stumbled upon a powerful new way to cheaply and constantly listen in on species—from afar. “Part of the challenge that we face in a time when there’s insect decline is that we still need to collect data about what population sizes are, and what insects are where,” says Ware. “Once we are able to familiarize ourselves with what’s possible with this type of remote sensing, I think we can be really creative.”</p><p>DAS is all about vibrations, whether they be the sounds of a singing brood of cicadas or the shifting of a geologic fault. Fiber optic cables transmit information, like high-speed internet, by firing pulses of light. Scientists can use an interrogator device to shine a laser down a cable and then analyze the tiny amounts of light that bounce back to the source. Because the speed of light is a known constant, they can pinpoint where along the cable a given disturbance happens: If something jostles the cable 100 feet down, the light will take slightly longer to return to the interrogator than something that happens at 50 feet. “Every 1 meter of fiber, more or less, we can turn it into a kind of microphone,” says Ozharar.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure><p><span>Courtesy of Journal of Insect Science/Entomological Society of America</span></p></figure><p>Ozharar’s team focused on a loop of the cable atop one of the utility poles, which you can see in the photo above. (The loop is highlighted in red.) “If the fiber is in a linear shape, a sound interacts with the fiber just once and then keeps traveling,” says Ozharar. “But if you have a coil, the same signal travels multiple times through the fiber.” That makes the system much more sensitive, like recording a concert with multiple microphones, instead of one fan in the crowd bootlegging it with their smartphone.</p><p>When Brood X emerged in the spring of 2021, Ozharar’s DAS system was accidentally listening in. This kind of “periodical cicada” develops underground and emerges every 13 or 17 years to mate, depending on the species. “Because of perhaps climate change—although we’re not exactly sure the reason—there have been stragglers, so populations that have come out early and populations that have come out later than what they’re metabolically timed to do,” says Ware. “Having a way to over time monitor those can be really helpful.”</p><p>Male cicadas have an organ, called the tymbal, that vibrates like a drum to produce that unmistakable song. Each species has its own variation on the song, allowing the right males and females to find each other. There’s extra information embedded in that sound, too: Males tend to call during the hottest time of day, which is energetically expensive. That allows females to assess the quality of their mates—they want to choose the fittest males so they can pass primo genes to their offspring.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Hence all the noise. DAS can listen from the very beginning of the emergence through the peak and into the decline as the mass mating ritual wanes. The volume of noise is a solid indicator of the number of cicadas, so entomologists can work out the population size of the brood. They can even see the effect of temperature: When it’s hotter, it’s more difficult for the male cicadas to sing. “You can see that as you go across the five days from which we have monitoring data, that when it’s slightly colder temperatures they have slightly different frequencies in hertz of the calling,” says Ware.</p><figure><p><span><p>Dead and dying cicadas from Brood X in Columbia, Maryland.</p>
</span><span>Photograph: Chip Somodevilla/Getty Images</span></p></figure><p>Fiber optic cables are already all over the place, just waiting for scientists to tap into them. They are abundant in cities, of course, but they also run between them, which would be handy for entomologists who want to monitor insects in more rural areas. “We use them just to transmit the data—zeros and ones—but we can do much more,” says Ozharar. “That’s why fiber sensing will become more and more important, and more widely used, in the near future.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Not that anyone’s suggesting DAS will replace other ways of monitoring insects—fiber optics are widespread, but they’re not <em>everywhere</em>. Instead, DAS could complement other techniques. A field called <a href="https://www.wired.com/story/why-scientists-are-bugging-the-rainforest/">bioacoustics</a> already uses microphones to listen for species in remote areas, sometimes assisted by AI to parse the data. This method could help confirm the data coming from the fiber optics. Scientists are also experimenting with “environmental DNA,” or <a href="https://www.wired.com/story/scientists-capture-airborne-animal-dna-for-the-first-time/">eDNA</a>, for instance using air quality stations to <a href="https://www.wired.com/story/a-secret-key-to-saving-species-is-blowing-in-the-wind/">gather the biological material</a> floating in a given area. And entomologists like Ware still need to collect specimens from the field to physically examine the health of individual animals.</p><p>“What seems really cool about this new technology is that you have this single cable that can cover potentially many kilometers, and all of the information is getting recorded by a single device,” says Elliott Smeds, an entomologist and research associate at the California Academy of Sciences, who wasn’t involved in the research. “Especially now that insects are declining, we’re realizing that we don’t even know what the baseline is for a lot of these species, to keep track of how they’re doing. The biggest obstacle is having enough boots on the ground to be collecting this kind of data.”</p><p>The trick will be adapting DAS to monitor species that <em>aren’t</em> the loudest insects on Earth. “In this case, it was very clear these were cicadas, because there were—without exaggeration—millions of them that suddenly descended,” says Ware. “But in most cases, the populations are much smaller for each species. Knowing whether or not we can actually distinguish among insects will be an interesting question.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI is killing our sense of awe (107 pts)]]></title>
            <link>https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe</link>
            <guid>38499843</guid>
            <pubDate>Sat, 02 Dec 2023 16:43:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe">https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe</a>, See on <a href="https://news.ycombinator.com/item?id=38499843">Hacker News</a></p>
Couldn't get https://www.fastcompany.com/90916652/generative-ai-killing-sense-of-awe: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Dark patterns in UX design and how to avoid them (125 pts)]]></title>
            <link>https://dodonut.com/blog/10-dark-patterns-in-ux-design/</link>
            <guid>38499824</guid>
            <pubDate>Sat, 02 Dec 2023 16:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dodonut.com/blog/10-dark-patterns-in-ux-design/">https://dodonut.com/blog/10-dark-patterns-in-ux-design/</a>, See on <a href="https://news.ycombinator.com/item?id=38499824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content"><p>A dark pattern is a term created by designer Harry Brignull. These patterns urge or persuade the user to perform actions or accept conditions they did not intend to. Companies use them to trick users into doing things that can bring them profits.</p><p>For example, some dark patterns trick users or pressure them to buy additional items, subscribe to newsletters, or spend more time on an app. Designer Sally Woellner, as part of her <a href="https://www.ted.com/talks/sally_woellner_dark_patterns_how_design_seeks_to_control_us/transcript" target="_blank" rel="nofollow noopener noreferrer">TED talk about Dark Patterns</a>, calls them “worryingly effective,” and this is because they are. They focus on human psychology and marketing to hit the user’s most primitive emotional and neurological response.</p><p>Dark patterns are not present in user experiences by mistake. They are carefully crafted to appear during a certain moment of the user interaction process. Sometimes, there are design errors, and, by mistake, the interface or user flow happens to benefit the company and confuse or mislead the user. But when companies realize this creates a benefit for them and then intentionally keep it that way, it becomes a dark pattern.</p>
<h3><strong>Why do people fall for dark patterns?</strong></h3><p>Users often fall for dark patterns because of emotional or contextual ‘triggers,’ such as:</p><ul><li>Fear of missing out (your friend tagged you in this post; open the app to check it out!),</li><li>Sunk-cost fallacy (having to accept terms and conditions or subscribing to newsletters to finish a signing-up process)</li><li>Frustration (desisting from actions that are hidden or unnecessarily complicated).</li><li>Confusion (ambiguous or hidden content or results from actions).</li><li>Guilt ("Are you sure you want to leave? Your friends will miss you!").
</li></ul><figure>
<img alt="The newsletter subscription with three vague options: opt in, don't opt out, don't opt in." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/b0ca5759cebe934d0b8a64532e893dd211ecdcb3-775x435.png?w=1200&amp;fit=max&amp;auto=format" height="435" width="775">
<figcaption>This newsletter subscription is extremely ambiguous and poorly written on purpose.</figcaption>
</figure>
<h3>If dark patterns are bad, why do companies use them?</h3><p>At this point, it’s common to think: Why would companies use them in the first place? And you won’t be surprised to learn that the answer is money.</p><p>Industries generate more profit by creating a user experience that manipulates users to buy more, stay longer, or invite their friends to use their platforms. This usually only works in the short term, often at the expense of creating a frustrating experience. People remember bad experiences and negative emotions rather than positive ones.</p><blockquote><div><p>— Howard Lax, Bad is Stronger than Good: Lessons for Customer Experience and Employee Engagement (and Life) LinkedIn (2018)</p>
</div>
</blockquote><p>Let’s discuss some of the most common dark patterns in UX and what to do instead.</p><p>This is one of the most common dark patterns. Confirmshaming means appealing to emotional blackmail to persuade people to confirm or stop actions from taking place. It’s okay to ask users if they are aware of and wish to proceed with their decisions. However, the wording and the way that it is presented can quickly turn into a dark pattern.</p><p>For example, the platform Duolingo sends you an email with their signature pet (an owl) crying. This is one of the most universal -yet effective- communication methods: showing sadness or vulnerability. We know an owl can’t feel sad because we’re leaving a service. Most importantly, we know the owl is not even real! However, there is something that goes beyond logic and goes straight to our emotional core.</p><p>According to <a href="https://www.theverge.com/2018/12/13/18137843/duolingo-owl-redesign-language-learning-app" target="_blank" rel="nofollow noopener noreferrer">The Verge</a>, they have even redesigned Duolingo’s signature pet over the years to widen their (apparent) facial expressions and cause an emotional reaction.</p><figure>
<img alt="The screen of Duolingo app with sad owl and text: We haven't seen you in a while." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/0e75ff43b83988ed1413577a3f2eb646b4acee25-1042x1999.png?w=1200&amp;fit=max&amp;auto=format" height="1999" width="1042">
<figcaption>You made our digital drawing resembling a bird sad.</figcaption>
</figure><p>Similarly, creating fake urgency is another typical dark pattern in UX.</p><p>Dark patterns focus solely on the interest’s company while disregarding the user’s interest. However, they use wording and emotional manipulation to present this urgent notification as something valuable to the user. Most social media platforms nowadays create this fear of missing out (FOMO) by hinting that something is happening within the app but without explaining in detail what that means.</p><p>A good example is a notification along the lines of “Your friends miss you” or “You have been invited to an event” to encourage you and find out what this is. Once you click or tap on the notification, you are inside the app, and it can show you endless content and make you stay for hours.</p><p>We all know and understand that companies want their customers to spend as much time as possible on their apps. But this gets out of scale often, and in reality, it invades the user’s lives while providing very little value.</p><figure>
<img alt="Screenshot with Facebook notifications" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/9a7fae70daffccbd050fc625a805ba851e9936db-1284x758.jpg?w=1200&amp;fit=max&amp;auto=format" height="758" width="1284">
<figcaption>Facebook lets you know many things are happening right now, they just won’t tell you what those are. Source: Reddit </figcaption>
</figure><p>Nagging is, in other words, not accepting a ‘No’ for an answer.</p><p>The most obvious example is suggesting premium subscriptions or newsletters but without allowing the user to refuse permanently. Replacing the “No” option with a “Not now,” “Not yet,” or “Maybe later” removes the choice from the user to benefit the company. The user, eventually, may accept those conditions because they give up in a way after the platform has nagged them once a day, for example.</p><figure>
<img alt="The window with user avatar, description 'You're all set!&quot; and button: Next: Invite friends" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/e9936164e7d1fec050812cb1d1d36b35812fdec4-1999x1243.png?w=1200&amp;fit=max&amp;auto=format" height="1243" width="1999">
<figcaption>This example shows nagging and contact theft. Source: Chris Oliver / Medium</figcaption>
</figure><p>Also called obstruction, sneaking is the act of including a secondary action in the middle of (usually towards the end of) a primary action. The user wants to complete the primary action but is not entirely aware of or is manipulated into accepting the secondary action.</p><p>In the past, companies, mostly from e-commerce, have already used sneaking to include additional cheap products (such as mugs) or hidden costs in the final step of the action. Because the additional amount is so small, most users won't complain or ask for a refund.</p><p>The <a href="https://www.deceptive.design/types/sneaking" target="_blank" rel="nofollow noopener noreferrer">Deceptive Patterns page</a> has talked about this in the past with the Sports Direct case.</p><p>Companies can (and should) suggest items that may be valuable to the user, either by common sense or by data (e.g., items that users buy in tandem). But it becomes a dark UX pattern when they outright place products or services that the user does not care for, and would have never thought of getting them otherwise.</p><figure>
<img alt="The white mug with big letters standing on the desk. " loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/346bbca723a1504729f6152a0a4e2e12d77f6899-1920x1920.png?w=1200&amp;fit=max&amp;auto=format" height="1920" width="1920">
<figcaption>Sports Direct used to put an extra £1 mug on their customer’s online baskets. That is now illegal.</figcaption>
</figure><p>Social media sites disguise ads very easily nowadays because they present the content, as cards or “blocks” with infinite scrolling.</p><p>This allows them to “sneak” an ad seamlessly and present it as another post. They disclose the fact that they are including ads, but in a very discreet way that goes unnoticed. The user ends up confusing ads with the “real” content they want to see. This often causes the user to end up on a different website than intended.</p><p>Other times, they just end up viewing content they are not interested in, or that provides no value.</p><figure>
<img alt="The website view with disguised ads. " loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/2528e32566b34d0d2affadf5bb8fd5c4db5ef7c9-1999x1040.png?w=1200&amp;fit=max&amp;auto=format" height="1040" width="1999">
<figcaption>Disguised ads cause confusion because the user doesn’t know which one is the ‘real’ download button. </figcaption>
</figure><p>Intentional misdirection is the use of visual or text content that creates an outcome that is ambiguous, vague or, even worse, the opposite of the desired or expected outcome.</p><p>Let’s think of an example: a user wants to cancel a subscription to a newsletter. When asking to confirm this action, a button with the word ‘Cancel’ may have two meanings: either ‘confirm’ the cancellation or ‘cancel’ the cancellation. This can happen by unintentional or poor wording or visual indicators (color, shape).</p><figure>
<img alt="Nextdoor unsubscribe panel with switch button described Marketing Updates." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/7393e5e8053ee0276442ad3513a9d172af1c9a00-1139x369.png?w=1200&amp;fit=max&amp;auto=format" height="369" width="1139">
<figcaption>Nextdoor’s unsubscribe panel has an ambiguous switch button.</figcaption>
</figure><p>We see the roach motel pattern when actions that benefit the company are sometimes intuitive, enticing, and even pushy. Conversely, actions that benefit the user and not the company are complex, ambiguous, and tedious.</p><p>Companies often use this pattern to ‘lure’ the user into taking an action by confusing or manipulating them. They make this process extremely smooth and direct; once they perform those actions, it’s hard to cancel or undo them.</p><p>In most companies, subscribing to a newsletter is easy, straightforward, and pointed out with a big CTA. However, unsubscribing is done via email, and users need to find the word Unsubscribe with a small, gray font that goes easily unnoticed. Even after users try to unsubscribe, they are asked to confirm several times and fill out surveys that discourage them from continuing this process. Sometimes, they even need to make a phone call or even go to a physical office.</p><p>Amazon’s users have had issues when canceling their Amazon Prime subscription, and with deleting their accounts as well.</p><p>In fact, the company recently <a href="https://techcrunch.com/2022/07/01/amazon-ends-prime-cancellation-dark-patterns-europe/?guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAJByGnNzjsO3wkFeXRDPeTGc4b4PfUGu-EMHthPxZAKzG_T0z7NLr-9LcOtl9z7OeTkdoZbbP58vImtJ3sm9E2PsaHpIFOBrV96ZlBC79Pcfu_9BMgLKOm08bWLnrskps-6B6XDcyoHCyAGRt8nrvrHc_zUr0QG6wHrD5UukGR_P&amp;_guc_consent_skip=1696250550" target="_blank" rel="nofollow noopener noreferrer">had to simplify the process</a> required for canceling their Prime membership, to meet EU regulations.</p><figure>
<img alt="The screenshot from cancelling Amazon Prime" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/97de8b4aa09e0138722fce6a38ce419242174e2e-749x662.png?w=1200&amp;fit=max&amp;auto=format" height="662" width="749">
<figcaption>Amazon Prime puts endless barriers to canceling a membership. Source: Martyn Reding / Twitter </figcaption>
</figure><p>We see this dark pattern often in conjunction with the roach motel pattern. With preselection, users aren’t even enticed or manipulated into taking actions: the platform already ‘pre-selected’ these actions for them. Again, this pattern applies to actions that benefit the company and that users wouldn’t usually choose by themselves.</p><p>With preselection, users end up subscribing to newsletters or getting premium travel insurance without noticing, for example. When the company creates actions that only benefit them and not the user, it should be completely up to them to agree to that action after being informed of the possible benefits and conditions.</p><figure>
<img alt="Right and wrong examples of newsletter sign-up checkboxes where the wrong force users to sign up to the newsletter to get the PDF." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/6867c83b06bf6b56111e4538ddc0d86f3a9b9356-1047x697.png?w=1200&amp;fit=max&amp;auto=format" height="697" width="1047">
<figcaption>Pre-selected newsletter sign-up checkboxes are illegal in the EU.</figcaption>
</figure><p>Companies use friend spam to manipulate users into giving them social media permissions and access to their contacts.</p><p>They often disguise this action as ‘inviting your friends’ or similar actions that seem to offer a positive outcome to the user. IIn 2013, <a href="https://time.com/4062519/linkedn-spam-settlement/" target="_blank" rel="nofollow noopener noreferrer">LinkedIn received a lawsuit</a> for harvesting some of their user’s contacts, going as far as sending an email on the user’s behalf to all the people in their email contact list. This could go anywhere from their boss to a friend from high school.</p><figure>
<img alt="The view of mail from LinkedIn where the user get information that somebody wants to connect them on LinkedIn." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/bca6442e2b31950557efbfb729d89bbfcbf37cef-1092x728.png?w=1200&amp;fit=max&amp;auto=format" height="728" width="1092">
<figcaption>LinkedIn’s infamous friend spam. </figcaption>
</figure><p>Jonathan Shariat speaks about this experience in his book:</p><blockquote><div><p>— Jonathan Shariat and Cynthia Savard Saucier, “Tragic Design”, O’Reilly Media 2017</p>
</div>
</blockquote><p>With this another dark pattern, companies manipulate the user into giving their billing data or information, sometimes even promising a free trial or a discount in exchange for a product or service.</p><p>With time, they start charging a recurring billing or subscription with no chance to opt-out. They use wording and manipulation to assure the user they won’t be charged anything right now. They start charging money after a month or two when the user forgets the subscription.</p><p>In UX, it’s important to give the user control and freedom to the actions taking place on the platform. If these actions involve billing, it’s even more critical. This can be fixed easily by emailing the user to let them know they will start charging money 3-5 days before the end of the free trial.</p><figure>
<img alt="The view of purchase summary informing both about paying nothing at the moment with additional information below about automatic renewal." loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/ca95cd5c01515cee2c9ba24cbc1f05d20ada86b2-975x620.png?w=1200&amp;fit=max&amp;auto=format" height="620" width="975">
<figcaption>This is a (potentially) dark pattern. Warning the user they are going to be billed a few days beforehand would be a significant improvement to the user experience.</figcaption>
</figure><p>If we want to avoid dark patterns and deceptive design, we need a good combination of research and common sense.</p>
<h3>Following research data to avoid Dark Patterns</h3><ul><li><strong>Competitive Analysis:</strong> For research, it's essential to be aware of the competition. What are some good examples of UX from similar platforms? Do their users complain about UX dark patterns? How do they convince users to subscribe to newsletters or buy their products or services?</li><li><a href="https://dodonut.com/design/guerrilla-testing/" target="_blank" rel="noopener"><strong>User Testing</strong></a> is a great way to detect design errors that can potentially become dark patterns and also to see how users react to the wording, interface, and user flow (e.g., suggesting a premium subscription is too pushy or the wording makes them feel manipulated).</li></ul>
<h3>Following common sense to avoid Dark Patterns</h3><p>As designers and users of digital products, it’s safe to say we have increased our attunement and common sense over time. Platforms usually have similar dark patterns because they share similar goals: sell a product, offer a service, or increase outreach (e.g., newsletters, followers).</p><p>Here are some common sense tips to avoid dark patterns in UX:</p><ul><li>Be transparent with the user to earn their trust and give them control and freedom to make an informed decision before taking an action.</li><li>Test and iterate your product until there’s a balance between the user’s and the company’s best interests.</li><li>Follow the best design principles and usability heuristics to keep the design user-centered and avoid common mistakes.</li><li>Create design patterns that benefit the user, even if it harms the company. At some point, the user wants to feel valued and heard and that they control the platform, not the other way around.</li></ul><p>There are many ways to make the user feel valued and heard, even if it doesn’t directly benefit the company.</p><p>YouTube included two reminders to take a break and close the app every X minutes and also a bedtime reminder to stop using the app between 11 p.m. and 8 a.m., for example.</p><figure>
<img alt="Screenshot from YouTube app" loading="lazy" src="https://cdn.sanity.io/images/7viwlzb6/production/4392409f725d60758941d42e915ceda55702027e-1999x1690.png?w=1200&amp;fit=max&amp;auto=format" height="1690" width="1999">
<figcaption>The YouTube app encourages users to take breaks from the app to balance their experience and avoid burnout.</figcaption>
</figure><p>The YouTube mobile app includes tools to manage time spent on the app. Even though the platform encourages the user to spend more time, these reminders help balance the user’s experience and avoid burnout.</p><p>Ryanair has a dark pattern history, hiding their “Don’t insure me” option inside an unrelated dropdown menu. This was heavily criticized in the past and is now illegal in the UK and the European Union. Since then, they have changed it for a much more friendly user interface.</p><p>With these strategies, users will leave a genuine, positive impression. This leads to satisfaction, positive reviews, and profit in the long term. Also, it helps to create more&nbsp;<a href="https://dodonut.com/blog/digital-sustainability-how-to-go-green-with-digital-products/" target="_blank" rel="noopener">sustainable websites</a>&nbsp;because it reduces content on a website, emails, newsletters, and unnecessary information in general.</p><p>We all know that companies want to make money by offering products and services, and there’s nothing wrong with that!</p><p>But there’s a difference between inviting the user to interact with the platform in a certain way while still giving them a positive experience and pressuring the user to do things that do not benefit them or punishing them for acting in a way that does not benefit the company.</p><p>Companies can find several reasons to avoid dark patterns. By following best design practices, they can build a positive brand image, maintain customer trust, and adhere to legal and ethical standards. In a long-distance it promotes transparency and a long-term focus on customer satisfaction and loyalty, ultimately benefiting the company's growth and sustainability.</p><p>As UX designers, it’s not easy to balance out company profit and positive user experiences. Sometimes, we don’t even notice the design process we create causes frustration and even makes people lose money. But by learning more about dark patterns, we can understand further how to avoid them and enhance the user experience. After all, we can always strive to be more transparent and ethical to our target audience and, why not, to ourselves as well.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>