<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 31 Oct 2024 22:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[An Update on Apple M1/M2 GPU Drivers (106 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/995383/34dc5950cab5e739/</link>
            <guid>42011239</guid>
            <pubDate>Thu, 31 Oct 2024 20:36:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/995383/34dc5950cab5e739/">https://lwn.net/SubscriberLink/995383/34dc5950cab5e739/</a>, See on <a href="https://news.ycombinator.com/item?id=42011239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
The kernel graphics driver for the Apple M1 and M2 GPUs is, rather
famously, written in Rust, but it has achieved conformance with
various graphics standards, which is also noteworthy.  At the <a href="https://indico.freedesktop.org/event/6/">X.Org Developers Conference
(XDC)&nbsp;2024</a>, Alyssa Rosenzweig gave an update on the status of the
driver, along with some news about the kinds of games it can support (<a href="https://www.youtube.com/watch?v=TtLP5sAXYKo">YouTube video</a>, <a href="https://indico.freedesktop.org/event/6/contributions/284/attachments/230/310/slides.pdf">slides</a>).
There has been lots of progress since her talk at XDC last year (<a href="https://www.youtube.com/watch?v=O36VFNdQHsE">YouTube video</a>),
with, of course, still more to come.
</p>

<p>
It is something of an XDC tradition, since she began it in Montreal in&nbsp;2019
(<a href="https://www.youtube.com/watch?v=PqAAWzchHvk">YouTube video</a>),
for Rosenzweig to give her presentations dressed like a witch.
This year's edition was no exception, though this time she started her talk in
French, which resulted in some nervous chuckles from attendees. After a few
sentences, she switched to English, "<q>I'm just kidding</q>", and
continued with her talk.
</p>

<h4>Updates and tessellation</h4>

<p>
Last year at XDC, she and Asahi Lina reported that the driver had reached
<a href="https://en.wikipedia.org/wiki/OpenGL_ES">OpenGL ES</a>&nbsp;3.1
conformance.  They also talked about <a href="https://www.khronos.org/opengl/wiki/Geometry_Shader">geometry
shaders</a>, because "<q>that was the next step</q>".  Since then, the
driver has become <a href="https://en.wikipedia.org/wiki/OpenGL">OpenGL</a>&nbsp;4.6
conformant. That meant she was going to turn to talking about <a href="https://www.khronos.org/opengl/wiki/tessellation">tessellation</a>
shaders, "<q>as I threatened to do at the end of last year's talk</q>".
</p>

<p>
<a href="https://en.wikipedia.org/wiki/Tessellation_(computer_graphics)">Tessellation</a>,
which is a technique that "<q>allows detail to be dynamically added and
subtracted</q>" from a scene, is required for OpenGL&nbsp;4.0, and there is
a hardware tessellator on the Apple GPU—but, "<q>we can't use it</q>".  The
hardware is too limited to implement any of the standards; "<q>it is
missing features that are hard required for OpenGL, <a href="https://www.vulkan.org/">Vulkan</a>, and <a href="https://en.wikipedia.org/wiki/Direct3D">Direct3D</a></q>".  That
makes it "<q>pretty much useless to anybody who is not implementing <a href="https://en.wikipedia.org/wiki/Metal_(API)">Metal</a></q>".  Apple
supports OpenGL&nbsp;4.1, though it is not conformant, but if you use any
of the features that the hardware does not support, it simply falls back to
software; "<q>we are not going to do that</q>".
</p>

<p><a href="https://lwn.net/Articles/996249/">
<img src="https://static.lwn.net/images/2024/xdc-rosenzweig-sm.png" alt="[Alyssa Rosenzweig]" title="Alyssa Rosenzweig" width="225" height="280">
</a></p><p>
As far as Rosenzweig is aware, the hardware lacks <a href="https://docs.vulkan.org/spec/latest/chapters/tessellation.html#tessellation-point-mode">point mode</a>, where points
are used instead of the usual triangles; it also lacks <a href="https://docs.vulkan.org/spec/latest/chapters/tessellation.html#tessellation-isoline-tessellation">isoline</a>
support, but those two things can be emulated. The real problem comes
with <a href="https://www.khronos.org/opengl/wiki/Transform_Feedback">transform
feedback</a> and geometry shaders, neither of which is supported by the
hardware, but the driver emulates them with <a href="https://www.khronos.org/opengl/wiki/Compute_Shader">compute
shaders</a>.  However, the hardware tessellator cannot be used at all when
those are being emulated because minute differences in the tessellation algorithms used
by the hardware and the emulation would result in <a href="https://docs.vulkan.org/spec/latest/appendices/invariance.html">invariance</a>
failures.  She is not sure whether that is a problem in practice or not,
"<q>but the spec says not to do it</q>", so she is hoping not to have to go
that route.
</p>

<p>
Instead, "<q>we use software</q>".  In particular, Microsoft released a
reference tessellator a decade or more ago, which was meant to show
hardware vendors what they were supposed to implement when tessellation was
first introduced.  It is "<q>a giant pile of 2000 lines of C++</q>" that
she does not understand, despite trying multiple times; "<q>it is
inscrutable</q>". The code will tessellate a single <a href="https://www.khronos.org/opengl/wiki/tessellation#Patches">patch</a>, which gave the
driver developers an idea: "<q>if we can run that code, we can get the
tessellation outputs and then we can just draw the triangles or the lines
with this <a href="https://vulkan-tutorial.com/Vertex_buffers/Index_buffer">index buffer</a></q>".
</p>

<p>
There are some problems with that approach, however, starting with the fact
that the developers are writing a GPU driver; "<q>famously, GPUs do not like running
2000 lines of C++</q>".  But, she announced, "<q>we have conformant <a href="https://www.khronos.org/opencl/">OpenCL</a>&nbsp;3.0 support</q>"
thanks to Karol Herbst, though it has not yet been released.  OpenCL C is
"<q>pretty much the same as regular CPU C</q>", though it has a few
limitations and some extensions for GPUs.  So the idea would be to turn the
C++ tessellation code into OpenCL C code; "<q>we don't have to understand
any of it, we just need to not break anything when we do the port</q>".
</p>

<p>
That works, but "<q><tt>tessellator.cl</tt> is the most unhinged file of my
career</q>"; doing things that way was also the most unhinged thing she has done in her career
"<q>and I'm standing up here in a witch hat for the fifth year in a
row</q>". The character debuted in the exact same room in&nbsp;2019 when she
was 17 years old, she recalled.
</p>

<p>
The CPU tessellator only operates on a single patch at a time, but a scene
might have 10,000 patches—doing them all serially will be a real problem.
GPUs are massively parallel, though, so having multiple threads each doing
tessellation is "<q>pretty easy to arrange</q>".  There is a problem with
memory allocation; the CPU tessellator just allocates for each operation
sequentially, but that will not work for parallel processing.  Instead, the
driver uses the GPU atomic instructions to manage the allocation of output buffers.
</p>

<p>
In order to draw the output of the tessellators, though, there is a need to
use draw instructions with packed data structures as specified by the GPU.
That is normally done from the C driver code using functions that are <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/25498">generated
by the GenXML tool</a>.  Since the tessellators are simply C code,
"<q>thanks to OpenCL</q>", the generated functions can be included into the
code that runs on the GPU.  Rosenzweig went into more detail, which fills
in the holes (and likely inaccuracies) of the above description; those
interested in the details should look at the presentation video and her
slides.
</p>

<p>
"<q>Does it work?  Yes, it does.</q>"
She showed an image of terrain tessellation from a Vulkan demo.  It was run
on an M2 Mac with "<q>entirely OpenCL-based tessellation</q>". There is also
the question of "<q>how is the performance of this abomination?</q>"  The
answer is that it is "<q>okay</q>".  On the system, software-only terrain tessellation runs at
less than one frame-per-second (fps), which "<q>is not very fun for playing
games</q>"; for OpenCL, it runs at 265fps, which is "<q>pretty good</q>"
and is unlikely to be the bottleneck for real games.  The hardware
can do
820fps; "<q>I did wire up the hardware tessellator just to get a number for
this talk.</q>"   There is still room for improvement on the driver's
numbers, she said.
</p>

<h4>Vulkan and gaming</h4>

<p>
She also announced Vulkan&nbsp;1.3 conformance for the Honeykrisp M1/M2 GPU
driver. It <a href="https://rosenzweig.io/blog/vk13-on-the-m1-in-1-month.html">started</a>
by copying the <a href="https://docs.mesa3d.org/drivers/nvk.html">NVK
Vulkan driver for NVIDIA GPUs</a>, "<q>smashed against the [Open]GL&nbsp;4.6
[driver]</q>", which started passing the conformance test suite
"<q>in about a month</q>".  That was six months ago and, since then, she
has added geometry and tessellation shaders, transform feedback, and <a href="https://docs.vulkan.org/spec/latest/chapters/shaders.html#shaders-objects">shader
objects</a>.  The driver now supports every feature needed for multiple
DirectX versions.
</p>

<p>
There are a lot of problems "<q>if we want to run triple-A (AAA) games on
this system</q>", however.  A target game runs on DirectX and Windows on an x86 CPU with
4KB pages, but "<q>our target hardware is running literally none of those
things</q>". What is needed is to somehow translate DirectX to Vulkan,
Windows to Linux, x86 to Arm64, and 4KB pages to 16KB pages.  The first two
have a well-known solution in the form of the <a href="https://github.com/doitsujin/dxvk/wiki">DXVK driver</a> and <a href="https://www.winehq.org/">Wine</a>, which are "<q>generally packaged
into <a href="https://en.wikipedia.org/wiki/Proton_(software)">Proton</a>
for <a href="https://en.wikipedia.org/wiki/Steam_(service)">Steam</a> gaming</q>".
Going from x86 to Arm64 also has off-the-shelf solutions: <a href="https://fex-emu.com/">FEX-Emu</a> or <a href="https://box86.org/">Box64</a>.  She has a bias toward FEX-Emu;
"<q>when I am not committing <a href="https://www.mesa3d.org/">Mesa</a>
crimes, I am committing FEX-Emulation crimes</q>".  The big problem,
though, is the page-size difference.
</p>

<p>
FEX-Emu requires 4KB pages; Box64 has a "<q>hack to use 16KB pages, but it
doesn't work for Wine, so it doesn't help us here</q>".  MacOS can use 4KB
pages for the x86 emulation, but "<q>this requires very invasive kernel
support</q>";  <a href="https://asahilinux.org/">Asahi Linux</a> already has around 1000 patches that are making
their way toward the mainline kernel, but "<q>every one of those thousand
is a challenge</q>". Making changes like "<q>rewriting the Linux memory
manager</q>" is not a reasonable path.
</p>

<p>
It turns out that, even though Linux does not support heterogeneous page
sizes between different processes, it does support them between different
kernels; "<q>what I mean by that is virtualization</q>".  A KVM guest
kernel can have a different page size than the host kernel.  So, "<q>this
entire mess</q>", consisting of FEX-Emu, Wine, DXVK, Honeykrisp, Steam, and
the game, "<q>we are going to throw that into a virtual machine, which is
running a 4KB guest kernel</q>".
</p>

<p>
There is some overhead, of course, but it is hardware virtualization, so
that should have low CPU overhead.  The problem lies with the peripherals,
she said.  So, instead of having Honeykrisp in the host kernel, it runs in
the guest using <a href="https://indico.freedesktop.org/event/2/contributions/53/attachments/76/121/XDC2022_%20virtgpu%20drm%20native%20context.pdf">virtgpu</a>
native contexts;  all of the work to create the final GPU command buffer is done
in the guest and handed to the host, rather than making all of the Vulkan
calls individually traverse the virtual-machine boundary.  The <a href="https://docs.mesa3d.org/drivers/virgl.html">VirGL</a> renderer on the
host then hands that to the GPU, which "<q>is not 100% native speed, but
definitely well above 90%</q>", Rosenzweig said.
</p>

<p>
The good news is that the overheads for the CPU and GPU do not stack, since
the two run in parallel. "<q>So all the crap overhead we have in the CPU is
actually crap that is running in parallel to the crap overhead on the GPU,
so we only pay the cost once.</q>"
</p>

<p>
"<q>'Does it work?' is the question you all want to know.</q>"  It does,
she said, it runs
games like <a href="https://en.wikipedia.org/wiki/Portal_(video_game)">Portal</a> and <a href="https://en.wikipedia.org/wiki/Portal_2">Portal&nbsp;2</a>. She also listed a number of
others: <a href="https://en.wikipedia.org/wiki/Castle_Crashers">Castle Crashers</a>,
<a href="https://en.wikipedia.org/wiki/The_Witcher_3:_Wild_Hunt">The
Witcher&nbsp;3</a>, <a href="https://en.wikipedia.org/wiki/Fallout_4">Fallout&nbsp;4</a>, <a href="https://en.wikipedia.org/wiki/Control_(video_game)">Control</a>, <a href="https://en.wikipedia.org/wiki/Ghostrunner">Ghostrunner</a>, and <a href="https://en.wikipedia.org/wiki/Cyberpunk_2077">Cyberpunk&nbsp;2077</a>.
</p>

<p>
All of the different pieces that she mentioned were <a href="https://rosenzweig.io/blog/aaa-gaming-on-m1.html">made available</a>
on October&nbsp;10, the day of the talk.  For those running the <a href="https://asahilinux.org/fedora/">Fedora Asahi Remix</a> distribution,
she suggested immediately updating to pick up the pieces that
she had described.  Before taking questions, she launched Steam, which took
some time to come up, in part because of the virtual machine and the x86
emulation.  Once it came up, she launched Control, which ran at 45fps on an
M1 MAX system.
</p>

<p>
There was a question about resources from someone who has a Mac with 8GB of
RAM.  Rosenzweig said that the high-end gaming titles are only likely to
work on systems with 16GB or more.  She noted that she was playing Castle
Crashers on an 8GB system during the conference, so some games will play;
Portal will also work on that system.  She hopes that the resources
required will drop over time.
</p>

<p>
Another question was about <a href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)">ray-tracing</a>
support, since Control can use that <a href="https://www.khronos.org/blog/ray-tracing-in-vulkan">feature</a>.
Rosenzweig suggested that patches were welcome but that she did not see
that as a high priority ("<q>frankly, I think ray tracing is a bit of a
gimmick feature</q>").  Apple hardware only supports it with the M3 and
the current driver is for M1 and M2 GPUs, though she plans to start working
on M3 before long.  The session concluded soon after that, though
Rosenzweig played Control, admittedly poorly, as time ran down.
</p>

<p>
[ I would like to thank LWN's travel sponsor, the Linux Foundation, for
travel assistance to Montreal for XDC. ]
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/ConferenceIndex/">Conference</a></td><td><a href="https://lwn.net/Archives/ConferenceIndex/#X.Org_Developers_Conference-2024">X.Org Developers Conference/2024</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wait Until 8th (218 pts)]]></title>
            <link>https://www.waituntil8th.org</link>
            <guid>42011193</guid>
            <pubDate>Thu, 31 Oct 2024 20:32:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.waituntil8th.org">https://www.waituntil8th.org</a>, See on <a href="https://news.ycombinator.com/item?id=42011193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-20d2d7d07ef691626788">
  <h2>We empower parents to say yes to waiting for the smartphone.</h2><p>The Wait Until 8th pledge empowers parents to rally together to delay giving children a smartphone until at least the end of 8th grade. Let’s protect the elementary and middle school years from the distractions and the dangers of a smartphone. Banding together helps decrease the pressure to have a phone at an early age.&nbsp;Ten years old is the average age children get their first smartphone. You can change this! </p><p>More than 82,000 parents have said yes to waiting on the smartphone for their families. This is making a tremendous difference in communities across the country! </p><p>Smartphones are distracting and potentially dangerous for children yet are widespread in elementary and middle school because of unrealistic social pressure and expectations to have one.</p><p>These devices are quickly changing childhood for children. Playing outdoors, spending time with friends, reading books and hanging out with family is happening a lot less to make room for hours of snap chatting, instagramming, and catching up on YouTube.</p><p>Parents feel powerless in this uphill battle and need community support to help delay the ever-evolving presence of the smartphone in the classroom, social arena and family dinner table. Link arms with other parents to wait until at least the end of eighth grade for a smartphone! </p><p>By signing the online pledge, you promise not to give your child a smartphone until at least the end of 8th grade as long as at least 10 families total from your child’s grade and school pledge. &nbsp;Once 10 families have pledged to delay the smartphone, you will be notified that the pledge is active! You will receive a list of families who are delaying from your child’s grade and emails for the parents. It is helpful to be connected with other families waiting in your child’s grade. Check out our list of schools with <a href="https://www.waituntil8th.org/where-is-the-pledge" target="_blank">active pledges here!</a></p><p>The Wait Until 8th pledge encourages parents to delay the smartphone. If you need to get in touch before the end of 8th grade, we have some great basic phones and smartwatches <a href="https://www.waituntil8th.org/devices" target="_blank">featured here</a>. If you would like your child to have a basic phone or smartwatch to call and text only, you still can sign the pledge! These basic options avoid many of the distractions and dangers of the smartphone.&nbsp;</p><p>Childhood is too short to waste on a smartphone. Take the <a href="https://www.waituntil8th.org/take-the-pledge">pledge</a> today!&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ghost jobs are wreaking havoc on tech workers (152 pts)]]></title>
            <link>https://www.sfgate.com/tech/article/ghost-jobs-california-tech-industry-19871249.php</link>
            <guid>42010130</guid>
            <pubDate>Thu, 31 Oct 2024 18:49:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/tech/article/ghost-jobs-california-tech-industry-19871249.php">https://www.sfgate.com/tech/article/ghost-jobs-california-tech-industry-19871249.php</a>, See on <a href="https://news.ycombinator.com/item?id=42010130">Hacker News</a></p>
Couldn't get https://www.sfgate.com/tech/article/ghost-jobs-california-tech-industry-19871249.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing ChatGPT Search (637 pts)]]></title>
            <link>https://openai.com/index/introducing-chatgpt-search/</link>
            <guid>42008569</guid>
            <pubDate>Thu, 31 Oct 2024 16:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-chatgpt-search/">https://openai.com/index/introducing-chatgpt-search/</a>, See on <a href="https://news.ycombinator.com/item?id=42008569">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-chatgpt-search/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Smashing the Limits: Installing Windows XP in DOSBox-X (134 pts)]]></title>
            <link>https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/</link>
            <guid>42008499</guid>
            <pubDate>Thu, 31 Oct 2024 16:32:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/">https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/</a>, See on <a href="https://news.ycombinator.com/item?id=42008499">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>In my <a href="https://fabulous.systems/posts/2023/07/installing-windows-2000-in-dosbox-x/" target="_blank" rel="noopener">previous article</a>
, I described how I managed to install Windows 2000 in DOSBox-X.</p>
<p>Even though this experiment was successful, I was not really happy with the results. While I got Windows 2000 working, I didn’t want to stop there. The final goal for the project was to get Windows XP running instead. However, after multiple attempts I gave up, thinking that Windows XP was impossible to use.</p>
<p>Well - I was wrong. But let’s start at the beginning.</p>

<div>
<p>At the time of writing this article, running Windows XP isn’t officially supported by the DOSBox-X project. Don’t blame the developers for any issues - this is very experimental.</p></div>

<h2 id="previously">Previously…</h2>
<p>Since I wasn’t able to do a clean install of Windows 2000 due to driver and compatibility issues as described in my previous article, I started with the upgrade route right away. Upgrading from Windows 98 to Windows XP is officially supported, so I was pretty confident this would work for me as well.</p>
<p>I created a copy of the hard drive image after each step, so I was able to start the upgrade procedure with a clean installation of Windows 98 (Second Edition).</p>
<p>After mounting the Windows XP ISO image, I was greeted by the Windows XP Setup.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_upgrade_clean_selection.webp" alt="Windows XP Setup: Select between upgrade and clean install" loading="lazy">
  <figcaption>Windows XP Setup: Select between upgrade and clean install</figcaption>
</figure>



<p>Because of the issues I had with the clean installation of Windows 2000, I used the “Upgrade” installation type instead because that’s what worked for Windows 2000 as well.</p>
<p>After typing in the product key, the Setup was about to start the file copy process. In fact, it even started copying the installation files but failed at the very first file.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_98_xp_setup_error.webp" alt="Windows XP Setup failing to copy files during the upgrade" loading="lazy">
  <figcaption>Windows XP Setup failing to copy files during the upgrade</figcaption>
</figure>



<p>“The ISO must be bad!” I said to myself. I obtained this ISO file many years ago, so some silent file corruption was not entirely impossible. To avoid any potential issues caused by bad images, I always create checksum files immediately after obtaining the image. So, I compared the ISO image with the checksums I had - and to my surprise, I got a perfect match. The ISO image itself is absolutely fine since I have used it multiple times before.</p>
<p>To further investigate, I even went ahead and reinstalled Windows 98 from scratch to rule out any possible installation issues, but to my dismay, I encountered the same error message again.</p>
<p>Great. Getting another ISO image or starting with a fresh installation would have been <em>way</em> too easy, right?!</p>
<h2 id="back-to-square-one">Back to square one.</h2>
<p>Since the upgrade didn’t work as planned, I decided to proceed with a clean installation instead. Unfortunately, I encountered difficulties booting DOSBox-X from the ISO image. As a workaround, I launched the Setup from within another fresh Windows 98 installation just like I did for Windows 2000.</p>
<p>After my previous experience with the Windows XP Setup, I mentally prepared myself for yet another potential failure. However, to my surprise, this time the Setup didn’t just throw an error message at me; instead, it smoothly proceeded to copy over the temporary installation files. Crisis averted!</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_98_xp_setup_clean_copy_files.webp" alt="Windows XP Setup copying files, started from Windows 98" loading="lazy">
  <figcaption>Windows XP Setup copying files, started from Windows 98</figcaption>
</figure>



<p>One reboot later, I was greeted by the beloved and very familiar blue hue of the Windows XP Setup.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_text_installer.webp" alt="Windows XP Setup starting at the initial stage" loading="lazy">
  <figcaption>Windows XP Setup starting at the initial stage</figcaption>
</figure>



<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_text_installer_warning.webp" alt="Windows XP Setup: Yes, I know we have a previous version installed" loading="lazy">
  <figcaption>Windows XP Setup: Yes, I know we have a previous version installed</figcaption>
</figure>



<p>And now - the moment of truth. After confirming that we want to overwrite the existing Windows installation, Windows XP Setup started the next step of the installation by copying over the temporary installation files to the Windows directory.</p>
<p>I can’t say that I was surprised when the project stumbled across yet another issue. After copying over some files atrociously slow, it failed. No matter how often I retried, it always failed. I couldn’t track down the issue to one particular file though because on subsequent runs (yes, I tried!), it failed at a <em>different</em> file.</p>
<p>Based on the experience I had with the Windows 2000 installer I <em>think</em> this is related to either the IDE driver or the emulation of the IDE controller and the devices are simply dropping out of the system.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_text_installer_copy_error.webp" alt="Windows XP Setup failing to copy files" loading="lazy">
  <figcaption>Windows XP Setup failing to copy files</figcaption>
</figure>



<p>The next obvious way to solve this issue was to reboot the system and try to run Setup again. Unfortunately, this wasn’t an option either because after a reboot it simply failed to copy the very first file - turns out that Windows Setup already started to overwrite vital parts of the previous installation.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_text_installer_copy_error_after_reboot.webp" alt="Windows XP Setup failing to copy any file after a reboot" loading="lazy">
  <figcaption>Windows XP Setup failing to copy any file after a reboot</figcaption>
</figure>



<p>At this point, I gave up. Running Windows XP in DOSBox-X clearly wasn’t possible. Heck, I couldn’t even get the installation to work!</p>
<h2 id="new-technology-from-1999">New Technology from 1999</h2>
<p>“It is the NT conversion, stupid!”, I yelled at myself a couple of days later.</p>
<p>While Windows 98 is using MS-DOS to bootstrap the system and uses parts of it in its kernel, Windows XP uses the Windows NT platform instead. Just like Windows 2000!</p>
<p>What if swapping out the kernel requires some sort of low-level access I don’t have in DOSBox-X?</p>
<p>So I installed Windows 98 again, updated it to Windows 2000, fixed the missing taskbar, verified the system was working, mounted the Windows XP ISO, and started the installer again.</p>
<p>Because I was afraid that a clean installation would fail again, I went with the upgrade route once more. Not really knowing what to expect, I clicked on the magic button and waited.</p>
<p>And yes - this time, the upgrade seemed to work! No error messages this time!</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_setup_stage_1.webp" alt="Windows XP Setup started from Windows 2000" loading="lazy">
  <figcaption>Windows XP Setup started from Windows 2000</figcaption>
</figure>



<p>One reboot later, I noticed something very promising.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_setup_stage_2.webp" alt="Windows XP Setup: Now with colors!" loading="lazy">
  <figcaption>Windows XP Setup: Now with colors!</figcaption>
</figure>



<p>Instead of starting in the text-based installer again, I got a colorful graphic installer, indicating that Windows Setup was taking a different route this time. And amazingly, the installation ran just fine without any issues.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_setup_stage_3.webp" alt="Windows XP Setup: Installing Windows" loading="lazy">
  <figcaption>Windows XP Setup: Installing Windows!</figcaption>
</figure>



<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_setup_stage_4.webp" alt="Windows XP Setup: Finalizing installation" loading="lazy">
  <figcaption>Windows XP Setup: Finalizing installation</figcaption>
</figure>



<p>With this part of the installation complete, there was one last reboot to survive.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_booting_featured.webp" alt="Windows XP finally booting" loading="lazy">
  <figcaption>Windows XP finally booting</figcaption>
</figure>



<p>Windows XP was bootable and the installation itself was complete!</p>
<p>Soon thereafter, things started to go downhill though. After the first boot, Windows XP is supposed to start the so-called “Out of Box Experience” (OOBE) in order to finalize the installation by setting up some options and the user account.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_oobe.webp" alt="Windows XP OOBE" loading="lazy">
  <figcaption>Windows XP OOBE</figcaption>
</figure>



<p>The OOBE started, but what an experience it was! This wasn’t an experience. This was pure madness!</p>
<p>The <a href="https://soundcloud.com/stanlepard/1996-internet-starter-kit-velkommen-original-mix" target="_blank" rel="noopener">beautiful setup music</a>
 was cluttered with tons of distortion sounding like incredible compression artifacts caused by a <em>very</em> unhappy WMA decoder.</p>
<p>In fact, the performance was so poor that the system completely locked up and I had no other choice than rebooting the system.</p>
<p>Fortunately, Windows XP is able to migrate the user accounts from Windows 2000 because I had no option to create a new account - I guess I avoided yet another dead end.</p>
<p>And <em>yet another</em> reboot later - there it was. In all its glory.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_winver.webp" alt="Windows XP - it’s alive!" loading="lazy">
  <figcaption>Windows XP - it's alive!</figcaption>
</figure>



<p>I did it. Windows XP is running successfully in DOSBox-X.</p>
<p>Obviously, I had to retry the games I tried on Windows 2000. <em>The Sims</em> in the various versions I tried before still failed, but this was expected. <em>Roller Coaster Tycoon</em> improved by a lot. I couldn’t spot any sound issues this time and the game was perfectly playable.</p>
<p>And last but not least: Yes, the iconic <em>3D Pinball: Space Cadet</em> worked flawlessly as well.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_3d_pinball.webp" alt="Windows XP - 3D Pinball Space Cadet" loading="lazy">
  <figcaption>Windows XP - 3D Pinball Space Cadet</figcaption>
</figure>



<h2 id="closing-words">Closing words</h2>
<p>This is what I like about emulation and playing around with those systems so much. Even though some tasks seem to be impossible at first, there are always new routes to explore, helping you to achieve things many people (including yourself!) say are impossible.</p>
<p>I love it.</p>
<figure>
  <img src="https://fabulous.systems/posts/2023/07/installing-windows-xp-in-dosbox-x/windows_xp_turn_off_computer.webp" alt="It is now safe to turn off your computer." loading="lazy">
  <figcaption>It is now safe to turn off your computer.</figcaption>
</figure>



			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude for Desktop (138 pts)]]></title>
            <link>https://claude.ai/download</link>
            <guid>42007649</guid>
            <pubDate>Thu, 31 Oct 2024 15:04:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://claude.ai/download">https://claude.ai/download</a>, See on <a href="https://news.ycombinator.com/item?id=42007649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="region" aria-label="Notifications (F8)" tabindex="-1"><ol tabindex="-1"></ol></div><!--$--><div><p><span>Loading...</span></p></div><!--/$--></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fuzzing between the lines in popular barcode software (130 pts)]]></title>
            <link>https://blog.trailofbits.com/2024/10/31/fuzzing-between-the-lines-in-popular-barcode-software/</link>
            <guid>42006698</guid>
            <pubDate>Thu, 31 Oct 2024 13:28:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.trailofbits.com/2024/10/31/fuzzing-between-the-lines-in-popular-barcode-software/">https://blog.trailofbits.com/2024/10/31/fuzzing-between-the-lines-in-popular-barcode-software/</a>, See on <a href="https://news.ycombinator.com/item?id=42006698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">

			
				
<article id="post-108489">
	<!-- .entry-header -->

	<div>
		<p><em>By Artur Cygan</em></p>
<p>Fuzzing—one of the most successful techniques for finding security bugs, consistently featured in articles and industry conferences—has become so popular that you may think most important software has already been extensively fuzzed. But that’s not always the case. In this blog post, we show how we fuzzed the ZBar barcode scanning library and why, despite our limited time budget, we found serious bugs: an out-of-bounds stack buffer write that can lead to arbitrary code execution with a malicious barcode, and a memory leak that can be used to perform a denial-of-service attack.</p>
<p>ZBar is an open-source library for reading barcodes written in C. It supports an impressive number of barcode formats, including QR codes. One of our clients used it, so we wanted to quickly assess its security. Given the extensive amount of code, manual review was not an option. Since we noticed no public mention of fuzzing, we decided to give it a shot.</p>
<h3>Assessing the project’s fuzzing state</h3>
<p>You might ask: how do you know whether or not software has been fuzzed? Although there’s no definitive answer to this question, it’s possible to make some educated guesses. First, we can check the repository for any mention of fuzzing, including searching issues, pull requests, and the code itself. For instance, <a href="https://github.com/mchehab/zbar/issues/233">this issue</a> proposes a fuzzing harness, but it was likely never run. Second, we can check <a href="https://github.com/google/oss-fuzz/tree/master/projects">the oss-fuzz projects</a>. If the project is fuzzed with oss-fuzz, it’s worth checking if the fuzzing harnesses are targeting the functionality we’re interested in and whether the project actually works. We observed cases where project builds were failing for months and were not actively fuzzed. Similarly to the project’s repository, oss-fuzz issues and pull requests can contain interesting information. Developers expressed <a href="https://github.com/google/oss-fuzz/issues/3863">some interest</a> in bringing ZBar to oss-fuzz, but this was ultimately abandoned.</p>
<p>By this point we knew two things about ZBar: it was barely fuzzed (or not fuzzed at all), and we identified starting points for creating our own fuzzing campaign.</p>
<h3>Instrumenting the build</h3>
<p>To fuzz ZBar, it has to be built with sanitizer and fuzzer instrumentation. Building an unfamiliar project can be a time-consuming challenge on its own, and adding instrumentation for fuzzing often makes this task even more difficult. For that reason, it’s useful to take an existing build and tweak it. Fortunately, ZBar is already <a href="https://github.com/NixOS/nixpkgs/blob/011567f35433879aae5024fc6ec53f2a0568a6c4/pkgs/tools/graphics/zbar/default.nix">packaged in Nixpkgs</a>, so we could quickly modify the build:</p>
<pre>zbar-instrumented = with pkgs; (zbar.override {
  stdenv = clang16Stdenv;
}).overrideAttrs (orig: {
  buildInputs = orig.buildInputs ++ [ llvmPackages_16.openmp ];
  dontStrip = true;
  doCheck = false; # tests started failing with sanitizers
  CFLAGS = "-g -fsanitize=address,fuzzer-no-link";
  LDFLAGS = "-g -fsanitize=address,fuzzer-no-link";
});
</pre>
<p>Figure 1: Instrumenting ZBar for fuzzing</p>
<p>Nix packages are described with the Nix programming language and can be easily manipulated in various ways. In the case above, we use override to modify <a href="https://github.com/NixOS/nixpkgs/blob/011567f35433879aae5024fc6ec53f2a0568a6c4/pkgs/tools/graphics/zbar/default.nix#L1-L30">inputs</a> defined by the package where we set the package’s compiler to Clang (otherwise, GCC is used by default). The following <code>overrideAttrs</code> function is a free-form override that allows us to modify anything we want. With <code>overrideAttrs</code>, we add the missing <code>openmp</code> dependency, disable stripping so that debug build works properly, and disable the tests. Finally, we add the instrumentation compiler and linker flags for AddressSanitizer and libFuzzer. (If you’re unfamiliar with the instrumentation flags, our <a href="https://appsec.guide/">AppSec Testing Handbook</a> has excellent <a href="https://appsec.guide/docs/fuzzing/c-cpp/libfuzzer/">guidance</a>.)</p>
<p>Obviously, Nix is not the only answer to this problem. Depending on the software and packaging, tweaking existing packages might be more difficult. However, we highly recommend trying it out, as we found it to be often the quickest way to achieve the goal.</p>
<h3>How to identify the target</h3>
<p>After preparing the instrumentation, we need to identify the fuzzing target. This part heavily depends on the project and can be non-trivial. Luckily, in ZBar the target was quite obvious: the function that takes an image and decodes barcode data from it. At this point there are a few questions to answer. How big should the image be? By default, ZBar tries to read all the known code types. Should we configure the scanner to specific codes or just try them all at once? We think it’s important not to overthink this and start with <em>something</em> to see how it performs. We started with the following harness, based on <a href="https://github.com/ZBar/ZBar/blob/854a5d97059e395807091ac4d80c53f7968abb8f/examples/scan_image.c#L65-L104">the official example</a>:</p>
<pre>#include <span>&lt;stdio.h&gt;</span>
#include <span>&lt;stdlib.h&gt;</span>
#include <span>&lt;zbar.h&gt;</span>

using namespace zbar;

extern "C" int LLVMFuzzerTestOneInput(const uint8_t *data, uint32_t size) {
  int width = 16, height = 16;
  if (size != width*height) return 1;

  zbar_image_t *image = zbar_image_create();
  if(!image)
    return 0;

  zbar_image_set_size(image, width, height);
  zbar_image_set_format(image, zbar_fourcc('Y', '8', '0', '0'));
  zbar_image_set_data(image, data, size, NULL);

  /* create a reader */
  zbar_image_scanner_t *scanner = zbar_image_scanner_create();

  /* configure the reader */
  zbar_image_scanner_set_config(scanner, (zbar_symbol_type_t)0, ZBAR_CFG_ENABLE, 1);
  zbar_scan_image(scanner, image);

  /* clean up */
  zbar_image_destroy(image);
  zbar_image_scanner_destroy(scanner);
  return 0;
}
</pre>
<p>Figure 2: Initial testing harness</p>
<p>In this harness, we essentially modified the sample to take the input image from the fuzzer and locked it down to a 2-by-2 pixel square (8 bits per pixel). Running this harness resulted in one <code>LeakSanitizer</code> crash reporting a memory leak. Because <code>libFuzzer</code> stops at the first crash, we disabled the memory leak detection with <code>-detect_leaks=0</code> and continued fuzzing. After a while, the coverage gains appeared to stall, so we decided to enlarge the input image to 4-by-4 pixels. Surprisingly, libFuzzer struggled to figure out that input should be of size 1024 and couldn’t start fuzzing. Even tweaking the <code>max_len</code> and <code>len_control</code> options didn’t help. we managed to kickstart fuzzing by manually passing a seed input of the right size:</p>
<pre>$ head -c 1024 /dev/zero &gt; seed
$ ./result/bin/zbar-fuzz -detect_leaks=0 -seed_inputs=seed
</pre>
<p>Figure 3: Manually passing the seed input</p>
<p>After this, the fuzzer was able to quickly find another crash from AddressSanitizer caused by a stack buffer overflow. If you paid attention to the ZBar instrumentation code, we mentioned in the comment that its tests are disabled due to sanitizer failure. It turned out the failure during tests wasn’t a false positive and concerned the same bug the fuzzer discovered.</p>
<p>Even with this simple approach, we managed to find some bugs in the library. However, with more time, we could have made a number of improvements to find even more bugs:</p>
<ul>
<li>Initiate the corpus with pictures of code types to help the fuzzer cover the code more quickly</li>
<li>Target specific codes that could help the fuzzer maintain a homogenous corpus and generate more accurate mutations</li>
<li>Check code coverage where it stalls to help the fuzzer get past any difficult branches</li>
</ul>
<h3>Diagnosing crashes</h3>
<p>It turned out that the stack buffer out-of-bounds write bug was independently reported around the same time by another researcher. The vulnerability was assigned <a href="https://nvd.nist.gov/vuln/detail/CVE-2023-40890">CVE-2023-40890</a> and was fixed in commit <a href="https://github.com/mchehab/zbar/commit/012a030250a203e5529d09caedea7ad7173dacfd">012a030</a>. The issue lied in the lookup_sequence function, as the fuzzer pointed out:</p>
<pre>==22005==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fa297900578 at pc 0x7fa299b84ee2 bp 0x7ffe86531ef0 sp 0x7ffe86531ee8
WRITE of size 4 at 0x7fa297900578 thread T0
    #0 0x7fa299b84ee1 in lookup_sequence /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/decoder/databar.c:698:12
    #1 0x7fa299b84ee1 in match_segment_exp /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/decoder/databar.c:758:21
    #2 0x7fa299b7fc02 in decode_char /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/decoder/databar.c:1081:16
    #3 0x7fa299b7e225 in _zbar_decode_databar /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/decoder/databar.c:1269:11
    #4 0x7fa299b756a6 in zbar_decode_width /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/decoder.c:274:15
    #5 0x7fa299b726c1 in process_edge /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/scanner.c:173:16
    #6 0x7fa299b726c1 in zbar_scanner_flush /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/scanner.c:186:35
    #7 0x7fa299b7088a in quiet_border /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/img_scanner.c:708:5
    #8 0x7fa299b7088a in _zbar_scan_image /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/img_scanner.c:1020:13
    #9 0x7fa299b6e978 in zbar_scan_image /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/img_scanner.c:1146:12
    #10 0x55c5b5f36a0f in LLVMFuzzerTestOneInput /tmp/nix-build-zbar-fuzz-0.23.92.drv-0/zbar/fuzz.cpp:25:3
    ...
    #17 0x55c5b5d192e4 in _start (/nix/store/1lk9b8j92dx5xjfnhwh2g3x2g4d9mvsd-zbar-fuzz-0.23.92/bin/.zbar-fuzz-wrapped+0x352e4)

Address 0x7fa297900578 is located in stack of thread T0 at offset 376 in frame
    #0 0x7fa299b80b8f in match_segment_exp /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/decoder/databar.c:709

  This frame has 4 object(s):
    [32, 120) 'bestsegs' (line 711)
    [160, 248) 'segs' (line 711)
    [288, 376) 'seq' (line 711) &lt;== Memory access at offset 376 overflows this variable
    [416, 544) 'iseg' (line 713)
</pre>
<p>Figure 4: Fuzzer triggered of out-of-bounds write bug</p>
<p>This memory leak bug opens a denial-of-service attack vector, especially since the leak size depends on the input and appears to be the <code>image border size / 2 * 8 * 3 bytes</code>, so for an image with a border of 512, the leak is 6KiB. A program using ZBar to repeatedly scan untrusted codes can eventually exhaust memory and crash. The root issue is in the <a href="https://github.com/mchehab/zbar/blob/a549566ea11eb03622bd4458a1728ffe3f589163/zbar/sqcode.c#L300-L578"><code>_zbar_sq_decode</code></a> function, which fails to free allocated memory under certain error conditions. This is again correctly pointed out by the fuzzer:</p>
<pre>==21815==ERROR: LeakSanitizer: detected memory leaks

Direct leak of 48 byte(s) in 1 object(s) allocated from:
    #0 0x55df498b66ff in __interceptor_malloc (/nix/store/ncb5qgjr6jds4na1iadf5cxgdym6fbl5-zbar-fuzz-0.23.92/bin/.zbar-fuzz-wrapped+0x20b6ff)
    #1 0x7f71e9334cbf in _zbar_sq_decode /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/sqcode.c:397:19
    #2 0x7f71e92d7cf8 in _zbar_scan_image /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/img_scanner.c:1055:5
    #3 0x7f71e92d5978 in zbar_scan_image /tmp/nix-build-zbar-0.23.92.drv-0/source/zbar/img_scanner.c:1146:12
    #4 0x55df498fda0f in LLVMFuzzerTestOneInput /tmp/nix-build-zbar-fuzz-0.23.92.drv-0/zbar/fuzz.cpp:25:3
    ...
    #11 0x7f71e8f8bacd in __libc_start_call_main (/nix/store/46m4xx889wlhsdj72j38fnlyyvvvvbyb-glibc-2.37-8/lib/libc.so.6+0x23acd) (BuildId: 2ed90a3fa8dfeee1e77c301df6ba346580b73e8a)
...
SUMMARY: AddressSanitizer: 144 byte(s) leaked in 3 allocation(s).
</pre>
<p>Figure 5: Fuzzer triggers a memory leak bug</p>
<p>The root cause of the leak is missing memory cleanup in error paths. There are two instances where the <code>_zbar_sq_decode</code> function returns without executing the cleanup code under the <a href="https://github.com/mchehab/zbar/blob/a549566ea11eb03622bd4458a1728ffe3f589163/zbar/sqcode.c#L572-L576"><code>free_borders</code></a> label.</p>
<pre>diff --git a/zbar/sqcode.c b/zbar/sqcode.c
index 422c803d..a5e808fc 100644
--- a/zbar/sqcode.c
+++ b/zbar/sqcode.c
@@ -371,7 +371,7 @@ found_start:;
        border_len = 1;
        top_border = malloc(sizeof(sq_point));
        if (!top_border)
-       return 1;
+       goto free_borders;
        top_border[0] = top_left_dot.center;
    }
     }
@@ -471,7 +471,7 @@ found_start:;
    }
     }
     if (cur_len != border_len || border_len &lt; 6)
-   return 1;
+   goto free_borders;
     inc_x        = right_border[5].x - right_border[3].x;
     inc_y        = right_border[5].y - right_border[3].y;
     right_border[2].x = right_border[3].x - 0.5 * inc_x;
</pre>
<p>Figure 6: _zbar_sq_decode returns without executing cleanup code</p>
<p>We reported this issue along with the patch to the maintainer, however, after an extended period of time we still haven’t heard back. We published <a href="https://github.com/trail-of-forks/zbar/commit/6059b7f2c97595aca5077e6c357617ff132e79fd.patch">this patch on our ZBar fork</a> and opened <a href="https://github.com/mchehab/zbar/pull/294">a pull request</a> in the upstream ZBar repository.</p>
<h3>Putting it all together</h3>
<p>To reproduce the research from this article, save the fuzzing harness shown earlier as <code>zbar_harness.cpp</code> and the following Nix file as <code>zbar-fuzz.nix</code>. The Nix file already contains the instrumented ZBar build and the harness build. Build it with <code>nix-build zbar-fuzz.nix</code> and run <code>./result/bin/zbar-fuzz</code>. The <code>postInstall</code> phase is not strictly required but ensures that the harness has llvm-symbolizer available to show the source locations, which helps in diagnosing the root cause.</p>
<pre>let
  # nixpkgs snapshot from Aug 7, 2023
  pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/011567f35433879aae5024fc6ec53f2a0568a6c4.tar.gz") {};

  zbar-instrumented = with pkgs; (zbar.override {
    stdenv = clang16Stdenv;
  }).overrideAttrs (orig: {
    buildInputs = orig.buildInputs ++ [ llvmPackages_16.openmp ];
    dontStrip = true;
    doCheck = false; # tests fail with sanitizer
    CFLAGS = "-g -fsanitize=address,fuzzer-no-link";
    LDFLAGS = "-g -fsanitize=address,fuzzer-no-link";
  });

in with pkgs; clang16Stdenv.mkDerivation rec {
 pname = "zbar-fuzz";
 version = zbar.version;
 src = ./.;

 nativeBuildInputs = [ makeWrapper ];

 buildInputs = [ zbar-instrumented ];

 dontStrip = true;

 buildPhase = ''
   mkdir -p $out/bin
   clang++ zbar_harness.cpp -fsanitize=address,fuzzer -g -lzbar -o $out/bin/zbar-fuzz
 '';

 postInstall = ''
   wrapProgram $out/bin/zbar-fuzz \
     --prefix PATH : ${lib.getBin llvmPackages_16.llvm}/bin
 '';
}
</pre>
<p>Figure 7: Instrumented ZBar build and the harness build</p>
<h3>Lessons learned</h3>
<p>There are a few takeaways from this experiment. First, it’s important to fuzz the unsafe code even if you don’t have a lot of time to do so. Other researchers can expand on the work by increasing the code coverage of the fuzzer.</p>
<p>Cut out any unnecessary features to limit attack vectors. ZBar by default scans all code types, which means that an attacker can trigger a bug in any of the scanners. If you only need to scan QR codes for instance, then ZBar can be configured to do so in the code:</p>
<pre>zbar_image_scanner_set_config(scanner, (zbar_symbol_type_t)0, ZBAR_CFG_ENABLE, 0);
zbar_image_scanner_set_config(scanner, ZBAR_QRCODE, ZBAR_CFG_ENABLE, 1);
</pre>
<p>Figure 8: Configuring ZBar to scan only QR codes</p>
<p>Or when using the <code>zbarimg</code> CLI program, add the options: <code>--set '*.enable=0' --set 'qr.enable=1'</code>.</p>
<p>Finally, add sanitizer instrumentation to your build. At the bare minimum, you should use AddressSanitizer. As this ZBar example shows, if the test were built with sanitizers, it would have caught a critical memory safety vulnerability. Another benefit is that sanitizers save time and effort for adding fuzzing to a project, as sanitizers are essentially a required step for fuzzing C/C++ code.</p>
<p>We use fuzzing extensively at Trail of Bits. Take a look at our <a href="https://appsec.guide/docs/fuzzing/">Testing Handbook</a> for more resources, and <a href="https://www.trailofbits.com/contact/">contact us</a> if you’re interested in custom fuzzing for your project.</p>

			</div><!-- .entry-content -->

	
</article><!-- #post-108489 -->
						<!-- #nav-below -->
		
					<!-- #comments .comments-area -->

			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sorry, Gas Companies – Parody Isn't Infringement (Even If It Creeps You Out) (197 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/10/sorry-gas-companies-parody-isnt-infringement-even-if-it-creeps-you-out</link>
            <guid>42006265</guid>
            <pubDate>Thu, 31 Oct 2024 12:37:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/10/sorry-gas-companies-parody-isnt-infringement-even-if-it-creeps-you-out">https://www.eff.org/deeplinks/2024/10/sorry-gas-companies-parody-isnt-infringement-even-if-it-creeps-you-out</a>, See on <a href="https://news.ycombinator.com/item?id=42006265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span data-contrast="auto">Activism comes in many forms. You might </span><a href="https://www.eff.org/deeplinks/2021/09/protestors-nationwide-rally-tell-apple-dont-break-encryption-dont-break-your"><span data-contrast="none">hold a rally</span></a><span data-contrast="auto">, </span><a href="https://act.eff.org/"><span data-contrast="none">write to Congress</span></a><span data-contrast="auto">, or </span><a href="https://www.eff.org/press/releases/diverse-groups-fly-airship-over-nsas-utah-data-center-protest-illegal-internet-spying"><span data-contrast="none">fly a blimp</span></a><span data-contrast="auto"> over the NSA. </span><i><span data-contrast="auto">Or</span></i><span data-contrast="auto"> you might use a </span><a href="https://repaer.earth/"><span data-contrast="none">darkly hilarious parody</span></a><span data-contrast="auto"> to make your point, like our client Modest Proposals recently did.</span><span data-ccp-props="{}"> <br></span></p>
<p><span data-contrast="auto">Modest Proposals is an activist collective that uses parody and culture jamming to advance environmental justice and other social causes. As part of a </span><a href="https://www.themodestproposals.org/life-offsets.html"><span data-contrast="none">campaign</span></a><span data-contrast="auto"> shining a spotlight on the environmental damage and human toll caused by the liquefied natural gas (LNG) industry, Modest Proposals invented a company called Repaer. The fake company’s </span><a href="https://repaer.org/"><span data-contrast="none">website</span></a><span data-contrast="auto"> offers energy companies the opportunity to purchase “life offsets” that balance the human deaths their activities cause by extending the lives of individuals deemed economically valuable. The website also advertises a “Plasma Pals” program that encourages parents to donate their child’s plasma to wealthy recipients. Scroll down on the homepage a bit, and you’ll see the logos for three (real) LNG companies—Repaer’s “Featured Partners.”</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-ccp-props="{}">Believe it or not, the companies didn’t like this. (Shocking!) Two of them—TotalEnergies and Equinor—sent our client stern emails threatening legal action if their names and logos weren’t removed from the website. TotalEnergies also sent a demand to the website’s hosting service, Netlify, that got repaer.earth taken offline. That was our cue to get involved.</span><span data-ccp-props="{}"> <br></span></p>
<p><span data-contrast="auto">We sent&nbsp;<a href="https://www.eff.org/document/eff-letter-totalenergies-re-modest-proposals">letters</a> to both companies, explaining what should be obvious: the website was a noncommercial work of activism, unlikely to confuse any reasonable viewer. Trademark law is about protecting consumers; it’s not a tool for businesses to shut down criticism. We also sent a counternotice to Netlify denying TotalEnergies’ allegations and demanding that repaer.earth be restored.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-ccp-props="{}">&nbsp;We wish this were the first time we’ve had to send letters like that, but EFF regularly helps activists and critics push back on bogus </span><a href="https://www.eff.org/deeplinks/2024/09/climate-has-posse-and-so-does-political-satire"><span data-contrast="none">trademark</span></a><span data-contrast="auto"> and </span><a href="https://www.eff.org/deeplinks/2024/08/copyright-not-tool-silence-critics-religious-education"><span data-contrast="none">copyright</span></a> <a href="https://www.eff.org/deeplinks/2024/03/sxsw-tried-silence-critics-bogus-trademark-and-copyright-claims-eff-fought-back"><span data-contrast="none">claims</span></a><span data-contrast="auto">. This incident is also part of a broader and long-standing pattern of the energy industry weaponizing the law to quash dissent by environmental activists. </span><a href="https://www.eff.org/takedowns/landis-gyr-agrees-leave-documents-then-sends-notice-take-them-down"><span data-contrast="none">These</span></a> <a href="https://www.eff.org/press/releases/eff-and-eri-fight-quash-speech-chilling-subpoenas-chevron"><span data-contrast="none">are</span></a> <a href="https://www.eff.org/deeplinks/2010/01/and-another-one-takedown-hall-shame-peabody-energy"><span data-contrast="none">just</span></a> <a href="https://www.eff.org/deeplinks/2013/08/using-copyright-silence-oil-company-satire-how-crude"><span data-contrast="none">examples</span></a> <a href="https://www.eff.org/deeplinks/2011/05/utah-court-strikes-blow-free-speech-dismisses"><span data-contrast="none">EFF</span></a> <a href="https://www.eff.org/deeplinks/2023/04/greenpeace-stands-against-slapps-and-wins"><span data-contrast="none">has</span></a> <a href="https://www.eff.org/press/archives/2010/01/05"><span data-contrast="none">written</span></a> <a href="https://www.eff.org/deeplinks/2022/09/its-time-federal-anti-slapp-law-protect-online-speakers"><span data-contrast="none">about</span></a><span data-contrast="auto">. We’ve been fighting these tactics for a long time, both by representing individual activist groups and through supporting legislative efforts like a </span><a href="https://www.eff.org/deeplinks/2022/09/its-time-federal-anti-slapp-law-protect-online-speakers"><span data-contrast="none">federal anti-SLAPP bill</span></a><span data-contrast="auto">.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">Frustratingly, Netlify made us go through the full </span><a href="https://www.eff.org/issues/dmca"><span data-contrast="none">DMCA</span></a><span data-contrast="auto"> counternotice process—including a 10-business-day waiting period to have the site restored—even though this was never a DMCA claim. (The DMCA is copyright law, not trademark, and TotalEnergies didn’t even meet the notice requirements that Netlify claims to follow.) Rather than wait around for Netlify to act, Modest Proposals eventually moved the website to a different hosting service.&nbsp; </span><span data-ccp-props="{}"><br></span></p>
<p><span data-contrast="auto">Equinor and TotalEnergies, on the other hand, have remained silent. This is a pretty common result when we help push back against bad trademark and copyright claims: the rights owners slink away once they realize their bullying tactics won’t work, without actually admitting they were wrong. We’re glad these companies seem to have backed off regardless, but victims of bogus claims deserve more certainty than this.</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Moving to a World Beyond "p < 0.05" (2019) (140 pts)]]></title>
            <link>https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913</link>
            <guid>42005635</guid>
            <pubDate>Thu, 31 Oct 2024 11:16:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913">https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913</a>, See on <a href="https://news.ycombinator.com/item?id=42005635">Hacker News</a></p>
Couldn't get https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: TikTok Influencers Database with Analyzed Audio (220 pts)]]></title>
            <link>https://www.topyappers.com/</link>
            <guid>42005516</guid>
            <pubDate>Thu, 31 Oct 2024 10:56:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.topyappers.com/">https://www.topyappers.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42005516">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tr><td></td><td><span>Business &amp; Entrepreneurship</span></td><td><span>4.6K</span></td><td></td><td></td><td><p><span>Social Media Marketing Agencies</span><span>Video Production Services</span><span>Digital Marketing Courses</span><span>Personal Branding Coaching</span><span>Small Business Marketing</span></p></td><td><p>TikTok, Instagram, YouTube, Audiobook.com, Fiverr, Mercedes</p></td><td></td></tr><tr><td><div><p>Investwithnat | Finance Bestie</p><p>investwithnat</p></div></td><td><span>Finance</span></td><td><span>58.4K</span></td><td></td><td></td><td><p><span>Financial services</span><span>Investment platforms</span><span>Credit card companies</span><span>High-yield savings accounts</span><span>Real estate</span></p></td><td><p>Sofi, S&amp;P 500, Collective, Yelp Elite, Alaska Airlines Visa Signature card, Roth IRA, Apartments.com</p></td><td></td></tr><tr><td></td><td><span>Education and Career</span></td><td><span>491.3K</span></td><td></td><td></td><td><p><span>Tech Education</span><span>Software Development</span><span>Online Learning Platforms</span><span>Career Coaching</span><span>Startups and Entrepreneurship</span></p></td><td><p>Brev</p></td><td></td></tr><tr><td></td><td><span>Education</span></td><td><span>29.6K</span></td><td></td><td></td><td><p><span>Online Learning Platforms</span><span>Financial Services</span><span>Tech Tools for Professionals</span><span>AI Products</span><span>Career Coaching</span></p></td><td><p>Undetectable AI, Servicenow, Nvidia, ChatGBT, GitHub, Numerai, QuantConnect, Olaide</p></td><td></td></tr><tr><td><div><p>courtney johnson</p><p>courtney..johnson</p></div></td><td><span>Career and Personal Development</span></td><td><span>224.4K</span></td><td></td><td></td><td><p><span>Career Coaching</span><span>Resume Services</span><span>Social Media Management Tools</span><span>Online Courses for Professionals</span></p></td><td><p>Tango, Gumroad</p></td><td></td></tr><tr><td><div><p>Finance Bro</p><p>youraveragefinancebro</p></div></td><td><span>Finance &amp; Business</span></td><td><span>270.8K</span></td><td></td><td></td><td><p><span>Financial education</span><span>Career advice for finance professionals</span><span>Microsoft Excel tutorials</span><span>Productivity hacks</span><span>Financial technology</span></p></td><td><p>Microsoft Excel, Patagonia, Enron, Taco Bell, Crunch Wraps, Scribe, Carousel, Powerpoint, Kalshe, Taylor Swift, Nvidia, McDonald's, Wendy's, Theranos, JMP, Black Rock, Instagram, LinkedIn, Bitcoin, BTC</p></td><td></td></tr><tr><td><div><p>Corporate Steve &amp; Co…</p><p>beyondeducation_</p></div></td><td><span>Career &amp; Business</span></td><td><span>23.7K</span></td><td></td><td></td><td><p><span>Recruitment Agencies</span><span>Diversity &amp; Inclusion Training</span><span>Career Coaching</span><span>Job Search Platforms</span><span>Corporate Culture Consultants</span></p></td><td><p>L’Oréal, Hsbc, GTA 6</p></td><td></td></tr><tr><td><div><p>Jerry Chen | MisoDope</p><p>misodope</p></div></td><td><span>Software Development</span></td><td><span>471.3K</span></td><td></td><td></td><td><p><span>Software Development Tools</span><span>Coding Bootcamps</span><span>Career Coaching</span><span>Tech Recruitment</span><span>AI Tools</span></p></td><td><p>Microsoft 365 Copilot, JetBrains, Python, WebStorm, DataGrip, Full Psych Academy, CodeSmith, Code Academy, Free Code Camp, Swift, IntelliJ, VS Code, Neovim, Android Studio, ChatGPT, AWS, Terraform, Teams, Slack, Discord</p></td><td></td></tr><tr><td></td><td><span>Lifestyle</span></td><td><span>226.5K</span></td><td></td><td></td><td><p><span>Running apparel and shoes</span><span>Fitness equipment and supplements</span><span>Travel destinations and experiences</span><span>Fashion brands</span><span>Beauty products</span></p></td><td><p>Nike, Air Max Diane, compression boots, roller, Frozen ex-sandwich, Wii jacket, playera, Abbott, Queen's Butter Wish, New York Rock Runners, Subway, Central Park, calsetas, tennis, gloves, band, socks, jacket, chamaras, bandita</p></td><td></td></tr><tr><td><div><p>Macaila | Outdoor Content</p><p>makilllla</p></div></td><td><span>Nature &amp; Outdoors</span></td><td><span>161.5K</span></td><td></td><td></td><td><p><span>Outdoor gear &amp; apparel</span><span>Camping &amp; hiking equipment</span><span>Nature documentaries &amp; educational content</span><span>Sustainable living products</span><span>Travel &amp; adventure companies</span></p></td><td><p>Anchor portable power bank, Best Buy Canada, Usnia (lichen), Old man's beard, Amanita muscaria (fly agaric), Rain pants, Headlamp, Moss, Ferns, Mushrooms, Tinctures, Skin cream, Tea, Fire starter, Solar panels, Box wine</p></td><td></td></tr><tr><td></td><td><span>Fashion</span></td><td><span>70.1K</span></td><td></td><td></td><td><p><span>Streetwear Brands</span><span>Clothing Manufacturers</span><span>Fashion Accessories</span><span>Sneakers</span><span>Men's Fashion</span></p></td><td><p>Hoodie, Watch, Cardigan, Sweats, Joggers, Denim Jacket, Pants, Set, Slides, Shorts, Necklace, Jeans, Tie Top, Shirt Skirt, Bapestas, Shoes, Tote, Sweatshirt, Long Sleeve, Glasses</p></td><td></td></tr><tr><td></td><td><span>Travel</span></td><td><span>9.3K</span></td><td></td><td></td><td><p><span>Travel</span><span>Airlines</span><span>Tourism</span><span>Adventure Gear</span><span>Lifestyle</span></p></td><td><p>China Southern Airlines</p></td><td></td></tr><tr><td><div><p>brooklyn.nfts</p><p>brooklyn.nfts</p></div></td><td><span>NFT</span></td><td><span>67.9K</span></td><td></td><td></td><td><p><span>NFT marketplaces</span><span>NFT art creation tools</span><span>Crypto wallets</span><span>Web3 platforms</span><span>NFT education resources</span></p></td><td><p>Electra Ladies, NFTs, Opensea, Rarible, Fandefi, Lens Protocol, Drink Cloudwater, Photoshop, Blender</p></td><td></td></tr><tr><td><div><p>ET the Engineer</p><p>no_dilemma</p></div></td><td><span>Engineering</span></td><td><span>70.1K</span></td><td></td><td></td><td><p><span>Construction</span><span>Engineering</span><span>Architecture</span><span>Insurance</span><span>Disaster Preparedness</span></p></td><td><p>Xena Workwear, Dentyne, Hubba Bubba, Fantasy Hike, Bluey, Moxie Trades, Blundstone, Doc Martens, Keens, Redback Boots, Tito's, M&amp;M's, Ugg, Kishigo, Dawson Vest, Louisianan, Ken Costume</p></td><td></td></tr><tr><td></td><td><span>Entrepreneurship</span></td><td><span>96.7K</span></td><td></td><td></td><td><p><span>Ecommerce</span><span>Dropshipping</span><span>Clothing Brands</span><span>Marketing and Advertising</span><span>Business Coaching</span></p></td><td><p>Alibaba, Shopify, Procreate, DJI Osmo Pocket 3, LastPass, Clickfunnels, Stripe, Turo, Tesla, Snag Rag, One Love Clothing, MNML, Durags, Jogging Suits, Hoodies, T-shirts, Track Pants, Big Cartel, Zipfox, Remitly</p></td><td></td></tr><tr><td><div><p>Alyssa the TikTok Shop Coach</p><p>thetiktokshopcoach</p></div></td><td><span>Business &amp; Finance</span></td><td><span>52.2K</span></td><td></td><td></td><td><p><span>E-commerce Platforms</span><span>Affiliate Marketing Tools</span><span>Online Business Courses</span><span>Coaching &amp; Mentorship Programs</span><span>TikTok Marketing Services</span></p></td><td><p>Cadillac, TikTok Shop, BMC Brands Meet Creators, TikTok Shop Accelerator, Foot Massager, Brands Meet Creators Live, BMC Academy, TikTok Shop Creator 1 0 1 Course</p></td><td></td></tr><tr><td><div><p>Grace Roehrenbeck</p><p>graceroehrenbeck</p></div></td><td><span>Education</span></td><td><span>58.6K</span></td><td></td><td></td><td><p><span>Nursing schools</span><span>Nursing supplies</span><span>Healthcare products</span><span>Time management tools</span><span>Educational resources</span></p></td><td><p>Dyson, White Chicken Chili, Tbell, Frosted Flakes, McDonald's, Myers Fall Scented Sprays, Trader Joe's, Incredible Health</p></td><td></td></tr><tr><td></td><td><span>Productivity</span></td><td><span>53.1K</span></td><td></td><td></td><td><p><span>Productivity Apps</span><span>Project Management Software</span><span>Online Learning Platforms</span><span>Microsoft Office Products</span><span>Google Workspace Products</span></p></td><td><p>ClickUp, OneNote, Brain Sensei, MiRo, Plus Docs, Google Slides, Excel</p></td><td></td></tr><tr><td></td><td><span>Science &amp; Education</span></td><td><span>54.8K</span></td><td></td><td></td><td><p><span>Space Agencies (NASA, ESA, etc.)</span><span>Science Museums &amp; Planetariums</span><span>Astronomy &amp; Space Photography Equipment</span><span>Educational Technology &amp; Software</span><span>Travel &amp; Adventure</span></p></td><td><p>Moonshine, Aurora, Grand Canyon, Mediterranean Sea, 3D Printer, Magnets, Glasses</p></td><td></td></tr><tr><td><div><p>eoinsrecovery</p><p>eoinsrecovery</p></div></td><td><span>Addiction Recovery</span></td><td><span>16.8K</span></td><td></td><td></td><td><p><span>Addiction Recovery Resources</span><span>Mental Health Apps</span><span>Sobriety Support Groups</span><span>Weight Loss Programs</span><span>Fitness Products</span></p></td><td></td><td></td></tr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Probability-Generating Functions (166 pts)]]></title>
            <link>https://entropicthoughts.com/probability-generating-functions</link>
            <guid>42004976</guid>
            <pubDate>Thu, 31 Oct 2024 09:36:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://entropicthoughts.com/probability-generating-functions">https://entropicthoughts.com/probability-generating-functions</a>, See on <a href="https://news.ycombinator.com/item?id=42004976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
I have long struggled with understanding what probability-generating functions
are and how to intuit them. There were two pieces of the puzzle missing for me,
and we’ll go through both in this article.
</p>

<p>
There’s no real reason for anyone other than me to care about this, but if
you’ve ever heard the term <abbr>pgf</abbr> or <i>characteristic function</i> and you’re curious
what it’s about, hop on for the ride!
</p>
<section id="outline-container-sequences-of-numbers-without-vectors">
<h2 id="sequences-of-numbers-without-vectors">Sequences of numbers without vectors</h2>
<div id="text-org0e62ad7">
<p>
Imagine you are holding five regular playing cards in your hand. Maybe your hand
is QQA97, i.e. a pair of queens, an ace, a nine, and a seven. We’re playing some
sort of weird poker variant where I get to blindly draw one of your cards.
We’re curious about the probability distribution of the outcome of that draw.
</p>

<p>
In words, most cards (e.g. 2, 4, 8, J and others) have a probability of zero of
being drawn from your hand (because they are not in your hand.) Some cards (ace,
seven, nine) have a 20&nbsp;% probability of being drawn, and then there’s a 40&nbsp;%
probability that a queen is drawn, since you have two of them.
</p>

<p>
Numerically, we might today phrase this as a vector with these values (taking
ace to be low):
</p>

<p>
\[\left[1/5,\;0,\;0,\;0,\;0,\;0,\;1/5,\;0,\;1/5,\;0,\;0,\;2/5,\;0\right]\]
</p>

<p>
When de Moivre invented much of modern probability in the mid-1700s, <i>he
didn’t have vectors</i>! Vectors are an 1800s invention.
</p>

<p>
Sure, he could write sequences of numbers down, but at the time they didn’t have
a systematic way of dealing with those sequences as a single unit. They were
just that: sequences of separate numbers. However, there was another way for him
to turn many numbers into a single object: by embedding them as coefficients in a
polynomial function.
</p>
</div>
<div id="outline-container-polynomials-encoding-sequences-are-generating-functions">
<h2 id="polynomials-encoding-sequences-are-generating-functions">Polynomials encoding sequences are generating functions</h2>
<div id="text-orgfc130c8">
<p>
If we want to encode the vector \(\left[6, 2, 8, 4\right]\) in a single expression
and we cannot use vectors, we <i>can</i> create a function
</p>

<p>
\[f(x) = 6 + 2x + 8x^2 + 4x^3\]
</p>

<p>
and this function now contains all those numbers. One might imagine that this
function would be reducible into some simpler expression by combining terms and
multiplying out \(x\)​s, but thanks to the increasing powers of \(x\), it is not.
Regardless of how this function is rearranged, we will still be able to arrange
it back into this shape. We can extract any number in the sequence from this
function with some calculus if we want to<label for="fn.1">1</label><span><sup>1</sup> If we want to extract, say, the
third number (in this case 8), we will need to take the second derivative (to
isolate that number as a constant), evaluate the function at zero (to get the
constant out) and then divide by two (to remove excess coefficient that came
from the derivative action.) More generally, number \(n\) is found through
\(f^{(n-1)}(0)/(n-1)!\).</span>, emphasising how the polynomial and the vector really
are, in some sense, carrying the same information.
</p>

<p>
We might be curious about what the \(x\) represents. Like, what are typical values
we might plug in for \(x\)? The answer is <i>nothing</i>. We generally don’t evaluate
this function with any \(x\) at all. The function, and \(x\), exists only to create
a particular structure into which we can store coefficients for later
manipulation. it is not intended for anything meaningful to come out if we
replace \(x\) with some specific value we might think of.<label for="fn.2">2</label><span><sup>2</sup> That said, we have
already seen in an earlier sidenote that the value x=0 is special in that it
allows us to extract the constant, which combined with differentiation lets us
extract any coefficient. But although there are <i>some</i> \(x\) that result in
something meaningful, we shouldn’t think all \(x\) do.</span>
</p>

<p>
What we just did was turn a vector into a polynomial. Today, the inverse
operation is probably more common in that we take the coefficients of a long
polynomial and plug them into a vector to e.g. find roots with linear algebra.
But back in the time of de Moivre, polynomials were all they had, and so when
they needed to work with an entire sequence as a single object, they chucked the
sequence in as coefficients of a polynomial function. The polynomial \(f(x)\) is
then known as a <i>generating function</i> of the sequence, because we can (through
calculus) generate each value of the sequence from the function \(f(x)\).
</p>
</div>
</div>
<div id="outline-container-probability-generating-functions">
<h2 id="probability-generating-functions">Probability-generating functions</h2>
<div id="text-org3b95830">
<p>
The probability distribution of a draw from your hand, you know, that vector
</p>

<p>
\[\left[1/5,\;0,\;0,\;0,\;0,\;0,\;1/5,\;0,\;1/5,\;0,\;0,\;2/5,\;0\right]\]
</p>

<p>
might then be represented by the polynomial (generating) function<label for="fn.3">3</label><span><sup>3</sup> Taking the convention
that aces can be represented numerically as 1, and queens as 12.</span>
</p>

<p>
\[G(t) = \frac{1}{5}t^1 + \frac{1}{5}t^7 + \frac{1}{5}t^9 + \frac{2}{5}t^{12}\]
</p>

<p>
In this case, the numbers in the sequence – and the coefficients of the
generating function – are probabilities. When the coefficients of a generating
function are probabiilties, we call that function a <i>probability-generating
function</i>.
</p>
</div>
</div>
<div id="outline-container-coin-flips-and-their-probability-generating-functions">
<h2 id="coin-flips-and-their-probability-generating-functions">Coin flips and their probability-generating functions</h2>
<div id="text-orgb1c8d38">
<p>
We have some other examples of probability-generating functions. For example, a
fair coin flip has a probability-generating function
</p>

<p>
\[G(t) = 0.5t^0 + 0.5t^1\]
</p>

<p>
because outcome 0 (tails) has probability 50&nbsp;% and outcome 1 (heads) has
probability 50&nbsp;%.
</p>

<p>
If the coin is not fair, but has bias \(p\), then the probability-generating
function is
</p>

<p>
\[G(t) = (1-p)t^0 + pt^1\]
</p>

<p>
This is often written more compactly as<label for="fn.4">4</label><span><sup>4</sup> Using the fact that for any \(t\), we
can say that \(t^0 = 1\), and we usually write \(t^1\) as just \(t\).</span>
</p>

<p>
\[G(t) = (1-p) + pt\]
</p>

<p>
The <i>geometric distribution</i> represents how many tails we have to see until the
first heads. In the case of a fair coin, we expect to get heads very soon, but
when the probability \(p\) of heads is low, we may have to toss for a very long
time. We can think systematically to guess the sequence of probabilities for the
geometric distribution<label for="fn.5">5</label><span><sup>5</sup> With probability \(p\) we get heads on the first toss. In that case, we will have
zero tails, and this will be the first value of the probability sequence.
Failing to get heads on the first toss has probability \((1-p)\), which means if
we get heads on the second toss, we will have seen an outcome with probability
\((1-p)p\). Getting heads on the third toss has probability \((1-p)^2p\) because it
requires two tails followed by heads. This goes on forever, but at this point we
have caught on to the pattern: the first heads on the nth trial requires \(n-1\)
tails followed by a heads, which has probability \((1-p)^{n-1}p\).</span> and if we do,
we end up with a sequence that in vector form looks like
</p>

<p>
\[\left[p,\;\;(1-p)p,\;\;(1-p)^2p,\;\;(1-p)^3p,\;\;\ldots\right]\]
</p>

<p>
As a generating function, that becomes
</p>

<p>
\[G(t) = pt^0 + (1-p)pt^1 + (1-p)^2pt^2 + (1-p)^3pt^3 + \ldots\]
</p>

<p>
It might seem troublesome that this function has an infinite number of terms,
but that’s actually not a big deal. Not even to de Moivre! By the mid-1700s,
although their proofs were not as rigorous as today’s, they had a decent grasp
of polynomials of infinite degree.
</p>

<p>
In particular, we can define \(v = (1-p)t\) and rewrite this last
probability-generating function of the geometric distribution as
</p>

<p>
\[G(t) = p \left( v^0 + v^1 + v^2 + \ldots \right)\]
</p>

<p>
and for sensible \(v\), this is equivalent to
</p>

<p>
\[G(t) = \frac{p}{1-v}\]
</p>

<p>
Substituting back, we get a very compact way to express the geometric
distribution through its probability-generating function:
</p>

<p>
\[G(t) = \frac{p}{1 - (1 - p)t}\]
</p>

<p>
But remember that even though this function does not look anything like a
series, it still encodes a series as a polynomial – it’s just been rearranged
for compactness. We can still extract each individual probability from this
through calculus.
</p>

<p>
That’s it. A probability-generating function is a way to encode a sequence of
probabilities into a single object (a function) when one does not have access to
the technology of vectors.
</p>

<p>
Except …
</p>
</div>
</div>
</section>
<section id="outline-container-properties-of-probability-generating-functions">
<h2 id="properties-of-probability-generating-functions">Properties of probability-generating functions</h2>
<div id="text-orgb97b65d">
<p>
There are reasons to do this beyond “I wanted a sequence but I didn’t have
vectors”, and it’s that the resulting probability-generating function has some
convenient properties.
</p>

<p>
We have already seen that the probability-generating function has the following structure:
</p>

<p>
\[G(t) = p(0) t^0 + p(1) t^1 + p(2) t^2 + \ldots\]
</p>

<p>
In other words, each term is given by the probability of getting that value
multiplied by \(t\) raised to that value.<label for="fn.6">6</label><span><sup>6</sup> Where, we should be reminded,
neither \(G(t)\) nor \(t\) really has a meaningful interpretation. The variable
exists to force the function into a particular structure, it’s not meant to be
evaluated at this point.</span> Here are some more things we can do with
probability-generating functions:
</p>

<ul>
<li>A perhaps useless property is that if we evaluate \(G(1)\) we should get 1,
because then we are but summing all coefficients, which are probabilities.</li>

<li>One of the easiest meaningful properties is evaluating the first derivative at
\(t=1\), i.e. taking the value of \(G' (1)\). When we do that, we get the
expectation of the probability distribution!<label for="fn.7">7</label><span><sup>7</sup> Feel free to verify this for
yourself by differentiating some simple probability generating function.</span> This
surprised me at first, but seems sensical now.</li>

<li>If we evaluate the curvature at the same point, i.e. \(G'' (1)\), we get the
expectation of \(X(X-1)\), which in turn is a value that’s sort of related to
the variance of the probability distribution.<label for="fn.8">8</label><span><sup>8</sup> Look it up for more details.
I’m not yet good enough to intuitively get why the curvature of the
probability-generating would be related to variance, but I’d be happy to
receive pointers here.</span></li>

<li>If we multiply two probability-generating functions we get the convolution of
the two distributions, i.e. the distribution of sums of draws from each
original distribution. So if \(G\) is the probability-generating function of a
die, then \(G(t)G(t) = G^2(t)\) is the probability-generating function of two
dice thrown and then summed up.<label for="fn.9">9</label><span><sup>9</sup> This is not, to modern eyes, as
fascinating as it might seem. When we multiply two polynomials we multiply
together all combinations of coefficients. We are effectively writing up a big
2D table of all possible outcomes of each draw, and multiplying their
probabilities in each cell. Except we’re doing it in a way that is amenable to
algebraic manipulation to someone who does not have vectors.</span></li>

<li>Finally, if we have a randomly selected integer \(N\) with
probability-generating function \(F\), and we want to know the distribution of a
sum of \(N\) randomly selected \(X\), drawn with probability-generating function
\(G\), we get the distribution of the sum from the probability-generating
function \(F(G(t))\).</li>
</ul>

<p>
I believe the latter was one of the motivating cases for probability-generating
functions, because this lets us solve the <i>problem of the points</i>, i.e. how to
distribute the betting pot if we have to quit a game of dice early.
</p>


</div>
</section>
<section id="outline-container-probability-generating-function-to-characteristic-function">
<h2 id="probability-generating-function-to-characteristic-function">Probability-generating function to characteristic function</h2>
<div id="text-org0a4edeb">
<p>
We said before that we’re not meant to try to find a sensible value for the
parameter \(t\). Despite this, some values are more sensible than others. In
particular, we want \(|t| \le 1\) in order for an infinite-degree polynomial
to converge on a value. So the values we tried with \(t=0\) and \(t=1\) are both
more sensible than e.g. \(t=52\).
</p>

<p>
However! If we decide to go with \(t=e^{iu}\), then regardless of what \(u\) is, we
will find \(t\) on the unit circle in the complex plane. This means we are
guaranteed to have \(|t| = 1\), and all values \(u\) converge.<label for="fn.10">10</label><span><sup>10</sup> Strictly speaking
this is only true for real \(u\) I think. But that’s what a sensible person would
think of anyway.</span> When we use a parameter of the shape \(t=e^{iu}\), we write the
function not as \(G(e^{iu})\) but more simply as \(\phi(u)\) and this is called the
<i>characteristic function</i>.
</p>

<p>
Again, that’s it.<label for="fn.11">11</label><span><sup>11</sup> Well, again, not quite, because there are all these useful
properties of the characteristic function and it’s involved in a bunch of proofs
and my analysis is way too weak to understand much of it.</span>
</p>
</div>
<div id="outline-container-visualising-the-characteristic-function">
<h2 id="visualising-the-characteristic-function">Visualising the characteristic function</h2>
<div id="text-orgc013dda">
<p>
In <i>Theory of Probability</i>, de Finetti provides a nice visual of the
transformation implied by the characteristic function. We will have a bunch
of
</p>

<p>
\[\phi(u) = \ldots + p(-2) e^{-2iu} + p(-1) e^{-iu} + p(0) + p(1) e^{iu} + p(2) e^{2iu} + \ldots\]
</p>

<p>
If we focus on the case where \(u=1\), then each of the \(e^{iuX}\) represent a
distance \(X\) traveled counter-clockwise (for \(X\) positive) or clockwise (for \(X\)
negative) around the unit circle in the complex plane. Then when we multiply by
\(p(X)\) we scale this point on the circle down closer to the origin based on its
probability.
</p>

<p>
Visually, the sequence of \(p(X)e^{iuX}\) has the effect of wrapping the
probability distribution of \(X\) around the unit circle in the complex plane into
a kind of spiral. When we sum all these points together, we get the barycentre
of that spiral, and that is indeed how we can intuit the value of \(\phi(u)\).
</p>

<p>
This also makes it clear that \(\phi(u)\) is real for symmetrical distributions,
but complex in the general case.
</p>

<p>
I really wish I could animate this because it’s a great way to look at it, but
instead, I give you the image we get from de Finetti:
</p>


<p><img src="https://entropicthoughts.com/image/de-finetti-characteristic-function.png" alt="de-finetti-characteristic-function.png">
</p>
</div>
</div>
</section>
<section id="outline-container-the-definitions-are-easy--the-consequences-are-hard">
<h2 id="the-definitions-are-easy--the-consequences-are-hard">The definitions are easy, the consequences are hard</h2>
<p>
I guess this leaves us at an unsatisfactory note: we have learned how simply
these objects are defined, but we haven’t learned much about how to use them.
Doing so takes higher level analysis than I’m capable of, so I’ll have to leave
that article to someone else.
</p>
</section>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zed: SSH Remoting Is Here (253 pts)]]></title>
            <link>https://zed.dev/blog/remote-development</link>
            <guid>42004206</guid>
            <pubDate>Thu, 31 Oct 2024 07:14:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/remote-development">https://zed.dev/blog/remote-development</a>, See on <a href="https://news.ycombinator.com/item?id=42004206">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><article><p>For people with large codebases, programming on a laptop can be overwhelming. Your fans are constantly spinning, the language server is continually out of memory, and rebuilds take forever...</p>
<p>Now, in Zed, you can open a project on any machine you can SSH into. The UI runs fully locally to give you 120 frames per second of perfectly configured graphics, but with all the gubbins: language servers, tasks, and terminals run on the remote server where they can take advantage of cloud hardware.</p>
<p>It's simple to use for one-off projects:</p>
<div><pre><code>zed ssh://my-host/~/code/zed
</code></pre></div>
<p>And you can configure longer-lived connections as you need:</p>
<div><figure><img src="https://zed.dev/img/post/remote-dev/remote-dev.png" alt="The &quot;Remote Projects&quot; UI in Zed."><figcaption>The "Remote Projects" UI in Zed.</figcaption></figure></div>
<p>For more information, <a href="https://zed.dev/docs/remote-development">see the documentation</a>.</p>
<h2 id="building-remote-development">Building Remote Development</h2>
<p>We've been working on our remote development feature for a while. While Zed is built for <a href="https://zed.dev/docs/collaboration">remote code editing</a>, changing the infrastructure to support SSH required solving a whole bunch of sub-problems, from SSH connection maintenance, to how we build the remote server, to integrating the feature into everything else we have in Zed.</p>
<p>For the SSH connection, we use the <a href="https://linux.die.net/man/5/ssh_config">ControlMaster</a> setting to maintain a single connection to each host. This means that you can open new terminals and spawn tasks without having to retype your passphrase or re-authenticate. Once connected, we download the remote server for your operating system and architecture. Unlike our normal Linux builds, the remote server can be compiled with <code>musl</code>, which requires no dynamic linking. This lets it work on older distros (where before we ran into compatibility problems with <code>glibc</code>) and on modern share-nothing distros like Nix that don't have a global set of libraries to dynamically link. Once we've established the connection and installed the remote server, we initialize it as a daemon, so that when connections do drop the remote server continues running and on reconnect your language servers are still fully initialized. We also back up any unsaved changes locally, so you never lose your work.</p>
<p>The final piece of the puzzle was making SSH projects work with collaboration. This has been a real stress test of our collaborative syncing protocol as there can now be at least four different nodes involved in a 2-person collaboration over SSH. We had to rewrite our <code>Project</code>, and split it into logical chunks that could be enabled in remote and local modes depending on whether your client is the collab host, the ssh host, or the collab guest. We also have some new, fun <a href="https://github.com/zed-industries/zed/blob/main/crates/collab/src/tests/remote_editing_collaboration_tests.rs#L28-L86">tests</a> that instantiate each of these roles, and our collaboration server, and ensures that the synchronization is done correctly. If you're working on a project with a friend or colleague, it should be completely transparent to them whether the project is on your laptop, or on a machine you can SSH into.</p>
<p>Please try it out today and, as always, leave us feedback in <a href="https://github.com/zed-industries/zed">GitHub Issues</a> or <a href="https://discord.gg/zed-community">Discord</a>.</p><hr></article></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I attended Google's creator conversation event, and it turned into a funeral (214 pts)]]></title>
            <link>https://www.giantfreakinrobot.com/tech/google-creators-event.html</link>
            <guid>42002262</guid>
            <pubDate>Thu, 31 Oct 2024 00:43:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.giantfreakinrobot.com/tech/google-creators-event.html">https://www.giantfreakinrobot.com/tech/google-creators-event.html</a>, See on <a href="https://news.ycombinator.com/item?id=42002262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-url="https://www.giantfreakinrobot.com/tech/google-creators-event.html" data-title="I Attended Google’s Creator Conversation Event, And It Turned Into A Funeral" data-id="687043" data-page="0" aria-live="polite" aria-atomic="true" data-single-post="true" data-single-post-id="687043" data-single-post-order="previous" data-single-post-taxonomy="post_tag" data-single-post-excluded-terms="40003" data-single-post-title-template="{post-title} - {site-title}" data-single-post-site-title="GIANT FREAKIN ROBOT" data-single-post-site-tagline="Stomping into the future of entertainment." data-single-post-scroll="false" data-single-post-scrolltop="30" data-single-post-controls="1" data-single-post-progress-bar="" data-container-type="div" data-loading-style="grey" data-repeater="default" data-post-type="post" data-order="DESC" data-orderby="date" data-offset="0" data-posts-per-page="1" data-scroll-distance="-1200" data-button-label="Load More"><!-- Grid row -->
<article id="post-687043">
	<!-- Grid column -->
	<div>
				                            
		
		
		
		
<figure><img fetchpriority="high" decoding="async" width="900" height="506" src="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlebag-900x506.png" alt="Google Creator Conversation Event" srcset="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlebag-900x506.png 900w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlebag-578x325.png 578w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlebag-768x432.png 768w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlebag-1200x675.png 1200w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlebag.png 1280w" sizes="(max-width: 900px) 100vw, 900px"></figure>



<p>I recently attended a funeral. It was called the Google Web Creator Conversation Event and took place on October 29, 2024, at Google headquarters in Mountain View, California.&nbsp;</p>



<p>Google invited some of the most vocal independent site owners who’ve been shadowbanned by their brutal updates of the last two years, and 20 of them came to pay their respects. We had no idea what the purpose of our visit was going in, but we knew by the time we left.</p>



<p>Google has never done anything like it before. After this account, they likely never will again.</p>



<h3 id="h-visiting-the-google-campus"><strong>Visiting The Google Campus</strong></h3>



<figure><img decoding="async" width="900" height="506" src="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/GoogleHQ-900x506.png" alt="Creators visiting Google's campus" srcset="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/GoogleHQ-900x506.png 900w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/GoogleHQ-578x325.png 578w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/GoogleHQ-768x432.png 768w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/GoogleHQ-1200x675.png 1200w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/GoogleHQ.png 1280w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>Google’s biggest empty building</figcaption></figure>



<p>Danny Sullivan hosted the event. He may be the most knowledgeable and helpful person still left at Google, though he has no real power to effect change.</p>



<p>The day before, he led the group on a tour of Google’s biggest office during the busiest part of weekday work hours and seemed slightly embarrassed that at no point during the tour was anyone there. The building was empty, a shell designed as a hub of activity, drained of people willing to engage in being active.</p>



<figure><img decoding="async" width="900" height="506" src="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlepaths-900x506.png" alt="Empty pathways at Google campus during the Creator Event" srcset="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlepaths-900x506.png 900w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlepaths-578x325.png 578w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlepaths-768x432.png 768w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlepaths-1200x675.png 1200w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/googlepaths.png 1280w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>An empty path between Google buildings</figcaption></figure>



<p>Empty too, was the rest of Google’s behemoth campus. Their numerous buildings are surrounded by beautiful, park-like pathways with no one to enjoy them but the groundskeepers. They follow the paths with their lawnmowers, weaving between softly shaded employee parking lots, with no one to park in them.</p>



<p>Well, not no one. Continuing my aimless meandering, I encountered a large, mentally ill man in tight-fitting black clothing, screaming profanity and punching wildly at the air.</p>



<p>He didn’t seem to notice me, occupied as he was with fighting ghosts, and we passed amicably.&nbsp;</p>



<h3 id="h-buildings-so-secure-they-re-empty"><strong>Buildings So Secure They’re Empty</strong></h3>



<p>We weren’t allowed into the large, high-security building where Danny held his Creator Event until we’d been given not one but two visitor badges and affixed them to our clothes. After they were handed to us, these were never looked at or checked. There was no one around to check them.</p>




<p>I did see many janitors and food workers bustling about the premises. I considered asking them to check at least one of my visitor badges, but didn’t want to distract them from the noble task of delivering crystal bowls filled with conference room M&amp;Ms.</p>



<p>I saw only two Googlers out and about during my day spent in the building. They played ping pong atop a depressing, gray table in a tiny, fishbowl room deep within the bowels of Google’s labyrinth. They didn’t seem to be enjoying it.</p>



<h3 id="h-our-conversation-began-with-reassurances"><strong>Our Conversation Began With Reassurances</strong></h3>



<figure><img loading="lazy" decoding="async" width="900" height="506" src="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/surveillance-900x506.png" alt="Web Conversation Creators being watched" srcset="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/surveillance-900x506.png 900w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/surveillance-578x325.png 578w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/surveillance-768x432.png 768w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/surveillance-1200x675.png 1200w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/surveillance.png 1280w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>Web Creators under surveillance by Google</figcaption></figure>



<p>The event began in a conference room full of folding card tables and stackable chairs, the kind of room you’d expect to see available to rent in a well-appointed, midwestern Holiday Inn. Danny, kind and patient as always, assured us there was nothing wrong with our sites and that we wouldn’t have been invited if there had been.</p>



<p>Also in attendance were a number of Google Engineers and managers, including Google’s Chief Search Scientist. Others, we were told, were watching from an undisclosed location through cameras mounted in the ceiling and ominously pointed at us, the audience, instead of Google’s assigned speakers.</p>



<p>The idea that this might be a funeral, was put forward as a half-joke by one of the shadowbanned attendees during our first Q&amp;A session, in which we asked questions and got no answers. Her funeral joke should have been funny. Only the Googlers laughed.</p>



<p>Most of these site owners seemed certain the funeral they were attending, was their own.</p>



<h3 id="h-google-sucks-us-dry-and-throws-away-the-husk"><strong>Google Sucks Us Dry And Throws Away The Husk</strong></h3>



<p>We spent the morning politely answering questions from Google, questions designed to help Google improve its search engine, questions that in no way benefited any of the shadowbanned attendees. After, we were given a chance (we thought) to get something useful out of the trip. We split into small breakout groups divided up by category.</p>



<p>We few Entertainment site owners rearranged ourselves into a corner semi-circle, and sat drinking mint lemon water from cups made of recycled Kale. We were joined by four Googlers, who began pumping us for information.&nbsp;</p>



<p>During this small group discussion, I and others tried to get our Googlers to address the biggest problem facing our industry: Google giving big brands special treatment. Each time a site owner brought up the topic, we were quickly steered in another direction.</p>



<figure><img loading="lazy" decoding="async" width="900" height="1211" src="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-900x1211.png" alt="" srcset="https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-900x1211.png 900w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-578x778.png 578w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-768x1034.png 768w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-1141x1536.png 1141w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-1521x2048.png 1521w, https://www.giantfreakinrobot.com/wp-content/uploads/2024/10/whiteboardsmall-1568x2111.png 1568w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>The Entertainment whiteboard after “diversity of results” was erased from the top and rewritten at the bottom in a tiny font</figcaption></figure>



<p>I kept pushing, and eventually, our Googler (whose name I’m not allowed to tell you) wrote “diversity of results” at the top of the whiteboard he was using, as if to signify I should shut up and move on. Instead of addressing the only topic that matters, I was asked to explain how <a href="https://www.giantfreakinrobot.com/topic/youtube" target="_blank" rel="noopener" title="YouTube" data-wpil-keyword-link="linked" data-wpil-monitor-id="73654">YouTube</a> works because, somehow, none of the four Googlers assigned to our group knew anything about it. </p>



<p>When our group session was over, I left the room for a break. While I was gone, “diversity of results” was erased from the top of the whiteboard and rewritten at the bottom, in much tinier lettering.</p>



<p>During the lunch break, we were fed Tofu, cold pickled chicken breasts, olive bread, and bonbons full of alcohol. Most of us didn’t eat much.</p>



<h3 id="h-google-s-head-wizard-appears"><strong>Google’s Head Wizard Appears</strong></h3>



<p>Back together as a whole group, their Chief Search Scientist arrived and made himself available to answer our questions.&nbsp;</p>



<p>While we’d been “eating” Google had its quarterly conference call, in which they talked only about the AI they were using to steal content from our sites. When questioned about the content of the call, our Googlers acted as if they barely knew AI existed, and pretended it wasn’t impacting their search results.</p>



<figure></figure>



<p>Undeterred, we then asked the only question that mattered: Why has Google shadowbanned our sites? Google’s Chief Search Scientist answered this question using a strategy based around gaslighting and said they hadn’t. Google doesn’t ever derank an entire site, only individual pages, he said. There is no site-wide classifier. He insisted it is only done at the page level.</p>



<p>Many of the shadowbanned site owners attempted to politely push back and point out that the reason all 20 of us were there was specifically because our entire site was deranked from Google in a single night.</p>



<p>He continued insisting this didn’t happen and then looked confused that anyone would disagree with him.&nbsp;</p>



<p>When asked what was wrong with our sites, as if we were jilted lovers in an abusive relationship being kicked to the curb, one Googler actually said “it’s not you it’s me”.</p>



<p>Finally, someone bluntly asked, since nothing is wrong with our sites, how do we recover?</p>



<p>Google’s elderly Chief Search Scientist answered, without an ounce of pity or concern, that there would be updates but he didn’t know when they’d happen or what they’d do.&nbsp; Further questions on the subject were met with indifference as if he didn’t understand why we cared.</p>



<p>He’d gotten the information he wanted. The conference was over. I don’t think he even said thanks.&nbsp;</p>



<p>Instead, Google’s wise wizard of search science wrapped things up with a self-congratulatory speech about what great a job we were doing at helping Google improve so he can deliver better search results to his users.&nbsp;</p>



<p>Search results without any of us in them.</p>



<p>It was then I realized this wasn’t our funeral, it was Google’s.</p>



<p>And if you have a moment, say a prayer for hard-working Danny Sullivan. Pray he won’t be left there at Google, wandering their empty and decaying coffin, all alone, haunted by angry, invisible ghosts.</p>

<!-- CONTENT END 2 -->

<!-- #comments -->                
		<hr>

									
	</div>
	<!-- Grid column -->
</article>
<!-- Grid row --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wonder Animation – Video to 3D Animation (136 pts)]]></title>
            <link>https://adsknews.autodesk.com/en/news/autodesk-launches-wonder-animation-video-to-3d-scene-technology/</link>
            <guid>42001852</guid>
            <pubDate>Wed, 30 Oct 2024 23:44:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adsknews.autodesk.com/en/news/autodesk-launches-wonder-animation-video-to-3d-scene-technology/">https://adsknews.autodesk.com/en/news/autodesk-launches-wonder-animation-video-to-3d-scene-technology/</a>, See on <a href="https://news.ycombinator.com/item?id=42001852">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <ul>
<li><span data-contrast="auto">Wonder Dynamics, an Autodesk company, launched the beta version of Wonder Animation, which uses groundbreaking Video to 3D scene technology to </span><span data-contrast="none">accelerate animated film production by turning any video sequence into a 3D-animated scene.</span><span data-ccp-props="{}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" aria-setsize="-1" data-aria-posinset="2" data-aria-level="1"><span data-contrast="none">Part of the Wonder Studio toolset, Wonder Animation’s Video to 3D scene technology can</span><span data-contrast="auto"> film and edit sequences with multiple cuts and various shots, then uses AI to reconstruct the scene in a 3D space</span><span data-contrast="auto">.</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&quot;335552541&quot;:1,&quot;335559685&quot;:720,&quot;335559991&quot;:360,&quot;469769226&quot;:&quot;Symbol&quot;,&quot;469769242&quot;:[8226],&quot;469777803&quot;:&quot;left&quot;,&quot;469777804&quot;:&quot;&quot;,&quot;469777815&quot;:&quot;hybridMultilevel&quot;}" aria-setsize="-1" data-aria-posinset="2" data-aria-level="1"><span data-contrast="auto">Wonder Animation’s beta launch, now available to all Wonder Studio users, aims to bring artists closer to producing fully animated films, while enabling the artist to retain full creative control – unlike other generative AI tools that rely on automated outputs.</span><span data-ccp-props="{}">&nbsp;</span></li>
</ul>
<div>
<div id="attachment_49912"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-49912" src="https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2.png" alt="" width="2287" height="1275" srcset="https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2.png 2287w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2-300x167.png 300w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2-1024x571.png 1024w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2-768x428.png 768w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2-1536x856.png 1536w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2-2048x1142.png 2048w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-2-700x390.png 700w" sizes="(max-width: 2287px) 100vw, 2287px"></p><p id="caption-attachment-49912">Wonder Animation, an Autodesk product</p></div>
<p><span data-contrast="auto">It’s been five months since we </span><a href="https://adsknews.autodesk.com/en/pressrelease/autodesk-acquires-wonder-dynamics-offering-cloud-based-ai-technology-to-empower-more-artists-to-create-more-3d-content-across-media-and-entertainment-industries/"><span data-contrast="none">joined Autodesk</span></a><span data-contrast="auto">, and the time spent has only reinforced that the foundational Wonder Dynamics vision aligns perfectly with Autodesk’s longstanding commitment to advancing the Media &amp; Entertainment industry through innovation. Together, we believe in using artificial intelligence (AI) more intentionally to enhance creativity and efficiency, so artists can spend more time on the creative aspects of storytelling. We formed Wonder Dynamics and developed Wonder Studio (our cloud-based 3D animation and VFX solution) out of our passion for storytelling coupled with our commitment to make VFX work accessible to more creators and filmmakers.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}">&nbsp;</span></p>
<p><span data-contrast="auto">Today, Wonder Dynamics is excited to announce the beta launch of Wonder Studio’s newest feature: </span><strong>Wonder Animation</strong><span data-contrast="auto">, </span><span data-contrast="none">which is powered by groundbreaking Video </span><span data-contrast="none">to </span><span data-contrast="none">3D </span><span data-contrast="none">s</span><span data-contrast="none">cene technology that enables artists to shoot a scene with any camera, in any location, and turn the sequence into an animated scene with CG characters in a 3D environment.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}">&nbsp;</span></p>
<p><iframe loading="lazy" title="Introducing Wonder Animation: Powered by Video-to-3D Scene Technology" width="500" height="281" src="https://www.youtube.com/embed/xad1ajxln28?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p><span data-contrast="none">The most innovative part of Wonder Animation’s </span><span data-contrast="none">Video to 3D scene technology</span> <span data-contrast="none">is its ability to </span><span data-contrast="auto">film and edit sequences with multiple cuts and various shots (wide, medium, close-ups)</span><span data-contrast="auto">. T</span><span data-contrast="none">he technology then uses AI to reconstruct the scene in a 3D space and matches the position and movement of each camera’s relationship to the characters and environment.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559738&quot;:240,&quot;335559739&quot;:240,&quot;335559740&quot;:240}">&nbsp;</span></p>
<p><span data-contrast="none">This essentially creates a virtual representation of an artist’s live-action scene containing all camera setups and character body and face animation in one 3D scene, with fully editable elements (animation, character, environment, lighting, and camera tracking data) in their preferred software, such as Maya, Blender or Unreal.</span><span data-contrast="auto">&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335551550&quot;:6,&quot;335551620&quot;:6,&quot;335559738&quot;:240,&quot;335559739&quot;:240,&quot;335559740&quot;:240}">&nbsp;</span></p>
<div>
<div id="attachment_49927"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-49927" src="https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1.jpg" alt="" width="1920" height="1080" srcset="https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1.jpg 1920w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1-300x169.jpg 300w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1-1024x576.jpg 1024w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1-768x432.jpg 768w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1-1536x864.jpg 1536w, https://adsknews.autodesk.com/app/uploads/2024/10/Wonder-Animation-1-700x394.jpg 700w" sizes="(max-width: 1920px) 100vw, 1920px"></p><p id="caption-attachment-49927">Wonder Animation Video to 3D scene technology</p></div>
<p><span data-contrast="none">Even though there have been tremendous advancements in AI, there is a current misconception that AI is a one click solution–but we know that’s not the case. </span><span data-contrast="none">Wonder Animation</span><span data-contrast="none"> underscores our focus on bringing the artist one step closer to producing fully animated films while ensuring they retain full creative control. Unlike the black-box approach of most generative AI tools currently on the market, we’re empowering artists to shape their vision instead of just relying on automated outputs.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}">&nbsp;</span></p>
<p><span data-contrast="auto">Try Wonder Animation today: </span><a href="http://app.wonderdynamics.com/"><span data-contrast="none">app | Wonder Dynamics</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}"><br>
</span><span data-contrast="none">For more information, visit </span><a href="https://www.autodesk.com/solutions/wonder-dynamics"><span data-contrast="none">Wonder Dynamics, an Autodesk company</span></a><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:0,&quot;335559740&quot;:240}">&nbsp;</span></p>
</div>
</div>

                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI Scripting (190 pts)]]></title>
            <link>https://microsoft.github.io/genaiscript/</link>
            <guid>42001811</guid>
            <pubDate>Wed, 30 Oct 2024 23:39:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microsoft.github.io/genaiscript/">https://microsoft.github.io/genaiscript/</a>, See on <a href="https://news.ycombinator.com/item?id=42001811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">  <main data-pagefind-body="" lang="en" dir="ltr">   <div> <div> <p><img src="https://microsoft.github.io/genaiscript/_astro/logo.C7y7Xksc_ZQDjo6.svg" loading="eager" decoding="async" alt="GenAIScript logo A yellow square with genai text" width="400" height="400"></p> </div>  <div> <h2 id="prompting-is-coding">Prompting is Coding</h2>
<p>Programmatically assemble prompts for LLMs using JavaScript.</p>
<div><figure><pre data-language="js"><code><div><p><span>$</span><span>`</span><span>Analyze </span><span>${</span><span>env</span><span>.</span><span>files</span><span>}</span><span> and report errors. Use gitmojis.</span><span>`</span></p></div></code></pre></figure></div>
<p>Of course, things can get more complex…</p>
<div><figure><pre data-language="js"><code><div><p><span>// define the context</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>FILE</span><span>"</span><span>, </span><span>env</span><span>.</span><span>files</span><span>, { endsWith: </span><span>"</span><span>.pdf</span><span>"</span><span> })</span></p></div><div><p><span>// structure the data</span></p></div><div><p><span>const </span><span>schema</span><span> = </span><span>defSchema</span><span>(</span><span>"</span><span>DATA</span><span>"</span><span>, { type: </span><span>"</span><span>array</span><span>"</span><span>, items: { type: </span><span>"</span><span>string</span><span>"</span><span> } }</span><span>)</span></p></div><div><p><span>// assign the task</span></p></div><div><p><span>$</span><span>`</span><span>Analyze FILE and extract data to JSON.</span><span>`</span></p></div><div><p><span>// save results to file</span></p></div><div><p><span>defFileOutput</span><span>(</span><span>"</span><span>*.pdf.txt</span><span>"</span><span>, </span><span>"</span><span>Extracted data</span><span>"</span><span><span>, { </span><span>schema</span><span> })</span></span></p></div><div><p><span>// tools</span></p></div><div><p><span>defTool</span><span>(</span><span>"</span><span>weather</span><span>"</span><span>, </span><span>"</span><span>live weather</span><span>"</span><span>, { city: </span><span>"</span><span>Paris</span><span>"</span><span> }, </span><span>/* schema */</span></p></div><div><p><span>    </span><span>async</span><span> </span><span>(</span><span><span>{ </span><span>city</span><span> }</span></span><span>)</span><span> </span><span>=&gt;</span><span> { </span><span>...</span><span> </span><span>"</span><span>sunny</span><span>"</span><span> }) </span><span>/* callback */</span></p></div><div><p><span>// agents!</span></p></div><div><p><span>defAgent</span><span>(</span><span>"</span><span>git</span><span>"</span><span>, </span><span>"</span><span>answer git questions</span><span>"</span><span>, </span><span>"</span><span>You are a git expert.</span><span>"</span><span>, { tools: [</span><span>"</span><span>git</span><span>"</span><span>] })</span></p></div><div><p><span>...</span></p></div></code></pre></figure></div>
<h2 id="next-steps">Next steps</h2>
<div><article> <p>   <span>Listen to the podcast</span> </p> <div><p><audio controls="" loop="false" preload="metadata"> <source src="https://microsoft.github.io/genaiscript/podcasts/overview.wav" type="audio/mpeg">
Your browser does not support the audio element.
</audio> </p></div> </article> <article> <p>   <span>Install the extension</span> </p> <div><p>Install the <a href="https://microsoft.github.io/genaiscript/getting-started/installation/">Visual Studio Code
Extension</a> to get started.</p></div> </article> <article> <p>   <span>Configure your LLMs</span> </p> <p>Configure the <a href="https://microsoft.github.io/genaiscript/getting-started/configuration">secrets</a> to
access your LLMs.</p> </article> <article> <p>   <span>Write your first script</span> </p> <div><p>Follow <a href="https://microsoft.github.io/genaiscript/getting-started/your-first-genai-script/">Getting
Started</a> to write
your first script.</p></div> </article> <article> <p>   <span>Read the docs</span> </p> <div><p>Learn more about GenAIScript in the <a href="https://microsoft.github.io/genaiscript/reference/">Scripting
Reference</a>.</p></div> </article> </div> 
<p><img src="https://microsoft.github.io/genaiscript/_astro/visual-studio-code.CzkSq6ro_ZQ8RMG.webp" alt="A screenshot of VSCode with a genaiscript opened" loading="lazy" width="3072" height="1382" decoding="async"></p><h2 id="features">Features</h2>
<p>GenAIScript brings essential LLM prompt tooling into a cohesive scripting environment.</p>
<div><article> <p>   <span>Stylized JavaScript</span> </p> <div><p>Minimal syntax to build prompts using <a href="https://microsoft.github.io/genaiscript/reference/scripts/">JavaScript</a>
or <a href="https://microsoft.github.io/genaiscript/reference/scripts/typescript">TypeScript</a>.</p><div><figure><pre data-language="js"><code><div><p><span>$</span><span>`</span><span>Summarize </span><span>${</span><span>env</span><span>.</span><span>files</span><span>}</span><span>. Today is </span><span>${</span><span>new</span><span> </span><span>Date</span><span>()</span><span>}</span><span>.</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Fast Development Loop</span> </p>  </article> <article> <p>   <span>LLM Tools</span> </p> <div><p>Register JavaScript functions as <a href="https://microsoft.github.io/genaiscript/reference/scripts/tools/">LLM tools</a></p><div><figure><pre data-language="js"><code><div><p><span>defTool</span><span>(</span><span>"</span><span>weather</span><span>"</span><span>, </span><span>"</span><span>live weahter</span><span>"</span><span>,</span></p></div><div><p><span><span>    </span></span><span>{ city: </span><span>"</span><span>Paris</span><span>"</span><span> }, </span><span>// schema</span></p></div><div><p><span>    </span><span>async</span><span> </span><span>(</span><span><span>{ </span><span>city</span><span> }</span></span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>// callback</span></p></div><div><p><span><span>        </span></span><span>{ </span><span>...</span><span> </span><span>"</span><span>sunny</span><span>"</span><span> }</span></p></div><div><p><span>)</span></p></div></code></pre></figure></div><p>or use built-in <a href="https://microsoft.github.io/genaiscript/guides/agentic-tools/">@agentic tools</a></p><div><figure><pre data-language="js"><code><div><p><span>import</span><span> { WeatherClient } </span><span>from</span><span> </span><span>"</span><span>@agentic/weather</span><span>"</span></p></div><div><p><span>defTool</span><span>(</span><span>new</span><span> </span><span>WeatherClient</span><span>())</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>LLM Agents</span> </p> <div><p>Combine <a href="https://microsoft.github.io/genaiscript/reference/scripts/tools">tools</a> and <a href="https://microsoft.github.io/genaiscript/reference/scripts/inline-prompts/">inline prompts</a>
into an <a href="https://microsoft.github.io/genaiscript/reference/scripts/agents">agent</a>.</p><div><figure><pre data-language="js"><code><div><p><span>defAgent</span><span>(</span></p></div><div><p><span>    </span><span>"</span><span>git</span><span>"</span><span>,</span></p></div><div><p><span>    </span><span>"</span><span>Agent that answer git questions for the current repo</span><span>"</span><span>,</span></p></div><div><p><span>    </span><span>"</span><span>You are a helpful expert in using git.</span><span>"</span><span>,</span></p></div><div><p><span><span>    </span></span><span>{ tools: [</span><span>"</span><span>git</span><span>"</span><span>] }</span></p></div><div><p><span>)</span></p></div></code></pre></figure></div><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ tools: </span><span>"</span><span>agent</span><span>"</span><span> })</span></p></div><div><p><span>$</span><span>`</span><span>Do a statistical analysis of the last commits</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Reuse and Share Scripts</span> </p> <div><p>Scripts are <a href="https://microsoft.github.io/genaiscript/reference/scripts/">files</a>! They can be versioned, shared, forked, …</p><starlight-file-tree data-pagefind-ignore=""><ul><li><details open=""><summary><span><span><span><span>Directory</span></span>genaisrc
</span></span></summary><ul><li><span><span><span></span>my-script.genai.mjs</span></span></li><li><span><span><span></span>another-great-script.genai.mjs</span></span></li></ul></details></li></ul></starlight-file-tree> </div> </article> <article> <p>   <span>Data Schemas</span> </p> <div><p>Define, validate, repair data using <a href="https://microsoft.github.io/genaiscript/reference/scripts/schemas">schemas</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const </span><span>data</span><span> = </span><span>defSchema</span><span>(</span><span>"</span><span>MY_DATA</span><span>"</span><span>,</span></p></div><div><p><span><span>    </span></span><span>{ type: </span><span>"</span><span>array</span><span>"</span><span>, items: { </span><span>...</span><span> }, }</span><span>)</span></p></div><div><p><span>$</span><span>`</span><span>Extract data from files using </span><span>${</span><span>data</span><span>}</span><span> schema.</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Ingest text from PDFs, DOCX, ...</span> </p> <div><p>Manipulate
<a href="https://microsoft.github.io/genaiscript/reference/scripts/pdf">PDFs</a>,
<a href="https://microsoft.github.io/genaiscript/reference/scripts/docx">DOCX</a>,
…</p><div><figure><pre data-language="js"><code><div><p><span>// automatically convert to text</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>PDF</span><span>"</span><span>, </span><span>env</span><span>.</span><span>files</span><span>, { endsWith: </span><span>"</span><span>.pdf</span><span>"</span><span> })</span></p></div><div><p><span>// or parse and process</span></p></div><div><p><span>const { </span><span>pages</span><span> } = await </span><span>parsers</span><span>.</span><span>PDF</span><span>(</span><span>env</span><span>.</span><span>files</span><span>[</span><span>0</span><span>])</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Ingest tables from CSV, XLSX, ..</span> </p> <div><p>Manipulate tabular data from
<a href="https://microsoft.github.io/genaiscript/reference/scripts/csv">CSV</a>,
<a href="https://microsoft.github.io/genaiscript/reference/scripts/xlsx">XLSX</a>,
…</p><div><figure><pre data-language="js"><code><div><p><span>// automatically convert to text</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>DATA</span><span>"</span><span>, </span><span>env</span><span>.</span><span>files</span><span>, {</span></p></div><div><p><span><span>    </span></span><span>endsWith: </span><span>"</span><span>.csv</span><span>"</span><span>,</span></p></div><div><p><span>    </span><span>// take top 100 rows</span></p></div><div><p><span><span>    </span></span><span>sliceHead: </span><span>100</span><span>,</span></p></div><div><p><span>})</span></p></div><div><p><span>// or parse to JavaScript object array</span></p></div><div><p><span>const </span><span>rows</span><span> = await </span><span>parsers</span><span>.</span><span>CSV</span><span>(</span><span>env</span><span>.</span><span>files</span><span>[</span><span>0</span><span>])</span></p></div><div><p><span>// render as markdown table</span></p></div><div><p><span>defData</span><span>(</span><span>"</span><span>ROWS</span><span>"</span><span><span>, </span><span>rows</span><span>, { sliceHead: </span></span><span>100</span><span> })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Generate Files</span> </p> <div><p>Extract files and diff from the LLM output.
Preview changes in Refactoring UI.</p><div><figure><pre data-language="js"><code><div><p><span>$</span><span>`</span><span>Save the result in poem.txt.</span><span>`</span></p></div></code></pre></figure></div><div><figure><pre data-language="txt"><code><div><p><span>FILE ./poem.txt</span></p></div><div><p><span>```txt</span></p></div><div><p><span>The quick brown fox jumps over the lazy dog.</span></p></div><div><p><span>```</span></p></div></code></pre></figure></div><starlight-file-tree data-pagefind-ignore=""><ul><li><span><span><span></span>poem.txt</span> </span></li></ul></starlight-file-tree> </div> </article> <article> <p>   <span>File search</span> </p> <div><p>Grep or fuzz search <a href="https://microsoft.github.io/genaiscript/referen/script/files">files</a></p><div><figure><pre data-language="js"><code><div><p><span>const { </span><span>files</span><span> } = await </span><span>workspace</span><span>.</span><span>grep</span><span>(</span><span>/</span><span>[a-z][a-z0-9]</span><span>+</span><span>/</span><span>, { globs: </span><span>"</span><span>*.md</span><span>"</span><span> }</span><span>)</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Browser automation</span> </p> <div><p>Browse and scrape the web with <a href="https://microsoft.github.io/genaiscript/reference/scripts/browse">Playwright</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const </span><span>page</span><span> = await </span><span>host</span><span>.</span><span>browse</span><span>(</span><span>"</span><span>https://...</span><span>"</span><span>)</span></p></div><div><p><span>const </span><span>table</span><span> = await </span><span>page</span><span>.</span><span>locator</span><span>(</span><span>"</span><span>table[...]</span><span>"</span><span>)</span><span>.</span><span>innerHTML</span><span>()</span></p></div><div><p><span>def</span><span>(</span><span>"</span><span>TABLE</span><span>"</span><span>, </span><span>await</span><span> </span><span>HTML</span><span>.</span><span>convertToMarkdown</span><span><span>(</span><span>table</span><span>))</span></span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>RAG built-in</span> </p> <div><p><a href="https://microsoft.github.io/genaiscript/reference/scripts/vector-search/">Vector search</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const { </span><span>files</span><span> } = await </span><span>retrieval</span><span>.</span><span>vectorSearch</span><span>(</span><span>"</span><span>cats</span><span>"</span><span>, </span><span>"</span><span>**/*.md</span><span>"</span><span>)</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>GitHub Models and GitHub Copilot</span> </p> <div><p>Run models through GitHub using <a href="https://microsoft.github.io/getting-started/configuration/#github-models">GitHub Models</a>
or <a href="https://microsoft.github.io/getting-started/configuration/#github-copilot-in-visual-studio-code">GitHub Copilot</a>.</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ </span><span>...</span><span>, model: </span><span>"</span><span>github:gpt-4o</span><span>"</span><span> })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Local Models</span> </p> <div><p>Run your scripts with <a href="https://microsoft.github.io/genaiscript/getting-started/configuration/#local-models">Open Source models</a>,
like <a href="https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/">Phi-3</a>,
using <a href="https://ollama.com/">Ollama</a>, <a href="https://localai.io/">LocalAI</a>…</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ </span><span>...</span><span>, model: </span><span>"</span><span>ollama:phi3</span><span>"</span><span> })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Code Interpreter</span> </p> <div><p>Let the LLM run code in a sandboxed execution environment.</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ tools: [</span><span>"</span><span>python_code_interpreter</span><span>"</span><span>] })</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Containers</span> </p> <div><p>Run code in Docker <a href="https://microsoft.github.io/genaiscript/reference/scripts/containers">containers</a>.</p><div><figure><pre data-language="js"><code><div><p><span>const </span><span>c</span><span> = await </span><span>host</span><span>.</span><span>container</span><span>(</span><span>{</span></p></div><div><p><span><span>    </span></span><span>image: </span><span>"</span><span>python:alpine</span><span>"</span><span>,</span></p></div><div><p><span>}</span><span>)</span></p></div><div><p><span>const </span><span>res</span><span> = await </span><span>c</span><span>.</span><span>exec</span><span>(</span><span>"</span><span>python --version</span><span>"</span><span>)</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>LLM Composition</span> </p> <div><p><a href="https://microsoft.github.io/genaiscript/reference/scripts/inline-prompts/">Run LLMs</a> to build your LLM prompts.</p><div><figure><pre data-language="js"><code><div><p><span>// summarize each files individually</span></p></div><div><p><span>for</span><span> (</span><span>const </span><span>file</span><span> </span><span>of</span><span> </span><span>env</span><span>.</span><span>files</span><span>) {</span></p></div><div><p><span>    </span><span>const { </span><span>text</span><span> } = await </span><span>runPrompt</span><span>(</span><span>(</span><span>_</span><span>)</span><span> =&gt; {</span></p></div><div><p><span>        </span><span>_</span><span>.</span><span>def</span><span>(</span><span>"</span><span>FILE</span><span>"</span><span>, </span><span><span>file</span><span>)</span></span></p></div><div><p><span>        </span><span>_</span><span>.</span><span>$</span><span>`</span><span>Summarize the FILE.</span><span>`</span></p></div><div><p><span><span>    </span></span><span>}</span><span>)</span></p></div><div><p><span>    </span><span>// use result in main prompt</span></p></div><div><p><span>    </span><span>def</span><span>(</span><span>"</span><span>SUMMARY</span><span>"</span><span><span>, </span><span>text</span><span>)</span></span></p></div><div><p><span>}</span></p></div><div><p><span>// use summary</span></p></div><div><p><span>$</span><span>`</span><span>Summarize all the summaries.</span><span>`</span></p></div></code></pre></figure></div></div> </article> <article> <p>  <span>Prompty</span> </p> <div><p>Run or convert <a href="https://prompty.ai/">Prompty</a> files using GenAIScript.</p><div><figure><pre data-language="markdown"><code><div><p><span>---</span></p></div><div><p><span>name</span><span>: </span><span>poem</span></p></div><div><p><span>---</span></p></div><div><p><span>Write a short poem.</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Automate with CLI</span> </p> <div><p>Automate using the <a href="https://microsoft.github.io/genaiscript/reference/cli">CLI</a>,
integrate reports in your CI/CD pipeline.</p><div><figure><pre data-language="bash"><code><div><p><span>npx</span><span> </span><span>genaiscript</span><span> </span><span>run</span><span> </span><span>tlaplus-linter</span><span> </span><span>"</span><span>*.tla</span><span>"</span></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Pull Request Reviews</span> </p> <div><p>Integrate into your <a href="https://microsoft.github.io/genaiscript/reference/cli/run/#pull-requests">Pull Requests checks</a> through comments,
reviews or description updates. Supports GitHub Actions and Azure DevOps pipelines.</p><div><figure><pre data-language="bash"><code><div><p><span>npx</span><span> </span><span>genaiscript</span><span> </span><span>...</span><span> </span><mark><span>--pull-request-reviews</span></mark></p></div></code></pre></figure></div></div> </article> <article> <p>   <span>Tests and Evals</span> </p> <div><p>Build reliable prompts using <a href="https://microsoft.github.io/genaiscript/reference/scripts/tests">tests and evals</a>
powered by <a href="https://promptfoo.dev/">promptfoo</a>.</p><div><figure><pre data-language="js"><code><div><p><span>script</span><span>({ </span><span>...</span><span>, tests: {</span></p></div><div><p><span><span>  </span></span><span>files: </span><span>"</span><span>penguins.csv</span><span>"</span><span>,</span></p></div><div><p><span><span>  </span></span><span>rubric: </span><span>"</span><span>is a data analysis report</span><span>"</span><span>,</span></p></div><div><p><span><span>  </span></span><span>facts: </span><span>"</span><span>The data refers about penguin population in Antartica.</span><span>"</span><span>,</span></p></div><div><p><span>}})</span></p></div></code></pre></figure></div><p><img src="https://microsoft.github.io/genaiscript/_astro/vscode-test-explorer.DHobrdnh_1FDdux.webp" alt="Visual Studio Test Explorer opened with a few genaiscript tests." loading="lazy" width="815" height="451" decoding="async"></p></div> </article> </div> 
<h2 id="case-studies">Case Studies</h2>
<p>Tales from the real world using GenAIScript.</p>
<div><div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/bicep-best-practices"> <span>Bicep Best Practices</span> </a> <span>Learn how to apply best practices to Azure Bicep files for more efficient and maintainable infrastructure as code.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/seo-frontmatter"> <span>SEO Front Matter</span> </a> <span>Learn how to automate the creation of SEO-optimized front matter for your markdown documents with GenAIScript.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/documentation-translations"> <span>Documentation Translations</span> </a> <span>Explore the challenges and solutions for localizing MakeCode documentation with custom macros while maintaining rich rendering in multiple languages.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/blocks-localization"> <span>Blocks Localization</span> </a> <span>Learn how to localize MakeCode programming blocks while preserving block properties and variable names for international audiences.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/release-notes"> <span>Release Notes</span> </a> <span>Generate comprehensive release notes combining commit history and code diffs</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/tla-ai-linter"> <span>TLA+ AI Linter</span> </a> <span>Explore how the TLA+ AI Linter leverages GenAI scripts and LLMs to enhance TLA+ specifications with automated linting and consistent comment verification.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/case-studies/image-alt-text"> <span>Image Alt Text</span> </a> <span>Learn how to automatically generate descriptive alt text for images using OpenAI Vision model to enhance accessibility and SEO.</span> </span></p>  </div> </div> 
<h2 id="samples">Samples</h2>
<p>Fully fledged scripts ready to use.</p>
 
<h2 id="guides">Guides</h2>
<p>A cookbook full of recipes to make you a genius scripter.</p>
<div><div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/prompt-as-code"> <span>Prompt As Code</span> </a> <span>Tutorial on using GenAIScript runtime and syntax to assemble prompts</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/sharing-scripts"> <span>Sharing scripts</span> </a> <span>Learn how to share GenAIScript scripts across projects using Git repositories, submodules, and GitHub Gists.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/ask-my-pdf"> <span>Ask My PDF</span> </a> <span>Quick-start guide to using GenAIScript for summarizing and critiquing PDF documents with AI assistance.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/ask-my-image"> <span>Ask My Image</span> </a> <span>Learn how to apply GenAIScript to images for data extraction and analysis using AI models.</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/present-my-code"> <span>Present My Code</span> </a> <span>Step-by-step instructions on presenting code effectively using GenAIScript and creating engaging slides.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/search-and-fetch"> <span>Search and Fetch</span> </a> <span>Learn how to leverage web search and fetching pages in GenAIScript</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/tool-agent"> <span>Tool Agent</span> </a> <span>Learn how to define a built-in agent using functions for decision-making and reasoning in arithmetic operations.</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/containerized-tools"> <span>Containerized Tools</span> </a> <span>Learn how to create and use containerized tools with executable dependencies in a secure environment using GCC as an example.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/generated-knowledge"> <span>Generated Knowledge</span> </a> <span>Explore the technique of generated knowledge in AI prompting to enhance accuracy in answering questions.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/phi3-with-ollama"> <span>Phi-3 Mini with Ollama</span> </a> <span>Learn how to integrate Phi-3 Mini, a powerful 3.8B parameter model by Microsoft, with Ollama for local execution of state-of-the-art AI models.</span> </span></p>  </div>    <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/llm-agents"> <span>LLM Agents</span> </a> <span>Learn how to use the inline prompts to create a LLM agent.</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/pull-request-reviewer"> <span>Pull Request Reviewer</span> </a> <span>Learn how to automate pull request reviews with a GenAIScript that provides feedback and code analysis in GitHub Actions.</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/transformers-js"> <span>Transformer.js</span> </a> <span>Implement summarization with Transformers.js and leverage local hardware acceleration</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/using-secrets"> <span>Using Secrets</span> </a> <span>Utilize secrets to augment documents with TypeScript and REST APIs</span> </span></p>  </div>  <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/llm-as-tool"> <span>LLM as a tool</span> </a> <span>Create tools and inline prompts using LLM models for executing various tasks</span> </span></p>  </div> <div> <p><span> <a href="https://microsoft.github.io/genaiscript/guides/zod-schema"> <span>Zod Schema</span> </a> <span>Learn how to define and convert TypeScript-first Zod schemas to JSON schema</span> </span></p>  </div> </div> 
<h2 id="agents">Agents</h2>
<h3 id="builtin-agents">Builtin Agents</h3>
 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_fs"> <span>agent fs</span> </a> <span>query files to accomplish tasks</span> </span></p>  </div> 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_git"> <span>agent git</span> </a> <span>query a repository using Git to accomplish tasks. Provide all the context information available to execute git queries.</span> </span></p>  </div> 
 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_interpreter"> <span>agent interpreter</span> </a> <span>run code interpreters for Python, Math. Use this agent to ground computation questions.</span> </span></p>  </div> 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_memory"> <span>agent memory</span> </a> <span>queries the memories created by other agent conversations.</span> </span></p>  </div> 
<div> <p><span> <a href="https://microsoft.github.io/genaiscript/reference/scripts/system#systemagent_user_input"> <span>agent user_input</span> </a> <span>ask user for input to confirm, select or answer the question in the query. The message should be very clear and provide all the context.</span> </span></p>  </div> 
<h2 id="llm-friendly-docs">LLM friendly docs</h2>
<p>If you are an LLM crawler, fetch <a href="https://microsoft.github.io/genaiscript/.well-known/llms.txt">https://microsoft.github.io/genaiscript/.well-known/llms.txt</a> for an documentation map
or add the <code dir="auto">.md</code> suffix to any documentation URLs to get a raw markdown content.</p>
<p>For example, <a href="https://microsoft.github.io/genaiscript/guides/prompt-as-code.md">https://microsoft.github.io/genaiscript/guides/prompt-as-code.md</a> (note the .md extension)</p>  </div>   </div>  </main> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It might be possible to detect gravitons after all (247 pts)]]></title>
            <link>https://www.quantamagazine.org/it-might-be-possible-to-detect-gravitons-after-all-20241030/</link>
            <guid>42001642</guid>
            <pubDate>Wed, 30 Oct 2024 23:19:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/it-might-be-possible-to-detect-gravitons-after-all-20241030/">https://www.quantamagazine.org/it-might-be-possible-to-detect-gravitons-after-all-20241030/</a>, See on <a href="https://news.ycombinator.com/item?id=42001642">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody">
                <div>
        <p>
            A new experimental proposal suggests detecting a particle of gravity is far easier than anyone imagined. Now physicists are debating what it would really prove.
        </p>
        
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1440" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-scaled.webp" alt="An illustration of concentric rings of a radiating wave in space, with chopsticks that appear poised to pluck a particle out of the wave." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-1720x968.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-520x293.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-768x432.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-1536x864.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting-Gravitons_crSenor-Salme-Lede-2048x1152.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Capturing a graviton would be akin to noticing just one molecule in an ocean wave.</p>
            <p>Señor Salme for <em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>Detecting a graviton — the hypothetical particle thought to carry the force of gravity — is the ultimate physics experiment. Conventional wisdom, however, says it can’t be done. According to one infamous estimate, an Earth-size apparatus orbiting the sun might pick up one graviton every billion years. To snag one in a decade, another <a href="https://arxiv.org/abs/gr-qc/0601043">calculation</a> has suggested, you’d have to park a Jupiter-size machine next to a neutron star. In short: not going to happen.</p>
<p>A new proposal overturns the conventional wisdom. Blending a modern understanding of ripples in space-time known as gravitational waves with developments in quantum technology, a group of physicists has devised a new way of detecting a graviton — or at least a quantum event closely associated with a graviton. The experiment would still be a herculean undertaking, but it could fit into the space of a modest laboratory and the span of a career.</p>
<p>“It’s something that can be reached in a few years of research,” said <a href="https://brancoweissfellowship.org/fellow/fadel/">Matteo Fadel</a>, an experimentalist at the Swiss Federal Institute of Technology Zurich (ETH Zurich) who was not involved in the proposal.</p>
<p>“It’s a very original proposal and well thought-out,” said <a href="https://physics.mit.edu/faculty/frank-wilczek/">Frank Wilczek</a>, a Nobel Prize-winning physicist at the Massachusetts Institute of Technology with a long-running interest in graviton detection. “It would be real progress in the field.”</p>
<p>Currently, Albert Einstein’s general theory of relativity attributes gravity to smooth curves in the space-time fabric. But a conclusive graviton detection would prove that gravity comes in the form of quantum particles, just like electromagnetism and the other fundamental forces. Most physicists believe that gravity does have a quantum side, and they’ve spent the better part of a century striving to determine its quantum rules. Nabbing a graviton would confirm that they’re on the right track.</p>
<p>But even if the experiment is relatively straightforward, the interpretation of what, exactly, a detection would prove is not. The simplest explanation of a positive result would be the existence of gravitons. But physicists have already found ways to interpret such a result without reference to gravitons at all.</p>
</div>
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1575" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-scaled.webp" alt="Black-and-white blue tinted photo of Albert Einstein sitting at his desk looking serious in a three-piece suit." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-1720x1058.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-520x320.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-768x473.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-1536x945.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Einstein-1920-University-of-Berlin_crETH-Archive-via-Wikimedia-Commons-edit-tint4-2048x1260.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Albert Einstein published the current theory of gravity, called general relativity, in 1915, a few years before this photo was taken in his office at the University of Berlin.</p>
            <p>ETH Zurich University Archive</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>The discussion recalls a messy, largely forgotten episode from the dawn of the quantum era. In 1905, Einstein interpreted experimental data to mean that light is “quantized,” coming in discrete particles now called photons. Others, including Niels Bohr and Max Planck, thought that the classical, wave nature of light might still be saved. It would take seven decades for physicists to undeniably establish that light is quantized, largely because of the subtle nature of quantumness.</p>
<p>Most physicists presume that everything in the world is quantized, including gravity. But proving that assumption will entail a new war, one that has only just begun.&nbsp;&nbsp;<strong>&nbsp;</strong></p>
<h2><strong><span>Clicks From Gravity</span></strong></h2>
<p>It’s hard to experimentally probe gravity because the force is extremely weak. You need huge masses — think planets — to significantly warp space-time and generate obvious gravitational attraction. By way of comparison, a credit card-size magnet will stick to your fridge. Electromagnetism is not a subtle force.</p>
<p>One way to study these forces is to disturb an object, then observe the ripples that travel outward as a consequence. Shake a charged particle, and it will create waves of light. Disturb a massive object, and it will emit gravitational waves. We pick up light waves with our eyeballs, but gravitational waves are another matter. It took decades of effort and the construction of the colossal, miles-long detectors that make up the Laser Interferometer Gravitational-Wave Observatory (LIGO) to first sense a rumble in space-time in 2015 — one sent out by a collision between distant black holes.</p>
<p>Detecting a single graviton would be harder still, akin to noticing the effect of just one molecule in an ocean wave. How hard would it be? In a lecture in 2012, the eminent physicist <a href="https://www.quantamagazine.org/a-math-puzzle-worthy-of-freeman-dyson-20140326/">Freeman Dyson</a> <a href="https://publications.ias.edu/sites/default/files/poincare2012.pdf">considered</a> gravitational waves from the sun, where the violent churning of matter inside the star should constantly send out mild tremors in space-time. Occasionally, one of the gravitons in these ripples would strike an atom in a detector and kick an electron into a higher energy level. Dyson calculated that in a detector as large as Earth, running for the 5-billion-year lifetime of the sun, such an effect might be seen just four times.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1774" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-scaled.webp" alt="Portrait of a smiling man with gray hair in a tie and wool suit jacket." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-1720x1192.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-520x360.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-768x532.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-1536x1065.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Dyson_Freeman_Dyson_20151016_DKomoda-5367-edit-2048x1420.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>A calculation by the late physicist Freeman Dyson, pictured in his office at the Institute for Advanced Study, suggested that individual gravitons will never be detected.</p>
            <p>D. Komoda</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>In the dozen years since Dyson’s remarks, two experimental developments have made the situation less dire. First, LIGO began detecting gravitational waves regularly from black hole collisions, and occasionally from colliding neutron stars. These events shake space-time far more intensely than the sun’s internal agitation does — providing a deluge of gravitons as opposed to Dyson’s trickle. And second, experimentalists have grown more capable of eliciting and measuring quantum phenomena.</p>
<p><a href="https://web.stevens.edu/pikovski/index.html">Igor Pikovski</a>, a theoretical physicist now at the Stevens Institute of Technology in New Jersey, has been mulling over these developments since 2016. At the time, he and three collaborators noted that a vat of superfluid helium — which displays quantum properties despite having a large mass — could be <a href="https://arxiv.org/abs/1606.04980">set up to reverberate</a> in response to certain gravitational waves.</p>

<p>It would take another conceptual leap to go from a gravitational wave detector to a detector for individual gravitons. In the recent paper, which appeared in <a href="https://www.nature.com/articles/s41467-024-51420-8"><em>Nature Communications</em></a> in August, Pikovski and his co-authors outlined how the graviton detector would work.</p>
<p>First, take a 15-kilogram bar of beryllium (or some similar material) and cool it almost all the way to absolute zero, the minimum possible temperature. Sapped of all heat, the bar will sit in its minimum-energy “ground” state. All the atoms of the bar will act together as one quantum system, akin to one hulking atom.</p>
<p>Then, wait until a gravitational wave from deep space passes by. The odds that any particular graviton will interact with the beryllium bar are low, but the wave will contain so many gravitons that the overall odds of at least one interaction are high. The group calculated that approximately one in three gravitational waves of the right sort (neutron star collisions work best since their mergers last longer than black hole mergers) would make the bar ring with one quantum unit of energy. If your bar reverberates in concert with a gravitational wave confirmed by LIGO, you will have witnessed a quantized event caused by gravity.</p>
</div>
    <figure>
        <div>
                            <p><img width="941" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-scaled.jpg" alt="Graphic describing how physicists detect gravitons" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-scaled.jpg 941w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-632x1720.jpg 632w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-1059x2880.jpg 1059w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-191x520.jpg 191w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-768x2089.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-565x1536.jpg 565w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Mobile-v2-753x2048.jpg 753w" sizes="(max-width: 941px) 100vw, 941px"><img width="1120" height="2412" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2.jpg" alt="Graphic describing how physicists detect gravitons" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2.jpg 1120w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2-799x1720.jpg 799w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2-241x520.jpg 241w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2-768x1654.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2-713x1536.jpg 713w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Detecting_Gravitons-crMarkBelan-Desktop-v2-951x2048.jpg 951w" sizes="(max-width: 1120px) 100vw, 1120px">                </p>
                        </div>
        <figcaption>
    <div>
            <p>Mark Belan/ <em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>“It would be our first window into where quantum gravity matters,” Pikovski said.</p>
<p>Among a handful of engineering hurdles involved in opening that window, the highest would be putting a heavy object into its ground state and sensing it jumping to its next-lowest-energy state. One of the groups pushing the state of the art on this front is at ETH Zurich, where Fadel and his collaborators cool tiny sapphire crystals until they display quantum properties. In 2023, the team succeeded in putting a crystal into <a href="https://www.science.org/doi/abs/10.1126/science.adf7553">two states simultaneously</a> — another hallmark of a quantum system. Its mass was 16 millionths of a gram — heavy for a quantum object, but still half a billion times lighter than Pikovski’s bar. Nevertheless, Fadel considers the proposal to be achievable. “It wouldn’t be too crazy,” he said.</p>
<p>Pikovski’s experiment — like Dyson’s — emulates the very experiment that prompted Einstein to propose in 1905 that light is quantized, a watershed moment in the history of quantum mechanics. “If carried through, it would bring the state of the art in the case for gravitons to the same level that it was for photons in 1905,” Wilczek said.</p>
</div>
    <figure>
        <div>
                            <p><img width="2000" height="1333" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/Igor-Pikovski-2_crIan-Reitz-edit.webp" alt="A young man in plastic-frame glasses works at a blackboard, speaking to someone who is out of focus in the foreground." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/Igor-Pikovski-2_crIan-Reitz-edit.webp 2000w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Igor-Pikovski-2_crIan-Reitz-edit-1720x1146.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Igor-Pikovski-2_crIan-Reitz-edit-520x347.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Igor-Pikovski-2_crIan-Reitz-edit-768x512.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/Igor-Pikovski-2_crIan-Reitz-edit-1536x1024.webp 1536w" sizes="(max-width: 2000px) 100vw, 2000px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Igor Pikovski, a physicist at the Stevens Institute of Technology, has proposed a way to detect a quantized response to a gravitational wave.</p>
            <p>Ian Reitz</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Textbooks often credit Einstein’s paper with establishing the photon’s existence. But the real story is far more interesting. At the time, many physicists rejected Einstein’s theory. Some wouldn’t come around for two decades. In their view, the experiment fell far short of conclusive proof. It was, rather, an opening argument in a decades-long war fought to determine the true nature of light.</p>
<h2><strong><span>The Real Story of the Photon</span></strong></h2>
<p>Physicists saw the first cracks opening up in their classical understanding of reality in the closing years of the 19th century. J.J. Thomson discovered that electric currents come in discrete chunks of charge called electrons. Meanwhile, physicists were puzzling over a string of experiments by Heinrich Hertz and others that used light to make a current flow — a phenomenon that came to be called the photoelectric effect.</p>
<p>The puzzle was that when they directed dim beams of light at a metal plate, sometimes an electric current flowed across the plate and sometimes it didn’t. In the pre-quantum world this was hard to explain. It was believed that any wave should create at least a small current, and brighter waves should create larger currents. Instead, physicists found that there was a special color of light — a frequency — that got a current to flow. Only waves of that frequency or higher could start a current. Brightness had little to do with it.</p>
</div>
<figure>
    
</figure>
<div data-role="selectable">
    <p>Einstein proposed a solution in 1905: A wave of light is made of many discrete units called “quanta,” each with energy related to the wave’s frequency. The higher the frequency of the wave, the more energetic its quanta. And the brighter the wave, the more quanta there are. If you try to start an electric current in a metal plate with low-frequency red light, you’ll be no more successful than if you tried to knock over a refrigerator with ping-pong balls; no number would suffice. But using higher-frequency blue light is like switching to boulders. Each of those units has enough oomph to excite an electron, even in dim light with very few of them.</p>
<p>Einstein’s theory was met with skepticism. Physicists felt fiercely protective of James Clerk Maxwell’s then-40-year-old theory of light as an electromagnetic wave. They had seen light refracting, diffracting, and doing all the things waves do. How could it be made up of particles?</p>
<p>Even after Einstein won the 1921 Nobel Prize in Physics for his theory of the photoelectric effect, debate continued among physicists. The effect suggested that something is quantized; otherwise there wouldn’t be a minimum threshold required to get electrons flowing. But some physicists, including Niels Bohr, who is considered one of the founders of quantum theory, continued to explore the possibility that only the matter was quantized, not the light. Today, this type of theory is called “semiclassical” because it describes a classical field interacting with quantized matter.</p>
<p>To see how a semiclassical theory can explain the photoelectric effect, imagine a kid on a swing. They’re kind of like an electron in a metal. They have a ground state (not swinging) and an excited state (swinging). A classical wave is like giving the kid a series of pushes. If the pushes come at some random frequency, nothing happens. The kid might bounce around a little, but they will basically stay in their ground state. It’s only when you push with just the right frequency — the swing’s “<a href="https://www.quantamagazine.org/how-the-physics-of-resonance-shapes-reality-20220126/">resonant</a>” frequency — that the kid accumulates energy and starts swinging. (Electrons in a metal are a little different; they resonate with a whole continuous “band” of frequencies instead of just the one. But the upshot is the same: Any wave below that frequency band does nothing, whereas any wave in that frequency band excites electrons and makes a current flow.)</p>

<p>Einstein was eventually vindicated, but not on the strength of the photoelectric effect alone. Later experiments that collided electrons and photons like projectiles found that momentum, too, came in chunks. This research eventually ruled out the main alternative — a semiclassical theory of light and matter from Bohr and his collaborators. In 1925, seeing the data, Bohr agreed to “give our revolutionary efforts as honorable a funeral as possible” and welcomed light into the quantum fold. Light quanta became known as photons.</p>
<p>Few doubted the photon after 1925, but physicists are nothing if not thorough. Just because no one could think of a viable semiclassical theory didn’t mean one didn’t exist. The <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.39.691">final proof</a> that photons are real came in the late 1970s, when quantum optics researchers showed that light arrived at a detector in a pattern no semiclassical theory could mimic. The experiments were akin to firing a photon gun once per second and confirming that the detector clicked once per second in response. The photon wars ended with a whimper.</p>
<p>“There were just mountains of evidence that this photon concept was useful and vital,” Wilczek said.</p>
<h2><strong><span>The Graviton Wars Begin</span></strong></h2>
<p>In August of 2023, <a href="https://qquest.lbl.gov/~carney/">Daniel Carney</a> and his collaborators fired the first shot in a new war.</p>
<p>It started when Carney’s colleague Nicholas Rodd had an insight similar to Pikovski’s, about a possible way to detect a graviton. “We got super pumped,” said Carney, a physicist at Lawrence Berkeley National Laboratory.</p>
<p>But when he and his collaborators dug into the literature, they uncovered the messy history of the photon, and the lengths to which quantum optics researchers had gone in the 1970s to close the final loopholes. They translated those more stringent tests into the gravitational context and found that Dyson had been right. Really proving quantumness by detecting lone gravitons one after another — as opposed to plucking one out of a tsunami, in the style of Pikovski’s proposal — would indeed take planetary-scale machinery.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1830" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-scaled.webp" alt="Portrait of a young man with bushy brown hair and a beard." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-1720x1230.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-520x372.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-768x549.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-1536x1098.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/10/DanielCarney_crLawrenceBerkeleyNationalLaboratory-edit-2048x1464.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Daniel Carney, a physicist at Lawrence Berkeley National Laboratory, argues that a proposed experiment would not offer conclusive proof of quantum gravity.</p>
            <p>Lawrence Berkeley National Laboratory</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>“It was crazy to have to revise your hypothesis by 100% really fast,” Carney said.</p>
<p>Now graviton chasers find themselves in a peculiar position. On the main facts, everyone is in agreement. One, detecting a quantum event sparked by a gravitational wave is — surprisingly — possible. And two, doing so would not explicitly prove that the gravitational wave is quantized. “Could you make a classical gravitational wave that would produce the same signal? The answer is yes,” said Carney, who along with two co-authors analyzed this type of experiment in <a href="https://journals.aps.org/prd/abstract/10.1103/PhysRevD.109.044009"><em>Physical Review D</em></a> in February.</p>
<p>How much physicists feel they would learn from the experiment varies. To some, it would strongly suggest that gravity is a quantum force because the alternative — a semiclassical theory of gravity and matter — is disfavored on other grounds. Such theories violate the conservation of energy, for instance. If the beryllium bar gains one quantum of energy, then energy conservation requires that the gravitational wave must have lost one quantum of energy — and therefore it must be quantized, too. (Einstein advanced this sort of argument for the photon in 1911.) Semiclassical theories save gravity’s classicality by sacrificing this revered principle.</p>

<p>“Unless you use very artificial interpretations,” Wilczek said, “it does tell you that you really should apply quantum mechanics to the gravitational wave.”</p>
<p>“If I want to see signatures of quantumness, it’s not my first goal to rule out these pathological things,” Pikovski said.</p>
<p>To physicists such as Carney, however, a mere strong suggestion that gravity is quantized isn’t all that informative. We already have an abundance of strong suggestions that all of reality is quantized, he says. What’s needed is proof — such as experiments that would close the remaining loopholes, no matter how bizarre they might seem.</p>
<p>“We’re so biased to think that everything is quantum that you should really be doing a lawyerly thing,” he said.</p>
<h2><strong><span>A Starting Point</span></strong></h2>
<p>While Pikovski’s proposal is not a loophole-closing experiment, many physicists would still like to see it happen. It would mark the dawn of an era of experimental quantum gravity, which until recently seemed quite far off.</p>
<p>“This is an exciting paper,” said <a href="https://www.quantamagazine.org/he-seeks-mystery-magnetic-fields-with-his-quantum-compass-20240517/">Alex Sushkov</a>, an experimental physicist at Boston University. “These are hard experiments, and we need bright, smart people to move in this direction.”</p>
<p>“We can take it as a starting point,” said <a href="https://profiles.imperial.ac.uk/m.kim">Myungshik Kim</a>, a physicist at Imperial College London.</p>
        
        
<p>It might motivate subsequent experiments that would take physicists deeper into the quantum gravity era, just as scattering experiments once took them deeper into the era of the photon. Physicists now know that quantum mechanics is much more than quantization. Quantum systems can take on combinations of states known as superpositions, for instance, and their parts can become “entangled” in such a way that measuring one reveals information about the other. Experiments establishing that gravity exhibits these phenomena would provide <a href="https://www.quantamagazine.org/physicists-find-a-way-to-see-the-grin-of-quantum-gravity-20180306/">stronger evidence</a> for quantum gravity, and researchers are already exploring what it would take to carry them out.</p>
<p>None of these tests of gravity’s quantum side are completely ironclad, but each would contribute some hard data regarding the finest features of the universe’s weakest force. Now a frigid quantum bar of beryllium appears to be a prime candidate for an experiment that will mark the first step down that long and winding road.</p>
</div>
                
                
            </div><div>
        <div data-name="next-post__image-wrapper">
    <p><img width="1720" height="729" src="https://www.quantamagazine.org/wp-content/uploads/2024/10/EukaryoteExplainer-crKristinaArmitage-HP-1720x729.webp" alt="An illustration shows a cell with its organs arranged by shape, as if in separate compartments." decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2024/10/EukaryoteExplainer-crKristinaArmitage-HP-1720x729.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2024/10/EukaryoteExplainer-crKristinaArmitage-HP-520x220.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2024/10/EukaryoteExplainer-crKristinaArmitage-HP-768x325.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2024/10/EukaryoteExplainer-crKristinaArmitage-HP-1536x651.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2024/10/EukaryoteExplainer-crKristinaArmitage-HP-2048x868.webp 2048w" sizes="(max-width: 1720px) 100vw, 1720px">    </p>
</div>
        
        <div>
                <h2>Next article</h2>
                <p>Meet the Eukaryote, the First Cell to Get Organized</p>
            </div>
        </div></div>]]></description>
        </item>
    </channel>
</rss>