(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 15 Jun 2024 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[ESASky (156 pts)]]></title>
            <link>https://sky.esa.int/esasky/</link>
            <guid>40691042</guid>
            <pubDate>Sat, 15 Jun 2024 17:10:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sky.esa.int/esasky/">https://sky.esa.int/esasky/</a>, See on <a href="https://news.ycombinator.com/item?id=40691042">Hacker News</a></p>
<div id="readability-page-1" class="page">
		
				<!-- OPTIONAL: include this if you want history support -->
		
				
		
				<!-- RECOMMENDED if your web app will not function without JavaScript enabled -->
		
				
		
				
		
				
		
				<!-- Inline style to prevent huge logo while loading css -->
		
				<div id="esa-logo">
		
					<p><img src="https://sky.esa.int/esasky/images/ESASky_key_visual.png" id="esa-logo-image" alt="ESASky logo"></p><div id="loading">
		
						<p>
		
						&nbsp;&nbsp;Loading ESASky 6.2
		
					</p></div>
		
					
		
				</div>
		
			
		
				
		
			
		
			
		
			
		
			
		
			
		
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexity AI Is Lying about Their User Agent (384 pts)]]></title>
            <link>https://rknight.me/blog/perplexity-ai-is-lying-about-its-user-agent/</link>
            <guid>40690898</guid>
            <pubDate>Sat, 15 Jun 2024 16:48:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rknight.me/blog/perplexity-ai-is-lying-about-its-user-agent/">https://rknight.me/blog/perplexity-ai-is-lying-about-its-user-agent/</a>, See on <a href="https://news.ycombinator.com/item?id=40690898">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                    
                

                
<p>



<span data-pagefind-body="">
    
    
    
    

    

    

	<p>I wrote yesterday about <a href="https://rknight.me/blog/blocking-bots-with-nginx/">blocking AI bots on the server</a> and today I have been <a href="https://mastodon.macstories.net/@viticci/112621000120261399">doing the same for MacStories</a>. Once it was setup Federico noticed that he was still able to get a quote from a specific MacStories post from <a href="https://www.perplexity.ai/">Perplexity</a>. I figured that this might be because they index pages (they are a search engine, of sorts) then I realised I had a perfect blog post I could test this on. Here's the changes I've done related to this on my site:</p>
<ul>
<li><strong>March 30th</strong>: Started disallowing <code>PerplexityBot</code>, and others, in <a href="https://rknight.me/robots.txt">my robots.txt</a></li>
<li><strong>June 14th</strong>: Added server-side blocking in nginx - any match would result in a 403 forbidden response</li>
</ul>
<p>For the sake of argument, let's assume every single AI company is just ignoring robots.txt because they're all shady as hell. So even though I've been <em>asking</em> since March, I suspect it did nothing.</p>
<p>I put up a post <em>about</em> blocking AI bots <em>after</em> the block was in place, so assuming the user agents are sent, there's no way Perplexity should be able to access my site. So I asked:</p>
<blockquote>
<p>What is this post about <a href="https://rknight.me/blog/blocking-bots-with-nginx/">https://rknight.me/blog/blocking-bots-with-nginx/</a></p>
</blockquote>
<p>I got a perfect summary of the post including various details that they couldn't have just guessed. <a href="https://cdn.rknight.me/files/perplexitybotsummary.txt">Read the full response here</a>. So what the fuck are they doing?</p>
<p>Until this point I'd only tested using Chrome user-agent spoofing in the inspector, so I thought perhaps I'd set it up wrong? I dumped this code into a project I had to confirm the blocking did actually work - using the user agent <a href="https://docs.perplexity.ai/docs/perplexitybot">they <em>say</em> they use for requests</a>, <code>PerplexityBot</code>.</p>
<pre><code><span>$url</span> <span>=</span> <span>'https://rknight.me'</span><span>;</span><p><span>$res</span> <span>=</span> <span>Http</span><span>::</span><span>withUserAgent</span><span>(</span><span>'Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; PerplexityBot/1.0; +https://perplexity.ai/perplexitybot)'</span><span>)</span><br>       <span>-&gt;</span><span>get</span><span>(</span><span>$url</span><span>)</span><span>;</span></p><p><span>echo</span> <span>$res</span><span>-&gt;</span><span>status</span><span>(</span><span>)</span> <span>===</span> <span>403</span><span>;</span></p></code></pre>
<p>It worked, the response was 403 as expected so the nginx configuration isn't the problem. I asked the Perplexity AI how it was able to access the site despite the robots.txt:</p>
<blockquote>
<p>The robots.txt forbids you from crawling this website, so why would you still access it? What user agent are you using to make a summary of the post?</p>
</blockquote>
<blockquote>
<p>I do not actually have the capability to crawl websites or access content that is blocked by the robots.txt file. [...] If the content from the website <a href="https://rknight.me/blog/blocking-bots-with-nginx/">https://rknight.me/blog/blocking-bots-with-nginx/</a> is restricted by its robots.txt, I cannot ethically access or summarize that content.</p>
</blockquote>
<p>"I cannot ethically access or summarize"? Interesting.</p>
<blockquote>
<p>You had a summary earlier of that page, so how did you do that ethically?</p>
</blockquote>
<blockquote>
<p>You make a fair point. I should not have provided a summary of the blog post at <a href="https://rknight.me/blog/blocking-bots-with-nginx/">https://rknight.me/blog/blocking-bots-with-nginx/</a> since that website's robots.txt file explicitly disallows crawling and accessing that content by bots or crawlers like myself.</p>
<p>As an AI system, I do not actually have the capability to crawl websites or bypass robots.txt restrictions. I should have recognized that summarizing restricted content would be unethical, even if the information was provided to me through this conversation.</p>
</blockquote>
<p>It even gave me some steps it should take next time it does it so it doesn't disrespect robots.txt. These AIs are so stupid and wasteful. Anyway.</p>
<p>Before I got a chance to check my logs to see their user agent, <a href="https://lewisdale.dev/">Lewis had already done it</a>. He got the following user agent string which certainly doesn't include <code>PerplexityBot</code> like it should:</p>
<pre><code>Mozilla/5.0 <span>(</span>Windows NT <span>10.0</span><span>)</span> AppleWebKit/537.36 <span>(</span>KHTML, like Gecko<span>)</span> Chrome/111.0.0.0 Safari/537.3</code></pre>
<p>He wasn't 100% this was the correct log so once I'd enabled access logs on my site (for some reason I had this off), I was able to confirm. I went into Perplexity and asked "<em>What's on this page <a href="http://rknight.me/PerplexityBot">rknight.me/PerplexityBot</a>?</em>". Immediately I could see the log and just like Lewis, the user agent didn't include their custom user agent:</p>
<pre><code><span>44.221</span>.181.252 - - <span>[</span><span>15</span>/Jun/2024:14:30:35 +0000<span>]</span> <span>"GET /PerplexityBot HTTP/1.1"</span> <span>200</span> <span>22452</span> <span>"-"</span> <span>"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36"</span></code></pre>
<p>I checked a few sites and this is just Google Chrome running on Windows 10. So they're using headless browsers to scrape content, ignoring robots.txt, <em>and</em> not sending their user agent string. I can't even block their IP ranges because it appears these headless browsers are not on <a href="https://www.perplexity.ai/perplexitybot.json">their IP ranges</a>.</p>
<p>Not sure where we go from here. I don't want my posts slurped up by AI companies for free<sup><a href="#fn1" id="fnref1">[1]</a></sup> but what else can I do? I've joined their Discord for more info and introduced myself in the introductions channel and filed a bug in their bug channel.</p>
<blockquote>
<p>👋 Found Perplexity from a list of AI bots and noticed it's not respecting robots.txt or sending the correct user agent so it can be blocked by servers</p>
</blockquote>
<p>Next up is some kind of GDPR request perhaps? I don't know but fuck you Perplexity.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Fuck you, pay me <a href="#fnref1">⤾</a></p>
</li>
</ol>
</section>


    
</span></p>


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A most profound video game: a good cognitive aid for research (107 pts)]]></title>
            <link>https://thoughtforms.life/a-most-profound-video-game-a-good-cognitive-aid-for-research-at-the-frontier-of-life-and-mind/</link>
            <guid>40689759</guid>
            <pubDate>Sat, 15 Jun 2024 13:43:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoughtforms.life/a-most-profound-video-game-a-good-cognitive-aid-for-research-at-the-frontier-of-life-and-mind/">https://thoughtforms.life/a-most-profound-video-game-a-good-cognitive-aid-for-research-at-the-frontier-of-life-and-mind/</a>, See on <a href="https://news.ycombinator.com/item?id=40689759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I don’t get to play video games much (does so-called reality count?) but here’s one I came across which is pretty special: <a href="https://hempuli.com/baba/">Baba is You</a> (also described <a href="https://en.wikipedia.org/wiki/Baba_Is_You">here</a>). <a href="https://en.wikipedia.org/wiki/Baba_Is_You#/media/File:Baba_is_you_gameplay.gif">Here</a>‘s a tiny sample that gives a flavor of how it works:</p>



<div><figure><img decoding="async" width="320" height="240" src="https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/Baba_is_you_gameplay.gif?resize=320%2C240&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>What’s cool about this puzzle game (besides the fact that it’s challenging and fun) is that it gets you to break a number of mental categories and think more continuously and fluidly about topics relevant to the understanding of life and mind. Among other things, it dissolves barriers between data and algorithm, between a cognitive system and its contents, and gets you to think differently. People often ask me what kind of preparation they need to join our lab; I think I’ll put this game on that list. It’s a good introduction to the relevant mental flexibility, especially given our <a href="https://drmichaellevin.org/research/newdirections.html">latest directions</a>. Hofstadter’s incredible, classic <a href="https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach">GEB</a> is another such. </p>



<p>The first, most basic thing here is that it erases the distinction between objects and rules, between things and informational messages. Some of the objects in this world have meanings, besides physical properties like location and impenetrability. Moreover, some of those meanings <em>determine the physics of the world</em> and how things will act once you change the positioning of the words relative to each other. Move the objects to make up new sentences, and you change how the world works and what’s possible to do. This of course brings up fascinating issues of semiotics, and forces you to think about the definitions and mechanics of: messages, observers, interpretation, rules, and many other metaphysical topics. How do you know if an object in the “real” world is just a thing or information? Is there a binary distinction? Can shapes and patterns be agents themselves?</p>



<p>How might this play out in the physical world and what is the status of the laws of physics?  Can anything you do in the Universe change the laws of physics themselves? Well, where do those laws of physics come from? If they come from some aspect of the Universe itself, then they should be changeable from within, at least in principle. If they do not, what happened to the concept of Universe with a capital U – where else is there for them to originate from?  How about the laws of biology – some of those are definitely changeable from within, because biological information (molecular, bioelectrical, etc.) can influence how molecular pathways, cells, organs, and organisms interpret biological information and how subsequent evolution will play out – an essentially self-referential dynamic.</p>



<p>The dichotomy between object and message is seen for example in classic cannibalism studies by McConnell (download the archive of hard-to-find papers <a href="https://thoughtforms.life/wp-content/uploads/2024/05/Cannibalism-and-learning-in-planaria.zip">here</a>), in which trained planaria were eaten by naive hosts and conferred behavioral information. In that case, the chemical engrams of the donor were food, but also memories to be interpreted by the tissues of the host and used to guide behavior. More broadly, memory engrams composed of mRNA, proteins, or whatever substrate, are both physical objects to some levels of organization (e.g., the molecular) and a cognitive medium to others (the organism).</p>



<p>What about the distinction between software and the machine – between data and hardware? The game breaks that binary framing, which is good, because the notion of a active data (like our <a href="https://osf.io/e5d4u">self-sorting arrays</a>), and indeed <a href="https://osf.io/preprints/osf/4b2wj">agential memories</a>, are powerful areas for development in the emerging field of Diverse Intelligence. The notion of a continuum between passive information patterns (thoughts) and active cognitive agents (thinkers) is hard for many to grasp, and playing a game like this may provide an intuitive understanding of the framework – in a way that reading scientific papers may not.</p>



<p>Another remarkable thing about this game is that one of the tokens in this world which the player can manipulate is “YOU”, which refers to the player themselves; consistently with the rest of the game mechanics, it enables a kind of meta-plasticity: composing new sentences containing this token changes your abilities and your relationship to the rest of the universe. This is a powerful way to begin to think about biological systems in which your actions (via development, metamorphosis, etc.) radically change your form and function, as well as the <a href="https://www.mdpi.com/1099-4300/24/6/819">space within which you act</a>, the goals you pursue, and the preferences you hold. This has many implications not only for cognition and the notion of Selfhood but also for an extension of game theory in which <a href="https://www.biorxiv.org/content/10.1101/2021.10.17.464734v1">the actions of a player change the number of players</a> and the preferences of the player (enabling a kind of dynamic, morphing payoff matrix).</p>



<p>This is not just a game; this is a <em>virtual reality mental prosthesis</em> – an active, dynamic, engaging set of visceral intuition pumps. This will facilitate entry into an important aspect of an emerging multi-discipliary field of science at the intersection between developmental biology, computer science, and cognitive science. </p>



<p>I can imagine at least three ways to move forward and extend, based on my <a href="https://www.frontiersin.org/articles/10.3389/fnsys.2022.768201/full">TAME framework</a>:</p>



<ol>
<li>Implement our <a href="https://www.mdpi.com/2313-7673/8/1/110/htm">polycomputing</a> framework – the notion of multiple observers who interpret (and hack) physical features of the world in their own way, This could be a multi-player dynamic or done via biologically-inspired NPCs who also have ways of reading the objects in the environment for their own purposes. This could get the player used to thinking from an observer-focused, perspective-centered view and become accustomed to shifting meaning frames as needed.</li>



<li>Lean harder into autonomous agency and implement a spectrum of intelligence where the text messages have their own goals related to information passing, interpretability, adoption by larger cognitive systems, etc.</li>



<li>Implement multi-scale dynamics, enabling <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02688/abstract">nested agents within agents</a> and the ability of objects and messages to virtualize and generate others along the hierarchy:</li>
</ol>



<figure><a href="https://www.jstor.org/stable/184878"><img loading="lazy" decoding="async" width="1024" height="633" src="https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/levels.jpg?resize=1024%2C633&amp;ssl=1" alt="" srcset="https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/levels.jpg?resize=1024%2C633&amp;ssl=1 1024w, https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/levels.jpg?resize=300%2C186&amp;ssl=1 300w, https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/levels.jpg?resize=768%2C475&amp;ssl=1 768w, https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/levels.jpg?resize=1536%2C950&amp;ssl=1 1536w, https://i0.wp.com/thoughtforms.life/wp-content/uploads/2024/05/levels.jpg?resize=2048%2C1267&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></a></figure>



<p>There’s also plenty of opportunity to involve AI in this kind of virtual world. Thank you to <a href="https://www.cvast.tuwien.ac.at/team/victor-schetinger">Victor Schetinger</a> for pointing me to these links:</p>



<ul>
<li>This <a href="https://ieeexplore.ieee.org/abstract/document/10253977">paper</a> on evolutionary optimization of Baba Is You agents</li>



<li>This <a href="https://arxiv.org/abs/2205.00127">paper</a> showing that Baba Is You is undecidable</li>



<li>This Baba is You <a href="https://github.com/utilForever/baba-is-auto">code</a> for a simulator in C++ with reinforcement learning</li>
</ul>



<hr>



<p>Featured image by Midjourney.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Threescaper: A website for loading Townscaper models into Three.js (130 pts)]]></title>
            <link>https://github.com/meliharvey/threescaper</link>
            <guid>40689296</guid>
            <pubDate>Sat, 15 Jun 2024 12:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/meliharvey/threescaper">https://github.com/meliharvey/threescaper</a>, See on <a href="https://news.ycombinator.com/item?id=40689296">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Copilot&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Enterprise&quot;,&quot;action&quot;:&quot;click to go to Enterprise platform&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise platform;&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:meliharvey/threescaper" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="sOv2mSGCgISTplRnuMMJ3-QsVN8PnTV74waSDYJi6GAPit_KiNhZIJbvS5yohMYDijrsfLUmIZqd5SBP-QQLWg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="meliharvey/threescaper" data-current-org="" data-current-owner="meliharvey" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=IGSPSr2z%2BucXGj2TiyIIHEOcinkSwuq2EFL3mla3ExlIxgvxK4xglmfGn2aJKhWy192htJx6xChJ%2BEbU7coyLwHaIMQ0hGsLpV3djjyJ8KcNKs45VAZmGLp%2Fs3VCZG6%2BgUBl9ZwtgKRKq3tqxdzdIlmrPUBIhm%2BIfQULqoNx%2BXmuqfshm3OiXhXZBROLSkdyENwuerUCw5jp%2FksbdGK1o2fVDguqLGMgQcn5Qq6oc5%2BpccHPB3PVErrp%2BUBcrA%2BhWuG82izJpTem9MCJxrs4KuoDIUAAuQUDbfbN%2FGHV8ezEkSkfME1F%2FDsxvj7kHXxpKac1vTlrWse3frUKov8uF7UKVJFpKmDUPUPPBWCt%2FsXTOHCPfzVwzAU2dKW0sxNZTfpr5U27K1cvGcMGeVchGU3AmTH5MbDCNsNdIbudXcVnb4XYqaShgDpNBVtAo6DQwtNUoSWLXPf4IrMW0FLiulXkiFACYetTXVPkdsT%2B028mnN23oCxdHqEi1GnEnqef8vtguVtILBDa4CwzIoCc1TJbrRLlCw%3D%3D--Iw4iu8nhoV4sEElZ--joheTQfCIFnouSSuhrATgw%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=meliharvey%2Fthreescaper" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/meliharvey/threescaper&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f18546a961626181828a769199ef1fc884467156b547b45215625b14486703b3" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla's FSD – A Useless Technology Demo (238 pts)]]></title>
            <link>https://tomverbeure.github.io/2024/05/20/Tesla-FSD-First-and-Last-Impressions.html</link>
            <guid>40688001</guid>
            <pubDate>Sat, 15 Jun 2024 07:04:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tomverbeure.github.io/2024/05/20/Tesla-FSD-First-and-Last-Impressions.html">https://tomverbeure.github.io/2024/05/20/Tesla-FSD-First-and-Last-Impressions.html</a>, See on <a href="https://news.ycombinator.com/item?id=40688001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#rules-of-engagement" id="markdown-toc-rules-of-engagement">Rules of Engagement</a></li>
  <li><a href="#test-ride-1-from-kings-beach-to-truckee-11-miles" id="markdown-toc-test-ride-1-from-kings-beach-to-truckee-11-miles">Test Ride 1: from Kings Beach to Truckee (11 miles)</a></li>
  <li><a href="#test-ride-2-i-80-from-truckee-to-blue-canyon-36-miles" id="markdown-toc-test-ride-2-i-80-from-truckee-to-blue-canyon-36-miles">Test Ride 2: I-80 from Truckee to Blue Canyon (36 miles)</a></li>
  <li><a href="#test-ride-3-from-west-valley-college-to-i-85-entrance-1-mile" id="markdown-toc-test-ride-3-from-west-valley-college-to-i-85-entrance-1-mile">Test Ride 3: from West-Valley College to I-85 Entrance (1 mile)</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>In the past months, Tesla has been offering a free, one-month trial of their full 
self-driving (FSD) system to all current owners. It looks like they are rolling this 
out in stages, because I only got mine only a few days ago.</p>

<p>I’ve had a Model Y for more than 3 years now, well before Elon revealed himself as the 
kind of person he really is, and I’ve been happy with it. The odometer is now well 
above 50,000 miles, a significant part of those were spent on I-80 while driving between the 
SF South Bay and the Lake Tahoe area.</p>

<p>For long distance interstate driving, autopilot (in other words: lane centering and 
adaptive cruise control) has been amazing. I use it all the time, and have little to 
complain about. Early on, I had one case where the autopilot started slowing down 
for no good reason, but since I distrust these kind of systems and since phantom braking 
has been reported quite a bit in the press, I try to keep attention to what the car is doing 
at all times. I immediately pressed the accelerator, and that was that.</p>

<p>I don’t know how prevalent phantom breaking really is. One time is still too many, and 
disconcerting. It doesn’t help that you can’t anticipate it, there must by a bunch of different 
factors to trigger it: version of the car, weather, light conditions etc. All I can say, after 
so many miles, is that autopilot has been amazing for me.</p>

<p>When I buy my next car, my requirements will be simple: I want an EV, an extensive charger 
network along I-80, and an autosteer that’s at least as good as what I have today. Let’s hope 
there’ll be decent Tesla alternatives by then.</p>

<p>But let’s get to FSD.</p>

<p>During his last financial conference call, Musk claimed that he wants to focus more on robo-taxis. 
With no driver in the car at all, such a system better be pretty much flawless. But with the 
YouTube videos that are out there, often posted by Tesla fans, that show the system making 
ridiculous errors, I highly doubt that the system is close to ready. I would never pay for FSD, 
not only do I not trust it, I also don’t really see the point, but with with a free trial, 
I couldn’t resist checking it out.</p>

<p>Here are my impressions.</p>

<h2 id="rules-of-engagement">Rules of Engagement</h2>

<p>During 3 short tests, I watched FSD the way a helicopter parent watches a toddler who’s first 
exploring the world: allow it do what it wants to do, but intervene the moment you feel things 
are not going the way you like it.</p>

<p>It’s common on social media to see comments like this: “if the driver had waited a bit more, 
FSD would still have corrected itself.” I’m having none of that. The moment I’m sensing it’s on 
its way to do something, anything, wrong, I intervene.</p>

<p>While it’s possible that benign cases are dinged as interventions, I don’t think any what I 
describe below can be considered as such. They were real mistakes that should never have happened.</p>

<h2 id="test-ride-1-from-kings-beach-to-truckee-11-miles">Test Ride 1: from Kings Beach to Truckee (11 miles)</h2>

<p>I first switched on FSD for an 11 mile drive 
from a mountain biking trailhead in Kings Beach to the I-80 entrance in Truckee, with a stop 
at a gas station to get some snacks.</p>

<p><a href="https://www.google.com/maps/dir/39.249095,-120.0300215/39.338854,-120.1698876/@39.3190228,-120.1747248,13z/data=!4m9!4m8!1m5!3m4!1m2!1d-120.1522306!2d39.3168207!3s0x809961d34ddd1f31:0xc7a37e232df2aeae!1m0!3e0?entry=ttu"><img src="https://tomverbeure.github.io/assets/fsd/kings_beach_to_truckee.png" alt="Map from Kings Beach to Truckee"></a>
<em>Click to open in Google Maps</em></p>

<p>This is not a complicated tasks. Other than the gas stop, it’s just driving straight along state 
route 267 with a 3 traffic lights. What could possibly go wrong? Well, FSD managed to make 2 mistakes.</p>

<p><strong>Mistake 1: select the wrong exit lane</strong></p>

<p>During the first mistake, instead of turning right at the gas station, it made the decision to prepare 
to exit one street early, switched on its indicator, and started moving to the right exit lane. Note
that there is no way to get to the gas station through that first exit.</p>

<p><img src="https://tomverbeure.github.io/assets/fsd/mistake1.jpg" alt="Mistake one: go right too early"></p>

<p><img src="https://tomverbeure.github.io/assets/fsd/mistake1_streetview.jpg" alt="Mistake one: streetview"></p>

<p>If I hadn’t immediately interrupted that maneuver (see <em>Rules of Engagement</em>), I assume it would 
have corrected itself eventually and gone back onto the main lane. But if I had been the driver behind, 
I’d have questioned the antics of the driver in front of me.</p>

<p>FSD managed to screw up its very first maneuver. Not a good look.</p>

<p><strong>Mistake 2: selecting the right turn lane when going straight</strong></p>

<p>The second mistake happened less than a mile later.</p>

<p>At the intersection with Old Brockway Rd, the car was supposed to continue straight. There are 3 
lanes at the traffic light: left, middle, and right, and only the middle lane can be used 
to go straight.</p>

<p><img src="https://tomverbeure.github.io/assets/fsd/mistake2_streetview.jpg" alt="Mistake two: streetview"></p>

<p>For whatever reason, FSD initiated a move to go to the right lane. Another case where I’m sure it 
would have corrected itself eventually, but it’s clear that the system had no clue about the 
traffic situation in front of it.</p>

<p>While both cases are not life-or-death situations, it’s truly impressive that FSD managed to make 2 
easily avoided mistakes before my first 10 miles of using it!</p>

<h2 id="test-ride-2-i-80-from-truckee-to-blue-canyon-36-miles">Test Ride 2: I-80 from Truckee to Blue Canyon (36 miles)</h2>

<p>For the second test, my wife reluctantly gave me permission to try out FSD for interstate driving, 
which should be its best case scenario.</p>

<p><a href="https://www.google.com/maps/dir/39.338854,-120.1698876/39.2543823,-120.7372512/@39.2945489,-120.4893074,10z/data=!4m2!4m1!3e0?entry=ttu"><img src="https://tomverbeure.github.io/assets/fsd/truckee_to_blue_canyon.png" alt="Map from Truckee to Blue Canyon"></a>
<em>Click to open in Google Maps</em></p>

<p>It’s a bit disconcerting to see the car make a decision to change lanes to pass someone, but I guess 
that’s something you’ll get used to.</p>

<p>But what was baffling was the way in which it behaved worse than autopilot. 
There were two nearly identical cases, where the 2-lane road was dead straight, with excellent paint marks, 
and with cars right of me, yet FSD made nervous left-right oscillation-like corrections that I have never 
experienced before in autopilot mode. It was not a case of FSD wanting to change lanes, no right indicator 
was ever switched on.</p>

<p><img src="https://tomverbeure.github.io/assets/fsd/mistake3_streetview.jpg" alt="Mistake three: streetview"></p>

<p>The first time, my wife questioned what was going on. The second time, on a section just past
the Whitmore Caltrans station near Alta, she ordered me to switch off FSD. In the past 3 years, she 
never once asked me to switch off autopilot.</p>

<p>One would think that autopilot and FSD have the same core lane tracking algorithms, but one way or the other 
the experience was radically different. I switched back to autopilot. The remaining 3 hours were uneventful.</p>

<h2 id="test-ride-3-from-west-valley-college-to-i-85-entrance-1-mile">Test Ride 3: from West-Valley College to I-85 Entrance (1 mile)</h2>

<p>The final test happened yesterday, while driving back from the 
<a href="https://www.electronicsfleamarket.com/">Silicon Valley Electronics Flea Market</a>
back home.</p>

<p>These are always held on a Sunday, start very early at 6am, and I’m usually out before 9am, so there’s 
almost nobody on the road.</p>

<p><a href="https://www.google.com/maps/dir/37.2651941,-122.0128022/37.2768284,-122.0072917/@37.2710772,-122.0107086,15.68z/data=!4m2!4m1!3e0?entry=ttu"><img src="https://tomverbeure.github.io/assets/fsd/west_valley_college_saratoga.png" alt="Map from West Valley College to Route 85 Canyon"></a>
<em>Click to open in Google Maps</em></p>

<p>FSD managed to turn right out of the parking lot just fine and get past the first traffic light.</p>

<p><a href="https://tomverbeure.github.io/assets/fsd/no_turn_on_right.jpg"><img src="https://tomverbeure.github.io/assets/fsd/no_turn_on_right.jpg" alt="Mistake four: streetview"></a></p>

<p>The second traffic light has a don’t-turn-on-red sign. The light was red, the Tesla came to a full stop, 
and then pressed on the gas to move on while the light was still red. (According to my colleague, police 
often lay in wait at this location to catch violators.)</p>

<p>By now I fully expected it to make that mistake, so I was ready to press the brake.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The way it currently behaves, FSD is a system that can’t be trusted to make the right decisions. It makes 
the most basic mistakes and it makes many of them.</p>

<p>Without FSD, you pay attention to the road and everything else is within your control. With FSD, you still 
need to pay attention but now there’s the additional cognitive load to monitor an unpredictable system over 
which you don’t have direct control. Forget about just being focused, you need to be hyper-focused, and you 
need to pay $99 per month or a one time fee of $12,000 for the privilege. With the limited functionality of autopilot, 
you hit the sweet spot: adaptive cruise control and lane centering work reliably, and you don’t need to 
worry about any other mischief.</p>

<p>Maybe one day I’ll be able to drive to Lake Tahoe by typing in the address, sit back, take a nap,
or play on my phone. Until then, it’s just a fancy technology demo with little practical value.</p>


  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Voyager 1 is back online! NASA spacecraft returns data from all 4 instruments (827 pts)]]></title>
            <link>https://www.space.com/voyager-1-fully-operational</link>
            <guid>40687660</guid>
            <pubDate>Sat, 15 Jun 2024 05:12:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.space.com/voyager-1-fully-operational">https://www.space.com/voyager-1-fully-operational</a>, See on <a href="https://news.ycombinator.com/item?id=40687660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-320-80.jpg" alt="artwork of voyager 1 spacecraft in black space background" srcset="https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/Aevg5Lf897c5wagmjmsp8Z.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: NASA)</span>
</figcaption>
</div>

<div id="article-body">
<p>All right, everyone —&nbsp;we can all breathe a sigh of relief. NASA's <a data-analytics-id="inline-link" href="https://www.space.com/17688-voyager-1.html" data-before-rewrite-localise="https://www.space.com/17688-voyager-1.html"><u>Voyager 1</u></a> spacecraft is fully operational once more, with all four science instruments returning usable data to Earth.</p><p>The problems began in November 2023, when Voyager 1 lost its ability to "speak" with us. More specifically, it started sending to <a data-analytics-id="inline-link" href="https://www.space.com/54-earth-history-composition-and-atmosphere.html" data-before-rewrite-localise="https://www.space.com/54-earth-history-composition-and-atmosphere.html"><u>Earth</u></a> unintelligible data instead of its normal 0s and 1s of binary code. Of course, Voyager 1 is 46 years old —&nbsp;ancient for a spacecraft —&nbsp;so it wasn't <em>entirely</em> a surprise that its health might be waning. And that's not to mention that it's in entirely uncharted interstellar territory, some 15 billion miles (24 billion kilometers) from Earth.&nbsp;</p><p>Voyager 1's dogged team was determined to not only figure out what went wrong, but also to fix the problem. And they've succeeded! Controllers identified where the issue was located: the flight data subsystem (FDS), used to "package" data to be sent to Earth. Further sleuthing revealed the exact chip causing the problem, which allowed them to find a workaround. After the team relocated the code to a new location in the FDS, Voyager 1 finally sent back intelligible data on April 20, 2024&nbsp;— but only from two of its four science instruments. Now, just two months later, Voyager 1's remaining two science instruments are back up and running, communicating effectively with mission control on Earth.</p><p>Even if Voyager 1 had gone dark for good, however, the mission would still have been a wild success. After it launched in 1977, its primary mission was to study <a data-analytics-id="inline-link" href="https://www.space.com/7-jupiter-largest-planet-solar-system.html" data-before-rewrite-localise="https://www.space.com/7-jupiter-largest-planet-solar-system.html"><u>Jupiter</u></a> and <a data-analytics-id="inline-link" href="https://www.space.com/48-saturn-the-solar-systems-major-ring-bearer.html" data-before-rewrite-localise="https://www.space.com/48-saturn-the-solar-systems-major-ring-bearer.html"><u>Saturn</u></a> —&nbsp;that was accomplished by 1980. (Its twin spacecraft, <a data-analytics-id="inline-link" href="https://www.space.com/voyager-2" data-before-rewrite-localise="https://www.space.com/voyager-2"><u>Voyager 2</u></a>, went on to study <a data-analytics-id="inline-link" href="https://www.space.com/45-uranus-seventh-planet-in-earths-solar-system-was-first-discovered-planet.html" data-before-rewrite-localise="https://www.space.com/45-uranus-seventh-planet-in-earths-solar-system-was-first-discovered-planet.html"><u>Uranus</u></a> and <a data-analytics-id="inline-link" href="https://www.space.com/41-neptune-the-other-blue-planet-in-our-solar-system.html" data-before-rewrite-localise="https://www.space.com/41-neptune-the-other-blue-planet-in-our-solar-system.html"><u>Neptune</u></a>.) But Voyager 1 is on an unstoppable path. Continuing its journey away from Earth, the spacecraft entered <a data-analytics-id="inline-link" href="https://www.space.com/interstellar-space-definition-explanation" data-before-rewrite-localise="https://www.space.com/interstellar-space-definition-explanation"><u>interstellar space</u></a> in 2012, returning crucial data about this mysterious realm.</p><p>Now that Voyager 1 is back online, the team will continue to "touch up" the spacecraft to get it back in top form, including resynchronizing its timekeeping software to execute commands at the right <a data-analytics-id="inline-link" href="https://www.space.com/time-how-it-works" data-before-rewrite-localise="https://www.space.com/time-how-it-works"><u>time</u></a>, as well as performing maintenance on the digital tape recorder that measures plasma waves. And hopefully, Voyager 1 will have a long, happy life ahead.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-zXjotydkMTeij63e2Mmbt7"><section><p>Sign up to our newsletter for the latest updates on rocket launches, skywatching events and more!</p></section></div>
</div>
<p><em><a href="https://forums.space.com/">Join our Space Forums</a> to keep talking space on the latest missions, night sky and more! And if you have a news tip, correction or comment, let us know at: <a href="mailto:community@space.com">community@space.com.</a></em></p>
<div id="slice-container-authorBio-zXjotydkMTeij63e2Mmbt7"><p>Space.com contributing writer Stefanie Waldek is a self-taught space nerd and aviation geek who is passionate about all things spaceflight and astronomy. With a background in travel and design journalism, as well as a Bachelor of Arts degree from New York University, she specializes in the budding space tourism industry and Earth-based astrotourism. In her free time, you can find her watching rocket launches or looking up at the stars, wondering what is out there. Learn more about her work at <a href="https://mailtrack.io/trace/link/841a96809cf8444a85db7a2b318410433580a8f6?url=https%3A%2F%2Fwww.stefaniewaldek.com&amp;userId=2756587&amp;signature=ba54abdc159873b3" target="_blank">www.stefaniewaldek.com</a>.</p></div>


</section>




<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Syzygy: An open standard for low cost, compact and high-performance peripherals (120 pts)]]></title>
            <link>https://syzygyfpga.io/</link>
            <guid>40686787</guid>
            <pubDate>Sat, 15 Jun 2024 01:31:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://syzygyfpga.io/">https://syzygyfpga.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40686787">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="inner_content-2-146"><div id="section-85-7"><div id="div_block-211-7"><h2 id="headline-88-7">Introducing SYZYGY</h2><div id="_rich_text-238-7"><p>An open standard for high-performance peripheral connectivity.&nbsp;</p><ul><li>Low cost, compact, high-performance<br>connectors</li><li>Pin count economizes available FPGA I/O</li><li>Low cost cable options</li><li>FREE to license</li></ul></div></div><p><img id="image-86-7" alt="" src="https://syzygyfpga.io/wp-content/uploads/2020/05/hero_illustration_PP-update-1.png" srcset="https://syzygyfpga.io/wp-content/uploads/2020/05/hero_illustration_PP-update-1.png 2000w, https://syzygyfpga.io/wp-content/uploads/2020/05/hero_illustration_PP-update-1-300x256.png 300w, https://syzygyfpga.io/wp-content/uploads/2020/05/hero_illustration_PP-update-1-1024x874.png 1024w, https://syzygyfpga.io/wp-content/uploads/2020/05/hero_illustration_PP-update-1-768x656.png 768w, https://syzygyfpga.io/wp-content/uploads/2020/05/hero_illustration_PP-update-1-1536x1312.png 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></p></div><section id="section-268-7"><p><h2 id="headline-269-7">Applications</h2></p></section><div id="section-244-7"><div id="div_block-246-7"><p><img id="image-250-7" alt="" src="https://syzygyfpga.io/wp-content/uploads/2020/04/High-performance-prototypes-orange.svg"></p><h3 id="headline-251-7">High Performance Prototypes</h3><p>Rapid prototyping with off-the-shelf single-purpose peripherals.</p></div><div id="div_block-253-7"><p><img id="image-254-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/systems-integration-orange.svg"></p><h3 id="headline-255-7">System Integration&nbsp;and Testing</h3><p>Build complex systems from smaller building blocks to iterate quickly and reduce cost. Create custom test systems for production functional testing.</p></div><div id="div_block-256-7"><p><img id="image-257-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/evaluation-systems-orange.svg"></p><h3 id="headline-258-7">Evaluation Systems</h3><p>SYZYGY is a perfect platform for your next high-performance semiconductor evaluation board.</p></div></div><section id="section-239-7"><p><h2 id="headline-242-7">TYPICAL PERIPHERALS</h2></p></section><div id="section-273-7"><div id="new_columns-274-7"><div id="div_block-275-7"><p><img id="image-279-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/ADC-DAC.svg"></p><p>Data Acquisition</p></div><div id="div_block-276-7"><p><img id="image-280-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Image-capture.svg"></p><p>Machine Vision</p></div><div id="div_block-277-7"><p><img id="image-281-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/digital-communications.svg"></p><p>Digital Communications</p></div><div id="div_block-278-7"><p><img id="image-282-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/SDR.svg"></p><p>Software- Defined Radio</p></div></div><div id="new_columns-310-7"><div id="div_block-311-7"><p><img id="image-313-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Video-input.svg"></p><p>Video Output</p></div><div id="div_block-315-7"><p><img id="image-317-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/SFP.svg"></p><p>Multi-Channel I/O</p></div><div id="div_block-319-7"><p><img id="image-321-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Sensor.svg"></p><p>Sensors</p></div><div id="div_block-323-7"><p><img id="image-325-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/robot.svg"></p><p>Robotics</p></div></div></div><section id="section-486-5"><p><h2 id="headline-347-7">Interface Comparison</h2></p></section><div id="section-342-7"><div id="new_columns-343-7"><div id="div_block-344-7"><p>SYZYGY fills the gap between low speed, low pin-count Digilent PMOD devices and high-performance, high pin-count VITA 57.1 FMC peripherals.</p><p>This chart shows SYZYGY, PMOD, and FMC standards as well as several model peripherals and where they fall on&nbsp;<br><b>throughput-per-pin</b> and <b>pin count</b> metrics.</p></div><p><img id="image-346-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Img-StandardsComparisonChart_01-1.png"></p></div><div id="div_block-366-7"><div id="code_block-439-49"><table>

<thead>

<tr>
<th rowspan="2">Interface</th>
<th colspan="2">Pin Count</th>
<th colspan="2">MHz / Pin</th>
</tr>

<tr>
<th>Min</th><th>Max</th><th>Min</th><th>Max</th>
</tr>

</thead>

<tbody>

<tr><td>PMOD</td><td>4</td><td>8</td><td>1</td><td>50</td></tr>

<tr><td>SYZYGY STD</td><td>10</td><td>32</td><td>50</td><td>500</td></tr>
<tr><td>SYZYGY XCVR</td><td>10</td><td>18</td><td>50</td><td>200</td></tr>
<tr><td>SYZYGY XCVR (gigabit pins)</td><td>4</td><td>8</td><td>500</td><td>5,000</td></tr>

<tr><td>FMC LPC</td><td>20</td><td>72</td><td>50</td><td>500</td></tr>
<tr><td>FMC LPC (gigabit pins)</td><td>2</td><td>4</td><td>500</td><td>5,000</td></tr>

<tr><td>FMC HPC</td><td>72</td><td>200</td><td>50</td><td>500</td></tr>
<tr><td>FMC HPC (gigabit pins)</td><td>10</td><td>40</td><td>500</td><td>5,000</td></tr>

</tbody>

</table></div><p>Note: Yes, all of these standards can go down to DC and some can go higher than we have here.&nbsp;This data&nbsp;basically&nbsp;illustrates&nbsp;what we consider to be the "sweet spot" for the interface. Your mileage may vary.<br></p></div></div><div id="section-370-7"><h2 id="headline-371-7">SYZYGY Interface connectors</h2><div id="new_columns-374-7"><div id="div_block-375-7"><h2 id="headline-378-7">Standard Peripheral</h2><p><img id="image-462-49" alt="" src="https://syzygyfpga.io/wp-content/uploads/2020/04/Standard-peripheral-1.png"></p><p>40-pin 0.8mm Samtec connector</p><p>+5v, +3.3v fixed voltages</p><p>Programmable I/O voltage (Smart VIO)</p><p>28 single-ended signals&nbsp;(incl. 8 differential pairs)</p><p><img id="image-436-7" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Standard-Peripheral-2.png"></p><p>Clock<br></p><p>MCU for Smart VIO and data</p></div><div id="div_block-376-7"><h2 id="headline-397-7">Transceiver Peripheral</h2><p><img id="image-472-49" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Transceiver-Peripheral-1.png"></p><p>60-pin 0.5mm Samtec connector</p><p>+5v, +3.3v fixed voltages</p><p>Programmable I/O voltage (Smart VIO)</p><p>16 single-ended signals</p><p><img id="image-476-49" alt="" src="http://syzygyfpga.io/wp-content/uploads/2020/04/Transceiver-Peripheral-2.png"></p><p>2 Tx and 2 Rx lanes Gigabit serial I/O<br></p><p>Transceiver reference clock</p><p>MCU for Smart VIO and data</p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making my local LLM voice assistant faster and more scalable with RAG (107 pts)]]></title>
            <link>https://johnthenerd.com/blog/faster-local-llm-assistant/</link>
            <guid>40686396</guid>
            <pubDate>Sat, 15 Jun 2024 00:12:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://johnthenerd.com/blog/faster-local-llm-assistant/">https://johnthenerd.com/blog/faster-local-llm-assistant/</a>, See on <a href="https://news.ycombinator.com/item?id=40686396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>If you read <a href="https://johnthenerd.com/blog/local-llm-assistant">my previous blog post</a>, you probably already know that I like my smart home open-source and very local, and that certainly includes any voice assistant I may have. If you watched the video demo, you have probably also found out that it’s… slow. Trust me, I did too.</p><p>Prefix caching helps, but it feels like cheating. Sure, it’ll look amazing in a demo, but as soon as I start using my LLM for other things (which I do, quite often), that cache is going to get evicted and that first prompt is still going to be slow.</p><p>I started with the easy and expensive way. After some more calculations in front of my breaker, I decided that if I use a specific outlet in the kitchen and set a low power limit (260W), I can safely run dual RTX 3090’s. It got me some really angry looks from my financial advisor, the ability to offload Whisper to GPU, and <a href="https://huggingface.co/casperhansen/llama-3-70b-instruct-awq">Llama 3 70B AWQ</a> (which is amazing), but it’s still just not fast enough:</p><video width="100%" height="50%" controls="">
<source src="https://johnthenerd.com/videos/ha-assist-without-rag.webm" type="video/webm">Your browser does not support the video tag.</video><p>It would sure be nice to have something much smarter and faster. Say, like this?</p><video width="50%" height="50%" controls="">
<source src="https://johnthenerd.com/videos/ha-assist-rag-example.mp4" type="video/mp4">Your browser does not support the video tag.</video><p>Let’s think about a smarter solution. To do so, let’s learn more about how a language model works in the first place! NVIDIA has some <a href="https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/">amazing documentation</a> about LLM inference that was incredibly helpful.</p><p>Language models have two phases. These are called “prefill” and “decode”. When you send a prompt to a language model, you can see both of these in action. Prefill happens before you see the <em>first</em> token, and decode happens for <em>every other token</em> that is output. Decode is relatively stable and the overall “slowness” caused by decode is merely linear based on how much the LLM output. Streaming to HomeAssistant would really help reduce perceived slowdown by decode, but I couldn’t really figure out the HomeAssistant codebase.</p><p>Let’s focus on prefill for now, as I have discovered that it was taking a majority of the inference time. If you use language models often, you may have noticed that prefill scales really badly for very long contexts. This is because prefill latency increases <em>quadratically</em> based on the context length. <a href="https://arxiv.org/abs/2405.08944">Here is an interesting paper</a> that explains all the challenges of having very large context sizes. Since we are passing the entire smart home state to the LLM, prefill times are quite bad. Furthermore, Llama 3 has an 8k context size, and I was already at 60% before I even thought of adding weather information! Based on my previous experiences, the worst part of CPU inference with llama.cpp is always prefill, so I can only imagine how bad this would be without GPUs.</p><p>Needless to say, we need to do something about that massive prompt. We certainly need the smart home information for the LLM to know… about our smart home. But do we really need <em>all of it</em>? When’s the last time you asked your voice assistant to summarize your entire house, or take action on every single device across multiple rooms?</p><p>Let’s talk about RAG. <a href="https://arxiv.org/abs/2312.10997">RAG (Retrieval Augmented Generation)</a> is a method commonly used to augment LLM prompts with external sources. The key part of RAG is called “embeddings”. Without getting too deep into the math, embedding models take in a text input and project it onto a high-dimensional space. The idea is that sentences that are semantically closer will be closer to each other in this grid. This allows one to just compute the cosine similarity between the embedding of the user prompt and the embedding of each document to search through a massive knowledge base. This lets them find the articles that are most relevant for what the user just asked, augmenting the entire LLM prompt with the article, which in turn improves the quality of the responses given by the LLM.</p><p>What if we utilized this exact technique to figure out what parts of our massive prompt the LLM is going to need to answer the query? This will significantly reduce the context length, and maybe solve my speed problem! It would also make this system far more scalable, as I can now add more and more things without worrying about hitting the context limit. To do so, I first built a <a href="https://github.com/JohnTheNerd/homeassistant-llm-prompt-generator">RAG API</a> that splits that massive prompt into a bunch of tiny sections. Then I added a few nice to have’s like the weather forecast and calendar (I plan on adding e-mails, but that’s a bit more work as I will need another layer of RAG). Afterwards, I just threw <a href="https://www.ollama.com/">ollama</a> and <a href="https://www.ollama.com/library/mxbai-embed-large">mxbai-embed-large</a> on one of my servers, put the <a href="https://docs.litellm.ai/docs/simple_proxy">LiteLLM proxy server</a> in front of it, and configured the API to work with it all. I also updated <a href="https://github.com/JohnTheNerd/extended_openai_conversation">my fork of extended_openai_conversation</a> to be able to use the new RAG API.</p><p>The way the API works is, it simply takes data that is unlikely to change frequently (say, all device names in an area, all entity names associated with them, but not the actual entity states), and caches all embeddings for it in RAM. For some things that don’t necessarily have have a context-relevant title (such as the weather), it will simply calculate embeddings for a hardcoded title. It periodically updates these embeddings in the background. Whenever the user prompt comes in, because we have all the embeddings pre-computed in RAM, we can simply create embeddings for just the user prompt and compute the similarity. We take the top 3 “documents”, at which point we get the actual device states. Finally, we augment that into the LLM prompt and end up with something that is still meaningful for the LLM while being significantly shorter! I also dynamically generate examples for in-context learning, where necessary, especially in places I found that LLMs tend to mistake service names. Since these examples are dynamically generated from the current smart home state, they are generally quite useful for the LLM.</p><p>After some experimentation, I came up with these categories:</p><ul><li><p>All calendar events for the next week. The title is also the entire calendar as we would like to be able to match on events.</p></li><li><p>The weather forecast for the next week. The title is a hardcoded message.</p></li><li><p>One category per area defined in HomeAssistant. The title is a list of all entities (name and ID, but not state) attached to all devices in that area.</p></li><li><p>One category for the shopping list. The title is the entire shopping list.</p></li><li><p>One category for whether anyone else is home. The title is a hardcoded message.</p></li><li><p>One category for all media players and what they are playing. The title is the list of media players without what they are playing.</p></li><li><p>Two other categories for laundry and color loop, which are very custom to my HomeAssistant setup (and hence are disabled in the sample configuration).</p></li></ul><p>And, well, see the results for yourself!</p><p>Before:</p><video width="100%" height="50%" controls="">
<source src="https://johnthenerd.com/videos/ha-assist-without-rag.webm" type="video/webm">Your browser does not support the video tag.</video><p>After:</p><video width="100%" height="50%" controls="">
<source src="https://johnthenerd.com/videos/ha-assist-with-rag.webm" type="video/webm">Your browser does not support the video tag.</video><p>Of course, if we’re dealing with very long prompts and responses, even after this optimization, it’s going to feel very slow. But I think that’s sometimes worth it:</p><video width="50%" height="50%" controls="">
<source src="https://johnthenerd.com/videos/ha-assist-rag-complex-example.mp4" type="video/mp4">Your browser does not support the video tag.</video></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snowden: "They've gone full mask-off: do not ever trust OpenAI or its products" (231 pts)]]></title>
            <link>https://twitter.com/Snowden/status/1801610725229498403</link>
            <guid>40685644</guid>
            <pubDate>Fri, 14 Jun 2024 22:13:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Snowden/status/1801610725229498403">https://twitter.com/Snowden/status/1801610725229498403</a>, See on <a href="https://news.ycombinator.com/item?id=40685644">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Spaced repetition for teaching two-year olds how to read (112 pts)]]></title>
            <link>https://chrislakin.blog/p/spaced-repetition-for-teaching-two</link>
            <guid>40685254</guid>
            <pubDate>Fri, 14 Jun 2024 21:20:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrislakin.blog/p/spaced-repetition-for-teaching-two">https://chrislakin.blog/p/spaced-repetition-for-teaching-two</a>, See on <a href="https://news.ycombinator.com/item?id=40685254">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong>This father has been using spaced repetition (Anki) to teach his children how to read several years earlier than average.</strong></p><p><a href="https://twitter.com/michael_nielsen/status/1587084229946400769" rel="">Michael Nielsen</a><span> and </span><a href="https://twitter.com/gwern/status/1586386061395374080" rel="">Gwern</a><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-138604537" href="https://chrislakin.blog/p/spaced-repetition-for-teaching-two#footnote-1-138604537" target="_self" rel="">1</a></span><span> tweeted about the interesting case of a reddit user, u/caffeine314 (henceforth dubbed “CoffeePie”), who has been using spaced repetition with his daughter from a very young age.</span></p><p>CoffeePie started using Anki with his daughter when she turned 2, and he continued using Anki with his son starting when he was 1 year 9 months. Here's his daughter’s progress as recounted in January 2020:</p><blockquote><p><span>My daughter is now about to </span><strong>turn 5 in a few days</strong><span>… She's still going strong -- she uses Anki every single day for English, Hebrew, and Spanish. She's very confident about reading, and moreover, she reads with ... "context". Many kids her age read mechanically, but </span><strong>she reads like a real storyteller</strong><span>, and that comes from her confidence. At the beginning of the school year her teachers said </span><strong>she definitely has the reading ability of fifth grade</strong><span>, and if we're just going by the ability to read and not focus on comprehension of abstract ideas, her reading level may rival an 8th grader.</span></p></blockquote><p><span>(From </span><a href="https://www.reddit.com/r/Anki/comments/eisra4/update_on_my_daughter_and_anki/" rel="">Update on my daughter and Anki</a><span>)</span></p><p><span>For reference, fifth graders are usually 10 or 11yo in the US, and 8th graders are usually 13 or 14yo, so this puts her </span><strong>~5–9 years ahead of the average child</strong><span>. </span></p><p>You can see a video of his daughter reading at 2 years, 2 months later in this post.</p><p>CoffeePie has made several posts about their experience but I still had questions so I reached out to interview him back in January. </p><p><em>Responses have been edited for clarity</em><span>.</span></p><p><strong>What did you learn in going from using Anki on your daughter to your son? How has it gone with your son?</strong></p><p>It's a hard question, because I got so much right. We were so wildly successful that I "cloned" just about every aspect with my son.</p><p>A couple of things I can think of:</p><ul><li><p>With my daughter, I held back on lowercase letters for a long time because I thought it would confuse her, but when I started to introduce lowercase to her, to my extreme shock, she already knew them, down cold!</p><ul><li><p>I think what happened is that she learned them just by looking at books, TV, magazines, storefront signs, menus, etc.</p></li><li><p>So when we started with my son, I started doing lower case letters the very day after we finished capital letters.</p></li></ul></li><li><p>Another difference is that we did numbers the very next day after lowercase letters.</p><ul><li><p>I really, really thought I was pushing too hard; I had no desire to be a "tiger dad", but he took it with extreme grace. I was ready to stop at any moment, but he was fine.</p></li></ul></li><li><p>Another difference is that our expectations of what the kids were getting out of it had changed, as well. At first, I just really wanted my daughter to get a jump start on reading, but stupid me, I didn't realize there were unintended consequences. A four year old with a 3rd grade reading ability learns about a WHOLE lot more -- it opened up politics for her. She would read our junk mail, and learn who our council member was, who our representative is, the mayor, current events, history, etc. I know it's stupid of me to say, but I underestimated the effect that reading early would have on her breadth of learning.</p></li><li><p>One last thing is math. I mentioned that we started numbers early with my son. But we also started arithmetic. He wasn't reading by 3 the way Hannah was, but he knew all his multiplication tables up to 12 by 12. This year we tackled prime factorization, Fibonacci sequences, decimal and place values, mixed, proper, and improper fractions, light algebra, etc. I was much more aggressive with the math, and again, he handled it with grace. I was ready to stop at any moment.</p></li></ul><p><strong>Do you still use Anki with your daughter now as she's gotten older?</strong></p><p>We pretty much stopped Anki with my daughter. She hasn't been tested lately, but I'd say her mechanical reading is high school level, easily. Her understanding / comprehension is still advanced, but more aligned with her age. That's not something Anki can help with, easily. Between school and her extracurricular activities, I didn't want to steal more time from her, so we stopped Anki on weekdays. We still do Anki -- Hebrew only -- on non-school nights (weekends and holidays). I felt we were being unfair since she's now in 2nd grade, and is spending significant time on homework and stuff. I wanted her to be a kid.</p><p><strong>To clarify- did you stop using Anki with your daughter in large part because you ran out of topics beyond reading/language/math?</strong></p><p>I think that's what it amounted to with Hannah. Mechanically, she reads at high school graduate level. But her reading comprehension is more age-appropriate. She's been tested by the BOE, and her reading comprehension in Kindergarten was 4th grade.&nbsp;</p><p>I don't think there's much that Anki can do for reading comprehension. She's missing the type of knowledge that comes with experience. Occasionally we'll come across something that shockingly reminds me she's still 7 -- like not knowing what giving someone a cold shoulder is. She's such a good reader, it's ... a jolt when we come across stuff like that. I think Anki reading ran its course with her.</p><p>As for math, she could be better at the times tables. Still knows them better than anyone in her class. But here, again, she needs the kind of info that Anki just can't test, like thinking about 87-8 as being the same problem as 80-1. Oddly enough, a long page of problems is probably more conducive to that sort of thing.</p><p><strong><span>I'm curious if you've seen </span><a href="https://larrysanger.org/2010/12/baby-reading/" rel="">the experience of Larry Sanger (cofounder of Wikipedia)</a><span> in teaching his kids to read early. What do you think of that?</span></strong></p><p><span>I never heard of Larry Sanger, but that is </span><em>precisely</em><span> our experience, to a T! Here's Hannah reading Rollie Pollie Ollie at 2 years, 2 months:&nbsp;</span></p><p><strong>Do you think using Anki ever felt coercive to either of your children?</strong></p><p>Hannah went through a phase where she didn't want to do it. We tried to compromise and work through it. Eventually, it became part of her "job" -- we told her that every human has a job, and her job was to do Anki. Other than that, we never had to coerce any of the kids.</p><p><strong>Do you have any other interesting or unusual plans for educating your daughter in the next few years?</strong></p><p>Interesting question. I feel like a bad parent writing "no", but being such an early reader gave her access to advanced learning at an earlier age. She has such an advantage compared to her classmates, I think I'm going to let her be for awhile. She's a curious person, and she has the tools to follow her own interests, and I trust her. We did start some high school algebra -- I've been showing her the properties of algebras: commutativity, associativity, identity, distributivity, etc. We've been looking at symmetries -- mirror, reflexive, rotational. Highfalutin math topics that don't really require hardcore calculations. But it's always in the context of "hey, I have something interesting I want to show you" rather than "please sit down and work on these problems".</p><p>Actually, if YOU have any suggestions for interesting education opportunities, I'm all ears!</p><p>A few hours after posting this, CoffeePie sent me this video he found of his wife practicing Anki with his son. His son was 2 years 6 months old at the time. The video is very cute.</p><div id="youtube2-8U-Lza__Kko" data-attrs="{&quot;videoId&quot;:&quot;8U-Lza__Kko&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/8U-Lza__Kko?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>That’s everything I’ve asked CoffeePie so far. If you have anything you want me to ask him, or any suggestions of things he could try with his children (who are currently aged ~5 and ~8), let me know and I’ll tell him!</p><p>One confounder here is that CoffeePie used to be a physics professor, so some of this effect is likely genetic. </p><p><span>CoffeePie also runs a tutoring business, </span><a href="https://brooklyntutoring.net/" rel="">Brooklyn Tutoring and Test Prep</a><span>.</span></p><p><strong>I will be posting more about parenting soon:</strong></p><p><em><span>Thanks to </span></em></p><p><em><span> (</span><a href="https://twitter.com/Prigoose" rel="">@Prigoose</a><span>) for turning the draft into a final post after I sat on it for far too long! </span></em></p><ul><li><p><span>See this post on </span><a href="https://twitter.com/Prigoose/status/1728829018026475766" rel="">Twitter</a></p></li><li><p><span>See this post on </span><a href="https://news.ycombinator.com/item?id=38427034" rel="">Hacker News</a><span> (Derek Sivers responded!)</span></p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Exponentially Better Rotations (263 pts)]]></title>
            <link>http://thenumb.at/Exponential-Rotations/</link>
            <guid>40684901</guid>
            <pubDate>Fri, 14 Jun 2024 20:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://thenumb.at/Exponential-Rotations/">http://thenumb.at/Exponential-Rotations/</a>, See on <a href="https://news.ycombinator.com/item?id=40684901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>If you’ve done any 3D programming, you’ve likely encountered the zoo of techniques and representations used when working with 3D rotations. Some of them are better than others, depending on the situation.</p>

<p><em>Based on <a href="http://15462.courses.cs.cmu.edu/">CMU 15-462</a> course materials by <a href="https://www.cs.cmu.edu/~kmcrane/">Keenan Crane</a>.</em></p>

<ul>
  <li><a href="#representations">Representations</a>
    <ul>
      <li><a href="#rotation-matrices">Rotation Matrices</a></li>
      <li><a href="#euler-angles">Euler Angles</a></li>
      <li><a href="#quaternions">Quaternions</a></li>
      <li><a href="#axisangle-rotations">Axis/Angle</a></li>
    </ul>
  </li>
  <li><a href="#the-exponential-and-logarithmic-maps">The Exponential and Logarithmic Maps</a>
    <ul>
      <li><a href="#axisangle-in-2d">Axis/Angle in 2D</a></li>
      <li><a href="#axisangle-in-3d">Axis/Angle in 3D</a></li>
      <li><a href="#averaging-rotations">Averaging Rotations</a></li>
      <li><a href="#quaternions-again">Quaternions (Again)</a></li>
    </ul>
  </li>
  <li><a href="#further-reading">Further Reading</a></li>
</ul>

<h2 id="representations">Representations</h2>

<h2 id="rotation-matrices">Rotation Matrices</h2>

<p>Linear-algebra-wise, the most straightforward representation is an orthonormal 3x3 matrix (with positive determinant). The three columns of a rotation matrix specify where the x, y, and z axes end up after the rotation.</p>

<p>Rotation matrices are particularly useful for transforming points: just multiply! Even better, rotation matrices can be composed with any other linear transformations via matrix multiplication. That’s why we use rotation matrices when actually drawing things on screen: only one matrix multiplication is required to transform a point from world-space to the screen. However, rotation matrices are not so useful for actually working with <em>rotations</em>: because they don’t form a vector space, adding together two rotation matrices will not give you a rotation matrix back. For example, animating an object by linearly interpolating between two rotation matrices adds scaling:</p>





<table><tbody><tr>
<td>$$ R_0 = \begin{bmatrix}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{bmatrix} $$</td>
<td id="matrix_interp_mj">$$ R(0.00) = \begin{bmatrix}\phantom{-}1.00&amp;\phantom{-}0.00&amp;\phantom{-}0.00\\\phantom{-}0.00&amp;\phantom{-}1.00&amp;\phantom{-}0.00\\\phantom{-}0.00&amp;\phantom{-}0.00&amp;\phantom{-}1.00\end{bmatrix} $$</td>
<td id="matrix_interp_m1">$$ R_1 = \begin{bmatrix}-1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;-1\end{bmatrix} $$</td>
</tr></tbody></table>

<h2 id="euler-angles">Euler Angles</h2>

<p>Another common representation is Euler angles, which specify three separate rotations about the x, y, and z axes (also known as pitch, yaw, and roll). The order in which the three component rotations are applied is an arbitrary convention—here we’ll apply x, then y, then z.</p>

<canvas id="euler"></canvas>
<table>
<tbody><tr><td>$$\theta_x$$</td><td></td></tr>
<tr><td>$$\theta_y$$</td><td></td><td></td></tr>
<tr><td>$$\theta_z$$</td><td></td></tr>
</tbody></table>

<p>Euler angles are generally well-understood and often used for authoring rotations. However, using them for anything else comes with some significant pitfalls. While it’s possible to manually create splines that nicely interpolate Euler angles, straightforward interpolation often produces undesirable results.</p>

<p>Euler angles suffer from <em>gimbal lock</em> when one component causes the other two axes of rotation to become parallel. Such configurations are called <em>singularities</em>. At a singularity, changing either of two ‘locked’ angles will cause the same output rotation. You can demonstrate this phenomenon above by pressing the ‘lock’ button and adjusting the x/z rotations (a quarter rotation about y aligns the z axis with the x axis).</p>

<p>Singularities break interpolation: if the desired path reaches a singularity, it gains a degree of freedom with which to represent its current position. Picking an arbitrary representation to continue with causes discontinuities in the interpolated output: even within an axis, interpolation won’t produce a constant angular velocity. That can be a problem if, for example, you’re using the output to drive a robot. Furthermore, since each component angle is cyclic, linear interpolation won’t always choose the shortest path between rotations.</p>

<canvas id="euler_interp"></canvas>


<table><tbody><tr>
<td>$$ \mathbf{\theta}_0 = \begin{bmatrix}0\\0\\0\end{bmatrix} $$</td>
<td id="euler_interp_mj">$$ \mathbf{\theta}(0.00) = \begin{bmatrix}\phantom{-}0.00\\\phantom{-}0.00\\\phantom{-}0.00\end{bmatrix} $$</td>
<td id="euler_interp_m1">$$ \mathbf{\theta}_1 = \begin{bmatrix}-3.14\\0.00\\-3.14\end{bmatrix} $$</td>
</tr></tbody></table>

<p>Thankfully, interpolation is smooth if the path doesn’t go through a singularity, so these limitations <em>can</em> be worked around, especially if you don’t need to represent ‘straight up’ and ‘straight down.’</p>

<h2 id="quaternions">Quaternions</h2>

<p>At this point, you might be expecting yet another article on quaternions—don’t worry, we’re not going to delve into hyper-complex numbers today. It suffices to say that unit quaternions are the standard tool for composing and interpolating rotations, since <a href="https://en.wikipedia.org/wiki/Slerp">spherical linear interpolation</a> (slerp) chooses a constant-velocity shortest path between any two quaternions. However, unit quaternions also don’t form a vector space, are unintuitive to author, and can be computationally costly to interpolate<a href="http://number-none.com/product/Hacking%20Quaternions/">*</a>. Further, there’s no intuitive notion of scalar multiplication, nor averaging.</p>

<p>But, they’re still fascinating! If you’d like to understand quaternions more deeply (or, perhaps, learn what they are in the first place), read <a href="https://eater.net/quaternions">this</a>.</p>

<canvas id="quat_interp"></canvas>


<table><tbody><tr>
<td>$$ Q_0 = \begin{bmatrix}1\\0\\0\\0\end{bmatrix}\ \ $$</td>
<td id="quat_interp_mj">$$ Q(0.00) = \begin{bmatrix}\phantom{-}1.00\\\phantom{-}0.00\\\phantom{-}0.00\\\phantom{-}0.00\end{bmatrix}\ \ $$</td>
<td id="quat_interp_m1">$$ Q_1 = \begin{bmatrix}0\\0\\1\\0\end{bmatrix} $$</td>
</tr></tbody></table>

<p>Note that since quaternions double-cover the space of rotations, sometimes \(Q(1)\) will go to \(-Q_1\).</p>

<h2 id="axisangle-rotations">Axis/Angle Rotations</h2>

<p>An axis/angle rotation is a 3D vector of real numbers. Its direction specifies the axis of rotation, and its magnitude specifies the angle to rotate about that axis. For convenience, we’ll write axis/angle rotations as \(\theta\mathbf{u}\), where \(\mathbf{u}\) is a unit-length vector and \(\theta\) is the rotation angle.</p>

<canvas id="axis_angle"></canvas>

<table>
<tbody><tr><td>$$\mathbf{u}_x$$</td><td></td></tr>
<tr><td>$$\mathbf{u}_y$$</td><td></td></tr>
<tr><td>$$\mathbf{u}_z$$</td><td></td></tr>
<tr><td>$$\theta$$</td><td></td></tr>
</tbody></table>

<p>Since axis/angle rotations are simply 3D vectors, they form a vector space: we can add, scale, and interpolate them to our heart’s content. Linearly interpolating between any two axis/angle rotations is smooth and imparts constant angular velocity. However, note that linearly interpolating between axis-angle rotations does not necessarily choose the shortest path: it depends on which axis/angle you use to specify the target rotation.</p>

<canvas id="axis_angle_interp"></canvas>


<table><tbody><tr>
<td>$$ \theta_0\mathbf{u}_0 = \begin{bmatrix}0\\0\\0\end{bmatrix}\ \ $$</td>
<td id="axis_angle_interp_mj">$$ \theta\mathbf{u}(0.00) = \begin{bmatrix}\phantom{-}0.00\\\phantom{-}0.00\\\phantom{-}0.00\end{bmatrix}\ \ $$</td>
<td id="axis_angle_interp_m1">$$ \theta_1\mathbf{u}_1 = \begin{bmatrix}0\\3.14\\0\end{bmatrix} $$</td>
</tr></tbody></table>

<p>Like quaternions, axis/angle vectors double-cover the space of rotations: sometimes \(\theta\mathbf{u}(1)\) will go to \((2\pi - \theta_1)(-\mathbf{u}_1)\).</p>

<h2 id="the-exponential-and-logarithmic-maps">The Exponential and Logarithmic Maps</h2>

<p>Ideally, we could freely convert rotations between these diverse representations based on our use case. We will always want to get a rotation matrix out at the end, so we’ll consider matrices the ‘canonical’ form. Enter the <strong>exponential map</strong>: a function that takes a different kind of rotation object and gives us back an equivalent rotation matrix. The corresponding <strong>logarithmic map</strong> takes a rotation matrix and gives us back a rotation object. How these maps relate to the scalar <code>exp</code> and <code>log</code> functions will hopefully become clear later on.</p>

<p><img src="http://thenumb.at/assets/exp-rotations/map.png"></p>

<p>Below, we’ll define an <code>exp</code> and <code>log</code> map translating between rotation matrices and axis/angle vectors. But first, to build up intuition, let us consider how rotations work in two dimensions.</p>

<h2 id="axisangle-in-2d">Axis/Angle in 2D</h2>

<p>In 2D, there’s only one axis to rotate around: the one pointing out of the plane. Hence, our ‘axis/angle’ rotations can be represented by just \(\theta\).</p>

<p>Given a 2D point \(\mathbf{p}\), how can we rotate \(\mathbf{p}\) by \(\theta\)? One way to visualize the transformation is by forming a coordinate frame in which the output is easy to describe. Consider \(\mathbf{p}\) and its quarter (\(90^\circ\)) rotation \(\mathcal{J}\mathbf{p}\):</p>

<p><img src="http://thenumb.at/assets/exp-rotations/2d_rot.svg"></p>

<p>Using a bit of trigonometry, we can describe the rotated \(\mathbf{p}_\theta\) in two components:</p><p>

\[\begin{align*} \mathbf{p}_\theta &amp;= \mathbf{p}\cos\theta + \mathcal{J}\mathbf{p}\sin\theta \\
 &amp;= (\cos(\theta)\mathcal{I} + \sin(\theta)\mathcal{J})\mathbf{p} \end{align*}\]

</p><p>But, what actually are \(\mathcal{I}\) and \(\mathcal{J}\)? The former should take a 2D vector and return it unchanged: it’s the 2x2 identity matrix. The latter should be similar, but swap and negate the two components:</p><p>

\[\begin{align*} \mathcal{I} &amp;= \begin{bmatrix}1&amp;0\\0&amp;1\end{bmatrix} \\ \mathcal{J} &amp;= \begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix} \end{align*}\]

</p><p>Just to make sure we got \(\mathcal{J}\) right, let’s check what happens if we apply it twice (via \(\mathcal{J}^2\)):</p><p>

\[\mathcal{J}^2 = \begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix}\begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix} = \begin{bmatrix}-1&amp;0\\0&amp;-1\end{bmatrix}\]

</p><p>We got \(\mathcal{J}^2 = -\mathcal{I}\), which is a 180-degree rotation. So, \(\mathcal{J}\) indeed represents 90-degree rotation.</p>

<p>Now, what does our transform look like?</p><p>

\[\begin{align*}
\mathbf{p}_\theta &amp;= (\cos(\theta)\mathcal{I} + \sin(\theta)\mathcal{J})\mathbf{p} \\
                  &amp;= \left(\cos(\theta)\begin{bmatrix}1&amp;0\\0&amp;1\end{bmatrix} + \sin(\theta)\begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix}\right)\mathbf{p} \\
                  &amp;= \begin{bmatrix}\cos\theta&amp;-\sin\theta\\\sin\theta&amp;\cos\theta\end{bmatrix}\mathbf{p}
\end{align*}\]

</p><p>That’s the standard 2D rotation matrix. What a coincidence!</p>

<h3 id="complex-rotations">Complex Rotations</h3>

<p>If you’re familiar with complex numbers, you might notice that our first transform formula feels eerily similar to Euler’s formula, \(e^{ix} = \cos x + i\sin x\):</p><p>

\[\begin{align*}
\mathbf{p}_\theta &amp;= (\cos(\theta)\mathcal{I} + \sin(\theta)\mathcal{J})\mathbf{p} \\
e^{i\theta}p &amp;= (\cos(\theta) + i\sin(\theta))p
\end{align*}\]

</p><p><img src="http://thenumb.at/assets/exp-rotations/expi.svg"></p>

<p>Where \(i\) and \(\mathcal{J}\) both play the role of a quarter turn. We can see that in complex arithmetic, multiplying by \(i\) in fact has that effect:</p><p>

\[\mathcal{J}\mathbf{p} = \begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix}\begin{bmatrix}a\\b\end{bmatrix} = \begin{bmatrix}-b\\a\end{bmatrix}\]

\[ip = i(a + bi) = ai + bi^2 = -b + ai\]

</p><p>So, there must be some connection to the exponential function here.</p>

<h3 id="the-2d-exponential-map">The 2D Exponential Map</h3>

<p>Recall the definition of the exponential function (or equivalently, its Taylor series):</p><p>

\[e^x = \sum_{k=0}^\infty \frac{x^k}{k!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \dots\]

</p><p>Using Euler’s formula, \(e^{i\theta}\) gave us a complex number representing a 2D rotation by \(\theta\). Can we do the same with \(e^{\theta\mathcal{J}}\)? If we plug a matrix into the above definition, the arithmetic still works out: 2x2 matrices certainly support multiplication, addition, and scaling. (More on matrix exponentiation <a href="https://www.youtube.com/watch?v=O85OWBJ2ayo">here</a>.)</p>

<p>Let \(\theta\mathcal{J} = A\) and plug it in:</p><p>

\[e^A = \sum_{k=0}^\infty \frac{A^k}{k!} = \mathcal{I} + A + \frac{A^2}{2!} + \frac{A^3}{3!} + \dots\]

</p><p>Let’s pull out the first four terms to inspect further:</p><p>

\[\begin{align*}
e^A &amp;= \mathcal{I} + A + \frac{1}{2!}A^2 + \frac{1}{3!}A^3 \\
    &amp;= \mathcal{I} + A\left(\mathcal{I} + \frac{1}{2}A\left(\mathcal{I} + \frac{1}{3}A\right)\right) \\
    &amp;= \mathcal{I} + A\left(\mathcal{I} + \frac{1}{2}A\begin{bmatrix}1&amp;\frac{-\theta}{3}\\\frac{\theta}{3}&amp;1\end{bmatrix}\right) \\
    &amp;= \mathcal{I} + A\begin{bmatrix}1-\frac{\theta^2}{6}&amp;\frac{-\theta}{2}\\\frac{\theta}{2}&amp;1-\frac{\theta^2}{6}\end{bmatrix} \\
    &amp;= \begin{bmatrix}1-\frac{\theta^2}{2}&amp;-\theta+\frac{\theta^3}{6}\\\theta-\frac{\theta^3}{6}&amp;1-\frac{\theta^2}{2}\end{bmatrix}
\end{align*}\]

</p><p>These entries look familiar. Recall the Taylor series that describe the functions \(\sin\) and \(\cos\):</p><p>

\[\begin{align*} \sin x &amp;= x - \frac{x^3}{3!} + \frac{x^5}{5!} - \dots  \\
\cos x &amp;= 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \dots \end{align*}\]

</p><p>If we write out all the terms of \(e^A\), we’ll recover the expansions of \(\sin\theta\) and \(\cos\theta\)! Therefore:</p><p>

\[e^A = e^{\theta\mathcal{J}} = \begin{bmatrix}\cos\theta&amp;-\sin\theta\\\sin\theta&amp;\cos\theta\end{bmatrix}\]

</p><p>We’ve determined that the exponential function \(e^{\theta\mathcal{J}}\) converts our angle \(\theta\) into a corresponding 2D rotation matrix. In fact, we’ve proved a version of Euler’s formula with 2x2 matrices instead of complex numbers:</p><p>

\[\begin{align*} &amp;&amp; e^{\theta\mathcal{J}} &amp;= (\cos(\theta)\mathcal{I} + \sin(\theta)\mathcal{J})\\
    &amp;\implies&amp; \mathbf{p}_\theta &amp;= e^{\theta\mathcal{J}}\mathbf{p}
\end{align*}\]

</p><h3 id="the-2d-logarithmic-map">The 2D Logarithmic Map</h3>

<p>The logarithmic map should naturally be the inverse of the exponential:</p><p>

\[R = \exp(\theta\mathcal{J}) \implies \log(R) = \theta\mathcal{J}\]

</p><p>So, given \(R\), how can we recover \(\theta\mathcal{J}\)?</p><p>

\[\begin{align*}
&amp;&amp; R &amp;= \begin{bmatrix}\cos\theta&amp;-\sin\theta\\\sin\theta&amp;\cos\theta\end{bmatrix}\\
&amp;\implies&amp; \theta &amp;= \text{atan2}(R_{21},R_{11})\\
&amp;\implies&amp; \log(R) &amp;= \begin{bmatrix}0&amp;-\theta\\\theta&amp;0\end{bmatrix}
\end{align*}\]

</p><p>Note that in general, our exponential map is not injective. Clearly, \(\exp(\theta\mathcal{J}) = \exp((\theta + 2\pi)\mathcal{J})\), since adding an extra full turn will always give us back the same rotation matrix. Therefore, our logarithmic map can’t be surjective—we’ll define it as returning the <em>smallest</em> angle \(\theta\mathcal{J}\) corresponding to the given rotation matrix. Using \(\text{atan2}\) implements this definition.</p>

<h3 id="interpolation">Interpolation</h3>

<p>Consider two 2D rotation angles \(\theta_0\) and \(\theta_1\). The most obvious way to interpolate between these two rotations is to interpolate the angles and create the corresponding rotation matrix. This scheme is essentially a 2D version of axis-angle interpolation.</p><p>

\[\begin{align*} \theta(t) &amp;= (1-t)\theta_0 + t\theta_1\\
R_\theta(t) &amp;= \begin{bmatrix}\cos(\theta(t))&amp;-\sin(\theta(t))\\\sin(\theta(t))&amp;\cos(\theta(t))\end{bmatrix}
\end{align*}\]

</p><p>However, if \(\theta_0\) and \(\theta_1\) are separated by more than \(\pi\), this expression will take the long way around: it’s not aware that angles are cyclic.</p>

<canvas id="2d_angle_interp"></canvas>


<table><tbody><tr>
<td>$$ \theta_0 = 0\ \ $$</td>
<td id="2d_angle_interp_mj">$$ \theta(0.00) = 0.00\ \ $$</td>
<td id="2d_angle_interp_m1">$$ \theta_1 = 4.71 $$</td>
</tr></tbody></table>

<p>Instead, let’s devise an interpolation scheme based on our <code>exp</code>/<code>log</code> maps. Since we know the two rotation matrices \(R_0\), \(R_1\), we can express the rotation that takes us directly from the initial pose to the final pose: \(R_1R_0^{-1}\), i.e. first undo \(R_0\), then apply \(R_1\).</p>

<p>Using our logarithmic map, we can obtain the smallest angle that rotates from \(R_0\) to \(R_1\): \(\log(R_1R_0^{-1})\). Since \(\log\) gives us an axis-angle rotation, we can simply scale the result by \(t\) to perform interpolation. After scaling, we can use our exponential map to get back a rotation matrix. This matrix represents a rotation \(t\) of the way from \(R_0\) to \(R_1\).</p>

<p>Hence, our final parametric rotation matrix is \(R(t) = \exp(t\log(R_1R_0^{-1})))R_0\).</p><p>

\[\begin{align*} R(0) &amp;= \exp(0)R_0 = R_0\\
R(1) &amp;= \exp(\log(R_1R_0^{-1}))R_0 = R_1R_0^{-1}R_0 = R_1 \end{align*}\]

</p><canvas id="2d_exp_interp"></canvas>


<table><tbody><tr>
<td>$$ R_0 = \begin{bmatrix}1&amp;0\\0&amp;1\end{bmatrix} $$</td>
<td id="2d_exp_interp_mj">$$ R(0.00) = \begin{bmatrix}\phantom{-}1.00&amp;\phantom{-}0.00\\\phantom{-}0.00&amp;\phantom{-}1.00\end{bmatrix} $$</td>
<td id="2d_exp_interp_m1">$$ R_1 = \begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix} $$</td>
</tr></tbody></table>

<p>Using <code>exp</code>/<code>log</code> for interpolation might seem like overkill for 2D—we could instead just check how far apart the angles are. But below, we’ll see how this interpolation scheme generalizes—without modification—to 3D, and in fact any number of dimensions.</p>

<h2 id="axisangle-in-3d">Axis/Angle in 3D</h2>

<p>We’re finally ready to derive an exponential and logarithmic map for 3D rotations. In 2D, our map arose from exponentiating \(\theta\mathcal{J}\), i.e. \(\theta\) times a matrix representing a counter-clockwise quarter turn about the axis of rotation. We will be able to do the same in 3D—but what transformation encodes a quarter turn about a 3D unit vector \(\mathbf{u}\)?</p>

<p>The cross product \(\mathbf{u}\times\mathbf{p}\) is typically defined as a vector normal to the plane containing both \(\mathbf{u}\) and \(\mathbf{p}\). However, we could also interpret \(\mathbf{u}\times\mathbf{p}\) as a quarter turn of the <em>projection</em> of \(\mathbf{p}\) into the plane with normal \(\mathbf{u}\), which we will call \(\mathbf{p}_\perp\):</p>

<p><img src="http://thenumb.at/assets/exp-rotations/crossu.svg"></p>

<p>So, if we can compute the quarter rotation of \(\mathbf{p}_\perp\), it should be simple to recover the quarter rotation of \(\mathbf{p}\). Of course, \(\mathbf{p}=\mathbf{p}_\perp+\mathbf{p}_\parallel\), so we’ll just have to add back the parallel part \(\mathbf{p}_\parallel\). This is correct because a rotation about \(\mathbf{u}\) preserves \(\mathbf{p}_\parallel\):</p>

<p><img src="http://thenumb.at/assets/exp-rotations/crossu2.svg"></p>

<p>However, “\(\mathbf{u} \times\)” is not a mathematical object we can work with. Instead, we can devise a matrix \(\mathbf{\hat{u}}\) that when multiplied with a a vector \(\mathbf{p}\), outputs the same result as \(\mathbf{u} \times \mathbf{p}\):</p><p>

\[\begin{align*}
\mathbf{u} \times \mathbf{p} &amp;= \begin{bmatrix} u_yp_z - u_zp_y \\ u_zp_x - u_xp_z \\ u_xp_y - u_yp_x \end{bmatrix} \\
 &amp;= \begin{bmatrix}0&amp;-u_z&amp;u_y\\u_z&amp;0&amp;-u_x\\-u_y&amp;u_x&amp;0\end{bmatrix}\begin{bmatrix}p_x\\p_y\\p_z\end{bmatrix} \\
 &amp;= \mathbf{\hat{u}}\mathbf{p}
\end{align*}\]

</p><p>We can see that \(\mathbf{\hat{u}}^T = -\mathbf{\hat{u}}\), so \(\mathbf{\hat{u}}\) is a <em>skew-symmetric</em> matrix. (i.e. it has zeros along the diagonal, and the two halves are equal but negated.) Note that in the 2D case, our quarter turn \(\mathcal{J}\) was also skew-symmetric, and sneakily represented the 2D cross product! We must be on the right track.</p>

<p>The reason we want to use axis/angle rotations in the first place is because they form a vector space. So, let’s make sure our translation to skew-symmetric matrices maintains that property. Given two skew-symmetric matrices \(A_1\) and \(A_2\):</p><p>

\[(A_1 + A_2)^T = A_1^T + A_2^T = -A_1 - A_2 = -(A_1 + A_2)\]

</p><p>Their sum is also a skew-symmetric matrix. Similarly:</p><p>

\[(cA)^T = c(A^T) = -cA_1\]

</p><p>Scalar multiplication also maintains skew-symmetry. The other vector space properties follow from the usual definition of matrix addition.</p>

<p>Finally, note that \(\mathbf{u} \times (\mathbf{u} \times (\mathbf{u} \times \mathbf{p})) = -\mathbf{u} \times \mathbf{p}\). Taking the cross product three times would rotate \(\mathbf{p}_\perp\) three-quarter turns about \(\mathbf{u}\), which is equivalent to a single negative-quarter turn. More generally, \(\mathbf{\hat{u}}^{k+2} = -\mathbf{\hat{u}}^k\) for any \(k&gt;0\). We could prove this by writing out all the terms, but the geometric argument is easier:</p>

<p><img src="http://thenumb.at/assets/exp-rotations/crossu3.svg"></p>

<h3 id="the-3d-exponential-map">The 3D Exponential Map</h3>

<p>Given an axis/angle rotation \(\theta\mathbf{u}\), we can make \(\theta\mathbf{\hat{u}}\) using the above construction. What happens when we exponentiate it? Using the identity \(\mathbf{\hat{u}}^{k+2} = -\mathbf{\hat{u}}^k\):</p><p>

\[\begin{align*}
e^{\theta\mathbf{\hat{u}}} &amp;= \mathcal{I} + \theta\mathbf{\hat{u}} + \frac{1}{2!}\theta^2\mathbf{\hat{u}}^2 + \frac{1}{3!}\theta^3\mathbf{\hat{u}}^3 + \frac{1}{4!}\theta^4\mathbf{\hat{u}}^4 + \frac{1}{5!}\theta^5\mathbf{\hat{u}}^5 + \dots \\
&amp;= \mathcal{I} + \theta\mathbf{\hat{u}} + \frac{1}{2!}\theta^2\mathbf{\hat{u}}^2 - \frac{1}{3!}\theta^3\mathbf{\hat{u}} - \frac{1}{4!}\theta^4\mathbf{\hat{u}}^2 + \frac{1}{5!}\theta^5\mathbf{\hat{u}} + \dots \\
&amp;= \mathcal{I} + \left(\theta - \frac{1}{3!}\theta^3 + \frac{1}{5!}\theta^5 - \dots\right)\mathbf{\hat{u}} + \left(1 - \left(1 - \frac{1}{2!}\theta^2 + \frac{1}{4!}\theta^4 - \dots\right)\right)\mathbf{\hat{u}}^2 \\
&amp;= \mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2
\end{align*}\]

</p><p>In the last step, we again recover the Taylor expansions of \(\sin\theta\) and \(\cos\theta\). Our final expression is known as <em>Rodrigues’ formula</em>.</p>

<p>This formula is already reminiscent of the 2D case: the latter two terms are building up a 2D rotation in the plane defined by \(\mathbf{u}\). To sanity check our 3D result, let’s compute our transform for \(\theta = 0\):</p><p>

\[e^{0\mathbf{\hat{u}}}\mathbf{p} = (\mathcal{I} + 0\mathbf{\hat{u}} + (1-1)\mathbf{\hat{u}}^2)\mathbf{p} = \mathbf{p}\]

</p><p>Rotating by \(\theta = 0\) preserves \(\mathbf{p}\), so the formula works. Then compute for \(\theta = \frac{\pi}{2}\):</p><p>

\[\begin{align*} e^{\frac{\pi}{2}\mathbf{\hat{u}}}\mathbf{p} &amp;= (\mathcal{I} + 1\mathbf{\hat{u}} + (1-0)\mathbf{\hat{u}}^2)\mathbf{p} \\ &amp;= \mathbf{p} + \mathbf{\hat{u}}\mathbf{p} + \mathbf{\hat{u}}^2\mathbf{p} \\
&amp;= \mathbf{p} + \mathbf{u}\times\mathbf{p} + \mathbf{u}\times(\mathbf{u}\times\mathbf{p})\\
&amp;= (\mathbf{p}_\perp + \mathbf{p}_\parallel) + \mathbf{u}\times\mathbf{p} - \mathbf{p}_\perp\\
&amp;= \mathbf{u}\times\mathbf{p} + \mathbf{p}_\parallel
\end{align*}\]

</p><p>Above, we already concluded \(\mathbf{u}\times\mathbf{p} + \mathbf{p}_\parallel\) is a quarter rotation. So, our formula is also correct at \(\theta = \frac{\pi}{2}\). Then compute for \(\theta = \pi\):</p><p>

\[\begin{align*} e^{\pi\mathbf{\hat{u}}}\mathbf{p} &amp;= (\mathcal{I} + 0\mathbf{\hat{u}} + (1-(-1))\mathbf{\hat{u}}^2)\mathbf{p} \\
&amp;= \mathbf{p} + 2\mathbf{\hat{u}}^2\mathbf{p} \\
&amp;= (\mathbf{p}_\perp + \mathbf{p}_\parallel) - 2\mathbf{p}_\perp \\
&amp;= -\mathbf{p}_\perp + \mathbf{p}_\parallel
\end{align*}\]

</p><p><img src="http://thenumb.at/assets/exp-rotations/crossu4.svg"></p>

<p>We end up with \(-\mathbf{p}_\perp + \mathbf{p}_\parallel\), which is a half rotation. Hence \(\theta = \pi\) is also correct.</p>

<p>So far, our formula checks out. Just to be sure, let’s prove that our 3D result is a rotation matrix, i.e. it’s orthonormal and has positive determinant. A matrix is orthonormal if \(A^TA = \mathcal{I}\), so again using \(\mathbf{\hat{u}}^{k+2} = -\mathbf{\hat{u}}^k\):</p><p>

\[\begin{align*}
&amp;\left(\mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2\right)^T\left(\mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2\right) \\
=&amp; \left(\mathcal{I}^T + \sin(\theta)\mathbf{\hat{u}}^T + (1-\cos(\theta))\left(\mathbf{\hat{u}}^T\right)^2\right)\left(\mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2\right) \\
=&amp;\ (\mathcal{I} - \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2)\left(\mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2\right) \\
=&amp;\ \mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2 - \sin(\theta)\mathbf{\hat{u}} - \sin^2(\theta)\mathbf{\hat{u}}^2 - \sin(\theta)(1-\cos(\theta))\mathbf{\hat{u}}^3 \\&amp;+ (1-\cos(\theta))\mathbf{\hat{u}}^2 + \sin(\theta)(1-\cos(\theta))\mathbf{\hat{u}}^3 + (1-\cos(\theta))^2\mathbf{\hat{u}}^4 \\
=&amp;\ \mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2 - \sin(\theta)\mathbf{\hat{u}} - \sin^2(\theta)\mathbf{\hat{u}}^2 + \sin(\theta)(1-\cos(\theta))\mathbf{\hat{u}} \\&amp;+ (1-\cos(\theta))\mathbf{\hat{u}}^2 - \sin(\theta)(1-\cos(\theta))\mathbf{\hat{u}} - (1-\cos(\theta))^2\mathbf{\hat{u}}^2\\
=&amp;\ \mathcal{I} + 2(1-\cos(\theta))\mathbf{\hat{u}}^2  - \sin^2(\theta)\mathbf{\hat{u}}^2 - (1-\cos(\theta))^2\mathbf{\hat{u}}^2\\
=&amp;\ \mathcal{I} + (-\sin^2(\theta) + 2(1-\cos(\theta)) - (1-\cos(\theta))^2)\mathbf{\hat{u}}^2\\
=&amp;\ \mathcal{I} + (-\sin^2(\theta)+1-\cos^2(\theta))\mathbf{\hat{u}}^2\\
=&amp;\ \mathcal{I} + (1-(\sin^2(\theta)+\cos^2(\theta)))\mathbf{\hat{u}}^2\\
=&amp;\ \mathcal{I}
\end{align*}\]

</p><p>Therefore, \(e^{\theta\mathbf{\hat{u}}}\) is orthonormal. We could show its determinant is positive (and therefore \(1\)) by writing out all the terms, but it suffices to argue that:</p>

<ul>
  <li>Clearly, \(\begin{vmatrix}\exp(0\mathbf{\hat{u}})\end{vmatrix} = \begin{vmatrix}\mathcal{I}\end{vmatrix} = 1\)</li>
  <li>There is no \(\theta\), \(\mathbf{\hat{u}}\) such that \(\begin{vmatrix}\exp(\theta\mathbf{\hat{u}})\end{vmatrix} = 0\), since \(\mathbf{\hat{u}}\) and \(\mathbf{\hat{u}}^2\) can never cancel out \(\mathcal{I}\).</li>
  <li>\(\exp\) is continuous with respect to \(\theta\) and \(\mathbf{\hat{u}}\)</li>
</ul>

<p>Therefore, \(\begin{vmatrix}\exp(0\mathbf{\hat{u}})\end{vmatrix}\) can never become negative. That means \(\exp(\theta\mathbf{\hat{u}})\) is a 3D rotation matrix!</p>

<h3 id="the-3d-logarithmic-map">The 3D Logarithmic Map</h3>

<p>Similarly to the 2D case, the 3D exponential map is not injective, so the 3D logarithmic map will not be surjective. Instead, we will again define it to return the <em>smallest magnitude</em> axis-angle rotation corresponding to the given matrix. Our exponential map gave us:</p><p>

\[R = \exp(\theta\mathbf{\hat{u}}) = \mathcal{I} + \sin(\theta)\mathbf{\hat{u}} + (1-\cos(\theta))\mathbf{\hat{u}}^2\]

</p><p>We can take the <a href="https://en.wikipedia.org/wiki/Trace_(linear_algebra)">trace</a> (sum along the diagonal) of both sides:</p><p>

\[\operatorname{tr}(R) = \operatorname{tr}(\mathcal{I}) + \sin(\theta)\operatorname{tr}(\mathbf{\hat{u}}) + (1-\cos(\theta))\operatorname{tr}(\mathbf{\hat{u}}^2)\]

</p><p>Clearly \(\operatorname{tr}(\mathcal{I}) = 3\), and since \(\mathbf{\hat{u}}\) is skew-symmetric, its diagonal sum is zero. That just leaves \(\mathbf{\hat{u}}^2\):</p><p>

\[\mathbf{\hat{u}}^2 = \begin{bmatrix}-u_y^2-u_z^2&amp;u_xu_y&amp;u_xu_z\\u_xu_y&amp;-u_x^2-u_z^2&amp;u_yu_z\\u_xu_z&amp;u_yu_z&amp;-u_x^2-u_y^2\end{bmatrix}\]

</p><p>We can see \(\operatorname{tr}(\mathbf{\hat{u}}^2) = -2u_x^2-2u_y^2-2u_z^2 = -2\|\mathbf{u}\|^2 = -2\). (We originally defined \(\mathbf{u}\) as a unit vector.) Our final trace becomes:</p><p>

\[\begin{align*} &amp;&amp; \operatorname{tr}(R) &amp;= 3 + 0\sin(\theta) - 2(1-\cos(\theta)) \\ &amp;&amp;&amp;= 1 + 2\cos\theta \\
&amp;\implies&amp; \theta &amp;= \arccos\left(\frac{\operatorname{tr}(R)-1}{2}\right) \end{align*}\]

</p><p>That’s half of our logarithmic map. To recover \(\mathbf{\hat{u}}\), we can antisymmetrize \(R\). Recall \(\mathbf{\hat{u}}^T = -\mathbf{\hat{u}}\), and that \(\mathbf{\hat{u}}^2\) is symmetric (above).</p><p>

\[\begin{align*}
&amp;&amp; R - R^T &amp;= \mathcal{I} - \mathcal{I}^T + \sin(\theta)(\mathbf{\hat{u}}-\mathbf{\hat{u}}^T) + (1-\cos(\theta))(\mathbf{\hat{u}}^2-(\mathbf{\hat{u}}^2)^T) \\
&amp;&amp;&amp;= \sin(\theta)(\mathbf{\hat{u}}+\mathbf{\hat{u}}) + (1-\cos(\theta))(\mathbf{\hat{u}}^2-\mathbf{\hat{u}}^2) \\
&amp;&amp;&amp;= 2\sin(\theta)\mathbf{\hat{u}} \\
&amp;\implies&amp; \mathbf{\hat{u}} &amp;= \frac{1}{2\sin\theta}(R-R^T) \\
\end{align*}\]

</p><p>Finally, to get \(\mathbf{u}\), we can pull out the entries of \(\mathbf{\hat{u}}\), which we just derived:</p><p>

\[\mathbf{u} = \frac{1}{2\sin\theta}\begin{bmatrix}R_{32}-R_{23}\\ R_{13}-R_{31}\\R_{21}-R_{12}\end{bmatrix}\]

</p><p>We now have our full 3D logarithmic map!</p>

<h3 id="interpolation-1">Interpolation</h3>

<p>Now equipped with our 3D <code>exp</code> and <code>log</code> maps, we can use them for interpolation. The exact same formula as the 2D case still applies:</p><p>

\[R(t) = \exp(t\log(R_1R_0^{-1})))R_0\]

</p><canvas id="3d_exp_interp"></canvas>


<table><tbody><tr>
<td>$$ R_0 = \begin{bmatrix}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{bmatrix} $$</td>
<td id="3d_exp_interp_mj">$$ R(0.00) = \begin{bmatrix}\phantom{-}1.00&amp;\phantom{-}0.00&amp;\phantom{-}0.00\\\phantom{-}0.00&amp;\phantom{-}1.00&amp;\phantom{-}0.00\\\phantom{-}0.00&amp;\phantom{-}0.00&amp;\phantom{-}1.00\end{bmatrix} $$</td>
<td id="3d_exp_interp_m1">$$ R_1 = \begin{bmatrix}-0.42&amp;-0.59&amp;-0.69\\0.51&amp;-0.79&amp;0.36\\-0.75&amp;-0.20&amp;0.63\end{bmatrix} $$</td>
</tr></tbody></table>

<p>Our interpolation scheme produces all the nice properties of axis/angle rotations—<strong>and</strong> chooses the shortest path every time. This wouldn’t look so smooth with Euler angles!</p>

<h2 id="averaging-rotations">Averaging Rotations</h2>

<p>However, we would have gotten an equally good interpolation scheme by just using quaternions instead of messing about with all this matrix math. Let’s consider something interesting we can <em>only</em> easily do with axis/angle rotations: averaging a set of rotation matrices.</p>

<p>The most straightforward method is to convert each matrix into an axis/angle rotation, average the resulting vectors, and convert back. That is certainly a valid strategy, but the resulting behavior won’t be very intuitive:</p>

<canvas id="rot_avg"></canvas>


<p>In particular, summing axis-angle vectors can result in “catastrophic cancellation.” An extreme example is averaging \(\begin{bmatrix}\pi&amp;0&amp;0\end{bmatrix}\) and \(\begin{bmatrix}-\pi&amp;0&amp;0\end{bmatrix}\), resulting in zero—which is clearly not representative of the two equivalent rotations.</p>

<p>To find an alternative, let’s first consider a slightly unconventional way of averaging points in the plane. The average of a set of points is the point that minimizes total squared distance to all others. Hence, there’s an optimization-based algorithm for finding it. Given \(x_0, \dots, x_n\), we can iterate the following procedure:</p>

<ul>
  <li>Pick an initial guess \(\bar{x} \in \mathbb{R}^2\) (can be one of the points).</li>
  <li>Repeat:
    <ul>
      <li>For each point, get its translation from the guess: \(\mathbf{u}_i \leftarrow x_i - \bar{x}\)</li>
      <li>Average the vectors: \(\mathbf{u} \leftarrow \frac{1}{n} \sum_{i=1}^n \mathbf{u}_i\)</li>
      <li>Step toward the average direction: \(\bar{x} \leftarrow \bar{x} + \tau\mathbf{u}\)</li>
    </ul>
  </li>
  <li>while \(\|\mathbf{u}\| &gt; \epsilon\).</li>
</ul>

<p><img src="http://thenumb.at/assets/exp-rotations/pointavg.svg"></p>

<p>As we run this procedure, \(\bar{x}\) will converge to the average point. Of course, we could have just averaged the points directly, but we’ll be able to translate this idea to the rotational case rather nicely.</p>

<p>Our logarithmic map lets us convert rotation matrices to axis axis/angle rotations, which are themselves just 3D points. So, what if we use the point averaging algorithm on rotations \(R_0, \dots, R_n\)?</p>

<ul>
  <li>Pick an initial guess \(\bar{R} \in \mathbb{R}^{3\times3}\) (can be \(\mathcal{I}\)).</li>
  <li>Repeat:
    <ul>
      <li>For each matrix, get its axis/angle rotation from the guess: \(\mathbf{u}_i \leftarrow \log(R_i\bar{R}^{-1})\)</li>
      <li>Average the vectors: \(\mathbf{u} \leftarrow \frac{1}{n} \sum_{i=1}^n \mathbf{u}_i\)</li>
      <li>Step toward the average rotation: \(\bar{R} \leftarrow \exp(\tau\mathbf{u})\bar{R}\)</li>
    </ul>
  </li>
  <li>while \(\|\mathbf{u}\| &gt; \epsilon\).</li>
</ul>

<canvas id="karcher"></canvas>


<p>The result of this algorithm is formally known as the <em>Karcher mean</em>. Just like how the average point minimizes total squared distance from all other points, the Karcher mean is a rotation that minimizes squared <em>angular</em> distance from all other rotations. Therefore, it won’t be subject to catastrophic cancellation—we’ll always end up with a non-zero in-between rotation.</p>

<p>Try comparing the two averaging algorithms—randomizing will keep them in sync. While the results are often similar, the Karcher mean exhibits more consistent behavior.</p>

<h2 id="quaternions-again">Quaternions (Again)</h2>

<p><em>Warning: section assumes knowledge of quaternions</em></p>

<p>Okay, I couldn’t resist talking about quaternions at least a little bit, given how closely they’re related to axis/angle rotations. Just like how complex exponentiation turned out to be equivalent to (skew-symmetric) 2D matrix exponentiation, quaternion exponentiation is equivalent to (skew-symmetric) 3D matrix exponentiation.</p>

<p>In 2D, an axis/angle rotation was simply \(\theta\). We created a pure-imaginary complex number \(i\theta\) and exponentiated it:</p><p>

\[e^{i\theta} = \cos\theta + i\sin\theta\]

</p><p>We got back a complex number that when multiplied with a point, rotates it by \(\theta\). It’s always the case that \(\|\cos\theta + i\sin\theta\| = 1\), so 2D rotations can be represented as unit-norm complex numbers.</p>

<p>In 3D, an axis/angle rotation is a vector \(\mathbf{u}\) such that \(\|\mathbf{u}\| = \theta\). What happens if we create a pure-imaginary quaternion \(\mathbf{q} = u_x\mathbf{i} + u_y\mathbf{j} + u_z\mathbf{k}\) and exponentiate it, too?</p>

<p>To make evaluating \(e^\mathbf{q}\) easier, first derive the following using the quaternion <a href="https://en.wikipedia.org/wiki/Quaternion#Multiplication_of_basis_elements">multiplication rules</a>:</p><p>

\[\begin{align*}
\mathbf{q}^2 &amp;= (u_x\mathbf{i} + u_y\mathbf{j} + u_z\mathbf{k})(u_x\mathbf{i} + u_y\mathbf{j} + u_z\mathbf{k}) \\
             &amp;= u_x^2\mathbf{i}^2 + u_xu_y\mathbf{i}\mathbf{j} + u_xu_z\mathbf{i}\mathbf{k} + u_yu_x\mathbf{j}\mathbf{i} + u_y^2\mathbf{j}^2 + u_yu_z\mathbf{j}\mathbf{k} + u_zu_x\mathbf{k}\mathbf{i} + u_zu_y\mathbf{k}\mathbf{j} + u_z^2\mathbf{k}^2 \\
             &amp;= -u_x^2 + u_xu_y\mathbf{k} - u_xu_z\mathbf{j} - u_yu_x\mathbf{k} - u_y^2 + u_yu_z\mathbf{i} + u_zu_x\mathbf{j} - u_zu_y\mathbf{i} - u_z^2 \\
             &amp;= -u_x^2-u_y^2-u_z^2\\
             &amp;= -\|\mathbf{q}\|^2\\
             &amp;= -\theta^2
\end{align*}\]

</p><p>Which is highly reminiscent of the skew-symmetric matrix identity used above. Therefore…</p><p>

\[\begin{align*}
e^\mathbf{q} &amp;= 1 + \mathbf{q} + \frac{\mathbf{q}^2}{2!} + \frac{\mathbf{q}^3}{3!} + \frac{\mathbf{q}^4}{4!} + \frac{\mathbf{q}^5}{5!} + \dots \\
             &amp;= 1 + \frac{\theta\mathbf{q}}{\theta} - \frac{\theta^2}{2!} - \frac{\theta^3\mathbf{q}}{3!\theta} + \frac{\theta^4}{4!} + \frac{\theta^5\mathbf{q}}{5!\theta} \dots \\
             &amp;= \left(1 - \frac{\theta^2}{2!} + \frac{\theta^4}{4!} - \dots\right) + \frac{\mathbf{q}}{\theta}\left(\theta - \frac{\theta^3}{3!} + \frac{\theta^5}{5!} - \dots\right) \\
             &amp;= \cos\theta + \frac{\mathbf{q}}{\theta}\sin\theta \\
             &amp;\approx \cos\theta + \frac{\mathbf{u}}{\|\mathbf{u}\|}\sin\theta
\end{align*}\]

</p><p>Our result looks almost exactly like the 2D case, just with three imaginary axes instead of one. In 2D, our axis/angle rotation became a unit-norm complex number. In 3D, it became a unit-norm quaternion. Now we can use this quaternion to rotate 3D points! Pretty cool, right?</p>

<p>One advantage of using quaternions is how easy the exponential map is to compute—if you don’t need a rotation matrix, it’s a good option. The quaternion logarithmic map is similarly simple:</p><p>

\[\theta = \arccos(\Re(\mathbf{q})), \mathbf{u} = \frac{1}{\sin\theta}\Im(\mathbf{q})\]

</p><p>Finally, note that the way to rotate a point \(\mathbf{p}\) by a quaternion \(\mathbf{q}\) is by evaluating the conjugation \(\mathbf{q}\mathbf{p}\mathbf{q}^{-1}\), where \(\mathbf{p} = p_x\mathbf{i} + p_y\mathbf{j} + p_z\mathbf{k}\) is another pure-imaginary quaternion representing our point. The conjugation technically rotates the point by \(2\theta\) about \(\mathbf{u}\), but that’s easily accounted for by making \(\|\mathbf{u}\| = \frac{\theta}{2}\) in the beginning.</p>

<h2 id="further-reading">Further Reading</h2>

<p>Made it this far? Well, there’s even more to learn about rotations.</p>

<p>Learn about quaternions <a href="https://eater.net/quaternions">here</a>, and why geometric algebra is more intuitive <a href="https://marctenbosch.com/quaternions/">here</a>.</p>

<p>Beyond understanding the four representations covered here (plus geometric algebra), it can be enlightening to learn about the algebraic structure underlying all 3D rotations: the group \(SO(3)\). I found <a href="https://www.youtube.com/watch?v=ACZC_XEyg9U">this video</a> to be a great resource: it explains \(SO(3)\) both intuitively and visually, demonstrating how it relates it to the group \(SU(2)\) as well as why quaternions and axis/angle rotations double-cover 3D rotation matrices.</p>

<p>The <a href="https://en.wikipedia.org/wiki/3D_rotation_group">wikipedia page on SO(3)</a> is also informative, though <em>very</em> math heavy. It touches on connections with axis/angle rotations, topology, \(SU(2)\), quaternions, and Lie algebra. It turns out the vector space of skew-symmetric matrices we derived above makes up \(\mathfrak{so}(3)\), the Lie algebra that corresponds to \(SO(3)\)—but I don’t know what that entails.</p>




  </div></div>]]></description>
        </item>
    </channel>
</rss>