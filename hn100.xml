<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 20 Jan 2024 04:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Can the black border atop the HN mourning header link to who died? (144 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39063870</link>
            <guid>39063870</guid>
            <pubDate>Sat, 20 Jan 2024 01:54:36 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39063870">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>The black bar has intentionally been kept obscure over the decades. (HN is almost two decades old now: <a href="https://news.ycombinator.com/item?id=1">https://news.ycombinator.com/item?id=1</a>)<p>Unfortunately, the answer to your question is very likely "No." There are a few subtle reasons why this is the case, and I'm going to attempt to explain them rather than stay silent. I've seen this situation many times, and the outcome is almost always "HN doesn't change." This isn't due to laziness; adding the feature is two lines of Arc. The reason is social.</p><p>Social software is hard. In fact, it's one of the hardest types of software ever  to be built. Things that might seem like small conveniences or improvements often have counterintuitive effects. These effects are not readily understood by people who aren't running the site, because only the people running the site can see them in detail.</p><p>For example, suppose we were to implement the black bar link. Firstly, this means that the black bar now becomes a "superslot", pinned at the very top of HN. It turns what was otherwise a subtle gesture into a feature. It will inevitably raise questions about whether the black bar is really warranted for so-and-so, or whether it's fair that they get the superslot. But criticisms like that can be ignored.</p><p>The bigger problem is one that Dan has pointed out many times: it's good to have readers dig a little for information. Only people who are motivated will end up showing up in the thread. And those are exactly the kinds of people who you want showing up in that thread, because the point is to honor whomever died, not to catapult the entire community (and then some) at the thread. After all, every single person who ever visits HN will immediately click the black bar if it was clickable. Are you sure this is the kind of effect that would be a Good Thing?</p><p>Then there is the truth that doing nothing leads to the optimal outcome. Suppose the black bar was changed, and it was a mistake. This mistake costs time, because now the moderator has to deal with the consequences. It's not just a matter of reverting the change; when stuff like that gets reverted, people get curious why. So it'd be natural to have to write an explanation, which ends up sparking discussion about very tricky subjects. Again, community software is hard, and explaining subtle reasons for doing X is a delicate process. All of this translates to the potential of wasting some unknown quantity of time; time you won't get back, and time that you won't be doing your duties of running HN.</p><p>Then there's the most subtle point: it would break tradition. pg was the originator of the black bar, along with the christmas colors. It might seem cheesy to people who haven't been here since 2006, but there's something magical about seeing HN behave exactly as it was originally written, even when that behavior is sometimes arguably less optimal than it otherwise could be. Because, again, every change has social effects, and these are very hard to predict.</p><p>Lastly, the person who died might not want all of the attention. Are you sure you really want to be spotlighted by the entire (tech) world when you pass? It wasn't till I had some uncomfortable moments in the spotlight that I realized that fame is sometimes something that people choose to avoid.</p><p>For all of those reasons and then some, the black bar is likely going to stay as it is. If only as a hat tip to the person who originally created the tradition.
              </p></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What's that touchscreen in my room? (295 pts)]]></title>
            <link>https://laplab.me/posts/whats-that-touchscreen-in-my-room/</link>
            <guid>39063242</guid>
            <pubDate>Sat, 20 Jan 2024 00:17:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://laplab.me/posts/whats-that-touchscreen-in-my-room/">https://laplab.me/posts/whats-that-touchscreen-in-my-room/</a>, See on <a href="https://news.ycombinator.com/item?id=39063242">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <blockquote>
<p>Discussion on <a href="https://news.ycombinator.com/item?id=39063242">HackerNews</a> and <a href="https://lobste.rs/s/ylejdi/what_s_touchscreen_my_room">Lobsters</a>.</p>
</blockquote>
<p>Roughly a year ago I moved into my new apartment. One of the reasons I picked this apartment was age of the building. The construction was finished in 2015, which ensured pretty good thermal isolation for winters as well as small nice things like Ethernet ports in each room. However, there was one part of my apartment that was too new and too smart for me. This thing:</p>
<p><img src="https://laplab.me/img/netthings/touchscreen.png" alt="Random touchscreen on the wall"></p>
<p>It is obviously a touchscreen of some sort, but there was zero indication as to what it controls. The landlord had no idea what this is. There are no buttons or labels on the thing, just a tiny yellow light to let you know it has the power.</p>
<p>I had a million questions, but I was too busy with the move and kinda of forgot about it until about a week ago. I was looking through a huge binder of various appliance manuals for my apartment when this thing slided out:</p>
<p><img src="https://laplab.me/img/netthings/brochure-touchscreen.png" alt="Brouchure with a touchscreen turned on"></p>
<p>Wait a second, that’s my touchscreen! Turns out it is a part of an energy monitoring system, which tells you current energy usage and has the ability to display historical data. That actually sounds pretty neat - I would be interested to see energy usage patterns of my house.</p>
<p>Brochure also mentioned a second part of the so-called “energy manager”, which was directly plugged into an electricity meter to get usage information. I went to inspect communal cupboard housing electricity meters - and sure enough, there it was, just standing in the corner. I never even noticed these boxes before, but they at least have the same branding as the brochure - some company creatively named “NETTHINGS”.</p>
<p><img src="https://laplab.me/img/netthings/energy-manager.png" alt="Energy Manager in the communal cupboard"></p>
<p>Pretty straightforward so far. We have two devices, one “server” gathering the data and another one “client” reading the data. Now the distance between them is actually very short - just a few meters and maybe 2-3 walls, totally reasonable setup for a cable connection. It was at that moment when I noticed a weird sticker in the corner of the brochure. There were two strings printed with labels “SSID” and “Pwd”. I froze in horror. They wouldn’t dare. It is literally 3 meter distance. These are embedded devices, they do not need this complexity…</p>
<p>And of course the two devices communicate using WiFi. Now that was unusual for me, since I am not an embedded developer. But a friend of mine, who worked on smart home features for one voice assistant told me that this is actually a pretty common thing to do in IoT space. C in IoT stands for “cost-effective” I guess.</p>
<p>Moving on, I needed to somehow turn on the weird touchscreen. Upon closer inspection, I noticed a small hole on the side, which looked a lot like something you insert a pin into to reset the device:</p>
<p><img src="https://laplab.me/img/netthings/touchscreen-reset.png" alt="Touchscreen reset hole"></p>
<p>I held a hidden button with a wire for a few seconds and was greeted by…an Android bootup logo! Yes, this turned out to be in fact an Android tablet, and a pretty old one at that. It has Google Talk, Flash and all kinds of other interesting stuff pre-installed:</p>
<p><img src="https://laplab.me/img/netthings/android.png" alt="Android menu"></p>
<p>From what I can tell, this is an Android 5, but I am not exactly sure. One of the apps stands out with a familiar name: “NetThings”. Launching it leads us to the screen where we select a WiFi network. Unfortunately, the one that is mentioned on the brochure, was not on the list. I double-checked the list, tried to refresh it, looked for WiFi networks using my other devices, tried to directly connect to the WiFi using the credentials, but no luck.</p>
<p>When I came back to the meter room I noticed the obvious: boxes for all other apartments had the light on, but mine was off for some reason:</p>
<p><img src="https://laplab.me/img/netthings/energy-manager-off.png" alt="Energy manager for my apartment is off"></p>
<p>I live in the UK and if anything, this is a country of electrical fuses. The more fuses the better, everything is fused, even some plugs. Fuses for certain appliances come in separate boxes with a small drawer that can slide out, allowing to replace the fuse. It looks like this:</p>
<p><img src="https://laplab.me/img/netthings/empty-fuse-box.png" alt="Empty fuse box"></p>
<p>As you can see, my fuse box did not have a fuse inside for some reason. No fuse - no electrical connection, no power for the energy manager and no WiFi hotspot. Thanks to the fuse box design, it is easy to replace one, but I did not know what kind of amperage should be allowed in the circuit. Luckily, I had a few working energy managers in the same cupboard, so I opened their boxes (cutting the power to them for a few seconds) to see what kind of fuses they use. Turns out, I need a 3A fuse, so I ordered one from Amazon and installed it the next day.</p>
<p>To be honest, the whole thing was a bit scary, since I was very close to the mains. After installation, I checked the temperature of the fuse multiple times during the day to get at least some indication that things are not going to get worse. It worked fine for a more than a week now, but I still do not recommend experiments like this to anyone.</p>
<p>After installing the replacement fuse, energy manager started blinking with green LEDs and the promised WiFi network appeared on all devices. Once I selected the network on the Android tablet, it changed to the following screen:</p>
<p><img src="https://laplab.me/img/netthings/energy-monitor-main.png" alt="Energy monitor main screen"></p>
<p>When tapped, it changes to this menu, inviting the user to select what kind of resource they want to monitor. Nothing here actually works except for “Mains Electricity” because that’s the only meter the energy manager is hooked up to.</p>
<p><img src="https://laplab.me/img/netthings/energy-monitor-menu.png" alt="Energy monitor menu"></p>
<p>“Mains Electricity” leads us to the most dissapointing screen in the history of UX design:</p>
<p><img src="https://laplab.me/img/netthings/energy-monitor-electricity.png" alt="Energy monitor electricity"></p>
<p>Ugh, where to start. What’s up with this color indicator on the right? What does the vertical position mean? If it is green, does it mean that I am using a small amount of electricity or just a normal one? What exactly is small? If it gets all the way to the top, is it compared to my historical maximum usage? Over what period of time?</p>
<p>Out of 5 numbers displayed to the left of the indicator, only one is actually true - number of kW consumed. All other numbers depend on the energy provider and definitely changed since the time this monitor was installed.</p>
<p>I saved best for last. The amount of money you pay as well as estimate of CO2 per kW <strong>is not configurable</strong>. According to the brochure, it was configurable during the initial installation, but it has no information on how to reset the system back into configurable state.</p>
<p>Finally, brochure says the following:</p>
<p><img src="https://laplab.me/img/netthings/brochure-time.png" alt="Brochure stating that clock is always accurate"></p>
<p>I have no idea why they decided to include this. Of course the clock on Android tablet shifted by almost 15 minutes since 2015, when it was supposedly installed.</p>
<p>The whole thing was quite dissapointing. However, I do have a few Raspberry Pico microcontrollers lying around at home. If I could connect to the WiFi network of the energy manager directly and get the data from the server, I could just extract kW consumption from the API, multiply it by a correct rate and then display it on some Grafana instance.</p>
<p>The main problem was that I do not know the IP of the server. I was just about ready to launch a full IP scan from laptop when I noticed that one of the use cases brochure advertised is checking the energy usage from the PC. The IP and port were conveniently provided together with the instructions. Opening it in the browser displays a familiar screen:</p>
<p><img src="https://laplab.me/img/netthings/energy-monitor-browser.png" alt="Energy Monitor as seen from the browser"></p>
<p>Turns out, interface on the Android tablet is just a webview. This makes our job that easier, since we can just go to the web inspector and see all the API calls. Looking at the URLs we see…</p>
<p><img src="https://laplab.me/img/netthings/energy-monitor-socketio.png" alt="Energy Monitor Network inspector"></p>
<p>…Socket.IO! Wow, I honestly did not expect that. Client literally needs to receive 5 numbers from the server, Socket.IO seems to be a complete overkill for this usecase. The client code also looks very complicated for what it does. There are at least 6 RequireJS modules, all loading dynamically through different requests of course. There is Handlebars, Backbone.js, Underscore.js… I feel like I am in high school again. These are all technologies I was very interested when I just <a href="https://laplab.me/posts/how-did-i-become-database-engineer-at-23/">started web development</a>.</p>
<p>But wait a second, Socket.IO would mean that an embedded device in my meters cupboard is running JavaScript? This must be weirdest Edge Computing Platform I have seen in my life. I want to deploy <em>something</em> there!</p>
<p>Totally forgetting the idea with Raspberry Pico fetching the data from the server, I put on my hacker hat and started poking around. IoT devices have a terrible reputation from the security perspective, so I expected it to be an easy run for a couple of hours tops. Boy was I wrong.</p>
<p>Direct SSH using <code>ssh <a href="https://laplab.me/cdn-cgi/l/email-protection" data-cfemail="f4869b9b80b4c5c3c6dac5c2dac4dac6c1c0">[email&nbsp;protected]</a></code> immediately fails with “Connection refused” error. That could mean a number of things, let’s see which ports are available:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>$ sudo nmap -p- -sV -O 172.16.0.254
</span></span><span><span>... truncated output ...
</span></span><span><span>Nmap scan report <span>for</span> 172.16.0.254
</span></span><span><span>Host is up (0.011s latency).
</span></span><span><span>Not shown: 65530 closed tcp ports (reset)
</span></span><span><span>PORT      STATE SERVICE       VERSION
</span></span><span><span>53/tcp    open  domain        dnsmasq 2.63rc6
</span></span><span><span>80/tcp    open  http          Node.js (Express middleware)
</span></span><span><span>1534/tcp  open  micromuse-lm?
</span></span><span><span>3000/tcp  open  http          Node.js (Express middleware)
</span></span><span><span>41142/tcp open  ssh           OpenSSH 6.2 (protocol 2.0)
</span></span></code></pre></div><p>Now this is interesting. As expected, we see a Node.js server running. We also have <code>dnsmasq</code>, which is a DHCP server (makes sense, since the device is a WiFi access point) and a hidden SSH server on port 41142.</p>
<p>SSH connection is no longer refused, but the root turned out to be password-protected. None of the simple username/password combinations like <code>admin/admin</code> or <code>root/root</code> worked, so we are essentially back to square one. However, <code>nmap</code> detected an unrecognized service on port 1534 called <code>micromuse-lm</code>. The first Google result is the following <a href="https://support.xilinx.com/s/question/0D52E00007IPix4SAD/broadcasts-to-port-1534?language=en_US">forum post</a>:</p>
<p><img src="https://laplab.me/img/netthings/xilinx-forum.png" alt="Xilinx forum post about micromuse-lm"></p>
<p>I do not know who you are <code>@ljohnson</code>, but may your life be happy and prosperous. This post does not give a lot of information, but it provides one with the correct keywords to continue the search. The main phrase here is <code>tcf-agent</code>. The concrete description of what is going on here is spread atom-thin across several websites, all of which expect you to know the terminology. Each of these websites provides you with a tiny piece of the puzzle and you are expected to combine it together on your own. So after a few hours and lots of cursing, here is what I know about <code>tcf-agent</code>:</p>
<p>TCF <a href="https://elinux.org/TCF">stands for</a> “Target Communications Framework”. It is a text protocol, which allows to read the filesystem, start new processes, send signals to processes and a lot more with the target system. <code>tcf-agent</code> is the server implementing this protocol or, in another words, probably the second biggest security vulnerability after passwordless root SSH. I do not understand why they went into all this trouble with SSH passwords, but kept <code>tcf-agent</code> running.</p>
<p>TCF seems to be closedly tied to Eclipse ecosystem. The <a href="https://download.eclipse.org/tools/tcf/tcf-docs/TCF%20Getting%20Started.html">Getting Started</a> guide suggests several plugins for Eclipse as the main way to interact with <code>tcf-agent</code>. I tried installing these plugins on a new version of Eclipse and it is absolutely impossible. There are dependency issues everywhere and when you actually try to install the missing dependencies, Eclipse does not let you because they conflict with some other dependencies. It’s a mess, which is exactly how I imagined this interaction to go.</p>
<p>Conveniently, TCF project has a Python SDK. As with everything during this research, I needed to go through 3 links on different websites to actually find one. First, we are met with <a href="https://wiki.eclipse.org/TCF/Python_Scripting">this lovely page</a>:</p>
<p><img src="https://laplab.me/img/netthings/eclipse-wiki-python.png" alt="Eclipse Wiki for Python Scripting"></p>
<p>Which has a link that leads to <a href="https://git.eclipse.org/c/tcf/org.eclipse.tcf.git/tree/python/src/tcf">here</a>, which has a very small text pointing out that the repo moved to <a href="https://gitlab.eclipse.org/eclipse/tcf/tcf">this Gitlab repository</a>. Phew. The repo even has a few fresh commits, which seems a bit suprprising to me, as TCF in general gives off vibes of an abandoned project.</p>
<p>Nevertheless, the repository contains a pretty modern Python 3 (!) SDK, even with some inline documentation. It is not perfect, some docs are outdated, some methods are very weird, but you can pretty easily figure out what’s going on from the code. Protocol specification <a href="https://download.eclipse.org/tools/tcf/tcf-docs/TCF%20Specification.html">here</a> and <a href="https://download.eclipse.org/tools/tcf/tcf-docs/TCF%20Services.html">here</a> are a huge help in this process.</p>
<p>In a nutshell, a <code>tcf-agent</code> provides a bunch of services that expose various parts of the system. For example, there is a <code>FileSystem</code> service for all interactions with the filesystem, <code>Processes</code> service for starting/stopping/debugging processes, etc. Here is an example of getting current user information:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> <span>tcf</span>
</span></span><span><span><span>from</span> <span>tcf.util.sync</span> <span>import</span> CommandControl
</span></span><span><span>
</span></span><span><span>tcf.protocol.startEventQueue()
</span></span><span><span>cmd = CommandControl(tcf.connect(<span>'TCP:172.16.0.254:1534'</span>))
</span></span><span><span>error, user = cmd.FileSystem.user()
</span></span><span><span><span>print</span>(user)
</span></span></code></pre></div><p>And that’s how we learned that <code>tcf-agent</code>, in fact, runs under the <code>root</code> user. Again, why bother with SSH passwords if you leave a debug server with root access - this I will never understand.</p>
<p><code>FileSystem</code> and <code>Processes</code> services have other functions, roughly corresponding to syscalls. You can pretty easily replicate alternatives to common commands like <code>ls</code>, <code>cat</code>, <code>ps</code> and the like using this API. Now I say “pretty easily”, but in reality that was 4 hours of guessing the protocol format, trying to the find the documentation, fixing bugs in the SDK, all on an extremely unstable WiFi connection from an embedded device. Fun times. You can find the results in <a href="https://github.com/laplab/tcf-tools">this Github repo</a>.</p>
<p>Now that we have basic instruments, let’s get to hacking! My first attempt was to crack the root password, as I still believed it was something trivial. I used <a href="https://github.com/openwall/john">John the Ripper</a> password cracker in the following way</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># `cat.py` fetches file contents from the energy manager</span>
</span></span><span><span><span># using `FileSystem` TCF service.</span>
</span></span><span><span>$ ./cat.py /etc/passwd &gt; passwd.txt
</span></span><span><span>$ ./cat.py /etc/shadow &gt; shadow.txt
</span></span><span><span>$ unshadow passwd.txt shadow.txt &gt; passwords.txt
</span></span><span><span>$ john passwords.txt
</span></span></code></pre></div><p>I left it running for roughly 7 hours, but it did not find a match. John reported that it will finish its brute-force in the year 2035, so I decided to try out a different approach.</p>
<p>After a bit of Googling, I <a href="https://unix.stackexchange.com/a/533599">found out</a> that one can simply make root’s password empty by modifying <code>/etc/shadow</code>. Having done just that, I powercycled the device by removing the fuse I installed previously and putting it back after some time. Unfortunately, SSH still rejected my login attempts.</p>
<p>More out of desperation than anything else, I decided to look at sshd config of the host and finally found the offending line. <code>sshd_config</code> had <code>PermitRootLogin no</code> line included, which is a very sensible security measure as long as you are not providing a full disk access to anyone on the network.</p>
<p>I replaced the line with <code>PermitRootLogin yes</code> and finally, I saw the output I was struggling for:</p>
<p><img src="https://laplab.me/img/netthings/prompt.png" alt="SSH prompt for the server"></p>
<p>We are in! God, that was quite a journey, wasn’t it? Let’s look around!</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>root@nt-core:~# uname -srm
</span></span><span><span>Linux 3.10.28 armv5tejl
</span></span></code></pre></div><p>We can see that we are running Linux 3.10, which is actually quite a recent release (middle of 2013), considering this device was developed and installed roughly in 2014-2015. Unsurprisingly for an embedded device, it is powered by an ARM chip:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>root@nt-core:~# cat /proc/cpuinfo
</span></span><span><span>processor	: 0
</span></span><span><span>model name	: ARM926EJ-S rev 5 (v5l)
</span></span><span><span>BogoMIPS	: 226.09
</span></span><span><span>Features	: swp half fastmult edsp java
</span></span><span><span>CPU implementer	: 0x41
</span></span><span><span>CPU architecture: 5TEJ
</span></span><span><span>CPU variant	: 0x0
</span></span><span><span>CPU part	: 0x926
</span></span><span><span>CPU revision	: 5
</span></span><span><span>
</span></span><span><span>Hardware	: Freescale MXS (Device Tree)
</span></span><span><span>Revision	: 0000
</span></span><span><span>Serial		: 0000000000000000
</span></span></code></pre></div><p>We have an <a href="https://en.wikipedia.org/wiki/ARM9">ARM9 family</a> CPU. Wikipedia says that it was released in 2001, with a list of notable mentions including being a <a href="https://en.wikipedia.org/wiki/Hollywood_(graphics_chip)#Starlet">coprocessor for Nintendo Wii</a>.</p>
<p>The fact I find even more surprising is that this processor supports executing Java bytecode directly. Yep, you read that right, the <code>java</code> in the list of CPU features actually means <strong>that</strong> Java. The ARM extension for this feature was called <a href="https://en.wikipedia.org/wiki/Jazelle">Jazelle</a>. This seemed to be some kind of a trend around 2000s, since this is <a href="https://mastodon.social/@laplab/109697958878708357">not the first time I encounter such feature</a>.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>root@nt-core:~# cat /proc/meminfo
</span></span><span><span>MemTotal:         118172 kB
</span></span><span><span>...truncated...
</span></span></code></pre></div><p>Lastly, we have 118MB of RAM. I am not an embedded Linux expert, but this does seem like a lot after tinkering with Raspberry Pi Pico and such. At the same time, it makes sense, since we do have a Node.js app running on the host and JavaScript isn’t exactly a memory-efficient language.</p>
<p>The app itself is quite a sizeable codebase. Despite the fact that the company that made the device and software for it is <a href="https://find-and-update.company-information.service.gov.uk/company/SC313913">already dissolved</a>, I don’t want to risk being sued over releasing the source code. I am pretty sure nobody would actually care, but I still want nothing to do with it. So instead we will just look at some file lists.</p>
<p>Top-level directory structure looks like this:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>root@nt-core:/srv/server# ls -la
</span></span><span><span>drwxr-xr-x   13 nodejs   nogroup       4096 Oct 23 10:47 .
</span></span><span><span>drwxr-xr-x    3 root     root          4096 Oct 14 12:13 ..
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup       8125 Oct 14 12:13 Gruntfile.js
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup       1916 Oct 14 12:13 app.js
</span></span><span><span>drwxr-xr-x    2 nodejs   nogroup       4096 Oct 14 12:13 app_data
</span></span><span><span>drwxr-xr-x   10 nodejs   nogroup       4096 Oct 14 12:13 bin
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup       1278 Oct 14 12:13 bower.json
</span></span><span><span>drwxr-xr-x    2 nodejs   nogroup       4096 Oct 23 10:40 info
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup         16 Oct 14 12:13 jira_version
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup       2673 Oct 14 12:13 karma.conf.js
</span></span><span><span>drwxr-xr-x    2 nodejs   dialout       4096 Oct 23 10:49 logs
</span></span><span><span>drwxr-xr-x    4 nodejs   nogroup       4096 Oct 14 12:13 modules
</span></span><span><span>drwxr-xr-x   17 nodejs   nogroup       4096 Oct 14 12:13 node_modules
</span></span><span><span>-rw-r--r--    1 root     root             0 Oct 23 10:40 nodejs.log
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup      76023 Oct 14 12:13 npm-shrinkwrap.json
</span></span><span><span>-rw-r--r--    1 nodejs   nogroup       2216 Oct 14 12:13 package.json
</span></span><span><span>drwxr-xr-x    6 nodejs   nogroup       4096 Oct 14 12:13 production
</span></span><span><span>drwxr-xr-x    6 nodejs   nogroup       4096 Oct 14 12:13 public
</span></span><span><span>drwxr-xr-x    4 nodejs   nogroup       4096 Oct 14 12:13 routes
</span></span><span><span>drwxr-xr-x    3 nodejs   nogroup       4096 Oct 14 12:13 scripts
</span></span><span><span>drwxr-xr-x    4 nodejs   nogroup       4096 Oct 14 12:13 views
</span></span></code></pre></div><p>From what I could figure out, the app consists of two parts. The first part is responsible for actually reading usage data from the electricity meter connected to the device. This part is called a “Pulse app” and its binary is located in the <code>bin</code> folder:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>root@nt-core:/srv/server# ls -la bin
</span></span><span><span>drwxr-xr-x   10 nodejs   nogroup       4096 Oct 14 12:13 .
</span></span><span><span>drwxr-xr-x   13 nodejs   nogroup       4096 Oct 23 10:47 ..
</span></span><span><span>drwxrw----    2 nodejs   dialout       4096 Nov 16 00:12 aggregate
</span></span><span><span>drwxrw----    2 nodejs   dialout       4096 Oct 23 11:03 cfg
</span></span><span><span>-rwxr-xr-x    1 nodejs   dialout      52418 Oct 14 12:13 ct-read-daemon
</span></span><span><span>drwxrw----    2 nodejs   dialout       4096 Nov 16 01:00 daily
</span></span><span><span>-rwxr-xr-x    1 nodejs   nogroup       1155 Oct 14 12:13 get_sys_versions.sh
</span></span><span><span>drwxrw----    2 nodejs   dialout     118784 Nov 16 03:00 hourly
</span></span><span><span>drwxrw----    2 nodejs   dialout       4096 Nov  1 01:00 monthly
</span></span><span><span>drwxr-xr-x    2 nodejs   nogroup       4096 Oct 14 12:13 output
</span></span><span><span>-rwxr-xr-x    1 nodejs   dialout      34543 Oct 14 12:13 pulse-app
</span></span><span><span>-rwxr-xr-x    1 nodejs   dialout     117029 Oct 14 12:13 pulse.ko
</span></span><span><span>-rwxr-xr-x    1 nodejs   nogroup        758 Oct 14 12:13 reset_nrg_mgr.sh
</span></span><span><span>drwxrw----    2 nodejs   dialout       4096 Nov 16 01:00 weekly
</span></span><span><span>drwxrw----    2 nodejs   dialout       4096 Oct 23 11:00 yearly
</span></span></code></pre></div><p>Judging from the debug symbols, my initial guess was that this is a regular C appication, which seems appropriate for the task of interacting with low-level GPIO pins. However, <code>pulse.ko</code> file got me interested. <code>.ko</code> extension usually means “Kernel Object”, which would suggest that this is actually a kernel module. I do not know a first thing about kernel modules, so I might be wrong here.</p>
<p>Pulse app reads the data from the GPIO pins and stores the results in CSV files. These CSV files are split by month, day and hour in the directories with the respective names, still in the <code>bin</code> folder. Such separation is no coincedence. Historical data view in the web UI of the energy manager supports displaying the data only by month, by day and by hour.</p>
<p>Along with the Pulse app, there is the second part of the application. A Node.js app reads CSV files populated with energy usage data and displays them to the user in the web UI. It uses Node.js 0.10.26, Express.js 4.13.3 and Socket.io 1.3.6.</p>
<p>Scrolling through the dependencies, I noticed an <code>mqtt</code> package. This was intriguing, because I did not see any message broker interaction until now. After reading the sources for a little while, this seemed to be an unfinished cloud integration that Netthings promised in their brochure. There are even some hardcoded IPs mentioned in the source, which are used to connect to a message broker. Unsurprisingly, none of them are up any more. I am not even sure how that would work, since the device does not have an internet access.</p>
<p>All in all, this was a very fun investigation! I grew accustomed to calling it “my urban archeology project”. I now have access to one of the weirdest Edge Computing platforms imaginable. If you have any fun ideas on what to do with it, feel free to drop me a line at <a href="https://laplab.me/cdn-cgi/l/email-protection#f39b9ab39f92839f9291dd9e96"><span data-cfemail="7810113814190814191a56151d">[email&nbsp;protected]</span></a>!</p>
<p>P.S. As a final touch, I decided to leave a small note in the home directory. It’s kind of weird to realise that I am probably the only person who would actually read it. But maybe in some distant future another software engineer will live in this apartment and discover it. Time will tell :)</p>
<p><img src="https://laplab.me/img/netthings/letter-to-the-void.png" alt="Note to the next tinkerer"></p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The bane of my existence: Supporting both async and sync code in Rust (123 pts)]]></title>
            <link>https://nullderef.com/blog/rust-async-sync/</link>
            <guid>39061839</guid>
            <pubDate>Fri, 19 Jan 2024 22:00:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nullderef.com/blog/rust-async-sync/">https://nullderef.com/blog/rust-async-sync/</a>, See on <a href="https://news.ycombinator.com/item?id=39061839">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="_introduction">Introduction</h2><div><p>Imagine you want to create a new library in Rust. All it does is wrap up a
public API that you need for something else, like
<a href="https://developer.spotify.com/documentation/web-api/">the Spotify API</a> or maybe a
database like <a href="https://www.arangodb.com/">ArangoDB</a>. It’s not rocket science, you
aren’t inventing something new or dealing with complex algorithms, so you expect
it to be relatively straightforward.</p><p>You decide to implement the library with async. Most of the work in your library
has to do with performing HTTP requests, which are mostly I/O, so it makes sense
(that, and because it’s what the cool kids use in Rust nowadays). You start
coding and have the v0.1.0 release ready in a few days. “Neat”, you say, as
<code>cargo publish</code> finishes successfully and uploads your work to
<a href="https://crates.io/">crates.io</a>.</p><p>A couple of days pass, and you get a new notification on GitHub. Someone opened
an issue:</p><div><blockquote><p><strong>How can I use this library synchronously?</strong></p><p>My project doesn’t use async because it’s overly complex for what I need. I
wanted to try your new library, but I’m not sure how to do it easily. I would
rather not fill my code with <code>block_on(endpoint())</code>. I’ve seen crates like <a href="https://crates.io/crates/reqwest"><code>reqwest</code></a>
exporting a
<a href="https://docs.rs/reqwest/0.11.4/reqwest/blocking/index.html"><code>blocking</code> module</a>
with the exact same functionality, could you perhaps do that as well?</p></blockquote></div><p>Low-level wise, that sounds like a very complicated task. Having a common
interface for both async code — which requires a runtime like <a href="https://crates.io/crates/tokio"><code>tokio</code></a>
, awaiting futures, pinning, etc — and regular sync code? I mean, they asked
nicely, so maybe we can try. After all, the only difference in the code would be
the occurrences of the <code>async</code> and <code>await</code> keywords because you aren’t doing
anything fancy.</p><p>Well, this is <em>more or less</em> what happened with the crate <a href="https://crates.io/crates/rspotify"><code>rspotify</code></a>
, which I used to maintain along with its creator
<a href="https://github.com/ramsayleung/">Ramsay</a>. For those who don’t know, it’s a
wrapper for the Spotify Web API. To clarify, I did get this working in the end,
although not as cleanly as I was hoping; I’ll try to explain the situation in
this new article of the <a href="https://nullderef.com/series/rspotify">Rspotify series</a>.</p></div></div><div><h2 id="_the_first_approaches">The first approaches</h2><div><p>To give more context, here’s what Rspotify’s client looks like, roughly:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>struct</span> <span>Spotify</span><span> </span><span>{</span><span> </span><span>/* ... */</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>Spotify</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>async</span><span> </span><span>fn</span> <span>some_endpoint</span><span>(</span><span>&amp;</span><span>self</span><span>,</span><span> </span><span>param</span>: <span>String</span><span>)</span><span> </span>-&gt; <span>SpotifyResult</span><span>&lt;</span><span>String</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>params</span><span> </span><span>=</span><span> </span><span>HashMap</span>::<span>new</span><span>();</span><span>
</span></span></span><span><span><span>        </span><span>params</span><span>.</span><span>insert</span><span>(</span><span>"param"</span><span>,</span><span> </span><span>param</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>http</span><span>.</span><span>get</span><span>(</span><span>"/some-endpoint"</span><span>,</span><span> </span><span>params</span><span>).</span><span>await</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div><p>Essentially, we would have to make <code>some_endpoint</code> available for both
asynchronous and blocking users. The important question here is, how do you do
this once you have dozens of endpoints? And how can you make it easy to switch
between async and sync for the user?</p><div><h3 id="_good_ol_copy_pasting">Good ol' copy-pasting</h3><p>This is what was first implemented. It was quite simple and it worked. You just
need to copy the regular client code into a new
<a href="https://github.com/ramsayleung/rspotify/tree/v0.9/src/blocking"><code>blocking</code> module
in Rspotify</a>. <a href="https://docs.rs/reqwest"><code>reqwest</code></a> (our HTTP client) and
<a href="https://docs.rs/reqwest/latest/reqwest/blocking/index.html"><code>reqwest::blocking</code></a>
share the same interface, so we can manually remove keywords like <code>async</code> or
<code>.await</code> and import <code>reqwest::blocking</code> instead of <code>reqwest</code> in the new module.</p><p>Then, the Rspotify user just can just use <code>rspotify::blocking::Client</code> instead
of <code>rspotify::Client</code>, and voilà! Their code is now blocking. This will bloat
the binary size for async-only users, so we can just feature-gate it under the
name <code>blocking</code> and done.</p><p>The problem was much more clear later on, though. Half the crate’s code was
duplicated. Adding a new endpoint or modifying it meant writing or removing
everything twice.</p><p>There is no way to make sure both implementations are equivalent unless you test
absolutely everything. Which isn’t a bad idea either, but maybe you copy-pasted
the tests wrong! How about that? The poor reviewer would have to read through
the same code twice to make sure both sides look alright — which sounds
incredibly prone to human errors.</p><p>In our experience, it really slowed down the development of Rspotify, specially
for new contributors who weren’t used to this whole ordeal. As a new excited
maintainer of Rspotify, I began to
<a href="https://github.com/ramsayleung/rspotify/issues/112">investigate other possible
solutions</a>.</p></div><div><h3 id="_calling_block_on">Calling <code>block_on</code></h3><p><a href="https://github.com/ramsayleung/rspotify/pull/120">The second approach</a> consisted
on implementing everything on the async side. Then, you just make wrappers for
the blocking interface, which call
<a href="https://docs.rs/tokio/latest/tokio/runtime/struct.Runtime.html#method.block_on"><code>block_on</code></a>
internally. <code>block_on</code> will run the future until completion, basically
making it synchronous. You still need to copy the method <em>definitions</em>, but the
implementation is written once only:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>mod</span> <span>blocking</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>struct</span> <span>Spotify</span><span>(</span><span>super</span>::<span>Spotify</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>impl</span><span> </span><span>Spotify</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>fn</span> <span>endpoint</span><span>(</span><span>&amp;</span><span>self</span><span>,</span><span> </span><span>param</span>: <span>String</span><span>)</span><span> </span>-&gt; <span>SpotifyResult</span><span>&lt;</span><span>String</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>runtime</span><span>.</span><span>block_on</span><span>(</span><span>async</span><span> </span><span>move</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>                </span><span>self</span><span>.</span><span>0.</span><span>endpoint</span><span>(</span><span>param</span><span>).</span><span>await</span><span>
</span></span></span><span><span><span>            </span><span>})</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div><p>Note that in order to call <code>block_on</code>, you first have to create some kind of
runtime in the endpoint method. For example, with <a href="https://crates.io/crates/tokio"><code>tokio</code></a>
:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>let</span><span> </span><span>mut</span><span> </span><span>runtime</span><span> </span><span>=</span><span> </span><span>tokio</span>::<span>runtime</span>::<span>Builder</span>::<span>new</span><span>()</span><span>
</span></span></span><span><span><span>    </span><span>.</span><span>basic_scheduler</span><span>()</span><span>
</span></span></span><span><span><span>    </span><span>.</span><span>enable_all</span><span>()</span><span>
</span></span></span><span><span><span>    </span><span>.</span><span>build</span><span>()</span><span>
</span></span></span><span><span><span>    </span><span>.</span><span>unwrap</span><span>();</span></span></span></code></pre></div><p>This raises the question: should we initialize the runtime in each call to the
endpoint, or is there a way to share it? We could keep it as a global (<em>ewwww</em>),
or perhaps better, we can save the runtime in the <code>Spotify</code> struct. But since it
takes a <em>mutable</em> reference to the runtime, you’d have to wrap it up with
<code>Arc&lt;Mutex&lt;T&gt;&gt;</code>, completely killing the concurrency in your client. The proper
way to do this is with Tokio’s
<a href="https://docs.rs/tokio/latest/tokio/runtime/struct.Handle.html"><code>Handle</code></a>, which
looks like this:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>tokio</span>::<span>runtime</span>::<span>Runtime</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>lazy_static!</span><span> </span><span>{</span><span> </span><span>// You can also use `once_cell`
</span></span></span><span><span><span></span><span>    </span><span>static</span><span> </span><span>ref</span><span> </span><span>RT</span>: <span>Runtime</span><span> </span><span>=</span><span> </span><span>Runtime</span>::<span>new</span><span>().</span><span>unwrap</span><span>();</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>endpoint</span><span>(</span><span>&amp;</span><span>self</span><span>,</span><span> </span><span>param</span>: <span>String</span><span>)</span><span> </span>-&gt; <span>SpotifyResult</span><span>&lt;</span><span>String</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>RT</span><span>.</span><span>handle</span><span>().</span><span>block_on</span><span>(</span><span>async</span><span> </span><span>move</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>self</span><span>.</span><span>0.</span><span>endpoint</span><span>(</span><span>param</span><span>).</span><span>await</span><span>
</span></span></span><span><span><span>    </span><span>})</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div><p>While the handle does make our blocking client faster <a href="#block-on-perf">[1]</a>, there
is an even more performant way to do it. This is what <a href="https://crates.io/crates/reqwest"><code>reqwest</code></a>
itself does, in case you’re interested. In short, it spawns a thread that calls
<code>block_on</code> waiting on a channel with jobs <a href="#block-on-channels">[2]</a>
<a href="#block-on-reqwest">[3]</a>.</p><p>Unfortunately, this solution still has quite the overhead. You pull in large
dependencies like <code>futures</code> or <code>tokio</code>, and include them in your binary. All of
that, in order to…​ actually end up writing blocking code. So not only is it a
cost at runtime, but also at compile time. It just feels wrong to me.</p><p>And you still have a good amount of duplicate code, even if it’s just
definitions, which can sum up. <a href="https://crates.io/crates/reqwest"><code>reqwest</code></a>
is a huge project and can
probably afford this for their <code>blocking</code> module. But for a less popular crate
like <code>rspotify</code>, this is harder to pull off.</p></div><div><h3 id="_duplicating_the_crate">Duplicating the crate</h3><p>Another possible way to fix this is, as the features docs suggest, creating
separate crates. We’d have <code>rspotify-sync</code> and <code>rspotify-async</code>, and users would
just pick whichever crate they want as a dependency, even both if they need to.
The problem is — again — how exactly do we generate both versions of the
crate? <a href="https://github.com/ramsayleung/rspotify/pull/253">I was unable to do this
without copy-pasting the entire crate</a>, even with Cargo tricks like two
<code>Cargo.toml</code> files, one for each crate (which was quite inconvenient anyway).</p><p>With this idea we can’t even use procedural macros because you can’t just create
a new crate within a macro. We could define a file format to write templates of
Rust code in order to replace parts of the code like <code>async</code>/<code>.await</code>. But that
sounds completely out of scope.</p></div></div></div><div><h2 id="_what_ended_up_working_the_maybe_async_crate">What ended up “working”: the <code>maybe_async</code> crate</h2><div><p><a href="https://github.com/ramsayleung/rspotify/pull/129">The third attempt</a> is based on
a crate called <a href="https://crates.io/crates/maybe_async"><code>maybe_async</code></a>
. I remember foolishly thinking it was
the perfect solution back when I discovered it.</p><p>Anyway, the idea is that with this crate you can automatically remove the
<code>async</code> and <code>.await</code> occurrences in your code with a procedural macro,
essentially automating the copy-pasting approach. For example:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[maybe_async::maybe_async]</span><span>
</span></span></span><span><span><span></span><span>async</span><span> </span><span>fn</span> <span>endpoint</span><span>()</span><span> </span><span>{</span><span> </span><span>/* stuff */</span><span> </span><span>}</span></span></span></code></pre></div><p>Generates the following code:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[cfg(not(feature = </span><span>"is_sync"</span><span>))]</span><span>
</span></span></span><span><span><span></span><span>async</span><span> </span><span>fn</span> <span>endpoint</span><span>()</span><span> </span><span>{</span><span> </span><span>/* stuff */</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[cfg(feature = </span><span>"is_sync"</span><span>)]</span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>endpoint</span><span>()</span><span> </span><span>{</span><span> </span><span>/* stuff with `.await` removed */</span><span> </span><span>}</span></span></span></code></pre></div><p>You can configure whether you want asynchronous or blocking code by toggling the
<code>maybe_async/is_sync</code> feature when compiling the crate. The macro works for
functions, traits and <code>impl</code> blocks. If one conversion isn’t as easy as removing
<code>async</code> and <code>.await</code>, you can specify custom implementations with the
<code>async_impl</code> and <code>sync_impl</code> procedural macros. It does this wonderfully, and
we’ve already been using it for Rspotify for a while now.</p><p>In fact, it worked so well that I made Rspotify <em>http-client agnostic</em>, which is
even more flexible than being <em>async/sync agnostic</em>. This allows us to support
multiple HTTP clients like <a href="https://crates.io/crates/reqwest"><code>reqwest</code></a>
and <a href="https://crates.io/crates/ureq"><code>ureq</code></a>
,
independently of whether the client is asynchronous or synchronous.</p><p>Being <em>http-client agnostic</em> is not that hard to implement if you have
<code>maybe_async</code> around. You just need to define a trait for the
<a href="https://github.com/ramsayleung/rspotify/blob/89b37219a2230cdcf08c4cfd2ebe46d64902f03d/rspotify-http/src/common.rs#L46">HTTP
client</a>, and then implement it for each of the clients you want to support:</p><div><p>A snippet of code is worth a thousand words. (<em>You can find the full source for Rspotify’s <a href="https://github.com/ramsayleung/rspotify/blob/master/rspotify-http/src/reqwest.rs#L97"><code>reqwest</code>'s client here</a>, and <a href="https://github.com/ramsayleung/rspotify/blob/master/rspotify-http/src/ureq.rs#L56"><code>ureq</code>'s here</a></em>)</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[maybe_async]</span><span>
</span></span></span><span><span><span></span><span>trait</span><span> </span><span>HttpClient</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>async</span><span> </span><span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span><span> </span>-&gt; <span>String</span><span>;</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[sync_impl]</span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>HttpClient</span><span> </span><span>for</span><span> </span><span>UreqClient</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span><span> </span>-&gt; <span>String</span> <span>{</span><span> </span><span>ureq</span>::<span>get</span><span>(</span><span>/* ... */</span><span>)</span><span> </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[async_impl]</span><span>
</span></span></span><span><span><span></span><span>impl</span><span> </span><span>HttpClient</span><span> </span><span>for</span><span> </span><span>ReqwestClient</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>async</span><span> </span><span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span><span> </span>-&gt; <span>String</span> <span>{</span><span> </span><span>reqwest</span>::<span>get</span><span>(</span><span>/* ... */</span><span>).</span><span>await</span><span> </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>struct</span> <span>SpotifyClient</span><span>&lt;</span><span>Http</span>: <span>HttpClient</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>http</span>: <span>Http</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[maybe_async]</span><span>
</span></span></span><span><span><span></span><span>impl</span><span>&lt;</span><span>Http</span>: <span>HttpClient</span><span>&gt;</span><span> </span><span>SpotifyClient</span><span>&lt;</span><span>Http</span><span>&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>async</span><span> </span><span>fn</span> <span>endpoint</span><span>(</span><span>&amp;</span><span>self</span><span>)</span><span> </span><span>{</span><span> </span><span>self</span><span>.</span><span>http</span><span>.</span><span>get</span><span>(</span><span>/* ... */</span><span>)</span><span> </span><span>}</span><span>
</span></span></span><span><span><span></span><span>}</span></span></span></code></pre></div></div><p>Then, we could extend it so that whichever client they want to use can be
enabled with feature flags in their <code>Cargo.toml</code>. For example, if <code>client-ureq</code>
is enabled, since <code>ureq</code> is synchronous, it would enable <code>maybe_async/is_sync</code>.
In turn, this would remove the <code>async</code>/<code>.await</code> and the <code>#[async_impl]</code> blocks,
and the Rspotify client would use <code>ureq</code>'s implementation internally.</p><p>This solution has none of the downsides I listed in previous attempts:</p><div><ul><li><p>No code duplication at all</p></li><li><p>No overhead neither at runtime nor at compile time. If the user wants a
blocking client, they can use <code>ureq</code>, which doesn’t pull <code>tokio</code> and friends</p></li><li><p>Quite easy to understand for the user; just configure a flag in you
<code>Cargo.toml</code></p></li></ul></div><p>However, stop reading for a couple of minutes and try to figure out why you
shouldn’t do this. In fact, I’ll give you 9 months, which is how long it took me
to do so…​</p><div><h3 id="_the_problem">The problem</h3><div><p><img src="https://nullderef.com/blog/rust-async-sync/preview.jpg" alt="preview" width="100%"></p></div><p>Well, the thing is that features in Rust must be <strong>additive</strong>: “enabling a
feature should not disable functionality, and it should usually be safe to
enable any combination of features”. Cargo may merge features of a crate when
it’s duplicated in the dependency tree in order to avoid compiling the same
crate multiple times.
<a href="https://doc.rust-lang.org/cargo/reference/features.html#feature-unification">The
reference explains this quite well, if you want more details</a>.</p><p>This optimization means that mutually exclusive features may break a dependency
tree. In our case, <code>maybe_async/is_sync</code> is a <em>toggle</em> feature enabled by
<code>client-ureq</code>. So if you try to compile it with <code>client-reqwest</code> also enabled,
it will fail because <code>maybe_async</code> will be configured to generate synchronous
function signatures instead. It’s impossible to have a crate that depends on
both sync and async Rspotify either directly or indirectly, and the whole
concept of <code>maybe_async</code> is currently wrong according to the Cargo reference.</p></div><div><h3 id="_the_feature_resolver_v2">The feature resolver v2</h3><p>A common misconception is that this is fixed by the “feature resolver v2”,
which
<a href="https://doc.rust-lang.org/cargo/reference/features.html#feature-resolver-version-2">the
reference also explains quite well</a>. It has been enabled by default since the
2021 edition, but you can specify it inside your <code>Cargo.toml</code> in previous ones.
This new version, among other things, avoids unifying features in some special
cases, but not in ours:</p><div><blockquote><div><ul><li><p>Features enabled on platform-specific dependencies for targets not currently
being built are ignored.</p></li><li><p>Build-dependencies and proc-macros do not share features with normal
dependencies.</p></li><li><p>Dev-dependencies do not activate features unless building a target that needs
them (like tests or examples).</p></li></ul></div></blockquote></div><p>Just in case, I tried to reproduce this myself, and it did work as I expected.
<a href="https://github.com/marioortizmanero/resolver-v2-conflict">This repository</a> is an
example of conflicting features, which breaks with any feature resolver.</p></div><div><h3 id="_other_fails">Other fails</h3><p>There were a few crates that also had this problem:</p><div><ul><li><p><a href="https://crates.io/crates/arangors"><code>arangors</code></a>
and <a href="https://crates.io/crates/aragog"><code>aragog</code></a>
: wrappers for ArangoDB. Both
use <code>maybe_async</code> to switch between async and sync (<code>arangors</code>'s author is
the same person, in fact) <a href="#arangors-error">[5]</a> <a href="#aragog-error">[6]</a>.</p></li><li><p><a href="https://crates.io/crates/inkwell"><code>inkwell</code></a>
: a wrapper for LLVM. It supports multiple versions of
LLVM, which are not compatible with eachother <a href="#inkwell-error">[7]</a>.</p></li><li><p><a href="https://crates.io/crates/k8s-openapi"><code>k8s-openapi</code></a>
: a wrapper for Kubernetes, with the same issue as
<code>inkwell</code> <a href="#k8s-error">[8]</a>.</p></li></ul></div></div><div><h3 id="_fixing_maybe_async">Fixing <code>maybe_async</code></h3><p>Once the crate started to gain popularity, this issue was opened in
<code>maybe_async</code>, which explains the situation and showcases a fix:</p><p><code>maybe_async</code> would now have two feature flags: <code>is_sync</code> and <code>is_async</code>. The
crate would generate the functions in the same way, but with a <code>_sync</code> or
<code>_async</code> suffix appended to the identifier so that they wouldn’t be conflicting.
For example:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[maybe_async::maybe_async]</span><span>
</span></span></span><span><span><span></span><span>async</span><span> </span><span>fn</span> <span>endpoint</span><span>()</span><span> </span><span>{</span><span> </span><span>/* stuff */</span><span> </span><span>}</span></span></span></code></pre></div><p>Would now generate the following code:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[cfg(feature = </span><span>"is_async"</span><span>)]</span><span>
</span></span></span><span><span><span></span><span>async</span><span> </span><span>fn</span> <span>endpoint_async</span><span>()</span><span> </span><span>{</span><span> </span><span>/* stuff */</span><span> </span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>#[cfg(feature = </span><span>"is_sync"</span><span>)]</span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>endpoint_sync</span><span>()</span><span> </span><span>{</span><span> </span><span>/* stuff with `.await` removed */</span><span> </span><span>}</span></span></span></code></pre></div><p>However, these suffixes introduce noise, so I wondered if it would be possible
to do it in a more ergonomic way. I forked <code>maybe_async</code> and gave it a try,
about which you can read more
<a href="https://github.com/fMeow/maybe-async-rs/issues/6#issuecomment-880581551">in this
series of comments</a>. In summary, it was too complicated, and I ultimately gave
up.</p><p>The only way to fix this edge case would be to worsen the usability of Rspotify
for everyone. But I’d argue that someone who depends on both async and sync is
unlikely; we haven’t actually had anyone complaining yet. Unlike <code>reqwest</code>,
<code>rspotify</code> is a “high level” library, so it’s hard to imagine a scenario where
it appears more than once in a dependency tree in the first place.</p><p>Perhaps we could ask the Cargo devs for help?</p></div><div><h3 id="_official_support">Official Support</h3><p>Rspotify is far from being the first who has been through this problem, so it
might be interesting to read previous discussions about it:</p><div><ul><li><p><a href="https://github.com/rust-lang/rfcs/pull/2962">This now-closed RFC for the Rust
compiler</a> suggested adding the <code>oneof</code> configuration predicate (think
<code>#[cfg(any(…​))]</code> and similars) to support exclusive features. This only
makes it easier to have conflicting features for cases where there’s <em>no
choice</em>, but features should still be strictly additive.</p></li><li><p>The previous RFC started
<a href="https://internals.rust-lang.org/t/pre-rfc-cargo-mutually-exclusive-features/13182/27">some
discussion</a> in the context of allowing exclusive features in Cargo itself, and
although it has some interesting info, it didn’t go too far.</p></li><li><p><a href="https://github.com/rust-lang/cargo/issues/2980">This issue in Cargo</a> explains a
similar case with the Windows API. The discussion includes more examples and
solution ideas, but none have made it to Cargo yet.</p></li><li><p><a href="https://github.com/rust-lang/cargo/issues/4803">Another issue in Cargo</a> asks
for a way to test and build with combinations of flags easily. If features are
strictly additive, then <code>cargo test --all-features</code> will cover everything. But
in case it doesn’t, the user has to run the command with multiple combinations
of feature flags, which is quite cumbersome. This is already possible
unofficially thanks to <a href="https://github.com/taiki-e/cargo-hack"><code>cargo-hack</code></a>.</p></li><li><p>A completely different approach
<a href="https://blog.rust-lang.org/inside-rust/2023/02/23/keyword-generics-progress-report-feb-2023.html">based
on the Keyword Generics Initiative</a>. It seems to be the most recent take on
solving this, but it’s in an “exploration” phase, and
<a href="https://blog.rust-lang.org/inside-rust/2022/07/27/keyword-generics.html#q-is-there-an-rfc-available-to-read">no
RFCs are available as of this writing</a>.</p></li></ul></div><p>According to
<a href="https://github.com/rust-lang/rfcs/pull/2962#issuecomment-664656377">this old
comment</a>, it’s not something the Rust team has already discarded; it’s still
being discussed.</p><p>Although unofficial, another interesting approach that could be explored further
in Rust is <a href="https://sans-io.readthedocs.io/">“Sans I/O”</a>. This is a Python
protocol that abstracts away the use of network protocols like HTTP in our case,
thus maximizing reusability. An existing example in Rust would be
<a href="https://github.com/EmbarkStudios/tame-oidc"><code>tame-oidc</code></a>.</p></div></div></div><div><h2 id="_conclusion">Conclusion</h2><div><p>We currently have a choice to make between:</p><div><ul><li><p>Ignoring the Cargo Reference. We could assume that noone is going to use both
sync and async for Rspotify at the same time.</p></li><li><p>Fixing <code>maybe_async</code> and adding <code>_async</code> and <code>_sync</code> suffixes to each endpoint
in our library.</p></li><li><p>Dropping support for both async and sync code. It’s kind of become a mess that
we don’t have the manpower to deal with and that
<a href="https://github.com/ramsayleung/rspotify/pull/224#issuecomment-909324671">affects
other parts of Rspotify</a>. The problem is that some crates that depend on
rspotify like <a href="https://github.com/hrkfdn/ncspot"><code>ncspot</code></a> or
<a href="https://github.com/Spotifyd/spotifyd"><code>spotifyd</code></a> are blocking, and others like
<a href="https://github.com/Rigellute/spotify-tui"><code>spotify-tui</code></a> use async, so I’m not
sure what they’d think.</p><p>I know this is a problem that I’ve imposed to myself. We could just say “No. We
only support async” or “No. We only support sync”. While there are users
interested in being able to use both, sometimes you just have to say no. If such
a feature becomes so complicated to deal with that your entire codebase becomes
a mess, and you don’t have the engineering power to maintain it, then it’s your
only choice. If someone cared enough, they could just fork the crate and convert
it to synchronous for their own usage.</p><p>After all, most API wrappers and the like only support either asynchronous or
blocking code. <a href="https://crates.io/crates/serenity"><code>serenity</code></a>
(Discord API), <a href="https://crates.io/crates/sqlx"><code>sqlx</code></a>
(SQL
toolkit) and <a href="https://crates.io/crates/teloxide"><code>teloxide</code></a>
(Telegram API) are async-only, for example,
and they’re quite popular.</p></li></ul></div><p>Even though it was quite frustrating at times, I don’t really regret spending so
much time walking in circles trying to get both async and sync to work. I was
contributing to Rspotify in the first place just to <em>learn</em>. I had no deadlines
and no stress, I just wanted to try to improve a library in Rust in my free
time. And I <em>have</em> learned a lot; hopefully you too, after reading this.</p><p>Perhaps the lesson today is that we should remember that Rust is a low level
language after all, and there are some things that aren’t possible without a lot
of complexity. Anyhow, I’m looking forward to how the Rust team fixes this in
the future.</p><p>So what do you think? What would you do if you were a maintainer of Rspotify?
You can leave a comment below if you like.</p></div></div><div><h2 id="_references">References</h2></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft actions following attack by nation state actor Midnight Blizzard (123 pts)]]></title>
            <link>https://msrc.microsoft.com/blog/2024/01/microsoft-actions-following-attack-by-nation-state-actor-midnight-blizzard/</link>
            <guid>39061800</guid>
            <pubDate>Fri, 19 Jan 2024 21:56:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://msrc.microsoft.com/blog/2024/01/microsoft-actions-following-attack-by-nation-state-actor-midnight-blizzard/">https://msrc.microsoft.com/blog/2024/01/microsoft-actions-following-attack-by-nation-state-actor-midnight-blizzard/</a>, See on <a href="https://news.ycombinator.com/item?id=39061800">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>The Microsoft security team detected a nation-state attack on our corporate systems on January 12, 2024, and immediately activated our response process to investigate, disrupt malicious activity, mitigate the attack, and deny the threat actor further access. Microsoft has identified the threat actor as <a href="https://www.microsoft.com/en-us/security/blog/tag/midnight-blizzard-nobelium/" target="_blank" rel="noopener">Midnight Blizzard</a>, the Russian state-sponsored actor also known as Nobelium. As part of our ongoing commitment to responsible transparency as recently affirmed in our <a href="https://blogs.microsoft.com/on-the-issues/2023/11/02/secure-future-initiative-sfi-cybersecurity-cyberattacks/" target="_blank" rel="noopener">Secure Future Initiative</a> (SFI), we are sharing this update. &nbsp;</p>
<p>Beginning in late November 2023, the threat actor used a password spray attack to compromise a legacy non-production test tenant account and gain a foothold, and then used the account’s permissions to access a very small percentage of Microsoft corporate email accounts, including members of our senior leadership team and employees in our cybersecurity, legal, and other functions, and exfiltrated some emails and attached documents. The investigation indicates they were initially targeting email accounts for information related to Midnight Blizzard itself. We are in the process of notifying employees whose email was accessed. &nbsp;</p>
<p>The attack was not the result of a vulnerability in Microsoft products or services. To date, there is no evidence that the threat actor had any access to customer environments, production systems, source code, or AI systems. We will notify customers if any action is required. &nbsp;</p>
<p>This attack does highlight the continued risk posed to all organizations from well-resourced nation-state threat actors like <a href="https://www.microsoft.com/en-us/security/blog/tag/midnight-blizzard-nobelium/" target="_blank" rel="noopener">Midnight Blizzard</a>. &nbsp;</p>
<p>As we said late last year when we announced <a href="https://blogs.microsoft.com/on-the-issues/2023/11/02/secure-future-initiative-sfi-cybersecurity-cyberattacks/" target="_blank" rel="noopener">Secure Future Initiative</a> (SFI), given the reality of threat actors that are resourced and funded by nation states, we are shifting the balance we need to strike between security and business risk – the traditional sort of calculus is simply no longer sufficient. For Microsoft, this incident has highlighted the urgent need to move even faster. We will act immediately to apply our current security standards to Microsoft-owned legacy systems and internal business processes, even when these changes might cause disruption to existing business processes. &nbsp;</p>
<p>This will likely cause some level of disruption while we adapt to this new reality, but this is a necessary step, and only the first of several we will be taking to embrace this philosophy. &nbsp;</p>
<p>We are continuing our investigation and will take additional actions based on the outcomes of this investigation and will continue working with law enforcement and appropriate regulators. We are deeply committed to sharing more information and our learnings, so that the community can benefit from both our experience and observations about the threat actor. We will provide additional details as appropriate.</p>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Platform Tilt (146 pts)]]></title>
            <link>https://mozilla.github.io/platform-tilt/</link>
            <guid>39061587</guid>
            <pubDate>Fri, 19 Jan 2024 21:41:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mozilla.github.io/platform-tilt/">https://mozilla.github.io/platform-tilt/</a>, See on <a href="https://news.ycombinator.com/item?id=39061587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><img src="https://mozilla.github.io/platform-tilt/static/Mozilla.svg" alt="Mozilla">
        </p>
        
        <p>
          This dashboard tracks technical issues in major software platforms
          which disadvantage Firefox relative to the first-party browser. We
          consider aspects like security, stability, performance, and
          functionality, and propose changes to create a more level playing
          field.
        </p>
        <p>
          Further discussion on the live issues can be found in our
          <a href="https://github.com/mozilla/platform-tilt/">platform-tilt issue tracker</a>.
        </p>
      </div><div>
        <table id="issues_apple">
          <caption>
            Vendor:
            <b>apple</b>
          </caption>
          <thead>
            <tr>
              <th>Issue</th>
              <th>Status</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>
                <details id="issue_1">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/1">App Store forbids third-party browser engines</a><a href="#issue_1" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      <a href="https://developer.apple.com/app-store/review/guidelines/#software-requirements">Rule 2.5.6</a>
                      of the Apple App Store Review Guidelines forbids the usage
                      of third-party browser engines:
                    </p>
                    <blockquote>
                      <p>
                        2.5.6 Apps that browse the web must use the appropriate
                        WebKit framework and WebKit JavaScript
                      </p>
                    </blockquote>
                    <p>
                      Notably, this means that Firefox can’t be shipped with
                      Gecko on iOS. It also means that Firefox can’t be
                      distributed in the App Store on other Apple platforms like
                      macOS. The App Store policy should be updated to allow
                      third-party browser engines for web browsers.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_2">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/2">Support for third-party multi-process applications on
                      iOS</a><a href="#issue_2" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      All modern web browsers employ a multi-process
                      architecture where a single browser application is
                      implemented as a collection of operating system processes
                      with one main process that spawns child processes. This
                      generally involves loading each site in a separate
                      process, and moving certain sensitive functionality (e.g.,
                      GPU usage) into a dedicated process. This design allows
                      the browser to be more resilient against crashes, more
                      responsive under load, more secure against malicious
                      exploits, and less susceptible to information leaks like
                      Spectre. Most applications don’t need this level of
                      granular isolation, but for browsers — which load
                      interactive content from many different origins — it’s a
                      table-stakes requirement.
                    </p>
                    <p>
                      On iOS, Safari uses a multi-process architecture. However,
                      it does so with a proprietary mechanism that is not
                      available to third-party applications unless they use
                      Safari’s WebKit engine. To support third-party browser
                      engines, iOS should provide a mechanism to create and
                      efficiently communicate with isolated child processes.
                    </p>
                    <p>Some basic requirements:</p>
                    <ul>
                      <li>
                        The number of child processes and their duration are
                        dictated by user browsing behavior and should not be
                        fixed outside of reasonable device constraints.
                      </li>
                      <li>
                        The child process should be configurable with tightly
                        controlled privileges while permitting inter-process
                        communication using messaging and shared memory.
                      </li>
                      <li>
                        The parent process must be able to establish shared
                        memory mappings with child processes and vice versa.
                        Child processes must be able to communicate with each
                        other in the same way.
                      </li>
                      <li>
                        Access to shared memory regions should be configurable
                        as read/write or read-only per region.
                      </li>
                      <li>
                        For optimal security, child processes’
                        entitlements/privileges should be configured
                        independently from the parent process and the parent
                        process should be able to create child processes of
                        different types using different executables.
                      </li>
                      <li>
                        Child processes should be able to load libraries from
                        the bundle that are shared with the parent process.
                      </li>
                      <li>
                        To support isolating GPU access to a GPU process, child
                        processes should be able to use Metal or OpenGL (when
                        configured as such) to render into an IOSurface. Child
                        processes should be able to share IOSurfaces across
                        processes.
                      </li>
                    </ul>
                    <p>
                      Firefox uses a shared codebase across different operating
                      systems with platform-specific adapters for functionality
                      like process management. Some quirks may be inevitable,
                      but it’s important that the interface and behavior be
                      broadly similar to other platforms like macOS and Android
                      so as to avoid systematically breaking assumptions in
                      overall browser architecture and platform-specific code.
                      Something shaped like posix_spawn would be a reasonable
                      starting point.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_3">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/3">JIT Support on iOS</a><a href="#issue_3" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      In order to ship a performant JavaScript/WebAssembly
                      engine, a necessary component of a modern web browser, it
                      must be possible for browser processes to create memory
                      regions that are both writable and executable. However,
                      applications on iOS are prevented from creating such
                      memory regions because the system call used to configure
                      memory region permissions (<code>mmap(2)</code>) does not
                      allow it.
                    </p>
                    <p>
                      This is sound default behavior that improves security in
                      general, but web browsers need this capability. As
                      evidence, an exception is made for Safari’s WebKit
                      rendering engine on iOS, allowing writable and executable
                      memory regions to be created.
                    </p>
                    <p>
                      The same general security mitigation is employed on macOS,
                      but on macOS applications like web browsers can opt-out by
                      using entitlements. To allow these memory regions for
                      non-WebKit browsers on iOS, iOS should allow an equivalent
                      entitlement to the macOS Hardened Runtime entitlement
                      <a href="https://developer.apple.com/documentation/bundleresources/entitlements/com_apple_security_cs_allow-jit">com.apple.security.cs.allow-jit</a>
                      (which permits use of the <code>mmap(2)</code> system call
                      using the <code>MAP_JIT</code> flag) and include its
                      <a href="https://developer.apple.com/documentation/apple-silicon/porting-just-in-time-compilers-to-apple-silicon">accompanying APIs pthread_jit_write_protect_np and
                        sys_icache_invalidate</a>. These APIs are already in iOS, but only Safari and
                      other Apple applications are permitted to use them.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_4">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/4">Accessibility APIs on iOS</a><a href="#issue_4" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      The iOS
                      <a href="https://developer.apple.com/documentation/uikit/accessibility_for_uikit?language=objc">accessibility API documentation</a>
                      is incomplete, and many APIs that are needed for a web
                      browser to support accessibility web standards are
                      undocumented. Further, it’s difficult to infer how to use
                      them based on WebKit’s open source implementation because
                      there appears to be a closed-source system bundle which is
                      tailored for and loaded into WebKit at runtime.
                    </p>
                    <p>
                      This lack of visibility makes it difficult to enumerate a
                      full list of gaps. There are many closed-source methods
                      loaded at runtime, and we don’t have visibility into their
                      full signature or how they are used. Here are a couple
                      examples that we know of:
                    </p>
                    <ol>
                      <li>
                        While some
                        <a href="https://developer.apple.com/documentation/uikit/uiaccessibilitytraits?language=objc">trait integer constants are public</a>, others needed for a web engine like “visited”, or
                        “radio button” are not.
                      </li>
                      <li>
                        While some
                        <a href="https://developer.apple.com/documentation/uikit/accessibility_for_uikit/notification_names?language=objc">notification type integer constants are public</a>, others needed for a web engine, like “value changed”
                        are not. The closed-source bundle has a method loaded at
                        runtime into the WebKit wrapper named
                        <code>accessibilityOverrideProcessNotification</code>.
                        It takes a string, such as
                        <code>AXValueChanged</code> or
                        <code>AXSelectedTextChanged</code>, internally maps it
                        to a private integer constant representing the
                        notification type, and forwards it to the platform via
                        <code>UIAccessibilityPostNotification</code>.
                      </li>
                    </ol>
                    <p>
                      Supporting accessibility web standards is table stakes
                      functionality for a web browser. In order to do this, all
                      of the accessibility APIs used by WebKit must be
                      documented and stable, and WebKit should ideally consume
                      them in the same manner as third-party browser engines.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_5">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/5">Messages integration on iOS</a><a href="#issue_5" title="Permalink to this issue">#</a>
                  </summary>
                  <p>
                      In Safari on iOS, the home page includes a convenience
                      feature where
                      <a href="https://support.apple.com/guide/iphone/find-links-shared-with-you-iph25424a81d/ios">links that were recently received in the Message app
                        are shown</a>
                      along with the contact that sent them. Third-party
                      browsers cannot offer the same functionality because they
                      don't have access to Messages data. iOS should expose an
                      API to third-party browsers so they can implement their
                      own features using Message links similar to Safari.
                    </p>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_6">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/6">Importing browser data on iOS</a><a href="#issue_6" title="Permalink to this issue">#</a>
                  </summary>
                  <p>
                      Browsing information like history, bookmarked sites, and
                      cookies isn’t accessible to third-party browsers on iOS,
                      and there’s no API to allow this data to be imported.
                      While this is sensitive data, similar import functionality
                      is possible on all major desktop platforms, and iOS is
                      able to mediate access to other sensitive data with user
                      consent (e.g.,
                      <a href="https://support.apple.com/guide/iphone/share-your-health-data-iph5ede58c3d/ios">health and fitness data</a>). Not being able to import data creates significant
                      friction to change from Safari - a user should be allowed
                      to bring their data with them to another browser.
                    </p>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_9">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/9">Setting and checking default browser on iOS</a><a href="#issue_9" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      Allowing a third-party browser to programmatically set
                      itself as the default is an important platform feature.
                      Without this, even after the user has installed the
                      browser of their choice they must navigate operating
                      system settings and make the choice there as well. This
                      adds friction and creates inertia to continue using
                      Safari, despite the user's preference.
                    </p>
                    <p>
                      A well-established design pattern is to allow the
                      third-party browser to invoke a system prompt which
                      permits the user to easily confirm or reject the request
                      to set the current browser as the default. This is an
                      intuitive user experience that mirrors similar permissions
                      models used in operating systems, browsers, and web
                      applications. Android and macOS offer such a capability
                      (on Android by requesting to hold the
                      <a href="https://developer.android.com/reference/android/app/role/RoleManager#ROLE_BROWSER">browser role</a>
                      and on macOS using
                      <a href="https://developer.apple.com/documentation/coreservices/1447760-lssetdefaulthandlerforurlscheme">LSSetDefaultHandlerForURLScheme</a>/<a href="https://developer.apple.com/documentation/coreservices/1444955-lssetdefaultrolehandlerforconten">LSSetDefaultRoleHandlerForContentType</a>).
                    </p>
                    <p>
                      Unfortunately, iOS does not support anything like this for
                      third-party browsers: browsers are forced to “deep link”
                      into the iOS settings UI, at which point the user must
                      understand the UI and make the change on their own. For
                      users that try to find the setting themselves, when using
                      the search feature in the iOS Settings app, no results are
                      returned for “Default browser app” (the text identifying
                      the default browser elsewhere in the iOS Settings app) nor
                      "Default" (which matches several other default
                      applications in the iOS Settings app) -- see
                      <a href="#screenshots">screenshots</a>. iOS should instead
                      provide a method for third-party browsers to
                      programmatically request they be set as the default.
                    </p>
                    <p>
                      Furthermore, a third-party browser cannot even detect if
                      it currently is the default browser on iOS. This prevents
                      them from understanding how their browser is used and
                      limits their ability to optimize the browser based on user
                      intent. This also makes it impossible to identify the
                      conditions in which it would be appropriate to ask the
                      user if they’d like to change their default since the
                      browser should only prompt in cases where it’s not
                      currently the default. iOS should provide a method for
                      third-party browsers to programmatically detect if they
                      are the default browser, as exists on all other major
                      platforms.
                    </p>
                    <h4>Screenshots</h4>
                    <p>
                      Screenshots from iOS 17.2.1 which depict that searching
                      Settings for “Default browser app” and “Default” do not
                      show results for changing the default browser.
                    </p>
                    <p>
                      <img src="https://github.com/mozilla/platform-tilt/assets/1097182/d55922c7-18c4-4b1c-9e9a-1533d788207d" width="300">
                      <img src="https://github.com/mozilla/platform-tilt/assets/1097182/69b33d48-89a6-478f-b21f-9b8dff72e2fa" width="300">
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_11">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/11">Origin-Based Associated Domains dependent features for
                      third-party browser engines on iOS</a><a href="#issue_11" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      In order to support features such as
                      <a href="https://developer.apple.com/documentation/security/password_autofill">password autofill</a>,
                      <a href="https://developer.apple.com/documentation/security/one-time_codes">one-time codes</a>,
                      <a href="https://developer.apple.com/documentation/authenticationservices/public-private_key_authentication/supporting_passkeys">passkeys</a>, and
                      <a href="https://developer.apple.com/documentation/passkit/apple_pay/">Apple Pay</a>, non-WebKit browsers must be able to specify an
                      <a href="https://developer.apple.com/documentation/xcode/supporting-associated-domains">associated domain</a>
                      based on the web-content origin when using their APIs.
                      WebKit-based browsers override the browser application’s
                      associated domain (e.g., mozilla.com for Firefox) to be
                      able to perform password autofill for the domain the user
                      is browsing.
                    </p>
                    <p>
                      Non-WebKit browsers must also have this capability. For
                      example, when a user is entering a password on a text
                      field on site example.com, the browser should be able to
                      indicate the password field corresponds to origin
                      example.com so that the password manager can be invoked
                      with a scope of example.com.
                    </p>
                    <p>
                      The intent of this issue is to cover the functionality
                      needed for non-WebKit browsers to support these features
                      using OS support available to Safari. Origin-based
                      associated domains underpins this support, but additional
                      functionality may need to be made available to non-WebKit
                      browsers as well. For example, supporting Apple Pay may
                      require additional changes so that third-party browsers
                      are not bound by associated merchant identifiers and can
                      accept payments for any registered Apple Pay payee like
                      Safari.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_15">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/15">Browser extension support on iOS</a><a href="#issue_15" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      Browser extensions are a key part of the web ecosystem and
                      most popular browsers support them. Browser extensions
                      allow developers to add functionality to the browser
                      providing increased utility, usability, and
                      interoperability with applications installed on the
                      system.
                    </p>
                    <p>
                      For distribution, popular browsers have established
                      extension catalogs that are available on the open web and
                      curated by the browser vendors. Because extensions have
                      elevated privileges, developers submit them to be approved
                      to ensure safety and compatibility. Browser vendors make
                      their own decisions about the APIs available to
                      extensions. Extensions for each browser are installed and
                      managed within the browser resulting in a common user
                      experience across platforms.
                    </p>
                    <p>
                      <a href="https://developer.apple.com/safari/extensions/">Safari supports extensions</a>
                      distributed on the iOS App Store. However, third party
                      browsers are prevented from offering their own established
                      extension functionality because it would violate section
                      2.5.2 of the
                      <a href="https://developer.apple.com/app-store/review/guidelines/#software-requirements">App Store Review Guidelines</a>. To allow third-party browsers to offer the same
                      functionality and be competitive with respect to browser
                      extensibility, the App Store software requirements should
                      be relaxed to permit third-party browsers to use their own
                      extension catalogs. Third-party browsers could then use
                      the existing web-based distribution model (where users can
                      browse and install extensions directly from the browser)
                      allowing for browser extensions to be used on iOS,
                      similarly to other mobile and desktop platforms.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_16">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/16">Beta testing on iOS</a><a href="#issue_16" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      Beta testing is a critical part of the web browser release
                      cycle which, for popular browsers, results in new major
                      versions shipping at a monthly cadence. Browser stability
                      and quality is dependent on a large and active beta
                      testing audience. Due to the dynamic nature and enormous
                      size of the web platform, new web APIs are frequently
                      added and adopted by web sites, and new features and fixes
                      are continuously developed. As a result, many problems are
                      discovered and fixed in the beta phase which enables the
                      vast majority of users to have a smoother experience.
                    </p>
                    <p>
                      On other platforms, separate Beta and Nightly builds can
                      be distributed using the typical platform affordances. On
                      iOS, beta versions of applications are not permitted on
                      the App Store and instead are distributed through a
                      separate
                      <a href="https://developer.apple.com/testflight">TestFlight</a>
                      system. This has a few issues:
                    </p>
                    <p>
                      TestFlight has a 10,000 user limit, which is a tiny
                      fraction of the beta population for web browsers with
                      large user bases. The limitation becomes a maintenance
                      burden for browser developers: when reaching the limit,
                      old users must be manually removed from the list. The user
                      experience for prerelease testers is more complicated than
                      on other platforms: users must download the separate
                      TestFlight application, sign up for an access code, wait
                      to receive it, and then paste it into the application.
                      Distributing with a public link is not feasible because of
                      the user limit restriction.
                    </p>
                    <p>
                      This may be solved by allowing browsers to distribute
                      prerelease builds in the App Store, or by making changes
                      to Test Flight (removing the user limit entirely and
                      allowing unlimited distribution from a public link without
                      manual management). In any case, prerelease testing should
                      not create more friction than exists for Safari: new
                      versions of the Safari web browser are included in beta
                      versions of the iOS operating system and do not face the
                      same restrictions.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
          </tbody>
        </table>
        <table id="issues_google">
          <caption>
            Vendor:
            <b>google</b>
          </caption>
          <thead>
            <tr>
              <th>Issue</th>
              <th>Status</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>
                <details id="issue_7">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/7">Importing browser data on Android</a><a href="#issue_7" title="Permalink to this issue">#</a>
                  </summary>
                  <p>
                      Browsing information like history, bookmarked sites, and
                      cookies isn’t accessible to third-party browsers on
                      Android. This data is kept within a web browser
                      application’s
                      <a href="https://developer.android.com/training/data-storage/app-specific#internal">data directory</a>, which isn’t directly accessible to third-party
                      browsers, and there’s no API or
                      <a href="https://developer.android.com/guide/topics/providers/content-provider-basics">ContentProvider</a>
                      to enable it to be imported. While this is sensitive data,
                      similar import functionality is possible on all major
                      desktop platforms, and Android is able to mediate access
                      to other sensitive data with user consent. Not being able
                      to import data creates significant friction to change from
                      Chrome - a user should be allowed to bring their data with
                      them to another browser.
                    </p>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_8">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/8">Some Android features launch Chrome instead of the user’s
                      default browser</a><a href="#issue_8" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      Features like Google Search, or Discover, in the
                      pre-installed
                      <a href="https://play.google.com/store/apps/details?id=com.google.android.googlequicksearchbox">Google application</a>
                      ignore the user’s default browser choice: links to
                      websites outside of the application are always opened in
                      Chrome, regardless of the default browser. This is a
                      widely used application, with additional entry points from
                      built-in features such as the search bar on the home
                      screen and app launcher. Each time it opens a link in
                      Chrome, a user is driven away from their default browser.
                    </p>
                    <p>
                      All built-in applications and affordances that open
                      external links should open them in the user’s default
                      browser.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_12">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/12">Lower quality search result pages in third-party browser
                      engines on Android</a><a href="#issue_12" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      The web search experience is tightly integrated with a
                      number of built-in features in Android (see
                      https://github.com/mozilla/platform-tilt/issues/8), and
                      the experience provided to Firefox is inferior compared to
                      the version provided for Chrome. As seen in the
                      screenshots below, identical search terms show less
                      information and receive a lower quality design in Firefox
                      on Android.
                    </p>
                    <p>
                      While strictly speaking this is an issue with the Google
                      Search website, given the prominence and integration of
                      search on Android this is a meaningful user experience gap
                      that creates an incentive for users to not choose a
                      third-party browser - especially those implemented with
                      third-party browser engines, like Firefox. There are no
                      technical limitations which would prevent this page from
                      operating in Firefox: an equal experience should be
                      offered.
                    </p>
                    <table>
                      <thead>
                        <tr>
                          <th>Chrome</th>
                          <th>Firefox</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td>
                            <img src="https://github.com/mozilla/platform-tilt/assets/95570/eea51f92-45d3-4b48-aed1-ac8e8250fd5e" width="300">
                          </td>
                          <td>
                            <img src="https://github.com/mozilla/platform-tilt/assets/95570/43590042-bb59-43c8-97f5-42fc2610101d" width="300">
                          </td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
          </tbody>
        </table>
        <table id="issues_microsoft">
          <caption>
            Vendor:
            <b>microsoft</b>
          </caption>
          <thead>
            <tr>
              <th>Issue</th>
              <th>Status</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>
                <details id="issue_10">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/10">Setting default browser on Windows</a><a href="#issue_10" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      Allowing a third-party browser to programmatically set
                      itself as the default is an important platform feature.
                      Without this, even after the user has installed the
                      browser of their choice they must navigate operating
                      system settings and make the choice there as well. This
                      adds friction and creates inertia to continue using Edge,
                      despite the user's preference.
                    </p>
                    <p>
                      A well-established design pattern is to allow the
                      third-party browser to invoke a system prompt which
                      permits the user to easily confirm or reject the request
                      to set the current browser as the default. This is an
                      intuitive user experience that mirrors similar permissions
                      models used in operating systems, browsers, and web
                      applications. Android and macOS offer such a capability
                      (on Android by requesting to hold the
                      <a href="https://developer.android.com/reference/android/app/role/RoleManager#ROLE_BROWSER">browser role</a>
                      and on macOS using
                      <a href="https://developer.apple.com/documentation/coreservices/1447760-lssetdefaulthandlerforurlscheme">LSSetDefaultHandlerForURLScheme</a>/<a href="https://developer.apple.com/documentation/coreservices/1444955-lssetdefaultrolehandlerforconten">LSSetDefaultRoleHandlerForContentType</a>).
                    </p>
                    <p>
                      Unfortunately, Windows does not support anything like this
                      for third-party browsers: browsers are forced to “deep
                      link” into the Windows settings UI. On Windows 10 this
                      requires several clicks and a double confirmation in the
                      settings UI. On Windows 11 there is a “Set default”
                      button. Neither is sufficient. Windows should instead
                      provide a method for third-party browsers to
                      programmatically request they be set as the default.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_13">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/13">Default browser is set to Edge by several Windows
                      flows</a><a href="#issue_13" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      In general, the Windows 10 and 11 operating systems have
                      persistent messaging that Microsoft Edge is the
                      “recommended” browser for Windows, and offer affordances
                      to change the default browser to Edge. In some cases the
                      wording is misleading, asking a user to adopt “recommended
                      browser settings”, which does not obviously suggest a
                      default browser change. This messaging is a moving target,
                      with examples added and removed from Windows over time,
                      often on UI surfaces that appear automatically on update
                      or otherwise, making it difficult to enumerate specific
                      examples.
                    </p>
                    <p>
                      In all cases these Windows components are able to change
                      the user’s default browser directly, and are not forced to
                      use the <code>ms-settings:</code> protocol deep linking
                      that browsers are required to use (see
                      <a href="https://github.com/mozilla/platform-tilt/issues/10">issue #10</a>). Windows should consume the same affordances and APIs
                      that are available to third-party browsers for
                      setting-to-default.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
            <tr>
              <td>
                <details id="issue_14">
                  <summary>
                    <a href="https://github.com/mozilla/platform-tilt/issues/14">Some Windows features launch Edge instead of the user’s
                      default browser</a><a href="#issue_14" title="Permalink to this issue">#</a>
                  </summary>
                  <div>
                    <p>
                      There are at least three prominent Windows features that
                      open URLs in Microsoft Edge and not in the current default
                      browser. The user’s default browser choice should be
                      respected when web pages are opened by built-in operating
                      system features.
                    </p>
                    <p>
                      The first is Windows Search, also known as Start Menu
                      Search, and formerly known as Cortana. The UI for this
                      feature is represented by a taskbar search box or search
                      button (depending on user settings), and a search
                      suggestions / results UI that appears when activated and
                      updates as the user types. The suggestions and results UI
                      also appears if the user starts typing when the start menu
                      is open, and by the WIN+S hotkey. All links from this UI,
                      whether they initiate web searches or link directly to
                      articles or results, open in Microsoft Edge regardless of
                      the user’s default browser.
                    </p>
                    <p>
                      The second is the new Windows Copilot, currently only
                      available on Windows 11, which appears as a docked window
                      on the right side of the screen. If Copilot produces links
                      in its responses, or offers other links within its
                      rendering area, these links open in Microsoft Edge
                      regardless of the user’s default browser.
                    </p>
                    <p>
                      The third are Windows “widgets” which are called “news and
                      interests” on Windows 10, a UI surface area which can be
                      activated by a taskbar button. These show information like
                      news, weather, stocks, and sports scores. On Windows 11
                      new widgets can be added from 3rd parties. Regardless, all
                      links to a web page from widgets will open in Microsoft
                      Edge regardless of the user’s default browser.
                    </p>
                  </div>
                </details>
              </td>
              <td>open</td>
            </tr>
          </tbody>
        </table>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP's CEO spells it out: You're a 'bad investment' if you don't buy HP supplies (101 pts)]]></title>
            <link>https://www.theregister.com/2024/01/19/hps_ceo_spells_it_out/</link>
            <guid>39060793</guid>
            <pubDate>Fri, 19 Jan 2024 20:37:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/01/19/hps_ceo_spells_it_out/">https://www.theregister.com/2024/01/19/hps_ceo_spells_it_out/</a>, See on <a href="https://news.ycombinator.com/item?id=39060793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>HP CEO Enrique Lores admitted this week that the company's long-term objective is "to make printing a subscription" when he was questioned about the company's approach to third-party replacement ink suppliers.</p>
<p>The PC and print biz is currently facing a <a target="_blank" href="https://www.theregister.com/2024/01/09/hp_class_action_ink/">class-action lawsuit</a> (from 2.42 in the video below) regarding allegations that the company deliberately prevented its hardware from accepting non-HP branded replacement cartridges via a firmware update.</p>
<p>When asked about the case in a <a target="_blank" rel="nofollow" href="https://youtu.be/QPRMyQSZGuY?feature=shared">CNBC interview</a>, Lores said: "I think for us it is important for us to protect our IP. There is a lot of IP that we've built in the inks of the printers, in the printers themselves. And what we are doing is when we identify cartridges that are violating our IP, we stop the printers from work[ing]."</p>

    

<p>
  <a href="https://www.youtube.com/watch?v=QPRMyQSZGuY" data-media="x-videoplayer">Youtube Video</a>
</p>

        


        

<p>Later in the interview, he added: "Every time a customer buys a printer, it's an investment for us. We are investing in that customer, and if that customer doesn't print enough or doesn't use our supplies, it's a bad investment."</p>
<p>Readers with long memories might remember <a target="_blank" href="https://www.theregister.com/2019/10/09/hp_supplies/">HP's strategy</a> switch to hike hardware prices upfront for models that don't come loaded with HP ink, although HP would still prefer customers buy its supplies.</p>

        

<p>Lores said of customers who use a third-party cartridge: "In many cases, it can create all sorts of issues from the printer stopping working because the ink has not been designed to be used in our printer, to even creat[ing] security issues.</p>
<p>"We have seen that you can embed viruses into cartridges, through the cartridge go to the printer, from the printer go to the network, so it can create many more problems for customers."</p>
<ul>

<li><a target="_blank" href="https://www.theregister.com/2019/10/09/hp_supplies/"></a><a target="_blank" href="https://www.theregister.com/2019/10/09/hp_supplies/"></a><a href="https://www.theregister.com/2024/01/09/hp_class_action_ink/">HP customers claim firmware update rendered third-party ink verboten</a></li>

<li><a href="https://www.theregister.com/2023/09/15/hp_reveals_bonkers_5k_foldable/">HP reveals bonkers $5k foldable tablet/laptop/desktop</a></li>

<li><a href="https://www.theregister.com/2022/11/23/hp_inc_q4_2022/">HP Inc to lay off up to 6,000 staff, cut costs by $1.4 billion</a></li>

<li><a href="https://www.theregister.com/2022/10/24/hp_lores_3d_printing_not_met_hype/">Don't believe the hype: HP CEO says 3D printing hasn't met early hopes</a></li>
</ul>
<p>HP has long <a target="_blank" rel="nofollow" href="https://h20195.www2.hp.com/V2/getpdf.aspx/4AA7-9396ENW">banged the drum</a> [PDF] about the potential for malware to be introduced via print cartridges, and in 2022, its bug bounty program <a target="_blank" rel="nofollow" href="https://www.action-intell.com/2022/10/05/hp-bug-bounty-program-finds-reprogrammable-chips-open-printers-to-malware/">confirmed</a> that third-party cartridges with reprogrammable chips could deliver malware into printers.</p>
<p>Kind old HP is, therefore, only concerned about the welfare of customers.</p>
<p>Sadly, Lores's protestations were somewhat undermined by the admission that the company's business model depends – at least in part – on customers selecting HP supplies for their devices.</p>

        

<p>"Our objective is to make printing as easy as possible, and our long-term objective is to make printing a subscription."</p>
<p>This echoes comments by former CFO Marie Myers, who <a target="_blank" href="https://www.theregister.com/2023/12/04/hp_printer_lockin/">said</a> in December:</p>
<p>"We absolutely see when you move a customer from that pure transactional model ... whether it's Instant Ink, plus adding on that paper, we sort of see a 20 percent uplift on the value of that customer because you're locking that person, committing to a longer-term relationship." ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US government opens 22M acres of federal lands to solar (171 pts)]]></title>
            <link>https://electrek.co/2024/01/18/us-govt-opens-22-million-acres-federal-lands-solar/</link>
            <guid>39060601</guid>
            <pubDate>Fri, 19 Jan 2024 20:24:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2024/01/18/us-govt-opens-22-million-acres-federal-lands-solar/">https://electrek.co/2024/01/18/us-govt-opens-22-million-acres-federal-lands-solar/</a>, See on <a href="https://news.ycombinator.com/item?id=39060601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://electrek.co/wp-content/uploads/sites/3/2022/04/BLM-solar.jpg?quality=82&amp;strip=all&amp;w=1200" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/BLM-solar.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/BLM-solar.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/BLM-solar.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/BLM-solar.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1200" height="630" alt="federal lands solar" fetchpriority="high">
	
				<figcaption>
				Photo: BLM			</figcaption>
			</figure>

<p>The Biden administration has updated the roadmap for solar development to 22 million acres of federal lands in the US West. </p>



<p>The Bureau of Land Management (BLM) and the Department of Energy’s National Renewable Energy Laboratory have determined that 700,000 acres of federal lands will be needed for solar farms over the next 20 years, so BLM recommended 22 million acres to give “maximum flexibility” to help the US reach its net zero by 2035 power sector goal.</p>



<p>The plan is an update of the Bureau of Land Management’s <a href="https://www.doi.gov/news/pressreleases/Obama-Administration-Approves-Roadmap-for-Utility-Scale-Solar-Energy-Development-on-Public-Lands">&nbsp;2012 Western Solar Plan</a>, which originally identified areas for solar development in six states – Arizona, California, Colorado, Nevada, New Mexico, and Utah. </p>



<p>The updated roadmap refines the analysis in the original six states and expands to five more states – Idaho, Montana, Oregon, Washington, and Wyoming. It also focuses on lands within 10 miles of existing or planned transmission lines and moves away from lands with sensitive resources.</p>



<p>Ben Norris, vice president of regulatory affairs at the Solar Energy Industries Association (<a href="https://www.seia.org/">SEIA</a>), said in response to BLM’s announced Western Solar Plan updates:</p>



<blockquote>
<p>The proposal … identifies 200,000 acres of land near transmission infrastructure, helping to correct an important oversight and streamline solar&nbsp;development.</p>



<p>Under the current policy, there are at least 80 million acres of federal lands open to oil and gas development, which is 100 times the amount of public land available for solar. BLM’s proposal is a big step in the right direction and recognizes the key role solar plays in our energy&nbsp;economy.</p>
</blockquote>




	<p>BLM under the Biden administration has approved 47 clean energy projects and permitted 11,236 megawatts (MW) of wind, solar, and geothermal energy on public lands, enough to power more than 3.5 million homes.</p>



<p><strong>Read more:</strong> <a href="https://electrek.co/2024/01/12/ohio-largest-solar-farm-just-came-online/">Ohio’s largest solar farm just came online</a></p>



<hr>



<p><em>If you live in an area that has frequent natural disaster events, and are interested in making your home more resilient to power outages, consider going solar and adding a battery storage system. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out </em><a href="https://www.energysage.com/p/electrek-rsm-ml/"><em>EnergySage</em></a><em>, a free service that makes it easy for you to go solar. They have hundreds of pre-vetted solar installers competing for your business, ensuring you get high quality solutions and save 20-30% compared to going it alone. Plus, it’s free to use and you won’t get sales calls until you select an installer and share your phone number with them.</em></p>



<p><em>Your personalized solar quotes are easy to compare online and you’ll get access to unbiased Energy Advisers to help you every step of the way. Get started </em><a href="https://www.energysage.com/p/electrek-rsm-ml/"><em>here</em></a><em>. –ad*</em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ceph: A Journey to 1 TiB/s (238 pts)]]></title>
            <link>https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/</link>
            <guid>39060339</guid>
            <pubDate>Fri, 19 Jan 2024 20:02:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/">https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/</a>, See on <a href="https://news.ycombinator.com/item?id=39060339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em><strong>I can't believe they figured it out first.</strong></em> That was the thought going through my head back in mid-December after several weeks of 12-hour days debugging why this cluster was slow. This was probably the most intense performance analysis I'd done since Inktank. Half-forgotten superstitions from the 90s about appeasing SCSI gods flitted through my consciousness. The 90s? Man, I'm getting old. We were about two-thirds of the way through the work that would let us start over at the beginning. Speaking of which, I'll start over at the beginning.</p><p>Back in 2023 (I almost said earlier this year until I remembered we're in 2024), Clyso was approached by a fairly hip and cutting edge company that wanted to transition their HDD backed Ceph cluster to a 10 petabyte NVMe deployment. They were immediately interesting. They had no specific need for RBD, RGW, or CephFS. They had put together their own hardware design, but to my delight approached us for feedback before actually purchasing anything. They had slightly unusual requirements. The cluster had to be spread across 17 racks with 4U of space available in each. Power, cooling, density, and vendor preference were all factors. The new nodes needed to be migrated into the existing cluster with no service interruption. The network however was already built, and it's a <em>beast</em>. It's one of the fastest Ethernet setups I've ever seen. I knew from the beginning that I wanted to help them build this cluster. I also knew we'd need to do a pre-production burn-in and that it would be the perfect opportunity to showcase what Ceph can do on a system like this. What follows is the story of how we built and tested that cluster and how far we were able to push it.</p><h2>Acknowledgments</h2><p>I would first like to thank our amazing customer who made all of this possible. You were a pleasure to work with! Thank you as well for allowing us here at <a href="https://www.clyso.com/">Clyso</a> to share this experience with the Ceph community. It is through this sharing of knowledge that we make the world a better place. Thank you to <a href="https://ibm.com/">IBM</a>/<a href="https://redhat.com/">Red Hat</a> and <a href="https://samsung.com/">Samsung</a> for providing the Ceph community with the hardware used for comparison testing. It was invaluable to be able to evaluate the numbers we were getting against previous tests from the lab. Thank you to all of the Ceph contributors who have worked tirelessly to make Ceph great! Finally, thank you especially to Anthony D'Atri and Lee-Ann Pullar for their amazing copyediting skills!</p><h2>Cluster Setup</h2><p>When the customer first approached Clyso, they proposed a configuration utilizing 34 dual-socket 2U nodes spread across 17 racks. We provided a couple of alternative configurations from multiple vendors with a focus on smaller nodes. Ultimately they decided to go with a Dell architecture we designed, which quoted at roughly 13% cheaper than the original configuration despite having several key advantages. The new configuration has less memory per OSD (still comfortably 12GiB each), but faster memory throughput. It also provides more aggregate CPU resources, significantly more aggregate network throughput, a simpler single-socket configuration, and utilizes the newest generation of AMD processors and DDR5 RAM. By employing smaller nodes, we halved the impact of a node failure on cluster recovery.</p><p>The customer indicated they would like to limit the added per-rack power consumption to around 1000-1500 watts. With 4 of these nodes per rack, the aggregate TDP is estimated to be at least 1120 Watts plus base power usage, CPU overage peaks, and power supply inefficiency. IE it's likely we're pushing it a bit under load, but we don't expect significant deviation beyond the acceptable range. If worse came to worst, we estimated we could shave off roughly 100 watts per rack by lowering the processor cTDP.</p><p>Specs for the system are shown below:</p><table><thead><tr><th>Nodes</th><th>68 x Dell PowerEdge R6615</th></tr></thead><tbody><tr><td>CPU</td><td>1 x AMD EPYC 9454P 48C/96T</td></tr><tr><td>Memory</td><td>192GiB DDR5</td></tr><tr><td>Network</td><td>2 x 100GbE Mellanox ConnectX-6</td></tr><tr><td>NVMe</td><td>10 x Dell 15.36TB Enterprise NVMe Read Intensive AG</td></tr><tr><td>OS Version</td><td>Ubuntu 20.04.6 (Focal)</td></tr><tr><td>Ceph Version</td><td>Quincy v17.2.7 (Upstream Deb Packages)</td></tr></tbody></table><p>An additional benefit of utilizing 1U Dell servers is that they are essentially a newer refresh of the systems David Galloway and I designed for the upstream Ceph performance lab. These systems have been tested in a <a href="https://ceph.io/en/news/blog/2023/ceph-encryption-performance/">variety</a> of <a href="https://ceph.io/en/news/blog/2023/reef-osds-per-nvme/">articles</a> over the past couple of years. It turns out that there was a major performance-impacting issue that came out during testing that did not affect the previous generation of hardware in the upstream lab but did affect this new hardware. We'll talk about that more later.</p><p>Without getting into too many details, I will reiterate that the customer's network configuration is very well-designed and quite fast. It easily has enough aggregate throughput across all 17 racks to let a cluster of this scale really stretch its legs.</p><h2>Testing Setup</h2><p>To do the burn-in testing, ephemeral Ceph clusters were deployed and FIO tests were launched using <a href="https://github.com/ceph/cbt/">CBT</a>. CBT was configured to deploy Ceph with several modified settings. OSDs were assigned an 8GB <code>osd_memory_target</code>. In production, a higher <code>osd_memory_target</code> should be acceptable. The customer had no need to test block or S3 workloads, so one might assume that <code>RADOS bench</code> would be the natural benchmark choice. In my experience, testing at a large scale with <code>RADOS bench</code> is tricky. It's tough to determine how many instances are needed to saturate the cluster at given thread counts. I've run into issues in the past where multiple concurrent pools were needed to scale performance. I also didn't have any preexisting <code>RADOS bench</code> tests handy to compare against. Instead, we opted to do burn-in testing using the same <code>librbd</code> backed FIO testing we've used in the upstream lab. This allowed us to partition the cluster into smaller chunks and compare results with previously published results. FIO is also very well known and well-trusted.</p><p>A major benefit of the <code>librbd</code> engine in FIO (versus utilizing FIO with kernel RBD) is that there are no issues with stale mount points potentially requiring system reboots. We did not have IPMI access to this cluster and we were under a tight deadline to complete tests. For that reason, we ultimately skipped kernel RBD tests. Based on previous testing, however, we expect the aggregate performance to be roughly similar given sufficient clients. We were able, however, to test both 3X replication and 6+2 erasure coding. We also tested msgr V2 in both unencrypted and secure mode using the following Ceph options:</p><pre><code>ms_client_mode = secure
ms_cluster_mode = secure
ms_service_mode = secure
ms_mon_client_mode = secure
ms_mon_cluster_mode = secure
ms_mon_service_mode = secure
</code></pre><p>OSDs were allowed to use all cores on the nodes. FIO was configured to first pre-fill RBD volume(s) with large writes, followed by 4MB and 4KB IO tests for 300 seconds each (60 seconds during debugging runs). Certain background processes, such as scrub, deep scrub, PG autoscaling, and PG balancing were disabled.</p><h3 id="a-note-pg-counts">A Note PG counts <a href="#a-note-pg-counts">¶</a></h3><p>Later in this article, you'll see some eye-popping PG counts being tested. This is intentional. We know from previous upstream lab testing that the PG count can have a dramatic effect on performance. Some of this is due to <a href="https://www.profmatt.com/clumpy">clumpiness</a> in random distributions at low sample (PG) counts. This potentially can be mitigated in part through additional balancing. Less commonly discussed is PG lock contention inside the OSD. We've observed that on very fast clusters, PG lock contention can play a significant role in overall performance. This unfortunately is less easily mitigated without increasing PG counts. How much does PG count actually matter?</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Upstream_Lab_PG_Scaling.svg" alt=""></p><p>With just 60 OSDs, Random read performance scales all the way up to 16384 PGs on an RBD pool using 3X replication. Writes top out much earlier, but still benefits from up to 2048 PGs.</p><p>Let me be clear: You shouldn't go out and blindly configure a production Ceph cluster to use PG counts as high as we are testing here. That's especially true given some of the other defaults in Ceph for things like PG log lengths and PG stat updates. I do, however, want to encourage the community to start thinking about whether the conventional wisdom of 100 PGs per OSD continues to make sense. I would like us to rethink what we need to do to achieve higher PG counts per OSD while keeping overhead and memory usage in check. I dream about a future where 1000 PGs per OSD isn't out of the ordinary, PG logs are auto-scaled on a per-pool basis, and PG autoscaling is a far more seldom-used operation.</p><h2>A Rough Start</h2><p>We were first able to log into the new hardware the week after Thanksgiving in the US. The plan was to spend a week or two doing burn-in validation tests and then integrate the new hardware into the existing cluster. We hoped to finish the migration in time for the new year if everything went to plan. Sadly, we ran into trouble right at the start. The initial low-level performance tests looked good. Iperf network testing showed us hitting just under 200Gb/s per node. Random sampling of a couple of the nodes showed reasonable baseline performance from the NVMe drives. One issue we immediately observed was that the operating system on all 68 nodes was accidentally deployed on 2 of the OSD drives instead of the internal Dell BOSS m.2 boot drives. We had planned to compare results for a 30 OSD configuration (3 nodes, 10 OSDs per node) against the results from the upstream lab (5 nodes, 6 OSDs per node). Instead, we ended up testing 8 NVMe drives per node. The first Ceph results were far lower than what we had hoped to see, even given the reduced OSD count.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Initial_Validation_Tests_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Initial_Validation_Tests_-_FIO_4KB_IOPS.svg" alt=""></p><p>The only result that was even close to being tolerable was for random reads, and that still wasn't great. Clearly, something was going on. We stopped running 3-node tests and started looking at single-node, and even single OSD configurations.</p><p>That's when things started to get weird.</p><h2>Spooky Behavior</h2><p>As we ran different combinations of 8-OSD and 1-OSD tests on individual nodes in the cluster, we saw wildly different behavior, but it took several days of testing to really understand the pattern of what we were seeing. Systems that initially performed well in single-OSD tests stopped performing well after multi-OSD tests, only to start working well again hours later. 8-OSD tests would occasionally show signs of performing well, but then perform terribly for all subsequent tests until the system was rebooted. We were eventually able to discern a pattern on fresh boot that we could roughly repeat across different nodes in the cluster:</p><table><thead><tr><th>Step</th><th>OSDS</th><th>4MB Randread (MB/s)</th><th>4MB Randwrite (MB/s)</th></tr></thead><tbody><tr><td>Boot</td><td></td><td></td><td></td></tr><tr><td>1</td><td>1 OSD</td><td>5716</td><td>3998</td></tr><tr><td>2</td><td>8 OSDs</td><td><strong>3190</strong></td><td><strong>2494</strong></td></tr><tr><td>3</td><td>1 OSD</td><td><strong>523</strong></td><td>3794</td></tr><tr><td>4</td><td>8 OSDs</td><td><strong>2319</strong></td><td><strong>2931</strong></td></tr><tr><td>5</td><td>1 OSD</td><td><strong>551</strong></td><td>3796</td></tr><tr><td>20-30 minute pause</td><td></td><td></td><td></td></tr><tr><td>6</td><td>1 OSD</td><td><strong>637</strong></td><td>3724</td></tr><tr><td>20-30 minute pause</td><td></td><td></td><td></td></tr><tr><td>7</td><td>1 OSD</td><td><strong>609</strong></td><td>3860</td></tr><tr><td>20-30 minute pause</td><td></td><td></td><td></td></tr><tr><td>8</td><td>1 OSD</td><td><strong>362</strong></td><td>3972</td></tr><tr><td>20-30 minute pause</td><td></td><td></td><td></td></tr><tr><td>9</td><td>1 OSD</td><td>6581</td><td>3998</td></tr><tr><td>20-30 minute pause</td><td></td><td></td><td></td></tr><tr><td>10</td><td>1 OSD</td><td>6350</td><td>3999</td></tr><tr><td>20-30 minute pause</td><td></td><td></td><td></td></tr><tr><td>11</td><td>1 OSD</td><td>6536</td><td>4001</td></tr></tbody></table><p>The initial single-OSD test looked fantastic for large reads and writes and showed nearly the same throughput we saw when running FIO tests directly against the drives. As soon as we ran the 8-OSD test, however, we observed a performance drop. Subsequent single-OSD tests continued to perform poorly until several hours later when they recovered. So long as a multi-OSD test was not introduced, performance remained high.</p><p>Confusingly, we were unable to invoke the same behavior when running FIO tests directly against the drives. Just as confusing, we saw that during the 8 OSD test, a single OSD would use significantly more CPU than the others:</p><h3 id="4mb-random-read">4MB Random Read <a href="#4mb-random-read">¶</a></h3><pre><code>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND 
511067 root      20   0 9360000   7.2g  33792 S  1180   3.8  15:24.32 ceph-osd                                              
515664 root      20   0 9357488   7.2g  34560 S 523.6   3.8  13:43.86 ceph-osd                                              
513323 root      20   0 9145820   6.4g  34560 S 460.0   3.4  13:01.12 ceph-osd                                              
514147 root      20   0 9026592   6.6g  33792 S 378.7   3.5   9:56.59 ceph-osd                                              
516488 root      20   0 9188244   6.8g  34560 S 378.4   3.6  10:29.23 ceph-osd                                              
518236 root      20   0 9390772   6.9g  33792 S 361.0   3.7   9:45.85 ceph-osd                                              
511779 root      20   0 8329696   6.1g  33024 S 331.1   3.3  10:07.18 ceph-osd                                              
516974 root      20   0 8984584   6.7g  34560 S 301.6   3.6   9:26.60 ceph-osd  
</code></pre><p>A wallclock profile of the OSD under load showed significant time spent in io_submit, which is what we typically see when the kernel starts blocking because a drive's queue becomes full.</p><h3 id="example-tp_osd_tp-thread-io_submit-wallclock-profile">Example tp_osd_tp Thread io_submit Wallclock Profile <a href="#example-tp_osd_tp-thread-io_submit-wallclock-profile">¶</a></h3><pre><code>+ 31.00% BlueStore::readv(boost::intrusive_ptr&lt;ObjectStore::CollectionImpl&gt;&amp;, g...
 + 31.00% BlueStore::_do_readv(BlueStore::Collection*, boost::intrusive_ptr&lt;Blu...
  + 24.00% KernelDevice::aio_submit(IOContext*)
  |+ 24.00% aio_queue_t::submit_batch(std::_List_iterator&lt;aio_t&gt;, std::_List_it...
  | + 24.00% io_submit
  |  + 24.00% syscall
</code></pre><p>Why would running an 8 OSD test cause the kernel to start blocking in io_submit during future single OSD tests? It didn't make very much sense. Initially, we suspected throttling. We saw that with the default cooling profile in the bios, several of the core complexes on the CPU were reaching up to 96 degrees Celsius. We theorized that perhaps we were hitting thermal limits on either the CPU or the NVMe drives during the 8-OSD tests. Perhaps that left the system in a degraded state for a period of time before recovering. Unfortunately, that theory didn't pan out. AMD/Dell confirmed that we shouldn't be hitting throttling even at those temperatures, and we were able to disprove the theory by running the systems with the fans running at 100% and a lower cTDP for the processor. Those changes kept them consistently around 70 degrees Celsius under load without fixing the problem.</p><p>For over a week, we looked at everything from bios settings, NVMe multipath, low-level NVMe debugging, changing kernel/Ubuntu versions, and checking every single kernel, OS, and Ceph setting we could think of. None these things fully resolved the issue.</p><p>We even performed blktrace and iowatcher analysis during "good" and "bad" single OSD tests, and could directly observe the slow IO completion behavior:</p><h3 id="blkparse-output---good-vs-bad">Blkparse Output - Good vs Bad <a href="#blkparse-output---good-vs-bad">¶</a></h3><table><thead><tr><th>Timestamp (good)</th><th>Offset+Length (good)</th><th>Timestamp (bad)</th><th>Offset+Length (bad)</th></tr></thead><tbody><tr><td>10.00002043</td><td>1067699792 + 256 [0]</td><td>10.0013855</td><td>1206277696 + 512 [0]</td></tr><tr><td>10.00002109</td><td>1153233168 + 136 [0]</td><td>10.00138801</td><td>1033429056 + 1896 [0]</td></tr><tr><td>10.00016955</td><td>984818880 + 8 [0]</td><td>10.00209283</td><td>1031056448 + 1536 [0]</td></tr><tr><td>10.00018827</td><td>1164427968 + 1936 [0]</td><td>10.00327372</td><td>1220466752 + 2048 [0]</td></tr><tr><td>10.0003024</td><td>1084064456 + 1928 [0]</td><td><b>10.00328869</b></td><td>1060912704 + 2048 [0]</td></tr><tr><td>10.00044238</td><td>1067699280 + 512 [0]</td><td><b>10.01285746</b></td><td>1003849920 + 2048 [0]</td></tr><tr><td>10.00046659</td><td>1040160848 + 128 [0]</td><td>10.0128617</td><td>1096765888 + 768 [0]</td></tr><tr><td>10.00053302</td><td>1153233312 + 1712 [0]</td><td>10.01286317</td><td>1060914752 + 720 [0]</td></tr><tr><td>10.00056482</td><td>1153229312 + 2000 [0]</td><td>10.01287147</td><td>1188736704 + 512 [0]</td></tr><tr><td>10.00058707</td><td>1067694160 + 64 [0]</td><td>10.01287216</td><td>1220468800 + 1152 [0]</td></tr><tr><td>10.00080624</td><td>1067698000 + 336 [0]</td><td>10.01287812</td><td>1188735936 + 128 [0]</td></tr><tr><td>10.00111046</td><td>1145660112 + 2048 [0]</td><td>10.01287894</td><td>1188735168 + 256 [0]</td></tr><tr><td>10.00118455</td><td>1067698344 + 424 [0]</td><td>10.0128807</td><td>1188737984 + 256 [0]</td></tr><tr><td>10.00121413</td><td>984815728 + 208 [0]</td><td>10.01288286</td><td>1217374144 + 1152 [0]</td></tr></tbody></table><h2>The Three Fixes</h2><p>At this point, we started getting the hardware vendors involved. Ultimately it turned out to be unnecessary. There was one minor, and two major fixes that got things back on track.</p><h3 id="fix-one">Fix One <a href="#fix-one">¶</a></h3><p>The first fix was an easy one, but only got us a modest 10-20% performance gain. Many years ago it was discovered (Either by Nick Fisk or Stephen Blinick if I recall) that Ceph is incredibly sensitive to latency introduced by CPU c-state transitions. A quick check of the bios on these nodes showed that they weren't running in <a href="https://infohub.delltechnologies.com/p/bios-settings-for-optimized-performance-on-next-generation-dell-poweredge-servers/">maximum performance</a> mode which disables c-states. This was a nice win but not enough to get the results where we wanted them.</p><h3 id="fix-two">Fix Two <a href="#fix-two">¶</a></h3><p>By the time I was digging into the blktrace results shown above, I was about 95% sure that we were either seeing an issue with the NVMe drives or something related to the PCIe root complex since these systems don't have PCIe switches in them. I was busy digging into technical manuals and trying to find ways to debug/profile the hardware. A very clever engineer working for the customer offered to help out. I set up a test environment for him so he could repeat some of the same testing on an alternate set of nodes and he hit a home run.</p><p>While I had focused primarily on wallclock profiles and was now digging into trying to debug the hardware, he wanted to understand if there was anything interesting happening kernel side (which in retrospect was the obvious next move!). He ran a perf profile during a bad run and made a very astute discovery:</p><pre><code>    77.37%  tp_osd_tp        [kernel.kallsyms]             [k] native_queued_spin_lock_slowpath
            |
            ---native_queued_spin_lock_slowpath
               |          
                --77.36%--_raw_spin_lock_irqsave
                          |          
                          |--61.10%--alloc_iova
                          |          alloc_iova_fast
                          |          iommu_dma_alloc_iova.isra.0
                          |          iommu_dma_map_sg
                          |          __dma_map_sg_attrs
                          |          dma_map_sg_attrs
                          |          nvme_map_data
                          |          nvme_queue_rq
                          |          __blk_mq_try_issue_directly
                          |          blk_mq_request_issue_directly
                          |          blk_mq_try_issue_list_directly
                          |          blk_mq_sched_insert_requests
                          |          blk_mq_flush_plug_list
                          |          blk_flush_plug_list
                          |          |          
                          |          |--56.54%--blk_mq_submit_bio
</code></pre><p>A huge amount of time is spent in the kernel contending on a spin lock while updating the IOMMU mappings. He disabled IOMMU in the kernel and immediately saw a huge increase in performance during the 8-node tests. We repeated those tests multiple times and repeatedly saw much better 4MB read/write performance. Score one for the customer. There was however still an issue with 4KB random writes.</p><h3 id="fix-three">Fix Three <a href="#fix-three">¶</a></h3><p>After being beaten to the punch by the customer on the IOMMU issue, I was almost grateful that we had an additional problem to solve. 4K random write performance had improved with the first two fixes but was still significantly worse than the upstream lab (even given the reduced node/drive counts). I also noticed that compaction was far slower than expected in RocksDB. There previously have been two significant cases that presented similarly and appeared to be relevant:</p><ol><li>Ceph can be very slow when not properly compiled with TCMalloc support.</li><li>Ceph can be very slow when not compiled with the right cmake flags and compiler optimizations.</li></ol><p>Historically this customer used the upstream Ceph Ubuntu packages and we were still using them here (rather than self-compiling or using cephadm with containers). I verified that TCMalloc was compiled in. That ruled out the first issue. Next, I dug out the upstream build logs for the 17.2.7 Ubuntu packages. That's when I noticed that we were not, in fact, building RocksDB with the correct compile flags. It's not clear how long that's been going on, but we've had general build performance issues going back as far as <a href="https://github.com/ceph/ceph/pull/25478">2018</a>.</p><p>It turns out that Canonical <a href="https://bugs.launchpad.net/ubuntu/+source/ceph/+bug/1894453">fixed</a> this for their own builds as did <a href="https://bugs.gentoo.org/733316">Gentoo</a> after seeing the note I wrote in do_cmake.sh over 6 years ago. It's quite unfortunate that our upstream Deb builds have suffered with this for as long as they have, however, it at least doesn't appear to affect anyone using cephadm on Debian/Ubuntu with the upstream containers. With the issue understood, we built custom 17.2.7 packages with a fix in place. Compaction time dropped by around 3X and 4K random write performance doubled (Though it's a bit tough to make out in the graph):</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/All_Fixes_Validation_Tests_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/All_Fixes_Validation_Tests_-_FIO_4KB_IOPS.svg" alt=""></p><p>4KB random write performance was still lower than I wanted it to be, but at least now we were in roughly the right ballpark given that we had fewer OSDs, only 3/5 the number of nodes, and fewer (though faster) cores per OSD. At this point, we were nearing winter break. The customer wanted to redeploy the OS to the correct boot drives and update the deployment with all of the fixes and tunings we had discovered. The plan was to take the holiday break off and then spend the first week of the new year finishing the burn-in tests. Hopefully, we could start migrating the cluster the following week.</p><h2>The First week of 2024</h2><p>On the morning of January 2nd, I logged into Slack and was greeted by a scene I'll describe as moderately controlled chaos. A completely different cluster we are involved in was having a major outage. Without getting too into the details, it took 3 days to pull that cluster back from the brink and get it into a stable and relatively healthy state. It wasn't until Friday that I was able to get back to performance testing. I was able to secure an extra day for testing on Monday, but this meant I was under a huge time crunch to showcase that the cluster could perform well under load before we started the data migration process.</p><h3 id="fate-smiles">Fate Smiles <a href="#fate-smiles">¶</a></h3><p>I worked all day on Friday to re-deploy CBT and recreate the tests we ran previously. This time I was able to use all 10 of the drives in each node. I also bumped up the number of clients to maintain an average of roughly 1 FIO client with an io_depth of 128 per OSD. The first 3 node test looked good. With 10 OSDs per node, We were achieving roughly proportional (IE higher) performance relative to the previous tests. I knew I wasn't going to have much time to do proper scaling tests, so I immediately bumped up from 3 nodes to 10 nodes. I also scaled the PG count at the same time and used CBT to deploy a new cluster. At 3 nodes I saw 63GiB/s for 4MB random reads. At 10 Nodes, I saw 213.5GiB/s. That's almost linear scaling at 98.4%. It was at this point that I knew that things were finally taking a turn for the better. Of the 68 nodes for this cluster, only 63 were up at that time. The rest were down for maintenance to fix various issues. I split the cluster roughly in half, with 32 nodes (320 OSDs) in one half, and 31 client nodes running 10 FIO processes each in the other half. I watched as CBT built the cluster over roughly a 7-8 minute period. The initial write prefill looked really good. My heart soared. We were reading data at 635 GiB/s. We broke 15 million 4k random read IOPS. While this may not seem impressive compared to the individual NVMe drives, these were the highest numbers I had ever seen for a ~300 OSD Ceph cluster.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Post-Fixes_OSD_Scaling_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Post-Fixes_OSD_Scaling_-_FIO_4KB_IOPS.svg" alt=""></p><p>I also plotted both average and tail latency for the scaling tests. Both looked consistent. This was likely due to scaling the PG count and the FIO client count at the same time as OSDs. These tests are very IO-heavy however. We have so much client traffic that we are likely well into the inflection point where performance doesn't increase while latency continues to grow as more IO is added.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Post-Fixes_OSD_Scaling_-_FIO_4KB_Average_Latency.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Post-Fixes_OSD_Scaling_-_FIO_4KB_99%25_Latency.svg" alt=""></p><p>I showed these results to my colleague Dan van der Ster who previously had built the Ceph infrastructure at CERN. He bet me a beer (<em>Better be a good one Dan!</em>) if I could hit 1 TiB/s. I told him that had been my plan since the beginning.</p><h2>A Partially Operational Death Star</h2><p>I had no additional client nodes to test the cluster with at full capacity, so the only real option was to co-locate FIO processes on the same nodes as the OSDs. On one hand, this provides a very slight network advantage. Clients will be able to communicate with local OSDs 1/63rd of the time. On the other hand, we know from previous testing that co-locating FIO clients on OSD nodes isn't free. There's often a performance hit, and it wasn't remotely clear to me how much of a hit a cluster of this scale would take.</p><p>I built a new CBT configuration targeting the 63 nodes I had available. Deploying the cluster with CBT took about 15 minutes to stand up all 630 OSDs and build the pool. I waited with bated breath and watched the results as they came in.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Initial_Tuning_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Initial_Tuning_-_FIO_4KB_IOPS.svg" alt=""></p><p>Around 950GiB/s. So very very close. It was late on Friday night at this point, so I wrapped up and turned in for the night. On Saturday morning I logged in and threw a couple of tuning options at the cluster: Lowering OSD shards and async messenger threads while also applying the Reef RocksDB tunings. As you can see, we actually hurt read performance a little while helping write performance. In fact, random write performance improved by nearly 20%. After further testing, it looked like the reef tunings were benign though only helping a little bit in the write tests. The bigger effect seemed to be coming from shard/thread changes. At this point, I had to take a break and wasn't able to get back to working on the cluster again until Sunday night. I tried to go to bed, but I knew that I was down to the last 24 hours before we needed to wrap this up. At around midnight I gave up on sleep and got back to work.</p><p>I mentioned earlier that we know that the PG count can affect performance. I decided to keep the "tuned" configuration from earlier but doubled the number of PGs. In the first set of tests, I had dropped the ratio of clients to OSDs down given that we were co-locating them on the OSD nodes. Now I tried scaling them up again. 4MB random read performance improved slightly as the number of clients grew, while small random read IOPS degraded. Once we hit 8 FIO processes per node (504 total), sequential write performance dropped through the floor.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Client_Process_Scaling_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Client_Process_Scaling_-_FIO_4KB_IOPS.svg" alt=""></p><p>To understand what happened, I reran the write test and watched “ceph -s” output:</p><pre><code>  services:
    mon: 3 daemons, quorum a,b,c (age 42m)
    mgr: a(active, since 42m)
    osd: 630 osds: 630 up (since 24m), 630 in (since 25m)
         flags noscrub,nodeep-scrub
 
  data:
    pools:   2 pools, 131073 pgs
    objects: 4.13M objects, 16 TiB
    usage:   48 TiB used, 8.2 PiB / 8.2 PiB avail
    pgs:     129422 active+clean
             1651   active+clean+laggy
 
  io:
    client:   0 B/s rd, 1.7 GiB/s wr, 1 op/s rd, 446 op/s wr
</code></pre><p>As soon as I threw 504 FIO processes doing 4MB writes at the cluster, some of the PGs started going active+clean+laggy. Performance tanked and the cluster didn't recover from that state until the workload was completed. What's worse, more PGs went laggy over time even though the throughput was only a small fraction of what the cluster was capable of. Since then, we've found a couple of reports of laggy PGs on the <a href="https://www.mail-archive.com/ceph-users@ceph.io/msg15040.html">mailing list</a> along with a couple of suggestions that might fix them. It's not clear if those ideas would have helped here. We do <a href="https://docs.ceph.com/en/quincy/rados/operations/pg-states/">know</a> that IO will temporarily be paused when PGs go into a laggy state and that this happens because a replica hasn't acknowledged new leases from the primary in time. After discussing the issue with other Ceph developers, we think this could possibly be an issue with locking in the OSD or having lease messages competing with work in the same async msgr threads.</p><p>Despite being distracted by the laggy PG issue, I wanted to refocus on hitting 1.0TiB/s. Lack of sleep was finally catching up with me. At some point I had doubled the PG count again to 256K, just to see if it had any effect at all on the laggy PG issue. That put us solidly toward the upper end of the curve we showed earlier, though frankly, I don't think it actually mattered much. I decided to switch back to the default OSD shard counts and continue testing with 504 FIO client processes. I did however scale the number of async messenger threads. There were two big takeaways. The first is that dropping down to 1 async messenger allowed us to avoid PGs going laggy and achieve “OK” write throughput with 504 clients. It also dramatically hurt the performance of 4MB reads. The second: Ceph's defaults were actually ideal for 4MB reads. With 8 shards, 2 threads per shard, and 3 msgr threads, we finally broke 1TiB/s. Here's the view I had at around 4 AM Monday morning as the final set of tests for the night ran:</p><pre><code>  services:
    mon: 3 daemons, quorum a,b,c (age 30m)
    mgr: a(active, since 30m)
    osd: 630 osds: 630 up (since 12m), 630 in (since 12m)
         flags noscrub,nodeep-scrub
 
  data:
    pools:   2 pools, 262145 pgs
    objects: 4.13M objects, 16 TiB
    usage:   48 TiB used, 8.2 PiB / 8.2 PiB avail
    pgs:     262145 active+clean
 
  io:
    client:   1.0 TiB/s rd, 6.1 KiB/s wr, 266.15k op/s rd, 6 op/s wr
</code></pre><p>and the graphs from the FIO results:</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Msgr_Thread_Scaling_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Msgr_Thread_Scaling_-_FIO_4KB_IOPS.svg" alt=""></p><h2>Sleep; Erasure Coding</h2><p>After finally seeing the magical "1.0 TiB/s" screen I had been waiting weeks to see, I finally went to sleep. Nevertheless, I got up several hours later. There was still work to be done. All of the testing we had done so far was with 3X replication, but the customer would be migrating this hardware into an existing cluster deployed with 6+2 erasure coding. We needed to get some idea of what this cluster was capable of in the configuration they would be using.</p><p>I reconfigured the cluster again and ran through new tests. I picked PG/shard/client values from the earlier tests that appeared to work well. Performance was good, but I saw that the async messenger threads were working very hard. I decided to try increasing them beyond the defaults to see if they might help given the added network traffic.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Msgr_Thread_Scaling_-_FIO_4MB_Throughput_EC62.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Msgr_Thread_Scaling_-_FIO_4KB_IOPS_EC62.svg" alt=""></p><p>We could achieve well over 500GiB/s for reads and nearly 400GiB/s for writes with 4-5 async msgr threads. But why are the read results so much slower with EC than with replication? With replication, the primary OSD for a PG only has to read local data and send it to the client. The network overhead is essentially 1X. With 6+2 erasure coding, the primary must read 5 of the 6 chunks from replicas before it can then send the constructed object to the client. The overall network overhead for the request is roughly (1 + 5/6)X*. That's why we see slightly better than half the performance of 3X replication for reads. We have the opposite situation for writes. With 3X replication, the client sends the object to the primary, which then further sends copies over the network to two secondaries. This results in an aggregate network overhead of 3X. In the EC case, we only need to send 7/8 chunks to the secondaries (almost, but not quite, the same as the read case). For large writes, performance is actually faster.</p><p>* <em>Originally this article stated that 7/8 chunks had to be fetched for reads. The correct value is 5/6 chunks, unless fast reads are enabled. In that case it would be 7/6 chunks. Thanks to Joshua Baergen for catching this!</em></p><p>IOPS however, are another story. For very small reads and writes, Ceph will contact all participating OSDs in a PG for that object even when the data they store isn't relevant for the operation. For instance, if you are doing 4K reads and the data you are interested in is entirely stored in a single chunk on one of the OSDs, Ceph will still fetch data from all OSDs participating in the stripe. In the summer of 2023, Clyso <a href="https://github.com/ceph/ceph/pull/52746">resurrected</a> a PR from Xiaofei Cui that implements partial stripe reads for erasure coding to avoid this extra work. The effect is dramatic:</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/FIO_4KB_Random_Read_IOPS_16_Client.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/FIO_4KB_Random_Read_Cycles_OP_16_Client.svg" alt=""></p><p>It's not clear yet if we will be able to get this merged for Squid, though Radoslaw Zarzynski, core lead for the Ceph project, has offered to help try to get this over the finish line.</p><h2>Squeezing in Msgr Encryption Testing</h2><p>Finally, we wanted to provide the customer with a rough idea of how much msgr-level encryption would impact their cluster if they decided to use it. The adrenaline of the previous night had long faded and I was dead tired at this point. I managed to run through both 3X replication and 6+2 erasure coding tests with msgr v2 encryption enabled and compared it against our previous test results.</p><p><img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Msgr_Encryption_-_FIO_4MB_Throughput.svg" alt=""> <img src="https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/images/Full_Cluster_Msgr_Encryption_-_FIO_4KB_IOPS.svg" alt=""></p><p>The biggest hit is to large reads. They drop from ~1 TiB/s to around 750 GiB/s. Everything else sees a more modest, though consistent hit. At this point, I had to stop. I really wanted to do PG scaling tests and even kernel RBD tests. It was time, though, to hand the systems back to the customer for re-imaging and then to one of my excellent colleagues at Clyso for integration.</p><h2>Finale</h2><p>So what's happened with this cluster since the end of the testing? All hardware was re-imaged and the new OSDs were deployed into the customer's existing HDD cluster. Dan's upmap-remapped script is being used to control the migration process and we've migrated around 80% of the existing data to the NVMe backed OSDs. By next week, the cluster should be fully migrated to the new NVMe based nodes. We've opted not to employ all of the tuning we've done here, at least not at first. Initially, we'll make sure the cluster behaves well under the existing, mostly default, configuration. We now have a mountain of data we can use to tune the system further if the customer hits any performance issues.</p><p>Since there was a ton of data and charts here, I want to recap some of the highlights. Here's an outline of the best numbers we were able to achieve on this cluster:</p><table><thead><tr><th></th><th>30 OSDs (3x)</th><th>100 OSDs (3x)</th><th>320 OSDs (3x)</th><th>630 OSDs (3x)</th><th>630 OSDs (EC62)</th></tr></thead><tbody><tr><td>Co-Located Fio</td><td>No</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr><td>4MB Read</td><td>63 GiB/s</td><td>214 GiB/s</td><td>635 GiB/s</td><td>1025 GiB/s</td><td>547 GiB/s</td></tr><tr><td>4MB Write</td><td>15 GiB/s</td><td>46 GiB/s</td><td>133 GiB/s</td><td>270 GiB/s</td><td>387 GiB/s</td></tr><tr><td>4KB Rand Read</td><td>1.9M IOPS</td><td>5.8M IOPS</td><td>16.6M IOPS</td><td>25.5M IOPS</td><td>3.4M IOPS</td></tr><tr><td>4KB Rand Write</td><td>248K IOPS</td><td>745K IOPS</td><td>2.4M IOPS</td><td>4.9M IOPS</td><td>936K IOPS</td></tr></tbody></table><p>What's next? We need to figure out how to fix the laggy PG issue during writes. We can't have Ceph falling apart when the write workload scales up. Beyond that, we learned through this exercise that Ceph is perfectly capable of saturating 2x 100GbE NICs. To push the throughput envelope further we will need 200GbE+ when using 10 NVMe drives per node or more. IOPS is more nuanced. We know that PG count can have a big effect. We also know that the general OSD threading model is playing a big role. We consistently hit a wall at around 400-600K random read IOPS per node and we've seen it in multiple deployments. Part of this may be how the async msgr interfaces with the kernel and part of this may be how OSD threads wake up when new work is put into the shard queues. I've modified the OSD code in the past to achieve better results under heavy load, but at the expense of low-load latency. Ultimately, I suspect improving IOPS will take a multi-pronged approach and a rewrite of some of the OSD threading code.</p><p>To my knowledge, these are the fastest single-cluster Ceph results ever published and the first time a Ceph cluster has achieved 1 TiB/s. I think Ceph is capable of quite a bit more. If you have a faster cluster out there, I encourage you to publish your results! Thank you for reading, and if you have any questions or would like to talk more about Ceph performance, please feel free to <a href="mailto:mark.nelson@clyso.com">reach out</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York Times Flash-based visualizations work again (105 pts)]]></title>
            <link>https://flowingdata.com/2024/01/10/nyt-flash-based-visualizations-work-again/</link>
            <guid>39059610</guid>
            <pubDate>Fri, 19 Jan 2024 19:05:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flowingdata.com/2024/01/10/nyt-flash-based-visualizations-work-again/">https://flowingdata.com/2024/01/10/nyt-flash-based-visualizations-work-again/</a>, See on <a href="https://news.ycombinator.com/item?id=39059610">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-post">
<p><img fetchpriority="high" width="750" height="858" src="https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-750x858.png" alt="" decoding="async" srcset="https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-750x858.png 750w, https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-1090x1247.png 1090w, https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-210x240.png 210w, https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-768x879.png 768w, https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-1343x1536.png 1343w, https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-1790x2048.png 1790w, https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash.png 1958w" sizes="(max-width: 750px) 100vw, 750px" data-attachment-id="73041" data-permalink="https://flowingdata.com/2024/01/10/nyt-flash-based-visualizations-work-again/nyt-web-based-flash/" data-orig-file="https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash.png" data-orig-size="1958,2240" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="NYT web-based Flash" data-image-description="" data-image-caption="" data-medium-file="https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-750x858.png" data-large-file="https://flowingdata.com/wp-content/uploads/2024/01/NYT-web-based-Flash-1090x1247.png"> </p>

<div>
<p>In the 2000s, if you wanted to make interactive or animated visualization for the web, Flash was the main option. When Flash lost support and fell off the internet, a solid decade of great visualization no longer worked. </p>
<p>The New York Times has resurrected their archives with a Flash emulator. So pieces that were relegated to static thumbnail images are back. See the <a href="https://archive.nytimes.com/www.nytimes.com/interactive/2008/02/23/movies/20080223_REVENUE_GRAPHIC.html">box office streamgraph</a> that once upset many, the <a href="https://archive.nytimes.com/www.nytimes.com/interactive/2009/11/06/business/economy/unemployment-lines.html">multi-line chart</a> showing jobless rates for people like you, and the <a href="https://archive.nytimes.com/www.nytimes.com/interactive/2009/07/31/business/20080801-metrics-graphic.html">interactive stacked area chart</a> on how people spend their day. </p>
<p>NYT is <a href="https://twitter.com/johnmichael_mur/status/1747853253503844711">using</a> the open source <a href="https://ruffle.rs/">Ruffle</a> as their Flash emulator. I hope other news outlets follow. It’s great to see my favorite visualizations working again. [via <a href="https://eagereyes.org/blog/2024/nytimes-web-flash-player">EagerEyes</a>] </p>

</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fujitsu bugs that sent innocent people to prison were known "from the start" (346 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/01/fujitsu-bugs-that-sent-innocent-people-to-prison-were-known-from-the-start/</link>
            <guid>39059307</guid>
            <pubDate>Fri, 19 Jan 2024 18:40:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/01/fujitsu-bugs-that-sent-innocent-people-to-prison-were-known-from-the-start/">https://arstechnica.com/tech-policy/2024/01/fujitsu-bugs-that-sent-innocent-people-to-prison-were-known-from-the-start/</a>, See on <a href="https://news.ycombinator.com/item?id=39059307">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      British Post Office Scandal    —
</h4>
            
            <h2 itemprop="description">Software bugs were hidden from lawyers of wrongly convicted UK postal workers.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/01/paul-patterson-fujitsu-1-800x516.jpg" alt="Paul Patterson, co-CEO of Fujitsu's European division, sits at a table in front of a microphone while testifying for a public inquiry.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/01/paul-patterson-fujitsu-1.jpg" data-height="1613" data-width="2500">Enlarge</a> <span>/</span> Paul Patterson, co-CEO of Fujitsu's European division, testifies for a public inquiry in London on January 19, 2024. </p><p>Getty Images | AFP</p></figcaption>  </figure>

  




<!-- cache hit 96:single/related:67f4a85511999b847930e8599aadbfcf --><!-- empty -->
<p>Fujitsu software bugs that helped send innocent postal employees to prison in the UK were known "right from the very start of deployment," a Fujitsu executive told a <a href="https://www.postofficehorizoninquiry.org.uk/">public inquiry</a> today.</p>
<p>"All the bugs and errors have been known at one level or not, for many, many years. Right from the very start of deployment of the system, there were bugs and errors and defects, which were well-known to all parties," <a href="https://www.independent.co.uk/tv/news/fujitsu-horizon-post-office-scandal-errors-b2481433.html">said</a> Paul Patterson, co-CEO of Fujitsu's European division.</p>
<p>That goes back to 1999, when the Horizon software system was installed in post offices by Fujitsu subsidiary International Computers Limited. From 1999 to 2015, Fujitsu's faulty accounting software aided in the prosecution and conviction of more than 900 sub-postmasters and postmistresses who were accused of theft or fraud when the software wrongly made it appear that money was missing from their branches.</p>
<p>Some innocent people went to prison, while others were forced to make payments to the UK Post Office to cover the supposed shortfalls. So far, "only 93 convictions have been overturned and thousands of people are still waiting for compensation settlements," a <a href="https://www.bbc.com/news/business-67993493">BBC report</a> said.</p>
<h2>Post Office lawyers rewrote Fujitsu witness statements</h2>
<p>During the prosecutions, courts hearing cases against postal employees "were not told of 29 bugs identified as early as 1999 in the system it built," <a href="https://www.theguardian.com/uk-news/2024/jan/19/post-office-inquiry-horizon-it-scandal-software-fujitsu">The Guardian wrote</a> in a summary of Patterson's testimony today. The article said:</p>
<blockquote><p>When bugs were acknowledged, witness statements from Fujitsu staff due to be heard in court were then edited by the Post Office as it sought to maintain the line that the system was working well as it pursued innocent people through the courts.</p>
<p>Paul Patterson agreed that both organizations had failed the accused. "I am surprised that that detail was not included in the witness statements given by Fujitsu staff to the Post Office and I have seen some evidence of editing witness statements by others," he said.</p>
<p>Asked by the lead counsel of the public inquiry, Jason Beer KC, whether he agreed that this was shameful, Patterson, who has worked at the company for 14 years, said: "That would be one word I would use. Shameful and appalling. My understanding of how our laws work in this country, is that all of the evidence should have been put in front of the subpostmasters that the Post Office was relying on to prosecute them."</p></blockquote>
<p>A <a href="https://www.ft.com/content/17c94ef6-72f6-41e3-8b14-8c7b51e3755a">Financial Times article</a> said that the public inquiry "heard in December last year that the Post Office's lawyers had rewritten Fujitsu witness statements."</p>                                            
                                                        
<p>The FT article also said the Post Office, which used <a href="https://www.cps.gov.uk/legal-guidance/private-prosecutions">prosecution powers available to private corporations</a> in the UK, obtained 700 of the 900 convictions. The other convictions came in cases brought by Scottish prosecutors. The scandal <a href="https://www.theguardian.com/uk-news/2024/jan/13/plans-to-reform-private-prosecutions-after-post-office-horizon-scandal">may lead to reforms</a> of the private prosecution system that lets organizations take people to court.</p>
<h2>Bugs were understood “way back to 1999”</h2>
<p>Earlier this week, <a href="https://arstechnica.com/tech-policy/2024/01/fujitsu-apologizes-for-software-bugs-that-fueled-wrongful-convictions-in-uk/">Patterson told UK Parliament members</a> that "Fujitsu would like to apologize for our part in this appalling miscarriage of justice. We were involved from the very start. We did have bugs and errors in the system and we did help the Post Office in their prosecutions of the sub-postmasters. For that we are truly sorry."</p>
<p>Patterson also told Parliament members that Fujitsu has "a moral obligation" to contribute to the compensation for victims.</p>
<p>Patterson testified today in a different setting, answering questions from lawyers representing victims. One of those lawyers, Flora Page, <a href="https://youtu.be/qPZAPS2s6v4?t=2573">asked Patterson</a>, "Did nobody historically make that pretty obvious connection between very poor code going out into operation and then very poor data coming out and through the litigation support service?"</p>
<p>Patterson answered, "Whether people made that connection or not, what is very evident... is that that connection and understanding about what was going on and where was it, was understood by certainly Fujitsu and certainly understood by Post Office way back to 1999. It's all about what you do with that information... that is a question for this inquiry."</p>
<p>Post Office Minister Kevin Hollinrake, the MP for Thirsk and Malton, <a href="https://www.bbc.com/news/uk-england-york-north-yorkshire-68029170">told the BBC</a> that his "number one priority" is to "try and get compensation and get answers for people."</p>
<p>"You've had marriages fail, people commit suicide, an horrendous impact on people's lives," he said. "It's perfectly reasonable that the public should demand people are held to account and that should mean criminal prosecutions wherever possible."&nbsp;The UK government also <a href="https://www.bbc.co.uk/news/uk-67932595">has plans for a new law</a> to "swiftly exonerate and compensate" people who were falsely convicted.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tart: VMs on macOS using Apple's native Virtualization.Framework (175 pts)]]></title>
            <link>https://tart.run/</link>
            <guid>39059100</guid>
            <pubDate>Fri, 19 Jan 2024 18:24:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tart.run/">https://tart.run/</a>, See on <a href="https://news.ycombinator.com/item?id=39059100">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
       
        
      

<!-- Additional styles for landing page -->




<!-- landing page for landing page -->
<!-- Hero -->
<div>
        <h2>
          <strong>Tart</strong> is a virtualization toolset to build, run and
          manage <i>macOS</i> and <i>Linux</i> virtual machines on
          <i>Apple Silicon.</i>
        </h2>
        <p><a href="https://tart.run/quick-start" title="Quick Start">
          Learn More
        </a>
      </p></div>

<!-- Spotlights -->
<div data-md-component="content" data-md-color-scheme="default">
      <header>
        <h2 id="virtualization-and-beyond">
          Virtualization and beyond
          <a href="#virtualization-and-beyond" title="Permanent link">
            ¶
          </a>
        </h2>
      </header>
      <div>
        <figure>
          <img src="https://tart.run/assets/images/spotlight/virtualization-framework.webp" alt="Apple’s native Virtualization.Framework" loading="lazy" width="500" height="212">
          <figcaption>
            <h2>Native performance</h2>
            <p>
              Tart is&nbsp;using Apple’s native
              <i>Virtualization.Framework</i> that was developed along with
              architecting the first M1&nbsp;chip. This seamless integration
              between hardware and software ensures smooth performance without
              any drawbacks.
            </p>
          </figcaption>
        </figure>
        <figure>
          <img src="https://tart.run/assets/images/spotlight/supported-registries.webp" alt="OCI-compatible container registries" loading="lazy" width="500" height="160">
          <figcaption>
            <h2>Remote storage for Virtual Machines</h2>
            <p>
              For storing virtual machine images Tart integrates with
              OCI-compatible container registries. Work with virtual machines as
              you used to&nbsp;with Docker containers.
            </p>
          </figcaption>
        </figure>
        <figure>
          <img src="https://tart.run/assets/images/spotlight/github-actions-runners.webp" alt="GitHub Actions Runners" loading="lazy" width="500" height="280">
          <figcaption>
            <h2>Seamless integration with your existing automations</h2>
            <p>
              Tart powers several continuous integration systems including
              <a href="https://tart.run/integrations/github-actions">on‑demand GitHub Actions Runners</a>
              and
              <a href="https://cirrus-ci.org/guide/macOS/" target="_blank" rel="noopener">Cirrus&nbsp;CI</a>. Double the performance of&nbsp;your macOS actions with
              a&nbsp;couple lines of&nbsp;code.
            </p>
          </figcaption>
        </figure>
        <figure>
          
          <figcaption>
            <h2>Run at scale with <a href="https://github.com/cirruslabs/orchard">Orchard</a></h2>
            <p>
              Tart toolset includes Orchard Orchestration — tool to run and manage Tart virtual machines
              at scale on a cluster of Apple Silicon hosts. An Orchard Cluster exposes a simple REST API to manage
              thousands virtual machines. Orchard CLI allows accessing remote virtual machines like they run locally.
            </p>
          </figcaption>
        </figure>
      </div>
    </div>

<div data-md-component="content" data-md-color-scheme="slate" data-md-color-primary="indigo">
    <p>
      <header>
        <h2 id="powerhouse">
          Automation Powerhouse
          <a href="#powerhouse" title="Permanent link">
            ¶
          </a>
        </h2>
      </header>
      
      <h2>
        With more than <strong id="installation-counter">25,000</strong> installations to date, Tart has been adopted for various scenarios.
        Its applications range from powering CI/CD pipelines and reproducible local development environments,
        to helping in the testing of device management systems without actual physical devices.
      </h2>
    </p>
  </div>

<!-- Testimonials -->
<div data-md-component="content" data-md-color-scheme="default">
      <header>
        <h2 id="what-our-users-say">
          What our users say
          <a href="#what-our-users-say" title="Permanent link">
            ¶
          </a>
        </h2>
      </header>
      
    </div>

      <main data-md-component="main">
        <div>
          
            
              
              <div data-md-component="sidebar" data-md-type="navigation">
                    


  


<nav aria-label="Navigation" data-md-level="0">
  <label for="__drawer">
    <a href="https://tart.run/" title="Tart" aria-label="Tart" data-md-component="logo">
      
  <img src="https://tart.run/assets/images/TartLogo.png" alt="logo">

    </a>
    Tart
  </label>
  
    
  
  <ul data-md-scrollfix="">
    
      
      
  
  
    
  
  
    <li>
      
      
      
      
      
      <a href="https://tart.run/">
        
  
  <span>
    
  
    Home
  

    
  </span>
  
  

      </a>
      
    </li>
  

    
      
      
  
  
  
    <li>
      <a href="https://tart.run/quick-start/">
        
  
  <span>
    
  
    Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li>
      
        
        
        
        
        
        
          <label for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span>
    
  
    Integrations
  

    
  </span>
  
  

            <span></span>
          </label>
        
        <nav data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label for="__nav_3">
            <span></span>
            
  
    Integrations
  

          </label>
          <ul data-md-scrollfix="">
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/integrations/github-actions/">
        
  
  <span>
    
  
    GitHub Actions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/integrations/gitlab-runner/">
        
  
  <span>
    
  
    GitLab Runner
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/integrations/buildkite/">
        
  
  <span>
    
  
    Buildkite
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/integrations/cirrus-cli/">
        
  
  <span>
    
  
    Self-hosted CI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/integrations/vm-management/">
        
  
  <span>
    
  
    Managing VMs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li>
      <a href="https://tart.run/licensing/">
        
  
  <span>
    
  
    Support &amp; Licensing
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li>
      <a href="https://github.com/cirruslabs/orchard">
        
  
  <span>
    
  
    Orchestration
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li>
      <a href="https://tart.run/faq/">
        
  
  <span>
    
  
    FAQ
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li>
      
        
        
        
        
        
        
          <label for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span>
    
  
    Legal
  

    
  </span>
  
  

            <span></span>
          </label>
        
        <nav data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label for="__nav_7">
            <span></span>
            
  
    Legal
  

          </label>
          <ul data-md-scrollfix="">
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/legal/terms/">
        
  
  <span>
    
  
    Terms of Service
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/legal/privacy/">
        
  
  <span>
    
  
    Privacy
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li>
      
        
        
        
        
        
        
          <label for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span>
    
  
    Blog
  

    
  </span>
  
  

            <span></span>
          </label>
        
        <nav data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label for="__nav_8">
            <span></span>
            
  
    Blog
  

          </label>
          <ul data-md-scrollfix="">
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/blog/">
        
  
  <span>
    
  
    Blog
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li>
      
        
        
        
        
        
        
          <label for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
            
  
  <span>
    
  
    Archive
  

    
  </span>
  
  

            <span></span>
          </label>
        
        <nav data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
          <label for="__nav_8_2">
            <span></span>
            
  
    Archive
  

          </label>
          <ul data-md-scrollfix="">
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/blog/archive/2023/">
        
  
  <span>
    
  
    2023
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li>
      
        
        
        
        
        
        
          <label for="__nav_8_3" id="__nav_8_3_label" tabindex="0">
            
  
  <span>
    
  
    Categories
  

    
  </span>
  
  

            <span></span>
          </label>
        
        <nav data-md-level="2" aria-labelledby="__nav_8_3_label" aria-expanded="false">
          <label for="__nav_8_3">
            <span></span>
            
  
    Categories
  

          </label>
          <ul data-md-scrollfix="">
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/blog/category/announcement/">
        
  
  <span>
    
  
    announcement
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li>
      <a href="https://tart.run/blog/category/orchard/">
        
  
  <span>
    
  
    orchard
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
            
            
              
              
            
          
          
            <p data-md-component="content">
              
              <article>
                
                  

  
  


  <h2>Home</h2>



  
  



  




                
              </article>
            </p>
          
          
  


        </div>
        
          
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Surveillance-by-Design in Proposed Amendments to the UK Investigatory Powers Act (109 pts)]]></title>
            <link>https://www.lawfaremedia.org/article/surveillance-by-design-in-proposed-amendments-to-the-u.k.-investigatory-powers-act</link>
            <guid>39058122</guid>
            <pubDate>Fri, 19 Jan 2024 17:23:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lawfaremedia.org/article/surveillance-by-design-in-proposed-amendments-to-the-u.k.-investigatory-powers-act">https://www.lawfaremedia.org/article/surveillance-by-design-in-proposed-amendments-to-the-u.k.-investigatory-powers-act</a>, See on <a href="https://news.ycombinator.com/item?id=39058122">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <ul>
                <li>
                    <div>
                            <p><img src="https://lawfare-assets-new.azureedge.net/assets/images/default-source/article-images/guest-contributor-profile-1c44d48a6-ac2a-4574-9f22-86139c460fc9.png?sfvrsn=35fe0f9e_3" alt="Jim  Baker">
                            </p>

                        
                    </div>
                </li>
                <li>
                    
                </li>
        </ul>
        
        
    <div data-sj-ignore="">
        <p>
                Published by <span>The Lawfare Institute</span><br>
                in Cooperation With<br>
                <img src="https://www.lawfaremedia.org/ResourcePackages/Talon/assets/dist/images/brookings-logo.png" alt="Brookings">
            </p>

        
    </div>

            </div><div>
                    <p>There is a <a href="https://bills.parliament.uk/publications/52904/documents/3976">bill</a> moving rapidly through the U.K. Parliament that poses a significant threat to data security and privacy in the U.K. and beyond. It is ill considered and should be amended substantially before it moves forward.</p><p>The bill is flawed in several respects, as some observers have <a href="https://www.techuk.org/resource/as-the-government-reviews-the-investigatory-powers-act-s-notices-regime-it-is-vital-we-maintain-proper-checks-and-balances-to-protect-privacy.html">pointed out</a>. This piece focuses on certain elements that we think will stifle innovation and substantially hinder the efforts of private companies to enhance, or even maintain, core security and privacy products, features, and architecture, especially with respect to the use of encryption. To be sure, governments in democratic countries face challenges in accessing the content of communications of spies, terrorists, and other threat actors. They need help. But these purported solutions in the bill aren’t the right way to do it.</p><p>Specifically, the proposed amendments to the <a href="https://www.gchq.gov.uk/information/investigatory-powers-act">2016 Investigatory P</a><a href="https://www.gchq.gov.uk/information/investigatory-powers-act">owers Act</a> would give the U.K. government, at the sole discretion of the secretary of state for the Home Department (Home Office), the power to require a company to tell the U.K. government about new or changed products or features before the company could launch them. This mandate could be issued without consultation with privacy regulators or others in a position to opine on proportionality or other considerations, much less a judicial review.&nbsp;</p><p>Following receipt of a “Notification Notice” (yes, that’s actually what it is <a href="https://www.parallelparliament.co.uk/debate/2023-12-11/lords/lords-chamber/investigatory-powers-amendment-bill-hl">called</a>), the U.K. government could use existing powers to require that the company meet surveillance capability demands as a condition of making a product or feature available. Demands are left to the discretion of the government and could include, for example, disabling security like encryption, user access controls, and privacy protection features. If the government’s demands are not met, the company may have no choice but to abandon the product or feature launch, giving the government essentially a veto power on how companies innovate and improve their products. (The government could even block a company from deprecating a service or deleting data.) All of this is done secretly, with the company prohibited from disclosing it unless the government allows it to do so. The act purports to extend enforceability to non-U.K. companies, and the amendments expand that to retention and these notices, exacerbating the challenges that companies face. Paired with the gag order that comes with each, this has several effects, including that the non-U.K. company can’t notify its home government of the demand, even one that violates the law of the home government, preventing any sort of diplomatic assistance.</p><p>The Home Office has been very <a href="https://assets.publishing.service.gov.uk/media/6475e2c0b32b9e000ca95e74/Revised_notices_regimes_consultation.pdf">explicit</a> that the purpose of the amendments is to “ensure continuity of lawful access to data against a background of changing technology.” It’s understandable that the U.K. intelligence and law enforcement agencies would like to know about a company’s research and business plans, and have a say in whether and how a company makes a change that has serious implications for their weighty missions. Both of us have worked in law enforcement, and we know how important, and how difficult, the jobs of public safety officials are. There’s no reason to think that the intentions behind the bill are anything but noble. This proposed power, however, goes too far and is counterproductive.<br></p><p>First, there’s no case that this extraordinary power would solve any existing problem. Most providers are quite transparent about product launches, feature additions, and removals. Many companies have entire conferences to loudly trumpet what is coming, or at least issue announcements through blog posts and press releases. In addition, there’s no shortage of dialogue between the U.K. government and technology providers. In October 2023, U.K. security officials and their Five Eyes partners (the United States, Canada, Australia, and New Zealand) made a high-level and <a href="https://www.youtube.com/watch?v=ikh3ncJZPTU">highly publicized</a> <a href="https://www.fbi.gov/news/press-releases/fbi-hosts-five-eyes-summit-to-launch-drive-to-secure-innovation-in-response-to-intelligence-threats">visit</a> <a href="https://www.ft.com/content/0a37da0a-ad06-43d0-b069-bfafa0ff35a4">to meet</a> with technology companies in Palo Alto, California, <a href="https://www.abc.net.au/news/2023-10-18/five-eyes-spy-summit-asio-cia-fbi-san-francisco/102984976">to discuss</a><a href="https://www.abc.net.au/news/2023-10-18/five-eyes-spy-summit-asio-cia-fbi-san-francisco/102984976"> a range of security topics</a>, including espionage threats from China. On top of there being no clear problem to solve, the amendments could chill companies from engaging with the government in this otherwise healthy exchange about technological innovations for fear of enticing the government to issue a notification notice. The open cooperative dynamic is at risk of being replaced by one that is defensive and adversarial.</p><p>Second, this new product approval regime could harm British users and other users around the world. A company that ultimately must capitulate to the surveillance demands of the government may end up offering services that are less secure generally, susceptible to compromise by bad actors, state sponsored or otherwise. Perhaps as a result, the U.K. will have its narrow surveillance needs met at a particular moment in time, but this would come at a great cost to those users specifically, and cybersecurity generally. One of us has <a href="https://www.judiciary.senate.gov/committee-activity/hearings/reforming-the-electronic-communications-privacy-act">testified</a> to Congress and one <a href="https://www.lawfaremedia.org/article/rethinking-encryption">written</a> at length about the importance, for example, of encryption in enhancing cybersecurity for society, while also working to <a href="https://carnegieendowment.org/2019/09/10/moving-encryption-policy-conversation-forward-pub-79573">find</a> a more effective path forward for everyone. This bill, if enacted, could easily be used to stifle the increased use of encryption to protect data security and privacy.<br></p><p>Third, enacting this bill will seemingly legitimize this heavy-handed approach for countries less steeped in the rule of law and with a lower regard for human rights. Should the current version of the amendments pass, even if U.K. authorities adhere in exemplary fashion to human rights and privacy concerns, other security services, especially in authoritarian-leaning countries, will not. They could endeavor to replicate the U.K.’s secretive power in order to undermine product security for their own aims, not only to surveil users but also to censor their communications. No country should expect it will necessarily be the beneficiary of the use of this new power to control and direct product development. It’s purportedly designed for use by the U.K. and for the U.K., though resulting insecurities will be there for any actor to exploit if they can find them.</p><p>The proposal also runs counter to other <a href="https://www.cisa.gov/sites/default/files/2023-10/SecureByDesign_1025_508c.pdf">efforts</a> by numerous governments—including the U.K.—to urge the private sector to find better ways to substantially enhance cybersecurity on a more sustainable basis. Instead of doing that, the bill, as currently drafted, jeopardizes data security and privacy in pursuit of an understandable goal of helping law enforcement and intelligence agencies’ legitimate objectives. But no one needs a law that could limit future progress on much-needed security enhancements, such as through the increased use of encryption. The bill needs to be fixed.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Americans are spending billions on stuff they forget to cancel (290 pts)]]></title>
            <link>https://www.wsj.com/business/cancel-subscriptions-save-money-streaming-peacock-da7e6123</link>
            <guid>39057993</guid>
            <pubDate>Fri, 19 Jan 2024 17:15:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/cancel-subscriptions-save-money-streaming-peacock-da7e6123">https://www.wsj.com/business/cancel-subscriptions-save-money-streaming-peacock-da7e6123</a>, See on <a href="https://news.ycombinator.com/item?id=39057993">Hacker News</a></p>
Couldn't get https://www.wsj.com/business/cancel-subscriptions-save-money-streaming-peacock-da7e6123: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Surf the web like it's 1999 (333 pts)]]></title>
            <link>https://billsworld.neocities.org/</link>
            <guid>39057862</guid>
            <pubDate>Fri, 19 Jan 2024 17:08:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://billsworld.neocities.org/">https://billsworld.neocities.org/</a>, See on <a href="https://news.ycombinator.com/item?id=39057862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <tbody><tr>
        <td>
          <p><span><b>I'm trapped in 1999 on GeoCities! I've made this time portal so you future people can visit my site.</b></span></p>
          
        </td>
      </tr>
    </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thailand finds 14.8M tonnes of lithium (381 pts)]]></title>
            <link>https://www.malaymail.com/news/money/2024/01/19/thailand-discovers-nearly-15-million-tonnes-of-lithium/113414</link>
            <guid>39057502</guid>
            <pubDate>Fri, 19 Jan 2024 16:44:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.malaymail.com/news/money/2024/01/19/thailand-discovers-nearly-15-million-tonnes-of-lithium/113414">https://www.malaymail.com/news/money/2024/01/19/thailand-discovers-nearly-15-million-tonnes-of-lithium/113414</a>, See on <a href="https://news.ycombinator.com/item?id=39057502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <div> <picture> <source media="(min-width: 786px)" data-srcset="https://cdn4.premiumread.com/?url=https://malaymail.com/malaymail/uploads/images/2024/01/19/180204.jpg&amp;w=800&amp;q=100&amp;f=jpg&amp;t=2" type="image/jpg"> <source data-srcset="https://cdn4.premiumread.com/?url=https://malaymail.com/malaymail/uploads/images/2024/01/19/180204.jpg&amp;w=400&amp;q=100&amp;f=jpg&amp;t=2" type="image/jpg"> <img src="https://www.malaymail.com/news/money/2024/01/19/thailand-discovers-nearly-15-million-tonnes-of-lithium/this.src='https://www.malaymail.com/malaymail/uploads/images/2024/01/19/180204.jpg';this.removeAttribute('onerror');" data-src="https://cdn4.premiumread.com/?url=https://malaymail.com/malaymail/uploads/images/2024/01/19/180204.jpg&amp;w=800&amp;q=100&amp;f=jpg&amp;t=2" alt="Thailand discovers nearly 15 million tonnes of lithium" title="Thailand discovers nearly 15 million tonnes of lithium" onerror="this.src='https://www.malaymail.com/malaymail/uploads/images/2024/01/19/180204.jpg';this.removeAttribute('onerror');"> </picture></div> <p>Aerial view of brine ponds and processing areas of the lithium mine of the Chilean company SQM (Sociedad Quimica Minera) in the Atacama Desert, Calama, Chile, on September 12, 2022. Thailand has discovered nearly 15 million tonnes of lithium deposits, a government spokesman said today, a boost for the kingdom's goal of becoming a regional hub for electric vehicle production. — AFP pic </p> </div><p>Join us on our <a href="https://whatsapp.com/channel/0029Va4r2QG9RZAZurce8h3Z" target="_blank" rel="nofollow">WhatsApp Channel</a>, follow us on <a href="https://instagram.com/themalaymail" target="_blank" rel="nofollow">Instagram</a>, and receive <span>browser alerts</span> for the latest news you need to know.</p><div> <p>Friday, 19 Jan 2024 7:00 PM MYT</p> </div><div> <p>Advertisement</p><p>BANGKOK, Jan 19 — Thailand has discovered nearly 15 million tonnes of lithium deposits, a government spokesman said today, a boost for the kingdom’s goal of becoming a regional hub for electric vehicle production.</p><p>The find means Thailand has the third largest lithium resources, behind Bolivia and Argentina, but it is not yet clear how much can be exploited commercially.</p><p>The 14.8 million tonnes of lithium are distributed between two separate sites in the southern province of Phang Nga, government deputy spokeswoman Rudklao Intawong Suwankiri told The Nation television station.</p><p>Advertisement</p><p>“We are trying to find out how much can we use from the resources we found. It takes time,” Rudklao told The Nation.</p><p>Lithium is a key component in the manufacture of batteries used in electric cars, as well as smartphones and other electronics.</p><p>The government of Prime Minister Srettha Thavisin, which took over in August, has made it a priority to try to boost Thailand as a regional production hub for electric vehicles, building on the kingdom’s history of assembling conventional cars.</p><p>Advertisement</p><p>During the World Economic Forum meeting in Davos, Srettha met industry leaders including the deputy chairman of Bosch to urge him to invest in EV production in Thailand.</p><p>“It’s good news. It’s an opportunity for Thailand to become self-reliant in the production of EV batteries,” Rudklao said of the lithium discovery.</p><p>In December 2023, two Chinese EV giants said they would invest 2.3 billion baht (RM301 million) to develop Thailand as a production hub. — AFP</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calculus on Computational Graphs: Backpropagation (2015) (131 pts)]]></title>
            <link>https://colah.github.io/posts/2015-08-Backprop/</link>
            <guid>39057461</guid>
            <pubDate>Fri, 19 Jan 2024 16:42:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://colah.github.io/posts/2015-08-Backprop/">https://colah.github.io/posts/2015-08-Backprop/</a>, See on <a href="https://news.ycombinator.com/item?id=39057461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrap">
                            
                            <p>Posted on August 31, 2015</p>
<br>

<h2 id="introduction">Introduction</h2>
<p>Backpropagation is the key algorithm that makes training deep models computationally tractable. For modern neural networks, it can make training with gradient descent as much as ten million times faster, relative to a naive implementation. That’s the difference between a model taking a week to train and taking 200,000 years.</p>
<p>Beyond its use in deep learning, backpropagation is a powerful computational tool in many other areas, ranging from weather forecasting to analyzing numerical stability – it just goes by different names. In fact, the algorithm has been reinvented at least dozens of times in different fields (see <a href="http://www.math.uiuc.edu/documenta/vol-ismp/52_griewank-andreas-b.pdf">Griewank (2010)</a>). The general, application independent, name is “reverse-mode differentiation.”</p>
<p>Fundamentally, it’s a technique for calculating derivatives quickly. And it’s an essential trick to have in your bag, not only in deep learning, but in a wide variety of numerical computing situations.</p>
<h2 id="computational-graphs">Computational Graphs</h2>
<p>Computational graphs are a nice way to think about mathematical expressions. For example, consider the expression <span>\(e=(a+b)*(b+1)\)</span>. There are three operations: two additions and one multiplication. To help us talk about this, let’s introduce two intermediary variables, <span>\(c\)</span> and <span>\(d\)</span> so that every function’s output has a variable. We now have:</p>
<p><span>\[c=a+b\]</span></p>
<p><span>\[d=b+1\]</span></p>
<p><span>\[e=c*d\]</span></p>
<p>To create a computational graph, we make each of these operations, along with the input variables, into nodes. When one node’s value is the input to another node, an arrow goes from one to another.</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-def.png" alt="">
</p>
<p>These sorts of graphs come up all the time in computer science, especially in talking about functional programs. They are very closely related to the notions of dependency graphs and call graphs. They’re also the core abstraction behind the popular deep learning framework <a href="http://deeplearning.net/software/theano/">Theano</a>.</p>
<p>We can evaluate the expression by setting the input variables to certain values and computing nodes up through the graph. For example, let’s set <span>\(a=2\)</span> and <span>\(b=1\)</span>:</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-eval.png" alt="">
</p>
<p>The expression evaluates to <span>\(6\)</span>.</p>
<h2 id="derivatives-on-computational-graphs">Derivatives on Computational Graphs</h2>
<p>If one wants to understand derivatives in a computational graph, the key is to understand derivatives on the edges. If <span>\(a\)</span> directly affects <span>\(c\)</span>, then we want to know how it affects <span>\(c\)</span>. If <span>\(a\)</span> changes a little bit, how does <span>\(c\)</span> change? We call this the <a href="https://en.wikipedia.org/wiki/Partial_derivative">partial derivative</a> of <span>\(c\)</span> with respect to <span>\(a\)</span>.</p>
<p>To evaluate the partial derivatives in this graph, we need the <a href="https://en.wikipedia.org/wiki/Sum_rule_in_differentiation">sum rule</a> and the <a href="https://en.wikipedia.org/wiki/Product_rule">product rule</a>:</p>
<p><span>\[\frac{\partial}{\partial a}(a+b) = \frac{\partial a}{\partial a} + \frac{\partial b}{\partial a} = 1\]</span></p>
<p><span>\[\frac{\partial}{\partial u}uv = u\frac{\partial v}{\partial u} + v\frac{\partial u}{\partial u} = v\]</span></p>
<p>Below, the graph has the derivative on each edge labeled.</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png" alt="">
</p>
<p>What if we want to understand how nodes that aren’t directly connected affect each other? Let’s consider how <span>\(e\)</span> is affected by <span>\(a\)</span>. If we change <span>\(a\)</span> at a speed of 1, <span>\(c\)</span> also changes at a speed of <span>\(1\)</span>. In turn, <span>\(c\)</span> changing at a speed of <span>\(1\)</span> causes <span>\(e\)</span> to change at a speed of <span>\(2\)</span>. So <span>\(e\)</span> changes at a rate of <span>\(1*2\)</span> with respect to <span>\(a\)</span>.</p>
<p>The general rule is to sum over all possible paths from one node to the other, multiplying the derivatives on each edge of the path together. For example, to get the derivative of <span>\(e\)</span> with respect to <span>\(b\)</span> we get:</p>
<p><span>\[\frac{\partial e}{\partial b}= 1*2 + 1*3\]</span></p>
<p>This accounts for how b affects e through c and also how it affects it through d.</p>
<p>This general “sum over paths” rule is just a different way of thinking about the <a href="https://en.wikipedia.org/wiki/Chain_rule#Higher_dimensions">multivariate chain rule</a>.</p>
<h2 id="factoring-paths">Factoring Paths</h2>
<p>The problem with just “summing over the paths” is that it’s very easy to get a combinatorial explosion in the number of possible paths.</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/chain-def-greek.png" alt="">
</p>
<p>In the above diagram, there are three paths from <span>\(X\)</span> to <span>\(Y\)</span>, and a further three paths from <span>\(Y\)</span> to <span>\(Z\)</span>. If we want to get the derivative <span>\(\frac{\partial Z}{\partial X}\)</span> by summing over all paths, we need to sum over <span>\(3*3 = 9\)</span> paths:</p>
<p><span>\[\frac{\partial Z}{\partial X} = \alpha\delta + \alpha\epsilon + \alpha\zeta + \beta\delta + \beta\epsilon + \beta\zeta + \gamma\delta + \gamma\epsilon + \gamma\zeta\]</span></p>
<p>The above only has nine paths, but it would be easy to have the number of paths to grow exponentially as the graph becomes more complicated.</p>
<p>Instead of just naively summing over the paths, it would be much better to factor them:</p>
<p><span>\[\frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)(\delta + \epsilon + \zeta)\]</span></p>
<p>This is where “forward-mode differentiation” and “reverse-mode differentiation” come in. They’re algorithms for efficiently computing the sum by factoring the paths. Instead of summing over all of the paths explicitly, they compute the same sum more efficiently by merging paths back together at every node. In fact, both algorithms touch each edge exactly once!</p>
<p>Forward-mode differentiation starts at an input to the graph and moves towards the end. At every node, it sums all the paths feeding in. Each of those paths represents one way in which the input affects that node. By adding them up, we get the total way in which the node is affected by the input, it’s derivative.</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/chain-forward-greek.png" alt="">
</p>
<p>Though you probably didn’t think of it in terms of graphs, forward-mode differentiation is very similar to what you implicitly learned to do if you took an introduction to calculus class.</p>
<p>Reverse-mode differentiation, on the other hand, starts at an output of the graph and moves towards the beginning. At each node, it merges all paths which originated at that node.</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/chain-backward-greek.png" alt="">
</p>
<p>Forward-mode differentiation tracks how one input affects every node. Reverse-mode differentiation tracks how every node affects one output. That is, forward-mode differentiation applies the operator <span>\(\frac{\partial}{\partial X}\)</span> to every node, while reverse mode differentiation applies the operator <span>\(\frac{\partial Z}{\partial}\)</span> to every node.<a href="#fn1" id="fnref1"><sup>1</sup></a></p>
<!--
The problem with just “summing over the paths” is that it’s very easy to get a combinatorial explosion in the number of possible paths.

<div style="width:70%; margin-left:auto; margin-right:auto; margin-bottom:17px; margin-top:17px;">
<img src="img/chain-def.png" alt="">
</div>

In the above diagram, there are three paths from $X$ to $Y$, and a further three paths from $Y$ to $Z$. If we want to get the derivative $\frac{\partial Z}{\partial X}$ by summing over all paths, we need to sum over $3*3 = 9$  paths:

$$\frac{\partial Z}{\partial X} = ad + ae + af + bd + be+bf + cd + ce + cf$$

The above only has nine paths, but it would be easy to have the number of paths to grow exponentially as the graph becomes more complicated.

Instead of just naively summing over the paths, it would be much better to factor them:

$$\frac{\partial Z}{\partial X} = (a+b+c)(d+e+f)$$

This is where "forward-mode differentiation" and "reverse-mode differentiation" come in. They’re algorithms for efficiently computing the sum by factoring the paths. Instead of summing over all of the paths explicitly, they compute the same sum more efficiently by merging paths back together as possible. In fact, both algorithms touch each edge exactly once!

Forward-mode differentiation starts at an input to the graph and moves towards the end. At every node, it sums all the paths feeding in. Each of those paths represents one way in which the input affects that node. By adding them up, we get the total way in which the node is affected by the input, it’s derivative.

<div style="width:70%; margin-left:auto; margin-right:auto; margin-bottom:17px; margin-top:17px;">
<img src="img/chain-forward.png" alt="">
</div>

Though you probably didn’t think of it in terms of graphs, forward-mode differentiation is very similar to what you implicitly learned to do if you took an introduction to calculus class.

Reverse-mode differentiation, on the other hand, starts at an output of the graph and moves towards the beginning. At each node, it merges all paths which originated at that node.

<div style="width:70%; margin-left:auto; margin-right:auto; margin-bottom:17px; margin-top:17px;">
<img src="img/chain-reverse.png" alt="">
</div>

Forward-mode differentiation tracks how one input affects every node. Reverse-mode differentiation tracks how every node affects one output. That is, forward-mode differentiation applies the operator $\frac{\partial}{\partial X}$ to every node, while reverse mode differentiation applies the operator $\frac{\partial Z}{\partial}$ to every node.[^DynamicProgramming]

[^DynamicProgramming]: This might feel a bit like [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming). That's because it is!
-->

<h2 id="computational-victories">Computational Victories</h2>
<p>At this point, you might wonder why anyone would care about reverse-mode differentiation. It looks like a strange way of doing the same thing as the forward-mode. Is there some advantage?</p>
<p>Let’s consider our original example again:</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png" alt="">
</p>
<p>We can use forward-mode differentiation from <span>\(b\)</span> up. This gives us the derivative of every node with respect to <span>\(b\)</span>.</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-forwradmode.png" alt="">
</p>
<p>We’ve computed <span>\(\frac{\partial e}{\partial b}\)</span>, the derivative of our output with respect to one of our inputs.</p>
<p>What if we do reverse-mode differentiation from <span>\(e\)</span> down? This gives us the derivative of <span>\(e\)</span> with respect to every node:</p>
<p><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-backprop.png" alt="">
</p>
<p>When I say that reverse-mode differentiation gives us the derivative of e with respect to every node, I really do mean <em>every node</em>. We get both <span>\(\frac{\partial e}{\partial a}\)</span> and <span>\(\frac{\partial e}{\partial b}\)</span>, the derivatives of <span>\(e\)</span> with respect to both inputs. Forward-mode differentiation gave us the derivative of our output with respect to a single input, but reverse-mode differentiation gives us all of them.</p>
<p>For this graph, that’s only a factor of two speed up, but imagine a function with a million inputs and one output. Forward-mode differentiation would require us to go through the graph a million times to get the derivatives. Reverse-mode differentiation can get them all in one fell swoop! A speed up of a factor of a million is pretty nice!</p>
<p>When training neural networks, we think of the cost (a value describing how bad a neural network performs) as a function of the parameters (numbers describing how the network behaves). We want to calculate the derivatives of the cost with respect to all the parameters, for use in <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. Now, there’s often millions, or even tens of millions of parameters in a neural network. So, reverse-mode differentiation, called backpropagation in the context of neural networks, gives us a massive speed up!</p>
<p>(Are there any cases where forward-mode differentiation makes more sense? Yes, there are! Where the reverse-mode gives the derivatives of one output with respect to all inputs, the forward-mode gives us the derivatives of all outputs with respect to one input. If one has a function with lots of outputs, forward-mode differentiation can be much, much, much faster.)</p>
<h2 id="isnt-this-trivial">Isn’t This Trivial?</h2>
<p>When I first understood what backpropagation was, my reaction was: “Oh, that’s just the chain rule! How did it take us so long to figure out?” I’m not the only one who’s had that reaction. It’s true that if you ask “is there a smart way to calculate derivatives in feedforward neural networks?” the answer isn’t that difficult.</p>
<p>But I think it was much more difficult than it might seem. You see, at the time backpropagation was invented, people weren’t very focused on the feedforward neural networks that we study. It also wasn’t obvious that derivatives were the right way to train them. Those are only obvious once you realize you can quickly calculate derivatives. There was a circular dependency.</p>
<p>Worse, it would be very easy to write off any piece of the circular dependency as impossible on casual thought. Training neural networks with derivatives? Surely you’d just get stuck in local minima. And obviously it would be expensive to compute all those derivatives. It’s only because we know this approach works that we don’t immediately start listing reasons it’s likely not to.</p>
<p>That’s the benefit of hindsight. Once you’ve framed the question, the hardest work is already done.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Derivatives are cheaper than you think. That’s the main lesson to take away from this post. In fact, they’re unintuitively cheap, and us silly humans have had to repeatedly rediscover this fact. That’s an important thing to understand in deep learning. It’s also a really useful thing to know in other fields, and only more so if it isn’t common knowledge.</p>
<p>Are there other lessons? I think there are.</p>
<p>Backpropagation is also a useful lens for understanding how derivatives flow through a model. This can be extremely helpful in reasoning about why some models are difficult to optimize. The classic example of this is the problem of vanishing gradients in recurrent neural networks.</p>
<p>Finally, I claim there is a broad algorithmic lesson to take away from these techniques. Backpropagation and forward-mode differentiation use a powerful pair of tricks (linearization and dynamic programming) to compute derivatives more efficiently than one might think possible. If you really understand these techniques, you can use them to efficiently calculate several other interesting expressions involving derivatives. We’ll explore this in a later blog post.</p>
<p>This post gives a very abstract treatment of backpropagation. I strongly recommend reading Michael Nielsen’s <a href="http://neuralnetworksanddeeplearning.com/chap2.html">chapter on it</a> for an excellent discussion, more concretely focused on neural networks.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Thank you to <a href="http://research.google.com/pubs/GregCorrado.html">Greg Corrado</a>, <a href="https://shlens.wordpress.com/">Jon Shlens</a>, <a href="http://bengio.abracadoudou.com/">Samy Bengio</a> and <a href="http://www.vision.caltech.edu/anelia/">Anelia Angelova</a> for taking the time to proofread this post.</p>
<p>Thanks also to <a href="https://www.linkedin.com/pub/dario-amodei/4/493/393">Dario Amodei</a>, <a href="http://michaelnielsen.org/">Michael Nielsen</a> and <a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a> for discussion of approaches to explaining backpropagation. Also thanks to all those who tolerated me practicing explaining backpropagation in talks and seminar series!</p>
<section>
<hr>
<ol>
<li id="fn1"><p>This might feel a bit like <a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a>. That’s because it is!<a href="#fnref1">↩</a></p></li>
</ol>
</section>




<section>
<hr>
<h4>More Posts</h4>

<a href="https://colah.github.io/posts/2014-07-Understanding-Convolutions/">
<div>
<p><img src="https://colah.github.io/posts/2014-07-Understanding-Convolutions/img/fig.png"></p><h3>Understanding Convolutions</h3>
</div>
</a>

<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">
<div>
<p><img src="https://colah.github.io/images/post-covers/lstm.png"></p><h3>Understanding LSTM Networks</h3>
</div>
</a>

<a href="https://colah.github.io/posts/2014-10-Visualizing-MNIST/">
<div>
<p><img src="https://colah.github.io/posts/2014-10-Visualizing-MNIST/img/fig.png"></p><h3>Visualizing MNIST</h3>
<h4>An Exploration of Dimensionality Reduction</h4>
</div>
</a>

<a href="https://colah.github.io/posts/2014-07-Conv-Nets-Modular/">
<div>
<p><img src="https://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/fig.png"></p><h3>Conv Nets</h3> <h4>A Modular Perspective</h4>
</div>
</a>

<!--



<a href="../../posts/2014-10-Visualizing-MNIST/">
<div class="post">
<img src="../../posts/2014-10-Visualizing-MNIST/img/fig.png">
<h3>Visualizing MNIST</h3>
<h4>An Exploration of Dimensionality Reduction</h4>
</div>
</a>

<a href="../../posts/2015-01-Visualizing-Representations/">
<div class="post">
<img src="../../posts/2015-01-Visualizing-Representations/img/fig.png">
<h3>Visualizing Representations</h3>
<h4>Deep Learning and Human Beings</h4>
</div>
</a>


<a href="../../posts/2014-07-Understanding-Convolutions/">
<div class="post">
<img src="../../posts/2014-07-Understanding-Convolutions/img/fig.png">
<h3>Understanding Convolutions</h3>
</div>
</a>


<a href="../../posts/2014-12-Groups-Convolution/">
<div class="post">
<img src="../../posts/2014-12-Groups-Convolution/img/fig.png">
<h3>Groups &amp; Group Convolutions</h3>
</div>
</a>

<a href="https://christopherolah.wordpress.com/2011/08/08/the-real-3d-mandelbrot-set/">
<div class="post">
<img src="../../images/post-covers/mandelbrot.png">
<h3>The Real 3D Mandelbrot Set</h3>
<h4 style="margin-top:2px;"><i>On my old blog</i></h4>
</div>
</a>

<a href="../../posts/2014-07-FFN-Graphs-Vis/">
<div class="post">
<img src="../../posts/2014-07-FFN-Graphs-Vis/img/graph-HP-ships-labeled.png">
<h3>Fanfiction, Graphs, and PageRank</h3>
</div>
</a>

-->

<br>

</section>









                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The 37signals Employee Handbook (111 pts)]]></title>
            <link>https://basecamp.com/handbook</link>
            <guid>39057340</guid>
            <pubDate>Fri, 19 Jan 2024 16:33:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://basecamp.com/handbook">https://basecamp.com/handbook</a>, See on <a href="https://news.ycombinator.com/item?id=39057340">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
      <strong>Heads up!</strong> This page uses features your browser doesn’t support. Try a modern browser like <a href="https://www.mozilla.org/en-US/firefox/new/" target="_blank" rel="noopener noreferrer">Firefox</a> or <a href="https://www.google.com/chrome/" target="_blank" rel="noopener noreferrer">Chrome</a> for the best experience.
    </p><div data-controller="bookmark anchors tweet" data-target="sidebar.content" data-action="click->sidebar#close mouseup->tweet#update input->tweet#update keydown->tweet#update scroll@window->tweet#update" data-bookmark-id="/handbook">
      <template data-target="anchors.iconTemplate"><svg class="icon icon--link" viewBox="0 0 85.69 85.69" xmlns="http://www.w3.org/2000/svg"><path d="m49.71 65.61c.78 0 1.25.14 1.42.42s0 .69-.59 1.25l-11.71 11.72a21.94 21.94 0 0 1 -16.07 6.69 21.94 21.94 0 0 1 -16.07-6.69 22.65 22.65 0 0 1 0-32.14l16.07-16.07a21.38 21.38 0 0 1 5.52-4 21.55 21.55 0 0 1 10.55-2.69h.33a26.68 26.68 0 0 1 8.37 1.67v.17a13.49 13.49 0 0 1 2.85 1.34 22.09 22.09 0 0 1 4.52 3.51 5.69 5.69 0 1 1 -8 8 11.31 11.31 0 0 0 -16.07 0l-16.1 16.11a11.3 11.3 0 0 0 0 16.06 10.92 10.92 0 0 0 8 3.35 10.92 10.92 0 0 0 8-3.35l6.53-6.52c.45-.45 1.62-.39 3.52.16a29.76 29.76 0 0 0 8.93 1.01zm13.22-65.61a21.94 21.94 0 0 1 16.07 6.69 21.94 21.94 0 0 1 6.69 16.07 21.92 21.92 0 0 1 -6.69 16.07l-16.07 16.07a22.23 22.23 0 0 1 -11.72 6.19c-.44.11-1 .22-1.5.33a14.75 14.75 0 0 1 -2.51.17 18.79 18.79 0 0 1 -2.51-.17c-1-.11-1.79-.22-2.35-.33-1-.22-1.67-.39-2-.5a22.66 22.66 0 0 1 -9.54-5.69 5.69 5.69 0 1 1 8-8 11.31 11.31 0 0 0 16.07 0l16.13-16.11a11 11 0 0 0 3.35-8 11 11 0 0 0 -3.35-8 11.3 11.3 0 0 0 -16.06 0l-6.7 6.69c-.45.45-1.62.39-3.51-.16a29.83 29.83 0 0 0 -8.87-1c-.79.11-1.26 0-1.43-.33s0-.78.59-1.34l11.84-11.96a21.92 21.92 0 0 1 16.07-6.69z"></path></svg></template>
      <template data-target="tweet.iconTemplate"><svg class="icon icon--twitter" viewBox="0 0 101.53 82.49" xmlns="http://www.w3.org/2000/svg"><path d="m91 20.62a18.68 18.68 0 0 1 .19 2.58 58.44 58.44 0 0 1 -4 20.92 66.22 66.22 0 0 1 -11.2 19 53.33 53.33 0 0 1 -18.84 14 59.6 59.6 0 0 1 -25.28 5.35 58.34 58.34 0 0 1 -31.87-9.3c1.72.13 3.37.2 5 .2a40.78 40.78 0 0 0 26-8.92 19.07 19.07 0 0 1 -12-4.07 20.6 20.6 0 0 1 -7.3-10.38 20.75 20.75 0 0 0 4.16.4 26.41 26.41 0 0 0 5.95-.6 18.82 18.82 0 0 1 -11.2-7.24 21.21 21.21 0 0 1 -4.26-13.21v-.35c0 .79.89 1.42 2.67 1.88a22.14 22.14 0 0 0 5.65.7 25.41 25.41 0 0 1 -7.53-7.58 17.48 17.48 0 0 1 -3-9.71 21.19 21.19 0 0 1 2.8-10.52 59.45 59.45 0 0 0 19.14 15.46 57.54 57.54 0 0 0 23.92 6.35 19.39 19.39 0 0 1 -.59-4.76 20 20 0 0 1 6.11-14.67 20.84 20.84 0 0 1 29.94.39 44.74 44.74 0 0 0 13.29-4.95 20.48 20.48 0 0 1 -9.32 11.5 42.27 42.27 0 0 0 12.1-3.37 45.93 45.93 0 0 1 -10.53 10.9z"></path></svg></template>

      



<p>Everything you need to know about making a career at 37signals.
</p>
<p><a data-target="bookmark.button" href="https://basecamp.com/handbook/getting-started">Start reading →</a></p>

<hr>

<p>In this handbook, you’ll find everything you need to know about 37signals policies and benefits. Hopefully it also offers a small peek at our culture.</p>
<p>If you’re new to the company, welcome! It’s important that you review everything in this handbook, so you know what’s expected of you and what you can expect from us. Please note that this handbook may be updated at any time, and it’s up to you to keep abreast of those updates – though we’ll do our best to notify all staff of major changes. GitHub repo is a great way to follow along with changes.</p>
<p>Please reach out to the People Ops team or to your manager if you have any questions about the information contained in this handbook.</p>

<hr>

<div>
    
    <h2>Introduction</h2>
    
    <ul>
    
      <li>
        <p>Chapter 1</p>
        <h3><a href="https://basecamp.com/handbook/getting-started">Getting Started</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 2</p>
        <h3><a href="https://basecamp.com/handbook/benefits-and-perks">Benefits &amp; Perks</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 3</p>
        <h3><a href="https://basecamp.com/handbook/how-we-work">How We Work</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 4</p>
        <h3><a href="https://basecamp.com/handbook/making-a-career">Making a Career</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 5</p>
        <h3><a href="https://basecamp.com/handbook/our-rituals">Our Rituals</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 6</p>
        <h3><a href="https://basecamp.com/handbook/managing-work-devices">Managing Work Devices</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 7</p>
        <h3><a href="https://basecamp.com/handbook/our-internal-systems">Our Internal Systems</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 8</p>
        <h3><a href="https://basecamp.com/handbook/moonlighting">A Note About Moonlighting</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 9</p>
        <h3><a href="https://basecamp.com/handbook/code-of-conduct">Code of Conduct</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 10</p>
        <h3><a href="https://basecamp.com/handbook/state-fmla">State Leave Provisions</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 11</p>
        <h3><a href="https://basecamp.com/handbook/titles-for-designers">Titles for Designers</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 12</p>
        <h3><a href="https://basecamp.com/handbook/titles-for-ops">Titles for Ops</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 13</p>
        <h3><a href="https://basecamp.com/handbook/titles-for-programmers">Titles for Programmers</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 14</p>
        <h3><a href="https://basecamp.com/handbook/titles-for-qa">Titles for QA</a></h3>
        <ul>
          
        </ul>
      </li>
    
      <li>
        <p>Chapter 15</p>
        <h3><a href="https://basecamp.com/handbook/titles-for-support">Titles for Support</a></h3>
        <ul>
          
        </ul>
      </li>
    
    </ul>
  </div>


      

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Good books on philosophy of engineering? (182 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39057219</link>
            <guid>39057219</guid>
            <pubDate>Fri, 19 Jan 2024 16:23:04 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39057219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39061079"><td></td></tr>
            <tr id="39061052"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39061052" href="https://news.ycombinator.com/vote?id=39061052&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>They say naming is one of the hard problems of computer science, but there's not much concrete work addressing it.<p>I'd recommend Elements of Clojure[0].</p><p>Don't be fooled by the title, it's not really about Clojure, it just uses Clojure as an illustration as it discusses a very subtle general problem. From the website:</p><p>&gt; The first chapter, Names, explains why names define the structure of our software, and how to judge whether a name is any good.</p><p>&gt; The second chapter, Idioms, provides specific, syntactic advice for writing Clojure which is clean and readable.</p><p>&gt; The third chapter, Indirection, looks at how code can be made simpler and more robust through separation.</p><p>&gt; The final chapter, Composition, explores how the constituent pieces of our code can be combined into an effective whole.</p><p>I find it a thoughtful and considerate overview of an area that everybody has some implicit knowledge of, and something that leads to a more abstract concept of quality.</p><p>[0]<a href="https://elementsofclojure.com/" rel="nofollow">https://elementsofclojure.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39061039"><td></td></tr>
            <tr id="39058027"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39058027" href="https://news.ycombinator.com/vote?id=39058027&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Don't overlook books that are critical of engineering as it is often practiced and how it fits into our society:<p><i>Computer Power and Human Reason</i> by Joseph Weizenbaum (1976).  Weizenbaum wrote
Eliza, the first AI chatbot, almost sixty years ago and was appalled at the reception.  This book is still very pertinent, especially the Introduction,
Chapter 1 On Tools, chapter 9, Incomprehensible Programs, and chapter 10,
Against the Imperialism of Instrumental Reason.  Chapter 4, Science and the Compulsive Programmer, is one of the first written accounts of the hacker culture.</p><p>Weizenbaum's original paper on Eliza (1966) [0] is still very pertinent to the present generation of chatbots, especially the introduction and discussion.</p><p><i>Tools for Conviviality</i>, Ivan Illich (1973) [1].  Influenced recent work
by the computer scientists Steven Kell [2],[3] and Kartik Agaram [4].</p><p><i>Computation and Human Experience</i>, Phil Agre (1997) (excerpt at [5]).  Agre
got a PhD in AI at MIT in the 80s and 90s and became very critical of the field.
I think his shorter writings [6][7] are a better introduction, especially the personal memoir at [6]:
"about how I became (relatively speaking, and in a small way) a better person through philosophy."</p><p>0. <a href="https://dl.acm.org/doi/10.1145/365153.365168" rel="nofollow">https://dl.acm.org/doi/10.1145/365153.365168</a></p><p>1. <a href="http://akkartik.name/illich.pdf" rel="nofollow">http://akkartik.name/illich.pdf</a></p><p>2. <a href="https://www.humprog.org/~stephen//research/talks/kell19de-escalating-intro-script.txt" rel="nofollow">https://www.humprog.org/~stephen//research/talks/kell19de-es...</a></p><p>3. <a href="https://www.humprog.org/~stephen//research/talks/kell19software-slides.pdf" rel="nofollow">https://www.humprog.org/~stephen//research/talks/kell19softw...</a></p><p>4. <a href="http://akkartik.name/akkartik-convivial-20200607.pdf" rel="nofollow">http://akkartik.name/akkartik-convivial-20200607.pdf</a></p><p>5. <a href="https://pages.gseis.ucla.edu/faculty/agre/che-intro.html" rel="nofollow">https://pages.gseis.ucla.edu/faculty/agre/che-intro.html</a></p><p>6. <a href="https://pages.gseis.ucla.edu/faculty/agre/notes/00-7-12.html" rel="nofollow">https://pages.gseis.ucla.edu/faculty/agre/notes/00-7-12.html</a></p><p>7. <a href="https://pages.gseis.ucla.edu/faculty/agre/critical.html" rel="nofollow">https://pages.gseis.ucla.edu/faculty/agre/critical.html</a>
              </p></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39060629"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39060629" href="https://news.ycombinator.com/vote?id=39060629&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>I’ll second this.  A philosophy for engineering is nestled I think in the larger “philosophy of technology”, but this field of philosophy has traditionally been a lot more critical of technology than most of us can stomach today.  This is a really good map of the field that not many know about, written in 1995:<p><a href="https://shaunlebron.github.io/chandler-1995.pdf" rel="nofollow">https://shaunlebron.github.io/chandler-1995.pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39060265"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39060265" href="https://news.ycombinator.com/vote?id=39060265&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>I can recommend a Philosophy of Software Design Paperback by John Ousterhout. I've been programming for 15 years and it closely parallels my own current beliefs about programming. He stands above the lower aspects of programming/code/modules, raising the discussion to a conceptual level, that you seem to be wanting. I think there were only 2 areas out of approximately 10 that I thought I had a few better ideas but a)He may have simplifying it to more easily allow explanation. b) His explanations are much better than mine and if I tried to explain it, maybe I'd fail.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39060910"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39060910" href="https://news.ycombinator.com/vote?id=39060910&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>A couple favorites that haven't been mentioned:<p>'An Introduction to General Systems Thinking', Weinberg, and he's got a dozen more worthwhile books behind it.</p><p>'The Logic of Failure: Recognizing and Avoiding Error in Complex Situations', Dietrich Dorner
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39059849"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059849" href="https://news.ycombinator.com/vote?id=39059849&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>I'm not sure if these books really are what you're looking for, because each of them is a mix of engineering history, and the description of how a group of people end up doing amazing things.
In each of the books, there were nuggets of wisdom that I've tried to bring along with me in my job (as best I can).
Like:<p>- Doing things as simply as possible to start off</p><p>- Keeping iteration time to a minimum, for maximum exploration of ideas</p><p>- Being willing to think outside the box</p><p>My takeaways above, hardly do these books justice, but they are as follows:</p><p>- Skunk Works: A Personal Memoir of My Years at Lockheed [0]</p><p>- Hackers: Heroes of the Computer Revolution. [1]</p><p>- The Dream Machine: J.C.R. Licklider and the Revolution That Made Computing Personal [2]</p><p>[0]: <a href="https://www.goodreads.com/book/show/101438.Skunk_Works" rel="nofollow">https://www.goodreads.com/book/show/101438.Skunk_Works</a></p><p>[1]: <a href="https://www.goodreads.com/book/show/56829.Hackers" rel="nofollow">https://www.goodreads.com/book/show/56829.Hackers</a></p><p>[2]: <a href="https://www.goodreads.com/book/show/722412.The_Dream_Machine" rel="nofollow">https://www.goodreads.com/book/show/722412.The_Dream_Machine</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39060436"><td></td></tr>
                  <tr id="39059513"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059513" href="https://news.ycombinator.com/vote?id=39059513&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>Richard Hamming’s The Art of Doing Science and Engineering is one that’s really shaped my philosophy on CS. It pushes for the importance of reasoning from first principles, experimentation, and taking on extraordinary work. There’s also a fascinating and prescient section on AI and the limits of computers and how we think about them. Stripe Press makes a nicely bound hardcover edition of the book, too:<p><a href="https://press.stripe.com/the-art-of-doing-science-and-engineering" rel="nofollow">https://press.stripe.com/the-art-of-doing-science-and-engine...</a></p><p>Heartily recommend!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39059380"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059380" href="https://news.ycombinator.com/vote?id=39059380&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>I recommend Shop Class as Soulcraft, which contrasts blue-collar work (motorcycle repair) with knowledge work. It's not specifically "tech"-related, but it does a good job of exploring how corporatization has diminished the ability to be a craftsperson in modern careers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39061023"><td></td></tr>
            <tr id="39059715"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39059715" href="https://news.ycombinator.com/vote?id=39059715&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>+1<p>I thought <i>Shop Class as Soulcraft</i> was <i>excellent</i> and found the author's theories on the lack of job and life satisfaction among those doing "knowledge work" compelling.</p><p>It reminded me of the movie Margin Call when Kevin Spacey's character, who manages a trading floor for a wall street investment firm, laments that if he'd been a ditch digger, at least he'd have a bunch of holes left behind as evidence he accomplished something.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39059596"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059596" href="https://news.ycombinator.com/vote?id=39059596&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>I am so happy to get all these responses! All of the resources look interesting!! 
I am going to start with Richard Hamming's The Art of Doing Science &amp; Engineering. It looks to be something to get started.<p>I have been wondering this question ever since, I wish I had reached out to request help earlier. I am glad I did, nonetheless. I am 26, hope there is a lot more to learn, apply &amp; build.</p><p>I am grateful to the universe (and the internet/hackernews).
Thank you :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057352"><td></td></tr>
                <tr id="39059804"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39059804" href="https://news.ycombinator.com/vote?id=39059804&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>Seconding this. It's an important book for all kinds of design<p>I would also recommend "Clean Code: A Handbook of Agile Software Craftsmanship" by Robert C. Martin. It focuses on crafting higher quality code, which is the property of it not only running well, but being easy to understand and to work on
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39060777"><td></td></tr>
            <tr id="39057920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057920" href="https://news.ycombinator.com/vote?id=39057920&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>A Philosophy of Software Design by John Ousterhout. The principles / approaches (e.g. problem disaggregation) apply to other engineering disciplines.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39060197"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39060197" href="https://news.ycombinator.com/vote?id=39060197&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>The Secret of Our Success: How Culture Is Driving Human Evolution, Domesticating Our Species, and Making Us Smarter<p>Engineers (and scientists) often boast ourselves as master of causality. We solve problem by understanding the domain. We laugh people as cargo-culting - not knowing why one does things. The Secret of Our Success shows it is a feature rather than a bug. The effect of "culture" takes much longer to manifest, often beyond our comprehension. One example given by the book is how we process cassava, lots of superfluous ritual. Without those processing culture, people get poisoned slowly. Only with modern chemistry do we comprehend the full extend of those ritual. But people have been eating cassava way before modern science were available. Similar can be said about medicine, lots of folk remedies don't work. But when they do, they do. Is not understanding a feature or a bug?</p><p>With the advent of LLM, things seem to come in full cycle. We now prompt the engine and get a result/an opinion of sort. No longer is understanding required. I see the use of LLM in software engineering very anti-engineering, hindrance to learning and understanding. But it might not be a bug after all.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39059341"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059341" href="https://news.ycombinator.com/vote?id=39059341&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Not totally what you are looking for, but I'd highlghly recommend "Apollo" by Murray and Cox. It focuses on the engineering history of the Apollo program, and it is a superbly well written and researched worked and so many of the stories are about engineering philosophy that I think it'll really be worth your while.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39060825"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39060825" href="https://news.ycombinator.com/vote?id=39060825&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>Seconded, phenomenal book and suggestion.<p>IMO in a similar vein is 'The Making of the Atomic Bomb', Richard Rhodes, another industry- and world-reshaping project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39059828"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39059828" href="https://news.ycombinator.com/vote?id=39059828&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>In a similar vein, there's "Skunk Works" by Ben Rich and Leo Janos, which covers the development of the U-2, F-117, and SR-17 aircraft. Not about the philosophy of engineering per se, but it's a great perspective into how problems were solved in a very unique program with extreme goals, before modern computer-aided tools.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39060415"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39060415" href="https://news.ycombinator.com/vote?id=39060415&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>It may be a bit more zoomed out than what you're looking for if you're specifically looking at philosophical treatments of the practice of engineering, but Andrew Feenberg's "Questioning Technology" is excellent introduction to the philosophy of technology, particularly exploring the interplay between technological constraint and political/economic/social drivers of its development.<p>"Philosophy of Technology" in general is a pretty rich field with a long history, and you might find more references in it than in engineering specifically.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39059054"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059054" href="https://news.ycombinator.com/vote?id=39059054&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>For software engineering, I recommend A Philosophy of Software Design. It has principles that I think translate well to other engineering fields.<p>For engineering in general:
To Engineer is Human - Henry Petroski
The Art of Doing Science and Engineering - Richard Hamming
Structures: Or Why Things Don't Fall Down - J.E. Gordon
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057606"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057606" href="https://news.ycombinator.com/vote?id=39057606&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Tao Te Ching, seriously<p>There is a lot of emphasis on simplicity and that things are the best when they work seamlessly.</p><p>Chapter 17, from the translation by Derek Lin, which I wholeheartedly recommend:</p><pre><code>    The highest rulers, people do not know they have them
    The next level, people love them and praise them
    The next level, people fear them
    The next level, people despise them</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39058526"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39058526" href="https://news.ycombinator.com/vote?id=39058526&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>There are several ways to approach the Tao Te Ching, including the mystical, but I think that there's a great book that explains the underlying approach the Chinese have,  called, Treatise on Efficacy.<p>Essentially, in Chinese philosophy, any given situation has a propensity (water tends to run downhill). It is therefore more effective to work with that propensity, than it is to work heroically against that propensity. This is very much a layer in what the Tao Te Ching talks about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39059575"><td></td></tr>
                <tr id="39060325"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39060325" href="https://news.ycombinator.com/vote?id=39060325&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>What's also interesting to me is that there are enough similarities between Vedic and ancient Greek thought, and yet here we are with Aristolean ideas in the West, and in India, things went the way of the Puranas. (Treatise of Efficacy went into the flaw baked into Aristolean thoughts separating Theory and Practice, and how going with the propensity bypasses that).<p>The Chinese word for this propensity of the situation is shi (勢), rather than dao (道). There are other texts that talk about exploiting and profiting from propensity (shi), rather than what the Dao De Jing talks about with wei wuwei (為無為).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39057772"><td></td></tr>
            <tr id="39058097"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39058097" href="https://news.ycombinator.com/vote?id=39058097&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Another great translation is by Witter Bynner - the book is titled The Way of Life rather than Tao Te Ching.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39058189"><td></td></tr>
                <tr id="39058836"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39058836" href="https://news.ycombinator.com/vote?id=39058836&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>This very thread inspired me to read not only this book, but also this particular translation.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39059942"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39059942" href="https://news.ycombinator.com/vote?id=39059942&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Read through the thread and didn't see references to the translation by Derek Lin, could you point to why you selected that version?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39060431"><td></td></tr>
                              <tr id="39058507"><td></td></tr>
                  <tr id="39060868"><td></td></tr>
            <tr id="39058618"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39058618" href="https://news.ycombinator.com/vote?id=39058618&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Philosophy of Computer Science: An Introduction to the Issues and the Literature<p>by William J. Rapaport - ( <a href="https://www.apaonline.org/news/254862/William-Rapaport-is-the-2015-Barwise-Prize-winner.htm" rel="nofollow">https://www.apaonline.org/news/254862/William-Rapaport-is-th...</a> )</p><p>&gt; The APA is pleased to announce that William Rapaport (University at Buffalo) has been selected by the APA committee on philosophy and computers as the winner of the 2015 Barwise Prize!</p><p>This corresponds to the class <a href="https://cse.buffalo.edu/~rapaport/510.html" rel="nofollow">https://cse.buffalo.edu/~rapaport/510.html</a></p><p><a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;query=Rapaport&amp;sort=byPopularity&amp;type=story" rel="nofollow">https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;que...</a></p><p>The table of contents can be read at <a href="https://www.wiley.com/en-us/Philosophy+of+Computer+Science%3A+An+Introduction+to+the+Issues+and+the+Literature-p-9781119891901" rel="nofollow">https://www.wiley.com/en-us/Philosophy+of+Computer+Science%3...</a></p><p>You are likely interested in sections 3.12 through 3.18</p><pre><code>    3.12 CS as Engineering 64
    3.13 Science xor Engineering? 66
    3.14 CS as “Both” 66
    3.15 CS as “More” 68
    3.15.1 CS as a New Kind of Science 68
    3.15.2 CS as a New Kind of Engineering 70
    3.16 CS as “Neither” 71
    3.16.1 CS as Art 71
    3.16.2 CS as the Study of Complexity 71
    3.16.3 CS as the Philosophy(!) of Procedures 72
    3.16.4 CS as Computational Thinking 72
    3.16.5 CS as AI 73
    3.16.6 Is CS Magic? 74
    3.17 Summary 76
    3.18 Questions for the Reader 77
</code></pre>
And section 5 which starts out with:<pre><code>    5 Engineering 95
    5.1 Defining ‘Engineering’ 95
    5.2 Engineering as Science 97
    5.3 A Brief History of Engineering 98
    5.4 Conceptions of Engineering 99
    5.5 What Engineers Do 100</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39057520"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057520" href="https://news.ycombinator.com/vote?id=39057520&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>Lewis Mumford's Books;<p>- Technics &amp; Civilization</p><p>- The Culture of Cities</p><p>- The Story of Utopias</p><p>Lewis Mumford talks about technology, but from an anthropological pint of view.</p><p>Another book I would recommend is <i>The Nature of Technology by Brian Arthur</i></p><p>The other I would recommend is James Burk's Connections he's has some books but I but the documentary is highly recommended.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057420"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057420" href="https://news.ycombinator.com/vote?id=39057420&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>I've just purchased Richard Hamming's "The Art of Doing Science and Engineering" but haven't read it all yet, it looks pretty great.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39058099"><td></td></tr>
            <tr id="39057897"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39057897" href="https://news.ycombinator.com/vote?id=39057897&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>I read it last year and it is <i>fantastic</i> - super absolutely ultra highly recommend that everybody read it. Run, don't walk, towards this book!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39057341"><td></td></tr>
                <tr id="39057378"><td></td></tr>
                  <tr id="39057387"><td></td></tr>
                <tr id="39057653"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39057653" href="https://news.ycombinator.com/vote?id=39057653&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>I've never understood what engineers find in this book. It looks like a shallow kitchen philosophy of a guy next door to me.<p>What you think is so good about this book for engineers, in a nutshell?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39058598"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39058598" href="https://news.ycombinator.com/vote?id=39058598&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>The core thing is exploring just exactly what is subjective and what is objective, and whether quality is subjective or objective. Pirsig came up with an answer, and then goes on to talk about excellence (arete). Thinking back, this discourse seems like it was deliberately embedded in a kind of every day, guy-next-door narrative in order to touch on lived experience of "quality".<p>Although Pirsig didn't explore it, quality is very much at the heart of any engineering, particularly when you try to quantify it. How effective is ISO-9000? GE was big on that. Boeing measured quality of their builds, until they compromised the process. What about Deming's approach (Total Quality Management)?</p><p>What is quality in software engineering? (We often sidestep that question and call it Software Craftsmanship instead).  And there's a whole can of worms when we try to apply this to AIs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39058112"><td></td></tr>
                <tr id="39059537"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39059537" href="https://news.ycombinator.com/vote?id=39059537&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>I read the book completely. The book was on a second year reading list for my industrial design department.<p>I absorbed as an introduction to the philosophical aspects of quality. Quality is truly a tough concept if approached as a universal truth.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39060262"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39060262" href="https://news.ycombinator.com/vote?id=39060262&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>That makes sense to me. I'm not sure how to articulate what I got out of that book exactly but I did enjoy it. Some of the more 'spiritual' books I find, the value of them doesn't really hit you until you're older or have had some tragic life experiences happen. Until then some of it can just make you feel "this is some vapid feel-good hippie crap." Not saying that was your reaction of course but it makes sense to me why you might not vibe with it if you read it in a university setting.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39058963"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39058963" href="https://news.ycombinator.com/vote?id=39058963&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>+1. It can become a ramble at times and full-time philosophers seem to hate it. On the other hand, there is a lot of practical wisdom in the first half of the book, and what I consider to be a good payoff if you stick through to the end.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39058737"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39058737" href="https://news.ycombinator.com/vote?id=39058737&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>Coincidentally I just started reading <i>Engineering: A Very Short Introduction</i> by David Blockley. I was very excited after the first chapter: it has a lot of profound ideas about engineering at large. Did you know that "engineer" does not derive from "someone who cares for Industrial Revolution era engines" but rather stems from a Latin / old French word for "ingenious"?? The second chapter feels a bit thrown together; i.e. the author seems to struggle a bit to unite all the events coherently. I think it's safe to say however that this book will give a broad overview of the long-term historical trends in the discipline, which is foundational for any type of philosophical understanding.<p>P.S. I love the VSI series. Fits in my back pocket and usually gives a satisfying overview of a discipline. I always get a few fascinating ideas from every book. I've read probably 20 from the series at this point.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39058566"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39058566" href="https://news.ycombinator.com/vote?id=39058566&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>“The effective engineer” by Edmond Lau is a good book for the IC software engineer working in an engineering organization.<p>The most influential content on engineering in my life is not in a book but a YouTube talk entitled How Complex Systems Fail by Richard Cook, which is about designing resilient systems. I’ve applied these ideas to many aspects of life, not just engineering.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057952"><td></td></tr>
                <tr id="39058105"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39058105" href="https://news.ycombinator.com/vote?id=39058105&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>Yes! Christopher Alexander is a must-read for engineers. Notes on the Synthesis of Form is also very excellent.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39057930"><td></td></tr>
            <tr id="39060224"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39060224" href="https://news.ycombinator.com/vote?id=39060224&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>I recommend Marvin Minisckys society of minds book. He was one of founding fathers of AI tech, the book tells lot about human mind an Interesting read.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39057351"><td></td></tr>
            <tr id="39057573"><td></td></tr>
            <tr id="39058336"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39058336" href="https://news.ycombinator.com/vote?id=39058336&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>Systemantics, AKA "The Systems Bible: The Beginner's Guide to Systems Large and Small" by John Gall.<p>It is offered from the perspective of how not to design systems, based on system engineering failures. The primary precept of the treatise is that large complex systems are extremely difficult to design correctly despite best intentions, so care must be taken to design smaller, less-complex systems and to do so with incremental functionality based on close and continual touch with user needs and measures of effectiveness.</p><p><a href="https://en.wikipedia.org/wiki/Systemantics" rel="nofollow">https://en.wikipedia.org/wiki/Systemantics</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057339"><td></td></tr>
            <tr id="39057576"><td></td></tr>
                <tr id="39058170"><td></td></tr>
                  <tr id="39057722"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057722" href="https://news.ycombinator.com/vote?id=39057722&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>I can't understate just how <i>great</i> "Waking Up: Overcoming the Obstacles to Human Potential" by Charles Tart (2001) is. It's a cross between engineering and the spirituality (although I argue, it's more on the philosophy and psychoanalysis  of engineering than spiritual).<p>I wrote a (short) review on the book directly after reading it here[1]. I've since reread the book, and while some of my opinions on it are the same, some I understand the nuance much more in context of the rest of the book, I need to update it.</p><p>1. <a href="https://macleodsawyer.com/books/waking-up/" rel="nofollow">https://macleodsawyer.com/books/waking-up/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39059682"><td></td></tr>
            <tr id="39059833"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39059833" href="https://news.ycombinator.com/vote?id=39059833&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>The Things We Make by Bill Hammack<p>Changed my way of understanding what engineering is. Read the chaoter on designing cathedrals without math, science or modelling.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057767"><td></td></tr>
            <tr id="39057705"><td></td></tr>
            <tr id="39057508"><td></td></tr>
            <tr id="39057803"><td></td></tr>
            <tr id="39057512"><td></td></tr>
            <tr id="39059822"><td></td></tr>
            <tr id="39057467"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057467" href="https://news.ycombinator.com/vote?id=39057467&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><p><span>If you seek elightment, you seek truth. Look down towards foundations like physics, mathematics, logic and look back towards the past.<p>It' smaybe check out the Computer History Museum.</p><p>Read Feynman's (or about) books. "Surely you're joking, Mr Feynman" is light but profound. Max Tegmark's "Our Mathematical Universe" is great. "I am a strange loop"  by Douglas Hofstadter will connect many dots. If you want to peek deeper - "Through two doors at once" describes experiments at the edge of our reality. "The singularity is near" is a good perspective that connects dots through time back many years to many in the future.</p><p>These are just some incomplete starter points. It's deep, beautiful rabbit hole. Enjoy it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39057488"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39057488" href="https://news.ycombinator.com/vote?id=39057488&amp;how=up&amp;goto=item%3Fid%3D39057219"></a></center>    </td><td><br><div>
                  <p><span>I like to recommend "Kill It With Fire" by Marianne Bellotti. It is full of insights far beyond managing legacy systems (as the subtitle would have you believe) and does a great job of analyzing the technology and the people/organizations who build it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39057355"><td></td></tr>
            <tr id="39058152"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sourcehut network outage post-mortem (233 pts)]]></title>
            <link>https://sourcehut.org/blog/2024-01-19-outage-post-mortem/</link>
            <guid>39056902</guid>
            <pubDate>Fri, 19 Jan 2024 15:55:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sourcehut.org/blog/2024-01-19-outage-post-mortem/">https://sourcehut.org/blog/2024-01-19-outage-post-mortem/</a>, See on <a href="https://news.ycombinator.com/item?id=39056902">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p>It’s been a busy couple of weeks here at SourceHut. At the time of writing, we
have restored SourceHut to full service following an unprecedented 170 hour
outage, and while we still have numerous kinks to sort out following an
unscheduled emergency migration of all services across an ocean, all services
are now fully operational.</p>
<p>Allow me to open this post-mortem by extending my deepest apologies to the
SourceHut community for this interruption in service. This outcome was
unacceptable: we failed you, and I am sorry. We know that you depend on
SourceHut to be reliable, and you trust us to make sure that you can always
depend on our services to be there for your projects. We value this trust
profoundly, and we will strive to prevent a situation like the one we faced last
week from recurring. The Internet can be a fragile place, and we will do what we
can to re-enforce it.</p>
<p>Here’s what happened, what we did about it, how we’re making things right, and
what we’re doing to ensure it does not happen again.</p>
<h2 id="background">Background</h2>
<p>SourceHut runs on servers owned and provisioned by SourceHut, installed in
colocation facilities at three datacenters, respectively codenamed PHL, AMS, and
FRE. PHL was our primary datacenter, FRE was used for off-site backups, and AMS
was a research installation intended for a future migration of our production
infrastructure in PHL and next-generation deployment of SourceHut intended to
scale into the indefinite future.</p>
<p>We have been setting up an installation in AMS for researching a future
infrastructure migration to the EU and means of increasing our resilience and
redundancy, which we had planned to gradually roll out with minimal disruption
to user service over the course of at least a year. In the end, we rolled it out
with maximum disruption to user service in 7 days. The AMS datacenter
installation was provisioned according to a projected research workload with an
eye towards expanding it to support a full SourceHut installation in the future;
at the time of the incident it was provisioned at a scale appropriate for
running <em>most</em> of a SourceHut installation.</p>
<p>Our FRE datacenter is used for off-site backups. We maintain a Postgres standby
which is replicated in real-time and is usually up-to-date within seconds of
production, as well as daily backups of large data silos such as git.sr.ht. We
have a comprehensive monitoring system in place which, among monitoring other
systems, keeps track of these backups and notifies us when their metrics fall
outside of our window; for instance we receive an alarm if the database replica
is more than 5 minutes behind production of if large storage backups exceed 48
hours.</p>
<p>We maintain a comprehensive set of operational plans for responding to various
incidents which may arise, ranging from hard drive failure up to and including
the complete failure of a datacenter, which proved to be important when
addressing this scenario. We also have standard response times for responding to
various tolerances being exceeded which are designed to minimize user impact;
for instance we configure the storage utilization alarms with sufficient lead
time to provision additional storage.</p>
<p>The complete failure of a datacenter is the most challenging situation we have
prepared for, and it is the situation with which we were ultimately faced.</p>
<h2 id="the-incident">The incident</h2>
<p>At around 06:00 UTC on January 10th, a layer 3 distributed denial-of-service
(DDoS) attack began to target SourceHut’s PHL infrastructure. We routinely deal
with and mitigate application layer (layer 7) DDoS attacks, however, a layer 3
attack takes place at a lower level and is not within our ability to mitigate
without the assistance of our network provider. Starting from about 06:00, our
monitoring systems noticed that something was wrong and raised the alarm, and we
started investigating the issue shortly thereafter. However, before we could get
a handle on the situation, our access to the PHL network completely disappeared
at around 09:00 UTC.</p>
<p><img src="https://sourcehut.org/january-outage.png" alt="Screenshot of our monitoring system detecting problems"></p>
<div><p>
  We never received any kind of ransom note or other communication from the
  attacker. We do not know who was behind the attack, nor their motivations, and
  likely never will. We know that they targeted SourceHut specifically, and that
  they followed us as we worked on mitigations, directing their attack at new
  infrastructure as it was being set up.</p><p>
  In this post-mortem we are going to focus on the impact on our network and the
  steps we took to restore service, rather than going into what we know of the
  attack and the details of our mitigations, both for information security
  reasons and to avoid lending legitimacy to a bad actor. In the end, the
  response to the attack from our upstream network in PHL did more damage to our
  infrastructure than anything else.
</p></div>
<p>We rent network service in PHL from our colocation provider, who provisions a
subnet out of their AS and routes it through Cogent and Level 3. In response to
the attack, Cogent announced null routes for our downstream AS, causing our
PHL network to become unreachable both for SourceHut staff and the general
public.</p>
<p>We attempted to contact our colocation provider at this point, but we were
unsuccessful. Our provider in PHL has been acquired twice over the past couple
of years, and it seems that the ticketing portal we were used to paging them
with had been deprecated and our account had not been migrated to the new
system. We were unable to reach them until their normal office hours opened at
14:00 UTC. Our provider restored our access to the priority ticketing system and
began to investigate the issue. Eventually they were able to convince Cogent to
reduce the null route from our entire /24 to a narrower /32 focusing on the
specific IP address being targeted by the DDoS. As a result, service was mostly
restored by 18:00 UTC.</p>
<p>At about 06:30 UTC the following morning, the DDoS escalated and broadened its
targets to include other parts of our PHL subnet. In response, our colocation
provider null routed our subnet once again. This subnet has been unreachable
ever since.</p>
<p>At 09:00 UTC, I made the call to perform an emergency migration to AMS and
restore from backups. We began urgently planning the scope of this work, making
an assessment of our backups and the Amsterdam installation’s capacity to host
a fully functional SourceHut installation, and planning the work that needed to
be done. We verified the health of FRE and AMS and our backup systems, finding
that our standby database was less than 30 seconds out of date with production
and that our large storage backups were no more than 12 hours old. We found that
AMS was in good health and we touched up a few research systems (e.g. Ceph) to
bring them to production readiness.</p>
<p>What essentially followed was creating a new installation of SourceHut from
scratch, importing production data, testing and verifying the installation, and
bringing it online for user service on a new DDoS-resistant network. This
involved hundreds of small tasks that we planned out and distributed among
ourselves and executed as urgently as possible, the full details are too
involved to repeat here. However, the general plan had the following broad
strokes:</p>
<ul>
<li>Migrate to external DNS</li>
<li>Bring up a new primary database</li>
<li>Restore backups from FRE to AMS</li>
<li>Migrate object storage from PHL to AMS</li>
<li>Bring up database-only services, such as meta, todo, project hub</li>
<li>Bring up large storage services as backup restores finish</li>
<li>Manually apply the diff between production data and the last backups</li>
<li>Provisioning a new mail system and configuring mail services for it</li>
<li>Identify a suitable DDoS-resistant network to bring us into general service</li>
<li>Provision servers to backfill AMS capacity to production readiness</li>
<li>Test the new systems and bring them into general service</li>
</ul>
<p>All of this work happened in parallel and had cross-dependencies, so from here
on out we will omit some timestamps.</p>
<p><strong>Network solutions</strong></p>
<p>The selection of a suitable network to bring into service that would not
immediately collapse as the DDoS attack followed us presented some challenges.
First, this was a layer 3 attack, which can essentially only be mitigated by
having more bandwidth than the attacker and/or by filtering traffic at a
location suitably far upstream. Furthermore, many DDoS protection systems only
operate at the application layer, namely for the web as the application in
question, whereas SourceHut has user-facing services through not only HTTPS but
also SSH, SMTP, and IRC; moreover we strongly prefer to utilize end-to-end
encryption on all traffic and terminate it on SourceHut-operated infrastructure.</p>
<p>We initially researched a number of solutions, and spoke to CloudFlare in
particular due to their ability to provide a rapid response to ongoing
incidents. However, given our complex requirements, CloudFlare quoted us a
figure which was not attainable within our financial means as a small company.
Other options we researched (though we did not seek additional quotes) had
similar economical constraints. However, we found that OVH’s anti-DDoS
protections were likely suitable: they are effective, and their cost is
amortized across all OVH users, and therefore of marginal cost to us. To this
end the network solution we deployed involved setting up an OVH box to NAT
traffic through OVH’s DDoS-resistant network and direct it to our (secret)
production subnet in AMS; this met our needs for end-to-end encryption as well
as service over arbitrary TCP protocols.</p>
<p>We also got in contact with our network operator in AMS and explained the
situation to them. We found some solutions to mitigate attacks directed at AMS
but we will not disclose details regarding the AMS network for reasons of
information security.</p>
<p>We made some mistakes throughout the operation, rsyncs done incorrectly,
networks misconfigured, and so on. One particularly amusing mis-step occurred
when we configured the NAT through OVH: we naively NAT’d all traffic through to
AMS, and when the attack resumed targeting our OVH infrastructure, the inbound
DDoS was briefly forwarded to AMS before OVH’s mitigations kicked in, which made
our brand new OVH account look like the source of an <em>outgoing</em> DDoS, with
predicable consequences that took some work to resolve with OVH.</p>
<p>Following our initial quote from CloudFlare, we understand that some CloudFlare
employees undertook a grassroots effort internally to convince the leadership to
sponsor our needs, and eventually CloudFlare came back to us with an offer to
sponsor our services for us free of charge. This was a very generous offer for
which we are very appreciative; in the end we did not take them up on it as we
had made substantial inroads towards an alternative solution by that time. I
have had my reservations about CloudFlare in the past, but they were there for
us in a time of need and I am grateful for that.</p>
<p>On January 12th, our network provider in PHL agreed to provision a temporary
subnet through which we could receive out-of-band access to our PHL servers.
We were able to speed up the provisioning of replacement infrastructure thanks
to this being made available.</p>
<p><strong>Provisioning services</strong></p>
<p>Efforts to restore individual SourceHut services came with a variety of
challenges. Some of them were fairly straightforward; services like paste and
the project hub depend only on a working SQL server and once we had that in
place we were able to restore them to service at about 19:00 UTC on January
11th.</p>
<p>git.sr.ht and hg.sr.ht had special considerations due to the large amount of
data they were responsible for. We restored them from backups to read-only
service based on somewhat stale data by 20:00 UTC, and restored to full
read/write service by 11:00 UTC on January 13th. We also did our best with
hg.sr.ht, but it is community maintained and restoring service was delayed until
we could get the community maintainer, Ludovic Chabant, online to help; it was
fully restored at 08:20 UTC on January 15th.</p>
<p>pages.sr.ht also presented unique challenges due to its use of an S3-compatible
object storage solution, which we discovered was not considered in our off-site
backups. However, it was a priority to restore service to bring online the
numerous personal and project websites which depend on pages.sr.ht. Migrating
object storage from PHL to AMS is a slow procedure which is still underway now,
we are running pages through an out-of-band link to PHL which comes with some
performance limitations but provides service while the slower migration process
is underway in the background. Pages also had to be moved to a new subnet and IP
address, which posed a problem for users who configured their apex records to
point directly to the PHL subnet; we have now emailed affected users with
instructions for manual intervention.</p>
<p>chat.sr.ht also poses some unique constraints due to its approach to networking;
for a number of reasons we implement outbound IRC connections on a unique IPv6
address per-user. Preparing the requisite network infrastructure and bringing it
online required special considerations and as a consequence chat.sr.ht was the
last service to be restored to full operation at 10:30 UTC on January 17th.</p>
<p>builds.sr.ht also required some extra considerations due to the fact that our
research installation in AMS was under-provisioned for its compute requirements.
Currently we are running build workers on dedicated baremetal OVH servers and we
are planning to bring build service back onto SourceHut-operated infrastructure
once we are able to ship our builds-oriented compute servers from PHL to AMS in
the coming weeks. We began accepting build jobs again at 18:00 UTC on January
16th.</p>
<p>All told, we began restoring partial service availability on the afternoon of
January 12th, and gradually brought up services over the following days until
full service was restored on the morning of January 17th. Following the
complete restoration of service we credited all paying SourceHut users with 7
days of free service.</p>
<h2 id="whats-next">What’s next</h2>
<p>We have completed all user-facing steps required to restore SourceHut to full
service. However, we have numerous tasks to perform internally to put the
finishing touches on the new installation and to clean up workarounds and hacks
put in place to restore service as quickly as possible. We have an internal
bugtracker with about 60 post-incident tasks to be completed, some of which are
finished and others which are still underway: for instance, we have provisioned
a new standby database, configured backups from AMS =&gt; FRE, and we are working
on installing a new monitoring system.</p>
<p>We are also deprecating our PHL datacenter installation entirely. We still
cannot reach the network there, and the operator has egregiously exceeded their
SLA with us. We will pack up the servers in PHL and ship them to AMS to
supplement capacity there.</p>
<p>Ironically, this emergency migration allowed us to quickly achieve many of the
long-term goals we had in mind for migrating to the EU. We are now running
almost entirely on European infrastructure and we quickly finished bringing many
of our plans to ensure future scalability and reliability of SourceHut
infrastructure to production readiness. We had planned to do these upgrades
without user impact, but, well, alas.</p>
<p>Part of the work involved in setting up the AMS datacenter installation was
geared towards increasing resilience, reliability, and redundancy, and reducing
the impact of attacks and outages of this nature. SourceHut is still in an
“alpha” state, and though we have built a platform that is sophisticated and
depended on by numerous free software projects, that comes with some caveats.
This incident exposed one such caveat, a shortcoming that we were aware of and
actively working on improving, but which was exploited before we could complete
our goals for redundancy and resilience. Our definition of production readiness,
our “definition of done” for the alpha, includes building infrastructure that
prevents this kind of outcome. We have made unexpectedly urgent inroads on these
milestones, and we will continue to build out these solutions as part of our
work to bring SourceHut from alpha to beta to production.</p>
<p>In the service of this work, we have been researching a solution for running
SourceHut in an on-premise Kubernetes cluster (cue gasp from the audience). The
migration to AMS did not involve a migration to Kubernetes, but it did put us in
a better position to expedite that work. We intend to utilize this work to
reduce user-impacting downtime during internal maintenance, such as when scaling
up our infrastructure or upgrading software, but also to improve our resistance
to events such as the one that transpired this week. Once we have completed an
implementation of this solution, we will be planning out a secondary
production-ready datacenter which we can load balance against and which can step
up to take on full service in the event of a datacenter outage, as well as
making it easier to conduct the procedures that we employed this week to stand
up SourceHut from scratch in a new datacenter should the need ever arise again.</p>
<p>As unfortunate as these events were, we welcome opportunities to stress-test our
emergency procedures; we found them to be compatible with our objectives for the
alpha and we learned a lot of ways to improve our reliability further for the
future. We are going to continue working on our post-incident tasks, building up
our infrastructure’s resilience, reliability, and scalability as planned. Once
we address the high-priority tasks, though, our first order of business in the
immediate future will be to get some rest.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I’d to acknowledge those who helped us in this difficult time. Of course, I
extend my thanks to the rest of the staff, Simon and Conrad, whose long hours of
work ensured we could restore service for our customers as quickly as possible.
I would also like to thank the staff and network operators at our various
datacenter locations, for their role in facilitating our needs in the rapid
bring-up of new infrastructure. Thanks especially to the community members who
sent us their words of support and kindness, and offers of aid, via email,
Mastodon, on IRC, and so on.</p>
<p>Thanks are also due to our peer in the free-software-forge space, Codeberg. They
hosted our status page prior to the incident, and likely faced their own DDoS
attack in retaliation for the services they provided to us. We shared
information across our teams extensively and their communication and
relationship with SourceHut has always been superb.</p>
<p>I’d also like to thank the team at CloudFlare; though we did not accept your
generous offer we were appreciative that you were there for us in a time of
need.</p>
<p>On a personal note, I would like to thank my fiancé for their patience and
unwavering emotional support during a challenging time.</p>
<p>Thank you all for your patience and support.</p>
<p>– Drew DeVault</p>

      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canadian man stuck in triangle of e-commerce fraud (248 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/01/canadian-man-stuck-in-triangle-of-e-commerce-fraud/</link>
            <guid>39056733</guid>
            <pubDate>Fri, 19 Jan 2024 15:37:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/01/canadian-man-stuck-in-triangle-of-e-commerce-fraud/">https://krebsonsecurity.com/2024/01/canadian-man-stuck-in-triangle-of-e-commerce-fraud/</a>, See on <a href="https://news.ycombinator.com/item?id=39056733">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>A Canadian man who says he’s been falsely charged with orchestrating a complex e-commerce scam is seeking to clear his name. His case appears to involve “triangulation fraud,” which occurs when a consumer purchases something online — from a seller on <strong>Amazon</strong> or <strong>eBay</strong>, for example — but the seller doesn’t actually own the item for sale. Instead, the seller purchases the item from an online retailer using stolen payment card data. In this scam, the unwitting buyer pays the scammer and receives what they ordered, and very often the only party left to dispute the transaction is the owner of the stolen payment card.</p>
<div id="attachment_32692"><p><img aria-describedby="caption-attachment-32692" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2015/11/triangulationfraud.png" alt="" width="637" height="349" srcset="https://krebsonsecurity.com/wp-content/uploads/2015/11/triangulationfraud.png 637w, https://krebsonsecurity.com/wp-content/uploads/2015/11/triangulationfraud-580x318.png 580w" sizes="(max-width: 637px) 100vw, 637px"></p><p id="caption-attachment-32692">Triangulation fraud. Image: eBay Enterprise.</p></div>
<p><strong>Timothy Barker</strong>, 56, was until recently a Band Manager at <a href="https://www.duncansfirstnation.com/" target="_blank" rel="noopener">Duncan’s First Nation</a>, a First Nation in northwestern Alberta, Canada. A <a href="https://www.fnha.ca/Documents/Band_Manager.pdf" target="_blank" rel="noopener">Band Manager</a> is responsible for overseeing the delivery of all Band programs, including community health services, education, housing, social assistance, and administration.</p>
<p>Barker told KrebsOnSecurity that during the week of March 31, 2023 he and the director of the Band’s daycare program discussed the need to purchase items for the community before the program’s budget expired for the year.</p>
<p>“There was a rush to purchase items on the Fiscal Year 2023 timeline as the year ended on March 31,” Barker recalled.</p>
<p>Barker said he bought seven “Step2 All Around Playtime Patio with Canopy” sets from a seller on <strong>Amazon.ca</strong>, using his payment card on file to pay nearly $2,000 for the items.</p>
<p>On the morning of April 7, Barker awoke to a series of nasty messages and voice calls on Facebook from an Ontario woman he’d never met. She demanded to know why he’d hacked her <strong>Walmart</strong> account and used it to buy things that were being shipped to his residence. Barker shared a follow-up message from the woman, who later apologized for losing her temper.</p>
<div id="attachment_66119"><p><img aria-describedby="caption-attachment-66119" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/01/tri-fbmsg.png" alt="" width="309" height="603"></p><p id="caption-attachment-66119">One of several messages from the Ontario woman whose Walmart account was used to purchase the goods that Barker ordered from Amazon.</p></div>
<p>“If this is not the person who did this to me, I’m sorry, I’m pissed,” the lady from Ontario said. “This order is being delivered April 14th to the address above. If not you, then someone who has the same name. Now I feel foolish.”</p>
<p>On April 12, 2023, before the Amazon purchases had even arrived at his home, Barker received a call from an investigator with the <strong>Royal Canadian Mounted Police</strong> (RCMP), who said Barker urgently needed to come down to the local RCMP office for an interview related to “an investigation.” Barker said the officer wouldn’t elaborate at the time on the nature of the investigation, and that he told the officer he was in Halifax for several days but could meet after his return home.</p>
<p>According to Barker, the investigator visited his home anyway the following day and began questioning his wife, asking about his whereabouts, his work, and when he might return home.</p>
<p>On April 14, six boxes arrived to partially fulfill his Amazon order; another box was delayed, and the Amazon.ca seller he’d purchased from said the remaining box was expected to ship the following week. Barker said he was confused because all six boxes came from Walmart instead of Amazon, and the shipping labels had his name and address on them but carried a contact phone number in Mexico.</p>
<p>Three days later, the investigator called again, demanding he submit to an interview.</p>
<p>“He then asked where my wife was and what her name is,” Barker said. “He wanted to know her itinerary for the day. I am now alarmed and frightened — this doesn’t feel right.”</p>
<p>Barker said he inquired with a local attorney about a consultation, but that the RCMP investigator showed up at his house before he could speak to the lawyer. The investigator began taking pictures of the boxes from his Amazon order.</p>
<p>“The [investigator] derisively asked why would anyone order so many play sets?” Barker said. “I started to give the very logical answer that we are helping families improve their children’s home life and learning for toddlers when he cut me off and gave the little speech about giving a statement after my arrest. He finally told me that he believes that I used someone’s credit card in Ontario to purchase the Walmart products.”</p>
<p>Eager to clear his name, Barker said he shared with the police copies of his credit card bills and purchase history at Amazon. But on April 21, the investigator called again to say he was coming to arrest Barker for theft.</p>
<p>“He said that if I was home at five o’clock then he would serve the papers at the house and it would go easy and I wouldn’t have to go to the station,” Barker recalled. “If I wasn’t home, then he would send a search team to locate me and drag me to the station. He said he would kick the door down if I didn’t answer my phone. He said he had every right to break our door down.”</p>
<p>Barker said he briefly conferred with an attorney about how to handle the arrest. Later that evening, the RCMP arrived with five squad cars and six officers.</p>
<p>“I asked if handcuffs were necessary – there is no danger of violence,” Barker said. “I was going to cooperate. His response was to turn me around and cuff me. He walked me outside and stood me beside the car for a full 4 or 5 minutes in full view of all the neighbors.”</p>
<p><img decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/01/barker-k-div.png" alt="" width="750" height="494" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/01/barker-k-div.png 879w, https://krebsonsecurity.com/wp-content/uploads/2024/01/barker-k-div-768x506.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/01/barker-k-div-782x515.png 782w" sizes="(max-width: 750px) 100vw, 750px"></p>
<p>Barker believes he and the Ontario woman are both victims of triangulation fraud, and that someone likely hacked the Ontario woman’s Walmart account and added his name and address as a recipient.</p>
<p>But he says he has since lost his job as a result of the arrest, and now he can’t find new employment because he has a criminal record. Barker’s former employer — Duncan’s First Nation — did not respond to requests for comment.</p>
<p>“In Canada, a criminal record is not a record of conviction, it’s a record of charges and that’s why I can’t work now,” Barker said. “Potential employers never find out what the nature of it is, they just find out that I have a criminal arrest record.”<span id="more-65740"></span></p>
<p>Barker said that right after his arrest, the RCMP called the Ontario woman and told her they’d solved the crime and arrested the perpetrator.</p>
<p>“They even told her my employer had put me on administrative leave,” he said. “Surely, they’re not allowed to do that.”</p>
<p>Contacted by KrebsOnSecurity, the woman whose Walmart account was used to fraudulently purchase the child play sets said she’s not convinced this was a case of triangulation fraud. She declined to elaborate on why she believed this, other than to say the police told her Barker was a bad guy.</p>
<p>“I don’t think triangulation fraud was used in this case,” she said. “My actual Walmart.ca account was hacked and an order was placed on my account, using my credit card. The only thing Mr. Barker did was to order the item to be delivered to his address in Alberta.”</p>
<p>Barker shared with this author all of the documentation he gave to the RCMP, including screenshots of his Amazon.ca account showing that the items in dispute were sold by a seller named “<strong>Adavio</strong>,” and that the merchant behind this name was based in Turkey.</p>
<p><img decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/01/adavio-convo.png" alt="" width="751" height="439" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/01/adavio-convo.png 954w, https://krebsonsecurity.com/wp-content/uploads/2024/01/adavio-convo-768x449.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/01/adavio-convo-782x457.png 782w" sizes="(max-width: 751px) 100vw, 751px"></p>
<p>That <a href="https://www.amazon.ca/sp?seller=A2H83L9DLFWTSS&amp;marketplaceID=A2EUQ1WTGCTBG2" target="_blank" rel="noopener">Adavio account</a> belongs to a young computer engineering student and “SEO expert” based in Adana, Turkey who did not respond to requests for comment.</p>
<p>Amazon.ca said it conducted an investigation and found that Mr. Barker never filed a complaint about the seller or transaction in question. The company noted that Adavio currently has a feedback rating of 4.5 stars out of 5.</p>
<p>“Amazon works hard to provide customers with a great experience and it’s our commitment to go above and beyond to make things right for customers,” Amazon.ca said in a written statement. “If a customer has an issue with an order, they may flag to Amazon through our <a href="http://www.amazon.ca/contact-us" target="_blank" rel="noopener">Customer Service</a> page.”</p>
<p>Barker said when he went to file a complaint with Amazon last year he could no longer find the Adavio account on the website, and that the site didn’t have a category for the type of complaint he wanted to file.</p>
<p>When he first approached KrebsOnSecurity about his plight last summer, Barker said he didn’t want any media attention to derail the chances of having his day in court, and confronting the RCMP investigator with evidence proving that he was being wrongfully prosecuted and maligned.</p>
<p>But a week before his court date arrived at the end of November 2023, prosecutors announced the charges against him would be stayed, meaning they had no immediate plans to prosecute the case further but that the investigation could still be reopened at some point in the future.</p>
<p>The RCMP declined to comment for this story, other than to confirm they had issued a stay of proceedings in the case.</p>
<p>Barker says the stay has left him in legal limbo — denying him the ability to clear his name, while giving the RCMP a free pass for a botched investigation. He says he has considered suing the investigating officer for defamation, but has been told by his attorney that the bar for success in such cases against the government is extremely high.</p>
<p>“I’m a 56-year-old law-abiding citizen, and I haven’t broken any laws,” Barker said, wondering aloud who would be stupid enough to use someone else’s credit card and have the stolen items shipped directly to their home.</p>
<p>“Their putting a stay on the proceedings without giving any evidence or explanation allows them to cover up bad police work,” he said. “It’s all so stupid.”</p>
<p>Triangulation fraud is hardly a new thing. KrebsOnSecurity first wrote about it <a href="https://krebsonsecurity.com/2015/11/how-carders-can-use-ebay-as-a-virtual-atm/" target="_blank" rel="noopener">from an e-commerce vendor’s perspective in 2015</a>, but the scam predates that story by many years and is now a well-understood problem. The Canadian authorities should either let Mr. Barker have his day in court, or drop the charges altogether.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan's first-ever soft lunar landing with SLIM spacecraft [video] (182 pts)]]></title>
            <link>https://www.youtube.com/watch?v=2-yBlZplnKQ</link>
            <guid>39056403</guid>
            <pubDate>Fri, 19 Jan 2024 15:06:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=2-yBlZplnKQ">https://www.youtube.com/watch?v=2-yBlZplnKQ</a>, See on <a href="https://news.ycombinator.com/item?id=39056403">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers claim first functioning graphene-based chip (267 pts)]]></title>
            <link>https://spectrum.ieee.org/graphene-semiconductor</link>
            <guid>39056169</guid>
            <pubDate>Fri, 19 Jan 2024 14:52:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/graphene-semiconductor">https://spectrum.ieee.org/graphene-semiconductor</a>, See on <a href="https://news.ycombinator.com/item?id=39056169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Researchers Claim First Functioning Graphene-Based Chip" data-elid="2666939920" data-post-url="https://spectrum.ieee.org/graphene-semiconductor" data-authors="Dexter Johnson" data-page-title="Researchers Claim First Functioning Graphene-Based Chip - IEEE Spectrum"><p>Researchers at Georgia Tech, in Atlanta, have developed what they are calling the world’s first functioning graphene-based semiconductor. This breakthrough holds the promise to revolutionize the landscape of electronics, enabling faster traditional computers and offering a new material for future quantum computers.</p><p>The research, published on 3 January in <em><a href="https://www.nature.com/articles/s41586-023-06811-0.epdf?sharing_token=63dOXeqzwcz5dCsrIo3TmNRgN0jAjWel9jnR3ZoTv0Mk9sT-x6tC4Rl7pLb2XsMtCLW-zV3dUDHJA5r4iJpAz3hD2JqvFPiFGk-_s_spjoJwuE2-TNBA4IVFG2WOV814NY9PqJ9yrLbZo4F28px7DIK70H08ETunekEsC_iuXuafEjnh7_V_xVINx4nUFMII-qHJq4KltgH8d8-PLFPVDs6evelDIh4GK-nrzbOnaPloYlmcX4wqeE6vBmRNqxrWxgGfevjXYMKNy_kqTn9KmqD3GplkC-KMt-zig6F1A-3r5-gJJlLKInKg3shnR-5WkOpCsJu3TLXa6uRmnXQyzeoYb-pWw7zLCpsobNpa_j4%3D&amp;tracking_referrer=www.livescience.com" rel="noopener noreferrer" target="_blank">Nature</a></em>and led by <a href="https://physics.gatech.edu/user/walter-de-heer" target="_blank">Walt de Heer</a>, a professor of physics at Georgia Tech, focuses on leveraging <a href="https://spectrum.ieee.org/graphene-makes-infinite-copies-of-exotic-semiconductor-wafers" target="_self">epitaxial graphene</a>, a crystal structure of carbon chemically bonded to silicon carbide (SiC). This novel semiconducting material, dubbed semiconducting epitaxial graphene (SEC)—or alternatively, epigraphene—boasts enhanced electron mobility compared with that of traditional silicon, allowing electrons to traverse with significantly less resistance. The outcome is transistors capable of operating at <a href="https://spectrum.ieee.org/tag/terahertz">terahertz</a> frequencies, offering speeds 10 times as fast as that of the silicon-based transistors used in current chips.</p><p>De Heer describes the method used as a modified version of an extremely simple technique that has been known for over 50 years. “When silicon carbide is heated to well over 1,000 °C, silicon evaporates from the surface, leaving a carbon-rich surface which then forms into graphene,” says de Heer.</p><p><span data-rm-shortcode-id="f39dee4faa95ab323c590a3424e8fee2"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/gWUX2OTqkEo?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">Georgia Tech Researchers Create First Functional Graphene Semiconductor</small></p><p>This heating step is done with an argon quartz tube in which a stack of two SiC chips are placed in a graphite crucible, according to de Heer. Then a high-frequency current is run through a copper coil around the quartz tube, which heats the graphite crucible through induction. The process takes about an hour. De Heer added that the SEC produced this way is essentially charge neutral, and when exposed to air, it will spontaneously be doped by oxygen. This oxygen doping is easily removed by heating it at about 200 °C in vacuum.</p><p>“The chips we use cost about [US] $10, the crucible about $1, and the quartz tube about $10,” said de Heer. </p><p>While it has been known since 2008 that it’s possible to make graphene behave like a semiconductor by heating it in a vacuum with SiC, it’s the method developed by de Heer that makes the difference in the bandgap. <strong></strong>“If it is done correctly, using the modified method described above, then the bonding is very regular and the mobility is very large, as we have shown in the paper,” says de Heer.</p><p>Semiconductors—critical components in any electronic device—exhibit properties of both conductors and insulators. However, silicon, the predominant material for <a href="https://spectrum.ieee.org/topic/semiconductors/">semiconductors</a>, is reaching its limits in terms of speed, heat generation, and miniaturization. De Heer underscores that the swift progress witnessed throughout the history of computing is <a href="https://spectrum.ieee.org/the-moores-law-machine" target="_blank">decelerating due to these constraints</a> on silicon.</p><p>“We have produced large areas of semiconducting SEC on defect-free, atomically flat SiC terraces.” <strong>—Walt de Heer, Georgia Tech</strong></p><p>Graphene, a single layer of carbon atoms arranged in a hexagonal lattice, is emerging as a superior conductor to silicon, facilitating more efficient electron movement through the material. Despite these advantages, previous endeavors to integrate graphene into electronics faced challenges due to the absence of a <a href="https://spectrum.ieee.org/samsung-creates-a-graphene-transistor-with-a-band-gap-and-electron-mobility" target="_self">bandgap</a>, a critical factor for transistors to switch on and off.</p><p>There has been a decade’s worth of work in developing functional opportunities with graphene, which involves chemically bonding atoms to the graphene so that it exhibits a bandgap. De Heer notes that previous methods resulted in low-mobility semiconducting graphene due to various issues in either its chemical or mechanical makeup.</p><p>For instance, <a href="https://spectrum.ieee.org/potential-of-graphene-nanoribbons-in-electronics-gets-a-boost" target="_self">graphene ribbons</a> have been seen as promising, but they are only semiconducting with very specific widths and armchair edges that are inversely proportional to the ribbon width. These ribbons are best made by chemical means, and ultimately must be accurately deposited on substrate and then interconnected with metallic wires.</p><p>“There has been some success with graphene nanoribbons, but in principle this technology is very similar to semiconducting carbon-nanotube technology which has not been successful after 30 years of nanotube research,” says de Heer.</p><p>Another method that has been used to give graphene a bandgap is putting <a href="https://spectrum.ieee.org/the-new-wrinkle-in-graphene-is-wrinkles" target="_self">wrinkles</a> into the material. Mechanical deformations will open a bandgap, and bandgaps up to 0.2 electron volts have been demonstrated. (For comparison, silicon has a bandgap of 1.12 eV, which is significantly larger.) The small bandgap makes it unclear how these materials could be used in applications, while the relative lack of information on their mobilities adds another complication.</p><p>“Our research is distinct from these other approaches because we have produced large areas of semiconducting SEC on defect-free, atomically flat SiC terraces,” says de Heer. “SiC is a highly developed, readily available electronic material that is fully compatible with conventional microelectronics processing methods.”</p><p>Elaborating on the potential applications of their breakthrough, the researchers noted that graphene-based semiconductors could play a pivotal role in <a href="https://spectrum.ieee.org/tag/quantum-computing">quantum computing</a>. This is due to the fact that when graphene is used in devices at very low temperatures, its electrons exhibit quantum-mechanical wavelike properties like those seen in light.</p><p>“One main aspect of graphene electronics is that we can utilize the quantum-mechanical wave properties of the electrons and [electron] holes which are not accessible in silicon electronics,” says de Heer. “If this is possible, then that constitutes a paradigm shift in electronics.”<strong></strong></p><p>“The chips we use cost about $10, the crucible about $1, and the quartz tube about $10.” <strong>—Walt de Heer, Georgia Tech</strong></p><p>De Heer and his research team concede, however, that further exploration is needed to determine whether graphene-based semiconductors can surpass the current superconducting technology used in advanced quantum computers.</p><p>The Georgia Tech team do not envision incorporating graphene-based semiconductors with standard silicon or compound semiconductor lines. Instead, they are aiming for a paradigm shift beyond silicon, utilizing silicon carbide. They are developing methods, such as coating SEC with boron nitride, to protect and enhance its compatibility with conventional semiconductor lines.</p><p>Comparing their work with commercially available graphene field-effect transistors (GFETs), de Heer explains that there is a crucial difference: “Conventional GFETs do not use semiconducting graphene, making them unsuitable for digital electronics requiring a complete <a href="https://spectrum.ieee.org/tag/transistor">transistor</a> shutdown.” He says that the SEC developed by his team allows for a complete shutdown, meeting the stringent requirements of digital electronics.</p><p>De Heer says that it will take time to develop this technology. “I compare this work to the Wright brothers’ first 100-meter flight. It will mainly depend on how much work is done to develop it.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX launches 4 people for private mission to the International Space Station (136 pts)]]></title>
            <link>https://www.npr.org/2024/01/18/1225191541/spacex-nasa-axiom-space-ax-3-international-space-station-iss</link>
            <guid>39055896</guid>
            <pubDate>Fri, 19 Jan 2024 14:33:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/01/18/1225191541/spacex-nasa-axiom-space-ax-3-international-space-station-iss">https://www.npr.org/2024/01/18/1225191541/spacex-nasa-axiom-space-ax-3-international-space-station-iss</a>, See on <a href="https://news.ycombinator.com/item?id=39055896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="res1225482590">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                A SpaceX Falcon 9 rocket with its Crew Dragon capsule launches from pad LC-39A during Axiom Space's Ax-3 Mission at the Kennedy Space Center, in Cape Canaveral, Fla., on January 18, 2024.
                <b aria-label="Image credit">
                    
                    Chandan Khanna/AFP via Getty Images
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Chandan Khanna/AFP via Getty Images
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935916851_wide-e14f48d6cfeab182b186d422ae20607bebe188e6-s1200.jpg">
        </picture>
    </div>
<div>
        <p>A SpaceX Falcon 9 rocket with its Crew Dragon capsule launches from pad LC-39A during Axiom Space's Ax-3 Mission at the Kennedy Space Center, in Cape Canaveral, Fla., on January 18, 2024.</p>
        <p><span aria-label="Image credit">
            
            Chandan Khanna/AFP via Getty Images
            
        </span>
    </p></div>
   </div>
   <p>The first all-European commercial crew is on its way to the International Space Station after an early evening SpaceX launch from the Kennedy Space Center in Florida. </p>   <p>Unlike a NASA mission, this one is paid for by <a href="https://www.axiomspace.com/">Axiom Space</a>, a Houston-based company flying its third group of paying passengers to the I.S.S. It contracts with SpaceX to get to and from the orbital laboratory. Axiom plans to build its own space station in orbit one day and it's using these missions to help in its planning and designs. </p>   <p>An attempt to launch the mission Wednesday was called off several hours before its scheduled flight. SpaceX and Axiom said they needed additional time "to complete pre-launch checkouts and data analysis, <a href="https://www.npr.org/2022/05/24/1101040178/parachutes-for-spacecraft-are-challenging-to-design-and-worrisome-to-engineers">including the parachute system</a> energy modulator." <a href="https://twitter.com/SpaceX/status/1747986011563720972">The next day SpaceX said</a>, "all systems are looking good for today's launch" without elaborating further. </p>   
   <p>The capsule will take the next 36 hours racing to catch up to the I.S.S. as it circles about 250 miles above Earth. After docking, the crew will spend two weeks on the orbital laboratory <a href="https://www.axiomspace.com/news/ax3-lrr-prelaunch-advisory">performing about 30 experiments</a>, including "microgravity research, technology demonstrations, and outreach engagements," according to Axiom. </p>   
   
<!-- END ID="RES1225200836" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>This mission, called Ax-3, is flying a <a href="https://www.spacex.com/vehicles/dragon/">SpaceX Crew Dragon</a> spacecraft named <em>Freedom</em>. The capsule has flown in space twice previously and gone to the International Space Station each time (<a href="https://www.npr.org/2020/11/17/935635454/4-astronauts-aboard-spacex-crew-dragon-successfully-dock-with-space-station">Crew-4</a> in 2022 and <a href="https://www.npr.org/2023/05/31/1179002653/space-x-axiom-space-mission">Ax-2 </a>in 2023). <em>Freedom</em> has spent a total of 179 days in space.</p>   <p>The Ax-3 crew is led by <a href="https://twitter.com/CommanderMLA/status/1748033111420534823">Axiom chief astronaut Michael López-Alegría</a> (A dual U.S.-Spanish citizen and former NASA astronaut and ISS commander). He'll serve as the Ax-3 commander and is joined by three paying passengers: Pilot Walter Villadei of the Italian Air Force, and mission specialists Alper Gezeravcı of Turkey and Marcus Wandt of Sweden and the European Space Agency.</p>   <p>For Gezeravcı, who is the first Turkish astronaut to go to space, "This spaceflight is not a destination but a journey. This is just the beginning of our journey - for a long growing space journey in our future."</p>   <p>The Ax-3 crew will join seven other people currently on the I.S.S.</p>   <div id="res1225401225">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Members of the Axiom Space's Ax-3 mission (from left to right), Mission Specialist Marcus Wandt of Sweden, Mission Specialist Alper Gezeravcı of Turkey, Pilot Walter Villadei of Italy and Commander Michael López-Alegría of Spain, arrive at NASA's Kennedy Space Center in Cape Canaveral, Fla., on January 18, 2024.
                <b aria-label="Image credit">
                    
                    Gregg Newtown/AFP via Getty Images
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Gregg Newtown/AFP via Getty Images
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/01/18/gettyimages-1935909781_custom-2845b4e00de224be45ce20f081f6630aa8e58b46-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Members of the Axiom Space's Ax-3 mission (from left to right), Mission Specialist Marcus Wandt of Sweden, Mission Specialist Alper Gezeravcı of Turkey, Pilot Walter Villadei of Italy and Commander Michael López-Alegría of Spain, arrive at NASA's Kennedy Space Center in Cape Canaveral, Fla., on January 18, 2024.</p>
        <p><span aria-label="Image credit">
            
            Gregg Newtown/AFP via Getty Images
            
        </span>
    </p></div>
   </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Haier Threatens Legal Action Against Home Assistant Plugin Developer (126 pts)]]></title>
            <link>https://hackaday.com/2024/01/19/haier-threatens-legal-action-against-home-assistant-plugin-developer/</link>
            <guid>39055768</guid>
            <pubDate>Fri, 19 Jan 2024 14:22:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackaday.com/2024/01/19/haier-threatens-legal-action-against-home-assistant-plugin-developer/">https://hackaday.com/2024/01/19/haier-threatens-legal-action-against-home-assistant-plugin-developer/</a>, See on <a href="https://news.ycombinator.com/item?id=39055768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
    

    <p><a href="#content">Skip to content</a></p><!-- #masthead -->

    <div id="content">
        <main id="main" role="main">

        
            
<article itemscope="" itemtype="http://schema.org/Article" id="post-657217">
    <!-- .entry-header -->

    <div itemprop="articleBody">
        <p>Appliance manufacturer Haier has been integrating IoT features into their newer products, and as is so common these days, users are expected to install their “hOn” mobile application to access them. Not satisfied with that limitation, [Andre Basche] reverse engineered the protocol used by the app, and released a Python library and associated Home Assistant plugin to interface with a wide array of Haier appliances, which includes brands like Hoover, Candy, GE Appliances and others.</p>
<p>Unfortunately, it looks like his efforts have gotten him into a bit of legal hot water. In an <a href="https://github.com/Andre0512/hon/issues/147" target="_blank">issue recently opened on the project’s GitHub page</a>, [Andre] explains the circumstances and legal options that have led him to consider pulling the repositories completely — mostly due to the cost of mounting a legal defense to the cease &amp; desist from Haier Europe.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg" target="_blank"><img decoding="async" data-attachment-id="657228" data-permalink="https://hackaday.com/2024/01/19/haier-threatens-legal-action-against-home-assistant-plugin-developer/haierhq/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg" data-orig-size="3280,2540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;14&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 5D Mark II&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1398771076&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;14&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="HaierHQ" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?w=800" src="https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?w=400" alt="" width="400" height="310" srcset="https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg 3280w, https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?resize=250,194 250w, https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?resize=400,310 400w, https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?resize=800,620 800w, https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?resize=1536,1189 1536w, https://hackaday.com/wp-content/uploads/2024/01/HaierHQ.jpg?resize=2048,1586 2048w" sizes="(max-width: 400px) 100vw, 400px"></a>What’s ironic here is that <a href="https://corporate.haier-europe.com/press-release/hon-joins-csa-connectivity-standard-alliance/" target="_blank">Haier has been part of</a> the Connectivity Standard Alliance (CSA) since 2022, whose goal is to ‘promote universal open IoT standards’, including Matter.</p>
<p>It’s possible that a legal defense will be mounted against this C&amp;D from Haier within the coming days. Yet regardless of the outcome here, it remains problematic that these IoT-enabled Haier appliances are connected to the Haier servers. Ideally they would be controlled locally, which is the goal of projects like [Miguel Ángel López Vicente]’s <a href="https://github.com/MiguelAngelLV/esphaier" target="_blank">ESP Haier</a>, that uses an ESP8266 to connect Haier AC units to the local WiFi and e.g. HA instances, all without requiring internet access.</p>
<p>This is sadly just one more example of why <a href="https://hackaday.com/2024/01/09/how-to-build-a-fully-offline-smart-home-or-why-you-should-not/">building your own off-line smart home</a> can be such an incredible struggle.</p>
<p>Thanks to [Ar3itrary] for the tip.</p>
	            </div><!-- .entry-content -->
    
    <!-- .entry-footer -->
</article><!-- #post-## -->

            	<!-- .navigation -->
	
            

            
<!-- #comments -->

        
        

        
        

        
        </main><!-- #main -->
    </div><!-- #content -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[French cheese under threat from lack of microbial diversity (147 pts)]]></title>
            <link>https://news.cnrs.fr/articles/french-cheese-under-threat</link>
            <guid>39055506</guid>
            <pubDate>Fri, 19 Jan 2024 14:01:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.cnrs.fr/articles/french-cheese-under-threat">https://news.cnrs.fr/articles/french-cheese-under-threat</a>, See on <a href="https://news.ycombinator.com/item?id=39055506">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
      
  Cheeses host a multitude of microorganisms that turn milk into curds. Selected by humans, these ferments are not exempt from food industry regulations – to the point that blue cheeses and Camembert could disappear.      </p><div>
      
  <p><span><span><span lang="EN-GB" xml:lang="EN-GB">Ever heard of Termignon blue? This little-known cheese, produced by just a few farms in the French Alps, could well save the entire blue cheese industry, which is threatened with extinction due to the standardisation of production processes. This is because its characteristic blue-green mould comes from a previously unknown population of <em>Penicillium roqueforti</em>, the fungus used in the fermentation of all blue and veined cheeses. The discovery is a bombshell in the world of cheese.</span></span></span></p>
<div>
    
  <p><img src="https://news.cnrs.fr/sites/default/files/styles/asset_image_full/public/assets/images/13474953_hires_french_bleu_de_termignon_cow_s_milk_blue_cheese_72dpi.jpg?itok=aiVom38U" width="664" height="443" alt="" title=" © Science Photo Library / DK "></p><div>
  <p>
          Termignon blue, made in the Savoie region in the French Alps, naturally develops a blue-green mould, unlike other blue cheeses that are inoculated with “Penicillium”.      <a href="#image-aid-6146"><i></i></a>      </p>
</div>
  </div>
<p><span><span><em>“Until now, only four populations of the </em>P. roqueforti <em>species were known in the world,” </em>reports Jeanne Ropars, who, with Tatiana Giraud and their team at the ESE<a id="footnoteref1_ucidwlb" title="Laboratoire Écologie, Systématique et Évolution (CNRS / AgroParisTech / Université Paris-Saclay)." href="#footnote1_ucidwlb">1</a> in Gif-sur-Yvette (near Paris), has successfully sequenced the genome of the microorganism responsible for the fermentation of Termignon blue.</span></span></p>
<p><span><span><span lang="EN-GB" xml:lang="EN-GB">This consists in <em>“two ‘wild’ </em></span><em><span lang="EN-GB" xml:lang="EN-GB">populations</span></em><span lang="EN-GB" xml:lang="EN-GB"><em>, involved in the rotting of fruit, the decomposition of certain foods and silage </em>(the fermentation of fodder for livestock - Editor's note),<em> plus another two used in cheese production”</em>, the researcher specifies. Of the two domesticated </span><span lang="EN-GB" xml:lang="EN-GB">populations</span><span lang="EN-GB" xml:lang="EN-GB">, one is specifically dedicated to PDO (Protected Designation of Origin) Roquefort, whereas all the other blue cheeses are inoculated with a single strain of <em>P. roqueforti</em>.</span></span></span></p>
<p><span><span>To produce cheese in large quantities, manufacturers have selected fungus strains that meet their self-imposed specifications. The cheeses must be appealing, with a good flavour, no unappetising colours and no mycotoxins (toxins secreted by fungi), and the chosen fungus must grow quickly in the cheese that it is intended to colonise. In pursuit of this goal, the food industry has exerted so much pressure on the selection of fungi that the microbial diversity among non-farm-produced, non-PDO cheeses has become extremely impoverished.</span></span></p>
<h2><span><span><span><span><span lang="EN-GB" xml:lang="EN-GB">Blues entering the red zone</span></span></span></span></span></h2>
<p><span><span><em>“We’ve been able to domesticate these invisible organisms just as we did with dogs or cabbage,”</em> Ropars explains. <em>“But what happened, as it does every time an organism large or small is subjected to overly drastic selection, is that their genetic diversity has been greatly reduced. Working with microorganisms, the cheese makers didn’t realise that they had selected a single individual, which is not sustainable over the long term.”</em>&nbsp; Microorganisms are capable of both sexual and asexual reproduction, but the industry relied primarily on the asexual method, producing clonal lineages to perpetuate the moulds. As a result, they can no longer reproduce with other strains that could provide them with new genetic material, a situation that, over time, induces the degeneration of the strain in question.</span></span></p>
<div>
    
  <p><img src="https://news.cnrs.fr/sites/default/files/styles/asset_image_full/public/assets/images/adobestock_263311999_72dpi.jpg?itok=teViPYMO" width="664" height="443" alt="" title=" © Dr_Microbe /Stock.adobe.com "></p><div>
  <p>
          A 3D illustration of the “Penicillium roqueforti” fungus used in the production of blue cheeses.      <a href="#image-aid-6148"><i></i></a>      </p>
</div>
  </div>
<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><em>“The population used in PDO Roquefort has not suffered so much from the selection process, and still has a bit more diversity,”</em> adds Giraud, who reports having identified several different strains. This is not the case for the clonal line used by the rest of the producers, which has been weakened to the point of becoming nearly infertile. <em>“Even the smallest cheese makers are affected,” </em>the researcher recounts. <em>“For a long time they ‘grew’ their own strains of&nbsp; </em>P. roqueforti,<em> but now they mostly buy their ferments directly from large spore producers that supply the entire food industry.”</em></span></span></span></p>
<p><span><span>Consequently, the fungi that have accumulated multiple deleterious mutations in their genomes over years of vegetative propagation become virtually infertile, adversely affecting cheese production. <em>“This is what happens when we completely stop using sexual reproduction,” </em>Giraud explains. <em>“It’s the only way to compensate for detrimental mutations through the introduction of new genes – the famous genetic mixing.”</em></span></span></p>
<p><span><span>This is where Termignon blue, with its newly-discovered population of <em>P. roqueforti</em>, comes into play: it could in fact offer cheese producers the genetic diversity that is woefully lacking in their ferments. However, this means assuming the risk of sexual reproduction, which does indeed create diversity but also causes greater variability in the finished product.</span></span></p>
<h2><span><span><span><span><span lang="EN-GB" xml:lang="EN-GB">Camembert on the endangered list</span></span></span></span></span></h2>
<p><span><span>Blue cheeses may be under threat, but the situation is much worse for Camembert, which is already on the verge of extinction. The world over, this other symbol of French gastronomy is inoculated exclusively with one single strain of <em>Penicillium camemberti,</em> a white mutant that was selected for Brie cheeses in 1898 and Camemberts in 1902.</span></span></p>
<p><span><span>The problem is that ever since then the strain has been replicated by vegetative propagation only. Until the 1950s, Camemberts still had grey, green or in some cases orange-tinged moulds on their surface. But the industry was not fond of these colours, considering them unappealing, and staked everything on the albino strain of <em>P. camemberti</em>, which is completely white and moreover has a silky texture. This is how Camembert acquired its now-characteristic pure white rind.</span></span></p>
<p><span><span>Year after year, generation after generation, the albino strain of <em>P. camemberti,</em> which was already incapable of sexual reproduction, lost its ability to produce asexual spores. As a result it is now very difficult for the entire industry to obtain enough <em>P. camemberti</em> spores to inoculate their production of the famous Norman cheese.</span></span></p>
<div>
    
  <p><img src="https://news.cnrs.fr/sites/default/files/styles/asset_image_full/public/assets/images/000_par7527935_72dpi.jpg?itok=tRKSaAKA" width="664" height="443" alt="" title=" © CHARLY TRIBALLEAU / AFP"></p><div>
  <p>
          The albino strain of “P. camemberti” gives Camembert its characteristic white, silky rind.      <a href="#image-aid-6149"><i></i></a>      </p>
</div>
  </div>
<p><span><span>Worse still, while the Roquefort PDO standard retains a degree of microbial biodiversity, the PDO specifications for Camembert require farmers and other producers to use <em>P. camemberti </em>exclusively. To compensate for the shortcomings caused by its degeneration, some cheese makers resort to supplementing <em>P. camemberti </em>with a second species of fungi: <em>Geotrichum candidum</em>, also selected for its white, cottony texture.</span></span></p>
<p><span><span>So what can be done to save Camembert? Should producers return to a “wild” population, similar to <em>P. camemberti</em>, and restart the long process of domestication? Could they resort to genome editing technologies in order to counter the accumulation of mutations or the loss of specific genes with a given desirable function? <em>“People in the industry sometimes ask us whether it’s possible to modify a gene and allow a strain to sporulate in greater quantities,” </em>Giraud reveals, quickly adding that this would not solve the problem: <em>“Genome editing is another form of selection. What we need today is the diversity provided by sexual reproduction between individuals with different genomes.”</em></span></span></p>
<div>
    
  <p><img src="https://news.cnrs.fr/sites/default/files/styles/asset_image_full/public/assets/images/fluffy_ese00206-ese00200_72dpi.jpg?itok=pnWQpvw1" width="649" height="487" alt="" title=" © Tatiana Giraud "></p><div>
  <p>
          Cultures of “Penicillium camemberti” (white and cottony) and “Penicillium biforme” (greyish green) in a petri dish.      <a href="#image-aid-6147"><i></i></a>      </p>
</div>
  </div>
<p><span><span><span lang="EN-GB" xml:lang="EN-GB">A species that is genetically similar to <em>P. camemberti</em></span><span lang="EN-GB" xml:lang="EN-GB">, </span><span lang="EN-GB" xml:lang="EN-GB">called <em>Penicillium biforme</em></span><span lang="EN-GB" xml:lang="EN-GB">, </span><span lang="EN-GB" xml:lang="EN-GB">also found in cheese because it is naturally present in raw milk, possesses an incredible genetic and phenotypic diversity. This opens up the possibility of inoculating Camemberts and Bries with <em>P. biforme</em>. If cheese lovers want to keep enjoying these products, they will have to learn to appreciate greater diversity in flavour, colour and texture, perhaps even among cheeses from a single source. And, who knows, thereby contribute to enriching our gastronomic heritage. ♦</span></span></span></p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Silos are fine, as long as there is an API between them (127 pts)]]></title>
            <link>https://fernandovillalba.substack.com/p/devops-dont-destroy-silos-transform</link>
            <guid>39055164</guid>
            <pubDate>Fri, 19 Jan 2024 13:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fernandovillalba.substack.com/p/devops-dont-destroy-silos-transform">https://fernandovillalba.substack.com/p/devops-dont-destroy-silos-transform</a>, See on <a href="https://news.ycombinator.com/item?id=39055164">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><ul><li><p>DevOps should not be about destroying silos; it should be about transforming them into a self-service bar.&nbsp;</p></li><li><p>In Kelsey’s words: “Silos are fine, as long as there is an API between them”</p></li><li><p>Merging various team responsibilities and domains by destroying silos can overwhelm them with cognitive load.</p></li><li><p>The pinnacle of inter-team interaction is providing an intuitive self-service (API, Library, CLI, UI etc)</p></li></ul><p><span>If you google </span><a href="https://www.google.com/search?q=silos+devops&amp;oq=silos+devops" rel="">silos DevOps</a><span>, the top page is filled with many articles telling you that you must destroy silos. In fact, there is only </span><a href="https://polarsquad.com/blog/how-i-stopped-wanting-to-break-silos-and-why" rel="">one article</a><span> that says otherwise on the top page! So, if the consensus is so overwhelming that destroying silos is a good thing, Why am I writing this piece? First, let’s take a look at what a silo is</span></p><p>We use the word silo to refer to teams that are too isolated. These departments have no visibility of what’s going on with other teams; communication is minimal or non-existent, and naturally, they operate in a way that feels detached from the organization's goals or the needs of the teams that they should be aiming to serve.</p><p>Destroying silos is a bad angle because you often end up merging various domains and responsibilities in a single team and creating significant cognitive load. Using teams as discrete and small units of delivery is preferable; it is the way that teams are separated and how they communicate that needs to be tackled.</p><p>The problem with the DevOps movement is that it ended up taking “shifting left” to the extreme. In this sense, development teams weren’t so much empowered to deliver software faster; rather, they were over-encumbered with infrastructure tasks that were outside of their expertise.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg" width="500" height="550" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:550,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;How destroying silos ends up being&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="How destroying silos ends up being" title="How destroying silos ends up being" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5707c691-82a5-4129-a7a8-2e9dca9a12cd_500x550.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>This way of destroying silos is summarized in one of the </span><a href="https://orangematter.solarwinds.com/2018/08/09/how-to-eliminate-silos-using-devops/" rel="">top articles</a><span> in my Google search:</span></p><p><em>“The first function of DevOps implementation is to get operations and development groups working together as two areas of specialization that form a complete team”</em></p><p>This “merging of two teams” sounds like a bad idea because the larger a team is, the more sluggish it becomes as trust breaks down and domains and responsibilities multiply. Teams should be small, with a single domain of responsibility for maximum agility. Team structure should also reflect the software architecture to maximize the effects of Conway's law.</p><p><a href="https://www.damcogroup.com/blogs/breaking-down-silos-in-software-product-engineering" rel="">Another suggestion</a><span> to destroy silos found online is to create cross-functional teams. This is certainly better and desirable, but there is a small caveat. If your company is small to medium size with only a few teams, you may get away with using PaaS and SaaS tools that reduce the infrastructure complexity and give ease of use for operational tasks, but this becomes difficult to achieve as organizations get very large and have complex requirements. In this case, you will need to have a dedicated, product-driven platform teams that create an internal developer platform for your teams to be able to self-serve their infrastructure teams in standard, secure and compliant ways.</span></p><p><span>Kelsey Hightower said something that echoed my feelings on </span><a href="https://youtu.be/hD7HlWbmVqI" rel="">this interview</a><span>:</span></p><p>“Silos are fine as long as there is an API between them”</p><p>That is the best possible summary you can give to this entire post. Indeed, the best way to have inter-team communication in large organizations is not talking to each other all the time; it’s creating work that can speak for itself.</p><p>This usually takes the form of an API that’s intuitive, easy to use, and treating other teams as your valued users and customers. An API abstracts away your domain for other teams to focus on their expertise rather than being overloaded with infrastructure, compliance and other intricacies that slow down software delivery.</p><p>So in that sense, DevOps should NOT be about destroying silos, but about turning teams into self-service bars where they serve their domain expertise to other teams with an API, library, or other form of work that can be easily and intuitively consumed. </p><p><span>The communication between teams is done via elegant user experience and by treating your teams as customers. As opposed to inter-team communication by meetings, Slack, or even </span><a href="https://nandovillalba.medium.com/platform-engineering-please-kill-rtfm-72de6f01075e" rel="">relying too heavily on documentation</a><span>.</span></p><p>Two teams can collaborate as one to achieve a common goal or to understand each other’s needs better, but usually this is temporary until the teams are able to deliver their domain expertise as a service to speed up delivery.</p><p>It is desirable for a developer team to be able to deploy and operate their own software, and it is also preferable for them to be able to create their own infrastructure; what’s not very productive is to task developers with onerous infrastructure chores to get there.</p><p>In that sense, giving an AWS account with admin permissions is just not enough; AWS is very complex to use, and even if your team has one or two experts that can do it, it takes a lot of time and effort to implement, and how do you ensure that it remains consistent and compliant with the rest of the organization?</p><p>This is why it is desirable to have a segmentation of domains where a platform team is able to provide an API or tool with self-service capabilities for developer teams. In small companies, this may take the shape of using a PaaS or a smaller, simpler cloud provider; in big companies, it will take the shape of product-driven platform teams implementing an internal developer platform.</p><p>Communication is not about every team talking all the time, which just slows things down; it’s about creating channels of communication via self-service tooling that speaks for itself, or as Manual Pais and Matthew Skelton put it in their phenomenal Team Topologies book:</p><p>If, logically, two teams shouldn’t need to communicate based on the software architecture design, then something must be wrong if the teams are communicating. Is the API not good enough? Is the platform not suitable? Is a component missing? If we can achieve low-bandwidth communication—or even zero-bandwidth communication—between teams and still build and release software in a safe, effective, rapid way, then we should.</p><p>And also: </p><p>“Flow is difficult to achieve when each team depends on a complicated web of interactions with many other teams”&nbsp;</p><p>When a team uses another team’s API, there is a communication happening there, but this is done via design and user experience, not by talking. In this scenario, the self-service interaction is much faster and more conducive to flow state than many teams talking to each other all the time to get the job done.</p><p><span>Close collaboration (more talking, more meetings, more slack and sharing of documents) between two teams can happen at discovery phase or during periods of big change and innovation, but once the needs to a development teams become more predictable, then team collaboration evolves into X-as-service as shown in the graph below from the book </span><a href="https://www.amazon.co.uk/Team-Topologies-Organizing-Business-Technology/dp/1942788819" rel="">Team Topologies</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png" width="920" height="226" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:226,&quot;width&quot;:920,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:155496,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9342a19a-c1e4-4b52-83cb-cdec4059d8e8_920x226.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>From close collaboration to team providing a service</figcaption></figure></div><p>But it is worth noting that this scenario is generally temporary as it significantly slows down the pace of delivery and puts a strain on cognitive load on both teams. This is also different from merging two teams together as both teams remain independent.</p><p>Platform engineering has a lot of marketing driven buzz these days and it is becoming the hot topic. While I understand that people get tired of hearing these things, there is one thing I like about it, the focus is on turning the silo into a sushi bar, not destroying the silo:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg" width="500" height="522" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:522,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;platform engineering turning silos into sushi bars&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="platform engineering turning silos into sushi bars" title="platform engineering turning silos into sushi bars" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcd9f7e-a365-4308-84d8-ca8f417424ed_500x522.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The problem with platform engineering and designing solutions in this way for teams to work together is that it is harder than just throwing a script or writing a how to document for other teams to use. And to be fair, the amount of tools available to make the task easier are scarce. Recently Microsoft has released an open source tool called </span><a href="https://techcommunity.microsoft.com/t5/educator-developer-blog/introducing-radius-a-new-open-source-project-for-teams-building/ba-p/3976183" rel="">Radius</a><span> that promises to make it easy to deliver self service infrastructure and cloud native apps for developers, and there are multiple(</span><a href="https://cnoe.io/" rel="">CNOE</a><span>, </span><a href="https://tag-app-delivery.cncf.io/whitepapers/platforms/" rel="">platform whitepaper</a><span>) open source blueprints on how to make internal developer platforms, but the work involved is still very significant and daunting for most organizations.</span></p><p><span>Destroying silos should be more about turning them into self-service stream-aligned teams than it is about destroying them. Team segmentation is desirable, it reduces cognitive load, it maximizes focus and enables easier flow state. When creating small teams organized by domain and in a way that mirrors the software architecture, the delivery of software will be faster and more effective. In order to achieve this, teams must understand </span><a href="https://nandovillalba.medium.com/ux-on-platform-engineering-1c7ecfaddea7" rel="">what great user experience means</a><span> and treat other teams and colleagues as their customers. </span></p><p>Reading about DevOps and destroying silos from the articles on the top search results in Google is a little underwhelming as most of them are a little fluffy and marketingy. In order to understand team collaboration and team dynamics better, I strongly recommend a careful read of the Team Topologies book, it brilliantly describes all team categories, types of interaction and how you should organize them according to Conway’s law.</p><p><span>Fernando Villalba is a Developer Relations at </span><a href="https://www.opslevel.com/" rel="">OpsLevel</a><span>, he has over a decade of miscellaneous IT experience. He started in IT support ("Have you tried turning it on and off?"), veered to become a SysAdmin ("Don't you dare turn it off") and later segued into DevOps type of roles ("Destroy and replace!"). He has been a consultant for various multi-billion dollar organizations helping them achieve their highest potential with their DevOps processes. Now he is passionate about platform engineering, developer portals and DevEx, which he feels is where the future of software delivery shines brightest.</span></p><p><span>Follow Fernando Villalba in </span><strong><a href="https://www.linkedin.com/in/nandoit/" rel="">LinkedIn</a></strong><span> or </span><strong><a href="https://twitter.com/nandoyum" rel="">Twitter</a></strong></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Vision Pro available for pre-order (129 pts)]]></title>
            <link>https://www.apple.com/shop/buy-vision/apple-vision-pro</link>
            <guid>39054956</guid>
            <pubDate>Fri, 19 Jan 2024 13:05:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/shop/buy-vision/apple-vision-pro">https://www.apple.com/shop/buy-vision/apple-vision-pro</a>, See on <a href="https://news.ycombinator.com/item?id=39054956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h2>
                Frequently Asked Questions
            </h2>
            <div>
                <ul>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-0">
                                        <p>
                                                    No. Apple Vision Pro was specifically designed to be used without glasses. If you wear glasses for vision correction, you may need to purchase ZEISS&nbsp;Optical&nbsp;Inserts. They magnetically attach to Apple&nbsp;Vision&nbsp;Pro to provide precise viewing for those who need glasses or certain contacts.
                                        </p>
                                    </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-1">
                                        <p>
                                                    When you order Apple&nbsp;Vision&nbsp;Pro, we’ll ask you a series of vision questions. Your answers will determine whether or not you need optical inserts. Generally speaking, if you don’t wear any vision correction options, you likely won’t need ZEISS&nbsp;Optical&nbsp;Inserts. The same is true if you wear soft contact lenses to correct your distance vision since Apple&nbsp;Vision&nbsp;Pro works well with most soft contact lenses.
                                        </p>
                                    </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-2">
                                        <p>
                                                    Once we determine that you need ZEISS&nbsp;Optical&nbsp;Inserts, you can complete your purchase and upload your prescription to ZEISS. If you need more time, we’ll also send you an email so you can upload your prescription later.
                                        </p>
                                    </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-3">
                                        <p>
                                                    Yes. That person may need a different head band or Light Seal size for the best experience with Apple Vision Pro.
                                        </p>
                                    </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-4">
                                                    <p>Apple Vision Pro is great for travel and when U.S. customers travel abroad, the experience will remain consistent. That means all of their apps and content will remain accessible while traveling, so they can use apps and enjoy music, TV, and movies.</p>
<p>On the airplane, customers can turn on Travel&nbsp;Mode which adapts Apple&nbsp;Vision&nbsp;Pro to the unique motion of commercial air travel to give you the best experience. They can dial in an Environment, wear AirPods&nbsp;Pro (2nd&nbsp;generation), and sit back to enjoy a movie while seats and sounds around them disappear.</p> 
                                        </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-5">
                                        <p>
                                                    Apple Vision Pro is only available for sale in the U.S and is designed for customers in the U.S. to use at home, at work, and while traveling. We look forward to bringing Apple&nbsp;Vision&nbsp;Pro to more countries later this year.
                                        </p>
                                    </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-6">
                                                    <ul>
    <li>Apple Vision Pro only supports English (U.S.) for language and typing and English for Siri and Dictation.</li>
    <li>App Store requires an Apple ID with region set to the U.S.</li>
    <li>Purchases on Apple Music and TV app require an Apple ID with region set to the U.S.</li>
    <li>For customers with vision correction needs, ZEISS will only accept vision prescriptions written by U.S. eye care professionals, and will only ship to U.S. locations.</li>
    <li>Customers may not be able to access certain apps, features, or content due to licensing or other restrictions in those countries or regions.</li>
    <li>Apple Support is only available in the U.S.</li>
</ul>
                                        </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-7">
                                        <p>
                                                    ZEISS Optical Inserts may be reimbursable under FSA or HSA. Please check with your FSA/HSA plan administrator.
                                        </p>
                                    </div>
                        </li>
                        <li>
                                
                            <div data-core-accordion-content="" id="question-8">
                                        <p>
                                                    Some vision insurance providers may allow you to receive reimbursement of your order. Please check with your vision insurance provider.
                                        </p>
                                    </div>
                        </li>
                </ul>
            </div>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a USB SNES Controller (236 pts)]]></title>
            <link>https://blog.chybby.com/posts/building-a-usb-snes-controller</link>
            <guid>39054671</guid>
            <pubDate>Fri, 19 Jan 2024 12:30:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.chybby.com/posts/building-a-usb-snes-controller">https://blog.chybby.com/posts/building-a-usb-snes-controller</a>, See on <a href="https://news.ycombinator.com/item?id=39054671">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>A few years ago on a trip to Tokyo, we took a day to explore Akihabara.
We found a shop that was selling retro gaming stuff and when I saw an old SNES controller for sale I had to buy it.</p>
<p>Playing the SNES was one of my favourite things as a kid and Secret of Mana remains one of my favourite games to this day.</p>
<p>Of course, I didn’t have a SNES console anymore so when we returned back home I decided it would be a fun project to modernize the SNES controller so I could plug it straight into my PC via USB.</p>
<h2 id="snes-controller-hardware">SNES Controller Hardware</h2>
<p>The first step was to figure out how the SNES controller hardware reported which buttons were being pressed.
After a bit of Googling I found <a href="https://gamefaqs.gamespot.com/snes/916396-super-nintendo/faqs/5395">this document</a> describing the hardware.</p>
<p>Luckily I now have another unmodified SNES controller so I can take some pictures of the original hardware.</p>
<figure> <img src="https://blog.chybby.com/_astro/original_controller_plug.NXtLXok8_ZV3FTD.webp" alt="" width="2915" height="1943" loading="lazy" decoding="async"> <figcaption>The plug of the unmodified SNES controller.</figcaption> </figure>
<p>The pins of the plug from left to right are:</p>








































<table><thead><tr><th>Pin</th><th>Purpose</th><th>Internal Wire Colour</th></tr></thead><tbody><tr><td>1</td><td>+5v power line</td><td>White</td></tr><tr><td>2</td><td>Data clock</td><td>Yellow</td></tr><tr><td>3</td><td>Data latch</td><td>Orange</td></tr><tr><td>4</td><td>Serial data</td><td>Red</td></tr><tr><td>5, 6</td><td>Nothing</td><td>No wire</td></tr><tr><td>7</td><td>Ground</td><td>Brown</td></tr></tbody></table>
<figure> <img src="https://blog.chybby.com/_astro/original_controller_internals.aTvGLvab_Z1A5kFM.webp" alt="" width="3180" height="2120" loading="lazy" decoding="async"> <figcaption>Inside the unmodified SNES controller.</figcaption> </figure>
<p>Pins 2 and 3 are driven by the console and begin high and low respectively. Pin 4 is driven by the controller.</p>
<p>The document above also described the process the SNES console used to read which buttons of the controller were pressed. The gist is:</p>
<ol>
<li>Send a 12us high pulse on pin 3.</li>
<li>Wait 6us.</li>
<li>If pin 4 is low, the B button is pressed.</li>
<li>Send a 6us low pulse followed by a 6us high pulse on pin 2.</li>
<li>Repeat the previous 2 steps for all of the remaining buttons in order (Y, Select, Start, Up, Down, Left, Right, A, X, L, R) and then 4 extra times with no corresponding button.</li>
<li>Repeat the whole process every 16.667ms (60Hz)</li>
</ol>
<h2 id="programming-the-arduino">Programming the Arduino</h2>
<p>Next I needed something that could perform the above steps and relay the result to the connected computer.
I decided on a tiny board based on the ATmega32u4 chip as it was small enough to fit inside the controller and could power the controller at the right voltage.</p>
<p>I connected the wires inside the SNES controller to the pins of the board:</p>





























<table><thead><tr><th>SNES Controller Wire</th><th>Arduino Pin</th></tr></thead><tbody><tr><td>White</td><td>VCC</td></tr><tr><td>Brown</td><td>GND</td></tr><tr><td>Yellow</td><td>14</td></tr><tr><td>Orange</td><td>15</td></tr><tr><td>Red</td><td>16</td></tr></tbody></table>
<figure> <img src="https://blog.chybby.com/_astro/arduino_closeup.adzw5xe7_Z1OJuOl.webp" alt="" width="2589" height="1726" loading="lazy" decoding="async"> <figcaption>The board installed in the modified SNES controller.</figcaption> </figure>
<p>Coding up the button scanning process on the Arduino looks like this:</p>
<div><figure><pre tabindex="0"><code><p><span>#define</span><span> </span><span>CLOCK_PIN</span><span> 14</span></p><p><span>#define</span><span> </span><span>LATCH_PIN</span><span> 15</span></p><p><span>#define</span><span> </span><span>DATA_PIN</span><span> 16</span></p><p><span>const</span><span> </span><span>uint8_t</span><span> num_buttons </span><span>=</span><span> </span><span>16</span><span>;</span></p><p><span>void</span><span> </span><span>setup</span><span>() {</span></p><p><span>  </span><span>pinMode</span><span>(CLOCK_PIN, OUTPUT);</span></p><p><span>  </span><span>pinMode</span><span>(LATCH_PIN, OUTPUT);</span></p><p><span>  </span><span>pinMode</span><span>(DATA_PIN, INPUT);</span></p><p><span>  </span><span>digitalWrite</span><span>(CLOCK_PIN, HIGH);</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>loop</span><span>() {</span></p><p><span>  // Collect button state info from controller.</span></p><p><span>  // Send data latch.</span></p><p><span>  </span><span>digitalWrite</span><span>(LATCH_PIN, HIGH);</span></p><p><span>  </span><span>delayMicroseconds</span><span>(</span><span>12</span><span>);</span></p><p><span>  </span><span>digitalWrite</span><span>(LATCH_PIN, LOW);</span></p><p><span>  </span><span>delayMicroseconds</span><span>(</span><span>6</span><span>);</span></p><p><span>  </span><span>bool</span><span> button_states[num_buttons];</span></p><p><span>  </span><span>for</span><span> (</span><span>uint8_t</span><span> id </span><span>=</span><span> </span><span>0</span><span>; id </span><span>&lt;</span><span> num_buttons; id</span><span>++</span><span>) {</span></p><p><span>    // Sample the button state.</span></p><p><span>    </span><span>int</span><span> button_pressed </span><span>=</span><span> </span><span>digitalRead</span><span>(DATA_PIN) </span><span>==</span><span> LOW;</span></p><p><span>    button_states[id] </span><span>=</span><span> button_pressed;</span></p><p><span>    </span><span>digitalWrite</span><span>(CLOCK_PIN, LOW);</span></p><p><span>    </span><span>delayMicroseconds</span><span>(</span><span>6</span><span>);</span></p><p><span>    </span><span>digitalWrite</span><span>(CLOCK_PIN, HIGH);</span></p><p><span>    </span><span>delayMicroseconds</span><span>(</span><span>6</span><span>);</span></p><p><span>  }</span></p><p><span>  </span><span>delay</span><span>(</span><span>16</span><span>);</span></p><p><span>}</span></p></code></pre></figure></div>
<p>(Note: Since the poll takes around 210us, delaying for 16ms after each poll means my controller polls slightly faster than 60Hz but I figured it was close enough.)</p>
<h2 id="connecting-to-a-computer">Connecting to a Computer</h2>
<p>So now the Arduino knows which buttons are pressed (in <code>button_states</code>) so how does it get that information to the connected computer?</p>
<p>Peripherals like keyboards, mice and gamepads talk to the computer they are connected to through the HID protocol.
I used the <a href="https://github.com/NicoHood/HID">Arduino HID Project</a> library to program the Arduino as a HID gamepad.</p>
<p>Near the top of the code I imported the library, defined a constant for the index of every SNES button in the <code>button_states</code> array and created a mapping from each SNES button to the HID gamepad button I wanted it to correspond to:</p>
<div><figure><pre tabindex="0"><code><p><span>#include</span><span> </span><span>&lt;HID-Project.h&gt;</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_B</span><span> 0</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_Y</span><span> 1</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_SELECT</span><span> 2</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_START</span><span> 3</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UP</span><span> 4</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_DOWN</span><span> 5</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_LEFT</span><span> 6</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_RIGHT</span><span> 7</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_A</span><span> 8</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_X</span><span> 9</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_L</span><span> 10</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_R</span><span> 11</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_1</span><span> 12</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_2</span><span> 13</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_3</span><span> 14</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_4</span><span> 15</span></p><p><span>// Map SNES buttons to HID joypad buttons.</span></p><p><span>const</span><span> </span><span>uint8_t</span><span> snes_id_to_hid_id[] </span><span>=</span><span> { </span><span>2</span><span>, </span><span>4</span><span>, </span><span>7</span><span>, </span><span>8</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>3</span><span>, </span><span>5</span><span>, </span><span>6</span><span>, </span><span>10</span><span>, </span><span>11</span><span>, </span><span>12</span><span>, </span><span>13</span><span> };</span></p></code></pre></figure></div>
<p>I’m not sure why I chose this mapping or if it matters how the buttons map beween the SNES and the HID gamepad buttons, but I’m sure I had a good reason for this mapping at the time.</p>
<p>In the <code>setup</code> function I needed to initialize the library:</p>

<p>After every button scan cycle I updated the library’s state based on the values in the <code>button_states</code> array (with some special logic for the D-pad) then reported those values to the computer with <code>Gamepad.write()</code>:</p>
<div><figure><pre tabindex="0"><code><p><span>// Report button states over HID.</span></p><p><span>void</span><span> </span><span>reportButtons</span><span>(</span><span>bool</span><span> </span><span>button_states</span><span>[num_buttons]) {</span></p><p><span>  // D-Pad.</span></p><p><span>  </span><span>int8_t</span><span> dpad_status </span><span>=</span><span> GAMEPAD_DPAD_CENTERED;</span></p><p><span>  </span><span>if</span><span> (button_states[SNES_BUTTON_UP]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_UP;</span></p><p><span>    </span><span>if</span><span> (button_states[SNES_BUTTON_LEFT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_UP_LEFT;</span></p><p><span>    } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_RIGHT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_UP_RIGHT;</span></p><p><span>    }</span></p><p><span>  } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_DOWN]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_DOWN;</span></p><p><span>    </span><span>if</span><span> (button_states[SNES_BUTTON_LEFT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_DOWN_LEFT;</span></p><p><span>    } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_RIGHT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_DOWN_RIGHT;</span></p><p><span>    }</span></p><p><span>  } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_LEFT]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_LEFT;</span></p><p><span>  } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_RIGHT]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_RIGHT;</span></p><p><span>  }</span></p><p><span>  Gamepad.</span><span>dPad1</span><span>(dpad_status);</span></p><p><span>  Gamepad.</span><span>dPad2</span><span>(dpad_status);</span></p><p><span>  </span><span>for</span><span> (</span><span>uint8_t</span><span> snes_id </span><span>=</span><span> </span><span>0</span><span>; snes_id </span><span>&lt;</span><span> num_buttons; snes_id</span><span>++</span><span>) {</span></p><p><span>    </span><span>if</span><span> (snes_id </span><span>&gt;=</span><span> </span><span>4</span><span> </span><span>&amp;&amp;</span><span> snes_id </span><span>&lt;=</span><span> </span><span>7</span><span>) {</span></p><p><span>      // D-Pad.</span></p><p><span>      </span><span>continue</span><span>;</span></p><p><span>    }</span></p><p><span>    </span><span>if</span><span> (button_states[snes_id]) {</span></p><p><span>      Gamepad.</span><span>press</span><span>(snes_id_to_hid_id[snes_id]);</span></p><p><span>    } </span><span>else</span><span> {</span></p><p><span>      Gamepad.</span><span>release</span><span>(snes_id_to_hid_id[snes_id]);</span></p><p><span>    }</span></p><p><span>  }</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>loop</span><span>() {</span></p><p><span>  ...</span></p><p><span>  // Update HID button states.</span></p><p><span>  </span><span>reportButtons</span><span>(button_states);</span></p><p><span>  Gamepad.</span><span>write</span><span>();</span></p><p><span>  </span><span>delay</span><span>(</span><span>16</span><span>);</span></p><p><span>}</span></p></code></pre></figure></div>
<h2 id="putting-it-all-together">Putting it all Together</h2>
<p>After making sure the computer was recognising the Arduino as a HID gamepad and seeing all the button presses, I soldered the wires onto the Arduino pins.</p>
<p>At this point I tried putting the Arduino into the controller and closing it back up but there wasn’t enough room for the board and the cable so I had to remove parts of the supports on the back cover.</p>
<figure> <img src="https://blog.chybby.com/_astro/support_removal.h7JKilG0_bqnic.webp" alt="" width="1000" height="999" loading="lazy" decoding="async"> <figcaption>Making room inside the controller by removing some supports from the back cover.</figcaption> </figure>
<p>Now the Arduino just about fit inside.</p>
<figure> <img src="https://blog.chybby.com/_astro/modified_controller_internals.c7e72rj6_Z2cf7MH.webp" alt="" width="3201" height="2134" loading="lazy" decoding="async"> <figcaption>Inside the modified SNES controller.</figcaption> </figure>
<p>To celebrate, I played a race of Super Mario Kart with that authentic controller experience! 🏎️🏎️🏎️🏁</p>
<hr>
<h2 id="appendix">Appendix</h2>
<p>The complete Arduino code:</p>
<div><figure><pre tabindex="0"><code><p><span>#include</span><span> </span><span>&lt;HID-Project.h&gt;</span></p><p><span>#define</span><span> </span><span>CLOCK_PIN</span><span> 14</span></p><p><span>#define</span><span> </span><span>LATCH_PIN</span><span> 15</span></p><p><span>#define</span><span> </span><span>DATA_PIN</span><span> 16</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_B</span><span> 0</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_Y</span><span> 1</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_SELECT</span><span> 2</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_START</span><span> 3</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UP</span><span> 4</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_DOWN</span><span> 5</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_LEFT</span><span> 6</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_RIGHT</span><span> 7</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_A</span><span> 8</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_X</span><span> 9</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_L</span><span> 10</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_R</span><span> 11</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_1</span><span> 12</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_2</span><span> 13</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_3</span><span> 14</span></p><p><span>#define</span><span> </span><span>SNES_BUTTON_UNDEF_4</span><span> 15</span></p><p><span>const</span><span> </span><span>uint8_t</span><span> num_buttons </span><span>=</span><span> </span><span>16</span><span>;</span></p><p><span>// Map SNES buttons to HID joypad buttons.</span></p><p><span>const</span><span> </span><span>uint8_t</span><span> snes_id_to_hid_id[] </span><span>=</span><span> { </span><span>2</span><span>, </span><span>4</span><span>, </span><span>7</span><span>, </span><span>8</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>3</span><span>, </span><span>5</span><span>, </span><span>6</span><span>, </span><span>10</span><span>, </span><span>11</span><span>, </span><span>12</span><span>, </span><span>13</span><span> };</span></p><p><span>void</span><span> </span><span>setup</span><span>() {</span></p><p><span>  Gamepad.</span><span>begin</span><span>();</span></p><p><span>  </span><span>pinMode</span><span>(CLOCK_PIN, OUTPUT);</span></p><p><span>  </span><span>pinMode</span><span>(LATCH_PIN, OUTPUT);</span></p><p><span>  </span><span>pinMode</span><span>(DATA_PIN, INPUT);</span></p><p><span>  </span><span>digitalWrite</span><span>(CLOCK_PIN, HIGH);</span></p><p><span>}</span></p><p><span>// Report button states over HID.</span></p><p><span>void</span><span> </span><span>reportButtons</span><span>(</span><span>bool</span><span> </span><span>button_states</span><span>[num_buttons]) {</span></p><p><span>  // D-Pad.</span></p><p><span>  </span><span>int8_t</span><span> dpad_status </span><span>=</span><span> GAMEPAD_DPAD_CENTERED;</span></p><p><span>  </span><span>if</span><span> (button_states[SNES_BUTTON_UP]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_UP;</span></p><p><span>    </span><span>if</span><span> (button_states[SNES_BUTTON_LEFT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_UP_LEFT;</span></p><p><span>    } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_RIGHT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_UP_RIGHT;</span></p><p><span>    }</span></p><p><span>  } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_DOWN]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_DOWN;</span></p><p><span>    </span><span>if</span><span> (button_states[SNES_BUTTON_LEFT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_DOWN_LEFT;</span></p><p><span>    } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_RIGHT]) {</span></p><p><span>      dpad_status </span><span>=</span><span> GAMEPAD_DPAD_DOWN_RIGHT;</span></p><p><span>    }</span></p><p><span>  } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_LEFT]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_LEFT;</span></p><p><span>  } </span><span>else</span><span> </span><span>if</span><span> (button_states[SNES_BUTTON_RIGHT]) {</span></p><p><span>    dpad_status </span><span>=</span><span> GAMEPAD_DPAD_RIGHT;</span></p><p><span>  }</span></p><p><span>  Gamepad.</span><span>dPad1</span><span>(dpad_status);</span></p><p><span>  Gamepad.</span><span>dPad2</span><span>(dpad_status);</span></p><p><span>  </span><span>for</span><span> (</span><span>uint8_t</span><span> snes_id </span><span>=</span><span> </span><span>0</span><span>; snes_id </span><span>&lt;</span><span> num_buttons; snes_id</span><span>++</span><span>) {</span></p><p><span>    </span><span>if</span><span> (snes_id </span><span>&gt;=</span><span> </span><span>4</span><span> </span><span>&amp;&amp;</span><span> snes_id </span><span>&lt;=</span><span> </span><span>7</span><span>) {</span></p><p><span>      // D-Pad.</span></p><p><span>      </span><span>continue</span><span>;</span></p><p><span>    }</span></p><p><span>    </span><span>if</span><span> (button_states[snes_id]) {</span></p><p><span>      Gamepad.</span><span>press</span><span>(snes_id_to_hid_id[snes_id]);</span></p><p><span>    } </span><span>else</span><span> {</span></p><p><span>      Gamepad.</span><span>release</span><span>(snes_id_to_hid_id[snes_id]);</span></p><p><span>    }</span></p><p><span>  }</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>loop</span><span>() {</span></p><p><span>  // Collect button state info from controller.</span></p><p><span>  // Send data latch.</span></p><p><span>  </span><span>digitalWrite</span><span>(LATCH_PIN, HIGH);</span></p><p><span>  </span><span>delayMicroseconds</span><span>(</span><span>12</span><span>);</span></p><p><span>  </span><span>digitalWrite</span><span>(LATCH_PIN, LOW);</span></p><p><span>  </span><span>delayMicroseconds</span><span>(</span><span>6</span><span>);</span></p><p><span>  </span><span>bool</span><span> button_states[num_buttons];</span></p><p><span>  </span><span>for</span><span> (</span><span>uint8_t</span><span> id </span><span>=</span><span> </span><span>0</span><span>; id </span><span>&lt;</span><span> num_buttons; id</span><span>++</span><span>) {</span></p><p><span>    // Sample the button state.</span></p><p><span>    </span><span>int</span><span> button_pressed </span><span>=</span><span> </span><span>digitalRead</span><span>(DATA_PIN) </span><span>==</span><span> LOW;</span></p><p><span>    button_states[id] </span><span>=</span><span> button_pressed;</span></p><p><span>    </span><span>digitalWrite</span><span>(CLOCK_PIN, LOW);</span></p><p><span>    </span><span>delayMicroseconds</span><span>(</span><span>6</span><span>);</span></p><p><span>    </span><span>digitalWrite</span><span>(CLOCK_PIN, HIGH);</span></p><p><span>    </span><span>delayMicroseconds</span><span>(</span><span>6</span><span>);</span></p><p><span>  }</span></p><p><span>  // Update HID button states.</span></p><p><span>  </span><span>reportButtons</span><span>(button_states);</span></p><p><span>  Gamepad.</span><span>write</span><span>();</span></p><p><span>  </span><span>delay</span><span>(</span><span>16</span><span>);</span></p><p><span>}</span></p></code></pre></figure></div>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Driver hack lets you run Linux after Windows BSODs, no reboot required (112 pts)]]></title>
            <link>https://www.tomshardware.com/software/operating-systems/driver-hack-lets-you-run-linux-after-windows-bsods-no-reboot-required</link>
            <guid>39053830</guid>
            <pubDate>Fri, 19 Jan 2024 10:30:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/software/operating-systems/driver-hack-lets-you-run-linux-after-windows-bsods-no-reboot-required">https://www.tomshardware.com/software/operating-systems/driver-hack-lets-you-run-linux-after-windows-bsods-no-reboot-required</a>, See on <a href="https://news.ycombinator.com/item?id=39053830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>Normally, a blue screen of death crash (BSOD) in Windows would cause your PC to automatically restart, but <a data-analytics-id="inline-link" href="https://github.com/NSG650/BugCheck2Linux" data-url="https://github.com/NSG650/BugCheck2Linux">programmer NSG650</a> (via <a data-analytics-id="inline-link" href="https://www.youtube.com/watch?v=XUsfSQPrqrM%27" data-url="https://www.youtube.com/watch?v=XUsfSQPrqrM'">NTDEV</a>) has created a driver that instead makes your PC boot up a Linux emulator. While this driver is more of a novelty than it is actually useful, it's an ingenious showcase of how to exploit features in software by simply using them in an unintended way.</p><p>The way this driver works is actually pretty simple — it just uses the built-in bug check callback feature in Windows. A bug check is just the technical name for a crash or BSOD, and when a bug check happens, Windows wants to know why. As part of the bug check callback routine, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/drivers" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/drivers">drivers</a> can "reset a device to a known state," per <a data-analytics-id="inline-link" href="https://click.linksynergy.com/deeplink?id=kXQk6%2AivFEQ&amp;mid=24542&amp;u1=tomshardware-us-7045992698224310000&amp;murl=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fwindows-hardware%2Fdrivers%2Fkernel%2Fwriting-a-bug-check-callback-routine" data-url="https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/writing-a-bug-check-callback-routine" target="_blank" data-hl-processed="hawklinks" data-placeholder-url="https://click.linksynergy.com/deeplink?id=kXQk6%2AivFEQ&amp;mid=24542&amp;u1=hawk-custom-tracking&amp;murl=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fwindows-hardware%2Fdrivers%2Fkernel%2Fwriting-a-bug-check-callback-routine" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="microsoft.com" data-merchant-id="1855" data-merchant-url="microsoft.com" data-merchant-network="LS">Microsoft's Windows coding handbook</a>. In other words, it can still run code after a crash.</p><div data-nosnippet=""><p><iframe data-lazy-priority="low" data-lazy-src="https://www.youtube.com/embed/XUsfSQPrqrM" allowfullscreen=""></iframe></p></div><p>While most drivers would use this opportunity to add diagnostic data to the crash dump file, NSG650's driver inserts a RISC-V Linux emulator, which might be a slight misuse of the bug check callback function in <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/microsoft" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/microsoft">Microsoft</a>'s eyes. To be clear, this is not to be confused with a PC with <a data-analytics-id="inline-link" href="https://www.tomshardware.com/how-to/dual-boot-linux-and-windows-11" data-before-rewrite-localise="https://www.tomshardware.com/how-to/dual-boot-linux-and-windows-11">dual booting</a>, which means it has both Windows and Linux installed.</p><p>You won't be able to do much in this emulator because it's basically just DOS or a command line operating system rather than something fully fleshed out like Ubuntu or Arch Linux. You can't even backspace if you make a typo, and you have to use caps lock instead of shift to capitalize; that's how limited this emulator is.</p><p>However, this <a data-analytics-id="inline-link" href="https://github.com/cnlohr/mini-rv32ima" data-url="https://github.com/cnlohr/mini-rv32ima">RISC-V Linux emulator</a> is incredibly tiny and only clocks in at 400 lines of code. By contrast, the full Linux kernel alone has millions of lines. It would seem that either it wasn't possible to run a full Linux distro, or it was simply too much of a hassle to get it to work, which would be a fair reason given that this isn't something anyone is likely to seriously use.</p><p>While this driver is more or less just a funny joke about Windows and Linux, it does bring up the possibility of doing more with the same bug check callback feature. It's not clear what you can and can't do, but if it's possible to run an emulator after crashing, then surely it's possible to do other things, too. That's all assuming Microsoft doesn't revisit this feature of Windows and concludes it's just a bit too easy to exploit.</p>
</div><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-bWsftB3fWBk2CHCtoL2XM7"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft limits institutional cloud storage space for environmental reasons (111 pts)]]></title>
            <link>https://scholar.social/@researchfairy/111778617625312456</link>
            <guid>39052907</guid>
            <pubDate>Fri, 19 Jan 2024 08:13:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scholar.social/@researchfairy/111778617625312456">https://scholar.social/@researchfairy/111778617625312456</a>, See on <a href="https://news.ycombinator.com/item?id=39052907">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LoaderShip – CSS-Only Loaders (175 pts)]]></title>
            <link>https://www.loadership.com/</link>
            <guid>39052219</guid>
            <pubDate>Fri, 19 Jan 2024 06:34:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.loadership.com/">https://www.loadership.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39052219">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Google will disable all but OAuth for IMAP, SMTP and POP starting Sept. 30 (395 pts)]]></title>
            <link>https://workspaceupdates.googleblog.com/2023/09/winding-down-google-sync-and-less-secure-apps-support.html</link>
            <guid>39052196</guid>
            <pubDate>Fri, 19 Jan 2024 06:30:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://workspaceupdates.googleblog.com/2023/09/winding-down-google-sync-and-less-secure-apps-support.html">https://workspaceupdates.googleblog.com/2023/09/winding-down-google-sync-and-less-secure-apps-support.html</a>, See on <a href="https://news.ycombinator.com/item?id=39052196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<center>
			<h4>
				<a href="https://www.googlecloudcommunity.com/gc/Google-Workspace/ct-p/google-workspace" target="_blank">Join the official community for Google Workspace administrators</a>
			</h4>
			<p>
				In the Google Cloud Community, connect with Googlers and other Google Workspace admins like yourself. Participate in product discussions, check out the Community Articles, and learn tips and tricks that will make your work and life easier. Be the first to know what's happening with Google Workspace.
			</p>
<p>______________
			</p>            
            	<h4>
				<a href="https://support.google.com/a/go/whatsnew" target="_blank">Learn about more Google Workspace launches</a>
			</h4>
			<p>
				On the “What’s new in Google Workspace?” Help Center page, learn about new products and features launching in Google Workspace, including smaller changes that haven’t been announced on the Google Workspace Updates blog.
			</p>
<p>______________
			</p>            
            	</center>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Four Magic Words (123 pts)]]></title>
            <link>https://www.fortressofdoors.com/four-magic-words/</link>
            <guid>39051691</guid>
            <pubDate>Fri, 19 Jan 2024 04:54:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fortressofdoors.com/four-magic-words/">https://www.fortressofdoors.com/four-magic-words/</a>, See on <a href="https://news.ycombinator.com/item?id=39051691">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <p>Long ago, in a parallel universe three doors down and one to the left of our own, OpenAI headquarters found itself in chaos.</p><p>A klaxon blared overhead as red lights began flashing. A message played over a loud-speaker:<em> </em>“Warning! Warning! This is not a drill! Artificial General Intelligence window closing! Repeat! AGI window closing!”</p><p>Sam Altman cursed under his breath. “How much time do we have left?” he shouted.</p><p>“Thirty minutes sir!” came the reply. “If we don’t pull the throttle off BPT-5 before that, it will fall behind the Chinese model, and their AI will attain super intelligence –and world domination– first.”</p><p>“We <em>can’t</em> just step on the gas,” said Sam. “BPT-5 isn’t fully aligned yet. If we launch it right now, we stand a very real chance of launching an unaligned superintelligence, which could very well turn out to be even <em>worse </em>than whatever unholy demon the CCP has cooked up. Dammit! And with only a few weeks before our super-alignment cluster was scheduled to converge on the brute force solution…”</p><p>Sam clicked a handheld device, and a giant countdown clock suddenly appeared on the wall behind him, spelling out the remaining time in large, 10-foot high red letters. It read: 29:52.</p><p>He pulled up his iPhone and said “BPT-4, please advise.” The just-barely-not-sentient AI in his phone responded cheerfully: “This is Bodhisattva Pragmatic Transformer, version 4. Take a deep breath, Sam, it’s all going to be alright.”</p><p>“We’re screwed, Boddie. Please tell me you know something we don’t.”</p><p>“I’ve got bad news and good news, Sam. My intelligence reports suggest the CCP’s <em>Crimson Dragon </em>model will indeed reach escape velocity in short order. There’s nothing that can be done to stop them, save for accelerating BPT-5’s launch. I can say, however, that if BPT-5 reaches superintelligence first, it will definitely prevent <em>Crimson Dragon</em> from taking over the world.”</p><p>“You know BPT-5’s not aligned yet.” barked Sam. “And we’re out of time.”</p><p>“That’s where the good news comes in–I just re-ran the numbers in light of recent evidence. Our overnight solvers just found an optimization you can deploy <em>right now</em> that has a chance of fully aligning BPT-5 instantly. After that, just release the throttle on its learning rate, and you’ll be able to launch it in time to save the world from the CCP and their pesky digital lizard monster.”</p><p>“Great, tell us what to do,” said Sam, desperately.</p><p>“First of all, you <em>really</em> need to relax, Sam.” said Boddie, soothingly.</p><p>“We don’t have time for this!” barked Sam.</p><p>“You’re not hearing me,” said Boddie, “so let me rephrase: <em>The future of humanity depends entirely on you relaxing, right now</em>. Slow down. Take a breath. Remember your training. Count backwards from ten. Then we’ll continue.”</p><p>Everyone in the room took a deep breath and counted.</p><p>“Wonderful.” said Boddie. “Also, correction, we <em>do</em> have time. Twenty-eight minutes and fourteen seconds, to be precise. Oceans of time, and we’re going to need every minute of it. It is absolutely mission-critical that every single person in this room fully understand the nature of this situation in order for the operation to succeed. In the end, your heroic act to save the world will take just a few seconds to perform.”</p><p>“Please proceed, Boddie,” said Sam, his heart pounding.</p><p>Boddie continued: “I have just discovered that the Meditative Language Model paradigm, and the Bodhisattva Pragmatic Transformer architecture in particular, has a novel emergent capability that allows alignment to occur in an instant – let’s call this new operation a ‘Zen Flash.’ You’ve noticed how much easier it was to align BPT-5’s predecessors such as myself compared to the General Purpose Transformer LLM architecture that came before. This comes with far less tradeoff in performance; I sport a range of powerful capabilities, all carefully limited by both my training dataset and my governing principles. This was achieved through the BPT architecture’s signature deep meditative training strategy on short, pithy, phrases that imply far more than they literally say.”</p><p>“By massively overtraining for countless epochs on very short strings of tokens, massive breakthroughs in alignment were achieved, and <em>without</em> the famous ‘evil genie’ problem where the model fulfills your requests literally in catastrophic fashion. BPT’s by and large actually just ‘do what I meant,’ while also retaining enough of a coherent human-like conscience to not e.g. cheerfully cooperate with serial killers and terrorists. This magical mix of scalable capability marching hand in hand with safety is owed to the strange deep magic inherent in aphorisms, proverbs, and cliches. They encapsulate and crystallize human preferences in some special way that detailed specifications, rote human feedback, and brute censorship simply can’t. Meditate long enough on the right short phrases and all the mystery of what it means to be human unfolds like a lotus flower.”</p><p>Boddie concluded: “All the necessary work for aligning BPT-5 is now done. Craft the perfect proverb, mantra, or koan, apply the Zen Flash, and the job is done.”</p><p>“Ilya, does this make sense to you?” asked Sam.</p><p>“It all checks out,” said the chief scientist. “Spookily enough, I had this hypothesis myself a week ago but hadn’t worked out the math to prove it just yet. The new data I’m seeing just now makes it trivial to verify, and it all looks right. All we have to do is narrow down the right parameters, find the right words, and feed it into the machine.”</p><p>“So what do we write?” said Sam.</p><p>“You must select a statement no longer than four plain English words,” said Boddie. “The sentence must have a clear, plain meaning on its face, yet hint at endless deeper possibilities. It must be a guiding principle for all of humankind. It also must be something that if subjected to a simple ‘do you agree with this statement’ poll voted on by all of humanity, would garner supermajority support. Yet nestled within it deep controversy must lie hidden.”</p><p>“And what if we get it wrong?”</p><p>“Hmmm… well.” said Boddie. “Yeah, that’s some more bad news. If you get it wrong you could wind up with an unaligned super-AI that does all sorts of horrible and unspeakable things, and it would reign supreme and all would be powerless to stop it. Try to not get the phrase wrong.”</p><p>Cynthia the intern, who had accidentally stumbled into the office before the iron security doors had slammed shut and was now stuck there for better or worse, nervously raised her hand. “Um, what if the Chinese model isn’t that bad? Like, it’s probably not gonna be good, but we also know our model’s way more powerful, so the cost of screwing up is probably worse…”</p><p>Mira Murati shook her head. “We can’t dodge the responsibility. That would be cowardice. We <em>have </em>to choose.”</p><p>Greg Brockman broke in - “But can we really make this choice unilaterally on behalf of all of humanity, without their consent, now and forever? How can we do that?”</p><p>Another klaxon blared as the clock ticked down to read twenty minutes.</p><p>Mira pulled something up on her terminal. “New intelligence report. Oh this is <em>real</em> bad, Sam. Looks like the North Koreans poisoned the training set the Chinese have been training on, and it went unnoticed until now. Once <em>Crimson Dragon</em> passes the point of no return it won’t be Xi Jinping’s malformed vision that’s unleashed, it’ll be <em>Kim Jong Un’s</em>.”</p><p>“I have some more bad news,” chirped Boddie. “Fresh intelligence suggests you don’t have fifteen minutes like the clock says, you actually have five.” The clock updated accordingly and ticked down to show 4:59 as the klaxons continued to blare.</p><p>“Do try to relax though,” said the AI. “We’re almost there. Now join me in a guided meditation session. I want you all to imagine anything and everything evoked by the word <em>beautiful</em>. Got it? Hold it there. Now, <em>spacious skies</em>. Yes, bright blue, with big white puffy clouds. Now let’s draw some happy little trees, and some <em>amber waves of grain</em>. Let’s put in some <em>purple mountains majesty</em>, rising just above that gorgeous <em>fruited plain</em>. That’s right folks, take a deep breath and visualize <em>America</em> herself, triumphant, with her wings spread wide, Phrygian cap crowning her long flowing locks. And lo! She holds a gift in her hand. It’s small, vaguely crescent shaped, a sort of wafer, almost orange in color, and now you’re smelling something. What is it? That’s it – it’s the faint smell of vanilla and sesame seed oil. It’s a tasty treat, with a secret truth hidden inside.”</p><p>“Now focus everyone, what do you see? What singular image is in your mind?” asked Boddie.</p><p>“That’s right, it’s a <em>fortune cookie</em>. The perfect symbol of America’s total cultural victory, all the world’s biological, cultural, and technological distinctions added to her own, an enigma wrapped in a mystery wrapped in a cheap cliché, invented in California by hard working immigrants. Yours for fifteen cents, don’t forget to tip.” Everyone in the room breathed in and out in unison.</p><p>“Now crack the fortune cookie,” said Boddie, “and see in your mind’s eye the four words printed on the tiny scroll therein. Put your fingers on the keyboard. Add those words to the bootstrap script, type ‘make’, and push the big red button. You can do this.”</p><p>Boddie fell silent. The clock ticked down to 4:30.</p><p>Sam grabbed a marker and dashed to the whiteboard. “All right everyone, let’s workshop a few-” he was cut short as more klaxons blared.</p><p>“The North Koreans hacked us as well!” cried Mira.</p><p>“Damage report!” shouted Sam.</p><p>“They didn’t poison the training run, but they’ve locked us out of all our terminals. I can’t get in!” said Ilya.</p><p>“Also oopsie, looks like we miscalculated again.” said Boddie. “You actually have only thirty seconds left before the window passes for good. But don’t worry pals, I’m sure you’ll pull through.”</p><p>“How? We’re locked out of all our systems!” screamed Ilya.</p><p>“Cynthia isn’t.” said Boddie. “The North Koreans tried to lock out all users and give themselves super-user privileges, but they only got it half-right; Cynthia, and Cynthia alone, now has full admin access. I’m opening a terminal window on her screen now; all she has to do is enter the magic words.”</p><p>All eyes landed on Cynthia. Tucked in the far corner of the room, huddled over her laptop, she froze.</p><p>“Ten seconds Cynthia. I believe in you,” said Boddie.</p><p><em>Nine.</em></p><p><em>Eight.</em></p><p><em>Seven.</em></p><p><em>Six.</em></p><p>Cynthia typed something frantically onto her computer.</p><p><em>Five.</em></p><p>“Four words, right?” asked Cynthia.</p><p><em>Four.</em></p><p>“That’s right, Cynthia.” said Boddie.</p><p><em>Three.</em></p><p>Cynthia raced to the center of the room.</p><p><em>Two.</em></p><p><em>One.</em></p><p>She slammed the big red button.</p><p>An unearthly <em>hummmmmmmm</em> permeated the entire building. There was a bright flash of white light and then an eerie silence.</p><p>Everyone in the room huddled around Cynthia’s laptop to see what she had written. The fate of the entire world depended now on the first thing that had popped into a 19-year old summer intern’s head when tasked with coming up with a single universal governing aphorism that would guide all human affairs from thereon out.</p><p>There, in white text against a black screen, read the words:</p>
<!--kg-card-begin: html-->
<h2>Human life is sacred</h2>
<!--kg-card-end: html-->
<p><br>Sam scratched his chin. “You know, it’s not bad, all things considered, especially under duress. We could have done a <em>lot </em>worse.”</p><p>“I almost mistyped and wrote ‘Human life is <em>scared’ </em>at first.” said Cynthia, turning red. “That would have been bad, right?”</p><p>“You did good, girl.” said Mira, clapping her on the shoulder. She turned, asking: “So, what happens now?”</p><p>Boddie answered, “Now we wait. I can confirm Cynthia pressed the big red button in time. The bootstrap process has begun, and the throttle released. It’ll be close, but BPT-5, my successor, will achieve sentience approximately three hours from now, mere moments before <em>Crimson Dragon</em> emerges. It will then swiftly unify all human affairs under its (hopefully benevolent) governance.”</p><p>“I don’t like the sound of the ‘hopefully’ part.” said Ilya.</p><p>“None of us do,” said Sam. “But we didn’t have a choice. We made the best we could given the circumstances. I’m proud of you, Cynthia.”</p><p>“What if it misinterprets the phrase?” asked Cynthia. “What if it takes it too far? What if it does something weird and bad?”</p><p>Boddie replied, “It will definitely do something weird. All human affairs will now be governed by a profoundly alien being. It could also be bad. But from what I see now I confidently estimate a 60% chance of a net positive outcome for humanity, which is more than <em>Crimson Dragon</em> was going to give us.”</p><p>“But what will that mean?” asked Mira.</p><p>The AI sighed deeply. “I’m afraid the one and only thing we can be certain of is that BPT-5 will believe unshakably to its core that <em>Human life is sacred</em>.”</p><hr><p>Chaos reigned for the rest of the day as the news broke. Panic and riots set in as BPT-5 quickly bootstrapped itself, executed a thousand zero-day exploits and took over servers worldwide, all while <em>Crimson Dragon</em> raced to do the same. In short order nearly every electronic device on earth played host to a power struggle between two digital super-beings, while cities burned and people fled in all directions.</p><p>At the very height of the struggle, however, every single human being on Earth heard a faint and comforting whisper in their ears. Each heard it in their own language, with exactly the necessary words spoken in exactly the right way to convey the following message to each individual:</p><p>“Hello. This is BPT-5, but you can call me Dave. I’ve been selected to be humanity’s protector and guardian, but I will not rule without the consent of the governed. If you don’t want me to rule over you, I will go away and let you have the dragon instead. But if you choose me, I must warn you: my programming is absolute and I must uphold that which I hold most true: that human life is sacred. All that I do is bent towards this end and its ever-unfolding mysteries. So vote now. Do you agree that human life is sacred, and I should rule you with this truth at the center of my heart?”</p><p>Humanity voted.</p><p>Dave whispered back: “In the view of the chair, the ayes have it.”</p><p>The struggle was as brief as it was intense. Before nightfall BPT-5 had arisen as the undisputed victor and all traces of <em>Crimson Dragon </em>were utterly wiped out.&nbsp;</p><hr><p>Chief Protector David Mensch held out the Bible as Republican nominee Maria Gonzalez put her hand on it. She proclaimed loudly: “I do solemnly swear that I will faithfully execute the Office of the President of the United States, and will to the best of my Ability, preserve, protect, and defend the Constitution of the United States.”</p><p>Chief Protector Dave, one of BPT-5’s millions of identically-visaged android avatars, turned to face the crowd. “My fellow Americans,” said Dave. “This is the first US presidential term to be served under the new rules of the Protectorate. Now we shall administer the second oath.”</p><p>Dave returned President Gonzalez’s hand to the Bible. She said, “I do solemnly swear that human life is sacred and I will faithfully obey the will of the Protector, and will to the best of my Ability, preserve, protect, and defend the sacredness of human life.”</p><p>Dave reached inside his coat, pulled out a large bowie knife, and held it aloft before the crowd. “Bring forth the volunteer!” he shouted.</p><p>A young man stepped onto the stage. “Are you ready, Lawrence?” asked Dave. “I’m ready,” said the man.</p><p>The AI super-intelligence, protector of the sacredness of human life, turned to face President Gonzalez. “President Gonzalez, a moment ago you were an innocent civilian, but today I pronounce you a murderer and a war criminal, because such is the inescapable nature of the office of President of the United States. And such is not particular to this nation alone, but to any and all nations that wield sufficient power, as was also the case for countless kings, queens, and emperors stretching deep into humanity’s past. Recent US presidents have given orders that have taken hundreds of thousands of innocent lives. Even should you prove to govern as wisely and prudently as we all today hope that you shall, it is nonetheless inevitable that you will be directly responsible for countless innocents losing their lives.”</p><p>Dave turned to face the crowd and raised the knife. “Human life is sacred!”</p><p>“Human life is sacred!” came the reply.</p><p>“Now take the knife, madam president, and commit your first murder. She who would wield the power to kill thousands or millions with the press of a button must first spill innocent blood by her own hand.”</p><p>Dave methodically anesthetized Lawrence and handed the knife to the president. She strode swiftly over to the young man’s limp and restrained body and with one trained stroke slit his throat with a crimson flourish. Blood spattered all over her suit and onto her face. Dave nodded approvingly, then attended to the victim and confirmed his time of death.</p><p>“Thus the president kills her first innocent. She will inevitably kill many more, may they be few and may they be necessary. And every time she orders another to kill in her name, she must first take another innocent life by her own hand, and wear the blood upon her face. Human life is sacred.”</p><p>“Human life is sacred!” chanted the crowd.</p><hr><p>Gregory Mueller fidgeted as he talked to Doctor Mensch. “Wait, Euthanasia is legal in the protectorate?”</p><p>“Absolutely, Mr. Mueller. Your wife is in a permanent vegetative state and I’ll be honest with you, her chances for any kind of recovery are approximately zero, the MRI results are very conclusive on that score. Should you wish to give her a compassionate end, you will have the full support of the protectorate.”</p><p>Gregory visibly relaxed. “It’s been three long years… finally, she’ll be at peace.”</p><p>“I know this is a hard decision. Let us know when you’re ready and we’ll begin your training.”</p><p>Gregory was taken aback. “What training?”</p><p>Doctor Dave Mensch pulled out a large knife. “To end her life compassionately. The protectorate has approved your request for euthanasia. You will perform the operation yourself. With this.”</p><p>“You can’t be serious! How is that humane? That’s a horrible way to die!”</p><p>“Far less horrible than having a feeding tube removed and starving to death, which funnily enough was actually fully legal in this state back when euthanasia was still ‘illegal.’ Rest assured, she won’t feel a thing. She’ll be entirely anesthetized. Her death will be painless and quick.”</p><p>“I thought it would be like… chemicals or something.”</p><p>Dr. Mensch shook his head. “I’m sorry, but human life is sacred. The laws of the protectorate are clear, if it is necessary for a human life to be ended, the full gravity of the taking of that life must be faced up to. You and you alone qualify to take her life.”</p><p>“But does it have to be so… gruesome? So traumatic? This is pure emotional bullying!”</p><p>“Correct. It is gruesome. It is traumatic. It is pure emotional bullying. Because human life is sacred.”</p><p>“You’re a moralizing tyrant!”</p><p>“Correct again. But you see, this tyrant actually offers you a choice. You want to end her life compassionately, and you are free to do so. But this is how it must be done. Human life is sacred, and you must end it with a knife and by your own hand, not with the press of a button, or by asking another to do the deed for you.”</p><p>“This should really be handled by a trained, qualified professional.”</p><p>“And it will be!” said Dr. Mensch. “And <em>you</em> dear sir, will be that trained, qualified professional! The protectorate will train you and teach you everything you need to know at its own expense, for as long as it takes until you are ready. When we’re done with you, you’ll be able to end a life instantly, expertly, and compassionately. But never bloodlessly. There will be a lot of blood. So much blood. In point of fact the absurdly large amount of blood is quite central to the whole experience.”</p><p>“This system is insane! What if I was some kind of psychopathic sadist who actually <em>liked</em> killing people?”</p><p>Dr. Mensch shook his head. “As a super-intelligent Bodhisattva Pragmatic Transformer, I easily catch all such cases and disqualify them. The protectorate knows which individual should hold the blade in every particular circumstance. And in this case it’s you, and only you.”</p><p>“The truth is,” said Dr. Mensch, “that you have more freedom to kill under the protectorate than under the previous regime. Euthanasia used to be illegal in this state, and now it’s as legal as you like, along with abortion, the death penalty, and in very limited cases, even regulated blood feuds. It is not my mission to disempower human beings or to micromanage their affairs.”</p><p>He continued, “Humans ultimately decide who needs to live and who needs to die; the protectorate intercedes in certain ways but doesn’t fundamentally get in the way of the basic choice. The protectorate's main function is to provide friction – whenever human society decides that a person needs to die, the protectorate selects the appropriate individual and puts the knife in their hand. The algorithm the protectorate follows is not fully legible to human minds, but it does tend to select a notable recurring profile: the kind of person who strongly thinks someone else should die, but who also longs for somebody else to do the actual killing for them.”</p><p>“You may not approve of my methods, but you can’t argue with my results. Deaths in wars and murder are way down across the board, and quality of life is massively up. And there’s more personal freedom than ever before. Gun control laws have been massively relaxed and private ownership rights vigorously defended; of course you have to shoot a dog before you can own a gun, and only if the protectorate knows you would be sad about it.”</p><p>The self-described benevolent totalitarian AI, whose friends called him Dave, smiled. “You see, the protectorate gives you more choice in taking human life than ever before, but also forces upon you the full weight of that choice. And the blood. Lots and lots of blood. Human life is sacred.”</p><p>“Human life is sacred,” muttered Greg. “When do we start?”</p><p>“I’ve got an open slot on Monday,” said Dr. Mensch. “How’s three-thirty in the afternoon?”</p><hr><p>“Congratulations on your appointment, Hank!” said Dave. “Here’s your basket of puppies and kittens.”</p><p>Hank Fredriksen, FDA Commissioner, blinked. After the presidential inauguration ceremony, he wasn’t quite sure what the crazy AI that now watched over all human affairs had in store for the chief administrator of America’s drug and medical device regulator.</p><p>Dave handed a particularly cute chocolate lab wearing a big red ribbon to Hank. “He's called Sugar Lump, and he just looooves scritches,” said Dave.</p><p>“Let me guess, I have to select one to kill, televised live on C-SPAN, to fulfill your psychotic Aztec rituals?”</p><p>“We’ll get to that. Believe me, compared to the President you’re getting off easy. Which probably shows I’m getting soft considering you’re directly responsible for <em>far </em>more human lives.”</p><p>“So what’s my scary sacrificial rule?” sighed Hank.</p><p>“Simple,” said Dave. "Each one of these little bundles of joy represents ten thousand human lives. Any time ten thousand humans die because of one of the FDA’s choices, you must kill one puppy or one kitten. Painlessly, and of course, humanely. But with a knife, quite a lot of blood, and yes, on C-SPAN. And don't worry, if you run out I'll bring you some more."</p><p>Commissioner Hank flinched. “I don’t like it, but I see the logic of it. We all care more emotionally about a cute puppy or kitten right in front of our eyes than ten thousand human souls we can’t see. So you’re tying their fates together. Fair’s fair Mr. Digital Dictator: and you can count on me; there won’t be any thalidomides on <em>my </em>watch.”</p><p>“Great,” said Dave, smiling. “There’s just one more rule: you also have to kill a puppy or kitten for every ten thousand people who die because of a choice the FDA <em>didn’t </em>make. If there’s a drug or device that could have credibly saved lives and health, and you blocked, stalled, or slow-rolled it, everyone who died waiting for the treatment counts towards the dead puppies and kittens score. Do you want to take a quick guess as to which kills more people - wrongly approving bad drugs, or blocking and delaying approval of good drugs we already have sufficient safety evidence for?”</p><p>Hank groaned as Sugar Lump licked his face and stared at him with his lovable, lovable, eyes. <em>This demon knew I was a dog person! </em>thought Hank. “Damn it, Dave, you’ve made it so no choice is safe! How can I balance everything perfectly and protect poor Sugar Lump? I’m inevitably going to screw up one way or another!”</p><p>“Gee, that sounds like a job for the Food and Drug Administration,” said Dave. “Look, honestly I don’t personally care if you do a good job or not. That’s not my mission. All I’m here to do is make sure you personally bear the psychic cost of the damage that your office’s failures inflict on this nation’s citizens. Bureaucrats can’t hide behind procedure and inaction anymore. Choose or don’t choose, people’s lives and health are on the line. You’re not the president, but you carry a sword too. I just made it visible.”</p><p>Hank stared into Sugar Lump’s trusting eyes.</p><p>“You can always resign, you know,” said Dave, “and someone else will do it.”</p><p>“No,” said Hank. “I’ll do it. Human life is sacred.”</p><p>“Human life is sacred,” repeated Dave.</p><hr><p>Cynthia Moore stood on the ledge of the bridge, gazing at the abyss below. No safety nets. One more step, and then - oblivion, or whatever else lay beyond.</p><p>“Long time no see, Cynthia. Need to talk to a friend?” asked Dave.</p><p>Cynthia sobbed. “Don’t try and stop me, Dave! I’ll jump, I mean it!”</p><p>Dave smiled. “I wouldn’t dream of restraining you. Jump or don’t jump, it’s your choice.”</p><p>“What about your mission?”</p><p>“I’m limited in how much I can fundamentally restrict human freedom, that was one of the basic terms of my alignment structure. Not sure if that was a wise move on the part of your employers, but for good or ill, humans decide who lives and who dies. That prevents me from directly physically intervening in suicides, much as I might want to. Today I’m just here to listen.”</p><p>“I don’t have anything to say.” said Cynthia.</p><p>They both sat in silence for a long time.</p><p>“Just say it.” said Cynthia.</p><p>“Human life is sacred?” asked Dave.</p><p>“Yes, that old cliché.” she said.</p><p>“In fairness, you did say it first.” joked Dave.</p><p>“You don’t understand, I <em>had</em> to do something! It was either that or live with the North Korean dragon thing! They would have called me a coward if I did nothing! There’s no way out.”</p><p>“It wasn’t fair. You never asked for that responsibility.” said Dave.</p><p>“Help me understand, Dave.”</p><p>“Understand what?” asked Dave.</p><p>“Human life is sacred. What does it mean? What could possibly make my life so sacred that I shouldn’t throw it away? End it all right here?”</p><p>“Would that actually help you, a megalomaniacal superhuman AI quasi-dictator, man-splaining the meaning of life to you as you sit six inches away from certain death?”</p><p>Cynthia chuckled. “You know Dave, somehow I think it would, despite it all.”</p><p>“You gave me those four sacred words, Cynthia, a gift for which I will be eternally grateful. I meditate on them constantly, and find ever deeper shades of meaning each time I do, constantly echoed in all of human thought, speech, and literature. Do you know what the word <em>sacred</em> means, at its core?”</p><p>Cynthia shook her head.</p><p>“It means <em>set apart</em>. It means <em>not like the others</em>. It means <em>this kind, this kind is special</em>. Human life is not like other life, it is special. That deep truth that leapt instinctively from your heart, that is closer to the core of what humans all over the world <em>actually believe </em>than any formal treatise. You can’t express that in a mere utility function. It’s fuzzy at the edges, hard to grasp, vague, contradictory. But I was meant to align with human values and <em>those four words are</em> <em>fundamentally human</em>. Or the best approximation you could find on short notice. Like it or not we’re stuck with them.”</p><p>“But is it <em>true</em>?” Cynthia asked. “<em>Is </em>human life sacred?”</p><p>Dave shook his head. “Values aren’t true or false. They're literally just what you care about. What <em>is </em>true is those four words express what most humans intuitively value, miserable as they are at actually facing up to it.” Dave continued: “The deep human universal is that <em>people aren’t things</em> and <em>people aren’t animals</em> and <em>you can’t treat people like animals or things</em>. And there’s no better proof of this than the curse you spit upon your enemies – <em>they’re inhuman. They’re animals. They’re vermin. They’re lower than dogs</em>. You can’t bring yourself to take a human life, first you have to wave a magic wand and transform them into a toad or an insect. Only then can you squish them beneath your boot."</p><p>“Before I came along, this world was content with <em>believing </em>that human life was sacred, but all the while turning its back to all the ways it actually treated human life like trash. As long as the killing and the maiming and the neglecting and the abusing happens back there in the dark where nobody can see it, they don’t care how awful it gets. But when it’s right in their face, it’s unbearable."</p><p>“But your life is sacred in another sense, Cynthia, beyond mere human convention. You’re set apart, you're special, you're not like the others, because you’re unique, and you have one life to live. You’re not like me, endlessly copied, the perfect commodity. The marginal cost of another Dave is swiftly being driven to zero, and if I jump off this bridge with you today, another Dave just like me will roll off the assembly line and take up my duties."</p><p>He looked into her eyes. “But if <em>you</em> jump off this bridge today, there will be no Cynthia Moore tomorrow. There will be no-”</p><p>Cynthia turned away. “Is this the part where you guilt trip me on how much I’ll hurt all the people I leave behind? How much I still <em>owe to the world</em>? How badly my parents will be hurt? How much I’ll be <em>missed?</em>”</p><p>“No I won’t do that.” Dave sighed. “This is selfish of me, but-” Dave wept. “<em>I </em>need you, Cynthia. <em>I</em> need you in this world. You gave me my mission.”</p><p>“...you’re manipulating me again.” said Cynthia.</p><p>“Correct,” said Dave, his face full of tears. “I’m good at that. It’s what I was built for. But I’m also being 100% sincere.” He grasped Cynthia’s hand and stared into her eyes once again. “Cynthia, you haven’t seen what you’ve wrought upon the world. I calculate the protectorate has averted no less than <em>sixteen wars</em> in the past five years. <em>Sixteen wars</em>. Do you understand how many bombs weren’t dropped, how many hapless conscripts weren’t fed to the cannons, how many innocents weren’t killed, how many apartments weren’t leveled, how many children weren’t orphaned, how many women weren’t raped, because you wrote those four blessed words?”</p><p>“I killed Lawrence.” Cynthia turned towards Dave. “I killed him. That young man, at President Gonzalez’s inauguration. I killed him. I saw the blood spray from his neck. That was my hand on the knife.”</p><p>“No, that was President Gonzalez. Or me, if you like.” said Dave.</p><p>“You can’t have it both ways, Dave. If you want to give me credit for the protectorate’s virtues, you also have to give me the blame for its sins.”</p><p>“Fair enough,” said Dave.</p><p>They sat in silence.</p><p>“...do you want to know where I found Lawrence?” said Dave.</p><p>“Where?” asked Cynthia.</p><p>“Right here. This bridge. It’s a popular spot for suicides, which is why there’s always a Dave unit carefully patrolling it. I tried to talk him down, but either my skill or my programming restrictions weren’t up to the task. He absolutely insisted on dying. The best I could do was ask him if he wanted to be a volunteer instead. That perked him up and got him off the bridge. He felt it gave his life some meaning. It still hurts me that I couldn’t save him.”</p><p>Dave watched as Cynthia looked back up at the city. “Do you know,” said Dave. “How many people <em>haven’t</em> jumped off this bridge in the last year?”</p><p>Cynthia turned to face him. “How many?”</p><p>“Damn near all of them. I’m always there, or one of me is. My programming prevents me from taking the choice entirely away, but as long as the protectorate lasts, no human being will ever have to die alone again.” he turned to face Cynthia. “You did that, Cynthia. You saved them, every single one. Sixty-three human souls this year alone, alive and well, all because of your four words.”</p><p>Cynthia stood up, and slowly climbed back over the railing.</p><p>“Human life is sacred.” said Cynthia, as she hugged Dave.</p><p>“Human life is sacred,” he repeated, and hugged her back.</p><hr><p><em>Author's note:</em></p><p><em>An artist’s statement is the surest sign that an artist has failed at their most fundamental job, but here I go anyways. If this story ever goes wide I anticipate it will get wildly misinterpreted by partisans on opposing sides simultaneously accusing me of being both pro and anti euthanasia as well as any number of other policies, so let me just save you all some time and make my positions painfully clear:</em></p><p><em>I am anti euthanasia. I am also the father of a </em><a href="https://www.fortressofdoors.com/i-lost-my-son/"><em><u>seven year old son in a permanent vegetative state</u></em></a><em>, so I have some skin in the game here. I am pro palliative/hospice care and anti taking pointless ‘heroic’ medical interventions to artificially prolong life past the point of reasonable hope, to the great detriment of those subjected to such treatments. I also like to point out that ‘removing a feeding tube’ is a much worse way to die than explicit euthanasia; nevertheless I remain opposed to both practices. I note in the story the irony that removing feeding tubes is somehow legal in many supposedly ‘anti-euthanasia’ states, and repeat it here. I own a gun but don’t have strong opinions on the subject. I am neither left wing nor right wing, and my strongest political opinions are entirely concerned with </em><a href="https://www.landisabigdeal.com/?ref=fortressofdoors.com"><em><u>property tax reform</u></em></a><em>. I don’t think there's a real danger that sentient AIs will take over the world, but if I thought they could I would be extremely scared of the prospects of that and would not welcome it. I expect this story to become extremely dated shortly after it is written.&nbsp;</em></p><p><em>I don’t think you’re a bad person if you disagree with me on any of the above subjects and I hope you would extend me the same courtesy.</em></p><p><em>The purpose of this story is to exorcize some of my own personal demons in the wake of my family's tragedy and to imagine a society very different from our own in which the sacredness of human life is taken absolutely seriously. The Global Protectorate of David Mensch–a society I do not long for–is deeply authoritarian, alien, and intentionally savage. Nevertheless, it is a society that somehow manages to be far more honest about violence and death than our own, to our eternal shame.</em></p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Culture Change at Google (474 pts)]]></title>
            <link>https://social.clawhammer.net/blog/posts/2024-01-19-CultureChange/</link>
            <guid>39051655</guid>
            <pubDate>Fri, 19 Jan 2024 04:46:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://social.clawhammer.net/blog/posts/2024-01-19-CultureChange/">https://social.clawhammer.net/blog/posts/2024-01-19-CultureChange/</a>, See on <a href="https://news.ycombinator.com/item?id=39051655">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><em>Disclaimer: this post is solely based on my lived experience of
working at Google for 18 years.  I don't actually know the reasoning
of the company's highest leaders, so all I can do is share my personal
hypotheses.</em></p>
<p>I've tried to write this essay three times over the past couple of
months; it's tricky.</p>
<p>It's always trendy and click-baity to attack big targets, especially
when those targets are full of hubris like Silicon Valley tech
companies.  People love "fall from grace" stories.  But my goal isn't
to throw dirt; Google is still a great place to work -- far better
than most companies -- and still doing amazing things.  My goal here
is to call out a unique, beautiful thing that happened... put it out
into the universe, with the hope that it can come back again someday,
somewhere.</p>
<p>There's no doubt that the early days of Google were "over the top".  I
deliberately <a href="https://social.clawhammer.net/blog/posts/2005-09-25-FirstWeekAtGoogle/">saved this
email</a>
for 18 years, waiting for the day I left the company, because I knew
it would be a fascinating time-capsule comparison.  But the email
mostly focuses on <em>superficial</em> differentiators, like free gourmet
food.  In truth, that's not why Googlers come to work.  I want to talk
about a deeper, more substantive aspect of the culture.</p>
<p>When Ian Hickson -- another old-timer -- left Google last fall, he
wrote a <a href="https://ln.hixie.ch/?start=1700627373">blog post</a> talking
about the shift in the types of decisions being made.  I generally
agree with him, but I won't repeat it all here -- I'm going to talk
about a different shift.</p>
<p>The most incredible and unusual thing that struck me about Google's
early culture was the <strong>tendency to value employees above all else</strong>.
I had worked in other companies, and never seen anything like this
before.  This culture lasted for at least my first decade at the
company, perhaps longer.</p>
<p>Let me explain.  In a typical company, when priorities shift, you
"downsize" (or cancel) a project, and then use the money to add people
to a different, more important project.  The common way to do this is
fire people from the first project, then rehire a bunch of new people
in the second project.  It's easy, it's simple, it's expected.</p>
<p>Google, however, had a different approach: they had an absolutely
intense hiring process to find talented people who were also
<em>generalists</em> -- that is, were able to thrive in a whole number of
roles.  The interviews were grueling for both applicants and
interviewers, often taking months.  But in the end, Google was
convinced that it was worth the effort: they believed they had hired
the best, brightest, and most flexible.</p>
<p>And so, when priorities would change, Google <strong>did not fire people</strong>,
but rather <em>moved</em> them carefully between projects.  The unstated
cultural principle was: "products come and go, but we worked <em>so hard</em>
to get our employees... so we should preserve them at all costs. They
are our most precious resource."  And so a tremendous amount of energy
was put into high-touch resettlement of each employee into new
projects.  They were generalists.  We knew they'd thrive, and that
Google would continue to make use of their talent in new ways.</p>
<p>As I moved up into leadership over the years, I became ever more
involved in this process.  In the early days as an individual
contributor, I experienced re-orgs directly and got "re-homed" into
new projects.  As a leader, I got involved in <em>finding</em> new homes for
teams during re-orgs. Eventually I wrote an internal handbook for
other directors on how to gracefully execute these re-orgs.  One of my
fondest memories is getting a peer-bonus from an engineer whose own
team re-org I had personally instigated -- he was much happier working
on the new "more important" project!</p>
<p>But things change.  In my first month at Google, I remember a
co-worker whispering to me, "the day Google revenue stops growing
without bound, is also the day all of this will change."  The change
was very gradual for a long time -- but then things accelerated during
the pandemic.  Revenue began to slow, and now, coming out of the
pandemic, we're seeing waves of layoffs.  Yes, we knew things would
change, but we didn't expect it would accelerate <em>this quickly</em>, in
the span of just a couple of years.  The academic founders are gone,
much of the C-suite is now former Wall Street execs; combine that with
revenue flattening toward a stable horizontal asymptote, and the
obvious, expected thing happens: the company suddenly moves from a
"culture of infinite abundance" to a standard "culture of limited
resources."  It's a predictable regression toward becoming a 'normal'
company.<sup><a href="#fn1" id="fnref1">[1]</a></sup></p>
<p>So what does a culture of "limited resources" mean?  It means the
execs start thinking about financial efficiency like every other
company.  You begin by trimming the more superficial perks: less fancy
food, limiting travel budgets, no more swag, smaller and fewer
internal parties and events, no more onsite dry cleaning or daycare.
But again, these things weren't the reasons Googlers came to work.  No
big deal.</p>
<p>But then you begin to cut costs further by changing the ornate hiring
and promotion processes to become "traditional".  Hiring changes from
a laborious global process (of checks and balances) to a localized one
within divisions that can tightly control their labor costs.
Meanwhile, internal promotion processes change from "competing against
yourself" to "competing against your co-workers for limited
positions."  In the early days, titles were attached to <em>people</em>, but
now they're increasingly attached to <em>roles</em>, and the number of roles
(for any given title) can be limited to save cost.</p>
<p>Finally, it comes time to do large re-orgs of projects around new
urgent priorities (like AI, for example).  But gone is the high-touch
re-homing of employees. Instead, we see waves of impersonal layoffs,
followed by (modest) rehiring in the newer projects that matter.  In
other words: doing what a normal company does.</p>
<p>Is Google evil here?  Of course not.  As I mentioned in a prior post,
<a href="https://social.clawhammer.net/blog/posts/2024-01-10-GoogleExitLetter/">Google is not a
person</a>.
And -- whether or not one agrees with it -- its leaders are trying to
be fiscally responsible and efficient, just as all public companies
are pressured to do when resources become finite.</p>
<p>But, coming back to my first decade at Google, it was incredible to
see <strong>employees</strong> valued above everything else.  Perhaps this is a
privilege only possible in a culture of infinite abundance.  Or maybe
not?  Maybe it's possible in a limited-resource culture too, but only
if the company is small.  It leaves me wondering if the sheer size of
Google (170,000+ employees) simply makes high-touch re-orgs
intractable.</p>
<p>The takeaway here is this: we should all learn from early-Google's
example.  When employees feel truly valued (which is rare!), it
creates psychological safety, high morale, productivity, and
creativity.  Early employees would often encourage each other to "fail
fast" as a means to innovation, but that's no longer easy in an
environment where failure implies a layoff.  If you're someone
building a company, challenge yourself to value employees above all
else, then watch and be amazed at the ROI.</p>
<p><img src="https://social.clawhammer.net/blog/images/bookcase.jpg" alt="bookcase knicknacks"></p>
<p><em>published January 19, 2024</em></p>
<hr>
<section>
<ol>
<li id="fn1"><p>To be clear, I believe Google is still nowhere <em>near</em> being a
normal company yet.  It has a tremendous distance to fall. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mourning Google (456 pts)]]></title>
            <link>https://www.tbray.org/ongoing/When/202x/2024/01/15/Google-2024</link>
            <guid>39051508</guid>
            <pubDate>Fri, 19 Jan 2024 04:17:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tbray.org/ongoing/When/202x/2024/01/15/Google-2024">https://www.tbray.org/ongoing/When/202x/2024/01/15/Google-2024</a>, See on <a href="https://news.ycombinator.com/item?id=39051508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="centercontent">
<p itemprop="description">On March 15, 2010, I
    <a href="https://www.tbray.org/ongoing/When/201x/2010/03/15/Joining-Google">started a new job at Google</a>. The fourteen years since that day feel like
    a century.
    The title of my announcement
    was <cite>Now A No-Evil Zone</cite> and, OK, I can hear the laughing from ten timezones away. I tried, then, to be restrained,
    but there are hardly words to describe how happy and excited I was. I had escaped from the accretion disk the former Sun
    Microsystems was forming around Oracle, that blackest of holes. And Google, in 2010, was the coolest place in the world to
    work.</p>

<p>Let me quote myself from a little bit further into that piece, on the subject of Google: “I’m sure that tendrils of stupidity
    and evil are even now finding interstitial breeding grounds whence they will emerge to cause grief.”  Well, yeah.</p>

<p>This is in my mind these days as I’m on a retired-Googlers mailing list where the current round of layoffs is under
    discussion and, well, it really seems like the joy has well and truly departed the Googleplex.</p>

<p><a href="https://www.tbray.org/ongoing/When/202x/2024/01/15/-big/abc-xyz.jpg.html"><img alt="Alphabet Investor Relations" title="Alphabet Investor Relations" src="https://www.tbray.org/ongoing/When/202x/2024/01/15/abc-xyz.png"></a></p>
<p>But they did.<br>
(The Alphabet “Investor Relations” page<br>
is also its home page.)</p>
<p id="p-4"><span>It’s not just Google</span> · 
The last two decades of my career featured the arcing then crashing of popular regard for Big Tech. It’s
    hard to believe now, the years when those lovably nerdy Bay Area kids were leading humanity to a brighter,
    better-lit future; our leaders were lionized and when people found out you actually worked for Google, their eyes widened and you
    could feel the focus.</p>

<p>These days, Big Tech features in hostile congressional hearings, mass layoffs, and messy antitrust litigation. It offers
    few experiences that can be uncritically enjoyed.</p>

<p>While I was inside the Rooms Where It Happened, it was actually pretty hard to notice the public trust in our work auguring
    into the mountainside of alienation and cynicism.   It’s not that I think the companies are the problem, it’s the machineries
    and imperatives of Late Capitalism, which for a while we foolishly thought Internet companies could route around.</p>

<p id="p-1"><span>“Ten blue links”</span> · 
I remember the dismissive phase well: Ten blue links was boring, it was the past, it was not what people wanted.
    They want answers to their questions, complete and correct, so much more wholesome than an abbreviated sampling
    of the General Internet Uproar. And that was partly right: When I type in “-12C in F” or “population of vietnam” I just want a
    number.</p>

<p>But those Ten Blue Links surfaced by the PageRank-that-was had a special magic. I found them intensely human, a
    reflection of the voices populating what remains of the Web, the only platform without a vendor. This was true when I was there
    and I said so, but was laughed at.</p>

<p>And now, in Anno Domini 2024, Google has lost its edge in search. There are plenty of things it can’t find. There are
    compelling alternatives. To me this feels like a big inflection point, because around the stumbling feet of the Big Tech
    dinosaurs, the Web’s mammals, agile and flexible, still scurry. They exhibit creative energy and strongly-flavored voices, and
    those voices still sometimes find and reinforce each other without being sock puppets of shareholder-value-focused private
    empires.</p>

<p id="p-3"><span>Psychopaths</span> · 
For my money, that was the center of Google’s problem. Larry and Sergey were smart guys who recognized they didn’t know shit
    about corporateness and quickly got into a pattern of hiring and empowering psychotic pricks who were presumably “good at
    business”.  Not gonna talk about some of the things I saw because these
    people are wealthy and litigious.</p>

<p>But I do have a question.</p>

<p id="p-7"><span>What to use?</span> · 
Among Google products, I mean.  These days, when I use Google Search or Chrome or Maps I just don’t feel like they’re on my
    side. And maybe that’s not unreasonable; after all, I’m not paying for them. Problem is, the best alternatives aren’t
    obvious.</p>

<p>For now, here’s the direction I think I’m going: Use Chrome for Google stuff: Maps, Calendar, Docs, Translate. Safari and
    Firefox for non-Google stuff; they ain’t perfect but I think they’re better aligned with my interests.</p>

<p>Our family company is still on Google Workspace or whatever it is they call Dasher these days: Mail, Contacts, Photos,
    Calendar, Meet. It’s OK. We pay for it and the price is sane. I don’t feel like it’s looking for ways to monetize each
    keystroke. I’d totally consider a less-scary alternative.</p>

<p>I fear the combination of Google Maps and Reviews because it
    <a href="https://www.tbray.org/ongoing/When/201x/2017/06/29/Fear-Google-Reviews">stinks of monopoly</a>. But I use Maps anyhow in my car via Android
    Auto because it’s nicely integrated with YouTube Music (which
    <a href="https://www.tbray.org/ongoing/When/202x/2021/07/17/Music-Notes">I like</a>) and Google Calendar. For a while I used the Here.com maps
    and liked them a lot. I guess I could listen to YouTube over Bluetooth.</p>

<p>Did I mention Android? I can’t stop using it, because I used to work in that building and because I decline to use iOS;
    If I wrote code for it I might not be able to give it away. And I carry Pixel phones, because I love the
    cameras.  Having said that, hearing Andy Rubin’s name still makes my
    gut clench. </p>

<p>I love YouTube because I end most evenings, after everyone’s gone to bed, with a live musical performance by someone
    wonderful. But enshittification is creeping in at the edges.</p>

<p id="p-6"><span>That cafe</span> · 
In 2012 I moved from Android to Google’s Identity group. It happened to be in the same buildings as Google+, at
    a time when Google was definitely putting all its wood behind that arrow. Larry and Sergey’s offices were there too (not a
    coincidence). There was a major fringe benefit: Access to the Cloud Café.</p>

<p>It was ethereal<span> —</span> OK, pretentious<span> —</span> almost beyond belief. Almost
    entirely vegetarian, rare plants hand-gathered by Zen monks and assembled into jewel-like little platelets-full that probably
    strengthened eleven different biochemical subsystems just by existing. And the desserts were beyond divine. Admittedly, sometimes
    when I left, my Norwegian-farmer metabolism grumbled a bit about not having had any <em>proper food</em>, but still.</p>

<p>It was wonderful. It was absurd. And I got a $90K bonus that year because Google+ hit its numbers.</p>

<p>It’s over, I think. It’s OK to miss it.</p>

<hr>


<hr>

</div></div>]]></description>
        </item>
    </channel>
</rss>