<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 17 Mar 2025 06:30:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Sunsetting Whois (377 pts)]]></title>
            <link>https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en</link>
            <guid>43384069</guid>
            <pubDate>Mon, 17 Mar 2025 00:48:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en">https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en</a>, See on <a href="https://news.ycombinator.com/item?id=43384069">Hacker News</a></p>
Couldn't get https://www.icann.org/en/announcements/details/icann-update-launching-rdap-sunsetting-whois-27-01-2025-en: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla drives into Wile E. Coyote fake road wall in camera vs. Lidar test (124 pts)]]></title>
            <link>https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/</link>
            <guid>43382230</guid>
            <pubDate>Sun, 16 Mar 2025 20:55:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/">https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/</a>, See on <a href="https://news.ycombinator.com/item?id=43382230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="834" src="https://electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1600" alt="Tesla cameras vs radar wall" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla Autopilot drove into Wile E. Coyote-style fake road wall in the middle of the road in a camera versus lidar test.</p>



<p>While most companies developing self-driving technologies have been using a mix of sensors (cameras, radar, lidar, and ultrasonic), Tesla insists on only using cameras.</p>



<p>The automaker removed radars from its vehicle lineup and even deactivated radars already installed in existing vehicles.</p>



<p>The strategy has yet to pay off as Tesla’s systems are still stuck at level 2 driver assist systems.</p>	
	



<p>CEO Elon Musk claims that Tesla’s advantage is that once it solves autonomy, it will be able to scale faster than competitors because its vision plus neural net system is designed to work like a human driver and, therefore, will be able to adapt to any road.</p>



<p>Critics have pushed back against those claims, especially since Musk mentioned Tesla achieving “level 5 autonomy”, which means “in any conditions,” and cameras have limitations on that front that are fixed by lidar sensors.</p>



<p>A new video by engineering Youtuber Mark Rober has provided a very interesting demonstration of that very problem:</p>



<figure><p>
<iframe id="post-youtube-video-1" title="Can You Fool A Self Driving Car?" width="500" height="281" data-src="https://www.youtube.com/embed/IQJL3htsDyQ?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>In the video, Rober puts a Tesla Model Y on Autopilot against a vehicle using a lidar system in a series of tests in different conditions.</p>



<p>The Tesla on Autopilot managed to stop for a kid mannequin in the middle of the road when statics, moving, and blinded by lights, but it couldn’t stop in fog or heavy rain:</p>



<figure><img decoding="async" src="https://electrek.co/wp-content/uploads/sites/3/2025/03/Screenshot-2025-03-16-at-12.25.18%E2%80%AFPM.png?w=1024" alt=""></figure>



<p>It’s not surprising that the lidar, a laser-based system, is capable of detecting better in heavy fog than a camera system.</p>



<p>The heavy rain was a bit more surprising, but to be fair, the level of rain was quite spectacular.</p>



<p>The last scenario of a Wile E. Coyote-style wall with a fake road painted on it was obviously not realistic, but it serves to illustrate the issue with cameras versus radar or lidar sensors: they rely on the perception of potential obstacles rather than hard data about potential obstacles.</p>



<p>In simple words, the lidar sensors didn’t care what was painted on the wall, they only cared that it was a wall, while cameras can be tricked.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>I think it’s clear that no Tesla vehicle currently available will be capable of level 5 autonomy as Elon claimed.</p>




	<p>Level 4 is also questionable.</p>



<p>I think you can accomplish a lot with cameras, but I think it’s undeniable that adding radars and lidars can make systems safer.</p>



<p>In DMs with us during Tesla’s transition to vision only, Elon even admitted that “very high-resolution radars would be better than pure vision”, but he claimed that “such a radar does not exist”: </p>



<blockquote>
<p>“A very high-resolution radar would be better than pure vision, but such a radar does not exist.”</p>
</blockquote>



<p>When we pointed one out to him, he didn’t respond. Also, while they use light rather than radio waves, lidars are basically high-resolution radars, but the problem is that Musk has taken such a strong stance against them for so long that now that they have improved immensely and reduced in prices, he still can’t admit that he was wrong and use them.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Military grade sonic weapon is used against protesters in Serbia (461 pts)]]></title>
            <link>https://twitter.com/nexta_tv/status/1901244199220982213</link>
            <guid>43382093</guid>
            <pubDate>Sun, 16 Mar 2025 20:40:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/nexta_tv/status/1901244199220982213">https://twitter.com/nexta_tv/status/1901244199220982213</a>, See on <a href="https://news.ycombinator.com/item?id=43382093">Hacker News</a></p>
Couldn't get https://twitter.com/nexta_tv/status/1901244199220982213: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Zlib-rs is faster than C (213 pts)]]></title>
            <link>https://trifectatech.org/blog/zlib-rs-is-faster-than-c/</link>
            <guid>43381512</guid>
            <pubDate>Sun, 16 Mar 2025 19:35:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trifectatech.org/blog/zlib-rs-is-faster-than-c/">https://trifectatech.org/blog/zlib-rs-is-faster-than-c/</a>, See on <a href="https://news.ycombinator.com/item?id=43381512">Hacker News</a></p>
Couldn't get https://trifectatech.org/blog/zlib-rs-is-faster-than-c/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI Is Making Developers Dumb (156 pts)]]></title>
            <link>https://eli.cx/blog/ai-is-making-developers-dumb</link>
            <guid>43381215</guid>
            <pubDate>Sun, 16 Mar 2025 18:51:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eli.cx/blog/ai-is-making-developers-dumb">https://eli.cx/blog/ai-is-making-developers-dumb</a>, See on <a href="https://news.ycombinator.com/item?id=43381215">Hacker News</a></p>
Couldn't get https://eli.cx/blog/ai-is-making-developers-dumb: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tcl Tutorial (119 pts)]]></title>
            <link>https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html</link>
            <guid>43381195</guid>
            <pubDate>Sun, 16 Mar 2025 18:48:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html">https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html</a>, See on <a href="https://news.ycombinator.com/item?id=43381195">Hacker News</a></p>
Couldn't get https://www.tcl-lang.org/man/tcl8.5/tutorial/tcltutorial.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Our Interfaces Have Lost Their Senses (302 pts)]]></title>
            <link>https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses</link>
            <guid>43380930</guid>
            <pubDate>Sun, 16 Mar 2025 18:11:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses">https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses</a>, See on <a href="https://news.ycombinator.com/item?id=43380930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>





<article id="our-interfaces-have-lost-their-senses">



<a href="https://wattenberger.com/"><svg style="width: min(8vw, 8vh)" viewBox="0 0 245 213" fill="none" xmlns="http://www.w3.org/2000/svg"><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M122.692 0.712992L163.395 71.213L163.394 71.2143L204.097 141.713H122.7L122.692 141.713L122.69 141.713H41.2939L81.993 71.2201L81.9889 71.213L122.692 0.712992Z" fill="#102A3D22"></path></g><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M81.9889 212.213L122.692 141.713L122.691 141.712L163.394 71.213H81.9972L81.9889 71.2129L81.9873 71.213H0.590759L41.2898 141.706L41.2857 141.713L81.9889 212.213Z" fill="#102A3D22"></path></g><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M163.39 212.213L204.094 141.713L204.093 141.712L244.795 71.213H163.399L163.39 71.2129L163.389 71.213H81.9922L122.691 141.706L122.687 141.713L163.39 212.213Z" fill="#102A3D22"></path></g></svg></a>




<p>Think about how you experience the world—</p>
<p>you touch, you hear, you move.</p>

<div>
		
		<p>But our digital world has been getting flatter, more muted.</p>
		<p>Reduced to text under glass screens.</p>
		<p>This shift made interfaces simpler.<br>But was that really the goal?
			</p></div>


<p>An interface is the bridge between
	</p>



<div><p>It's how we tell computers what we want,
			</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/arrow-right.png" alt=""></p><p>and it's how computers communicate back to us.
		</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/arrow-left.png" alt=""></p><div><div><p>The shape should fit how we work,
				</p><p>for ergonomics and ease of use</p></div>
			<div><p>and it should fit how the computer works.
			</p><p>for simplicity and a good mental model</p></div></div>

	<p>Recently, we've been too focused on fitting to the computer's shape, and not enough to our own bodies.
	</p></div>

<h2>The Great Flattening</h2>
<p>Computers used to be physical beasts.</p>
<p>We programmed them by punching cards, plugging in wires, and flipping switches. Programmers walked among banks of switches and cables, physically choreographing their logic. Being on a computer used to be a full-body experience.
</p>


<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition1.png"></p>
	<p><span><span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span></span></p></div>

<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition2.png"></p>
	<p><span><span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span></span></p></div>


<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition3.png"></p>
	<p><span><span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span></span></p></div>

<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition4.png"></p>
	<p><span><span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span></span></p></div>



<h2>The Joy of Doing</h2>

<p>We've been successfully removing all friction from our apps — think about how effortless it is to scroll
	through a social feed. But is that what we want? Compare the feeling of doomscrolling to kneading
	dough, playing an instrument, sketching... these take effort, but they're also deeply
	satisfying. When you strip away too much friction, meaning and satisfaction go with it.
</p>

<p>Think about how you use physical tools. Drawing isn't just moving your hand—it's the
	feel of the pencil against paper, the tiny adjustments of pressure, the sound of graphite
	scratching. You shift your body to reach the other side of the canvas. You erase with your other
	hand. You step back to see the whole picture.
</p>

<p>We made painting feel like typing,</p>

<div>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/typing.png"></p>
	
	<div><p>but we should have made <em>typing</em> feel like <em>painting</em>.
			</p>
			<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/artist.png"></p></div></div>

<h2>Putting the you back in UI</h2>

<p>So how might our interfaces look if we shaped them to fit us?
</p>


<div><p>We think in <em>movement</em>,
		<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/movement.png"></p>
	<p>in <em>space</em>,
		<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/space.png"></p>
	
	<div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/sound.png"></p></div>
	<div><p>in <em>patterns</em>.
		</p><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/patterns.png"></p></div>
	</div>
<p>We use our hands to sculpt, our eyes to scan, our ears to catch patterns.
	</p>







<p>Our computers can communicate to us in many different formats, each with their own strengths:</p>

<div><div><div><p>Text</p>
			<p>Great for depth, detail, and precision.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/images.png"></p><p>But it doesn't always have to be in full paragraphs. How about showing key points first, then letting users expand?
		</p></div>
	<div><div><p>Visualizations</p>
			<p>Ideal for spatial relationships, trends, and quick insights.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/vision.png"></p><p>Can we show more content spatially? Or encode it in charts or colors?</p></div>
	<div><div><p>Sound</p>
			<p>Perfect for alerts and background awareness. Also, patterns.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/hearing.png"></p><p>Why are most web UIs silent? Can we use subtle chimes or sonification to highlight patterns?</p></div>
	<div><div><p>Haptics</p>
			<p>Provides passive feedback (vibrations, force).</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/touch.png"></p><p>Here's one I always forget about! We can vibrate phones to alert or convey patterns.
		</p></div></div>

<p>And what about the reverse! We can communicate to our computers in many different ways, each with their own strengths:
</p>

<div><div><div><p>Typing</p>
			<p>Precise, detailed, and familiar</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/typing2.png"></p><p>Good for composing long-form thoughts, keyboard shortcuts, and rough direction.
		</p></div>
	<div><div><p>Clicking &amp; Dragging</p>
			<p>Direct, fine-grained control.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/clicking.png"></p><p>Great for spatial tasks (design, organization) and pointing at things-on-a-screen.
		</p></div>
	<div><div><p>Tapping, Swiping, Pinching</p>
			<p>Intuitive for direct manipulation.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/tapping.png"></p><p>Great for mobile, but do we have to limit guestures to mimicking mouse interactions?
		</p></div>
	<div><div><p>Gesturing</p>
			<p>Hands-free, fluid, and expressive.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/guesturing.png"></p><p>Could be powerful for accessibility, quick actions, and complex fine control—reliable detection feels very possible at this time.
		</p></div>
	<div><div><p>Speaking</p>
			<p>Easy for loose thoughts.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/speaking.png"></p><p>LLMs have made speech more viable—can we let users think out loud or navigate roughly with their voice?
		</p></div></div>



<p>And the real magic happens when we combine different modalities. You can't read and listen and speak
	at the same time—try reading this excerpt while talking about your day:
</p>

<div><p>If it had not rained on a certain May morning Valancy Stirling’s whole life would have been
		entirely different. She would have gone, with the rest of her clan, to Aunt Wellington’s
		engagement picnic and Dr. Trent would have gone to Montreal. But it did rain and you shall hear
		what happened to her because of it.
	</p>
	</div>

<div><div><p>But you can talk while clicking,</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/click.png"></p></div>
<div><p>listen while reading,</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/listen.png"></p></div>
<div><p>look at an image while spinning a knob,</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/look.png"></p></div>
<div><p>guesture while talking.</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/guesture.png"></p></div>
</div>

<p>Let's build interfaces that let us multitask across senses.</p>

<h2>Rebuilding the bridge</h2>
<p>So, what might a richer interface look like? I have strong conviction that our future interfaces should:
</p>
<ul><li>let us collaborate on <strong>tangible artifacts</strong>, not just ephemeral chat logs.</li>
	<li>support <strong>multiple concurrent modalities</strong>—voice, gestures,
		visuals, spatial components.
	</li>
	<li>respond to <strong>ambient signals</strong>—detecting context, organizing information, helping
		us think better.
	</li></ul>

<p>Last year, I did a rough exploration of what this could look like for a thought organizing tool. One that listened as you talked or typed, and organized your rambling thoughts into cards.
</p>



<p>This interface is very rough, but felt like a different way of working with technology. Especially how it let me bumble through rough ideas one second, then responded to commands like "re-group my cards" or "add 3 cards about this" the next.
</p>

<p>I would love to see more explorations like this!
</p>

<h2>Our interfaces have lost their senses</h2>
<p>All day, we poke, swipe, and scroll through flat, silent
	screens. But we're more than just eyes and a pointer finger. We think with our hands, our ears,
	our bodies.
</p>

<p>The future of computing is being designed right now. Can we build something richer—something that
	moves with us, speaks our language, and molds to our bodies?
</p>

<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/footer.png">
</article>


			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teach, Don't Tell (2013) (118 pts)]]></title>
            <link>https://stevelosh.com/blog/2013/09/teach-dont-tell/</link>
            <guid>43380833</guid>
            <pubDate>Sun, 16 Mar 2025 17:55:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stevelosh.com/blog/2013/09/teach-dont-tell/">https://stevelosh.com/blog/2013/09/teach-dont-tell/</a>, See on <a href="https://news.ycombinator.com/item?id=43380833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on September 3rd, 2013.</p><p>This post is about writing technical documentation.  More specifically: it's
about writing documentation for programming languages and libraries.</p>

<p>I love reading great documentation.  When I have a question and the
documentations explains the answer almost as if the author has magically
anticipated my problem, I get a warm, fuzzy feeling inside.  I feel a connection
with the writer that makes me smile.</p>

<p>I also love writing documentation.  Being able to rewire the neurons in
someone's brain so that they understand something they didn't understand before
is extremely satisfying.  Seeing (or hearing about) the "click" when a bunch of
concepts suddenly fall together and make sense never fails to make my day.</p>

<p>This post is going to be about what I think good documentation is and how
I think you should go about writing it.  I'm not perfect, so you should take
everything with a grain of salt, but I hope you'll find it useful and
thought-provoking even if you don't agree with me about everything.</p>

<p>I'd like to say thanks to <a href="http://craigzheng.com/">Craig Zheng</a> and <a href="http://honza.ca/">Honza Pokorny</a> for
proofreading this.</p>

<ol><li><a href="#s1-prior-reading">Prior Reading</a></li><li><a href="#s2-why-do-we-document">Why Do We Document?</a></li><li><a href="#s3-teaching">Teaching</a></li><li><a href="#s4-a-play-in-seven-acts">A Play in Seven Acts</a></li><li><a href="#s5-act-1-read-the-source">Act 1: "Read the Source"</a></li><li><a href="#s6-tools-of-the-trade">Tools of the Trade</a></li><li><a href="#s7-act-2-read-the-tests">Act 2: "Read the Tests"</a></li><li><a href="#s8-how-to-teach">How to Teach</a></li><li><a href="#s9-act-3-literate-programming">Act 3: "Literate Programming"</a></li><li><a href="#s10-the-anatomy-of-good-documentation">The Anatomy of Good Documentation</a></li><li><a href="#s11-first-contact">First Contact</a></li><li><a href="#s12-act-4-read-the-docstrings">Act 4: "Read the Docstrings"</a></li><li><a href="#s13-the-black-triangle">The Black Triangle</a></li><li><a href="#s14-act-5-read-the-api-docs">Act 5: "Read the API Docs"</a></li><li><a href="#s15-the-hairball">The Hairball</a></li><li><a href="#s16-act-6-read-the-wiki">Act 6: "Read the Wiki"</a></li><li><a href="#s17-the-reference">The Reference</a></li><li><a href="#s18-act-7-a-new-hope">Act 7: "A New Hope"</a></li></ol>

<h2 id="s1-prior-reading"><a href="#s1-prior-reading">Prior Reading</a></h2>

<p>Before you read this post there are two other things I think you should read
first.</p>

<p>The first is Jacob Kaplan-Moss' <a href="http://jacobian.org/writing/great-documentation/">Writing Great Documentation</a> series.  He's
certainly more qualified than I am to write about this stuff, so you should
check that out if you haven't already.  A lot of what I say here is going to
agree with and build on the ideas he talked about.</p>

<p>The other thing you should read is <a href="http://www.americanscientist.org/issues/id.877,y.0,no.,content.true,page.1,css.print/issue.aspx">The Science of Scientific Writing</a> by
George Gopen and Judith Swan.  Don't be put off by the fact that it's written
for scientists publishing papers in journals.  Everything in that article
applies equally well to programmers writing technical docs.  Read the entire
thing.  It's worth it.</p>

<h2 id="s2-why-do-we-document"><a href="#s2-why-do-we-document">Why Do We Document?</a></h2>

<p>Let's get started.  The first thing to nail down is <em>why</em> we're documenting
a programming language or library in the first place.  There are many things you
might want to accomplish, but I'm going to boil them down into a single
statement:</p>

<p><strong>The purpose of technical documentation is to take someone who has never seen
your project, teach them to be an expert user of it, and support them once they
become an expert.</strong></p>

<p>At first glance this probably doesn't seem too controversial or interesting.
But there's one word in there that makes <em>all</em> the difference, and it frames my
entire perspective on documentation.</p>

<h2 id="s3-teaching"><a href="#s3-teaching">Teaching</a></h2>

<p>If you want to take a person who has never played the guitar and turn them into
a virtuoso guitarist, how can you do that?</p>

<p>You <em>teach</em> them.</p>

<p>If you want to take a high school student and turn them into a computer
scientist, how can you do that?</p>

<p>You <em>teach</em> them.</p>

<p>If you want to take a programmer who has never seen your library before and turn
them into an expert user of it, how can you do that?</p>

<p>You <em>teach</em> them!</p>

<p>Guitar lessons are usually taught in person, one-on-one, with a teacher.
Computer Science is usually taught by professors in classrooms.  Programming
library usage is usually taught by documentation.</p>

<p>If the goal of documentation is to turn novices into experts, then <em>the
documentation must teach</em>.  You should think of your documentation as a lesson
(or series of lessons) because <em>that's what it is</em>.</p>

<p>When writing technical documentation you (usually) don't have the advantage of
having a one-on-one dialog with the learners.  This makes it a bit more
difficult, but not impossible as long as you're careful.  Your documentation
needs to fill the role of both the in-person lessons <em>and</em> the textbook.</p>

<p>The rest of this post will be almost entirely about how to apply the
"documentation is teaching" mindset to writing programming docs.</p>

<h2 id="s4-a-play-in-seven-acts"><a href="#s4-a-play-in-seven-acts">A Play in Seven Acts</a></h2>

<p>I'm going to break up the content of this post with some venting about <em>bad</em>
documentation.  If you want to skip these little rants, go ahead.</p>

<p>Each act in our play has two characters: a teenager and a parent.  The teenager
has just turned sixteen and would like to learn to drive so they can hang out
with their friends without relying on their parents to drive them everywhere.</p>

<p>Each act will demonstrate a caricature of a particularly <em>bad</em> form of
documentation.  I hope these little metaphors will help show why certain forms
of documentation are ineffective cop-outs and why you should write <em>real</em>
documentation instead.</p>

<h2 id="s5-act-1-read-the-source"><a href="#s5-act-1-read-the-source">Act 1: "Read the Source"</a></h2>

<p>Our play starts with a son and father sitting at the breakfast table.  The son
is munching on some cereal before school while the father reads his iPad before
leaving for work.</p>

<p>The son says: "Hey Dad, you said you were going to teach me how to drive after
school today.  Are we still going to do that?"</p>

<p>The father, without looking up from his iPad, replies: "Of course, son.  The car
is in the garage and I laid out a set of wrenches on the workbench.  Take the
car apart and look at each piece, then put it back together.  Once you've done
that I'll take you to the DMV for your driving test."</p>

<p>The son quietly continued eating his cereal.</p>

<p>If you use many open source libraries you've undoubtedly encountered some whose
README says something like "read the source".  Every time I see one, I die
a little bit inside.</p>

<p>Source code is <em>not</em> documentation.  Can you learn to be a guitarist by simply
listening to a piece of music intently?  Can you become a painter by visiting
a lot of museums?  Of course not!</p>

<p>Let me be clear: I'm not trying to say that reading source code isn't a valuable
thing to do.  It is!</p>

<p>Looking at other artists' paintings is extremely useful <em>once you know how to
paint</em>.  Learning how the brakes of a car are constructed can save your life,
<em>once you know how to drive</em>.</p>

<p>Once your library's users know how to work with it, reading its source is
absolutely worth their time.  But you can't look at the finished product and
understand the perspective and ideas that went into it without additional
guidance.  That's a job for documentation.</p>



<p>Writing good documentation doesn't take much in the way of tools.</p>

<p>For example: you don't need a thesaurus.  Don't try to avoid using the same
words by substituting synonyms.  Just talk to your users like you would talk to
another human being in real life!</p>

<p>If you use the same word ten times in a row your readers probably won't even
notice.  But I guarantee they're going to notice if you throw in strange,
uncommon words for no good reason.</p>

<p>There are two tools I <em>will</em> recommend before moving on.  The first isn't
actually a tool, but a skill.</p>

<p>To write great documentation, you need to be able to type.</p>

<p>When you write docs you'll inevitably write yourself into a corner and realize
you need to take a new direction.  If you don't type quickly, you might be
hesitant to throw away writing that doesn't really work.  You need to learn to
type well so you don't feel bad throwing away a chunk of a thousand words that
don't fit.</p>

<p>Steve Yegge's article <a href="http://steve-yegge.blogspot.com/2008/09/programmings-dirtiest-little-secret.html">Programming's Dirty Little Secret</a> is
a great rant on this topic.</p>

<p>You should also get yourself a nice keyboard.  A good keyboard won't make you
a good writer (just like a good guitar won't make you a good guitarist), but it
<em>will</em> make you want to write more just for the sheer joy of using
a well-designed piece of equipment.</p>

<p>I started practicing guitar a lot more after I got a new guitar that was much
nicer than my old one.  If you spend a hundred dollars, get a nice keyboard, and
end up wanting to write more, it was worth it!</p>

<p>Be thankful that a nice keyboard only costs $100 to $300 and not several
thousand dollars like a nice instrument.</p>

<h2 id="s7-act-2-read-the-tests"><a href="#s7-act-2-read-the-tests">Act 2: "Read the Tests"</a></h2>

<p>The next scene opens with a mother picking her daughter up from high school.</p>

<p>"Hi Mom", she says, "are you still going to teach me to drive today?"</p>

<p>"Yep!" she replies.  "Let's get going."</p>

<p>After ten minutes of driving they arrive at the Chevrolet factory.</p>

<p>The girl looks around, puzzled.  She asks: "What are we doing here?"</p>

<p>The mother smiles and says: "You're in luck, honey, my friend Jim works here at
the Chevy plant, and he's gonna let you watch a few crash tests of the new
Malibu!  Once you see a few cars smash into each other, I'll take you down to
the DMV for your driving test."</p>

<p>Another common form of "documentation" is the README instructing users to "read
the tests".</p>

<p>Tests aren't docs.</p>

<p>Again, let's be clear: once you already know how to use a library, reading the
tests is <em>very</em> useful.  But you need documentation to make you an expert user
first!</p>

<p>You don't learn to drive by watching crash tests.  But learning how your car
behaves during a crash can save your life <em>once you know how to drive</em>.</p>

<p>A common argument I see goes something like this:</p>

<p>"The tests use the library, so they're a good example of how to use it!"</p>

<p>This is true in some very superficial sense, but completely misses the mark.</p>

<p>Most of the tests are probably going to deal with edge cases.  Edge cases are
things a normal user won't be encountering very often (otherwise they wouldn't
be edge cases!).</p>

<p>If you're lucky, you might get a test that verifies the library works correctly
on a normal set of input.  But a "normal set of input" is what the users are
going to be working with the majority the time!</p>

<p>Tests simply aren't a good guide to what a user is going to be encountering on
a day-to-day basis.  They can't teach a novice to be an expert.</p>

<h2 id="s8-how-to-teach"><a href="#s8-how-to-teach">How to Teach</a></h2>

<p>If you accept my idea that the purpose of documentation is to <em>teach</em> users, the
next question is obviously: "How do I teach my users?"</p>

<p>I've been lucky enough to have the chance to teach dancing semi-formally for
around 6 or 7 years, and lots of various other things informally for a long
time.  The only way to <em>really</em> learn how to teach is to <em>do it</em>.</p>

<p>There's no substitute for sitting down with someone face-to-face and teaching
them something.  <strong>If you want to write better documentation, you need to
practice teaching</strong>.</p>

<p>I'm not talking about writing out lesson plans or anything nearly so formal.  Do
you have a hobby (not programming)?  If so, spend a couple of hours on a weekend
teaching a friend about it.  You'll get some practice teaching and they'll get
to learn something new.</p>

<p>(If you don't have any non-programming hobbies, maybe you should find some.)</p>

<p>If you like photography, teach someone the basics of exposure and composition.
If you dance, teach them some basic steps.  If you play an instrument, teach
them how to play a simple song.  If you like camping, teach them what all the
gear is for.  You get the idea.</p>

<p>Don't go overboard.  You don't need to give someone a degree, you just need to
practice teaching a little bit.  You need to practice the art of rewiring
someone's neurons with your words.</p>

<p>Once you jump into teaching something (even something simple) you'll probably
realize that although you know how to do it yourself, it's a lot harder to teach
someone else.</p>

<p>This is obvious when you're working face-to-face with someone.  When you tell
them how to play a C major chord on the guitar and they only produce a strangled
squeak, it's clear that you need to slow down and talk about how to press down
on the strings properly.</p>

<p>As programmers, we almost <em>never</em> get this kind of feedback about our
documentation.  We don't see that the person on the other end of the wire is
hopelessly confused and blundering around because they're missing something we
thought was obvious (but wasn't).  Teaching someone in person helps you learn to
anticipate this, which will pay off (for your users) when you're writing
documentation.</p>

<p>With all that said, I do want to also talk a little about the actual process of
teaching.</p>

<p>The best description of how to teach that I've seen so far is from the book <a href="http://www.amazon.com/dp/069111966X/?tag=stelos-20">How
to Solve It</a>.  Everyone who wants to teach should read this book.  The passage
that really jumped out at me is right in the first page of the first chapter:</p>

<blockquote>
<p>The best [way for the teacher to help their student] is to help the student
naturally.  The teacher should put himself in the student's place, he should
see the student's case, he should try to understand what is going on in the
student's mind, and ask a question or indicate a step that <em>could have
occurred to the student himself</em>.</p>
</blockquote>

<p>This, right here, is the core of teaching.  This is it.  This is how you do it.</p>

<p>People don't learn by simply absorbing lots of unstructured information as it's
thrown at them.  You can't read a Spanish dictionary to someone to teach them
Spanish.</p>

<p>When you want to teach someone you need to put yourself in their shoes and walk
along the path with them.  Hold their hand, guide them around the dangerous
obstacles and catch them when they fall.  <em>Don't</em> carry them.  <em>Certainly
don't</em> just drive them to the destination in your car!</p>

<p>The process needs to go something like this:</p>

<ol>
<li>Figure out what they already know.</li>
<li>Figure out what you want them to know after you finish.</li>
<li>Figure out a single idea or concept that will move state 1 a little bit
   closer to state 2.</li>
<li>Nudge the student in the direction of that idea.</li>
<li>Repeat until state 1 becomes state 2.</li>
</ol>

<p>Too often I see documentation that has very carefully considered step 2, and
then simply presents it to the reader as a pronouncement from God.  That isn't
teaching.  That's telling.  People don't learn by being <em>told</em>, they
learn by being <em>taught</em>.</p>

<h2 id="s9-act-3-literate-programming"><a href="#s9-act-3-literate-programming">Act 3: "Literate Programming"</a></h2>

<p>The third act opens with a daughter talking to her mother the day before her
sixteenth birthday.</p>

<p>"Hey Mom," she says, "I don't know if you got me a present yet, but if not, what
I'd <em>really</em> like for my birthday are driving lessons."</p>

<p>The mother smiles and says: "Don't worry, it's all taken care of.  Just wait for
tomorrow."</p>

<p>The next day at her birthday party she unwraps the present from her mom.  Inside
is a DVD of the show How It's Made.  She looks quizzically at her mother.</p>

<p>"That DVD has an episode about the factory that builds your car!  Once you watch
the whole thing I'll take you for your driving test."</p>

<p>A horrible trend I've noticed lately is using "literate programming" tools like
Docco, Rocco, etc and telling users to read the results for documentation.</p>

<p>Programming languages and libraries are tools.  Knowing how a tool was made
doesn't mean you know how to use it.  When you take guitar lessons, you don't
visit a luthier to watch her shape a Telecaster out of Ash wood.</p>

<p>Knowing how your car was built can help you, <em>once you know how to drive</em>.</p>

<p>Knowing how your guitar was built can help you, <em>once you know how to play</em>.</p>

<p>A common theme throughout these acts/rants is that all of these things I'm
picking on (source, tests, literate programming, and more) are good things with
real benefits <em>once you have actual documentation in place to teach users</em>. </p>

<p>But until that happens, they're actually <em>bad</em> because they let you pretend
you've written documentation and your job is done (JKM mentions this in his
series).  Your job is not done until you've taught your users enough to become
experts.  <em>Then</em> they can take advantage of all these extras.</p>

<h2 id="s10-the-anatomy-of-good-documentation"><a href="#s10-the-anatomy-of-good-documentation">The Anatomy of Good Documentation</a></h2>

<p>The rest of this post is going to be about the individual components that make
up good documentation.  My views are pretty similar to JKM's, so if you haven't
read the series I mentioned in the first section you should probably do that.</p>

<p>In my mind I divide good documentation into roughly four parts:</p>

<ol>
<li>First Contact</li>
<li>The Black Triangle</li>
<li>The Hairball</li>
<li>The Reference</li>
</ol>

<p>There don't necessarily have to be four separate documents for each of these.
In fact the first two can usually be combined into a single file, while the last
two should probably be split into many pieces.  But I think each component is
a distinct, important part of good documentation.</p>

<p>Let's take a look at each.</p>



<p>When you release a new programming language or library into the wild, the
initial state of your "users" is going to be blank.  The things they need
to know when they encounter your library are:</p>

<ol>
<li>What is this thing?</li>
<li>Why would I care about this thing?</li>
<li>Is it worth the effort to learn this thing?</li>
</ol>

<p>Your "first contact" documentation should explain these things to them.</p>

<p>You don't need to explain things from first principles.  Try to put yourself in
the shoes of your users.  When you're teaching your teenager to drive, you don't
need to explain what a "wheel" is.  They probably have some experience with
"things on wheels that you move around in" like lawn mowers or golf carts (or
even video games).</p>

<p>Likewise: if you're creating a web framework, most of the people that stumble on
to your project are probably going to know what "HTML" is.  It's good to err
a little bit on the side of caution and explain a little more than to assume too
much, but you can be practical here.</p>

<p>Your "first contact" docs should explain what, in plain words, your thing does.
It should show someone why they should care about that.  Will it save them time?
Will it take more time, but be more stable in exchange?  Is it just plain fun?</p>

<p>For bonus points, you can also mention why someone might want to <em>not</em> use your
project.  Barely anyone ever mentions the tradeoffs involved with using their
work, so to see a project do this is refreshing.</p>

<p>Finally, the user needs to know if it's worth spending some of their finite
amount of time on this planet learning more about your project.  You should
explicitly spell out things like:</p>

<ul>
<li>What license the project uses (so they know if it's practical to use).</li>
<li>Where the bug tracker is (so they can see issues).</li>
<li>Where the source code is (so they can see if it's (relatively) recently
  maintained).</li>
<li>Where the documentation is (so they can skim it and get an idea of the effort
  that's going to be involved in becoming an expert).</li>
</ul>

<h2 id="s12-act-4-read-the-docstrings"><a href="#s12-act-4-read-the-docstrings">Act 4: "Read the Docstrings"</a></h2>

<p>Scene four.  A father is finally making good on his promise to give his daughter
driving lessons.</p>

<p>"Okay Dad," she says, "I'm ready.  I've never driven a car before.  Where do we
start?"</p>

<p>A woman in her mid-forties walks through the door.  "Who's this?" the daughter
asks.</p>

<p>"This is your driving teacher, Ms. Smith." the father replies.  "She's going to
sit in the passenger seat with you while you drive the two hour trip to visit
grandpa.  If you have any questions about a part of the car while you're
driving, you can ask her and she'll tell you all about that piece.  Here are
the keys, good luck!"</p>

<p>In languages with <a href="https://en.wikipedia.org/wiki/Docstring">docstrings</a> there's a tendency to write great docstrings
and call them documentation.  I'm sure the "doc" in the word "docstrings"
contributes to this.</p>

<p>Docstrings don't provide any organization or order (beyond "the namespace they
happen to be implemented in").  Users need to somehow know the name of the
function they need to even be able to <em>see</em> the docstring, and they can't know
that unless you <em>teach</em> them.</p>

<p>Again, docstrings are great <em>once you know the project</em>.  But when you're
teaching a novice how to use your library, you need to guide them along they
way and not sit back and answer questions when they manage to guess a magic
word correctly.</p>

<h2 id="s13-the-black-triangle"><a href="#s13-the-black-triangle">The Black Triangle</a></h2>

<p>The next important piece of documentation is <a href="http://rampantgames.com/blog/2004/10/black-triangle.html">the "black triangle"</a>.  It
should be a relatively short guide to getting your project up and running so the
user can poke at it.</p>

<p>This serves a couple of purposes.  First, it lets the user verify that yes, this
collection of bytes is actually going to run and <em>do something</em> on their
machine.  It's a quick sanity check that the project hasn't bit rotted and is
still viable to use at that point in time.  More importantly, it lets your
prospective user <a href="http://worrydream.com/LearnableProgramming/#react">get some paint on the canvas</a>.</p>

<p>Imagine if you went to your first guitar lesson and the teacher said: "Okay,
we're going to start by learning 150 different chords.  Then in about six months
we can play some songs."  No guitar teacher does that.  They teach you three
chords and give you a couple of cheesy pop songs to play.  It helps the student
get a feel for what being a guitarist as a whole is going to be like, and it
gives them something to help keep their interest.</p>

<p>Your "black triangle" documentation should be a short guide that runs the user
through the process of retrieving, installing, and poking your project or
language.</p>

<p>"Short" here is a relative word.  Some projects are going to require more setup
to get running.  If the benefits are enough to justify the effort, that's not
necessarily a problem.  But try to keep this as short as possible.  <em>Just get
something on the screen</em> and move on.</p>

<h2 id="s14-act-5-read-the-api-docs"><a href="#s14-act-5-read-the-api-docs">Act 5: "Read the API Docs"</a></h2>

<p>Our next scene opens a year after the last, with the father from the last scene
talking to his son.</p>

<p>(Sadly, the daughter in that scene died in a car crash because she didn't know
to ask Ms. Smith about seatbelts before getting on the expressway.  Ms.  Smith
was wearing hers, of course.)</p>

<p>"Okay son, I know you're a little scared of driving because of what happened to
your sister, but I've fixed the problem."</p>

<p>He hands the young man an inch-thick book.  "Asking Ms. Smith questions along
the way clearly didn't work, so we had her write out a paragraph or two about
each piece of your car.  Go ahead and read the entire manual cover to cover and
then drive down to see grandpa."</p>

<p>API documentation is like the user's manual of a car.  When something goes wrong
and you need to replace a tire it's a godsend.  But if you're learning to drive
it's not going to help you because <em>people don't learn by reading alphabetized
lists of disconnected information</em>.</p>

<p>If you actually try to teach someone to use your project face-to-face, you'll
probably find yourself talking about things in one namespace for a while, then
switching to another to cover something related, then switching back to the
first.  Learning isn't a straight path through the alphabet, it's a zig-zaggy
ramble through someone else's brain.</p>

<h2 id="s15-the-hairball"><a href="#s15-the-hairball">The Hairball</a></h2>

<p>This brings me to the next type of documentation: "the hairball".  By now the
user has hopefully seen the "first contact" docs and the "black triangle" docs.
You've got them hooked and ready to learn, but they're still novices.</p>

<p>The "hairball" is the twisted, tangled maze of teaching that is going to take
these novices and turn them into expert users.  It's going to mold their brains,
one nudge at a time, until they have a pretty good understanding of how your
project works.</p>

<p>You'll usually want to organize the "hairball" into sections (unless this is
a very small project).  These sections will probably <em>kind of</em> line up with
namespaces in your project's public API, but when it makes sense to deviate you
should do so.</p>

<p>Don't be afraid to write.  Be concise but err on the side of explaining a bit
too much.  Programmers are pretty good at skimming over things they already
know, but if you forget to include a crucial connection it can leave your users
lost and stumbling around in the woods.</p>

<p>You should have a table of contents that lists each section of the "hairball".
And then each section should have its own table of contents that lists the
sections inside it.  A table of contents is a wonderful way to get a birds-eye
view of what you're about to read, to prepare your brain for it.  And of
course it's also handy for navigating around.</p>

<p>This is where your hobby-teaching practice and your reading of How to Solve It
are going to come in handy.  Put yourself in a user's brain and figure out each
little connective leap they're going to need to make to become an expert.</p>

<h2 id="s16-act-6-read-the-wiki"><a href="#s16-act-6-read-the-wiki">Act 6: "Read the Wiki"</a></h2>

<p>In the penultimate scene, a mother has signed her teenage son up for an
after-school driving class.</p>

<p>On the first day, the teacher hands them a syllabus detailing what they're going
to cover, talks about grading, and sends them home a bit early.</p>

<p>On the second day, she gives them a brief overview of the various pieces of
a car and how they work together.  She also talks about a few of the most
important laws they'll need to be aware of.</p>

<p>On the third day, the teacher calls in sick and they have a substitute.  He
covers the material for half of the fifth day in the syllabus.  He has to leave
early, so he brings in his nineteen year old daughter to finish the class.
She covers the first half of the fourth day's material.</p>

<p>The fourth day the students arrive to find a note on the door saying the class
has been cancelled because the teacher is still sick and they can't find
a substitute.  There's a note saying "TODO: we'll talk about the material
later."</p>

<p>The fifth day the teacher has partially recovered, so she returns and covers the
material for the fifth day.  It's a bit hard to understand her because she's had
half a bottle of Nyquil and is slurring most of her words and keeps saying
"cat" instead of "car".</p>

<p>All the students fail the driving test.</p>

<p>Wikis are an abomination.  They are the worst form of "documentation".</p>

<p>First of all: assuming they work as intended, they have no coherent voice.</p>

<p>Have you ever taken a class with multiple teachers at once?  Probably not,
because it doesn't work very well (with exceptions for things like partnered
dancing where there are distinct lead/follow parts).</p>

<p>Worse still: have you ever taken a class where there's one jackass in the room
who keeps constantly raising his hand and offering his own (often incorrect)
opinions?  Wikis are like that, except they <em>actively encourage</em> random people
to interrupt the teacher with their own interjections.</p>

<p>I can hear the objections now: "But putting our docs on a wiki means <em>anyone</em>
can fix typos!"</p>

<p>Jesus.  Christ.</p>

<p>"It makes it easy to fix typos" is a horrible argument for using a wiki.</p>

<p>First of all, as JKM says, you should have an editor (or at least someone to
proofread) which will catch a lot of the typos.</p>

<p>And even if there <em>are</em> typos, they're one of the least important things you
need to worry about anyway.  Misspelling "their" isn't going to impact the
effectiveness of your teaching very much.  Your lessons being a disorganized
mess because they were written by three different people across six months <em>is</em>
going to make them less effective.</p>

<p>Keeping your documentation in a wiki also makes it hard or impossible to keep it
where it belongs: in version control right alongside your code.</p>

<p>But all that is irrelevant because aside from Wikipedia itself and video game
wikis, <em>they don't fucking work</em>.</p>

<p>The project maintainer sets up a wiki, sits back and pats herself on the back
saying: "I have set up a way for other people to do this boring job of writing
documentation for me.  Now we wait." </p>

<p>Maybe one or two people fix some typos.  A dude who thinks he understands
a topic but actually doesn't writes some completely wrong docs.  Maybe they get
reverted, maybe they don't.</p>

<p>The project changes.  A new user reads some of the (sparse) documentation which
is now out of date.  Eventually they discover this and complain only to be met
with: "Well it's a wiki, fix it yourself!"</p>

<p>It is not the responsibility of the student to fix a broken lesson plan.  For
fuck's sake, <em>the entire point of having a teacher</em> is that they know what the
students need to learn and the students don't!</p>

<p>It's completely okay to ask your students for criticism so you can improve your
lesson plan.  Asking "what parts did you find difficult?" is fine.  It's another
thing entirely to ask them to <em>write your lesson plan for you</em>.</p>

<p>Seriously: fuck wikis.  They are bad and terrible.  Do not use them.  Take the
time and effort to write some real documentation instead.</p>

<h2 id="s17-the-reference"><a href="#s17-the-reference">The Reference</a></h2>

<p>The final type of documentation is "the reference".  This section is for the
users who have traveled through the "hairball" and made it to the other side.
They're now your experts, and the reference should support them as they use your
project in their daily work.</p>

<p>This section should contain things that experienced users are likely to need,
such as:</p>

<ul>
<li>"API documentation" for every user-facing part of your project.</li>
<li>A full changelog, with particular attention to backwards-incompatible changes
  between versions.</li>
<li>Details about the internal implementation of the project.</li>
<li>Contribution policies (if your project accepts outside contributions).</li>
</ul>

<p>Tools like JavaDoc can produce something that looks like the first, but I share
the same opinion as Jacob Kaplan-Moss:</p>

<blockquote>
<p>Auto-generated documentation is almost worthless. At best it's a slightly
improved version of simply browsing through the source, but most of the time
it's easier just to read the source than to navigate the bullshit that these
autodoc tools produce. About the only thing auto-generated documentation is
good for is filling printed pages when contracts dictate delivery of a certain
number of pages of documentation. I feel a particularly deep form of rage
every time I click on a "documentation" link and see auto-generated
documentation.</p>

<p>There's no substitute for documentation written, organized, and edited by
hand.</p>
</blockquote>

<p>Yes, you can probably find a tool to read your project's source and shit out
some HTML files with the function names in them.  Maybe it will even include the
docstrings!</p>

<p>I would still urge you to write your API docs by hand.  It's going to be
a little more typing, but the results will be much better for a number of
reasons.</p>

<p>API docs and docstrings, while similar, serve different purposes.  Docstrings
have to provide what you need in the heat of coding in a REPL-friendly format.
API docs can afford the luxury of a bit more explanation, as well as links to
other things the user might want to know while browsing them on their couch.
API docs should also be Google-friendly.</p>

<p>A common objection here is that you're going to be retyping a lot of words.
Copy and paste mostly solves that problem, and learning to type makes the rest
a non-issue.</p>

<p>Some will say: "But copy and pasting is evil!  You're duplicating effort!  How
will you keep the changes in the docstrings and the API docs in sync if they
change?"</p>

<p>My opinion here is that if your public-facing API is changing often, you're
probably going to be making your users' lives harder when they need to
constantly update their code to work with yours.  So the least you can do is
make <em>your</em> life a little harder to provide them with the best documentation
possible to help ease the pain.</p>

<p>Auto-generated documentation has no coherent voice.  It pulls in everything in
the code without regard for overall structure and vision.  You can <em>probably</em>
get away with it for the API docs in your "reference" documentation, or you
could take some pride in your work and write the best docs possible!</p>

<h2 id="s18-act-7-a-new-hope"><a href="#s18-act-7-a-new-hope">Act 7: "A New Hope"</a></h2>

<p>The final act of our play is set in a mall parking lot on a Sunday afternoon.
A single car is in the parking lot.  Inside is a family: a mother and father who
are teaching their son to drive.</p>

<p>They start by driving the car into the middle of the lot, away from any
obstacles.  The son gets into the driver's seat, and the parents explain briefly
what the main controls do.  They let him drive around the empty lot a bit to get
a feel for how the car works.</p>

<p>When it's time for him to park he shifts to park and takes off his seatbelt.
His mom reminds him of the control called a "parking brake".  He realizes that
he should use this when parking.  A set of neurons is now linked in his brain
and he will remember to use the parking brake properly for the rest of his life.</p>

<p>Over time the parents take their son driving many times, always being sure that
they're putting him into situations he can handle (but will still learn from).
He drives on a road, then learns to parallel park, then drives on a highway.</p>

<p>He has questions along the way.  Sometimes the parents are ready with an answer.
Sometimes the questions reveal something else missing deeper down in his
knowledge which the parents correct.</p>

<p>Over time he learns more and more.  He gets his license and begins driving on
his own.</p>

<p>When he gets a flat tire he reads the owner's manual and fixes it.</p>

<p>He watches the How It's Made episode about his car because he's curious how the
brakes which saved his life at a stop sign last week actually work.</p>

<p>His windshield wipers stop working one day.  He opens up the hood and figures
out the problem, fixing it himself.</p>

<p>One day he is hit by a drunk driver.  He walks away with only bruises.  He never
saw the countless crash tests the engineers performed to create the airbag
system, but they saved his life.</p>

<p>In the last scene we see the son many years later.  His hair is a bit gray now,
but otherwise he looks a lot like the teenager who forgot to use the parking
brake.</p>

<p>He's in a car with his teenage daughter, and he's teaching her how to drive.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amiga 600: From the Amiga No One Wanted to Retro Favorite (110 pts)]]></title>
            <link>https://dfarq.homeip.net/amiga-600-the-amiga-no-one-wanted/</link>
            <guid>43380649</guid>
            <pubDate>Sun, 16 Mar 2025 17:28:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dfarq.homeip.net/amiga-600-the-amiga-no-one-wanted/">https://dfarq.homeip.net/amiga-600-the-amiga-no-one-wanted/</a>, See on <a href="https://news.ycombinator.com/item?id=43380649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Amiga 600 was one of the last Amigas, and it became a symbol of everything wrong with Commodore and the product line. Retro enthusiasts like it today because of its small size, so it’s the perfect retro Amiga for today. But it couldn’t have been much more wrong for the time it was introduced, March 11-18, 1992 at the CeBit show.</p><p><strong>The Amiga 600 was a cost-reduced Amiga for home use, similar in size and appearance to a Commodore 64. But internally it wasn’t much more than a repackaged <a href="https://dfarq.homeip.net/amiga-1000-ten-years-ahead-of-its-time/">Amiga 1000 from 1985</a>, trying to compete with VGA graphics and 386 CPUs.</strong></p><h2>Commodore didn’t understand its own success</h2><figure id="attachment_23905" aria-describedby="caption-attachment-23905"><a href="https://dfarq.homeip.net/amiga-600-the-amiga-no-one-wanted/amiga-600/" rel="attachment wp-att-23905"><img data-recalc-dims="1" fetchpriority="high" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2020/07/Amiga-600.jpg?resize=300%2C205&amp;ssl=1" alt="Amiga 600" width="300" height="205" srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2020/07/Amiga-600.jpg?resize=300%2C205&amp;ssl=1 300w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2020/07/Amiga-600.jpg?w=749&amp;ssl=1 749w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-23905">The Amiga 600 was repackaged 1985 technology at a non-competitive price. Since it came on the market in 1992, it’s no surprise it flopped.</figcaption></figure><p>The Amiga 600 shows how Commodore didn’t understand its previous successes and failures. When Commodore was at its best, the process looked something like this. It decided on a price point to hit. Then its engineers built the computer they would want while staying within that budget. Most of Commodore’s engineers were computer enthusiasts themselves, so it was like a car company selling cars designed by car enthusiasts.</p><p>The machines built momentum fairly quickly. Other enthusiasts took to the machines, built peripherals and software to go with it, and created an ecosystem that sold the computer. Commodore’s marketing rarely said much more than their computer was better and cheaper than the others. For a while, that was all it took.</p><h3>What was wrong with the Amiga 600</h3><p>The Amiga 600 was the opposite of all that. It was 1985 technology repackaged to look as much like 1982 technology as possible, priced at $500 and released in 1992. But that didn’t include a monitor and hard drive. You wanted those. By the time you added a monitor and a hard drive to get the system you really wanted, it cost closer to $1,000. At that price, you could get an off-brand PC with a VGA monitor. It wouldn’t be great. But it also didn’t feel like someone ripping you off with expensive add-ons. Or you could pay $200 more and get a pretty nice PC with lots of expansion capability. Either way you went, the PC seemed like a better value. And as 1992 wore on, that PC came down in price while Amiga prices held mostly steady.</p><p>The Amiga 600 failed, and Commodore discontinued it in 1993. No one noticed though. Commodore still had inventory when it folded in 1994 so you could still get one if you wanted one. They had refurbished Amiga 500s too, so you could get one of those instead. And that’s what the people in the know went for, if they bought an Amiga instead of a PC.</p><h2>Amiga 600 vs Amiga 500</h2><p>In most ways, the Amiga 600 was just a cut-down version of the Amiga 500. <a href="https://dfarq.homeip.net/amiga-500-and-amiga-2000-introduction-date/">Launched in 1987</a>, the Amiga 500 had been pretty successful. It initially cost $695 when released, and was also a cut-down version of the Amiga 1000, repackaged in a single piece with a full keyboard that resembled the now-ubiquitous PC keyboard layout of today.</p><p>An ecosystem sprung up around the Amiga 500 because it was really expandable. It featured a port on the side where you could plug in a hard drive or CD-ROM drive, and a trapdoor expansion that could take additional memory. If you were willing to tinker, you could expand it inside, because all of the major chips were in sockets. Lots of Amiga 500 add-0ns were circuit boards that plugged into chip sockets.</p><p>The Amiga 600 dispensed with most of that. All of the chips except the system ROM were soldered to the motherboard, so all the wonderful internal A500 expansions didn’t work anymore. The expansion port on the side disappeared, with a PCMCIA port in its place. That’s nice today, but in 1992, PCMCIA peripherals were fairly scarce. The keyboard shrunk down to something resembling today’s 40% keyboards. The only improvement it featured over the A500 was having a 44-pin IDE port on the motherboard.</p><p>It was fully software-compatible with the A500, but most of the peripherals that had sprung up around it over the previous five years had to be redesigned. It was a dated machine, with no hardware ecosystem around it, and offered no significant price savings over the machine it replaced.</p><h4>The Amiga 300</h4><p>At one point, the Amiga 600 was going to be called the Amiga 300 and sold as a cut-down Amiga. That sounds like a solution in charge of a problem but at least wouldn’t have meant discontinuing a machine that still sold well. Discontinuing a machine that was still selling and replacing it with one with a name that made it sound like an upgrade when it wasn’t created new problems for a company that didn’t need any more new problems.</p><h3>Dated technology</h3><p>Both the Amiga 500 and 600 featured a <a href="https://dfarq.homeip.net/motorola-born-on-this-day-in-1928/">Motorola</a> 68000 CPU running at 7 MHz. In 1987 this was fine. By 1992, that 68000 was competing with 16 MHz 386SX CPUs, which at least sounded much better. The perceived value of a 386SX at 16 MHz was much higher than that of a 7 MHz 68000. Apple discontinued its last computer based on the 68000 CPU in October 1992, which shows Commodore didn’t need to be trotting out a new machine based on that chip in March.</p><p>They also had 4-voice, stereo sound. In 1987, the Amiga’s sound was as good as it got. In 1992, a cheap PC couldn’t keep up. It either came with the standard PC speaker, or 3-voice Tandy sound, if you bought a <a href="https://dfarq.homeip.net/ibm-pcjr-and-tandy-1000/">Tandy 1000</a>. But you could get an add-on card. By 1992, you could get a <a href="https://dfarq.homeip.net/what-does-a-sound-blaster-do/">Sound Blaster</a> with 22-voice sound. It cost more, but the perceived value was much higher too.</p><h4>The graphics problem</h4><p>But the biggest problem was the graphics. In <a href="https://dfarq.homeip.net/computers-in-1985/">1985</a>, the Amiga’s 640×200 resolution and ability to display up to 4,096 colors was revolutionary. But 1987 saw the introduction of VGA, with the ability to display 256 colors from a palette of 262,144 colors, and a maximum resolution of 640×480. It was shockingly expensive in 1987, but prices came down rapidly. The Amiga’s graphics lended themselves well to 2D platform-style games and allowed the Amiga to punch above its weight. A stock Amiga 600 can play a <em>Commander Keen</em>-style game just as smoothly as a faster PC.</p><p>But in May 1992, id Software dropped <em>Wolfenstein 3D</em>, the first 3D first-person shooting game. It ran reasonably well on a 386sx-based PC with VGA graphics, while nothing comparable existed on the Amiga. While a brand-name 386SX with a VGA monitor cost slightly more than an Amiga 600 with a monitor and comparable hard drive, it could do something fun that an Amiga couldn’t do. People will pay more money if it seems like it’s worth it. And with every succeeding month in 1992 and 1993, the value proposition favored the PC more and more.</p><h3>How the Amiga 600 could have been better</h3><p>Commodore’s bad decisions have led to a ton of armchair quarterbacking over the years, especially around the <a href="https://dfarq.homeip.net/so-why-didnt-commodore-make-the-commodore-128-differently/">C-128</a> and <a href="https://dfarq.homeip.net/commodore-65/">C-65</a>, and many of those ideas weren’t technologically possible at the time. One thing Commodore <em>could</em> have done fairly easily would have been to replace the CPU. ICD had an accelerator board for the Amiga 500 containing a 68000 CPU running at 14 MHz. Supra had an even better one, the Supra Turbo 28, with a 68HC000 running at 28 MHz. These made the Amiga noticeably faster, without costing a lot of money and while maintaining very high compatibility with the original. Commodore’s engineers could have redesigned the A600 motherboard to accommodate a faster 68000. They had the ability.</p><p>A faster CPU would have made the A600 look better on paper, and made Amiga owners more willing to forgive its other shortcomings. Commodore might have even been able to raise the price a little to eek out a little more much-needed profit margin.</p><p>Putting the AGA chipset in the A600 would have also helped. The CPU still would have hurt, but the graphics would have been more competitive. But there’s a problem with that idea: the AGA chipset wasn’t ready to ship in March.</p><h2>The logic behind the Amiga 600</h2><p>The blame for the Amiga 600 primarily lies on Commodore product manager Bill Sydnes. Sydnes had been the product manager for <a href="https://dfarq.homeip.net/why-the-ibm-pcjr-failed/">IBM’s doomed PCjr</a>. His influence showed. He took a successful product, made a cut-down version of it, and made it look like the <a href="https://dfarq.homeip.net/commodore-64-vs-ibm-pcjr/">machine that beat his PCjr</a> in the marketplace. Amiga engineers called it the Amiga Junior and got in trouble for doing so.</p><p>Had Commodore been able to cut the price significantly, consumers might have accepted it. The problem was the redesign didn’t have a lot to work with. Reducing the board size and changing to newer, cheaper capacitors saved a few dollars, but the big money was elsewhere. The Amiga’s custom chipset was still being manufactured using a dated manufacturing process. Commodore’s MOS subsidiary used a 3.5 <span> µm</span> manufacturing process, while Intel and other chip manufacturers were using a 1 or 1.5<span> µm process</span> in 1985. By 1992, the rest of the industry had moved on to a .8 or .6<span> µm process. This meant Commodore’s competitors went from getting twice as many chips per wafer in 1985 to getting 3-5 times as many chips per wafer in 1992, so they could lower their prices much more quickly.</span></p><p>That’s why Commodore couldn’t price a bare A600 at $199 or $299. At that price, it might have had a chance because it could be the computer you bought if you couldn’t afford anything else. At $499, you had enough money to have other options, whether that meant a dated PC/XT clone, a used or refurbished Amiga 500, or saving up a few more months to get a more current PC.</p><p>Commodore’s ability to make its own chips had been a big advantage in 1982. Its process was out of date even then, but was competitive enough that it saved money by making them itself. Ten years later, it didn’t.</p><h2>Commodore’s other option</h2><p>Commodore had an ace in the hole in 1992: The Amiga 1200. Unlike the Amiga 600, it was a real improvement over the Amiga 500, with a faster 32-bit 68EC020 CPU running at 14 MHz, and VGA-like AGA graphics. In some ways it was too little, too late and it probably was. But the Amiga had a cult following, and it was enough to keep that niche interested, especially in Europe where the Amiga had a bigger following.</p><p>The problem was MOS technology couldn’t make the new chips. They were too complex. Commodore farmed out the graphics chip to HP and the memory/bus controller to VLSI. But since it wasn’t used to working with outside suppliers, it didn’t get the order in soon enough to get the chips in large quantities. So when Christmas 1992 came around, Commodore didn’t have enough chips to keep up with Amiga 1200 demand.</p><h3>Osborneing itself</h3><p>The Amiga 600 came out in March 1992 and the A1200 came out in October. Commodore couldn’t make up its mind which machine to build, and stepped right into the <a href="https://dfarq.homeip.net/osborne-computers-bankruptcy-and-the-osborne-effect/">Osborne effect</a>. In a perfect world, Commodore would have decided much earlier in the year to go with the Amiga 1200 so it could at least flood the market at Christmas. Better yet, it would have introduced it earlier in the year.</p><p>With too few A1200s to meet demand, they tried to make up the difference with Amiga 600s, and that went about as well as you’d imagine. Commodore ended up with piles of unsellable inventory, and the inability to keep up with early demand for the Amiga 1200 meant it lost momentum. Given the choice between going on a waiting list for an Amiga 1200, buying a 386SX immediately, or buying an Amiga 600, many more chose that 386sx. The 386sx looked like a comparable machine and it had <em>Wolfenstein 3D.</em></p><p>This meant Commodore had a problem. It had a pile of machines no one wanted. It had money tied up in those machines. That meant Commodore had less money to pay HP and VLSI for chips to make the machines people did want. After a disastrous Christmas 1992 season, Commodore <a href="https://dfarq.homeip.net/commodore-financial-history-1978-1994/">bled cash for five more quarters</a> and <a href="https://dfarq.homeip.net/who-bought-commodore/">went out of business</a> in April 1994.</p><h2>The Amiga 600 today</h2><p>It’s no help to Commodore now, but it seems like more people want an Amiga 600 today than in 1992. It’s small and self-contained, so it takes up less space than other retro systems. You can plug it into a <a href="https://dfarq.homeip.net/lcd-monitor-retro-computing/">Dell 2001fp</a> or similar monitor and it takes up less space than a PC keyboard. When you’re done with it, you can swap it in for another system and stash the A600 on a shelf or <a href="https://dfarq.homeip.net/make-a-picture-ledge-for-your-vintage-computer/">wall bracket</a>. Internally, the A600 takes a 44-pin hard drive or compact flash-to-IDE adapter for storage, and there’s a lot more PCMCIA hardware available now than there was in 1992. And if you want to really hotrod it, the Vampire board featuring a faster CPU and AGA-compatible chipset came out for the A600 before other Amiga models. So today it’s possible to turn the A600 into something compatible with the A1200, only smaller, faster, and better.</p><p>Even without modification, it’s a smaller and lighter Amiga 500. The A500’s keyboard is better, but if you’re playing games, you probably won’t notice the difference. And that’s the main reason people want a classic Amiga today. If you have multiple classic computers, it’s nice for them to be as small as possible. An Amiga 600 gives the classic Amiga experience in the smallest possible form factor. It was the worst Amiga possible in 1992 but in some ways it’s the ideal Amiga now.</p><h2>Amiga 600 caveats</h2><p>The major problem with the A600 is that it uses surface-mount capacitors, a cost-reducing measure from 1992. These capacitors tend to fail and leak, so many A600s don’t work today until you replace the caps. Be sure to ask if the caps have been replaced, and be prepared to replace them if they are original. The electrolyte leaks out and damages the motherboard over time, so be sure to replace the caps if they are still original. Original caps don’t improve the system value, and turn the system into a time bomb. Older Amigas used through-hole caps that weren’t as prone to leak, so there’s nothing wrong with leaving those original.</p><p>Similarly, many memory expansion boards contain a battery for a real-time clock. Ensure the battery is new, since a leaky battery can damage both the expansion board and the motherboard.</p><p>The A600 is also very prone to discoloration. While the machine still works, it doesn’t look as nice. Fortunately it responds well to the <a href="https://dfarq.homeip.net/retrobright-with-sunlight-and-no-chemicals/">chemical-free retrobright method</a> to restore its original color.</p><p>So while the Amiga 600 was the Amiga no one wanted and it neatly summed up everything wrong at Commodore in a neat little package, it’s a very nice retro computer now. It cures Amiga sprawl by packing all the essentials into less space than you need for a C-64. In some ways it’s the original Amiga Mini.</p><div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" data-src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" width="100" height="100" alt="" itemprop="image"></p><div><p>David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Wait, not like that": Free and open access in the age of generative AI (113 pts)]]></title>
            <link>https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/</link>
            <guid>43380617</guid>
            <pubDate>Sun, 16 Mar 2025 17:23:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/">https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=43380617">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

        <header>

                <a href="https://www.citationneeded.news/tag/artificial-intelligence/">Artificial intelligence</a>
            
                <p>The real threat isn’t AI using open knowledge — it’s AI companies killing the projects that make knowledge free</p>

            <div>
                <p><a href="https://www.citationneeded.news/author/molly/">
                                <img src="https://www.citationneeded.news/content/images/size/w160/2023/12/molly-sq.jpeg" alt="Molly White">
                            </a>
                </p>
                
            </div>

                <figure>
        <img srcset="https://www.citationneeded.news/content/images/size/w320/2025/03/ai-vampire-1.jpg 320w,
                    https://www.citationneeded.news/content/images/size/w600/2025/03/ai-vampire-1.jpg 600w,
                    https://www.citationneeded.news/content/images/size/w960/2025/03/ai-vampire-1.jpg 960w,
                    https://www.citationneeded.news/content/images/size/w1200/2025/03/ai-vampire-1.jpg 1200w,
                    https://www.citationneeded.news/content/images/size/w2000/2025/03/ai-vampire-1.jpg 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://www.citationneeded.news/content/images/size/w1200/2025/03/ai-vampire-1.jpg" alt="A digital collage depicting a vampire biting onto a laptop displaying the Wikipedia homepage">
    </figure>

        </header>

        <section>
            <div><p><img src="https://www.citationneeded.news/content/media/2025/03/2025-03-14-Wait-not-like-that_thumb.png" alt="audio-thumbnail"></p><div><p>“Wait, not like that”: Free and open access in the age of generative AI</p></div></div>
<!--kg-card-begin: html-->
<p>Listen to me read this post here (not an AI-generated voice!), <a href="https://www.citationneeded.news/podcast/">subscribe</a> to the feed in your podcast app, or <a href="https://www.citationneeded.news/content/media/2025/03/2025-03-14-Wait-not-like-that.mp3">download</a> the recording for later.</p>


<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<p>The visions of the open access movement have inspired countless people to contribute their work to the commons: a world where “every single human being can freely share in the sum of all knowledge” (Wikimedia), and where “education, culture, and science are equitably shared as a means to benefit humanity” (Creative Commons<sup id="footnote-anchor-1"><a href="#footnote-1">a</a></sup>).</p>
<!--kg-card-end: html-->
<p>But there are scenarios that can introduce doubt for those who contribute to free and open projects like the Wikimedia projects, or who independently release their own works under free licenses. I call these “wait, no, not like that” moments.</p><p>When a passionate Wikipedian discovers their carefully researched article has been packaged into an e-book and sold on Amazon for someone else’s profit? <em>Wait, no, not like that</em>.</p><p>When a developer of an open source software project sees a multi-billion dollar tech company rely on their work without contributing anything back? <em>Wait, no, not like that.</em></p><p>When a nature photographer discovers their freely licensed wildlife photo was used in an NFT collection minted on an environmentally destructive blockchain? <em>Wait, no, not like that</em>.</p><p>And perhaps most recently, when a person who publishes their work under a free license discovers that work has been used by tech mega-giants to train extractive, exploitative large language models? <strong><em>Wait, no, not like that</em>.</strong></p><p>These reactions are understandable. When we freely license our work, we do so in service of those goals: free and open access to knowledge and education. But when trillion dollar companies exploit that openness while giving nothing back, or when our work enables harmful or exploitative uses, it can feel like we've been naïve. The natural response is to try to regain control.</p><p>This is where many creators find themselves today, particularly in response to AI training. But the solutions they're reaching for — more restrictive licenses, paywalls, or not publishing at all — risk destroying the very commons they originally set out to build.</p><div><p><i><em>Citation Needed</em></i> is an independent publication, entirely supported by readers like you. Consider <a href="https://www.citationneeded.news/signup">signing up</a> for a free or pay-what-you-want subscription — it really helps me to keep doing this work.</p></div>
<!--kg-card-begin: html-->
<p>The first impulse is often to try to tighten the licensing, maybe by switching away to something like the <a href="https://en.wikipedia.org/wiki/Creative_Commons_NonCommercial_license" target="_blank" rel="noopener noreferrer nofollow">Creative Commons’ non-commercial</a> (and thus, non-free) license. When NFTs enjoyed a moment of popularity in the early 2020s, some artists looked to Creative Commons in hopes that they might declare NFTs fundamentally incompatible with their free licenses (they didn’t<sup id="reference-anchor-1"><a href="#reference-1">1</a></sup>). The same thing happened again with the explosion of generative AI companies training models on CC-licensed works, and some were disappointed to see the group take the stance that, not only do CC licenses not prohibit AI training wholesale, AI training should be considered non-infringing by default from a copyright perspective.<sup id="reference-anchor-2"><a href="#reference-2">2</a></sup></p>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<p>But the trouble with trying to continually narrow the definitions of “free” is that it is impossible to write a license that will perfectly prohibit each possibility that makes a person go “wait, no, not like that” while retaining the benefits of free and open access. If that is truly what a creator wants, then they are likely better served by a traditional, all rights reserved model in which any prospective reuser must individually negotiate terms with them; but this undermines the purpose of free, and restricts permitted reuse only to those with the time, means, and bargaining power to negotiate on a case by case basis.<sup id="footnote-anchor-2"><a href="#footnote-2">b</a></sup></p>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<p>Particularly with AI, there’s also no indication that tightening the license even <i><em>works</em></i>. We already know that major AI companies have been training their models on all rights reserved works in their ongoing efforts to ingest as much data as possible. Such training may prove to have been permissible in US courts under fair use, and it’s probably best that it does.<sup id="reference-anchor-3"><a href="#reference-3">3</a></sup><sup id="reference-anchor-4"><a href="#reference-4">4</a></sup><sup id="reference-anchor-5"><a href="#reference-5">5</a></sup><sup id="reference-anchor-6"><a href="#reference-6">6</a></sup></p>
<!--kg-card-end: html-->
<p>There’s also been an impulse by creators concerned about AI to dramatically limit how people can access their work. Some artists have decided it’s simply not worthwhile to maintain an online gallery of their work when that makes it easily accessible for AI training. Many have implemented restrictive content gates — paywalls, registration-walls, “are you a human”-walls, and similar — to try to fend off scrapers. This too closes off the commons, making it more challenging or expensive for those “every single human beings” described in open access manifestos to access the material that was originally intended to be common goods.</p>
<!--kg-card-begin: html-->
<p>Often by trying to wall off those considered to be bad actors, people wall off the very people they intended to give access to. People who gate their work behind paywalls likely didn’t set out to create works that only the wealthy could access. People who implement registration walls probably didn’t intend for their work to only be available to those willing to put up with the risk of incessant email spam after they relinquish their personal information. People who try to stave off bots with CAPTCHAs asking “are you a human?” probably didn’t mean to limit their material only to abled people<sup id="reference-anchor-7"><a href="#reference-7">7</a></sup> who are willing to abide ever more protracted and irritating riddles.<sup id="reference-anchor-8"><a href="#reference-8">8</a></sup> And people using any of these strategies likely didn’t want people to struggle to even find their work in the first place after the paywalls and regwalls and anti-bot mechanisms thwarted search engine indexers or social media previews.</p>
<!--kg-card-end: html-->
<p>And frankly, if we want to create a world in which every single human being can freely share in the sum of all knowledge, and where education, culture, and science are equitably shared as a means to benefit humanity, we should stop attempting to erect these walls. If a kid learns that carbon dioxide traps heat in Earth's atmosphere or how to calculate compound interest thanks to an editor’s work on a Wikipedia article, does it really matter if they learned it via ChatGPT or by asking Siri or from opening a browser and visiting Wikipedia.org?</p><p><strong>Instead of worrying about “wait, not like that”, I think we need to reframe the conversation to “wait, not <em>only</em> like that” or “wait, not in ways that threaten open access itself”.</strong> The true threat from AI models training on open access material is not that more people may access knowledge thanks to new modalities. It’s that those models may stifle Wikipedia and other free knowledge repositories, benefiting from the labor, money, and care that goes into supporting them while also bleeding them dry. It’s that trillion dollar companies become the sole arbiters of access to knowledge after subsuming the painstaking work of those who made knowledge free to all, killing those projects in the process.</p><p>Irresponsible AI companies are already imposing huge loads on Wikimedia infrastructure, which is costly both from a pure bandwidth perspective, but also because it requires dedicated engineers to maintain and improve systems to handle the massive automated traffic. And AI&nbsp;companies that do not attribute their responses or otherwise provide any pointers back to Wikipedia prevent users from knowing where that material came from, and do not encourage those users to go visit Wikipedia, where they might then sign up as an editor, or donate after seeing a request for support. (This is most AI companies, by the way. Many AI “visionaries” seem perfectly content to promise that artificial superintelligence is just around the corner, but claim that attribution is somehow a permanently unsolvable problem.)</p><p>And while I rely on Wikipedia as an example here, the same goes for any website containing freely licensed material, where scraping benefits AI companies at often extreme cost to the content hosts. This isn't just about strain on one individual project, it's about the systematic dismantling of the infrastructure that makes open knowledge possible.</p><p>Anyone at an AI company who stops to think for half a second should be able to recognize they have a vampiric relationship with the commons. While they rely on these repositories for their sustenance, their adversarial and disrespectful relationships with creators reduce the incentives for anyone to make their work publicly available going forward (freely licensed or otherwise). They drain resources from maintainers of those common repositories often without any compensation. They reduce the visibility of the original sources, leaving people unaware that they can or should contribute towards maintaining such valuable projects. AI companies should want a thriving open access ecosystem, ensuring that the models they trained on Wikipedia in 2020 can be continually expanded and updated. Even if AI companies don’t care about the benefit to the common good, it shouldn’t be hard for them to understand that by bleeding these projects dry, they are destroying their own food supply.</p><p>And yet many AI companies seem to give very little thought to this, seemingly looking only at the months in front of them rather than operating on years-long timescales. (Though perhaps anyone who has observed AI companies’ activities more generally will be unsurprised to see that they do not act as though they believe their businesses will be sustainable on the order of years.)</p><p>It would be very wise for these companies to immediately begin prioritizing the ongoing health of the commons, so that they do not wind up strangling their golden goose. It would also be very wise for the rest of us to not rely on AI companies to suddenly, miraculously come to their senses or develop a conscience en masse.</p><p>Instead, we must ensure that mechanisms are in place to <em>force</em> AI companies to engage with these repositories on their creators' terms.</p>
<!--kg-card-begin: html-->
<p>There are ways to do it: models like Wikimedia Enterprise, which welcomes AI companies to use Wikimedia-hosted data, but requires them to do so using paid, high-volume pipes to ensure that they do not clog up the system for everyone else and to make them financially support the extra load they’re placing on the project’s infrastructure. Creative Commons is experimenting with the idea of “<a href="https://www.ietf.org/slides/slides-aicontrolws-creative-commons-position-paper-on-preference-signals-00.pdf">preference signals</a>” — a non-copyright-based model by which to communicate to AI companies and other entities the terms on which they may or may not reuse CC licensed work.<sup id="footnote-anchor-3"><a href="#footnote-3">c</a></sup> Everyday people need to be given the tools — both legal and technical — to enforce their own preferences around how their works are used.</p>
<!--kg-card-end: html-->
<p>Some might argue that if AI companies are already ignoring copyright and training on all-rights-reserved works, they'll simply ignore these mechanisms too. But there's a crucial difference: rather than relying on murky copyright claims or threatening to expand copyright in ways that would ultimately harm creators, we can establish clear legal frameworks around consent and compensation that build on existing labor and contract law. Just as unions have successfully negotiated terms of use, ethical engagement, and fair compensation in the past, collective bargaining can help establish enforceable agreements between AI companies, those freely licensing their works, and communities maintaining open knowledge repositories. These agreements would cover not just financial compensation for infrastructure costs, but also requirements around attribution, ethical use, and reinvestment in the commons.</p><p>The future of free and open access isn't about saying “wait, not like that” — it’s about saying "yes, like that, but under fair terms”. With fair compensation for infrastructure costs. With attribution and avenues by which new people can discover and give back to the underlying commons. With deep respect for the communities that make the commons — and the tools that build off them —&nbsp;possible. Only then can we truly build that world where every single human being can freely share in the sum of all knowledge.</p><hr>
<!--kg-card-begin: html-->
<p>As I was writing this piece, I discovered that a SXSW panel featuring delegates from the Wikimedia Foundation and Creative Commons, titled “<a href="https://schedule.sxsw.com/2025/events/PP153044">Openness Under Pressure: Navigating the Future of Open Access</a>”, discussed some of the same topics. (I was, sadly, scheduled to speak at the same time and so was unable to attend in person). The audio recording is available online, and I would highly recommend giving it a listen if this is a topic that interests you!</p>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->

<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<div>
  <h4>References</h4>
  <ol><li id="reference-1"><p>“<a href="https://creativecommons.org/cc-and-nfts/" target="_blank" rel="noopener noreferrer nofollow">FAQ: CC and NFTs</a>”, Creative Commons. <a href="#reference-anchor-1" title="Jump back to reference 1 in the text.">↩</a></p></li><li id="reference-2"><p>“<a href="https://creativecommons.org/2021/03/04/should-cc-licensed-content-be-used-to-train-ai-it-depends/" target="_blank" rel="noopener noreferrer nofollow">Should CC-Licensed Content be Used to Train AI? It Depends.</a>” Creative Commons. <a href="#reference-anchor-2" title="Jump back to reference 2 in the text.">↩</a></p></li><li id="reference-3"><p>“<a href="https://www.regulations.gov/comment/COLC-2023-0006-8735" target="_blank" rel="noopener noreferrer nofollow">Comment from Creative Commons</a>”, published by the US Copyright Office. <a href="#reference-anchor-3" title="Jump back to reference 3 in the text.">↩</a></p></li><li id="reference-4"><p>“<a href="https://www.eff.org/deeplinks/2025/02/ai-and-copyright-expanding-copyright-hurts-everyone-heres-what-do-instead" target="_blank" rel="noreferrer">AI And Copyright: Expanding Copyright Hurts Everyone—Here’s What to Do Instead</a>”, EFF. <a href="#reference-anchor-4" title="Jump back to reference 4 in the text.">↩</a></p></li><li id="reference-5"><p>“<a href="https://pluralistic.net/2024/06/21/off-the-menu/" target="_blank" rel="noopener noreferrer nofollow">Neither the devil you know nor the devil you don’t</a>”, Cory Doctorow. <a href="#reference-anchor-5" title="Jump back to reference 5 in the text.">↩</a></p></li><li id="reference-6"><p>“<a href="https://www.techdirt.com/2023/12/04/if-creators-suing-ai-companies-over-copyright-win-it-will-further-entrench-big-tech/" target="_blank" rel="noopener noreferrer nofollow">If Creators Suing AI Companies Over Copyright Win, It Will Further Entrench Big Tech</a>”, <i><em>TechDirt</em></i>. <a href="#reference-anchor-6" title="Jump back to reference 6 in the text.">↩</a></p></li><li id="reference-7"><p>“<a href="https://www.w3.org/TR/turingtest/#the-accessibility-challenge" target="_blank" rel="noopener noreferrer nofollow">Inaccessibility of CAPTCHA</a>”, W3C. <a href="#reference-anchor-7" title="Jump back to reference 7 in the text.">↩</a></p></li><li id="reference-8"><p>“<a href="https://www.thetimes.com/business-money/technology/article/youre-not-imagining-it-captchas-are-getting-harder-x73kr720x?region=global" target="_blank" rel="noopener noreferrer nofollow">You’re not imagining it, Captchas are getting harder</a>”, <i><em>The Times</em></i>. <a href="#reference-anchor-8" title="Jump back to reference 8 in the text.">↩</a></p></li></ol>
</div>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->

<!--kg-card-end: html-->

        </section>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When the Dotcom Bubble Burst (148 pts)]]></title>
            <link>https://dfarq.homeip.net/when-the-dotcom-bubble-burst/</link>
            <guid>43380453</guid>
            <pubDate>Sun, 16 Mar 2025 17:02:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dfarq.homeip.net/when-the-dotcom-bubble-burst/">https://dfarq.homeip.net/when-the-dotcom-bubble-burst/</a>, See on <a href="https://news.ycombinator.com/item?id=43380453">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>25 years ago, on March 10, 2000, the dotcom bubble reached its peak. The tech-heavy NASDAQ reached its peak that day at 5,048.62, before the bubble burst and stocks went tumbling. Pinpointing when the dotcom bubble burst is harder. But pinpointing when it reached its biggest point is easy.</p><p>And while we sometimes call it the dotcom boom and the dotcom bust, it really was more of a bubble. Investors were terrified at missing out on the next <a href="https://dfarq.homeip.net/microsofts-1986-ipo/">Microsoft</a>. And they were convinced the next Microsoft would come out of the dotcom era. One could say they were right. Amazon and <a href="https://dfarq.homeip.net/google-incorporated-september-4-1998/">Google</a> did emerge from the dotcom era and both outrank Microsoft on the Fortune 500 today. But that took time. It wasn’t clear in 2000 how an online bookseller and a search engine were going to eclipse Microsoft in revenue someday. Nor was it clear they were going to be the ones to do it.</p><h2>A wild time</h2><figure id="attachment_37115" aria-describedby="caption-attachment-37115"><a href="https://dfarq.homeip.net/when-the-dotcom-bubble-burst/nasdaq_composite_dot-com_bubble-svg/" rel="attachment wp-att-37115"><img data-recalc-dims="1" fetchpriority="high" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2025/01/Nasdaq_Composite_dot-com_bubble.svg_.png?resize=300%2C168&amp;ssl=1" alt="the Dotcom bubble illusrated as the NASDAQ index" width="300" height="168" srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2025/01/Nasdaq_Composite_dot-com_bubble.svg_.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2025/01/Nasdaq_Composite_dot-com_bubble.svg_.png?w=640&amp;ssl=1 640w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-37115">The dotcom bubble drove the Nasdaq to its early-2000 peak. It took 15 years for it to reach that level again.</figcaption></figure><p>The dotcom era was a wild ride. When the NASDAQ peaked on March 10, 2000, it was double its value of a year before. Historically, it takes seven years for a market to double in value on average. So to say the dotcom era was overheated is an understatement.</p><p>And it’s a misnomer to call it a boom. In a boom, someone’s actually making money. Amazon didn’t have a profitable quarter until Q4 of 2001, and it was a modest profit of $5 million. It didn’t have a profitable year until 2003. Google was more promising, as it was turning profits before its IPO.</p><p>But Google was the exception. A company didn’t have to be profitable for its stock to boom. <a href="https://dfarq.homeip.net/netscape-the-ipo-that-went-boom-on-its-way-up-and-down/">Netscape</a> was the poster child for this. It created a necessary product, but Marc Andreessen and Jim Clark couldn’t figure out how to make it profitable. Andreessen is only rich today because he and Clark managed to <a href="https://dfarq.homeip.net/why-aol-bought-netscape/">convince AOL to pay</a> $10 billion for the company before they could finish running it into the ground. <a href="https://dfarq.homeip.net/what-happened-to-transmeta-the-last-big-dotcom-ipo/">Transmeta</a> was another example of a company with interesting technology but no profits. Competing with Intel wasn’t any easier during the dotcom bubble than it was in the years right before it.</p><p>The stereotypical dotcom business model went something like this: Find something nobody’s selling on the Internet. Register a domain name. Start selling that product on the Internet. Then wait for profits to happen like magic. And without a solid business plan that included things like logistics, those profits rarely happened and typically weren’t sustainable when they did. Just like in any other business. But since this was the Internet, it was going to be different this time, somehow.</p><p>A generation of billionaires made their fortunes in this era, including Peter Thiel and Mark Cuban. And it seemed like everyone was trying it. Even <a href="https://dfarq.homeip.net/ghislaine-maxwells-connection-to-the-dotcom-boom/">Ghislaine Maxwell’s family</a>. Really.</p><h2>The dotcom Super Bowl</h2><p>Super Bowl XXXIV also reflected this excess. A total of 14 dotcom companies paid an average of $2.2 million each for a Super Bowl commercial spot. E*Trade’s Super Bowl XXXIV ad exemplified the excess better than any of the others. It showed a chimpanzee lip-synching to La Cucaracha and bragged about having just wasted $2 million.</p><h2>The company that doubled in price for no reason</h2><p>But my favorite dotcom story is <a href="https://dfarq.homeip.net/the-most-excessive-dotcom-internet-america/">Internet America</a>. It was just a random regional provider of dialup service. Its name happened to be two magic words. On December 21, 1999, its share price doubled in spite of there being no news whatsoever about the company on that day. Smart investors cashed out immediately, and many did. In after hours trading it lost 25 percent of its value.</p><h2>The house of cards</h2><p>It turned out that business on the Internet was like business anywhere else in one regard. Companies without a business plan don’t make it very long. But since investors didn’t mind if a company didn’t have a plan or a path to profitability, it was a house of cards. Just three days after NASDAQ peaked, news of a recession in Japan was enough to tip the balance.</p><p>And <a href="https://dfarq.homeip.net/what-was-the-y2k-problem-and-solution/">Y2K</a> was over along with its spending boom, so while Y2K money helped send the NASDAQ skyward, it wasn’t there to cushion the fall. Tech stocks started tumbling, and they didn’t pop back up again for years.</p><p>Some of the companies started failing too. Three of the companies who bought expensive Super Bowl ads, Pets.com, Epidemic.com, and Computer.com, were out of business before the year ended. E*Trade’s Super Bowl XXXV ad made fun of the previous year’s dotcom ads, including directly making fun of Pets.com. It was set in a ghost town, reflecting how many dotcom companies had already failed. E*Trade’s message was clear: The dotcom bubble had burst.</p><p>The dotcom bubble hurt the tech industry as a whole too. Companies like <a href="https://dfarq.homeip.net/what-happened-to-sun-microsystems/">Sun Microsystems</a>, <a href="https://dfarq.homeip.net/why-did-compaq-fail/">Compaq</a>, and <a href="https://dfarq.homeip.net/what-happened-to-3com/">3Com</a> all profited selling equipment to these well-funded startups, but as the startups started struggling and going out of business, sales dried up. The wide availability of surplus lightly used equipment drove down demand for their products even further. The aftermath of the dotcom bubble didn’t just turn dotcoms into acquisition targets. Established tech companies became acquisition targets themselves. In some cases, they even sought out acquisition as a matter of survival.</p><p>It was a long ride down too. The market didn’t bottom out until 2002, and when it did, it fell back to 1997-like levels.&nbsp; It rallied in 2003, only to plateau in 2004.</p><p>A full recovery took a long time. The NASDAQ didn’t reach a level above 5,000 again until 2015. <a href="https://dfarq.homeip.net/google-incorporated-september-4-1998/">Google</a>‘s 2004 IPO is generally seen as the point when the recovery started. Google intentionally postponed its IPO as a result of the dotcom bust.</p><div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" data-src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" width="100" height="100" alt="" itemprop="image"></p><div><p>David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a Personal Archive with Hoarder (101 pts)]]></title>
            <link>https://brainsteam.co.uk/2025/2/15/personal-archive-hoarder/</link>
            <guid>43379917</guid>
            <pubDate>Sun, 16 Mar 2025 15:46:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brainsteam.co.uk/2025/2/15/personal-archive-hoarder/">https://brainsteam.co.uk/2025/2/15/personal-archive-hoarder/</a>, See on <a href="https://news.ycombinator.com/item?id=43379917">Hacker News</a></p>
Couldn't get https://brainsteam.co.uk/2025/2/15/personal-archive-hoarder/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[DiceDB (156 pts)]]></title>
            <link>https://dicedb.io/</link>
            <guid>43379262</guid>
            <pubDate>Sun, 16 Mar 2025 14:20:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dicedb.io/">https://dicedb.io/</a>, See on <a href="https://news.ycombinator.com/item?id=43379262">Hacker News</a></p>
Couldn't get https://dicedb.io/: Error: getaddrinfo ENOTFOUND dicedb.io]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: 10 teams are racing to build a pivotal tracker replacement (105 pts)]]></title>
            <link>https://bye-tracker.net</link>
            <guid>43378925</guid>
            <pubDate>Sun, 16 Mar 2025 13:30:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bye-tracker.net">https://bye-tracker.net</a>, See on <a href="https://news.ycombinator.com/item?id=43378925">Hacker News</a></p>
Couldn't get https://bye-tracker.net: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Learn You Some Erlang for Great Good (2013) (103 pts)]]></title>
            <link>https://learnyousomeerlang.com/content</link>
            <guid>43378415</guid>
            <pubDate>Sun, 16 Mar 2025 12:14:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://learnyousomeerlang.com/content">https://learnyousomeerlang.com/content</a>, See on <a href="https://news.ycombinator.com/item?id=43378415">Hacker News</a></p>
Couldn't get https://learnyousomeerlang.com/content: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Big LLMs weights are a piece of history (263 pts)]]></title>
            <link>https://antirez.com/news/147</link>
            <guid>43378401</guid>
            <pubDate>Sun, 16 Mar 2025 12:13:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/147">https://antirez.com/news/147</a>, See on <a href="https://news.ycombinator.com/item?id=43378401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section id="newslist"><article data-news-id="147"></article></section><topcomment><article data-comment-id="147-" id="147-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 4 hours ago. 19973 views.  </span><pre>By multiple accounts, the web is losing pieces: every year a fraction of old web pages disappear, lost forever. We should regard the Internet Archive as one of the most valuable pieces of modern history; instead, many companies and entities make the chances of the Archive to survive, and accumulate what otherwise will be lost, harder and harder. I understand that the Archive headquarters are located in what used to be a church: well, there is no better way to think of it than as a sacred place.

Imagine the long hours spent by old programmers hacking with the Z80 assembly on their Spectrums. All the discussions about the first generation of the Internet. The subcultures that appeared during the 90s. All things that are getting lost, piece by piece.

And what about the personal blogs? Pieces of life of single individuals that dumped part of their consciousness on the Internet. Scientific papers and processes that are lost forever as publishers fail, their websites shut down. Early digital art, video games, climate data once published on the Internet and now lost, and many sources of news, as well.

This is a known issue and I believe that the obvious approach of trying to preserve everything is going to fail, for practical reasons: a lot of efforts for zero economic gains: the current version of the world is not exactly the best place to make efforts that cost a lot of money and don't pay money. This is why I believe that the LLMs' ability to compress information, even if imprecise, hallucinated, lacking, is better than nothing. DeepSeek V3 is already an available, public lossy compressed view of the Internet, as other very large state of-art models are.

This will not bring back all the things we are losing, and we should try hard supporting The Internet Archive and other similar institutions and efforts. But, at the same time, we should focus on a much simpler effort: to make sure that the weights of LLMs publicly released do not get lost, and also to make sure that the Archive is part of the pre-training set as well.</pre></article></topcomment>


<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The good times in tech are over (162 pts)]]></title>
            <link>https://www.seangoedecke.com/good-times-are-over/</link>
            <guid>43378321</guid>
            <pubDate>Sun, 16 Mar 2025 11:59:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/good-times-are-over/">https://www.seangoedecke.com/good-times-are-over/</a>, See on <a href="https://news.ycombinator.com/item?id=43378321">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>For most of the last decade, being a software engineer has been a lot of fun. Every company offered lots of perks, layoffs and firings were almost unheard of, and in general we were treated as special little geniuses who needed to be pampered so we could work our magic. That’s changed in the last two years. The <a href="https://techcrunch.com/2024/05/01/a-comprehensive-archive-of-2023-tech-layoffs/">first round</a> of tech layoffs in 2023 came as a shock, but at least companies were falling over themselves to offer generous severance and teary CEO letters regretting the necessity. Two years later, Meta is explicitly <a href="https://fortune.com/2025/02/13/meta-low-performer-layoffs-staff-experts-criticism/">branding</a> its layoffs as “these were our lowest performers, good riddance”. What the hell happened?<sup id="fnref-1"><a href="#fn-1">1</a></sup> What does it mean for us?</p>
<h3>Why did the vibe shift?</h3>
<p>In the 2010s, interest rates were zero or close to zero<sup id="fnref-2"><a href="#fn-2">2</a></sup>. Investors could thus borrow a <em>lot</em> of money. Much of that money was spent on tech companies in the hope of outsized returns. Tech companies were thus incentivized to (a) hire like crazy, and (b) do a lot of low-risk high-reward things, even if that ends up wasting money. Tech companies definitely did <em>not</em> have to be profitable. In fact, they didn’t even need to make money - they just had to acquire users, or at least hype, to drive up the valuation of the company itself. In that environment, throwing money at their software engineers (in the form of paid trips, in-house chefs, and huge comp packages) was a sensible business decision.</p>
<p>In 2023, this underlying economic situation reversed: interest rates went up to around 5%<sup id="fnref-3"><a href="#fn-3">3</a></sup>. Tech company incentives completely flipped: now it’s suddenly important to be profitable, or at least to make lots of money. That means it’s not wise for most companies to hire like crazy, or to continue throwing near-unlimited amounts of money at their software engineers.</p>
<p>I think that’s a sufficient explanation for the vibe shift all by itself. What about COVID? It helped, but it wasn’t the root cause. Two years (or thereabouts) of people staying inside more meant much more engagement with tech products, which meant much more money flowing into tech companies. <em>Everyone</em> was hiring during COVID. Once that short-term boom finished, companies naturally wanted to get rid of some of those engineers, which is what triggered a lot of the initial layoffs. However, I do think that even without COVID, we’d still be in something like the current situation. Companies were constantly hiring pre-2020 as well.</p>
<p>This idea that AI is taking software engineering jobs or contributing to layoffs is - as far as I can tell - currently pure fantasy. I do believe in the power of AI, and I wouldn’t be surprised if it takes software jobs at some point in the future, but it’s certainly not behind the vibe shift in software engineering right now.</p>
<h3>What does that mean for us?</h3>
<p>I think a lot of software engineers right now are planting their feet and refusing to change. After ten years of their opinion being consulted on big company decisions, they’re trying to hold on to that power. I have respect for anyone who stands up for what they think is right at personal cost. I just want to stress that there <em>is</em> going to be a personal cost to not going along with the vibe shift, particularly for more junior or more vulnerable engineers. As someone who lives in Australia, I feel <a href="https://www.seangoedecke.com/working-for-americans">pretty vulnerable</a> myself.</p>
<p>The biggest thing to internalize is that <strong>companies now are actually trying to focus</strong>. In 2015, there was a lot of appetite to do everything at the same time: building out new product lines, transitioning from a product to a platform, making significant open-source contributions, working on a top-tier developer experience, and so on. In 2025, most of these initiatives have been abruptly defunded in order to put more resources into a handful of bets that the company executives actually care about.</p>
<p>During the 2010s, it was as if companies <em>were</em> their software engineers, and were interested in the same things as their engineers were. A lot of engineers were fooled by this into identifying strongly with their employer. But this was a mirage: in part caused by companies’ desire to attract and retain talent, and in part by there being no real pressure on companies to say no to anything. Now the mirage has vanished. Companies are their executive leadership, and their executive leadership are interested in a much smaller set of things.</p>
<p>If you were an engineer who loved working on your company’s open-source libraries, it’s probably sensible to confront the fact that the company never really cared about it that much. When interest rates were zero, it was worth doing because most things were worth doing. At 5% interest rates, most open-source work doesn’t meet that bar. In other words, <strong>your interests now conflict with your company’s interests</strong>.</p>
<p>It’s okay for your interests to conflict with your company’s. You get to decide what you care about, and what you’re willing to fight for. But when you act in ways that don’t further your company’s interests, you risk being seen as ineffective or unreliable. In 2025, that makes you vulnerable to being laid off.</p>
<h3>Is there a silver lining?</h3>
<p>The good news is that tech companies now live in (or at least a lot closer to) the “real world”. It was nice to be pampered, but there was a fundamental ridiculousness about it, even at the time. I know a lot of engineers who found that offputting, including myself. It’s why many engineers found the TV show <em>Silicon Valley</em> hard to watch - the satire was too real to laugh at. It was mainly embarrassing.</p>
<p>If I had to choose, I’d definitely choose to return to the job market of the 2010s, so I can be paid more to work less and have more job security. I’m not an idiot. But the silver lining to <em>actually having to ship</em> is that you’re no longer living in a dream. If you’re realistic about how things work, <a href="https://www.seangoedecke.com/how-to-ship">the job of software engineering</a> becomes much easier to understand:</p>
<ol>
<li>Providing value to the company gets you rewarded</li>
<li>Not providing value to the company gets you punished</li>
<li>“Value to the company” means furthering the explicit plans of your company’s executives</li>
</ol>
<p>It’s not much of a mission statement! Certainly nothing on <a href="https://www.youtube.com/watch?v=B8C5sjjhsso&amp;ab_channel=BrianJ.Hall">“making the world a better place”</a>. But it has the comforting solidity of the truth. The good thing about the music finally stopping is that you don’t have to worry about when it’s going to stop.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Docs – Open source alternative to Notion or Outline (1277 pts)]]></title>
            <link>https://github.com/suitenumerique/docs</link>
            <guid>43378239</guid>
            <pubDate>Sun, 16 Mar 2025 11:38:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/suitenumerique/docs">https://github.com/suitenumerique/docs</a>, See on <a href="https://news.ycombinator.com/item?id=43378239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://github.com/suitenumerique/docs">
    <img alt="Docs" src="https://github.com/suitenumerique/docs/raw/main/docs/assets/docs-logo.png" width="300">
  </a>
</p>
<p dir="auto">
Welcome to Docs! The open source document editor where your notes can become knowledge through live collaboration
</p>
<p dir="auto">
  <a href="https://matrix.to/#/#docs-official:matrix.org" rel="nofollow">
    Chat on Matrix
  </a> - <a href="https://github.com/suitenumerique/docs/blob/main/docs">
    Documentation
  </a> - <a href="#getting-started-">
    Getting started
  </a> - <a href="mailto:docs@numerique.gouv.fr">
    Reach out
  </a>
</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/suitenumerique/docs/blob/main/docs/assets/docs_live_collaboration_light.gif"><img src="https://github.com/suitenumerique/docs/raw/main/docs/assets/docs_live_collaboration_light.gif" width="100%" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why use Docs ❓</h2><a id="user-content-why-use-docs-" aria-label="Permalink: Why use Docs ❓" href="#why-use-docs-"></a></p>
<p dir="auto">Docs is a collaborative text editor designed to address common challenges in knowledge building and sharing.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Write</h3><a id="user-content-write" aria-label="Permalink: Write" href="#write"></a></p>
<ul dir="auto">
<li>😌 Simple collaborative editing without the formatting complexity of markdown</li>
<li>🔌 Offline? No problem, keep writing, your edits will get synced when back online</li>
<li>💅 Create clean documents with limited but beautiful formatting options and focus on content</li>
<li>🧱 Built for productivity (markdown support, many block types, slash commands, keyboard shortcuts).</li>
<li>✨ Save time thanks to our AI actions (generate, sum up, correct, translate)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Collaborate</h3><a id="user-content-collaborate" aria-label="Permalink: Collaborate" href="#collaborate"></a></p>
<ul dir="auto">
<li>🤝 Collaborate with your team in real time</li>
<li>🔒 Granular access control to ensure your information is secure and only shared with the right people</li>
<li>📑 Professional document exports in multiple formats (.odt, .doc, .pdf) with customizable templates</li>
<li>📚 Built-in wiki functionality to turn your team's collaborative work into organized knowledge <code>ETA 02/2025</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-host</h3><a id="user-content-self-host" aria-label="Permalink: Self-host" href="#self-host"></a></p>
<ul dir="auto">
<li>🚀 Easy to install, scalable and secure alternative to Notion, Outline or Confluence</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started 🔧</h2><a id="user-content-getting-started-" aria-label="Permalink: Getting started 🔧" href="#getting-started-"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test it</h3><a id="user-content-test-it" aria-label="Permalink: Test it" href="#test-it"></a></p>
<p dir="auto">Test Docs on your browser by logging in on this <a href="https://impress-preprod.beta.numerique.gouv.fr/docs/0aa856e9-da41-4d59-b73d-a61cb2c1245f/" rel="nofollow">environment</a></p>
<div data-snippet-clipboard-copy-content="email: test.docs@yopmail.com
password: I'd<3ToTestDocs"><pre><code>email: test.docs@yopmail.com
password: I'd&lt;3ToTestDocs
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run it locally</h3><a id="user-content-run-it-locally" aria-label="Permalink: Run it locally" href="#run-it-locally"></a></p>
<blockquote>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Running Docs locally using the methods described below is for testing purposes only.  It is based on building Docs using Minio as the S3 storage solution: if you want to use Minio for production deployment of Docs, you will need to comply with Minio's AGPL-3.0 licence.</p>
</blockquote>
<p dir="auto"><strong>Prerequisite</strong></p>
<p dir="auto">Make sure you have a recent version of Docker and <a href="https://docs.docker.com/compose/install" rel="nofollow">Docker Compose</a> installed on your laptop:</p>
<div data-snippet-clipboard-copy-content="$ docker -v

Docker version 20.10.2, build 2291f61

$ docker compose version

Docker Compose version v2.32.4"><pre lang="shellscript"><code>$ docker -v

Docker version 20.10.2, build 2291f61

$ docker compose version

Docker Compose version v2.32.4
</code></pre></div>
<blockquote>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> You may need to run the following commands with sudo but this can be avoided by adding your user to the <code>docker</code> group.</p>
</blockquote>
<p dir="auto"><strong>Project bootstrap</strong></p>
<p dir="auto">The easiest way to start working on the project is to use GNU Make:</p>
<div data-snippet-clipboard-copy-content="$ make bootstrap FLUSH_ARGS='--no-input'"><pre lang="shellscript"><code>$ make bootstrap FLUSH_ARGS='--no-input'
</code></pre></div>
<p dir="auto">This command builds the <code>app</code> container, installs dependencies, performs database migrations and compile translations. It's a good idea to use this command each time you are pulling code from the project repository to avoid dependency-related or migration-related issues.</p>
<p dir="auto">Your Docker services should now be up and running 🎉</p>
<p dir="auto">You can access to the project by going to <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a>.</p>
<p dir="auto">You will be prompted to log in, the default credentials are:</p>
<div data-snippet-clipboard-copy-content="username: impress
password: impress"><pre><code>username: impress
password: impress
</code></pre></div>
<p dir="auto">📝 Note that if you need to run them afterwards, you can use the eponym Make rule:</p>

<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> For the frontend developer, it is often better to run the frontend in development mode locally.</p>
<p dir="auto">To do so, install the frontend dependencies with the following command:</p>
<div data-snippet-clipboard-copy-content="$ make frontend-development-install"><pre lang="shellscript"><code>$ make frontend-development-install
</code></pre></div>
<p dir="auto">And run the frontend locally in development mode with the following command:</p>
<div data-snippet-clipboard-copy-content="$ make run-frontend-development"><pre lang="shellscript"><code>$ make run-frontend-development
</code></pre></div>
<p dir="auto">To start all the services, except the frontend container, you can use the following command:</p>

<p dir="auto"><strong>Adding content</strong>
You can create a basic demo site by running:</p>

<p dir="auto">Finally, you can check all available Make rules using:</p>

<p dir="auto"><strong>Django admin</strong></p>
<p dir="auto">You can access the Django admin site at</p>
<p dir="auto"><a href="http://localhost:8071/admin" rel="nofollow">http://localhost:8071/admin</a>.</p>
<p dir="auto">You first need to create a superuser account:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback 🙋‍♂️🙋‍♀️</h2><a id="user-content-feedback-️️" aria-label="Permalink: Feedback 🙋‍♂️🙋‍♀️" href="#feedback-️️"></a></p>
<p dir="auto">We'd love to hear your thoughts and hear about your experiments, so come and say hi on <a href="https://matrix.to/#/#docs-official:matrix.org" rel="nofollow">Matrix</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto">Want to know where the project is headed? <a href="https://github.com/orgs/numerique-gouv/projects/13/views/11">🗺️ Checkout our roadmap</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licence 📝</h2><a id="user-content-licence-" aria-label="Permalink: Licence 📝" href="#licence-"></a></p>
<p dir="auto">This work is released under the MIT License (see <a href="https://github.com/suitenumerique/docs/blob/main/LICENSE">LICENSE</a>).</p>
<p dir="auto">While Docs is a public driven initiative our licence choice is an invitation for private sector actors to use, sell and contribute to the project.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing 🙌</h2><a id="user-content-contributing-" aria-label="Permalink: Contributing 🙌" href="#contributing-"></a></p>
<p dir="auto">This project is intended to be community-driven, so please, do not hesitate to <a href="https://matrix.to/#/#docs-official:matrix.org" rel="nofollow">get in touch</a> if you have any question related to our implementation or design decisions.</p>
<p dir="auto">You can help us with translations on <a href="https://crowdin.com/project/lasuite-docs" rel="nofollow">Crowdin</a>.</p>
<p dir="auto">If you intend to make pull requests see <a href="https://github.com/suitenumerique/docs/blob/main/CONTRIBUTING.md">CONTRIBUTING</a> for guidelines.</p>
<p dir="auto">Directory structure:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docs
├── bin - executable scripts or binaries that are used for various tasks, such as setup scripts, utility scripts, or custom commands.
├── crowdin - for crowdin translations, a tool or service that helps manage translations for the project.
├── docker - Dockerfiles and related configuration files used to build Docker images for the project. These images can be used for development, testing, or production environments.
├── docs - documentation for the project, including user guides, API documentation, and other helpful resources.
├── env.d/development - environment-specific configuration files for the development environment. These files might include environment variables, configuration settings, or other setup files needed for development.
├── gitlint - configuration files for `gitlint`, a tool that enforces commit message guidelines to ensure consistency and quality in commit messages.
├── playground - experimental or temporary code, where developers can test new features or ideas without affecting the main codebase.
└── src - main source code directory, containing the core application code, libraries, and modules of the project."><pre>docs
├── bin - executable scripts or binaries that are used for various tasks, such as setup scripts, utility scripts, or custom commands.
├── crowdin - for crowdin translations, a tool or service that helps manage translations for the project.
├── docker - Dockerfiles and related configuration files used to build Docker images for the project. These images can be used for development, testing, or production environments.
├── docs - documentation for the project, including user guides, API documentation, and other helpful resources.
├── env.d/development - environment-specific configuration files for the development environment. These files might include environment variables, configuration settings, or other setup files needed for development.
├── gitlint - configuration files for <span>`</span><span>gitlint</span><span>`</span>, a tool that enforces commit message guidelines to ensure consistency and quality in commit messages.
├── playground - experimental or temporary code, where developers can test new features or ideas without affecting the main codebase.
└── src - main source code directory, containing the core application code, libraries, and modules of the project.</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits ❤️</h2><a id="user-content-credits-️" aria-label="Permalink: Credits ❤️" href="#credits-️"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Stack</h3><a id="user-content-stack" aria-label="Permalink: Stack" href="#stack"></a></p>
<p dir="auto">Docs is built on top of <a href="https://www.django-rest-framework.org/" rel="nofollow">Django Rest Framework</a>, <a href="https://nextjs.org/" rel="nofollow">Next.js</a>, <a href="https://www.blocknotejs.org/" rel="nofollow">BlockNote.js</a>, <a href="https://tiptap.dev/docs/hocuspocus/introduction" rel="nofollow">HocusPocus</a> and <a href="https://yjs.dev/" rel="nofollow">Yjs</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Gov ❤️ open source</h3><a id="user-content-gov-️-open-source" aria-label="Permalink: Gov ❤️ open source" href="#gov-️-open-source"></a></p>
<p dir="auto">Docs is the result of a joint effort led by the French 🇫🇷🥖 (<a href="https://www.numerique.gouv.fr/dinum/" rel="nofollow">DINUM</a>) and German 🇩🇪🥨 governments (<a href="https://zendis.de/" rel="nofollow">ZenDiS</a>).</p>
<p dir="auto">We are proud sponsors of <a href="https://www.blocknotejs.org/" rel="nofollow">BlockNotejs</a> and <a href="https://yjs.dev/" rel="nofollow">Yjs</a>.</p>
<p dir="auto">We are always looking for new public partners (we are currently onboarding the Netherlands 🇳🇱🧀), feel free to <a href="mailto:docs@numerique.gouv.fr">reach out</a> if you are interested in using or contributing to Docs.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/suitenumerique/docs/blob/main/docs/assets/europe_opensource.png"><img src="https://github.com/suitenumerique/docs/raw/main/docs/assets/europe_opensource.png" width="50%"></a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT 4.5 level for 1% of the price (286 pts)]]></title>
            <link>https://twitter.com/Baidu_Inc/status/1901089355890036897</link>
            <guid>43377962</guid>
            <pubDate>Sun, 16 Mar 2025 10:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Baidu_Inc/status/1901089355890036897">https://twitter.com/Baidu_Inc/status/1901089355890036897</a>, See on <a href="https://news.ycombinator.com/item?id=43377962">Hacker News</a></p>
Couldn't get https://twitter.com/Baidu_Inc/status/1901089355890036897: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Lynx is the oldest web browser still being maintained (214 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43377829</link>
            <guid>43377829</guid>
            <pubDate>Sun, 16 Mar 2025 09:37:59 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43377829">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=43377829: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My high school team’s space probe (135 pts)]]></title>
            <link>https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing</link>
            <guid>43377690</guid>
            <pubDate>Sun, 16 Mar 2025 08:48:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing">https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing</a>, See on <a href="https://news.ycombinator.com/item?id=43377690">Hacker News</a></p>
Couldn't get https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>