<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 12 Sep 2024 23:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[OpenAI O1 Model (1325 pts)]]></title>
            <link>https://openai.com/index/learning-to-reason-with-llms/</link>
            <guid>41523070</guid>
            <pubDate>Thu, 12 Sep 2024 17:08:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/learning-to-reason-with-llms/">https://openai.com/index/learning-to-reason-with-llms/</a>, See on <a href="https://news.ycombinator.com/item?id=41523070">Hacker News</a></p>
Couldn't get https://openai.com/index/learning-to-reason-with-llms/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Metformin decelerates aging clock in male monkeys (154 pts)]]></title>
            <link>https://www.cell.com/cell/abstract/S0092-8674(24)00914-0</link>
            <guid>41522931</guid>
            <pubDate>Thu, 12 Sep 2024 16:56:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cell.com/cell/abstract/S0092-8674(24)00914-0">https://www.cell.com/cell/abstract/S0092-8674(24)00914-0</a>, See on <a href="https://news.ycombinator.com/item?id=41522931">Hacker News</a></p>
Couldn't get https://www.cell.com/cell/abstract/S0092-8674(24)00914-0: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: iFixit created a new USB-C, repairable soldering system (625 pts)]]></title>
            <link>https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/</link>
            <guid>41521919</guid>
            <pubDate>Thu, 12 Sep 2024 15:18:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/">https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/</a>, See on <a href="https://news.ycombinator.com/item?id=41521919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>Like many people who solder regularly, I decided years ago to upgrade from a basic iron and invest in a soldering station. My RadioShack digital station has served me well for the better part of 20 years. It heats up fast, tips are readily available, and it’s a breeze to dial in whatever temperature I need. It’s older than both of my children, has moved with me to three different homes, and has outlived two cars and one marriage (so far, anyway).</p>
<figure id="attachment_706988" aria-describedby="caption-attachment-706988"><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg"><img decoding="async" data-attachment-id="706988" data-permalink="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/fixhub_radioshack/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg" data-orig-size="1026,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fixhub_radioshack" data-image-description="" data-image-caption="<p>Hackaday still used B&amp;W pictures when I bought this.</p>
" data-medium-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg?w=752" tabindex="0" role="button" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg?w=400" alt="" width="350" height="291" srcset="https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg 1026w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg?resize=250,208 250w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg?resize=400,333 400w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_radioshack.jpg?resize=752,625 752w" sizes="(max-width: 350px) 100vw, 350px"></a><figcaption id="caption-attachment-706988">When I got this, Hackaday still used B&amp;W pictures.</figcaption></figure>
<p>As such, when the new breed of “smart” USB-C soldering irons started hitting the scene, I didn’t find them terribly compelling. Oh sure, I bought a Pinecil. But that’s because I’m an unrepentant open source zealot and love the idea that there’s a soldering iron running a community developed firmware. In practice though, I only used the thing a few times, and even then it was because I needed something portable. Using it at home on the workbench? It just never felt up to the task of daily use.</p>
<p>So when iFixit got in contact a couple weeks back and said they had a <a href="https://www.ifixit.com/fixhub" target="_blank">prototype USB-C soldering iron</a> they wanted me to take a look at, I was skeptical to say the least. But then I started reading over the documentation they sent over, and couldn’t deny that they had some interesting ideas. For one, it was something of a hybrid iron. It was portable when you needed it to be, yet offered the flexibility and power of a station when you were at the bench.</p>
<p>Even better, they were planning on putting their money where their mouth is. The hardware was designed with repairability in mind at every step. Not only was it modular and easy to open up, but the company would be providing full schematics, teardown guides, and spare parts.</p>
<p>Alright, fine. Now you’ve got my attention.</p>

<h2>Best of Both Worlds</h2>
<p>Before we get too much farther, I should clarify that the FixHub is technically two separate devices. Officially iFixit calls the combo a “<a href="https://www.ifixit.com/News/99434/introducing-fixhub-the-portable-soldering-system" target="_blank">Portable Soldering System</a>” in their documentation, which is made up of the <a href="https://www.ifixit.com/products/fixhub-power-series-smart-soldering-iron" target="_blank">Smart Soldering Iron</a> and the <a href="https://www.ifixit.com/products/fixhub-power-series-portable-soldering-station" target="_blank">Portable Power Station</a>. While they are designed to work best when combined, both are fully capable of working independently of each other.</p>
<h3>Smart Soldering Iron</h3>
<p>The star of the show is, of course, the Smart Soldering Iron. It’s a 100 watt iron that comes up to operating temperature in under five seconds and can work with any suitably beefy USB-C Power Delivery source. The size and general proportions of the iron are very close to the Pinecil V2, though the grip is larger and considerably more comfortable to hold. The biggest difference between the two however is the absence of a display or configuration buttons. According to iFixit, most users don’t change their settings enough to justify putting the interface on the iron itself. That doesn’t mean you can’t tweak the iron’s settings when used in this stand-alone configuration, but we’ll get back to that in a minute.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg" target="_blank"><img decoding="async" data-attachment-id="706962" data-permalink="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/fixhub_pinecil/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg" data-orig-size="1268,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fixhub_pinecil" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg?w=800" tabindex="0" role="button" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg" alt="" width="800" height="252" srcset="https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg 1268w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg?resize=250,79 250w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg?resize=400,126 400w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_pinecil.jpg?resize=800,252 800w" sizes="(max-width: 800px) 100vw, 800px"></a></p>
<p>The only control on the iron is a slide switch on the tail end that cuts power to the heating element. I like this arrangement a lot more than the software solution used on irons like the Pinecil. The click of the switch just feels more reliable than having to hold down a button and hoping the iron’s firmware understands that I want to turn the thing off and not adjust some setting. Of course, this is still a “smart” iron, so naturally there’s also support for accelerometer based idle and sleep modes that you can enable.</p>
<p>While there’s no display, the illuminated ring behind the grip does provide a visual indicator of what the iron is doing: solid blue means it has power but the heating element is off, a pulsing blue indicates the iron is heating, and orange means it has reached the desired temperature. If you flick the heater switch off, the ring pulses purple until it cools back off and returns to blue. It’s a simple and effective system, but the visual distinction between the blue and purple isn’t great. Would love to see the ability to customize these colors in a future firmware update.</p>
<p><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video id="video-706883-1" width="800" height="322" preload="metadata" controls="controls"><source type="video/mp4" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_ring_demo.mp4?_=1"><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_ring_demo.mp4">https://hackaday.com/wp-content/uploads/2024/09/fixhub_ring_demo.mp4</a></video></p>
<p>The iron has a couple of clever portability features for those who often find themselves hacking on the go. The magnetic cap can be placed over the tip even when it’s hot, which means you don’t need to wait for the iron to cool down before you pack it away in your bag. The included USB-C cable also comes with a locking collar that mates with the groves in the tail of the iron — this keeps the cable from pulling out if you’ve got yourself contorted into some weird angle, but doesn’t prevent you from using your own cable should you want.</p>

<p>As for the tip, it can be easily removed without tools and uses a 3.5 mm TRS plug like the Miniware TS80, although I don’t have a TS80 handy to test if the tips are actually compatible. For their part, iFixit says they plan on offering an array of styles and sizes of tips in addition to the 1.5 mm bevel that the Smart Soldering Iron ships with.</p>
<h3>Portable Power Station</h3>
<p>While it’s not required to use the Smart Soldering Iron, for the best experience, you’ll want to spring for the Portable Power Station. It’s essentially a 5,200 mAh battery bank capable of powering devices at 100 W, with a single USB-C port on the back for charging and two on the front for whatever devices you want to plug into it.</p>
<p>The trick is, once the Station detects you’ve plugged a Smart Soldering Iron into it, you’re given the ability to configure it via the OLED screen and rotary encoder on the front of the device. There’s even support for connecting a pair of Smart Soldering Irons to the Station, each with its own independent configuration. Though in that case, both would have to share the total 100 W output.</p>
<p><video id="video-706883-2" width="800" height="442" preload="metadata" controls="controls"><source type="video/mp4" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_station_demo.mp4?_=2"><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_station_demo.mp4">https://hackaday.com/wp-content/uploads/2024/09/fixhub_station_demo.mp4</a></video></p>
<p>Assuming a single Smart Soldering Iron, iFixit says you should expect to get up to eight hours of runtime from the Portable Power Station. Of course there are a lot of variables involved, so your mileage may vary. If you’re spending most of your time at the bench, you can keep the rear USB-C port connected to a Power Delivery charger and use it more or less like a traditional station.</p>
<h2>The Internet of Irons</h2>
<p>Plugging the Smart Soldering Iron into the Power Station is the most obvious way of tweaking its various settings, but as I mentioned earlier, it’s not the only way.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png" target="_blank"><img loading="lazy" decoding="async" data-attachment-id="706970" data-permalink="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/fixhub_web/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png" data-orig-size="636,945" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fixhub_web" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png?w=269" data-large-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png?w=421" tabindex="0" role="button" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png?w=421" alt="" width="310" height="461" srcset="https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png 636w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png?resize=168,250 168w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png?resize=269,400 269w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_web.png?resize=421,625 421w" sizes="(max-width: 310px) 100vw, 310px"></a></p>
<p>Maybe you don’t want to buy the Station, or you left it at home. In either event, you can simply plug the iron into your computer and <a href="https://hackaday.com/2022/03/21/web-serial-terminal-means-its-always-hacking-time/">configure it via WebSerial</a>.</p>
<p>You’ll need a browser based on Chrome to pull this trick off, as Mozilla has decided (at least, for now) to not include the capability in Firefox. In testing, it worked perfectly on both my Linux desktop and Chromebook.</p>
<p>Unfortunately, plugging the iron into your phone won’t work, as the mobile version of Chrome does not currently support WebSerial. But given the vertical layout of the interface and the big touch-friendly buttons, I can only assume that iFixit is either banking on this changing soon or has a workaround in mind. Being able to plug the iron into your phone for a quick settings tweak would be incredibly handy, so hopefully it will happen one way or another.</p>
<p>The WebSerial interface not only gives you access to all the same settings as plugging the iron into the Power Station does, but it also serves as the mechanism for updating the firmware on the iron.</p>
<p>Incidentally, the Power Station has it’s own nearly identical WebSerial interface. Primarily this would be used for upgrading the firmware, but it’s not hard to imagine that some users would prefer being able to change their settings on the big screen rather than having to squint at an OLED not much larger than their thumbnail.</p>
<h2>Solder At Your Command</h2>
<p>But wait! I hear those gears turning in your head. If the Smart Soldering Iron into the Power Station both feature WebSerial interfaces that let you play around with their settings, does that mean they might also offer a traditional serial interface for you to poke around in?</p>
<p><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png" target="_blank"><img loading="lazy" decoding="async" data-attachment-id="706978" data-permalink="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/fixhub_serial_border/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png" data-orig-size="842,946" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fixhub_serial_border" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png?w=356" data-large-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png?w=556" tabindex="0" role="button" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png" alt="" width="800" height="899" srcset="https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png 842w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png?resize=223,250 223w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png?resize=356,400 356w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_serial_border.png?resize=556,625 556w" sizes="(max-width: 800px) 100vw, 800px"></a></p>
<p>Hell yeah they do!</p>
<p>There was no mention of this terminal interface in any of the documentation I received from iFixit, but thanks to the built-in help function and tab completion, I was able to make my way around the various tools and functions. I never knew how badly I yearned to adjust the temperature on my soldering station from the command line before this moment. There’s clearly a lot of potential here, and I’m really looking forward to seeing what the community can come up given this level of control.</p>
<h2>A Look Under the Hood</h2>
<p>iFixit offered to give me a peek at the in-development repair guides for the Smart Soldering Iron and the Power Station, but I passed. For one thing, there’s no doubt in my mind that the finished product is going to be phenomenally detailed. Just look at any of their in-house guides, and you’ll know what to expect. But more to the point, I wanted to see how hard it would be to take the two devices apart without any guidance.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg" target="_blank"><img loading="lazy" decoding="async" data-attachment-id="706981" data-permalink="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/fixhub_iron_open/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg" data-orig-size="2000,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.89&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1726002228&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.43&quot;,&quot;iso&quot;:&quot;53&quot;,&quot;shutter_speed&quot;:&quot;0.016665&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fixhub_iron_open" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg?w=800" tabindex="0" role="button" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg" alt="" width="800" height="200" srcset="https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg 2000w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg?resize=250,63 250w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg?resize=400,100 400w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg?resize=800,200 800w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_iron_open.jpg?resize=1536,384 1536w" sizes="(max-width: 800px) 100vw, 800px"></a></p>
<p>I’m happy to report that the iron and its base station are some of the most easily dissembled devices I’ve ever come across. No glue, weird tape, or hidden fasteners. No little plastic tabs that break if you look at them the wrong way. Just two pieces of hardware that were designed and assembled in a logical enough way that you only need to look at them to understand how it all goes together.</p>
<p><a href="https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg" target="_blank"><img loading="lazy" decoding="async" data-attachment-id="706982" data-permalink="https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/fixhub_base_open/" data-orig-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg" data-orig-size="2000,1263" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D3300&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1726011451&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;30&quot;,&quot;iso&quot;:&quot;1400&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fixhub_base_open" data-image-description="" data-image-caption="" data-medium-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg?w=400" data-large-file="https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg?w=800" tabindex="0" role="button" src="https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg" alt="" width="800" height="505" srcset="https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg 2000w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg?resize=250,158 250w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg?resize=400,253 400w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg?resize=800,505 800w, https://hackaday.com/wp-content/uploads/2024/09/fixhub_base_open.jpg?resize=1536,970 1536w" sizes="(max-width: 800px) 100vw, 800px"></a></p>
<p>Of course, this should come as no surprise. Imagine the mud that would have been slung had iFixit had dropped the ball here. You can’t very well campaign for repairability if you don’t hold your own products to the same standards you do for everyone else. Presumably they designed the Smart Soldering Iron and the Power Station to <a href="https://www.ifixit.com/News/75533/how-ifixit-scores-repairability" target="_blank">hit a perfect ten by their published standards</a>, and from what I’ve seen, they nailed it.</p>
<p>I also got a look at the schematics, exploded diagrams, and parts list for both products. Like the repair guides, these won’t be made public until the hardware ships in October. But don’t worry, this isn’t some crowdsource bait-and-switch. They’ve got the goods, and it’s all very impressive.</p>
<p>Now to be clear, we’re not talking open source hardware here. Don’t expect to pull Gerbers from a GitHub repo so you can crank out your own Power Station. But the documentation they’re providing is remarkable for a consumer device. The schematics especially — they’re filled with all sorts of notes in the margins from the engineers which were fascinating to go through.</p>
<h2>Investing in the Future</h2>
<p>If I’ve not made it abundantly clear so far, iFixit really blew me away with the Portable Soldering System. I knew they would put a solid effort into the product from their reputation alone, but even still, I wasn’t expecting the hardware and software to be this polished. iFixit didn’t just raise the bar, they sent it into orbit.</p>
<p>But all this comes at a price. Literally. The Smart Soldering Iron alone will set you back $79.95, and if you want to get the Power Station along with it, the combo comes in at $249.95. You could get a nice soldering station from Weller or Hakko for half the price. Then again, it’s hard to compare what iFixit is offering here to anything else on the market.</p>
<p>In the end, this is one of those times when you’ve got to decide what’s really important to you. If you just want a quality soldering station, there are cheaper options that will meet all of your needs and then some. But if you want to support a company that’s working to change the status quo, sometimes you’ve got to reach a little deeper into those pockets.</p>
	            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1913: When Hitler, Trotsky, Tito, Freud and Stalin all lived in the same place (164 pts)]]></title>
            <link>https://www.bbc.com/news/magazine-21859771</link>
            <guid>41521824</guid>
            <pubDate>Thu, 12 Sep 2024 15:09:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/magazine-21859771">https://www.bbc.com/news/magazine-21859771</a>, See on <a href="https://news.ycombinator.com/item?id=41521824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="main-content" data-testid="main-content"><article><header data-component="legacy-header-block"></header><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/news/240/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 240w, https://ichef.bbci.co.uk/news/320/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 320w, https://ichef.bbci.co.uk/news/480/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 480w, https://ichef.bbci.co.uk/news/624/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 624w, https://ichef.bbci.co.uk/news/800/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 800w, https://ichef.bbci.co.uk/news/976/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 976w" type="image/jpeg"><img alt="Rooftops of Vienna about 1920" loading="eager" src="https://ichef.bbci.co.uk/news/624/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg" srcset="https://ichef.bbci.co.uk/news/240/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 240w, https://ichef.bbci.co.uk/news/320/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 320w, https://ichef.bbci.co.uk/news/480/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 480w, https://ichef.bbci.co.uk/news/624/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 624w, https://ichef.bbci.co.uk/news/800/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 800w, https://ichef.bbci.co.uk/news/976/mcs/media/images/67006000/jpg/_67006500_vienna-624getty.jpg 976w" width="624" height="450"></picture></span></p></figure></div><div data-component="text-block"><p><b>A century ago, one section of Vienna played host to Adolf Hitler, Leon Trotsky, Joseph Tito, Sigmund Freud and Joseph Stalin. </b></p><p>In January 1913, a man whose passport bore the name Stavros Papadopoulos disembarked from the Krakow train at Vienna's North Terminal station. </p><p>Of dark complexion, he sported a large peasant's moustache and carried a very basic wooden suitcase.</p><p>"I was sitting at the table," wrote the man he had come to meet, years later, "when the door opened with a knock and an unknown man entered.</p><p>"He was short... thin... his greyish-brown skin covered in pockmarks... I saw nothing in his eyes that resembled friendliness."</p><p>The writer of these lines was a dissident Russian intellectual, the editor of a radical newspaper called Pravda (Truth). His name was Leon Trotsky. </p></div><div data-component="text-block"><p>The man he described was not, in fact, Papadopoulos. </p><p>He had been born Iosif Vissarionovich Dzhugashvili, was known to his friends as Koba and is now remembered as Joseph Stalin.</p><p>Trotsky and Stalin were just two of a number of men who lived in central Vienna in 1913 and whose lives were destined to mould, indeed to shatter, much of the 20th century.</p><p>It was a disparate group. The two revolutionaries, Stalin and Trotsky, were on the run. Sigmund Freud was already well established. </p><p>The psychoanalyst, exalted by followers as the man who opened up the secrets of the mind, lived and practised on the city's Berggasse. </p><p>The young Josip Broz, later to find fame as Yugoslavia's leader Marshal Tito, worked at the Daimler automobile factory in Wiener Neustadt, a town south of Vienna, and sought employment, money and good times.</p><p>Then there was the 24-year-old from the north-west of Austria whose dreams of studying painting at the Vienna Academy of Fine Arts had been twice dashed and who now lodged in a doss-house in Meldermannstrasse near the Danube, one Adolf Hitler. </p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>The characters would have spent much time in these same two square miles of central Vienna</p></figcaption></figure></div><div data-component="text-block"><p>In his majestic evocation of the city at the time, Thunder at Twilight, Frederic Morton imagines Hitler haranguing his fellow lodgers "on morality, racial purity, the German mission and Slav treachery, on Jews, Jesuits, and Freemasons".</p><p>"His forelock would toss, his [paint]-stained hands shred the air, his voice rise to an operatic pitch. Then, just as suddenly as he had started, he would stop. He would gather his things together with an imperious clatter, [and] stalk off to his cubicle." </p></div><div data-component="text-block"><p>Presiding over all, in the city's rambling Hofburg Palace was the aged Emperor Franz Joseph, who had reigned since the great year of revolutions, 1848. </p><p>Archduke Franz Ferdinand, his designated successor, resided at the nearby Belvedere Palace, eagerly awaiting the throne. His assassination the following year would spark World War I. </p><p>Vienna in 1913 was the capital of the Austro-Hungarian Empire, which consisted of 15 nations and well over 50 million inhabitants. </p><p>"While not exactly a melting pot, Vienna was its own kind of cultural soup, attracting the ambitious from across the empire," says Dardis McNamee, editor-in-chief of the Vienna Review, Austria's only English-language monthly, who has lived in the city for 17 years.</p><p>"Less than half of the city's two million residents were native born and about a quarter came from Bohemia (now the western Czech Republic) and Moravia (now the eastern Czech Republic), so that Czech was spoken alongside German in many settings." </p><p>The empire's subjects spoke a dozen languages, she explains. </p><p>"Officers in the Austro-Hungarian Army had to be able to give commands in 11 languages besides German, each of which had an official translation of the National Hymn."</p><p>And this unique melange created its own cultural phenomenon, the Viennese coffee-house. Legend has its genesis in sacks of coffee left by the Ottoman army following the failed Turkish siege of 1683.</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Cafe Landtmann, much frequented by Freud, remains popular to this day</p></figcaption></figure></div><div data-component="text-block"><p>"Cafe culture and the notion of debate and discussion in cafes is very much part of Viennese life now and was then," explains Charles Emmerson, author of 1913: In Search of the World Before the Great War and a senior research fellow at the foreign policy think-tank Chatham House.</p><p>"The Viennese intellectual community was actually quite small and everyone knew each other and... that provided for exchanges across cultural frontiers."</p><p>This, he adds, would favour political dissidents and those on the run. </p><p>"You didn't have a tremendously powerful central state. It was perhaps a little bit sloppy. If you wanted to find a place to hide out in Europe where you could meet lots of other interesting people then Vienna would be a good place to do it."</p><p>Freud's favourite haunt, the Cafe Landtmann, still stands on the Ring, the renowned boulevard which surrounds the city's historic Innere Stadt. </p><p>Trotsky and Hitler frequented Cafe Central, just a few minutes' stroll away, where cakes, newspapers, chess and, above all, talk, were the patrons' passions.</p><p>"Part of what made the cafes so important was that 'everyone' went," says MacNamee. "So there was a cross-fertilisation across disciplines and interests, in fact boundaries that later became so rigid in western thought were very fluid."</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Both Trotsky and Hitler sipped coffee under Cafe Central's magnificent arches</p></figcaption></figure></div><div data-component="text-block"><p>Beyond that, she adds, "was the surge of energy from the Jewish intelligentsia, and new industrialist class, made possible following their being granted full citizenship rights by Franz Joseph in 1867, and full access to schools and universities."</p><p>And, though this was still a largely male-dominated society, a number of women also made an impact. </p><p>Alma Mahler, whose composer husband had died in 1911, was also a composer and became the muse and lover of the artist Oskar Kokoschka and the architect Walter Gropius.</p><p>Though the city was, and remains, synonymous with music, lavish balls and the waltz, its dark side was especially bleak. Vast numbers of its citizens lived in slums and 1913 saw nearly 1,500 Viennese take their own lives.</p><p>No-one knows if Hitler bumped into Trotsky, or Tito met Stalin. But works like Dr Freud Will See You Now, Mr Hitler - a 2007 radio play by Laurence Marks and Maurice Gran - are lively imaginings of such encounters.</p><p>The conflagration which erupted the following year destroyed much of Vienna's intellectual life. </p><p>The empire imploded in 1918, while propelling Hitler, Stalin, Trotsky and Tito into careers that would mark world history forever.</p><p><i>You can hear more about Vienna's role in shaping the 20th Century on </i><a href="http://www.bbc.co.uk/programmes/b006qj9z">BBC Radio 4's Today</a><i> programme on 18 April.</i></p><p><i>You can follow the Magazine on </i><a href="https://twitter.com/BBCNewsMagazine">Twitter<span>, <!-- -->external</span></a><i> and on </i><a href="http://www.facebook.com/BBCMagazine">Facebook<span>, <!-- -->external</span></a></p></div><section data-component="related-internet-links"><p><h2 type="normal">Related internet links</h2></p><ul role="list" spacing="responsive"><li></li><li></li></ul><p>The BBC is not responsible for the content of external sites.</p></section></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unity is cancelling the runtime fee (131 pts)]]></title>
            <link>https://unity.com/blog/unity-is-canceling-the-runtime-fee</link>
            <guid>41521630</guid>
            <pubDate>Thu, 12 Sep 2024 14:49:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unity.com/blog/unity-is-canceling-the-runtime-fee">https://unity.com/blog/unity-is-canceling-the-runtime-fee</a>, See on <a href="https://news.ycombinator.com/item?id=41521630">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>"Unity", Unity logos, and other Unity trademarks are trademarks or registered trademarks of Unity Technologies or its affiliates in the U.S. and elsewhere (<a href="https://unity.com/legal/trademarks">more info here</a>). Other names or brands are trademarks of their respective owners.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GAZEploit: Remote keystroke inference attack by gaze estimation in VR/MR devices (140 pts)]]></title>
            <link>https://www.wired.com/story/apple-vision-pro-persona-eye-tracking-spy-typing/</link>
            <guid>41520516</guid>
            <pubDate>Thu, 12 Sep 2024 13:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/apple-vision-pro-persona-eye-tracking-spy-typing/">https://www.wired.com/story/apple-vision-pro-persona-eye-tracking-spy-typing/</a>, See on <a href="https://news.ycombinator.com/item?id=41520516">Hacker News</a></p>
Couldn't get https://www.wired.com/story/apple-vision-pro-persona-eye-tracking-spy-typing/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Old Easter Island genomes show no sign of a population collapse (105 pts)]]></title>
            <link>https://arstechnica.com/science/2024/09/old-easter-island-genomes-show-no-sign-of-a-population-collapse/</link>
            <guid>41520465</guid>
            <pubDate>Thu, 12 Sep 2024 13:05:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2024/09/old-easter-island-genomes-show-no-sign-of-a-population-collapse/">https://arstechnica.com/science/2024/09/old-easter-island-genomes-show-no-sign-of-a-population-collapse/</a>, See on <a href="https://news.ycombinator.com/item?id=41520465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-2068621148-800x450.jpg" alt="A row of grey rock sculptures of human torsos and heads, arranged in a long line.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 52:single/related:a94418b30b77f79141491c7284bb2c6e --><!-- empty -->
<p>Rapa Nui, often referred to as Easter Island, is one of the most remote populated islands in the world. It's so distant that Europeans didn't stumble onto it until centuries after they had started exploring the Pacific. When they arrived, though, they found that the relatively small island supported a population of thousands, one that had built imposing monumental statues called moai. Arguments over how this population got there and what happened once it did have gone on ever since.</p>
<p>Some of these arguments, such as the idea that the island's indigenous people had traveled there from South America, have since been put to rest. Genomes from people native to the island show that its original population was part of the Polynesian expansion across the Pacific. But others, such as the role of ecological collapse in limiting the island's population and altering its culture, continue to be <a href="https://arstechnica.com/science/2024/06/we-now-have-even-more-evidence-against-the-ecocide-theory-of-easter-island/">debated</a>.</p>
<p>Researchers have now obtained genome sequence from the remains of 15 Rapa Nui natives who predate European contact. And they indicate that the population of the island appears to have grown slowly and steadily, without any sign of a bottleneck that could be associated with an ecological collapse. And roughly 10 percent of the genomes appear to have a Native American source that likely dates from roughly the same time that the island was settled.</p>
<h2>Out of the museum</h2>
<p>The remains that provided these genomes weren't found on Rapa Nui, at least not recently. Instead, they reside at the Muséum National d’Histoire Naturelle in France, having been obtained at some uncertain point in the past. Their presence there is a point of contention for the indigenous people of Rapa Nui, but the researchers behind the new work had the cooperation of the islanders in this project, having worked with them extensively. The researchers' description of these interactions could be viewed as a model for how this sort of work should be done:</p>
<blockquote><p>Throughout the course of the study, we met with representatives of the Rapanui community on the island, the Comisión de Desarrollo Rapa Nui and the Comisión Asesora de Monumentos Nacionales, where we presented our research goals and ongoing results. Both commissions voted in favor of us continuing with the research... We presented the research project in public talks, a short video and radio interviews on the island, giving us the opportunity to inquire about the questions that are most relevant to the Rapanui community. These discussions have informed the research topics we investigated in this work.</p></blockquote>
<p>Given the questionable record-keeping at various points in the past, one of the goals of this work was simply to determine whether these remains truly had originated on Rapa Nui. That was unambiguously true. All comparisons with genomes of modern populations show that all 15 of these genomes have a Polynesian origin and are most closely related to modern residents of Rapa Nui. "The confirmation of the origin of these individuals through genomic analyses will inform repatriation efforts led by the Rapa Nui Repatriation Program (Ka Haka Hoki Mai Te Mana Tupuna)," the authors suggest.</p>                                                                        
                                                                                
<p>A second question was whether the remains predate European contact. The researchers attempted to perform carbon dating, but it produced dates that made no sense. Some of the remains had dates that were potentially <em>after</em> they had been collected, according to museum records. And all of them were from the 1800s, well after European contact and introduced diseases had shrunk the native population and mixed in DNA from non-Polynesians. Yet none of the genomes showed more than one percent European ancestry, a fraction low enough to be ascribed to a spurious statistical fluke.</p>
<p>So the precise date these individuals lived is uncertain. But the genetic data clearly indicates that they were born prior to the arrival of Europeans. They can therefore tell us about what the population was experiencing in the period between Rapa Nui's settlement and the arrival of colonial powers.</p>
<h2>Back from the Americas</h2>
<p>While these genomes showed no sign of European ancestry, they were not fully Polynesian. Instead, roughly 10 percent of the genome appeared to be derived from a Native American population. This is the highest percentage seen in any Polynesian population, including some that <a href="https://arstechnica.com/science/2020/07/genetic-data-suggests-polynesians-and-native-americans-met/">show hints of Native American contact</a> that dates to before Europeans arrived on the scene.</p>
<p>Isolating these DNA sequences and comparing them to populations from across the world showed that the group most closely related to the one who contributed to the Rapa Nui population presently resides in the central Andes region of South America. That's in contrast to the earlier results, which suggested the contact was with populations further north in South America.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Officer who ignored NYPD's 'courtesy cards' receives $175K settlement (146 pts)]]></title>
            <link>https://apnews.com/article/nypd-courtesy-card-police-misconduct-d5dfdbdad12b01a2cda864f69aa3d1aa</link>
            <guid>41519736</guid>
            <pubDate>Thu, 12 Sep 2024 11:47:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/nypd-courtesy-card-police-misconduct-d5dfdbdad12b01a2cda864f69aa3d1aa">https://apnews.com/article/nypd-courtesy-card-police-misconduct-d5dfdbdad12b01a2cda864f69aa3d1aa</a>, See on <a href="https://news.ycombinator.com/item?id=41519736">Hacker News</a></p>
Couldn't get https://apnews.com/article/nypd-courtesy-card-police-misconduct-d5dfdbdad12b01a2cda864f69aa3d1aa: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX Astronauts Begin Spacewalk, Putting New Spacesuits to Test (197 pts)]]></title>
            <link>https://www.wsj.com/science/space-astronomy/spacex-launch-polaris-dawn-space-walk-bfed7f84</link>
            <guid>41519623</guid>
            <pubDate>Thu, 12 Sep 2024 11:30:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/science/space-astronomy/spacex-launch-polaris-dawn-space-walk-bfed7f84">https://www.wsj.com/science/space-astronomy/spacex-launch-polaris-dawn-space-walk-bfed7f84</a>, See on <a href="https://news.ycombinator.com/item?id=41519623">Hacker News</a></p>
Couldn't get https://www.wsj.com/science/space-astronomy/spacex-launch-polaris-dawn-space-walk-bfed7f84: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ergo: Erlang-inspired event driven actor framework in Go (136 pts)]]></title>
            <link>https://github.com/ergo-services/ergo</link>
            <guid>41519471</guid>
            <pubDate>Thu, 12 Sep 2024 11:06:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ergo-services/ergo">https://github.com/ergo-services/ergo</a>, See on <a href="https://news.ycombinator.com/item?id=41519471">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://ergo.services/" rel="nofollow"><img src="https://github.com/ergo-services/ergo/raw/master/.github/images/logo.svg" alt="Ergo Framework" width="159" height="49"></a></h2><a id="" aria-label="Permalink: " href="#"></a></div>
<p dir="auto"><a href="https://docs.ergo.services/" rel="nofollow"><img src="https://camo.githubusercontent.com/d8f2c27f511059ee8a4c1d56dd43bb9e2774ef4b78044f4a7a79aa179c4e3339/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476974426f6f6b2d446f63756d656e746174696f6e2d6633376634303f7374796c653d706c6173746963266c6f676f3d676974626f6f6b266c6f676f436f6c6f723d7768697465267374796c653d666c6174" alt="Gitbook Documentation" data-canonical-src="https://img.shields.io/badge/GitBook-Documentation-f37f40?style=plastic&amp;logo=gitbook&amp;logoColor=white&amp;style=flat"></a>
<a href="https://pkg.go.dev/ergo.services/ergo" rel="nofollow"><img src="https://camo.githubusercontent.com/bd896ed06160fe0e621b6b2997f20b8d9dfb222d79617cc9cccd9af3db7b1f69/68747470733a2f2f706b672e676f2e6465762f62616467652f6572676f2d73657276696365732f6572676f" alt="GoDoc" data-canonical-src="https://pkg.go.dev/badge/ergo-services/ergo"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/2c688e7decdaf0ee046dbefbf1bfeff0500b962e151b1a606d791f8f2e9f54c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d627269676874677265656e2e737667" alt="MIT license" data-canonical-src="https://img.shields.io/badge/license-MIT-brightgreen.svg"></a>
<a href="https://t.me/ergo_services" rel="nofollow"><img src="https://camo.githubusercontent.com/cce21c76f2dde10c8fb5595003bb4b8933b22676aaf29397bf0fcd5cb417ed8f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f54656c656772616d2d6572676f5f5f73657276696365732d3232396564393f7374796c653d666c6174266c6f676f3d74656c656772616d266c6f676f436f6c6f723d7768697465" alt="Telegram Community" data-canonical-src="https://img.shields.io/badge/Telegram-ergo__services-229ed9?style=flat&amp;logo=telegram&amp;logoColor=white"></a>
<a href="https://x.com/ergo_services" rel="nofollow"><img src="https://camo.githubusercontent.com/e8b4ce62f4932487dc85a8b6bd5442c76fc8e9fa6d029f7145f30ec4c31d49dc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f747769747465722d6572676f5f5f73657276696365732d3030616365653f7374796c653d666c6174266c6f676f3d78266c6f676f436f6c6f723d7768697465" alt="Twitter" data-canonical-src="https://img.shields.io/badge/twitter-ergo__services-00acee?style=flat&amp;logo=x&amp;logoColor=white"></a>
<a href="https://reddit.com/r/ergo_services" rel="nofollow"><img src="https://camo.githubusercontent.com/3f5c5b45660461a2063fc75b9805d934fa5a15d96aca030a0d8ca1caa4bb7ed9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5265646469742d722f6572676f5f5f73657276696365732d6666343530303f7374796c653d706c6173746963266c6f676f3d726564646974266c6f676f436f6c6f723d7768697465267374796c653d666c6174" alt="Reddit" data-canonical-src="https://img.shields.io/badge/Reddit-r/ergo__services-ff4500?style=plastic&amp;logo=reddit&amp;logoColor=white&amp;style=flat"></a></p>
<p dir="auto">The Ergo Framework is an implementation of ideas, technologies, and design patterns from the Erlang world in the Go programming language. It is based on the actor model, network transparency, and a set of ready-to-use components for development. This significantly simplifies the creation of complex and distributed solutions while maintaining a high level of reliability and performance.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Actor Model</strong>: enables the creation of scalable and fault-tolerant systems using isolated actors that interact through message passing. Actors can exchange asynchronous messages as well as perform synchronous requests, offering flexibility in communication patterns.</p>
</li>
<li>
<p dir="auto"><strong>Network Transparency</strong>: actors can interact regardless of their physical location, supported by a <a href="https://github.com/ergo-services/benchmarks">high-performance</a> implementation of the <a href="https://docs.ergo.services/networking/network-stack" rel="nofollow">network stack</a>, which simplifies the creation of distributed systems.</p>
</li>
<li>
<p dir="auto"><strong>Observability</strong>: framework includes built-in observability features, including <a href="https://docs.ergo.services/networking/service-discovering" rel="nofollow">service discovery</a> and <a href="https://docs.ergo.services/networking/static-routes" rel="nofollow">static routes</a>, allowing nodes to automatically register themselves and find routes to remote nodes. This mechanism simplifies managing distributed systems by enabling seamless communication and interaction between nodes across the network.</p>
</li>
<li>
<p dir="auto"><strong>Ready-to-use Components</strong>: A set of <a href="https://docs.ergo.services/actors" rel="nofollow">ready-to-use actors</a> simplifying development, including state management and error handling.</p>
</li>
<li>
<p dir="auto"><strong>Support for Distributed Systems</strong>: framework includes built-in mechanisms for creating and managing clustered systems, <a href="https://docs.ergo.services/basics/events" rel="nofollow">distributed events</a> (publish/subscribe mechanism), <a href="https://docs.ergo.services/networking/remote-spawn-process" rel="nofollow">remote actor spawning</a>, and <a href="https://docs.ergo.services/networking/remote-start-application" rel="nofollow">remote application startup</a>. These features enable easy scaling, efficient message broadcasting across your cluster, and the ability to manage distributed components seamlessly.</p>
</li>
<li>
<p dir="auto"><strong>Reliability and Fault Tolerance</strong>: the framework is designed to minimize failures and ensure automatic recovery, featuring a <a href="https://docs.ergo.services/basics/supervision-tree" rel="nofollow">supervisor tree</a> structure to manage and <a href="https://docs.ergo.services/actors/supervisor#restart-strategy" rel="nofollow">restart failed actors</a>, which is crucial for mission-critical applications.</p>
</li>
<li>
<p dir="auto"><strong>Flexibility</strong>: This framework offers convenient interfaces for customizing <a href="https://docs.ergo.services/networking/network-stack#network-stack-interfaces" rel="nofollow">network stack components</a>, creating and integrating custom <a href="https://docs.ergo.services/basics/logging" rel="nofollow">loggers</a>, <a href="https://docs.ergo.services/basics/certmanager" rel="nofollow">managing SSL certificates</a>, and more.</p>
</li>
</ol>
<p dir="auto">In the <a href="https://github.com/ergo-services/examples">https://github.com/ergo-services/examples</a> repository, you will find examples that demonstrate a range of the framework's capabilities.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Observer</h3><a id="user-content-observer" aria-label="Permalink: Observer" href="#observer"></a></p>
<p dir="auto">To inspect the node, network stack, running applications, and processes, you can use the <a href="https://github.com/ergo-services/tools/"><code>observer</code></a> tool</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/118860/357791972-1cb83305-6c56-4eb7-b567-76f3c551c176.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjYxNjYxMDksIm5iZiI6MTcyNjE2NTgwOSwicGF0aCI6Ii8xMTg4NjAvMzU3NzkxOTcyLTFjYjgzMzA1LTZjNTYtNGViNy1iNTY3LTc2ZjNjNTUxYzE3Ni5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxMlQxODMwMDlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mMjE0M2VhZDJhMTQ1MTAyZTVlYTU1YTFiMTI3NzNkNGFhYWM5MDIzNDIyYmZlNTBiZWU4ZDc3ODNlYzYwMGZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.4nLzUebhkQoM2U603oSXe7OopIBwBQbJnE1hdEcDj1U"><img src="https://private-user-images.githubusercontent.com/118860/357791972-1cb83305-6c56-4eb7-b567-76f3c551c176.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjYxNjYxMDksIm5iZiI6MTcyNjE2NTgwOSwicGF0aCI6Ii8xMTg4NjAvMzU3NzkxOTcyLTFjYjgzMzA1LTZjNTYtNGViNy1iNTY3LTc2ZjNjNTUxYzE3Ni5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxMlQxODMwMDlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mMjE0M2VhZDJhMTQ1MTAyZTVlYTU1YTFiMTI3NzNkNGFhYWM5MDIzNDIyYmZlNTBiZWU4ZDc3ODNlYzYwMGZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.4nLzUebhkQoM2U603oSXe7OopIBwBQbJnE1hdEcDj1U" width="500"></a>
<p dir="auto">To install the Observer tool, you need to have the Go compiler version 1.20 or higher. Run the following command:</p>
<div data-snippet-clipboard-copy-content="$ go install ergo.services/tools/observer@latest"><pre><code>$ go install ergo.services/tools/observer@latest
</code></pre></div>
<p dir="auto">You can also embed the <a href="https://docs.ergo.services/extra-library/applications/observer" rel="nofollow">Observer application</a> into your node. To see it in action, see example <code>demo</code> at <a href="https://github.com/ergo-services/examples">https://github.com/ergo-services/examples</a>. For more information <a href="https://docs.ergo.services/tools/observer" rel="nofollow">https://docs.ergo.services/tools/observer</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick start</h3><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<p dir="auto">For a quick start, use the <a href="https://docs.ergo.services/tools/ergo" rel="nofollow"><code>ergo</code></a> tool — a command-line utility designed to simplify the process of generating boilerplate code for your project based on the Ergo Framework. With this tool, you can rapidly create a complete project structure, including applications, actors, supervisors, network components, and more. It offers a set of arguments that allow you to customize the project according to specific requirements, ensuring it is ready for immediate development.</p>
<p dir="auto">To install use the following command:</p>
<div data-snippet-clipboard-copy-content="$ go install ergo.services/tools/ergo@latest"><pre><code>$ go install ergo.services/tools/ergo@latest
</code></pre></div>
<p dir="auto">Now, you can create your project with just one command. Here is example:</p>
<p dir="auto">Supervision tree</p>
<div data-snippet-clipboard-copy-content="  mynode
  ├─ myapp
  │  │
  │  └─ mysup
  │     │
  │     └─ myactor
  ├─ myweb
  └─ myactor2"><pre><code>  mynode
  ├─ myapp
  │  │
  │  └─ mysup
  │     │
  │     └─ myactor
  ├─ myweb
  └─ myactor2
</code></pre></div>
<p dir="auto">To generate project for this design use the following command:</p>
<div data-snippet-clipboard-copy-content="$ ergo -init MyNode \
      -with-app MyApp \
      -with-sup MyApp:MySup \
      -with-actor MySup:MyActor \
      -with-web MyWeb \
      -with-actor MyActor2 \
      -with-observer "><pre><code>$ ergo -init MyNode \
      -with-app MyApp \
      -with-sup MyApp:MySup \
      -with-actor MySup:MyActor \
      -with-web MyWeb \
      -with-actor MyActor2 \
      -with-observer 
</code></pre></div>
<p dir="auto">as a result you will get generated project:</p>
<div data-snippet-clipboard-copy-content="  mynode
  ├── apps
  │  └── myapp
  │     ├── myactor.go
  │     ├── myapp.go
  │     └── mysup.go
  ├── cmd
  │  ├── myactor2.go
  │  ├── mynode.go
  │  ├── myweb.go
  │  └── myweb_worker.go
  ├── go.mod
  ├── go.sum
  └── README.md"><pre><code>  mynode
  ├── apps
  │  └── myapp
  │     ├── myactor.go
  │     ├── myapp.go
  │     └── mysup.go
  ├── cmd
  │  ├── myactor2.go
  │  ├── mynode.go
  │  ├── myweb.go
  │  └── myweb_worker.go
  ├── go.mod
  ├── go.sum
  └── README.md
</code></pre></div>
<p dir="auto">to try it:</p>
<div data-snippet-clipboard-copy-content="$ cd mynode
$ go run ./cmd"><pre><code>$ cd mynode
$ go run ./cmd
</code></pre></div>
<p dir="auto">Since we included Observer application, open <a href="http://localhost:9911/" rel="nofollow">http://localhost:9911</a> to inspect your node and running processes.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Erlang support</h3><a id="user-content-erlang-support" aria-label="Permalink: Erlang support" href="#erlang-support"></a></p>
<p dir="auto">Starting from version 3.0.0, support for the Erlang network stack has been moved to a separate module and is distributed under the BSL 1.1 license - <a href="https://github.com/ergo-services/proto">https://github.com/ergo-services/proto</a>. You can find detailed information on using this module in the documentation at <a href="https://docs.ergo.services/extra-library/network-protocols/erlang" rel="nofollow">https://docs.ergo.services/extra-library/network-protocols/erlang</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Requirements</h3><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>Go 1.20.x and above</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Changelog</h3><a id="user-content-changelog" aria-label="Permalink: Changelog" href="#changelog"></a></p>
<p dir="auto">Fully detailed changelog see in the <a href="https://github.com/ergo-services/ergo/blob/master/CHANGELOG.md">ChangeLog</a> file.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><a href="https://github.com/ergo-services/ergo/releases/tag/v1.999.300">v3.0.0</a> 2024-09-04 [tag version v1.999.300]</h4><a id="user-content-v300-2024-09-04-tag-version-v1999300" aria-label="Permalink: v3.0.0 2024-09-04 [tag version v1.999.300]" href="#v300-2024-09-04-tag-version-v1999300"></a></p>
<p dir="auto">This version marks a significant milestone in the evolution of the Ergo Framework. The framework's design has been completely overhauled, and this version was built from the ground up. It includes:</p>
<ul dir="auto">
<li>Significant API Improvements: The <code>gen.Process</code>, <code>gen.Node</code>, and <code>gen.Network</code> interfaces have been enhanced with numerous convenient methods.</li>
<li>A New Network Stack: This version introduces a completely new network stack for improved performance and flexibility. See <a href="https://github.com/ergo-services/benchmarks">https://github.com/ergo-services/benchmarks</a> for the details</li>
</ul>
<p dir="auto">Alongside the release of Ergo Framework 3.0.0, new tools and an additional components library are also introduced:</p>
<ul dir="auto">
<li>Tools (observer, saturn) <a href="https://github.com/ergo-services/tools">https://github.com/ergo-services/tools</a></li>
<li>Loggers (rotate, colored) - <a href="https://github.com/ergo-services/logger">https://github.com/ergo-services/logger</a></li>
<li>Meta (websocket) - <a href="https://github.com/ergo-services/meta">https://github.com/ergo-services/meta</a></li>
<li>Application (observer) - <a href="https://github.com/ergo-services/application">https://github.com/ergo-services/application</a></li>
<li>Registrar (client Saturn) - <a href="https://github.com/ergo-services/registrar">https://github.com/ergo-services/registrar</a></li>
<li>Proto (erlang23) - <a href="https://github.com/ergo-services/proto">https://github.com/ergo-services/proto</a></li>
</ul>
<p dir="auto">Finally, we've published comprehensive documentation for the framework, providing detailed guides to assist you in leveraging all the capabilities of Ergo Framework effectively. Its available at <a href="https://docs.ergo.services/" rel="nofollow">https://docs.ergo.services</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Benchmarks</h3><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">You can find available benchmarks in the following repository <a href="https://github.com/ergo-services/benchmarks">https://github.com/ergo-services/benchmarks</a>.</p>
<ul dir="auto">
<li>
<p dir="auto">Messaging performance (local, network)</p>
</li>
<li>
<p dir="auto">Memory consumption per process (demonstrates framework memory footprint).</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development and debugging</h3><a id="user-content-development-and-debugging" aria-label="Permalink: Development and debugging" href="#development-and-debugging"></a></p>
<p dir="auto">To enable Golang profiler just add <code>--tags debug</code> in your <code>go run</code> or <code>go build</code> (profiler runs at
<code>http://localhost:9009/debug/pprof</code>)</p>
<p dir="auto">To disable panic recovery use <code>--tags norecover</code>.</p>
<p dir="auto">To enable trace logging level for the internals (node, network,...) use <code>--tags trace</code> and set the log level <code>gen.LogLevelTrace</code> for your node.</p>
<p dir="auto">To run tests with cleaned test cache:</p>
<div data-snippet-clipboard-copy-content="go vet
go clean -testcache
go test -v ./tests/..."><pre><code>go vet
go clean -testcache
go test -v ./tests/...
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Commercial support</h3><a id="user-content-commercial-support" aria-label="Permalink: Commercial support" href="#commercial-support"></a></p>
<p dir="auto">please, contact <a href="mailto:support@ergo.services">support@ergo.services</a> for more information</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kolmogorov-Arnold networks may make neural networks more understandable (208 pts)]]></title>
            <link>https://www.quantamagazine.org/novel-architecture-makes-neural-networks-more-understandable-20240911/</link>
            <guid>41519240</guid>
            <pubDate>Thu, 12 Sep 2024 10:14:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/novel-architecture-makes-neural-networks-more-understandable-20240911/">https://www.quantamagazine.org/novel-architecture-makes-neural-networks-more-understandable-20240911/</a>, See on <a href="https://news.ycombinator.com/item?id=41519240">Hacker News</a></p>
Couldn't get https://www.quantamagazine.org/novel-architecture-makes-neural-networks-more-understandable-20240911/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why Haskell? (285 pts)]]></title>
            <link>https://www.gtf.io/musings/why-haskell</link>
            <guid>41518600</guid>
            <pubDate>Thu, 12 Sep 2024 08:06:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gtf.io/musings/why-haskell">https://www.gtf.io/musings/why-haskell</a>, See on <a href="https://news.ycombinator.com/item?id=41518600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-pos="3:1-10:0">“Impractical”, “academic”, “niche”. These are a few of the reactions I get when someone discovers that my favourite programming language is Haskell, and not only my favourite in some sort of intellectually-masturbatory way, but favourite for building things, real things, mostly involving web servers. Hobby projects would be one thing, but it gets worse: I have actual teams at <a href="https://www.converge.io/">Converge</a> working in Haskell, too.</p>
<p data-pos="11:1-20:0">I find this reaction quite curious: not only can any problem suitable to one general-purpose programming language be tackled in another, but a lot of the new features we see making their way into programming languages like Python, Rust, and Typescript, are either inspired by, or at least more robustly implemented in, Haskell. It seems to me that part of this response is a version of “choose boring technology” (although Haskell is far older than most of the most popular programming languages) twisted to suit another pernicious ideology: that programming is not maths, and that anything that smells of maths should be excised.</p>
<p data-pos="21:1-26:0">This comes up in all sorts of unlikely places in which it would be quite awkward to have to take my interlocutors through all the reasons I think Haskell is probably the best choice for whatever computational problems they are trying to solve themselves (e.g. dinner parties, the pub, etc.) and thus I find myself writing this apologia.</p>
<p data-pos="27:1-33:0">Indeed the remainder of this essay will consist of my attempt to reason around why I think Haskell is probably the best choice<a id="fnref1" href="#fn1" role="doc-noteref"><sup>1</sup></a> for most programmers<a id="fnref2" href="#fn2" role="doc-noteref"><sup>2</sup></a>, especially if one cares about being able to productively write robust software, and even more so if one wants to have fun while doing it (which is a frequently underrated aspect of writing software).</p>
<p data-pos="34:1-41:0">All mainstream, general purpose programming languages are (basically) Turing-complete, and therefore any programme you can write in one you can, in fact, write in another. There is a computational equivalence between them. The main differences are instead in the expressiveness of the languages, the guardrails they give you, and their performance characteristics (although this is possibly more of a runtime/compiler implementation question).</p>
<p data-pos="42:1-46:0">I think that the things that make Haskell great (meaning both more productive and more fun) can be grouped as follows: the things that stop you making mistakes; the things that make you more productive; and the things that help you reason better about your programmes.</p>
<section data-pos="47:1-101:0" id="Unlearning-and-relearning">
<h2 data-pos="47:1-48:0">Unlearning and relearning</h2>
<p data-pos="49:1-57:0">The first thing to say here is that most programmers in the 2020s have been brought up in some sort of imperative<a id="fnref3" href="#fn3" role="doc-noteref"><sup>3</sup></a> paradigm. As a result, the learning curve for a pure, functional language like Haskell will be steep. There are two aspects to this: one is the Haskell language <em>itself</em> which, if you constrain yourself to a simple subset of it, is actually quite easy to learn; and the second is functional programming, which requires a total shift in how the programmer approaches constructing a programme.</p>
<p data-pos="58:1-61:0">This process of unlearning and relearning is incredibly helpful and will make one a better programmer, regardless as to whether one uses Haskell thenceforth. As Alan Perlis writes:</p>
<blockquote data-pos="62:1-64:30">
<p data-pos="62:3-64:30">A language that doesn’t affect the way you think about programming is not worth knowing. ~ Perlisism #19 <a id="fnref4" href="#fn4" role="doc-noteref"><sup>4</sup></a></p>
</blockquote>
<section data-pos="66:1-101:0" id="A-small-note-on-syntax">
<h3 data-pos="66:1-67:0">A small note on syntax</h3>
<p data-pos="68:1-71:0">In the subsequent sections there will be simple snippets of Haskell. Since the syntax is quite distant from C-like syntax with which many readers will be familiar, here is a small guide:</p>
<ul data-pos="72:1-98:0">
<li>
<code>::</code> denotes a type signature (so <code>myThing :: String</code> says I have a name “myThing” and its value is of type <code>String</code>).
</li>
<li>
function calls do not use parentheses, you simply put the arguments, space-separated, after the function name. There are good reasons for this, but they’re beyond the scope of this explainer (so where in one language you may have <code>doSomething(withThis, withThat)</code> in Haskell you have <code>doSomething withThis withThat</code>).
</li>
<li>
lower-case letters in type-signatures are type-variables, and just represent any type (so <code>head :: [a] -&gt; a</code> just takes a list of any type <code>a</code> and returns a single value of the same type <code>a</code>).
</li>
<li>
you will see two types of “forward” arrows: <code>-&gt;</code> and <code>=&gt;</code>. A single arrow <code>-&gt;</code> is used to describe the type of a function: <code>add1 :: Int -&gt;
Int</code> describes a function which takes an integer and returns an integer. A double arrow <code>=&gt;</code> describes constraints on the type variables used, and always come first: <code>add1 :: Num a =&gt; a -&gt; a</code> describes a function which takes any type <code>a</code> which satisfies <code>Num a</code>, and returns a value of the same type.
</li>
<li>
comments start with <code>--</code>.
</li>
<li>
<code>return</code> does not mean what you think it means, it’s just a regular function.
</li>
<li>
<code>do</code> is syntactic sugar allowing you to write things that “look” imperative.
</li>
<li>
There are various ways of assigning values to local names (“variables”) which differ depending on the context. So you can recognise them they either take the form <code>let x = &lt;something&gt; in
&lt;expression&gt;</code> or <code>x &lt;- &lt;something&gt;</code>.
</li>
</ul>
<p data-pos="98:1-101:0">Otherwise the syntax should be fairly easy to parse, if not for a detailed understanding of every aspect, at least to a sufficient level to get the gist of what I am trying to convey.</p>
</section>
</section>
<section data-pos="102:1-611:0" id="Make-fewer-mistakes">
<h2 data-pos="102:1-103:0">Make fewer mistakes</h2>
<p data-pos="104:1-108:0">In many languages, the way one tries to make sure one’s code is “correct” (or, at least, will do the right thing in most circumstances) is through a large number of test cases, some of which may be automated, and some of which may be manual.</p>
<p data-pos="109:1-112:0">Two aspects of Haskell drastically reduce the test-case-writing burden typical in other languages: one is the type system and the other is pure functional programming.</p>
<p data-pos="113:1-121:0">Haskell’s type system is <em>very</em> strong, which is to say that it makes very specific guarantees about the programme, and enforces those guarantees very strictly. The concomitant expressiveness of the language gives the programmer the tools to more precisely and simply express the <em>meaning</em> of the programme within its domain, as well as the general domain of programming. These two properties of the type system, together, reduce the space of possible mistakes, resulting in a more correct programme with much less effort.</p>
<p data-pos="122:1-127:0">So far, so abstract. Some concrete features of the type system that reduce the “error surface” of your programme are: no nullable types; the ability to represent “failable” computations; pattern matching and completeness checks; and the avoidance of “primitive obsession” for free. Let’s take a look at each of those.</p>
<p data-pos="128:1-146:0">The availability of a <code>null</code> (or <code>nil</code> or <code>none</code>) value which can inhabit any (or the majority) of types in a language is often viewed as a convenience, but in practice it has a huge cost. In a language in which one can use such null values, the programmer can never know if the value they are handling is actually of the expected type or if it is null, and therefore is required to check wherever this value is consumed. Programmers can forget things, and the fact that the null value can inhabit many types means that the type system does not help prevent this, leading to errors of the sort “undefined is not a function” or “NoneType object has no attribute &lt;x&gt;”. These, however, are runtime errors, which both means that the programme has failed in its principal task and also that the errors are harder to find as they occur in the wild. Haskell does not have null values. You can define them in a particular data type (for example the <code>Maybe</code> type, which we will come onto shortly) but you have to explicitly define them and explicitly handle them. As such, the error surface available due to this flaw in language design is eliminated, and the programmer no longer has to think about it.</p>
<p data-pos="147:1-163:0">Null values, however, are often used to represent a “failed” computation. For example, what if you are getting the head of an empty list, how do you represent the result? In languages with null values, such functions will often return <code>null</code> in these circumstances. This is a specific case of the more general question of how to deal with computations which may fail. There are many examples: if you are parsing some user input and that input is malformed, this failure to parse is a valid state of your programme, and therefore you need some way to represent it. Similarly, network requests may time out, solvers may fail to find a solution, users may cancel actions, and so on. There are two common solutions, null values (which we have mentioned) and exception handling. Both of these solutions cause a new problem for the programmer: you have to remember to handle them, in the case of exceptions at the call site rather than where you consume the value as with null, and nothing in the type system is going to prevent you forgetting.</p>
<p data-pos="164:1-175:0">Haskell solves the problem of the representation of computations which may fail very differently: explicitly through the type system. There are types in Haskell to represent a computation which may fail, and because this is done in the type system, these are first-class entities and you can pass around your computation-result-which-may-or-may-not-be-a-failure as you like. When it comes to consuming the result of that computation, the type system forces you to reckon with the fact that there may be no result. This prevents a whole class of runtime errors without the mental burden of keeping track of values which may be present or which functions might throw an exception somewhere.</p>
<p data-pos="176:1-183:0">The two most common of these types are <code>Maybe</code> and <code>Either</code>. <code>Maybe</code> represents a computation which may or may not have a result. For example, if you want to get the first element of a list, but you do not know if the list is empty, then you may want to specify that your <code>head</code> function can return either a result or <code>Nothing</code>. Unlike null values, however, you cannot just pretend that the function must have returned a result, as the following snippet should demonstrate:</p>
<pre data-pos="184:1-210:3"><code>safeHead :: [a] -&gt; Maybe a
-- the implementation isn't important here, but I'm including it
-- because it is simple and, for the curious, might be helpful
safeHead [] = Nothing
safeHead (x : _) = Just x

myFavouriteThings = ["raindrops on roses", "whiskers on kittens"]
emptyList = []

faveThing = safeHead myFavouriteThings 
-- ^ but what is the type of this thing? 
-- It's not a string, it's `Maybe String`
-- and the value is, in fact, `Just "raindrops on roses"`

something = safeHead emptyList
-- ^ and what's the type of this thing?
-- again, it's a `Maybe String`, but in this
-- case the value is `Nothing` because the list
-- has no first element!

-- so how can we use the value we have computed?
printTheFirstThing :: [String] -&gt; IO ()
printTheFirstThing myList = case safeHead myList of
  Just something -&gt; putStrLn something
  Nothing -&gt; putStrLn "You don't have any favourite things? How sad."
</code></pre>
<p data-pos="212:1-216:0">In this example you can see that when consuming the result of a computation that might fail, you have to explicitly handle the failure case. There are many ways of doing this, and the pattern matching ( <code>case x of ...</code>) above is just one to which we will come shortly.</p>
<p data-pos="217:1-221:0"><code>Maybe</code> can also be used when you might want a nullable field of a data structure. This is a specific case of a computation which may fail, but is often thought of as distinct. Here is how this would look in Haskell:</p>
<pre data-pos="222:1-228:3"><code>data Person = Person {
  name :: String,
  dob :: Day,
  favouriteThing :: Maybe String
}
</code></pre>
<p data-pos="230:1-234:0">As before, Haskell’s type system will not let you fail to handle the case that <code>favouriteThing</code> might be an empty value, so you will not end up with a runtime error as you might in a language in which you could forget to do so.</p>
<p data-pos="235:1-242:0"><code>Maybe</code> is useful in these situations in which the failure condition is obvious, but it doesn’t give you much resolution on <em>why</em> the computation failed, it only tells you <em>that</em> it has failed. By contrast, an <code>Either a b</code> can contain two values, <code>Left a</code> or <code>Right b</code>. By convention, <code>Left</code> contains a failure value, whereas <code>Right</code> contains a success value, so the type is often given as <code>Either e a</code> where <code>e</code> is for “error” and <code>a</code> is just the result type.</p>
<p data-pos="243:1-247:0">One way in which this could be used is in parsing or validating some user input, in which you may want to tell the user more than just that what they gave you is invalid, but rather in what way it is invalid. To that end you could have a <code>validate</code> function that looked like this:</p>
<pre data-pos="248:1-250:3"><code>validateAddress :: String -&gt; Either AddressParseError ValidAddress
</code></pre>
<p data-pos="252:1-256:0">This gives you the ability to return more helpful errors to the user, which are an expected path in your programme, but it prevents you from failing to handle the failure case, or from treating the failure case like a success case accidentally.</p>
<p data-pos="257:1-263:0">To be clear, this means that we no longer treat known error states as exceptions by throwing them up the call stack <a id="fnref5" href="#fn5" role="doc-noteref"><sup>5</sup></a>, and instead we treat them as potential values for the type of our expression. In turn, this means that we now can have a total description of all the failure modes from the point of the function call <em>down</em> the stack. Consider these two snippets of code:</p>
<pre data-pos="264:1-270:3"><code>def do_something():
  result = get_a_result()
  if result != "a result":
    raise InvalidResultError(result)
  return 42
</code></pre>
<pre data-pos="272:1-279:3"><code>doSomething :: Either InvalidResultError Int
doSomething = 
  let result = getResult
   in if result /= "a result"
        then Left (InvalidResultError result)
        else Right 42
</code></pre>
<p data-pos="281:1-286:0">In the first snippet, we have no idea what possible exceptions may be raised by <code>do_something</code>, partly because we have no way of knowing what exceptions may be raised by <code>get_a_result</code>. By contrast, in the second snippet, we know <em>all</em> of the possible failure states immediately, because they are captured in the type system.</p>
<p data-pos="287:1-297:0">We can generalise this idea of being forced to handle the failure cases by saying that Haskell makes us write <strong>total</strong> functions rather than <strong>partial</strong> functions. This means that we have to handle the entire input domain rather than only part of the input domain, otherwise the compiler will complain at us and, sometimes, point-blank refuse to give us a programme. The easiest way to see how this works is to look at how pattern matching is done in Haskell, using a basic programme which helps us organise our evenings given a chosen option. Instead of implementing the entire programme, here is an extract to illustrate the use of pattern matching.</p>
<pre data-pos="298:1-316:3"><code>data Option =
  NightIn
  | Restaurant VenueName
  | Theatre VenueName EventName

data OrganiserResult = Success | NeedsSeatChoice [Seat] | Failure Reason

organiseMyEvening :: Option -&gt; IO OrganiserResult
organiseMyEvening NightIn = do
  cancelAllPlans 
  return Success
organiseMyEvening (Restaurant venue) = attemptBooking venue
organiseMyEvening (Theatre venue event) = do
  availableSeats &lt;- checkForSeats venue event
  case availableSeats of
    [] -&gt; return (Failure (Reason "there are no seats available, sorry :("))
    seats -&gt; return (NeedsSeatChoice seats)
</code></pre>
<p data-pos="318:1-325:0">In the above example, if we were to add an additional option for what we may want to do with our evening, like going to the cinema, and <em>forget</em> to update the <code>organiseMyEvening</code> function accordingly, the compiler would complain to us until we fix it. Without this completeness check in the type system, we could end up with a runtime error, but with this type of check, we just do not have to worry about whether we have <em>remembered</em> to update all the places in which a given value is used.</p>
<p data-pos="326:1-337:0">The final major way in which Haskell’s type system makes it easy for us to avoid common errors when programming is related to how easy it is to avoid “primitive obsession”. There is a hint in our evening-organising snippet above: our <code>Restaurant</code> and <code>Theatre</code> constructors take a <code>VenueName</code> and <code>EventName</code>. These could, naturally, be represented as plain old strings, and in many languages they are, but Haskell gives us a very simple, zero-cost way of representing them as something with more semantic value, more meaning, than just a string. It may not be obvious why this is a problem worth solving, however. Let’s imagine we represented these as plain old strings, so we would have something like this:</p>
<pre data-pos="338:1-345:3"><code>data Option =
  NightIn
  | Restaurant String
  | Theatre String String -- venue name and event name respectively

checkForSeats :: String -&gt; String -&gt; IO [Seat]
</code></pre>
<p data-pos="347:1-366:0">This is probably <em>ok</em> the first time you write it, although you will need comments, as above, in order to remind yourself which value is which. This is where we come to our first annoyance (although not yet a problem) – the type system doesn’t help us remember what is what, we have to rely on arbitrary comments or documentation (or perhaps variable names) to remember, which is a lot of overhead. The problem comes, however, when using these values, such as in <code>checkForSeats</code>. We could easily mix up the venue name and event name, and we would always return zero seats (because we probably don’t know a theatre called <em>King Lear</em> in London where they are playing Shakespeare’s masterful <em>The National Theatre</em>). This is erroneous behaviour, but is easily done, and the type system will not help us out. “Primitive obsession” is the use of primitives (strings, numbers, booleans, etc.) to represent data, instead of types with more semantic value. The solution is to encode your domain in your type system, which prevents such errors. This can be very cumbersome in many imperative languages, but in Haskell we can simply wrap a value in a <code>newtype</code> and the type system suddenly stops us falling into the trap of using the wrong value. Therefore our code above becomes:</p>
<pre data-pos="367:1-377:3"><code>newtype VenueName = VenueName String
newtype EventName = EventName String

data Option =
  NightIn
  | Restaurant VenueName
  | Theatre VenueName EventName

checkForSeats :: VenueName -&gt; EventName -&gt; IO [Seat]
</code></pre>
<p data-pos="379:1-385:0">Above it is written that this is a “zero-cost” method, which means that unlike the normal way of creating a data structure to wrap around some values, <code>newtypes</code> have exactly the same representation in memory as the type they wrap (with the result that they can only wrap a single type), they therefore only exist at the level of the type system, but have no impact on your programme otherwise.</p>
<p data-pos="386:1-391:0">Thus far we have discussed four features of the type system which help us as programmers to write correct code with minimal mental overhead: the lack of nullable types, representations of “failable” computations, pattern matching and completeness checks, and the avoidance of “primitive obsession”.</p>
<p data-pos="392:1-398:0">Other languages have some of these features (notably Rust, whose type system was inspired by Haskell’s), but most of these other languages lack the second pillar: pure functional programming. There are two aspects of a pure functional language which help us avoid common errors: immutable data and explicit side-effects (which, together, give us purity and referential transparency).</p>
<p data-pos="399:1-413:0">Almost all data in Haskell are immutable. This means that a whole class of errors like data races, or objects changing between write and read, just do not exist. In single-threaded code this is great because you don’t have to think about mutating state anywhere, you just use things like folds or traversals to achieve your goals, but where this really shines is in concurrent code. For concurrent Haskell you do not have to worry about mutices and locks because your data can’t be mutated <em>anyway</em>. That means that if you want to parallelise a computation, you just fork it into different threads and wait for them all to come back without all of the hairy bugs of multi-threaded computations. Even when you do require some sort of shared, mutable state between your threads, the way this is constructed in Haskell (e.g. in the <a href="https://hackage.haskell.org/package/stm"><code>STM</code> library</a>) still avoids the problems solved by locks and mutices in other languages.</p>
<p data-pos="414:1-424:0">Immutability gets you halfway towards eliminating the sorts of errors found in imperative languages, but <em>purity</em> will get us the rest of the way. Haskell functions are pure, in the sense that they do not permit any side-effects, nor do they rely on anything except for the arguments passed into them. There are ways to encode side-effects, for, at some point, any useful programme needs to at least perform <em>some</em> I/O, and there are ways to include things in functions which are not <em>directly</em> passed as arguments (implicit parameters), but the way Haskell is constructed means that these ways do not violate the purity of the language because we use monads to encode these things.</p>
<p data-pos="425:1-431:0">Monads: at first they throw every novice Haskeller into disarray, and then nearly everyone feels the need to write their own monad tutorial. Exactly what monads are and why they are useful is beyond the scope of what we want to talk about here, but the specific benefit we <em>are</em> looking at is how this allows us to encode side-effects and why that is going to help you avoid mistakes when programming.</p>
<p data-pos="432:1-433:0">Let’s look at some functions for a basic online community:</p>
<pre data-pos="434:1-442:3"><code>data Response = Success | Failure FailureReason

sendGreetings :: User -&gt; IO Response

updateUser :: UserId -&gt; User -&gt; IO Response

findNewestUser :: [User] -&gt; Maybe User
</code></pre>
<p data-pos="444:1-451:0">In many imperative languages, the activity of finding the newest user and sending them some sort of greeting might all be done in one function, or a set of deeply nested functions. There would be nothing to stop you, however, making database calls, sending emails, or doing anything else inside the simple <code>findNewestUser</code> function. This can be a nightmare for tracking down bugs and performance issues, as well as preventing tight-coupling between functions.</p>
<p data-pos="452:1-464:0">The functions above take two forms: <code>findNewestUser</code> returns something by now familiar to us, <code>Maybe User</code> – if there is a newest user, it will return it, otherwise it will return <code>Nothing</code>. The other two functions return something we have not yet seen: <code>IO Response</code>. <code>IO</code>, like <code>Maybe</code> wraps another type (in this case: <code>Response</code>) but instead of representing a “failable” computation as <code>Maybe</code> does, it represents any context in which you are permitted to perform I/O actions (like talking to your database or sending emails, as our cases are above). It is not possible to perform I/O outside of the <code>IO</code> monad – your code will not compile – and, furthermore, I/O “colours” all the functions which call it, because if you are calling something which returns <code>IO</code>, then you have to be returning <code>IO</code> as well.</p>
<p data-pos="465:1-474:0">This might look like a lot of bureaucracy, but it actually does two very helpful things: firstly, it immediately tells the programmer “hey, this function performs side-effects in I/O” which means that they don’t have to read the code in order to understand what it does, just the type signature; secondly, it means that you cannot accidentally perform I/O in a function you thought was pure – this, in itself, eliminates whole classes of bugs in which one may think one understands all the dependencies of a function, but actually something is affecting it which you did not realise, because it can perform side-effects.</p>
<p data-pos="475:1-482:0">This is only partially satisfying, however, as wrapping everything that performs side-effects in <code>IO</code> is a bit imprecise in a similar way in which using primitive types for values with higher-level semantics in the domain is also imprecise, and it can cause similar classes of error: there is nothing to say “in this function you can send emails, but you can’t write to the database.” The type-system has helped you <em>a little bit</em> but stopped short of the guardrail we have come to expect by now.</p>
<p data-pos="483:1-493:0">Thankfully, due to two additional language features: namely ad hoc polymorphisms and typeclasses, we can <em>exactly</em> encode the effects we want a function to be permitted to perform, and make it impossible to perform any others. Let’s modify our example to take advantage of this, noting that <code>class X a where</code> means that we are declaring a <em>class</em> <code>X</code> of types with some associated functions for which we have to write concrete implementations. This is similar to interfaces in some languages, or traits in Rust (which were based on Haskell’s typeclasses). In this example, <code>m</code> is just a type variable representing a “2nd order”<a id="fnref6" href="#fn6" role="doc-noteref"><sup>6</sup></a> type (e.g. <code>IO</code> or <code>Maybe</code>).</p>
<pre data-pos="494:1-515:3"><code>data Response = Success | Failure FailureReason

class CanReadUsers m where
  getUsers :: m (Either FailureReason [User])

class CanWriteUsers m where
  updateUser :: UserId -&gt; User -&gt; m Response

class CanSendEmails m where
  sendEmail :: EmailAddress -&gt; Subject -&gt; Body -&gt; m Response

findNewestUser :: [User] -&gt; Maybe User

sendGreetings :: CanSendEmails m =&gt; User -&gt; m Response

greetNewestUser :: (
  CanReadUsers m,
  CanWriteUsers m,
  CanSendEmails m
  ) =&gt; m Response
</code></pre>
<p data-pos="517:1-527:0">We have introduced a new function here <code>greetNewestUser</code> to illustrate how we can compose these <em>constraints</em> on what we are able to do. Our implementation of this would do something like: find all the users, filter for the newest one, send an email, and mark the user as having been greeted. We have encoded these capabilities at the type level for <code>greetNewestUser</code>, whereas we have not for <code>sendGreetings</code>, so it would be impossible, in fact, for <code>sendGreetings</code> to fetch users from the database or to accidentally update the user information in the database<a id="fnref7" href="#fn7" role="doc-noteref"><sup>7</sup></a>. It can <em>only</em> send emails. To finish this example off, let’s see how the implementations of these functions might look:</p>
<pre data-pos="528:1-555:3"><code>-- these would be defined elsewhere, but just so you know the types
joinDate :: User -&gt; Day
emailAddress :: User -&gt; EmailAddress
setAlreadyGreeted :: User -&gt; User
hasBeenGreeted :: User -&gt; Bool
userId :: User -&gt; UserId

findNewestUser users = safeHead (sortOn joinDate users)

sendGreetings user = 
  let subject = Subject "Welcome to the club!"
      body = Body "Remember: don't stare at the guests..."
   in sendEmail (emailAddress user) subject body

greetNewestUser = do
  fetchResult &lt;- getUsers
  case fetchResult of
    Left err -&gt; return (Failure err)
    Right users -&gt; case findNewestUser users of
      Nothing -&gt; return (Failure NoUsers)
      Just user -&gt; if hasBeenGreeted user
        then return (Failure AlreadyGreetedUser)
        else do
          sendGreetings user
          let newUserData = setAlreadyGreeted user
           in updateUser (userId user) newUserData
</code></pre>
<p data-pos="557:1-566:0">While the exact syntax may be unfamiliar, everything in this section has been building up to this point: we represent “failable” computations with data types which encapsulate that they can fail and how they can fail; we use semantically meaningful types to describe our data, rather than primitives; we explicitly handle failure cases rather than being allowed to forget about them; we cannot mutate state so we create new copies of our data with the requisite updates; and we explicitly encode the side-effects we want to perform, rather than just firing them off willy-nilly.</p>
<p data-pos="567:1-574:0">That rounds off the section about the guardrails Haskell puts in place for you as a programmer, both through the strength of its type system and the purity and referential transparency of the language itself. Far from being an imposition on the programmer, this is incredibly freeing as it allows you to spend your mental energy <em>describing</em> your problem and thereby solving it, not worrying about keeping track of all the ways in which your programme could fail.</p>
<section data-pos="575:1-611:0" id="But-language-has-feature-too">
<h3 data-pos="575:1-576:0">But &lt;language&gt; has &lt;feature&gt;, too!</h3>
<p data-pos="577:1-581:0">Some of the features of Haskell above exist, or <em>look like</em> they exist, in other languages. Without trying to talk about every possible language, we can look at some of the common patterns and how they differ, or do not, from those in Haskell.</p>
<p data-pos="582:1-590:0">Pattern matching, for example, has been introduced into many languages. Some of those have the same characteristics as Haskell, like Rust’s pattern matching, which is exhaustive and enforced by the compiler, whereas some are quite different, especially in gradually-typed languages like Typescript and Python, where there is no guarantee that this sort of safety permeates the codebase, and there are often escape-hatches, because you are using optional tools external to the built-in toolchain.</p>
<p data-pos="591:1-595:0">Very few languages make use of higher-order types like <code>Either</code> and <code>Maybe</code> to represent computations which may fail, but Rust is a notable exception which, like Haskell, strongly encourages representing failure in this way.</p>
<p data-pos="596:1-606:0">Subclassing is commonly used in some languages to make it “easy” to avoid primitive obsession, but this is not as strict as Haskell’s <code>newtype</code>s. Python, for example, has a <code>NewType</code> construction, but it has two weaknesses common to this type of implementation: the first is that subclassing means that our <code>VenueName</code> and <code>EventName</code> types can be passed to functions expecting <code>String</code>, because they are not treated as completely different types, and the second is that, unlike in Haskell, you cannot hide the constructors of these types, which means there are certain patterns you cannot fully implement like the parsing pattern (as opposed to validating)<a id="fnref8" href="#fn8" role="doc-noteref"><sup>8</sup></a>.</p>
<p data-pos="607:1-611:0">Finally, while some libraries exist in other languages in order to isolate and control side-effects<a id="fnref9" href="#fn9" role="doc-noteref"><sup>9</sup></a>, they are not enforced as part of the language in the same way, because this would require purity to be built into the language itself.</p>
</section>
</section>
<section data-pos="612:1-738:0" id="The-things-which-make-you-more-productive">
<h2 data-pos="612:1-613:0">The things which make you more productive</h2>
<p data-pos="614:1-620:0">Providing guardrails, for all the reasons listed in the previous section, is a very useful feature of a language, but that alone might make for a very slow experience of building programmes. Haskell has several properties which actually make it <em>more</em> productive to construct such programmes, especially as those programmes grow in complexity (or sheer size).</p>
<p data-pos="621:1-627:0">As before, these properties derive from the two key characteristics of the language<a id="fnref10" href="#fn10" role="doc-noteref"><sup>10</sup></a>: the strength of the type-system and the pure-functional semantics of the language. These two together give us code which is highly declarative, and therefore easily and unambiguously manipulable, as well as a tendency towards heavy concept and code re-use.</p>
<p data-pos="628:1-635:0">Why are these useful? Starting with the former: if our programme is declarative rather than imperative, we can easily understand it ourselves, as well as simply generate other code from it (or documentation), and refactoring becomes a “fearless” activity. Taking the latter, this means that we can “discover” a set of core concepts and continue to build upon them, instead of having to learn disjoint sets of concepts for each domain or library one uses.</p>
<p data-pos="636:1-650:0">It can be hard to explain just how radically these things transform the way one constructs programmes without experiencing them, but to take a small example, the Haskell ecosystem has a tool called <a href="https://hoogle.haskell.org/">“Hoogle”</a> which allows one to search for functions by type signature. Not only by full type signature with concrete types, but, even by partial type signature with type variables instead of actual types. That means that, instead of searching for something which applies a function to each string in a list of strings (<code>(String -&gt; String)
-&gt; [String] -&gt; [String]</code>), one can instead search for something which applies a function to a list of things, returning a list of the results: (<code>(a -&gt; b) -&gt; [a] -&gt; [b]</code>). You can even get the arguments the wrong way around, and Hoogle will still find you the right functions, so <code>[a] -&gt;
(a -&gt; b) -&gt; [b]</code> will give you the same answers (sorted differently) to <code>(a -&gt; b) -&gt; [a] -&gt; [b]</code>!</p>
<p data-pos="651:1-659:0">This works so well because Haskell’s semantics, standard library, and ecosystem all rely heavily on concept re-use. Almost every library builds upon the core set of concepts<a id="fnref11" href="#fn11" role="doc-noteref"><sup>11</sup></a>. This means that if you are wondering how to do something, and you are faced with one library or set of data types, you can probably search for the general pattern of what you want to achieve and you will get what you want. Almost no other ecosystem<a id="fnref12" href="#fn12" role="doc-noteref"><sup>12</sup></a> has something comparable to this.</p>
<p data-pos="660:1-663:0">In order to flesh out this idea of concept generalisation and re-use, let’s consider two examples: functors and monoids. Before we get there, we will start with lists.</p>
<p data-pos="664:1-672:0">A list is Haskell looks like this <code>myList = [1, 2, 3] :: [Int]</code>. You can do various things with lists, like apply a function to each member of the list (<code>map</code>) in order to obtain a new list, or stitch two lists together (<code>[1, 2] &lt;&gt; [3, 4]</code>). In this sense, we have described two properties of lists which we can generalise: a list is a container over which you can apply a function (a “functor”), and a list is an object which has a binary combining operator with an identity value <code>[]</code> (a “monoid”).</p>
<p data-pos="673:1-678:0">Lots of other structures exhibit these properties, for example a list is a functor, but so is a <code>Maybe</code> or an <code>Either</code>, or even a parser! As a result, if you understand the core concept of functors, you have a set of tools which can apply to all sorts of other data structures which you use day-to-day, but with no extra overhead:</p>
<pre data-pos="679:1-688:3"><code>fmap (+ 2) [1, 2, 3] -- [3, 4, 5]
fmap (+ 2) (Just 2) -- Just 4
fmap (+ 2) (Right 5) -- Right 7
number = fmap (+ 2) decimal :: Parser Int
-- parses a string representation of a decimal, adding 2 to it, but
-- the nice thing here is that we don't have to explicitly handle the
-- failure case with our `+ 2` function!
parseMaybe number "4" -- Just 6
</code></pre>
<p data-pos="690:1-696:0">Similarly, there are plenty of monoids lurking about. Obvious examples might be strings, but then, for example, the <a href="https://hackage.haskell.org/package/lucid"><code>Lucid</code> library</a> for writing HTML represents HTML as monoids, which allows you to compose them with the same tools you would use for any other monoid. Once again, you learn a single core concept, and it becomes applicable across a large part of the ecosystem.</p>
<pre data-pos="697:1-701:3"><code>[1, 2] &lt;&gt; [3, 4] -- [1, 2, 3, 4]
"hello" &lt;&gt; " " &lt;&gt; "world" -- "hello world"
myIntro = p_ (i_ "Don't " &lt;&gt; b_ "panic") -- &lt;p&gt;&lt;i&gt;Don't &lt;/i&gt;&lt;b&gt;panic&lt;/b&gt;&lt;/p&gt;
</code></pre>
<p data-pos="703:1-708:0">You can even use this in your own code, and can write simple instances for your own data structures. This vastly reduces the amount of specialised code you have to write – instead, you can simply re-use code and concepts from elsewhere, whether the standard library or an extension to those concepts like bifunctors.</p>
<p data-pos="709:1-715:0">In short: Haskell’s semantics and standard library encourage generalised concepts which, in turn, heavily promote both concept and code reuse, and this has driven the development of the ecosystem in a similar direction. That re-use means that the programmer need only discover the core concepts once, rather than for each library, providing an accelerating rate of learning and a much more efficient use of code.</p>
<p data-pos="716:1-729:0">The final productivity boost to discuss here is “fearless refactoring”, a term often thrown about in the Haskell community, but what does it actually mean? The essential point here is that the intransigence of the compiler makes it a useful ally when refactoring code. In languages with a more forgiving compiler or weaker type-system, refactoring code can introduce new bugs which are only discovered at runtime. When refactoring Haskell, because the type-system gives you the power to express your programme domain correctly, the process normally works as a constant cycle of “change, compile, change, compile” until all the compilation errors are gone, at which point you can be very confident you will not encounter runtime bugs. This reduces the cognitive load on the programmer, making it far faster (and less scary) to make changes to a codebase, whether large or small.</p>
<p data-pos="730:1-738:0">This section goes beyond just providing guardrails, guardrails which are clearly inspiring other language maintainers to introduce them into their languages, to talk about something very fundamental to productivity in programming: composable, re-usable concepts and the ability to “fearlessly” make changes to your programme. These are not simply features which can be added into a language, they are characteristics of it, and they relate to the more abstract notions laid out in the next section.</p>
</section>
<section data-pos="739:1-898:0" id="Reason-about-your-programmes-more-easily">
<h2 data-pos="739:1-740:0">Reason about your programmes more easily</h2>
<p data-pos="741:1-750:0">In general, programming is about telling a machine about some problem domain: the ontology of it, and the logical rules governing it, and then asking it to compute some results. These results should have some sort of meaning we can interpret, which is going to depend on how well we understand what our programme actually <em>means</em>. Additionally, for us to be able to trust the results of the computations we ask of the machine, we need to be confident that we have done a good job describing the problem domain in terms that result in a “good” understanding on the part of the machine.</p>
<p data-pos="751:1-757:0">A programme can have essential complexity or accidental complexity. The essential complexity comes from precisely describing the problem domain, and some domains are more complex than others. The accidental complexity comes from our (in)ability to express the problem domain to the machine. We can refer to these as <em>complexity</em> and <em>complication</em> to differentiate them.</p>
<p data-pos="758:1-764:0">Complications are bad and should be eliminated. They make it hard to reason about our programmes and therefore hard to trust their results. It also makes it hard to write the programmes in the first place, because we have to deal with all these complications. It’s a bit like trying to embroider a tapestry using a Rube Goldberg machine operated with thick mittens: unlikely to give you what you want.</p>
<p data-pos="765:1-776:0">We could look at general purpose programming languages on a scale of how well we are able to express a problem domain to a machine, and therefore to what extent we are able to trust the results of the computations we ask of that machine. Assembly is at one end: it is all about moving bytes between registers and performing arithmetic on them. Yes, you can write anything in Assembly but it is really hard to reason about the results you will get. As we move along the scale towards “high-level” languages we gain a set of abstractions which allow us to forget about the semantics of the lower level (e.g. moving bytes between registers) because they give us new semantics which are closer to those of the problem domain.</p>
<blockquote data-pos="777:1-779:36">
<p data-pos="777:3-779:36">The purpose of abstracting is not to be vague, but to create a new semantic level in which one can be absolutely precise. ~ Dijkstra, 1972<a id="fnref13" href="#fn13" role="doc-noteref"><sup>13</sup></a></p>
</blockquote>
<p data-pos="781:1-788:0">Haskell improves upon most high-level languages in this regard, providing a level of expressivity that allows more precise descriptions of the problem domain, easily intelligible both to the programmer and the machine. Broadly there are three major contributing factors to this (perhaps all of them can fit under the idea of denotation semantics): algebraic data types, parametric and ad hoc polymorphism, and declarative programming.</p>
<p data-pos="789:1-793:0">We can distinguish declarative and imperative programming by saying that declarative programming describes what a computation is supposed to be with respect to the problem domain, whereas imperative programming describes how a computation is to be carried out, step-by-step.</p>
<p data-pos="794:1-801:0">This is useful distinction: in imperative programming the operational semantics of the programme (the steps a machine must execute in order to compute a result) are mixed into the problem domain, making it difficult to reason about the meaning of a programme and, therefore, its correctness. Declarative programming, however, does not bother with defining these execution steps, making programmes much simpler to understand and reason about.</p>
<p data-pos="802:1-812:0">In Haskell, everything is an expression. In fact, your entire programme is a <em>single</em> expression composed of sub-expressions. These sub-expressions have themselves some sort of meaning, as does their composition. This is different to imperative languages, in which is common for there to be many lines of function calls and loops, with, often, deeply nested function calls, but these are not essentially composable. Haskell’s purity forces concise programmes composed of meaningful sub-expressions with no side-effects. This means that it takes far less time to understand the purpose of a given expression, and therefore reason about whether it is correct or not.</p>
<p data-pos="813:1-818:0">As ever, we are back to our two familiar pillars: so far, we have discussed the pure-functional pillar (single expression, compositionality, no side-effects), but the type system gives us the tools for expressing ourselves clearly to the machine (and to ourselves).</p>
<p data-pos="819:1-828:0">In fact, most of the preceding sections touch upon this in one way or another: we have data types for expressing the idea that some computations can fail in well-defined ways; we have sum types like <code>data
Response = Success | Failure FailureReason</code> which allow us to define all the possible values we might get from a function; we have typeclasses we can use as constraints on a function to semantically express what the result is in the most general way (like <code>CanSendEmails</code>); and we have generalised concepts like <code>Functor</code> and <code>Monoid</code> which describe how things behave rather than the steps to implement those behaviours.</p>
<p data-pos="829:1-838:0">Algebraic data types and typeclasses (and other, similar mechanics which deal with various polymorphisms) allow us to construct our own domain-specific languages within Haskell with which to write our programmes, while building upon common, well-established concepts to do so. These are declarative rather than imperative, and therefore are easy to reason about and to understand <em>semantically</em> because you do not have to either weed out the operational semantics (the step-by-step instructions) nor do you have to translate from a layer of primitives into your own domain.</p>
<p data-pos="839:1-843:0">This section has been necessarily abstract, because the idea is hard to communicate if one has not stepped outside the imperative paradigms in which most of modern programming sits. To try to elucidate it somewhat, here is a small sample programme using the concepts discussed above.</p>
<p data-pos="844:1-847:0">This programme is a basic accounting tool: given some initial monetary value, and a set of transactions (either in or out) in a variety of currencies, allow us to calculate the final value of the account.</p>
<pre data-pos="848:1-897:3"><code>-- this is a bit like an "enum" of possible constructors of the type Currency
data Currency = GBP | EUR | USD 

data Money = Money {
  currency :: Currency,
  value :: Double
  }

convert :: Currency -&gt; Money -&gt; Money
convert = -- not interesting to implement here as it is basically a lookup table

zero :: Money
zero = Money GBP 0

-- Ord gives us ways of comparing things (a natural ordering)
instance Ord Money where
  compare m1 m2 
    | currency m1 == currency m2 = compare (value m1) (value m2)
    | otherwise                  = compare m1 (convert (currency m1) m2)

instance Monoid Money where
  m1 &lt;&gt; m2 = Money (currency m1) (convert (currency m1) m2)
  mempty = zero

instance Functor Money where
  fmap f (Money curr val) = Money curr (f val)

data Transaction = In Money | Out Money

instance Functor Transaction where
  fmap f (In m) = In (f m)
  fmap f (Out m) = Out (f m)

normalise :: Transaction -&gt; Transaction
normalise transaction =
  let m = money transaction
   in if m &lt; zero then Out m else In m

instance Monoid Transaction where
  t1 &lt;&gt; In m2 = normalise (fmap (&lt;&gt; m2) t1)
  t1 &lt;&gt; Out m2 = normalise (fmap (&lt;&gt; (fmap (* (-1)) m2)) t1)

apply :: Transaction -&gt; Money -&gt; Money
apply (In m) initial = initial &lt;&gt; m
apply (Out m) initial = initial &lt;&gt; fmap (* (-1)) m

getAccountValue :: Money -&gt; [Transaction] -&gt; Money
getAccountValue startValue transactions = apply (fold transactions) startValue
</code></pre>
</section>
<section data-pos="899:1-1003:73" id="Epilogue">
<h2 data-pos="899:1-900:0">Epilogue</h2>
<p data-pos="901:1-905:0">I love writing in Haskell, and there are many reasons beyond this apologia why that is the case, but I also think it is an excellent choice for general purpose programming for anyone who wants to write robust software confidently and efficiently, and, of course, enjoyably.</p>
<p data-pos="906:1-913:0">I think what makes Haskell unique is the combination of its type system and functional purity – it’s not enough just to have functional programming, much as I love LISPs, nor is it enough just to have the type system, much as Rust seems like a great language. Many languages have bits of these features, but only a few have all of them, and, of those languages (others include Idris, Agda, and Lean), Haskell is the most mature, and therefore has the largest ecosystem.</p>
<p data-pos="914:1-921:0">While other languages are certainly adding features which I have mentioned above, this combination of a strong and expressive type system and pure functional programming is fundamental to the language: other languages without these axiomatic characteristics simply will not be able to implement them (and attempts to build some of these things into non-functional languages with weaker type systems is often extremely awkward and not very useful).</p>
<p data-pos="922:1-928:0">Not everyone has the luxury of choosing their tools in a professional context, whether because there is history in their team or the decisions are made by others. Even in this case, if you never end up using Haskell professionally, it will change how you think about programming, and to invert Alan Perlis’ quotation from the start of this essay: any language which changes how you think about programming is worth learning.</p>
</section>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1">
<p data-pos="939:21-943:0">This is, however, not supposed to be an exhaustive list of all the things I think are great about Haskell, but just a subset of the most compelling reasons I recommend it to programmers. The rest they can discover for themselves.<a href="#fnref1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn2">
<p data-pos="944:26-947:0">Haskell is, of course, not always an appropriate choice. For example, it is never going to replace C or C++ for writing software for micro-controllers.<a href="#fnref2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn3">
<p data-pos="948:19-949:0">And quite possibly an “object-oriented” paradigm, to boot.<a href="#fnref3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn4">
<p data-pos="929:17-930:0">Perlis, A., “Epigrams in Programming” (<a href="http://cs.yale.edu/homes/perlis-alan/quotes.html">retrieved 2024-07-07</a>)<a href="#fnref4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn5">
<p data-pos="965:22-970:0">This is a bit like using <code>goto</code> to manage known failure states, which, I think, would be quite unintuitive if it hadn’t become such a dominant way of managing such failure states. In any case, I think it would make <a href="https://dl.acm.org/doi/10.1145/362929.362947">Dijkstra quite sad</a>.<a href="#fnref5" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn6">
<p data-pos="987:9-996:0">This use of “2nd order” is not idiomatic in Haskell, as this is technically a higher-kinded type, whereas “order” is typically used to refer to functions, but just like a higher-order function is a function which takes another function as its argument, a higher-kinded type is a type which takes another type as an “argument”, and thereby produces a “concrete type”. Diogo Castro’s <a href="https://diogocastro.com/blog/2018/10/17/haskells-kind-system-a-primer/">2018 blog post “Haskell’s kind system – a primer”</a>  has more details on this.<a href="#fnref6" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn7">
<p data-pos="997:9-1000:0">For those who are familiar with the idea, this is a bit like command-query segregation in the imperative world, but enforced by the type system.<a href="#fnref7" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn8">
<p data-pos="971:25-980:0">To expand slightly on this, although it would be worth reading the <a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">excellent blog post by Alexis King</a>, this means that instead of <em>validating</em>, i.e. checking a value meets some criterion, we parse an “unknown” value into a “valid” value, and thereby change its type. The result is that you can write functions which are defined to take the “valid” type (e.g. <code>EmailAddress</code>) and which never have to worry that it might be invalid, because you simply cannot forget to verify it, as you can in a “validation” pattern.<a href="#fnref8" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn9">
<p data-pos="981:32-986:0">Christopher Armstrong <a href="https://www.youtube.com/watch?v=D37dc9EoFus">gave an interesting talk at Strange Loop in 2015</a> on his python library, which includes an introduction to the motivation for this sort of pattern. This might be good follow-on content if you are interested.<a href="#fnref9" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn10">
<p data-pos="954:21-958:0">Actually, what is really distinctive about Haskell is that it is a <strong>lazy</strong>, pure, functional language, but laziness can be confusing and is only lightly related to the benefits discussed in this essay, and so I am going to ignore it.<a href="#fnref10" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn11">
<p data-pos="1001:21-1003:73">You can find a big map of how these concepts related to each other by checking out the <a href="https://wiki.haskell.org/Typeclassopedia#Introduction">Typeclassopedia</a>.<a href="#fnref11" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn12">
<p data-pos="961:18-964:0">Unison <em>does</em> have something called Unison Share, but it was written by a Haskeller and directly inspired by Hoogle (and, in fact, Unison is based on Haskell).<a href="#fnref12" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn13">
<p data-pos="935:23-936:0">Dijkstra, E.W., ACM Turing Lecture: “The Humble Programmer”, 1972 (<a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html">transcript</a>)<a href="#fnref13" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Konty – A Balsamiq-alternative lo-fi wireframe tool for modern apps (347 pts)]]></title>
            <link>https://konty.app/http://localhost:4321/</link>
            <guid>41517312</guid>
            <pubDate>Thu, 12 Sep 2024 03:31:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://konty.app/http://localhost:4321/">https://konty.app/http://localhost:4321/</a>, See on <a href="https://news.ycombinator.com/item?id=41517312">Hacker News</a></p>
<div id="readability-page-1" class="page"> <header>   </header>  <!-- <main class="w-full mx-auto max-w-5xl px-4"> -->  <div>  <div>  <p> Make hand-drawn style wireframes quickly and easily. </p> </div>  <p><img src="https://konty.app/images/hero.png" alt="Hero"> </p>  </div> <div> <h2>
Features
</h2> <div> <div> <h2>Stress-free hand-drawn style</h2> <p> 
Don't spend a lot of time and effort creating low-fidelity wireframes.
        Express and communicate your ideas quickly. A hand-drawn style reduces
        stress on perfection and allows you to express ideas quickly.
  </p> </div> <div> <p><img src="https://konty.app/images/feat-hand.png" alt="Feature 1"> </p> </div> </div> <div> <div> <h2>Mix with various diagrams</h2> <p> 
You can also draw various types of diagrams including Flowchart, UML
        diagrams (Use Case, Class), Entity-Relationship diagram. It help you
        drawing user flows, information architecture, data models and others in
        one place.
  </p> </div> <div> <p><img src="https://konty.app/images/feat-dgms.png" alt="Feature 1"> </p> </div> </div> <div> <div> <h2>Rich shapes, icons and templates</h2> <p> 
Offer almost every UI component shape you need, over 1,500 icons, and a
        variety of templates for web, mobile, desktop and more.
  </p> </div> <div> <p><img src="https://konty.app/images/feat-libs.png" alt="Feature 1"> </p> </div> </div> <div> <div> <h2>Presentation mode</h2> <p> 
Shape could have a link to another page and you can present your
        wireframe like a slide show.
  </p> </div> <div> <p><img src="https://konty.app/images/feat-link.png" alt="Feature 1"> </p> </div> </div> <div> <div> <h2>Mirroring a frame</h2> <p> 
You can create a mirror of a frame. It allows you to create a master
        frame and reuse it in multiple places. When you update the master frame,
        all the mirrors will be updated.
  </p> </div> <div> <p><img src="https://konty.app/images/feat-mirror.png" alt="Feature 1"> </p> </div> </div> <!-- <Feature title="Export and share">
        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam ullamcorper
        magna eget ipsum dapibus viverra. Suspendisse odio diam, tempus vitae
        neque et, convallis vehicula felis. Cras porttitor, lorem vel egestas
        molestie, nulla nisl feugiat ex, sit amet hendrerit justo ante in
        tortor.
        <div slot="image" class="bg-slate-100 w-full aspect-video rounded-lg">
        </div>
      </Feature>
      <Feature title="AI assistant without subscription">
        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam ullamcorper
        magna eget ipsum dapibus viverra. Suspendisse odio diam, tempus vitae
        neque et, convallis vehicula felis. Cras porttitor, lorem vel egestas
        molestie, nulla nisl feugiat ex, sit amet hendrerit justo ante in
        tortor.
        <div slot="image" class="bg-slate-100 w-full aspect-video rounded-lg">
        </div>
      </Feature> --> </div> <div> <h2>
Subscribe to our newsletter
</h2> <p>
Get notified about new features and future giveaways by subscribing to
        our newsletter 👇
</p> <astro-island uid="Z2t7Dex" component-url="/_astro/subscribe-form.DHOhAvhe.js" component-export="SubscribeForm" renderer-url="/_astro/client.BIGLHmRd.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;SubscribeForm&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> </div>  <!-- </main> -->  </div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA Pulls Off Delicate Thruster Swap, Keeping Voyager 1 Mission Alive (254 pts)]]></title>
            <link>https://gizmodo.com/nasa-pulls-off-delicate-thruster-swap-keeping-voyager-1-mission-alive-2000497434</link>
            <guid>41517272</guid>
            <pubDate>Thu, 12 Sep 2024 03:22:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/nasa-pulls-off-delicate-thruster-swap-keeping-voyager-1-mission-alive-2000497434">https://gizmodo.com/nasa-pulls-off-delicate-thruster-swap-keeping-voyager-1-mission-alive-2000497434</a>, See on <a href="https://news.ycombinator.com/item?id=41517272">Hacker News</a></p>
Couldn't get https://gizmodo.com/nasa-pulls-off-delicate-thruster-swap-keeping-voyager-1-mission-alive-2000497434: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Minneapolis Street Grid: Explained (125 pts)]]></title>
            <link>https://streets.mn/2024/09/11/streets-and-avenues-in-minneapolis/</link>
            <guid>41516627</guid>
            <pubDate>Thu, 12 Sep 2024 00:53:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://streets.mn/2024/09/11/streets-and-avenues-in-minneapolis/">https://streets.mn/2024/09/11/streets-and-avenues-in-minneapolis/</a>, See on <a href="https://news.ycombinator.com/item?id=41516627">Hacker News</a></p>
Couldn't get https://streets.mn/2024/09/11/streets-and-avenues-in-minneapolis/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[My business card runs Linux (and Ultrix), yours can too (192 pts)]]></title>
            <link>http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard</link>
            <guid>41516476</guid>
            <pubDate>Thu, 12 Sep 2024 00:21:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://dmitry.gr/?r=05.Projects&#x26;proj=33.%20LinuxCard">http://dmitry.gr/?r=05.Projects&#x26;proj=33.%20LinuxCard</a>, See on <a href="https://news.ycombinator.com/item?id=41516476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p><span>My business card runs Linux (and Ultrix), yours can too</span>

<b>UPDATES:</b>: See "<a href="#fwv2">Version 2</a>"</p><h2>Table of Contents</h2>
<p><img src="http://dmitry.gr/images/linuxCardPromo.jpg" alt="Linux card project cover image"></p><ol type="1"><li><a href="#_TOC_2673ce8234cc65bf5d5e81743172700b">Why?</a></li><li><a href="#_TOC_544a3f85f27429ab93dcd5ab2a63de0f">Parts selection</a></li><li><a href="#_TOC_7c1edc4d9290405fda54122244529141">What to emulate</a><ol type="a"><li><a href="#_TOC_d30f50757568b8cfaf8978a26d616b30">A MIPS primer</a></li><li><a href="#_TOC_1f0bd75c3792469488787400675c6973">What system?</a></li></ol></li><li><a href="#_TOC_7e76ca59b9efa6e1895f99d810e88da7">Let's emulate!</a><ol type="a"><li><a href="#_TOC_2e782d97f878671469dbb579dab9819e">The CPU</a></li><li><a href="#_TOC_d26852db28343b84596911de435caac9">The FPU</a></li><li><a href="#_TOC_5568f04140f1e9c2bde99c4e9c3572c9">The MMU</a><ol type="I"><li><a href="#_TOC_f05af7a1cabb44e206600aa7d7074fbc">MMU basics</a></li><li><a href="#_TOC_68fe0e8a8517a9a939dc8ad830f3ed3f">The MIPS MMU</a></li><li><a href="#_TOC_3ec65a91b377c508e2a27543e95858ca">Emulating the MMU efficiently</a></li></ol></li><li><a href="#_TOC_07a3dd247ad6bec7fe401aa11619959f">Communication</a></li><li><a href="#_TOC_3a173782d010897c6136c3b4ca51cd47">Hypercalls</a></li></ol></li><li><a href="#_TOC_d2ce354603c45f5e016fd47b9b5c8524">Bring on the hardware!</a><ol type="a"><li><a href="#_TOC_30aace8835696930f69a264dd89cbc60">The honeymoon period</a></li><li><a href="#_TOC_da93b232e827178270bfa561bdf6569c">How not to design a DMA unit</a></li><li><a href="#_TOC_e8ee65a238a03dd3a641faaff13a9c8a">Clocks again</a></li><li><a href="#_TOC_f53cca91f548c50486dcd52bac3efe7c">SD card support</a></li><li><a href="#_TOC_03751c187a665141b52e489852323619">Coolness enhancement</a></li></ol></li><li><a href="#_TOC_9ffdb95250e26c7a6b468126ac7c75b0">How it works</a><ol type="a"><li><a href="#_TOC_ddd6939c0f0cff6ceb8b36172e02b459">How a normal DECstation boots</a></li><li><a href="#_TOC_f9ff15b5ee1683a37691730e23cbd714">How uMIPS boots</a></li><li><a href="#_TOC_55a0a5396aa1bd6b11c6eb5f8ce8d62a">How uMIPS runs</a></li><li><a href="#_TOC_d70d07edc2b683000e09c709f5921fe9">Linux changes</a></li></ol></li><li><a href="#_TOC_9a98bd63857ec302fcec693aae109dde">Improving performance</a><ol type="a"><li><a href="#_TOC_0f63c0f6caf6daba30629abfa403d51a">Instruction cache</a></li><li><a href="#_TOC_fc5278bbec5501f7f5fe590fb59653f2">Improving CPU speed</a></li><li><a href="#_TOC_aee3d0e166f8b8358baf265cb949a756">Improving RAM bandwidth</a></li><li><a href="#_TOC_73dc18b03073c31c5a2bbf1264aff327">Dirty hacks specifically for Linux</a></li></ol></li><li><a href="#_TOC_23b5439c727c2e8557d28f8495da9977">How to build and use one</a><ol type="a"><li><a href="#_TOC_c39b56d4489fb2507289e7ae19567b80">Building</a></li><li><a href="#_TOC_b3abf203d70a08b6d9725f0000f27122">Building from source</a></li><li><a href="#_TOC_7b797cff6f4cf0ca82225d6125fe1861">If you are lazy</a></li><li><a href="#_TOC_3f05d6f38862a5b18b2eb4e867a61fb1">Using</a></li></ol></li><li><a href="#_TOC_425d8e1e777a03c3e220dfaac38dbf1f">Version 2</a><ol type="a"><li><a href="#_TOC_2b50d6628ed817de809605854d478f68">Booting Ultrix</a><ol type="I"><li><a href="#_TOC_2375a25fb86a26c24006ed1d6e2c1c47">About Ultrix</a></li><li><a href="#_TOC_c7bce03d32236f53d1a3d5c04e680838">First time booting Ultrix</a></li><li><a href="#_TOC_87e05c1a936fe8f08f1621e5cd10c534">SCSI</a></li><li><a href="#_TOC_938bce276b64c8ccdaeb079ff7a0bd84">LANCE</a></li><li><a href="#_TOC_2b0d0fb2ee0246234fe0fd9845b87021">ESAR</a></li><li><a href="#_TOC_73d22765ace36f09f4bab935a1608d3c">Memory probing &amp; proper PROM API</a></li><li><a href="#_TOC_c6323dca5b2dcaf05756b569ad13f4b9">Ultrix Loader</a></li></ol></li><li><a href="#_TOC_fd2d1e73f2cd71a4c375685b4abed537">Making Ultrix work</a><ol type="I"><li><a href="#_TOC_42badd9e49002a3cefeaaf28867add83">Framebuffer</a></li><li><a href="#_TOC_347b8386b145ced18ea02f2654e00883">Mouse, Keyboard, ... and Tablet</a></li><li><a href="#_TOC_c4d283323af70979073f5cb6145f3a4b">Patches</a></li></ol></li><li><a href="#_TOC_9f744f0f0ac29e818b7b95da8ad8ee40">Improvements in the emulator</a><ol type="I"><li><a href="#_TOC_7c775bb4800b345425796dce2acef3a8">USB improvements</a></li><li><a href="#_TOC_c5f0dc32adc4e66649115eef7e76f94f">More perf improvements</a></li><li><a href="#_TOC_819a79dcd016b5a99e05c56515825abb">Removing the TLB refill fast path</a></li><li><a href="#_TOC_dda4cbe5c1a77c2c9bf66b0adc6fff4b">Cache geometry changes</a></li><li><a href="#_TOC_b3c8fd852368b78e09e2fc8b39a6ea5c">Serial improvements</a></li></ol></li><li><a href="#_TOC_cb1862398dbf0b5f7d8a7dbe73bee626">More Floating Point Unit work</a></li><li><a href="#_TOC_244cd79fc0c2e4a295228e647cf88dbc">A bootloader</a></li><li><a href="#_TOC_7fa430e699655fa918b84f63d1c5fae5">Hardware improvements</a><ol type="I"><li><a href="#_TOC_9183d42e96c2104c27070b535e3793d9">v1.3 hardware</a></li><li><a href="#_TOC_8971392389323f2057db749c94dcba05">And old hardware too</a></li></ol></li><li><a href="#_TOC_1a574cfae32687e675d081616b06e0a0">Building from source (updated)</a><ol type="I"><li><a href="#_TOC_3d2780b0eeabee178926de36f72658b8">The emulator</a></li><li><a href="#_TOC_7213a2cd3fa80d577b3092f614b7fdb3">The loader</a></li></ol></li><li><a href="#_TOC_d8926db6c437f738792454ba22ec2755">Further Updates</a><ol type="I"><li><a href="#_TOC_52cbfe3bfc8a13d03124dd2283d83807">Firmware v2.1.1</a></li><li><a href="#_TOC_6b3ae1897005585fd36708ff39e693cf">Firmware v2.2.0</a></li></ol></li></ol></li><li><a href="#_TOC_3cd960e7edc378fd94d8777b595ea515">In conclusion</a><ol type="a"><li><a href="#_TOC_0407c27180c9b019e644e8ad4c6a9324">Acknowledgements</a></li><li><a href="#_TOC_c20c35ef53bf1b70789ce94e66800147">Downloads</a></li></ol></li><li><a href="#_TOC_7e1e75c32bc9b275daf70df8cba8efb5">Comments...</a></li></ol>







<h2>Why?</h2>
<p><a href="http://dmitry.gr/images/linuxCardWhole.jpg"><img src="http://dmitry.gr/images/linuxCardWholeSmall.jpg" alt="Linux card in action"></a></p><p>A long long time ago (in 2012) I <a href="http://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit">ran Linux on an 8-bit AVR</a>. It was kind of a cool record at the time. I do not think anyone has beaten it - nobody's managed to run Linux on a lower-end device than that 8-bit AVR. The main problem was that is was too slow to be practical. The effective speed was 10KHz, the boot time was 6 hours. Cool, but I doubt that any one of those people who built one of those devices based on my design ever waited for the device to boot more than once. It was time to improve it!
</p>
<p>So what could I improve? A number of things. First, I wanted the new design to be speedy enough to boot in a few minutes and reply to commands in seconds. This would make using the device practical and not a test of patience. Second, I wanted it to be easy to assemble for anyone. This meant no components with tight spacing, no components with too many pins, and no components with contacts hidden underneath them. A part of this wish was also that someone could <em>actually</em> assemble one, meaning that I had to select components that are <em>actually</em> buyable in the middle of the current ongoing shortage of, well, everything. Additionally, I wanted the device to be easy to interface with. The original project required a USB-to-serial adapter. This would not do. And, finally, I wanted the whole thing to be cheap and compact enough to serve as my business card.
</p>

<h2>Parts selection</h2>
<p><a href="http://dmitry.gr/images/linuxCardSchem.png"><img src="http://dmitry.gr/images/linuxCardSchemSmall.jpg" alt="Linux card schematics"></a></p><p>Some things were pretty easy to decide on. For storage, for example, microSD is perfect - easy to interface with, widely available, cheap. I picked a simple microSD slot that is easy to solder and easy to buy: <a href="https://octopart.com/1140084168-amphenol-25513977?r=sp">Amphenol 1140084168</a>.
</p>
<p>Some choices were a litle harder, but not too much so. For example, I was surely not going to use DRAM again. It requires too many pins, necessitating more soldering than I would consider acceptable, given that I wanted this device to be easy to assemble. SRAM in megabyte sizes does not really exist. But there is a cool thing called PSRAM. It is basically DRAM, but in easy mode. It itself takes care of all the refreshing and externally acts just like SRAM. Ok, cool, but still that would usually be a lot of pins. Right? Enter "AP Memory" and "ISSI". They make QSPI PSRAM chips in nice SOIC-8 packages. AP Memory has models with <a href="https://octopart.com/search?q=APS1604M-3&amp;currency=USD&amp;specs=0">2MB</a> and <a href="https://octopart.com/search?q=APS6404L-3&amp;currency=USD&amp;specs=0">8MB</a> of RAM per chip, ISSI has them in <a href="https://octopart.com/search?q=IS66WVS1M8BLL&amp;currency=USD&amp;specs=0">1MB</a>, <a href="https://octopart.com/search?q=IS66WVS2M8BLL&amp;currency=USD&amp;specs=0">2MB</a>, and <a href="https://octopart.com/search?q=IS66WVS4M8BLL&amp;currency=USD&amp;specs=0">4MB</a> sizes. I decided to use these. They are available and my code supports them all!
</p>
<p>There were some miscellaneous choices, like which regulator to use. I chose <a href="https://octopart.com/search?q=MIC5317-3.3YM5TR&amp;currency=USD&amp;specs=0">MIC5317-3.3YM5TR</a> due to having worked with it before and it being available in my "random chips" box. It is also easily available to buy.
</p>
<p>The USB connector was also a fun choice. I settled on: none. With the proper PCB thickness, one can lay out the board edge to fit into the end of a USB-C cable. I've seen this done before for micro-USB and figured it could be done for USB-C as well. At the end, though, I did not even need to do it, since <a href="https://github.com/Pinuct/Eagle_PCB_USB_connectors">someone else</a> already saved me the 30 minutes it would have taken. I just had to remember that the board thickness needs to be 0.8mm for this to work. 
</p>
<p>The last choice was the hardest - which microcontroller to use. The criteria were: built-in USB, no more than 32 pins with at least 0.65mm spacing, no pin-less packages, actually available to buy, QSPI support, as fast as possible. I did not get my last two wishes. After much searching and filtering for "in stock", I was forced to settle for an ATSAMD21 series chip, specifically the <a href="https://octopart.com/search?q=ATSAMDA1E16b-a&amp;currency=USD&amp;specs=0">ATSAMDA1E16</a>. It is not fast (specced to 48MHz, I clock it at 90MHz), it has many bugs (especially in its DMA engine), but it can be bought, it is easy to solder, and it'll have to do... <b>UPDATE</b>: another chip is now supported too, see later in this article.
</p>

<h2>What to emulate</h2>
<p><a href="http://dmitry.gr/images/linuxCardWholeBoot.png"><img src="http://dmitry.gr/images/linuxCardWholeBootSmall.png" alt="Linux card boot log"></a></p><p>I could have just taken my old ARM emulator (uARM) and used that. But what's the fun there? I decided to pick a new target. The ideal emulation target will: (1) be a RISC chip so that I have to spend fewer cycles on decoding instructions, (2) have no condition codes (like MIPS) or only set them on demand (like ARM), so that I am not wasting time calculating them every virtual cycle, (3) be 32-bit since 16-bit machines are all funky and 64 bit is a pain to emulate, (4) be known, and (5) have a workable set of GNU tools and Linux userspaces available. This set of requirements actually only leaves a few candidates: PowerPC, ARM, MIPS. I've done ARM, and I had no desire to mess with an endian-switchable CPU, so MIPS it was! This gives rise to the internal name of the project: uMIPS.
</p>
<h3>A MIPS primer</h3>
<p>MIPS is old - one of the original RISC designs. If you are a RISC-V fanboy(/girl/being), MIPS will look familiar - it is where 99.9994% of the initial RISC-V spec was copied from. The original MIPS was a 32-bit design, optimized for ease-of-designing-it. It has (and does not hide) a delay slot, has a lot of registers, including a hard-wired zero register, and does not use condition codes. The original design was R2000, back in 1986, followed soon by the improved R3000 in 1988. These were the last chips implementing the MIPS-I instruction set. MIPS-II was short lived and only included the R6000, which barely saw the light of day. The real successors were the MIPS-III R4000-series chips, released in 1991. These were 64-bit already in 1991! Clearly, the easiest target would be the R2000/R3000 chips with their simple MIPS-I instruction set.
</p>
<p>MIPS-I is a <a href="https://vhouten.home.xs4all.nl/mipsel/r3000-isa.html">rather simple instruction set</a>. So much so that a complete emulator of just the instructions can be written in under 1000 lines of C code without any dirty tricks. The floating point unit is optional, so it can be skipped (for now). The MMU is weird. It is just a TLB that the software must fill manually. This may seem like a rather unusual choice, but in reality it is a clever one, if you're in 1986 and tring to minimize the number of transistors in your chip. Why have a hardware pagetable walker, when you can make the software do it? You may ask how it handles the situation where the code that would do the walking is itself not mapped? Well, a part of physical memory is always hard-mapped at a certain address, and all exception handlers live there. Even if this were not the case, since the software manages the TLB, it would not be hard to reserve an entry for this purpose. The hardware even has support for some "wired" entries that are meant to be permanent. More on all of this later.
</p>
<h3>What system?</h3>
<p>MIPS R2000/R3000 is a processor. A processor does not a complete system make. What system to emulate? I searched around for a cool system and settled on DECstation2100 (or its big brother - DECstation3100). Why bother? It seemed like a simple system that Linux does support. Initially I was not planning to emulate the whole thing. Why? I had no plans to emulate the LANCE network adapter or the SII SCSI adapter. The last part might surprise you, since we will need a disk to use as our root fs. I did later add emulation of both of these parts, to make Ultrix happy.
</p>

<h2>Let's emulate!</h2>
<h3>The CPU</h3>
<p>MIPS is a rather old instruction set, which shows in a few places. The main one is that it attempts to prevent signed overflow. The normal instructions used for addition and subtraction will cause an actual exception if they cause an overflow. This does not map to how CPUs are used today, so nobody cares, but I still had to emulate it. There are "unsigned" versions of the instructions for addition and subtraction that do not do this, which is what all modern compilers will emit on MIPS.
</p>
<p>I wrote an emulator for the CPU in C first, to allow easy testing on my desktop, while the PCBs were being manufactured. It was not fast, nor meant to be, but it did allow for testing. You can see this emulator in <span>cpu.c</span>. Along the way here, I implemented some features of the R4000 CPU optionally. It turned out that to boot Linux compiled with modern compilers, this is necessary, as the compilers assume these instructions exist. Technically this is a bug. Realistically, I am likely the only person to ever notice. So, which features did I need to add? Likely branches (<span>BxxL</span> instructions), conditional traps (<span>Tcc/TccI</span> instructions), and atomics (<span>LL/CC</span> instructions).
</p>
<p>Of course, C is not the language one uses when one wants to go fast. I wrote an emulator in assembly too, targetting ARMv6-M (for the Cortex-M0 MCU I chose). I later added a sprinking of enhancements for ARMv7-M (in case I ever upgrade the project to a fancier CPU). This was tested on a Cortex-M7 and worked well too. The assembly emulator core is contained in <span>cpuAsm.S</span> and the ARMv6-M specific parts are in <span>cpuM0.inc</span>
</p>
<p>I mentioned delay slots earlier. What is a delay slot? Well, back in the day it was considered cool to expose your CPU's pipeline to the world. Just kiding, it was just a way to save some more transistors. Basically, the instruction after a jump will be executed even if the jump happens. This is called the delay slot. A naive way to avoid dealing with this is to place a <span>NOP</span> after each jump instruction. But with a good compiler, the delay slot can be put to a good use in almost all cases. Obviously one cannot place a jump instruction in the delay slot, since the CPU is already jumping somewhere. Doing this is illegal and undefined. An issue arises, however, if the instruction in the delay slot causes an exception of any sort. The CPU will record that the instruction was in the delay slot, and point the exception handler to the <em>jump</em> whose delay slot we're in. There is no way to return to this "in delay slot" state, so the exception handler is expected to take steps to somehow execute the delay-slot instruction and then complete the jump.
</p>

<h3>The FPU</h3>
<p>The DECstation came with an FPU, so that floating point operations would be fast. Back then this was a separate chip, which was optional in a MIPS R2000/R3000 system. Linux, in fact, will more-or-less corectly emulate the FPU if it is not present, but this is slow. I used this mode initially, and even fixed a few bugs in Linux's emulation, but, in the end, I implemented an FPU emulator. This was necessary since it seems like a lot of MIPS binaries I could find all assume the FPU is available and use it freely. I never reimplemented the FPU emulator in assembly, instead calling out to the C FPU emulator when needed. I figure that squeezing a few cycles out of each instruction is meaningless when the actual FPU operation takes hundreds. The code for this is in <span>fpu.c</span>. I include Linux patches to remove FPU emulation support from the kernel. This saves some RAM. Later, I also added support for a "minimal" FPU - it supports the registers but no operations. This is allowed by the spec, since the FPU may refuse to execute any operation it is "not sure it can do perfectly correctly", so any compliant OS must implement a full FPU fallback anyways. Why? This saves 16K of code size in the binary, opening the possibility of running uMIPS on smaller devices yet.
</p>
<h3>The MMU</h3>
<h4>MMU basics</h4>
<p>(this is a <em>very</em> oversimplified summary, feel free to skip if you know this, and do not complain to me that it is not perfectly accurate!)
</p>
<p>Most CPUs access memory using virtual addresses (<span>VA</span>). The hardware works in terms of physical addresses (<span>PA</span>). Ability to map one to the other is the underpinning of memory safety in modern operating systems. The purpose of an <span>MMU</span> (Memory Management Unit) is to translate virtual addresses to physical addresses, to allow for this mapping. Normally this is done using a tree-like structure in RAM, called a <span>pagetable</span>. Most CPUs have a component whose job it is to walk that structure to resolve what physical address a given virtual address maps to. This component is a <span>pagetable walker</span>. In most cases the <span>pagetable</span> has 3 or 4 levels, which means that resolving a <span>VA</span> to a <span>PA</span> requires reading 3 or 4 words from main memory. Clearly you do not want to do 3 useless memory accesses for every useful one. So usually another component is included in an <span>MMU</span> - a <span>TLB</span> (Translation Lookaside Buffer). Basically you can think of a <span>TLB</span> as a cache of some of the current <span>pagetable</span>'s contents. The idea is that before you go off doing those 3-4 memory reads into the <span>pagetables</span>, you can check and see if the <span>TLB</span> has a matching entry. If so, you can skip the <span>pagetable walk</span>.
</p>
<p>Clearly, like any cache, the <span>TLB</span> needs to stay in sync with the things it caches (the current <span>pagetables</span>). So, if the OS changes the <span>pagetables</span>, it needs to flush the <span>TLB</span>, since it might have stale entries. Usually, <span>TLB</span>s expose very little interface to the CPU, so there isn't a way to go read all the entries and remove only the newly-invalid ones. Additionally, this would be slow, so this is not usually done. However, invalidating the entire <span>TLB</span> also has costs - it needs to be re-filled, at the cost of 3-4 memory accesses per entry. This could hurt performance. A solution commonly used is called an <span>ASID</span>.
</p>
<p>What are the four main cases when <span>pagetables</span> might be modified? (1) Adding a new mapping over a virtual address that previously was not mapped to anything, (2) changing permissions on on existing mapping, (3) removing a mapping, and (4) entirely changing the memory map (for example to switch to a completely different process). In case 1, no <span>TLB</span> flush is necessary, since no stale <span>TLB</span> entry can exist. Cases 2 and 3 do indeed require flushing the <span>TLB</span>, but they aren't that common. Case 4 is quite common, though. It is done at every context switch. One might point out that since we're changing the entire memory map, the entire <span>TLB</span> would be invalid, and thus flushing it isn't a problem. This is wrong. Besides mapping userspace things, the <span>MMU</span> also maps various kernel structures, and there is no point penalizing them.
</p>
<p>If we could somehow tag which entries in the <span>TLB</span> go with which process, and temporarily disable them when another process runs, we could avoid a lot of context-swich flushing and the performance costs imposed by it. It would also be cool if we could tag entires that belong to the kernel and are valid in every process. Well, this exact technology exists in many <span>MMU</span>s. The idea here is that each <span>pagetable</span> entry will have a bit marking it as "global" (valid in all memory maps) or not. There should also be a register in the CPU setting the current <span>ASID</span> (Address Space ID). When a <span>TLB</span> entry is populated from the <span>pagetables</span>, the current <span>ASID</span> is recorded in it. When a lookup in the <span>TLB</span> is done, only entries matching the current <span>ASID</span> or those marked "global" will match. Cool!
</p>
<h4>The MIPS MMU</h4>
<p>The idea at the time was to save transistors. Which of the above could be cut? Well, cutting out the <span>TLB</span> guarantees terrible performance in all cases. But that <span>pagetable walker</span>, do we really need it? What if we make the sotware do it? We can add a little bit of assistance, like ability to manage the <span>TLB</span> efficiently, but skip on the <span>pagetable walker</span> hardware. This is what MIPS did. Here is the MIPS virtual address space:
</p>
<p>Addresses               Name   Mapping
0x00000000..0x7fffffff  kuseg  mapped via MMU
0x80000000..0x9fffffff  kseg0  mapped to physical 0x00000000..0x1fffffff, cached if there is a cache, only accessible in priviledged mode
0xa0000000..0xbfffffff  kseg1  mapped to physical 0x00000000..0x1fffffff, not cached, only accessible in priviledged mode
0xc0000000..0xffffffff  kseg2  mapped via MMU, only accessible in priviledged mode
</p>
<p>So, as you can see, some <span>VA</span>s do not map via the <span>MMU</span> at all. This means that code living there is able to run no matter the state of the <span>MMU</span>. Linux and Ultrix, predictably, put the kernel in <span>kseg0</span>. The kernel does, however, need to be able to dynamically map things in as well. <span>kseg2</span> is one gigabyte of address space that is mappable via the <span>MMU</span> that the kernel can use. Memory-mapped devices will usually be accessed via <span>kseg1</span>. The 2 gigabytes at the bottom of the address range(<span>kuseg</span>) are for userspace tasks.
</p>
<p>What entry in a <span>TLB</span> should one replace when one needs to insert a new entry? An obvious answer might be "the one least recently used", but that would require tracking use, which costs transistors too. A simplification is "the one least recently added". This is easy, but it hides a fatal flaw. Imagine your <span>TLB</span> has N entries, and your workload sequentially uses N + 1 addresses, such that each would need a <span>TLB</span> entry. Now you'll always be replacing the entry you're about to need, guaranteeing that you <em>NEVER</em> hit the <span>TLB</span> and do a lot of pointless <span>pagetable</span> walks. How do we avoid this? The simplest method is replace a random entry. Sure, it might be the entry you're about to need, but for an N-entry <span>TLB</span> the chances are 1/N.
</p>
<p>Generating random numbers is slow in software, so MIPS R2000/R3000 provide some help. The CPU has a register called, literally <span>RANDOM</span> which is supposed to be constantly incrementing, every cycle. Since the "when" of "when will you next need a new <span>TLB</span> entry" is not predictable, this is as good as random, and requires very few transistors. The idea is that whenever you need to replace a <span>TLB</span> entry, you use a special instruction <span>TLBWR</span> to write to a random entry. I did not tell you about <span>ASID</span>s by accident either. The MIPS R3000 <span>MMU</span> implements a 6-bit <span>ASID</span>.
</p>
<h4>Emulating the MMU efficiently</h4>
<p>Emulating the R3000 <span>MMU</span> is a bit of a pain. Since any entry can be in any location, the proper way to do a lookup is to check each one. Doing a 64-cycle loop for every memory access is a non-starter speed-wise, of course. I use a hashtable indexed by the virtual address to keep all the TLB entries in buckets for faster checking. Using 128 buckets virtually guarantees that most buckets have zero or one entry in them, permitting much faster lookups. Initially this was a simple table of pointers, but this used too much RAM, so now it is a table of indices.
</p>
<h3>Communication</h3>
<p>The DECstation had a few ways to communicate with the outside world. It had a built-in network card<s>, which I do not emulate</s>. It was optional<s>, and I haven't found a use for it yet</s>. Maybe I will later - it does not look complex. It also had a SCSI controller which one could attach hard disks and other SCSI peripherals to. Emulating this would be a fun challenge, and I'll probably get to it later, but I did not do it now - it was not necessary - I wrote a paravirtualized disk driver for Linux using hypercalls, more on this later. There was also an optional framebuffer card one could install that added support for a monochrome or a color display. Emulating these would also not be too hard, but my business card lacks a display, <s>so I did not do it either</s> - plus I am not even sure that Linux can make a use of it.
</p>
<p>The last method of communications that the DECstation had was <span>DC7085</span> - a serial port controller that is basically a clone of a PDP11-era <a href="https://gunkies.org/wiki/DZ11_asynchronous_serial_line_interface"><span>DZ-11</span></a>. It supports four serial ports at a blistering 9,600bps speed (or any integer division thereof). Each serial port was allocated a purpose, and they were wired to different connectors indicating this purpose. #0 was for the keyboard, #1 for the mouse, #2 for modem, and #3 for printer. To the machine they are all the same, this was just the purpose DEC assigned to them. The stock <span>PROM</span> would use #3 as serial console instead if it did not detect a keyboard at #0, thus it is customary to use #3 as serial console for Linux on the DECstation. My <span>PROM</span> surrogate does not bother looking for or supporting external keyboard, and just defaults to serial console on #3. That being said, since it is cool to allow multiple login sessions, I also export <s>#0</s> #2 as a second virtual serial port, so that you may login from two serial consoles at once, and do two things at once. How cool is that?
</p>
<p>So, how do I export these serial ports? When you connect the card to a computer, it'll show up as a USB composite device comprised of two CDC-ACM virtual serial ports. One of them is port #3, another is port <s>#0</s> #2 on the virtual <span>DZ-11</span>. How will you know which is which? #3 has the boot console printing and will have the initial <span>sh</span> prompt. If you do not see this, try the other one, computers do not always number them in the order I export them.
</p>
<h3>Hypercalls</h3>
<p>In the real world the <span>PROM</span> had to probe the real hardware to detect what was present where. As my <span>PROM</span> is running in an emulator, there is no need for such mess. We can simply request things from the emulator in an agreed-upon way. That way is a <span>hypercall</span> - a special invalid instruction that, if encounted in supervisor mode, the emulator will treat as a request for some kind of service. The instruction I chose is <span>0x4f646776</span>, which is in the <span>COP3</span> (coprocessor 3) decode space that was not allocated to any real purpose in these chips. The calling convention is close to the normal C calling convention on MIPS: parameters are passed in <span>$a0</span>, <span>$a1</span>, <span>$a2</span>, and <span>$a3</span>, return values are in <span>$v0</span> and <span>$v1</span>. The <span>$at</span> register gets the "hypercall number" - the specific service we're requesting.
</p>
<p>A few hypercalls are implemented. #0 is used to get the memory map. The parameter is word index of the memory map to read. Word 0 is "how many bits the memory map bitmap contains", word 1 is "how many bytes of RAM each bit represents", words 2 and on are the bits of the map, up to the total specified in word 0. This can be used to build a memory map that the <span>PROM</span> can furnish to the running OS and allows me to have discontinuous RAM. Linux supports this and I tried it, but did not end up needing it. It is here in case I change my mind and need it again.
</p>
<p>Hypercall #1 outputs a single byte to the debug console (which is the same as <span>DZ-11</span> port 3). This is used by the <span>PROM</span> and <span>mbrboot</span> to output debug strings without needing to have a complete <span>DZ-11</span> driver in there. Hypercall #5 will terminate emulation. This can be used on the PC version of the emulator to quit peacefully.
</p>
<p>Hypercalls #2, #3, and #4 are used for SD card access. #2 will return card size in sectors, #3 will request a read of a given sector to a given physical RAM address and reply with a nonzero value if that worked. #4 will do the same for a card write.
</p>

<h2>Bring on the hardware!</h2>
<h3>The honeymoon period</h3>
<p><a href="http://dmitry.gr/images/linuxCardBoard.png"><img src="http://dmitry.gr/images/linuxCardBoardSmall.jpg" alt="Linux card board layout"></a></p><p>The first revision of this board came up well initially, after I sorted out the mess that is ATSAMD21's clocking system. I appreciate flexibility as much as the next guy, but this thing is <em>TOO</em> flexible. It took a lot longer than I'd care to admit to get this thing running at a sane speed and to enable some peripherals. The docs were too sparse to be of much use, too. Atmel, what happened to you? You used to have the best docs!
</p>
<p>The first revision of the board had two memory chips, each on their own SPI bus, an SD card on an SPI bus, and USB with the proper resistors. The USB was perfect. Unlike everyone and their grandmother (STMicro, I am glaring at you), Atmel did not license annoying Synopsis USB IP. They made their own. It is easy to use, elegant, and works well. Seriously, it just worked. In two days I got the hardware to work and wrote a USB device stack. I tip my hat to the team that worked on the USB controller. That being said, I have concerns. My main issue: USB descriptors aren't small. They are constant. I'd prefer to keep them in flash. I'd prefer to, but cannot. The USB unit uses a built-in DMA unit to read the data to send. This DMA unit <em>CAN</em> access flash, but if you have any flash wait states enabled, it sends garbage. I suspect that Atmel only tested it for reading from RAM, forgot that some memories have wait states, and did not account for that. Keeping all my descriptors in RAM is a colossal waste of RAM, which there is only 8KB of. Remember that tiped hat? I rescind it, Atmel. I had to work around the issue by sending the descriptors one piece at a time (rather than letting the hardware DMA it all automatically) just to save the valuable RAM.
</p>
<p>Using the SPI units directly worked well enough, until I tried to speed them up. Past about 18MHz The received data was garbled (missing a bit or two, all the following bits shifted). No amount of searching found an issue in my code, and all sample code did more or less the same things. My bus analyzer showed no issues. What gives? <a href="https://microchipsupport.force.com/s/article/SPI-max-clock-frequency-in-SAMD-SAMR-devices">THIS GIVES</a> (<a href="https://archive.ph/IJTHU">archived</a>)! I was beyond furious when I found this forum post. Here I was, trying to build a fast device, and my SPI bus was going to be limited to the speed of a tired snail calmly strolling through peanut butter! With some more testing I found that the SPI units will work fine to about 16MHz, which I'll have to live with.
</p>
<p>The SPI units have no FIFOs, so code must manually feed them one byte at a time and read one byte at a time. This means that there is space between bytes on the bus as code wrangles bytes in and out of registers and memory. This is a waste of potential speed. The solution is DMA. Luckily this chip has DMA. Unluckily, it is fucked beyond belief, to a point where I am beginning to suspect that it was designed by a sleep-deprived stark raving lunatic.
</p>
<h3>How not to design a DMA unit</h3>
<p>A normal garden-variety DMA unit has some minimal global configuration, and a few channels, each independent from the rest. Each channel will usually have a source address, a destination address, a length, and some configuration, to store things like transfer chunk size, trigger, interrupt enable bits, etc. Thus it is common in ARM MCUs to have each channel have precisely these 4 32-bit configuration registeres: SRC, DST, LEN, CFG. This is 16 bytes of SRAM per channel. ATSAMD21 has 12 DMA channels, so that would be 192 bytes of config data for the DMA unit as a whole. Not that much. Well, Atmel was having none of this! Instead, the unit itself only has a <em>POINTER</em> to where in the user RAM all this config data lives. For every transfer, the DMA unit will load its internal state for the active channel from this structure in RAM, and then operate on the channel. If another channel's data was already loaded, it will be written out to RAM first. Depending on your experience level, you may already be on your third or fourth "oh, hell fucking no" as you read this...
</p>
<p>Why is this bad? Let's imagine two SPI units being fed by DMA. Each one will have two DMA channels, one for receive, one for transmit. Four channels are active in total. Now what happens as both the SPI units are enabled? Two DMA channels (the transmit ones) will go active and attempt to send a byte. One will go first, then the second. This will generate <em>14</em>(!!) bus transactions to the RAM! Four to read config data for one channel, one to read the byte to send, four to write back this config data, four to read the config data for the next channel, and one more to read the byte to send. So in order to send 2 bytes, the DMA unit did 14 RAM accesses. Not great. But wait...there's more. Let's take a look what happens next, as the SPI units finish sending this byte and clocking in the received byte, but are also ready for the next byte to send! At this point in time, logically only four bytes need to be moved (two from the units into the receive buffers, two from the transmit buffers into the units). Let's see how this plays out. Remember the DMA unit's internal config data is currently loaded to the second transmit channel's. First, it'll have to do 4 writes to write that data out, then 4 reads to load the first receive channel's structures, one write to memory to write the received byte to RAM, 4 writes to write out this channel's structures out, 4 reads to load structures for receive channel number 2, one write of the received byte to RAM, 4 bytes to write out the config structure for this channel back out to RAM, and then the 14 we already discussed to send the next two bytes. That adds up to 36 RAM accesses to simply read two bytes and write two bytes. All this pain, simply to save the transistors on the 192 bytes of SRAM it would have taken for the DMA unit to store all the config data internally.
</p>
<p>So, why is this bad? Let's say our MCU is running at its designed speed of 48MHz, its SPI units running at their designed max speed of 12MHz. At the point the second bytes need to be sent and first received bytes need to be received, we'll need to perform 36 accesses to RAM, but also 4 accesses to the SPI unit. The SPI unit is on an APB bus, which means that any access to it takes at least 4 cycles. This means that in between each sent and received byte we'll need 36 + 4 * 4 = 52 cycles. If the SPI unit runs at 1/4 the CPU speed, then it will send/receive a byte every 8 * 4 = 32 cycles. So every 32 cycles we'll need to do 52 cycles' worth of work. When they do not get enough cycles, the DMA channels give up and stop working... Oops... 
</p>
<p>So, what can be done? I worked out a hybrid method where I send data using CPU writes and receive using DMA. This worked for two channels, but would not work for more. Once I got rev2 boards that had 4 RAM chips, even this failed, as just the 4 receive DMA units starved each other of bandwidth and got cancelled. Why was Atmel so damn stingy with internal SRAM? We'll probably never know. But they could have solved this exact issue simpler than with 192 bytes of SRAM in the DMA unit. Just adding a 4-byte FIFOs into the SPI units would do as well, then each DMA transaction could transfer more than a single byte, alleviating this traffic jam. Sadly, apparently nobody at Atmel has even tried to actually use their chip for anything. Atmel, what happened to you?
</p>
<h3>Clocks again</h3>
<p>My clocking woes were not over yet. This chip has a number of internal oscillators, one of which is supposed to be a rather precise 32KHz oscillator called <span>OSC32K</span>. I wanted to use that as a source clock for a timer to implement my virtual real time clock. Well, despite much pain and many tears, the damn clock would not start... ever. The code should be simple: <span>SYSCTRL-&gt;OSC32K.bit.EN32K = 1; SYSCTRL-&gt;OSC32K.bit.ENABLE = 1; while (!SYSCTRL-&gt;PCLKSR.bit.OSC32KRDY); </span> Yeah... that did not happen. At the end, I decided that I can use a less-precise <span>OSC32KULP</span> to clock my timer. That one did start and I was able to use it. By this point in the project I was worn out, desensitized to this chip's many faults, and completely out of WTFs, so I resigned myself to a slightly imprecise real-time clock and trudged on.
</p>
<h3>SD card support</h3>
<p>Not really much to say about SD card support. Been there, done that, got the t-shirt. My initial code for the prototype used multi-block reads and writes for better card access speed, but in the final prototype I was forced to abandon it since one of the RAM chips on the b2 boards shared the SPI bus with the SD card, so leaving the card selected was not an option. This was not that big a deal since SD access is rarely, if ever, a bottleneck here. Any card up to 2TB is supported.
</p>
<p>In the v2 revision of the board I wired up card detect pin to the MCU. It was not used, but I thought that I might find a use for it. I did not, so in v3 boards it was removed. I also added a card "activity" LED which lights up when card is accessed. It is simply a LED between the card's chip select line and Vcc. Whenever the card is selected, it is on. This LED also surves a second purpose. If at boot time the SD card or SPI SRAMs fail to initialize, it'll blink out an error code to help identify the problem.
</p>
<h3>Coolness enhancement</h3>
<p>Now that the prototype worked and I was doing the layout for the final version, I decided to do some things to make it look cool. I buried all the traces in layers 2 and 3, leaving layers 1 and 4 uninterrupted copper. It loooks super cool! Of course the top layer copper is interrupted for the actual SMT pads, but other than that, it is all perfectly smooth and looks amazing!
</p>

<h2>How it works</h2>
<h3>How a normal DECstation boots</h3>
<p>Normally there is a built in 256KB ROM (called <span>PROM</span> by DEC) at physical address <span>0x1fc00000</span> that contains enough code to show messages onscreen and accept keyboard input, talk to SCSI devices, load files from disk to RAM and jump to them. This <span>PROM</span> also provides a lot of services to the loaded operating system via an array of callbacks. This includes things like console logging, EEPROM-backed environment variables, memory mapping info, etc. This is rather similar to UEFI. Normally this <span>PROM</span> would read the environment variables from EEPROM that would tell it which device to boot, and then load a kernel and boot from that device if all goes well. This emulator does not boot this way
</p>
<h3>How uMIPS boots</h3>
<p>I had no desire to include a large ROM in the emulator, as the flash space in the microcontroller is limited. I also do not have a graphical console or a keyboard per se. That being said, I had to implement a sizeable subset of the <span>PROM</span> somehow, since MIPS Linux uses it. What to do? I decided to come up with my own boot process, which can still work just as well. There is indeed a ROM at <span>0x1fc00000</span>. This is necessary for rebooting to work from Linux. <s>That rom is tiny - 32 bytes</s>. Its source code is found in the "romboot" directory. It <s>merely</s> loads the first sector of the SD card to the start of RAM at <span>0x80000000</span> and jumps to it. The first sector of the SD card contains a standard MBR partition table and up to 446 bytes of code. The code that lives here can found in the "mbrboot" directory. It is also rather simple. It looks through the partition table for a partition with type byte of <span>0xBB</span>. If not found, an error is shown. Else, the partition in its entirety is read into RAM at <span>0x80001000</span>, and then jumped to. This partition can be arbitrarily large, and this is where my implementation of the "PROM" lives. The actual size limit on it is placed by the fact that MIPS Linux expects to be loaded at <span>0x80040000</span>. This is no accident - the first 192K of RAM is reserved for the <span>PROM</span> to use as long as the operating system expects to use <span>PROM</span>'s services. Thus the limit on the loader's size is 188K. 
</p>
<p>My <span>PROM</span> implementation's code can be found in the "loader" directory. It will search the SD card for a partition marked as active, attempt to mount it as FAT12/16/32, and look for a file called "VMLINUX" in the root directory. If found, it will be parsed as an ELF file, properly loaded, and run. Else an error will be shown. As this code has no serious size limits, it implements a proper ability to log to console, printf, and all sort of such creature comforts. As far as <span>PROM</span> services go, it provides console logging, memory mapping info, and reading environment variables, at least enough to make Linux happy. I have not tried to boot other operating systems on uMIPS (yet?).
</p>
<p>The kernel commandline I pass is rather simple: <span>earlyprintk=prom0 console=ttyS3 root=/dev/pvd3 rootfstype=ext4 rw init=/bin/sh</span>. The first parameter provides for early boot logging via the <span>PROM</span> console, which is useful to see. After the kernel is up, it'll use the third serial port for console. Originally for the DECstation that was the printer serial port, but Linux users on DECstation use that for serial console due to that being the easiest port to convert into a simple serial port. The rest just tells the kernel how to boot. I prefer to boot into sh, and then issue <span>exec init</span> myself, thus the <span>init=/bin/sh</span>
</p>
<h3>How uMIPS runs</h3>
<p>After all the optimizations (which I'll detail in a bit) the effective speed of my virtual MIPS R2000/R3000 on this infernal ATSAMD21 chip is around <s>900KHz</s> 1.2MHz. The CPU spends around 8% of its time handling timer interrupts, and thus around <s>0.83MIPS</s> 1.06MIPS of CPU cycles are left for useful work. With this, the kernel takes around 2 minutes to boot and run <span>sh</span>. Executing busybox's <span>init</span> and getting to the login prompt takes another minute. Overall not too bad. Commands reply instantly, or in a few seconds. It takes gcc around 2 minutes to compile a hello world C program, and I estimate that in a few days' time, one could rebuild the kernel on the device itself, copy it to <span>/boot</span>, and reboot into it. Yes, I <s>do intend to try this and time it</s> did do this and it worked!
</p>
<p>The emulated real time clock is actually real time, plus or minus the inaccuracies of ATSAMD21's ultra-low-power 32KHz timer. It is ok enough that you will not notice. Try the <span>uptime</span> command.
</p>
<p>There is just one thing I did not yet address concerning running Linux on uMIPS. The storage. I said that it is an SD card, but surely DECstation had no SD card slot. However, Linux is open source. I simply created my own very simple paravirtualized disk driver which uses a hypercall to talk directly to the emulator and request sectors to be read or written directly into the virtual RAM. To Linux, this looks just like DMA, except instant. The whole implementation of the driver is under 200 lines of code and can be seen in <span>pvd.patch</span>
</p>

<h3>Linux changes</h3>
<p>I made some changes to the kernel to make life easier. They are provided as patches against the 4.4.292 kernel, and as is a working kernel image. Why that version? Because when I started that project, it was an LTS version of the kernel, and since RAM is short, I wanted the smallest possible kernel, so this was preferable to a later version. The config I am using is available in <span>kernel_4.4.292.config</span>. A config for an even smaller kernel (that requires uMIPS to emulate the full FPU) is available in <span>kernel_4.4.292.config_nofpu</span>
</p>
<p>I did a lot of work making the kernel as small as possible. Since Linux does not support paging out pieces of the kernel, every byte of kernel code is one byte fewer available to use for user space. I ruthlessly removed options that were not needed. In the end I got the kernel down to just under 4MB, which is pretty damn good, considering that MIPS instructions are not very dense.
</p>
<p>As part of this work, I made a few code patches. For various reasons (cough..delay slots..cough) the kernel can find itself needing to interpret userspace code, or parse userspace instructions. No matter what kernel configs I gave, the code to handle microMIPS (a future MIPS expansion not known in the days of R2000/R3000) was present. It was wasting space and time trying to handle things that would never happen. The patch <span>useless_exc_code.patch</span> removes this code if the target CPU does not support microMIPS</p>
<p>Before I implemented my FPU emulator, I was using the kernel's FPU emulation code that traps and executes FPU instructions. It had a bug. If compiled for a 32-bit MIPS processor it did not properly emulate some FPU instructions that operate on the double type. I believe this is wrong. It was causing crashes in code compiled for R3000. The patch <span>fpu.patch</span> modifies the kernel's MIPS FPU emulator by adding a config option to enable the full FPU emulation even on MIPS-I chips.
</p>
<p>Due to the differences between the R2000/R3000 and the R4000 the kernel needs to know at build time which CPU it is being built for. If you attempt to run the wrong kind of kernel on the wrong kind of CPU, it only gets far enough to panic about it. Fine, OK, but then why does this flag not affect a lot of TLB-handling code. Both kinds are always compiled in, despite us knowing at build time with 100% certainty that at least half of it will not ever be of any use? The patch <span>tlbex_shrinkify.patch</span> wraps the useless code in checks for the compile-time-selected CPU type and thus removes some kernel code, saving valuable bytes.
</p>
<p>As uMIPS runs with a real real-time clock, I did not want Linux to spend too much time handling timer interrupts. Normally, a 128Hz timer is used on DECstations by Linux. I added options for 64Hz, 32Hz, and 16Hz timer ticks as well. This reduces effective timer resolution, but effectively unloads the virtual CPU from having to spend most of its time handling timer interrupts. The patch <span>clocksrc.patch</span> does this, and the one called <span>kill_clocksrc_warning.patch</span> silences a pointless warning about timer resolution.
</p>
<p>If you do build uMIPS with full FPU emulation, there is aso a patch to remove all of the FPU emulation code from the kernel to save a few KB of RAM: <span>fpu.patch</span>. 
</p>

<h2>Improving performance</h2>
<h3>Instruction cache</h3>
<p><a href="http://dmitry.gr/images/linuxCardCompileTime.png"><img src="http://dmitry.gr/images/linuxCardCompileTimeSmall.jpg" alt="Linux card board layout"></a></p><p>One thing the processor will surely do every cycle is fetch an instruction. This means that every cycle begins with a memory access. For us that is a painful subject thanks to Atmel's errata-ridden SPI unit. And not just that, memory translation also needs to happen, and that also takes time. A good way to avoid both of these problems is a VIVT instruction cache. It'll read instructions 32 bytes at a time, and allow us to hopefully often not need to translate addresses or reach for main memory. I allocated 2KB of RAM to this cache. It is 32 sets of 2 ways of 32 byte lines. Whenever memory mappings change, it needs to be invalidated. I do this automatically and thus the running code on the virtual MIPS CPU does not need to know about it. The measured hit rate while booting Linux is around 95%, which is pretty nice for such a small cache. The geometry was determined experimentally by profiling how long a boot takes with various cache geometries. This one was found to be the best.
</p>
<h3>Improving CPU speed</h3>
<p>ATSAMD21 series is specified to run at 48MHz. In my testing they run perfectly well up to 96MHz, with some specific chips able to hit 110MHz. I found no chip unstable at 96MHz, so I decided to just run at 90MHz, for some safety margin. This immediately got me a pretty serious performance uplift. No, it is not really 100%, since (1) SPI RAM is still limited by the SPI speed limit, and (2) flash memory has wait states which had to increase for the larger speed. But this did give me an honest 65% improvement. Still a good start. Now RAM SPI runs at CPU / 6 = 15MHz.
</p>
<h3>Improving RAM bandwidth</h3>
<p>Since I could not make the RAM SPI units go faster due to Atmel's incompetence, I decided to go wider! I can drive four units at once. Given, there is overhead to each read and write command, but still this is faster than one or two. <s>My code initially supported one, two, or four RAM chips, but for simplification I dropped that support and now only support four-channel RAM.</s> Quite the statement eh? This microcontroller has four-channel RAM! The emulator accesses RAM in increments of 32 bytes. The RAM read/write commands themselves are 4 bytes each. This means that for a single-RAM chip situation, reading 32 bytes takes (4 + 32) * 8 = 288 SPI bits. In dual-channel configuration it'll take (4 + 16) * 8 = 160 SPI bits, since the command is still 4 bytes long, but we only read 16 bytes from each RAM , for a total of 32. For quad-channel RAM, we thus have (4 + 8) * 8 = 96 SPI bits to read 32 bytes. This is a 66% improvement from the single-channel case! In reality the improvement is less, since quad-channel mode cannot use DMA at all, so it is a bit slower. Real-life measurement shows that quad-channel mode is a 50% improvement over the single-channel case. But still, given this damn chip, any improvement is an improvement I'll take.
</p>
<p>But, why are all the RAM acceses 32 bytes in size? Well, as you see RAM accesses are slow. A typical 32-byte access takes 140-ish SPI cycles, which is around 12 microseconds. If every access took that long, my emulated CPU would be limited to no more than 85,000 memory accesses per second. That is too slow to be practical. Something had to be done. I decided on a cache. Sadly, my microcontroller has a very limited amount of RAM, so the cache had to be small. I evaluated various cache geometries, and found that a 20-set 2-way cache with 32-byte lines produced the best performance uplift for the emulator. It gets a 91% hit rate while booting the kernel, which is a pretty good payoff for 1.25KB of RAM. With a hit taking around half a microsecond and a miss taking around 12 microseconds, adding this cache improved the average memory access by 87%! Yes, this is effectively an L2 cache. Now, how many emulators do you know that have an L2 cache to paper over the terrible performance of their chosen host hardware, eh? The cache allocates on reads and writes, except for reads and writes of precisely 32 bytes in size. Those are passed through directly because they are either SD card access DMA or icache fetches that do not need to also be cached in this cache.
</p>
<p>After some more profiling, I rewrote the "hot" part of the memory access code in assembly for some more speed gain. GCC may have come a long way since a decade ago, but it still does not hold a candle up to hand-written assembly. I removed support I had for one and two-channel RAM to simplify the hot path as well. So now you need to populate all four RAM slots for the card to boot. If you populate different RAM sizes, the smallest one will dictate the final usable RAM size. The usable RAM size will always be four times the size of the smallest RAM chip. This isn't a big deal, the DECstation came with 4MB of RAM, and could be outfitted with a maximum of 24MB. This card can be outfitted with 32MB, so you'll be living like a king! That being said, due to the size of the Linux kernel, you're not going to get a successfull Linux boot unless you have at least 6MB of RAM<s>, and uMIPS will refuse to boot if that is the case (eg: if you populate 4x 1MB chip)</s>.
</p>
<h3>Dirty hacks specifically for Linux</h3>
<p><s>Remember how on MIPS the operating system must do its own pagetable walking and filling of the TLB? As you can imagine this happens often. Very often. How could I speed this up without causing any correctness issues? On taking the <span>TLB refill</span> exception, I verify the handler has not changed and matches the expected bytes, if so, I do what it would have done, but in native code, not emulated MIPS. This helps this particular code run quite a bit faster. Correctness is not compromised since this is only done if the handler matches what is expected, byte for byte.</s>
</p>
<p>I also mentioned that due to how delay slots work, if a CPU takes an exception on an instruction in the delay slot, the kernel must be able to completely emulate that instruction, or in other way execute it and then jump to the right place? Linux uses the fact that MIPS has no PC-relative instructions, except jumps, and it is illegal to place a jump in the delay slot. How? Instead of emulating the delay-slot instruction, Linux copies it out to a special page in memory, where it is followed by a trap. Linux then jumps there in user mode to let it execute, catches the trap, and then re-directs execution where it should go. Now, if this sounds like a giant hassle to you, you are right. What can we do? Well, if an instruction in a delay slot causes an actual exception (like an illegal access, or a TLB refill exception, or some such thing), not much can be done. But what we <em>CAN</em> do is not make things worse. uMIPS will not deliver IRQs before executing an instruction in the delay slot of a branch. At worst, this will delay an IRQ by a cycle, which makes no difference to correctness. The benefit is that this sort of instruction copying and juggling can be done less.
</p>

<h2>How to build and use one</h2>
<h3>Building</h3>

<p><a href="http://dmitry.gr/images/linuxCardPcb.jpg"><img src="http://dmitry.gr/images/linuxCardPcb.jpg" alt="Linux card PCBs"></a></p><p>Now, why you really came here. How do you get one? Well, you could try knowing me personally and asking for my business card, I have a few to give out, but other than that, here is how to do it.
</p>
<p>You'll need to order the board from a board fabrication place. I am a fan of <a href="https://jlcpcb.com/">JLPCB</a> and recommend them. The gerber files I provide come in two flavours. One as you see my card exactly, and one without my name and contact info :). This is a four-layer board, the board house will ask you for layer order, it is: GTL, G1, G2, GBL. At least JLPCB has options to also cover the edge connector in gold for better contact, called "gold fingers" and to grind the board edge to 45° for easier insertion. I suggest selecting both of these options - they are free. Remember to set the board thickness to 0.8mm.
</p>
<p>While you wait for the board to arrive, you'll want to order the parts. You'll need four of the same memory chip (I have the links above), an ATSAMDA1E16, an AMPHENOL 11400841 SD card slot, and a MIC5317-3.3YM5TR regulator. You'll also want to (optionally) order an 0603 sized blue or white LED for SD activity light. If you choose to have that LED, you'll also need a 430 ohm resistor in 0603 or 0805 size. Besides that, you'll need in 0603 or 0805 sizes: 2x 5.1Kohm resistor, 1x 1Kohm resistor, 3x 0.1uF capacitor, and 7x 1.0uF capacitor. You will also need an SD card and any SWD programmer capable of programming the ATSAMD chip. There are many out there. Pick your favourite.
</p>
<p>You'll need an SD card as well. 128MB is the bare minimum here if you want to fit the busybox-based rootfs in. To fit the debian or hybrid image I am providing, you'll want at least 512MB. You can write the image to the card using your favourite tool for that. On Linux and MacOS that is probably <span>dd</span>, on windows, <span>Win32DiskImager</span>.
</p>
<p>Once you've assembled the board, program the MCU with the provided binary <span>software/emu/uMIPS.bin</span> and you're done!
</p>
<h3>Building from source</h3>
<p>You'll want to build a few things. You'll need both an ARM (CodeSourcery) and a MIPS GCC toolchain (I used mips-mti-linux I found online). First, build "romboot", "mbrboot", and "loader". Then, build the kernel. I provided the config, patches, etc. Then you'll want to build the emulator. To build for the MCU, use <s><span>make CPU=atsamd21</span></s>(<b>UPDATE</b>: proper target name changed, see updates later in the article). To build for PC, try <span>make CPU=pc</span>. Then you can build the SD card image. You'll want to copy the MBR from one of mine and modify it, then use <span>mkdisk.sh</span> to embed your kernel, mbrboot, and loader. Use a loopback mount to copy in your rootfs.
</p>
<p>If you want to run the emulator on PC, there are a few things to note. First of all, Ctrl^C will kill it :). Second, unlike the MCU version, the PC version does not incorporate the rom loader in the binary, so you'll need to provide a pointer to it on the command line. A typical command line is <span>./uMIPS ../romboot/loader.bin ../disk.wheezy</span>
</p>

<h3>If you are lazy</h3>
<p>For the lazy ones I am trialing selling all the parts and the board together as a kit on tindie. I'll see how this goes. My suspicion is that it'll end up being a giant pain in my ass and not worth the time, but I am giving it a fair shot. <b>EDIT:</b> Apparently not, and not even with a good reason. I quote: <em>Please resubmit for admin approval once you have addressed: Other Reason.</em>. LOL, how about <em>NO</em>? As a sidenote, if anyone knows companies that do this sort of thing for me (sell a kit I designed), please drop me a line <a href="mailto:tips@dmitry.gr">by email</a>. If you are <em>really really</em> lazy, I might consider having a batch of these factory-assembled by JLPCB as well. If you are interested, click <a href="mailto:assembled_requests_linuxcard@dmitry.gr">here</a> and let me know. No promises yet.
</p>
<h3>Using</h3>
<p>I provide a few disk images. The smallest is the busybox-based one (disk.busybox) - it is small, fast, and cool. I built the busybox from source for MIPS-I with as many applets enabled as I could imagine being needed. The second image is a full debian wheezy (last version to support MIPS-I) rootfs. I should warn you that debian's "init" starts around 3000 processes while it boots, so that takes a long time. If you are using the debian disk image (disk.wheezy), I strongly suggest to just mount proc and sys, and do your things in "sh" without running "init", but it will work if you do ... eventually. I also provide a hybrid image (disk.hybrid). It has a busybox shell and init, but has all of the debian binaries, so things not provided by busybox are still there and work, like gcc and vim. This is the "hybrid" image.
</p>
<p>Using the LinuxCard is easy, insert the SD card, connect USB-C to a computer, and open your favourite serial console app (minicom, PuTTY, etc), if you do not see the boot log, try the other virtual serial port (two exist). In case of a boot error, the SD card LED will blink in an infinite pattern, you can see the code for details on what various numbers of blinks mean.
</p>
<p>Once you see the shell prompt, you can play around, or continue boot to login by typing <span>exec init</span>. After this you'll be able to login as "root" with the password of <s>"mips"</s> "mipsmips". There will also be a login prompt on the second serial port as well. So cool!
</p>


<h2>Version 2</h2>


<h3>Booting Ultrix</h3>
<h4>About Ultrix</h4>
<p>Ultrix is the period-correct UNIX for the DECstation2100/3100. The latest version is 4.5 and with some google-fu you can find ISOs of the install media. It supports the DECstation2100/3100 perfectly, and even has an X11-based UI! The goal of the v2 firmware was to properly run Ultrix on the card. This ended up requiring a lot of work. I had to improve emulation accuracy and implement more hardware. But it did work!
</p>
<h4>First time booting Ultrix</h4>
<p>My first attempts were simple - copy the kernel to my "boot" partition and attempt to load it. It would, of course, not find its root filesystem and panic, but I wanted to see how far I would get at all. The first roadblock was an obvious one - the kernel is not in the <span>ELF</span> format that the linux kernel uses and my loader expects. It is in an older format called <span>COFF</span>. I dug up docs and started working on a parser for <span>COFF</span>. After a little work, I was able to load the kernel and let it run, just to see how far it would go. To my susprise, it got far enough to log some messages to the console! It crashed soon after, when it asked my PROM code for an env variable that I did not know about "scsiid0". Not a bad start. At this point I figured that in a week or so I would have Ultrix booting. It took a little longer...
</p>
<p>Ultrix was designed for this machine, and it was designed to support all parts of it. It does not probe for hardware since it knows that a DECstation2100/3100 should have. It assumes that the requisite hardware is there and starts initializing it. This was a problem for me - I still was not emulating the graphics, SCSI, or the network card. Linux has no support for them so I had not bothered.
</p>
<h4>SCSI</h4>
<p>As this was my first time attempting to emulate SCSI, it took a while. SCSI is so over-engineered, the very word "overengineered" does not do justice to just how much so it it. There are messages, commands, statusses, selects and reselects, and oh so very much more. The SCSI chip in the DECstation2100/3100 is a very strange one that DEC designed just for this device. It is called SII or SMII and I found no docs for it other than the official summary in the <a href="http://www.bitsavers.org/pdf/dec/mips/DS3100_Functional_Specification_Rev3.1_Aug1990.pdf">DECstation3100 specification</a>. It was helpful, as it listed the register bits and values. It was a start. Watching the Ultrix kernel try to access it before it gave up and paniced provided some more help, and reading the SCSI-I and SCSI-II specs filled in the rest. After much work it seemed like the kernel was happy enough to try to enumerate the bus. It would try to select each device in order. Progress!
</p>
<p>From there, the next step was to write a virtual SCSI disk. If you haven't dealt with SCSI before, it is rather unlike most sane designs. A sane design would have a host controller be a heavy/expensive/complex machine that talks to cheap simple devices. This makes sense because typically one would have more devices than host controllers. Not here. A SCSI device drives the bus and determines what it does and when. The only thing the host can do is reqest attention from the device. This took a little while to wrap my head around as it is rather backwards. It is actually even more complex since the target device can disconnect from the bus to do things and later reconnect and continue a transaction. It <em>really</em> is quite complex. Luckily, some of that is optional. A device can also reply without disconnecting, and my virtual disk does that. With a lot of work, I was able to figure out the proper state machinery to make Ultrix indeed identify and talk to my virtual SCSI disk. I split the code into two layers. The bottom handles the basics of just being a SCSI device and the top handles actual disk-specific things.</p>
<p>The code later got expanded to support emulating a CDROM too, to allow me to do an Ultrix install from a virtual CDROM. While working on this, I noticed that the bus enumeration is slowing down the boot a lot. The issue is that there is no way to detect that "no device with this ID exists on the bus". One must attempt a select, and then wait for a timeout. This was taking a while since Ultrix implemented a timeout using a loop with a counter (not using the RTC), and at my virtal CPU speed it was taking seconds. The solution was a dummy SCSI device that does reply to some commands enough to be identified and tell the host that it has no media and is of an unknown type. This device is the "SCSI nothing".
</p>
<p>The SII controller has 128KB of SRAM for DMA-ing data to/from devices. The idea is that one schedules the transfer and it goes on at its pace, when done, an interrupt occurs and data can be copied in/out of this memory. On the PC, this is simple - i can allocate 128KB of RAM and be done with it. On the microcontroller, I do not have that much SRAM, so I steal some memory from my external memory for this, and present less than the full amount to the virtual OS. This works fine for Ultrix as it probes the memory amount page-by-page. Linux probes in 4MB increments, but I have a patch <span>allow_64K_memory_multiples.patch</span> that changes it to probe in smaller increments so that this memory stealing does not cost 4MB of usable RAM.
</p>
<p>Linux has no support for SII SCSI controller, so it continues to use the <span>pvd</span> device.
</p>
<h4>LANCE</h4>
<p>The network card in the DECstation2100/3100 is LANCE. It is somewhat documented in the DECstation2100/3100 specification sheet and I implemented it enought to please Ultrix. It never sends or receives any packets (I can add that later), but it does initialize and interrupt as needed. LANCE has a 64KB SRAM buffer for packets. The PC build of uMIPS fully supports this, the "micro" build of uMIPS will just ignore writes and produce zero reads of this area to avoid wasting 64KB of memory. This works well enough to please Ultrix. Linux has no support for LANCE, so I have no idea if it would be ok with this setup.
</p>
<h4>ESAR</h4>
<p>The MAC address for the network card is stored in a on-board EPROM called the "ESAR" (Ethernet Station AddRess). It lives at the same address as the real time clock, except it is wired to the upper byte of every word, while the DS1287 is wired to the bottom byte. This is a weird thing to do but it works. It does mean that some weird things are possible, like reading both the ESAR and the real time clock registers at once with one read. Luckily this is not usualy done. The ESAR data has some checksums and redundancy (so that its correctness is easy to verify). I implemented an ESAR for uMIPS, assigned the ethernet address <span>66:44:22:44:66:22</span> to the device, and provided for all the required redundancy and checksums. Ultrix is satisfied with this.
</p>
<h4>Memory probing &amp; proper PROM API</h4>
<p>While booting Ultrix I notied that it directly probed the amount of RAM in the system. This is strange since Linux simply queried the memory amount from a PROM API that conveniently exists for this. This was actually my mistake since I was emulating a much newer PROM iterface than the real DECstation2100/3100 had, and Linux was happy to use it. The newer standard (called REX) provides the OS a function pointer table with a lot of API. To signal REX support, a magic value is also passed. DECstation2100/3100 predate the REX API and used a different method of providing API to the OS - a table of jumps is placed at known offsets from the start of the PROM in the <span>0xbfcXXXXX</span> address space. This API is also more primitive, and lacks, for example, the ability to tell the OS how much RAM there is. The pieces now fall into place... My only problem is that I do not have an ability to have a huge PROM, as I wrote earlier. I needed another method to offer this API. I decided to indeed have this jump table, but redirect all the jumps to an address in the RAM area reserved for the PROM <span>0x80001000..0x8002ffff</span>. You'll recall that my OS loader loads there. Now it can provide this PROM API, just like it did the REX API. Cool! Testing Linux also shows that it happily uses this API properly as well. It is, of course, now also forced to <em>probe</em> the RAM amount. No big deal. I did find a bona fide bug in the kernel here! While it means (as per comments) to probe for a maximum of 480MB of RAM, but actually only probes for up to 30. The fix is in <span>fix_mem_limit.patch</span>.
</p>
<h4>Ultrix Loader</h4>
<p>At this point, the kernel was loading far enough to panic about not finding the root filesystem, so it was time to figure out a good way to make this work. The problem is that Ultrix uses a completely different partitioning system than the well-familiar MBR I had been using. The Ultrix "disklabel" allows for 8 "partitions" but with some assumptions, like that the first (caled "a") is always the rootfs, the second (called "b") is always swap, the third ("c") always covers the entire disk (yes it does and is expected to overlap others), and another one ("g") is <span>/usr</span>. Now, if this was not fun enough yet, the partition table itself is expected to be <em>inside</em> the rootfs partition, and a whole lot of tools (including the installer) assume that this all starts at sector zero. Fun, eh?
</p>
<p>I spent a lot of time trying to figure out how to make the installer be happy to not start the rootfs at the 0th sector, but this was a lost cause. A large number of scripts involved assume that both the "a" and the "c" partition start at zero. The kernel also has similar assumptions. With some patching, I got it to work with an offset, but this was not a good approach. I decided to see if I could live with how Ultrix does things, instead of trying to force it to do things my way. Even though the rootfs and the partition table both start at the 0th sector, they both reserve some space up front for "boot code". Specifically, the first 16 sectors (8KB) are always free. I decided to simply place my loader there and teach it how to understand the Ultrix disklabel. As part of this work, I refactored the loader into a few pieces. One part was a partition table handler. There is an option for MBR, one for Ultrix, and one for NetBSD disk labels. One of these (build-time determined) is linked in to the loader, as needed. Another module was a binary loader. Two exist: ELF for Linux and NetBSD, and COFF for Ultrix. Same as before, only one is linked into the loader, as needed. The third modue is the filesystem driver. There is one for FAT12/16/32 (used for my Linux boot sequence), one for old UFS (for Ultrix), and one for modern UFS (for NetBSD). Again, just one is linked in, as needed.
</p>
<p>The cool part now is that I can mix and match these pieces as needed to create a loader for the OS I want to boot. The Linux loader is thus <span>FAT + ELF + MBR</span>, for Ultrix, the loader is <span>UFS.old + COFF + Ultrix disklabel</span>, and for NetBSD, it is <span>UFS.new + ELF + NetBSD disklabel</span>. I was too lazy to implement proper CD-booting, so installing Ultrix is a bit weird. I make a disk image with just the installer kernel (extracted from the CD), in a FAT partition, attach the CDROM to the emulator, and then boot. The installer will then re-partition the disk. For this, yet another loader combination is used: <span>FAT + COFF + MBR</span>. The modularity pays for itself!
</p>
<h3>Making Ultrix work</h3>
<p><a href="http://dmitry.gr/images/linuxCardUltrixUiBig.png"><img src="http://dmitry.gr/images/linuxCardUltrixUiSmall.jpg" alt="Ultrix UI fully booted with a graphical paint program and a terminal open"></a>
<a name="_TOC_42badd9e49002a3cefeaaf28867add83"></a></p><h4>Framebuffer</h4>
<p>Once I had the Ultrix kernel booting properly, at least in the PC build of uMIPS, I <em>really</em> wanted to get the GUI working. Who wouldn't‽ The framebuffer came in two varieties for this machine. There was a monochrome one and a 8-bit color one. They both supported hardware cursor as well. I implemented most of the normally-used modes in the cursor hardware, but not any test modes. I emulated both the framebuffer types and they both work! The 8-bit framebuffer can display up to 259 colors onscreen at a time, out of a 24-bit palette. That is not a typo. The display itself can display 256 colors, and the cursor has its own 3-entry palette, which need not use any of the same colors. The resolution is 1024x1024 in memory, and 1024x864 onscreen. The remaining memory is free for the OS to use however it wishes. I steal memory from the main RAM, same as for the SII buffer. 128KB is used for the mono framebuffer, and a whole megabyte for the color one. The palette is also stored in stolen ram (just about a kilobyte).
</p>
<h4>Mouse, Keyboard, ... and Tablet</h4>
<p>Of course, to make this work, I also had to make the keyboard and mouse work. They talk to the DECstation via serial, and the protocol is somewhat known, from various shreds available online. I was able to put together a passable keyboard emulator rather quickly. It is <em>not</em> a dumb keyboard. It has regions of keys, a bell, some lights, and can support differing autorepeat settings per key group. It is actually pretty cool. The mouse is a pretty basic one, with three buttons. I got that working rather quickly. The problem with emulating mice is a well known one - they are relative device, and most OSs apply acceleration to the mouse as you keep moving it to allow for better reach. Now, if you are running another OS, and passing these accelerated movements to it, it will re-accelerate them even more. This ends up being a mess. This is why most virtualization solutions prefer to load an absolute-pointing-device driver into the guest. I was not prepared to hack up Ultrix or find a way to load a different mouse driver in it. But then I noticed that DEC wrote about a "graphical tablet" that they were selling, that hooked up to the mouse port. Could it be that Ultrix supports this? Yup... Ultrix does. I wrote an emulator for the tablet and it worked wondefully - no more over-accelerated mouse for me! Sweet!
</p>
<h4>Patches</h4>
<p>Ultrix assumes that it is booting on a real DECstation2100/3100, and that includes expecting the CPU to have caches. My virtual CPU does not expose caches to the guest OS, and while Linux handles that fine, Ultrix does not. It correctly probes the cache and finds its size as zero. But there is a logic bug in <span>r3_kn01flush_cache</span>, where if the cache size is zero, it gets into an almost-infinite loop. As uMIPS exposes no cache, it makes sense to patch the function away into just a return. There is another function of interest: <span>kn01delay</span>. It is used for short busy-wait delays when dealing with hardware. All of our virtual hardware is instant-fast, and thus no delays are needed. As long as I am patching a kernel, might as well make it faster. There is also a third area of interest - the periodic timer. In Linux, I was able to change the tick to 16Hz, but I cannot build Ultrix from source, so I cannot modify it easily. Ultrix uses a 256Hz tick. At that rate, on uMIPS hardware we'd never get any useful work done while only handling interrupts. I attempted to patch Ultrix to use a 16Hz timer and account for it correctly. This does not work - there are mathematical errors that happen. 64Hz works, but that is still too freqent for the uMIPS hardware to be usefully fast. I ended up patching the init code to set the timer to 16Hz, but accounting code to act like it is 64Hz. This means that "realtime" in Ultrix runs 4x slower than actual real time, but this is not really a big deal. Just keep in mind that a <span>sleep 1</span> will delay 4 seconds and not 1.
</p>
<p>So how does one even apply such patches? How does one find the proper places to patch? I spent a <em>LOT</em> of time learning about the barely-documented symbol format used in the Ultrix kernel. It worked! I made a working parser for it and was able to properly identify the symbols I needed and to patch the places that needed patching. This was good until I realized that while the installer kernel does ship with symbols, the kernel installed for first boot does not (after first boot, the kernel is recompiled again, with options you choose, and that version DOES have symbols). No symbols means that I cannot use them to find the proper locations to patch. I decided on a different method - binary matching. Look for the proper set of bytes in a row, it should be unique in the kernel. If you find just one case - it's the right one. To save space in the loader (as it is limited to 8KB), I compress the "pattern to look for" cleverly. Cool. This is the final approach I used and you can see it in <span>loadUltrix.c</span>.
</p>
<h3>Improvements in the emulator</h3>
<h4>USB improvements</h4>
<p>After a lot of googling, I learned about interface association descriptors. Turns out that without them, windows will not load the USB CDC-ACM drivers for a device. After adding them, Windows would properly load the driver and it would show up as a COM port. I also learned about the peculiar ways that Windows enumerates devices. Sometimes it'll ask for a descriptor, stating that it'll accept 64 bytes, but after receiving just one 8-byte packet it will reset the bus. This was breaking my USB code, and this is now fixed. Windows now properly supports uMIPS and shows it as two COM ports. Sweet!
</p>
<h4>More perf improvements</h4>
<p>At the end of emulating every instruction, the emulator jumps "to the top", fetching a new instruction to execute. In most cases before this a check is done for whether there is an interrupt pending. This jump was done using a <span>BL</span> - the only long-distance branch available on the Cortex-M0. It takes 3 cycles. The check involved loading a byte from memory (2 cycles), checking if it is zero (1 cycle), and jumping to the interrupt exception creation code if so (1 cycle if not - the common case). That means that the entire "jump and begin handling the next instruction" step took 6 cycles. I wanted to make it faster somehow. I decided that if I could free up a register, I could. Some reworking freed <span>r11</span>. There is a parameter you can pass to gcc to tell it to not use a given register in any C code it compiles: <span>--ffixed-r11</span>. Now that this register is not being used by anyone ever, we can do the clever thing. We keep the address of the "load next instruction and execute it" label in it. Now we can jump to it using just <span>bx r11</span>. This takes just 2 cycles - 4 cycles saved per virtual instruction - a significant speed up. But what if we do have a virtual interrupt to report? Whenever we have one to deliver, we just set <span>r11</span> to point to the "report a virtual interrupt" label, and whenever the current virtual instruction is done being emulated, the interrupt will be reported and <span>r11</span> will be reset. There is a bit more machinery needed to make this work, but this is it in general terms, and it does work!
</p>
<p>I also changed how the TLB hash works (from a table of 32-bit pointers to a table of 8-bit indices) to make the table and each entry smaller (from 24 bytes to 16). This saved a bit under a kilobyte of RAM, which I was able to allocate to the L2 cache. It has now grown from 1.25KB to a full 2KB for a measurable perf improvement!
</p>
<h4>Removing the TLB refill fast path</h4>
<p>For Linux, I had implemented a fast-path for the TLB refill code - it executed in native code what he TLB refill handler would do. In my measurements it slightly improved performance. With all the other performance improvements I had implemented, it no longer offered a measurable improvement. Plus, it did not help Ultrix at all, by definition. Removing it saved flash space and removed complexity. Less complexity is always better. It is gone.
</p>
<h4>Cache geometry changes</h4>
<p>Previously, when profiling to find the best L1i geometry, I used the Linux boot process. I decided to try harder. Now I profiled that, gcc compiling some code, a few other Linux binaries, Ultrix boot, and some Ultrix userspace utilities. The result of this investigation was that a direct-mapped L1i is slightly faster than a 2-way L1i cache. The hit rate goes down slightly, but checking only one cache line instead of two speeds up the checking enough to make up for it. I thus reconfigured the cache as a direct-mapped cache.
</p>
<h4>Serial improvements</h4>
<p>Previously, the emulator would wait a fixed 20ms to send a character to the PC before giving up. I changed this to a permanent wait for the main console. This allows the user to not miss any output if they close their terminal. The emulator also shows its version up front, since it will definitely not be missed now. As of firmware v2.1.1, uMIPS also shows the RAM configuration in terms of the number of chips, each chip's size, and the bit width of the per-chip interface.
</p>
<h3>More Floating Point Unit work</h3>
<p>I had already implemented a full virtual FPU, but now I wanted to see how necessary it really was. I knew that Linux would run if I emulated no FPU at all and would emulate it. I wanted to see if Ultrix would. It did not - it crashed with an invalid instruction trap in the kernel. This was not all that surprising. Once again, it was compiled for a particular machine - a machine that had an FPU. Its assumption that an FPU exists was sane. But there was still more to investigate. The MIPS spec says that the FPU may refuse to execute any instruction if it is not sure that it can perform it perfectly accurately. Since the spec is not clear on what that really means, basically any OS running on such a MIPS chip must implement a complete FPU fallback, capable of emulating any FPU instruction. But then why am I hitting an exception?
</p>
<p>The trick is that the FPU must still exist, it must refuse to do math. This is strictly different from not existing at all. I thus implemented a "minimal" FPU. It implements the instructions to identify itself, move data in and out of the floating point registers, and load and store floating point registers to memory. Any attempts to do actual floating point math report a "coprocessor usage exception" which is the proper way for the FPU to refuse to do math. This worked correctly for Ultrix - it now will not crash at boot, all applications that do floating point math still run, with the kernel emulating the math. I checked and Linux also supports this setup. Thus uMIPS now has three FPU configs that it can be built with: <span>full</span>, <span>minimal</span>, and <span>none</span>.
</p>
<h3>A bootloader</h3>
<p>As I handed out more and more of these cards, the update story needed to be improved. Not everyone has a <a href="https://cortexprog.com/">CortexProg</a> lying around to reflash the firmare. I decided to make it simple and require as little user interaction as possible. The bootloader is just under 3K, I allocated 4K of flash to it, and relocated the main firmware to start 4K into the flash. So, how does it work? At boot, the bootloader will minimally initialize the SD card, attempt to find a FAT16 partition on it, see if it contains a properly-sized file called <span>FIRMWARE.BIN</span> on it, and if so, the firmware will be flashed from this file. On error, the error number will be blinked out on the LED, repeatedly. On success, a varying-frequency pattern of the LED will be repeated forever.
</p>
<p>If the card fails to be initialized, if it fails to mount, if the update file does not exist, or if it is not correctly sized, the bootloader will continue to boot the existing firmware, if any exists (some sanity checking is peformed). This means that when you insert a card with my Linux image or the Ultrix image, all will work as expected. Only FAT16 is supported, so some partitioning may be required on larger cards. I can live with that.
</p>

<h3>Hardware improvements</h3>
<h4>v1.3 hardware</h4>
<p><a href="http://dmitry.gr/images/linuxCardSchem2.png"><img src="http://dmitry.gr/images/linuxCardSchemSmall2.jpg" alt="Linux card schematics"></a>
<a href="http://dmitry.gr/images/linuxCardBoard2.png"><img src="http://dmitry.gr/images/linuxCardBoardSmall2.jpg" alt="Linux card board layout"></a></p><p>After reading my original article, a few people wrote in (including in the comments section here, on twitter, and in email) to suggest that maybe I should entirely abandon the shitty SPI units in this chip. Initially I was worried that the SPI unit speed issue was really an IO port speed issue, but a quick test showed that I could toggle a pin at half my CPU clock reliably and get nice square edges. I prototyped bit-banging SPI on the existing board to see what speeds I could attain and it was promising. I then laid out a new board, with different wiring, to allow me to actually use QSPI mode. The images for the new schematics and the layouts are the ones you see here!
</p>
<p>The ATSAMD21 series features a single-cycle IO port. This optional Cortex-M0+ feature is pretty useful for bit-banging. It really is single-cycle-fast. Normal loads and stores take two cycles minimum on a Cortex-M0+, but ones targetting this kind of a unit take just one. That is <em>how</em> I could toggle a pin at half the cpu speed for my test that I had just mentioned.
</p>
<p>With big-banging, the trick is to do as few operations per cycle as possible. Given this, it would be ideal to do minimal bit-twiddling. It would be super-awesome if I could wire up the four QSPI chips to GPIOS numbered 0..15, allowing me to just read/write the bottom 16 bits of the GPIO port for simple access. Alas, this was not meant to be. This chip has no contiguous 16 GPIO pins wired to the physical pins, so I settled for wiring RAM0 to GPIO0..3, RAM1 to GPIO4..7, RAM2 to GPIO8..11, and RAM3 to GPIO14..17. Since I will be driving them all together, the clock and chip select lines are all wired together. After all was said and done, after the assembly was coded, and the dust settled, I was able to get around a 9MHz clock speed on average. Since the command and address are also sent 4-bits-wide, the speed increase is nice. Previously (using hardware SPI) it took around 8 microseconds to read/write 32 bytes, now it took just under 4 microseconds. A nice speedup.
</p>
<p>An astute reader might notice that the first three RAMS <em>ARE</em> on consecutive GPIO pins. Three is not of much use to us, as it is not a power of two, but <em>two</em>... Yes indeed using only two RAMs i can attain faster speeds (but at half the width). The actual time to read/write 32 bytes is around 5 microseconds. Given this, I decided to re-add the previously-removed support for using less than 4 RAMs on the board. And I did. The newest firmware now supports 1, 2, or 4 RAMs populated on the new boards. I then went futher, and re-added this support for the old boards. That is not as well optimized - it is in C, not ASM, but good enough to play with. This will allow assembling these boards cheaper. Plus, Ultrix happily boots and runs in 4MB (it does need 5MB to start the GUI though).
</p>
<h4>And old hardware too</h4>
<p>I did not want to maintain two separate-but-almost-equal branches of code for the older v1.2 hardware and the new v1.3 hardware. There was also no easy way to tell them apart in software from first glance. But a bit more investigation does provide an idea. The wiring for the RAMs is different enough that we can try each way and see if we detect a plausible RAM chip. It helps that not having RAM0 populated is never supported. This is precisely what I did, in fact. I tried both configs and see which produces a valid-looking ID from RAM0. From there, all four RAMs are probed, identified, and a configuration is picked.
</p>
<p>Support for less than 4 populated RAMs raises a few interesting questions. For speed, all RAMs are treated as if they are the same size, so the size of the smallest RAM determines the total amount of available RAM. This is because I stripe the data across them, of course. So, what if RAM0 is populated with 8MB, and RAM1 with 2MB? We could use just RAM0 and get 8MB of RAM or we could use both and get just 4MB, but faster, since more RAMs in parallel is always faster. I decided that more RAM is better than faster RAM, so in case of such conflicts, more RAM is always chosen. When there is a tie, the faster configuration is used, eg: 4MB, 1MB, 1MB, 1MB RAMs populated add up to 4MB in both the x1 and x4 configs. In this case the x4 config will be chosen and all the RAMs will be used.
</p>
<h3>Building from source (updated)</h3>
<h4>The emulator</h4>
<p>A new parameter called <span>FPU</span> is now passed to uMIPS build to specify the FPU type desired. Options are: <span>none</span> - no FPU at all, Ultrix will not like this but it makes the smallest image; <span>minimal</span> - an FPU that can store values but refuses to do math - Ultrix and Linux will support this, it is slightly larger; and <span>full</span> - a full FPU that does all the math - the fastest option that bloats the Cortex-M0 image by 17KB or so.
</p>
<h4>The loader</h4>
<p>To build the proper loader, pass the <span>BUILD</span> parameter to <span>make</span>. The options are <span>linux</span>, <span>ultrix</span>, <span>ultrix_install</span>, or <span>netbsd</span>. The install loader is just for clean installs, which you have no reason to do since I already did it for you. The netbsd one is to attempt boots of NetBSD on this machine, as it is supported by NetBSD. The proper loader needs to be built and integrated into a disk image for a working system.
</p>
<p>The integration step also changed, <span>mkdisk.sh</span> is gone, replaced by a number of different tools, depending on the intended system. They are: <span>mkdisk-linux.sh</span>, <span>mkdisk-netbsd.sh</span>, <span>mkdisk-unix.sh</span>, and <span>mkdisk-unixinstall.sh</span>. Unix here refers to Ultrix, of course. The scripts are small and self explanatory. Open them for more details. They all operate on a disk image called "disk"
</p>
<p>To enable GUI in Ultrix, the env variable "console" needs to be properly set. In <span>loader.c</span>, find it and set it to "0,0" for text mode or "1,0" for console mode.
</p>
<h3>Further Updates</h3>
<h4>Firmware v2.1.1</h4>
<p>In this version, BBQSPI memory access sped up by 11% for 4-chip case, 6% for others. Ram config shown on boot.
</p>
<h4>Firmware v2.2.0</h4>
<p>In this version, the bootloader was updated to better support other ATSAMD21 parts, including those with more flash &amp; RAM. It now also exposes a version byte at offset <span>0x08</span>. The previous bootloader was version <span>0x10</span>, making this one version <span>0x11</span>. The version will be shows on the serial console at boot now.
</p>
<p>Also, as ATSAMDA1E16 is now apparently out of stock everywhere, I added support for <a href="https://octopart.com/atsamd21e17a-au-microchip-77761547?r=sp">ATSAMD21E17A-AU</a>/<a href="https://octopart.com/atsamd21e17a-aut-microchip-77761548?r=sp">ATSAMD21E17A-AUT</a>. The sad news is that this non-automotive part does not overclock nearly as well. It gets unstable much past 76MHz, so I decided to clock it at 72MHz. It does have more RAM (16KB), which allowed me to allocate a lot more memory to L1i and L2 caches. In most measurements, the performance loss due to lower speed is papered over by the gains of larger caches.
</p>
<p>On the topic of performance, I also rewrote the L2 cache code in assembly for speed and size gains. The speed gains are significant. For extra speed, there is now an option to move the actual access functions to RAM (which is faster than flash). This gains an extra 8% speed, but at the cost of using RAM. On the old 8KB-of-RAM parts this is not always worth it, since it necessitates shrinking the L2 from 2KB to 1.625KB to make space. On the new 16KB-of-RAM parts, though, it is we;ll worth it. It should be noted that there are 6 variants of RAM access low level functions as there are 2 possible access types (SERCOM or bit-banged) and 3 possible chip counts (1, 2, or 4). Only the ones you plan to use need to be moved to RAM. Others will still work from flash, if you want to make a universal firmware. The firmware I provide now moves the 4-chip bit-banged functions to RAM for ATSAMD21E17. See <span>RAM_FUNCS_IN_RAM</span> in the Makefile and the contents of <span>spiRamAtsamd21.c</span>
</p>
<p>While moving functions to RAM, it is easy to accidentally use too much RAM and end up with random crashes as stack collides with data. These are a pain to debug, so I decided to improve this experience. As an option in the Makefile, there is now ability to enable <span>STACKGUARD</span>. What does this do? As the very last word in the pre-allocated RAM (and thus the very first one that stack would overflow over) the code will keep a magic cookie, whose value depends on the current <span>ticks.hi</span> value. This value is checked and updated in the <span>SysTick</span> interrupt which happens every 16 million cycles. If the check fails, an error will be blinked out the LED and the execution will be halted. 
</p>
<p>Starting with this version, the proper make incantations are now <span>make CPU=atsamda1e16</span> and <span>make CPU=atsamd21e17</span>
</p>
<p>The downloads have been updated with the new code and binaries for both chip types. They can be updated using the bootloader and an SD card
</p>





<h2>In conclusion</h2>
<h3>Acknowledgements</h3>
<p>I send a great many thanks to my cats for cutely lying under my table to keep me company during the many hours spent on this project. I send a giant, Mount Rushmore-sized middle finger to Atmel for this sorry excuse of a chip. <b>UPDATE:</b> I even gave up on using the SPI units here, so at this point, I send <em>two</em> of those fingers. Thanks for nothing, Atmel.
</p>
<h3>Downloads</h3>
<p>The source code, gerbers, schematics, and all else <em>except</em> the disk images can be downloaded [<a href="http://dmitry.gr/images/LinuxCard2.7z?v=220">here</a>]. The license on my code is simple: free for all non-commercial use, including using as your own business card. For commercial use (like if you wish to sell kits of this project), <a href="mailto:licensing@dmitry.gr">contact me</a>.
</p>
<p>The disk images (<b>updated</b>) are large so I have no desire to host them on my site, so: [<a href="https://drive.google.com/file/d/14fhdW4Vdz4-ZKucB-iIP4MLTk8OLB7dI/view?usp=sharing">Google Drive</a>] or [<a href="https://mega.nz/file/p9ZWzLrK#saRKVlgBthOFE4Cp-6sb2fMTM7JXtuXMlsYQaaWrEAI">MEGA</a>].
</p>


<!--- We do not show this to the user, but ToC system will index this and we'll get a link to comments in the ToC -->






					
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Be a Thermostat, Not a Thermometer (282 pts)]]></title>
            <link>https://larahogan.me/blog/be-a-thermostat-not-a-thermometer/</link>
            <guid>41516327</guid>
            <pubDate>Wed, 11 Sep 2024 23:50:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://larahogan.me/blog/be-a-thermostat-not-a-thermometer/">https://larahogan.me/blog/be-a-thermostat-not-a-thermometer/</a>, See on <a href="https://news.ycombinator.com/item?id=41516327">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
		
		<p>Originally posted Apr 4, 2023  
			
				• More resources on <a href="https://larahogan.me/resources/communication-team/">communication &amp; team dynamics</a>
			
		</p>

		
			<p>This post originally appeared in my <a href="https://mailchi.mp/wherewithall/be-a-thermostat-not-a-thermometer">newsletter</a>. <a href="http://eepurl.com/dxUybL">Subscribe</a> to receive it!</p>
		

		<p>As I’ve learned more about how humans interact with one another at work, I’ve been repeatedly reminded that we are very easily influenced by the mood of those around us. It’s usually not even something we do consciously; we just see someone using a different tone of voice or shifting their body language, and something deep in our brain notices it.</p>

<p>If you’ve ever attended a meeting where there were some “weird vibes,” you know what I’m talking about. You couldn’t quite put your finger on it, but something about the energy of the room was <em>off</em>—and that feeling affected you, even if it was super subtle.</p>

<p>We’re wired to spidey sense this stuff; this gut instinct is part of what’s helped us stay safe for millenia. Our amygdalas are constantly on the lookout for threats in our environment that could be bad news. Plus, we tend to infer meaning from those weird vibes. Our brain is trying to make sense of the shift in behavior, so we’ll make some (often subconscious) guesses about what’s truly going on. We often even jump to the assumption that those vibes are about us.</p>

<h2 id="humans-mirror-each-other">Humans mirror each other</h2>

<p>If I’m distracted in our one-on-one because I’ve got some stuff happening out of work that you don’t know about, it’s a recipe for misunderstanding. What you might observe is that I’m not making eye contact, I’m suddenly changing the subject, and my arms are crossed. How does your brain make sense of this? It decides that I’m upset with you—without any other information, it’s the most likely reason, of course. :)</p>

<p>Plus, humans, like most other mammals, mirror each other. When I change my tone or my body language, there’s some likelihood that your tone and body language will change in response. So now we’ve got a compounding situation—I’m having a bad day, so I’m giving off strange vibes, then <em>you’re</em> giving off strange vibes because you’re picking up on my bad day. We leave the one-on-one and go meet with other people, and now <em>they’re</em> picking up on our strange vibes.</p>

<p>This cycle is far more noticeable when someone is <a href="https://en.wikipedia.org/wiki/Amygdala_hijack">amygdala-hijacked</a>. It’s tremendously easy to be caught off guard by someone who is overcome with a surprising emotion, and feel triggered by it ourselves. Again, this is just a normal defense mechanism—there is no judgment here.</p>

<h3 id="noticing-a-change-in-someones-behavior">Noticing a change in someone’s behavior</h3>

<p>It takes a lot of practice to recognize when this pattern of shifting and influencing behavior is happening! But once you start paying attention to people’s patterns of behavior (what words do they use when they’re feeling upset? How does their body language change? Do they get louder or quieter? In what situations are they cracking jokes, and in what situations are they more quiet?) you can develop a stronger spidey sense when someone’s “vibes” are different than usual.</p>

<p>In my video course on <a href="https://courses.wherewithall.com/courses/surprising-emotions">Dealing with Surprising Human Emotions</a>, I talk about how to recognize when someone’s behavior seems off, it’s just a signal—just data—that one of their core needs might be being messed with. (Or maybe they simply didn’t get enough sleep last night, or haven’t had coffee yet today!) You can try to see it as a weather vane that something has gone awry for this person. Because once you can transform these signals into data—and not simply mirror the weird vibes back—you have an opportunity to positively affect what happens next.</p>

<h3 id="thermometer-vs-thermostat">Thermometer vs thermostat</h3>
<p>I like to use the metaphor of a thermometer and a thermostat for this idea. If you’re looking for signals about how someone is feeling, it’s kind of like you’re trying to take their emotional temperature. You’re being a thermometer. When they’re subtly giving off weird vibes—they’re frowning, answering your questions with fewer words than normal, etc.—you’ve noticed that their temperature is different. When their amygdala is hijacked, you might see large changes in their behavior (they’re picking a fight with you, going completely silent, skipping your meeting, etc.)—in the thermometer metaphor, they’re running a fever, and you’re picking up on it.</p>

<p>And since we know that one person’s behavior change can cause <em>others</em> to change their behavior in response, we can think of it like they’re being a thermostat: they’re setting the whole temperature for the room. Even if it’s unintentional on both sides. It’s just how we’re wired: to mirror the “vibes” that someone else is giving off.</p>

<p>Rather than let that cycle play out subconsciously, you have an opportunity to become the thermostat as soon as you notice that another person’s temperature has changed. <strong>You</strong> get to set the new temperature of the room, in a positive and healthy way.</p>

<h2 id="being-the-thermostat">Being the thermostat</h2>

<p>Once you’re able to start noticing when someone’s amygdala-hijacked, or simply that the vibes are <em>off</em>, you can reframe and use “be the thermostat, not the thermometer” for good. Since humans tend to mirror each other, you can <strong>intentionally</strong> change the energy in the room, setting the thermostat to a more comfortable temperature.</p>

<h3 id="naming-whats-happening">Naming what’s happening</h3>

<p>One way to reset the temperature is to say out loud, with your mouthwords, that you’ve noticed that the energy has shifted. Here’s a how-to blog post on <a href="https://larahogan.me/blog/skill-naming-whats-happening/">naming what’s happening in the room</a>.</p>

<p>As I mention in that post, there are a few risks to doing this, so you should use your best judgment on whether or not naming what’s happening in the room would be helpful in the moment. You won’t always get it right! Avoid projecting your feelings onto others, or putting them on the defensive, that would make the temperature of the room even more uncomfortable!</p>

<p>If you’re noticing a major shift in someone’s demeanor, instead of guessing what’s going on for them (like “you seem upset”) ask an open question about what they need or how they’re feeling. This way you’ll know if you need to get your thermostat hat on.</p>

<h3 id="choose-your-tone-and-body-language">Choose your tone and body language</h3>

<p>When naming what’s happening or asking open questions, keep what you say short and sweet, and remember to use a calm tone and open body language. I’ve <a href="https://larahogan.me/blog/when-coaching-questions-dont-work/#check-your-tone-and-body-language">written about this before</a>, but it’s definitely worth recapping here, because this is a huge component of being an effective thermostat!</p>

<ol>
  <li>
    <p>Gently <strong>nod</strong> at the pace they’re talking at, or slightly slower. It shows you’re following and tracking what they’re saying.</p>
  </li>
  <li>
    <p>Make <strong>soft eye contact</strong>. Hard eye contact is intense, eyes wide—it’s a little creepy. Soft eye contact is more like a Tyra Banks “smize”—a subtle relaxing of your facial muscles that shows you’re not ready to pounce as soon as they’re done talking. Don’t worry about keeping constant eye contact. Research shows you can break eye contact every 3 seconds naturally, then connect again, and this still feels attentive and affirming to the other person.</p>
  </li>
  <li>
    <p><strong>Lean in</strong>, but not too much. When we’re uncomfortable, we sometimes unconsciously tip away from the person in whatever way we can. This can send a signal that you’re uncomfortable or trying to get out of this conversation ASAP, or even that you are asserting dominance. Make sure you’re squarely facing the person—or if you’re on video, squarely face the camera—and lean in slightly. Even as little as 1” will do the trick! If I’m on Zoom and sitting at my desk, I like to make sure my elbows or wrists are evenly resting on it.</p>
  </li>
  <li>
    <p>Be intentional about the <strong>tone</strong> that you’re using. You’re responsible for communicating that you want to hear what they have to say, and that you’re here to support them. This intentional choice, in combination with your body language cues, will communicate to the other person that you are actively listening. I’ve found that even a subtle change in my tone—like going a little quieter if the other person has gotten a little louder, or adding a little bit of joy to my voice if they seem unsure or a little bit stressed—can reset the temperature in the room.</p>
  </li>
</ol>

<p>There’s a lot more to say about active listening; you can read more in <a href="https://larahogan.me/blog/actively-listening/">this blog post</a>! Your whole goal here is to set or reset the temperature of the room by modeling it with your tone, body language, and word choice.</p>

<p>This skill of intentionally choosing your body language, tone, and words can help the other person move out of whatever “weird vibes” they were giving off earlier, as they can now start mirroring yours. But if it’s a more drastic scenario, like this person is in an amygdala-hijack mode, this approach can also help them feel more heard, understood, and confident that you are decidedly not mad at them.</p>

<p>Usually, this skill does the trick. You smiled a bit, told a little joke that made them chuckle, nodded at the pace that they spoke to indicate you’re listening, and their mood started to change. You’ve just acted as the thermostat in a healthy, intentional way. But in case this doesn’t work, or if this person is in a more lizard-brain state, read on for some additional tools you can try.</p>

<h3 id="offer-a-break">Offer a break</h3>

<p>If it feels like the other person has been amygdala-hijacked, or if they are decidedly stressed or distracted and you sense that there’s no way that the rational, logical part of their brain will be able to return in the next few minutes, use a <a href="https://larahogan.me/blog/get-feedback-from-colleagues/#what-if-you-need-some-processing-time">back-pocket script</a> to offer a pause in the conversation and a plan to return to it later. Some of my favorites to use are:</p>

<ul>
  <li>“I’m not sure how y’all are feeling, but I think I could use some more processing time on this. Could we reconvene again tomorrow at 2pm?”</li>
  <li>“I know how much we want to come to an agreement on this decision today, but my spidey sense is that we might need some more time to think on it. How about we sleep on it and check in again tomorrow?”</li>
  <li>“I really want to support you on this and make sure you feel good about our next steps. How would you feel about us taking a break now to spend some more time thinking it through, and chat again at 4pm?”</li>
</ul>

<p>You’ll notice that the phrasing is intentionally trying to avoid putting someone else on the spot, or make them feel attacked. Your gentleness can help set the new temperature in the room.</p>

<h3 id="what-i-learnedwhat-ill-do">What I learned/What I’ll do</h3>

<p>If you’ve contributed to a big shift in the temperature by creating or escalating an awkward or tense situation, you have an opportunity to own your role as the thermostat here. Because if you never acknowledge it, you’re going to risk developing a forever-antagonistic relationship with them.</p>

<p>Sure, they should just be a grownup and get over it, right? But this does not happen in practice. (When was the last time you, yourself, actually did that?) People hold on to this stuff! Your life is going to be SO MUCH HARDER if you don’t clear the air after you amygdala-hijack someone.</p>

<p>In the <a href="https://courses.wherewithall.com/courses/surprising-emotions">Dealing With Surprising Human Emotions</a> video course, I talk with Jason Wong about this template that we both learned from Paloma Medina :)</p>

<blockquote>
<p>“What I <strong>learned</strong>…”<br>“What I’ll <strong>do</strong>…”</p>
</blockquote>

<p>For example, “What I learned is that that last email didn’t do a good job explaining the changes, so what I plan to do is start a forum for folks to post their questions and our CEO will answer them every Tuesday.”</p>

<p>When said with heartfelt authenticity, this phrase tells people that their needs, feelings, and concerns are not irrelevant. It allows people’s bellies to relax because their needs have been acknowledged. You can begin the work of recovering from the amygdala hijack, because you’ve reset the temperature in the room.</p>

<p>My parents actually taught me to “be the thermostat, not the thermometer”. It’s not always easy, that’s for sure. But by being aware of these cycles, we’re more likely to remember to use our thermostat power for good (not just give up or bail out when you notice someone else is running hot).</p>

<p>Next time you find yourself in a conversation that’s exuding some <em>off</em> vibes, or even an intense one, if you use a combination of these tools, you’ll be giving others the opportunity to mirror the temperature you set right back to you.</p>

	</article></div>]]></description>
        </item>
    </channel>
</rss>