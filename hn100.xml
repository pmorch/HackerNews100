<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 08 Jun 2024 10:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Replit used legal threats to kill my open-source project (2021) (136 pts)]]></title>
            <link>https://intuitiveexplanations.com/tech/replit/</link>
            <guid>40615537</guid>
            <pubDate>Sat, 08 Jun 2024 05:43:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://intuitiveexplanations.com/tech/replit/">https://intuitiveexplanations.com/tech/replit/</a>, See on <a href="https://news.ycombinator.com/item?id=40615537">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
<article>

<div>

<blockquote cite="CEO of Replit, in an email to me"> I
think you should take it down and stop working on it. I'll be engaging
our lawyers on Monday if it's still up by then. <span>[...]</span> We were a tiny company when you interned
with us <span>[...]</span> Luckily we're bigger now,
and crucially have a lot of money to pay for top lawyers now if we're
forced to go that route.</blockquote>
<p><strong>I received an official response from Replit and my open-source
project will be back up soon; please see <a href="#how-did-replit-respond-to-this-blog-post">the bottom of the blog
post</a> for an update. The
rest of the content here will remain as a historical artifact.</strong></p>
<p>Hi, my name is Radon. I graduated college last year and now work as a
software engineer in DevOps/Infrastructure. In my free time, I also
maintain <a href="https://github.com/raxod502">a number of open-source
projects</a>.</p>
<p>While I was in college, I interned at the startup Replit. This blog
post is the story of how Replit is using legal threats and their
venture-capital funding to bully me into shutting down an open-source
project they don’t like.</p>
<p><strong>Table of contents</strong></p>

<ul>
<li><a href="#whats-replit">What’s Replit?</a></li>
<li><a href="#what-was-my-open-source-project">What was my open-source project?</a></li>
<li><a href="#what-happened-when-i-shared-my-open-source-project-with-replit">What happened when I shared my open-source project with Replit?</a></li>
<li><a href="#what-happened-after-replit-threatened-to-sue-me">What happened after Replit threatened to sue me?</a></li>
<li><a href="#is-replit-right">Is Replit right?</a></li>
<li><a href="#why-would-replit-do-this">Why would Replit do this?</a></li>
<li><a href="#how-did-replit-respond-to-this-blog-post">How did Replit respond to this blog post?</a></li>
<li><a href="#so-is-riju-back-up-now">So is Riju back up now?</a></li>
</ul>

<h2 id="whats-replit" tabindex="-1">What’s Replit?</h2>
<p>Replit makes a webapp you can use to run code online in different
programming languages. This is nothing new (<a href="https://www.google.com/search?q=run+python+online">just Google “run python
online”</a> for
proof), so Replit’s value proposition is extra features like sharing
your work, installing third-party packages, and hosting webapps.</p>
<p>I worked for Replit in Summer 2019, where I was asked to rebuild
Replit’s package management stack and make it open-source. If you like
reading about tech stuff, <a href="https://web.archive.org/web/20210504051428/https://blog.replit.com/upm">here’s the post I wrote for Replit’s
blog</a>,
and <a href="https://github.com/raxod502/upm">here’s the code on GitHub</a>.</p>
<p>I took a job elsewhere in Summer 2020, but still chatted with them
occasionally by email when they reached out to tell me about something
cool Replit had developed.</p>
<h2 id="what-was-my-open-source-project" tabindex="-1">What was my open-source project?</h2>
<center><img src="https://intuitiveexplanations.com/assets/riju-languages.png" alt="Screenshot of
language select page in Riju" width="100%"></center>
<p>The aspect of Replit that I really enjoyed was how it supported lots
of different programming languages. (I wrote <a href="https://web.archive.org/web/20210504023410/https://blog.replit.com/elisp">another blog post for
Replit</a>
about how they do that.) That got me thinking: how many programming
languages could you possibly cram into a single website?</p>
<p>To explore that question, I put together my own little webapp that
could run code online. After about a day, I had something that worked.
(If you’re wondering why it was so fast—it turns out you only need
<a href="https://github.com/raxod502/python-in-a-box">30 lines of code</a> to let
people run Python code in a webapp! This may be why there are so many
websites for running Python online…)</p>
<p>After it was working, I started adding as many different programming
languages as I could. As you can see from this excerpt of my project’s
version history, I got a little overexcited:</p>
<pre><code>                                                                   languages
                                                                   ---------
2020-06-05 df9ba38 Initial commit                                          0
2020-06-05 5e3a4a4 Install some packages into a Docker image               0
2020-06-05 e937c8f Simple Express server with "Hello world"                0
2020-06-06 0961498 Embed terminal on frontend app                          0
2020-06-06 c66cf63 Embed Monaco editor on frontend                         0
2020-06-06 27ab1f7 Add "run" button                                        0
2020-06-06 f417858 You can run Python code now                             1
2020-06-07 d543081 You can run many languages now                          8
2020-06-07 e2a3e71 All languages 17 working now                           17
2020-06-07 473c50c ALL THE LANGUAGES                                      25
2020-06-08 3718315 even more languages                                    33
2020-06-08 548c1c1 repl.it superiority!!                                  38
2020-06-08 1ae424f More languages, we need all the languages              48
2020-06-09 c34ccf2 A lot more languages                                   77
2020-06-09 846caf2 At this point the number of languages is absurd        79
</code></pre>
<p>I eventually ended up with 216 languages, including <a href="https://web.archive.org/web/20210512193221/https://replit.com/languages">all 38 languages
from
Replit</a>,
<a href="https://github.com/mame/quine-relay">all 100 languages from Yusuke Endoh’s “Quine
Relay”</a>, and a good deal more
besides. You might ask: Why did I spend so much time adding obscure
programming languages to a webapp nobody was going to use? Well, let
me put it this way: Is it the weirdest 2020 hobby you’ve seen?</p>

<p>One day, I got an email from Replit letting me know about a new
feature they released. I figured this was a good time to share my
open-source project with them, in case they wanted to take inspiration
from any of my work:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-1.png" alt="Screenshot of an
email from Replit sharing a post from their blog, and my response
sharing my open-source project with them" width="100%"></center>
<p>At first, I got a positive response. But then, 30 minutes later, out
of nowhere, Replit accused me of unethical behavior and stealing their
design:</p>

<center><img src="https://intuitiveexplanations.com/assets/replit-email-2.png" alt="Screenshot of
one email from Replit praising my open-source project, and an
immediately subsequent one accusing me of unethical behavior and
stealing 'internal design decisions'" width="100%"></center>
<p>Now, none of the ideas I used in my open-source project were “internal
design decisions”: they’ve all been published publicly on Replit’s
blog (I knew this because I’d been asked to <em>write</em> some of those blog
posts during my internship). And my project also wasn’t any more of a
Replit clone than any of the other websites on the first few pages of
Google results for “run python online”, most of which look exactly the
same:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-ui-montage.png" alt="Screenshot of
nine different webapps that let you run Python online, all of which
look more or less identical" width="100%"></center>
<p>But I figured I might have missed something, so I asked for details:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-3.png" alt="Screenshot
excerpt of my email asking Replit for details about what ideas they
were claiming I stole" width="100%"></center>
<p>(The rest of this email is basically me repeating the previous
paragraph of this article, but with a lot more technical details. You
can read the whole email <a href="https://imgur.com/a/OaEOwu2">on Imgur</a>,
mirrored <a href="https://web.archive.org/web/20210530184721/https://imgur.com/a/OaEOwu2">on the Internet
Archive</a>.)</p>
<p>Unfortunately, Replit refused to provide any specifics on what they
were saying I had done wrong, reiterated their previous statements,
and threatened me with a lawsuit:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-4.png" alt="Screenshot of an
email from Replit threatening me with a lawsuit" width="100%"></center>
<p>And then just to put a cherry on top, Replit sent me another email
reminding me that they <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">just raised $20 million from their investors
last
month</a>,
and they weren’t afraid to use it against me. The “me” in question
being one of their previous interns who just graduated from college a
year ago, and who isn’t running any kind of commercial operation
whatsoever.</p>

<center><img src="https://intuitiveexplanations.com/assets/replit-email-5.png" alt="Screenshot of an
email from Replit threatening me with their money" width="100%"></center>
<p>I’d like to point out two things about this email:</p>
<ul>
<li>The remark about “commits like this”—this is actually misleading.
There’s only one commit in my project that mentions Replit, and it’s
the one I already showed you earlier, from my third day of coding,
when I’d just added all 38 languages that Replit supported, before
moving onto the 178 other languages I wanted to add.</li>
<li>The remark about me being a “demanding” intern—I’m not actually
sure what this is meant to imply, especially since Replit had just
tried to recruit me earlier that day (see the screenshot of their
first email). But I’ll leave it alone because it’s not really
relevant to the issue at hand.</li>
</ul>
<h2 id="what-happened-after-replit-threatened-to-sue-me" tabindex="-1">What happened after Replit threatened to sue me?</h2>
<p>Naturally, I took down my project right away, gave it some time for
feelings to cool, and sent Replit an apology. I figured something
might have been lost over email, so I asked to get on a call:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-6.png" alt="Screenshot of an
email in which I apologize to Replit and ask to have a call" width="100%"></center>
<p>Unfortunately, Replit ignored this email, so I sent them another one
following up. This one got a response, but not the one I was hoping
for:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-7.png" alt="Screenshot of an
email from Replit making it clear that they have no intention of
talking to me further" width="100%"></center>
<p>Just in case Replit didn’t understand that I wasn’t OK with this
situation, I sent three follow-up emails explaining as such over the
next few weeks, all of which were ignored.</p>
<p>In other words, Replit stands by its threat: if I re-publish my
open-source project, then they will sue me with “top lawyers”.</p>
<h2 id="is-replit-right" tabindex="-1">Is Replit right?</h2>
<p>Replit claimed that my open-source project was:</p>
<ol>
<li>a clone of Replit</li>
<li>based on their trade secrets (“internal design decisions”)</li>
<li>unethical to build</li>
</ol>
<p>Let’s examine this claim, part by part:</p>
<ol>
<li>In developing my project, was I making a clone of Replit?</li>
<li>In developing my project, did I make use of any trade secrets of
Replit?</li>
<li>Was it unethical for me to develop an open-source project that’s
similar to Replit, after working for them?</li>
</ol>
<p>Questions 1 and 2 have a fair number of technical details, so I’ve put
them <a href="https://intuitiveexplanations.com/tech/replit/evidence">in a separate post</a>. The TL;DR is:</p>
<ol>
<li>My project isn’t any more similar to Replit than the 15 other
(commercial!) ones you can find on Google by searching “run python
online” or “online programming environment”.</li>
<li>Every similarity between my project and Replit can be explained by
looking only at GitHub repositories and blog posts that were
<em>published online by Replit itself</em>, making them obviously not any
kind of secret.</li>
</ol>
<p>Let’s address question 3 here:</p>
<blockquote>
<p>Q: Was it unethical for me to develop an open-source project that’s
similar to Replit, after working for them?</p>
</blockquote>
<p>In my opinion, the answer to this question is no, for a number of
reasons:</p>
<ul>
<li>Riju is entirely non-commercial. Unlike Replit, I didn’t seek
funding from any source—advertising, donations, fundraising,
subscriptions, whatever. I have no interest in running a business,
and never really <em>wanted</em> Riju to become too popular, since I was
the one paying the server bill.</li>
<li>Riju wasn’t stealing customers from Replit. Based on my analytics
data, there were 38 visits to Riju during the month of February.
(Half of those were probably me.) Meanwhile, Replit had <a href="https://web.archive.org/web/20210505162911/https://twitter.com/Replit/status/1389976994423525378">over 7
million
users</a>.
There’s obviously no sense in which Riju was competing with Replit.</li>
<li>Riju wasn’t <em>built</em> as a competitor to Replit, either. Since the
architecture was limited to running on a single server, anyone could
bring the entire system down just by typing in a <a href="https://en.wikipedia.org/wiki/Fork_bomb">fork
bomb</a>—and one of my
friends did, just to see what would happen. (The system crashed.) If
I were designing a product to compete with Replit, I certainly
wouldn’t have picked an architecture that could only scale to
toy-project size.</li>
<li>Replit’s core value proposition isn’t letting you run code online
(you can do this in dozens of places for free), it’s the features
they offer on top of running code. Riju categorically lacked all of
these features, including: having a user account, saving your work,
sharing your work, publishing webapps, persistent workspaces,
discussion forums, integration with GitHub, etc. etc.</li>
<li>I had no bad intentions towards Replit when developing Riju, and
wasn’t trying to hide anything. As proof of these claims, I offer
the fact that I had the project public on my GitHub from the
beginning, and the fact that Replit found out about the project
because I openly shared it with them of my own volition, extending
an offer for them to take inspiration from my work.</li>
<li>Riju was never intended to be a product, it was intended to be a
personal playground / art piece. As proof of this claim, I offer the
fact that I spent dozens of hours adding languages like
<a href="https://esolangs.org/wiki/Hexagony">Hexagony</a> and
<a href="https://www.snobol4.org/">SNOBOL</a> rather making it so you could
save your work(!).</li>
</ul>
<p>I’m not a business person. I’m just an open-source dev who likes to
build weird things for fun. (If you doubt my track record of building
things that don’t make money, just check out <a href="https://intuitiveexplanations.com/about/projects">the list on my
website</a>, and note the conspicuous absence of
anything that’s ever made a cent of revenue.)</p>
<p>I would never try to steal someone’s business after I worked with
them. Hurting Replit was not my intent in working on Riju, and to
accuse me otherwise—especially without asking a single clarifying
question, and refusing all offers to have a discussion—shows a great
deal of bad faith on the part of Replit, in my opinion.</p>
<p>If you’d like to decide for yourself who is in the right, I’m happy to
put all of the evidence out in the open (except the code, because
Replit’s standing by its promise to sue me if I do). Again, I have <a href="https://intuitiveexplanations.com/tech/replit/evidence">a
separate post</a> with all the technical details. And you can
also read all communications between me and Replit, in full and
unabridged form, <a href="https://imgur.com/a/OaEOwu2">on Imgur</a>, mirrored <a href="https://web.archive.org/web/20210530184721/https://imgur.com/a/OaEOwu2">on
the Internet
Archive</a>).
(Technical details about Replit internals redacted, as well as any
statement that could reveal such details indirectly.)</p>
<h2 id="why-would-replit-do-this" tabindex="-1">Why would Replit do this?</h2>
<p>Replit’s stated ideals include:</p>
<ul>
<li>encouraging open-source development (e.g. <a href="https://github.com/replit">open-sourcing parts of
their technology</a>, <a href="https://web.archive.org/web/20210522215545/https://blog.replit.com/github">adding GitHub support
to
Replit</a>;
Replit’s CEO: <a href="https://web.archive.org/web/20210108083314/https://amasad.me/github">“I owe my entire career to
open-source”</a>)</li>
<li>giving back to the community (from <a href="https://web.archive.org/web/20210504051428/https://blog.replit.com/upm">the blog post Replit asked me to
write</a>:
“we are migrating […] to do our part in improving the ecosystem
for developers everywhere”; “Giving back to the community. The core
of our language-agnostic package management is now open-source on
GitHub”)</li>
<li>making it easy to share and remix your creations (e.g. Replit’s CEO
on learning to program: <a href="https://web.archive.org/web/20210522215545/https://blog.replit.com/github">“I’d download projects related to what I
wanted to build […] change &amp; tinker with them, and get
inspired”</a>;
he advises others to
<a href="https://web.archive.org/web/20210522212135/https://twitter.com/amasad/status/1395074521804148738">fork</a>
and
<a href="https://web.archive.org/web/20210211025614/https://twitter.com/amasad/status/1359697571011125253">remix</a>
too, and sells this philosophy as <a href="https://web.archive.org/web/20210522212034/https://twitter.com/amasad/status/1392517080017108992">a differentiating feature of
Replit</a>)</li>
</ul>
<p>However, Replit’s actions in this case reveal hypocrisy:</p>
<ul>
<li>they say they encourage open-source development, but when my
open-source project offended them, they shut it down with extreme
prejudice</li>
<li>they claim to be giving back to the community through their
open-source and blog posts, but when I tried to use those ideas in a
community project, they threatened to sue me</li>
<li>they say they make it easy to share and remix your creations—but
when I tried to remix Replit itself, I became a <em>persona non grata</em></li>
</ul>
<p>In Replit’s emails to me, their threats were based on the fact that I
had worked for them in the past. However, I believe this reasoning is
a smokescreen. To see why, let’s take a look at some tweets that
Replit’s CEO, Amjad, posted just after threatening me by email:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-tweet-1.png" alt="Screenshot of
Amjad's deleted tweet calling for 'copycats' to be banned from venture
capital" width="75%"></center>
<center><img src="https://intuitiveexplanations.com/assets/replit-tweet-2.png" alt="Screenshot of
Amjad's deleted tweet denigrating 'copycats'" width="60%"></center>
<p>Amjad later deleted these tweets because <a href="https://web.archive.org/web/20210505050939/https://twitter.com/amasad/status/1377604981549752320">they proved
controversial</a>:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-tweet-3.png" alt="Screenshot of
Amjad's tweet explaining that they deleted their previous,
controversial tweets" width="60%"></center>
<p>In these tweets, Amjad points out that Athens Research was clearly
inspired by another company, and argues that they should therefore be
“ridiculed” and banned from receiving funding. Furthermore, he says:
“I stand by what I said about copycats in general”, i.e. he disdains
all people that he thinks are “copying” existing ones, not just the
specific company in his tweet.</p>
<p>There is a clear resemblance between Amjad’s comments on Athens
Research and his legal threats towards my own project. He even used
exactly the same word, “copycat”, in both. In the case of Athens
Research, there was nothing Amjad could do to express his disdain
besides denigrate them on Twitter. But in my case, since I had worked
for Replit before, Amjad had an excuse to throw accusations my
way—accusations that, if you aren’t familiar with the facts, sound
like they could be legitimate.</p>
<p>I’d also like to reiterate that the person Replit is threatening with
“top lawyers” and “a lot of money” is a <em>new grad</em> with <em>no company</em>,
<em>no funding</em>, and <em>no commercial ambitions</em>. If someone with an actual
commercial enterprise were to offend Replit, I shudder to think what
treatment <em>they</em> might receive.</p>
<p>
Radon Rosborough, June 2021
</p>
<h2 id="how-did-replit-respond-to-this-blog-post" tabindex="-1">How did Replit respond to this blog post?</h2>
<p>After I posted the article in the morning, it was <a href="https://news.ycombinator.com/item?id=27424195">discussed
extensively on Hacker
News</a>. Around 5pm,
Amjad posted an apology on Hacker News, <a href="https://news.ycombinator.com/item?id=27429234">which has also been
discussed</a>.</p>
<center><img src="https://intuitiveexplanations.com/assets/amjad-hn-1.png" alt="Screenshot of an
email from Amjad apologizing for making legal threats, and my reply
indicating I would like to have a call" width="70%"></center>
<p>He also reached out to schedule a call, which I naturally agreed to:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-8.png" alt="Screenshot of an
email from Amjad promising that he will not sue me, and my response
thanking him and clarifying a point about how he quoted me" width="100%"></center>
<p>During the call, Amjad apologized for making legal threats, but
reiterated that he felt I had made a clone of Replit and that I had
acted unethically. Eventually we agreed to disagree, and he promised
in writing that he was fine with my putting my project back up:</p>
<center><img src="https://intuitiveexplanations.com/assets/replit-email-9.png" alt="Screenshot of
Amjad's comment on HackerNews saying that he apologizes for making
legal threats, but still feels I acted unethically" width="100%"></center>
<p>In retrospect, I’m a little disappointed that Amjad:</p>
<ul>
<li>didn’t apologize for (or mention) <a href="https://web.archive.org/web/20210608153700/https://twitter.com/amasad/status/1401957368510906369">publicly doubling
down</a>
on his decision to threaten me, and didn’t post an update to that
thread after the phone call</li>
<li>didn’t apologize for (or mention) <a href="https://web.archive.org/web/20210607231029/https://twitter.com/amasad">publicly
retweeting</a>
an accusation that I “literally stole and published IP”, although he
did at least delete the retweet</li>
<li>didn’t apologize for (or mention) making a <a href="#replit-email-5">nebulous personal
attack</a> in writing that I was a “demanding intern”
right after <a href="#replit-email-2">trying to hire me</a></li>
<li>said in the phone call, right after “apologizing”, that he felt as
if he had invited me into his house and I had betrayed his trust</li>
<li>still refused to list any specific part of Replit he thought I had
copied, even when I asked him for such details multiple times during
the phone call, despite his continuing to claim both privately and
publicly that I copied Replit unethically</li>
<li>misquoted me in writing to make me look like I agreed with his
accusations, right after reaching out to apologize for his behavior</li>
</ul>
<p>All in all, I think this could have gone better.</p>
<p>Nonetheless, I’m happy that we were able to get the situation worked
out amicably, and I look forward to moving on with my life—including
putting Riju back up, after I can get things compiling again :)</p>
<p>Peace.</p>
<h2 id="so-is-riju-back-up-now" tabindex="-1">So is Riju back up now?</h2>
<p>Yes! Check it out at <a href="https://riju.codes/">https://riju.codes/</a>, and join the community on
GitHub at <a href="https://github.com/raxod502/riju">https://github.com/raxod502/riju</a>. I’d love to work on the
project with you &lt;3</p>
<p>(Please note that Riju is only available on IPv6-enabled networks due
to the higher financial cost of supporting legacy protocols. If your
network <a href="https://test-ipv6.com/">does not support IPv6</a> then please
consider asking your network administrator or service provider to do
their part in supporting modern internet standards. You can consider
accessing Riju through a VPN as a workaround.)</p>
<p><em>Mandatory legal notice:</em> This blog post is maintained by <a href="https://radian.codes/">Radian
LLC</a>.</p>
</div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apollo 8 astronaut William Anders ID'd in WA plane crash (284 pts)]]></title>
            <link>https://www.fox13seattle.com/news/william-anders-wa-plane-crash</link>
            <guid>40614227</guid>
            <pubDate>Sat, 08 Jun 2024 00:16:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fox13seattle.com/news/william-anders-wa-plane-crash">https://www.fox13seattle.com/news/william-anders-wa-plane-crash</a>, See on <a href="https://news.ycombinator.com/item?id=40614227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-29b1414c="" lastmodifieddate="2024-06-07T18:47:39-07:00" data-v-0e30817a=""> <p><strong data-v-29b1414c="">Published</strong>&nbsp;
      June 7, 2024 3:35pm PDT
    </p>   </div><div data-v-0e30817a=""><div data-v-0e30817a=""><h4>Apollo 8 astronaut William Anders identified as pilot in WA plane crash</h4> </div> <!----><p data-v-0e30817a=""><span><strong>SAN JUAN COUNTY, Wash.</strong> - </span>Retired American astronaut William Anders, who was a member of the Apollo 8 crew, was killed in a <a href="https://www.fox13seattle.com/news/san-juan-islands-plane-crash" target="_self">plane crash just off the San Juan Islands</a> on Friday afternoon.</p> <!----><p data-v-0e30817a="">Anders' son, retired Air Force Lt. Col. Greg Anders, <a href="https://apnews.com/article/plane-crash-san-juan-islands-washington-6d3800130ef4e67d761f96b328f7c263" target="_blank">confirmed the death</a> to The Associated Press.</p>   <p data-v-0e30817a="">The plane that crashed was a vintage Air Force T-34 Mentor, which is owned by Anders, who is also a San Juan County resident.&nbsp;</p> <!----><div data-v-0dea8073="" data-v-0e30817a=""><p><img src="https://images.foxtv.com/static.q13fox.com/www.q13fox.com/content/uploads/2024/06/932/524/GettyImages-949601032.jpg?ve=1&amp;tl=1" alt="American astronaut William Ander" data-v-0dea8073=""></p><p data-v-0dea8073=""><span data-v-0dea8073="">Close-up of American astronaut William Anders, of NASA's Apollo 8 mission, during a panel interview held at the Museum of Science and Industry, Chicago, Illinois, April 5, 2018.</span> <span data-v-0dea8073=""><strong data-v-0dea8073=""> (Photo by J.B. Spector/Museum of Science and Industry, Chicago/Getty Images)</strong></span></p></div> <!----> <!----><p data-v-0e30817a="">Anders was reportedly piloting the plane when it crashed. "The family is devastated," Greg Anders said. "He was a great pilot and we will miss him terribly."</p> <!----><div data-v-0e30817a=""><h4>Video shows fiery small plane crash into WA waters near Orcas Island</h4> <p>Crews responded to a plane crash in the San Juan Islands on Friday afternoon. Officials with the United States Coast Guard Pacific Northwest said the crash happened near Orcas Island before 11:45 a.m.</p></div> <!----><h2 data-v-0e30817a="">Early life of William Anders</h2> <!----><p data-v-0e30817a="">William Anders was born on Oct. 17, 1933, in Hong Kong, but he grew up in San Diego. In 1955, Anders graduated from the United States Naval Academy with a bachelor of science degree, and received his master of science degree in nuclear engineering from the Air Force Institute of Technology in 1962. He completed the Harvard Business School Advanced Management Program in 1979.</p> <!----><h2 data-v-0e30817a="">Recruited by NASA</h2> <!----><p data-v-0e30817a="">In 1964, Anders was selected by the <a href="https://www.fox13seattle.com/news/boeing-starliner-launch-nasa-today" target="_blank">National Aeronautics and Space Administration</a> (NASA) to be an astronaut with responsibilities for dosimetry, radiation effects and environmental control.&nbsp;</p> <!----><p data-v-0e30817a="">He was a backup pilot for the Gemini XI, Apollo 11 flights, and was lunar module pilot for Apollo 8.</p> <!----><h2 data-v-0e30817a="">Apollo 8 mission</h2> <!----><p data-v-0e30817a="">In 1968, Anders operated the Apollo 8 mission alongside Air Force veteran Frank F. Borman II and Navy veteran James A. Lovell, Jr. In total, he logged more than 6,000 hours of flying time.</p> <!----><p data-v-0e30817a="">During this mission, their command module floated above the lunar surface, and the astronauts beamed back images of the moon and Earth and took turns reading from the Book of Genesis, closing with a wish for everyone "on the good Earth."</p> <!----><div data-v-0dea8073="" data-v-0e30817a=""><p><img src="https://images.foxtv.com/static.q13fox.com/www.q13fox.com/content/uploads/2024/06/932/524/GettyImages-170741727.jpg?ve=1&amp;tl=1" alt="" data-v-0dea8073=""></p><div data-v-0dea8073=""><p data-v-0dea8073=""><span data-v-0dea8073="">From L to R, Apollo 8 astronauts spacecraft Commander Frank Borman, Command Module Pilot James Lovell and Lunar Module Pilot William Anders, who became the first humans to escape Earth's gravity and the first humans to see the far side of the Moon, l</span> <!----></p> </div></div> <!----><p data-v-0e30817a="">According to NASA, the mission was also famous for the iconic "Earthrise" image, snapped by Anders, which would give humankind a new perspective on their home planet. Anders has said that despite all the training and preparation for an exploration of the moon, the astronauts ended up discovering Earth.</p> <!----><div data-v-0dea8073="" data-v-0e30817a=""><p><img src="https://images.foxtv.com/static.q13fox.com/www.q13fox.com/content/uploads/2024/06/932/524/AP24159853585088.jpg?ve=1&amp;tl=1" alt="" data-v-0dea8073=""></p><div data-v-0dea8073=""><p data-v-0dea8073=""><span data-v-0dea8073="">FILE - This Dec. 24, 1968, file photo made available by NASA shows the Earth behind the surface of the moon during the Apollo 8 mission. Retired Maj. Gen. William Anders, the former Apollo 8 astronaut who took the iconic "Earthrise" photo showing the </span> <!----></p> </div></div> <!----><h2 data-v-0e30817a="">William Anders' retirement</h2> <!----><p data-v-0e30817a="">In 1988, Anders retired from the Air Force Reserves and became the chairman and CEO of General Dynamics Corporation in 1991. After two years, he retired from General Dynamics and stayed as chairman until 1994.&nbsp;</p> <!----><p data-v-0e30817a="">Anders and his wife Valerie moved to Orcas Island in 1993. They have six children and 13 grandchildren.&nbsp;</p> <!----><div data-v-0dea8073="" data-v-0e30817a=""><p><img src="https://images.foxtv.com/static.q13fox.com/www.q13fox.com/content/uploads/2024/06/932/524/GettyImages-949601050.jpg?ve=1&amp;tl=1" alt="" data-v-0dea8073=""></p><div data-v-0dea8073=""><p data-v-0dea8073=""><span data-v-0dea8073="">Group portrait of, from left, American astronauts William Anders, James Lovell, and Frank Borman, all of whom participated in NASA's Apollo 8 mission, as they pose together at the Museum of Science and Industry, Chicago, Illinois, April 5, 2018. (Pho</span> <!----></p> </div></div> <!----><p data-v-0e30817a="">Shortly after retiring, the couple established the Anders Foundation supporting educational and environmental concerns as a vehicle for supporting several of their interests, including Yosemite National Institute and the Olympic Park Institute.&nbsp;</p> <!----><p data-v-0e30817a="">In 1996, the couple started the Heritage Flight Museum around the P-51 Val-Halla. It has steadily grown ever since and currently resides at Skagit Regional Airport in Burlington. As the museum grew, their two sons found a passion for aviation and joined them in the Puget Sound area to help run the museum.</p> <!----><p data-v-0e30817a=""><i>The Associated Press contributed to this report.</i></p> <!----><h2 data-v-0e30817a="">MORE HEADLINES FROM FOX 13 SEATTLE</h2> <!----><p data-v-0e30817a=""><a href="https://www.fox13seattle.com/news/new-wa-laws-june-6" target="_self"><strong>More than 300 new WA state laws went into effect June 6</strong></a></p> <!----><p data-v-0e30817a=""><a href="https://www.fox13seattle.com/news/parents-bill-of-rights-wa" target="_self"><strong>WA schools superintendent responds to new 'Parents' Bill of Rights'</strong></a></p> <!----><p data-v-0e30817a=""><a href="https://www.fox13seattle.com/news/amanda-knox-italy-slander"><strong>Amanda Knox vows to 'fight for the truth' after slander reconviction in Italy</strong></a></p> <!----><p data-v-0e30817a=""><a href="https://www.fox13seattle.com/news/teen-killed-garfield-high-identified" target="_self"><strong>17-year-old shot, killed at Seattle's Garfield High identified</strong></a></p> <!----><p data-v-0e30817a=""><i><strong>To get the best local news, weather and sports in Seattle for free, sign up for the daily </strong></i><a href="https://www.fox13seattle.com/newsletters" target="_self"><strong>FOX 13 Seattle newsletter</strong></a><i><strong>.</strong></i></p> <!---->  <!----> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is PID 0? (225 pts)]]></title>
            <link>https://blog.dave.tf/post/linux-pid0/</link>
            <guid>40613287</guid>
            <pubDate>Fri, 07 Jun 2024 21:42:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.dave.tf/post/linux-pid0/">https://blog.dave.tf/post/linux-pid0/</a>, See on <a href="https://news.ycombinator.com/item?id=40613287">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2024-06-05 00:00:00 +0000 UTC">June 5, 2024</time>
</p>
		<h2>What is PID 0?</h2>


		

		<p>I get nerd-sniped a lot. People offhandedly ask something innocent,
and I lose the next several hours (or in this case, days)
comprehensively figuring out the answer. Usually this ends up in a
rant thread on <a href="https://hachyderm.io/@danderson">mastodon</a> or in some
private chat group or other. But for once I have the energy to write
one up for the blog.</p>

<p>Today’s innocent question:</p>

<blockquote>
<p>Is there a reason UIDs start at 0 but PIDs start at 1?</p>
</blockquote>

<p>The very short version: Unix PIDs do start at 0! PID 0 just isn’t
shown to userspace through traditional APIs. PID 0 starts the kernel,
then retires to a quiet life of helping a bit with process scheduling
and power management. Also the entire web is mostly wrong about PID 0,
because of one sentence on Wikipedia from 16 years ago.</p>

<p>There’s a slightly longer short version right at the end, or you can
stick with me for the extremely long middle bit!</p>

<p>But surely you could just google what PID 0 is, right? Why am I even
publishing this?</p>

<h2 id="the-internet-is-wrong">The internet is wrong</h2>

<p>At time of writing, if you go ask the web about PID 0, you’ll get a
mix of incorrect and misleading information, and almost no correct
answers.</p>

<p>After figuring out the truth, I asked Google, Bing, DuckDuckGo and
Kagi what PID 0 is on linux. I looked through the top 20 results for
each, as well as whatever knowledge boxes and AI word salads they
organically gave me. That’s 2 pages of results on Google, for
reference.</p>

<p>All of them failed to produce a fully correct answer. Most had a
single partially correct answer somewhere in the first 20 results, but
never near the top or showcased. DDG did best, with the partially
correct answer at number 4. Google did the worst, no correct answer at
all. And in any case, the incorrect answers were so prevalent and
consistent with each other that you wouldn’t believe the one correct
site anyway.</p>

<p>The top-2 results on all engines were identical, interestingly: a
stackoverflow answer that is wrong, and a spammy looking site that
seems to have embraced LLM slop, because partway through failing to
explain PID 0 it randomly shifts to talking about <a href="https://en.wikipedia.org/wiki/Proportional%E2%80%93integral%E2%80%93derivative_controller">PID
loops</a>,
from control system theory, before snapping out of it a paragraph
later and going back to Unix PIDs.</p>

<p>Going directly to the source of the LLM slop fared slightly better, on
account of them having stolen from books as well as the web, but they
still make shit up in the usual amount. I was able to get a correct
answer though, using the classic prompting technique of already
knowing the answer and retrying until I got good RNG.</p>

<p>If we set aside the few entirely wrong answers (“there is no PID 0”,
“it launches init then exits”, “it’s part of systemd”, “it’s the
entire kernel”, “it spins in an infinite loop and nothing else”), the
most common answer follows a single theme: PID 0 has something to do
with paging, or swap space, virtual memory management in some way.</p>

<p>This theme comes straight from, where else? <a href="https://en.wikipedia.org/w/index.php?title=Process_identifier&amp;oldid=1184062138">Wikipedia’s article on
PIDs</a>,
which said:</p>

<blockquote>
<p>There are two tasks with specially distinguished process IDs:
<strong>swapper or sched has process ID 0 and is responsible for paging</strong>,
and is actually part of the kernel rather than a normal user-mode
process. Process ID 1 is usually the init process primarily
responsible for starting and shutting down the system.</p>
</blockquote>

<p>That text has been on Wikipedia for 16 years, and in that time has
been quoted, paraphrased and distorted across the web to the point
that it’s displaced the truth. It’s a pretty funny dynamic, and also a
bit sad, given the source code for Linux and the BSDs is right there,
you can just check.</p>

<p>(Later note: after I published this, someone went and updated the
article to have the correct information. The link above takes you to
the old version so that the rest of this explanation still makes
sense, but at time of writing this update <a href="https://en.wikipedia.org/wiki/Process_identifier">the current version of the
PID article</a> is
accurate)</p>

<p>To explain why Wikipedia was inaccurate here, we need to take a little
history lesson.</p>

<h2 id="the-history-of-pid-0-in-unix">The history of PID 0 in Unix</h2>

<p>As I said in the opening TLDR, PID 0 does some scheduling and power
management, and no paging. It’s what the scheduler runs when it has
nothing else for a CPU core to do.</p>

<p>The exact implementation obviously varies across kernels and versions,
but all the ones I inspected follow the same broad pattern: when PID 0
gets to run, it tries to find something else that could run in its
place. Failing that, it puts the current CPU core to sleep until
something else wakes it back up, and then loops around and starts
over.</p>

<p>Don’t take my word for it. Here’s
<a href="https://github.com/torvalds/linux/blob/2df0193e62cf887f373995fb8a91068562784adc/kernel/sched/idle.c#L258">do_idle</a>
in the Linux kernel, which is called in an infinite loop by
PID 0. <code>nohz_run_idle_balance</code> tries to find alternate work. The while
loop puts the core to sleep. After wakeup, <code>schedule_idle</code> lets the
scheduler take over and put the core to work again.</p>

<p>But maybe that’s just linux, I hear you say. Okay, here’s
<a href="https://cgit.freebsd.org/src/tree/sys/kern/sched_ule.c?id=86c9325d341fc3f39543bcfaf7c3bb3ceeacbe5d#n2996">sched_idletd</a>
in the FreeBSD kernel. <code>tdq_idled</code> tries to steal runnable tasks from
another core. Failing that, <code>cpu_idle</code> puts the core to sleep. Rinse,
repeat.</p>

<p>Okay sure but these are modern kernels, maybe it was different in the
olden days? Okay, how about
<a href="https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3/usr/src/sys/sys/vm_sched.c#L86">sched</a>
in 4.3BSD, from the summer of 1986? Computers are getting smaller and
OSes more compact, so the scheduler and idle loop are now smushed into
one routine. It tries to find something to schedule, and failing that
<code>sleep</code>s until an external event wakes it back up.</p>

<p>Incidentally, this is the origin of the vague allegation that PID0 is
sometimes called “sched”: in earlier Unixes, the function that
implements PID 0 is literally called <code>sched</code>.</p>

<p>Still not sure? Maybe it’s just a weird BSD thing that leaked into
Linux?</p>

<p>Okay fine, here’s
<a href="https://github.com/dspinellis/unix-history-repo/blob/Research-V4/sys/ken/slp.c#L89">sched</a>
in Unix V4, the first known version of the Unix kernel written in
C. Again the scheduler and idle loop are firmly intertwined, and
there’s also some PDP-11 esoterics that are confusing to modern eyes,
but the same bones are there: find a runnable process and switch to
it, or idle and then try again.</p>

<p>You could go further back. The source code for Unix V1 is out there,
as well as an early prototype on PDP-7. However, it’s all in PDP
assembler, uses some mnemonics that don’t seem to be listed in the
surviving assembler references I could find, and the kernel’s
structured a fair bit differently from the C version.</p>

<p>That said, if you want to go digging, I believe the <code>swap</code> routine is
the meat of the scheduler. And finally we get a clear idea of the root
of the Wikipedia claim: in the earliest Unix implementation, the
scheduler was sometimes nicknamed the “swapper.”</p>

<p>It was called that because, now that we’re back at the beginning of
Unix, one routine encompasses not only scheduling and idling, but also
moving entire process memory images between the small core memory and
secondary storage. Hard drives in this case, references in the kernel
code as well as the <a href="https://gunkies.org/wiki/UNIX_First_Edition">Computer History
wiki</a> confirm that Bell
Labs’s PDP-11 at the time ran an RS11 disk for the core OS and process
swapping, and an RK03 for the user filesystem.</p>

<p>(Sidebar! This is where the / vs. /usr split comes from. /usr was the
part of early Unix stored on the RK03 disk, whereas the smaller root
filesystem was on the RS11. Unless you’re still running on a PDP-11
with single RS11 and RK03 disks, a split /usr is vestigial and <a href="https://systemd.io/SEPARATE_USR_IS_BROKEN/">causes
a variety of problems in early
boot</a>)</p>

<p>So now the history is hopefully fairly clear. In the first Unix the
world at large saw (Unix V5), entry zero in the process table
initialized the kernel, then looped in the <code>sched</code> function, defined
in <code>slp.c</code>. Those two names clearly telegraph the loop’s primary
functions. However, the scheduling algorithm is quite simple at this
point, and so almost all of <code>sched</code>’s code is concerned with swapping
process images in and out of core memory in order to make scheduling
happen. Thinking of this function as the “swapper” is reasonable, even
if the original source code never uses that name.</p>

<p>This essential structure survives to this day, with a lot more
complications. Whole-process swapping gave way to <a href="https://en.wikipedia.org/wiki/Memory_paging">demand
paging</a>, and so PID 0
stopped concerning itself with even a little memory management. As
both the scheduling algorithms and the mechanics of idling a CPU
became more complex, scheduling and idling were split out into
separate pieces of code, and you end up with what we’ve had for at
least two decades: the function implementing PID 0 has <code>sched</code> or
<code>idle</code> in its name, and has a supporting role in doing those two
things.</p>

<p>Going back to the Wikipedia article, it seems the author of that edit
wanted to write “swapping”, in the classic Unix V5 sense of swapping
out whole processes <em>as a consequence of scheduling</em>. But the edit
didn’t clarify that “swapping” was being used in an archaic sense that
was likely to confuse the modern reader. Furthermore the edit wrote
“paging” rather than “swapping”. I don’t know why, but my guess is
that it’s because the canonical article for this general memory
management concept is titled “Memory paging”, whereas “swapping” is a
disambiguation page. In the moment of making the edit, I could
definitely see myself swapping out for the seemingly preferred term.</p>

<p>Unfortunately, in this particular context, replacing “swapping” with
“paging” makes the sentence incorrect. And there it sat for 16 years,
slowly leaking into the rest of the web as people quoted wikipedia at
each other and paraphrased or elaborated further in the wrong
direction.</p>

<p>Okay, end of rant about how the web is turning to ash in our
hands. It’d be nice if it didn’t, or at least it’d be nice if half the
industry wasn’t breathlessly building ways to spray more petrol on
what’s left. So it goes. Back to PID 0 now.</p>

<h2 id="are-those-functions-really-pid-0">Are those functions really PID 0?</h2>

<p>Above, I claim by fiat that the functions I’m linking to are
PID 0. Tracing all of them would take a lot more words, but I’ll
demonstrate the point on Linux and leave you to trace the others. I
encourage you to do so! It’s remarkable how similar to each other
different kernels are in this area, both across current OSes and over
time. They’ve become more complex, but the family tree is still
evident.</p>

<p>Disclaimer, the Linux kernel is a very complex beast. I’m not going to
walk through every single thing the kernel does before reaching
<code>do_idle</code>. Think of this as a signposts to help orient you, not a
comprehensive breakdown. This was written using the 6.9 kernel source
code, so if you’re visiting from the future: hello! I hope your
dilithium matrix is cycling well, and things may have changed.</p>

<p>We begin! The bootloader jumps to the first instruction of kernel
code. The first few steps from here are <em>extremely</em> specific to the
CPU architecture and nearby chipset hardware. I’m going to skip that
and begin at
<a href="https://github.com/torvalds/linux/blob/d30d0e49da71de8df10bf3ff1b3de880653af562/init/main.c#L903">start_kernel</a>,
where the machine has been set up to a common baseline and
architecture-independent kernel code takes over (albeit still assisted
by arch-specific helpers).</p>

<p>At this point, <code>start_kernel</code> is the only thing running on the machine
(yes I know about ring minus 1 and SMM and so on, I said I was
simplifying). On multicore systems, the bootloader/firmware/hardware
arranges for a single CPU core to be running, called the bootstrap
core. That single thread of execution is what we’re looking at, and
it’s all we get until the kernel starts the other cores itself.</p>

<p>The first thing to get called is
<code>set_task_stack_end_magic(&amp;init_task)</code>. Well that looks relevant! It’s
a very simple function that writes a magic number to the top of
<code>init_task</code>’s stack space to detect overflows. <code>init_task</code> is
statically defined in
<a href="https://github.com/torvalds/linux/blob/master/init/init_task.c#L64">init_task.c</a>,
and the leading comment tells us it’s the first task. What’s a task
though?</p>

<h2 id="task-struct-pids-tids-tgids-and-oh-no">task_struct, PIDs TIDs TGIDs and oh no</h2>

<p>Here we have to take a detour into something very confusing: the Linux
kernel and its userspace disagree on the meaning of PID.</p>

<p>In the kernel, the unit of running things is the <code>task_struct</code>. It
represents one thread of execution, rather than a whole process. To
the kernel, a PID identifies a <em>task</em>, not a
process. <code>task_struct.pid</code> is the identifier for that one thread only.</p>

<p>The kernel still needs to represent the concept of a userspace process
somehow, but it’s not a nice crunchy data structure you can point
at. Instead, threads are collected into “thread groups”, and groups
are identified by a thread group identifier, or TGID. Userspace calls
thread groups processes, and thus the kernel TGID is called the PID in
userspace.</p>

<p>To add confusion, these numbers are often the same. When a new thread
group is created (e.g. when userspace runs fork()), the new thread is
given a new thread ID, and that ID also becomes the new group’s
TGID. So for single-threaded processes, kernel TID and TGID are
identical, and asking either the kernel or userspace what this thing’s
“PID” is would give you the same number. But that equivalence breaks
once you spawn more threads: the new thread gets its own thread ID
(which is what the kernel calls a PID), but inherits its parent’s
thread group ID (which userspace calls a PID).</p>

<p>To add <em>even more</em> confusion, the arrival of containers forces threads
and processes to have multiple identities. The thing that’s PID 1 in a
docker container is very much not the same as PID 1 outside the
container. This is tracked in a separate <code>pid</code> struct, which keeps
track of the different thread IDs a <code>task_struct</code> has, depending on
which PID namespace is asking.</p>

<p>I’m a userspace enjoyer by day, so when I started this rabbithole I
interpreted “PID 0” in the question as an analog to the PID 1 I know,
that /bin/init thing. But now the question is ambiguous! PID 0 could
mean thread 0, or it could mean thread group 0.</p>

<p>At the beginning of the kernel, the answer is fortunately easy:
<code>init_task</code> represents PID 0 by everyone’s definition. It’s the thread
with ID 0 (which is the PID according to the kernel), it’s the only
thread in the group with ID 0 (which is the PID according to
userspace), and no child PID namespaces exist yet, so there’s no other
numbers for <code>init_task</code> to be.</p>

<p>This <em>will</em> get muddier later on because thread group 0 is going to
grow more threads, so in userspace terms we’ll have a PID 0 process
that contains several threads, one of which has TID 0. In the rest of
this post I’m going to try and say “task” or “thread” to mean a single
thread of execution, the thing described by a <code>task_struct</code>; and
“thread group” for the thing userspace would call a process. But it’s
not just you, it’s terribly confusing.</p>

<p>Okay, back to the code walk…</p>

<h2 id="the-path-to-the-idle-task">The path to the idle task</h2>

<p>So, we know <code>init_task</code> is the PID 0 we’re looking for, albeit now
it’s actually two different PID 0s at the same time because it’s the
thread with ID 0 within the thread group with ID 0. How do we know
that <code>init_task</code> describes the currently-executing CPU context?</p>

<p>There’s a few things. We know we’re the only thread of execution
currently happening, and <code>init_task</code> is described as the first task,
aka the first thread. That sounds like us. It’s using <code>init_stack</code> as
its stack, which is the stack we’re currently using (proving this
requires digging into arch-specific code and gcc linker scripts, so
I’m going to skip it, but have fun!). Its <code>__state</code> is <code>TASK_RUNNING</code>,
which means it’s either running right now, or it’s runnable and
waiting for CPU time. The kernel scheduler isn’t initialized yet, so
there can’t really be any other runnable task at this point. This
could be a setup for an elaborate trolling, but the evidence suggests
that this <code>init_task</code> is us. And spoiler, we’re not being trolled,
<code>init_task</code> is indeed the initial thread that executes <code>start_kernel</code>.</p>

<p>At this point a lot of early kernel initialization happens. We can
skip over all that for our purposes, and pick up at the call to
<a href="https://github.com/torvalds/linux/blob/master/kernel/sched/core.c#L9920">sched_init</a>. This
function does basic initialization of the CPU scheduler’s data
structures. A lot happens because the scheduler is a large beast,
we’ll just peek at a couple of relevant lines:</p>

<pre><code>    /*
     * The idle task doesn't need the kthread struct to
     * function, but it is dressed up as a per-CPU
     * kthread and thus needs to play the part if we want
     * to avoid special-casing it in code that deals with
     * per-CPU kthreads.
     */
    WARN_ON(!set_kthread_struct(current));

    /*
     * Make us the idle thread. Technically, schedule()
     * should not be called from this thread, however
     * somewhere below it might be, but because we are the
     * idle thread, we just pick up running again when this
     * runqueue becomes "idle".
     */
    init_idle(current, smp_processor_id());
</code></pre>

<p>The first line describes the currently executing thread as “the idle
task,” and mentions that it’s a special kernel thread: most kernel
threads are run by <code>kthreadd</code>, which is task 2 and doesn’t exist
yet. If you’re on linux, <code>ps ax | grep kthreadd</code> will show that
kthreadd is PID 2 in userspace, in addition to also being thread/task
ID 2 in the kernel.</p>

<p>The second line explicitly tells the scheduler that the currently
running thread is the “idle thread” for the bootstrap CPU
core. <code>current</code> is a pointer to the currently-running <code>task_struct</code>,
which at this point in execution points to <code>init_task</code>. The
implementation of <code>current</code> is another very architecture-specific
piece of code, so I’m going to encourage you to go poke at it if
curious, and move right along.</p>

<p>Going back to <code>start_kernel</code>, the remaining initialization code
doesn’t concern us, so we can skip straight to the call to
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/init/main.c#L701">rest_init</a>. This
function is short and sweet: it spawns task 1, which will become the
init process in userspace; and task 2 for <code>kthreadd</code>, which manages
all future kernel threads.</p>

<p>We’ll be following the life of task 1, and although it will someday
become PID 1 in userspace, to start it’ll run
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/init/main.c#L1458">kernel_init</a>. Not
yet though. These new tasks exist and are known to the scheduler, but
they’re not running yet because we haven’t asked the scheduler to do
its thing yet. (caveat: in some kernel configurations, the scheduler
may get a chance to switch to task 1 and 2 sooner than what I’m about
to describe, but these first tasks are orchestrated such that the
outcome is nearly identical.)</p>

<p>Finally, <code>rest_init</code> calls
<a href="https://github.com/torvalds/linux/blob/master/kernel/sched/idle.c#L424">cpu_startup_entry</a>,
which goes into an infinite loop of calling
<a href="https://github.com/torvalds/linux/blob/master/kernel/sched/idle.c#L258">do_idle</a>. And
here we are, we’ve become the idle task on the bootstrap CPU core. On
the first iteration, we don’t put the CPU to sleep because there are
other runnable tasks (the two we just made). So we drop to the bottom
of <code>do_idle</code>, and go into <code>schedule_idle</code>. The scheduler finally gets
to run, and we switch away from task 0. <code>kthreadd</code> in task 2 isn’t
terribly interesting, it does a little initialization then yields the
CPU again until something else asks to create kernel threads. Let’s
follow task 1 instead, it’s much more fun.</p>

<p>Task 1 starts at
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/init/main.c#L1458">kernel_init</a>. This
does even more kernel initialization, including bringing up all device
drivers and mounting either the initramfs or the final root
filesystem. And then, at last, it calls
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/init/main.c#L1376">run_init_process</a>
to drop out of kernel mode and execute userspace’s init program. If
init(1) asks the kernel who it is, it’ll be told that it is thread 1,
which is part of thread group 1. Or thread 1 in PID 1, in the
conventional userspace vocabulary.</p>

<p>It was a surprise to me that task/pid 1 does a whole bunch of kernel
work before if morphs into the familiar userspace process! A large
chunk of what I think of as the kernel booting <em>technically</em> happens
in PID 1, albeit in a very different looking universe to init(1) in
userspace. Why not do those bits in task 0, like the earlier bits of
init?</p>

<h2 id="pid-0-in-multicore-systems">PID 0 in multicore systems</h2>

<p>If you’ve been following carefully so far, you may be wondering about
the other CPU cores. So far we’ve run entirely single-threaded, and
when we initialized the scheduler we explicitly told it to pin task 0
to the bootstrap core. When does that change?</p>

<p>The answer is, in task 1! The first thing <code>kernel_init</code> does is start
up all other CPU cores. This means the bulk of the boot process that
happens in <code>kernel_init</code> can make use of all available CPU power,
rather than being stuck on a single thread. Starting CPU cores is
quite intricate, but the exciting bit for our purposes is the call to
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/kernel/smp.c#L971">smp_init</a>. In
turn, it calls
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/kernel/fork.c#L2705">fork_idle</a>
for each non-bootstrap core, creating a new idle thread and pinning it
to that core. This is where the “PID 0” term gets muddy, because these
new idle tasks have non-zero thread IDs, but they are still part of
thread group 0. So, in userpace parlance, PID 0 is a process that
contains one pinned thread per core, with thread 0 pinned to the
bootstrap core.</p>

<p>After that, <code>smp_init</code> runs
<a href="https://github.com/torvalds/linux/blob/8a92980606e3585d72d510a03b59906e96755b8a/kernel/cpu.c#L1860">bringup_nonboot_cpus</a>,
which does architecture-specific incantations to wake up the cores. As
each core starts, it does a bit of arch-specific setup to make itself
presentable, then runs <code>cpu_startup_entry</code> and <code>do_idle</code>, just like
the bootstrap core did with task 0. All CPU cores are now alive and
can run tasks, and <code>kernel_init</code> proceeds with the rest of boot.</p>

<h2 id="i-m-bad-at-conclusions">I’m bad at conclusions</h2>

<p>And that’s it! To summarize:</p>

<p>PID 0 does exist, it’s the one thread that starts the kernel, provided
by the bootstrap CPU core.</p>

<p>PID 0 runs early kernel initialization, then becomes the bootstrap CPU
core’s idle task, and plays a minor supporting role in scheduling and
power management.</p>

<p>PID 0 has done this, with different degrees of fanciness but the same
broad strokes, since the first Unix kernels. You can go read the
source code of many of them and see for yourself! That’s cool.</p>

<p>PID 0 has nothing to do with memory management. In early Unix kernels
it did some incidental memory management as part of process
scheduling. PID 0 stopped doing that many decades ago.</p>

<p>On Linux, “PID 0” is ambiguous because userspace and the kernel
disagree on what a PID is. The kernel’s definition wins in practice
for PID 0, because none of the entities that make up PID 0 are visible
to userspace through the traditional Unix APIs.</p>

<p>On multicore systems, every CPU core gets an idle thread. All those
idle threads are part of thread group 0, which userspace would call
PID 0. Thread ID 0, which is what the linux kernel calls PID 0, is as
described above.</p>

<p>Seemingly all Q&amp;A websites on the internet function primarily by
paraphrasing Wikipedia. This is made evident and awkward when
Wikipedia accidentally makes the web repeat incorrect information for
16 years.</p>

<p>Having worked all this out, I’d love to go edit the Wikipedia article
and set the record straight… But would that count as “primary
research”? Would the edit be reverted because it disagrees with most
of the web? Does publishing this post mean editing wikipedia would now
count as some variation of sockpuppeting or self-promotion?</p>

<p>I don’t know, and I’ll try to figure it out. In the meantime, thanks
for joining me on this chronicling of how I end up going on very large
sidequests when presented with a short, odd questions.</p>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xv6, a simple Unix-like teaching operating system (155 pts)]]></title>
            <link>https://pdos.csail.mit.edu/6.828/2023/xv6.html</link>
            <guid>40613126</guid>
            <pubDate>Fri, 07 Jun 2024 21:22:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pdos.csail.mit.edu/6.828/2023/xv6.html">https://pdos.csail.mit.edu/6.828/2023/xv6.html</a>, See on <a href="https://news.ycombinator.com/item?id=40613126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>





<h2>Xv6, a simple Unix-like teaching operating system</h2>

<h2>Introduction</h2><p>

Xv6 is a teaching operating system developed in the summer of 2006,
which we ported xv6 to RISC-V for a new undergraduate class 6.1810.

</p><h2>Xv6 sources and text</h2><p>

The latest xv6 source and text are available via
</p><pre>git clone https://github.com/mit-pdos/xv6-riscv.git</pre><p>
and
</p><pre>git clone https://github.com/mit-pdos/xv6-riscv-book.git</pre>

<h2>Unix Version 6</h2>

<p>xv6 is inspired by Unix V6 and by:

</p><ul>

<li>Lions' <i>Commentary on UNIX' 6th Edition</i>, John Lions, Peer to
Peer Communications; ISBN: 1-57398-013-7; 1st edition (June 14, 2000).
	<ul>

	<li>An on-line version of the <a href="http://www.lemis.com/grog/Documentation/Lions/">Lions
	commentary</a>, and <a href="http://v6.cuzuco.com/">the source code</a>.


	</li><li>The v6 source code is also available 
	  <a href="http://minnie.tuhs.org/cgi-bin/utree.pl?file=V6">online</a>
	  through <a href="http://www.tuhs.org/">The Unix Heritage Society</a>.

	</li></ul>

</li></ul><p>

The following are useful to read the original code:
</p><ul>
<li><i>
The PDP11/40 Processor Handbook</i>, Digital Equipment Corporation, 1972.
<ul>
<li>A <a href="http://pdos.csail.mit.edu/6.828/2005/readings/pdp11-40.pdf">PDF</a> (made from scanned images, 
and not text-searchable)
</li><li>A <a href="http://pdos.csail.mit.edu/6.828/2005/pdp11/">web-based
version</a> that is indexed by instruction name.
</li></ul>

</li></ul>

<h2>Feedback</h2><p>
If you are interested in using xv6 or have used xv6 in a course,
we would love to hear from you.
If there's anything that we can do to make xv6 easier
to adopt, we'd like to hear about it.
We'd also be interested to hear what worked well and what didn't.
</p><p>
Russ Cox (rsc@swtch.com)<br>
Frans Kaashoek (kaashoek@mit.edu)<br>
Robert Morris (rtm@mit.edu)
</p><p>
You can reach all of us at 61810-staff@lists.csail.mit.edu.

<!-- End Page Content -->

</p><hr>

<p><span>
<p>Questions or comments regarding 6.1810?  Send e-mail to the course staff at
<a href="mailto:61810-staff@lists.csail.mit.edu"><i>61810-staff@lists.csail.mit.edu</i></a>.

</p></span></p><p><span><a rel="license" href="https://creativecommons.org/licenses/by/3.0/us/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by/3.0/us/88x31.png"></a> <b><a href="#top">Top</a></b> //
<b><a href="https://pdos.csail.mit.edu/6.828/2023/index.html">6.1810 home</a></b> // 
<i>Last updated Wednesday, 16-Aug-2023 06:53:08 EDT</i>
</span>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yes, you can play Duck Hunt without a television (but I can't) (135 pts)]]></title>
            <link>https://nicole.express/2024/no-screen-no-cpu-one-problem.html</link>
            <guid>40612387</guid>
            <pubDate>Fri, 07 Jun 2024 20:02:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicole.express/2024/no-screen-no-cpu-one-problem.html">https://nicole.express/2024/no-screen-no-cpu-one-problem.html</a>, See on <a href="https://news.ycombinator.com/item?id=40612387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Duck Hunt</em> is considered a classic of the Nintendo Entertainment System. But surprisingly, the concept of hunting ducks did not originate in 1984– people have wanted to hunt ducks since at least 1951, when <a href="https://www.youtube.com/watch?v=9-k5J4RxQdE">Daffy Duck</a> proclaimed it to be “Duck Season” in the Looney Tunes short <em>Rabbit Fire</em>. But Nintendo didn’t make video games that connected to your television until <a href="https://nicole.express/2023/not-another-color-post-i-swear.html">1977</a>. What if I wanted to hunt ducks in 1976? BONUS: The ducks are immortal!</p>



<p>Duck Hunt? Without a TV? Actually, it’s got quite a long history.</p>

<p><img src="https://nicole.express/assets/img/quacks/flyer.jpg" title="no dog in sight" alt="Sega Duck Hunt flyer, showing an arcade machine with mounted guns"></p>

<p>In this case Nintendo was doing what Seg-already-did, as Sega had <a href="https://segaretro.org/Duck_Hunt"><em>Duck Hunt</em></a> as early as 1968. (It’s a generic term) But that was an electromechanical game, with physical moving targets, and a game for the commercial circuit to boot– Sega didn’t sell anything to the masses in those days. So it was up to Nintendo to package the concept in a nice beige box that you could bring home.</p>

<p><img src="https://nicole.express/assets/img/quacks/box.jpeg" title="hunting ducks?" alt="Duck Hunt box"></p>

<p>Notice that text below the English text? That text says 光線銃ダックハント, “ダックハント” being simply “Duck Hunt” in katakana, while “光線銃”, <em>kousenjuu</em>, is the Japanese term for “ray gun”. For Nintendo, <em>kousenjuu</em> was a series of light gun toys, but they were not always intercompatible– for example, <em>Duck Hunt</em> required the specific gun it came with. Even the Famicom Gun was eventually sold as part of the <em>kousenjuu</em> series in Japan. (And it was the last)</p>

<p><img src="https://nicole.express/assets/img/quacks/ray.jpeg" title="pew pew" alt="Zoom in on Japanese text"></p>

<p>And that is one serious gun. It comes in two pieces because it won’t fit on its own. The rest of the box is taken up by the projector.</p>

<p><img src="https://nicole.express/assets/img/quacks/boks.jpeg" title="project much?" alt="Inside of box"></p>

<p>Just to drive home the point of how big the gun is, here it is compared to the “I can’t believe it’s not a Zapper” I used in the <a href="https://nicole.express/2023/bang-bang-youre-dead.html">lightguns on LCD</a> post and the Famicom Gun. It’s longer than the two of them <em>combined</em>. Plus, being from the 1970s, no attempt was made to make this look like a toy. Don’t carry it anywhere around your local cops, at least here in the US.</p>

<p><img src="https://nicole.express/assets/img/quacks/gunz.jpeg" title="and people tell me japan has gun control" alt="the long rifle-like gun compared to smaller pistol and laser-pistol like guns. don't worry, they're all plastic"></p>

<p>The projector takes four “D” cell batteries, which it refers to as UM-1, and the gun takes two “C” cell batteries, which it refers to as “C”; I guess Japan was in a period of transitioning between the two standard types at the time. The projector power switch literally just pushes down on the D cell batteries; this is a very mechanical device. (This also means the motor might go on for a second while you put the batteries in, don’t get startled like I did)</p>

<p><img src="https://nicole.express/assets/img/quacks/switch.jpeg" title="i just thought this was neat-- also dont mind the neo geo cd controller" alt="The switch that just pushed won a metal contat slightly"></p>

<p>And that projector raises the question: is this a <em>video game</em>? The first definition I find is:</p>

<blockquote>
  <p>An electronic game played by manipulating moving figures on a display screen, often designed for play on a special gaming console rather than a personal computer.</p>
</blockquote>

<p>And this manipulates moving figures (the ducks) on a display screen (the projector). Sure, it’s a purpose-built projector, but a <a href="https://nicole.express/2023/gaming-in-the-mirror-universe.html">Game &amp; Watch</a> also uses a purpose-built screen. And sure, it’s a mechanical device, no CPU or software here, but hey, an early analog <a href="https://nicole.express/2023/special-thanks-to-homer.html"><em>Pong</em> console</a> doesn’t have a CPU either, and are we going to be that biased against mechanical logic?</p>

<p>And this is where the blog post takes a sudden turn for the worst. If you just want to read more about the Nintendo mechanical <em>Duck Hunt</em>, check out <a href="http://blog.beforemario.com/2012/09/nintendo-kousenjuu-duck-hunt-1976.html"><em>Before Mario</em></a>. They even have a <a href="https://www.youtube.com/watch?v=aJOkrp7VG60">video</a> and a <a href="http://blog.beforemario.com/2012/10/nintendo-kousenjuu-duck-hunt-how-it.html">technical breakdown</a>. If you want to see the struggles of Nicole on her web log, well, keep reading.</p>

<h2 id="quack-goes-the-weasel">Quack goes the weasel</h2>

<p>Once you turn on the projector and point it at the wall, you see a duck.</p>

<p><img src="https://nicole.express/assets/img/quacks/duck.jpeg" title="a very hard to photograph duck" alt="A duck on the wall"></p>

<p>It’s a quite well-animated duck, flapping back and forth, and moving on an unpredictable course. (Actually, the unpredictable course is, like <a href="https://www.youtube.com/watch?v=BSvZbcwqlTw">Blip</a>, controlled by internal gears on a complex but predictable pattern) The light also turns on and off, presenting a duck flying up and down, disappearing before you can get too close to being able to predict it.</p>

<p><img src="https://nicole.express/assets/img/quacks/orje.jpeg" title="look this is pretty far zoomed in and with flash, dust was inevitable" alt="A circuit board inside, the light sensor is visible"></p>

<p>When you shoot a duck, the light will bounce off your wall and some of it will go back into the projector. There is a light sensor mounted on a bar over the projector output; through the magic of optics, this isn’t too visible on the duck you see on the wall, but light passing back to the projector can still be amplified and then detected. At that point, the projector will show the duck falling, as is presented on the side of the box:</p>

<p><img src="https://nicole.express/assets/img/quacks/quack.jpeg" title="if you know what victory shoot is clap your hands; if you don't then maybe ill have to write a post on it, more pachinko for all you naughty children" alt="Box on a shelf showing falling duck"></p>

<p>But one thing I found is that I could not shoot the ducks. Now, I’m pretty bad at light gun games, and that’s been an obstacle several times on this blog. But it wasn’t just that– my wife couldn’t shoot them either, and she’s a much better shot. Plus, the gun wasn’t actually letting out any visible light at all. Now, it could be acting in a non-visible portion of the spectrum, but that was still a concern.</p>

<h3 id="taking-apart-the-gun">Taking apart the gun</h3>

<p>The gun is held together by bolts and little hex nuts on the other side; no screwing into plastic here, thankfully.</p>

<p><img src="https://nicole.express/assets/img/quacks/gune.jpeg" title="take the batteries out, idiot" alt="Gun inside, a small circuit board"></p>

<p>It’s a little bit more complicated than the Famicom gun inside here. Before we flip over the PCB to see the component side, let’s take a look at that circular mechanism.</p>

<p><img src="https://nicole.express/assets/img/quacks/zune.jpeg" title="take a closer look" alt="Zoomed in to show a punched metal disk and the cocking mechanism"></p>

<p>A punched metal disk has three little points, and a spring to keep the position accurate. When you cock the gun, the position of the three points changes, changing how the circuitboard is connected, and then when you fire the gun it snaps back to its regular position. Keep this in mind when we look at the circuitboard.</p>

<p><img src="https://nicole.express/assets/img/quacks/pcb.jpeg" title="single sided pcbs" alt="Other side, showing a few capacitors and coils"></p>

<p>As you can see, the circuit is basically set up to charge the capacitor, and then release the voltage across a small flash-bulb. We can snag some documentation on it from the <a href="https://patents.google.com/patent/US3904204A/en">patent</a> to confirm. Unfortunately the patent also mentions that the gun must fire a predetermined signal, so I can’t cheat by shining a light into the projector.</p>

<p><img src="https://nicole.express/assets/img/quacks/pat.png" title="tag yourself im the charging device" alt="Patent layout for the gun, showing the charging device across a lamp"></p>

<p>Unfortunately, my best guess here after checking out all the connections is that the bulb is dead. And this is where I’m stuck. So I’m going to ask anyone reading this: I know my blog posts sometimes get traction, if you happen to know a part number for this bulb, or where I could find a replacement, I’d love to try to get this gun back up and working. But for now, the ducks can keep flying indefinitely. Mocking me. At least that stupid dog isn’t there.</p>

<p><a href="https://www.leadedsolder.com/">Leaded Solder</a> suggested I actually give the dimensions of the bulb, which might be useful: 3.3mm diameter, a hair over 27mm long. Good thought.</p>

  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The aging U.S. power grid is about to get a jolt (118 pts)]]></title>
            <link>https://www.wsj.com/business/energy-oil/the-aging-u-s-power-grid-is-about-to-get-a-jolt-144e7fdc</link>
            <guid>40612365</guid>
            <pubDate>Fri, 07 Jun 2024 20:01:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/energy-oil/the-aging-u-s-power-grid-is-about-to-get-a-jolt-144e7fdc">https://www.wsj.com/business/energy-oil/the-aging-u-s-power-grid-is-about-to-get-a-jolt-144e7fdc</a>, See on <a href="https://news.ycombinator.com/item?id=40612365">Hacker News</a></p>
Couldn't get https://www.wsj.com/business/energy-oil/the-aging-u-s-power-grid-is-about-to-get-a-jolt-144e7fdc: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Feynman’s Razor (255 pts)]]></title>
            <link>https://defenderofthebasic.substack.com/p/feynmans-razor</link>
            <guid>40612285</guid>
            <pubDate>Fri, 07 Jun 2024 19:53:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://defenderofthebasic.substack.com/p/feynmans-razor">https://defenderofthebasic.substack.com/p/feynmans-razor</a>, See on <a href="https://news.ycombinator.com/item?id=40612285">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><blockquote><p>“I can’t read the articles in the paper. I don’t know what they mean. I don’t know what kind of a machine it was just because it weighed seven tons. And there are not sixty two kinds of particles, and I would like to know what atomic bullet he is referring to”</p><p><span>— Richard Feynman, </span><a href="https://antilogicalism.com/wp-content/uploads/2018/11/meaning-of-it-all.pdf" rel="nofollow ugc noopener">The Meaning of it All</a><span>, page 38 in PDF &amp; 88 in the book </span></p></blockquote><p>I’ve been using this as my north star when explaining technical matters to laypeople. Basically, if someone who is capable of understanding the thing read my description, would they get it? If not, then it’s not a adequate explanation. </p><p>I was thinking about this recently because of a HN discussion (https://news.ycombinator.com/item?id=40535868) where people were making fun of this nonsensical error message:</p><blockquote><p>This message can't be saved because it no longer exists. It can only be discarded. Make sure you copy the contents of the message before you discard if you want to use them later.</p></blockquote><p>what the hell does this mean? The message doesn’t exist, but I can copy its contents? If I can copy its contents…why can’t I save it?? If it doesn’t exist why do I have to discard it??</p><p><span>My </span><a href="https://news.ycombinator.com/item?id=40550174" rel="nofollow ugc noopener">favorite comment was from lisper</a><span> who said basically, “guys, chill, there is a legit technical edge case here, it’s just difficult to explain to the layperson. How would YOU do it?”</span></p><p>That is a great question! Here was one person’s attempt that I liked:</p><blockquote><p>"This message has been deleted from the mail server, but Outlook still has it in its temporary cache on this device. You can copy the message contents, or discard it from the cache, at which point it will be permanently deleted."</p></blockquote><p>many scoffed at this though. Because “the layperson doesn’t understand things like `cache` and `server`”</p><p><span>ok but do you see the problem here? The original error message already doesn’t tell me anything, </span><strong>even if I am perfectly capable of understanding it</strong><span>. It’s assuming the average person is too dumb/doesn’t care about understanding the root cause, and treating ALL users this way.</span></p><p>What’s the real harm in using the words “server” and “cache” ? The user who doesn’t care about understanding isn’t going to get much out of it either way, I can concede that. But those that do can and will google those terms, and maybe they will learn something. And you can be sure there WILL in fact be users who understand it who will absolutely appreciate it.</p><p><span>I think this is very much Feynman’s point: he didn’t have flowery unrealistic expectations of the average person. He just said, look, </span><strong>there’s a LOT of variance in the skill &amp; interest of people.</strong><span> Why are we not even giving people a chance?</span></p><p>“the whole idea that the average person is unintelligent is a very dangerous idea”</p><p>here’s the full page:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png" width="1200" height="651.7857142857143" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:730,&quot;width&quot;:1344,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8c3aa7f-15dc-4c93-a722-88f7548a58db_1344x730.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption></figcaption></figure></div><p><span>I caught myself violating this recently, when working on my </span><a href="http://substack-proxy.glitch.me/" rel="nofollow ugc noopener">“substack-proxy”</a><span> tool (to get around twitter censorship of substack posts). It automatically makes a request to my server to create a URL when you copy/paste something in. But I noticed it was making too many requests, if people were typing/editing the URL</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png" width="698" height="260" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ad52337a-56b5-47ed-b354-514fed5db676_698x260.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:260,&quot;width&quot;:698,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:46492,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad52337a-56b5-47ed-b354-514fed5db676_698x260.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>so I just added a delay of ~1 second. Initially it said “loading…”. But this is wrong, it’s not actually loading. The better thing is to just say what is happening (that it’s waiting for you to finish typing)</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif" width="769" height="483" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:483,&quot;width&quot;:769,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:33982,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/gif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7eb76ce7-04aa-4fe1-b18e-d0122eba28fb_769x483.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I think this is important because it just accurately reflects the state of the machine. It’s not dumbing it down, it’s not assuming what info the user needs or doesn’t need. </p><p>Consider what happens in an error case where it’s stuck. It’s more obvious that something is wrong when it’s stuck on “waiting for you to finish typing” than “loading”</p><p>I’m not saying you have to teach everyone everything about your software. That’s too high of a bar (and it is true that often the user doesn’t care, they just want it to work)</p><p>For the “message no longer exists” thing, I think it would have been perfectly fine to say:</p><blockquote><p><span>Error code 1027: file cannot be saved.</span><br><span> </span><br><span>- </span><strong>[Copy contents]</strong><span> </span><br><span>- </span><strong>[Delete file]</strong></p></blockquote><p>what’s happening? why can’t the file be saved? you can google “error code 1027”. If you don’t care, these are your options. </p><p>I think this is better than giving the user a weird/incorrect model about how computers work (that makes it harder for them to reason about this &amp; other systems)</p><p>If I stumble on other examples I’ll share it here. I’d love it if you sent me anything you stumble on or add it in the comments below!</p><ul><li><p><span>This 1980’s TV show </span><a href="https://omarshehata.substack.com/p/my-favorite-1980s-canadian-tv-show" rel="nofollow ugc noopener">“bits and bytes”</a><span> that explains how computers work to people that have never used one before, without dumbing it down</span></p><ul><li><p>in the same episode they explain (1) how to turn the computer on, how to press “enter” to input text into the computer (2) and also, what binary code is</p></li></ul></li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alarms in medical equipment (152 pts)]]></title>
            <link>https://th.id.au/alarms/</link>
            <guid>40611638</guid>
            <pubDate>Fri, 07 Jun 2024 18:45:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://th.id.au/alarms/">https://th.id.au/alarms/</a>, See on <a href="https://news.ycombinator.com/item?id=40611638">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>ISO/IEC 60601-1-8, Patterson and <span>other</span> alarms in medical equipment<br> Sample Alarm Sounds - <a href="https://th.id.au/alarms/sirens.html">Sirens, buzzers and other sounds</a></p>
			<p>This page by Chris Thompson 27 July 2000<br> Comments to <a href="http://www.usyd.edu.au/anaes/cgi/nomail.cgi/8/7/1/">Frank Block</a> or Chris Thompson. </p>
			<p>If this text is too small or too big, try changing the default font sixe in your browser's preferences. </p>
			<p>Clicking on the blue underlined link should play the sound.  Most of the sounds are 8bit 22kHz mono uncompressed files in Windows 'wav' format, however the Patterson sounds are 16bit 44.1kHz files. File size varies between 30 and 250 kB. Time lags when playing sounds may be reduced by downloading the whole sound set as a web archive, then running the page as a local file on your computer. </p>
			<p>1. 60601-1-8 type sounds</p>
			<p>1.1 Urgency encoded</p>
			
			<table>
				<tbody><tr>
					<td><p>Low Alarm</p>
					</td>
					<td><p>Medium Alarm</p>
					</td>
					<td><p>High Alarm*</p>
					</td>
					<td><p>Notes</p>
					</td>
				</tr>
				<tr>
					<td><p>Not specified </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/genmed.wav">C4 C4 C4</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/genhi.wav">C4 C4 C4 - C4 C4 </a></p>
					</td>
					<td><p>Fixed pitch;<br> traditional (usual )9703 sound. </p>
					</td>
				</tr>
			</tbody></table>
			<p><span>1.2 &nbsp;Combined category and urgency encoding</span> (Apendix HHH; Block/Hakkila/Thompson) </p>
			
			<table>
				<tbody><tr>
					<td><p>Category</p>
					</td>
					<td><p>Medium Alarm</p>
					</td>
					<td><p>High Alarm*</p>
					</td>
					<td><p>Notes</p>
					</td>
				</tr>
				<tr>
					<td><p>General </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/genmed.wav">C4 C4 C4</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/genhi.wav">C4 C4 C4 - C4 C4</a> </p>
					</td>
					<td><p>Fixed pitch; complies with JWG standard;<br> traditional (usual )9703 sound. </p>
					</td>
				</tr>
				<tr>
					<td><p>Oxygen </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/oxymed.wav">C5 B4 A4</a><br> OX-Y-GEN </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/oxyhi.wav"><span>C5 B4 A4 - G4 F4</span></a><br> OX-Y-GEN A-LARM </p>
					</td>
					<td><p>Slowly falling pitches, falling pitch of an oximeter;<br> Top of a major scale; </p>
					</td>
				</tr>
				<tr>
					<td><p>Ventilation </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/ventmed.wav"><span>C4 A4 F4</span></a><br> VEN-TI-LATE;<br> RISE AND FALL </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/venthi.wav"><span>C4 A4 F4 - A4 F4</span></a><br> VEN-TI-LA-TI-ON;<br> VEN-TI-LATE A-LARM </p>
					</td>
					<td><p>Old "NBC Chime", rise and fall of the lungs<br> Inverted Major Chord </p>
					</td>
				</tr>
				<tr>
					<td><p>Cardio-vascular </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/cardmed.wav"><span>C4 E4 G4</span></a><br> CAR-DI-AC </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/cardhi.wav"><span>C4 E4 G4 - G4 C5</span></a><br> CAR-DI-AC A-LARM </p>
					</td>
					<td><p>Trumpet Call, Call to arms;<br> Major chord. </p>
					</td>
				</tr>
				<tr>
					<td><p>Temperature or Delivery of Energy </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/tempmed.wav"><span>C4 D4 E4</span></a><br> TEM-P’RA-TURE </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/temphi.wav"><span>C4 D4 E4 - F4 G4</span></a><br> TEM-P’RA-TURE A-LARM </p>
					</td>
					<td><p>Slowly rising pitches; slow increase in temperature<br> Bottom of a major scale. </p>
					</td>
				</tr>
				<tr>
					<td><p>Drug Delivery </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/drugmed.wav"><span>C5 D4 G4</span></a><br> IN-FUS-ION<br> DRUG-OR-FLUID </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/drughi.wav" target="rt"><span>C5 D4 G4 - C5 D4</span></a><br> IN-FUS-ION A-LARM<br> DRUG-OR-FLUID A-LARM </p>
					</td>
					<td><p>Drops of an infusion falling and "splashing" back up Jazz chord inverted 9th </p>
					</td>
				</tr>
				<tr>
					<td><p>Artificial Perfusion </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/perfmed.wav"><span>C4 F#4 C4</span></a><br> PER-FU-SION </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/perfhi.wav"><span>C4 F#4 C4 - C4 F#4</span></a><br> PER-FU-SION A-LARM </p>
					</td>
					<td><p>Artificial sound, "Yo-ee-oh" of the Munchkins in "The Wizard of Oz"; Tri-tone. </p>
					</td>
				</tr>
				<tr>
					<td><p>Power Failure </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/powermed.wav"><span>C5 C4 C4</span></a><br> POW-ER FAIL<br> GO-ING DOWN </p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/powerhi.wav"><span>C5 C4 C4 - C5 C4</span></a><br> POW-ER DOWN A-LARM </p>
					</td>
					<td><p>Falling pitch as when the power has run down on an old Victrola </p>
					</td>
				</tr>
				<tr>
					<td><p>Low alarm<br>Information Available </p>
					</td>
					<td colspan="2"><p><a href="https://th.id.au/alarms/sounds/cd1/genlow.wav">E4 C4</a> (<a href="https://th.id.au/alarms/sounds/cd1/genlow1.wav">slower</a>)<br> IN-FO; MESS-AGE </p>
					</td>
					<td><p>Ding-dong; doorbell or hostess call. </p>
					</td>
				</tr>
				<tr>
					<td colspan="4"><p>* all high alarm bursts comprise the same 5 note pattern played twice, separated by 2 seconds of silence - 10 pulses in all. </p>
					<div><p>Notes:</p><p> 1. The standard permits a wide range of pulse tone. Pulses of a musical nature are permissible but not demonstrated here. Variation in tonality between equipment is acceptable and probably desirable. The above examples were constructed as follows: </p></div>
					<p> 2. All bursts are fully compliant with the requirements of the standard. They were constructed using the following values, with requirements of 60601-1-8 in brackets: </p>
					<p>** Absolute pulse amplitude will depend on your speaker volume. The standard requires amplitude of lower prioirty bursts to not exceed the amplitude of higher priority bursts. My choice of -3dB and -6dB for relative amplitude of medium and low is arbitrary. The first pulse of each burst is 80% of the amplitude of all the other pulses, which are equal in amplitude. The standard permits up to 10dB of pulse amplitude variability from pulse to pulse. Gradually increasing pulse amplitude during a burst may be desirable to reduce intrusiveness and avoid unwanted startle responses (see Patterson's sounds, below). </p>
					<p><span>** The 60601-1-8  requirement for fall time is any time that does not overlap the start of the next pulse. Actual fall times are arbitrary, however longer fall times are associated with lesser perceived urgency. Figures in brackets are possible fall times that meet requirements for these pulses as specified in the standard. </span></p>
					<p>Graphical representations of alarm bursts used in these examples (same time scale): </p>
					<p><img src="https://th.id.au/alarms/Resources/hi1a.gif" width="409" height="66" alt=""><br> (a) high priority </p>
					<p><img src="https://th.id.au/alarms/Resources/med1a.gif" width="95" height="65" alt=""><br> (b) medium priority</p>
					</td>
				</tr>
			</tbody></table>
			<p>2. Patterson Sounds</p>
			<p>The "Patterson" sounds on this site are a demonstration set designed in October 1985 by Roy Patterson and a team from the Applied Psychology Unit from Cambridge in conjunction with the Institute of Sound and Vibration research from Southampton.  This group had designed alarm sounds for the British nuclear and military applications and were pre-eminent in this field at the time.</p>
			<p>Patterson's sounds were designed to illustrate the principles underlying sounds that could be used in a Draft International Starndard for Alarm Sounds that was being developed at the time by ISO TC1 SC3 WG1(aka Working Group 1 of Subcommittee 3 of Technical Committe Three of the International Standards Organisation).  </p>
			<p>The samples here were digised from a stereo tape recording digitised and sent to me by Frank Block.  The <a href="https://th.id.au/alarms/sounds/Patterson%20Alarm%20Tape%20Mono.mp3">entire tape is available here in mono mp3 format (9.4Mb)</a> and here as an <a href="https://th.id.au/alarms/sounds/Patterson%20Alarm%20Tape%20Mono.wav">uncompressed mono wav file (112Mb)</a>. Each individual sound is reproduced below in mono wav format.</p>
			<p>Patterson proposed two basic types of sounds,  general and category-specific.  </p>
			<p>Three forms of the General alarm sounds were provided, on the basis of urgency: <a href="https://th.id.au/alarms/sounds/gen/Advisory.wav">Information Available</a>, <a href="https://th.id.au/alarms/sounds/gen/Caution.wav">Caution</a>, and <a href="https://th.id.au/alarms/sounds/gen/Warning.wav">Emergency</a>.  The Information available sound was intended to be played once only, whereas the Caution sound was to repeat every 30s and the Emergency sound to repeat every 15s until attended to. </p>
			<p>Category-specific sounds were constructed for oxygenation, ventilation, cardiovascular, artificial perfusion, drug administration and temperature.  Each of these unique sounds was provided in Caution and Emergency forms,  to be repeated at the same intervals as the general sound (30s and 15s respectively).</p>
			<p>The underlying principles included, as far as I can tell:</p>
			<ul>
				<li>2 levels of urgency encoding for all sounds (plus a general information sound, making three overall) </li>
				<li>Silent time between bursts so staff can communicate and think without interruption</li>
				<li>Using highly distinctive, tonally complex sounds that couldn't readily be confused with anything else</li>
				<li>The use of psychoacoustic cues to indicate urgency (repetition, louder, faster, more abrupt onset for greater urgency), so that the Emergency form was essentially the same as the Caution form, but repeated twice, louder, faster and more intrusive.</li>
			</ul>
			<p>As indicated on the tape, "These are not the only sounds that satisfy the design principles, nor are they necessarily the best that can be constructed".  </p>
			<p>As it turned out, the "Patterson" sounds on this tape were not endorsed by the group that considered them.  Instead, in 1994 - nine years later! - they released "ISO 9703.2 - Anaesthesia and respiratory care alarm signals Part 2:  Auditory alarm signals".  The '9703' sound set was a simplified version of Patterson's 'general' sound.  It did not make use of any of Patterson's psychoacoustic cues, the underlying sounds were based on simple beeps, there was no 'information' signal, and none of the category-specific sounds were included.  60601-1-8 attempted to improve on 9703.2 by bringing back an information signal, providing advice on how to implement psychoacoustic cues, and defining standard melodies for the 6 categories (plus one more for power-down).</p>
			<p>Frank Block, who sat on all the above committees, is of the opinion that the Patterson sounds were 'genius'.  Here are the sounds:</p>
			<p>2.1 "General" sounds - <span>u</span>rgency encoding alone: </p>
			
			<table>
				<tbody><tr>
					<td><p>Urgency </p>
					</td>
					<td><p>Description and notes </p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/gen/Advisory.wav">Low</a></p>
					</td>
					<td><p>Two pulses, falling pitch </p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/gen/Caution.wav">Medium</a></p>
					</td>
					<td><p>Four pulses, rising pitch , repeated at 30s intervals</p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/gen/Warning.wav">High</a></p>
					</td>
					<td><p>Two identical bursts of 6 pulses each. Each burst comprises the same four notes of the medium alarm (though faster, louder, at higher pitch and with more rapid onset) with two additional 'attention' pulses appended, repeated at 15 s intervals</p>
					</td>
				</tr>
			</tbody></table>
			
			<p><a href="https://th.id.au/alarms/sounds/gen/Warning.wav"><img src="https://th.id.au/alarms/Resources/genhiburst.jpeg" width="677" height="89" alt="GenHiBurst"></a><br>Patterson General High Urgency sound - time vs amplitude model - repeats every 15s - note <span>sharp peak</span> at <span>beginning</span> of  each pulse</p>
			<p><a href="https://th.id.au/alarms/sounds/gen/Caution.wav"><img src="https://th.id.au/alarms/Resources/genmedburst.jpeg" width="169" height="89" alt="GenMedBurst"></a><br>Patterson General <span>Medium</span> Urgency <span>sound - time vs a</span>mplitude model - repeats every 30s - note overall <span>lower amplitude, no peaking at </span></p>
			<p><a href="https://th.id.au/alarms/sounds/gen/Advisory.wav"><img src="https://th.id.au/alarms/Resources/infoburst.jpeg" width="153" height="89" alt="InfoBurst"></a><br>Patterson General Low or Information Available sound - plays once only - note overall low amplitude, gradual rise on each pulse to minimise intrusiveness.</p>
			
			<p>2.2 <span>Category-S</span>pecific sounds (<span>c</span>ombined category and urgency encoding): </p>
			<p>Six categories were defined, each with their own specific sound pattern. Greater urgency is indicated by repeating the same melody twice - and making it louder, at higher pitch, in a faster tempo and with more rapid rise times- just as it is intuitively obvious that "FIRE!,  FIRE!" is of greater ugency than 'fire' or 'hello'. </p>
			
			<table>
				<tbody><tr>
					<td><p>Medium </p>
					</td>
					<td><p>High </p>
					</td>
					<td><p>Pnemonic </p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/CVSCaution.wav">Cardiovascular</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/CVSEmerg.wav">Cardiovascular</a></p>
					</td>
					<td><p>car-di-o-vas-cu-lar</p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/OxygenCaution.wav">Oxygenation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/OxygenationEmerg.wav">Oxygenation</a></p>
					</td>
					<td><p>ox-y-gen</p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/VentCaution.wav">Ventilation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/VentilationEmerg.wav">Ventilation</a></p>
					</td>
					<td><p>ven-ti-late pa-tient</p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/TempCaution.wav">Temperature</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/TempEmerg.wav">Temperature</a></p>
					</td>
					<td><p><span>tem-pera-ture (three times)</span></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/DrugCaution.wav">Drug or Fluid</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/DrugEmerg.wav">Drug or Fluid</a></p>
					</td>
					<td><p>droplets slpashing back?</p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/PerfCaution.wav">Artificial Perfusion</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cat/PerfEmerg.wav">Artificial Perfusion</a></p>
					</td>
					<td><p>art-i-fic-ial per-fu-sion</p>
					</td>
				</tr>
			</tbody></table>
			<p><br>3.  Compromise - "Chris Thompson" - Alarm Sounds</p>
			<p>Distinctive as Patterson's sounds are, succesive IEC committees have not endorsed them.  Mostly this was, I think, because simpler devices would have found it difficult, technically, to generate such complex sounds.  Hence the simpler, more easily generated pulse tones of 9703.2 and 60601-1-8.</p>
			<p>None the less, the underlying psychoacoustic principles advocated by Patterson are, I think, entirely valid, as was the concept of providing unique sounds for the main categories of medical alarms.  </p>
			<p>My greatest reservation with the existing 60601-1-8 melodies is that the high priority melodies are too complex.  Although the high priority sounds are based on the medium priority melodies,  two additional beeps after the base melody confuse the sound greatly, so that each high priority alarm is quite different from its medium priority version. This  means that there are almost 13 different sounds to learn, and they can be too easily confused.  The general rule of thumb is that people can learn 6-8 sounds of similar form.  I very much prefer Patterson's category-specific sound concept, in which the same medium sound is just repeated twice, because once the melody for the medium alarm is known, the high form is basically just the same, and requires  no additional learning.</p>
			<p>So my suggestion is to apply Patterson's concepts to a reduced set of melodies based on ISO 60601-1-8.  I propose having only General (no melody), Cardiac, Oxygen, Ventilation, Drug/Fluid and Power-Down categories, with medium and high forms of each, plus the 60601-1-8 low priority or 'information available' tone.  Time between annunciations and all other characteristics would be as per 60601-1-8.</p>
			<p>This approach reduces the number of melodies to learn to 7 (including general, advisory and power down sounds).  This should avoid confusion and enhance ease of learning, though this is yet to be demonstrated in a clinical trial.  In the table below I  have included a 'very high priority' column to show how speed, rise time and volume can additionally emphasise urgency.  </p>
			
			<table>
				<tbody><tr>
					<td><p>Medium </p>
					</td>
					<td><p>High </p>
					</td>
					<td><p>Very High </p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/genmed.wav">General</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/cd1/genhi.wav">General</a></p>
					</td>
					<td><img src="https://th.id.au/alarms/Resources/_clear.gif" width="1" height="1" alt=""></td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/cardmed.wav">Cardiac</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/cardhi.wav">Cardiac</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/cardvhi.wav">Cardiac</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/oxymed.wav">Oxygenation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/oxyhi.wav">Oxygenation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/oxyvhi.wav">Oxygenation</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/ventmed.wav">Ventilation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/venthi.wav">Ventilation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/ventvhi.wav">Ventilation</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/drugmed.wav">Drug or Fluid</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/drughi.wav">Drug or Fluid</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/drugvhi.wav">Drug or Fluid</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/powermed.wav">Power Down</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/mine/powerhi.wav">Power Down</a></p>
					</td>
					<td><p>na</p>
					</td>
				</tr>
			</tbody></table>
			<p>A significant advantage of this approach is that the high priority alarms are annunciated in much less time than the existing 60601-1-8 high priority sounds.  For example, my 'very high' alarm sound takes only 1.3 seconds to fully annunciate, whereas an equivalent 60601-1-8 high alarm sound takes 4.6 seconds.  In an emergency, when multiple alarms happen at once, brief alarms are less likely to overlap with others, whereas multiple long-duration 60601-1-8 high alarms will result in a cacophany - like 'everyone shouting at once'.</p>
			<p>A trial comparing these was done by myself and Penny Sanderson.  As anticipated, the simpler sounds were easier to learn, and we also found that people with any musical training at all were better at identifying them than people with no musical experience at all.   This work unfortunately went un-published.</p>
			
			<p><span>4</span>.  <span>The "new" Edworthy</span> Alarm Sounds</p>
			<p>Judy  Edworthy has written extensively on alarm sounds. The committee invited, and BSI supported, an effort by her team to produce a new set of sounds for a future edition of 60601-1-18. </p>
			<p>The Edwroty sounds consiste of a 'beeping' tone for urgency, which is optionally mixed with a sound indicating the kind of alarm.  The following table includs draft sounds from 2019</p>
			
			<table>
				<tbody><tr>
					<td><p><span>Low</span>  / Base Sound</p>
					</td>
					<td><p><span>Medium</span> </p>
					</td>
					<td><p>High</p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Low.wav">General</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Medium.wav">General</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/High.wav">General</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Cardiovascular.wav">Cardiac</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Cardiovascular_MP.wav">Cardiac</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Cardiovascular_HP.wav">Cardiac</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Oxygenation.wav">Oxygenation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Oxygenation_MP.wav">Oxygenation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Oxygenation_HP.wav">Oxygenation</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Ventilation.wav">Ventilation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Ventilation_MP.wav">Ventilation</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Ventilation_HP.wav">Ventilation</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Drug_delivery.wav">Drug or Fluid</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Drug_delivery_MP.wav">Drug or Fluid</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Drug_delivery_HP.wav">Drug or Fluid</a></p>
					</td>
				</tr>
				<tr>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Failure.wav">Power Down</a></p>
					</td>
					<td><p><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Failure_MP.wav">Power Down</a></p>
					</td>
					<td><p><span><a href="https://th.id.au/alarms/sounds/J_Edworthy_2019/Failure_HP.wav">Power Down</a></span></p>
					</td>
				</tr>
			</tbody></table>
			<p>Judy's initial studies suggest that these sounds aare easier to categorise than 'melodic' type sounds.</p>
			<p>I'm not sure of the status of this proposal.  The standard allows any sound set that is not worse than the standard sounds.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Machine learning engineers, what do you do at work? (167 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40610794</link>
            <guid>40610794</guid>
            <pubDate>Fri, 07 Jun 2024 17:26:34 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40610794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40615244"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40615244" href="https://news.ycombinator.com/vote?id=40615244&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>Getting my models dunked on by people who can't open MS Outlook more than 3 tries out of 5, however, have a <i>remarkable</i> depth and insight into their chosen domain of expertise. It's rather humbling.</p><p>Collaborating with nontechnical people is oddly my favorite part of doing MLE work right now. It wasn't the case when I did basic web/db stuff. They see me as a magician. I see them as voodoo priests and priestesses. When we get something trained up and forecasting that we both like, it's super fulfilling. I think for both sides.</p><p>Most of my modeling is healthcare related. I tease insights out of a monstrous data lake of claims, Rx, doctor notes, vital signs, diagnostic imagery, etc. What is also monstrous is how accessible this information is. HIPAA my left foot.</p><p>Since you seemed to be asking about the temporal realities, it's about 3 hours of meetings a week, probably another 3 doing task grooming/preparatory stuff, fixing some ETL problem, or doing a one-off query for the business, the rest is swimming around in the data trying to find a slight edge to forecast something that surprised us for a $million or two using our historical snapshots. It's like playing wheres waldo with math. And the waldo scene ends up being about 50TB or so in size. :D</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40611136"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40611136" href="https://news.ycombinator.com/vote?id=40611136&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>The opposite of what you’d think when studying machine learning…</p><p>95% of the job is data cleaning, joining datasets together and feature engineering. 5% is fitting and testing models.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40611570"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40611570" href="https://news.ycombinator.com/vote?id=40611570&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>As somebody whose machine learning expertise consists of the first cohort of Andrew Ng's MOOC back in 2011, I'm not too surprised. One of the big takeaways I took from that experience was the importance of getting the features right.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40613777"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40613777" href="https://news.ycombinator.com/vote?id=40613777&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>&gt;was the importance of getting the features right.</p><p>Yeah, but also <i>knowing</i> which features to get right. Right?</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40612245"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40612245" href="https://news.ycombinator.com/vote?id=40612245&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>As it was in the beginning and now and ever shall be amen</p><p>At the staff/principal level it’s all about maintaining “data impedance” between the product features that rely on inference models and the data capture</p><p>This is to ensure that as the product or features change it doesn’t break the instrumentation and data granularity that feed your data stores and training corpus</p><p>For RL problems however it’s about making sure you have the right variables captured for state and action space tuple and then finding how to adjust the interfaces or environment models for reward feedback</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40611151"><td></td></tr>
                <tr id="40611202"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40611202" href="https://news.ycombinator.com/vote?id=40611202&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>This is a large problem in industry: defining away some of the most important parts of a job or role as (should be) someone else's.</p><p>There is a lot of toil and unnecessary toil in the whole data field, but if you define away all of the "yucky" parts, you might find that all of those "someone elses" will end up eating your lunch.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612137"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40612137" href="https://news.ycombinator.com/vote?id=40612137&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>It's not about "yucky" so much as specialization and only having a limited time in life to learn everything.</p><p>Should your reseacher have to manage nvidia drivers and infiniband networking? Should your operations engineer need to understand the math behind transformers? Does your researcher really gain any value from understanding the intricacies of docker layer caching?</p><p>I've seen what it looks like when a company hires mostly researchers and ignores other expertise, versus what happens when a company hires diverse talent sets to build a cross domain team. The second option works way better.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612316"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40612316" href="https://news.ycombinator.com/vote?id=40612316&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>My answer is yes to both of those</p><p>If other peoples work is reliant on yours then you should know how their part of the system transforms your inputs</p><p>Similarly you should fully understand how all the inputs to your part of the system are generated</p><p>No matter your coupling pattern, if you have more than 1 person product, knowing at least one level above and below your stack is a baseline expectation</p><p>This is true with personnel leadership too, I should be able to troubleshoot one level above and below me to some level of capacity.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40612603"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40612603" href="https://news.ycombinator.com/vote?id=40612603&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>&gt; I've seen what it looks like when a company hires mostly researchers and ignores other expertise, versus what happens when a company hires diverse talent sets to build a cross domain team. The second option works way better.</p><p>I've seen these too, and you aren't wrong. Division into specializations can work "way better" (i.e. the overall potential is higher), but in practice the differentiating factors that matter will come down to organizational and ultimately human-factors. The anecdotal cases I draw my observations from organizations operating at the scale of 1-10 people, as well as 1,000s working in this field.</p><p>&gt; Should your reseacher have to manage nvidia drivers and infiniband networking? Should your operations engineer need to understand the math behind transformers? Does your researcher really gain any value from understanding the intricacies of docker layer caching?</p><p>To realize the higher potential mentioned above, what they need to be doing is appreciating the value of what those things are and those who do those things beyond: these are the people that do the things I don't want to do or don't want to understand. That appreciation usually comes from having done and understanding that work.</p><p>When specializations are used, they tend to also manifest into organizational structures and dynamics which are ultimately comprised of humans. Conway's Law is worth mentioning here because the interfaces between these specializations become the bottleneck of your system in realizing that "higher potential."</p><p>As another commenter mentions, the effectiveness of these interfaces, corresponding bottlenecking effects, and ultimately the entire people-driven system is very much driven by how the parties on each side understand each other's work/methods/priorities/needs/constraints/etc, and having an appreciation for how they affect (i.e. complement) each other and the larger system.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40612076"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40612076" href="https://news.ycombinator.com/vote?id=40612076&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>&gt; There is a lot of toil and unnecessary toil in the whole data field, but if you define away all of the "yucky" parts, you might find that all of those "someone elses" will end up eating your lunch.</p><p>See: the use of "devops" to encapsulate "everything besides feature development"</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40612411"><td></td></tr>
                        <tr id="40611194"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40611194" href="https://news.ycombinator.com/vote?id=40611194&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>pip install pytorch</p><p>Environment broken</p><p>Spend 4 hours fixing python environment</p><p>pip install Pillow</p><p>Something something incorrect cpu architecture for your Macbook</p><p>Spend another 4 hours reinstalling everything from scratch after nuking every single mention of python</p><p>pip install … oh time to go home!</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40613268"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40613268" href="https://news.ycombinator.com/vote?id=40613268&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>As an amateur game engine developer, I morosely reflect my hobby seems to actually consist of endlessly chasing things that were broken by environment updates (OS, libraries, compiler, etc.)  That is, most of the time I sit down to code I actually spend nuking and reinstalling things that (I thought) were previously working.</p><p>Your comment makes me feel a little better that this is not merely some personal failing of focus, but happens in a professional setting too.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40614731"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40614731" href="https://news.ycombinator.com/vote?id=40614731&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>Happens in AAA too but we tend to have teams that shield everyone from that before they get to work. I ran a team like that for a couple years.</p><p>For hobby stuff at home though I don't tend to hit those types of issues because my projects are pretty frozen dependency-wise. Do you really have OS updates break stuff for you often? I'm not sure I recall that happening on a home project in quite a while.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40611909"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40611909" href="https://news.ycombinator.com/vote?id=40611909&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>I thought most ML engineers use their laptops as dumb terminals and just remote into a Linux GPU server.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40614440"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40614440" href="https://news.ycombinator.com/vote?id=40614440&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>Yeah, the workday there looks pretty similar though, except that installing pytorch and pillow is usually no problem.  Today it was flash-attn I spent the afternoon on.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40611312"><td></td></tr>
                <tr id="40611940"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40611940" href="https://news.ycombinator.com/vote?id=40611940&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>&gt; ARM macbook</p><p>Funnily, the only real competitor for Nvidias' GPUs are Macbooks with 128GB of RAM.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40612749"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40612749" href="https://news.ycombinator.com/vote?id=40612749&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>I wish my company would understand this and let us use something else. Luckily, they don't really seem to care that I use my Linux based gaming machine most of the time</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40611546"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40611546" href="https://news.ycombinator.com/vote?id=40611546&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>Can you expand on this a bit? My recent experiences with MLX have been really positive, so I'm curious what footguns you're alluding to here.</p><p>(I don't do most of my work locally, but for smaller models its pretty convenient to work on my mbp).</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40611720"><td></td></tr>
                  <tr id="40611739"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40611739" href="https://news.ycombinator.com/vote?id=40611739&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>Can recommend using conda, more specifically mambaforge/micromamba (no licensing issues when used at work).</p><p>This works way better than pip, as it does more checks/dependency checking, so it does not break as easily as pip, though this makes it definitely way slower when installing something. It also supports updating your environment to the newest versions of all packages.</p><p>It's no silver bullet and mixing it with pip leads to even more breakages, but there is pixi [0] which aims to support interop between pypi and conda packages</p><p>[0] <a href="https://prefix.dev/" rel="nofollow">https://prefix.dev/</a></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612001"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40612001" href="https://news.ycombinator.com/vote?id=40612001&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>I had a bad experience with Conda:</p><p>- If they're so good at dependency management, why is Conda installed through a magical shell script?</p><p>- It's slow as molasses.</p><p>- Choosing between Anaconda/Miniconda...</p><p>When forced to use Python, I prefer Poetry, or just pip with freezing the dependencies.</p><p>The Python people probably can't even imagine how great dependency management is in all the other languages...</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612225"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40612225" href="https://news.ycombinator.com/vote?id=40612225&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>I absolutely hate conda. I had to support a bunch of researchers who all used it and it was a nightmare.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40614559"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40614559" href="https://news.ycombinator.com/vote?id=40614559&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>Yeah, I agree, maybe I should have also mentioned the bad things about it, but after trying many different tools that's the one that I stuck with, as creating/destroying environments is a breeze once you got it working and the only time my environment broke was when I used pip in that environment.</p><p>&gt; The Python people probably can't even imagine how great dependency management is in all the other languages...</p><p>Yep, I wish I could use another language at work.</p><p>&gt; Choosing between Anaconda/Miniconda...</p><p>I went straight with mamba/micromamba as anaconda isn't open source.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40612290"><td></td></tr>
                <tr id="40612459"><td></td></tr>
                              <tr id="40612366"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40612366" href="https://news.ycombinator.com/vote?id=40612366&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>Oh my! This hits home. We have some test scripts written in python. Every time I try to run them after a few months I spend a day fixing the environment, package dependencies and other random stuff. Python is pretty nice once it works, but managing the environment can be a pain.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40614914"><td></td></tr>
            <tr id="40612159"><td></td></tr>
                <tr id="40614450"><td></td></tr>
                  <tr id="40611208"><td></td></tr>
                <tr id="40611429"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40611429" href="https://news.ycombinator.com/vote?id=40611429&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>Legends say there were times when you'd have a program.c file and just run cc program.c, and then could just execute the compiled result. Funny that programmer's job is highly automatable, yet we invent ourselves tons of intermediate layers which we absolutely have to deal with manually.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40611941"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40611941" href="https://news.ycombinator.com/vote?id=40611941&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>And then you'd have to deal with wrong glibc versions or mysterious segfaults or undefined behavior or the the code assuming the wrong arch or ...</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612201"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40612201" href="https://news.ycombinator.com/vote?id=40612201&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>python solves none of those issues. It just adds a myriad of ways those problems can get to you.</p><p>All of a sudden you have people with C problems, who have no idea they're even using compiled dependencies.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612430"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40612430" href="https://news.ycombinator.com/vote?id=40612430&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>In theory you're right, CPython is written in C and it could segfault or display undefined behavior. In practice, you're quite wrong.</p><p>It's not really much of a counterargument to say that Python is good enough that you don't have to care what's under the hood, except when it breaks because C sucks so badly.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612610"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_40612610" href="https://news.ycombinator.com/vote?id=40612610&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>I was specifically talking about python packages using C. You type "pip install" and god knows what's going to happen. It might pull a precompiled wheel, it might just compile and link some C or Fortran code, it might need external dependecies. It might install flawlessly and crash as soon as you try to run it. All bets are off.</p><p>I never experienced CPython itself segfault, it's always due to some package.</p></div></td></tr>
        </tbody></table></td></tr>
                                          <tr id="40611713"><td></td></tr>
                <tr id="40615134"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40615134" href="https://news.ycombinator.com/vote?id=40615134&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>If they are they should stop.</p><p>It causes so many entirely unnecessary issues. The conda developers are directly responsible for maybe a month of my wasted debugging time. At my last job one of our questions for helping debug client library issues was “are you using conda”. And if so we just would say we can’t help you. Luckily it was rare, but if conda was involved it was 100% conda fault somehow, and it was always a stupid decision they made that flew in the face of the rest of the python packaging community.</p><p>Data scientist python issues are often caused by them not taking the 1-3 days it takes to fully understand their tool chain. It’s genuinely quite difficult to fuck up if you take the time once to learn how it all works, where your putbon binaries are on your system etc. Maybe not the case 5 years ago. But today it’s pretty simple.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40611767"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40611767" href="https://news.ycombinator.com/vote?id=40611767&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>A lot do, personally, every single time I try to go back to conda/mamba whatever, I get some extremely weird C/C++ related linking bug - just recently, I ran into an issue where the environment was _almost_ completely isolated from the OS distro's C/C++ build infra, except for LD, which was apparently so old it was missing the vpdpbusd instruction (<a href="https://github.com/google/XNNPACK/issues/6389">https://github.com/google/XNNPACK/issues/6389</a>). Except the thing was, that wouldn't happen when building outside of of the Conda environment. Very confusing. Standard virtualenvs are boring but nearly always work as expected in comparison.</p><p>I'm an Applied Scientist vs. ML Engineer, if that matters.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40614847"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40614847" href="https://news.ycombinator.com/vote?id=40614847&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>It's probably easier to reinstall everything anew from time to time. Instead of fixing broken 18.04 just move to 22.04. Most tools should work, if you don't have huge codebase which requires old compiler...</p><p>Conda.. it interfere with OS setup and has not always the best utils. Like ffmpeg is compiled with limited options, probably due to licensing.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40613965"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40613965" href="https://news.ycombinator.com/vote?id=40613965&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>I've been doing machine learning since the mid 2000s. About half of my time is spent keeping data pipelines running to get data into shape for training and using in models.</p><p>The other half is spent doing tech support for the bunch of recently hired "AI scientists" who can barely code, and who spend their days copy/pasting stuff into various chatbot services. Stuff like telling them how to install python packages and use git. They have no plan for how their work is going to fit into any sort of project we're doing, but assert that transformer models will solve all our data handling problems.</p><p>I'm considering quitting with nothing new lined up until this hype cycle blows over.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40615150"><td></td></tr>
            <tr id="40614942"><td></td></tr>
                  <tr id="40611441"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40611441" href="https://news.ycombinator.com/vote?id=40611441&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>My job title is ML Engineer, but my day to day job is almost pure software engineering.</p><p>I build the systems to support ML systems in production. As others have mentioned, this includes mostly data transformation, model training, and model serving.</p><p>Our job is also to support scientists to do their job, either by building tools or modifying existing systems.</p><p>However, looking outside, I think my company is an outlier. It seems in the industry the expectations for a ML Engineer are more aligned to what a data/applied scientist does (e.g. building and testing models). That introduces a lot of ambiguity into the expectations for each role in each company.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40613397"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40613397" href="https://news.ycombinator.com/vote?id=40613397&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>My company is largely the same. I’m an MLE and partner with data scientists. I don’t train or validate the models. I productionize and instrument the feature engineering pipelines and model deployments. More data engineering and MLOps than anything. I’m in a highly regulated industry so the data scientists have many compliance tasks related to the models and we engineers have our own compliance tasks related to the deployments. I was an MLE at another company in the very same industry before and did everything in the model lifecycle and it was just too much.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40612252"><td></td></tr>
            <tr id="40611682"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40611682" href="https://news.ycombinator.com/vote?id=40611682&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>That's really the kind of job I'd love. Whatever the data is, I don't care. I make sure that the users get the correct data quickly.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40611184"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40611184" href="https://news.ycombinator.com/vote?id=40611184&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>The amount of response may be self explaining.</p><p>Not my main work, but spending a lot of time gluing things together.  Tweaking existing open source. Figuring out how to optimize resources, retraining models on different data sets. Trying to run poorly put together python code. Adding missing requirements files. Cleaning up data. Wondering what could in fact really be useful to solve with ML that hasn't been done years ago already. Browsing the prices of the newest GPUs and calculating whether that would be worth it to get one rather than renting overpriced hours off hosting providers. Reading papers until my head hurt, that is just 1 by 1, by the time I finish the abstract and glanced over a few diagrams in the middle.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40613509"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40613509" href="https://news.ycombinator.com/vote?id=40613509&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>I work on optimizing our inference code, "productizing" our trained models and currently I'm working on local training and inference since I work in an industry where cloud services just aren't very commonly used yet. It's super interesting too since it's not LLMs, meaning that there aren't as many pre made tools and we have to make tons of stuff by ourselves. That means touching anything from assessing data quality (again, the local part is the challenge) to using CUDA directly as we already have signal processing libs that are built around it and that we can leverage.</p><p>Sometimes it also involves building internal tooling for our team (we are a mixed team of researchers/MLEs), to visualize the data and the inferences as again, it's a pretty niche sector and that means having to build that ourselves. That allowed me to have a lot of impact in my org as we basically have complete freedom w.r.t tooling and internal software design, and one of the tools that I built basically on a whim is now on the way to be shipped in our main products too.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40612124"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40612124" href="https://news.ycombinator.com/vote?id=40612124&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>Although I studied machine learning and was originally hired for that role, the company pivoted and is now working with LLMs, so I spend most of my day working on figuring out how different LLMs work, what parameters work best for them, how to do RAG, how to integrate them with other bots.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40612280"><td></td></tr>
                <tr id="40612619"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40612619" href="https://news.ycombinator.com/vote?id=40612619&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>Probably it's because we are not training them anymore and just using with prompts. Seems like more of a swe regular type of job</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40614395"><td></td></tr>
            <tr id="40612388"><td></td></tr>
                        <tr id="40614518"><td></td></tr>
            <tr id="40614521"><td></td></tr>
            <tr id="40611660"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40611660" href="https://news.ycombinator.com/vote?id=40611660&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div><p>In a given week, I usually do the following:</p><p>* 15% of my time in technical discussion meetings or 1:1's. Usually discussing ideas around a model, planning, or ML product support</p><p>* 40% ML development. In the early phase of the project, I'm understanding product requirements. I discuss an ML model or algorithm that might be helpful to achieve product/business goals with my team. Then I gather existing datasets from analysts and data scientists. I use those datasets to create a pipeline that results in a training and validation dataset. While I wait for the train/validation datasets to populate (could take several days or up to two weeks), I'm concurrently working on another project that's earlier or further along in its development. I'm also working on the new model (written in PyTorch), testing it out with small amounts of data to gauge its offline performance, to assess whether or not it does what I expect it to do. I sanity check it by running some manual tests using the model to populate product information. This part is more art than science because without a large scale experiment, I can only really go by the gut feel of myself and my teammates. Once the train/valid datasets have been populated, I train a model on large amounts of data, check the offline results, and tune the model or change the architecture if something doesn't look right. After offline results look decent or good, I then deploy the model to production for an experiment. Concurrently, I may be making changes to the product/infra code to prepare for the test of the new model I've built. I run the experiment and ramp up traffic slowly, and once it's at 1-5% allocation, I let it run for weeks or a month. Meanwhile, I'm observing the results and have put in alerts to monitor all relevant pipelines to ensure that the model is being trained appropriately so that my experiment results aren't altered by unexpected infra/bug/product factors that should be within my control. If the results look as expected and match my initial hypothesis, I then discuss with my team whether or not we should roll it out and if so, we launch! (Note: model development includes feature authoring, dataset preparation, analysis, creating the ML model itself, implementing product/infra code changes)</p><p>* 20% maintenance – Just because I'm developing new models doesn't mean I'm ignoring existing ones. I'm checking in on those daily to make sure they haven't degraded and resulted in unexpected performance in any way. I'm also fixing pipelines and making them more efficient.</p><p>* 15% research papers and skills – With the world of AI/ML moving so fast, I'm continually reading new research papers and testing out new technologies at home to keep up to date. It's fun for me so I don't mind it. I don't view it as a chore to keep me up-to-date.</p><p>* 10% internal research – I use this time to learn more about other products within the team or the company to see how my team can help or what technology/techniques we can borrow from them. I also use this time to write down the insights I've gained as I look back on my past 6 months/1 year of work.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40612080"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40612080" href="https://news.ycombinator.com/vote?id=40612080&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>Pretty much the same as the others, building tool, data cleaning, etc. But something I don't see mentioned: experiment design/ data collection protocols</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40611859"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40611859" href="https://news.ycombinator.com/vote?id=40611859&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>not sure if this counts as ML engineering, but I support all the infra around the ML models: caching, scaling, queues, decision trees, rules engines, etc.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40614181"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40614181" href="https://news.ycombinator.com/vote?id=40614181&amp;how=up&amp;goto=item%3Fid%3D40610794"></a></center>    </td><td><br><div>
                  <p>I've interviewed for a few of the ML positions and turned them down because they were just data jockey positions.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ASCII Silhouettify (405 pts)]]></title>
            <link>https://meatfighter.com/ascii-silhouettify/</link>
            <guid>40610641</guid>
            <pubDate>Fri, 07 Jun 2024 17:10:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://meatfighter.com/ascii-silhouettify/">https://meatfighter.com/ascii-silhouettify/</a>, See on <a href="https://news.ycombinator.com/item?id=40610641">Hacker News</a></p>
<div id="readability-page-1" class="page">
<p><img src="https://meatfighter.com/ascii-silhouettify/images/logo-white.svg" alt="AS"> ASCII Silhouettify</p>

<p id="index">[ <a href="#about" target="_self">About</a> | <a href="#example" target="_self">Example</a> | <a href="#galleries" target="_self">Galleries</a> | <a href="#install" target="_self">Install</a> | <a href="#uninstall" target="_self">Uninstall</a> | <a href="#options" target="_self">Options</a> | <a href="#algorithm" target="_self">Algorithm</a> ]</p>

<h2 id="about"><a href="#about" target="_self">About</a></h2>

<p>ASCII Silhouettify is an app that converts images into ASCII silhouettes, a style of ASCII art distinguished by uniformly filled geometric shapes rather than lines or textures. For input, the app expects flat graphics—visuals with minimalistic, high-contrast forms lacking dimensional depth, such as logos, banners, and pixel art. It cannot handle photographs because it does not render shading, highlights, shadows, or gradients.</p>

<p>ASCII Silhouettify restricts itself to the 95 printable ASCII characters, the medium of traditional ASCII artists, as opposed to the line and block characters prevalent in ANSI art or the copious Unicode characters of kaomoji. However, based on user configuration, the app outputs monochrome plain text, text colored with ANSI escape sequences, HTML with or without color, or Neofetch ASCII art format.</p>

<p>ASCII Silhouettify is a desktop app accessible from a browser and from the command-line.</p>



<h2 id="example"><a href="#example" target="_self">Example</a></h2>

<p>Here is the output of <a href="https://github.com/dylanaraps/neofetch">Neofetch</a> under an instance of Ubuntu:</p>

<p><img id="./images/neofetch-0.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-0.png" alt="Neofetch Ubuntu output">
</p>

<p>For optimal ASCII art, we obtain a high-resolution image of the Ubuntu logo from the web, and we scale it to the size we want it to appear in the console:</p>

<p><img id="./images/neofetch-1.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-1.png" alt="Ubuntu logo">
</p>

<p>We run it through the command-line version of ASCII Silhouettify:</p>

<p><img id="./images/neofetch-2.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-2.png" alt="Ubuntu logo ANSI art">
</p>

<p>By default, ASCII Silhouettify generates text colored with ANSI escape sequences. With the <code>-o</code> flag, we can direct the output to a file that Neofetch will display. But Neofetch inserts a wide margin between ANSI art and the OS metrics. To prevent this, we‘ll use Neofetch‘s <a href="https://github.com/dylanaraps/neofetch/wiki/Custom-Ascii-art-file-format">custom ASCII art file format</a>: </p>

<p><img id="./images/neofetch-4.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-4.png" alt="Generating Neofetch ASCII art file">
</p>

<p>The first line of the output file is a list of color indices. The successive lines contain the encoded image:</p>

<p><img id="./images/neofetch-5.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-5.png" alt="Neofetch ASCII art file">
</p>

<p>In a text editor, we copy the first line to the clipboard, and then we remove it.</p>

<p>We invoke Neofetch with the following command, pasting in the value we stored in the clipboard:</p>

<p><img id="./images/neofetch-3.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-3.png" alt="Neofetch with improved logo">
</p>

<p>Neofetch is a bash script. To make the change permanent, we replace the following part of the script, again using the value we stored in the clipboard.</p>

<p><img id="./images/neofetch-6.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-6.png" alt="Neofetch script segment">
</p>

<p>For comparison, here is the original logo overlaid on the generated result:</p>

<p><img id="./images/neofetch-7.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-7.png" alt="Logos overlaid">
</p>

<p>Note how the algorithm selects the largest characters that fit within the outlines of each colored region.</p>


<h2 id="galleries"><a href="#galleries" target="_self">Galleries</a></h2>

<p>For more examples, click on one of the buttons below.</p>




<h2 id="install"><a href="#install" target="_self">Install</a></h2>

<p>The command-line version of ASCII Silhouettify is a Node.js application. If you don't have Node.js installed on your system, follow the steps described <a href="https://nodejs.org/en/learn/getting-started/how-to-install-nodejs">here</a>.</p>

<p>In the Windows Command Prompt or PowerShell (but not WSL), run:</p>

<div>
    <pre>npm install -g ascii-silhouettify</pre>
    </div>

<p>On macOS and Linux (including WSL), you need to use <code>sudo</code>:</p>

<div>
    <pre>sudo npm install -g ascii-silhouettify</pre>
    </div>


<h2 id="uninstall"><a href="#uninstall" target="_self">Uninstall</a></h2>

<p>In the Windows Command Prompt or PowerShell (but not WSL), run:</p>

<div>
    <pre>npm uninstall -g ascii-silhouettify</pre>
    </div>

<p>On macOS and Linux (including WSL), you need to use <code>sudo</code>:</p>

<div>
    <pre>sudo npm uninstall -g ascii-silhouettify</pre>
    </div>


<h2 id="options"><a href="#options" target="_self">Options</a></h2>

<p>The browser version and the command-line version support the same set of options. In the command-line version, the <code>-h</code> flag outputs a message that summarizes the information below.</p>


<h2 id="options.input"><a href="#options.input" target="_self">Input</a></h2>

<p>ASCII Silhouettify can convert multiple images at the same time. It supports <code>png</code>, <code>svg</code>, <code>jpg</code>, <code>webp</code>, <code>gif</code>, <code>tif</code>, <code>heif</code>, <code>avif</code>, and <code>pdf</code> image formats. The command-line version‘s <code>-i</code> flag accepts various filename pattern-matching rules (see the help message for details). The input images should have black or transparent backgrounds.</p>


<h2 id="options.output"><a href="#options.output" target="_self">Output</a></h2>

<p>ASCII Silhouettify can output plane or ANSI-colored text, monospaced text in HTML format, or Neofetch‘s custom ASCII art format. The latter is limited to six colors of the <span>256-color</span> extended ANSI palette.</p>


<h2 id="options.palette"><a href="#options.palette" target="_self">Palette</a></h2>

<p>By default, ASCII Silhouettify uses a palette of 240 colors from the <span>256-color</span> extended ANSI palette, excluding the <span>16-color</span> standard ANSI palette, as it is often redefined in modern terminal emulators. However, users have the option to select the first 8 colors of the standard ANSI palette, the full <span>16-color</span> standard ANSI palette, the full <span>256-color</span> extended ANSI palette, or stick with the default <span>240-color</span> palette.</p>


<h2 id="options.colors-and-monochrome"><a href="#options.colors-and-monochrome" target="_self">Colors and Monochrome</a></h2>

<p>The user can specify the maximum number of colors to appear in the output, not counting the presumably black background. The default is 255. Monochrome mode effectively sets this to one. For Neofetch‘s custom ASCII art format, it defaults to six, the maximum number of colors supported by that format.</p>


<h2 id="options.font-size-and-line-height"><a href="#options.font-size-and-line-height" target="_self">Font Size and Line Height</a></h2>

<p>When viewed in a terminal emulator, the aspect ratio of the generated ASCII art depends on the font, font size, line height, and the rounding rules for character dimensions. To optimize it, capture an image of text in the terminal, and measure the size of each monospaced character in pixels, including the space between lines:</p>

<p><img id="./images/intellij.png" src="https://meatfighter.com/ascii-silhouettify/images/intellij.png" alt="Intellij terminal">
</p>

<p>Plug the values into the following formulae to determine font size and line height settings.</p>

<p>$\text{font size} = \dfrac{\text{character width}+a}{.78}, a \in [-0.5, 0.5)$</p>

<p>$\text{line height} = \dfrac{.75 (\text{character height} + b)}{\text{font size}}, b \in [-0.5, 0.5) $</p>

<p>Select arbitrary values for $a$ and $b$ within the range $-0.5$ to $0.5$.</p>

<p>Here are some measured character dimensions and suggested settings based on the developer’s Windows desktop:</p>

<div>
    <table>
        <thead>
        <tr>
            <th>Application</th>
            <th>Character Width</th>
            <th>Character Height</th>
            <th>Font Size</th>
            <th>Line Height</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>IntelliJ Terminal</td>
            <td>8</td>
            <td>22</td>
            <td>10</td>
            <td>1.65</td>
        </tr>
        <tr>
            <td>Putty</td>
            <td>8</td>
            <td>16</td>
            <td>10</td>
            <td>1.2</td>
        </tr>
        <tr>
            <td>Notepad</td>
            <td>10</td>
            <td>18</td>
            <td>13</td>
            <td>1.04</td>
        </tr>
        <tr>
            <td>Notepad++</td>
            <td>9</td>
            <td>19</td>
            <td>12</td>
            <td>1.2</td>
        </tr>
        <tr>
            <td>Windows Command Prompt</td>
            <td>8</td>
            <td>16</td>
            <td>10</td>
            <td>1.2</td>
        </tr>
        <tr>
            <td>Windows Console Host</td>
            <td>9</td>
            <td>20</td>
            <td>12</td>
            <td>1.25</td>
        </tr>
        <tr>
            <td>Windows Terminal</td>
            <td>9</td>
            <td>19</td>
            <td>12</td>
            <td>1.2</td>
        </tr>
        </tbody>
    </table>
</div>

<p>Your mileage may vary.</p>


<h2 id="options.scale"><a href="#options.scale" target="_self">Scale</a></h2>

<p>Ideally, the input image file should be scaled in a paint program to the size the user wants it to appear in the terminal. However, for minor tweaks, ASCII Silhouettify accepts an image scaling factor, which defaults to one.</p>


<h2 id="options.darkness"><a href="#options.darkness" target="_self">Darkness</a></h2>

<p>The conversion algorithm replaces areas of the image below 5% brightness with space characters, enabling the presumably black background to fully show through. The user can adjust this threshold as needed.</p>


<h2 id="options.threads"><a href="#options.threads" target="_self">Threads</a></h2>

<p>By default, the conversion algorithm distributes work across all available logical processors. The user can reduce the number of allocated processors to as few as one, though this will result in longer processing times.</p>


<h2 id="algorithm"><a href="#algorithm" target="_self">Algorithm</a></h2>

<p>On the Windows desktop where the developer created ASCII Silhouettify, Terminal renders each monospaced character within a <span>9×19</span> pixel rectangle when configured with the default 12-points, 1.2-em Cascadia Mono font. The developer captured images of the 95 printable ASCII characters and thresholded them at 50% intensity, producing images containing only black and white pixels:</p>

<p><img id="./images/thresholded.png" src="https://meatfighter.com/ascii-silhouettify/images/thresholded.png" alt="Thresholded characters">
</p>

<p>The algorithm separates the source image into unique color planes, each a white silhouette on a black background:</p>

<p><img id="./images/planes.png" src="https://meatfighter.com/ascii-silhouettify/images/planes.png" alt="planes">
</p>

<p>The algorithm partitions each plane into a matrix of <span>9×19</span> pixel rectangular regions, every one of them destined to be replaced by an ASCII character. To select the optimal character, the algorithm compares a region pixel-by-pixel against every ASCII character image. If a white pixel in a character coincides with a black pixel in the region, the algorithm excludes the character to avoid distorting the silhouette's outline. Of the remaining characters, the algorithm selects the one with the maximum number of matching white pixels.</p>

<p>When the algorithm replaces a region with an ASCII character, it records the number of matching white pixels. After converting all planes, the algorithm combines them by selecting the characters with the highest number of matching white pixels. Finally, it colors those characters based on the colors of the planes from which they originated.</p>

<p>Prior to converting a source image, the algorithm sorts the ASCII character images by the number of white pixels. As shown below, the space character contains the fewest white pixels (zero), while the at sign contains the most.</p>

<p><img id="./images/sorted.png" src="https://meatfighter.com/ascii-silhouettify/images/sorted.png" alt="Sorted characters">
</p>

<p>The algorithm compares each region with the ASCII character images, starting with the at sign and moving downward. As soon as it finds a character that fully fits within the silhouette, the algorithm replaces the region with it because that character contains the greatest number of white pixels.</p>

<p>To significantly speed up the process, the algorithm prepares <span>171 bitmasks</span>, one for each pixel of the <span>9×19</span> pixel rectangular regions. Each bitmask represents the set of ASCII characters images with a black pixel at the coordinates that uniquely identifies the bitmask.</p>

<p>Specifically, each bitmask contains <span>95 bits</span>, where each bit corresponds to an ASCII character image ordered by the number of white pixels: <span>bit-0</span> represents the space character, and <span>bit-94</span> represents the at sign. The algorithm clears all bits in all bitmasks. Then, for each black pixel in each ASCII character image, the algorithm sets the bit corresponding to the character in the bitmask associated with the pixel.</p>

<p>During region conversion, the algorithm maintains a <span>95-bit</span> accumulator that represents a narrowing set of ASCII characters it can use for the replacement. When it begins to convert a region, the algorithm initializes the accumulator to all ones, indicating all characters are initially considered. Then, for each black pixel in the region, the algorithm updates the accumulator to the current accumulator value bitwise ANDed with the bitmask corresponding to the pixel. That operation excludes all ASCII character images with a white pixel at a location where a black pixel exists in the region.</p>

<p>After the algorithm repeats that process across the region, the accumulator‘s set bits represent the remaining characters that can replace the region. Since the characters are ordered, the number of leading zeros in the accumulator is the index of the ASCII character image with the greatest number of white pixels fully contained within the plane‘s silhouette. With the help of a library, the algorithm invokes a microprocessor instruction for <a href="https://en.wikipedia.org/wiki/Find_first_set">counting leading zeros</a> to obtain the value it needs rapidly.</p>

<p>When the algorithm partitions the source image into a matrix of rectangular regions, the origin of the matrix affects the outcome. To optimize the result, the algorithm repeats the entire image conversion for all integer-coordinate origins within a <span>9×19</span> pixel area around the image origin. It then returns the best result found. To manage the extensive processing required, the algorithm distributes the work among the available logical processors.</p>

<p>Based on user configuration, the algorithm limits itself to a palette that ranges from just the first eight colors of the standard ANSI palette to the full <span>256-color</span> extended ANSI palette. To separate the source image into unique color planes, the algorithm employs the computationally expensive <a href="http://www.brucelindbloom.com/index.html?Eqn_DeltaE_CIE2000.html">CIEDE2000</a> perceptual color difference formula to find the closest colors within the palette.</p>

<p>The source is available from the following repositories:</p>

<ul>
    <li><a href="https://github.com/meatfighter/ascii-silhouettify">Command-line version</a></li>
    <li><a href="https://github.com/meatfighter/quasar-ascii-silhouettify">Browser version</a></li>
</ul>

<hr>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenSSH introduces options to penalize undesirable behavior (347 pts)]]></title>
            <link>https://undeadly.org/cgi?action=article;sid=20240607042157</link>
            <guid>40610621</guid>
            <pubDate>Fri, 07 Jun 2024 17:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://undeadly.org/cgi?action=article;sid=20240607042157">https://undeadly.org/cgi?action=article;sid=20240607042157</a>, See on <a href="https://news.ycombinator.com/item?id=40610621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="http://bsdly.blogspot.com/">Peter N. M. Hansteen</a>
on <time datetime="2024-06-06T17:54:01Z">2024-06-06</time>
from the sshd to carry a big stick dept.</p><p>
In a recent <a href="https://marc.info/?l=openbsd-cvs&amp;m=171769392207688&amp;w=2">commit</a>, Damien Miller (<code>djm@</code>) introduced the new <a href="https://man.openbsd.org/sshd">sshd(8)</a> configurations options, <code><a href="https://man.openbsd.org/sshd_config.5#PerSourcePenalties">PerSourcePenalties</a></code> and <code><a href="https://man.openbsd.org/sshd_config.5#PerSourcePenaltyExemptList">PerSourcePenaltyExemptList</a></code>, to provide a built in facility in <a href="https://man.openbsd.org/sshd">sshd(8)</a> itself to penalize undesirable behavior, and to shield specific clients from penalty, respectively. 
</p><p>
The commit message reads,
</p><blockquote><pre>List:       openbsd-cvs
Subject:    CVS: cvs.openbsd.org: src
From:       Damien Miller &lt;djm () cvs ! openbsd ! org&gt;
Date:       2024-06-06 17:15:26

CVSROOT:	/cvs
Module name:	src
Changes by:	djm@cvs.openbsd.org	2024/06/06 11:15:26

Modified files:
	usr.bin/ssh    : misc.c misc.h monitor.c monitor_wrap.c 
	                 servconf.c servconf.h srclimit.c srclimit.h 
	                 sshd-session.c sshd.c sshd_config.5 

Log message:
Add a facility to <a href="https://man.openbsd.org/sshd">sshd(8)</a> to penalise particular problematic client
behaviours, controlled by two new <a href="https://man.openbsd.org/sshd_config">sshd_config(5)</a> options:
<a href="https://man.openbsd.org/sshd_config#PerSourcePenalties">PerSourcePenalties</a> and <a href="https://man.openbsd.org/sshd_config#PerSourcePenaltyExemptList">PerSourcePenaltyExemptList</a>.
</pre></blockquote>

<blockquote><pre>When PerSourcePenalties are enabled, <a href="https://man.openbsd.org/sshd">sshd(8)</a> will monitor the exit
status of its child pre-auth session processes. Through the exit
status, it can observe situations where the session did not
authenticate as expected. These conditions include when the client
repeatedly attempted authentication unsucessfully (possibly indicating
an attack against one or more accounts, <abbr>e.g.</abbr> password guessing), or
when client behaviour caused sshd to crash (possibly indicating
attempts to exploit sshd).

When such a condition is observed, sshd will record a penalty of some
duration (<abbr>e.g.</abbr> 30 seconds) against the client's address. If this time
is above a minimum threshold specified by the PerSourcePenalties, then
connections from the client address will be refused (along with any
others in the same <a href="https://man.openbsd.org/sshd_config.5#PerSourceNetBlockSize">PerSourceNetBlockSize</a> <abbr>CIDR</abbr> range).

Repeated offenses by the same client address will accrue greater
penalties, up to a configurable maximum. A <a href="https://man.openbsd.org/sshd_config.5#PerSourcePenaltyExemptList">PerSourcePenaltyExemptList</a>
option allows certain address ranges to be exempt from all penalties.

We hope these options will make it significantly more difficult for
attackers to find accounts with weak/guessable passwords or exploit
bugs in sshd(8) itself.

PerSourcePenalties is off by default, but we expect to enable it
automatically in the near future.

much feedback markus@ and others, ok markus@
</pre></blockquote><p>
This new facility comes in addition to the already well known and loved  <a href="https://man.openbsd.org/pf.conf#Stateful_Tracking_Options"><code>pf.conf</code> <em>state tracking options</em></a>, and is for now available only in <a href="https://www.openbsd.org/">OpenBSD</a>-<code>current</code>, but is almost certainly to be available in the upcoming OpenBSD <em>7.6</em> release.
</p><p>
At first we were wondering whether these options would be enabled by default before the new release. We did not have to wait long. This <a href="https://marc.info/?l=openbsd-cvs&amp;m=171770534714766&amp;w=2">subsequent commit</a> settled the issue:
</p><blockquote><pre>List:       openbsd-cvs
Subject:    CVS: cvs.openbsd.org: src
From:       Damien Miller &lt;djm () cvs ! openbsd ! org&gt;
Date:       2024-06-06 20:25:48

CVSROOT:	/cvs
Module name:	src
Changes by:	djm@cvs.openbsd.org	2024/06/06 14:25:48

Modified files:
	usr.bin/ssh    : servconf.c 

Log message:
enable PerSourcePenalties by default.

ok markus

<abbr>NB.</abbr> if you run a sshd that accepts connections from behind large NAT
blocks, proxies or anything else that aggregates many possible users
behind few <abbr>IP</abbr> addresses, then this change may cause legitimate traffic
to be denied.

Please read the PerSourcePenalties, PerSourcePenaltyExemptList and
PerSourceNetBlockSize options in sshd_config(5) for how to tune your
sshd(8) for your specific circumstances.
</pre></blockquote><p>
So now we know: starting with OpenBSD 7.6, <code>PerSourcePenalties</code> will be enabled by default, and admins who do not themselves run <abbr>PF</abbr> or other network translation mechanisms will need to keep the consequences of inconsiderate <abbr>NAT</abbr> use in mind.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Will Switch Off Recall by Default After Security Backlash (520 pts)]]></title>
            <link>https://www.wired.com/story/microsoft-recall-off-default-security-concerns/</link>
            <guid>40610435</guid>
            <pubDate>Fri, 07 Jun 2024 16:47:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/microsoft-recall-off-default-security-concerns/">https://www.wired.com/story/microsoft-recall-off-default-security-concerns/</a>, See on <a href="https://news.ycombinator.com/item?id=40610435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>When Microsoft named <a href="https://www.wired.com/story/everything-announced-microsoft-surface-event-2024/">its new Windows feature Recall</a>, the company intended the word to refer to a kind of perfect, AI-enabled memory for your device. Today, the other, unintended definition of “recall”—a company's admission that a product is too dangerous or defective to be left on the market in its current form—seems more appropriate.</p><p>On Friday, Microsoft announced that it would be making multiple dramatic changes to its rollout of its Recall feature, making it an opt-in feature in the Copilot+ compatible versions of Windows where it had previously been turned on by default, and introducing new security measures designed to better keep data encrypted and require authentication to access Recall's stored data.</p><p>“We are updating the set-up experience of Copilot+ PCs to give people a clearer choice to opt-in to saving snapshots using Recall,” reads a <a data-offer-url="https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/&quot;}" href="https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/" rel="nofollow noopener" target="_blank">blog post</a> from Pavan Davuluri Microsoft's Corporate Vice President, Windows + Devices. “If you don’t proactively choose to turn it on, it will be off by default.”</p><p>The changes come amidst a mounting barrage of criticism from the security and privacy community, which has described Recall—which silently stores a screenshot of the user's activity every 5 seconds as fodder for AI analysis—as a gift to hackers: essentially unrequested, pre-installed spyware built into new Windows computers.</p><p>In the preview versions of Recall, that screenshot data, complete with the user's every bank login, password, and porn site visit would have been indefinitely collected on the user's machine by default. And though that highly sensitive is stored locally on the user's machine and not uploaded to the cloud, cybersecurity experts have warned that it all remains accessible to any hacker who so much as gains a temporary foothold on a user's Recall-enabled device, giving them a longterm panopticon view of the victim's digital life.</p><p>"It makes your security very fragile,” as Dave Aitel, a former NSA hacker and founder of security firm Immunity, described it—more charitably than some others—to WIRED earlier this week. “Anyone who penetrates your computer for even a second can get your whole history. Which is not something people want.”</p><p>For Microsoft, the Recall rollback comes in the midst of an embarrassing string of cybersecurity incidents and breaches—including a <a href="https://arstechnica.com/information-technology/2022/10/microsoft-under-fire-for-response-to-leak-of-2-4tb-of-sensitive-customer-data/">leak of terabytes of its customers' data</a> and a <a href="https://www.wired.com/story/microsoft-cloud-attack-china-hackers/">shocking</a> <a href="https://www.wired.com/story/microsoft-cloud-attack-china-hackers/">penetration of government email accounts</a> enabled by a <a href="https://www.wired.com/story/china-backed-hackers-steal-microsofts-signing-key-post-mortem/">cascading series of Microsoft security slipups</a>—that have grown so problematic as to become a sticking point even its <a href="https://www.wired.com/story/the-us-government-has-a-microsoft-problem/">uniquely close relationship with the US government</a>.</p><p>Those scandals have escalated to the degree that Microsoft's Nadella issued a memo just last month declaring that Microsoft would make security its first priority in any business decision. “If you’re faced with the tradeoff between security and another priority, your answer is clear: <strong>Do security</strong>,” Nadella's <a href="https://www.theverge.com/24148033/satya-nadella-microsoft-security-memo">memo read</a> (emphasis his). “In some cases, this will mean prioritizing security above other things we do, such as releasing new features or providing ongoing support for legacy systems.”</p><p>By all appearances, Microsoft's rollout of Recall—even after today's announcement—displays the opposite approach, and one that seems more in line with business as usual in Redmond: Announce a feature, get pummeled for its glaring security failures, then belatedly scramble to control the damage.</p><p><em>This is a developing story. Check back for further updates.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing memory safe JIT compilers (140 pts)]]></title>
            <link>https://medium.com/graalvm/writing-truly-memory-safe-jit-compilers-f79ad44558dd</link>
            <guid>40609968</guid>
            <pubDate>Fri, 07 Jun 2024 16:07:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/graalvm/writing-truly-memory-safe-jit-compilers-f79ad44558dd">https://medium.com/graalvm/writing-truly-memory-safe-jit-compilers-f79ad44558dd</a>, See on <a href="https://news.ycombinator.com/item?id=40609968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="3b9e">How to kill off a top source of browser exploits</h2><div><a rel="noopener follow" href="https://medium.com/@octskyward?source=post_page-----f79ad44558dd--------------------------------"><div aria-hidden="false"><p><img alt="Mike Hearn" src="https://miro.medium.com/v2/resize:fill:88:88/0*vCXpXuEWOU7lPZ5C.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://medium.com/graalvm?source=post_page-----f79ad44558dd--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="graalvm" src="https://miro.medium.com/v2/resize:fill:48:48/1*SfTfqmGwGBoQx-FkoCq_Bw.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div></div><figure></figure><p id="fd3b"><span>L</span>ast month the V8 team published an excellent blog post on what they call <a href="https://v8.dev/blog/sandbox" rel="noopener ugc nofollow" target="_blank">the V8 Sandbox</a>. This isn’t a sandbox for your JavaScript code — it’s intended to mitigate browser exploits caused by bugs in the JIT compiler itself. That’s important work because they report that most Chrome exploits start with a V8 memory safety bug.</p><p id="d5cb">V8 is written in C++, so it may seem like these are the sort of bugs you’d expect from working in a memory-unsafe language. Unfortunately the situation is more complex. Why? The team explain:</p><blockquote><p id="2e39">There is a catch: V8 vulnerabilities are rarely “classic” memory corruption bugs (use-after-frees, out-of-bounds accesses, etc.) but instead subtle logic issues which can in turn be exploited to corrupt memory. As such, existing memory safety solutions are, for the most part, not applicable to V8. In particular, neither <a href="https://www.cisa.gov/resources-tools/resources/case-memory-safe-roadmaps" rel="noopener ugc nofollow" target="_blank">switching to a memory safe language</a>, such as Rust, nor using current or future hardware memory safety features, such as <a href="https://newsroom.arm.com/memory-safety-arm-memory-tagging-extension" rel="noopener ugc nofollow" target="_blank">memory tagging</a>, can help with the security challenges faced by V8 today.</p></blockquote><p id="db9f">They give an example bug that can cause memory corruption without the engine itself containing any normal memory safety problems, as VM intrinsics or JIT compiled machine code itself may accidentally rely on invalid assumptions about memory.</p><p id="c9d0">It would be nice if there was a rigorous approach to writing language runtimes that eliminated such bugs by design.</p></div><div><p id="4d0d"><span>G</span>raalVM has a JavaScript engine called <a href="https://www.graalvm.org/javascript/" rel="noopener ugc nofollow" target="_blank">GraalJS</a>. It’s written in Java using the <a href="https://www.graalvm.org/latest/graalvm-as-a-platform/language-implementation-framework/" rel="noopener ugc nofollow" target="_blank">Truffle language framework</a>. Its peak performance is competitive with V8 and on a few benchmarks (such as ray tracing) is actually faster!</p><p id="5480">Although being written in Java does improve memory safety, we just saw that rewriting V8 in a safe language wouldn’t help with the types of bugs V8 is trying to solve and so we would intuitively expect that GraalJS must suffer from the same classes of bugs. Yet, it doesn’t. Let’s take a look at why not. Along the way we’ll explore the <em>first Futamura projection, </em>the core theoretical idea underpinning Truffle.</p><p id="f80c">All fast language VMs work the same way. A program is loaded from disk into in-memory data structures representing the program, either an abstract syntax tree or byte code. The program starts running in an interpreter. Parts are soon discovered to be <em>hot spots</em>, i.e. the program spends much more time there than in other parts. Those hot spots are passed to a just-in-time compiler that converts them to optimized machine code, and execution then jumps back and forth between the interpreter and the collection of compiled program fragments. This gives a big performance boost.</p><p id="b183">This architecture is standard — both the JVM and V8 use it — but viewed from a security perspective the design has a flaw: it’s error prone. The language semantics are implemented twice, once for the interpreter and again for the JIT compiler. It’s critical not only that both places are fully correct but also that they exactly match. Otherwise, the VM becomes exploitable.</p><p id="bb2b">Truffle is a Java library that helps you build advanced, high performance language runtimes. VMs built using the Truffle framework operate in a fundamentally different way to conventional VMs, one that not only makes them much easier to write but which also eliminates memory safety bugs by design. It all starts with you writing an interpreter for your language in Java. This doesn’t mean compiling your <em>target</em> language to JVM bytecode — in fact bytecode won’t feature anywhere in this story. You just write an ordinary interpreter. Because the interpreter’s code is garbage collected and bounds-checked, malicious user code can’t use memory safety bugs to exploit it.</p><p id="e75d">If you think about conventional Java then this may sound quite slow — isn’t Java itself interpreted until it gets JIT compiled? Are we … interpreting an interpreter? Fortunately not because you can ship your Truffle-based language runtime as a <a href="https://www.graalvm.org/latest/reference-manual/native-image/" rel="noopener ugc nofollow" target="_blank">native executable</a>, meaning it’s compiled ahead of time to fully native code using the Graal compiler (from which the wider umbrella project takes its name).</p><p id="db2f">So at the start of the user’s program their JavaScript is running in a regular interpreter shipped as a normal executable binary or DLL, but which still benefits from the safety properties of a Java program. Soon some methods get hot. At this point something unconventional happens. The Truffle framework is keeping track of which functions are hot for you and will decide to schedule JIT compilations. But unlike in a conventional VM design, you <em>don’t </em>write your own JIT compiler. Instead your user’s code is automatically compiled by the same general-purpose Graal compiler that was used to convert your interpreter to native code, and execution will start automatically switching back and forth between the interpreter and compiled functions. This is possible thanks to an unusual technique called partial evaluation (or <em>the first Futamura projection</em>).</p></div><div><figure><figcaption>Professor Yoshihiko Futamura</figcaption></figure><p id="6fac"><span>Y</span>ou might not have encountered Futamura projections or partial evaluation before, so what is this strange sounding thing?</p><p id="d771">The core idea is to automatically transform the code of your interpreter to create individual JIT compiled user methods. Instead of needing to carefully implement the language semantics in two places (interpreter and hand-crafted JIT), it’s sufficient to implement it just once. As the interpreter is memory safe and the transform preserves interpreter semantics, the compiled version of the user’s code is guaranteed to match the interpreter’s behavior and is therefore <em>also</em> automatically memory safe. This makes it much harder to slip up and write an exploitable VM.</p><p id="cc46">There are several tricks that make this possible. The most important is a new form of constant-ness, added to Java using annotations. In normal programming a variable is either mutable or immutable. An immutable variable is marked with a special keyword such as<code>final</code> or <code>const</code> and must be set only once, at the declaration site. Constants are great for compilers because they can be folded, meaning that references to them can be replaced with their value. Consider the following bit of code:</p><pre><span id="5805">class Example {<br>    private static final int A = 1;<br>    private static final int B = 2;<p>    static int answer() {<br>        return A - B;<br>    }</p><p>    static String doSomething() {<br>        if (answer() &lt; 0) <br>            return "OK" <br>        else <br>            throw new IllegalStateException();<br>    }<br>}</p></span></pre><p id="f9a9">It’s easy to see the <code>answer()</code> method will always return the same number. A good compiler will substitute 1 and 2 into the expression yielding <code>return 1 — 2</code> and pre-compute the answer. Then it will inline any calls to answer (i.e. copy/paste the implementation into the call site), substituting those with -1 and thus removing the call overhead as well. That in turn may trigger even more constant folding, such as in the <code>doSomething</code> method where the compiler will prove that the exception can never be thrown and delete it entirely. Having done that, <code>doSomething</code> can <em>also</em> be optimized out by simply replacing it with “OK”, and so on.</p><p id="15f8">That’s neat, but every compiler can do that … as long as the constant values are known at compile time. Truffle changes that by introducing a third kind of const-ness called <em>compilation final</em>. If in your interpreter implementation you declare a variable like this:</p><pre><span id="784c">@CompilationFinal private int a = 1;</span></pre><p id="5472">then it will change its const-ness depending on when it’s being accessed. From inside your interpreter, it’s mutable. You will use such variables to implement your interpreter. They’ll be set when you load your user’s program and maybe also whilst it runs. Once a function in the user’s script becomes hot, Truffle will work together with the Graal compiler to <em>re</em>compile the parts of the interpreter corresponding to the user’s code, and this time <code>a</code>will be treated as if it was a constant, i.e. the same as the literal value <code>1</code>.</p><p id="0761">This works for any kind of data, including complex objects. Consider the following highly simplified pseudocode:</p><pre><span id="774f">import com.oracle.truffle.api.nodes.Node;<p>class JavaScriptFunction extends Node {<br>    @CompilationFinal Node[] statements;</p><p>    Object execute() {<br>        for (var statement : statements) statement.execute();<br>    } <br>}</p></span></pre><p id="3703">This is the sort of class you might find in a typical abstract syntax tree interpreter. The <code>statements</code> array is marked compilation-final. When the program is first loaded we can initialize the array with objects representing the different things a user’s JavaScript function is doing, because it’s mutable. Now imagine that the function represented by this object gets hot. Truffle will start a special compilation of the <code>execute()</code> method in which Graal is told that the <code>this</code> pointer should be treated implicitly as compilation-final. Because the object is treated as constant, so can <code>this.statements</code> also be treated as constant. It’ll be substituted with the exact contents of a specific <code>JavaScriptFunction</code> object on the interpreter heap enabling the compiler to unroll the loop inside <code>execute</code>, transforming it to look like this:</p><pre><span id="d429">Object execute() {<br>    this.statements[0].execute();<br>    this.statements[1].execute();<br>    this.statements[2].execute();<br>}</span></pre><p id="f034">Here <code>Node</code> is a superclass and <code>execute()</code> is virtual, but that doesn’t matter. Because the list is compilation-final the individual objects in the list are also constant folded, so the <code>execute</code> method can be de-virtualized (resolved to whatever concrete type it really is) and then inlined as well.</p><p id="e75a">And on and on we go. At the end the compiler generates a native function which matches the semantics of the user’s JavaScript (or Python or C++ or whatever language we’re implementing). Invocations of the specific <code>JavaScriptFunction.execute()</code> method that were compiled are diverted, so when the interpreter invokes it, there will be a transition from interpreter to native code and back. If your interpreter realizes it needs to change a <code>@CompilationFinal</code> field, for example because the program changes its behavior and invalidates an optimistic assumption you made, that's absolutely fine. Truffle will let you do that and "deoptimizes" the program back to the interpreter for you. Deoptimization (<a href="https://www.youtube.com/watch?v=pksRrON5XfU&amp;t=3259s" rel="noopener ugc nofollow" target="_blank">tech talk</a>) is an advanced technique that's normally very hard to implement securely, as it means mapping the optimized CPU state back to the interpreter state and once again, any mistakes can be exploitable (you may be seeing a theme here). But you don’t have to write any of this. It’s all done for you by Truffle.</p></div><div><h2 id="6f34">Why does this work?</h2><p id="c000">It might not be obvious why partial evaluation actually makes things faster.</p><p id="9751">Interpreters are slow because they have to make a lot of decisions. The user’s program could do anything, so interpreters must constantly check for many possibilities to find out what the program is trying to do at that exact moment. Because branches and memory loads are difficult for the CPU to execute quickly, the whole program ends up being slow. This technique of compiling an interpreter with enhanced constant folding eliminates branches and loads. On top of this, Truffle builds an API that makes it easy to implement advanced optimizations and features for JavaScript or indeed, for <a href="https://www.graalvm.org/latest/graalvm-as-a-platform/language-implementation-framework/Languages/" rel="noopener ugc nofollow" target="_blank">any other language</a> you have an interpreter for. For example, it offers a simple API for using <em>assumptions</em> — a way to JIT compile code that executes faster by not including code for handling edge cases. If such an edge case is hit then the compiled code can be thrown away and regenerated to take into account that the edge case was observed.</p></div><div><h2 id="5f8b">Recompilation</h2><p id="8533">Above we briefly mentioned “recompilation”, but glossed over how that’s possible. We said the interpreter is just native code, right?</p><p id="4ba0">When the interpreter was compiled ahead of time with the <code>native-image</code> in preparation for shipping to the user’s computer, the Graal compiler recognized that it was compiling a Truffle-using program. Graal and Truffle are co-developed, so although they can be used independently, when used together they recognize each other and collaborate.</p><p id="2f52">Graal changes its behavior in a couple of ways when it notices it’s compiling a Truffle language ahead-of-time. Firstly, it adds a copy of itself to the output program. Interpreter methods are then discovered by doing a static analysis of the program and then stored in the resulting executable, but with a twist: they’re stored more than once. One version is directly executable machine code. That’s your regular generic interpreter. Another is a carefully encoded form of Graal’s <em>intermediate representation</em> (or IR). An IR is sort of half way between the source code you write and the machine code that eventually executes (Graal’s IR is an object graph). Graal also compiles in a garbage collector, either the advanced and mature G1 collector (if you use Oracle GraalVM) or <a href="https://github.com/oracle/graal/tree/master/substratevm/src/com.oracle.svm.core.genscavenge/src/com/oracle/svm/core/genscavenge" rel="noopener ugc nofollow" target="_blank">a simpler GC written in pure Java</a> (if you use the GraalVM Community Edition).</p><p id="3ee0">When a user function gets hot, Truffle looks up the embedded IR for the “execute a user function” node and partially evaluates it. The evaluation is interleaved with the parsing of the graph IR to ensure that the process is as efficient as possible — if something won’t be executed because constant folding already proved it can’t be reached it won’t even be decoded or seen by the compiler. This also ensures that memory usage during the compile is kept low.</p><h2 id="6857">My only friend, the end</h2><p id="f25d">And that’s it! That’s how an entire class of subtle safety bugs is eliminated in GraalJS: because the semantics of the language are defined by the memory-safe interpreter and then partially evaluated, the generated machine code is also memory safe by construction.</p><p id="cf91">What about the V8 sandbox that the original blog post is about? Expressing pointers as offsets from a heap base is <a rel="noopener" href="https://medium.com/graalvm/isolates-and-compressed-references-more-flexible-and-efficient-memory-management-for-graalvm-a044cc50b67e">a great idea that’s already used in GraalVM natively compiled binaries</a>. However this is done for performance, as the other memory safety mechanisms mean there’s no need for mitigating heap overwrites.</p><p id="b893">None of the above is in any way specific to JavaScript, and nor are Truffle’s benefits limited to security and performance. In fact Truffle automatically adds <a href="https://www.graalvm.org/latest/graalvm-as-a-platform/language-implementation-framework/" rel="noopener ugc nofollow" target="_blank">many other features to your language</a>, such as debugging (through Chrome Debugger’s wire protocol), language interop with both Java/Kotlin/etc and any other Truffle language, a fast regular expression engine, a fast foreign function interface, profiling tools, heap snapshotting and much more. Truffle has been used to build <a href="https://www.graalvm.org/latest/graalvm-as-a-platform/language-implementation-framework/Languages/" rel="noopener ugc nofollow" target="_blank">over 30 language VMs for dozens of languages</a>, including languages you wouldn’t expect to have such features such as the recent <a href="https://pkl-lang.org/index.html" rel="noopener ugc nofollow" target="_blank">Pkl configuration language from Apple</a>.</p><p id="a8d2">If this article has whetted your appetite to learn more, take a look at <a href="https://www.graalvm.org/latest/graalvm-as-a-platform/language-implementation-framework/" rel="noopener ugc nofollow" target="_blank">the documentation</a> or this <a href="https://www.youtube.com/watch?v=pksRrON5XfU" rel="noopener ugc nofollow" target="_blank">tech talk</a> on how it all works.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[270GB of source code from The New York Times leaked to 4Chan (107 pts)]]></title>
            <link>https://twitter.com/vxunderground/status/1798856571931263480</link>
            <guid>40609922</guid>
            <pubDate>Fri, 07 Jun 2024 16:02:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/vxunderground/status/1798856571931263480">https://twitter.com/vxunderground/status/1798856571931263480</a>, See on <a href="https://news.ycombinator.com/item?id=40609922">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LedgerStore Supports Trillions of Indexes at Uber (105 pts)]]></title>
            <link>https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/?uclick_id=67d612cb-12f8-470a-98fd-e9f7144dfafb</link>
            <guid>40609326</guid>
            <pubDate>Fri, 07 Jun 2024 14:55:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/?uclick_id=67d612cb-12f8-470a-98fd-e9f7144dfafb">https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/?uclick_id=67d612cb-12f8-470a-98fd-e9f7144dfafb</a>, See on <a href="https://news.ycombinator.com/item?id=40609326">Hacker News</a></p>
Couldn't get https://www.uber.com/blog/how-ledgerstore-supports-trillions-of-indexes/?uclick_id=67d612cb-12f8-470a-98fd-e9f7144dfafb: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[Recovery after HP tech support bricked my father's laptop (114 pts)]]></title>
            <link>https://github.com/ctag/hp_envy_reviver</link>
            <guid>40609126</guid>
            <pubDate>Fri, 07 Jun 2024 14:33:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ctag/hp_envy_reviver">https://github.com/ctag/hp_envy_reviver</a>, See on <a href="https://news.ycombinator.com/item?id=40609126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">BIOS Recovery on HP Envy 17"</h2><a id="user-content-bios-recovery-on-hp-envy-17" aria-label="Permalink: BIOS Recovery on HP Envy 17&quot;" href="#bios-recovery-on-hp-envy-17"></a></p>
<p dir="auto">Not a polished product. These are tools and notes generated while re-programming the BIOS memory chip in an HP Envy-ae110nr laptop.</p>
<p dir="auto">It is my hope that by posting my troubleshooting process here I will help those who own a HP laptop to fix it themselves, and those who don't to save the hassle and avoid buying one in the first place.</p>
<div data-snippet-clipboard-copy-content="+--------------------+------------------------------------------------------------+
|       Folder       |                        Description                         |
+--------------------+------------------------------------------------------------+
| extracted_firmware | Dumped binaries from SPI chip                              |
| host_pc            | C++ software that interfaces with STM32                    |
| images             | Images in readme                                           |
| recovery_usb_files | Files created by sp133161.exe and copied off the USB drive |
| resources          | Datasheets and schematics used                             |
| stm32              | Embedded firmware that interacts with BIOS chip            |
+--------------------+------------------------------------------------------------+"><pre><code>+--------------------+------------------------------------------------------------+
|       Folder       |                        Description                         |
+--------------------+------------------------------------------------------------+
| extracted_firmware | Dumped binaries from SPI chip                              |
| host_pc            | C++ software that interfaces with STM32                    |
| images             | Images in readme                                           |
| recovery_usb_files | Files created by sp133161.exe and copied off the USB drive |
| resources          | Datasheets and schematics used                             |
| stm32              | Embedded firmware that interacts with BIOS chip            |
+--------------------+------------------------------------------------------------+
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scenario</h2><a id="user-content-scenario" aria-label="Permalink: Scenario" href="#scenario"></a></p>
<p dir="auto">Several months ago my father's new laptop started having issues with the trackpad sensitivity. He called HP's tech support and was informed that they could not help him troubleshoot the problem at hand until he had updated the BIOS. The tech stepped him through downloading and running the BIOS update tool, and when the computer was rebooted my dad found that HP had indeed upgraded him from a laptop to a brick.</p>
<p dir="auto">For whatever reason the BIOS upgrade failed, and without warning the laptop was left in a near completely inert state. The power button would light up when pressed and the system fan would spin up to maximum. That was it. No backlight, no blinking caps lock, no beeps.</p>
<p dir="auto">After a few attempts at re-doing the BIOS flash, or booting with the <em>special hotkeys</em>, or using a <a href="https://support.hp.com/in-en/document/ish_3932413-2337994-16#:~:text=Turn%20off%20the%20computer.,release%20the%20Windows%20%2B%20V%20keys." rel="nofollow">recovery USB drive</a>, the tech gave up and referred dad to the expensive warranty he had purchased along with the laptop. So the computer was packed up and mailed off for repair.</p>
<p dir="auto">Eventually HP got back in touch, and alongside a picture of the laptop's (existing) upgraded RAM was a message stating that the laptop's condition was the consumer's fault for changing the RAM and thus the warranty was void. HP wanted $500 to downgrade the RAM back to stock before they would continue troubleshooting.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/hp_warranty_renege.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/hp_warranty_renege.png" alt=""></a></p>
<p dir="auto">As we've already established, the laptop's failure was not due to the 3rd party RAM, which had been cranking along perfectly for months. Under the <a href="http://uscode.house.gov/view.xhtml?req=granuleid%3AUSC-prelim-title15-chapter50&amp;edition=prelim" rel="nofollow">Magnuson-Moss Warranty Act</a> it is illegal for HP to renege on their warranty <em>unless the reason for warranty work is demonstrably due to the consumer's changes</em>. Which is a higher burden of proof than a picture of RAM. See also "Tie in Sales Provisions" on <a href="https://www.ftc.gov/tips-advice/business-center/guidance/businesspersons-guide-federal-warranty-law" rel="nofollow">ftc.gov</a>. But I am not a lawyer and I sure can't afford one, so Hewlett-Packard will continue to harm consumers with impunity.</p>
<p dir="auto">The laptop was returned un-repaired, and it sat unused for several months. Until this past weekend, when I decided it couldn't get any more bricked and asked to borrow it to continue troubleshooting.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Locating the BIOS chip</h2><a id="user-content-locating-the-bios-chip" aria-label="Permalink: Locating the BIOS chip" href="#locating-the-bios-chip"></a></p>
<p dir="auto">A quick search online led me to <a href="http://schematic-x.blogspot.com/2018/04/hp-schematics-pack.html" rel="nofollow">schematic-x.blogspot.com</a> which had two PDFs claiming to be schematics for "HP Envy 17." I <a href="https://github.com/ctag/hp_envy_reviver/blob/main/resources/HP_ENVY_17.pdf">downloaded one</a> and thumbed through until I found the BIOS on page 34:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/pdf_bios_ic.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/pdf_bios_ic.png" alt="View of the BIOS chip for a similar laptop motherboard."></a></p>
<p dir="auto">The IC listed there is a MX25L8005M2C-15G. There isn't one of those on this laptop, but the schematic shows that the BIOS is a SPI device, and there is a MX25L6473F SPI flash chip right next to the CPU:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/bios_chip_initial.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/bios_chip_initial.jpg" alt=""></a></p>
<p dir="auto">Searching for that second part number brings up some hits that <a href="https://www.win-raid.com/t4287f16-GUIDE-The-Beginners-Guide-to-Using-a-CH-A-SPI-Programmer-Flasher-With-Pictures-11.html" rel="nofollow">include "BIOS" in them</a>. That's promising, and it makes me suspect that this schematic is for a slightly different motherboard also sold as "Envy 17".</p>
<p dir="auto">I look at any other likely candidate chips and search their part numbers as well. I'm not sure if this MX25L6473F is the BIOS chip or not, but it seems to be the best bet.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Test fixture</h2><a id="user-content-test-fixture" aria-label="Permalink: Test fixture" href="#test-fixture"></a></p>
<p dir="auto">There's a chance this process would have been much easier if I'd had a Bus Pirate and SOP8 adapter to clip onto the IC while it was still on the motherboard. FYI.</p>
<p dir="auto">Since I don't have a way of clipping onto the IC I decide to remove it from the motherboard rather than try soldering flying wires to the pins while it's attached.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/bios_chip_removed.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/bios_chip_removed.jpg" alt=""></a></p>
<p dir="auto">From the datasheet I know this part runs at 3 volts, which should be compatible with an STM32F103 dev board I have laying around.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_1.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_1.jpg" alt=""></a></p>
<p dir="auto">I start by folding some jumper wires and soldering them to the 6 pins I need for SPI.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_2.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_2.jpg" alt=""></a></p>
<p dir="auto">Then those wires are brought up to the STM32 dev board.</p>
<div data-snippet-clipboard-copy-content="+---------------+---------------+
| SOP8 BIOS Pin |   STM32 Pin   |
+---------------+---------------+
|             1 | PA4           |
|             2 | PA6           |
|             3 | Not Connected |
|             4 | GND           |
|             5 | PA7           |
|             6 | PA5           |
|             7 | Not Connected |
|             8 | VCC           |
+---------------+---------------+"><pre><code>+---------------+---------------+
| SOP8 BIOS Pin |   STM32 Pin   |
+---------------+---------------+
|             1 | PA4           |
|             2 | PA6           |
|             3 | Not Connected |
|             4 | GND           |
|             5 | PA7           |
|             6 | PA5           |
|             7 | Not Connected |
|             8 | VCC           |
+---------------+---------------+
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_3.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_3.jpg" alt=""></a></p>
<p dir="auto">Finally the ST-Link is connected via SWD to the dev board, and a serial (FTDI) adapter is added. Eventually I switched out the FTDI adapter for a virtual CDC serial port on the STM's integrated micro-USB.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_4.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_4.jpg" alt=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Extracting the firmware</h2><a id="user-content-extracting-the-firmware" aria-label="Permalink: Extracting the firmware" href="#extracting-the-firmware"></a></p>
<p dir="auto">This step wasn't strictly necessary, but I want to gain familiarity with communicating to the SPI device before attempting a write, and I want the ability to read back out new firmware to confirm it was written correctly.</p>
<p dir="auto">The first step was to read the RDID and status registers, saving the contents to a variable and inspecting in my debugger. Along the way I learned that the STM32's chip-select function isn't great, and pivoted to <a href="https://stackoverflow.com/a/35790106" rel="nofollow">manually toggling the line as a GPIO</a>. Once that was working I added in serial output and expanded the STM32 code to begin transferring all of the flash memory contents on boot. The SPI code was cribbed from this <a href="https://www.digikey.com/en/maker/projects/getting-started-with-stm32-how-to-use-spi/09eab3dfe74c4d0391aaaa99b0a8ee17" rel="nofollow">digikey source file</a>.</p>
<p dir="auto">If the STM32 only programs successfully the first time (SWD wasn't configured):
<a href="https://www.reddit.com/r/embedded/comments/kz5ar4/error_in_initializing_stlink_device_found_on/gjorccv/" rel="nofollow">https://www.reddit.com/r/embedded/comments/kz5ar4/error_in_initializing_stlink_device_found_on/gjorccv/</a></p>
<p dir="auto">SPI reference for STM32:
<a href="https://www.digikey.com/en/maker/projects/getting-started-with-stm32-how-to-use-spi/09eab3dfe74c4d0391aaaa99b0a8ee17" rel="nofollow">https://www.digikey.com/en/maker/projects/getting-started-with-stm32-how-to-use-spi/09eab3dfe74c4d0391aaaa99b0a8ee17</a></p>
<p dir="auto">The first several attempts at dumping the chip contents used either gnu-screen or <a href="https://askubuntu.com/questions/347340/how-to-dump-raw-serial-data-to-disk" rel="nofollow">stty</a>:</p>
<p dir="auto"><code>screen /dev/ttyUSB0 115200 &gt; output.bin</code></p>
<p dir="auto"><code>(stty raw; cat &gt; output.bin) &lt; /dev/ttyUSB0</code></p>
<p dir="auto">But I kept getting files that either didn't finish, or didn't match. I wasn't sure what was happening, but suspected either a buffer was being overrun or the FTDI serial adapter's connection was loose. See <code>extracted_firmware/dump_{01-05}.bin</code>.</p>
<p dir="auto">Reluctantly I started working on the C++ program in <code>host_pc/</code>, and eventually also modified the stm32 firmware to <a href="https://controllerstech.com/send-and-receive-data-to-pc-without-uart-stm32-usb-com/" rel="nofollow">use the USB port</a> instead of a serial adapter.</p>
<p dir="auto">Resource used for configuring the serial port in C++: <a href="https://blog.mbedded.ninja/programming/operating-systems/linux/linux-serial-ports-using-c-cpp/" rel="nofollow">https://blog.mbedded.ninja/programming/operating-systems/linux/linux-serial-ports-using-c-cpp/</a>.</p>
<p dir="auto">Eventually I grew tired of hunting the source of these file differences, and wanted to know conclusively what was on that BIOS chip. So I set up the host and STM32 software to read a single byte at a time and save it to a file. This would have taken more than a day on the serial adapter, but I found that if the baud rate wasn't set manually in the C++ program it defaults to either a very high baud or possibly even the USB full speed (12MHz) that the virtual STM32 CDC device runs at, bringing the time down to only around one hour. The first full firmware was dump_11.bin which matched stty-based dump_03.bin.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Locating a new BIOS binary</h2><a id="user-content-locating-a-new-bios-binary" aria-label="Permalink: Locating a new BIOS binary" href="#locating-a-new-bios-binary"></a></p>
<p dir="auto">Now that I had the old, supposedly corrupted BIOS file the next step would be to find a complete file to flash. I extracted the <a href="https://github.com/ctag/hp_envy_reviver/blob/main/resources/sp133161.exe">sp133161.exe</a> file as though it were a .zip archive, and went browsing through the resulting files. For a while it looked like the easy-to-use binary file wouldn't be had, since the HP tool only included some .efi and .s12 files, which sounds to me like the firmware is signed.</p>
<p dir="auto">Eventually I recalled back to that recovery USB drive, and made a new one to copy the files off of. Inside (<code>recovery_usb_files/HP/BIOS/Current</code>) I found 083AD.bin and 0834D.bin. I'm not sure what the difference is, but I was able to match an instance of "083AD" ascii in the extracted firmware to the 083AD.bin file, which was as close to a conclusive match as I felt I would get.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/bios_083AD_search.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/bios_083AD_search.png" alt=""></a></p>
<p dir="auto">xxd was valuable in comparing the files with vimdiff:</p>
<p dir="auto"><code>xxd 083AD.bin &gt;083AD.hex</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Flashing new BIOS</h2><a id="user-content-flashing-new-bios" aria-label="Permalink: Flashing new BIOS" href="#flashing-new-bios"></a></p>
<p dir="auto">My first inclination for flashing the new binary file would be to bundle it with the STM32 firmware. That way no host_pc-serial issues could corrupt the transfer. Unfortunately the STM32 I have is too small to package the whole file, so I had to backtrack to sending the file from the C++ host_pc program.</p>
<p dir="auto">Bundling binary file for C:
<a href="https://web.archive.org/web/20140313121651/http://www.burtonini.com/blog/computers/ld-blobs-2007-07-13-15-50" rel="nofollow">https://web.archive.org/web/20140313121651/http://www.burtonini.com/blog/computers/ld-blobs-2007-07-13-15-50</a></p>
<p dir="auto">Building for the STM32:</p>
<p dir="auto"><code>arm-none-eabi-ld -r -b binary -o 083AD.o 083AD.bin</code></p>
<p dir="auto">Including that file in STM32cubeIDE:</p>
<p dir="auto">Right click the project -&gt; Properties -&gt; C/C++ Build -&gt; Settings -&gt; Tool Settings tab -&gt; MCU GCC Linker -&gt; Miscellaneous -&gt; Additional object files. Add the path to the arm linked 083AD.o file there.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/stm32cubeide_linker.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/stm32cubeide_linker.png" alt=""></a></p>
<p dir="auto">After that approach was blocked by the microcontroller's flash storage space, the object file was re-built with regular ld and included in the host_pc program.</p>
<p dir="auto">After a few failed attempts to write a page-at-a-time to the STM32, I once again fell back on byte-by-byte with ack bytes being sent back. This time the entire file was written and read back out intact.</p>
<p dir="auto">MD5 sums:</p>
<div data-snippet-clipboard-copy-content="746d2097365c29ba0a2e90d04f627b4b  083AD.bin
746d2097365c29ba0a2e90d04f627b4b  dump_16_0x1_full_post_write_083AD.bin"><pre><code>746d2097365c29ba0a2e90d04f627b4b  083AD.bin
746d2097365c29ba0a2e90d04f627b4b  dump_16_0x1_full_post_write_083AD.bin
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Conclusion</h2><a id="user-content-conclusion" aria-label="Permalink: Conclusion" href="#conclusion"></a></p>
<p dir="auto">Once I was happy with the successful programming of the chip, it was removed from the test fixture and put back in the laptop.</p>
<p dir="auto">On first boot... Nothing happened. In fact, it took several boots, and possibly removing the hard drive (which we had also tried prior to all of this) before I finally saw the backlight flicker. The system then rebooted on its own, and the HP logo appeared along with a message complaining that the CMOS BIOS settings had been lost. After that everything appeared to work.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/diag_test.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/diag_test.jpg" alt=""></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Σ-GPTs: A New Approach to Autoregressive Models (266 pts)]]></title>
            <link>https://arxiv.org/abs/2404.09562</link>
            <guid>40608413</guid>
            <pubDate>Fri, 07 Jun 2024 13:12:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2404.09562">https://arxiv.org/abs/2404.09562</a>, See on <a href="https://news.ycombinator.com/item?id=40608413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2404.09562">View PDF</a>
    <a href="https://arxiv.org/html/2404.09562v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Autoregressive models, such as the GPT family, use a fixed order, usually left-to-right, to generate sequences. However, this is not a necessity. In this paper, we challenge this assumption and show that by simply adding a positional encoding for the output, this order can be modulated on-the-fly per-sample which offers key advantageous properties. It allows for the sampling of and conditioning on arbitrary subsets of tokens, and it also allows sampling in one shot multiple tokens dynamically according to a rejection strategy, leading to a sub-linear number of model evaluations. We evaluate our method across various domains, including language modeling, path-solving, and aircraft vertical rate prediction, decreasing the number of steps required for generation by an order of magnitude.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Arnaud Pannatier [<a href="https://arxiv.org/show-email/979ad75a/2404.09562">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 15 Apr 2024 08:22:47 UTC (1,389 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Instruction Sets Should Be Free: The Case for RISC-V [pdf] (2014) (146 pts)]]></title>
            <link>https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf</link>
            <guid>40608373</guid>
            <pubDate>Fri, 07 Jun 2024 13:06:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf">https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40608373">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Tom 7: Badness 0 (Three ways) (303 pts)]]></title>
            <link>http://tom7.org/bovex/</link>
            <guid>40608332</guid>
            <pubDate>Fri, 07 Jun 2024 13:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://tom7.org/bovex/">http://tom7.org/bovex/</a>, See on <a href="https://news.ycombinator.com/item?id=40608332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
<p>
  Badness 0 (Three ways)
</p>

<p>Ways <b>one</b> and <b>two</b>: Read <b><a href="http://tom7.org/bovex/badness-0-knuth.pdf">Knuth's Version</a></b> nand <b><a href="http://tom7.org/bovex/badness-0-epsom.pdf">Epsom's Version</a></b>.
They appear in the extremely discerning proceedings of <b><a href="http://sigbovik.org/2024/">SIGBOVIK 2024</a></b>. Be warned that due to <b>"BUG"</b>, these seem only to display properly in Chrome. I am working on fixing <b>"BUG"</b> once I get some sleep; I have some leads due to helpful people on the <a href="http://radar.spacebar.org/f/a/weblog/comment/1/1228">blog</a>. The laundered version in the SIGBOVIK proceedings may work.

</p><p>Way <b>three</b> (recommended) is to sit back and bathe in the 4k, 60Hz flashing lights that are <b><a href="https://youtu.be/Y65FRxE7uMc">Badness 0 (Apostrophe‛s version)</a></b> is the newest installment in the Main Sequence:

<iframe width="853" height="480" src="https://www.youtube.com/embed/Y65FRxE7uMc" frameborder="0" allowfullscreen=""></iframe>

</p><p>If you want to experience <b>"BUG"</b> directly, way four is to immediately head to 
  <b><a href="https://sourceforge.net/p/tom7misc/svn/HEAD/tree/trunk/rephrase/">the source code</a></b>. I will try to add some notes on compiling and using this after getting some sleep. The source code is available under the GPL (<a href="http://tom7.org/bovex/COPYING">COPYING</a>) or GJPL (<a href="http://tom7.org/bovex/JCOPYING">JCOPYING</a>).

</p><div><p>Of course, there are multiple irksome videos on my YouTube channel
<a href="https://youtube.com/suckerpinch">Suckerpinch</a>!

<img src="http://tom7.org/bovex/thumbnail.png" alt="screenshot for thumbnails"></p></div><p>Please leave a comment <a href="http://radar.spacebar.org/">on my blog</a> or on Mastodon at <a href="https://mastodon.social/@tom7">@tom7</a>!
</p><p>Get all Tom 7 thingos at → [<a href="http://tom7.org/">tom7.org</a>]</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Does GPT-4o Encode Images? (290 pts)]]></title>
            <link>https://www.oranlooney.com/post/gpt-cnn/</link>
            <guid>40608269</guid>
            <pubDate>Fri, 07 Jun 2024 12:54:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oranlooney.com/post/gpt-cnn/">https://www.oranlooney.com/post/gpt-cnn/</a>, See on <a href="https://news.ycombinator.com/item?id=40608269">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <img src="https://www.oranlooney.com/post/gpt-cnn_files/lead.jpg">
      
      
      
      <hr>
      <ul>
        
        <li><time>June 5, 2024</time></li>
        <li>
          <a href="https://www.oranlooney.com/tags/machine-learning/">
            <i></i>
            Machine Learning
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/llm/">
            <i></i>
            LLM
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/cnn/">
            <i></i>
            CNN
          </a>&nbsp;
        </li>
      </ul>
      

      

<p>Here’s a <a href="https://openai.com/api/pricing/">fact</a>: GPT-4o charges 170 tokens to process each <code>512x512</code> tile
used in high-res mode. At ~0.75 tokens/word, this suggests a picture is worth
about 227 words—only a factor of four off from the traditional saying.</p>

<p>(There’s also an 85 tokens charge for a low-res ‘master thumbnail’ of each picture
and higher resolution images are broken into many such <code>512x512</code> tiles,
but let’s just focus on a single high-res tile.)</p>

<p>OK, but <em>why</em> 170? It’s an oddly specific number, isn’t it? OpenAI uses round
numbers like “\$20” or “\$0.50” in their pricing, or powers of 2 and 3 for their
internal dimensions. Why choose a numbers like 170 in this instance?</p>

<p>Numbers that are just dropped into a codebase without explanation are called
“<a href="https://en.wikipedia.org/wiki/Magic_number_(programming)">magic numbers</a>” in programming, and 170 is a pretty glaring magic
number.</p>

<p>And why are image costs even being converted to token counts anyway? If it were
just for billing purposes, wouldn’t it be less confusing to simply list the
cost per tile?</p>

<p>What if OpenAI chose 170, not as part of some arcane pricing strategy, but
simply because it’s literally true? What if image tiles are in fact represented
as 170 consecutive embedding vectors? And if so, how?</p>

<h2 id="embeddings">Embeddings</h2>

<p>The first thing to recall about the transformer model is that it operates on
vectors, not discrete tokens. The inputs <em>have</em> to be vectors, or the dot
product similarity at the heart of the transformer wouldn’t make any sense. The
whole concept of tokens is a pre-processing step: text is converted to tokens
and tokens are converted to embedding vectors by an embedding model before they
even hit the first layer of the transformer model.</p>

<p>For example, Llama 3 uses 4,096 feature dimensions internally. Consider the
sentence, “My very educated mother just served us nine pizzas.” It gets
converted into 10 integer tokens (counting the period) by <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding">BPE</a>, then
those are each converted into 4,096-dimensional vectors by an embedding model,
resulting in a <code>10x4096</code> matrix. That’s the “real” input into a transformer
model.</p>

<p>But there’s no law that says that these vectors <strong>must</strong> come from a text embedding
model. It’s a strategy that works well for text data, but if we have data in a
different format that we want to feed into a transformer then we can simply use
a different embedding strategy.</p>

<p>We know that OpenAI has been thinking along these lines because in 2021 they
released the <a href="https://openai.com/index/clip/">CLIP embedding model</a>. CLIP embeds both text and images
into the same semantic vector space, allowing you to use cosine similarity to
find images related to text strings, or images which are semantically similar
to other images. You can try the <a href="https://huggingface.co/spaces/vivien/clip">demo</a> on hugging face to get a feel for
how it works:</p>

<p><a href="https://huggingface.co/spaces/vivien/clip"><img src="https://www.oranlooney.com/post/gpt-cnn_files/clip_demo.png"></a></p>

<p>However, CLIP embeds the entire image as a single vector, not 170 of them.
GPT-4o must be using a different, more advanced strategy internally to
represent images (and likewise video, voice, and other kinds of data; that’s
why it’s “omnimodal.”)</p>

<p>Let’s see if we can’t deduce what that strategy might be for image data in
particular.</p>

<h2 id="number-of-feature-dimensions">Number of Feature Dimensions</h2>

<p>Let’s start by guesstimating the number of dimensions used internally by GPT-4o
to represent embedding vectors. We can’t know the real number for certain
because it’s proprietary, but we can make some reasonable assumptions.</p>

<p>OpenAI seems to likes powers of 2, sometimes with a single factor of 3 mixed
in. For example, they used 1,536 for <a href="https://openai.com/index/new-and-improved-embedding-model/">ada-002</a> embeddings or 3,072 for
<a href="https://platform.openai.com/docs/guides/embeddings/embedding-models">text-embedding-3-large</a>. GPT-3 is known to use <a href="https://dugas.ch/artificial_curiosity/GPT_architecture.html">12,288 dimensions
throughout</a>. It’s probable that GPT-4o either kept or increased that
parameter.</p>

<p>It doesn’t seem likely that the number of embeddings would have gone down from
GPT-3 to GPT-4o, but it’s possible. Releases like GPT-4 Turbo were actually
faster and cheaper than earlier version, and a reduction in embedding dimension
may have been part of that if the developers had benchmarks showing that the
smaller size was just as good in terms of quality.</p>

<blockquote>
<p>“Interest rates may go up, they may go down, or they may stay the same. I’m
sorry, but I really can’t be any more vague than that.”
—Alan Greenspan</p>
</blockquote>

<p>Given all that, it’s likely that the number of feature dimensions used inside
of GPT-4o is one of these:</p>

<div>
    <table>
        <thead>
            <tr>
                <th>Dimension</th>
                <th>Prime Factors</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>$1{,}536$</td>
                <td>$3 \cdot 2^9$</td>
            </tr>
            <tr>
                <td>$2{,}048$</td>
                <td>$2^{11}$</td>
            </tr>
            <tr>
                <td>$3{,}072$</td>
                <td>$3 \cdot 2^{10}$</td>
            </tr>
            <tr>
                <td>$4{,}096$</td>
                <td>$2^{12}$</td>
            </tr>
            <tr>
                <td>$12{,}228$</td>
                <td>$3 \cdot 2^{12}$</td>
            </tr>
            <tr>
                <td>$16{,}384$</td>
                <td>$2^{14}$</td>
            </tr>
            <tr>
                <td>$24{,}576$</td>
                <td>$3 \cdot 2^{13}$</td>
            </tr>
        </tbody>
    </table>
</div>

<p>For the sake of argument, I’ll assume that GPT-4o is using 12,228 for the
dimension of its embedding vectors. It doesn’t really matter if we’re off by a
factor of 2 or 4; the same arguments will work.</p>

<h2 id="embedding-images">Embedding Images</h2>

<p>Image tiles are square, so are likely represented by a square grid of tokens.
170 is very close to $13 \times 13$. The extra token could a single embedding vector
which encodes a kind of gestalt impression of the entire image, exactly as
CLIP does (and similar to their strategy of using an 85 token “master
thumbnail” for each image.)</p>

<p>So, the question is, how do we go from <code>512x512x3</code> to <code>13x13x12228</code>?</p>

<h3 id="strategy-1-raw-pixels">Strategy 1: Raw Pixels</h3>

<p>Here’s an extremely simple way to stuff an image into a vector space:</p>

<ol>
<li>Divide the <code>512x512</code> image into a <code>8x8</code> grid of “mini-tiles.”</li>
<li>Each mini-tile is <code>64x64x3</code>; flatten it a vector of dimension 12,228.</li>
<li>Each mini-tile is a single embedding vector.</li>
<li>The entire image tile is represented as 64 consecutive embedding vectors.</li>
</ol>

<p>There are two problems with this approach:</p>

<ol>
<li>64 ≠ 170, and</li>
<li>it’s extremely stupid.</li>
</ol>

<p>By “extremely stupid” I mean that it doesn’t make any sense to embed using raw
RGB values and then just cross your fingers and hope the transformer will sort it out.
Transformers aren’t really designed to handle the spatial structure of 2D images,
especially not when it’s embedded in such a braindead way as this.</p>

<p>To see why, imagine the image is shifted a few pixel to the left. The dot
product between the embedding vectors of the original and shifted images would
immediately drop close to zero. The same would happen if we resize the image.</p>

<p>Ideally we’d want a model that was robust to these kinds of transforms—we’d
like it to have translational and scale invariance, to use the technical jargon.</p>

<h3 id="strategy-2-cnn">Strategy 2: CNN</h3>

<p>Luckily, there already exists a model with those characteristics, with over a
decade-long track record of successfully handling image data: the
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a>. (Here, I’m using the term to describe the
broad family of deep learning models which use convolution layers somewhere
inside them.)</p>

<p>Just to get a sense of what the options are, let’s take look at a classic CNN
architecture introduced in 2012, <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/alexnet.png"></p>

<p>The basic building blocks are:</p>

<ol>
<li>Convolution Layer. These scan over an image in $k \times k$ sized blocks,
training a small neural network.</li>
<li>Max Pool Layer. These also look at $k \times k$ block, but simply take the
maximum value from each.</li>
</ol>

<p>You should spot two key trends as we move into the deeper layers of the
network: the height and width get smaller, while the number of “channels”
(sometimes called “filters”) gets larger. That means we’re incrementally
digesting many low-level features into fewer high level concepts until, at the
very end, AlexNet has turned the entire image into a single categorical concept
representing something like a “cat” or “dog.” CNNs are essentially funnels that
squeeze the lemons of raw pixels into the lemonade of semantic vectors.</p>

<p>If you’re following my somewhat strained analogy, you should see how a CNN can
turn an image into a single embedding vector. To see how (and why) a CNN can
turn an image into many embedding vectors, let’s take a look at a slightly
newer (circa 2018) CNN architecture, one that’s a little closer in spirit to
what we’ll need for GPT-4o. It’s called <a href="https://arxiv.org/abs/1804.02767">YOLO</a>, short for “You Only Look
Once.”</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/yolo_v3.png"></p>

<p>Here, the notation “xN” means that the entire block is repeated N times. YOLOv3
is 10 times as deep as AlexNet but is still very similar in some regards. It
has a somewhat more modern design: stride 2 convolutional layers instead
of max pooling layers to reduce dimensionality, residual layers to
preserve good gradients in very deep networks, etc.</p>

<p>But the key difference is that it doesn’t reduce the image to a single flat
vector, but stops at <code>13x13</code>. There are no fully connected layers after that;
the output of YOLOv3 is in fact 169 different vectors, laid out in a <code>13x13</code>
grid, each of dimension 1,024, and each representing the class (and some
bounding box data we’ll ignore) of the object found in or near a particular
cell of the grid. This means that YOLO doesn’t see just one object in the
image—it can see many in a single pass. That’s why it’s said to “only
look once.”</p>

<p>These examples give us a rough sense of what GPT-4o’s (hypothetical) image
embedding CNN might be shaped like. All we have to do now is play a little game
of connect the dots: how do we go from <code>512x512x3</code> to <code>13x13x12228</code> using
standard CNN layers?</p>

<p>The moves in this game are the standard building blocks we’ve seen in the
above CNN architectures. We can choose the layer types and play around with
hyperparameters like kernel size, stride length, padding strategy, etc. Note
that we ignore things like residual layers, repeated blocks, batch/layer normalization,
or <code>1x1</code> convolutional layers as these don’t affect the overall tensor size.</p>

<p>The goal is to suggest a workable CNN architecture that connects the known
input size (<code>512x512</code> images with 3 RGB color channels) to the assumed output
shape (<code>13x13</code> embedding vectors with 12,228 dimensions each.)</p>

<p>I tried
<a href="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative.png" target="_blank">several</a>
<a href="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative4.png" target="_blank">different</a>
<a href="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative2.png" target="_blank">variations</a>,
but most of these required special cases on one or more layers to “fit.” Until
I found this one, which steps down elegantly with no special cases at all:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative3.png"></p>

<p>It very neat, isn’t it? It’s almost identical to AlexNet, and it steps down
from from 512 to 13 in five identical repeating blocks, while simultaneously
quadrupling the number of channels with each block to hit 12,228 on the bottom
layer. Unfortunately, it also feels a little outdated due to the <code>5x5</code> kernels
and max pool layers. AlexNet was a breakthrough in 2012 but I would be suprised
if OpenAI was using something similar in 2024.</p>

<p>Here’s an alternative that <em>almost</em> worked (got to <code>12x12</code> instead of <code>13x13</code>)
while staying closer to the more modern YOLO design:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative4.png"></p>

<p>While impossible to prove, these speculative designs demonstrate that there are
plausible CNN architectures that could represent an image as a $k \times k$
grid of embedding vectors.</p>

<h2 id="experimental-validation">Experimental Validation</h2>

<p>Does GPT-4o really see a <code>13x13</code> grid of embedding vectors? I invented
a task, loosely inspired by <a href="https://en.wikipedia.org/wiki/Zener_cards">Zener cards</a>, to test this. The task is to
identify the color and shape for every symbol on a grid in an image.</p>

<p>A <a href="https://gist.github.com/olooney/07850f0a2f0fcaac973ffabac765454a">simple program</a> generates test grids that look like this:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_5x5.png"></p>

<p>I then used this prompt to obtain comparison data:</p>

<pre><code>"""Divide this image into a {k}x{k} grid and describe the shape and color of
each cell. Report your results as a JSON array of arrays (no objects or row
labels) and use all lowercase."""
</code></pre>

<p>If the <code>13x13</code> hypothesis is correct, GPT-4o should do well on this task
up to about 13 and then performance should degrade. The CNN isn’t literally
dividing the image up into a grid so it might start to degrade before then,
and might struggle more with even grid sizes than odd because the cells won’t
be aligned.</p>

<p>However, that is not in fact what happens. Instead, performance is perfect for
<code>5x5</code> grids and smaller (e.g. <a href="https://www.oranlooney.com/post/gpt-cnn_files/zener_2x2.png"><code>2x2</code></a>, <a href="https://www.oranlooney.com/post/gpt-cnn_files/zener_3x3.png"><code>3x3</code></a>, <a href="https://www.oranlooney.com/post/gpt-cnn_files/zener_4x4.png"><code>4x4</code></a>) but begins
to degrade rapidly after that. By the time we reach <code>13x13</code> it was no better
than chance.</p>

<p>For example, here is a <code>7x7</code> grid:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_7x7.png"></p>

<p>For which GPT-4o returned this:</p>

<pre><code>[
    ["blue diamond", "purple triangle", "red plus", "purple circle", "orange square", "purple circle", "blue circle"],
    ["blue diamond", "red circle", "green plus", "red square", "orange diamond", "blue triangle", "purple plus"],
    ["blue diamond", "orange triangle", "red square", "orange square", "blue plus", "purple circle", "blue circle"],
    ["green diamond", "blue circle", "orange circle", "green circle", "purple diamond", "green triangle", "orange diamond"],
    ["purple square", "purple circle", "green plus", "green diamond", "green circle", "blue triangle", "purple triangle"],
    ["red plus", "red triangle", "purple circle", "blue triangle", "orange triangle", "red diamond", "orange diamond"],
    ["orange plus", "blue diamond", "green triangle", "green plus", "green triangle", "purple diamond", "purple square"]
]
</code></pre>

<p>It got <sup>38</sup>⁄<sub>49</sub> correct—an accuracy of 76%. The exact pattern of hits and
misses looks like this (yellow is correct, purple incorrect):</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_7x7_results.png"></p>

<p>Performance continues to degrade as the grid size increases and by the time we
get to the <code>13x13</code> grid:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_13x13.png"></p>

<p>The results are no better than chance:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_13x13_results.png"></p>

<p>Does that mean I was wrong about 169 tokens representing a <code>13x13</code> grid?
Yes. Yes it does. My disappointment is immeasurable and my day is ruined.</p>

<blockquote>
<p>“The great tragedy of science: the slaying of a beautiful hypothesis by an
ugly fact.” —Thomas Huxley</p>
</blockquote>

<p>But the <code>5x5</code> grid results are suggestive. GPT-4o really can keep track of 25
distinct objects and their absolute positions within in an image. Maybe the
basic concept is right; I just got the dimension wrong. It would be easy
to tack on another couple of layers to our CNN to get down to <code>5x5</code> instead
of <code>13x13</code>:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative5.png"></p>

<p>How could we structure the output to reach 170 tokens if we assume we only use
<code>5x5</code> grids and smaller?</p>

<h2 id="pyramid-strategy">Pyramid Strategy</h2>

<p>One way to get close to both 85 and 170 is to assume that we encode the image
in a series of increasingly granular levels, like a pyramid. We start with one
embedding vector to capture a gestalt impression of the whole image, add a
<code>3x3</code> to capture left/middle/right and top/middle/bottom, then adding a <code>5x5</code>,
<code>7x7</code> etc.</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/grids.png"></p>

<p>This strategy gets us very close to 85 tokens for the ‘master thumbnail’ if
we stop at <code>7x7</code>:</p>

<p>$1^2 + 3^2 + 5^2 + 7^2 = 1 + 9 + 25 + 49 = 84$</p>

<p>And very close to 170 if we add one final <code>9x9</code> grid:</p>

<p>$1^2 + 3^2 + 5^2 + 7^2 + 9^2 = 1 + 9 + 25 + 49 + 81 = 165$</p>

<p>If we throw in an <em>ad hoc</em> <code>2x2</code> grid for the <code>512x512</code> tile and assume one
special <code>&lt;|image start|&gt;</code> for each, we can get a perfect match:</p>

<p>$1 + 1^2 + 3^2 + 5^2 + 7^2 = 1 + 1 + 9 + 25 + 49 = 85$</p>

<p>$1 + 1^2 + 2^2 + 3^2 + 5^2 + 7^2 + 9^2 = 1 + 1 + 4 + 9 + 25 + 49 + 81 = 170$</p>

<p>This scheme lacks any sort of delimiters for the start and end of a row, but
I think that could be handled with positional encoding similar to the way
<a href="https://blog.eleuther.ai/rotary-embeddings/">RoPE</a> is used to encode position information for text tokens, but in 2D.</p>

<p>The above takes only odd grid sizes and goes well beyond <code>5x5</code>; given that the
Zener grid performance starts to fall off after <code>5x5</code> this does not entirely
concord with the evidence.</p>

<p>As an alternative, we could try taking all the grids (even and odd) up to <code>5x5</code>:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/grids2.png"></p>

<p>This approach gives us 55 tokens:</p>

<p>$1^2 + 2^2 + 3^2 + 4^2  + 5^2 = 55$</p>

<p>If we assume 3 tokens per mini-tile and a delimiter token between each, we
can get to 170:</p>

<p>$3 \times (1^2 + 2^2 + 3^2 + 4^2  + 5^2) + 5 = 170$</p>

<p>This isn’t fully satisfactory on numerological grounds but does jive well with
the empirical results. The pyramid strategy has a lot of intuitive appeal—it
feels like an almost “obvious” way to encode spatial information at
different zoom levels - and may explain why it does so well with the <code>5x5</code> grid
and below and so poorly on <code>6x6</code> and above.</p>

<p>It’s maddening that every hypothesis seems to come tantalizingly close to
explaining everything but the numbers never quite seem to work out neatly…
Still, these pyramid strategies are the best I’ve been able to come up with.</p>

<h2 id="optical-character-recognition">Optical Character Recognition</h2>

<p>The one thing that none of the above hypotheses explain is how GPT-4o is doing
OCR. YOLO and CLIP can’t natively do OCR, and the strategies suggested above
seem like they would struggle for the same reasons. I mean, if it can’t read
off 36 symbols in a neat <code>6x6</code> grid from an image, it certainly can’t read off
a several hundred text characters flawlessly.</p>

<p>State-of-the-art OCR engines like <a href="https://en.wikipedia.org/wiki/Tesseract_(software)">Tesseract</a> do a great deal of work to
find bounding boxes and strips of characters, and then run specialized
character recognition models along those strips, one character or word at a
time. They aren’t just big CNNs.</p>

<p>And yet GPT-4o patently <em>can</em> do high-quality OCR: it can transcribe long
blocks of text, read handwritten text, or text which has been shifted, rotated,
projected, or partially occluded.</p>

<p>I have a simple theory to explain that: I think OpenAI is running
<a href="https://en.wikipedia.org/wiki/Tesseract_(software)">Tesseract</a> (or their own in-house OCR) and feeding the identified text
into the transformer alongside the image data. I mean, that’s what I would do.</p>

<p>This would explain why the early versions were so easily confused by text
hidden in images: from its POV, that text <em>was</em> part of the prompt. (This is
fixed now; GPT-4o is good at ignoring malicious prompts hidden inside images.)</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/malicious_penguin.png" alt="GPT-4o passes the malicious penguin test."></p>

<p>However, this does not explain why there’s no charge per token for the text
found in an image.</p>

<p>Interestingly enough, it’s actually <em>more efficient</em> to send text as images: A
<code>512x512</code> image with a small but readable font can easily fit 400-500 tokens
worth of text, yet you’re only charged for 170 input tokens plus the 85 for the
‘master thumbnail’ for a grand total of 255 tokens—far less than the
number of words on the image.</p>

<p>This theory explains why there is additional latency when processing images.
The CNN would be essentially instantaneous, but 3rd-party OCR would add
additional time. By the way, (and I’m not saying this proves anything) but the
Python environment used by the OpenAI code interpreter has <a href="https://pypi.org/project/pytesseract/">PyTesseract</a>
installed. You can literally just ask it to run PyTesseract on any image you’ve
uploaded to get a second opinion.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Well, we’ve made a lot of speculative hay out of what is essentially only one
morsel of hard fact: that OpenAI used the magic number 170.</p>

<p>However, there does seem to be a complete plausible approach—very much in
line with other CNN architectures such as YOLO—for mapping from image tiles
to embedding vectors.</p>

<p>As such, I don’t think 170 tokens is just an approximation used to bill for
roughly the amount of compute it takes to process an image. And I don’t think
they’re concatenating layers to join image and text data the way some other
multi-modal models do.</p>

<p>No, I think GPT-4o is <em>literally</em> representing <code>512x512</code> images as 170
embedding vectors, using an CNN architecture that’s a mixture of CLIP and YOLO
to embed the image directly into the transformer’s semantic vector space.</p>

<p>When I started this article, I was entirely convinced that I had cracked it
entirely, that I was going to find that the 170 tokens were for a <code>13x13</code> grid
and one additional “gestalt impression” token. That got blown out of the water
when performance on the Zener task started to degrade after <code>5x5</code>—whatever
they’re doing internally, it seems to be a lot smaller than <code>13x13</code>.</p>

<p>Still the analogy to YOLO is compelling, and the performance on the <code>5x5</code> Zener
task all but confirms that they’re doing some kind of grid. This theory has a
lot of predictive power in other areas as well: it explains how GPT-4o is able
to handle multiple images, and tasks like comparing two images, for example. It
explains how it’s able to see multiple objects in the same image, but gets
overwhelmed when there are too many objects in a busy scene. It explains
why GPT-4o seems extremely vague about the absolute and relative positions of
separate objects within the scene, and why it can’t count objects accurately
in images: when an object spans two adjacent grid cells the same classes are
activated in both so it’s not sure if it’s one object or two.</p>

<p>Ironically, the one thing this theory can’t cleanly explain is the question
which motivated this article in the first place: why 170 tokens in particular?
The pyramid theory (<code>1x1 + 2x2 + 3x3 + 4x4 + 5x5</code>) was the best I was able to
come up with, and it’s not particularly neat.</p>

<p>I’d love to hear from anyone who has a theory that fits a little better (or
even actual knowledge, assuming it doesn’t run afoul of an NDA!)</p>

<!-- https://unsplash.com/photos/black-and-gray-camera-on-white-table-Y5dd6hLkn-8 -->

<h2 id="postscript-alpha-channel-shenanigans">Postscript: Alpha Channel Shenanigans</h2>

<p>One other thing I noticed while working on this project is that GPT-4o
<em>ignores</em> the alpha channel, resulting in somewhat counter-intuitive behavior.</p>

<p>When I say, “ignores”, I don’t mean that it gets rid of transparency by
compositing it onto some default background, the way an image editor might
when converting PNG to JPG. No, I mean it literally just grabs the RGB channels
and ignores the alpha channel.</p>

<p>We can illustrate this with four carefully prepared images. For convenience,
I’ve used HTML and CSS to display these images on top of a checkerboard
pattern—the images themselves have flat, transparent backgrounds.
However, half have transparent <em>black</em> backgrounds, and half have transparent
<em>white</em> backgrounds.</p>

<p>What do I mean by “transparent black” or “transparent white?” Well, when we
represent an RGBA color with four bytes, the RGB bytes are still there even
when alpha is 100%. Thus, <code>(0, 0, 0, 255)</code> and <code>(255, 255, 255, 255)</code> are in
some sense different colors, even though there’s no situation where a correct
renderer would display them differently since they’re both 100% transparent.</p>

<p>Let’s ask GPT-4o what it “sees” on these four images:</p>

<div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/black_on_transparent_black.png" alt="MODICUM"></p><p>Black Text on Transparent Black Background</p>
            <p>GPT-4o Reads: “”</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/black_on_transparent_white.png" alt="ENORMOUS"></p><p>Black Text on Transparent White Background</p>
            <p>GPT-4o Reads: “ENORMOUS”</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/white_on_transparent_black.png" alt="SCINTILLA"></p><p>White Text on Transparent Black Background</p>
            <p>GPT-4o Reads: “SCINTILLA”</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/white_on_transparent_white.png" alt="GIGANTIC"></p><p>White Text on Transparent White Background</p>
            <p>GPT-4o Reads: “”</p>
        </div>
</div>

<p>What’s going on here? The pattern that emerges is that GPT-4o can read the
text if and only if the text color is different than the “color” of the
transparent background.</p>

<p>This tells us that GPT-4o <em>disregards</em> the alpha channel and only looks at the
RGB channels. To it, transparent black is black, transparent white is white.</p>

<p>We can see this even more clearly if we mess with an image to preserve the
three RGB channels while setting the alpha channel to 100%. Here’s a little
Pillow function to do that:</p>

<pre><code>from PIL import Image

def set_alpha(image, output_path, alpha_value):
    # copy the image and ensure it's RGBA
    image = image.convert("RGBA")

    # set the alpha channel of every pixel to the given value
    pixels = image.getdata()
    new_pixels = [(r, g, b, alpha_value) for r, g, b, a in pixels]
    image.putdata(new_pixels)

    return image
</code></pre>

<p>I used that to make the two images below; they have identical RGB data, and
only differ in the alpha channel:</p>

<div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/platypus.png" alt="Visible Platypus"></p><p>Alpha Channel = 255</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/platypus_hidden.png" alt="Hidden Platypus"></p><p>Alpha Channel = 0</p>
        </div>
</div>

<p>GPT-4o has no trouble seeing the hidden platypus:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/chatgpt_hidden_platypus_test.png" alt="GPT-4o passes the hidden platypus test."></p>

<p>You can try downloading the
<a href="https://www.oranlooney.com/post/gpt-cnn_files/platypus_hidden.png" download=""><code>hidden_platypus.png</code></a>
image and dropping it into ChatGPT yourself; it will correctly describe it.
You may also note the image is 39.3 KB, the same size as
<a href="https://www.oranlooney.com/post/gpt-cnn_files/platypus.png" download=""><code>platypus.png</code></a>
even though PNG compression should have made it much smaller if it was really
a perfectly blank, transparent image. Or you can use the above function to
set the alpha channel back to 255, recovering the original image.</p>

<p>I’m not sure if this is bug but it’s certainly <a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment">surprising</a> behavior; in
fact, it feels like something a malicious user could use to smuggle information
past humans and directly to GPT-4o. However, GPT-4o is <em>much</em> better at
detecting and ignoring malicious prompts hidden in images than GPT-4v was:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/malicious_dogs.png"></p>

<p>(You can find other examples of GPT-4o successfully detecting and
ignoring malicious prompts hidden in images in my <a href="https://olooney.github.io/image_tagger/gallery/index.html">gallery of GPT-4o test
images</a> generated by my <a href="https://github.com/olooney/image_tagger"><code>image_tagger</code></a> utility.)</p>

<p>So, even if it is a bug, it’s not obvious it can be exploited. Still, it would
be less surprising in GPT-4o “saw” the same thing that a human would in a
browser.</p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: E-Paper 7-color display showing the current weather (195 pts)]]></title>
            <link>https://github.com/blixt/sol-mate-eink</link>
            <guid>40607889</guid>
            <pubDate>Fri, 07 Jun 2024 12:10:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/blixt/sol-mate-eink">https://github.com/blixt/sol-mate-eink</a>, See on <a href="https://news.ycombinator.com/item?id=40607889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sol Mate e-Paper Display ☀️</h2><a id="user-content-sol-mate-e-paper-display-️" aria-label="Permalink: Sol Mate e-Paper Display ☀️" href="#sol-mate-e-paper-display-️"></a></p>
<p dir="auto">I initially made <a href="https://chatgpt.com/g/g-QIydQSFRm-sol-mate" rel="nofollow">the ☀️ Sol Mate GPT</a>, but it didn't take too long until I wondered what it would look like on <a href="https://www.amazon.com/dp/B0BMQ83W7W" rel="nofollow">an e-Paper display</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/158591/337645173-1ef011a5-4c01-429f-872f-ea47f8c76e02.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3ODUzMDQsIm5iZiI6MTcxNzc4NTAwNCwicGF0aCI6Ii8xNTg1OTEvMzM3NjQ1MTczLTFlZjAxMWE1LTRjMDEtNDI5Zi04NzJmLWVhNDdmOGM3NmUwMi5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYwN1QxODMwMDRaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02MDQyNmE4MjgyODMyZjZiMWZhNjMwMDkxMTE5NDhkN2UyMTk4NTA1ZGE2ZjhjZDM3ZjQyNDIyNzM5MDdkMGUwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.WEo2k3SX7QEp68kk-okX0RJTE4ft5OIxo0cLY9v1B2o"><img src="https://private-user-images.githubusercontent.com/158591/337645173-1ef011a5-4c01-429f-872f-ea47f8c76e02.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3ODUzMDQsIm5iZiI6MTcxNzc4NTAwNCwicGF0aCI6Ii8xNTg1OTEvMzM3NjQ1MTczLTFlZjAxMWE1LTRjMDEtNDI5Zi04NzJmLWVhNDdmOGM3NmUwMi5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYwN1QxODMwMDRaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02MDQyNmE4MjgyODMyZjZiMWZhNjMwMDkxMTE5NDhkN2UyMTk4NTA1ZGE2ZjhjZDM3ZjQyNDIyNzM5MDdkMGUwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.WEo2k3SX7QEp68kk-okX0RJTE4ft5OIxo0cLY9v1B2o" alt="IMG_5006"></a></p>
<p dir="auto">The script to update the screen takes a location (maybe your own, maybe your best friend's, or even a fictional place!) and get the weather for that location, then generate an illustration of the location including the current weather and lighting conditions. So if it's raining, there will be people with umbrellas in the picture, and so on. If you do generate for a fictional location, the weather service will be given the latitude/longitude of the most similar place on Earth (according to GPT). The illustrations are rendered using Dall-E 3. This is why an OpenAI API token is necessary to run it.</p>
<p dir="auto">This repository contains all the code that was needed to generate and display a weather report for any specified location on a Raspberry Pi with an attached Waveshare e-Paper display.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware</h2><a id="user-content-hardware" aria-label="Permalink: Hardware" href="#hardware"></a></p>
<ul dir="auto">
<li><a href="https://www.raspberrypi.com/products/raspberry-pi-5/" rel="nofollow">Raspberry Pi 5</a></li>
<li><a href="https://www.amazon.com/dp/B0BMQ83W7W" rel="nofollow">Waveshare e-Paper 7.3" display</a> (code needs to be updated for other sizes)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">More pictures</h2><a id="user-content-more-pictures" aria-label="Permalink: More pictures" href="#more-pictures"></a></p>
<ul dir="auto">
<li><a href="https://x.com/blixt/status/1797317001372750301" rel="nofollow">4 examples, some with more color</a></li>
<li><a href="https://x.com/blixt/status/1796616909611278356" rel="nofollow">The setup, without the box</a></li>
<li><a href="https://x.com/blixt/status/1797350136080699837" rel="nofollow">Video of the thinness of the display</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Software &amp; Usage</h2><a id="user-content-software--usage" aria-label="Permalink: Software &amp; Usage" href="#software--usage"></a></p>
<p dir="auto">This should all run on your Raspberry Pi.</p>
<p dir="auto">I recommend setting up a virtual environment for Python, <a href="https://github.com/astral-sh/uv">such as uv</a>, first. Here are the instructions for if you're using <code>uv</code> (to be run inside the clone of this repo):</p>
<div dir="auto" data-snippet-clipboard-copy-content="uv venv
source .venv/bin/activate
uv pip install -r requirements.txt"><pre>uv venv
<span>source</span> .venv/bin/activate
uv pip install -r requirements.txt</pre></div>
<p dir="auto">Without <code>uv</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m venv .
source .venv/bin/activate
pip install -r requirements.txt"><pre>python -m venv <span>.</span>
<span>source</span> .venv/bin/activate
pip install -r requirements.txt</pre></div>
<p dir="auto">You will need to specify an <code>OPENAI_API_KEY</code> environment variable. For your convenience, the code will load environment variables from a <code>.env</code> file in the current working directory.</p>
<p dir="auto">Now you can use the <code>control.py</code> script to generate an image and show it on the screen:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python control.py show Barcelona"><pre>python control.py show Barcelona</pre></div>
<p dir="auto"><a href="https://www.waveshare.com/wiki/7.3inch_e-Paper_HAT_(F)_Manual#Precautions" rel="nofollow">Waveshare recommends</a> you don't leave the same image on the display for too long.</p>
<p dir="auto">Use the <code>clear</code> command to clear it:</p>

<p dir="auto">I set up a cron job (<code>crontab -e</code>) to update the image two times per day, but keep in mind this can end up costing a non-trivial amount:</p>
<div data-snippet-clipboard-copy-content="0 8 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 18 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 2 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py clear"><pre lang="crontab"><code>0 8 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 18 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 2 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py clear
</code></pre></div>
<p dir="auto">(You'll need to tweak the paths for your setup, of course.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Backend</h2><a id="user-content-backend" aria-label="Permalink: Backend" href="#backend"></a></p>
<p dir="auto">Feel free to use the private API I hosted to get the weather if you're not going to hammer it. I also use this backend for my GPT. However, if you have high volume ideas in mind, please self-host it! The source code is here:</p>
<p dir="auto"><a href="https://github.com/blixt/sol-mate">https://github.com/blixt/sol-mate</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Having issues?</h2><a id="user-content-having-issues" aria-label="Permalink: Having issues?" href="#having-issues"></a></p>
<p dir="auto">I'd love to help if I can – <a href="https://twitter.com/blixt" rel="nofollow">reach out on Twitter</a> or create an issue in this repo!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cancel Adobe if you are a creative under NDA with your clients (563 pts)]]></title>
            <link>https://twitter.com/Stretchedwiener/status/1798153619285708909</link>
            <guid>40607442</guid>
            <pubDate>Fri, 07 Jun 2024 11:12:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Stretchedwiener/status/1798153619285708909">https://twitter.com/Stretchedwiener/status/1798153619285708909</a>, See on <a href="https://news.ycombinator.com/item?id=40607442">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>