<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 03 Nov 2024 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Auth Wiki (101 pts)]]></title>
            <link>https://auth.wiki/</link>
            <guid>42033295</guid>
            <pubDate>Sun, 03 Nov 2024 14:37:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://auth.wiki/">https://auth.wiki/</a>, See on <a href="https://news.ycombinator.com/item?id=42033295">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-j7pv25f6=""> <section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">A</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Access control </h3> <p data-astro-cid-dohjnao5=""> Access control is the restriction of who can perform what actions on certain resources in a system. It is a fundamental security mechanism to define and enforce access policies. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/access-control" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Access token </h3> <p data-astro-cid-dohjnao5=""> An access token is a credential used to access protected resources on behalf of an identity (e.g., user or service). It is a bearer token that grants access to resources based on the token's scopes (permissions). </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/access-token" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> API key </h3> <p data-astro-cid-dohjnao5=""> An API key is a unique identifier used to authenticate and authorize a client when accessing an API. It serves as a secret token included in API requests to verify the client’s identity and allow access to specific resources or services. API keys are typically used in server-to-server communications or when accessing public data. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/api-key" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Attribute-based access control (ABAC) </h3> <p data-astro-cid-dohjnao5=""> Attribute-based access control (ABAC) is an access control model that uses attributes (such as user roles, resource properties, and environmental conditions) to make access control decisions. It is a flexible and dynamic way to manage access to protected resources. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/abac" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Audience </h3> <p data-astro-cid-dohjnao5=""> The audience claim in a token specifies the intended recipient, typically the client application or API resource. It ensures the token is used only by the correct service, enhancing security by preventing unauthorized access. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/audience" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Authentication </h3> <p data-astro-cid-dohjnao5=""> Authentication is the process of verifying the identity ownership (e.g. user or service). It is the foundation of identity and access management (IAM) systems and is essential for securing applications and services. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/authentication" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Authentication request </h3> <p data-astro-cid-dohjnao5=""> An authentication request is an OpenID Connect (OIDC) request for authenticating a user. It reuses the OAuth 2.0 authorization request and extends it to support authentication. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/authentication-request" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Authorization </h3> <p data-astro-cid-dohjnao5=""> Authorization is the process of determining what actions an identity can perform on a resource. It is a fundamental security mechanism to define and enforce access policies. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/authorization" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Authorization code flow </h3> <p data-astro-cid-dohjnao5=""> The authorization code dlow is a secure OAuth 2.0 mechanism that enables applications to obtain access tokens on behalf of users. It involves user authentication, authorization code generation, and token exchange. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/authorization-code-flow" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Authorization request </h3> <p data-astro-cid-dohjnao5=""> An authorization request is an OAuth 2.0 request for authorizing a client to access protected resources on behalf of a user. It is the first step of user authorization flows in OAuth 2.0. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/authorization-request" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Authorization server </h3> <p data-astro-cid-dohjnao5=""> An authorization server is a component of the OAuth 2.0 framework that issues access tokens to clients upon successful authentication and authorization. It is also the OpenID Provider (OP) in OpenID Connect (OIDC) that issues ID tokens to clients. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/authorization-server" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">C</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Claim </h3> <p data-astro-cid-dohjnao5=""> A claim in JSON Web Token (JWT) is a name-value pair that conveys specific information. In a wider context, a claim can be any name-value pair that represents information. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/claim" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Client </h3> <p data-astro-cid-dohjnao5=""> In OAuth 2.0 and OpenID Connect (OIDC), a client is an application that requests authentication or authorization on behalf of a user or itself. Clients can be public or private (confidential), and they use different grant types to obtain tokens. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/client" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Client credentials flow </h3> <p data-astro-cid-dohjnao5=""> Client credentials flow is an OAuth 2.0 grant type that allows confidential clients to obtain access tokens to access protected resources. It is suitable for machine-to-machine (server-to-server) communication. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/client-credentials-flow" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Cross-site request forgery (CSRF) </h3> <p data-astro-cid-dohjnao5=""> Cross-site request forgery (CSRF) is an attack that deceives users into executing unwanted actions on a web application in which they are authenticated. It is a common security vulnerability that can lead to unauthorized actions. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/csrf" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">D</h2> <section data-astro-cid-dohjnao5="" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-dohjnao5=""> Device flow </h3> <p data-astro-cid-dohjnao5=""> OAuth 2.0 device authorization flow is a user-friendly sign-in method for input-limited devices or headless applications.  By verifying a unique device code, making it possible for users to authorize the device via a secondary device with a full user interface. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/device-flow" data-astro-cid-dohjnao5="">Learn more</a> </section> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">E</h2> <section data-astro-cid-dohjnao5="" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-dohjnao5=""> Enterprise SSO </h3> <p data-astro-cid-dohjnao5=""> Enterprise Single Sign-On (SSO) is a specific type of SSO designed for employees within an organization. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/enterprise-sso" data-astro-cid-dohjnao5="">Learn more</a> </section> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">H</h2> <section data-astro-cid-dohjnao5="" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-dohjnao5=""> Hybrid flow </h3> <p data-astro-cid-dohjnao5=""> The hybrid flow is an OpenID Connect (OIDC) flow that combines the authorization code flow and the implicit flow. It is designed to provide a balance between security and usability for authentication. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/hybrid-flow" data-astro-cid-dohjnao5="">Learn more</a> </section> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">I</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> ID token </h3> <p data-astro-cid-dohjnao5=""> An ID token is a JSON Web Token (JWT) issued by an authorization server to a client application. It contains information about the authenticated user, such as their unique identifier and claims. This token is used to verify the user's identity and allows the client application to access protected resources on behalf of the user. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/id-token" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Identity and access management (IAM) </h3> <p data-astro-cid-dohjnao5=""> Identity and access management (IAM) is a broad concept that encompasses the processes, technologies, and policies used to manage digital identities and control access to resources. It is a fundamental aspect of security in modern applications and systems. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/iam" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Identity provider (IdP) </h3> <p data-astro-cid-dohjnao5=""> Identity provider (IdP) is a service that manages identities. Modern identity providers support OpenID Connect (OIDC) for authentication and OAuth 2.0 for authorization. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/identity-provider" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Implicit flow </h3> <p data-astro-cid-dohjnao5=""> The OIDC implicit flow is a authentication method for SPAs, enabling them to quickly receive tokens directly from the authorization server. While it simplifies the process by eliminating the need for a backend server, it comes with lower security due to token exposure in the URL. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/implicit-flow" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">J</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> JSON Web Encryption (JWE) </h3> <p data-astro-cid-dohjnao5=""> JSON Web Encryption (JWE) is a standard way to encrypt and decrypt data in JSON format. It is often used to protect sensitive information in transitting JSON Web Tokens (JWTs). </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/jwe" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> JSON Web Key (JWK) </h3> <p data-astro-cid-dohjnao5=""> A JSON Web Key (JWK) is a JSON-based format used for representing cryptographic keys. When multiple JWKs need to be grouped together, they are organized into a JSON Web Key Set (JWKS). </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/jwk" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> JSON Web Signature (JWS) </h3> <p data-astro-cid-dohjnao5=""> JSON Web Signature (JWS) is a standard way to sign and verify data in JSON format. It is often used to ensure the integrity and authenticity of JSON Web Tokens (JWTs) in OpenID Connect (OIDC). </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/jws" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> JSON Web Token (JWT) </h3> <p data-astro-cid-dohjnao5=""> JSON Web Token (JWT) is an open standard defined in RFC 7519 that enables secure communication between two parties. It is compact, URL-safe, and self-contained, making it ideal for transmitting authentication and authorization data between services. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/jwt" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Just-in-time (JIT) provisioning </h3> <p data-astro-cid-dohjnao5=""> Just-in-time (JIT) provisioning is an identity and access management (IAM) process where user accounts are created dynamically and automatically when a user attempts to access a system or application for the first time. This approach helps streamline the onboarding process and ensures that user accounts are only created when needed, reducing administrative overhead and improving security. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/jit-provisioning" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">M</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Machine-to-machine </h3> <p data-astro-cid-dohjnao5=""> Machine-to-machine (M2M) communication refers to the automated exchange of data between devices without human intervention. In the context of authentication and authorization, M2M communication often involves a client application that needs to access resources, where the client application is a machine (service) or a machine acting on behalf of a user. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/machine-to-machine" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Magic link </h3> <p data-astro-cid-dohjnao5=""> Magic link is a one-time URL that can be used to complete authentication process. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/magic-link" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Management API </h3> <p data-astro-cid-dohjnao5=""> The Management API in the context of identity and access management (IAM) allows for programmatic management of resources such as users, applications, roles, and permissions. Typically RESTful, it provides an abstraction layer between the IAM system and the user interface, enabling automation, integration, and custom feature development. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/management-api" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Multi-factor authentication (MFA) </h3> <p data-astro-cid-dohjnao5=""> Multi-factor authentication (MFA) is a security mechanism that requires users to provide at least two forms of identification to complete the authentication process. It adds an extra layer of security that significantly reduces the risk of unauthorized access. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/mfa" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Multi-tenancy </h3> <p data-astro-cid-dohjnao5=""> Multi-tenancy is a software architecture where a single application instance serves multiple customers (tenants), keeping their data isolated and secure. It’s common in cloud computing and SaaS to optimize resources and simplify maintenance. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/multi-tenancy" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">O</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> OAuth 2.0 </h3> <p data-astro-cid-dohjnao5=""> OAuth 2.0 is a widely used authorization framework that allows an application (client) to obtain limited access to protected resources on behalf of a user or the application itself. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/oauth-2.0" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> OAuth 2.0 grant </h3> <p data-astro-cid-dohjnao5=""> An OAuth 2.0 authorization grant (sometimes referred to as an "OAuth 2.0 grant type" or "OAuth 2.0 flow"), is a method used by clients to obtain an access token from an authorization server. It is an essential part for OAuth clients to authenticate and authorize identities. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/oauth-2.0-grant" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> OAuth 2.1 </h3> <p data-astro-cid-dohjnao5=""> OAuth 2.1 is a proposed update to the OAuth 2.0 authorization framework that aims to improve security and usability by deprecating insecure flows and introducing new best practices. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/oauth-2.1" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Offline access </h3> <p data-astro-cid-dohjnao5=""> Offline access allows clients to obtain new access tokens without requiring the user to re-authenticate. It is useful for long-lived sessions and better user experience. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/offline-access" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> One-time password (OTP) </h3> <p data-astro-cid-dohjnao5=""> A One-time password (OTP) is a unique, temporary code that is used for a single transaction or sign-in session. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/otp" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Opaque token </h3> <p data-astro-cid-dohjnao5=""> An opaque token is a type of token whose format is determined by the issuer, typically appearing as a string of characters or numbers, and requires validation by the issuer rather than containing all necessary information for direct validation. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/opaque-token" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> OpenID Connect (OIDC) </h3> <p data-astro-cid-dohjnao5=""> OpenID Connect (OIDC) is an authentication (identity) layer on top of OAuth 2.0, allowing clients to authenticate users and obtain identity information in a standardized way. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/openid-connect" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> OpenID Connect (OIDC) Discovery </h3> <p data-astro-cid-dohjnao5=""> OpenID Connect (OIDC) Discovery is a mechanism that allows clients to automatically discover the OpenID Provider's endpoints and configuration. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/openid-connect-discovery" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">P</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Passkey </h3> <p data-astro-cid-dohjnao5=""> Passkey is a phishing-resistant and convenient credential that replaces passwords which can be used for sign-in and multi-factor authentication. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/passkey" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Passwordless </h3> <p data-astro-cid-dohjnao5=""> Passwordless is an authentication method that allows users to sign in to computer systems without entering (or remembering) a password or any other knowledge-based secret. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/passwordless" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Proof Key for Code Exchange (PKCE) </h3> <p data-astro-cid-dohjnao5=""> Proof Key for Code Exchange (PKCE) is a security extension for OAuth 2.0 that protects authorization codes from interception and misuse. It is enforced for all types of clients in OAuth 2.1. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/pkce" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">R</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Redirect URI </h3> <p data-astro-cid-dohjnao5=""> Redirect URI is a URI where the authorization server redirects the user-agent after an authorization request. It is an essential parameter in the OAuth 2.0 and OpenID Connect (OIDC) grants that involve user interaction. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/redirect-uri" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Refresh token </h3> <p data-astro-cid-dohjnao5=""> A refresh token is a long-lived credential used to obtain new access tokens without requiring the user to re-authenticate. It is used to maintain user sessions and provide a better user experience. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/refresh-token" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Resource indicator </h3> <p data-astro-cid-dohjnao5=""> Resource indicator in OAuth 2.0 is an extension parameter defined in RFC 8707 that allows clients to specify the resource server's location in the authorization request. It provides a scalable way to handle multiple resource servers in a single authorization server. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/resource-indicator" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Resource owner </h3> <p data-astro-cid-dohjnao5=""> A resource owner is an identity (usually a user) that has the ability to grant access to a protected resource. In OAuth 2.0, the resource owner can authorize the client to access its resources in a resource server on their behalf. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/resource-owner" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Resource server </h3> <p data-astro-cid-dohjnao5=""> Resource server refers to the server hosting the protected resources that the client wants to access. It also has the responsibility to verify the access tokens and serve the protected resources to the client. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/resource-server" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Role </h3> <p data-astro-cid-dohjnao5=""> A role is a collection of permissions in access control systems that defines what actions users can perform, providing an efficient way to manage and assign access rights to users. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/role" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Role-based access control (RBAC) </h3> <p data-astro-cid-dohjnao5=""> Role-based access control (RBAC) is an access control model that assigns permissions to roles rather than directly to users, providing a flexible and efficient way to manage access rights in systems. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/rbac" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">S</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Scope </h3> <p data-astro-cid-dohjnao5=""> Scope defines the permissions that an application requests from a user to access their protected resources. It is a fundamental concept in OAuth 2.0 and OIDC that controls the level of access an application can have to a user's data. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/scope" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Security Assertion Markup Language (SAML) </h3> <p data-astro-cid-dohjnao5=""> Security Assertion Markup Language (SAML) is an XML-based standard for exchanging authentication and authorization data between identity providers and service providers. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/saml" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Service provider (SP) </h3> <p data-astro-cid-dohjnao5=""> Service provider (SP) is an application or service that relies on an identity provider (IdP) for authentication and authorization. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/service-provider" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Signing key </h3> <p data-astro-cid-dohjnao5=""> A signing key is a cryptographic key used to sign and verify JSON Web Tokens in OpenID Connect (OIDC). It is used to ensure the integrity and authenticity of the tokens issued by the OpenID provider. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/signing-key" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Single sign-on (SSO) </h3> <p data-astro-cid-dohjnao5=""> Single sign-on (SSO) is an authentication method that allows users to access multiple systems with a single set of credentials. As a key component of identity and access management (IAM) systems, SSO is widely used in modern cloud-based applications and services, simplifying user access and enhancing security. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/single-sign-on" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">T</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Time-based one-time password (TOTP) </h3> <p data-astro-cid-dohjnao5=""> A time-based one-time password (TOTP) is a temporary, unique code generated by an algorithm that uses the current time as a key factor. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/totp" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Token introspection </h3> <p data-astro-cid-dohjnao5=""> Token introspection is an OAuth 2.0 extension that allows clients to query the authorization server to validate access tokens and retrieve metadata about them. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/token-introspection" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Token request </h3> <p data-astro-cid-dohjnao5=""> Token request refers to the OAuth 2.0 request for exchanging credentials (e.g., authorization code, refresh token) for a set of tokens, typically including one or more of the following: access token, ID token, or refresh token. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/token-request" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">U</h2> <section data-astro-cid-dohjnao5="" data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-dohjnao5=""> Userinfo endpoint </h3> <p data-astro-cid-dohjnao5=""> Userinfo endpoint is an OpenID Connect (OIDC) endpoint that provides user information to clients. It is a supplementary endpoint to the ID token and allows clients to retrieve additional user information. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/userinfo-endpoint" data-astro-cid-dohjnao5="">Learn more</a> </section> </section><section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">W</h2> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> WebAuthn </h3> <p data-astro-cid-dohjnao5=""> WebAuthn is an API for accessing public key credentials, facilitating the implementation of passkeys. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/webauthn" data-astro-cid-dohjnao5="">Learn more</a> </section> <section data-astro-cid-dohjnao5=""> <h3 data-astro-cid-dohjnao5=""> Webhook </h3> <p data-astro-cid-dohjnao5=""> Webhooks are a method for web applications to communicate with each other in real-time. They allow one application to send automated messages or information to another application when a specific event occurs. Unlike traditional APIs where one application needs to poll another for updates, webhooks push data to the receiving application as soon as the event happens. </p> <hr data-astro-cid-dohjnao5=""> <a href="https://auth.wiki/webhook" data-astro-cid-dohjnao5="">Learn more</a> </section>  </div> </section> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Touchscreens are out, and tactile controls are back (431 pts)]]></title>
            <link>https://spectrum.ieee.org/touchscreens</link>
            <guid>42033241</guid>
            <pubDate>Sun, 03 Nov 2024 14:29:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/touchscreens">https://spectrum.ieee.org/touchscreens</a>, See on <a href="https://news.ycombinator.com/item?id=42033241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Touchscreens Are Out, and Tactile Controls Are Back"><p>Tactile controls are back in vogue. Apple added two new buttons to the <a href="https://www.apple.com/newsroom/2024/09/apple-introduces-iphone-16-and-iphone-16-plus/" rel="noopener noreferrer" target="_blank"><u>iPhone 16</u></a>, home appliances like <a href="https://spectrum.ieee.org/handson-with-ultrahaptics-invisible-touchable-controls" target="_blank">stoves</a> and washing machines are returning to knobs, and several car manufacturers are <a href="https://arstechnica.com/cars/2023/03/buttons-are-back-at-porsche-as-we-see-the-2024-cayenne-interior/" target="_blank">reintroducing</a>&nbsp;<a href="https://www.carsguide.com.au/car-news/hallelujah-hyundai-vows-to-resist-modern-trend-for-all-digital-cabins-and-keep-using" target="_blank">buttons</a> and dials to dashboards and <a href="https://www.thedrive.com/news/vw-brings-back-steering-wheel-buttons-after-many-customers-complain" target="_blank">steering wheels</a>. </p><p>With this “<a href="https://www.wsj.com/tech/personal-tech/touch-screens-are-over-even-apple-is-bringing-back-buttons-86fb9ea8" rel="noopener noreferrer" target="_blank">re-buttonization</a>,” as <em>The Wall Street Journal </em>describes it, demand for <a href="https://mediaschool.indiana.edu/people/profile.html?p=raplotni" target="_blank">Rachel Plotnick</a>’s expertise has grown. Plotnick, an associate professor of Cinema and Media Studies at Indiana University in Bloomington, is the leading expert on buttons and how people interact with them. She studies the relationship between technology and society with a focus on everyday or overlooked technologies, and wrote the 2018 book <em>Power Button: A History of Pleasure, Panic, and the Politics of Pushing</em>. Now, companies are reaching out to her to help improve their tactile controls.</p><ul><li><a href="#research">Researching the history of buttons</a></li><li><a href="#renaissance">The renaissance of physical controls</a></li><li><a href="#companies">Working with companies on “re-buttoning”</a></li></ul><p id="research"><strong>You wrote <a href="https://mitpress.mit.edu/9780262551953/power-button/" target="_blank">a book</a> a few years ago about the history of buttons. What inspired that book?</strong></p><p><strong>Rachel Plotnick:</strong><strong></strong>Around 2009, I noticed there was a lot of discourse in the news about the death of the button. This was a couple years after the first iPhone had come out, and a lot of people were saying that, as touchscreens were becoming more popular, eventually we weren’t going to have any more physical buttons to push. This started to happen across a range of devices <a href="https://spectrum.ieee.org/microsoft-kinect-hand-gesture-control" target="_blank">like the Microsoft Kinect</a>, and after films like Minority Report had come out in the early 2000s, everyone thought we were moving to this kind of gesture or speech interface. I was fascinated by this idea that an entire interface could die, and that led me down this big wormhole, to try to understand how we came to be a society that pushed buttons everywhere we went. </p><p data-rm-resized-container="25%"><img alt="Portrait of Rachel Plotnick smiling outdoors." data-rm-shortcode-id="0046944df6813b298576239d6085ebba" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/portrait-of-rachel-plotnick-smiling-outdoors.jpg?id=54089372&amp;width=980" height="2374" id="b2bb6" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/portrait-of-rachel-plotnick-smiling-outdoors.jpg?id=54089372&amp;width=980" width="3166"><small placeholder="Add Photo Caption...">Rachel Plotnick studies the ways we use everyday technologies and how they shape our relationships with each other and the world.</small><small placeholder="Add Photo Credit...">Rachel Plotnick</small></p><p>The more that I looked around, the more that I saw not only were we pressing digital buttons on social media and to order things from <a href="https://spectrum.ieee.org/tag/amazon">Amazon</a>, but also to start our coffee makers and go up and down in elevators and operate our televisions. The pervasiveness of the button as a technology pitted against this idea of buttons disappearing seemed like such an interesting dichotomy to me. And so I wanted to understand an origin story, if I could come up with it, of where buttons came from.</p><p><strong>What did you find in your research?</strong></p><p><strong>Plotnick:</strong><strong></strong>One of the biggest observations I made was that a lot of fears and fantasies around pushing buttons were the same 100 years ago as they are today. I expected to see this society that wildly transformed and used buttons in such a different way, but I saw these persistent anxieties over time about control and who gets to push the button, and also these pleasures around button pushing that we can use for advertising and to make technology simpler. That pendulum swing between fantasy and fear, pleasure and panic, and how those themes persisted over more than a century was what really interested me. I liked seeing the connections between the past and the present.</p><p><a href="#menu">[Back to top]</a></p><p id="renaissance"><strong>We’ve experienced the rise of touchscreens, but now we might be seeing another shift—a renaissance in buttons and physical controls. What’s prompting the trend?</strong></p><p><strong>Plotnick:</strong><strong></strong>There was this kind of touchscreen mania, where all of a sudden everything became a touchscreen. Your <a href="https://spectrum.ieee.org/quantum-dot-display-hyundai-mobis" target="_blank">car was a touchscreen</a>, your refrigerator was a touchscreen. Over time, people became somewhat fatigued with that. That’s not to say touchscreens aren’t a really useful interface, I think they are. But on the other hand, people seem to have a hunger for physical buttons, both because you don’t always have to look at them—you can feel your way around for them when you don’t want to directly pay attention to them—but also because they offer a greater range of tactility and feedback. </p><p>If you look at gamers playing video games, they want to push a lot of buttons on those controls. And if you look at DJs and digital musicians, they have endless amounts of buttons and joysticks and dials to make music. There seems to be this kind of richness of the tactile experience that’s afforded by pushing buttons. They’re not perfect for every situation, but I think increasingly, we’re realizing the merit that the interface offers.</p><p><strong>What else is motivating the re-buttoning of consumer devices?</strong></p><p><strong>Plotnick:</strong><strong></strong>Maybe <a href="https://spectrum.ieee.org/zoom-fatigue" target="_blank">screen fatigue</a>. We spend all our days and nights on these devices, scrolling or constantly flipping through pages and videos, and there’s something tiring about that. The button may be a way to almost de-technologize our everyday existence, to a certain extent. That’s not to say buttons don’t work with screens very nicely—they’re often partners. But in a way, it’s taking away the priority of vision as a sense, and recognizing that a screen isn’t always the best way to interact with something. </p><p>When I’m driving, it’s actually unsafe for my car to be operated in that way. It’s hard to generalize and say, buttons are always easy and good, and touchscreens are difficult and bad, or vice versa. Buttons tend to offer you a really limited range of possibilities in terms of what you can do. Maybe that simplicity of limiting our field of choices offers more safety in certain situations.</p><p><strong>It also seems like there’s an accessibility issue when prioritizing vision in device interfaces, right?</strong></p><p><strong>Plotnick:</strong><strong></strong>The blind community had to fight for years to make touchscreens more accessible. It’s always been funny to me that we call them touchscreens. We think about them as a touch modality, but a touchscreen prioritizes the visual. Over the last few years, we’re seeing Alexa and Siri and a lot of these other voice activated systems that are making things a little bit more auditory as a way to deal with that. But the touch screen is oriented around visuality.</p><p><strong>It sounds like, in general, having multiple interface options is the best way to move forward—not that touchscreens are going to become completely passé, just like the button never actually died. </strong></p><p><strong>Plotnick:</strong><strong></strong>I think that’s accurate. We see paradigm shifts over time with technologies, but for the most part, we often recycle old ideas. It’s striking that if we look at the 1800s, people were sending messages via telegraph about what the future would look like if we all had this dashboard of buttons at our command where we could communicate with anyone and shop for anything. And that’s essentially what our smartphones became. We still have this dashboard menu approach. I think it means carefully considering what the right interface is for each situation. </p><p><a href="#menu">[Back to top]</a></p><p id="companies"><strong>Several companies have reached out to you to learn from your expertise. What do they want to know?</strong></p><p><strong>Plotnick:</strong> I think there is a hunger out there from companies designing buttons or consumer technologies to try to understand the history of how we used to do things, how we might bring that to bear on the present, and what the future looks like with these interfaces. I’ve had a number of interesting discussions with companies, including one that manufactures push button interfaces. I had a conversation with them about <a href="https://spectrum.ieee.org/tag/medical-devices">medical devices</a> like CT machines and X-ray machines, trying to imagine the easiest way to push a button in that situation, to save people time and improve the patient encounter. </p><p>I’ve also talked to people about what will make someone use a defibrillator or not. Even though it’s really simple to go up to these automatic machines, if you see someone going into cardiac arrest in a mall or out on the street, a lot of people are terrified to actually push the button that would get this machine started. We had a really fascinating discussion about why someone wouldn’t push a button, and what would it take to get them to feel okay about doing that. </p><p>In all of these cases, these are design questions, but they’re also social and cultural questions. I like the idea that people who are in the humanities studying these things from a long term perspective can also speak to engineers trying to build these devices.</p><p><strong>So these companies also want to know about the history of buttons? </strong></p><p><strong>Plotnick:</strong><strong></strong>I’ve had some fascinating conversations around history. We all want to learn what mistakes not to make and what worked well in the past. There’s often this narrative of progress, that things are only getting better with technology over time. But if we look at these lessons, I think we can see that sometimes things were simpler or better in a past moment, and sometimes they were harder. Often with new technologies, we think we’re completely reinventing the wheel. But maybe these concepts existed a long time ago, and we haven’t paid attention to that. There’s a lot to be learned from the past. </p><p><a href="#menu">[Back to top]</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If you need the money, don't take the job (224 pts)]]></title>
            <link>https://bitfieldconsulting.com/posts/need-money</link>
            <guid>42032638</guid>
            <pubDate>Sun, 03 Nov 2024 12:17:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bitfieldconsulting.com/posts/need-money">https://bitfieldconsulting.com/posts/need-money</a>, See on <a href="https://news.ycombinator.com/item?id=42032638">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="23" id="block-yui_3_17_2_1_1703715719472_17380"><p>It’s late, and the campfire is burning low. My fellow content creator <a href="https://www.zackproser.com/">Zack Proser</a> and I are sitting on a log, chowing down on s’mores and enjoying a few spine-chilling tales of terror about my horrible career.</p>
<p>Well, not that horrible: I now make a living from at least two of my favourite activities, <a href="https://bitfieldconsulting.com/books">writing</a> and <a href="https://bitfieldconsulting.com/courses">mentoring</a>. No luck so far getting people to pay me to tinker with their vintage Land Rovers, or to sit in a comfy chair eating chocolates and watching classic <em>Doctor Who</em>, but hope springs eternal.</p>
<p>Last time, we talked about how I made the leap from salaried server-monkey to starting my own company. Independence is great, but it turns out that when you quit your job, you also stop getting the regular paychecks (why does no one ever tell you these things?)</p>
<p>Money, like oxygen, is one of those things that you don’t really appreciate until you suddenly don’t have enough of it. Some of the biggest challenges for the newly independent developer or creator, indeed, revolve around money: how to get people to give it to you, how much to ask for, and how to be <em>worth</em> what you’re asking. Let’s get into that. Over to Zack.</p>
<p><strong>In our last chat, John, you froze my blood with a horror story about what happened when you unwisely took on a fixed-price contract. From what you said, it doesn’t sound as though a deal like that is good for either you or the client?</strong></p>
<p>It’s not. A fixed-price deal sets up the wrong incentive structure. It’s in the client’s interest to agree the lowest price possible, and then to squeeze the consultant for every drop of juice they can get. So that sucks.</p>
<p>On the other hand, it’s in the consultant’s interest to do the quickest and cheapest work necessary to get the client to sign off on the job. After that, they have zero incentive to fix any problems that arise. It’s just bad news all round.</p>
<p><strong>So what would you recommend instead?</strong></p>
<p>When someone asks for a fixed price, I’ll explain to them why that’s not in either of our interests, and suggest that instead they pay me a fair hourly rate for what I do. And, so they know what they’re in for, I’ll give them a careful and realistic estimate of how many hours it’ll take to deliver what they’ve asked for. That gives them the cost control they need, but doesn’t <em>commit</em> them to the whole sum right away.</p>
<p>Once we’ve agreed the terms, I can get started, and I have a strong incentive to deliver value for them right away. If they like the work I’m doing, and they want more, I’ll happily provide it: it pays me to do so! On the other hand, if after the first day or two they think “This guy’s no good,” they can just pay me off and wave goodbye: they’re not locked in for the long term to a vendor choice they’re already regretting.</p>
<p>At the end of the job, if they want further changes or enhancements, they can have them, but not for free. I’ll estimate them, and then they can decide whether or not it’s worth the extra cost. That prevents a nasty case of “just one more thing” syndrome.</p>
<p>One reason some companies don’t like to pay for consulting work by the hour is that they think it’ll incentivise the consultant to goof off. You know, take it slowly, invent problems and delays, anything to rack up a few extra hours. Sure, unscrupulous consultants will do that, but then it’s on the client to pick that up and get rid of them. It’s not a successful long-term strategy.</p>
<p><strong>Why not?</strong></p>
<p>I’ve heard it wisely said that there are two kinds of consultants: poachers and farmers. The poacher wants to make a quick kill and get clean away. The farmer, on the other hand, is in the game for the long haul. She shears the sheep closely, but gently, and nurtures it. She feeds it, cares for it, keeps it warm in the winter, and tends it when it’s sick. That way, it’ll be around for her to shear again next year.</p>
<p><strong>Flattering analogy.</strong></p>
<p>Okay, but I’ve worked on farms: you’ll never find a deeper love than a farmer has for her sheep. They’re literally her livelihood: if they do well, she does well. Sure, she might see a quick profit if she slaughtered them all this year, but then there’s no <em>next</em> year. Instead, she looks after the sheep, and they’ll look after her.</p>
<p>Similarly, as a consultant you <em>could</em> strike fast, extract as much money from the client for as little work as possible, and then ride like hell for the hills. There’ll always be more unsuspecting clients for you to predate upon, won’t there?</p>
<p>It seems tempting, but actually, it doesn’t work. Hunting for new clients all the time is difficult and expensive, and often it doesn’t work out: you put time and effort into meetings, proposals, and estimates, and half the time it just doesn’t go anywhere. Much better not to lose the old client in the first place.</p>
<p>Also, sooner or later, the word about you will get around. One way or the other. So you should be the consultant that <em>you’d</em> want to hire.</p>
<p>Repeat business is the best business, because marketing is hard. After a while, you won’t <em>need</em> to market your services. People will start coming to <em>you</em>. At that point you know you’re doing something right.</p>
<p><strong>I see the value of charging by the hour, but one thing I struggle with personally is knowing <em>what</em> to charge. Do you have any advice?</strong></p>
<p>Yes, that’s difficult. The best advice <em>I</em> ever got on this was “Think of a number, then double it.” If you don’t feel a little embarrassed when you tell them the rate, that probably means you’re coming in too low. If you always get a yes, then you’re <em>definitely</em> coming in too low.</p>
<p>The tendency is always to under-price yourself. Partly because you’re modest and self-effacing (that’s one of the reasons we all love you), but also because you want the business. That’s another big mistake I made starting out. I thought “Well, I don’t really <em>know</em> very much. I’ll charge a low rate to reflect that.”</p>
<p>Here’s a weird fact: businesses actually <em>like</em> paying a lot for consultants. It’s called the <a href="https://vinepair.com/articles/chivas-regal-effect/">Chivas Regal effect</a>. You know, if people see a cheap bottle of whisky, they’ll assume (rightly) that it’s horrible. But if it costs sixty bucks a bottle, they’ll assume it must be a quality product. Otherwise, how on earth could the manufacturer justify charging that much for it?</p>
<p><strong>And the whisky actually tastes better <em>because</em> it costs a lot.</strong></p>
<p>It sure does. Cheers!</p>
<p>Imagine a manager has some problem they can’t fix. What’s their response? Hire a consultant. A cheap consultant? Absolutely not. Only bad managers have cheaply-solved problems.</p>
<p>The more they spend, the greater the kudos they’ll get from upstairs, and the bigger their budget will be next year. After all, the division with the most expensive problems must be the most important one in the company.</p>
<p>And everyone can relax and feel good knowing that the problem’s being taken care of by the highest-priced consultancy firm available.</p>
<p><strong>Wait, what?</strong></p>
<p>I’m serious. When you’re on trial for murder, do you want to hire the cheapest lawyer in the phone book? I don’t think so. You go to the <em>super</em> expensive lawyer, the one that defends Tom Cruise against whatever the latest weird and concerning allegations might be.</p>
<p>Okay, someone else, not Tom Cruise: I don’t want to hear from his lawyers. But that’s my point.</p>
<p><strong>So it’s about being reassuringly expensive.</strong></p>
<p>It really is. You have to <em>actually</em> be good at what you’re doing too, of course, or the whole scheme falls apart. What the client’s money really buys, though, is that delightful feeling of making the thing <em>somebody else’s problem</em>. You know, we’ve turned it all over to a top-tier expert, and now we just don’t have to think about it anymore. The more that person charges, the more reassured the client feels.</p>
<p>It’s better for you, too, because when they’re paying you a lot of money, they put a lot of value on your advice. By contrast, the less they’re paying, the less they’re inclined to listen to you. You need them to listen to you, and that’s why you need to charge top dollar.</p>
<p>In <a href="https://amzn.to/3T37iVY">“Secrets of Consulting”</a>, which is the first book everybody should read on this subject, the incredibly wise Jerry Weinberg says:</p>
<blockquote>
<p><em>Make sure they pay you enough so they’ll do what you say.</em></p>
</blockquote>
<p><strong>That’s genius, but… how do you work out how much that should be?</strong></p>
<p>Here’s a good way to get to the right number: every time a client accepts your price, make it a little bit higher the next time around. When people start complaining, or turning you down, you know you’re getting into the ballpark. When your acceptance rate falls to about fifty percent, then you’re probably there.</p>
<p>And don’t forget, the more clients you work with, the more <em>you</em> learn. The more you’ve learned, the better a consultant you are, and the more you can charge. So your price should steadily increase over time (but make sure it’s always in line with your value).</p>
<p><strong>What if they want to negotiate?</strong></p>
<p>You can negotiate on everything else, but don’t negotiate on price. Would you go to the cheapest dentist? Would you haggle with your brain surgeon from the operating table? I hope not. Some things just aren’t worth cheaping out on. Clients will still try, but you should politely decline.</p>
<p>Clients who want a discount always turn out to be the worst clients, if you cave in to them. By offering you less, they’re really saying “We don’t think you’re worth what you’re asking.” You don’t want to work for someone who sees you that way.</p>
<p>Plus, people who ask for discounts are habitual cheapskates. They think they’re smarter than everybody else: only suckers pay sticker price. They think you’re trying to take <em>them</em> for a sucker.</p>
<p>If you accept their lowball offer, now they know they’ve got you on the hook. They’ll try to screw you in every other way, too: asking for extra things here and there, demanding shorter deadlines, out-of-hours support, every little deal-sweetener they can think of.</p>
<p>Unless you really can’t survive without that client, don’t take them on. Jerry Weinberg also says “If you need the money, don’t take the job.”</p>
<p><strong>That’s great advice. I’m putting “Secrets of Consulting” on my reading list! What else?</strong></p>
<p>One common problem is that the client doesn’t know anything about the subject area: if they did, they wouldn’t need you. So they also don’t know what constitutes a fair price for the work. When they hear your rate, it may sound too high, and you won’t get the deal.</p>
<p>But that’s okay. You just dodged a bullet, because you don’t actually want a client who doesn’t understand the value of what you do. That’ll never be a profitable engagement, in any sense of the word.</p>
<p>Once someone got in touch with me and, when I quoted my rate, they said “Gosh, that’s so much more than we were expecting. We’d like to hire you, but there’s a guy in Eastern Europe who says he’ll do it for like 20% of that.” I said fine. Absolutely, go with the cheap guy. If he can do the same quality work as me for a fifth of what I charge, I told them, then it’s positively their fiduciary <em>duty</em> to hire him, which they did.</p>
<p>A few months later they came back to me and said, “Now we understand why he was so cheap. Are <em>you</em> still available, by any chance?” And of course I was… at the rate I originally quoted.</p>
<p><strong>Business Jack does not play gentle.</strong></p>
<p>That ended up being a long and very rewarding engagement, and they were super happy with my work. Partly because it <em>was</em> good, if I say so myself, but also because they’d seen something of the cheaper alternative. They’d learned the value of what I do, and I learned that it’s okay not to let yourself be beat down on price.</p>
<p>Things can still go squirrely even after you’ve landed the gig, too. You know, you give the client the benefit of your expertise, and they say something like “Thanks very much, but that won’t work for us. We’re going to do XYZ instead, because money / politics / reasons.”</p>
<p>It’s easy to get upset in that situation, and start arguing with them or berating them. What kind of idiots pay for an expensive consultant and then ignore what they say? The commonest kind, it turns out.</p>
<p>The fact is that they may just not be ready to <em>hear</em> what you’re saying. Sometimes they need a little time to think about it, and sometimes they need to learn what happens if they do it the other way. In fact, I’ve gone so far as to formulate what I call Bitfield’s First Law of Consulting:</p>
<blockquote>
<p><em>Sometimes the client needs to feel the pain of not taking your advice, before they’re ready to take your advice.</em></p>
</blockquote>
<p>It’s amazing how effective that can be. When they <em>do</em> come back to you, it’s often with a greatly increased respect for what you say next. “He said we’d crash and burn if we did X, and he was right! This guy really knows what he’s talking about. Let’s listen to him in a rapt, respectful silence.”</p>
<p><strong>I’m doing just that. Shall we take another natural break, and return for a final bite of your wisdom s’more later on?</strong></p>
<p>Sure thing. We’ll talk about how my consulting career ended up taking me somewhere quite unexpected, but that turned out to be exactly where I needed to be. See you next time.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matrix 2.0 Is Here (164 pts)]]></title>
            <link>https://matrix.org/blog/2024/10/29/matrix-2.0-is-here/?resubmit</link>
            <guid>42032387</guid>
            <pubDate>Sun, 03 Nov 2024 11:09:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matrix.org/blog/2024/10/29/matrix-2.0-is-here/?resubmit">https://matrix.org/blog/2024/10/29/matrix-2.0-is-here/?resubmit</a>, See on <a href="https://news.ycombinator.com/item?id=42032387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Hi all,</p>
<p>Since the outset of Matrix, our aim has always been to provide a protocol that lets you build open, decentralised,
secure communication apps which outperform the mainstream centralised alternatives.  It’s been a twisty journey - first
focusing on making Matrix work at all (back in 2014), and then getting it out of beta with Matrix 1.0 in 2019, and now
focusing on making Matrix fast, usable and mainstream-ready with Matrix 2.0.</p>
<p>Meanwhile, the pendulum of decentralisation continues to accelerate in our direction. Our friends at Bluesky have shown
that it’s possible to build decentralised social apps which are mainstream friendly enough for
<a href="https://techcrunch.com/2024/08/31/bluesky-tops-app-charts-and-sees-all-time-highs-after-brazil-bans-x/">Presidents</a> to
recommend them; Elon continues to <a href="https://mashable.com/article/x-elon-musk-bans-blocking">destroy Twitter</a> and showcase
the importance of decentralisation to everyone, and even Meta is dabbling in decentralised social media (and
<a href="https://matrix.org/blog/2024/09/whatsapp-dma/">decentralised communication</a>!)</p>
<p>So, where does Matrix sit in all this? Well, in order to make the transition to mainstream, we’ve been beavering away to
implement four main pillars in Matrix 2.0:</p>
<ol>
<li>Instant login, instant launch, and instant sync (aka Simplified Sliding Sync, <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4186">MSC4186</a>)</li>
<li>Next Generation Auth (aka Native OIDC, <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3861">MSC3861</a>)</li>
<li>Native Matrix Encrypted Multiparty VoIP/Video (aka MatrixRTC, <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4143">MSC4143</a>)</li>
<li>Invisible Encryption (<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4153">MSC4153</a> &amp; friends).</li>
</ol>
<p>Between these, we believe that Matrix can now be used to build apps which genuinely outperform the mainstream
alternatives - and what’s more, <strong>these MSCs now all have implementations you can use today.</strong>  The MSCs themselves are
not all finalised and ready for merge (but are getting close), and when they pass FCP (Final Comment Period) to merge
into the spec, we will formally bump the spec release to version 2.0.</p>
<p>We actually declared Matrix 2.0 as ready for action back at The Matrix Conference last month, and now that the
<a href="https://matrix.org/blog/2024/10/29/matrixconf/">videos have been published</a> you can watch the launch right here:</p>

<youtube-player video-id="ZiRYdqkzjDU"></youtube-player>

<p>Since the conference talk things have already moved on a bit, though, and we’ve landed a bunch of tweaks to address
teething issues - and so here’s the current state of action:</p>
<h3 id="1-simplified-sliding-sync">1. Simplified Sliding Sync</h3>
<p>Simplified Sliding Sync is the final version of Sliding Sync - the API which provides instant login, launch &amp; sync in
Matrix 2.0.  To say that the API has been through a lot of iterations is an understatement, but we’re finally there
with <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4186">MSC4186</a>, which simplifies the original Sliding
Sync API (<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3575">MSC3575</a>) by removing the concept of a
server-determined room list ordering entirely, and instead lets the client sort the roomlist as needed (while letting
the client paginate in the roomlist incrementally, to ensure instant responsivity, no matter how large your room list
is).</p>
<p><strong>Simplified Sliding Sync is now implemented natively in Synapse as of 1.114</strong>, and so there is no longer any need to
run a Sliding Sync Proxy in order to use the API.  In fact, the Sliding Sync Proxy is being deprecated and the old
Sliding Sync code will be removed from matrix-rust-sdk in the nearish future. Unfortunately we don’t have bandwidth
to maintain both the native implementation Synapse as well as the proxy shim - and the proxy inevitably has suffered
from a lot of limitations (e.g. having to do a full v2 initial sync for new logins, slowing them down to v2
performance - as well as duplicating storage between Synapse and the proxy).  There’ll be a dedicated deprecation
blog post for the proxy and pre-simplified Sliding Sync shortly.  Meanwhile, work is well underway for native Sliding
Sync support in <a href="https://conduit.rs/">conduit</a>, <a href="https://github.com/girlbossceo/conduwuit">conduwuit</a> and
<a href="https://gitlab.computer.surgery/matrix/grapevine">grapevine</a> - conduwuit guesses “next few weeks” for native Simplified
Sync Support to land. Dendrite is unfortunately still not funded, so will happen on a best effort basis.</p>
<p>In terms of performance, native Simplified Sliding Sync in Synapse is spectacular - outperforming the proxy throughout,
and making the old sync v2 API look positively prehistoric.  Gone are the days of waiting for your app to sync, even if
you’ve been offline for weeks/months; gone are the days of waiting minutes to login, and gone are the days of staring
at a spinner as your app launches.  It really is a new era - and having been hyping it since the first demo at FOSDEM
2023, I promise we won’t bang on about sliding sync any more after this; it’s finally here and landed and we can move
on and enjoy it!  For more details, see Ivan’s talk from The Matrix Conference:</p>

<youtube-player video-id="kI2lSCVEunw"></youtube-player>
<h3 id="2-next-generation-auth">2. Next Generation Auth</h3>
<p>Next Generation Auth is what we’re calling the migration to using industry standard OpenID Connect as the authentication
API in Matrix 2.0, moving on from the custom auth API that Matrix has historically used.  We’re calling this Next Gen
Auth because we were seeing a lot of folks incorrectly assuming that adopting OpenID Connect for auth meant we would
somehow be encouraging 3rd party social login or single-sign-on - which is <strong>not</strong> the case.</p>
<p>Next Gen Auth is simply swapping out Matrix’s old custom auth APIs with equivalents which are defined by the OpenID
Foundation; after all, Matrix is a communication protocol, not an authentication protocol. In return, we get much more
mature and secure authentication APIs - and access to the whole OpenID Identity Provider ecosystem, including support
for Two Factor Auth and Multi-Factor Auth, hardware authentication tokens, passkeys, and device-based login flows
(aka QR Login).  We also stop both Matrix clients and servers having to implement the sprawling legacy Matrix
authentication API surface - ensuring that users only ever hand their account password to their auth server, rather
than having to trust their clients to handle it securely, which in turn plays much nicer with password managers
(who only have to remember how to auth with your auth server, rather than a myriad different clients).  It also lets
you share authentication between apps if you want; gives us access_token refresh (at last!) to avoid long-lived
access_tokens hanging around; and in future will also support OIDC scopes so you can limit the access particular
clients get to your account.</p>
<p>In short, Next Gen Auth is transformative, and the initial implementation at
<a href="https://github.com/element-hq/matrix-authentication-service">matrix-authentication-service</a> (MAS) is ready for admins
to deploy and use (and in future will be available embedded in Synapse too).  Unfortunately it is <strong>not yet live on
matrix.org</strong> (given we have to migrate tens of millions of accounts, complete with all the social login complexities)
but we’re hoping to get it there in the coming months.</p>
<p>Probably one of the clearest immediate benefits of Next Gen Auth is the ability to do a full login <strong>including setting
up all your end-to-end-encryption</strong> simply by scanning a QR code on an existing client, courtesy of
<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4108">MSC4108</a> and OAuth 2.0 Device Authorization Grants.  In
other words, you don’t have to specify a server, or your username, or account password, or your recovery key - you just
scan a QR code and you’re in.  The very latest Element X releases on iOS &amp; Android have this implemented and enabled by
default, and so if you’re on a server which has deployed MAS, you can go to “link new device” in Element Web/Desktop to
show a QR code to instantly log in.</p>
<p>For more info on all things Next Gen Auth, see Quentin’s talk from The Matrix Conference:</p>

<youtube-player video-id="wOW8keNafdE"></youtube-player>
<h3 id="3-native-matrix-group-voip-video-matrixrtc">3. Native Matrix Group VoIP/Video: MatrixRTC</h3>
<p>Next we have MatrixRTC: end-to-end-encrypted group voice and video conferencing over Matrix. Historically, group VoIP in
Matrix has relied on third party conferencing systems (Jitsi, and before that FreeSWITCH) - providing no support for
Matrix’s end-to-end encryption, or indeed Matrix’s user identities, decentralisation or decentralised access control.</p>
<p>With MatrixRTC this changes: <strong>we now have a standard way to establish large-scale end-to-end-encrypted group video
calls via Matrix</strong>, leveraging all the benefits of Matrix’s end-to-end-encryption infrastructure, user identity, room
permissions, etc.  It also supports different media stacks to actually handle the media conferencing - today, the main
implementation uses the <a href="https://docs.livekit.io/reference/internals/livekit-sfu/">LiveKit SFU</a>, but there’s also an
experimental full-mesh WebRTC implementation.</p>
<p>Element Call has been the driving app behind MatrixRTC, and as of today is now enabled in the release versions of both
Element Web/Desktop and Element X to provide native MatrixRTC calling embedded in the apps: if you hit the video call
button you will now have the option to spin up a MatrixRTC call via Element Call rather than via Jitsi or Legacy 1:1
calling, and if the room is end-to-end-encrypted, all the conference will be too.</p>
<p>Meanwhile - MatrixRTC isn’t just Element Call: Famedly showed off experimental interop with FluffyChat at
<a href="https://archive.fosdem.org/2024/schedule/event/fosdem-2024-2876-matrixrtc-the-future-of-matrix-calls/">FOSDEM</a> back in
Feb, and Element showed off experimental interop with <a href="https://youtu.be/EPJM_lSmDpg?t=426">BigBlueButton</a> in August.
Given more and more conferencing tools are converging on LiveKit as a best-in-class SFU, it’s an amazing opportunity to
use Matrix and MatrixRTC to power the end-to-end-encryption and decentralisation and get standardised voip/video interop
from the outset.</p>
<p>For more info, see Timo’s talk from The Matrix Conference:</p>

<youtube-player video-id="OXPuYbfiXDQ"></youtube-player>

<p>That said, there are a few caveats right now:</p>
<ul>
<li>We do not have interoperability between legacy Matrix 1:1 voice/video calling and MatrixRTC (and it’s not clear
if/when we will get to it) - but Matrix 2.0 clients like Element X exclusively use MatrixRTC for VoIP/video,
including for 1:1 calls.  This is in order to only maintain one VoIP stack, and so that you get multidevice and
multiuser support for free, even in 1:1s.  As a result, we’re in the process of figuring out how to warn legacy
callers that MatrixRTC-only clients won’t be able to answer their calls (e.g.
<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4220">MSC4220</a>) - this hasn’t shipped yet.</li>
<li>iOS 18 broke CallKit + WebRTC, so Element X iOS has had to disable fancy OS-natively-integrated MatrixRTC calling;
and has a support issue open with Apple to try to solve this.</li>
<li>We’ve had some fun teething issues thanks to the volume of signalling in MatrixRTC exposing some sync bugs - these
are almost solved, but probably mean MatrixRTC should still be considered beta for a few more days until the fixes
land.</li>
</ul>
<h3 id="4-invisible-encryption">4. Invisible Encryption</h3>
<p>The final pillar of Matrix 2.0 is Invisible Encryption - <strong>making Matrix’s end-to-end encryption as seamless and
invisible as the centralised alternatives</strong> (Signal, WhatsApp, iMessage and friends).  This does <em>not</em> mean reducing
security in any way - just the opposite, in fact. It means:</p>
<ol>
<li>Ensuring that Unable To Decrypt (UTD) bugs never happen.  Huge amounts of work has gone into this over the course of
the year, especially via <a href="https://github.com/matrix-org/complement-crypto">complement-crypto</a> as a comprehensive
end-to-end-test suite for both matrix-rust-sdk and matrix-js-sdk based Matrix clients.  We are finally at the point
where UTDs are so rare that most people simply never see them, and any reports get jumped on (and complement-crypto
tests get written) whenever they emerge.  Anecdotally, I now get way more “waiting for message…” errors on WhatsApp
than I do on Matrix, these days!  For more details on the Hunt For UTDs, see Kegan’s talk from The Matrix Conference:</li>
</ol>

<youtube-player video-id="FHzh2Y7BABQ"></youtube-player>
<br>
<ol start="2">
<li>
<p>We are excluding non-cross-signed devices from Matrix (<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4153">MSC4153</a>).
The fact that Matrix ever supported the idea of users enabling encryption on a device without proving that they are
the valid owner by signing it (by verifying it with another device, or providing their recovery key/passphrase) is a
nasty hangover from back before we introduced cross-signing.  Nowadays, the fact that non-cross-signed devices exist
acts to reduce security and complicate UX and implementations with big scary red warnings whenever an unverified
device joins a conversation.  Instead, once MSC4153 lands, we’re going to simply exclude unverified devices
entirely - not encrypt to them, and not decrypt from them.  We can then get rid of all the confusing warnings
associated with them.</p>
</li>
<li>
<p>We’re also solving the confusing “grey shield” warnings: “the authenticity of this message cannot be confirmed on this
device” and similar.  These are avoidable warnings caused by message keys which can no longer be tracked back to the
original sender - e.g. if they’re restored from backup, or if the original sending device has been deleted.  We’re
fixing these with authenticated backup (<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4048">MSC4048</a>) and
including device keys on Olm events (<a href="https://github.com/matrix-org/matrix-spec-proposals/pull/4147">MSC4147</a>)
respectively.</p>
</li>
<li>
<p>Finally, we’re moving to Trust On First Use (TOFU). This means that even if you didn’t explicitly verify another user,
you still get warned if their identity changes (unlike previously, when it was ignored).  An initial implementation
just <a href="https://github.com/matrix-org/matrix-rust-sdk/pull/4068">landed in matrix-rust-sdk</a> a few weeks ago, and so
appropriate warnings at the application level should <a href="https://github.com/element-hq/element-x-ios/pull/3457">arrive shortly</a> -
matching the equivalent Signal or WhatsApp “this user’s identity has changed” warnings, albeit not yet synced between
devices.</p>
</li>
</ol>
<p>As you can probably tell, Invisible Encryption is something of a moving target; for instance, the scope could extend to
cover all scenarios where users might expect messages to be decryptable (e.g. Dehydrated Devices: the ability to
decrypt messages sent to you when you are not logged in anywhere - or Sharing Keys when new users join a room/space).
However, the 4 points above are the main ones, and they are in the process of landing right now.</p>
<p>The end result is already an immeasurable improvement in the reliability and robustness of Matrix’s encryption - and
once the remaining pieces land, the user experience of a Matrix client should be that the encryption is almost entirely
invisible to the user - unless something bad is happening; much like TLS.</p>
<p>Valere &amp; Patrick’s talk on Invisible Crypto from The Matrix Conference would get embedded here, but unfortunately the
audio was mangled - we’ll rerecord it and publish it shortly. In the meantime, you can find their slides 
<a href="https://2024.matrix.org/documents/talk_slides/LAB%20Green%202024-09-20%20Valere%20Fedronic%20Patrick%20Maier%20Invisible%20Crypto.pdf">here</a>.</p>
<h3 id="what-s-next">What’s next?</h3>
<p>Well, first of all we’re going to stop announcing Matrix 2.0 - it’s finally here (modulo the spec release)!</p>
<p>There’s obviously a bit of follow-up still to be done though:</p>
<ul>
<li>Getting MAS live on matrix.org</li>
<li>Gracefully handling the lack of interop between legacy Matrix calls and MatrixRTC</li>
<li>Landing the various remaining components of Invisible Crypto</li>
<li>Broadening the implementation base for these APIs, and rolling it out across the ecosystem</li>
</ul>
<p>Beyond Matrix 2.0, though, there’s a large pile of other areas which need attention:</p>
<ul>
<li>Improving state resolution.  We’re currently investigating a set of issues where the merge resolution algorithm has
misbehaved, and are planning a new room version to address it - watch this space for updates.</li>
<li>Trust and Safety.  Abuse is increasing concern, and moderation and trust &amp; safety tooling work has ended up fragmented
and balkanised.  The Governing Board is putting together a cross-ecosystem working group to try to address this -
again, watch this space for updates.</li>
<li>All the business-as-usual MSCs which have stacked up - Custom Emoji, Extensible Profiles, Custom Presence, etc.</li>
<li>It’d also be good to finally realise the full performance advantages of faster room joins…</li>
</ul>
<p>And then, in the longer term - what might Matrix 3.0 bring?  Honestly, at this point, it’s an open question.  Could it
be landing major Trust &amp; Safety changes in order to radically empower users to avoid and mitigate abuse?  Could it be
switching to MLS (or Decentralised MLS) for encryption?  Could it be the glorious return of P2P Matrix (if it was
funded)?  Could it even be figuring out if/how to converge with (or layer on top of) MIMI or other federation
protocols?  Answers on a postcard to <a href="http://matrix.to/#/#sct-office:matrix.org">#sct-office:matrix.org</a> please!</p>
<h3 id="conclusion">Conclusion</h3>
<p><strong>If ever there was a time to exhort your friends to give Matrix another go - this is it.</strong></p>
<p>Matrix 2.0 has been a long time coming, and we need to get the word out that the step change forwards has finally
arrived, and that apps built on Matrix 2.0 can seriously outperform the mainstream alternatives.  Ideally, this could
be Matrix’s “Firefox moment” - when from the ashes of old open source code, a new generation appears which can punch
its weight against the proprietary incumbents.</p>
<p>Right now the only Matrix 2.0 client is Element X (and Element Web/Desktop if you enable the experimental Simplified
Sliding Sync implementation in labs on develop/nightly builds) - see <a href="https://element.io/blog">element.io/blog</a> for full
details - but we expect to see at least matrix-rust-sdk and matrix-js-sdk based clients using the new APIs as a matter
of course in the coming months, and then hopefully everyone else too.</p>
<p>So: if you run a Matrix server, please consider
<a href="https://element-hq.github.io/matrix-authentication-service/">deploying MAS</a> to enable next-gen auth
(<a href="https://sspaeth.de/2024/08/tldr-matrix-nextcloud-setup/">Sebastien Spaeth’s blog</a> also has a good indie tutorial) -
and add <a href="https://github.com/element-hq/element-call">Element Call</a> to give MatrixRTC a try. Over the coming months we
should see more support in more Matrix distributions, until hopefully we will all be living in a Matrix 2.0 world!</p>
<p>Huge thanks are due to everyone who has helped design, build, and iterate on Matrix 2.0, and to everyone who has kept
the faith as we’ve put it all together. A special thanks also to BWI who helped fund much of Element’s work on this for
the benefit of Matrix as a whole.</p>
<p>Finally, if you want Matrix to prevail - <em>please</em> join the Foundation and support the project financially.  We urgently
need organisational members, especially after the costs of running The Matrix Conference, and particularly if your
organisation is commercially dependent on Matrix, you simply <em>must</em> become a member.  While it’s very flattering that
Matrix gets treated as a commons these days, without financial support the underlying Matrix project will die and your
project will fail.  Whereas if everyone building on Matrix supported us, we would be moving way faster and with fewer
constraints - so please get involved at <a href="https://matrix.org/support">matrix.org/support</a> and help.</p>
<p>Thanks for flying Matrix!</p>
<p>Matthew</p>

            <div>
                <p>
                    <h2>The Foundation needs you</h2>
                </p>
                <div>
                    <p>
                        The Matrix.org Foundation is a non-profit and only relies
                        on donations to operate. Its core mission is to maintain
                        the Matrix Specification, but it does much more than that.
                    </p>
                    <p>
                        It maintains the matrix.org homeserver and hosts several
                        bridges for free. It fights for our collective rights to
                        digital privacy and dignity.
                    </p>
                    <p><a href="https://matrix.org/support">Support us</a>
                </p></div>
            </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Speed, scale and reliability: 25 years of Google datacenter networking evolution (212 pts)]]></title>
            <link>https://cloud.google.com/blog/products/networking/speed-scale-reliability-25-years-of-data-center-networking</link>
            <guid>42031169</guid>
            <pubDate>Sun, 03 Nov 2024 04:29:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/networking/speed-scale-reliability-25-years-of-data-center-networking">https://cloud.google.com/blog/products/networking/speed-scale-reliability-25-years-of-data-center-networking</a>, See on <a href="https://news.ycombinator.com/item?id=42031169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>Rome wasn’t built in a day, and neither was Google’s network. But 25 years in, we’ve built out network infrastructure with scale and technical sophistication that’s nothing short of remarkable.</span></p>
<p><span>It’s all the more impressive because in the beginning, Google’s network infrastructure was relatively simple. But as our user base and the demand for our services grew exponentially, we realized that we needed a network that could handle an unprecedented scale of data and traffic, and that could adapt to dynamic traffic patterns as our workloads changed over time. This ignited a 25-year journey marked by numerous engineering innovations and milestones, ultimately leading to our current fifth-generation </span><a href="https://cloud.google.com/blog/topics/systems/the-evolution-of-googles-jupiter-data-center-network?e=48754805"><span>Jupiter data center network</span></a><span> architecture, which now scales to 13 Petabits/sec of bisectional bandwidth. To put this data rate in perspective, this network could support a video call (@1.5 Mb/s) for all 8 billion people on Earth!&nbsp;</span></p>
<p><span>Today, we have hundreds of Jupiter fabrics deployed around the world, simultaneously supporting hundreds of services, billions of active daily users, all of our Google Cloud customers, and some of the largest ML training and serving infrastructures in the world. I would like to share more about our journey as we look ahead to the next generation of data center network infrastructure.</span></p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h3><strong>Guiding principles</strong></h3>
<p><span>Our network evolution has been guided by a few key principles:</span></p>
<ul>
<li><strong>Anything, anywhere: </strong><span>Our data center networks support efficiency and simplicity by allowing large-scale jobs to be placed anywhere among 100k+ servers within the same network fabric, with high-speed access to needed storage and support services. This scale improves application performance for internal and external workloads and eliminates internal fragmentation.&nbsp;</span></li>
<li>
<p><strong>Predictable, low latency: </strong><span>We prioritize consistent performance and minimizing tail latency by provisioning bandwidth headroom, maintaining 99.999% network availability, and proactively managing congestion through end-host and fabric cooperation.</span></p>
</li>
<li>
<p><strong>Software-defined and systems-centric:</strong><span> Leveraging software-defined networking (SDN) for flexibility and agility, we qualify and globally release dozens of new features every two weeks across our global network.</span></p>
</li>
<li>
<p><strong>Incremental evolution and dynamic topology: </strong><span>Incremental evolution helps us to refresh the network granularly (rather than bringing it down wholesale), while dynamic topology helps us to continuously adapt to changing workload demands. The combination of optical circuit switching and SDN supports in-place physical upgrades and an ever-evolving, heterogeneous network that supports multiple hardware generations in a single fabric.</span></p>
</li>
<li>
<p><strong>Traffic engineering and application-centric QoS:</strong><span> Optimizing traffic flows and ensuring Quality of Service helps us tailor the network to each application's needs.</span></p>
</li>
</ul>
<p><span>Integrating across the above principles is the foundation for our work. The network is the foundation of reliability for all other compute services, from storage to AI. As such, the network must fail last and fail least. To support this foundational responsibility, we rigorously define and monitor every </span><span>bad minute<sup>1</sup></span><span> across hundreds of clusters and millions of ports across our global network. Our progress on reliability is such that our in-house, software-defined Jupiter networks deliver a factor of </span><a href="https://research.google/pubs/orion-googles-software-defined-networking-control-plane/" rel="noopener" target="_blank"><span>50x more reliability</span></a><span> than prior versions of our data center networks.&nbsp;</span></p>
<h3><strong>2015 - Jupiter, the first Petabit network&nbsp;</strong></h3>
<p><span>In a seminal paper, we</span><span> </span><a href="https://research.google/pubs/jupiter-rising-a-decade-of-clos-topologies-and-centralized-control-in-googles-datacenter-network/" rel="noopener" target="_blank"><span>showed</span></a><span> </span><span>that</span><span> </span><span>Jupiter data center networks scaled to 1.3 Pb/s of aggregate bandwidth by leveraging merchant switch silicon, Clos topologies and Software Defined Networking (SDN). This generation of Jupiter was the culmination of five generations of data center networks developed in house by the Google networking team. At that time, this data rate — in </span><span>one</span><span> Google data center — was more than the estimated aggregate IP traffic data rate for the global internet.&nbsp;</span></p>
<h3><strong>2022 - Enabling 6 Petabit per second</strong></h3>
<p><span>In 2022 we</span><span> </span><a href="https://cloud.google.com/blog/topics/systems/the-evolution-of-googles-jupiter-data-center-network"><span>announced</span></a><span> </span><span>that our Jupiter networks scaled to over 6 Pb/s, with deep integration of optical circuit switching (OCS), wave division multiplexing (WDM), and a highly scalable </span><a href="https://www.usenix.org/conference/nsdi21/presentation/ferguson" rel="noopener" target="_blank"><span>Orion</span></a><span> SDN controller. These technologies unlocked a range of advancements, including incremental network builds, enhanced performance, reduced costs, lower power consumption, dynamic traffic management, and seamless upgrades.</span></p>
<h3><strong>2023 - 13 Petabit per second network</strong></h3>
<p><span>We have further enhanced Jupiter to support native 400 Gb/s link speeds in the network core. The fundamental building block of Jupiter networks (called the </span><span>aggregation block</span><span>) now consists of 512 ports of 400 Gb/s of connectivity both to end hosts and to the rest of the data center, for an aggregate of 204.8 Tb/s of bidirectional non-blocking bandwidth per block. We support 64 such blocks for a total bisection bandwidth of 64*204.8 Tb/s = 13.1 Pb/s. This technology has been powering Google's production data centers for over a year, fueling the rapid advancement of artificial intelligence, machine learning, web search, and other data-intensive applications.</span></p>
<h3><strong>2024 and beyond - Extreme networking in the age of AI</strong></h3>
<p><span>While celebrating over two decades of innovation in data center networking, we’re already charting the course for the next generation of network infrastructure to support the age of AI. For example, our teams are busy working on networking infrastructure needs for our upcoming </span><a href="https://cloud.google.com/blog/products/compute/trillium-sixth-generation-tpu-is-in-preview"><span>A3 Ultra VMs</span></a><span>, that feature NVIDIA ConnectX-7 networking, </span><span>&nbsp;supports non-blocking 3.2 Tbps per server of GPU-to-GPU traffic over RoCE (RDMA over converged ethernet) and our future offerings based on </span><a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/" rel="noopener" target="_blank"><span>NVIDIA GB200 NVL72</span></a><span>. </span></p>
<p><span>Over the next few years, we will deliver significant advances in network scale and bandwidth, both per-port and network-wide. We will continue to push the boundaries of end-host integration, including the transport and congestion control stack, and streamline network stages to achieve even lower latency with tighter tails. Real-time topology engineering, deeper integration with the compute and storage stacks, and continued refinements to host-based load balancing techniques will further enhance network reliability and latency. With these innovations, our network will remain a cornerstone for the transformative applications and services that enrich the lives of our users throughout the world while simultaneously supporting the groundbreaking AI capabilities that power both our internal services and Google Cloud products.</span></p>
<p><span>We are excited to take on these challenges and opportunities to see what the next 25 years hold for Google networking!</span></p>
<h3><strong>Further resources</strong></h3>
<ul>
<li>
<p><span>Jupiter Rising: A Decade of Clos Topologies and Centralized Control in Google’s Datacenter Network, SIGCOMM ‘15 [</span><a href="https://research.google/pubs/jupiter-rising-a-decade-of-clos-topologies-and-centralized-control-in-googles-datacenter-network/" rel="noopener" target="_blank"><span>paper</span></a><span>]</span></p>
</li>
<ul>
<li>
<p><span>Journey of the first Jupiter datacenter network leveraging merchant switch silicon, Clos topologies and Software Defined Networking (SDN).</span></p>
</li>
<li>
<p><span>First deployed in production in 2012.</span></p>
</li>
</ul>
<li>
<p><span>Mission Apollo: Landing Optical Circuit Switching at Datacenter Scale, </span><a href="http://arxiv.org/" rel="noopener" target="_blank"><span>arxiv.org</span></a><span>, 2022 [</span><a href="https://arxiv.org/abs/2208.10041" rel="noopener" target="_blank"><span>paper</span></a><span>]</span></p>
</li>
<ul>
<li>
<p><span>First deployed in production in 2013.</span></p>
</li>
</ul>
<li>
<p><span>Orion: Google's Software-Defined Networking Control Plane. NSDI ‘21 [</span><a href="https://research.google/pubs/orion-googles-software-defined-networking-control-plane/" rel="noopener" target="_blank"><span>paper</span></a><span>]</span></p>
</li>
<ul>
<li>
<p><span>Google's high-performance, scalable, intent-based distributed SDN platform used in both datacenter and wide area networks.</span></p>
</li>
<li>
<p><span>First deployed in production in 2016.</span></p>
</li>
</ul>
<li>
<p><span>Jupiter Evolving: Transforming Google's Datacenter Network via Optical Circuit Switches and Software-Defined Networking, SIGCOMM ’22 [</span><a href="https://research.google/pubs/jupiter-evolving-transforming-googles-datacenter-network-via-optical-circuit-switches-and-software-defined-networking/" rel="noopener" target="_blank"><span>paper</span></a><span>]</span></p>
</li>
<ul>
<li>
<p><span>Enabling technologies: OCS (2013), Orion SDN (2016), 200Gbps networking (2020), direct-connect topology (2017), dynamic traffic engineering (2018), dynamic topology engineering (2021).</span></p>
</li>
</ul>
<li>
<p><span>Swift: Delay is Simple and Effective for Congestion Control in the Datacenter, SIGCOMM ‘20 [</span><a href="https://research.google/pubs/swift-delay-is-simple-and-effective-for-congestion-control-in-the-datacenter/" rel="noopener" target="_blank"><span>paper</span></a><span>]</span></p>
</li>
<ul>
<li>
<p><span>Swift, a congestion control protocol using hardware timestamps and AIMD control with a delay target, delivers excellent performance in Google datacenters with low flow completion times for short RPCs and high throughput for long RPCs.</span></p>
</li>
<li>
<p><span>First deployed in production in 2017</span></p>
</li>
</ul>
<li>
<p><span>PLB: Congestion Signals are Simple and Effective for Network Load Balancing, SIGCOMM ‘22 [</span><a href="https://research.google/pubs/plb-congestion-signals-are-simple-and-effective-for-network-load-balancing/" rel="noopener" target="_blank"><span>paper</span></a><span>]</span></p>
</li>
<ul>
<li>
<p><span>Protective Load Balancing (PLB) is a simple, effective host-based load balancing design that reduces network congestion and improves performance by randomly changing paths for congested connections, preferring to repath after idle periods to minimize packet reordering.</span></p>
</li>
<li>
<p><span>First deployed in production in 2020</span></p>
</li>
</ul>
</ul>
<hr>
<p><sup><em><span>1. Any minute where a statistically significant number of network flows in the data center network experience a total or partial outage above a defined threshold.</span></em></sup></p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/networking" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/networking" track-metadata-module="tag list" track-metadata-module_headline="posted in">Networking</a></li><li><a href="https://cloud.google.com/blog/topics/systems" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/systems" track-metadata-module="tag list" track-metadata-module_headline="posted in">Systems</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ractor – a Rust Actor Framework (129 pts)]]></title>
            <link>https://slawlor.github.io/ractor/quickstart/</link>
            <guid>42030625</guid>
            <pubDate>Sun, 03 Nov 2024 01:47:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slawlor.github.io/ractor/quickstart/">https://slawlor.github.io/ractor/quickstart/</a>, See on <a href="https://news.ycombinator.com/item?id=42030625">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          


        </header>
      

      <section itemprop="text">
        
          
        
        <h2 id="some-notations-to-keep-in-mind">Some notations to keep in mind</h2>

<p>While working through this quickstart, a few notations we want to clarify for readers.</p>

<h3 id="messaging-actors">Messaging actors</h3>

<p>Since we’re trying to model as best we can around <a href="https://www.erlang.org/doc/man/gen_server.html#call-2">Erlang’s practices</a>, message sends in
Ractor can occur in 2 ways, first-and-forget and waiting on a reply. Their notations however follow the Erlang naming schemes of “cast” and “call”
respectively.</p>

<h2 id="installation">Installation</h2>

<p>Install <code>ractor</code> by adding the following to your Cargo.toml dependencies</p>

<div><pre><code><span>[dependencies]</span>
<span>ractor</span> <span>=</span> <span>"0.9"</span>
</code></pre></div>

<h2 id="your-first-actor">Your first actor</h2>

<p>We have to, of course, start with the iconic “Hello world” sample. We want to build an actor
that’s going to print “Hello world” for every message sent to it. Let’s begin by defining our
actor and filling in the necessary bits. We’ll start with out message definition</p>

<div><pre><code><span>pub</span> <span>enum</span> <span>MyFirstActorMessage</span> <span>{</span>
    <span>/// Print's hello world</span>
    <span>PrintHelloWorld</span><span>,</span>
<span>}</span>
</code></pre></div>

<p>Then we follow up with the most basic required actor definition</p>

<div><pre><code><span>use</span> <span>ractor</span><span>::{</span><span>Actor</span><span>,</span> <span>ActorRef</span><span>,</span> <span>ActorProcessingErr</span><span>};</span>

<span>pub</span> <span>struct</span> <span>MyFirstActor</span><span>;</span>

<span>#[async_trait::async_trait]</span>
<span>impl</span> <span>Actor</span> <span>for</span> <span>MyFirstActor</span> <span>{</span>
    <span>type</span> <span>State</span> <span>=</span> <span>();</span>
    <span>type</span> <span>Msg</span> <span>=</span> <span>MyFirstActorMessage</span><span>;</span>
    <span>type</span> <span>Arguments</span> <span>=</span> <span>();</span>

    <span>async</span> <span>fn</span> <span>pre_start</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_myself</span><span>:</span> <span>ActorRef</span><span>&lt;</span><span>Self</span><span>::</span><span>Msg</span><span>&gt;</span><span>,</span> <span>_arguments</span><span>:</span> <span>Self</span><span>::</span><span>Arguments</span><span>)</span>
        <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>::</span><span>State</span><span>,</span> <span>ActorProcessingErr</span><span>&gt;</span> 
    <span>{</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>Let’s break down what we’re doing here, firstly we need our actor’s struct-type which we’re calling <code>MyFirstActor</code>.
We are then defining our <code>Actor</code> behavior, which minimally needs to define three types</p>

<ol>
  <li><code>State</code> - The “state” of the actor, for stateless actors this can be simply <code>()</code> denoting that the actor has no mutable state</li>
  <li><code>Msg</code> - The actor’s message type.</li>
  <li><code>Arguments</code> - Startup arguments which are consumed by <code>pre_start</code> in order to construct initial state. This is helpful for say a
TCP actor which is spawned from a TCP listener actor. The listener needs to pass the owned stream to the new actor, and <code>Arguments</code> is
there to facilitate that so the other actor can properly build it’s state without <code>clone()</code>ing structs with potential side effects.</li>
</ol>

<p>Lastly we are defining the actor’s startup routine in <code>pre_start</code> which emits the initial state of the actor upon success. Once this
is run, your actor is alive and healthy just waiting for messages to be received!</p>

<p><strong>Well that’s all fine and dandy, but how is this going to print hello world?!</strong> Well we haven’t defined that bit yet, we need to
wire up a message handler. Let’s do that!</p>

<div><pre><code><span>#[async_trait::async_trait]</span>
<span>impl</span> <span>Actor</span> <span>for</span> <span>MyFirstActor</span> <span>{</span>
    <span>type</span> <span>State</span> <span>=</span> <span>();</span>
    <span>type</span> <span>Msg</span> <span>=</span> <span>MyFirstActorMessage</span><span>;</span>
    <span>type</span> <span>Arguments</span> <span>=</span> <span>();</span>

    <span>async</span> <span>fn</span> <span>pre_start</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_myself</span><span>:</span> <span>ActorRef</span><span>&lt;</span><span>Self</span><span>::</span><span>Msg</span><span>&gt;</span><span>,</span> <span>_arguments</span><span>:</span> <span>Self</span><span>::</span><span>Arguments</span><span>)</span>
        <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>::</span><span>State</span><span>,</span> <span>ActorProcessingErr</span><span>&gt;</span>
    <span>{</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>

    <span>async</span> <span>fn</span> <span>handle</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_myself</span><span>:</span> <span>ActorRef</span><span>&lt;</span><span>Self</span><span>::</span><span>Msg</span><span>&gt;</span><span>,</span> <span>message</span><span>:</span> <span>Self</span><span>::</span><span>Msg</span><span>,</span> <span>_state</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Self</span><span>::</span><span>State</span><span>)</span> 
        <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>ActorProcessingErr</span><span>&gt;</span>
    <span>{</span>
        <span>match</span> <span>message</span> <span>{</span>
            <span>MyFirstActorMessage</span><span>::</span><span>PrintHelloWorld</span> <span>=&gt;</span> <span>{</span>
                <span>println!</span><span>(</span><span>"Hello world!"</span><span>);</span>
            <span>}</span>
        <span>}</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>Ok now that looks better! Here we’ve added the message handler <code>handle()</code> method which will be executed for every message received in
the queue.</p>

<h2 id="all-together-now">All together now</h2>

<p>Let’s wire it all up into a proper program now.</p>

<div><pre><code><span>#[tokio::main]</span>
<span>async</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>// Build an ActorRef along with a JoinHandle which lives for the life of the </span>
    <span>// actor. Most of the time we drop this handle, but it's handy in the </span>
    <span>// main function to wait for clean actor shut-downs (all stop handlers will</span>
    <span>// have completed)</span>
    <span>let</span> <span>(</span><span>actor</span><span>,</span> <span>actor_handle</span><span>)</span> <span>=</span> <span>Actor</span><span>::</span><span>spawn</span><span>(</span><span>None</span><span>,</span> <span>MyFirstActor</span><span>,</span> <span>())</span><span>.await</span><span>.expect</span><span>(</span><span>"Actor failed to start"</span><span>);</span>
    
    <span>for</span> <span>_i</span> <span>in</span> <span>0</span><span>..</span><span>10</span> <span>{</span>
        <span>// Sends a message, with no reply</span>
        <span>actor</span><span>.cast</span><span>(</span><span>MyFirstActorMessage</span><span>::</span><span>PrintHelloWorld</span><span>)</span><span>.expect</span><span>(</span><span>"Failed to send message to actor"</span><span>);</span>
    <span>}</span>

    <span>// give a little time to print out all the messages</span>
    <span>tokio</span><span>::</span><span>time</span><span>::</span><span>sleep</span><span>(</span><span>tokio</span><span>::</span><span>time</span><span>::</span><span>Duration</span><span>::</span><span>from_millis</span><span>(</span><span>100</span><span>))</span><span>.await</span><span>;</span>

    <span>// Cleanup</span>
    <span>actor</span><span>.stop</span><span>(</span><span>None</span><span>);</span>
    <span>actor_handle</span><span>.await</span><span>.unwrap</span><span>();</span>
<span>}</span>
</code></pre></div>

<h2 id="adding-state">Adding State</h2>

<p>Now what if we wanted to ask the actor for some information? Like the number of hello-worlds that it has printed thus far
in its lifecycle, let’s see what that might look like.</p>

<div><pre><code><span>use</span> <span>ractor</span><span>::{</span><span>Actor</span><span>,</span> <span>ActorRef</span><span>,</span> <span>ActorProcessingErr</span><span>,</span> <span>RpcReplyPort</span><span>};</span>

<span>pub</span> <span>enum</span> <span>MyFirstActorMessage</span> <span>{</span>
    <span>/// Print's hello world</span>
    <span>PrintHelloWorld</span><span>,</span>
    <span>/// Replies with how many hello worlds have occurred</span>
    <span>HowManyHelloWorlds</span><span>(</span><span>RpcReplyPort</span><span>&lt;</span><span>u16</span><span>&gt;</span><span>),</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>MyFirstActor</span><span>;</span>

<span>#[async_trait::async_trait]</span>
<span>impl</span> <span>Actor</span> <span>for</span> <span>MyFirstActor</span> <span>{</span>
    <span>type</span> <span>State</span> <span>=</span> <span>u16</span><span>;</span>
    <span>type</span> <span>Msg</span> <span>=</span> <span>MyFirstActorMessage</span><span>;</span>
    <span>type</span> <span>Arguments</span> <span>=</span> <span>();</span>

    <span>async</span> <span>fn</span> <span>pre_start</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_myself</span><span>:</span> <span>ActorRef</span><span>&lt;</span><span>Self</span><span>::</span><span>Msg</span><span>&gt;</span><span>,</span> <span>_arguments</span><span>:</span> <span>Self</span><span>::</span><span>Arguments</span><span>)</span>
        <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>::</span><span>State</span><span>,</span> <span>ActorProcessingErr</span><span>&gt;</span>
    <span>{</span>
        <span>Ok</span><span>(</span><span>0</span><span>)</span>
    <span>}</span>

    <span>async</span> <span>fn</span> <span>handle</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_myself</span><span>:</span> <span>ActorRef</span><span>&lt;</span><span>Self</span><span>::</span><span>Msg</span><span>&gt;</span><span>,</span> <span>message</span><span>:</span> <span>Self</span><span>::</span><span>Msg</span><span>,</span> <span>state</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Self</span><span>::</span><span>State</span><span>)</span> 
        <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>ActorProcessingErr</span><span>&gt;</span>
    <span>{</span>
        <span>match</span> <span>message</span> <span>{</span>
            <span>MyFirstActorMessage</span><span>::</span><span>PrintHelloWorld</span> <span>=&gt;</span> <span>{</span>
                <span>println!</span><span>(</span><span>"Hello world!"</span><span>);</span>
                <span>*</span><span>state</span> <span>+=</span> <span>1</span><span>;</span>
            <span>}</span>
            <span>MyFirstActorMessage</span><span>::</span><span>HowManyHelloWorlds</span><span>(</span><span>reply</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>if</span> <span>reply</span><span>.send</span><span>(</span><span>*</span><span>state</span><span>)</span><span>.is_err</span><span>()</span> <span>{</span>
                    <span>println!</span><span>(</span><span>"Listener dropped their port before we could reply"</span><span>);</span>
                <span>}</span>
            <span>}</span>
        <span>}</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>There’s a bit to unpack here, so let’s start with the basics.</p>

<ol>
  <li>We changed the type of the <code>Actor::State</code> to be a <code>u16</code> so that the actor could maintain some internal state which is the count of the number of times it’s printed “Hello world”</li>
  <li>We changed the hello-world message handling to increment the state every time it prints</li>
  <li>We added a new message type <code>MyFirstActorMessage::HowManyHelloWorlds</code> which has an argument of type <code>RpcReplyPort</code>. This is one of the primary ways actors can inter-communicate, via remote procedure calls. This call is a message which provides the response channel (the “port”) as an argument, so the receiver doesn’t need to know who asked. We’ll look at how we construct this in a bit</li>
  <li>We added a hander match arm for this message type, which sends the reply back when requested.</li>
</ol>

<h3 id="running-a-stateful-sample">Running a stateful sample</h3>

<p>Very similar to the non-stateful example, we’ll wire it up as such!</p>

<div><pre><code><span>#[tokio::main]</span>
<span>async</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>// Build an ActorRef along with a JoinHandle which lives for the life of the </span>
    <span>// actor. Most of the time we drop this handle, but it's handy in the </span>
    <span>// main function to wait for clean actor shut-downs (all stop handlers will</span>
    <span>// have completed)</span>
    <span>let</span> <span>(</span><span>actor</span><span>,</span> <span>actor_handle</span><span>)</span> <span>=</span> 
        <span>Actor</span><span>::</span><span>spawn</span><span>(</span><span>None</span><span>,</span> <span>MyFirstActor</span><span>,</span> <span>())</span>
            <span>.await</span>
            <span>.expect</span><span>(</span><span>"Actor failed to start"</span><span>);</span>
    
    <span>for</span> <span>_i</span> <span>in</span> <span>0</span><span>..</span><span>10</span> <span>{</span>
        <span>// Sends a message, with no reply</span>
        <span>actor</span><span>.cast</span><span>(</span><span>MyFirstActorMessage</span><span>::</span><span>PrintHelloWorld</span><span>)</span>
            <span>.expect</span><span>(</span><span>"Failed to send message to actor"</span><span>);</span>
    <span>}</span>

    <span>let</span> <span>hello_world_count</span> <span>=</span> 
        <span>ractor</span><span>::</span><span>call_t!</span><span>(</span><span>actor</span><span>,</span> <span>MyFirstActorMessage</span><span>::</span><span>HowManyHelloWorlds</span><span>,</span> <span>100</span><span>)</span>
        <span>.expect</span><span>(</span><span>"RPC failed"</span><span>);</span>
    
    <span>println!</span><span>(</span><span>"Actor replied with {} hello worlds!"</span><span>,</span> <span>hello_world_count</span><span>);</span>

    <span>// Cleanup</span>
    <span>actor</span><span>.stop</span><span>(</span><span>None</span><span>);</span>
    <span>actor_handle</span><span>.await</span><span>.unwrap</span><span>();</span>
<span>}</span>
</code></pre></div>

<p><strong>WHOA</strong> what is <code>call_t!</code>?! That’s a handy macro which constructs our RPC call for us! There’s are three macro variants to ease development use for actor messaging</p>

<ol>
  <li><code>cast!</code> - alias of <code>actor.cast(MESG)</code>, simply send a message to the actor non-blocking</li>
  <li><code>call!</code> - alias of <code>actor.call(|reply| MESG(reply))</code> which builds our message for us without having to provide a lambda function to take the reply port as an argument to construct the message type. We don’t need to actually build &amp; wait on the port, the RPC functionality will do that for us.</li>
  <li><code>call_t!</code> - Same as <code>call!</code> but with a timeout argument</li>
</ol>

<p>Checkout <a href="https://docs.rs/ractor/latest/ractor/macro.call.html">docs.rs on RPCs</a> for more detailed information on these macros.</p>

<p>In this brief example, we’re having our actor send our 10 messages, and then sending a final query message to read
the current count and print it. We’re additionally giving it 100ms to execute (hence the use of <code>call_t!</code>) or return
a timeout result.</p>

        
      </section>

      

      

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Security flaws found in all Nvidia GeForce GPUs. Update drivers ASAP (193 pts)]]></title>
            <link>https://www.pcworld.com/article/2504035/security-flaws-found-in-all-nvidia-geforce-gpus-update-drivers-asap.html</link>
            <guid>42030463</guid>
            <pubDate>Sun, 03 Nov 2024 01:06:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcworld.com/article/2504035/security-flaws-found-in-all-nvidia-geforce-gpus-update-drivers-asap.html">https://www.pcworld.com/article/2504035/security-flaws-found-in-all-nvidia-geforce-gpus-update-drivers-asap.html</a>, See on <a href="https://news.ycombinator.com/item?id=42030463">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="link_wrapped_content">




<p>Graphics card manufacturer Nvidia is currently issuing a warning to all owners of GeForce GPUs. According to an <a href="https://go.skimresources.com/?id=111346X1569483&amp;xs=1&amp;url=https://nvidia.custhelp.com/app/answers/detail/a_id/5586&amp;xcust=2-1-2504035-1-0-0&amp;sref=https://www.pcworld.com/article/2504035/security-flaws-found-in-all-nvidia-geforce-gpus-update-drivers-asap.html" target="_blank" rel="nofollow">Nvidia security bulletin</a>, several security vulnerabilities requiring urgent attention have been discovered in the company’s own display drivers and other software.</p>



<p>A total of eight vulnerabilities are listed, all of them with a “High” severity rating. If you have an Nvidia GeForce GPU, you need to act now.</p>



<h2 id="the-scope-of-the-security-flaws">The scope of the security flaws</h2>



<p>According to Nvidia, it’s possible for attackers to gain access to your entire system by exploiting one of the vulnerabilities. With this kind of access, hackers can not only infiltrate and execute malicious code in your PC, but also read and steal personal data.</p>



<p>The vulnerabilities affect GeForce software, Nvidia RTX, Quadro, NVS, and Tesla, both under Windows and Linux.</p>

		
			
			


<p>Nvidia hasn’t explicitly said whether any of these vulnerabilities are already being exploited in the wild. However, as all GeForce graphics cards are affected, it’s probably a far-reaching problem.</p>



<h2 id="urgent-steps-for-geforce-users">Urgent steps for GeForce users</h2>



<p>To address these security vulnerabilities, you’ll need the latest <strong>Nvidia GeForce drivers with version 566.03 for Windows</strong> and versions 565.57.01, 550.127.05, and 535.216.01 for Linux. Nvidia also points out that some distributors also supply the necessary security updates as versions 565.92, 561.03, 556.35, and 553.05.</p>



<p>For Nvidia RTX, Quadro, and NVS, update versions 566.03, 553.24, and 538.95 will address the security issues.</p>



<p>You can search for the appropriate updates using <a href="https://go.skimresources.com/?id=111346X1569483&amp;xs=1&amp;url=https://www.nvidia.com/en-us/drivers/&amp;xcust=2-1-2504035-1-0-0&amp;sref=https://www.pcworld.com/article/2504035/security-flaws-found-in-all-nvidia-geforce-gpus-update-drivers-asap.html" target="_blank" rel="nofollow">Nvidia’s Manual Driver Search tool</a> and download them directly. The latest drivers are also offered in the Nvidia App and GeForce Experience app.</p>



<blockquote>
<p><strong>Further reading:</strong> <a href="https://www.pcworld.com/article/2457257/nvidia-app-tweaks-5-changes-every-geforce-gamer-should-make-asap.html">Important Nvidia App tweaks for GeForce gamers</a></p>
</blockquote>

</div><p>This article originally appeared on our sister publication <a href="https://www.pcwelt.de/" rel="noreferrer noopener" target="_blank">PC-WELT</a> and was translated and localized from German.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spann: Highly-Efficient Billion-Scale Approximate Nearest Neighbor Search (2021) (112 pts)]]></title>
            <link>https://arxiv.org/abs/2111.08566</link>
            <guid>42028873</guid>
            <pubDate>Sat, 02 Nov 2024 20:02:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2111.08566">https://arxiv.org/abs/2111.08566</a>, See on <a href="https://news.ycombinator.com/item?id=42028873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2111.08566">View PDF</a></p><blockquote>
            <span>Abstract:</span>The in-memory algorithms for approximate nearest neighbor search (ANNS) have achieved great success for fast high-recall search, but are extremely expensive when handling very large scale database. Thus, there is an increasing request for the hybrid ANNS solutions with small memory and inexpensive solid-state drive (SSD). In this paper, we present a simple but efficient memory-disk hybrid indexing and search system, named SPANN, that follows the inverted index methodology. It stores the centroid points of the posting lists in the memory and the large posting lists in the disk. We guarantee both disk-access efficiency (low latency) and high recall by effectively reducing the disk-access number and retrieving high-quality posting lists. In the index-building stage, we adopt a hierarchical balanced clustering algorithm to balance the length of posting lists and augment the posting list by adding the points in the closure of the corresponding clusters. In the search stage, we use a query-aware scheme to dynamically prune the access of unnecessary posting lists. Experiment results demonstrate that SPANN is 2$\times$ faster than the state-of-the-art ANNS solution DiskANN to reach the same recall quality $90\%$ with same memory cost in three billion-scale datasets. It can reach $90\%$ recall@1 and recall@10 in just around one millisecond with only 32GB memory cost. Code is available at: {\footnotesize\color{blue}{\url{<a href="https://github.com/microsoft/SPTAG" rel="external noopener nofollow">this https URL</a>}}}.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Jingdong Wang [<a href="https://arxiv.org/show-email/9fb7c74e/2111.08566" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 5 Nov 2021 06:28:15 UTC (127 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Next Generation Out of Band Garbage Collection (153 pts)]]></title>
            <link>https://railsatscale.com/2024-10-23-next-generation-oob-gc/</link>
            <guid>42028833</guid>
            <pubDate>Sat, 02 Nov 2024 19:57:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://railsatscale.com/2024-10-23-next-generation-oob-gc/">https://railsatscale.com/2024-10-23-next-generation-oob-gc/</a>, See on <a href="https://news.ycombinator.com/item?id=42028833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In 2023, <a href="https://shopify.engineering/adventures-in-garbage-collection">I wrote about how we’ve tuned Ruby’s garbage collector for Shopify’s monolith</a>,
including how we implemented out-of-band garbage collection to reduce the impact of major collection on latency.</p>

<p>While the latency improvements were massive, we weren’t entirely satisfied with the heuristics used to trigger out-of-band
garbage collection. It was purely based on averages, so we had to trade latency for capacity.
More importantly, it didn’t fully eliminate major collection from request cycles, it only made it very rare.</p>

<p>But <a href="https://github.com/rails/rails/issues/50449#issuecomment-1870515141">in December 2023, while discussing with Koichi Sasada, we came up with a new idea</a>.</p>

<h2 id="disabling-major-gc-entirely">Disabling Major GC Entirely</h2>

<p>If we want major GC to never trigger during a request cycle, why not disable it entirely?</p>

<p>In March 2024, during our annual Ruby Infrastructure team gathering, we fleshed out the details of the new feature we wanted,
and Matthew Valentine-House started working on a proof of concept, which we then deployed to a small percentage of our production servers to see how effective it could be.</p>

<p>First, we needed a way to entirely prevent the Garbage Collector from automatically performing a major collection, but
also to stop promoting objects to the old generation. Ideally in a web application, aside from some in-memory caches, no object allocated as part of a request should survive longer than the request itself.
Any object that does is probably something that should be eagerly loaded during boot, or some state that is leaking between requests.
As such, any object promoted to the old generation during a request cycle is very unlikely to be immortal, so promoting it is wasteful.</p>

<p>We also needed a way to ask the GC whether it would have run a major collection so that we could manually trigger it outside
of the request cycle, and only exactly as much as needed.</p>

<p><a href="https://bugs.ruby-lang.org/issues/20443">The initial proposal was for three new methods, <code>GC.disable_major</code>, <code>GC.enable_major</code> and <code>GC.needs_major?</code></a>.</p>

<p>After some back and forth with other Ruby committers, it became a single new method: <code>GC.config(rgengc_allow_full_mark: true/false)</code>.
We also exposed a new key in <code>GC.latest_gc_info</code>, <code>:needs_major_by</code>, for use in checking whether a major GC needs to run: <code>GC.latest_gc_info(:needs_major_by)</code>.</p>

<p>This new feature was released as part of Ruby <code>3.4.0-preview2</code>.</p>

<h2 id="effectiveness">Effectiveness</h2>

<p>Since Shopify monolith runs on Ruby’s master branch, we don’t have to wait for the December release to use these new features,
so recently I went to work on enabling the new out-of-band GC implementation on 50% of production servers, and the results are amazing on all metrics.</p>

<p>First, as we anticipated, the time spent in GC during request cycles at the very tail end (p95/p99/p99.99) dropped very significantly.</p>

<p>However, more surprisingly, it also improved median latency:</p>

<p><img src="https://railsatscale.com/2024-10-23-next-generation-oob-gc/images/oobgc-gctime-speedup.png" alt=""></p>

<p><img src="https://railsatscale.com/2024-10-23-next-generation-oob-gc/images/oobgc-gctime.png" alt=""></p>

<p>The overall impact on service latency is of course more modest, but still very nice with a 5% reduction of average latency and a 10% reduction of p99 latency:</p>

<p><img src="https://railsatscale.com/2024-10-23-next-generation-oob-gc/images/oobgc-latency-impact.png" alt=""></p>

<p>The impact on capacity, however, is less significant than we had hoped for. During the day, when there are frequent deploys, this doesn’t make much of a difference.
However when deploys pause for a few hours, the new out-of-band collector runs much less often than the old implementation:</p>

<p><img src="https://railsatscale.com/2024-10-23-next-generation-oob-gc/images/oobgc-count.png" alt=""></p>

<h2 id="implementation">Implementation</h2>

<p>In addition, to be more effective, this new implementation is also radically simple, thanks to the hooks provided by <a href="https://github.com/Shopify/pitchfork">Pitchfork</a></p>

<div><pre><code><span># pitchfork.conf.rb</span>

<span>after_worker_fork</span> <span>do</span> <span>|</span><span>_server</span><span>,</span> <span>_worker</span><span>|</span>
  <span>GC</span><span>.</span><span>config</span><span>(</span><span>rgengc_allow_full_mark: </span><span>false</span><span>)</span>
<span>end</span>

<span>after_request_complete</span> <span>do</span> <span>|</span><span>_server</span><span>,</span> <span>_worker</span><span>,</span> <span>_rack_env</span><span>|</span>
  <span>if</span> <span>GC</span><span>.</span><span>latest_gc_info</span><span>(</span><span>:need_major_by</span><span>)</span>
    <span>GC</span><span>.</span><span>start</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<h2 id="next-steps">Next Steps?</h2>

<p>Now that the major collection is out of the picture, the next step is to look at the minor collections.</p>

<p>We can’t disable minor collection, as otherwise large requests that allocate a lot would run out of memory. However, we could try to
additionally use heuristics from <code>GC.stat</code> to eagerly trigger minor garbage collection out-of-band, so that the majority of requests don’t have
to spend any time at all in GC.</p>

<p>But the potential gains are much smaller because minor collection is quite fast even on our monolith.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
    </channel>
</rss>