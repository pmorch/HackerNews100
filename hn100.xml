<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 01 Feb 2026 03:30:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Swift is a more convenient Rust (233 pts)]]></title>
            <link>https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust</link>
            <guid>46841374</guid>
            <pubDate>Sat, 31 Jan 2026 22:05:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust">https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust</a>, See on <a href="https://news.ycombinator.com/item?id=46841374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a href="https://naman34.svbtle.com/swift-is-the-more-convenient-rust"></a>
<p><em>(originally published on my <a href="https://naman34.svbtle.com/swift-is-the-more-convenient-rust">old blog</a>)</em></p>
<p>I’ve been learning Rust lately.</p>
<p>Rust is one of the most loved languages out there, is fast, and has an amazing community. Rust invented the concept of ownership as a solution memory management issues without resorting to something slower like Garbage Collection or Reference Counting. But, when you don’t need to be quite as low level, it gives you utilities such as <code>Rc</code>, <code>Arc</code> and <code>Cow</code> to do reference counting and “clone-on-right” in your code. And, when you need to go lower-level still, you can use the <code>unsafe</code> system and access raw C pointers.</p>
<p>Rust also has a bunch of awesome features from functional languages like tagged enums, match expressions, first class functions and a powerful type system with generics.</p>
<p>Rust has an LLVM-based compiler which lets it compile to native code and WASM.</p>
<p>I’ve also been doing a bit of Swift programming for a couple of years now. And the more I learn Rust, the more I see a reflection of Swift. (I know that Swift stole a lot of ideas from Rust, I’m talking about my own perspective here).</p>
<p>Swift, too, has awesome features from functional languages like tagged enums, match expressions and first-class functions. It too has a very powerful type system with generics.</p>
<p>Swift too gives you complete type-safety without a garbage collector. By default, everything is a value type with “copy-on-write” semantics. But when you need extra speed you can opt into an ownership system and “move” values to avoid copying. And if you need to go even lower level, you can use the unsafe system and access raw C pointers.</p>
<p>Swift has an LLVM-based compiler which lets it compile to native code and WASM.</p>
<a id="deja-vu" href="#deja-vu"><h3><span>#</span>Deja Vu?</h3></a>
<p>You’re probably feeling like you just read the same paragraphs twice. This is no accident. Swift is extremely similar to Rust and has most of the same feature-set. But there is a very big difference is <em>perspective</em>. If you consider the default memory model, this will start to make a lot of sense.</p>
<a id="rust-is-bottom-up-swift-is-top-down" href="#rust-is-bottom-up-swift-is-top-down"><h3><span>#</span>Rust is bottom-up, Swift is top-down.</h3></a>
<p>Rust is a low-level systems language at heart, but it gives you the tools to go higher level. Swift starts at a high level and gives you the ability to go low-level.</p>
<p>The most obvious example of this is the memory management model. Swift use value-types by default with <code>copy-on-write</code> semantics. This is the equivalent of using <code>Cow&lt;&gt;</code> for all your values in Rust. But defaults matter. Rust makes it easy to use “moved” and “borrowed” values but requires extra ceremony to use <code>Cow&lt;&gt;</code> values as you need to “unwrap” them <code>.as_mutable()</code> to actually use the value within. Swift makes these Copy-on-Write values easy to use and instead requires extra ceremony to use borrowing and moving instead. Rust is faster by default, Swift is simpler and easier by default.</p>
<a id="swift-takes-rusts-ideas-and-hides-them-in-c-like-syntax" href="#swift-takes-rusts-ideas-and-hides-them-in-c-like-syntax"><h3><span>#</span>Swift takes Rust’s ideas and hides them in C-like syntax.</h3></a>
<p>Swift’s syntax is a masterclass in taking awesome functional language concepts and hiding them in C-like syntax to trick the developers into accepting them.</p>
<p>Consider <code>match</code> statements. This is what a match statement looks like in Rust:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>Coin</span><span> {</span><br></span></p><p><span><span>    Penny</span><span>,</span><br></span></p><p><span><span>    Nickel</span><span>,</span><br></span></p><p><span><span>    Dime</span><span>,</span><br></span></p><p><span><span>    Quarter</span><span>,</span><br></span></p><p><span><span>}</span><br></span></p><p><span><span>fn </span><span>value_in_cents</span><span>(</span><span>coin</span><span>: </span><span>Coin</span><span>) -&gt; </span><span>u8</span><span> {</span><br></span></p><p><span><span>    match </span><span>coin</span><span> {</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Penny</span><span> =&gt; </span><span>1</span><span>,</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Nickel</span><span> =&gt; </span><span>5</span><span>,</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Dime</span><span> =&gt; </span><span>10</span><span>,</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Quarter</span><span> =&gt; </span><span>25</span><span>,</span><br></span></p><p><span><span>    }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>Here’s how that same code would be written in Swift:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>Coin</span><span> {</span><br></span></p><p><span><span>    case </span><span>penny</span><br></span></p><p><span><span>    case </span><span>nickel</span><br></span></p><p><span><span>    case </span><span>dime</span><br></span></p><p><span><span>    case </span><span>quarter</span><br></span></p><p><span><span>}</span><br></span></p><p><span><span>func </span><span>valueInCents</span><span>(</span><span>coin</span><span>: Coin) -&gt; </span><span>Int</span><span> {</span><br></span></p><p><span><span>    switch</span><span> coin {</span><br></span></p><p><span><span>    case</span><span> .</span><span>penny</span><span>: </span><span>1</span><br></span></p><p><span><span>    case</span><span> .</span><span>nickel</span><span>: </span><span>5</span><br></span></p><p><span><span>    case</span><span> .</span><span>dime</span><span>: </span><span>10</span><br></span></p><p><span><span>    case</span><span> .</span><span>quarter</span><span>: </span><span>25</span><br></span></p><p><span><span>    }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>Swift doesn’t have a <code>match</code> statement or expression. It has a <code>switch</code> statement that developers are already familiar with. Except this <code>switch</code> statement is actually not a <code>switch</code> statement at all. It’s an expression. It doesn’t “fallthrough”. It does pattern matching. It’s just a <code>match</code> expression with a different name and syntax.</p>
<p>In fact, Swift treats <code>enums</code> as more than <em>just</em> types and lets you put methods directly on it:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>Coin</span><span> {</span><br></span></p><p><span><span>    case </span><span>penny</span><br></span></p><p><span><span>    case </span><span>nickel</span><br></span></p><p><span><span>    case </span><span>dime</span><br></span></p><p><span><span>    case </span><span>quarter</span><br></span></p><p><span><span>    func </span><span>valueInCents</span><span>() -&gt; </span><span>Int</span><span> {</span><br></span></p><p><span><span>        switch </span><span>self</span><span> {</span><br></span></p><p><span><span>        case</span><span> .</span><span>penny</span><span>: </span><span>1</span><br></span></p><p><span><span>        case</span><span> .</span><span>nickel</span><span>: </span><span>5</span><br></span></p><p><span><span>        case</span><span> .</span><span>dime</span><span>: </span><span>10</span><br></span></p><p><span><span>        case</span><span> .</span><span>quarter</span><span>: </span><span>25</span><br></span></p><p><span><span>        }</span><br></span></p><p><span><span>    }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<a id="optional-types" href="#optional-types"><h4><span>#</span>Optional Types</h4></a>
<p>Rust doesn’t have <code>null</code>, but it does have <code>None</code>. Swift has a <code>nil</code>, but it’s really just a <code>None</code> in hiding. Instead of an <code>Option&lt;T&gt;</code>, Swift let’s you use <code>T?</code>, but the compiler still forces you to check that the value is not <code>nil</code> before you can use it.</p>
<p>You get the same safety with more convenience since you can do this in Swift with an optional type:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>let</span><span> val: T?</span><br></span></p><p><span><span>if </span><span>let</span><span> val {</span><br></span></p><p><span><span>  // val is now of type `T`.</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>Also, you’re not forced to wrap every value with a <code>Some(val)</code> before returning it. The Swift compiler takes care of that for you. A <code>T</code> will transparently be converted into a <code>T?</code> when needed.</p>
<a id="error-handling" href="#error-handling"><h4><span>#</span>Error Handling</h4></a>
<p>Rust doesn’t have <code>try-catch</code>. Instead it has a <code>Result</code> type which contains the success and error types.</p>
<p>Swift doesn’t have a <code>try-catch</code> either, but it does have <code>do-catch</code> and you have to use <code>try</code> before calling a function that could throw. Again, this is just deception for those developers coming from C-like languages. Swift’s error handling works exactly like Rust’s behind the scenes, but it is hidden in a clever, familiar syntax.</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>func </span><span>usesErrorThrowingFunction</span><span>() </span><span>throws</span><span> {</span><br></span></p><p><span><span>  let</span><span> x = </span><span>try </span><span>thisFnCanThrow</span><span>()</span><br></span></p><p><span><span>}</span><br></span></p><p><span><span>func </span><span>handlesErrors</span><span>() {</span><br></span></p><p><span><span>  do</span><span> {</span><br></span></p><p><span><span>    let</span><span> x = </span><span>try </span><span>thisFnCanThrow</span><span>()</span><br></span></p><p><span><span>  } </span><span>catch </span><span>err</span><span> {</span><br></span></p><p><span><span>    // handle the `err` here.</span><br></span></p><p><span><span>  }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>This is very similar to how Rust let’s you use <code>?</code> at the end of statements to automatically forward errors, but you don’t have to wrap your success values in <code>Ok()</code>.</p>
<a id="rusts-compiler-catches-problems-swifts-compiler-solves-some-of-them" href="#rusts-compiler-catches-problems-swifts-compiler-solves-some-of-them"><h3><span>#</span>Rust’s compiler catches problems. Swift’s compiler solves some of them</h3></a>
<p>There are many common problems that Rust’s compiler will catch at compile time and even suggest solutions for you. The example that portrays this well is self-referencing enums.</p>
<p>Consider an enum that represents a tree. Since, it is a recursive type, Rust will force you to use something like <code>Box&lt;&gt;</code> for referencing a type within itself.</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>TreeNode</span><span>&lt;</span><span>T</span><span>&gt; {</span><br></span></p><p><span><span>    Leaf</span><span>(</span><span>T</span><span>),</span><br></span></p><p><span><span>    Branch</span><span>(</span><span>Vec</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>TreeNode</span><span>&lt;</span><span>T</span><span>&gt;&gt;&gt;),</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>(You could also us <code>Box&lt;Vec&lt;TreeNode&lt;T&gt;&gt;&gt;</code> instead)</p>
<p>This makes the problem explicit and forces you to deal with it directly. Swift is a little more, <em>automatic</em>.</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>indirect enum </span><span>TreeNode</span><span>&lt;</span><span>T</span><span>&gt; {</span><br></span></p><p><span><span>    case </span><span>leaf</span><span>(T)</span><br></span></p><p><span><span>    case </span><span>branch</span><span>([TreeNode&lt;T&gt;])</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p><strong>Note</strong>: that you still have to annotate this <code>enum</code> with the <code>indirect</code> keyword to indicate that it is recursive. But once you’ve done that, Swift’s compiler takes care of the rest. You don’t have to think about <code>Box&lt;&gt;</code> or <code>Rc&lt;&gt;</code>. The values just work normally.</p>
<a id="swift-is-less-pure" href="#swift-is-less-pure"><h3><span>#</span>Swift is less “pure”</h3></a>
<p>Swift was designed to replace Objective-C and needed to be able to interface with existing code. So, it has made a lot of pragmatic choices that makes it a much less “pure” and “minimalist” language. Swift is a pretty big language compared to Rust and has many more features built-in. However, Swift is designed with “progressive disclosure” in mind which means that just as soon as you think you’ve learned the language a little more of the iceberg pops out of the water.</p>
<p>Here are just <em>some</em> of the language features:</p>
<ul>
<li>Classes / Inhertence</li>
<li>async-await</li>
<li>async-sequences</li>
<li>actors</li>
<li>getters and setters</li>
<li>lazy properties</li>
<li>property wrappers</li>
<li>Result Builders (for building tree-like structures. e.g. HTML / SwiftUI)</li>
</ul>
<a id="convenience-has-its-costs" href="#convenience-has-its-costs"><h3><span>#</span>Convenience has its costs</h3></a>
<p>Swift is a far easier language to get started and productive with. The syntax is more familiar and a lot more is done for you automatically. But this really just makes Swift a higher-level language and it comes with the same tradeoffs.</p>
<p>By default, a Rust program is much faster than a Swift program. This is because Rust is fast by default, and <em>lets</em> you be slow, while Swift is easy by default and <em>lets</em> you be fast.</p>
<p>Based on this, I would say both languages have their uses. Rust is better for systems and embedded programming. It’s better for writing compilers and browser engines (Servo) and it’s better for writing entire operating systems.</p>
<p>Swift is better for writing UI and servers and some parts of compilers and operating systems. Over time I expect to see the overlap get bigger.</p>
<a id="the-cross-platform-problem" href="#the-cross-platform-problem"><h3><span>#</span>The “cross-platform” problem</h3></a>
<p>There is a perception that Swift is only a good language for Apple platforms. While this was once true, this is no longer the case and Swift is becoming increasingly a good cross-platform language. Hell, Swift even compiles to wasm, and the forks made by the swift-wasm team were merged back into Swift core earlier this year.</p>
<p>Swift on Windows is being used by The Browser Company to share code and bring the Arc browser to windows. Swift on Linux has long been supported by Apple themselves in order to push “Swift on Server”. Apple is directly sponsoring the Swift on Server conference.</p>
<p>This year Embedded Swift was also announced which is already being used on small devices like the Panic Playdate.</p>
<p>Swift website has been highlighting many of these projects:</p>
<ul>
<li><a href="https://www.swift.org/blog/swift-everywhere-windows-interop/">Swift on Windows</a></li>
<li><a href="https://www.swift.org/blog/embedded-swift-examples/">Embedded Swift</a></li>
<li><a href="https://www.swift.org/blog/adwaita-swift/">Gnome apps with Swift on Linux</a></li>
<li><a href="https://www.swift.org/blog/byte-sized-swift-tiny-games-playdate/">Swift on Playdate</a></li>
</ul>
<p>The browser company says that <a href="https://speakinginswift.substack.com/p/interoperability-swifts-super-power">Interoperability is Swift’s super power</a>.</p>
<p>And the Swift project has been trying make working with Swift a great experience outside of XCode with projects like an open source LSP and funding the the VSCode extension.</p>
<!-- -->
<!--$?--><template id="B:0"></template><!--/$-->
<a id="swift-is-not-a-perfect-language" href="#swift-is-not-a-perfect-language"><h3><span>#</span>Swift is not a perfect language.</h3></a>
<p>Compile times are (like Rust) quite bad. There is some amount of feature creep and the language is larger than it should be. Not all syntax feels familiar. The <a href="https://swiftpackageindex.com/">package ecosystem</a> isn’t nearly as rich as Rust.</p>
<p>But the “Swift is only for Apple platforms” is an old and tired cliche at this point. Swift is already a cross-platform, ABI-stable language with no GC, automatic Reference Counting and the option to opt into ownership for even more performance. Swift packages increasingly work on Linux. Foundation was ported to Swift, open sourced and made open source. It’s still early days for Swift as a good, more convenient, Rust alternative for cross-platform development, but it is here now. It’s no longer a future to wait for.</p><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nintendo DS code editor and scriptable game engine (103 pts)]]></title>
            <link>https://crl.io/ds-game-engine/</link>
            <guid>46839215</guid>
            <pubDate>Sat, 31 Jan 2026 18:27:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crl.io/ds-game-engine/">https://crl.io/ds-game-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=46839215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <header><p>2026</p></header> <br data-astro-cid-tkmlznkr=""> <section data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">TL;DR</p> <p data-astro-cid-tkmlznkr="">
I built a <strong data-astro-cid-tkmlznkr="">scriptable 3D game engine</strong> for the Nintendo DS so
      you can write and run games directly on the console itself. Written in <strong data-astro-cid-tkmlznkr="">C</strong> using
<strong data-astro-cid-tkmlznkr="">libnds</strong>, it compiles to a <strong data-astro-cid-tkmlznkr="">~100KB .nds ROM</strong>
that runs at <strong data-astro-cid-tkmlznkr="">60 FPS</strong>. Features a touch-based code editor
      on the bottom screen and real-time 3D rendering on the top screen. Ships
      with a working 3D pong game as the default script.
</p> </section> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr=""> <iframe src="https://www.youtube.com/embed/3NlipciOHcY?si=6oqYL7KYsNa2DzGI&amp;start=0" title="DS game engine video demo short clip" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-astro-cid-tkmlznkr=""></iframe> </p> </div> <h2 data-astro-cid-tkmlznkr="">What is it?</h2> <p data-astro-cid-tkmlznkr="">
I felt nostalgic for when I made my first games on an old TI-82 graphing
    calculator. So I tried bringing that whole experience to my Nintendo DS. A
    complete programming environment you can hold in your hands.
</p>  <p data-astro-cid-tkmlznkr="">
What you see is a <strong data-astro-cid-tkmlznkr="">scriptable game engine</strong> with a custom programming
    language featuring variables, loops, and conditionals. You write code using the
    bottom touchscreen, click play, and the game will execute in real-time on the
    top screen with full 3D rendering.
</p> <br data-astro-cid-tkmlznkr=""> <div> <figure data-astro-cid-tkmlznkr=""> <img src="https://crl.io/images/ds-game-engine-reddit.png" alt="" data-astro-cid-tkmlznkr=""> </figure> </div> <h2 data-astro-cid-tkmlznkr="">How it works</h2> <p data-astro-cid-tkmlznkr="">At a high level, the engine breaks down into three parts:</p> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">1. Top screen: 3D rendering (hardware accelerated)</h3> <p data-astro-cid-tkmlznkr="">
Uses the DS's 3D hardware to render colored cubes at 60 FPS. Each model has
    position (X, Y, Z), rotation angle, and color. The camera is fully
    controllable with position and yaw/pitch angles.
</p> <pre data-astro-cid-tkmlznkr="">// DS 3D rendering code (C + libnds)
glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(camX, camY, camZ,  // camera position
          camX + lookX, camY + lookY, camZ + lookZ,  // look target
          0, 1, 0);  // up vector</pre> <p data-astro-cid-tkmlznkr="">
Each model is drawn with a transform (position + Y-axis rotation), then the
    cube geometry: one color, six quads (24 vertices).
</p> <pre data-astro-cid-tkmlznkr="">// Per-model draw calls (from main.c)
for (i = 0; i &lt; MAX_MODELS; i++) {
    if (!modelActive[i]) continue;
    glPushMatrix();
    glTranslatef(modelX[i], modelY[i], modelZ[i]);
    glRotatef(modelAngle[i], 0, 1, 0);
    drawCube(CUBE_COLORS[modelColorIndex[i]]);
    drawWireframeCube();
    glPopMatrix(1);
}

// Cube geometry: RGB15 color -&gt; glColor3b, then 6 faces as GL_QUADS
glColor3b(r * 255/31, g * 255/31, b * 255/31);
glBegin(GL_QUADS);
    /* +Z face */
    glVertex3f(-1.0f,  1.0f,  1.0f);
    glVertex3f( 1.0f,  1.0f,  1.0f);
    glVertex3f( 1.0f, -1.0f,  1.0f);
    glVertex3f(-1.0f, -1.0f,  1.0f);
    /* -Z, +Y, -Y, +X, -X ... (24 vertices total) */
glEnd();</pre> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">2. Bottom screen: Script editor (software rendered)</h3> <p data-astro-cid-tkmlznkr="">
A touch-based code editor with a custom UI drawn pixel-by-pixel to a 256x192
    bitmap. Features include:
</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Token picker</strong>: tap to insert commands (SET, ADD, LOOP,
      IF_GT, etc.)
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Numpad</strong>: edit number parameters for each command</li> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Register selector</strong>: choose which variable (A-Z) to use
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Play/Pause/Stop/Step</strong>: control script execution</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">6 script slots</strong>: save and load different programs</li> </ul> <pre data-astro-cid-tkmlznkr="">// Software rendering to bottom screen
u16 *subBuffer = (u16*)BG_BMP_RAM_SUB(0);  // 256x192 framebuffer
subBuffer[y * 256 + x] = RGB15(31, 31, 31);  // white pixel</pre> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">3. Script interpreter</h3> <p data-astro-cid-tkmlznkr="">
Executes one line of script per frame (~60 lines/sec). Scripts can use 26
    variables (A-Z) plus 9 read-only registers for input (D-pad, buttons) and
    system state (elapsed time, camera direction).
</p> <pre data-astro-cid-tkmlznkr="">// Script execution (simplified)
if (tokenEquals(script[scriptIP], "add")) {
    int r = scriptReg[scriptIP];  // which register (A-Z)
    registers[r] += getNumberParamValue(scriptIP, 0);
    scriptIP++;  // next line
}</pre> <h2 data-astro-cid-tkmlznkr="">The scripting language</h2> <p data-astro-cid-tkmlznkr="">
Scripts are built from <strong data-astro-cid-tkmlznkr="">tokens</strong> (commands) with numeric parameters.
    Each line executes instantly, with no parsing overhead, just a series of if-checks
    against token names.
</p> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Available commands</h3> <div data-astro-cid-tkmlznkr=""> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">Variables &amp; Math</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">SET A 5</code> — set register A to 5</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">ADD A 1</code> — add 1 to A</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">SUBTRACT A 2</code> — subtract 2 from A</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">MULTIPLY B -1</code> — multiply B by -1</li> </ul> </div> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">Control Flow</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">LOOP</code> / <code data-astro-cid-tkmlznkr="">END_LOOP</code> — infinite loop</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">IF_GT A 10</code> — if A &gt; 10</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">IF_LT A 0</code> — if A &lt; 0</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">IF_TRUE kA</code> — if A button pressed</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">END_IF</code> — close conditional</li> </ul> </div> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">3D Objects</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">MODEL 0</code> — create model at index 0</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">POSITION 0 X Y Z</code> — set position</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">ANGLE 0 45</code> — set rotation angle</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">NEXT_COLOR 0</code> — cycle color</li> </ul> </div> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">Camera &amp; Rendering</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">CAM_POS X Y Z</code> — set camera position</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">CAM_ANGLE yaw pitch</code> — set look direction</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">BACKGROUND 2</code> — set bg color (0-3)</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">BEEP</code> — play 0.1s sound</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">SLEEP 0.016</code> — pause (60 FPS = 0.016s/frame)</li> </ul> </div> </div> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Read-only registers (input &amp; state)</h3> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""> <code data-astro-cid-tkmlznkr="">LEFT, UP, RGT, DN</code>: D-pad (1.0 when held, 0.0 when released)
</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">KA, KB</code>: A and B buttons</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">TIME</code>: elapsed seconds since script started</li> <li data-astro-cid-tkmlznkr=""> <code data-astro-cid-tkmlznkr="">LOOKX, LOOKZ</code>: camera forward direction (normalized X and Z)
</li> </ul> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Example: 3D pong (default script)</h3> <p data-astro-cid-tkmlznkr="">
The engine ships with a playable pong game. Here's a simplified excerpt:
</p> <pre data-astro-cid-tkmlznkr="">MODEL 0           ; create ball
MODEL 1           ; create paddle
CAM_POS 0 8 18    ; position camera
SET A 0           ; ball X position
SET B 1           ; ball velocity
SET C 0           ; paddle Z position
LOOP
  ADD A B         ; move ball
  IF_GT A 10      ; hit right wall?
    MULTIPLY B -1 ; reverse velocity
  END_IF
  IF_TRUE Up      ; up button pressed?
    ADD C -0.5    ; move paddle up
  END_IF
  POSITION 0 A 0 0     ; update ball position
  POSITION 1 -13 0 C   ; update paddle position
  SLEEP 0.016          ; ~60 FPS
END_LOOP</pre>  <p data-astro-cid-tkmlznkr="">
The full script includes collision detection, game-over logic, and beep
    sounds on miss, all done with simple register math and conditionals.
</p> <h2 data-astro-cid-tkmlznkr="">Technical details</h2> <h3 data-astro-cid-tkmlznkr="">Language &amp; toolchain</h3> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Language</strong>: C</li> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Library</strong>: <a href="https://github.com/devkitPro/libnds" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">libnds</a> (Nintendo DS development library)
</li> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Toolchain</strong>: <a href="https://devkitpro.org/" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">devkitPro</a> (ARM cross-compiler)
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Source size</strong>: ~3,100 lines of C (main.c)</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Binary size</strong>: ~100 KB (.nds ROM)</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Performance</strong>: 60 FPS on DS Lite (2006 hardware)</li> </ul> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Capabilities &amp; limitations</h3> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr="">Up to <strong data-astro-cid-tkmlznkr="">128 script lines</strong> per program</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">26 variables</strong> (A-Z) + 9 read-only registers</li> <li data-astro-cid-tkmlznkr="">
Up to <strong data-astro-cid-tkmlznkr="">16 3D models</strong> (simple cubes with color/position/rotation)
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">6 save slots</strong> for different scripts</li> <li data-astro-cid-tkmlznkr="">No dynamic memory allocation, all arrays are statically sized</li> <li data-astro-cid-tkmlznkr="">No string variables, numbers only (floats)</li> <li data-astro-cid-tkmlznkr="">No function calls or subroutines (yet!)</li> </ul> <h2 data-astro-cid-tkmlznkr="">How to build &amp; run</h2> <h3 data-astro-cid-tkmlznkr="">Compilation (on your computer)</h3> <ol data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr="">
Install <a href="https://devkitpro.org/wiki/Getting_Started" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">devkitPro</a> (includes devkitARM and libnds)
</li> <li data-astro-cid-tkmlznkr=""> <a href="https://crl.io/ds-game-engine.zip" download="" data-astro-cid-tkmlznkr="">Download the source code</a> (main.c
      + Makefile)
</li><li data-astro-cid-tkmlznkr="">
Run <code data-astro-cid-tkmlznkr="">make</code> in the project directory
</li> <li data-astro-cid-tkmlznkr="">
Output: <code data-astro-cid-tkmlznkr="">program.nds</code> (~100 KB ROM file)
</li> </ol> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Running on real hardware</h3> <p data-astro-cid-tkmlznkr="">
You need a <strong data-astro-cid-tkmlznkr="">flashcart</strong> (e.g. R4, DSTT, Acekard) with a microSD
    card:
</p> <ol data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr="">
Copy <code data-astro-cid-tkmlznkr="">program.nds</code> to the microSD card
</li> <li data-astro-cid-tkmlznkr="">Insert the microSD into the flashcart</li> <li data-astro-cid-tkmlznkr="">Insert the flashcart into your DS</li> <li data-astro-cid-tkmlznkr="">Boot the DS and select the ROM from the flashcart menu</li> </ol> <p data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Note</strong>: I got my R4 cart + SD card from a friend years ago,
    so I don't have detailed setup instructions for the cart itself. Most modern
    flashcarts just need you to copy their firmware to the SD root, then add
    ROMs in a folder.
</p> <h2 data-astro-cid-tkmlznkr="">Try it in your browser (Nintendo DS emulator)</h2> <p data-astro-cid-tkmlznkr="">
You can test the DS game engine build directly below. The emulator loads <code data-astro-cid-tkmlznkr="">ds-game-engine.nds</code>. Loads a more basic pong game than the one in the video.
</p>   <p data-astro-cid-tkmlznkr="">
Nintendo DS emulator (<a href="https://notan127.github.io/DS-Emulator-Web/" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">Desmond</a>). If the game doesn’t start, ensure JavaScript is enabled and the page has
    finished loading.
</p> <h2 data-astro-cid-tkmlznkr="">Download</h2>  <p data-astro-cid-tkmlznkr=""> <a href="https://crl.io/dist/ds-game-engine.zip" data-astro-cid-tkmlznkr="">Source (ds-game-engine.zip)</a> </p>  <p data-astro-cid-tkmlznkr=""> <a href="https://crl.io/dist/ds-game-engine.nds" data-astro-cid-tkmlznkr="">Compiled ROM (ds-game-engine.nds)</a> </p> <h2 data-astro-cid-tkmlznkr="">Discussion</h2>  <p data-astro-cid-tkmlznkr="">
Feel free to ask or discuss in
<a href="https://www.reddit.com/r/NDSHacks/comments/1qrwost/ds_code_editor_making_3d_pong/" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">this Reddit thread</a> </p>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genode OS is a tool kit for building highly secure special-purpose OS (111 pts)]]></title>
            <link>https://genode.org/about/index</link>
            <guid>46838981</guid>
            <pubDate>Sat, 31 Jan 2026 18:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://genode.org/about/index">https://genode.org/about/index</a>, See on <a href="https://news.ycombinator.com/item?id=46838981">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="portal-column-content">

 <p>
  The Genode OS Framework is a tool kit for building highly secure
  special-purpose operating systems. It scales from embedded systems with as
  little as 4 MB of memory to highly dynamic general-purpose workloads.
 </p>
 <p>
  Genode is based on a recursive system structure. Each program runs in a
  dedicated sandbox and gets granted only those access rights and resources that
  are needed for its specific purpose. Programs can create and manage
  sub-sandboxes out of their own resources, thereby forming hierarchies where
  policies can be applied at each level. The framework provides mechanisms to
  let programs communicate with each other and trade their resources, but only
  in strictly-defined manners. Thanks to this rigid regime, the attack surface
  of security-critical functions can be reduced by orders of magnitude compared
  to contemporary operating systems.
 </p>
 <p>
  The framework aligns the construction principles of L4 with Unix philosophy.
  In line with Unix philosophy, Genode is a collection of small building blocks,
  out of which sophisticated systems can be composed. But unlike Unix, those
  building blocks include not only applications but also all classical OS
  functionalities including kernels, device drivers, file systems, and protocol
  stacks.
 </p>
 
 <ul>
  <li>
   <p>
    CPU architectures: x86 (32 and 64 bit), ARM (32 and 64 bit), RISC-V
   </p>
  </li>
  <li>
   <p>
    Kernels: most members of the L4 family
    (<a href="http://hypervisor.org/">NOVA</a>,
    <a href="https://sel4.systems/">seL4</a>,
    <a href="http://os.inf.tu-dresden.de/fiasco/">Fiasco.OC</a>,
    <a href="http://okl4.org/">OKL4 v2.1</a>,
    <a href="http://www.l4ka.org/65.php">L4ka::Pistachio</a>,
    <a href="http://os.inf.tu-dresden.de/fiasco/prev/">L4/Fiasco</a>),
    Linux, and a custom kernel.
   </p>
  </li>
  <li>
   <p>
    Virtualization: VirtualBox (on NOVA), a custom virtual machine monitor
    for ARM, and a custom runtime for Unix software
   </p>
  </li>
  <li>
   <p>
    Over 100 ready-to-use
    <a href="https://genode.org/documentation/components">components</a>
   </p>
  </li>
 </ul>
 <p>
  Genode is open source and commercially supported by
  <a href="http://www.genode-labs.com/">Genode Labs</a>.
 </p>
 <div><dl>
  <dt><a href="https://genode.org/about/road-map">Road map</a></dt>
  <dd>
   <p>
    The direction where the project is currently heading
   </p>
  </dd>
  <dt><a href="https://genode.org/about/challenges">Challenges</a></dt>
  <dd>
   <p>
    A collection of project ideas, giving a glimpse on possible future directions
   </p>
  </dd>
  <dt><a href="https://genode.org/about/publications">Publications</a></dt>
  <dd>
   <p>
    Publications related to Genode
   </p>
  </dd>
  <dt><a href="https://genode.org/about/licenses">Licensing</a></dt>
  <dd>
   <p>
    Open-Source and commercial licensing
   </p>
  </dd>
  <dt><a href="https://genode.org/about/screenshots">Screenshots</a></dt>
  <dd>
   <p>
    Screenshots of Genode-based system scenarios
   </p>
  </dd>
 </dl></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US has investigated claims WhatsApp chats aren't private (169 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private</link>
            <guid>46838635</guid>
            <pubDate>Sat, 31 Jan 2026 17:25:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private">https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private</a>, See on <a href="https://news.ycombinator.com/item?id=46838635">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Mobile carriers can get your GPS location (486 pts)]]></title>
            <link>https://an.dywa.ng/carrier-gnss.html</link>
            <guid>46838597</guid>
            <pubDate>Sat, 31 Jan 2026 17:21:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://an.dywa.ng/carrier-gnss.html">https://an.dywa.ng/carrier-gnss.html</a>, See on <a href="https://news.ycombinator.com/item?id=46838597">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  

  <p>
    <time datetime="2026-01-31 00:00:00 +0000">2026-01-31</time>
  </p>
  
  <p>In iOS 26.3, Apple introduced a new privacy feature which limits “precise location” data made available to cellular networks via cell towers. The feature is only available to devices with Apple’s in-house modem introduced in 2025. The announcement<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> says</p>

<blockquote>
  <p>Cellular networks can determine your location based on which cell towers your device connects to.</p>
</blockquote>

<p>This is well-known. I have served on a jury where the prosecution obtained location data from cell towers. Since cell towers are sparse (especially before 5G), the accuracy is in the range of tens to hundreds of metres<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>.</p>

<p><strong>But this is not the whole truth</strong>, because cellular standards have built-in protocols that make your device silently send GNSS (i.e. GPS, GLONASS, Galileo, BeiDou) location to the carrier. This would have the same precision as what you see in your Map apps, in single-digit metres.</p>

<p>In 2G and 3G this is called <a href="https://projects.osmocom.org/projects/security/wiki/RRLP">Radio Resources LCS Protocol (RRLP)</a></p>

<blockquote>
  <p>So the network simply asks “tell me your GPS coordinates if you know them” and the phone will respond<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup>.</p>
</blockquote>

<p>In 4G and 5G this is called <a href="https://tech-academy.amarisoft.com/LTE_LPP.html">LTE Positioning Protocol (LPP)</a></p>

<blockquote>
  <p>RRLP, RRC, and LPP are natively control-plane positioning protocols. This means that they are transported in the inner workings of cellular networks and are practically invisible to end users<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup>.</p>
</blockquote>

<p>It’s worth noting that GNSS location is never <em>meant</em> to leave your device. GNSS coordinates are calculated entirely passively, your device doesn’t need to send a single bit of information. Using GNSS is like finding out where you are by reading a road sign: you don’t have to tell anyone else you read a road sign, anyone can read a road sign, and the people who put up road signs don’t know who read which road sign when.</p>

<p>These capabilities are not secrets but somehow they have mostly slid under the radar of the public consciousness. They have been used in the wild for a long time, such as by the DEA in the US in 2006<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup>:</p>

<blockquote>
  <p>[T]he DEA agents procured a court order (but not a search warrant) to obtain GPS coordinates from the courier’s phone via a ping, or signal requesting those coordinates, sent by the phone company to the phone.</p>
</blockquote>

<p>And by Shin Bet in Israel, which tracks everyone everywhere all the time<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup>:</p>

<blockquote>
  <p>The GSS Tool was based on centralized cellular tracking operated by Israel’s General Security Services (GSS). The technology was based on a framework that tracks all the cellular phones running in Israel through the cellular companies’ data centers. According to news sources, it routinely collects information from cellular companies and identifies the location of all phones through cellular antenna triangulation and GPS data<sup id="fnref:7:1" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup>.</p>
</blockquote>

<p>Notably, the Israeli government started using the data for contact tracing in March 2020<sup id="fnref:7:2" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup><sup id="fnref:8" role="doc-noteref"><a href="#fn:8" rel="footnote">8</a></sup>, only a few weeks after the first Israeli COVID-19 case. An individual would be sent an SMS message informing them of close contact with a COVID patient and required to quarantine. This is good evidence that the location data Israeli carriers are collecting are far more precise than what cell towers alone can achieve.</p>

<p>A major caveat is that I don’t know if RRLP and LPP are the exact techniques, and the only techniques, used by DEA, Shin Bet, and possibly others to collect GNSS data; there could be other protocols or backdoors we’re not privy to.</p>

<p>Another unknown is whether these protocols can be exploited remotely by a foreign carrier. Saudi Arabia has abused SS7 to spy on people in the US<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" rel="footnote">9</a></sup>, but as far as I know this only locates a device to the coverage area of a Mobile Switching Center, which is less precise than cell tower data. Nonetheless, given the abysmal culture, competency, and integrity in the telecom industry, I would not be shocked if it’s possible for a state actor to obtain the precise GNSS coordinates of anyone on earth using a phone number/IMEI.</p>

<p>Apple made a good step in iOS 26.3 to limit at least one vector of mass surveillance, enabled by having full control of the modem silicon and firmware. They must now allow users to disable GNSS location responses to mobile carriers, and notify the user when such attempts are made to their device.</p>

<hr>


</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finland to end "uncontrolled human experiment" with ban on youth social media (519 pts)]]></title>
            <link>https://yle.fi/a/74-20207494</link>
            <guid>46838417</guid>
            <pubDate>Sat, 31 Jan 2026 17:06:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yle.fi/a/74-20207494">https://yle.fi/a/74-20207494</a>, See on <a href="https://news.ycombinator.com/item?id=46838417">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Lunch break at the Finnish International School of Tampere (FISTA) is a boisterous time.</p><p>The yard is filled with children — ranging from grades 1 to 9, or ages 6 to 16 — running around, shouting, playing football, shooting basketball hoops, doing what kids do.</p><p>And there's not a single screen in sight.</p><p>FISTA has taken advantage of the <a href="https://yle.fi/a/74-20103459" role="link">law change</a>, brought in last August, which allows schools to restrict or completely ban the use of mobile phones during school hours. At FISTA, this means no phones at all unless specifically used for learning in the classroom.</p><p>"We've seen that cutting down on the possibilities for students to use their phones, during the breaks for instance, has spurred a lot of creativity," FISTA vice principal <strong>Antti Koivisto</strong> notes.</p><p>"They're more active, doing more physical things like playing games outdoors or taking part in the organised break activities or just socialising with each other."</p><p>With the smartphone restriction in schools widely considered to have been a success, Finland's government has now set its sights on social media platforms.</p><p>Prime Minister <strong>Petteri Orpo</strong> (NCP) <a href="https://yle.fi/a/74-20204220" role="link">said earlier this month</a> that he supports banning the use of social media by children under the age of 15.</p><p>"I am deeply concerned about the lack of physical activity among children and young people, and the fact that it is increasing," Orpo said at the time.</p><p>And there is a growing groundswell of support for Finland introducing such a ban. Two-thirds of respondents to a survey published earlier this week <a href="https://yle.fi/a/74-20206519" role="link">said they back a ban</a> on social media for under-15s. This is a near 10 percentage point jump compared to a similar survey carried out just last summer.</p><h2>"Uncontrolled human experiment"</h2><p>The concerns over social media, and in particular the effects on children, have been well-documented — but Finnish researcher <strong>Silja Kosola</strong>'s <a href="https://yle.fi/a/74-20205877" role="link">recent description of the phenomenon</a> as an "uncontrolled human experiment" has grabbed people's attention once again.</p><p>Kosola, an associate professor in adolescent medicine, has researched the impact of social media on young people, and tells Yle News that the consequences are not very well understood.</p><p>"We see a rise in self-harm and especially eating disorders. We see a big separation in the values of young girls and boys, which is also a big problem in society," Kosola explains.</p><p><strong>In the video below, Silja Kosola explains the detrimental effects that excessive use of social media can have on young people.</strong></p><figure><figcaption><span>Silja Kosola speaking on the All Points North podcast.</span></figcaption></figure><p>She further notes that certain aspects of Finnish culture — such as the independence and freedom granted to children from a young age — have unwittingly exacerbated the ill effects of social media use.</p><p>"We have given smartphones to younger people more than anywhere else in the world. Just a couple of years ago, about 95 percent of first graders had their own smartphone, and that hasn't happened anywhere else," she says.</p><h2>All eyes on Australia</h2><p>Since 10 December last year, children under the age of 16 in Australia have been banned from using social media platforms such as TikTok, Snapchat, Facebook, Instagram and YouTube.</p><p>Prime Minister <strong>Anthony Albanese</strong> began drafting the legislation after he received a heartfelt letter from a grieving mother who lost her 12-year-old daughter to suicide.</p><p>Although Albanese has never revealed the details of the letter, <a href="https://www.abc.net.au/news/2025-12-13/how-australia-developed-social-media-ban-under-16s/106137700" role="link">he told public broadcaster</a> ABC that it was "obvious social media had played a key role" in the young girl's death.</p><p>The legislation aims to shift the burden away from parents and children and onto the social media companies, who face fines of up to 49.5 million Australian dollars (29 million euros) if they consistently fail to keep kids off their platforms.</p><p><strong>Clare Armstrong</strong>, ABC's chief digital political correspondent, told Yle News that the initial reaction to the roll-out has been some confusion but no little "relief".</p><p>"The government often talks about this law as being a tool to help parents and other institutions enforce and start conversations about tech and social media in ways that before, they couldn't," she says.</p><p>Although it is still early days, as the ban has only been in force for about six weeks, Armstrong adds that the early indicators have been good.</p><p><strong>ABC journalist Clare Armstrong explains in the video below how children in Australia have been spending their time since the social media ban was introduced.</strong></p><figure><figcaption><span>Clare Armstrong speaking on the All Points North podcast.</span></figcaption></figure><p>However, she adds a note of caution to any countries — such as Finland — looking to emulate the Australian model, noting that communication is key.</p><p>"Because you can write a very good law, but if the public doesn't understand it, and if it can't be enforced at that household level easily, then it's bound to fail," Armstrong says.</p><h2>Playing to Finland's strengths</h2><p><strong>Seona Candy,</strong> an Australian living in Helsinki for over eight years, has been keenly following the events in her homeland since the social media ban came into effect in December.</p><p>She has heard anecdotally that if kids find themselves blocked from one platform, they just set up an account on another, "ones that maybe their parents don't even know exist".</p><p>"And this is then much, much harder, because those platforms don't have parental controls, so they don't have those things already designed into them that the more mainstream platforms do," Candy says.</p><p>Because of this issue, and others she has heard about, she warns against Finland introducing like-for-like legislation based around Australia's "reactive, knee-jerk" law change.</p><p>"I think the Finnish government should really invest in digital education, and digital literacy, and teach kids about digital safety. Finland is world-famous for education, and for media literacy. Play to your strengths, right?"</p><p><em>The All Points North podcast asked if Finland should introduce a similar ban on social media as in Australia. You can listen to the episode via this embedded player, on</em> <a href="https://areena.yle.fi/podcastit/1-4355773" role="link"><em>Yle Areena</em></a><em>,</em> <em>via</em> <a href="https://podcasts.apple.com/us/podcast/all-points-north/id1678541537" role="link"><em>Apple</em></a>, <a href="https://open.spotify.com/show/11M4NJ3cfmNCo0qYiIXXU1" role="link"><em>Spotify</em></a> <em>or wherever you get your podcasts.</em></p><figure><div><div><p><strong>Should Finland ban kids from using social media?</strong></p><div><canvas></canvas><picture><source data-testid="source-for-S" media="(max-width: 767px)" srcset="https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_104,w_104/dpr_2.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 2x,https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_104,w_104/dpr_1.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 1x"><source data-testid="source-for-M" media="(min-width: 768px)" srcset="https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_135,w_135/dpr_2.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 2x,https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_135,w_135/dpr_1.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 1x"><img alt="" src="https://images.cdn.yle.fi/image/upload/ar_1.7777777777777777,c_fill,g_faces,h_75,w_135/dpr_1.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917"></picture></div></div></div></figure></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Film students who can no longer sit through films (106 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/</link>
            <guid>46838026</guid>
            <pubDate>Sat, 31 Jan 2026 16:26:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/">https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/</a>, See on <a href="https://news.ycombinator.com/item?id=46838026">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">Everyone knows it’s hard to get college students to do the reading—remember books? But the attention-span crisis is not limited to the written word. Professors are now finding that they can’t even get film students—<em>film </em>students—to sit through movies. “I used to think, <em>If homework is watching a movie, that is the best homework ever</em>,” Craig Erpelding, a film professor at the University of Wisconsin at Madison, told me. “But students will not do it.”</p><p data-flatplan-paragraph="true">I heard similar observations from 20 film-studies professors around the country. They told me that over the past decade, and particularly since the pandemic, students have struggled to pay attention to feature-length films. Malcolm Turvey, the founding director of Tufts University’s Film and Media Studies Program, officially bans electronics during film screenings. Enforcing the ban is another matter: About half the class ends up looking furtively at their phones.</p><p data-flatplan-paragraph="true">A handful of professors told me they hadn’t noticed any change. Some students have always found old movies to be slow, Lynn Spigel, a professor of screen cultures at Northwestern University, told me. “But the ones who are really dedicated to learning film always were into it, and they still are.”</p><p data-flatplan-paragraph="true">Most of the instructors I spoke with, however, feel that something is different now. And the problem is not limited to large introductory courses. Akira Mizuta Lippit, a cinema and media-studies professor at the University of Southern California—home to perhaps the top film program in the country—said that his students remind him of nicotine addicts going through withdrawal during screenings: The longer they go without checking their phone, the more they fidget. Eventually, they give in. He recently screened the 1974 Francis Ford Coppola classic <em>The Conversation</em>. At the outset, he told students that even if they ignored parts of the film, they needed to watch the famously essential and prophetic final scene. Even that request proved too much for some of the class. When the scene played, Lippit noticed that several students were staring at their phones, he told me. “You do have to just pay attention at the very end, and I just can’t get everybody to do that,” he said.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/magazine/archive/2024/11/the-elite-college-students-who-cant-read-books/679945/">From the November 2024 issue: The elite college students who can’t read books</a></p><p data-flatplan-paragraph="true">Many students are resisting the idea of in-person screenings altogether. Given the ease of streaming assignments from their dorm rooms, they see gathering in a campus theater as an imposition. Professors whose syllabi require in-person screenings outside of class time might see their enrollment drop, Meredith Ward, director of the Program in Film and Media Studies at Johns Hopkins University, told me. Accordingly, many professors now allow students to stream movies on their own time.</p><p data-flatplan-paragraph="true">You can imagine how that turns out. At Indiana University, where Erpelding worked until 2024, professors could track whether students watched films on the campus’s internal streaming platform. Fewer than 50 percent would even start the movies, he said, and only about 20 percent made it to the end. (Recall that these are students who chose to take a film class.) Even when students stream the entire film, it’s not clear how closely they watch it. Some are surely folding laundry or scrolling Instagram, or both, while the movie plays.</p><p data-flatplan-paragraph="true">The students I spoke with admitted to their own inattentiveness. They even felt bad about it. But that wasn’t enough to make them sit through the assigned movies. Mridula Natarajan, a freshman at the University of Texas at Austin, took a world-cinema class this past fall. “There were some movies that were extremely slow-paced, and ironically, that was the point of the movie,” she told me. “But I guess impatience made me skip through stuff or watch it on two-times speed.”</p><p data-flatplan-paragraph="true">After watching movies distractedly—if they watch them at all—students unsurprisingly can’t answer basic questions about what they saw. In a multiple-choice question on a recent final exam, Jeff Smith, a film professor at UW Madison, asked what happens at the end of the Truffaut film <em>Jules and Jim</em>. More than half of the class picked one of the wrong options, saying that characters hide from the Nazis (the film takes place during World War I) or get drunk with Ernest Hemingway (who does not appear in the movie). Smith has administered similar exams for almost two decades; he had to grade his most recent exam on a curve to keep students’ marks within a normal range.</p><p data-flatplan-paragraph="true">The professors I spoke with didn’t blame students for their shortcomings; they focused instead on how media diets have changed. From 1997 to 2014, screen time for children under age 2 doubled. And the screen in question, once a television, is now more likely to be a tablet or a smartphone. Students arriving in college today have no memory of a world before the infinite scroll. As teenagers, they spent nearly five hours a day on social media, with much of that time used for flicking from one short-form video to the next. An <a data-event-element="inline link" href="https://www.apa.org/news/podcasts/speaking-of-psychology/attention-spans">analysis</a> of people’s attention while working on a computer found that they now switch between tabs or apps every 47 seconds, down from once every two and a half minutes in 2004. “I can imagine that if your body and your psychology are not trained for the duration of a feature-length film, it will just feel excruciatingly long,” USC’s Lippit said. (He also hypothesized that, because every movie is available on demand, students feel that they can always rewatch should they miss something—even if they rarely take advantage of that option.)</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/podcasts/archive/2024/03/smartphone-anxious-generation-mental-health/677817/">Listen: The smartphone kids are not all right</a></p><p data-flatplan-paragraph="true">Kyle Stine, a film and media-studies professor at Johns Hopkins, usually begins his course with an icebreaker: <em>What’s a movie you watched recently?</em> In the past few years, some students have struggled to name any film. Kristen Warner, a performing- and media-arts professor at Cornell University, has noticed a similar trend. Some of her students arrive having seen only Disney movies. Erpelding, at UW Madison, said he tries to find a movie that everyone in his class has seen, to serve as a shared reference point they can talk about. Lately, that’s become impossible. Even students who are interested in going into filmmaking don’t necessarily love watching films. “The disconnect is that 10 years ago, people who wanted to go study film and media creation were cinephiles themselves,” Erpelding told me. “Nowadays, they’re people that consume the same thing everyone else consumes, which is social media.”</p><p data-flatplan-paragraph="true">Of course, young people haven’t given up on movies altogether. But the feature films that they do watch now tend to be engineered to cater to their attentional deficit. In a recent appearance on <em>The Joe Rogan Experience</em>, Matt Damon, the star of many movies that college students may not have seen, said that Netflix has started encouraging filmmakers to put action sequences in the first five minutes of a film to get viewers hooked. And just because young people are streaming movies, it doesn’t mean they’re paying attention. When they sit down to watch, many are browsing social media on a second screen. Netflix has accordingly advised directors to have characters <a data-event-element="inline link" href="https://au.variety.com/2026/film/news/matt-damon-netflix-movies-restate-plot-viewers-on-phones-32039/">repeat the plot</a> three or four times so that multitasking audiences can keep up with what’s happening, Damon said.</p><p data-flatplan-paragraph="true">Some professors are treating wilting attention spans as a problem to be solved, not a reality to accept. Stine, at Johns Hopkins, is piloting a course on “slow cinema”—minimalist films with almost no narrative thrust—with the goal of helping students redevelop long modes of attention. Rick Warner, the director of film studies at the University of North Carolina, deliberately selects films with slow pacing and subtle details, such as Chantal Akerman’s <em>Jeanne Dielman, 23 quai du Commerce, 1080 Bruxelles</em>, a three-hour movie that mostly follows a woman doing chores in her apartment. “I try to teach films that put their habits of viewing under strain,” Warner told me. “I’m trying to sell them on the idea that a film watched properly can actually help them retrain their perception and can teach them how to concentrate again.” Once they get used to it, students enjoy the challenge, he said.</p><p data-flatplan-paragraph="true">But other professors, perhaps concluding that resistance is futile, are adjusting to the media their students grew up on. Some show shorter films or have students watch movies over multiple sittings. Erpelding, who primarily teaches filmmaking courses, has moved from teaching traditional production methods to explaining how to maximize audience engagement. He now asks students to make three- or four-minute films, similar to the social-media edits they see online. After all, that seems to be the only type of video many young people want to watch.</p><p data-flatplan-paragraph="true">By the way, the last scene of <em>The Conversation</em> has the paranoid Gene Hackman destroying his apartment in a desperate and futile search for listening devices. He eventually gives up, and mournfully plays the saxophone amid the wreckage. It’s a brilliant scene, and worth the wait.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Platform Security (Jan 2026) [pdf] (133 pts)]]></title>
            <link>https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf</link>
            <guid>46837814</guid>
            <pubDate>Sat, 31 Jan 2026 16:04:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf">https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=46837814">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[US reportedly investigate claims that Meta can read encrypted WhatsApp messages (171 pts)]]></title>
            <link>https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages</link>
            <guid>46836487</guid>
            <pubDate>Sat, 31 Jan 2026 13:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages">https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages</a>, See on <a href="https://news.ycombinator.com/item?id=46836487">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>US authorities have reportedly investigated claims that Meta can read users’ encrypted chats on the <a href="https://www.theguardian.com/technology/whatsapp" data-link-name="in body link" data-component="auto-linked-tag">WhatsApp</a> messaging platform, which it owns.</p><p>The reports follow a lawsuit filed last week, which claimed <a href="https://www.theguardian.com/technology/meta" data-link-name="in body link" data-component="auto-linked-tag">Meta</a> “can access virtually all of WhatsApp users’ purportedly ‘private’ communications”.</p><p>Meta has denied the allegation, reported by <a href="https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private" data-link-name="in body link">Bloomberg</a>, calling the lawsuit’s claim “categorically false and absurd”. It suggested the claim was a <a href="https://x.com/andymstone/status/2016920479362171305" data-link-name="in body link">tactic</a> to support the NSO Group, an Israeli firm that develops spyware used against activists and journalists, and which recently lost a lawsuit brought by WhatsApp.</p><p>The firm that filed last week’s lawsuit against Meta, Quinn Emanuel Urquhart &amp; Sullivan, attributes the allegation to <a href="https://www.washingtonpost.com/technology/2026/01/29/whatsapp-lawsuit-read-messages-denied/" data-link-name="in body link">unnamed</a> “courageous” whistleblowers from Australia, Brazil, India, Mexico and South Africa.</p><p>Quinn Emanuel is, in a separate case, helping to represent the NSO Group in its appeal against a <a href="https://www.davispolk.com/experience/trial-victory-meta-and-whatsapp-spyware-case" data-link-name="in body link">judgment</a> from a US federal court last year, which ordered it to pay $167m to WhatsApp for violating its terms of service in its <a href="https://www.theguardian.com/news/series/pegasus-project" data-link-name="in body link">deployment</a> of Pegasus spyware against more than 1,400 users.</p><p>“We’re pursuing sanctions against Quinn Emanuel for filing a meritless lawsuit that was designed purely to grab headlines,” said Carl Woog, a Meta spokesperson, in a statement. “This is the same firm that is trying to help NSO overturn an injunction that barred their operations for targeting journalists and government officials with spyware.”</p><p>Adam Wolfson, a partner at Quinn Emanuel said: “Our colleagues’ defence of NSO on appeal has nothing to do with the facts disclosed to us and which form the basis of the lawsuit we brought for worldwide WhatsApp users.</p><p>“We look forward to moving forward with those claims and note WhatsApp’s denials have all been carefully worded in a way that stops short of denying the central allegation in the complaint – that Meta has the ability to read WhatsApp messages, regardless of its claims about end-to-end encryption.”</p><p>Steven Murdoch, professor of security engineering at UCL, said the lawsuit was “a bit strange”. “It seems to be going mostly on whistleblowers, and we don’t know much about them or their credibility,” he said. “I would be very surprised if what they are claiming is actually true.”</p><p>If WhatsApp were, indeed, reading users’ messages, this was likely to have been discovered by staff and would end the business, he said. “It’s very hard to keep secrets inside a company. If there was something as scandalous as this going on, I think it’s very likely that it would have leaked out from someone within WhatsApp.”</p><p>The Bloomberg article cites reports and interviews from officials within the US Department of Commerce in claiming that the US has investigated whether Meta could read WhatsApp messages. However, a spokesperson for the department called these assertions “unsubstantiated”.</p><p>WhatsApp <a href="https://faq.whatsapp.com/820124435853543" data-link-name="in body link">bills itself</a> as an end-to-end encrypted platform, which means that messages can be read only by their sender and recipient, and are not decoded by a server in the middle.</p><p>This contrasts with some other messaging apps, such as Telegram, which encrypt messages between a sender and its own servers, preventing third parties from reading the messages, but allowing them – in theory – to be decoded and read by Telegram itself.</p><p>A senior executive in the technology sector told the Guardian that WhatsApp’s vaunted privacy “leaves much to be desired”, given the platform’s willingness to collect metadata on its users, such as their profile information, their contact lists, and who they speak to and when.</p><p>However, the “idea that WhatsApp can selectively and retroactively access the content of [end-to-end encrypted] individual chats is a mathematical impossibility”, he said.</p><p>Woog, of Meta, said: “We’re pursuing sanctions against Quinn Emanuel for filing a meritless lawsuit that was designed purely to grab headlines. WhatsApp’s encryption remains secure and we’ll continue to stand up against those trying to deny people’s right to private communication.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guix System First Impressions as a Nix User (160 pts)]]></title>
            <link>https://nemin.hu/guix.html</link>
            <guid>46835612</guid>
            <pubDate>Sat, 31 Jan 2026 11:22:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nemin.hu/guix.html">https://nemin.hu/guix.html</a>, See on <a href="https://news.ycombinator.com/item?id=46835612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div role="doc-toc" id="table-of-contents">
<h2>Table of Contents</h2>
<div role="doc-toc" id="text-table-of-contents">
<ul>
<li><a href="#my-journey-to-guix-system">1. My Journey to Guix System</a></li>
<li><a href="#installer-impressions">2. Installer Impressions</a></li>
<li><a href="#i-can-t-find-my-way-land">3. I Can't Find my Way-land</a></li>
<li><a href="#sympathy-for-the-devil">4. Sympathy for the Devil</a></li>
<li><a href="#goals">5. Goals</a></li>
<li><a href="#results">6. Results</a>
<ul>
<li><a href="#the-good">6.1. The Good</a></li>
<li><a href="#the-ambiguous">6.2. The Ambiguous</a></li>
<li><a href="#the-bad">6.3. The Bad</a></li>
</ul>
</li>
<li><a href="#overall">7. Overall</a></li>
<li><a href="#notes">8. Notes</a></li>
</ul>
</div>
</div>
<div id="outline-container-my-journey-to-guix-system">
<h2 id="my-journey-to-guix-system"><span>1.</span> My Journey to Guix System</h2>
<div id="text-1">
<p>
Feel free to skip this section if you don't really care about backstories. I just figured it makes sense to recap how and why one might start having an interest in declarative distros before tackling the main topic.
</p>

<p>
I've been a Linux-only<sup><a role="doc-backlink" id="fnr.1" href="#fn.1">1</a></sup> user for about ten years now and, like many others, I too embarked on the arduous journey of distro-hopping. I started with <a href="https://www.linuxmint.com/">Mint</a> and when that felt too slow, I switched to <a href="https://ubuntu.com/">Ubuntu</a>. When Ubuntu felt too handholdy<sup><a role="doc-backlink" id="fnr.2" href="#fn.2">2</a></sup>, I switched to <a href="https://archlinux.org/">Arch</a>, which proved to be my main driver for well over five or so years. And when I couldn't resist the Siren's call, I moved on to <a href="https://gentoo.org/">Gentoo</a>, thinking surely "harder is better". Which resulted in severe burnout in a few months, so I capitulated and switched to <a href="https://fedoraproject.org/">Fedora</a>, which was very stable and honestly an all around excellent system. But once more, my interest was piqued, and (before today's adventure) I finally switched to <a href="https://nixos.org/">NixOS</a>.
</p>

<p>
I've always had a passing interest towards Nix ever since I've first heard about it, but until fairly recently, I always dismissed it as a tool for DevOps guys. The syntax was <i>weird</i>, the need for reproducible environments seemingly irrelevant, and stuff like the oft-recommended <a href="https://nixos.org/guides/nix-pills/">Nix Pills</a> seemed anything but newbie-friendly.
</p>

<p>
So then why would someone like me, who's so adamant about not needing Nix eventually choose to go all-in? I guess it was at first less about Nix being better and just the rest being worse.
</p>

<p>
Of the two big reasons for the switch, one was that I realized that having per-directory environments for your projects is actually a very handy thing to do when you like to toy around with many technologies. I used to generate my <a href="https://oddwords.hu/">other blog</a> using <a href="https://jekyllrb.com/">Jekyll</a> and, no matter which distro I used, it was always a pain in the neck to have a good Ruby environment set up. <code>bundler install</code> didn't really want to work without privileges and I wasn't really a fan of unleashing <code>sudo</code> on it, but usually that was the only way I could get things to work.
</p>

<p>
With Nix, however, it was a matter of just describing a few packages in a shell and boom, Ruby in one folder, no Ruby (and thus no mess) everywhere else. <b>I was hooked!</b> I started adding <code>shell.nix</code> files to all my little projects, hell, I started planning projects by first adding a <code>shell.nix</code> with all the dependencies I would reasonably need.
</p>

<p>
The other reason, which ultimately cemented that I need to commit, was that I was getting tired of my installed packages slowly drifting out of control. Sure, every package manager has some method of listing what's installed, but these are usually cumbersome and completely ephemeral (in the sense that any listing becomes invalid the moment you change anything).
</p>

<p>
With NixOS, the equation is flipped on its head: No longer did I query the system to tell me what's installed and what's not, it was now the system that worked based on files that I edit. The difference sounds small on paper, but for me it was an extremely liberating feeling to know that I could edit my system configuration in a versionable, explicit, and centralized way.
</p>

<p>
But NixOS isn't the only declarative distro out there. In fact GNU forked Nix fairly early and made their own spin called <a href="https://guix.gnu.org/">Guix</a>, whose big innovation is that, instead of using the unwieldy Nix-language, it uses Scheme. Specifically <a href="https://www.gnu.org/software/guile/">Guile Scheme</a>, GNU's sanctioned configuration language. I've been following Guix for a bit, but it never felt quite ready to me with stuff like KDE being only barely supported and a lot of hardware not working out of the box.
</p>

<p>
However, now that (after three years) Guix announced its <a href="https://guix.gnu.org/en/blog/2026/gnu-guix-1.5.0-released/">1.5.0 release</a> with a lot of stuff stabilized and KDE finally a first-party citizen, I figured now is the best time to give it a fresh shot. This post captures my experiences from installation to the first 3-4 days.
</p>
</div>
</div>
<div id="outline-container-installer-impressions">
<h2 id="installer-impressions"><span>2.</span> Installer Impressions</h2>
<div id="text-2">
<p>
Plug your USB in, <code>dd</code> the file onto the drive, reboot, nothing unusual. If you've ever installed a Linux system, it's more of the same.
</p>

<p>
After selecting the pendrive in my BIOS settings, the monitor began to glow in a deep, radiant blue as the Guix System logo appeared on my screen… only to suddenly switch to a menacing red: My CPU's integrated GPU is not supported by free firmware. A helpful popup gave me a gentle nudge about picking free hardware next time (buddy, have you seen the PC part prices these days?) and off I went into the installer proper.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/installer_partitions.avif" alt="installer_partitions.avif">
</p>
<p><span>Figure 1: </span>Picture of the installer graciously borrowed from the Guix installer manual.</p>
</div>

<p>
The installer itself is refreshingly barebones and I mean this in a positive way. It asks all the necessary questions and provides a nice basic configuration file, all done in a retro <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Guided-Graphical-Installation.html">Ncurses-based TUI</a>. I was really happy to see that, unlike my last attempt at using Guix System in the early 2020-s, KDE Plasma is now a first-party choice during installation. I never really vibed too much with GNOME and the other options didn't appeal either, so the choice was obvious.
</p>

<p>
Now, I'm not sure if I just picked the worst possible time or if the Guix servers were facing unusual load or whatever may have happened, but after such a breeze of a setup, the moment I pressed install, my PC became unusable for the next 2.5 <b>hours.</b> Which is unacceptable for an installation process these days in my opinion. I am lucky enough to live in a household with fiber-optic internet, that merely shrugs at bandwidth of up to a gigabyte per second and yet nearly all packages downloaded with a whopping 50 <i>kilobytes</i> per second, meaning even small-ish 5-10 megabyte packages took long minutes to download.<sup><a role="doc-backlink" id="fnr.3" href="#fn.3">3</a></sup>
</p>

<p>
A reboot later my issues only got worse.
</p>
</div>
</div>
<div id="outline-container-i-can-t-find-my-way-land">
<h2 id="i-can-t-find-my-way-land"><span>3.</span> I Can't Find my Way-land</h2>
<div id="text-3">
<p>
I was assuming I'd get SDDM after having chosen KDE Plasma, but (what a later, <a href="https://guix.gnu.org/manual/devel/en/html_node/X-Window.html#:~:text=by%20default%20the%20GNOME%20Display%20Manager%20(GDM).">closer read</a> of the manual made me realize is the expected outcome for a default config) it was GDM that loaded in. I entered my name and password, and I was greeted with the familiar Plasma 6 spinner. The first hint that something might be off was that it loaded a bit longer than usual, but I was not going to get mad at waiting 10 seconds instead of 3. After all, I did just wait magnitudes longer to get here.
</p>

<p>
With practically nothing installed beyond the very basics, I clicked on Konsole, hoping to start prodding around my config and add some of my day to day apps. To my horror, it opened in the top left corner, without a titlebar and without any borders. What's more, no matter what I did, I couldn't move it. It also didn't show up on the menu bar, despite the application launcher still being completely usable. At this point I was fairly exhausted by these antics, but I figured,
</p>

<blockquote>
<p>
Well, it's a brand new release, perhaps this just snuck in. Let's give updating a shot and see if that helps.
</p>
</blockquote>

<p>
So I issued <code>guix pull</code>… The download whizzed by with speed quite unexpected after what I experienced with the installer… Only to crash into the brick wall that's indexing. Okay, whatever, another 10-12 minutes down the drain, at least now I have newest version.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/downloads.avif" alt="downloads.avif">
</p>
<p><span>Figure 2: </span>Better than before download speeds</p>
</div>

<p>
Except I didn't. Because, unlike Nix, the <code>guix</code> executable is not an omnipresent, unique thing that anyone and everyone uses on your PC. Not only does every user have their own instance, if you don't issue a certain set of commands, you won't start using the new version, despite updating it.
</p>

<p>
To Guix's credit, the CLI does scream at you to update your environment or else you'll keep using the old version, but I still find this system very disorientating compared to Nix. I'm certain experienced Guixheads are long past being tripped up by this sort of stuff and might even struggle to remember that there was a time they had to do these special steps too, but as a new user it felt a bit rough, especially consdering this is Guix System, i.e. the system whose whole purpose is to be integrate Guix as much as it can.
</p>

<p>
Back to our issue at hand. I issued <code>sudo -s</code> and <code>guix pull</code>-ed again. Once more 10-12 minutes passed indexing. But at least I could finally call <code>guix system reconfigure /etc/config.scm</code>. Interestingly things are much faster this time around, I saw speeds up to 30-50 Mbps. Before long the system was updated to the newest commit and I rebooted with high hopes.
</p>

<p>
High hopes, that were immediately dashed when Plasma loaded in the same messed up way. At this point I started to suspect this might be an issue with the GPU driver, so I enabled the LXQT desktop environment and rebooted once more. Thankfully that one worked like a charm and I was able to boot up both Emacs (editing Scheme with GNU Nano is a pain I do not wish on anyone) and <a href="https://librewolf.net/">LibreWolf</a> (Firefox's de-Mozilla-d variant).
</p>

<p>
Not having found anything too useful in the docs, I decided to make my problem someone else's so I fired up ERC<sup><a role="doc-backlink" id="fnr.4" href="#fn.4">4</a></sup> and connected to Libera.chat's <code>#guix</code> channel. After around half an hour of wait, a user by the name of Rutherther stepped up and offered me some help. We were able to figure it out that Nouveau wasn't able to drive my GPU (an RTX 5070), so his recommendation was that I should try booting with <code>nomodeset</code>. I did, but it sadly didn't help much either.
</p>
</div>
</div>
<div id="outline-container-sympathy-for-the-devil">
<h2 id="sympathy-for-the-devil"><span>4.</span> Sympathy for the Devil</h2>
<div id="text-4">
<p>
At this point I was out of ideas. Ideas of solving this using pure-Guix System, that is. There was still one option I wanted to avoid as long as I could, but alas, it seemed like the only option, that still had a realistic chance of working.
</p>




<p>
Enter <a href="https://gitlab.com/nonguix/nonguix">Nonguix</a>, the Mr. Hyde to Guix's Dr. Jekyll, the shady guy who offers you a hit and first time's for free, the… Erm, in a nutshell, it's the repository for non-free applications and drivers packages for Guix System, basically. Interestingly enough, by Guix's own findings <a href="https://guix.gnu.org/en/blog/2025/guix-user-and-contributor-survey-2024-the-results-part-2/">about 64% of users</a> utilize the Nonguix channel, which is perhaps not "literally everyone", but it does paint a picture that there is still stuff out there that you simply cannot replace with FOSS software yet.
</p>

<div>
<p><label><span>Listing 1: </span>At the time of writing, this is all one has to do to enable Nonguix.</label></p><pre><span> 1: </span>(cons* (channel
<span> 2: </span>      (name 'nonguix)
<span> 3: </span>      (url <span>"https://gitlab.com/nonguix/nonguix"</span>)
<span> 4: </span>            (introduction
<span> 6: </span>       (make-channel-introduction
<span> 7: </span>        <span>"897c1a470da759236cc11798f4e0a5f7d4d59fbc"</span>
<span> 8: </span>        (openpgp-fingerprint
<span> 9: </span>         <span>"2A39 3FFF 68F4 EF7A 3D29  12AF 6F51 20A0 22FB B2D5"</span>))))
<span>10: </span>     %default-channels)
</pre>
</div>

<p>
Enabling the repo wasn't exactly difficult. You just paste the short excerpt from above (also found in the README) into your <code>~/.config/guix/channels.scm</code> and <code>/etc/guix/channels.scm</code> files, <code>guix pull</code>, let it index to its heart's content again, and then you have access to all that is nasty (yet occasionally useful) in the world.
</p>

<p>
I figured perhaps if <a href="https://www.fsfla.org/ikiwiki/selibre/linux-libre/">Linux-libre</a> and its free firmware couldn't deal with my GPU, then surely Linux proper with its binary blobs could. Hell, for good measure I threw in the NVIDIA transform, which is supposed to automagically translate all dependencies to use the proprietary drivers.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/nvidia_first_shot_crash.avif" alt="nvidia_first_shot_crash.avif">
</p>
<p><span>Figure 4: </span>What haste and half-reading manuals gets you…</p>
</div>

<p>
Turns out my eagerness was a mistake. Not only did the process take yet another half an hour (if not more, I stopped counting), upon reboot all I was met with was a kernel panic about the driver not being able to cope with the GPU it found and a massive spew of FSCK logs.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/fsck.avif" alt="fsck.avif">
</p>
<p><span>Figure 5: </span>'FSCK' was indeed very close to the first words that came to my mind at this moment.</p>
</div>

<p>
With no better ideas in mind, I took out my pendrive again and burned Nonguix's own pre-built ISO on it using my partner's PC. While it ultimately did get me a working system, this version has three unfortunate hindrances:
</p>

<ol>
<li>It was built in 2022, far before Guix's <a href="https://guix.gnu.org/blog/2025/migrating-to-codeberg/">migration to Codeberg</a>, meaning it still attempts to pull content from the unfathomably slow <a href="https://savannah.gnu.org/">GNU Savannah</a> mirror. I had to manually override my <code>channels.scm</code> to point at the Codeberg repo instead, but with no easy means of finding its "<a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Channel-Authentication.html">channel introduction</a>"<sup><a role="doc-backlink" id="fnr.5" href="#fn.5">5</a></sup>, I had to pass in <code>--disable-authentication</code> to Guix when updating my system. A bit scary, but I trust the Codeberg repo.</li>
<li>Because of its age, I got a lot of somewhat intimidating errors about hardware not being recognized and other stuff I couldn't even decipher, but ultimately the system booted to the installer without issue.</li>
<li>For some reason while the installer itself does include Nonguix stuff, it actually does not include the repo in the resulting channels files, nor the substitution server for the project. The README has a warning about this, but if you happen to miss it, you could accidentally install a non-Nonguix Guix System (say that three times fast).</li>
</ol>

<p>
None of these were particularly hard to fix, however, and soon enough I was back where I started. That is to say, in a <code>nomodeset</code> X11 session, except this time running <a href="https://i3wm.org/">i3</a>, as LXQT wasn't an available option on an installer this old. There was certainly a bit of a hacker-ish vibe to messing with code files in an environment like that, but I was honestly much more looking forward to finally having a usable desktop.
</p>

<p>
Having learned from my hastiness, this time I was smarter. I only enabled the full kernel and firmware blobs, without going anywhere near the NVIDIA transform. I issued another <code>guix system reconfigure</code> and, after having time for another tea session, my update was finally finished.
</p>

<p>
I rebooted with tentative nervousness and… Success? Huh.
</p>
</div>
</div>
<div id="outline-container-goals">
<h2 id="goals"><span>5.</span> Goals</h2>
<div id="text-5">
<p>
Obviously there is little point in throwing Guix System on my PC and declaring success. I wanted to be able to at least reproduce the kind of workflow I'm used to using NixOS. For that, I need the following:
</p>

<ul>
<li><b>A browser:</b> preferably Firefox, as I'm not a huge fan of Chrome / Chromium,</li>
<li><b>An E-mail client:</b> preferably Thunderbird,</li>
<li><b>A basic office suite:</b> preferably LibreOffice,</li>
<li><b>Dev environments:</b> for Rust, Zig, Scheme, and TypeScript (with the option for more, if possible),</li>
<li><b>Emacs:</b> I do almost all my text editing in it these days, falling back to Neovim for quick tasks,</li>
<li><b>Discord:</b> for chatting with friends,</li>
<li><b>Telegram:</b> for chatting with family,</li>
<li><b>Steam:</b> for the very rare occasions I want to game,</li>
<li><b>NVIDIA drivers:</b> I prefer to offload day-to-day usage to my CPU's integrated GPU, as it cuts my energy usage in half.</li>
</ul>

<p>
Of these it was obvious that two would be relatively hard and one "outright impossible". The two being Steam and the drivers (as both are non-free and thus not in Guix's default repos) and the "impossible" one being Discord (which not even the non-free repo has packaged). But I was ready to compromise a little bit since I am requesting stuff that's explicitly against Guix's goals.
</p>
</div>
</div>
<div id="outline-container-results">
<h2 id="results"><span>6.</span> Results</h2>
<div id="text-6">

<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/desktop.avif" alt="desktop.avif">
</p>
<p><span>Figure 6: </span>My desktop running Wezterm packaged by me and Emacs.</p>
</div>

<p>
While there has been occasional bumps and hitches along the ride, I must say I'm very impressed with Guix System so far. Let's go through this list in order:
</p>

<ul>
<li><b>Browser:</b> So far I'm really enjoying LibreWolf. It feels a lot snappier than Firefox and I'm really baffled how much speed I was apparently missing out on.</li>
<li><b>E-mails:</b> I installed Icedove, which is basically just Thunderbird without Mozilla branding. It works as expected.</li>
<li><b>Office suite:</b> LibreOffice is available as expected. Not much to say about it. I guess it's interesting that Guix isn't following the usual <code>-stale</code> / <code>-fresh</code> packaging schema, but I don't really mind not having cutting edge versions of an office suite :)</li>
<li><b>Dev environments:</b> I've only briefly toyed with development environments so far, but to me it seems like for simple use-cases it might be even easier to use than <code>shell.nix</code> (you don't need any sort of ceremony, just a <code>manifest.scm</code> file with a <code>(specifications-&gt;manifest &lt;list of packages&gt;)</code> form inside and you have a dev env ready to go.)</li>
<li><b>Emacs:</b> Installed just fine. I had to install <code>emacs-vterm</code> to make <a href="https://github.com/akermu/emacs-libvterm">Vterm</a> work, but all that took was the very simple process of adding the library to my home configuration and then referencing it in my Emacs config as per this <a href="https://reddit.com/r/GUIX/comments/11gzhyu/how_to_compile_the_vterm_module_from_emacs_and/">Reddit post</a>.</li>
<li><b>Discord:</b> I decided to just use Discord's browser version, which works just as fine (if not better). It's trading a tiny bit of convenience in return for not having to figure out how to manually add a package for it from some random third-party source. From what I've read elsewhere Flatpak is also an option, but I prefer having just one package manager at a time.</li>
<li><b>Steam:</b> Installed shockingly easily. I have to really give props to the Nonguix team. I tested Portal 2 with the Nouveau driver, it is a little disheartening to see a 15 years old game<sup><a role="doc-backlink" id="fnr.6" href="#fn.6">6</a></sup> lag, but I understand the people's hands are tied when it comes to the free drivers. After I managed to install the proprietary drivers, I was able to play even Portal RTX, which is something I never managed to get to work using NixOS.</li>
<li><b>NVIDIA drivers:</b> This time I actually read the docs properly and it didn't take long for me to realize the initial problem that caused my previous install to be unbootable was of course found between the chair and keyboard. This time, after making sure I enabled the open drivers and kernel mode-setting, I crossed my fingers, issued a reconfigure and it works beautifully!</li>
</ul>
</div>
<div id="outline-container-the-good">
<h3 id="the-good"><span>6.1.</span> The Good</h3>
<div id="text-6-1">
<ul>
<li><p>
<b>Helpful community:</b> While I do feel like Guix's community could be much larger (see below), the one that exists is very helpful and nice from my limited experience. In all places I've looked so far (Libera's <code>#guix</code>, /r/Guix, and the guix/guix Codeberg repository) I was met with genuinely kind and helpful people.
</p>

<p>
That is not to say I haven't seen some bad eggs, especially in posts from years ago, but I don't think there is any community without those, so I'm not going to cite this as a negative.
</p></li>
<li><b>Home configuration:</b> Having <code>guix home</code> be a built-in, first class citizen, instead of a community made "extension" is excellent. Instead of needing to consult a third-party resource like Home Manager's <a href="https://nix-community.github.io/home-manager/">documentation</a> you can simply use what you already know about Guix and, if you happen to hit a wall, you can just read the <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Home-Configuration.html">official handbook</a> which is guaranteed to always stay up to date with the rest of the system.</li>
<li><b>Package availability:</b> As long as you largely use FOSS stuff (which is much easier than one might think), the amount of choice is awesome. I could basically just copy over the list of packages from my Nix config and practically everything had an equivalent.</li>
<li><p>
<b>Scheme:</b> I'm not really a seasoned Schemer, but I have dabbled in the language previously and it feels so much better to me than Nix (the language) ever did. One great benefit of this is that it's a lot easier to start digging into package definitions to figure things out for yourself.
</p>

<p>
This is "<a href="https://www.gnu.org/philosophy/free-sw.html#make-changes">Freedom 1</a>" of GNU's Four Essential Freedoms in effect. Since the code is pretty much just Scheme and the different mechanisms available are fairly well documented (see caveat below), the barrier to entry is much lower than with Nix in my opinion.<sup><a role="doc-backlink" id="fnr.7" href="#fn.7">7</a></sup>
</p>

<p>
Another nice benefit of this is that you can use Emacs' extensive Scheme support to help your configuration. Tools like <a href="https://github.com/emacsmirror/geiser">Geiser</a> can plug right into Guix and help you find package and function names and, once you're experienced enough, debug your config/packages on the fly. I personally haven't yet achieved mastery of such level yet, but having the REPL confirm if I've entered names in correctly before running the code is already a boon.
</p></li>
<li><p>
<b>Ease of hacking:</b> In the "to tinker on" sense, rather than "being insecure". With Nix, merely pulling in Nixpkgs is an effort, due to the repository being massive. My otherwise beefy machine struggled to switch between branches and make commits, which doesn't exactly inspire confidence in contributing, even though it was otherwise something I was excited to do. Meanwhile, with Guix I was able to get a fully functioning development environment in 15 minutes tops, which includes cloning the repo, authenticating all commits, generating bytecode for the entire repository, and getting Emacs set up to work nice with the codebase.
</p>

<p>
Not to mention, at the time of writing <a href="https://github.com/NixOS/nixpkgs/pull/453219">my Nixpkgs PR of guile-colorized</a> is still not accepted, despite being open since October, 2025. Which is kind of disheartening, when the package is really trivial and has a very low blast-radius. With Guix I <a href="https://codeberg.org/guix/guix/pulls/5962">got an answer</a> to an extremely noobish question on my first PR in mere hours.
</p>

<p>
On a separate, but related note, I also found it a lot easier to test my package in a "live" environment as <code>guix pull</code> supports a parameter called <code>--url</code> which you can easily point to a folder on your own PC. So once I was confident my code should work, I could just "check out" my local repository clone and build it like I was an end user. This let me make sure it really does work.
</p></li>
</ul>
</div>
</div>
<div id="outline-container-the-ambiguous">
<h3 id="the-ambiguous"><span>6.2.</span> The Ambiguous</h3>
<div id="text-6-2">
<ul>
<li><p>
<b>Search:</b> <code>guix search</code> not taking an extra parameter like <code>nix search</code> is both very convenient and a bit of a bummer.
</p>

<p>
Its absence is not a deal breaker, but I really loved how with Nix, you could search in <i>anything</i>, that has a flake. Be that Nixpkgs, a repo you downloaded, a repo that's on a git forge, etc. I remember being awestruck that I could just do <code>nix search github:mozilla/nixpkgs-mozilla</code> and search for their builds of Firefox without having to manually check out anything.
</p></li>
<li><p>
<b>The documentation:</b> Oof, this one is a bit hard to pass definite judgment on.
</p>

<p>
On one hand I love the thoroughness of it all. You can get a fairly decent idea of what Guix, what it can do for your, how to use it, and how to extend it, just by reading the manual. It is evident that the Guix team and GNU in general takes its mission to educate using free software very seriously. Stuff like the <a href="https://guix.gnu.org/cookbook/en/html_node/Packaging-Tutorial.html">Packaging tutorial</a> make it very easy for complete beginners to hack together package definitions without needing to consult any other resource.
</p>

<p>
On the other hand, it really is just a manual, not a tutorial. What I mean by this is that concepts that could belong together aren't placed near each other. A simple example would be <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Services.html">services</a> and <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Service-Reference.html#:~:text=modify-services%20services">customizing them</a>. Assuming, you're in one of the sub-pages of Services and you suddenly realize you want to replace/modify one of the services, you are left completely clueless how that works. You have to go to a completely different chapter and find one particular function's description and then apply what you learn there. The <a href="https://guix.gnu.org/cookbook/en/guix-cookbook.html">Guix Cookbook</a> has some examples, but you have to know about the cookbook in the first place.
</p>

<p>
And before anyone misunderstands me, I'm fine with RTFM, but in my opinion one of the preconditions of mass-appeal is having "pre-chewed" solutions for common problems, that don't require perusing multiple chapters.
</p></li>
</ul>
</div>
</div>
<div id="outline-container-the-bad">
<h3 id="the-bad"><span>6.3.</span> The Bad</h3>
<div id="text-6-3">
<ul>
<li><b>Substitute server stability:</b> I imagine this is an issue that only a massive bag of money could fix, but the CI/CD servers could definitely use some more processing power. It's really annoying when you're trying to test something and you're suddenly forced to wait 10-15 minutes because the server can only spare 50-100 kbps for you.</li>
<li><p>
<b>Content out there:</b> Clearly this isn't the Guix team's fault (and it's something I'm trying to lessen with this post, even if just a tiny bit), but it's really hard to find good quality material when it comes to Guix.
</p>

<p>
I mean, sure, there is the excellent <a href="https://systemcrafters.net/craft-your-system-with-guix/">System Crafters</a> tutorial series, and the odd gems like <a href="https://dthompson.us/posts/guix-for-development.html">DThompson's dev env tutorial</a>, but as a whole you're largely left to your own to trawl through the manual, IRC logs, Reddit threads, Codeberg and the previous issue tracker, etc. It's not an impossible task, especially if you're used to doing Linux things "the hard way", but it's certainly a far cry from such one-stop shops as <a href="https://nixos-and-flakes.thiscute.world/nixos-with-flakes/introduction-to-flakes">the Nix Flakes book</a> or <a href="https://mhwombat.codeberg.page/nix-book/">Wombat's Book of Nix</a>.
</p></li>
<li><b>Guix's own build speed:</b> Nix excels in speed, so I was hoping Guix would be the same. Yet stuff like <code>guix pull</code> really bog things down. Doubly so, if you want to update not just your own <code>guix</code> instance, but also root's.</li>
<li><b>Clarity of commands:</b> The fact that all concerns are lumped together (unlike Nix's many utilities) means that to the new user the many commands such as <code>guix pull</code>, <code>guix {system, home} reconfigure</code>, <code>guix update</code> can easily feel overwhelming and unclear what's updating/changing what. With time I'm sure you obtain a sort of mental muscle memory and you never think about it again, but starting out it's definitely a confusing part.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-overall">
<h2 id="overall"><span>7.</span> Overall</h2>
<div id="text-7">
<div>
<p><label><span>Listing 2: </span>My current, fairly barebones Guix home config.</label></p><pre><span> 1: </span>(<span>define-module</span> (<span>guix-home-config</span>)
<span> 2: </span>  <span>#:use-module</span> (nongnu packages)
<span> 3: </span>  <span>#:use-module</span> (gnu packages)
<span> 4: </span>  <span>#:use-module</span> (gnu home)
<span> 5: </span>  <span>#:use-module</span> (gnu home services)
<span> 6: </span>  <span>#:use-module</span> (gnu home services shells)
<span> 7: </span>  <span>#:use-module</span> (gnu services)
<span> 8: </span>  <span>#:use-module</span> (gnu system shadow)
<span> 9: </span>  <span>#:use-module</span> (guix gexp))
<span>10: </span>
<span>11: </span>(<span>define</span> <span>%packages</span>
<span>12: </span>  (list <span>"git"</span> <span>"openssh"</span> <span>"librewolf"</span> <span>"ripgrep"</span>
<span>13: </span>        <span>"bat"</span> <span>"eza"</span> <span>"fd"</span> <span>"zoxide"</span> <span>"bc"</span> <span>"gimp"</span>
<span>14: </span>        <span>"libreoffice"</span> <span>"jujutsu"</span> <span>"starship"</span> <span>"direnv"</span>
<span>15: </span>        <span>"okular"</span> <span>"gwenview"</span> <span>"bitwarden-desktop"</span>
<span>16: </span>        <span>"icedove-wayland"</span> <span>"telegram-desktop"</span>
<span>17: </span>        <span>"emacs-vterm"</span> <span>"ispell"</span> <span>"hunspell"</span> <span>"wezterm"</span>))
<span>18: </span>
<span>19: </span>(<span>define</span> <span>%nonfree-packages</span>
<span>20: </span>  (list <span>"steam-nvidia"</span>
<span>21: </span>        <span>"mpv-nvidia"</span>))
<span>22: </span>
<span>23: </span>(<span>define</span> <span>home-config</span>
<span>24: </span>  (home-environment
<span>25: </span>   (packages (specifications-&gt;packages (append %nonfree-packages %packages)))
<span>26: </span>   (services
<span>27: </span>    (append
<span>28: </span>     (list
<span>29: </span>      (service home-bash-service-type
<span>30: </span>               (home-bash-configuration
<span>31: </span>                 (aliases '((<span>"ls"</span> . <span>"eza"</span>)))
<span>32: </span>                 (bashrc (list (local-file <span>"./bashrc.sh"</span>)))))
<span>33: </span>
<span>34: </span>      (service home-files-service-type
<span>35: </span>               `((<span>".guile"</span> ,%default-dotguile)
<span>36: </span>                 (<span>".Xdefaults"</span> ,%default-xdefaults)))
<span>37: </span>
<span>38: </span>      (service home-xdg-configuration-files-service-type
<span>39: </span>               `((<span>"gdb/gdbinit"</span> ,%default-gdbinit)
<span>40: </span>                 (<span>"nano/nanorc"</span> ,%default-nanorc))))
<span>41: </span>
<span>42: </span>     %base-home-services))))
<span>43: </span>
<span>44: </span>home-config
</pre>
</div>

<p>
In a nutshell I'm very positively surprised by Guix System. After struggling so much with it years ago, this time everything just clicked after a much shorter battle. So much so that I'm happy to make it my daily driver for the foreseeable future. Beyond the slightly slower execution speed, I'm getting a comparable experience to NixOS, with all the usual pros a declarative environment brings and without having to put up with Nixlang.
</p>

<p>
My only recurring issues so far are the occasional slow download speeds and that I have to start my kernel in <code>nomodeset</code> because otherwise the graphical environment crashes without me being able to switch to a TTY. It's a bummer, but honestly, I'm not too bothered by it so far. I'm trusting a driver update will fix it soon enough and, if not, it's not exactly difficult to <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/operating_002dsystem-Reference.html#:~:text=kernel-arguments">throw in a kernel parameter</a> into your config.
</p>

<p>
I'm hoping to do a followup post about packaging in Guix, because I've been dipping my toes into it by <a href="https://codeberg.org/guix/guix/pulls/6020">trying to package</a> Wezterm and the journey there was similarly arduous as installing the system itself.
</p>

<p>
Till then, thank you for reading and see you next time!
</p>
</div>
</div>
<div id="outline-container-notes">
<h2 id="notes"><span>8.</span> Notes</h2>
<div id="text-8">
<p>
The stuff you see below are all I managed to write down mid-process. Some of these I threw it into the file from Nano, some from half-broken X11 sessions. Because of this, it's not exactly well-edited, but I hope it might provide a glimpse into my mind at the time.
</p>

<blockquote>
<ul>
<li>The installer is decently simple
<ul>
<li>I appreciate the warning about incompatible hardware</li>
</ul></li>
<li>2.5 hours at least to install (mirrors throttle connection to 50kbps)</li>
<li>KDE is simply not working out of the box (titlebars are missing)
<ul>
<li>It seems to also default to X11, when I'm looking for Wayland</li>
</ul></li>
<li>The first <code>guix pull</code> is horrendously slow</li>
<li>Wayland continues to elude me, seems to be an Nvidia issue
<ul>
<li>IRC recommends <code>nomodeset</code>, doesn't help</li>
</ul></li>
<li>Try enabling Nonguix, system no longer boots</li>
<li>Try installing using the Nonguix ISO
<ul>
<li>Lots of errors, terribly old release</li>
<li>Having to <code>guix pull</code> myself to the present day again</li>
<li>Also I'm missing the introduction, so I have to run it using <code>--disable-authentication</code>, not great, but I trust the Codeberg repo</li>
<li>At least the download speed seems to have normalized</li>
</ul></li>
<li>It isn't entirely clear when you have to use <code>sudo</code></li>
<li>Running <code>i3</code> on a shitty low-res has a certain vibe to it, but I'd prefer a system working out of the box</li>
</ul>
</blockquote>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Giving up upstream-ing my patches & feel free to pick them up" (140 pts)]]></title>
            <link>https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118080.html</link>
            <guid>46835454</guid>
            <pubDate>Sat, 31 Jan 2026 10:53:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118080.html">https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118080.html</a>, See on <a href="https://news.ycombinator.com/item?id=46835454">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>xtex</b> 
    <a href="mailto:hotspot-dev%40openjdk.org?Subject=Re%3A%20Giving%20up%20upstream-ing%20my%20patches%20%26%20feel%20free%20to%20pick%20them%20up&amp;In-Reply-To=%3C4555062.ejJDZkT8p0%40xtex1%3E" title="Giving up upstream-ing my patches &amp; feel free to pick them up">xtex at envs.net
       </a><br>
    <i>Sat Jan 31 09:51:36 UTC 2026</i>
    <ul>
        <li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118077.html">RFR: 8372942: AArch64: Set JVM flags for Neoverse V3AE core [v2]
</a></li>
        <li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118081.html">Giving up upstream-ing my patches &amp; feel free to pick them up
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/date.html#118080">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/thread.html#118080">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/subject.html#118080">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/author.html#118080">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Hi,

About one year ago, in Jan. 2025, I began my adventure of the OpenJDK 
codebase. Later I attempted to make some patches into the repository.
I checked the documentation and learned that I have to sign an Oracle 
Contributor Agreement before submitting patches to OpenJDK. At that time, I 
dreamed that it was just a pretty normal CLA, like the ones I signed for other 
projects and shall just take at most several days.

A few days later, I received an email asking me to update some information in 
the agreement. I did. After that, I have sent 5 emails to 
<a href="https://mail.openjdk.org/mailman/listinfo/hotspot-dev">opensource_ww_grp at oracle.com</a> asking if there was anything wrong (once a month 
from January to May). For each of my emails, I got a reply, saying that they 
"sincerely apologize" and "@Dalibor Topic Can you please review...", with no 
actual progress being made. Now it has been (more than) one year since I 
submitted my first OCA submission. And I have been tired of "/touch"-ing my PR 
once a month.

I wonder if there is a reason for not reviewing my OCA submission. I do live 
in Chinese Mainland but I have no contractual or subordinate or teacher-
student relationship with any entities that are restricted by the US import/
export control laws (according to OpenSanctions). If you think that I have 
such a relationship or should be rejected for any other reasons, please simply 
reject my OCA submission, instead of hanging it for months.

As I no longer have enough interest and spare time to work on OpenJDK, I 
decided to give up upstreaming those patches.
If anyone is interested in them, please feel free to pick up and submit these 
patches, most of which are small but I believe they are useful.
As OCA requires that "each contribution that you submit is and shall be an 
original work of authorship", you may rewrite my patches from scratch so it is 
an original work, and you don't need to sign my name or ping me.

I would like to give a list of the patches that I wanted to upstream but 
failed:

- Checks if "llvm-config" is broken:
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
6a8b12b1ad700d994a2803de593ca06e698ef1a9
- Extend default thread stack size for zero:
This addresses the stack overflow exception in javac when building JDK 24 with 
zero variants.
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
4534fcaafc149f649105dc9914c7cf4aaf8c802c
<a href="https://www.mail-archive.com/build-dev@openjdk.org/msg14818.html">https://www.mail-archive.com/build-dev@openjdk.org/msg14818.html</a>

Some patches that are not for the upstream OpenJDK but Loongson's fork of JDK 
and were also blocked by OCA:
<a href="https://github.com/loongson/jdk/pull/134">https://github.com/loongson/jdk/pull/134</a>
<a href="https://github.com/loongson/jdk/pull/126">https://github.com/loongson/jdk/pull/126</a>
<a href="https://github.com/loongson/jdk/pull/125">https://github.com/loongson/jdk/pull/125</a>
<a href="https://github.com/loongson/jdk/pull/135">https://github.com/loongson/jdk/pull/135</a>
<a href="https://github.com/loongson/jdk/pull/136">https://github.com/loongson/jdk/pull/136</a>
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
913dcb2b2759437876ae3a40a1b074eeb1bfe09f
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
caba8e6de73fd9ffa078d6c257d6be8500b9d16a

Best wishes,
Bye.
-- 
Bingwu Zhang (a.k.a. xtex) @ Sat, 31 Jan 2026 08:42:31 +0000



</pre>


<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118077.html">RFR: 8372942: AArch64: Set JVM flags for Neoverse V3AE core [v2]
</a></li>
	<li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118081.html">Giving up upstream-ing my patches &amp; feel free to pick them up
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/date.html#118080">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/thread.html#118080">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/subject.html#118080">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/author.html#118080">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://mail.openjdk.org/mailman/listinfo/hotspot-dev">More information about the hotspot-dev
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euro firms must ditch Uncle Sam's clouds and go EU-native (718 pts)]]></title>
            <link>https://www.theregister.com/2026/01/30/euro_firms_must_ditch_us/</link>
            <guid>46835336</guid>
            <pubDate>Sat, 31 Jan 2026 10:34:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/01/30/euro_firms_must_ditch_us/">https://www.theregister.com/2026/01/30/euro_firms_must_ditch_us/</a>, See on <a href="https://news.ycombinator.com/item?id=46835336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Opinion</span> I'm an eighth-generation American, and let me tell you, I wouldn't trust my data, secrets, or services to a US company these days for love or money. Under our current government, we're simply not trustworthy.</p>
<p>In the Trump‑redux era of 2026, European enterprises are finally taking data seriously, and that means packing up from Redmond-by-Seattle and moving their most sensitive workloads home. This isn't just compliance theater; it's a straight‑up national economic security play.</p>
<div><p><img src="https://regmedia.co.uk/2021/08/25/shutterstock_penguins.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="penguins"></p><h2 title="Freedom can be very contagious if it grows on its own terms. Europe of all places should know that">Open source's new mission: Rebuild a continent's tech stack</h2>
<p><a href="https://www.theregister.com/2026/01/19/open_sources_new_mission_rebuild/"><span>READ MORE</span></a></p></div>
<p>Europe's digital sovereignty paranoia, long waved off as regulatory chatter, is now feeding directly into procurement decisions. Gartner told <em>The Reg</em> last year that IT spending in Europe is set to grow by 11 percent in 2026, <a target="_blank" href="https://www.theregister.com/2025/11/14/it_spending_europe/">hitting $1.4 trillion</a>, with a big chunk rolling into "sovereign cloud" options and on‑prem/edge architectures.</p>
<p>The kicker? Fully <a target="_blank" href="https://www.theregister.com/2025/11/13/gartner_cio_cloud_sovereignty/">61 percent of European CIOs and tech leaders</a> say they want to increase their use of local cloud providers. More than half say geopolitics will prevent them from leaning further on US‑based hyperscalers.</p>
<p>The American hypercloud vendors have figured this out. <a target="_blank" href="https://www.theregister.com/2026/01/15/aws_european_sovereign_cloud/">AWS recently made its European Sovereign Cloud available</a>. This AWS cloud, Amazon claims, is "entirely located within the EU, and physically and logically separate from other AWS Regions." On top of that, EU residents will "independently operate it" and "be backed by strong technical controls, sovereign assurances, and legal protections designed to meet the needs of European governments and enterprises for sensitive data."</p>

    

<p>Many EU-based companies aren't pleased with this Euro-washing of American hypercloud services. The Cloud Infrastructure Service Providers in Europe (CISPE) trade association accuses the EU Cloud Sovereignty Framework of being <a target="_blank" href="https://www.theregister.com/2025/10/27/cispe_eu_sovereignty_framework/">set up to favor the incumbent</a> (American) hypercloud providers.</p>

        


        

<p>They're not wrong.</p>
<p>You don't need a DEA warrant or a Justice Department subpoena to see the trend: Europe's 90‑plus‑percent dependency on US cloud infrastructure, as former European Commission advisor <a target="_blank" href="https://www.theregister.com/2025/12/22/europe_gets_serious_about_cutting/">Cristina Caffarra put it, is a single‑shock‑event security nightmare</a> waiting to rupture the EU's digital stability.</p>

        

<p>Seriously. What will you do if Washington decides to unplug you? Say Trump gets up on the wrong side of the bed and decides to invade Greenland. There goes NATO, and in all the saber-rattling leading up to the 10th Mountain Division being shipped to Nuuk, he orders American companies to cut their services to all EU countries and the UK.</p>
<ul>

<li><a href="https://www.theregister.com/2026/01/26/cursor_opinion/">When AI 'builds a browser,' check the repo before believing the hype</a></li>

<li><a href="https://www.theregister.com/2026/01/16/linus_torvalds_vibe_coding/">Just because Linus Torvalds vibe codes doesn't mean it's a good idea</a></li>

<li><a href="https://www.theregister.com/2025/12/31/long_lived_tech/">The most durable tech is boring, old, and everywhere</a></li>

<li><a href="https://www.theregister.com/2025/12/22/what_linux_desktop_really_needs/">What the Linux desktop really needs to challenge Windows</a></li>
</ul>
<p>With the way things are going, they're not going to say no. I mean, CEOs Tim Cook of Apple, Eric Yuan of Zoom, Lisa Su of AMD, and – pay attention – Amazon's Andy Jassy all went obediently to watch a feature-length White House screening of Melania, the universally-loathed, 104‑minute Amazon‑produced documentary about First Lady Melania Trump.</p>
<div><p><img src="https://regmedia.co.uk/2016/05/20/shutterstock_plane.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Plane. Image via shutterstock"></p><h2 title="Countries that banded together to challenge Boeing in the air try to do the same to AWS, Microsoft, and Google on the ground">Europe's cloud challenge: Building an Airbus for the digital age</h2>
<p><a href="https://www.theregister.com/2025/12/29/europes_cloud_challenge_building_an/"><span>READ MORE</span></a></p></div>
<p>Sure, that's a silly example, but for American companies to do business today, they're kowtowing to Trump. Or, take a far more serious example, when Minnesota company CEOs called for "de-escalation" in the state, there was not one word about ICE or the government's role in the bloodshed. It was the corporate equivalent of the mealy-mouthed "thoughts and prayers" American right-wingers always say after a US school shooting.</p>
<p>Some companies have already figured out which way the wind is blowing. Airbus, the European aerospace titan, has put out a €50 million, decade‑long tender to migrate its <a target="_blank" href="https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/">mission‑critical applications to a "sovereign European cloud."</a> Airbus wants its whole stack – data at rest, data in transit, logging, IAM, and security‑monitoring infrastructure – all rooted in EU law and overseen by EU operators. As Catherine Jestin, Airbus's executive vice president of digital, told <em>The Register</em>: "We want to ensure this information remains under European control."</p>
<p>Who can blame them? Thanks to the American CLOUD Act and related US surveillance statutes, US‑headquartered providers must hand over European data regardless of where the bytes sit. Exhibit A is that <a target="_blank" href="https://www.theregister.com/2025/07/25/microsoft_admits_it_cannot_guarantee/">Microsoft has already conceded that it cannot guarantee data independence from US law enforcement</a>. Airbus is betting that "data residency on paper" from AWS‑styled "EU sections" is not enough. Real sovereignty demands EU‑owned and run operations with full contractual and legal firewalls. Sure, your data may live in Frankfurt, but your fate still rests in Seattle, Redmond, or Mountain View if an American company owns your cloud provider.</p>
<p>Besides, do you really want some Trump apparatchik getting their hands on your data? I mean, this is a government where Madhu Gottumukkala, the acting director of the US Cybersecurity and Infrastructure Security Agency, <a target="_blank" rel="nofollow" href="https://www.politico.com/news/2026/01/27/cisa-madhu-gottumukkala-chatgpt-00749361">uploaded sensitive data into ChatGPT</a>!</p>
<div><p><img src="https://regmedia.co.uk/2019/04/26/plug_shutterstock.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="plug"></p><h2 title="Campaigners say Britain's dependence on Big Tech leaves critical systems exposed to political pressure">UK urged to unplug from US tech giants as digital sovereignty fears grow</h2>
<p><a href="https://www.theregister.com/2026/01/06/uk_urged_to_unplug_from/"><span>READ MORE</span></a></p></div>
<p>In response, Brussels is pushing an <a target="_blank" href="https://www.theregister.com/2025/12/29/europes_cloud_challenge_building_an/">open source‑led exit from hyperscaler lock‑in</a>. Ministries are standardizing on Nextcloud‑style collaboration stacks instead of Microsoft 365 to fund Euro‑native clouds via the European Cloud Alliance. Some countries, like France, are already <a target="_blank" href="https://www.theregister.com/2026/01/27/france_videoconferencing_visio/?td=rt-3a">shoving Zoom, Teams, and other US videoconferencing platforms out the door</a> in favor of a local service.</p>
<p>If you're running an EU‑based firm in 2026, the takeaway isn't that AWS‑in‑Frankfurt is evil; it's that for certain workloads, especially national security, industrial IP, or high‑profile consumer data franchises, EU‑native cloud and services are no longer a nice‑to‑have but a business continuity plan requirement.</p>

        

<p>It's time to get serious about digital sovereignty. The clock is ticking, and there's no telling when Trump will go off. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Automatic Programming (201 pts)]]></title>
            <link>https://antirez.com/news/159</link>
            <guid>46835208</guid>
            <pubDate>Sat, 31 Jan 2026 10:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/159">https://antirez.com/news/159</a>, See on <a href="https://news.ycombinator.com/item?id=46835208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section id="newslist"><article data-news-id="159"><h2><a href="https://antirez.com/news/159">Automatic programming</a></h2></article></section><topcomment><article data-comment-id="159-" id="159-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 3 hours ago. 17855 views.  </span><pre>In my YouTube channel, for some time now I started to refer to the process of writing software using AI assistance (soon to become just "the process of writing software", I believe) with the term "Automatic Programming".

In case you didn't notice, automatic programming produces vastly different results with the same LLMs depending on the human that is guiding the process with their intuition, design, continuous steering and idea of software.

Please, stop saying "Claude vibe coded this software for me". Vibe coding is the process of generating software using AI without being part of the process at all. You describe what you want in very general terms, and the LLM will produce whatever happens to be the first idea/design/code it would spontaneously, given the training, the specific sampling that happened to dominate in that run, and so forth. The vibe coder will, at most, report things not working or not in line with what they expected.

When the process is actual software production where you know what is going on, remember: it is the software *you* are producing. Moreover remember that the pre-training data, while not the only part where the LLM learns (RL has its big weight) was produced by humans, so we are not appropriating something else. We can pretend AI generated code is "ours", we have the right to do so. Pre-training is, actually, our collective gift that allows many individuals to do things they could otherwise never do, like if we are now linked in a collective mind, in a certain way.

That said, if vibe coding is the process of producing software without much understanding of what is going on (which has a place, and democratizes software production, so it is totally ok with me), automatic programming is the process of producing software that attempts to be high quality and strictly following the producer's vision of the software (this vision is multi-level: can go from how to do, exactly, certain things, at a higher level, to stepping in and tell the AI how to write a certain function), with the help of AI assistance. Also a fundamental part of the process is, of course, *what* to do.

I'm a programmer, and I use automatic programming. The code I generate in this way is mine. My code, my output, my production. I, and you, can be proud.

If you are not completely convinced, think to Redis. In Redis there is not much technical novelty, especially at its start it was just a sum of basic data structures and networking code that every competent system programmer could write. So, why it became a very useful piece of software? Because of the ideas and visions it contained.

Programming is now automatic, vision is not (yet).</pre></article></topcomment>


<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CERN accepts $1B in private cash towards Future Circular Collider (137 pts)]]></title>
            <link>https://physicsworld.com/a/cern-accepts-1bn-in-private-cash-towards-future-circular-collider/</link>
            <guid>46835124</guid>
            <pubDate>Sat, 31 Jan 2026 09:58:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://physicsworld.com/a/cern-accepts-1bn-in-private-cash-towards-future-circular-collider/">https://physicsworld.com/a/cern-accepts-1bn-in-private-cash-towards-future-circular-collider/</a>, See on <a href="https://news.ycombinator.com/item?id=46835124">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-126061">
		<div>

				<!-- Issue information -->
				
				<!-- Standfirst -->
										<p>Mark Thomson takes the reins at the CERN particle-physics lab, which recently received $1bn in private donations for its next collider project, as <strong>Michael Banks </strong>reports</p>
				
				<!-- Thumbnail -->
												<figure>
										<a href="https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026.jpg" data-fancybox="" data-src="https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026.jpg" data-caption="igger and better: The Large Hadron Collider at CERN will shut down later this year to make way for a major upgrade – the High-Luminosity LHC (courtesy: CERN)
">
												<img src="https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026-635x423.jpg" srcset="
															https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026.jpg 1440w,
															https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026-635x423.jpg 635w" sizes="(max-width: 768px) 100vw, 635w" alt="The Large Hadron Collider" title="cern-19-01-2026" width="635" height="423">
										</a>
																						
																				<figcaption>Bigger and better: The Large Hadron Collider at CERN will shut down later this year to make way for a major upgrade – the High-Luminosity LHC (courtesy: CERN)
</figcaption>
								</figure>
								<p>The CERN particle-physics lab near Geneva <a href="https://home.cern/news/press-release/cern/private-donors-pledge-860-million-euros-cerns-future-circular-collider">has received $1bn</a> from private donors towards the construction of the <a href="https://home.cern/science/accelerators/future-circular-collider">Future Circular Collider</a> (FCC). The cash marks the first time in the lab’s 72-year history that individuals and philanthropic foundations have agreed to support a major CERN project. If built, the FCC would be the successor to the Large Hadron Collider (LHC), where the Higgs boson was discovered.</p>
<p>CERN originally released&nbsp;<a href="https://physicsworld.com/a/europe-unveils-successor-to-the-large-hadron-collider/">a four-volume conceptual design report</a>&nbsp;for the FCC in early 2019, with more detail included in a <a href="https://cds.cern.ch/record/2928193">three-volume feasibility study</a> that came out last year. It calls for a giant tunnel some 90.7 km in circumference – roughly three times as long as the LHC&nbsp; – that would be built about 200&nbsp;m underground on average.</p>
<p>The FCC has been recommended as the preferred option for the next flagship collider at CERN in the <a href="https://url.uk.m.mimecastprotect.com/s/xtPXC0Rv8tvN53FRhwF9G-Hn?domain=u7061146.ct.sendgrid.net">ongoing process to update the European Strategy for Particle Physics</a>, which will be passed over to the &nbsp;CERN Council in May 2026.If the plans are given the green light by CERN Council in 2028, construction on the FCC electron-positron machine, dubbed FCC-ee, would begin in 2030. It would start operations in 2047, a few years after the High Luminosity LHC (HL-LHC) closes down, and run for about 15 years until the early 2060s.</p>
<p>The FCC-ee would focus on creating a million Higgs particles in total to allow physicists to study its properties with an accuracy an order of magnitude better that possible with the LHC. The FCC feasibility study then calls for a hadron machine, dubbed FCC-hh, to replace the FCC-ee in the existing 91 km tunnel. It would be a “discovery machine”, smashing together protons at high energy – about 85 TeV – with the aim of creating new particles. If built, the FCC-hh will begin operation in 2073 and run to the end of the century.</p>
<p>The funding model for the FCC-ee, which is expected to have a price tag of about $18bn, is still a work in progress. But it is estimated that at least two-thirds of the construction costs will come from CERN’s 24 member states with the rest needing to be found elsewhere. One option to plug that gap is private donations and in late December CERN received a significant boost from several organizations including the Breakthrough Prize Foundation, the Eric and Wendy Schmidt Fund for Strategic Innovation, and the entrepreneurs John Elkann and Xavier Niel. Together, they pledged a total of $1bn towards the FCC-ee.</p>
<p>Costas Fountas, president of the CERN Council, says CERN is “extremely grateful” for the interest. “This once again demonstrates CERN’s relevance and positive impact on society, and the strong interest in CERN’s future that exists well beyond our own particle physics community,” he notes.</p>
<p>Eric Schmidt, who founded Google, claims that he and Wendy Schmidt were “inspired by the ambition&nbsp;of this project and by what it could mean for the future of humanity”. The FCC, he believes, is an instrument that “could push the boundaries of human knowledge and deepen our understanding of the fundamental laws of the Universe” and could lead to technologies that could benefit society “in profound ways” from medicine to computing to sustainable energy.</p>
<p>The cash promised has been welcomed by outgoing CERN director-general Fabiola Gianotti. “It’s the first time in history that private donors wish to partner with CERN to build an extraordinary research instrument that will allow humanity to take major steps forward in our understanding of fundamental physics and the universe,” she said. “I am profoundly grateful to them for their generosity, vision, and unwavering commitment to knowledge and exploration.”</p>
<h3>Further boost</h3>
<p>The cash comes a few months after the Circular Electron–Positron Collider (CEPC) – a rival collider to the FCC-ee that also involves building a huge 100 km tunnel to study the Higgs in unprecedented detail – was not considered for inclusion in China’s next five-year plan, which runs from 2026 to 2030. There has been much discussion in China about whether the CEPC is the right project for the country, with the collider facing criticism from particle physicist and Nobel laureate Chen-Ning Yang, before he died last year.</p>
<p>Wang Yifang of the Institute of High Energy Physics (IHEP) in Beijing says they will submit the CEPC for consideration again in 2030 unless FCC is officially approved before then. But for particle theorist John Ellis from Kings College London, China’s decision to effectively put the CEPC on the back burner &nbsp;“certainly simplifies the FCC discussion”. “However, an opportunity for growing the world particle physics community has been lost, or at least deferred [by the decision],” Ellis told <em>Physics World</em>.</p>
<p>Ellis adds, however, that he would welcome China’s participation in the FCC. “Their accelerator and detector [technical design reviews] show that they could bring a lot to the table, if the political obstacles can be overcome,” he says. </p><article>
			<a href="https://physicsworld.com/a/cern-releases-plans-for-the-most-extraordinary-instrument-ever-built/">
				<div>
					<p>Read more</p>
					<p><img decoding="async" width="129" height="90" src="https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-129x90.jpg" alt="Outline of the FCC near Geneva" srcset="https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-129x90.jpg 129w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-211x148.jpg 211w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-317x222.jpg 317w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-768x538.jpg 768w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-571x400.jpg 571w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-589x412.jpg 589w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-586x410.jpg 586w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-635x445.jpg 635w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-281x197.jpg 281w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-257x180.jpg 257w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-300x210.jpg 300w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-128x90.jpg 128w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN.jpg 1000w" sizes="(max-width: 129px) 100vw, 129px">
				</p></div>
				<h4><p>CERN releases plans for the ‘most extraordinary instrument ever built’</p>
</h4>
			</a>
		</article>
<p>However, if the FCC-ee goes ahead China could perhaps make significant “in-kind” contributions rather like those that occur with the ITER experimental fusion reactor, which is currently being built in France. In this case, instead of cash payments, the countries provide components, equipment and other materials.</p>
<p>Those considerations and more will now fall to the British physicist Mark Thomson, who took over from Gianotti as CERN director-general on 1 January for a five-year term. As well as working on funding requirements for the FCC-ee, top of his in-tray will actually be shutting down the LHC in June to make way for further work on the HL-LHC, which involves installing powerful new superconducting magnets and improving the detection.</p>
<p>About 90% of the 27 km LHC accelerator will be affected by the upgrade with a major part being to replace the magnets in the final focus systems of the two large experiments, ATLAS and CMS. These magnets will take the incoming beams and then focus them down to less than 10 µm in cross section. The upgrade includes the installation of brand new state-of-the-art niobium-tin (Nb<sub>3</sub>Sn) superconducting focusing magnets.</p>
<p>The HL-LHC will probably not turn on until 2030, at which time Thomson’s term will nearly be over, but that doesn’t deter him from leading the world’s foremost particle-physics lab. “It’s an incredibly exciting project,” Thomson <a href="https://www.theguardian.com/science/2025/dec/31/large-hadron-collider-head-of-cern-mark-thomson">told the <em>Guardian</em></a>. “It’s more interesting than just sitting here with the machine hammering away.”</p>




				

		</div><!-- .entry-content -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We have ipinfo at home or how to geolocate IPs in your CLI using latency (208 pts)]]></title>
            <link>https://blog.globalping.io/we-have-ipinfo-at-home-or-how-to-geolocate-ips-in-your-cli-using-latency/</link>
            <guid>46834953</guid>
            <pubDate>Sat, 31 Jan 2026 09:30:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.globalping.io/we-have-ipinfo-at-home-or-how-to-geolocate-ips-in-your-cli-using-latency/">https://blog.globalping.io/we-have-ipinfo-at-home-or-how-to-geolocate-ips-in-your-cli-using-latency/</a>, See on <a href="https://news.ycombinator.com/item?id=46834953">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
				<blockquote>
<p>TLDR: I made a CLI tool that can resolve an IP address to a country, US state and even a city. <a href="https://github.com/jimaek/geolocation-tool?ref=blog.globalping.io">https://github.com/jimaek/geolocation-tool</a><br>
It works well and confirms ipinfo's findings.</p>
</blockquote>
<p>Recently, I read how <a href="https://ipinfo.io/blog/vpn-location-mismatch-report?ref=blog.globalping.io">ipinfo finally proved</a> what most technical people assumed: VPN providers don't actually maintain a crazy amount of infrastructure in hundreds of countries. They simply fake the IP geolocation by intentionally providing wrong location data to ARIN, RIPE, and Geo DB providers via geofeeds.</p>
<p>They achieved their results using a novel approach compared to other geo IP providers. Based on their blog and HackerNews comments, they built a large probe network and used it to trace and ping every (or most) IP addresses on the internet.</p>
<p>This latency and hop data, most likely along with advanced algorithms and data cross-reference, provides a reliable way of correctly detecting the physical geolocation of an IP address, without relying on faked data available in public sources.</p>
<p>This is a very interesting approach that makes total sense, and I'm sure their clients appreciate it and heavily rely on it.</p>
<p>While I can't ping every single IP address on the internet from hundreds of locations just yet, I can do it to a limited subset using Globalping. So I decided to try it out and see if I can replicate their results and build a small tool to allow anyone to do the same.</p>
<p>Globalping is an open-source, community-powered project that allows users to self-host container-based probes. These probes then become part of our <a href="https://globalping.io/network?ref=blog.globalping.io">public network</a>, which allows anyone to use them to run network testing tools such as ping and traceroute.</p>
<p><img src="https://blog.globalping.io/content/images/2025/12/network-map-globalping.png" alt="network-map-globalping.png" loading="lazy"></p>
<p>At the moment, the network has more than 3000 probes, which in theory should be plenty to geolocate almost any IP address down to a country and even a US state level.</p>
<p>To automate and simplify this process, I made a little CLI tool using the <a href="https://github.com/jsdelivr/globalping-typescript?ref=blog.globalping.io">globalping-ts</a> library. My original idea was simple:</p>
<ol>
<li>Accept a single IP as input</li>
<li>Ping it a few times per continent to select the continent</li>
<li>Then ping the IP from many different probes on that continent</li>
<li>Group and sort the results; the country with the lowest latency should be the correct one</li>
<li>And as a bonus, repeat the same process for USA states if the winning country was the US</li>
</ol>
<p>Essentially, what I had to do was simply create a few measurements and pass the location I needed using Globalping’s magic field, which would automatically figure out what I was looking for and select a few pseudo-random probes that fit the location and limit.</p>
<p>Now initially, I used <code>ping</code> with 2 packets to run all measurements as quickly as possible, but I quickly realized it wasn’t a good idea as most networks block ICMP traffic. Next, I tried switching to TCP-based <code>ping</code>, which required trying a few popular ports to get it to work. I quickly realized this was too complicated and unreliable and switched to <code>traceroute</code>.</p>
<p>It worked perfectly. Even though <code>traceroute</code> uses ICMP by default, it did not matter to me if the target IP’s network allowed ICMP or not, I simply analyzed the latency of the last available hop. Even if you block ICMP, your upstream most likely allows it, and in most cases, it’s located in the same country.</p>
<p>Of course, this means the resulting data is not 100% perfect. A better approach would be to analyze each IP using different methods, including TCP and UDP-based <code>traceroute</code> on different ports, and expand to the last few hops instead of just one. Maybe even try to figure out the location of the registered ASNs and use a weights system in combination with public whois info in order to “vote” for the right location based on different inputs. Probably even mark low certainty IPs to be retested with a double amount of probes. (end of rant)</p>
<p>But that’s something for a commercial provider to figure out, which it seems they did.</p>
<p>For continent detection, I decided to use just 5 probes per continent; the results were extremely accurate. Although for IPs just on the "border" of continents it might be ineffective, a higher amount of probes would generate better results. For this use case, it was good enough.</p>
<p>My home IP in central Europe was too easy to detect:</p>
<pre><code>Phase 1: Detecting continent...
  North America: 137.18 ms
  Europe: 32.39 ms
  Asia: 174.54 ms
  South America: 215.08 ms
  Oceania: 244.15 ms
  Africa: 156.83 ms
</code></pre>
<p>In phase 2, all we need to do is run a single measurement with the winning continent as the location and a higher limit. Initially, I started with 250 probes with great accuracy.</p>
<p>Eventually, I decided to drop down to 50 as the default. Based on my tests, the results continued to look really good, and it would allow the tool to be run even without authentication, as the Globalping API allows 250 tests per hour per IP and 50 probes per measurement.</p>
<p>Although I recommend registering for a free account at <a href="https://dash.globalping.io/?ref=blog.globalping.io">https://dash.globalping.io/</a> and authenticating with a token to get up to 500 tests per hour and run more tests.</p>
<blockquote>
<p>Note: If you need more tests than that, you can either host a probe to generate passive credits to be used as tests, or donate via GitHub Sponsors. We will automatically detect it and credit your account.</p>
</blockquote>
<pre><code>Phase 2: Detecting country...
  Measuring from 50 probes...

  [████████████████████████████████████████] 100.0%   50/50 - Best: PL (7.29 ms)                    

Top 3 Locations:
─────────────────────────────────────────────────
  1.. Poland, EU                               7.29 ms
  2.. Germany, EU                              13.42 ms
  3.. Lithuania, EU                            17.65 ms

═══════════════════════════════════════════════════
                      SUMMARY
═══════════════════════════════════════════════════
  Location: Poland, EU
  Minimum Latency: 7.29 ms
  Confidence: Medium
</code></pre>
<p>Great, now we have a basic IP-to-country resolver that only takes a few seconds to provide a response, and I didn’t even have to understand or write any complicated math. Although I’m sure someone smarter could use a formula to geolocate IPs with even fewer probes and higher accuracy.</p>
<p>For phase 3, we want to resolve the US to a specific state or territory, just like ipinfo did, and luckily they even provided a few sample IPs and locations to benchmark against during testing.</p>
<p>Again, this was as simple as creating a new measurement with the USA as the location. I used 50 probes as the default limit and tested the NordVPN IP advertised as Bahamas but resolved to Miami by ipinfo.</p>
<pre><code>Phase 3: Detecting US state...
  Measuring from 50 probes...

  [████████████████████████████████████████] 100.0%   50/50 - Best: FL (0.45 ms)                    

Top 3 Locations:
─────────────────────────────────────────────────
  1. Florida, USA                             0.45 ms
  2. South Carolina, USA                      12.23 ms
  3. Georgia, USA                             15.01 ms

═══════════════════════════════════════════════════
                      SUMMARY
═══════════════════════════════════════════════════
  Location: Florida, United States
  Minimum Latency: 0.45 ms
  Confidence: Very High
═══════════════════════════════════════════════════
</code></pre>
<p>The tool agrees, Florida is the correct location. But how accurate can this system be? Can we expand it to show the city too?</p>
<p>Let's make a new phase, which again, will simply set the resulting country or state as the location and extract the city of the probe with the lowest latency. Here, since there are too many possible cities and towns per state and country, I expect the accuracy to be low and only point to the closest major hub. But in theory, this should be more than enough for use cases like routing or performance debugging.</p>
<p>And here we go, the same result ipinfo got</p>
<pre><code>Phase 4: Detecting city...
  Measuring from 36 probes...

  [████████████████████████████████████████] 100.0%   36/36 - Best: Miami (0.00 ms)                 

Top 3 Locations:
─────────────────────────────────────────────────
  1. Miami, Florida, USA                      0.00 ms
  2. West Palm Beach, Florida, USA            4.36 ms
  3. Tampa, Florida, USA                      5.85 ms

═══════════════════════════════════════════════════
                      SUMMARY
═══════════════════════════════════════════════════
  Location: Miami, Florida, United States
  Minimum Latency: 0.00 ms
  Confidence: Very High
═══════════════════════════════════════════════════
</code></pre>
<p>The current results are good but could be better. The main problem is with how the magic field works: when setting, for example, 'Europe' as the location, it tries to spread the tests across all European probes but does not guarantee that every single country is going to be included.</p>
<p>This results in inconsistencies where a probe in the same country as the target IP was not selected, and so the tool assumes the IP is located in a different neighbouring country.</p>
<p>To fix this and make the results more consistent, you would need to change the selection logic and manually set every country per continent and US state. By passing the full list of countries/states to the Globalping API, you ensure that at least one probe in that location is going to be selected. Additionally, you fully control the number of probes per location, which is very important to control the accuracy.</p>
<p>For example, North America technically contains 43 countries and territories. This means you can't just set a limit of one probe per country, it is not enough to properly understand the latency to the target IP from the disproportionately larger USA. A better limit would be around 200 probes for the USA, 20 for Canada, and 10 for Mexico.</p>
<p>But the goal of this tool was to use a minimum amount of probes to allow unauthenticated users to test it out. The current approach works great, it is simple to implement and it is very easy to control the accuracy by simply setting a higher limit of probes.</p>
<p>Overall, latency-based geolocation detection seems to be a great way to verify the location of any IP as long as you have enough vantage points. It will most likely fall apart in regions with minimal or no coverage.</p>
<p>The tool itself is open source and you can run it like this:</p>
<p><code>geolocate $IP</code></p>
<p>You can also use the –limit parameter to use more probes per phase. But be careful as it applies the set value to all phases and this will very quickly eat through your limit. Check the full docs in GitHub.</p>
<p>Pull requests with improvements are welcome!</p>
<p>Feel free to email me if you need some free credits to play around with <a href="mailto:d@globalping.io">d@globalping.io</a></p>
<p>And of course consider hosting a probe, it’s as simple as running a container <a href="https://github.com/jsdelivr/globalping-probe?ref=blog.globalping.io">https://github.com/jsdelivr/globalping-probe</a></p>

			</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube blocks background video playback on Brave and other Browsers (184 pts)]]></title>
            <link>https://piunikaweb.com/2026/01/28/youtube-background-play-samsung-internet-brave/</link>
            <guid>46834441</guid>
            <pubDate>Sat, 31 Jan 2026 07:54:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://piunikaweb.com/2026/01/28/youtube-background-play-samsung-internet-brave/">https://piunikaweb.com/2026/01/28/youtube-background-play-samsung-internet-brave/</a>, See on <a href="https://news.ycombinator.com/item?id=46834441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p><strong>Update 30/01/26 – 12:50 pm (IST)</strong>: In a statement to the folks over at <a href="https://www.androidauthority.com/youtube-background-play-broken-3636179/" target="_blank" rel="noopener">Android Authority</a>, Google confirmed that they’ve tweaked the platform experience to prevent non-Premium users from accessing background playback when using browsers.</p>
<blockquote><p>Background playback is a feature intended to be exclusive for YouTube Premium members. While some non-Premium users may have previously been able to access this through mobile web browsers in certain scenarios, we have updated the experience to ensure consistency across all our platforms.</p></blockquote>
<hr>
<p><em><strong>Original article published on January 28, 2026, follows:</strong></em></p>
<p>It looks like YouTube has thrown a wrench into the works for a lot of mobile users who enjoy listening to videos with their screen off. Over the past few days, reports have been flooding in that the handy background video playback feature has suddenly stopped working on Samsung Internet.</p>
<p>Judging by the reports, it seems that the problem seems to have cropped up around a week ago and has since been impacting more users. While a majority of <a href="https://us.community.samsung.com/t5/Galaxy-S25/Background-Play-on-Samsung-Browser-stop-working/m-p/3467684#M50167" target="_blank" rel="nofollow ugc noopener">reports</a> are coming from Samsung Internet users, it’s not the only browser impacted. Users on <a href="https://us.community.samsung.com/t5/Samsung-Apps-and-Services/Background-Video-Play-Issue/td-p/3464259" target="_blank" rel="nofollow ugc noopener">Brave</a>, <a href="https://www.reddit.com/r/oneui/comments/1qni74a/background_audio_play_not_working_on_one_ui_8/" target="_blank" rel="nofollow ugc noopener">Vivaldi</a>, and even <a href="https://www.reddit.com/r/MicrosoftEdge/comments/1qmhv2n/background_playback_not_working/" target="_blank" rel="nofollow ugc noopener">Microsoft Edge</a> have complained about the issue.</p>
<p>What’s happening is pretty specific. When users try to minimize the browser or turn off their screen, the audio cuts out. On Samsung devices, some users <a href="https://www.reddit.com/r/oneui/comments/1qo2rp0/background_play_issue/" target="_blank" rel="nofollow ugc noopener">noticed</a> a fleeting notification that said “MediaOngoingActivity” right before the media controls vanished entirely.</p>
<p><a href="https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint.webp"><img fetchpriority="high" decoding="async" src="https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint.webp" alt="samsung-internet-youtube-background-play-not-working-complaint" width="600" height="339" srcset="https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint.webp 600w, https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint-300x170.webp 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>For years, people have relied on these mobile browser workarounds to get a free taste of what YouTube Premium offers: ad-free viewing and, crucially, background audio. This sudden, simultaneous failure across multiple browsers strongly suggests a targeted change by YouTube.</p>
<p>Samsung’s community forums and subs like r/oneui and r/youtube are becoming hubs to discuss the problem. Users have confirmed that basic troubleshooting tips, like ensuring that PiP mode and JavaScript are enabled, and also clearing the app’s cache, do not work.&nbsp;</p>
<p>Even the privacy-focused Brave browser has a new open issue on its <a href="https://github.com/brave/brave-browser/issues/52254" target="_blank" rel="nofollow ugc noopener">GitHub page</a>, confirming that the background play feature, which was working perfectly, has now failed. This widespread nature makes it hard to blame a single browser update or a simple bug.</p>
<p><a href="https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug.webp"><img decoding="async" src="https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug.webp" alt="brave-browser-youtube-background-playback-bug" width="600" height="1474" srcset="https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug.webp 600w, https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug-122x300.webp 122w, https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug-417x1024.webp 417w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>That said, at least one Brave user <a href="https://www.reddit.com/r/MicrosoftEdge/comments/1qmhv2n/comment/o1zaa1q/" target="_blank" rel="noopener">claims</a> that this problem was fixed, and it now works fine. So I’d suggest Brave users keep an eye out for any new updates and try again (the same goes for other browsers too).</p>
<p>While YouTube hasn’t officially commented, the consensus among users is that the company has finally closed a popular loophole, effectively breaking the YouTube Premium workaround for millions. If you’re searching for why your YouTube background play is not working, or your Samsung Internet background video issue is suddenly a problem, you’re definitely not alone.</p>
<p>If this isn’t a random glitch, then the move is a clear push to convert more users to a paid subscription, leaving those who relied on the feature to either pay up or keep their screens on. We’ve already reported on YouTube’s fresh <a href="https://piunikaweb.com/2026/01/28/newpipe-content-unavailable-error-fix/" target="_blank" rel="noopener">crackdown on third-party clients like NewPipe</a>. So it won’t be a stretch to assume that YouTube is indeed patching such workarounds.</p>
<p>It’s a tough break for anyone who used this trick to listen to podcasts or music videos on the go.</p>
 
              
             </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sumerian Star Map Recorded the Impact of an Asteroid (2024) (138 pts)]]></title>
            <link>https://archaeologyworlds.com/5500-year-old-sumerian-star-map-recorded/</link>
            <guid>46834313</guid>
            <pubDate>Sat, 31 Jan 2026 07:32:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologyworlds.com/5500-year-old-sumerian-star-map-recorded/">https://archaeologyworlds.com/5500-year-old-sumerian-star-map-recorded/</a>, See on <a href="https://news.ycombinator.com/item?id=46834313">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	




<p>For more than 150 years scientists have tried to solve the mystery of a notorious cuneiform clay tablet that reveals that in the past the impact case of so-called Köfel was detected. The circular stone-cast tablet was discovered in the late 1800s from the 650 BC King Ashurbanipal ‘s underground library in Nineveh, Iraq.</p>



<p>Data processing, which was long believed to be an Assyrian tablet, mirrored the sky over Mesopotamia in 3300 BC and proved to be much more <a href="https://archaeologyworlds.com/">ancient Sumerian origin</a>.</p>



<p>The tablet is the first astronomical instrument, the “Astrolabe.”&nbsp; It consists of a segmented, disk-shaped star chart with marked units of angle measure inscribed upon the rim.</p>



<p>Unfortunately considerable parts of the planisphere on this tablet are missing (approximately 40%), damage which dates to the sacking of Nineveh. The reverse of the tablet is not inscribed.</p>


<div>
<figure><img decoding="async" width="768" height="769" src="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min.jpg" alt="Sumerian Star Map Recorded " srcset="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min.jpg 768w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min-300x300.jpg 300w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min-150x150.jpg 150w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min-96x96.jpg 96w" sizes="(max-width: 768px) 100vw, 768px"></figure>
</div>


<p>Still under study by modern scholars, the cuneiform tablet in the <a href="https://www.britishmuseum.org/" target="_blank" rel="noopener">British Museum</a> collection No K8538 (known as “the Planisphere”) provides extraordinary proof for the existence of sophisticated Sumerian astronomy.</p>



<p>In 2008 two authors, Alan Bond and Mark Hempsell published a book about the tablet called&nbsp;“A Sumerian Observation of the Kofels’ Impact Event”.</p>



<p>Raising a storm in archaeological circles, they re-translated the cuneiform text and asserted the tablet records an ancient asteroid strike, the Köfels’ Impact, which struck Austria sometime around 3100 BC.</p>



<p>The giant landslide centred at Köfels in Austria is 500m thick and five kilometres in diameter and has long been a mystery since geologists first looked at it in the 19th century.</p>



<p>The conclusion drawn by research in the middle 20th century was that it must be due to a very large meteor impact because of the evidence of crushing pressures and explosions. But this view lost favor as a much better understanding of impact sites developed in the late 20th century.</p>



<p>In the case of Köfels there is no crater, so to modern eyes it does not look as an impact site should look. However, the evidence that puzzled the earlier researchers remains unexplained by the view that it is just another landslide.</p>



<p>So what is the connection between the sophisticated Sumerian star chart discovered in the underground library in Nineveh and mysterious impact that took place in Austria?</p>



<p>Examination of the clay tablet reveals that it is an astronomical work as it has drawings of constellations on it and the text has known constellation names. It has attracted a lot of attention but in over a hundred years nobody has come up with a convincing explanation as to what it is.</p>



<p>With modern computer programs that can simulate trajectories and reconstruct the night sky thousands of years ago the researchers have established what the Planisphere tablet refers to. It is a copy of the night notebook of a Sumerian astronomer as he records the events in the sky before dawn on 29 June 3123 BC (Julian calendar).</p>



<p>Half the tablet records planet positions and cloud cover, the same as any other night, but the other half of the tablet records an object large enough for its shape to be noted even though it is still in space.</p>



<p>The astronomers made an accurate note of its trajectory relative to the stars, which to an error better than one degree is consistent with an impact at Köfels.</p>


<div>
<figure><img loading="lazy" decoding="async" width="600" height="467" src="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2.jpg" alt="Sumerian Star Map Recorded " srcset="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2.jpg 600w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2-300x234.jpg 300w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2-150x117.jpg 150w" sizes="auto, (max-width: 600px) 100vw, 600px"></figure>
</div>


<p>The observation suggests the asteroid is over a kilometer in diameter and the original orbit about the Sun was an Aten type, a class of asteroids that orbit close to the Earth, that are resonant with the Earth’s orbit.</p>



<p>This trajectory explains why there is no crater at Köfels. The incoming angle was very low (six degrees) and means the asteroid clipped a mountain called Gamskogel above the town of Längenfeld, 11 kilometers from Köfels, and this caused the asteroid to explode before it reached its final impact point. As it traveled down the valley it became a fireball, around five kilometers in diameter (the size of the landslide).</p>



<p>When it hit Köfels it created enormous pressures that pulverized the rock and caused the landslide but because it was no longer a solid object it did not create a classic impact crater.</p>



<p>Mark Hempsell, discussing the Köfels event, said: “Another conclusion can be made from the trajectory. The back plume from the explosion (the mushroom cloud) would be bent over the Mediterranean Sea re-entering the atmosphere over the Levant, Sinai, and Northern Egypt.</p>



<p>“The ground heating though very short would be enough to ignite any flammable material – including human hair and clothes. It is probable more people died under the plume than in the Alps due to the impact blast.”</p>



<p>In other words, the remarkable ancient star map shows that the Sumerians made an observation of an Aten asteroid over a kilometer in diameter that impacted Köfels in Austria in the early morning of 29th June 3123 BC.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starlink updates privacy policy to allow consumer data to train (118 pts)]]></title>
            <link>https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html</link>
            <guid>46833847</guid>
            <pubDate>Sat, 31 Jan 2026 05:44:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html">https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html</a>, See on <a href="https://news.ycombinator.com/item?id=46833847">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   <p><!-- HTML_TAG_START -->By David Jeans and Joey Roulette<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->NEW YORK, Jan 30 (Reuters) - SpaceX (<a data-i13n="cpos:1;pos:1" href="https://finance.yahoo.com/quote/SPAX.PVT" data-ylk="slk:SPAX.PVT;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">SPAX.PVT</a>) revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ​could bolster Elon Musk's AI ambitions.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Ahead of a blockbuster IPO planned for later this year, ‌SpaceX is in talks to merge with Musk’s AI company, xAI (<a data-i13n="cpos:2;pos:1" href="https://finance.yahoo.com/quote/XAAI.PVT" data-ylk="slk:XAAI.PVT;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas">XAAI.PVT</a>), a deal first reported by Reuters on Thursday. SpaceX, already the ‌world’s most valuable private company, could reach a value of more than $1 trillion after the IPO.<!-- HTML_TAG_END --></p>         <p><!-- HTML_TAG_START -->Starlink updated its Global Privacy Policy on January 15, according to the Starlink website. The policy includes new details stating that unless a user opts out, Starlink data may be used “to train our machine learning or <a href="https://tech.yahoo.com/ai/" data-ylk="slk:artificial intelligence;elm:context_link;itc:0;sec:content-canvas">artificial intelligence</a> ⁠models” and could be shared with ‌the company’s service providers and “third-party collaborators,” without providing further details.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->A previous version of the privacy policy, an archived version from November and reviewed by Reuters, did not ‍contain language about AI training on Starlink data.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->SpaceX did not respond to a request for comment.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Starlink collects vast amounts of user data, spanning location information, credit card information, contact information and user IP ​addresses. It also collects so-called communication data, which includes audio and visual information, data in shared ‌files, and “inferences we may make from other personal information we collect,” according to its global privacy policy.<!-- HTML_TAG_END --></p>      <p><!-- HTML_TAG_START -->The policy did not make clear exactly what data would be used to train AI. The move has raised concerns among privacy advocates and consumer rights groups, which argue that using personal data to train AI risks expanding surveillance and creates new avenues for misuse.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->“It certainly raises my eyebrow and would make ⁠me concerned if I was a Starlink user,” said Anupam ​Chander, a technology law professor at Georgetown University. “Often there's perfectly ​legitimate uses of your data, but it doesn’t have a clear limit to what kind of uses it will be put to.”<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Musk's xAI, most recently valued at $230 billion ‍after a recent funding round, ⁠is currently developing its Grok LLM chatbot and also owns X, the social media platform.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->The potential merger with xAI would turbocharge the space company’s deployment of AI-powered services, while giving xAI ⁠vast new data sets to train its models on, including communication data. Starlink, a network of more than 9,000 satellites, ‌currently provides internet connection to more than 9 million users.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->(Reporting by David Jeans and ‌Joey Roulette; Editing by Joe Brock and Lisa Shumaker)<!-- HTML_TAG_END --></p>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Phage Explorer (115 pts)]]></title>
            <link>https://phage-explorer.org/</link>
            <guid>46833754</guid>
            <pubDate>Sat, 31 Jan 2026 05:22:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phage-explorer.org/">https://phage-explorer.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46833754">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Naples' 1790s civil war was intensified by moral panic over Real Analysis (2023) (112 pts)]]></title>
            <link>https://lareviewofbooks.org/article/foundational-anxieties-modern-mathematics-and-the-political-imagination/</link>
            <guid>46833254</guid>
            <pubDate>Sat, 31 Jan 2026 03:53:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lareviewofbooks.org/article/foundational-anxieties-modern-mathematics-and-the-political-imagination/">https://lareviewofbooks.org/article/foundational-anxieties-modern-mathematics-and-the-political-imagination/</a>, See on <a href="https://news.ycombinator.com/item?id=46833254">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><div><h2>Massimo Mazzotti uses a forgotten episode in revolutionary Naples to demonstrate the entanglement of mathematics and politics.</h2><div><p><img loading="lazy" decoding="async" data-nimg="fill" sizes="
          (max-width: 768px) 100vw, 
          (max-width: 960px) 750px, 
          750px
        " srcset="https://cdn.lareviewofbooks.org/unsafe/fit-in/640x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 640w, https://cdn.lareviewofbooks.org/unsafe/fit-in/750x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 750w, https://cdn.lareviewofbooks.org/unsafe/fit-in/828x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 828w, https://cdn.lareviewofbooks.org/unsafe/fit-in/1080x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 1080w, https://cdn.lareviewofbooks.org/unsafe/fit-in/1200x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 1200w, https://cdn.lareviewofbooks.org/unsafe/fit-in/1920x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 1920w, https://cdn.lareviewofbooks.org/unsafe/fit-in/2048x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 2048w, https://cdn.lareviewofbooks.org/unsafe/fit-in/3840x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg 3840w" src="https://cdn.lareviewofbooks.org/unsafe/fit-in/3840x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2F202306Reactionary-Math.jpg"></p></div></div><div><h4><a href="https://lareviewofbooks.org/donate/">Did you know LARB is a reader-supported nonprofit?</a></h4><hr><div><p>LARB publishes daily without a paywall as part of our mission to make rigorous, incisive, and engaging writing on every aspect of literature, culture, and the arts freely accessible to the public. Help us continue this work with your tax-deductible donation today!</p><br></div></div><p><em>This essay is adapted from Massimo Mazzotti’s 2023 book </em>Reactionary Mathematics: A Genealogy of Purity<em>,</em> <a rel="" target="_self" href="https://press.uchicago.edu/ucp/books/book/chicago/R/bo195982549.html"><em>available now</em></a><em> from the University of Chicago Press.</em></p><p>¤</p><p>A FORGOTTEN EPISODE in French-occupied Naples in the years around 1800—just after the French Revolution—illustrates why it makes sense to see mathematics and politics as entangled. The protagonists of this story were gravely concerned about how mainstream mathematical methods were transforming their world—somewhat akin to our current-day concerns about how digital algorithms are transforming ours. But a key difference&nbsp;was their straightforward moral and political reading of those mathematical methods. By contrast, in our own era we seem to think that mathematics offers entirely neutral tools for ordering and reordering the world—we have, in other words,&nbsp;forgotten something that was obvious to them.</p><p>In this essay, I’ll use the case of revolutionary Naples to argue that the rise of a new and allegedly neutral mathematics—characterized by rigor and voluntary restriction—was a mathematical response to pressing political problems. Specifically, it was a response to the question of how to stabilize social order after the turbulence of the French Revolution. Mathematics, I argue, provided the logical infrastructure for the return to order. This episode, then, shows how and why mathematical concepts and methods are anything but timeless or neutral; they define what “reason” is, and what it is not, and thus the concrete possibilities of political action. The technical and political are two sides of the same coin—and changes in notions like mathematical rigor, provability, and necessity simultaneously constitute changes in our political imagination.</p><p>¤</p><p>In 1806, the Kingdom of Naples was occupied by a French army and integrated into Napoleon’s imperial system. The French and their local supporters had a clear agenda: they wanted to transform the semifeudal society into a centralized administrative monarchy with a liberal economy. This ambitious plan, however, soon ran up against obdurate realities like muddy roads, brigandage, popular insurgencies, and the thinly disguised hostility of powerful local elites. There was another problem, too. Open a Neapolitan university textbook of the time and you will see that the French had to fight their battles in a land where their mathematics was wrong.</p><p>While armed and cultural resistance against the French invaders’ imperial ambitions happened in other parts of Europe, the Neapolitan case is particularly interesting because it includes a <em>mathematical resistance</em>. This resistance took the form of a distinctive mathematical culture that was hegemonic in that kingdom for several decades—from the late 1790s to the 1830s. Contemporaries called it the Neapolitan synthetic school. The name referred to synthetic (or pure) geometry, a geometry that does not use coordinates and algebraic formulas to study figures and solve problems. Leading Neapolitan mathematicians embraced it as the veritable foundation of all mathematics. Only its methods and assumptions, they believed, could be trusted.</p><p>What the Neapolitans most adamantly did not trust was what they called, not without irony, the “very modern mathematics.” This body of knowledge, associated mainly with France, was characterized by the rapid advancements of an algebraized form of infinitesimal calculus and by its stunning and far-reaching practical applications. It had severed its connections with Euclidean geometry, and was referred to as “analysis”—a term that, in this context, meant a vast array of algebraic methods and algorithmic procedures that could be used to represent how things change, whether those things were, say, the trajectory of a cannonball or agricultural productivity.</p><p>Driven by eminently practical goals, analysis had become highly abstract: a versatile tool that could be applied to describe and control natural and social phenomena. The Neapolitans were quite sure it was morally suspect—a degenerate form of knowledge, and dangerous for the stability of society. Its proliferation across Europe and globally was, to them, an unmitigated disaster. While these allegations sound extravagant to our ears, some of their concerns resonate with ones in this century—e.g., about how even programmers who fashion certain complex algorithms do not understand their inner workings or why they come to the conclusions they do. Synthetics, for instance, pointed out that the analysts prioritized practical success over understanding: they aimed to model phenomena using algebraic tools that they could not fully justify, neither through some form of intellectual intuition nor through logic. By contrast, synthetic geometers clarified and grounded every single step of their procedures. They often used metaphors of sight to make this point: synthetic geometry allowed practitioners to <em>see </em>with clarity, and this is why their results could be trusted; analysts were <em>blind</em> when they manipulated their formulas. Using another set of metaphors: Analysts followed the fast flights of their feverish and uncontrolled imagination, while synthetics kept their feet on the ground. Their procedures were slow but safe.</p><p>¤</p><p>The mathematical 19th century was suffused with a distinctive foundational anxiety. We can see an early and radical manifestation of this anxiety in revolutionary Naples—in its bizarre and apparently backward attempt to return to a Greek-like pure geometry. The champion of this new old mathematics was Nicola Fergola (1753–1824), the charismatic and mystically inclined leader of a group of mathematicians and scientists who understood themselves as the last heirs of an ancient tradition, a tradition that was now under attack and needed to be defended.</p><p>Skeptics, however, understood the synthetic school’s mathematical resistance as backwardness, the rearguard action of a group of isolated practitioners. And yet, Fergola’s puzzling quest for purity was something more. For one thing, there was no established tradition of synthetic geometry worth defending in Naples. The tradition Fergola invoked was largely an invention—an imaginary mathematical lineage that ran through ancient Greece, late antiquity, and Christian Europe, all the way down to these self-proclaimed final paladins. In fact, Fergola, who was well aware of recent mathematical developments, breathed new life into forgotten mathematical techniques. Neapolitan synthetic mathematics, in other words, was not a remnant of the past, but a new way of understanding mathematics, characterized by new canons of rigor and founded on a core of “pure” mathematics. In the name of a mythical tradition, it imposed a new discipline on its practitioners by emphasizing self-restraint as the key epistemic virtue. Fergola, his admirers reported, was a champion of self-control: he controlled his body, passions, and imagination, and knew well when to stop trusting his own mathematical techniques.</p><p>¤</p><p>The Neapolitans did not reject modern analysis simply because they considered it French. What triggered their anxiety were its technical features—<em>the way it worked</em>. Following the example of mathematicians like Condorcet, analysts were aiming to create a repertoire of finite and infinite algebraic methods that were abstract and general enough to apply to any kind of problem, be it in geometry, physics, economics, or even politics. This zealous quest for universal problem-solving algorithms is precisely what made the synthetics uneasy. Interestingly, the analysts themselves knew well that the manipulation of these algorithms—the way they produced results—was not grounded in either geometric intuition or logical arguments. What warranted their use, they believed, was that algebraic procedures mirrored the fundamental workings of the human mind. If, as the analysts believed, the mind was an analytic machine, then analysis was the quintessential expression of human reason—and, as such, isomorphic to nature: analysis was effective because it mirrored the deep structures of reality. This was a mathematics essentially interwoven with the world of experience—one that, as d’Alembert had written, “gives us the most perfect examples of the manner in which one should use the art of reasoning.”</p><p>When asked to solve a geometric problem, the analysts would find an appropriate system of coordinates that would allow them to turn figures into algebraic formulas, then would manipulate these formulas to obtain the “solving equation,” as they called it. They would interpret the solutions as solutions to the original geometric problem. Their operations had thus shifted from geometry to algebra. Was this a legitimate move? The synthetics would say that it was legitimate only when they could <em>see </em>the geometry behind the formulas. But for complex problems this was not always possible, and in these instances algebra was blind; there was no way to reconstruct the geometrical meaning of the algebraic operations that led to the solution. It followed that the nature of the problem had changed. For the analysts, this was irrelevant: algebra captured the essential relations expressed by the terms of the problem, which then served to guide the mathematician toward the solution. For the synthetics, by contrast, a solution to the original geometrical problem could only be geometrical in nature; and so, what the analysts were offering were not solutions but meaningless numbers.</p><p>While the analysts strove for maximum generality, the synthetics argued for the specificity and locality of all mathematical methods. They saw this as a question of jurisdiction: there are many different ways of reasoning and many different methods, and they all have their legitimate function and scope. It would be illusory—and deceitful—to try to solve a geometrical problem using purely algebraic methods, or a political problem using the methods of geometry. Even more misleading would be to believe that there is a single universal method that can be applied to all kinds of problems. The synthetics’ world was, so to speak, epistemologically stratified. They recognized many kinds of truth, and thought it essential to keep them separated from one another. The truth of the geometer, they claimed, has nothing to do with the truths of the theologian, historian, or politician.</p><p>These two mathematical cultures differed sharply in the way they conceived mathematical reasoning. For the synthetics, mathematical knowledge was the product of a process of recognition, the imperfect representation of metaphysical states of affairs that the gifted mathematician would be able to glimpse. Their teaching reflected this view: a close-knit school with an inner circle of students who worked with their maestro, engaging in an endless reflection on geometrical problems received from antiquity. For the analysts, mathematical reasoning was just a particular case of analytic reasoning—calculus, especially, was where analytic reason could be best seen in action. They saw themselves as the standard bearers of modernization and the promoters of rational action across both scientific and social life. For them, mathematical training was a matter of learning to frame problems analytically and then solving them following a set of standard procedures. It was not a matter of intellectual intuition, gift, and genius. On the contrary, anyone, with proper training, could become an effective problem-solver.</p><p>Analysts enthusiastically compared their method to the clunky workings of a machine: to them, the machine was an emblem of rational thinking. It was also a way of arguing for the algorithmic nature and therefore accessibility of the method, as its standardized procedures could be easily learned, and deployed across different contexts. At the core of their science was not the “pure and simple knowledge of truths,” they argued, but the knowledge of methods and their relative “strength” in getting useful results, including approximate ones, through the sheer power of calculation. The synthetics countered that results needed always to be precise and perfectly interpretable. The analysts were teaching their students blind methods that deformed their young minds; they were turning them into automata—soulless, machinelike number-crunchers—who ignored at their peril the meaning of the formulas they were manipulating. Well before the dawn of digital computing, the questions of the meaning of formal procedures and of the social implications of their extensive use were at the core of a debate that, using the language of morals, addressed basic questions of social order.</p><p>¤</p><p>Why did some mathematicians perceive logical gaps in analysis in the years around 1800, and why did they consider them <em>unbearable</em>? It turns out that anxieties about the foundations of analysis were growing even among its supporters. By the 1820s, these anxieties were spreading across Europe. Consider Augustin-Louis Cauchy (1789–1857), who played a key role in the creation of modern mathematics as we know it. His much-celebrated revolution had less to do with his specific contributions and more with his overall transformation of mathematics as a discipline.</p><p>He brought order to the world of mathematics. He modernized it by imposing <em>rigor</em>. Mathematicians in the 18th century had achieved stunning results in algebra and infinitesimal calculus, but to Cauchy’s eyes, they had been too casual in how they defined their concepts and devised and applied their methods. This blithe attitude needed to end, he declared, and a new Euclidean spirit—a spirit of rigor—needed to replace it. Cauchy was not interested in bringing back synthetic geometry. Rather, he aimed to reinterpret analysis within a new logical framework in which every concept and procedure would be logically justified. Cauchy’s program of rigorization redefined the meaning of mathematical techniques, providing precise definitions and limits for the application of each method. He set boundaries, in other words, within which certain techniques could be <em>legitimately</em> deployed. The modern mathematicians were those who, following Cauchy, could discipline themselves through a new kind of technical precision.</p><p>Cauchy’s rigorous analysis seems distant from Fergola’s Greek-like geometry. But it was shaped by the same foundational anxiety and urgency to restore order to a mathematical world that—in the views of both men—had gone badly astray. What we learn from the comparison is that the fundamental opposition was not between geometry and algebra but between mathematics as a pure, rigorous, self-contained, and reliable body of knowledge and mathematics as a set of highly general and universally applicable algorithmic procedures expressing an all-encompassing analytic rationality. The fact that Fergola tried literally to reinstate geometry at the core of mathematics while Cauchy injected a rigorous Euclidean spirit within analysis was more about their local conditions than anything else. What really mattered is that both programs promised a return to mathematical order.</p><p>¤</p><p>Fergola and his students were initially marginal to Neapolitan scientific life. Their geometrical program was perceived as outdated, while the world of the salons scoffed at their baroque religious devotion and ascetic lifestyle. But this changed dramatically after the storming of the Bastille, when they quickly acquired an unprecedented cultural relevance. The Neapolitan government would take a decisive anti-French stance, reorient its entire cultural politics accordingly, and align itself with the Catholic Church. Within the Church itself, enlightened reformism gave way to a Jesuitic religiosity that reactivated baroque devotions and mobilized popular piety to support the alliance of throne and altar.</p><p>In 1794, the discovery of a Jacobin conspiracy to overthrow the monarchy sent the court into a state of panic. The Jacobins would succeed five years later, in 1799, when Naples became a republic. The leading revolutionaries were mathematicians. The chief conspirator of 1794, and the first president of the republic, Carlo Lauberg (1752–1834), was a teacher of chemistry and mathematics. It is no accident that almost every noteworthy figure in Neapolitan Jacobinism received some mathematical training: a basic understanding of analysis was an essential part of their worldview, as were republicanism, egalitarianism, and anticlericalism. The very structure of their secret society—a network of Jacobin clubs—was a working model of how analysis could be deployed in matters of social organization.</p><p>Neapolitan Jacobins aimed to find universal methods to address pressing social and political problems—above all, the problems of political representation and wealth redistribution. By the mid-1790s, they had become convinced that their vision of a just and equal society could be realized only through the universal implementation of analysis, which they understood as a <em>revolutionary mathematics</em>. Analysis was already being applied to the natural sciences and now, they said, it was time to apply it to the science of society as well, and to political matters. The analytic method would turn the art of politics into a science, replacing tradition, prejudice, and private interests with rational decision-making. To apply analysis to politics meant to reduce it to its elementary components, study their relations, and use algebraic procedures to intervene. This would detach politics from its metaphysical assumptions, turning it into a matter of rational and transparent administration. The analytic revolution could now be expected to transform society by making it possible to operationalize “the will of the people.”</p><p>Neapolitan Jacobins thus took the tools and basic assumptions of analysis and turned them into a militant mathematics—the veritable “backbone of society.” A programmatically <em>impure </em>mathematics, it was a universal language and reasoning style that could be applied across disciplinary boundaries to bring about immediate social change. In fact, mathematics and politics merged seamlessly in the lived experience of these Jacobins, who saw themselves as agents of change, able to escape the logic of reform and the apparent fatalities of history.</p><p>The counterrevolutionaries reacted by turning these analytic features into the “Jacobin machine,” a deadly device for the control of public opinion, political life, and the state. The metaphor emphasized discipline, organization, and the capacity for control, but also gestured toward the extraneous and polluting character of what was described as a set of manipulation techniques. In Naples, the Jacobin machine was viewed as foreign, disconnected from local political traditions. But in France too, its effect was seen as one of contamination, this time from the inside. In both cases, the purity of the body politic had to be defended from a malignant mechanical-analytic threat.</p><p>The breathtaking adventure of the Jacobin Republic, characterized by sweeping plans for popular education and redistribution of wealth, ended abruptly five months after it started, in June 1799, when British, Russian, and Turkish forces joined a local counterrevolutionary army and stormed the walls of Naples. In its aftermath, about 120 prominent Jacobins were put on show trials and executed. Fergola had moved to the countryside during these months. A biographer reported that he could not stand “the noise” of the city. When he returned, he and his students were asked to reorganize scientific life in the university and in the entire system of public education. Education, which had been “infected” by the Jacobins, a royal dispatch read, now needed to be brought back to its ancient order.</p><p>Fergola, a celibate vegetarian who found the presence of women extremely unpleasant, was a tormented man. He was not someone who could easily fit into the salons of Enlightenment Naples. His religiosity was deliberately untimely and baroque. He chose the most anti-modern and anti-rationalist religiosity, the popular piety of the Neapolitan crowds, when this religiosity was under attack. A spate of crying and bleeding Madonnas signaled the crisis of a subaltern agrarian world that would soon explode in massive counterrevolutionary insurgencies. Embracing popular religion in the 1790s meant embracing it as resistance. In general terms, it was a resistance against the modern state’s secularized and rational principles of organization. In this sense, Fergola’s public display of his rosary and bloodied scourge was a politicized act of resistance. And in this sense, his mathematics, too, was a politicized act of resistance.</p><p>Fergola suffered numerous and often inexplicable “organic” and “moral” ailments that progressively hampered his activity. Yet, we are told, he gazed serenely at his sore body as if that flesh was not his own: his entire life could be recounted as a triumph of spirit over matter. Exhausted by mysterious convulsions and prostrated by horrific demonic visions, Fergola felt that his faith was constantly put to the test. But even as his own health failed, his school prospered. To the end, he railed about the degeneration of learning and the “sacrilegious horde,” which included Freemasons, Jacobins, liberals, and even some of his legitimist colleagues.</p><p>¤</p><p>With the French occupation of 1806, the synthetic school had to face, once again, the threat of analysis. The world, however, had changed. Most surviving Jacobins had come to terms with the Napoleonic normalization. The synthetics controlled the university, but outside of it, analysis thrived, constituting the core training in the new schools of engineering fostered by the French. The continuity, however, was mostly apparent. Many former revolutionaries, in France as in Naples, had turned the question of modernization into a <em>technical problem</em>, and had refashioned their personas and social function in terms of scientific neutrality and technocratic efficiency. Historian Ken Alder has aptly labeled them “techno-Jacobins.” In this normalized context, mathematics was a neutral tool, the distinctive expertise of technical elites who served the state. The direct connection between mathematics, egalitarianism, and republicanism, built through the notion of a universal analytic reason, had been severed, and with it vanished the very possibility of a revolutionary mathematics. But reframing modernization as a technical rather than a political problem meant detaching analysis’s formal tools from their original source of legitimation. Intriguingly, the <em>political </em>choice of reframing modernization in exclusively technical terms had produced a profound and pervasive <em>mathematical</em> problem.</p><p>Led by Fergola’s students, the synthetic school fought against the technical elites of the modern state, mostly civil engineers and statisticians, for scientific hegemony. The old regime had long been imploding in Naples, but a new order struggled to consolidate itself. The French had arrived in Naples with a promise of order through modernization, and had found receptive interlocutors in the landed elites who could most benefit from the abolition of the feudal-communal system. The new technical experts had been charged with changing the kingdom’s physical and social landscape accordingly. Technical disciplines such as statistics or topography became key sites for negotiation, collaboration, and conflict between landed elites and the central government. On this technical terrain, the new experts would continuously clash with the synthetics.</p><p>It is not a coincidence that the synthetic school faded into oblivion when the reactionary position lost ground as a viable political option. From the 1820s onward, what was really at stake was the form of the new relations between the centralized administrative state, the landed elites, and the largely dispossessed peasant masses. Analysis had morphed into a set of allegedly neutral administrative tools, and the controversy between analytics and synthetics, which had long defined Neapolitan academic life, became increasingly meaningless. The technicians who supported the state’s modernizing action now argued for a <em>mathematical reconciliation</em>. What the two groups were defending, it was now believed, were simply two different ways of looking at mathematics, which should not be seen as opposed to each other but rather as complementary. The synthetics approach was useful for didactic purposes, while the analytic one was best suited for research and the discovery of new mathematical truths. This compromise was an elegant way of disposing of what, at that point, was an embarrassing anomaly for Neapolitan science. This normalized reconstruction eliminated revolutionary and reactionary scientific aberrations, emphasized continuity in the history of mathematics, and aligned with the political life of Restoration-age Naples, which was hegemonized by new landed elites and their liberal and constitutional ambitions. Emblematic of this cultural climate was the success of philosophical positions grounded on consciousness, which insisted that, within certain limits, individual reason was autonomous and legislative, and that fighting for liberty of conscience coincided with fighting for political and economic liberty.</p><p>The mathematical controversy between synthetics and analytics had been a controversy about the nature of reason all along. At stake was reason’s nature and limits. The Jacobin’s analytic reason was universal, active, calculative, individual, a priori, and ahistorical; it was a completely <em>autonomous</em> reason that, when not obstructed, could truthfully describe and legitimately change the world—through revolutionary action, if necessary. The reason of the synthetic, by contrast, was local, passive, intuitive, collective, a posteriori, and eminently suited to historical thinking; it was a <em>dependent</em> reason, whose outcomes needed to be warranted by external sources of legitimation like tradition, custom, experience, religion, and metaphysical principles. It was, as such, a reactionary reason that envisioned the return to order as a return to hierarchy—order produced by subordination. This reactionary reason was a militant reason, its arguments forged in battle.</p><p>It is only by contrast to an abhorred revolutionary reason, political theorist Corey Robin reminds us, that the invocation of ancient forms of wisdom can captivate the modern mind. The image of reason that emerged with the consolidation of the modern liberal state valued individual reason while acknowledging its clear limits. The principles of a liberal economy and the new relationships of subordination between landed elites and peasant masses were not to be questioned. The autonomy of individual reason was celebrated against prerevolutionary obscurantism and absolutism, but it was only a relative autonomy, to be exercised within the boundaries of postfeudal order. The newly rigorous mathematics and the constitutional project set those boundaries <em>with precision</em>. If absolutism was a thing of the past, so should be revolutionary anarchy.</p><p>¤</p><p>Logical inference, Wittgenstein quipped, is how we refer to what we do not intend to question. The case of the Neapolitan mathematical resistance should not be seen as one in which mathematics was temporarily <em>distorted </em>by politics. When we craft logico-mathematical concepts and techniques, we design ways of ordering the natural and social world. These ways of ordering the world open up certain possibilities for action—including political action—while closing down others. They discriminate between what is visible, plausible, and logical, and what is none of those things. Jacobin mathematics was deployed to critique and radically transform the existing social order, empowering traditionally subordinate social groups and bringing them into the space of politics as legitimate autonomous agents. The mathematics of the synthetics was designed to deny this possibility, to turn it, in fact, into a <em>logical impossibility</em>—hence it was, strictly speaking, a reactionary mathematics.</p><p>Modern mathematics, as it took shape with Cauchy and those who continued his program, was constitutive of the postrevolutionary political normalization. It was the logico-mathematical infrastructure of the new moderate liberal discourse. It retained analysis’s operative orientation while embracing the synthetics’ quest for a foundational core of mathematical knowledge. The image of reason it embodied was bounded and self-disciplined, and while it legitimated a neutral, instrumental technical dimension, it confined the <em>truth</em> of mathematics to the ethereal and otherworldly realm of pure mathematics. Fergola’s mathematics, it turns out, was modern.</p><p>¤</p><p><a rel="" target="_self" href="https://lareviewofbooks.org/contributor/massimo-mazzotti/"><em>Massimo Mazzotti</em></a><em> is a professor at UC Berkeley, where he holds the Thomas M. Siebel Presidential Chair in the History of Science. He is the author of</em><a rel="" target="_self" href="https://press.uchicago.edu/ucp/books/book/chicago/R/bo195982549.html"> Reactionary Mathematics: A Genealogy of Purity </a><em>(2023).</em></p><div><p>LARB Contributor</p><p><h4>Massimo Mazzotti is a professor at UC Berkeley, where he holds the Thomas M. Siebel Presidential Chair in the History of Science. He is the co-editor of<em> Algorithmic Modernity: Mechanizing Thought and Action, 1500–2000</em> (2023), and the author of<a rel="" target="_self" href="https://press.uchicago.edu/ucp/books/book/chicago/R/bo195982549.html"><em> Reactionary Mathematics: A Genealogy of Purity</em></a> (2023).</h4></p></div><section><h3>LARB Staff Recommendations</h3><ul><li><article><h2><a href="https://lareviewofbooks.org/article/weird-science/">Weird Science</a></h2><p>From anti-vaxxers to Flat Earthers, the public’s (and scholars’) perception of science shifted sometime between 1990-2010, writes Michael Gordin.</p></article></li><li><article><h2><a href="https://lareviewofbooks.org/article/i-dont-really-care-do-you-scientists-in-the-grey-zone-in-1930s-italy/">“I Don’t Really Care. Do You?”: Scientists in the Grey Zone in 1930s Italy</a></h2><p>Massimo Mazzotti reflects on how Italian scientists failed as a bulwark against fascist politics in the 1930s.</p><p><span><a href="https://lareviewofbooks.org/contributor/massimo-mazzotti/">Massimo Mazzotti</a></span><span>Jul 8, 2019</span></p></article></li></ul></section><div><h4><a href="https://lareviewofbooks.org/donate/">Did you know LARB is a reader-supported nonprofit?</a></h4><hr><div><p>LARB publishes daily without a paywall as part of our mission to make rigorous, incisive, and engaging writing on every aspect of literature, culture, and the arts freely accessible to the public. Help us continue this work with your tax-deductible donation today!</p><br></div></div></div></article></div>]]></description>
        </item>
    </channel>
</rss>