<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 25 Apr 2024 15:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A useful front-end confetti animation library (234 pts)]]></title>
            <link>https://github.com/catdad/canvas-confetti</link>
            <guid>40156330</guid>
            <pubDate>Thu, 25 Apr 2024 11:53:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/catdad/canvas-confetti">https://github.com/catdad/canvas-confetti</a>, See on <a href="https://news.ycombinator.com/item?id=40156330">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://github.com/catdad/canvas-confetti/"><img src="https://camo.githubusercontent.com/eb786c99b352202fd6215ba451ff5a45f1d77973e4d5217742702e108510e097/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f6361746461642d6578706572696d656e74732f6361746461642d6578706572696d656e74732d6f7267403565643738622f63616e7661732d636f6e66657474692f6c6f676f2e6a7067" alt="Canvas Confetti" data-canonical-src="https://cdn.jsdelivr.net/gh/catdad-experiments/catdad-experiments-org@5ed78b/canvas-confetti/logo.jpg"></a></h2><a id="" aria-label="Permalink: " href="#"></a></div>
<p dir="auto"><a href="https://github.com/catdad/canvas-confetti/actions/workflows/ci.yml?query=branch%3Amaster"><img src="https://github.com/catdad/canvas-confetti/actions/workflows/ci.yml/badge.svg" alt="github actions ci"></a>
<a href="https://www.jsdelivr.com/package/npm/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/b4d4962066dbc03d8bdaf0fb0a4f62e9fa6e8ec8ef395eee6f529d04b2274da3/68747470733a2f2f646174612e6a7364656c6976722e636f6d2f76312f7061636b6167652f6e706d2f63616e7661732d636f6e66657474692f62616467653f7374796c653d726f756e646564" alt="jsdelivr" data-canonical-src="https://data.jsdelivr.com/v1/package/npm/canvas-confetti/badge?style=rounded"></a>
<a href="https://www.npmjs.com/package/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/c1b0ce113e31fce5713bd1f7b5653dd3243260c93e1e27837d3cc27bc51ded60/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f63616e7661732d636f6e66657474692e737667" alt="npm-downloads" data-canonical-src="https://img.shields.io/npm/dm/canvas-confetti.svg"></a>
<a href="https://www.npmjs.com/package/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/a237711cc7988d9297c6b690272b0ebd0fc0ea896bd5eae4198447ec4542fa8b/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f63616e7661732d636f6e66657474692e737667" alt="npm-version" data-canonical-src="https://img.shields.io/npm/v/canvas-confetti.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><a href="https://catdad.github.io/canvas-confetti/" rel="nofollow">catdad.github.io/canvas-confetti</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">You can install this module as a component from NPM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install --save canvas-confetti"><pre>npm install --save canvas-confetti</pre></div>
<p dir="auto">You can then <code>require('canvas-confetti');</code> to use it in your project build. <em>Note: this is a client component, and will not run in Node. You will need to build your project with something like <a href="https://github.com/webpack/webpack">webpack</a> in order to use this.</em></p>
<p dir="auto">You can also include this library in your HTML page directly from a CDN:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<script src=&quot;https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js&quot;></script>"><pre><span>&lt;</span><span>script</span> <span>src</span>="<span>https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js</span>"<span>&gt;</span><span>&lt;/</span><span>script</span><span>&gt;</span></pre></div>
<p dir="auto"><em>Note: you should use the latest version at the time that you include your project. You can see all versions <a href="https://github.com/catdad/canvas-confetti/releases">on the releases page</a>.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reduced Motion</h2><a id="user-content-reduced-motion" aria-label="Permalink: Reduced Motion" href="#reduced-motion"></a></p>
<p dir="auto">Thank you for joining me in this very important message about motion on your website. See, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">not everyone likes it, and some actually prefer no motion</a>. They have <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">ways to tell us about it</a> and we should listen. While I don't want to go as far as tell you not to have confetti on your page just yet, I do want to make it easy for you to respect what your users want. There is a <code>disableForReducedMotion</code> option you can use so that users that have trouble with chaotic animations don't need to struggle on your website. This is disabled by default, but I am considering changing that in a future major release. If you have strong feelings about this, <a href="https://github.com/catdad/canvas-confetti/issues/new">please let me know</a>. For now, please confetti responsibly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto">When installed from <code>npm</code>, this library can be required as a client component in your project build. When using the CDN version, it is exposed as a <code>confetti</code> function on <code>window</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti([options {Object}])</code> ‚Üí <code>Promise|null</code></h3><a id="user-content-confettioptions-object--promisenull" aria-label="Permalink: confetti([options {Object}]) ‚Üí Promise|null" href="#confettioptions-object--promisenull"></a></p>
<p dir="auto"><code>confetti</code> takes a single optional object. When <code>window.Promise</code> is available, it will return a Promise to let you know when it is done. When promises are not available (like in IE), it will return <code>null</code>. You can polyfill promises using any of the popular polyfills. You can also provide a promise implementation to <code>confetti</code> through:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const MyPromise = require('some-promise-lib');
const confetti = require('canvas-confetti');
confetti.Promise = MyPromise;"><pre><span>const</span> <span>MyPromise</span> <span>=</span> <span>require</span><span>(</span><span>'some-promise-lib'</span><span>)</span><span>;</span>
<span>const</span> <span>confetti</span> <span>=</span> <span>require</span><span>(</span><span>'canvas-confetti'</span><span>)</span><span>;</span>
<span>confetti</span><span>.</span><span>Promise</span> <span>=</span> <span>MyPromise</span><span>;</span></pre></div>
<p dir="auto">If you call <code>confetti</code> multiple times before it is done, it will return the same promise every time. Internally, the same canvas element will be reused, continuing the existing animation with the new confetti added. The promise returned by each call to <code>confetti</code> will resolve once all animations are done.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>options</code></h4><a id="user-content-options" aria-label="Permalink: options" href="#options"></a></p>
<p dir="auto">The <code>confetti</code> parameter is a single optional <code>options</code> object, which has the following properties:</p>
<ul dir="auto">
<li><code>particleCount</code> <em>Integer (default: 50)</em>: The number of confetti to launch. More is always fun... but be cool, there's a lot of math involved.</li>
<li><code>angle</code> <em>Number (default: 90)</em>: The angle in which to launch the confetti, in degrees. 90 is straight up.</li>
<li><code>spread</code> <em>Number (default: 45)</em>: How far off center the confetti can go, in degrees. 45 means the confetti will launch at the defined <code>angle</code> plus or minus 22.5 degrees.</li>
<li><code>startVelocity</code> <em>Number (default: 45)</em>: How fast the confetti will start going, in pixels.</li>
<li><code>decay</code> <em>Number (default: 0.9)</em>: How quickly the confetti will lose speed. Keep this number between 0 and 1, otherwise the confetti will gain speed. Better yet, just never change it.</li>
<li><code>gravity</code> <em>Number (default: 1)</em>: How quickly the particles are pulled down. 1 is full gravity, 0.5 is half gravity, etc., but there are no limits. You can even make particles go up if you'd like.</li>
<li><code>drift</code> <em>Number (default: 0)</em>: How much to the side the confetti will drift. The default is 0, meaning that they will fall straight down. Use a negative number for left and positive number for right.</li>
<li><code>flat</code> <em>Boolean (default: false)</em>: Optionally turns off the tilt and wobble that three dimensional confetti would have in the real world. Yeah, they look a little sad, but y'all asked for them, so don't blame me.</li>
<li><code>ticks</code> <em>Number (default: 200)</em>: How many times the confetti will move. This is abstract... but play with it if the confetti disappear too quickly for you.</li>
<li><code>origin</code> <em>Object</em>: Where to start firing confetti from. Feel free to launch off-screen if you'd like.
<ul dir="auto">
<li><code>origin.x</code> <em>Number (default: 0.5)</em>: The <code>x</code> position on the page, with <code>0</code> being the left edge and <code>1</code> being the right edge.</li>
<li><code>origin.y</code> <em>Number (default: 0.5)</em>: The <code>y</code> position on the page, with <code>0</code> being the top edge and <code>1</code> being the bottom edge.</li>
</ul>
</li>
<li><code>colors</code> <em>Array&lt;String&gt;</em>: An array of color strings, in the HEX format... you know, like <code>#bada55</code>.</li>
<li><code>shapes</code> <em>Array&lt;String|Shape&gt;</em>: An array of shapes for the confetti. There are 3 built-in values of <code>square</code>, <code>circle</code>, and <code>star</code>. The default is to use both squares and circles in an even mix. To use a single shape, you can provide just one shape in the array, such as <code>['star']</code>. You can also change the mix by providing a value such as <code>['circle', 'circle', 'square']</code> to use two third circles and one third squares. You can also create your own shapes using the <a href="#confettishapefrompath-path-matrix---shape"><code>confetti.shapeFromPath</code></a> or <a href="#confettishapefromtext-text-scalar-color-fontfamily---shape"><code>confetti.shapeFromText</code></a> helper methods.</li>
<li><code>scalar</code> <em>Number (default: 1)</em>: Scale factor for each confetti particle. Use decimals to make the confetti smaller. Go on, try teeny tiny confetti, they are adorable!</li>
<li><code>zIndex</code> <em>Integer (default: 100)</em>: The confetti should be on top, after all. But if you have a crazy high page, you can set it even higher.</li>
<li><code>disableForReducedMotion</code> <em>Boolean (default: false)</em>: Disables confetti entirely for users that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">prefer reduced motion</a>. The <code>confetti()</code> promise will resolve immediately in this case.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.shapeFromPath({ path, matrix? })</code> ‚Üí <code>Shape</code></h3><a id="user-content-confettishapefrompath-path-matrix---shape" aria-label="Permalink: confetti.shapeFromPath({ path, matrix? }) ‚Üí Shape" href="#confettishapefrompath-path-matrix---shape"></a></p>
<p dir="auto">This helper method lets you create a custom confetti shape using an <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/d" rel="nofollow">SVG Path string</a>. Any valid path should work, though there are a few caveats:</p>
<ul dir="auto">
<li>All paths will be filed. If you were hoping to have a stroke path, that is not implemented.</li>
<li>Paths are limited to a single color, so keep that in mind.</li>
<li>All paths need a valid transform matrix. You can pass one in, or you can leave it out and use this helper to calculate the matrix for you. Do note that calculating the matrix is a bit expensive, so it is best to calculate it once for each path in development and cache that value, so that production confetti remain fast. The matrix is deterministic and will always be the same given the same path value.</li>
<li>For best forward compatibility, it is best to re-generate and re-cache the matrix if you update the <code>canvas-confetti</code> library.</li>
<li>Support for path-based confetti is limited to browsers which support <a href="https://developer.mozilla.org/en-US/docs/Web/API/Path2D" rel="nofollow"><code>Path2D</code></a>, which should really be all major browser at this point.</li>
</ul>
<p dir="auto">This method will return a <code>Shape</code> -- it's really just a plain object with some properties, but shhh... we'll pretend it's a shape. Pass this <code>Shape</code> object into the <code>shapes</code> array directly.</p>
<p dir="auto">As an example, here's how you might do a triangle confetti:</p>
<div dir="auto" data-snippet-clipboard-copy-content="var triangle = confetti.shapeFromPath({ path: 'M0 10 L5 0 L10 10z' });

confetti({
  shapes: [triangle]
});"><pre><span>var</span> <span>triangle</span> <span>=</span> <span>confetti</span><span>.</span><span>shapeFromPath</span><span>(</span><span>{</span> <span>path</span>: <span>'M0 10 L5 0 L10 10z'</span> <span>}</span><span>)</span><span>;</span>

<span>confetti</span><span>(</span><span>{</span>
  <span>shapes</span>: <span>[</span><span>triangle</span><span>]</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.shapeFromText({ text, scalar?, color?, fontFamily? })</code> ‚Üí <code>Shape</code></h3><a id="user-content-confettishapefromtext-text-scalar-color-fontfamily---shape" aria-label="Permalink: confetti.shapeFromText({ text, scalar?, color?, fontFamily? }) ‚Üí Shape" href="#confettishapefromtext-text-scalar-color-fontfamily---shape"></a></p>
<p dir="auto">This is the highly anticipated feature to render emoji confetti! Use any standard unicode emoji. Or other text, but... maybe don't use other text.</p>
<p dir="auto">While any text should work, there are some caveats:</p>
<ul dir="auto">
<li>For flailing confetti, something that is mostly square works best. That is, a single character, especially an emoji.</li>
<li>Rather than rendering text every time a confetti is drawn, this helper actually rasterizes the text. Therefore, it does not scale well after it is created. If you plan to use the <code>scalar</code> value to scale your confetti, use the same <code>scalar</code> value here when creating the shape. This will make sure the confetti are not blurry.</li>
</ul>
<p dir="auto">The options for this method are:</p>
<ul dir="auto">
<li><code>options</code> <em><code>Object</code></em>:
<ul dir="auto">
<li><code>text</code> <em><code>String</code></em>: the text to be rendered as a confetti. If you can't make up your mind, I suggest "üêà".</li>
<li><code>scalar</code> <em><code>Number, optional, default: 1</code></em>: a scale value relative to the default size. It matches the <code>scalar</code> value in the confetti options.</li>
<li><code>color</code> <em><code>String, optional, default: #000000</code></em>: the color used to render the text.</li>
<li><code>fontFamily</code> <em><code>String, optional, default: native emoji</code></em>: the font family name to use when rendering the text. The default follows <a href="https://nolanlawson.com/2022/04/08/the-struggle-of-using-native-emoji-on-the-web/" rel="nofollow">best practices for rendring the native OS emoji of the device</a>, falling back to <code>sans-serif</code>. If using a web font, make sure this <a href="https://developer.mozilla.org/en-US/docs/Web/API/FontFace/load" rel="nofollow">font is loaded</a> before rendering your confetti.</li>
</ul>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="var scalar = 2;
var pineapple = confetti.shapeFromText({ text: 'üçç', scalar });

confetti({
  shapes: [pineapple],
  scalar
});"><pre><span>var</span> <span>scalar</span> <span>=</span> <span>2</span><span>;</span>
<span>var</span> <span>pineapple</span> <span>=</span> <span>confetti</span><span>.</span><span>shapeFromText</span><span>(</span><span>{</span> <span>text</span>: <span>'üçç'</span><span>,</span> scalar <span>}</span><span>)</span><span>;</span>

<span>confetti</span><span>(</span><span>{</span>
  <span>shapes</span>: <span>[</span><span>pineapple</span><span>]</span><span>,</span>
  scalar
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.create(canvas, [globalOptions])</code> ‚Üí <code>function</code></h3><a id="user-content-confetticreatecanvas-globaloptions--function" aria-label="Permalink: confetti.create(canvas, [globalOptions]) ‚Üí function" href="#confetticreatecanvas-globaloptions--function"></a></p>
<p dir="auto">This method creates an instance of the <code>confetti</code> function that uses a custom canvas. This is useful if you want to limit the area on your page in which confetti appear. By default, this method will not modify the canvas in any way (other than drawing to it).</p>
<p dir="auto"><em>Canvas can be misunderstood a bit though, so let me explain why you might want to let the module modify the canvas just a bit. By default, a <code>canvas</code> is a relatively small image -- somewhere around 300x150, depending on the browser. When you resize it using CSS, this sets the display size of the canvas, but not the image being represented on that canvas. Think of it as loading a 300x150 jpeg image in an <code>img</code> tag and then setting the CSS for that tag to <code>1500x600</code> -- your image will end up stretched and blurry. In the case of a canvas, you need to also set the width and height of the canvas image itself. If you don't want to do that, you can allow <code>confetti</code> to set it for you.</em></p>
<p dir="auto">Note also that you should persist the custom instance and avoid initializing an instance of confetti with the same canvas element more than once.</p>
<p dir="auto">The following global options are available:</p>
<ul dir="auto">
<li><code>resize</code> <em>Boolean (default: false)</em>: Whether to allow setting the canvas image size, as well as keep it correctly sized if the window changes size (e.g. resizing the window, rotating a mobile device, etc.). By default, the canvas size will not be modified.</li>
<li><code>useWorker</code> <em>Boolean (default: false)</em>: Whether to use an asynchronous web worker to render the confetti animation, whenever possible. This is turned off by default, meaning that the animation will always execute on the main thread. If turned on and the browser supports it, the animation will execute off of the main thread so that it is not blocking any other work your page needs to do. Using this option will also modify the canvas, but more on that directly below -- do read it. If it is not supported by the browser, this value will be ignored.</li>
<li><code>disableForReducedMotion</code> <em>Boolean (default: false)</em>: Disables confetti entirely for users that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">prefer reduced motion</a>. When set to true, use of this confetti instance will always respect a user's request for reduced motion and disable confetti for them.</li>
</ul>
<p dir="auto"><em><strong>Important: If you use <code>useWorker: true</code>, I own your canvas now. It's mine now and I can do whatever I want with it (don't worry... I'll just put confetti inside it, I promise). You must not try to use the canvas in any way (other than I guess removing it from the DOM), as it will throw an error. When using workers for rendering, control of the canvas must be transferred to the web worker, preventing any usage of that canvas on the main thread. If you must manipulate the canvas in any way, do not use this option.</strong></em></p>
<div dir="auto" data-snippet-clipboard-copy-content="var myCanvas = document.createElement('canvas');
document.body.appendChild(myCanvas);

var myConfetti = confetti.create(myCanvas, {
  resize: true,
  useWorker: true
});
myConfetti({
  particleCount: 100,
  spread: 160
  // any other options from the global
  // confetti function
});"><pre><span>var</span> <span>myCanvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>myCanvas</span><span>)</span><span>;</span>

<span>var</span> <span>myConfetti</span> <span>=</span> <span>confetti</span><span>.</span><span>create</span><span>(</span><span>myCanvas</span><span>,</span> <span>{</span>
  <span>resize</span>: <span>true</span><span>,</span>
  <span>useWorker</span>: <span>true</span>
<span>}</span><span>)</span><span>;</span>
<span>myConfetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>100</span><span>,</span>
  <span>spread</span>: <span>160</span>
  <span>// any other options from the global</span>
  <span>// confetti function</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.reset()</code></h3><a id="user-content-confettireset" aria-label="Permalink: confetti.reset()" href="#confettireset"></a></p>
<p dir="auto">Stops the animation and clears all confetti, as well as immediately resolves any outstanding promises. In the case of a separate confetti instance created with <a href="#confetticreatecanvas-globaloptions--function"><code>confetti.create</code></a>, that instance will have its own <code>reset</code> method.</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti();

setTimeout(() => {
  confetti.reset();
}, 100);"><pre><span>confetti</span><span>(</span><span>)</span><span>;</span>

<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>confetti</span><span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>,</span> <span>100</span><span>)</span><span>;</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="var myCanvas = document.createElement('canvas');
document.body.appendChild(myCanvas);

var myConfetti = confetti.create(myCanvas, { resize: true });

myConfetti();

setTimeout(() => {
  myConfetti.reset();
}, 100);"><pre><span>var</span> <span>myCanvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>myCanvas</span><span>)</span><span>;</span>

<span>var</span> <span>myConfetti</span> <span>=</span> <span>confetti</span><span>.</span><span>create</span><span>(</span><span>myCanvas</span><span>,</span> <span>{</span> <span>resize</span>: <span>true</span> <span>}</span><span>)</span><span>;</span>

<span>myConfetti</span><span>(</span><span>)</span><span>;</span>

<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>myConfetti</span><span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>,</span> <span>100</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Launch some confetti the default way:</p>

<p dir="auto">Launch a bunch of confetti:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  particleCount: 150
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>150</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Launch some confetti really wide:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  spread: 180
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>spread</span>: <span>180</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Get creative. Launch a small poof of confetti from a random part of the page:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  particleCount: 100,
  startVelocity: 30,
  spread: 360,
  origin: {
    x: Math.random(),
    // since they fall down, start a bit higher than random
    y: Math.random() - 0.2
  }
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>100</span><span>,</span>
  <span>startVelocity</span>: <span>30</span><span>,</span>
  <span>spread</span>: <span>360</span><span>,</span>
  <span>origin</span>: <span>{</span>
    <span>x</span>: <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span><span>,</span>
    <span>// since they fall down, start a bit higher than random</span>
    <span>y</span>: <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> <span>-</span> <span>0.2</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">I said creative... we can do better. Since it doesn't matter how many times we call <code>confetti</code> (just the total number of confetti in the air), we can do some fun things, like continuously launch more and more confetti for 30 seconds, from multiple directions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// do this for 30 seconds
var duration = 30 * 1000;
var end = Date.now() + duration;

(function frame() {
  // launch a few confetti from the left edge
  confetti({
    particleCount: 7,
    angle: 60,
    spread: 55,
    origin: { x: 0 }
  });
  // and launch a few from the right edge
  confetti({
    particleCount: 7,
    angle: 120,
    spread: 55,
    origin: { x: 1 }
  });

  // keep going until we are out of time
  if (Date.now() < end) {
    requestAnimationFrame(frame);
  }
}());"><pre><span>// do this for 30 seconds</span>
<span>var</span> <span>duration</span> <span>=</span> <span>30</span> <span>*</span> <span>1000</span><span>;</span>
<span>var</span> <span>end</span> <span>=</span> <span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>+</span> <span>duration</span><span>;</span>

<span>(</span><span>function</span> <span>frame</span><span>(</span><span>)</span> <span>{</span>
  <span>// launch a few confetti from the left edge</span>
  <span>confetti</span><span>(</span><span>{</span>
    <span>particleCount</span>: <span>7</span><span>,</span>
    <span>angle</span>: <span>60</span><span>,</span>
    <span>spread</span>: <span>55</span><span>,</span>
    <span>origin</span>: <span>{</span> <span>x</span>: <span>0</span> <span>}</span>
  <span>}</span><span>)</span><span>;</span>
  <span>// and launch a few from the right edge</span>
  <span>confetti</span><span>(</span><span>{</span>
    <span>particleCount</span>: <span>7</span><span>,</span>
    <span>angle</span>: <span>120</span><span>,</span>
    <span>spread</span>: <span>55</span><span>,</span>
    <span>origin</span>: <span>{</span> <span>x</span>: <span>1</span> <span>}</span>
  <span>}</span><span>)</span><span>;</span>

  <span>// keep going until we are out of time</span>
  <span>if</span> <span>(</span><span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>&lt;</span> <span>end</span><span>)</span> <span>{</span>
    <span>requestAnimationFrame</span><span>(</span><span>frame</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>(</span><span>)</span><span>)</span><span>;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC unveils 1.6nm process technology with backside power delivery (164 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design</link>
            <guid>40156275</guid>
            <pubDate>Thu, 25 Apr 2024 11:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design">https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design</a>, See on <a href="https://news.ycombinator.com/item?id=40156275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg" alt="TSMC fire at new plant" srcset="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: TSMC)</span>
</figcaption>
</div>

<div id="article-body">
<p>TSMC announced its leading-edge 1.6nm-class process technology today, a new A16 manufacturing process that will be the company's first Angstrom-class production node and promises to outperform its predecessor, N2P, by a significant margin. The technology's most important innovation will be its backside power delivery network (BSPDN).</p><p>Just like TSMC's 2nm-class nodes (N2, N2P, and N2X), the company's 1.6nm-class fabrication process will rely on gate-all-around (GAA) nanosheet transistors, but unlike the current and next-generation nodes, this one uses backside power delivery dubbed Super Power Rail. Transistor and BSPDN innovations enable tangible performance and efficiency improvements compared to TSMC's N2P: the new node promises an up to 10% higher clock rate at the same voltage and a 15% - 20% lower power consumption at the same frequency and complexity. In addition, the new technology could enable 7% - 10% higher transistor density, depending on the actual design.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The most important innovation of TSMC's A16 process, which was unveiled at the company's <a data-analytics-id="inline-link" href="https://www.tsmc.com/static/english/campaign/Symposium2024/index.htm" data-url="https://www.tsmc.com/static/english/campaign/Symposium2024/index.htm" target="_blank" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">North American Technology Symposium 2024</a>, is the introduction of the Super Power Rail (SPR), a sophisticated backside power delivery network (BSPDN). This technology is tailored specifically for AI and HPC processors that tend to have both complex signal wiring and dense power delivery networks.&nbsp;</p><p>Backside power delivery will be implemented into many upcoming process technologies as it allows for an increase in transistor density and improved power delivery, which affects performance. Meanwhile, there are several ways to implement a BSPDN. TSMC's Super Power Rail plugs the backside power delivery network to each transistor's source and drain using a special contract that also reduces resistance to get the maximum performance and power efficiency possible. From a production perspective, this is one of the most complex BSPDN implementations and is more complex than Intel's Power Via.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The choice of backside power rail implementation is perhaps why TSMC decided not to add this feature to its N2P and N2X process technologies, as it would make using the production nodes considerably more expensive. Meanwhile, by offering a 1.6nm-class node with GAA nanosheet transistors and SPR as well as 2nm-class nodes with GAAFETs only, the company will now have two distinct nodes that will not compete with each other directly but offer distinctive advantages for different customers.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The production timeline for A16 indicates that volume production of A16 will commence in the second half of 2026. Therefore, actual A16-made products will likely debut in 2027. This timeline positions A16 to potentially compete with Intel's 14A node, which will be the Intel's most advanced node at the time.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-Bhv28ghXS2smx6QV966UDU"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news ‚Äî and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-Bhv28ghXS2smx6QV966UDU"><p>Anton Shilov is a Freelance News Writer at Tom‚Äôs Hardware US. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How NASA Repaired Voyager 1 from 15B Miles Away (130 pts)]]></title>
            <link>https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/</link>
            <guid>40155293</guid>
            <pubDate>Thu, 25 Apr 2024 09:28:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/">https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/</a>, See on <a href="https://news.ycombinator.com/item?id=40155293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
  




<!-- cache miss 366:single/related:7b642dbe541c5baf60cd5beb87e2ab40 --><!-- empty -->
<p>Engineers have partially restored a 1970s-era computer on NASA's Voyager 1 spacecraft after five months of long-distance troubleshooting, building confidence that humanity's first interstellar probe can eventually resume normal operations.</p>
<p>Several dozen scientists and engineers gathered Saturday in a conference room at NASA's Jet Propulsion Laboratory, or connected virtually, to wait for a new signal from Voyager 1. The ground team sent a command up to Voyager 1 on Thursday to recode part of the memory of the <a href="https://arstechnica.com/space/2024/02/humanitys-most-distant-space-probe-jeopardized-by-computer-glitch/">spacecraft's Flight Data Subsystem (FDS)</a>, one of the probe's three computers.</p>
<p>‚ÄúIn the minutes leading up to when we were going to see a signal, you could have heard a pin drop in the room," said Linda Spilker, project scientist for NASA's two Voyager spacecraft at JPL. "It was quiet. People were looking very serious. They were looking at their computer screens. Each of the subsystem (engineers) had pages up that they were looking at, to watch as they would be populated."</p>
<h2>Finally, a breakthrough</h2>
<p>Launched nearly 47 years ago, Voyager 1 is flying on an outbound trajectory more than 15 billion miles (24 billion kilometers) from Earth, and it takes 22-and-a-half hours for a radio signal to cover that distance at the speed of light. This means it takes nearly two days for engineers to uplink a command to Voyager 1 and get a response.</p>
<p>In November, Voyager 1 suddenly stopped transmitting its usual stream of data containing information about the spacecraft's health and measurements from its scientific instruments. Instead, the spacecraft's data stream was entirely unintelligible. Because the telemetry was unreadable, experts on the ground could not easily tell what went wrong. They hypothesized the source of the problem might be in the memory bank of the FDS.</p>
<p>There was a breakthrough last month when engineers sent up a novel command to "poke" Voyager 1's FDS to send back a readout of its memory. This readout allowed engineers to <a href="https://arstechnica.com/space/2024/04/the-diagnosis-is-in-bad-memory-knocked-nasas-aging-voyager-1-offline/">pinpoint the location of the problem in the FDS memory</a>. The FDS is responsible for packaging engineering and scientific data for transmission to Earth.</p>
<p>After a few weeks, NASA was ready to uplink a solution to get the FDS to resume packing engineering data. This data stream includes information on the status of the spacecraft‚Äîthings like power levels and temperature measurements. This command went up to Voyager 1 through one of NASA's large Deep Space Network antennas Thursday.</p>                                            
                                                        
<p>Then, the wait for a response. Spilker, who started working on Voyager right out of college in 1977, was in the room when Voyager 1's signal reached Earth Saturday.</p>
<p>"When the time came to get the signal, we could clearly see all of a sudden, boom, we had data, and there were tears and smiles and high fives," she told Ars. "Everyone was very happy and very excited to see that, hey, we're back in communication again with Voyager 1. We're going to see the status of the spacecraft, the health of the spacecraft, for the first time in five months."</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team.jpg" data-height="1125" data-width="1500" alt="Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday."><img alt="Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team-640x480.jpg" width="640" height="480" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team-1280x960.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team.jpg" data-height="1125" data-width="1500">Enlarge</a> <span>/</span> Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday.</p></figcaption></figure>
<p>Throughout the five months of troubleshooting, Voyager's ground team continued to receive signals indicating the spacecraft was still alive. But until Saturday, they lacked insight into specific details about the status of Voyager 1.</p>
<p>‚ÄúIt‚Äôs pretty much just the way we left it," Spilker said. "We're still in the initial phases of analyzing all of the channels and looking at their trends. Some of the temperatures went down a little bit with this period of time that's gone on, but we're pretty much seeing everything we had hoped for. And that's always good news.‚Äù</p>
<h2>Relocating code</h2>
<p>Through their investigation, Voyager's ground team discovered a single chip responsible for storing a portion of the FDS memory stopped working, probably due to either a cosmic ray hit or a failure of aging hardware. This affected some of the computer's software code.</p>
<p>"That took out a section of memory," Spilker said. "What they have to do is relocate that code into a different portion of the memory, and then make sure that anything that uses those codes, those subroutines, know to go to the new location of memory, for access and to run it."</p>
<p>Only about 3 percent of the FDS memory was corrupted by the bad chip, so engineers needed to transplant that code into another part of the memory bank. But no single location is large enough to hold the section of code in its entirety, NASA said.</p>
<p>So the Voyager team divided the code into sections for storage in different places in the FDS. This wasn't just a copy-and-paste job. Engineers needed to modify some of the code to make sure it will all work together. "Any references to the location of that code in other parts of the FDS memory needed to be updated as well," NASA said in a statement.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing retaliated against its own engineers working for FAA, union says (103 pts)]]></title>
            <link>https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/</link>
            <guid>40155240</guid>
            <pubDate>Thu, 25 Apr 2024 09:20:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/">https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/</a>, See on <a href="https://news.ycombinator.com/item?id=40155240">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
    <p>Boeing‚Äôs white-collar union alleged Tuesday that company management retaliated against engineers overseeing design work on behalf of the Federal Aviation Administration, heightening concerns about a self-regulation regime that‚Äôs come under renewed fire since Jan. 5, when a fuselage panel blew out midair.</p><p>In 2022, as Boeing worked to integrate new avionics packages into its 777 and 787 widebody aircraft,  two of its engineers insisted the company needed to reevaluate prior engineering work completed on the two aircraft. The engineering union contends Boeing managers objected to this on the grounds that it would add costs and slow production.</p><p>After the FAA backed the engineers about how the work should be performed and the dispute was settled, in mid-2023 Boeing gave both men negative performance reviews, which cuts pay raises and promotion prospects.</p><p>The two ‚Äúdid the right thing and stuck to their guns despite heavy pressure from Boeing, and then got hit with career-damaging performance reviews,‚Äù said Rich Plunkett, the union‚Äôs director of strategic development. ‚ÄúThis helps show why Boeing doesn‚Äôt have a healthy safety culture.‚Äù</p><p>The union said one of the engineers quit Boeing over the way he was treated; it‚Äôs appealing the performance downgrade to management on behalf of the other.</p><p>Boeing denies the charge of retaliation. </p><p>‚ÄúAfter an extensive review of documentation and interviewing more than a dozen witnesses, our investigators found no evidence of retaliation or interference,‚Äù spokesperson Bobbie Egan said Tuesday. ‚ÄúWe have determined the allegations are unsubstantiated.‚Äù </p>
<p>‚ÄúWe have zero tolerance for retaliation and encourage our employees to speak up when they see an issue,‚Äù Egan said.</p><p>If proven, the union allegations would undercut Boeing‚Äôs recent insistence that it prioritizes safety over cost and schedule considerations and maintains an open culture that protects employees who flag safety issues.</p><p>The&nbsp;union, the Society of Professional Engineering Employees in Aerospace, SPEEA, has filed a complaint with the National Labor Relations Board demanding access to the report of the internal Boeing investigation that concluded the negative reviews did not amount to interfering in the oversight work of the two engineers.</p><p>Boeing said it is ‚Äúlooking into the union‚Äôs requests‚Äù but added that investigations into interference claims are typically confidential.</p><p>‚ÄúProviding the report to any party outside the FAA would be a departure from our standard practice, ‚Äù Boeing said.</p>
<h2>Eyes of the FAA</h2><p>More than 1,000 engineers inside Boeing are authorized to act as the FAA‚Äôs eyes in overseeing work. They are legally required to have ‚Äúa commitment to safety above all other priorities‚Äù and so must be independent and free of interference from management concerns about added cost and schedule delays.</p><p>But after the two deadly 737 MAX crashes five years ago, some of these engineers alleged management during the MAX‚Äôs development had <a href="https://www.seattletimes.com/business/boeing-aerospace/engineers-say-boeing-pushed-to-limit-safety-testing-in-race-to-certify-planes-including-737-max/">interfered to limit safety testing</a>. </p><p>That coupled with the failure of this internal oversight organization to flag the obvious flaws in <a href="https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/">the new flight control software that led to the crashes</a> raised serious doubts about Boeing‚Äôs ability to certify its own work.</p><p>Congress subsequently began to reverse the yearslong trend of delegating more of the FAA‚Äôs safety oversight to Boeing itself. </p><p>After a chain of quality lapses last year and then the fuselage panel blowout on an Alaska Airlines 737 MAX in January, Boeing leadership said it would revamp its safety reporting systems and has repeatedly insisted that all employees can raise safety concerns without fear of retaliation.</p><p>In February, the report of an FAA-appointed panel of independent aviation experts flagged concerns that the employees who represent the FAA fear raising safety issues because Boeing‚Äôs internal safety reporting systems fails to ensure ‚Äúopen communication and non-retaliation.‚Äù</p>
<p>The findings of that report were <a href="https://www.seattletimes.com/business/boeing-workers-still-scared-to-raise-safety-concerns-says-faa-appointed-experts/">highlighted just last week in a hearing before the U.S. Senate Committee</a> on Commerce, Science and Transportation. One finding was that some employees did not receive a raise they had been expecting after bringing up safety concerns.&nbsp;</p><p>After that hearing, Boeing said retaliation is strictly prohibited.&nbsp;</p><p>‚ÄúBoeing can tell Congress and the media all it wants about how ‚Äòretaliation is strictly prohibited,‚Äô‚Äù said Plunkett. ‚ÄúBut our union is fighting retaliation cases on a regular basis.‚Äù</p><h2>Following FAA guidelines</h2><p>The job of the Boeing engineers authorized to work on behalf of the FAA is to check on the work of company engineers as they develop designs and instruct them what must be accomplished to get those designs approved as compliant with regulations.</p>      <p>The union said when overseeing the 777 and 787 avionics integration in 2022, the two engineers insisted the company reevaluate prior engineering calculations, citing an FAA advisory document updated in 2013 that provided guidelines on how to obtain airworthiness approval&nbsp;for such work.</p><p>An FAA advisory typically outlines a standard way of achieving compliance. It‚Äôs not mandatory and does not constitute a regulation.</p><p>According to the union, Boeing managers ‚Äústrongly objected‚Äù to the conclusion that the prior work should be redone, ‚Äúsaying that going back to run calculations using the new assumptions would cost money and cause production delays.‚Äù</p>
<p>Eventually, after six months of back and forth, the FAA backed the two engineers and Boeing had to redo the analysis. </p><p>Subsequently, however, ‚Äúwhen they came up for their next performance reviews, the two engineers received identical negative evaluations,‚Äù the union said.</p><p>SPEEA said that when its staff met with Boeing officials on the matter, ‚Äúthe manager of the two engineers admitted that he had rated them both poorly at the request of the 777 and 787 managers who had been forced to resubmit their work.‚Äù</p><p>Still, Boeing refused to change the performance evaluations. </p><p>While one of the engineers chose to leave Boeing, the other filed a complaint in the company‚Äôs ‚ÄúSpeak Up‚Äù reporting system alleging retaliation. </p><p>In a meeting with the engineer, accompanied by a SPEEA official, Boeing labor relations personnel told him that his complaint ‚Äúdid not meet the legal threshold of interference, nor the legal definition of retaliation, and as a result, they were closing his case,‚Äù the union said.</p>
<p>Because that internal complaint implied interference with an FAA designee, Boeing had to file a report on the incident with the safety agency. As it appeals the performance downgrade, the union now seeks access to that report.</p><p>In 2022, responding to Congress, the FAA introduced new policies to prevent ‚Äúundue pressure‚Äù on the engineers working on its behalf at aviation manufacturers.</p><p>The new regulations require Boeing to monitor for, report and investigate all allegations of interference and to report the results to the FAA. The agency now has the SPEEA charges.</p><p>‚ÄúThe FAA is investigating these allegations,‚Äù spokesperson Ian Gregor said Tuesday. </p>    
        <div>
   <p><span>
         Dominic Gates:      </span>
       <span>206-464-2963</span> or <span><a href="mailto:dgates@seattletimes.com">dgates@seattletimes.com</a>;</span>      <span>Dominic Gates is a Pulitzer Prize-winning aerospace journalist for The Seattle Times.</span>   </p>
</div>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny GPU: A minimal GPU implementation in Verilog (142 pts)]]></title>
            <link>https://github.com/adam-maj/tiny-gpu</link>
            <guid>40153815</guid>
            <pubDate>Thu, 25 Apr 2024 05:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/adam-maj/tiny-gpu">https://github.com/adam-maj/tiny-gpu</a>, See on <a href="https://news.ycombinator.com/item?id=40153815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">tiny-gpu</h2><a id="user-content-tiny-gpu" aria-label="Permalink: tiny-gpu" href="#tiny-gpu"></a></p>
<p dir="auto">A minimal GPU implementation in Verilog optimized for learning about how GPUs work from the ground up.</p>
<p dir="auto">Built with &lt;15 files of fully documented Verilog, complete documentation on architecture &amp; ISA, working matrix addition/multiplication kernels, and full support for kernel simulation &amp; execution traces.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#architecture">Architecture</a>
<ul dir="auto">
<li><a href="#gpu">GPU</a></li>
<li><a href="#memory">Memory</a></li>
<li><a href="#core">Core</a></li>
</ul>
</li>
<li><a href="#isa">ISA</a></li>
<li><a href="#execution">Execution</a>
<ul dir="auto">
<li><a href="#core-1">Core</a></li>
<li><a href="#thread">Thread</a></li>
</ul>
</li>
<li><a href="#kernels">Kernels</a>
<ul dir="auto">
<li><a href="#matrix-addition">Matrix Addition</a></li>
<li><a href="https://github.com/adam-maj/tiny-gpu/blob/master/tree/master?tab=readme-ov-file#matrix-multiplication">Matrix Multiplication</a></li>
</ul>
</li>
<li><a href="#simulation">Simulation</a></li>
<li><a href="#advanced-functionality">Advanced Functionality</a></li>
<li><a href="#next-steps">Next Steps</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">If you want to learn how a CPU works all the way from architecture to control signals, there are many resources online to help you.</p>
<p dir="auto">GPUs are not the same.</p>
<p dir="auto">Because the GPU market is so competitive, low-level technical details for all modern architectures remain proprietary.</p>
<p dir="auto">While there are lots of resources to learn about GPU programming, there's almost nothing available to learn about how GPU's work at a hardware level.</p>
<p dir="auto">The best option is to go through open-source GPU implementations like <a href="https://github.com/VerticalResearchGroup/miaow">Miaow</a> and <a href="https://github.com/hughperkins/VeriGPU/tree/main">VeriGPU</a> and try to figure out what's going on. This is challenging since these projects aim at being feature complete and functional, so they're quite complex.</p>
<p dir="auto">This is why I built <code>tiny-gpu</code>!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is tiny-gpu?</h2><a id="user-content-what-is-tiny-gpu" aria-label="Permalink: What is tiny-gpu?" href="#what-is-tiny-gpu"></a></p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><strong>tiny-gpu</strong> is a minimal GPU implementation optimized for learning about how GPUs work from the ground up.</p>
<p dir="auto">Specifically, with the trend toward general-purpose GPUs (GPGPUs) and ML-accelerators like Google's TPU, tiny-gpu focuses on highlighting the general principles of all of these architectures, rather than on the details of graphics-specific hardware.</p>
</div>
<p dir="auto">With this motivation in mind, we can simplify GPUs by cutting out the majority of complexity involved with building a production-grade graphics card, and focus on the core elements that are critical to all of these modern hardwareaccelerators.</p>
<p dir="auto">This project is primarily focused on exploring:</p>
<ol dir="auto">
<li><strong>Architecture</strong> - What does the architecture of a GPU look like? What are the most important elements?</li>
<li><strong>Parallelization</strong> - How is the SIMD progamming model implemented in hardware?</li>
<li><strong>Memory</strong> - How does a GPU work around the constraints of limited memory bandwidth?</li>
</ol>
<p dir="auto">After understanding the fundamentals laid out in this project, you can checkout the <a href="#advanced-functionality">advanced functionality section</a> to understand some of the most important optimizations made in production grade GPUs (that are more challenging to implement) which improve performance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/gpu.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/gpu.png" alt="GPU" width="48%"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/core.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/core.png" alt="Core" width="48%"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">GPU</h2><a id="user-content-gpu" aria-label="Permalink: GPU" href="#gpu"></a></p>
<p dir="auto">tiny-gpu is built to execute a single kernel at a time.</p>
<p dir="auto">In order to launch a kernel, we need to do the following:</p>
<ol dir="auto">
<li>Load global program memory with the kernel code</li>
<li>Load data memory with the necessary data</li>
<li>Specify the number of threads to launch in the device control register</li>
<li>Launch the kernel by setting the start signal to high.</li>
</ol>
<p dir="auto">The GPU itself consists of the following units:</p>
<ol dir="auto">
<li>Device control register</li>
<li>Dispatcher</li>
<li>Variable number of compute cores</li>
<li>Memory controllers for data memory &amp; program memory</li>
<li>Cache</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Device Control Register</h3><a id="user-content-device-control-register" aria-label="Permalink: Device Control Register" href="#device-control-register"></a></p>
<p dir="auto">The device control register usually stores metadata specifying how kernels should be executed on the GPU.</p>
<p dir="auto">In this case, the device control register just stores the <code>thread_count</code> - the total number of threads to launch for the active kernel.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dispatcher</h3><a id="user-content-dispatcher" aria-label="Permalink: Dispatcher" href="#dispatcher"></a></p>
<p dir="auto">Once a kernel is launched, the dispatcher is the unit that actually manages the distribution of threads to different compute cores.</p>
<p dir="auto">The dispatcher organizes threads into groups that can be executed in parallel on a single core called <strong>blocks</strong> and sends these blocks off to be processed by available cores.</p>
<p dir="auto">Once all blocks have been processed, the dispatcher reports back that the kernel execution is done.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory</h2><a id="user-content-memory" aria-label="Permalink: Memory" href="#memory"></a></p>
<p dir="auto">The GPU is built to interface with an external global memory. Here, data memory and program memory are separated out for simplicity.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Global Memory</h3><a id="user-content-global-memory" aria-label="Permalink: Global Memory" href="#global-memory"></a></p>
<p dir="auto">tiny-gpu data memory has the following specifications:</p>
<ul dir="auto">
<li>8 bit addressability (256 total rows of data memory)</li>
<li>8 bit data (stores values of &lt;256 for each row)</li>
</ul>
<p dir="auto">tiny-gpu program memory has the following specifications:</p>
<ul dir="auto">
<li>8 bit addressability (256 rows of program memory)</li>
<li>16 bit data (each instruction is 16 bits as specified by the ISA)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Controllers</h3><a id="user-content-memory-controllers" aria-label="Permalink: Memory Controllers" href="#memory-controllers"></a></p>
<p dir="auto">Global memory has fixed read/write bandwidth, but there may be far more incoming requests across all cores to access data from memory than the external memory is actually able to handle.</p>
<p dir="auto">The memory controllers keep track of all the outgoing requests to memory from the compute cores, throttle requests based on actual external memory bandwidth, and relay responses from external memory back to the proper resources.</p>
<p dir="auto">Each memory controller has a fixed number of channels based on the bandwidth of global memory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cache (WIP)</h3><a id="user-content-cache-wip" aria-label="Permalink: Cache (WIP)" href="#cache-wip"></a></p>
<p dir="auto">The same data is often requested from global memory by multiple cores. Constantly access global memory repeatedly is expensive, and since the data has already been fetched once, it would be more efficient to store it on device in SRAM to be retrieved much quicker on later requests.</p>
<p dir="auto">This is exactly what the cache is used for. Data retrieved from external memory is stored in cache and can be retrieved from there on later requests, freeing up memory bandwidth to be used for new data.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core</h2><a id="user-content-core" aria-label="Permalink: Core" href="#core"></a></p>
<p dir="auto">Each core has a number of compute resources, often built around a certain number of threads it can support. In order to maximize parallelization, these resources need to be managed optimally to maximize resource utilization.</p>
<p dir="auto">In this simplified GPU, each core processed one <strong>block</strong> at a time, and for each thread in a block, the core has a dedicated ALU, LSU, PC, and register file. Managing the execution of thread instructions on these resources is one of the most challening problems in GPUs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scheduler</h3><a id="user-content-scheduler" aria-label="Permalink: Scheduler" href="#scheduler"></a></p>
<p dir="auto">Each core has a single scheduler that manages the execution of threads.</p>
<p dir="auto">The tiny-gpu scheduler executes instructions for a single block to completion before picking up a new block, and it executes instructions for all threads in-sync and sequentially.</p>
<p dir="auto">In more advanced schedulers, techniques like <strong>pipelining</strong> are used to stream the execution of multiple instructions subsequent instructions to maximize resource utilization before previous instructions are fully complete. Additionally, <strong>warp scheduling</strong> can be use to execute multiple batches of threads within a block in parallel.</p>
<p dir="auto">The main constraint the scheduler has to work around is the latency associated with loading &amp; storing data from global memory. While most instructions can be executed synchronously, these load-store operations are asynchronous, meaning the rest of the instruction execution has to be built around these long wait times.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fetcher</h3><a id="user-content-fetcher" aria-label="Permalink: Fetcher" href="#fetcher"></a></p>
<p dir="auto">Asynchronously fetches the instruction at the current program counter from program memory (most should actually be fetching from cache after a single block is executed).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Decoder</h3><a id="user-content-decoder" aria-label="Permalink: Decoder" href="#decoder"></a></p>
<p dir="auto">Decodes the fetched instruction into control signals for thread execution.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Register Files</h3><a id="user-content-register-files" aria-label="Permalink: Register Files" href="#register-files"></a></p>
<p dir="auto">Each thread has it's own dedicated set of register files. The register files hold the data that each thread is performing computations on, which enables the same-instruction multiple-data (SIMD) pattern.</p>
<p dir="auto">Importantly, each register file contains a few read-only registers holding data about the current block &amp; thread being executed locally, enabling kernels to be executed with different data based on the local thread id.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ALUs</h3><a id="user-content-alus" aria-label="Permalink: ALUs" href="#alus"></a></p>
<p dir="auto">Dedicated arithmetic-logic unit for each thread to perform computations. Handles the <code>ADD</code>, <code>SUB</code>, <code>MUL</code>, <code>DIV</code> arithmetic instructions.</p>
<p dir="auto">Also handles the <code>CMP</code> comparison instruction which actually outputs whether the result of the difference between two registers is negative, zero or positive - and stores the result in the <code>NZP</code> register in the PC unit.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LSUs</h3><a id="user-content-lsus" aria-label="Permalink: LSUs" href="#lsus"></a></p>
<p dir="auto">Dedicated load-store unit for each thread to access global data memory.</p>
<p dir="auto">Handles the <code>LDR</code> &amp; <code>STR</code> instructions - and handles async wait times for memory requests to be processed and relayed by the memory controller.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PCs</h3><a id="user-content-pcs" aria-label="Permalink: PCs" href="#pcs"></a></p>
<p dir="auto">Dedicated program-counter for each unit to determine the next instructions to execute on each thread.</p>
<p dir="auto">By default, the PC increments by 1 after every instruction.</p>
<p dir="auto">With the <code>BRnzp</code> instruction, the NZP register checks to see if the NZP register (set by a previous <code>CMP</code> instruction) matches some case - and if it does, it will branch to a specific line of program memory. <em>This is how loops and conditionals are implemented.</em></p>
<p dir="auto">Since threads are processed in parallel, tiny-gpu assumes that all threads "converge" to the same program counter after each instruction - which is a naive assumption for the sake of simplicity.</p>
<p dir="auto">In real GPUs, individual threads can branch to different PCs, causing <strong>branch divergence</strong> where a group of threads threads initially being processed together has to split out into separate execution.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ISA</h2><a id="user-content-isa" aria-label="Permalink: ISA" href="#isa"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/isa.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/isa.png" alt="ISA"></a></p>
<p dir="auto">tiny-gpu implements a simple 11 instruction ISA built to enable simple kernels for proof-of-concept like matrix addition &amp; matrix multiplication (implementation further down on this page).</p>
<p dir="auto">For these purposes, it supports the following instructions:</p>
<ul dir="auto">
<li><code>BRnzp</code> - Branch instruction to jump to another line of program memory if the NZP register matches the <code>nzp</code> condition in the instruction.</li>
<li><code>CMP</code> - Compare the value of two registers and store the result in the NZP register to use for a later <code>BRnzp</code> instruction.</li>
<li><code>ADD</code>, <code>SUB</code>, <code>MUL</code>, <code>DIV</code> - Basic arithmetic operations to enable tensor math.</li>
<li><code>LDR</code> - Load data from global memory.</li>
<li><code>STR</code> - Store data into global memory.</li>
<li><code>CONST</code> - Load a constant value into a register.</li>
<li><code>RET</code> - Signal that the current thread has reached the end of execution.</li>
</ul>
<p dir="auto">Each register is specified by 4 bits, meaning that there are 16 total registers. The first 13 register <code>R0</code> - <code>R12</code> are free registers that support read/write. The last 3 registers are special read-only registers used to supply the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> critical to SIMD.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Execution</h2><a id="user-content-execution" aria-label="Permalink: Execution" href="#execution"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core</h3><a id="user-content-core-1" aria-label="Permalink: Core" href="#core-1"></a></p>
<p dir="auto">Each core follows the following control flow going through different stages to execute each instruction:</p>
<ol dir="auto">
<li><code>FETCH</code> - Fetch the next instruction at current program counter from program memory.</li>
<li><code>DECODE</code> - Decode the instruction into control signals.</li>
<li><code>REQUEST</code> - Request data from global memory if necessary (if <code>LDR</code> or <code>STR</code> instruction).</li>
<li><code>WAIT</code> - Wait for data from global memory if applicable.</li>
<li><code>EXECUTE</code> - Execute any computations on data.</li>
<li><code>UPDATE</code> - Update register files and NZP register.</li>
</ol>
<p dir="auto">The control flow is laid out like this for the sake of simplicity and understandability.</p>
<p dir="auto">In practice, several of these steps could be compressed to be optimize processing times, and the GPU could also use <strong>pipelining</strong> to stream and coordinate the execution of many instructions on a cores resources without waiting for previous instructions to finish.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Thread</h3><a id="user-content-thread" aria-label="Permalink: Thread" href="#thread"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/thread.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/thread.png" alt="Thread"></a></p>
<p dir="auto">Each thread within each core follows the above execution path to perform computations on the data in it's dedicated register file.</p>
<p dir="auto">This resembles a standard CPU diagram, and is quite similar in functionality as well. The main difference is that the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> values lie in the read-only registers for each thread, enabling SIMD functionality.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kernels</h2><a id="user-content-kernels" aria-label="Permalink: Kernels" href="#kernels"></a></p>
<p dir="auto">I wrote a matrix addition and matrix multiplication kernel using my ISA as a proof of concept to demonstrate SIMD programming and execution with my GPU. The test files in this repository are capable of fully simulating the execution of these kernels on the GPU, producing data memory states and a complete execution trace.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix Addition</h3><a id="user-content-matrix-addition" aria-label="Permalink: Matrix Addition" href="#matrix-addition"></a></p>
<p dir="auto">This matrix addition kernel adds two 1 x 8 matrices by performing 8 element wise additions in separate threads.</p>
<p dir="auto">This demonstration makes use of the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> registers to show SIMD programming on this GPU. It also uses the <code>LDR</code> and <code>STR</code> instructions which require async memory management.</p>
<p dir="auto"><code>matadd.asm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content=".threads 8
.data 0 1 2 3 4 5 6 7          ; matrix A (1 x 8)
.data 0 1 2 3 4 5 6 7          ; matrix B (1 x 8)

MUL R0, %blockIdx, %blockDim
ADD R0, R0, %threadIdx         ; i = blockIdx * blockDim + threadIdx

CONST R1, #0                   ; baseA (matrix A base address)
CONST R2, #8                   ; baseB (matrix B base address)
CONST R3, #16                  ; baseC (matrix C base address)

ADD R4, R1, R0                 ; addr(A[i]) = baseA + i
LDR R4, R4                     ; load A[i] from global memory

ADD R5, R2, R0                 ; addr(B[i]) = baseB + i
LDR R5, R5                     ; load B[i] from global memory

ADD R6, R4, R5                 ; C[i] = A[i] + B[i]

ADD R7, R3, R0                 ; addr(C[i]) = baseC + i
STR R7, R6                     ; store C[i] in global memory

RET                            ; end of kernel"><pre><span>.threads </span><span>8</span>
<span>.data </span><span>0</span><span> </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span> </span><span>5</span><span> </span><span>6</span><span> </span><span>7</span><span>          ; matrix A (1 x 8)</span>
<span>.data </span><span>0</span><span> </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span> </span><span>5</span><span> </span><span>6</span><span> </span><span>7</span><span>          ; matrix B (1 x 8)</span>

<span>MUL</span><span> R0</span><span>,</span><span> %blockIdx</span><span>,</span><span> %blockDim</span>
<span>ADD</span><span> R0</span><span>,</span><span> R0</span><span>,</span><span> %threadIdx</span><span>         ; i = blockIdx * blockDim + threadIdx</span>

<span>CONST R1</span><span>,</span><span> #</span><span>0</span><span>                   ; baseA (matrix A base address)</span>
<span>CONST R2</span><span>,</span><span> #</span><span>8</span><span>                   ; baseB (matrix B base address)</span>
<span>CONST R3</span><span>,</span><span> #</span><span>16</span><span>                  ; baseC (matrix C base address)</span>

<span>ADD</span><span> R4</span><span>,</span><span> R1</span><span>,</span><span> R0</span><span>                 ; addr(A[i]) = baseA + i</span>
<span>LDR R4</span><span>,</span><span> R4</span><span>                     ; load A[i] from global memory</span>

<span>ADD</span><span> R5</span><span>,</span><span> R2</span><span>,</span><span> R0</span><span>                 ; addr(B[i]) = baseB + i</span>
<span>LDR R5</span><span>,</span><span> R5</span><span>                     ; load B[i] from global memory</span>

<span>ADD</span><span> R6</span><span>,</span><span> R4</span><span>,</span><span> R5</span><span>                 ; C[i] = A[i] + B[i]</span>

<span>ADD</span><span> R7</span><span>,</span><span> R3</span><span>,</span><span> R0</span><span>                 ; addr(C[i]) = baseC + i</span>
<span>STR</span><span> R7</span><span>,</span><span> R6</span><span>                     ; store C[i] in global memory</span>

<span>RET</span><span>                            ; end of kernel</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix Multiplication</h3><a id="user-content-matrix-multiplication" aria-label="Permalink: Matrix Multiplication" href="#matrix-multiplication"></a></p>
<p dir="auto">The matrix multiplication kernel multiplies two 2x2 matrices. It performs element wise calculation of the dot product of the relevant row and column and uses the <code>CMP</code> and <code>BRnzp</code> instructions to demonstrate branching within the threads (notably, all branches converge so this kernel works on the current tiny-gpu implementation).</p>
<p dir="auto"><code>matmul.asm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content=".threads 4
.data 1 2 3 4                  ; matrix A (2 x 2)
.data 1 2 3 4                  ; matrix B (2 x 2)

MUL R0, %blockIdx, %blockDim
ADD R0, R0, %threadIdx         ; i = blockIdx * blockDim + threadIdx

CONST R1, #1                   ; increment
CONST R2, #2                   ; N (matrix inner dimension)
CONST R3, #0                   ; baseA (matrix A base address)
CONST R4, #4                   ; baseB (matrix B base address)
CONST R5, #8                   ; baseC (matrix C base address)

DIV R6, R0, R2                 ; row = i // N
MUL R7, R6, R2
SUB R7, R0, R7                 ; col = i % N

CONST R8, #0                   ; acc = 0
CONST R9, #0                   ; k = 0

LOOP:
  MUL R10, R6, R2
  ADD R10, R10, R9
  ADD R10, R10, R3             ; addr(A[i]) = row * N + k + baseA
  LDR R10, R10                 ; load A[i] from global memory

  MUL R11, R9, R2
  ADD R11, R11, R7
  ADD R11, R11, R4             ; addr(B[i]) = k * N + col + baseB
  LDR R11, R11                 ; load B[i] from global memory

  MUL R12, R10, R11
  ADD R8, R8, R12              ; acc = acc + A[i] * B[i]

  ADD R9, R9, R1               ; increment k

  CMP R9, R2
  BRn LOOP                    ; loop while k < N

ADD R9, R5, R0                 ; addr(C[i]) = baseC + i
STR R9, R8                     ; store C[i] in global memory

RET                            ; end of kernel"><pre><span>.threads </span><span>4</span>
<span>.data </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span>                  ; matrix A (2 x 2)</span>
<span>.data </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span>                  ; matrix B (2 x 2)</span>

<span>MUL</span><span> R0</span><span>,</span><span> %blockIdx</span><span>,</span><span> %blockDim</span>
<span>ADD</span><span> R0</span><span>,</span><span> R0</span><span>,</span><span> %threadIdx</span><span>         ; i = blockIdx * blockDim + threadIdx</span>

<span>CONST R1</span><span>,</span><span> #</span><span>1</span><span>                   ; increment</span>
<span>CONST R2</span><span>,</span><span> #</span><span>2</span><span>                   ; N (matrix inner dimension)</span>
<span>CONST R3</span><span>,</span><span> #</span><span>0</span><span>                   ; baseA (matrix A base address)</span>
<span>CONST R4</span><span>,</span><span> #</span><span>4</span><span>                   ; baseB (matrix B base address)</span>
<span>CONST R5</span><span>,</span><span> #</span><span>8</span><span>                   ; baseC (matrix C base address)</span>

<span>DIV</span><span> R6</span><span>,</span><span> R0</span><span>,</span><span> R2</span><span>                 ; row = i // N</span>
<span>MUL</span><span> R7</span><span>,</span><span> R6</span><span>,</span><span> R2</span>
<span>SUB</span><span> R7</span><span>,</span><span> R0</span><span>,</span><span> R7</span><span>                 ; col = i % N</span>

<span>CONST </span><span>R8</span><span>,</span><span> #</span><span>0</span><span>                   ; acc = 0</span>
<span>CONST </span><span>R9</span><span>,</span><span> #</span><span>0</span><span>                   ; k = 0</span>

<span>LOOP</span><span>:</span>
<span>  </span><span>MUL</span><span> </span><span>R10</span><span>,</span><span> R6</span><span>,</span><span> R2</span>
<span>  </span><span>ADD</span><span> </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>,</span><span> </span><span>R9</span>
<span>  </span><span>ADD</span><span> </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>,</span><span> R3</span><span>             ; addr(A[i]) = row * N + k + baseA</span>
<span>  LDR </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>                 ; load A[i] from global memory</span>

<span>  </span><span>MUL</span><span> </span><span>R11</span><span>,</span><span> </span><span>R9</span><span>,</span><span> R2</span>
<span>  </span><span>ADD</span><span> </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>,</span><span> R7</span>
<span>  </span><span>ADD</span><span> </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>,</span><span> R4</span><span>             ; addr(B[i]) = k * N + col + baseB</span>
<span>  LDR </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>                 ; load B[i] from global memory</span>

<span>  </span><span>MUL</span><span> </span><span>R12</span><span>,</span><span> </span><span>R10</span><span>,</span><span> </span><span>R11</span>
<span>  </span><span>ADD</span><span> </span><span>R8</span><span>,</span><span> </span><span>R8</span><span>,</span><span> </span><span>R12</span><span>              ; acc = acc + A[i] * B[i]</span>

<span>  </span><span>ADD</span><span> </span><span>R9</span><span>,</span><span> </span><span>R9</span><span>,</span><span> R1</span><span>               ; increment k</span>

<span>  </span><span>CMP</span><span> </span><span>R9</span><span>,</span><span> R2</span>
<span>  BRn </span><span>LOOP</span><span>                    ; loop while k &lt; N</span>

<span>ADD</span><span> </span><span>R9</span><span>,</span><span> R5</span><span>,</span><span> R0</span><span>                 ; addr(C[i]) = baseC + i</span>
<span>STR</span><span> </span><span>R9</span><span>,</span><span> </span><span>R8</span><span>                     ; store C[i] in global memory</span>

<span>RET</span><span>                            ; end of kernel</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simulation</h2><a id="user-content-simulation" aria-label="Permalink: Simulation" href="#simulation"></a></p>
<p dir="auto">tiny-gpu is setup to simulate the execution of both of the above kernels. Before simulating, you'll need to install <a href="https://steveicarus.github.io/iverilog/usage/installation.html" rel="nofollow">iverilog</a> and <a href="https://docs.cocotb.org/en/stable/install.html" rel="nofollow">cocotb</a>.</p>
<p dir="auto">Once you've installed the pre-requisites, you can run the kernel simulations with <code>make test_matadd</code> and <code>make test_matmul</code>.</p>
<p dir="auto">Executing the simulations will output a log file in <code>test/logs</code> with the initial data memory state, complete execution trace of the kernel, and final data memory state.</p>
<p dir="auto">If you look at the initial data memory state logged at the start of the logfile for each, you should see the two start matrices for the calculation, and in the final data memory at the end of the file you should also see the resultant matrix.</p>
<p dir="auto">Below is a sample of the execution traces, showing on each cycle the execution of every thread within every core, including the current instruction, PC, register values, states, etc.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/trace.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/trace.png" alt="execution trace"></a></p>
<p dir="auto"><strong>For anyone trying to run the simulation or play with this repo, please feel free to DM me on <a href="https://twitter.com/majmudaradam" rel="nofollow">twitter</a> if you run into any issues - I want you to get this running!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced Functionality</h2><a id="user-content-advanced-functionality" aria-label="Permalink: Advanced Functionality" href="#advanced-functionality"></a></p>
<p dir="auto">For the sake of simplicity, there were many additional features implemented in modern GPUs that heavily improve performance &amp; functionality that tiny-gpu omits. We'll discuss some of those most critical features in this section.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi-layered Cache &amp; Shared Memory</h3><a id="user-content-multi-layered-cache--shared-memory" aria-label="Permalink: Multi-layered Cache &amp; Shared Memory" href="#multi-layered-cache--shared-memory"></a></p>
<p dir="auto">In modern GPUs, multiple different levels of caches are used to minimize the amount of data that needs to get accessed from global memory. tiny-gpu implements only one cache layer between individual compute units requesting memory and the memory controllers which stores recent cached data.</p>
<p dir="auto">Implementing multi-layered caches allows frequently accessed data to be cached more locally to where it's being used (with some caches within individual compute cores), minimizing load times for this data.</p>
<p dir="auto">Different caching algorithms are used to maximize cache-hits - this is a critical dimension that can be improved on to optimize memory access.</p>
<p dir="auto">Additionally, GPUs often use <strong>shared memory</strong> for threads within the same block to access a single memory space that can be used to share results with other threads.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Coalescing</h3><a id="user-content-memory-coalescing" aria-label="Permalink: Memory Coalescing" href="#memory-coalescing"></a></p>
<p dir="auto">Another critical memory optimization used by GPUs is <strong>memory coalescing.</strong> Multiple threads running in parallel often need to access sequential addresses in memory (for example, a group of threads accessing neighboring elements in a matrix) - but each of these memory requests is put in separately.</p>
<p dir="auto">Memory coalescing is used to analyzing queued memory requests and combine neighboring requests into a single transaction, minimizing time spent on addressing, and making all the requests together.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pipelining</h3><a id="user-content-pipelining" aria-label="Permalink: Pipelining" href="#pipelining"></a></p>
<p dir="auto">In the control flow for tiny-gpu, cores wait for one instruction to be executed on a group of threads before starting execution of the next instruction.</p>
<p dir="auto">Modern GPUs use <strong>pipelining</strong> to stream execution of multiple sequential instructions at once while ensuring that instructions with dependencies on each other still get executed sequentially.</p>
<p dir="auto">This helps to maximize resource utilization within cores as resources are not sitting idle while waiting (ex: during async memory requests).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Warp Scheduling</h3><a id="user-content-warp-scheduling" aria-label="Permalink: Warp Scheduling" href="#warp-scheduling"></a></p>
<p dir="auto">Another strategy used to maximize resource utilization on course is <strong>warp scheduling.</strong> This approach involves breaking up blocks into individual batches of theads that can be executed together.</p>
<p dir="auto">Multiple warps can be executed on a single core simultaneously by executing instructions from one warp while another warp is waiting. This is similar to pipelining, but dealing with instructions from different threads.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Branch Divergence</h3><a id="user-content-branch-divergence" aria-label="Permalink: Branch Divergence" href="#branch-divergence"></a></p>
<p dir="auto">tiny-gpu assumes that all threads in a single batch end up on the same PC after each instruction, meaning that threads can be executed in parallel for their entire lifetime.</p>
<p dir="auto">In reality, individual threads could diverge from each other and branch to different lines based on their data. With different PCs, these threads would need to split into separate lines of execution, which requires managing diverging threads &amp; paying attention to when threads converge again.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Synchronization &amp; Barriers</h3><a id="user-content-synchronization--barriers" aria-label="Permalink: Synchronization &amp; Barriers" href="#synchronization--barriers"></a></p>
<p dir="auto">Another core functionality of modern GPUs is the ability to set <strong>barriers</strong> so that groups of threads in a block can synchronize and wait until all other threads in the same block have gotten to a certain point before continuing execution.</p>
<p dir="auto">This is useful for cases where threads need to exchange shared data with each other so they can ensure that the data has been fully processed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Next Steps</h2><a id="user-content-next-steps" aria-label="Permalink: Next Steps" href="#next-steps"></a></p>
<p dir="auto">Updates I want to make in the future to improve the design, anyone else is welcome to contribute as well:</p>
<ul>
<li> Add a simple cache for instructions</li>
<li> Build an adapter to use GPU with Tiny Tapeout 7</li>
<li> Add basic branch divergence</li>
<li> Add basic memory coalescing</li>
<li> Add basic pipelining</li>
<li> Optimize control flow and use of registers to improve cycle time</li>
<li> Write a basic graphics kernel or add simple graphics hardware to demonstrate graphics functionality</li>
</ul>
<p dir="auto"><strong>For anyone curious to play around or make a contribution, feel free to put up a PR with any improvements you'd like to add üòÑ</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTML Attributes vs. DOM Properties (268 pts)]]></title>
            <link>https://jakearchibald.com/2024/attributes-vs-properties/</link>
            <guid>40152682</guid>
            <pubDate>Thu, 25 Apr 2024 02:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakearchibald.com/2024/attributes-vs-properties/">https://jakearchibald.com/2024/attributes-vs-properties/</a>, See on <a href="https://news.ycombinator.com/item?id=40152682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Attributes and properties are <em>fundamentally</em> different things. You can have an attribute and property of the same name set to different values. For example:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>foo</span><span><span>=</span><span>"</span>bar<span>"</span></span><span>&gt;</span></span>‚Ä¶<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'div[foo=bar]'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// undefined</span>

  div<span>.</span>foo <span>=</span> <span>'hello world'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// 'hello world'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>It seems like fewer and fewer developers know this, partially thanks to frameworks:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>If you do the above in a framework's templating language, you're using attribute-like syntax, but under the hood it'll sometimes be setting the property instead, and when it does that differs from framework to framework. In some cases, it'll set a property <em>and</em> an attribute as a side-effect, but that isn't the framework's fault.</p>
<p>Most of the time, these distinctions don't matter. I think it's good that developers can have a long and happy career without caring about the differences between properties and attributes. But, if you need to dig down into the DOM at a lower level, it helps to know. Even if you feel you know the difference, maybe I'll touch on a couple of details you hadn't considered. So let's dig in‚Ä¶</p>
<h2 id="the-key-differences"><a href="#the-key-differences">The key differences</a></h2>
<p>Before we get to the interesting stuff, let's get some of the technical differences out of the way:</p>
<h3 id="html-serialisation"><a href="#html-serialisation">HTML serialisation</a></h3>
<p>Attributes serialise to HTML, whereas properties don't:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
div<span>.</span>hello <span>=</span> <span>'world'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>div<span>.</span>outerHTML<span>)</span><span>;</span> <span>// '&lt;div foo="bar"&gt;&lt;/div&gt;'</span></code></pre></div><p>So when you're looking at the elements panel in browser developer tools, you're only seeing attributes on elements, not properties.</p>
<h3 id="value-types"><a href="#value-types">Value types</a></h3>
<p>In order to work in the serialised format, attribute values are always strings, whereas properties can be any type:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>
<span>const</span> obj <span>=</span> <span>{</span> <span>foo</span><span>:</span> <span>'bar'</span> <span>}</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> obj<span>)</span><span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'string'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// '[object Object]'</span>

div<span>.</span>hello <span>=</span> obj<span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span>hello<span>)</span><span>;</span> <span>// 'object'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span>hello<span>)</span><span>;</span> <span>// { foo: 'bar' }</span></code></pre></div><h3 id="case-sensitivity"><a href="#case-sensitivity">Case sensitivity</a></h3>
<p>Attribute names are case-insensitive, whereas property names are case-sensitive.</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>test<span>"</span></span> <span>HeLlO</span><span><span>=</span><span>"</span>world<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#test'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello']</span>

  div<span>.</span><span>setAttribute</span><span>(</span><span>'FOO'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello', 'foo']</span>

  div<span>.</span>TeSt <span>=</span> <span>'value'</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>TeSt<span>)</span><span>;</span> <span>// 'value'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>test<span>)</span><span>;</span> <span>// undefined</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>However, attribute <em>values</em> are case-sensitive.</p>
<p>Ok, here's where things start to get blurry:</p>
<h2 id="reflection"><a href="#reflection">Reflection</a></h2>
<p>Take a look at this:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>foo<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#foo'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'foo'</span>

  div<span>.</span>id <span>=</span> <span>'bar'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'bar'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This seems to contradict the first example in the post, but the above only works because <code>Element</code> has an <code>id</code> getter &amp; setter that 'reflects' the <code>id</code> attribute.</p>
<p>When a property reflects an attribute, the <em>attribute</em> is the source of the data. When you set the property, it's updating the attribute. When you read from the property, it's reading the attribute.</p>
<p>For convenience, most specs will create a property equivalent for every defined attribute. It didn't work in the example at the start of the article, because <code>foo</code> isn't a spec-defined attribute, so there isn't a spec-defined <code>foo</code> property that reflects it.</p>
<p><a href="https://html.spec.whatwg.org/multipage/grouping-content.html#the-ol-element">Here's the spec for <code>&lt;ol&gt;</code></a>. The "Content attributes" section defines the attributes, and the "DOM interface" defines the properties. If you click on <code>reversed</code> in the DOM interface, it takes you to this:</p>
<blockquote>

<p>The <code>reversed</code> and <code>type</code> IDL attributes must <a href="https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#reflect">reflect</a> the respective content attributes of the same name.</p>
</blockquote>

<p>But not all of these reflectors are as simple as these.</p>
<h3 id="naming-differences"><a href="#naming-differences">Naming differences</a></h3>
<p>Ok, this is relatively minor, but sometimes the property has a different name to the attribute it reflects.</p>
<p>In some cases it's just to add the kind of casing you'd expect from a property:</p>
<ul>
<li>On <code>&lt;img&gt;</code>, <code>el.crossOrigin</code> reflects the <code>crossorigin</code> attribute.</li>
<li>On all elements, <code>el.ariaLabel</code> reflects the <code>aria-label</code> attribute (the aria reflectors became cross browser in late 2023. Before that you could only use the attributes).</li>
</ul>
<p>In some cases, names had to be changed due to old JavaScript reserved words:</p>
<ul>
<li>On all elements, <code>el.className</code> reflects the <code>class</code> attribute.</li>
<li>On <code>&lt;label&gt;</code>, <code>el.htmlFor</code> reflects the <code>for</code> attribute.</li>
</ul>
<h3 id="validation-type-coercion-and-defaults"><a href="#validation-type-coercion-and-defaults">Validation, type coercion, and defaults</a></h3>
<p>Properties come with validation and defaults, whereas attribute don't:</p>
<div><pre><code><span>const</span> input <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span>

input<span>.</span>type <span>=</span> <span>'number'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'number'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'number'</span>

input<span>.</span>type <span>=</span> <span>'foo'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span></code></pre></div><p>In this case, the validation is handled by the <code>type</code> getter. The setter allowed the invalid value <code>'foo'</code>, but when the getter saw the invalid value, or no value, it returned <code>'text'</code>.</p>
<p>Some properties perform type coercion:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>open</span><span>&gt;</span></span>‚Ä¶<span><span><span>&lt;/</span>details</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> details <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'details'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>

  details<span>.</span>open <span>=</span> <span>false</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// false</span>

  details<span>.</span>open <span>=</span> <span>'hello'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>In this case, the <code>open</code> property is a boolean, returning whether the attribute exists. The setter also coerces the type - even though the setter is given <code>'hello'</code>, it's turned to a boolean rather than going directly to the attribute.</p>
<p>Properties like <code>img.height</code> coerce the attribute value to a number. The setter converts the incoming value to a number, and treats negative values as 0.</p>
<h3 id="value-on-input-fields"><a href="#value-on-input-fields"><code>value</code> on input fields</a></h3>
<p><code>value</code> is a fun one. There's a <code>value</code> property and a <code>value</code> attribute. However, the <code>value</code> property does not reflect the <code>value</code> attribute. Instead, the <code>defaultValue</code> property reflects the <code>value</code> attribute.</p>
<p>I know, I know.</p>
<p>In fact, the <code>value</code> property doesn't reflect <em>any</em> attribute. That isn't unusual, there's loads of these (<code>offsetWidth</code>, <code>parentNode</code>, <code>indeterminate</code> on checkboxes for some reason, and many more).</p>
<p>Initially, the <code>value</code> property defers to the <code>defaultValue</code> property. Then, once the <code>value</code> property is set, either via JavaScript or through user interaction, it switches to an internal value. It's as if it's implemented <em>roughly</em> like this:</p>
<div><pre><code><span>class</span> <span>HTMLInputElement</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>get</span> <span>defaultValue</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span> <span>??</span> <span>''</span><span>;</span>
  <span>}</span>

  <span>set</span> <span>defaultValue</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>String</span><span>(</span>newValue<span>)</span><span>)</span><span>;</span>
  <span>}</span>

  #value <span>=</span> <span>undefined</span><span>;</span>

  <span>get</span> <span>value</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span>#value <span>??</span> <span>this</span><span>.</span>defaultValue<span>;</span>
  <span>}</span>

  <span>set</span> <span>value</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>String</span><span>(</span>newValue<span>)</span><span>;</span>
  <span>}</span>

  <span>// This happens when the associated form resets</span>
  <span>formResetCallback</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>undefined</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>So:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>default<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> input <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'default'</span>

  input<span>.</span>defaultValue <span>=</span> <span>'new default'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  <span>// Here comes the mode switch:</span>
  input<span>.</span>value <span>=</span> <span>'hello!'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  input<span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>'another new default'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'another new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'another new default'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This would have made way more sense if the <code>value</code> attribute was named <code>defaultvalue</code>. Too late now.</p>
<h2 id="attributes-should-be-for-configuration"><a href="#attributes-should-be-for-configuration">Attributes should be for configuration</a></h2>
<p>In my opinion, attributes should be for configuration, whereas properties can contain state. I also believe that the light-DOM tree should have a single owner.</p>
<p>In that sense, I think <code>&lt;input value&gt;</code> gets it right (aside from the naming). The <code>value</code> attribute configures the default value, whereas the <code>value</code> property gives you the current state.</p>
<p>It also makes sense that validation applies when getting/setting properties, but never when getting/setting attributes.</p>
<p>I say 'in my opinion', because a couple of recent HTML elements have done it differently.</p>
<p>The <code>&lt;details&gt;</code> and <code>&lt;dialog&gt;</code> elements represent their open state via the <code>open</code> attribute, and the browser will self add/remove this attribute in response to user interaction.</p>
<p>I think this was a design mistake. It breaks the idea that attributes are for configuration, but more importantly it means that the system in charge of maintaining the DOM (a framework, or vanilla JS) needs to be prepared for the DOM to change itself.</p>
<p>I think it should have been:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>defaultopen</span><span>&gt;</span></span>‚Ä¶<span><span><span>&lt;/</span>details</span><span>&gt;</span></span></code></pre></div><p>And a <code>details.open</code> property to get/set the current state, along with a CSS pseudo-class for targeting that state.</p>
<p>I guess <code>contenteditable</code> also breaks that contract, but‚Ä¶ well‚Ä¶ it's a opt-in to a lot of breakage.</p>
<h2 id="how-frameworks-handle-the-difference"><a href="#how-frameworks-handle-the-difference">How frameworks handle the difference</a></h2>
<p>Back to the example from earlier:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>How do frameworks handle this?</p>
<h3 id="preact-and-vuejs"><a href="#preact-and-vuejs">Preact and VueJS</a></h3>
<p>Aside from a predefined set of cases where they favour attributes, they'll set the prop as a property if <code>propName in element</code>, otherwise they'll set an attribute. Basically, they prefer properties over attributes. Their render-to-string methods do the opposite, and ignore things that are property-only.</p>
<ul>
<li><a href="https://github.com/preactjs/preact/blob/aa95aa924dd5fe28798f2712acdabdc2e9fa38c9/src/diff/props.js#L37"><code>setProperty</code> in Preact</a>.</li>
<li><a href="https://github.com/vuejs/core/blob/958286e3f050dc707ad1af293e91bfb190bdb191/packages/runtime-dom/src/patchProp.ts#L69"><code>shouldSetAsProp</code> in VueJS</a>.</li>
</ul>
<h3 id="react"><a href="#react">React</a></h3>
<p>React does things the other way around. Aside from a predefined set of cases where they favour properties, they'll set an attribute. This makes their render-to-string method similar in logic.</p>
<p>This explains why custom elements don't seem to work in React. Since they're custom, their properties aren't in React's 'predefined list', so they're set as attributes instead. Anything that's property-only on the custom element simply won't work. This will be fixed in React 19, where they'll switch to the Preact/VueJS model for custom elements.</p>
<p>The funny thing is, React popularised using <code>className</code> instead of <code>class</code> in what <em>looks like</em> an attribute. But, even though you're using the property name rather than the attribute name, <a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L388-L389">React will set the <code>class</code> attribute under the hood</a>.</p>
<ul>
<li><a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L349"><code>setProp</code> in React</a>.</li>
</ul>
<h3 id="lit-html"><a href="#lit-html">lit-html</a></h3>
<p>Lit does things a little differently:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>.value</span><span><span>=</span><span>"</span>‚Ä¶<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>It keeps the distinction between attributes and properties, requiring you to prefix the name with <code>.</code> if you want to set the property rather than the attribute.</p>
<ul>
<li><a href="https://lit.dev/docs/templates/expressions/">Lit's expression docs</a>.</li>
</ul>
<h2 id="and-thats-yer-lot"><a href="#and-thats-yer-lot">And that's yer lot</a></h2>
<p>That's pretty much everything I know about the difference between properties and attributes. If there's something I've missed, or you have a question, let me know in the comments below!</p>
<p>Thanks to my <a href="https://offthemainthread.tech/">podcast husband</a> <a href="https://surma.dev/">Surma</a> for his usual reviewing skills.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine tune LLAMA3 on million scale dataset in consumer GPU using QLora, DeepSpeed (127 pts)]]></title>
            <link>https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</link>
            <guid>40152486</guid>
            <pubDate>Thu, 25 Apr 2024 02:03:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a">https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</a>, See on <a href="https://news.ycombinator.com/item?id=40152486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@sumandas0?source=post_page-----3ae8ad75299a--------------------------------"><div aria-hidden="false"><p><img alt="Suman" src="https://miro.medium.com/v2/resize:fill:88:88/1*cPgbuLwwvCkde8ztQQcNFA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><h2 id="6688">Highlights,</h2><p id="9884"><strong>Model</strong> : LLAMA-8b-instruct</p><p id="e592"><strong>Dataset</strong>: Openhermes-2.5(700k training, 300k testing)</p><p id="7df9"><strong>GPU</strong>: 4 RTX 4090, 24GB</p><h2 id="88aa">Bit of background about me,</h2><p id="cd1d">I‚Äôm a full-time software engineer 2, at the core of our platform team. In my scarce free time, I explore various aspects of the machine learning world, with interests in tabular data, NLP, and sound. Whatever I‚Äôm sharing here are scraps from all over the internet consolidated into one place. I have decent experience in training small NLP models and have submitted a solution in a Kaggle competition using DeBERTa v3, scoring enough to be in the top 50%, but I have never tried working with large language models. This is my first time, so please let me know if there are any oversights. Yes, this is my first blog post. Writing this will definitely help me, and hopefully, it will be useful for any readers as well</p><h2 id="023a">LLama</h2><p id="7eff">Who don‚Äôt know about this long necked creature revolutionizing the AI field from its birth. Joke apart release of llama where the whole OSS powered LLM kicked of the revolution which don‚Äôt seems like stopping in near future.</p><p id="b306">To learn more on llama in depth and technical do checkout this <a href="https://www.linkedin.com/posts/ujamil_llama-explained-kv-cache-rotary-positional-activity-7100620274642866176-XaKO/" rel="noopener ugc nofollow" target="_blank">Post | LinkedIn</a> , this is one of the most technically simplified explanation I can found all over the internet. Few things they implemented in their architecture like Grouped Multi Query Attention, KV-Cache, Rotary Positional Embeddings(RoPE) which are very cool. These are not in scope of this article. They continued releasing their versions of LLama with latest version came few days ago. And this time with massive data compacted into few GBs of parameters.</p><figure><figcaption><a href="https://www.forbes.com/sites/janakirammsv/2024/04/19/meta-unveils-llama-310-key-facts-about-the-advanced-llm/" rel="noopener ugc nofollow" target="_blank">Meta Unveils Llama 3‚Äì10 Key Facts About The Advanced LLM (forbes.com)</a></figcaption></figure><h2 id="226e">Deepspeed</h2><blockquote><p id="0a5f"><em>DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.</em></p><p id="eddb"><a href="https://github.com/microsoft/DeepSpeed" rel="noopener ugc nofollow" target="_blank"><em>https://github.com/microsoft/DeepSpeed</em></a></p></blockquote><p id="dee0">I will be training this model using four RTX 4090 GPUs that I‚Äôve rented from <a href="http://vast.ai/" rel="noopener ugc nofollow" target="_blank">vast.ai</a>, so we need to take some steps to train the models across multiple GPUs. Training on multiple GPUs is a complex task compared to training on a single GPU. Why? When we train on a single GPU, the Optimizer state, parameters and gradients reside in a single system, which helps iterating over models on one GPU.</p><p id="c422">Now, if we add another GPU, there are two systems that will train the models, each with its own state(Optimizer state, parameters and gradients). After one epoch or several steps, we would like to obtain a single result. Now imagine two systems training two batches of data in parallel; they need to communicate about their state and converge the results with minimal data loss. There are multiple ways to utilize multiple GPUs: we can replicate parameters, gradients, and optimizer state across all GPUs, or we could shard only the optimizer state, or the optimizer state and gradients. DeepSpeed helps in distributing the load over the GPUs without any issues. And accelerate package from Huggingface lets us do this like its piece of cake.</p><p id="91cc">I will use stage 3 which will shard all parameters, gradients and optimizer state which will let us training over less memory requirement,</p><figure></figure><p id="2411">More details in their blog, <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/" rel="noopener ugc nofollow" target="_blank">ZeRO &amp; DeepSpeed: New system optimizations enable training models with over 100 billion parameters ‚Äî Microsoft Research</a></p><h2 id="9ade">QLoRA</h2><p id="ebf1">Until I write something about QLoRA, please take a look into this blog to get more technical context <a href="https://wandb.ai/sauravmaheshkar/QLoRA/reports/What-is-QLoRA---Vmlldzo2MTI2OTc5" rel="noopener ugc nofollow" target="_blank">What is QLoRA? | QLoRA ‚Äî Weights &amp; Biases (wandb.ai)</a>, basically 70B/8B models are very large in size means when you fine tune it you will not be able to fully fine tune with any GPU in normal people‚Äôs budget, so we tried to fine tune it with very low resource and came LoRA which helped us just training over parameters with low rank and merging them with original weights, then came QLoRA which helped even more reducing memory consumption by quantizing the pre trained LLM to 4 bit precision, quantizing is a topic in itself so not going beyond this.</p><p id="51ad">Also take a look into this article <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></p><h2 id="50cb">Lets start finetuning LLamA 3</h2><p id="a905">We will be finetuning the llama3 instruct model <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" rel="noopener ugc nofollow" target="_blank">meta-llama/Meta-Llama-3‚Äì8B-Instruct ¬∑ Hugging Face</a> over <a href="https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B" rel="noopener ugc nofollow" target="_blank">openhermes</a> dataset provided by teknium.</p><h2 id="0e59">Data preparation</h2><p id="a219">Meta has their own chat format so tried to follow the format they provided and read their encoding algorithm in their llama3 repository,</p><p id="b4df"><strong>Load the dataset</strong></p><pre><span id="0492">from datasets import load_dataset<p>dataset = load_dataset("teknium/OpenHermes-2.5")</p></span></pre><p id="3943"><strong>The encoding utility I took inspiration from</strong><a href="https://github.com/meta-llama/llama3/blob/af6eedf7042fb51d00b2b26d8ef1ceaab73e1670/llama/tokenizer.py#L202" rel="noopener ugc nofollow" target="_blank"><strong> llama3 repo</strong></a><strong>,</strong></p><pre><span id="2427">def _return_header(message)-&gt; str:<br>    role = message["from"]<br>    header = ""<br>    if role == "system":<br>        header = "system"<br>    elif role == "gpt":<br>        header = "assistant"<br>    elif role == "human":<br>        header = "user"<br>    return header<p>def encode_header(message):<br>    text = ''<br>    text = text + "&lt;|start_header_id|&gt;"<br>    header = _return_header(message)<br>    text = text + header<br>    text = text + "&lt;|end_header_id|&gt;"<br>    text = text + "\n\n"<br>    return text</p><p>def encode_message(message)-&gt;str:<br>    text = encode_header(message)<br>    text = text + message["value"].strip()<br>    text = text + "&lt;|eot_id|&gt;"<br>    return text</p><p>def encode_dialog_prompt(dialog):<br>    text = ''<br>    text = text + "&lt;|begin_of_text|&gt;"<br>    for message in dialog:<br>        text = text + encode_message(message)<br>    return text</p></span></pre><pre><span id="c697">ds = dataset.map(lambda x: {"content":encode_dialog_prompt(x['conversations'])}, num_proc=10)</span></pre><p id="6128">Remove redundunt columns and split it into train and validation</p><pre><span id="6147">ds = ds.remove_columns(['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'])<br>train_test_split = ds["train"].train_test_split(test_size=0.3)</span></pre><p id="e8fc"><strong>And push it to hub,</strong></p><pre><span id="c29e">train_test_split.push_to_hub("sumandas/openhermes-2.5-llama3")</span></pre><p id="6614">The resultant dataset, <a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 ¬∑ Datasets at Hugging Face</a>, example text</p><pre><span id="3556">&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt; You are an AI assistant. Provide a detailed answer so user don‚Äôt need to search outside to understand the answer.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Instructions: Given a sentence, generate what should be the most likely next statement. The next statement should be reasonable and logically correct. Input: The screen is full of white bubbles and words, while a pair of hands plays the piano. The bubbles and words disappear and it Output:&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt; Output: becomes apparent that the hands are creating a visual representation of the music being played, captivating the audience with this unique sensory experience.&lt;|eot_id|&gt;</span></pre><h2 id="1ba2">Now its time for training LLama3</h2><p id="cab1">All of the resources were already available in internet I just fine tuned those for my setup and requirements,</p><p id="ebdc"><strong>Prerequisites,</strong></p><ol><li id="0bf2">Install cuda dev kit <code>conda install cuda</code> or follow <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux" rel="noopener ugc nofollow" target="_blank">developer.nvidia.com/cuda-downloads?target_os=Linux</a></li><li id="0a0a">Install deepspeed</li><li id="cd39">Install flash-attention <em>pip install flash-attn ‚Äî no-build-isolation</em></li><li id="6a5a">Install these libraries, I use <a href="https://github.com/astral-sh/uv" rel="noopener ugc nofollow" target="_blank">uv</a> for faster dependency resolution,</li></ol><pre><span id="2bb2">git+https://github.com/huggingface/transformers<br>git+https://github.com/huggingface/accelerate<br>git+https://github.com/huggingface/peft<br>git+https://github.com/huggingface/trl<br>huggingface-hub<br>bitsandbytes<br>evaluate<br>datasets<br>einops<br>wandb<br>tiktoken<br>xformers<br>sentencepiece<br>deepspeed<br>torch==2.2.2</span></pre><p id="ebd9"><strong>Training code</strong></p><p id="d43d">This is Swiss knife training code where you can train in multiple mode as per you convenience, found this in this repo <a href="https://github.com/pacman100/LLM-Workshop" rel="noopener ugc nofollow" target="_blank">pacman100/LLM-Workshop: LLM Workshop by Sourab Mangrulkar (github.com)</a>,</p><blockquote><p id="93e4">The <code>training.py</code> file is the one we will launch using accelerate with proper configs, just putting the training.py gist here, <a href="https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab</a></p></blockquote><p id="831b">This training code uses SFTTrainer from huggingface, more details <a href="https://huggingface.co/docs/trl/en/sft_trainer" rel="noopener ugc nofollow" target="_blank">Supervised Fine-tuning Trainer (huggingface.co)</a></p><p id="7822">You can do multiple thing with this, you can train with loftq, unsloth, FFT, normal lora but I will just use QloRa with Deepspeed ZerO stage 3.</p><p id="cc17"><strong>First lets define the accelerate config for using deepspeed</strong></p><figure></figure><blockquote><p id="2bfa">Note, If you increase the number of GPU update number in <em>num_processes</em></p></blockquote><p id="56e5">Now lets just run the accelerate command to start training,</p><pre><span id="7326">accelerate launch --config_file "deepspeed_config.yaml"  train.py \<br>--seed 100 \<br>--model_name_or_path "meta-llama/Meta-Llama-3-8B-Instruct" \<br>--dataset_name "sumandas/openhermes-2.5-llama3" \<br>--chat_template_format "none" \<br>--add_special_tokens False \<br>--append_concat_token False \<br>--splits "train,test" \<br>--max_seq_len 2048 \<br>--num_train_epochs 1 \<br>--logging_steps 5 \<br>--log_level "info" \<br>--logging_strategy "steps" \<br>--evaluation_strategy "epoch" \<br>--save_strategy "steps" \<br>--push_to_hub \<br>--hub_private_repo True \<br>--report_to "wandb" \<br>--hub_strategy "every_save" \<br>--bf16 True \<br>--packing True \<br>--learning_rate 1e-4 \<br>--lr_scheduler_type "cosine" \<br>--weight_decay 1e-4 \<br>--warmup_ratio 0.0 \<br>--max_grad_norm 1.0 \<br>--output_dir "llama3-openhermes-2.5" \<br>--per_device_train_batch_size 4\<br>--per_device_eval_batch_size 4\<br>--gradient_accumulation_steps 2 \<br>--gradient_checkpointing True \<br>--use_reentrant True \<br>--dataset_text_field "content" \<br>--use_flash_attn True \<br>--use_peft_lora True \<br>--lora_r 8 \<br>--lora_alpha 16 \<br>--lora_dropout 0.1 \<br>--lora_target_modules "all-linear" \<br>--use_4bit_quantization True \<br>--use_nested_quant True \<br>--bnb_4bit_compute_dtype "bfloat16" \<br>--bnb_4bit_quant_storage_dtype "bfloat16"</span></pre><p id="85c8"><strong>Notes,</strong></p><ol><li id="7f33">Set env variable HF_HUB_ENABLE_HF_TRANSFER=1 first</li><li id="10d8">output_dir will also be the repo created in huggingface where all the checkpoints will be stored, checkpoints will be created every 500 steps by default</li><li id="e8df">I set chat template format as <code>none</code> , because I already formatted those in my way, if you have other format do use for e.g chatml, zephyr</li><li id="9507"><code>lora_target_modules</code> is set as all-linear which is QLoRa specific where they published paper to show fine tuning all linear layers gives us comparable result to full fine tune.</li><li id="7c14">For setting up hyperparameters for LoRa, take a look into this awesome blog <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></li><li id="c733">Set up WANDB_API_KEY=&lt;key&gt; if you are reporting to wandb else remove <code>report_to='wandb'</code></li></ol><p id="bc6b">This should be it and your training should be running in full force, look for GPU utilization.</p><h2 id="f2df">Observation</h2><p id="38ff">Ran the fine tuning for only 1 epoch, took around 15 hours. Loss curve</p><figure><figcaption>fig: training loss <a href="https://wandb.ai/sumandas0/huggingface/reports/train-loss-24-04-25-02-44-11---Vmlldzo3Njg1NzIw?accessToken=hinzctjy4lbm48zwjoamnmhxs5r56zp8l88iqpss2jb0xo2w2bu049jkiqd59btj" rel="noopener ugc nofollow" target="_blank">train/loss (24/04/25 02:44:11) | huggingface ‚Äî Weights &amp; Biases (wandb.ai)</a></figcaption></figure><p id="38c3"><strong>WandB summary</strong></p><pre><span id="e856">{<br>  "train/learning_rate": 0.00004551803455482833,<br>  "eval/steps_per_second": 0.893,<br>  "_wandb.runtime": 51487,<br>  "_runtime": 51480.36651659012,<br>  "_timestamp": 1713698971.6200776,<br>  "train/epoch": 1.0571428571428572,<br>  "train/grad_norm": 0.14189070214353952,<br>  "train/global_step": 8325,<br>  "eval/samples_per_second": 7.141,<br>  "_step": 1665,<br>  "eval/loss": 0.963840126991272,<br>  "train/loss": 0.9674,<br>  "eval/runtime": 7532.9797<br>}</span></pre><h2 id="602e">Last steps,</h2><p id="02a5">After the finetuning what model you will get is small adapter model not full model that you can just start using just now, we need to add the adapter to the original meta llama3 weights,</p><p id="d092">Load PEFT adapter model,</p><pre><span id="866d">from peft import PeftModel<br>from transformers import AutoModelForCausalLM<p>base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Meta-Llama-3-8B-Instruct",torch_dtype=torch.bfloat16, device_map="auto")<br>adapter_model = PeftModel.from_pretrained(base_model, "sumandas/llama3-openhermes-2.5")<br>adapter_model.merge_and_unload()</p></span></pre><p id="11a1">Now save the adapter model into hf,</p><pre><span id="c058">adapter_model.push_to_hub("sumandas/llama3-openhermes-2.5")</span></pre><h2 id="6ffe">Inference</h2><pre><span id="2c4c">import torch<br>import transformers<br>from transformers import pipeline<p>pipe = pipeline("text-generation", model="sumandas/llama3-openhermes-2.5",model_kwargs={"torch_dtype": torch.bfloat16},<br>    device="cuda")</p><p>generate_kwargs = {<br>    "do_sample": True,<br>    "temperature": 0.7,<br>    "max_new_tokens": 35,<br>}</p></span></pre><pre><span id="e8fe">pipe("&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Describe the food of Thailand&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;",max_length=2048)</span></pre><p id="a1a4">Response,</p><pre><span id="dce7">Thai cuisine is a blend of bold flavors and aromatic ingredients that create a harmonious balance of sweet, sour, salty, bitter, and spicy taste. The food in Thailand varies between different regions, but some common ingredients found throughout include rice, noodles, vegetables, herbs, and spices. Rice is a staple of Thai cuisine and is served with almost every meal, whether it is stir-fried, boiled, or used to make congee or fried rice. Noodles, made from rice or wheat, are also very popular and can be found served with various broths, sauces, and toppings in many Thai dishes. Thai food is known for its use of fresh herbs and spices such as lemongrass, galangal, coriander, basil, kaffir lime leaves, ginger, and garlic, which give the dishes their distinct flavors. Thai chilies are also widely used to add varying levels of heat to the food. Some popular Thai dishes include Tom Yum soup (hot and sour soup with lemongrass, kaffir lime leaves, and chilies), Pad Thai (stir-fried rice noodles with vegetables, peanuts, and a tangy sauce), and green curry (a spicy curry made with green chilies, coconut milk, and Thai basil). Many Thai dishes are also accompanied by a variety of sauces and condiments, including fish sauce, soy sauce, chili paste, and tamarind sauce. Fresh fruits like mango, papaya, and pineapple are also commonly enjoyed as a sweet ending to a meal. Overall, Thai food is a vibrant and flavorful cuisine that combines traditional ingredients and cooking techniques with a balance of flavors that tantalize the taste buds.&lt;|eot_id|&gt;</span></pre><p id="9238">Do send my model and dataset some love if it has any worth :)</p><p id="45d9"><a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 ¬∑ Datasets at Hugging Face</a></p><p id="2c72"><a href="https://huggingface.co/sumandas/llama3-openhermes-2.5" rel="noopener ugc nofollow" target="_blank">sumandas/llama3-openhermes-2.5 ¬∑ Hugging Face</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Air Force picks Anduril, General Atomics to develop unmanned fighter jets (156 pts)]]></title>
            <link>https://breakingdefense.com/2024/04/air-force-picks-anduril-general-atomics-for-next-round-of-cca-work/</link>
            <guid>40152049</guid>
            <pubDate>Thu, 25 Apr 2024 01:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://breakingdefense.com/2024/04/air-force-picks-anduril-general-atomics-for-next-round-of-cca-work/">https://breakingdefense.com/2024/04/air-force-picks-anduril-general-atomics-for-next-round-of-cca-work/</a>, See on <a href="https://news.ycombinator.com/item?id=40152049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="entry-351504">
<div id="attachment_351513"><p><img aria-describedby="caption-attachment-351513" decoding="async" fetchpriority="high" src="https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235.jpg" alt="SecAF Kendall speaks at SLOC" width="2560" height="1442" srcset="https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235.jpg 2560w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-350x197.jpg 350w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-1024x577.jpg 1024w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-768x433.jpg 768w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-1536x865.jpg 1536w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-2048x1154.jpg 2048w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-1070x603.jpg 1070w" sizes="(max-width: 2560px) 100vw, 2560px"></p><p id="caption-attachment-351513">Secretary of the Air Force Frank Kendall speaks with students and guests during the Senior Leader Orientation Course at Joint Base Andrews, Md., Nov. 13, 2023. (U.S. Air Force photo by Eric Dietrich)</p></div>
<p><em><strong>UPDATED 4/24/24 at 5:48 PM ET with details from an Air Force press release and comments from CCA vendors.&nbsp;</strong></em></p>
<p><span>WASHINGTON ‚Äî Defense startup Anduril and drone maker General Atomics Aeronautical Systems (GA-ASI) have been picked by the Air Force to build and test drone prototypes for the next phase of the service‚Äôs</span><a href="https://breakingdefense.com/tag/collaborative-combat-aircraft/"> <span>Collaborative Combat Aircraft</span></a><span> program, the Air Force announced tonight.</span></p>
<p><span>The Air Force‚Äôs decision winnows down a pool of five competitors to two. As a result, three other vendors ‚Äî Boeing, Lockheed Martin and Northrop Grumman ‚Äî have been eliminated from the running.</span></p>

<p><span>‚ÄúThe companies not selected to build these production representative CCA vehicles, and execute the flight test program, will continue to be part of the broader industry partner vendor pool consisting of more than 20 companies to compete for future efforts, including future production contracts,‚Äù the Air Force said.</span><span>&nbsp;</span></p>
<p><span>As Breaking Defense</span><a href="https://breakingdefense.com/2023/12/exclusive-5-companies-in-early-running-for-air-forces-cca-drone-wingmen/#:~:text=Boeing%2C%20General%20Atomics%2C%20Lockheed%20Martin,aircraft%2C%20Breaking%20Defense%20has%20learned."> <span>first reported</span></a><span>, the five contractors were previously picked by the Air Force for the program‚Äôs first phase, which largely focused on design work. Today‚Äôs selection narrows down the vendors who will take their designs from the drawing board to the real world. As Air Force acquisition chief Andrew Hunter recently told lawmakers in a congressional hearing, the upcoming CCA stage will see those vendors ‚Äúcomplete detailed designs, build prototypes and test production-representative test articles.‚Äù</span></p>

<p><span>Unveiled by the service as a major multibillion dollar program in the fiscal year 2024 budget, the CCA effort aims to initially field</span><a href="https://breakingdefense.com/2023/03/air-force-plans-nominal-buy-of-200-ngad-fighters-1000-drone-wingmen-kendall-says/"><span> as many as 1,000 drones</span></a><span>. According to the service‚Äôs press release today, officials plan to make a ‚Äúcompetitive production decision‚Äù by FY26 for the first round of CCA work and ‚Äúfield a fully operational capability before the end of the decade.‚Äù</span></p>
<p><b><i>RELATED:</i></b><a href="https://breakingdefense.com/2024/04/in-a-world-first-darpa-project-demonstrates-ai-dogfighting-in-real-jet/"> <b><i>In a ‚Äòworld first,‚Äô DARPA project demonstrates AI dogfighting in a real jet</i></b></a></p>


<p><span>At the Air &amp; Space Forces Association Warfare Symposium in February,</span><a href="https://breakingdefense.com/2024/02/air-force-plans-cca-downselect-within-months-second-increment-in-fy25-kendall/"> <span>Kendall revealed</span></a><span> that the CCA competition underway right now would be the program‚Äôs first ‚Äúincrement,‚Äù with a second to follow in the FY25 budget. That second increment would provide vendors eliminated today, as well as</span><a href="https://breakingdefense.com/2024/02/take-2-kratos-aims-for-prime-status-on-second-cca-increment/"> <span>new ones</span></a><span>, another shot at a CCA contract.</span><a href="https://breakingdefense.com/2023/10/is-a-us-aussie-japanese-loyal-wingman-drone-in-the-cards/"> <span>International collaboration</span></a><span> could also feature in the second increment, Kendall said, and the service‚Äôs release today indicated foreign military sales could be on the table for the program.&nbsp;</span></p>
<p><span>During the February roundtable, Kendall further revealed the ‚Äúpossibility‚Äù that more than one vendor could see their drone bid enter service for the first increment. He also floated the chance of carrying up to three vendors through the preceding test phase if industry helped share some of the cost.&nbsp;</span></p>
<p><span>With only two vendors making the cut today, it‚Äôs unclear if that idea bore any fruit. Asked recently whether industry was convinced to pick up some of the tab, Hunter told reporters that ‚Äúcost sharing is not core to our approach on CCA.‚Äù</span></p>
<p><span>The service‚Äôs press release today said that the down select decision ‚Äúdoes not exclude any of the vendors from competing for the future Increment 1 production contract‚Äù ‚Äî likely suggesting companies would have to spend internal funds to move their designs forward and compete for an eventual production deal.</span></p>
<h2><b>What Companies Pitched, And What Comes Next</b></h2>
<p><span>When it comes to specific designs, GA-ASI has</span><a href="https://breakingdefense.com/2023/11/general-atomics-exec-eyes-williams-pratt-engines-as-company-searches-for-cca-propulsion/"> <span>stated</span></a><span> that the company‚Äôs Gambit drone family would be its entry, while</span><a href="https://breakingdefense.com/2023/09/defense-startup-anduril-acquires-uas-maker-blue-force-technologies/"> <span>Anduril‚Äôs acquisition</span></a><span> last year of autonomous aircraft vendor Blue Force positioned the Fury drone to be Anduril‚Äôs bid. In images today touting the company‚Äôs win, Anduril showcased the Fury drone, appearing to confirm the drone was the company‚Äôs bid.</span></p>
<p><span>‚ÄúThere is no time to waste on business as usual. With the CCA program, Secretary Kendall and the Air Force have embraced a fast-moving, forward-looking approach to field autonomous systems at speed and scale,‚Äù Anduril CEO and Co-Founder Brian Schimpf said in a statement. ‚ÄúWe are honored to be selected for this unprecedented opportunity, which signals a demand for continued expansion of the defense industrial base. Anduril is proud to pave the way for other non-traditional defense companies to compete and deliver on large scale programs.‚Äù</span></p>
<p><span>‚ÄúThroughout our 30-year history, GA-ASI has been at the forefront of rapidly advancing unmanned aircraft systems that support our warfighters,‚Äù GA-ASI President David Alexander said in a statement. ‚ÄúThe USAF is moving forward with GA-ASI due to our focused commitment to unmanned air-to-air combat operations and unmatched UAS experience, ensuring the production of the CCA aircraft at scale to deliver affordable combat mass for the warfighter.‚Äù</span></p>
<p><span>Boeing said in a statement today that the aerospace giant offered a ‚Äúproprietary solution tailored to the U.S. Air Force‚Äôs unique CCA phase one requirements,‚Äù and did not pitch the MQ-25 Stingray or MQ-28 Ghost Bat.</span><span>&nbsp;</span></p>
<p><span>‚ÄúWhile we are disappointed that we won‚Äôt be moving forward in this phase of the Air Force‚Äôs CCA program, we are undeterred in our commitment to providing next-generation autonomous combat aircraft for U.S. and global military customers. Work continues on our robust and growing autonomous family, including the MQ-25 Stingray and future derivatives, the MQ-28 Ghost Bat, and a number of proprietary programs we can‚Äôt disclose,‚Äù Boeing said.&nbsp;</span></p>
<p><span>Lockheed and Northrop have also not confirmed what candidates they put forward.</span></p>
<p><span>In a statement, Lockheed said</span><span> the company ‚Äúremains committed to advancing the state of the art in autonomous systems for air and ground missions. Our work to develop and integrate pathfinding open architectures, ground control systems like the Multi-Domain Combat System‚Ñ¢, human factors interfaces, and mission systems continues. For some time, we‚Äôve been focused on bringing to life the transformative power of autonomous and AI/ML enabled operations in crewed and uncrewed DoD systems, with particular focus on integrating CCA with F-35 and F-22. These commitments and work are ongoing.‚Äù</span></p>
<p><span>A representative for Northrop did not immediately respond to a request for comment.&nbsp;</span></p>
<p><span>A second parallel effort under CCA is also known to be working on the drones‚Äô autonomous software, though it‚Äôs unclear what companies are involved. Hunter</span><a href="https://breakingdefense.com/2023/05/air-force-expects-sizeable-vendor-pool-for-drone-wingmen/"> <span>said last year</span></a><span> the service already had 20 to 30 vendors working on that element of CCA work, and more recently said in February that the autonomy piece would continue independent of progress on the hardware side.</span></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Beginner's Guide to the ESP8266 (199 pts)]]></title>
            <link>https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html</link>
            <guid>40151982</guid>
            <pubDate>Thu, 25 Apr 2024 01:03:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html">https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html</a>, See on <a href="https://news.ycombinator.com/item?id=40151982">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

   
<i>Pieter P,‚ÄÉ08-03-2017</i>
   <p>
        Some time ago, I wrote <a href="http://www.instructables.com/id/A-Beginners-Guide-to-Arduino/">a Beginner's Guide to Arduino</a> that seems to be very popular, so I decided to create a follow-up: <b>A Beginner's Guide to the ESP8266</b>. That's right, a tutorial on how to use the world's most popular $3 Wi-Fi board.
   </p>
   
   <p>
        This is going to be a very in-depth tutorial, covering some networking concepts as well. If you're a beginner, and just want to go straight to the more exciting Wi-Fi part, feel free to do so, I included short <i>TL;DR's </i>in the longer, more technical parts.
   </p>
   
   <p>
        A short overview of what I'll cover in this article: 
   </p>
   <div>
       <ol>
           <li><b>What is an ESP8266?</b> A short overview of what an ESP8266 is, and what you can do with it</li>
           <li><b>Deciding on what board to buy</b>: There's loads of different ESP8266 available these days, finding the one that's best for you can be hard</li>
           <li><b>Installing the software</b>: you need to install some software to program the ESP8266, and maybe a USB driver</li>
           <li><b>Setting up the hardware</b>: some modules and boards need some external components</li>
           <li><b>The ESP8266 as a microcontroller</b>: the ESP8266 can be used as a normal microcontroller, just like an Arduino</li>
           <li><b>Network protocols</b>: Before we start using the Wi-Fi capabilities of the ESP8266, I'll teach you some of the network protocols involved</li>
           <li><b>Setting up a Wi-Fi connection</b>: That's probably why you're reading this, right?</li>
           <li><b>Name resolution</b>: Find the ESP8266 on your local network using mDNS</li>
           <li><b>Setting up a simple web server</b>: This enables you to add web pages to the ESP8266, and browse them from your computer or phone</li>
           <li><b>Setting up an advanced web server</b>: a more advanced server with a real file system that allows you to upload new files over Wi-Fi</li>
           <li><b>OTA - uploading programs over Wi-Fi</b>: You don't have to upload programs over USB, you can use Wi-Fi instead</li>
           <li><b>Wirelessly controlling your RGB lighting</b>: Change the color of your LED strips using your phone or computer</li>
           <li><b>Getting the time</b>: Connect to a time server using NTP and sync the ESP's clock</li>
           <li><b>Monitoring sensors</b>: log the temperature in your living room, save it in flash memory and show it in a fancy graph in your browser</li>
           <li><b>Getting email notifications</b>: Turn on a notification light when you've got unread emails</li>
           <li><b>Advanced features</b>: use DNS, captive portals, Wi-Fi connector libraries, OSC ...</li>
       </ol>
   </div>
   
   <p>
        This guide expects some basic knowledge of microcontrollers like the Arduino. If that's something you're not already familiar with, I'd recommend you to read my <a href="https://www.instructables.com/id/A-Beginners-Guide-to-Arduino/">Beginner's Guide to Arduino</a> first, it covers a lot of the basics that I won't go into in this article.
   </p>
   <p>
        I really want to focus on the ESP8266-specific things, like Wi-Fi and other network protocols, the ESP's hardware, software, IoT, etc ...
   </p>
   <h3>What is an ESP8266?</h3>
   <p>
        The ESP8266 is a System on a Chip (SoC), manufactured by the Chinese company <a href="https://espressif.com/en/">Espressif</a>. It consists of a Tensilica L106 32-bit <b>micro controller</b> unit (MCU) and a <b>Wi-Fi transceiver</b>. It has <b>11 GPIO pins</b>* (General Purpose Input/Output pins), and an <b>analog input</b> as well. This means that you can program it like any normal Arduino or other microcontroller. And on top of that, you get Wi-Fi communication, so you can use it to connect to your Wi-Fi network, connect to the Internet, host a web server with real web pages, let your smartphone connect to it, etc ... The possibilities are endless! It's no wonder that this chip has become the most popular IOT device available. 
   </p>
   
   <p>
        There are many different modules available, standalone modules like the <a href="http://en.ai-thinker.com/html/Products/WIFI_Module/ESP_01-14Series/">ESP-## series</a> by AI Thinker, or complete development boards like the <a href="http://nodemcu.com/index_en.html">NodeMCU DevKit</a> or the <a href="http://www.wemos.cc/">WeMos D1</a>. Different boards may have different pins broken out, have different Wi-Fi antennas, or a different amount of flash memory on board.
   </p>
   
   <p><small>(*) The ESP8266 chip itself has 17 GPIO pins, but 6 of these pins (6-11) are used for communication with the on-board flash memory chip.</small>
   </p>
   <h3>Programming</h3>
   <p>
        There are different ways to program the ESP8266, but I'll only cover the method using the Arduino IDE. This is really easy for beginners, and it's a very familiar environment if you've used Arduino boards before. 
   </p>
   <p>
        Just keep in mind that it's not limited to this option: there's also an official SDK available to program it in real C, this is very useful if you want to optimize your code or do some advanced tricks that aren't supported by the Arduino IDE. Another possibility is to flash it with a <a href="https://github.com/nodemcu/nodemcu-firmware">LUA</a> interpreter, so you can upload and run LUA scripts. Or maybe you're more familiar with Python? Then you should check out the <a href="http://micropython.org/download#esp8266">MicroPython firmware</a> to interpret MicroPython scripts. I'm sure there's other languages available as well, so just do a quick Google search and write your code in the language of your choice.
   </p>
   <h3>Requirements</h3>
   <p>
        You'll need a couple of things in order to follow this guide:
   </p>
   <div>
       <ul>
           <li>An ESP8266 board</li>
           <li>A computer that can run the Arduino IDE (Windows, Mac or Linux)</li>
           <li>A USB-to-Serial converter, it is very important that you use a <b>3.3V</b> model*</li>
           <li>A USB cable</li>
           <li>A 3.3V power supply or voltage regulator*</li>
           <li>A Wi-Fi network to connect to</li>
       </ul>
       <p><small>(*) Your board may already include these. More information can be found in the next chapter.</small>
       </p>
   </div>
    
<hr>
            
            
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You are what you read, even if you don't always remember it (641 pts)]]></title>
            <link>https://blog.jim-nielsen.com/2024/you-are-what-you-read/</link>
            <guid>40151952</guid>
            <pubDate>Thu, 25 Apr 2024 00:58:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jim-nielsen.com/2024/you-are-what-you-read/">https://blog.jim-nielsen.com/2024/you-are-what-you-read/</a>, See on <a href="https://news.ycombinator.com/item?id=40151952">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          <p>Here‚Äôs Dave Rupert (<a href="https://notes.jim-nielsen.com/#2024-03-22T1029">from my notes</a>):</p>
<blockquote>
<p>the goal of a book isn‚Äôt to get to the last page, it‚Äôs to expand your thinking.</p>
</blockquote>
<p>I have to constantly remind myself of this. Especially in an environment that prioritizes optimizing and maximizing personal productivity, where it seems if you can‚Äôt measure (let alone remember) the impact of a book in your life then it wasn‚Äôt worth reading.</p>
<p>I don‚Äôt believe that, but I never quite had the words for expressing why I don‚Äôt believe that. Dave‚Äôs articulation hit pretty close.</p>
<p>Then a couple days later my wife sent me this quote from Ralph Waldo Emerson:</p>
<blockquote>
<p>I cannot remember the books I've read any more than the meals I have eaten; even so, they have made me.</p>
</blockquote>
<p>YES!</p>
<p>Damn, great writers are sO gOOd wITh wORdz, amirite?</p>
<p>Emerson articulates with acute brevity something I couldn‚Äôt suss out in my own thoughts, let alone put into words. It makes me jealous.</p>
<p>Anyhow, I wanted to write this down to reinforce remembering it.</p>
<p>And in a similar vein for the online world: I cannot remember the blog posts I‚Äôve read any more than the meals I‚Äôve eaten; even so, they‚Äôve made me.</p>
<p>It‚Äôs a good reminder to be mindful of my content diet ‚Äî you are what you <del>eat</del> read, even if you don‚Äôt always remember it.</p>
<h2 id="update-2024-04-12">Update 2024-04-12</h2>
<p><a href="https://mastodon.online/@halas#.">@halas@mastodon.social</a> shared this story in response, which I really liked:</p>
<blockquote>
<p>At the university I had a professor who had a class with us in the first year and then in the second. At the beginning of the second year‚Äôs classes he asked us something from the material of previous year. When met with silence he nodded thoughtfully and said: ‚ÄúEducation is something you have even if you don't remember anything‚Äù</p>
</blockquote>
<p>I love stories that stick with people like that, e.g. ‚Äúsomething a teacher told me once...‚Äù</p>
<p><a href="https://blog.jim-nielsen.com/2024/immeasurable-impact/">Some impact is immeasurable</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airlines required to refund passengers for canceled, delayed flights (617 pts)]]></title>
            <link>https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733</link>
            <guid>40150639</guid>
            <pubDate>Wed, 24 Apr 2024 22:29:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733">https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733</a>, See on <a href="https://news.ycombinator.com/item?id=40150639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="prism-article-body"><p>Good news for airline travelers: the Department of Transportation on Wednesday announced it is rolling out new rules that will require airlines to automatically give cash refunds to passengers for canceled and significantly delayed flights.</p><p>"This is a big day for America's flying public," said Transportation Secretary Pete Buttigieg at a Wednesday morning news conference. Buttigieg said the new rules -- which require prompt refunds -- are the biggest expansion of passenger rights in the department's history.</p><p>Airlines can no longer decide how long a delay must be before a refund is issued. Under the new DOT rules, the delays covered would be more than three hours for domestic flights and more than six hours for international flights, the agency said.</p><p>This includes tickets purchased directly from airlines, travel agents and third-party sites such as Expedia and Travelocity.</p><p>The DOT rules lay out that passengers will be "entitled to a refund if their flight is canceled or significantly changed, and they do not accept alternative transportation or travel credits offered."</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: A person walks through the terminal as planes remain at gates at Ronald Reagan Washington National Airport in Arlington, Va., Wednesday, Jan. 11, 2023." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/2b5ef9d0-6caa-4597-893b-48a6a419bb31/airport-file-ap-jef-240424_1713963231114_hpMain.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>A person walks through the terminal as planes remain at gates at Ronald Reagan Washington National Airport in Arlington, Va., Wednesday, Jan. 11, 2023.</span></span></span></p><p><span>Patrick Semansky/AP, FILE</span></p></div></figcaption></figure></div><p>DOT will also require airlines to give cash refunds if your bags are lost and not delivered within 12 hours.</p><p>The refunds must be issued within seven days, according to the new DOT rules, and must be in cash unless the passenger chooses another form of compensation. Airlines can no longer issue refunds in forms of vouchers or credits when consumers are entitled to receive cash.</p><p>Airlines will have six months to comply with the new rules.</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: U.S. Secretary of Transportation Pete Buttigieg speaks at a press conference at the Reagan National Airport on April 24, 2024." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/22e4aad0-0b73-4e97-a784-ba8ba3bf64af/airport-abc-ml-240424_1713973025448_hpMain_16x9.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>U.S. Secretary of Transportation Pete Buttigieg speaks at a press conference at the Reagan National Airport on April 24, 2024.</span></span></span></p><p><span>ABC News, POOL</span></p></div></figcaption></figure></div><p>"Passengers deserve to get their money back when an airline owes them -- without headaches or haggling," Buttigieg said in a statement.</p><p>The DOT said it is also working on rules related to family seating fees, enhancing rights for wheelchair-traveling passengers for safe and dignified travel and mandating compensation and amenities if flights are delayed or canceled by airlines.</p><p>Buttigieg said the DOT is also protecting airline passengers from being surprised by hidden fees -- a move he estimates will have Americans billions of dollars every year.</p><section data-testid="prism-collection"><header><p><h2>Related Stories</h2></p></header></section><p><a data-testid="prism-linkbase" href="https://www.transportation.gov/briefing-room/biden-harris-administration-announces-final-rule-requiring-automatic-refunds-airline" target="_blank">The DOT rules</a> include that passengers will receive refunds for extra services paid for and not provided, such as Wi-Fi, seat selection or inflight entertainment.</p><p>The rules come after the agency <a data-testid="prism-linkbase" href="https://abcnews.go.com/International/southwest-airlines-fined-record-140-million-dot-2022/story?id=105733507" target="_blank">handed Southwest Airlines a record $140 million fine</a> for its <a data-testid="prism-linkbase" href="https://abcnews.go.com/Business/stranded-southwest-customers-details-exhaustive-efforts-home-amid/story?id=95848764" target="_blank">operational meltdown</a> during the 2022 holiday travel season.</p><p>Buttigieg said Southwest's fine sets a "new standard" for airlines and passenger rights.</p><p>"To be clear, we want the airline sector to thrive. It is why we put so much into helping them survive the pandemic and honestly it's why we're being so rigorous on passenger protection," he said.</p><p>Buttigieg reiterated that refund requirements are already the standard for airlines, but the new DOT rules hold the airlines to account and makes sure passengers get the "refunds that are owed to them."</p><p>"Airlines are not enthusiastic about us holding them to a higher standard," Buttigieg said, adding that he "knows they will be able to adapt to this."</p><p>Airlines for America, the trade association for the country's leading passenger and cargo airlines, told ABC News in a statement that its members "offer a range of options -- including fully refundable fares." Is said consumers are "given the choice of refundable ticket options with terms and conditions that best fit their needs at first search results."</p><p>The group said the 11 largest U.S. airlines issued $43 billion in customer refunds from 2020 through 2023 nearly $11 billion in refunds just last year.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bicycle use now exceeds car use in Paris (121 pts)]]></title>
            <link>https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html</link>
            <guid>40150545</guid>
            <pubDate>Wed, 24 Apr 2024 22:20:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html">https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html</a>, See on <a href="https://news.ycombinator.com/item?id=40150545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>It‚Äôs rush hour on Rue de Rivoli, one of the main arteries of the French capital. The bicycles pass one after another in quick succession, ringing their bell when a pedestrian crosses without looking. Five years ago, it was cars that monopolized this three-kilometer axis that runs in front of Paris City Hall and <a href="https://english.elpais.com/culture/2023-07-01/the-restitution-of-art-to-its-origins.html">the Louvre Museum</a>. Not anymore. Two-wheel transportation has prevailed, favored by a paradigm shift in urban mobility. The cycling revolution, promoted by local authorities, is beginning to bear fruit: according to a recent study by the Paris R√©gion Institute, a public agency, bicycles already surpass cars as a means of transportation in the interior of Paris, accounting for 11.2% of trips compared to 4.3%. A similar trend is seen in trips between the suburbs and the city center: 14% are made by bicycle and 11.8% by car.</p><p>Rue de Rivoli, with its two-way cycle lanes and its dedicated lane for buses and taxis, is perhaps one of the most emblematic examples of the change that the city has experienced in recent years. But it‚Äôs not the only one. The perpendicular Boulevard de S√©bastopol has become the route most frequented by cyclists, with figures that usually exceed 10,000 daily trips, according to the count kept by the association Paris en Selle.</p><p>When it is sunny, the density can be so high that traffic jams sometimes occur, and the narrowness of the lane causes friction between bikes, creating moments of tension. City officials led by Mayor Anne Hidalgo, a Socialist, have tried to remedy this situation by building other bike lanes on parallel streets.</p><p>From north to south and east to west, the map of the capital has been filled with infrastructure that gives the bicycle a privileged place. Paris has more than 1,000 kilometers (621 miles) of facilities adapted for cyclists, including more than 300 km (186 m) of bike lanes and 52 km (32 m) of provisional lanes, according to the latest available municipal data, from 2021. The rest are lanes shared with cars or lanes only marked with paint on the ground.</p><p>By 2026, local officials want the entire city to be suitable for two-wheel transportation. To this end, it has set aside $250 million, $100 million more than in Hidalgo‚Äôs first term. This summer‚Äôs Olympic Games will serve as an accelerator of this new ‚Äúbike plan,‚Äù with routes that will allow access to the Olympic venues.</p><p>But there is still some way to go. The Paris en Selle association warns that only 27% of the ‚Äúbike plan‚Äù has been carried out despite the fact that 62% of Hidalgo‚Äôs second term in office has already elapsed. The Deputy Mayor of Paris for Transportation, David Belliard, acknowledges that there are delays, but does not lose hope. Progress is noticeable.</p><p>In some thoroughfares, the number of bikes already surpasses vehicles. Between 2022 and 2023, the use of bike lanes doubled at peak times, according to data collected by the capital‚Äôs 128 counters. The goal is to create a network of cycling paths that run along the busiest metro lines, to unclog public transit and offer an equally fast and safe alternative for commuters.</p><p>The number of people who travel by bicycle has increased exponentially. V√©lib, the municipal urban bicycle rental service, has increased its fleet with 3,000 new bikes since March. Edm√©e Doroszlai, a 62-year-old Parisian, still remembers the first time she started riding on two wheels in the early 1980s. ‚ÄúIt was monstrous, almost impossible and very dangerous,‚Äù she says from the center of Paris, with her bike at her side.</p><p>‚ÄúThere is also a big change in how men behave when they see a woman on a bike,‚Äù she adds, alluding to the normalization of its use. The presence of adapted infrastructure, she confirms, has encouraged her to use it more, as have many families who travel on cycle paths with small children.</p><p>‚ÄúWe still have to go further,‚Äù Belliard insisted in an interview with BFMTV earlier this month. The councilor was reacting to the study by the Paris R√©gion Institute, the regional urban planning and environment agency, which indicated that 11.2% of trips in Paris were made by bike between 2022 and 2023, compared to 4.3% by car. The change in trend is clear. In 2021, two wheels still represented 5.6% of trips, while cars were 9%, according to Belliard.</p><figure><span><img alt="Notre Dame" decoding="auto" height="262" srcset="https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=1960 1960w" width="414" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=414" loading="lazy"></span><figcaption><span>Bike path on the banks of the Seine, in Paris.</span><span>Ciclistas y 'pic-nics' en la orilla sur del Sena, en Par√≠s (Jon Hicks)</span></figcaption></figure><p>In addition to surpassing the car as a means of travel within Paris, the research indicates that residents of the nearest suburbs also prefer to use the bike, with 14% of trips compared to 11.8% for cars. The figures are even better during rush hour, when 18.9% of trips are made by bike and only 6.6% by car. Travel on foot, however, continues to lead mobility within the municipality with 53%, followed by those made on public transit, with 30%. The study was carried out with 3,337 residents of the capital region who agreed to be fitted with a GPS tracker.</p><p>The bike gradually gained popularity during the public transist strike that paralyzed the capital in December 2019, in protest of <a href="https://english.elpais.com/international/2023-03-17/france-braces-for-more-unrest-after-macron-passes-pension-reform-by-decree.html">President Emmanuel Macron‚Äôs pension reform</a>. But it was also prominent <a href="https://english.elpais.com/society/2023-05-20/millions-ditched-cars-for-bikes-during-the-pandemic-these-cities-want-the-habit-to-stick.html">after the Covid confinement</a> in 2020, when the city tested the so-called ‚Äúcoronapistes,‚Äù temporary cycling lanes that progressively became permanent. Like Rivoli‚Äôs.</p><h3>Better connections with neighborhoods</h3><p>‚ÄúThe network is very good,‚Äù says Arnaud Faure, 31, co-owner of the Bivouac Cycles bicycle repair shop in Saint Ouen, a banlieue (suburb) in the north of the city. He has been in the French capital for two years and every day he travels 13 km (8 miles) to get to work and again the same to get back home. He says that almost all of his journey is along bike paths. But he cites two drawbacks. On one hand, the lack of safe parking, a determining factor for bicycle use. On the other hand, the fact that ‚Äújust like in big cities, traffic is dense and can sometimes be dangerous.‚Äù</p><p>In 12 years, car traffic has decreased by 40% in Paris, according to City Hall. ‚ÄúBut these rapid changes in habits have been accompanied by tension‚Äù in the streets, the mayor has admitted. ‚ÄúIt takes time for everyone to find their place and feel safe,‚Äù she added, following road regulations that seek to raise awareness about the shared use of public space. Last summer, posters appeared throughout the city reminding everyone that pedestrians have the priority and that the speed limit for cars is 30 km/h (18 mph).</p><p>The city‚Äôs plan includes increasing the number of parking spaces for bicycles. The goal is to build more than 130,000 new spots. ‚ÄúParking at train stations must be developed on a massive scale,‚Äù stresses Aymeric Cotard, 29, a member of the association Mieux se d√©placer √† bicyclette [Better to get around by bike]. One of the large projects that should be completed this year, with 1,200 spaces, is located just behind the Gare du Nord, one of the busiest stations in France. For Cotard, however, it will be insufficient. In <a href="https://english.elpais.com/international/2023-02-27/we-didnt-know-if-they-were-being-taken-to-another-country-where-do-stolen-dutch-bikes-go.html">the Dutch city</a> of Utrecht, the station has 12,500 spaces for bikes.</p><p>The idea is that people who live in the suburbs and take the train daily to work will also use the bicycle once they arrive in Paris. It is one of the main challenges of the coming years, along with facilitating continuous journeys between the capital and its suburbs. ‚ÄúThis requires the banlieue cities to do their job and the city of Paris to also improve its entrances, which are inhospitable and unpleasant by bike,‚Äù warns Cotard. In addition, it is necessary to provide infrastructure for a flow of cyclists that will be even greater in the future.</p><p>The process takes time and has encountered some opposition. But the morphology of the city is changing, adapting to the bike. And, with it, its resilience to the effects of climate change.</p><p><i>Sign up for </i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i><u>our weekly newsletter</u></i></a> <i>to get more English-language news coverage from EL PA√çS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magic Numbers (154 pts)]]></title>
            <link>https://exple.tive.org/blarg/2024/04/24/magic-numbers/</link>
            <guid>40149446</guid>
            <pubDate>Wed, 24 Apr 2024 20:50:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://exple.tive.org/blarg/2024/04/24/magic-numbers/">https://exple.tive.org/blarg/2024/04/24/magic-numbers/</a>, See on <a href="https://news.ycombinator.com/item?id=40149446">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-6105" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

	<header>

		
		

	</header>

	<section itemprop="articleBody">

		<p><strong>April 24, 2024</strong></p>

		<p>The <a href="https://en.wikipedia.org/wiki/Maximum_transmission_unit">Maximum Transmission Unit</a> ‚Äì MTU ‚Äì of an <a href="https://en.wikipedia.org/wiki/Ethernet">Ethernet</a> frame is 1500 bytes.</p>
<p>1500 bytes is a bit out there as numbers go, or at least it seems that way if you touch computers for a living. It‚Äôs not a power of two or anywhere close, it‚Äôs <em>suspiciously</em> base-ten-round, and computers don‚Äôt care all that much about base ten, so how did we get here? </p>
<p>Well, today I learned that the size of an Ethernet header ‚Äì 36 bytes ‚Äì comes from the fact that MTU plus Ethernet header is 1536 bytes, which is 12288 bits, which takes 2^12 microseconds to transmit at 3Mb/second, because the <a href="https://en.wikipedia.org/wiki/Xerox_Alto">Xerox Alto</a> computer for which Ethernet was invented had a internal data path that ran at 3Mhz, so the interface could <em>just</em> write the bits into the Alto‚Äôs memory at the precise speed at which they arrived, saving the very-expensive-then cost of extra silicon for an interface or any buffering hardware. </p>
<p>Now, ‚Äúwe need to pick just the right magic number <em>here</em> so we can take data straight off the wire and blow it directly into the memory of this specific machine over <em>there</em>‚Äù is to any modern sensibilities insane. It‚Äôs obviously, dangerously insane. But back when the idea of network security didn‚Äôt exist because computers barely existed and networks mostly didn‚Äôt exist and unvetted and unsanctioned access to those networks definitely didn‚Äôt exist, I bet it seemed like a very reasonable tradeoff.</p>
<p>It really is amazing how many of the things we sort of ambiently accept as standards today, if we even realize we‚Äôre making that decision at all, are what they are only because some now-esoteric property of the now-esoteric hardware on which the tech was first invented let the inventors save a few bucks.</p>

		
	</section> <!-- end article section -->

	

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM to Acquire HashiCorp, Inc for $6.4 billion (354 pts)]]></title>
            <link>https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform</link>
            <guid>40149136</guid>
            <pubDate>Wed, 24 Apr 2024 20:24:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform">https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform</a>, See on <a href="https://news.ycombinator.com/item?id=40149136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wd_move_content_up">

<p>$6.4 billion acquisition adds suite of leading hybrid and multi-cloud lifecycle management products to help clients grappling with today's AI-driven application growth and complexity</p><p>HashiCorp's capabilities to drive significant synergies across multiple strategic growth areas for IBM, including Red Hat, watsonx, data security, IT automation and Consulting</p><p>As a part of IBM, HashiCorp is expected to accelerate innovation and enhance its go-to-market, growth and monetization initiatives</p><p>Transaction expected to be accretive to Adjusted EBITDA within the first full year, post close, and free cash flow in year two</p>
<p>Apr 24, 2024</p>

			
		
</div><div wd_resize="formatNews" wd_print_url="https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform?printable=1"><p>,  /<a href="http://www.prnewswire.com/" target="_blank">PRNewswire</a>/ -- IBM (NYSE: <a href="http://www.ibm.com/investor" rel="nofollow" target="_blank">IBM</a>) and HashiCorp Inc. (NASDAQ: HCP), a leading multi-cloud infrastructure automation company, today announced they have entered into a definitive agreement under which IBM will acquire HashiCorp for <span>$35</span> per share in cash, representing an enterprise value of <span>$6.4 billion</span>. HashiCorp's suite of products provides enterprises with extensive Infrastructure Lifecycle Management and Security Lifecycle Management capabilities to enable organizations to automate their hybrid and multi-cloud environments. Today's announcement is a continuation of IBM's deep focus and investment in hybrid cloud and AI, the two most transformational technologies for clients today.</p>

<p><a href="https://mma.prnewswire.com/media/2319830/IBM_LOGO_1.html" rel="nofollow" target="_blank"><img alt="IBM Corporation logo. (PRNewsfoto/IBM Corporation)" src="https://mma.prnewswire.com/media/2319830/IBM_LOGO_1.jpg" title="IBM Corporation logo. (PRNewsfoto/IBM Corporation)"> </a></p>

<p>"Enterprise clients are wrestling with an unprecedented expansion in infrastructure and applications across public and private clouds, as well as on-prem environments. The global excitement surrounding generative AI has exacerbated these challenges and CIOs and developers are up against dramatic complexity in their tech strategies," said <span>Arvind Krishna</span>, IBM chairman and chief executive officer. "HashiCorp has a proven track record of enabling clients to manage the complexity of today's infrastructure and application sprawl. Combining IBM's portfolio and expertise with HashiCorp's capabilities and talent will create a comprehensive hybrid cloud platform designed for the AI era."</p>

<p>The rise of cloud-native workloads and associated applications is driving a radical expansion in the number of cloud workloads enterprises are managing. In addition, generative AI deployment continues to grow alongside traditional workloads. As a result, developers are working with increasingly heterogeneous, dynamic, and complex infrastructure strategies. This represents a massive challenge for technology professionals.</p>

<p>HashiCorp's capabilities enable enterprises to use automation to deliver lifecycle management for infrastructure and security, providing a system of record for the critical workflows needed for hybrid and multi-cloud environments. HashiCorp's Terraform is the industry standard for infrastructure provisioning in these environments. HashiCorp's offerings help clients take a cloud-agnostic, and highly interoperable approach to multi-cloud management, and complement IBM's commitment to industry collaboration (including deep and expanding partnerships with hyperscale cloud service providers), developer communities, and open-source hybrid cloud and AI innovation.</p>

<p>"Our strategy at its core is about enabling companies to innovate in the cloud, while providing a consistent approach to managing cloud at scale. The need for effective management and automation is critical with the rise of multi-cloud and hybrid cloud, which is being accelerated by today's AI revolution," said <span>Armon Dadgar</span>, HashiCorp co-founder and chief technology officer. "I'm incredibly excited by today's news and to be joining IBM to accelerate HashiCorp's mission and expand access to our products to an even broader set of developers and enterprises."</p>

<p>"Today is an exciting day for our dedicated teams across the world as well as the developer communities we serve," said <span>Dave McJannet</span>, HashiCorp chief executive officer. "IBM's leadership in hybrid cloud along with its rich history of innovation, make it the ideal home for HashiCorp as we enter the next phase of our growth journey. I'm proud of the work we've done as a standalone company, I am excited to be able to help our customers further, and I look forward to the future of HashiCorp as part of IBM."</p>

<p><b>Transaction Rationale</b></p>

<ul type="disc">
	<li><b>Strong Strategic Fit ‚Äì </b>The acquisition of HashiCorp by IBM creates a comprehensive end-to-end hybrid cloud platform built for AI-driven complexity. The combination of each company's portfolio and talent will deliver clients extensive application, infrastructure and security lifecycle management capabilities</li>
	<li><b>Accelerates growth in key focus areas ‚Äì </b>Upon close, HashiCorp is expected to drive significant synergies for IBM, including across multiple strategic growth areas like Red Hat, watsonx, data security, IT automation and Consulting. For example, the powerful combination of Red Hat's Ansible Automation Platform's configuration management and Terraform's automation will simplify provisioning and configuration of applications across hybrid cloud environments. The two companies also anticipate an acceleration of HashiCorp's growth initiatives by leveraging IBM's world-class go-to-market strategy, scale, and reach, operating in more than 175 countries across the globe</li>
	<li><b>Expands Total Addressable Market (TAM) ‚Äì </b>The acquisition will create the opportunity to deliver more comprehensive hybrid and multi-cloud offerings to enterprise clients. HashiCorp's offerings, combined with IBM and Red Hat, will give clients a platform to automate the deployment and orchestration of workloads across evolving infrastructure including hyperscale cloud service providers, private clouds and on-prem environments. This will enhance IBM's ability to address the total cloud opportunity, which according to IDC had a TAM of <span>$1.1 trillion</span> in 2023, with a compound annual growth rate in the high teens through 2027.<sup>1</sup></li>
	<li><b>Attractive Financial Opportunity ‚Äì </b>The transaction will accelerate IBM's growth profile over time driven by go-to-market and product synergies. This growth combined with operating efficiencies, is expected to achieve substantial near-term margin expansion for the acquired business. It is anticipated that the transaction will be accretive to Adjusted EBITDA within the first full year, post close, and free cash flow in year two.</li>
</ul>

<p>HashiCorp boasts a roster of more than 4,400 clients, including Bloomberg, Comcast, Deutsche Bank, GitHub, J.P Morgan Chase, Starbucks and Vodafone. HashiCorp's offerings have widescale adoption in the developer community and are used by 85% of the Fortune 500. Their community products across infrastructure and security were downloaded more than 500 million times in HashiCorp's FY2024 and include:</p>

<ul type="disc">
	<li><b>Terraform</b> ‚Äì provides organizations with a single workflow to provision their cloud, private datacenter, and SaaS infrastructure and continuously manage infrastructure throughout its lifecycle</li>
	<li><b>Vault</b> ‚Äì provides organizations with identity-based security to automatically authenticate and authorize access to secrets and other sensitive data</li>
	<li><b>Additional products</b> ‚Äì <i>Boundary</i> for secure remote access;<i> Consul</i> for service-based networking; <i>Nomad</i> for workload orchestration; <i>Packer</i> for building and managing images as code; and <i>Waypoint</i> internal developer platform</li>
</ul>

<p><b>Transaction Details</b></p>

<p>Under the terms of the agreement, IBM will acquire HashiCorp for <span>$35</span> per share in cash, or <span>$6.4 billion</span> enterprise value, net of cash. HashiCorp will be acquired with available cash on hand.</p>

<p>The boards of directors of IBM and HashiCorp have both approved the transaction. The acquisition is subject to approval by HashiCorp shareholders, regulatory approvals and other customary closing conditions.</p>

<p>The Company's largest shareholders and investors, who collectively hold approximately 43% of the voting power of&nbsp;HashiCorp's outstanding common stock, entered into a voting agreement with IBM pursuant to which each has agreed to vote all of their common shares in favor of the transaction and against any alternative transactions.</p>

<p>The transaction is expected to close by the end of 2024.</p>

<p>____________________<br>
<sup>1</sup> The total cloud opportunity is the sum of the cloud-directed spends across Hardware, IT services and SW for Private and Public cloud implementation, sourced from IDC's Worldwide Black Book Live Edition, <span>March 2024</span> (V1 2024)</p>

<p><b>Conference Call Details</b></p>

<p>IBM's regular quarterly earnings conference call is scheduled to begin at <span>5:00 p.m. ET</span>, today. The Webcast may be accessed <a href="https://www.ibm.com/investor/events/earnings-1q24" rel="nofollow" target="_blank">here</a>. Presentation charts will be available shortly before the Webcast.</p>

<p><b>About IBM</b></p>

<p>IBM is a leading provider of global hybrid cloud and AI, and consulting expertise. We help clients in more than 175 countries capitalize on insights from their data, streamline business processes, reduce costs and gain the competitive edge in their industries. Thousands of government and corporate entities in critical infrastructure areas such as financial services, telecommunications and healthcare rely on IBM's hybrid cloud platform and Red Hat OpenShift to affect their digital transformations quickly, efficiently and securely. IBM's breakthrough innovations in AI, quantum computing, industry-specific cloud solutions and consulting deliver open and flexible options to our clients. All of this is backed by IBM's legendary commitment to trust, transparency, responsibility, inclusivity and service. Visit&nbsp;<a href="http://www.ibm.com/" rel="nofollow" target="_blank">www.ibm.com</a>&nbsp;for more information.&nbsp;</p>

<p><b>About HashiCorp</b></p>

<p>HashiCorp&nbsp;is The Infrastructure Cloud‚Ñ¢ company, helping organizations automate multi-cloud and hybrid environments with Infrastructure Lifecycle Management and Security Lifecycle Management. HashiCorp&nbsp;offers The Infrastructure Cloud on the HashiCorp&nbsp;Cloud Platform (HCP) for managed cloud services, as well as self-hosted enterprise offerings and community source-available products. The company is headquartered in <span>San Francisco, California</span>. For more information, visit&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=http-3A__hashicorp.com&amp;d=DwMFaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=uOTnwadDTxZ2XD2uC6bDCFPG-9K-Oq5GBVfeuYs3n7-_Z1xbsLo_2585JrS2L788&amp;s=RF6C-_LsY0GUJ3MnM2K_hfDsjYfnI-WCPo4lNlnulgE&amp;e=" rel="nofollow" target="_blank">HashiCorp.com</a>.</p>

<p><b>Press Contacts:</b></p>

<p>IBM:<br>
<span>Tim Davidson</span>, 914-844-7847<br>
<a href="mailto:tfdavids@us.ibm.com" rel="nofollow" target="_blank">tfdavids@us.ibm.com</a></p>

<p>HashiCorp:<br>
<span>Matthew Sherman</span> / <span>Jed Repko</span> / <span>Haley Salas</span> / <span>Joycelyn Barnett</span><br>
<span>Joele Frank</span>, Wilkinson Brimmer Katcher<br>
212-355-4449</p>



<p><i><b>Additional Information and Where to Find It</b></i></p>

<p><i>HashiCorp, Inc. ("HashiCorp"), the members of HashiCorp's board of directors and certain of HashiCorp's executive officers are participants in the solicitation of proxies from stockholders in connection with the pending acquisition of HashiCorp (the "Transaction"). HashiCorp plans to file a proxy statement (the "Transaction Proxy Statement") with the Securities and Exchange Commission (the "SEC") in connection with the solicitation of proxies to approve the Transaction. <span>David McJannet</span>, <span>Armon Dadgar</span>, <span>Susan St. Ledger</span>, <span>Todd Ford</span>, <span>David Henshall</span>, <span>Glenn Solomon</span> and <span>Sigal Zarmi</span>, all of whom are members of HashiCorp's board of directors, and <span>Navam Welihinda</span>, HashiCorp's chief financial officer, are participants in HashiCorp's solicitation. Information regarding such participants, including their direct or indirect interests, by security holdings or otherwise, will be included in the Transaction Proxy Statement and other relevant documents to be filed with the SEC in connection with the Transaction. Additional information about such participants is available under the captions "Board of Directors and Corporate Governance," "Executive Officers" and "Security Ownership of Certain Beneficial Owners and Management" in HashiCorp's definitive proxy statement in connection with its 2023 Annual Meeting of Stockholders (the "2023 Proxy Statement"), which was filed with the SEC on <span>May 17, 2023</span> (and is available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_ix-3Fdoc-3D_Archives_edgar_data_1720671_000114036123025250_ny20008192x1-5Fdef14a.htm&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=DAxP0uH2PZLVIrXRiK8JS2ywGdYGNx-kvMHxAEWkP_4&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/ix?doc=/Archives/edgar/data/1720671/000114036123025250/ny20008192x1_def14a.htm</a>). To the extent that holdings of HashiCorp's securities have changed since the amounts printed in the 2023 Proxy Statement, such changes have been or will be reflected on Statements of Change in Ownership on Form 4 filed with the SEC (which are available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_cgi-2Dbin_browse-2Dedgar-3Faction-3Dgetcompany-26CIK-3D0001720671-26type-3D-26dateb-3D-26owner-3Donly-26count-3D40-26search-5Ftext-3D&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=bqavEZgqjNge6kAvbmk0zLhMXTAYmIjA5rzwhQaJDd8&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&amp;CIK=0001720671&amp;type=&amp;dateb=&amp;owner=only&amp;count=40&amp;search_text=</a>). Information regarding HashiCorp's transactions with related persons is set forth under the caption "Related Person Transactions" in the 2023 Proxy Statement. Certain illustrative information regarding the payments to that may be owed, and the circumstances in which they may be owed, to HashiCorp's named executive officers in a change of control of HashiCorp is set forth under the caption "Executive Compensation‚ÄîPotential Payments upon Termination or Change in Control" in the 2023 Proxy Statement. With respect to Ms. St. Ledger, certain of such illustrative information is contained in the Current Report on Form 8-K filed with the SEC on <span>June 7, 2023</span> (and is available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_ix-3Fdoc-3D_Archives_edgar_data_1720671_000162828023021270_hcp-2D20230607.htm&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=4QQvgxl7VrRT-9dgZy45Vw0gBhmWz7KH8fzaGjGwkIk&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/ix?doc=/Archives/edgar/data/1720671/000162828023021270/hcp-20230607.htm</a>).&nbsp;Promptly after filing the definitive Transaction Proxy Statement with the SEC, HashiCorp will mail the definitive Transaction Proxy Statement and a WHITE proxy card to each stockholder entitled to vote at the special meeting to consider the Transaction. STOCKHOLDERS ARE URGED TO READ THE TRANSACTION PROXY STATEMENT (INCLUDING ANY AMENDMENTS OR SUPPLEMENTS THERETO) AND ANY OTHER RELEVANT DOCUMENTS THAT HASHICORP WILL FILE WITH THE SEC WHEN THEY BECOME AVAILABLE BECAUSE THEY WILL CONTAIN IMPORTANT INFORMATION. Stockholders may obtain, free of charge, the preliminary and definitive versions of the Transaction Proxy Statement, any amendments or supplements thereto, and any other relevant documents filed by HashiCorp with the SEC in connection with the Transaction at the SEC's website (<a href="https://urldefense.proofpoint.com/v2/url?u=http-3A__www.sec.gov&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=97Mk6TtDEGohehH043KUy50rAX9jXPHlNPxdtGwcYPc&amp;e=" rel="nofollow" target="_blank">http://www.sec.gov</a>). Copies of HashiCorp's definitive Transaction Proxy Statement, any amendments or supplements thereto, and any other relevant documents filed by HashiCorp with the SEC in connection with the Transaction will also be available, free of charge, at HashiCorp's investor relations website (<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__ir.hashicorp.com_&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=zgti-5JjrLH_7Ja9Wdc81ipMwWNQ-4K0YQu2LW5qZnw&amp;e=" rel="nofollow" target="_blank">https://ir.hashicorp.com/</a>), or by emailing HashiCorp's investor relations department (<a href="mailto:ir@hashicorp.com" rel="nofollow" target="_blank">ir@hashicorp.com</a>).</i></p>

<p><i><b>Forward-Looking Statements</b></i></p>

<p><i>Certain statements contained in this communication may be characterized as forward-looking under the Private Securities Litigation Reform Act of 1995. These statements involve a number of risks, uncertainties and other factors that could cause actual results to differ materially.</i></p>

<p><i>Statements in this communication regarding IBM and HashiCorp that are forward-looking may include statements regarding: (i) the Transaction; (ii) the expected timing of the closing of the Transaction; (iii) considerations taken into account in approving and entering into the Transaction; (iv) the anticipated benefits to, or impact of, the Transaction on IBM's and HashiCorp's businesses; and (v) expectations for IBM and HashiCorp following the closing of the Transaction. There can be no assurance that the Transaction will be consummated.</i></p>

<p><i>Risks and uncertainties that could cause actual results to differ materially from those indicated in the forward-looking statements, in addition to those identified above, include: (i) the possibility that the conditions to the closing of the Transaction are not satisfied, including the risk that required approvals from HashiCorp's stockholders for the Transaction or required regulatory approvals to consummate the Transaction are not obtained, on a timely basis or at all; (ii) the occurrence of any event, change or other circumstance that could give rise to a right to terminate the Transaction, including in circumstances requiring HashiCorp to pay a termination fee; (iii) possible disruption related to the Transaction to IBM's and HashiCorp's current plans, operations and business relationships, including through the loss of customers and employees; (iv) the amount of the costs, fees, expenses and other charges incurred by IBM and HashiCorp related to the Transaction; (v) the risk that IBM's or HashiCorp's stock price may fluctuate during the pendency of the Transaction and may decline if the Transaction is not completed; (vi) the diversion of IBM and HashiCorp management's time and attention from ongoing business operations and opportunities; (vii) the response of competitors and other market participants to the Transaction; (viii) potential litigation relating to the Transaction; (ix) uncertainty as to timing of completion of the Transaction and the ability of each party to consummate the Transaction; and (x) other risks and uncertainties detailed in the periodic reports that IBM and HashiCorp filed with the SEC, including IBM's and HashiCorp's respective Annual Reports on Form 10-K.&nbsp; All forward-looking statements in this communication are based on information available to IBM and HashiCorp as of the date of this communication, and, except as required by law, IBM and HashiCorp do not assume any obligation to update the forward-looking statements provided to reflect events that occur or circumstances that exist after the date on which they were made.</i></p>

<p>SOURCE IBM</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM to buy HashiCorp in $6.4B deal (494 pts)]]></title>
            <link>https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/</link>
            <guid>40149095</guid>
            <pubDate>Wed, 24 Apr 2024 20:21:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/">https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/</a>, See on <a href="https://news.ycombinator.com/item?id=40149095">Hacker News</a></p>
Couldn't get https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Eric Schmidt-backed Augment, a GitHub Copilot rival, launches out of stealth (129 pts)]]></title>
            <link>https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</link>
            <guid>40149071</guid>
            <pubDate>Wed, 24 Apr 2024 20:19:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/">https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</a>, See on <a href="https://news.ycombinator.com/item?id=40149071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">AI is supercharging coding ‚Äî and developers are embracing it.</p>
<p>In a recent StackOverflow poll, 44% of software engineers said that they <a href="https://stackoverflow.blog/2023/06/14/hype-or-not-developers-have-something-to-say-about-ai/" target="_blank" rel="noopener">use AI tools as part of their development processes</a> now and 26% plan to soon. Gartner <a href="https://www.gartner.com/en/newsroom/press-releases/2024-04-11-gartner-says-75-percent-of-enterprise-software-engineers-will-use-ai-code-assistants-by-2028" target="_blank" rel="noopener">estimates</a> that over half of organizations are currently piloting or have already deployed AI-driven coding assistants, and that 75% of developers will use coding assistants in some form by 2028.</p>
<p>Ex-Microsoft software developer Igor Ostrovsky <span>believes that soon, there won‚Äôt be a developer who </span><em>doesn‚Äô</em><em>t&nbsp;</em><span>use AI in their workflows.&nbsp;</span>‚ÄúSoftware engineering remains a difficult and all-too-often tedious and frustrating job, particularly at scale,‚Äù he told TechCrunch. ‚ÄúAI can improve software quality, team productivity and help restore the joy of programming.‚Äù</p>
<p>So Ostrovsky <span>decided to build the AI-powered coding platform that he himself would want to use.</span></p>
<p>That platform is <a href="https://www.augmentcode.com/" target="_blank" rel="noopener">Augment</a>, and on Wednesday it <a href="https://www.augmentcode.com/blog/augment-inc-raises-227-million">emerged</a> from stealth with $252 million in funding at a near-unicorn ($977 million) post-money valuation. With investments from former Google CEO Eric Schmidt and VCs including Index Ventures, Sutter Hill Ventures, Lightspeed Venture Partners, Innovation Endeavors and Meritech Capital, Augment aims to shake up the still-nascent market for generative AI coding technologies.</p>
<p>‚ÄúMost companies are dissatisfied with the programs they produce and consume; software is too often fragile, complex and expensive to maintain with development teams bogged down with long backlogs for feature requests, bug fixes, security patches, integration requests, migrations and upgrades,‚Äù Ostrovsky said. ‚ÄúAugment has both the best team and recipe for empowering programmers and their organizations to deliver high-quality software quicker.‚Äù</p>
<p>Ostrovsky spent nearly seven years at Microsoft before joining Pure Storage, a startup developing flash data storage hardware and software products, as a founding engineer. While at Microsoft, Ostrovsky worked on components of Midori, a next-generation operating system the company never released but whose concepts have made their way into other Microsoft projects over the last decade.</p>
<p>In 2022, Ostrovsky and Guy Gur-Ari, previously an AI research scientist at Google, teamed up to create Augment‚Äôs MVP. To fill out the startup‚Äôs executive ranks, Ostrovsky and Gur-Ari brought on Scott Dietzen, ex-CEO of Pure Storage, and Dion Almaer, formerly a Google engineering director and a VP of engineering at Shopify.</p>
<p>Augment remains a strangely hush-hush operation.</p>
<p>In our conversation, Ostrovsky wasn‚Äôt willing to say much about the user experience or even the generative AI models driving Augment‚Äôs features (whatever they may be) ‚Äî save that Augment is using fine-tuned ‚Äúindustry-leading‚Äù open models of some sort.</p>
<p>He did say how Augment plans to make money: standard software-as-a-service subscriptions. Pricing and other details will be revealed later this year, Ostrovsky added, closer to Augment‚Äôs planned GA release.</p>
<p>‚ÄúOur funding provides many years of runway to continue to build what we believe to be the best team in enterprise AI,‚Äù he said. ‚ÄúWe‚Äôre accelerating product development and building out Augment‚Äôs product, engineering and go-to-market functions as the company gears up for rapid growth.‚Äù</p>
<p>Rapid growth is perhaps the best shot Augment has at making waves in an increasingly cutthroat industry.</p>
<p>Practically every tech giant offers its own version of an AI coding assistant. Microsoft has GitHub Copilot, which is by far the firmest entrenched with over 1.3 million paying individual and 50,000 enterprise customers as of February. Amazon has AWS‚Äô CodeWhisperer. And Google has Gemini Code Assist, recently rebranded from Duet AI for Developers.</p>
<p>Elsewhere, there‚Äôs a torrent of coding assistant startups: <a href="https://techcrunch.com/2023/02/06/magic-dev-code-generating-startup-raises-23m/" data-mrf-link="https://techcrunch.com/2023/02/06/magic-dev-code-generating-startup-raises-23m/">Magic</a><span>,&nbsp;</span><a href="https://techcrunch.com/2023/11/08/code-generating-ai-platform-tabnine-nabs-25m-investment/" data-mrf-link="https://techcrunch.com/2023/11/08/code-generating-ai-platform-tabnine-nabs-25m-investment/">Tabnine</a><span>,&nbsp;</span><a href="https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/" data-mrf-link="https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/">Codegen</a>, <a href="https://techcrunch.com/2024/01/29/refact-launches-to-make-code-generating-ai-more-appealing-to-enterprises/">Refact</a>, <a href="https://techcrunch.com/2023/10/10/tabbyml-github-copilot-alternative-raises-3-2-million/">TabbyML</a>, <a href="https://techcrunch.com/2023/11/02/sweep-aims-to-automate-basic-dev-tasks-using-large-language-models/">Sweep</a>,<span>&nbsp;</span><a href="https://techcrunch.com/2023/12/12/laredo-wants-to-use-gen-ai-to-automate-dev-work/" data-mrf-link="https://techcrunch.com/2023/12/12/laredo-wants-to-use-gen-ai-to-automate-dev-work/">Laredo</a> and <span>Cognition (which <a href="https://www.theinformation.com/articles/six-month-old-ai-coding-startup-valued-at-2-billion-by-founders-fund?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cognition%2FFou&amp;utm_content=3915&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=2713" target="_blank" rel="noopener">reportedly</a> just raised $175 million), </span>to name a few. <span><a href="https://techcrunch.com/2023/06/21/harness-releases-generative-ai-assistant-to-help-ease-developer-workloads/">Harness</a></span> and <span>JetBrains, which developed the Kotlin programming language, recently </span><a href="https://techcrunch.com/2023/12/07/as-a-new-ai-driven-coding-assistant-is-launched-the-battle-for-ai-mindshare-moves-to-developers/">released</a><span> their <a href="https://techcrunch.com/2023/12/07/as-a-new-ai-driven-coding-assistant-is-launched-the-battle-for-ai-mindshare-moves-to-developers/">own</a>. So did&nbsp;<a href="https://techcrunch.com/2024/03/20/sentrys-ai-powered-autofix-helps-developers-quickly-debug-and-fix-their-production-code/">Sentry</a> (albeit with more of a cybersecurity bent).&nbsp;</span></p>
<p>Can they all ‚Äî plus Augment now ‚Äî do business harmoniously together? It seems unlikely. Eye-watering compute costs alone make the AI coding assistant business a challenging one to maintain. Overruns related to training and serving models forced generative AI coding startup <a href="https://techcrunch.com/2022/12/10/with-kites-demise-can-generative-ai-for-code-succeed/" data-mrf-link="https://techcrunch.com/2022/12/10/with-kites-demise-can-generative-ai-for-code-succeed/">Kite</a> to shut down in December 2022. <a href="https://aibusiness.com/nlp/github-copilot-loses-20-a-month-per-user" target="_blank" rel="noopener">Even Copilot loses money</a>, to the tune of around $20 to $80 a month per user, according to The Wall Street Journal.</p>
<p>Ostrovsky implies that there‚Äôs momentum behind Augment already; he claims that ‚Äúh<span>undreds‚Äù of software developers across ‚Äúdozens‚Äù of companies, including payment startup <a href="https://techcrunch.com/2023/06/06/eric-schmidt-keeta-cross-border-payments-fintech/">Keeta</a> (which is also Eric Schmidt-backed), are using Augment in early access. But will the uptake sustain? That‚Äôs the million-dollar question, indeed.</span></p>
<p>I also wonder if Augment has made any steps toward solving the technical setbacks plaguing code-generating AI, particularly around vulnerabilities.</p>
<p>An analysis by GitClear, the developer of the code analytics tool of the same name, <a href="https://visualstudiomagazine.com/Articles/2024/01/25/copilot-research.aspx">found</a> that coding assistants are resulting in more mistaken code being pushed to codebases, creating headaches for software maintainers. Security researchers have warned that generative coding tools can <a href="https://www.techtarget.com/searchsecurity/news/366571117/GitHub-Copilot-replicating-vulnerabilities-insecure-code" target="_blank" rel="noopener">amplify</a> existing bugs and exploits in projects. And Stanford researchers have <a href="https://www.theregister.com/2022/12/21/ai_assistants_bad_code/" target="_blank" rel="noopener">found</a> that developers who accept code recommendations from AI assistants tend to produce less secure code.</p>
<p>Then there‚Äôs copyright to worry about.</p>
<p>Augment‚Äôs models were undoubtedly trained on publicly available data, like all generative AI models ‚Äî some of which may‚Äôve been copyrighted or under a restrictive license. Some vendors have argued that <a href="https://www.copyright.gov/fair-use/#:~:text=Fair%20use%20is%20a%20legal,protected%20works%20in%20certain%20circumstances." target="_blank" rel="noopener" data-mrf-link="https://www.copyright.gov/fair-use/#:~:text=Fair%20use%20is%20a%20legal,protected%20works%20in%20certain%20circumstances.">fair use doctrine</a> shields them from copyright claims while at the same time rolling out tools to mitigate potential infringement. But that hasn‚Äôt stopped coders from <a href="https://www.finnegan.com/en/insights/articles/insights-from-the-pending-copilot-class-action-lawsuit.html" target="_blank" rel="noopener" data-mrf-link="https://www.finnegan.com/en/insights/articles/insights-from-the-pending-copilot-class-action-lawsuit.html">filing</a> class action lawsuits over what they allege are open licensing and IP violations.</p>
<p>To all this, Ostrovsky says: ‚ÄúCurrent AI coding assistants don‚Äôt adequately understand the programmer‚Äôs intent, improve software quality nor facilitate team productivity, and they don‚Äôt properly protect intellectual property. Augment‚Äôs engineering team boasts deep AI and systems expertise. We‚Äôre poised to bring AI coding assistance innovations to developers and software teams.‚Äù</p>
<p>Augment, which is based in Palo Alto, has around 50 employees; Ostrovsky expects that number to double by the end of the year.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Reports First Quarter 2024 Results (125 pts)]]></title>
            <link>https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx</link>
            <guid>40148998</guid>
            <pubDate>Wed, 24 Apr 2024 20:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx">https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=40148998">Hacker News</a></p>
Couldn't get https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Rise and Fall of the LAN Party (207 pts)]]></title>
            <link>https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom</link>
            <guid>40148833</guid>
            <pubDate>Wed, 24 Apr 2024 19:56:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom">https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom</a>, See on <a href="https://news.ycombinator.com/item?id=40148833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today it is trivially easy to play games on a computer with one‚Äôs friends over the internet. I can log into a game like <em>Fortnite</em>, party up with a squad and chat in either the game‚Äôs built-in voice protocol or use another service like Discord, and be in a game within minutes. I can do this from my computer, a game console, or even my phone. But before the wide availability of high-speed internet, things were more complicated.</p><hr><p><em>The following is excerpted from the book </em>LAN Party, <em>by Merritt K.&nbsp;<a rel="noreferrer noopener" href="https://readonlymemory.com/shop/book/lan-party/" target="_blank">The book is available for purchase now.</a></em></p><hr><p>In the 1990s and early 2000s, three-dimensional graphics in videogames were becoming more and more complex. Titles like 1998‚Äôs <em>Half-Life</em> pushed games in more cinematic directions, with lighting and textures that went beyond anything released even a few years earlier. Other first-person shooters (FPS) like <em>Counter-Strike</em> (itself originally a mod for <em>Half-Life</em>) and <em>Unreal Tournament</em> built on the work of earlier titles like <em>DOOM</em>, <em>Wolfenstein 3D</em>, and <em>Duke Nukem 3D</em>. Many of these titles were designed for multiplayer action. However, the typically low network speeds of the period meant that these games, unlike slower-paced and less graphically intensive strategy games, were nearly unplayable over an internet connection. In this moment, in which communications technology was being outpaced by graphical power, the LAN (local area network) party was born.</p><p>The term itself conjures up strong sensory memories for those who were there‚Äîsweaty bodies packed into a basement or convention hall, a&nbsp;dozen CPUs noticeably warming the space, the heft of a CRT monitor being maneuvered into position. For those on the outside, these were scenes of incomprehension or ridicule. But for those who were there, the LAN party was a singular event, a&nbsp;defining social occasion of the early 21st century. It represented the last gasps of the isolated gamer stereotype, ushering in an age in which gaming was not only mainstream, but a social, networked activity.</p><p>Of course, people had been bringing together computers for some time prior to the Y2K era. (The demoparty, in which participants cracked code to evade copyright protection and share artistic creations, was an important antecedent to the LAN party.) But it was in this particular period‚Äîin the United States, at least‚Äîthat the social and technological configuration of the LAN party became a true phenomenon. Participants hauled their monitors, towers, and peripherals to a central location, where they would set up their machines and connect them through a network switch. This&nbsp;local connection enabled speeds far beyond those available to the average internet user, enabling lag-free gameplay, not to mention high-speed file sharing at a time when downloading or transporting large files could be an extremely onerous task.</p><p>LAN parties ranged from small, private gatherings to massive, multi-day events with thousands of participants, such as QuakeCon, DreamHack, The Gathering, and Euskal Encounter. Both types are represented in this book, though the focus is more on the former. As accessible digital photography was emerging around the same time as LAN parties‚Äîand perhaps because computer enthusiasts were more likely than the general population to own gadgets like digital cameras‚Äîthese events are extraordinarily well documented.</p><h6>Gaming at the Turn of the Millennium</h6><p>What do these photos show? Young people‚Äîprimarily young men‚Äîgoofing off and playing games, of course. But it‚Äôs more than that. Technological and cultural artifacts of the era are strewn throughout, illustrating trends, obsessions, and now-forgotten relics. One of my favorite photos in the book depicts, among other things: a Windows XP error dialogue box; a beige Microsoft keyboard; a disposable film camera; a pair of wraparound headphones that I and nearly everyone else I knew owned in the early 2000s; and a pile of burned CD-Rs, one of which has ‚Äú<em>StarCraft</em>‚Äù written on it in permanent marker. Junk foods and caffeinated beverages appear frequently in the collection, with the energy drink Bawls Guarana in particular popping up again and again. While Mountain Dew&nbsp;has since acquired a reputation as the gamer beverage of choice, Bawls was certainly the unofficial sponsoring drink of the LAN party.</p><p>Some games feature prominently in the mythos of the LAN party and in the photos collected in this book. The aforementioned <em>Counter-Strike</em> and <em>Unreal Tournament</em> are two of them, being primarily team-based first-person shooters that laid the groundwork for the ongoing popularity of the genre. These games are best played with minimum latency; they each support large numbers of players and feature quick rounds, which made them big hits at LAN parties. Certain maps in these games have become iconic, celebrated and recreated in other titles‚Äîfor <em>Counter-Strike</em>, Dust II (de_dust2) is probably the best-known, while for <em>Unreal Tournament</em>, it‚Äôs Facing Worlds (CTF-Face). Both of these maps are so significant, so well-remembered and influential that they have their own Wikipedia pages.</p><p>Other first-person shooters popular at turn-of-the-century LAN parties include <em>Starsiege: Tribes</em>, <em>Tom Clancy‚Äôs Rainbow Six: Rogue Spear</em>, and id‚Äôs <em>Quake</em> series. <em>Quake III Arena</em> was released in 1999 and eschewed a single-player narrative component, instead focusing on highspeed multiplayer battles. The engine developed for the game was later used for a number of other successful games, including the awkwardly titled <em>Star Wars Jedi Knight II: Jedi Outcast</em>, which contained a robust multiplayer mode that players built on by creating elaborate rituals around lightsaber duels.</p><p>Of course, not all of the games played at LAN parties were first-person shooters. Real-time strategy (RTS) games were also quite popular in the early 2000s, with Blizzard‚Äôs <em>StarCraft</em> (1998) and <em>Warcraft III : Reign of Chaos</em> (2002) celebrated for their intricate design, customizability, and multiplayer capabilities. These games, like many 3FPS games of the era, came with tools that made it easy for players to create their own content. This led to a boom in hobbyist developer creativity that in turn generated entirely new genres of videogames such as the multiplayer online battle arena (MOBA), later refined by immensely successful titles like <em>League of Legends</em> and <em>Dota 2</em>. Other well-loved RTS games of the era include Westwood‚Äôs <em>Command &amp; Conquer</em> franchise, Ensemble‚Äôs <em>Age of Empires</em> series, and Creative Assembly‚Äôs <em>Total War</em> titles.</p><p>When it came to console gaming in the Y2K era, the Nintendo 64 set a new standard for multiplayer games with the introduction of four controller ports in 1996, and most subsequent machines followed its lead. Microsoft released the original Xbox in 2001, and its launch title, <em>Halo: Combat Evolved</em>, kicked off a new generation of console-based first-person shooters. In addition to featuring split-screen multiplayer, the Xbox supported a form of LAN play called <em>System Link</em>, which allowed up to sixteen players to play games like <em>Halo</em> simultaneously. The <em>Halo</em> series and Xbox also happened to be instrumental in the decline of the LAN party‚Äîmore on that later.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pg 26: ¬© Erwin de Gier Amsterdam (The Netherlands), 1998</span></figcaption></figure><h6>Y2K Cultural Trends</h6><p>Beyond games, LAN party photos also demonstrate some other cultural trends of the period. The late 90s and early 2000s saw the rise of the nu metal musical genre, which included artists like Limp Bizkit, Slipknot, Korn, and Linkin Park. These groups harnessed feelings of isolation and teenage angst and fused rock instrumentation with hip-hop style and delivery, creating a kind of music that was beloved and reviled in equal measure for its direct, unselfconscious emotional pleas, macho posturing, and nihilistic themes.</p><p>Simultaneously, anime and Japanese subcultures were becoming more popular in the US due to the introduction of shows like Dragon Ball Z and Sailor Moon on American children‚Äôs networks. The growth of the internet, too, was making it easier than ever for young people interested in anime and other niche topics to share their interests and learn more about them on message boards and webrings. Anime and nu metal often went together in the form of the animated music video (AMV), where fans would stitch together clips of their favorite shows as makeshift music videos for their favorite angsty tracks.</p><p>The influence of anime and nu metal, as well as the mainstreaming of hip-hop to white suburban audiences, the dark guns-and-leather aesthetics of the films Blade and The Matrix, skater culture, and more can be seen in many of the photos in this book‚Äîin the clothing people are wearing, the posters on their walls, and desktop backgrounds. What has today become massively mainstream‚Äîanime, gaming, comic books, and so on‚Äîwas, in the early 2000s, still on the fringes of normalcy. Remember: Iron Man didn‚Äôt kick off the Marvel Cinematic Universe until 2008. Crunchyroll, the anime streaming platform, didn‚Äôt exist until 2006.</p><p>In the same vein, this period also saw the birth of meme culture online. Early internet memes like ‚ÄúMr. T Ate My Balls,‚Äù ‚ÄúAll your base are belong to us,‚Äù and l33tspeak spread through forums like Something Awful and Flash portals such as Newgrounds, giving young internet users a kind of shared secret language. In the late 2000s, as social networks like Facebook gained traction among college students and more and more people got online, meme culture gradually became mass culture.</p><h6>Creative Chaos</h6><p>In addition to the cultural trends of the time, these pictures also show people bringing computers into places where they didn‚Äôt traditionally belong. In the 1990s and early 2000s, bulky desktop computers often lived in home offices or even dedicated ‚Äúcomputer rooms.‚Äù Some lucky few kids at that time had their own personal computers in their bedrooms, but in my experience, this was rare.</p><p>During LAN parties, participants brought computers into garages, basements, living rooms, and other spaces, setting them up on dining-room tables, TV trays, kitchen counters, and any available surface. The raw excitement on the part of the participants is evident in the sometimes absurd lengths they went to in order to participate in LAN parties‚Äîcomputer towers crammed between cushions in the back seat of a van to ensure their safe transportation across town; cables crisscrossing the floor to connect machines; CRT monitors balanced haphazardly around the room.</p><p>It‚Äôs this passion, I think, which partly explains the appeal of these photos‚Äîeven to those who weren‚Äôt around at the time. This book is full of images of people being truly excited about computers and playing games on them. There‚Äôs a sense, in looking at these photos, that these people were on the cusp of something‚Äîeven if they weren‚Äôt necessarily aware of it at the time. Since the home computer boom of the 1990s and the introduction of high-speed internet in the 2000s, the omnipresence of computers and communication technology has rendered them mundane to many people. It‚Äôs almost quaint to see people so genuinely thrilled to be playing PC games with their friends when, today, doing so is an everyday occurrence.</p><p>Making a LAN party happen took work. It took physical effort, technical know-how, and a willingness to hack things together. The range of computer equipment depicted in the photos is testament to that. Yes, there are the standard massive, beige CRT monitors associated with the period, but we see computer towers ranging from stock models in the same color to complex monstrosities built by enthusiastic geeks. This was before Apple‚Äôs sleek industrial design took over the tech world, before LED lights were standard on pretty much any gaming PC. It was the era of user-driven customization, and LAN parties are perfectly emblematic of that time.</p><h6>The Decline Of The LAN Party</h6><p>LAN parties occurred throughout the 1990s, peaked (in the US, at least) in the early-mid-2000s and began to decline in the early 2010s. Of course, people do still throw LAN parties, especially people who grew up with them, but their heyday has long since passed. So what killed the LAN party? The most obvious answer is the widespread introduction of communication infrastructure that made it possible to play games like first-person shooters over the internet with low latency.</p><p>LAN parties were a creation of circumstance, which withered away once it was no longer a necessity to transport computers to the same physical space in order to get an ideal gaming experience. It‚Äôs certainly true that it is now more convenient than ever for many people to play games online with strangers or friends. But convenience in technology often comes with a commensurate loss of control on the part of users.</p><p>In 2004, Bungie released <em>Halo 2</em> for the Xbox. The game built on the original‚Äôs landmark success by introducing online play through Microsoft‚Äôs Xbox Live service. It went on to become the most popular Xbox Live title of all time and was played until the discontinuation of the service on the original Xbox in 2010.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pgs 70-71: ¬© Kiel Oleson/Electronox  Lee‚Äôs Summit, MO (USA), 2002</span></figcaption></figure><p>The Xbox Live service was easy to use, popularizing the method of allowing players to party up with their friends and enter into matchmaking queues. This was a major shift from the then prevalent system of presenting players with a list of servers to join, each hosted by different players and groups. As well as being a more seamless experience emphasizing ease of use, this new model also represented a move away from user control. Matchmaking is now the dominant mode of playing multiplayer games online. There are certainly advantages inherent in it‚Äîdevelopers can try to create fairer matchups based on skill and players can keep their ranks and reputations across games‚Äîbut it also puts players at the mercy of a company‚Äôs algorithms and servers.</p><p>Many of the most popular multiplayer videogames today are entirely server-side, meaning that they cannot be played without connecting to the game‚Äôs servers. This is advantageous for developers and publishers, who can ensure that players have the latest updates, prevent cheating, and create large worlds in which numerous players can be online and interacting at once. But it also means that control of game experiences has shifted significantly away from users. Even games that have offline components often do not have any kind of peer-to-peer or private server functionality, meaning that it is impossible for a group to play them together in a LAN environment.</p><p>The way we buy and play games has also changed. Today, digital platforms like Steam and the Epic Game Store allow players to purchase titles without leaving their homes. But digital copies of games, and their management through these platforms, mean that the old practices of burning copies of games or sharing legal ‚Äúspawn installations‚Äù of games to facilitate multiplayer experiences are less and less possible.</p><p>Thus, the story that LAN parties died because they were simply an obsolete social structure is a little too straightforward. It may be true that most people would prefer to play games in the comfort of their own home rather than transporting expensive and bulky equipment elsewhere, but technological and economic forces also contributed to the decline of LAN events. The fact is that the shift to digital, producer-owned environments in every aspect of gaming‚Äîfrom sales to play‚Äîtremendously benefits the corporations publishing and selling games, sometimes at the expense of those purchasing and playing them.</p><h6>Looking Back</h6><p>In the photos collected in this book, then, we can see some things that have been lost, or at least forgotten‚Äîan adventurous spirit around computing and a world in which ownership of software and play belonged more to individuals than corporations. I don‚Äôt mean to suggest that LAN parties were utopian spaces. They were, of course, mostly‚Äîbut&nbsp;certainly not exclusively‚Äîattended and organized by young white men, and even many of the larger events were male-dominated spaces, hostile to women. Nonetheless, from my position, decades later, I can‚Äôt help but look fondly on images of LAN parties. At a time when communications technology paradoxically seems to produce a sense of disconnection for many people through algorithmically generated echo chambers and the indexing of personal worth to follower counts or likes, seeing people literally coming together with and around computers is almost aspirational.</p><p>It‚Äôs tempting to see the mainstreaming of gaming and tech as a uniformly positive trend. And certainly, more people having access to these things and feeling like they belong in associated spaces is a good thing. But there are always trade-offs. The ubiquity of, and widespread access to, tech has come with an unprecedented rise in surveillance through our devices, a loss of control over our personal data, and a sense of alienation fostered by tech companies who want to own as much of our attention as possible.</p><p>For people like me, who grew up during the 1990s and 2000s, it can sometimes feel like the exciting period of the internet and computing is over. Pictures of LAN parties represent that early era of the internet, when it was a place that you visited rather than a parallel layer of reality. As we‚Äôve watched that mysterious, alluring, and perilous internet get progressively fenced off, paywalled, and centralized by a few massive corporations, some of us are beginning to reflect on our relationship to&nbsp;it.</p><p>Perhaps this thing that was so important to us in our youth, that we‚Äôve stubbornly stuck with despite sweeping structural changes, is no longer so relevant to our lives. Maybe it‚Äôs time to start figuring out new ways to use the internet and computers to enrich our world. And maybe LAN parties can offer one model for that.</p><p><em>Excerpted from </em>LAN PARTY: Inside the Multiplayer Revolution<em>, by merritt k</em></p><p><em>Text ¬© 2023 merritt k&nbsp;</em></p><p><em>¬© 2024 Thames &amp; Hudson Ltd, London</em></p><p><em>Reprinted by permission of Thames &amp; Hudson Inc, </em><a href="http://www.thamesandhudsonusa.com/" target="_blank" rel="noreferrer noopener"><em>www.thamesandhudsonusa.com</em></a></p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pg 118: ¬© Robert McNeil  Brisbane (Australia), 2006</span></figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[McKinsey Under Criminal Investigation over Opioid-Related Consulting (358 pts)]]></title>
            <link>https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4</link>
            <guid>40148729</guid>
            <pubDate>Wed, 24 Apr 2024 19:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4">https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4</a>, See on <a href="https://news.ycombinator.com/item?id=40148729">Hacker News</a></p>
Couldn't get https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Nearsightedness is at epidemic levels ‚Äì and the problem begins in childhood (211 pts)]]></title>
            <link>https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255</link>
            <guid>40148707</guid>
            <pubDate>Wed, 24 Apr 2024 19:44:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255">https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255</a>, See on <a href="https://news.ycombinator.com/item?id=40148707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Myopia, or the need for corrected vision to focus or see objects at a distance, has become a lot more common in recent decades. <a href="https://doi.org/10.1038/519276a">Some even consider myopia</a>, also known as nearsightedness, an epidemic.</p>

<p>Optometry researchers estimate that <a href="http://dx.doi.org/10.1016/j.ophtha.2016.01.006">about half of the global population</a> will need corrective lenses to offset myopia by 2050 if current rates continue ‚Äì up from 23% in 2000 and <a href="https://myopiainstitute.org/myopia/#">less than 10% in some countries</a>. </p>

<p>The associated health care costs are huge. In the United States alone, spending on corrective lenses, eye tests and related expenses <a href="https://www.doi.org/10.3389/fmed.2021.718724">may be as high as US$7.2 billion a year</a>.</p>

<p>What explains the rapid growth in myopia? </p>

<p><a href="https://scholar.google.com/citations?user=fExMMysAAAAJ&amp;hl=en">I‚Äôm a vision scientist</a> who has studied visual perception and perceptual defects. To answer that question, first let‚Äôs examine what causes myopia ‚Äì and what reduces it.</p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/ezP3oCRaBBQ?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>A closer look at myopia.</span></figcaption>
          </figure>

<h2>How myopia develops</h2>

<p>While having two myopic parents does mean you‚Äôre more likely to be nearsighted, <a href="https://doi.org/10.1007/978-981-13-8491-2_5">there‚Äôs no single myopia gene</a>. That means the causes of myopia are more behavioral than genetic. </p>

<p>Optometrists have learned a great deal about the progression of myopia by <a href="https://www.scientificamerican.com/article/space-perception-in-the-chick/">studying visual development in infant chickens</a>. They do so by putting little helmets on baby chickens. Lenses on the face of the helmet cover the chicks‚Äô eyes and are adjusted to affect how much they see.</p>

<p>Just like in humans, if visual input is distorted, a chick‚Äôs eyes grow too large, <a href="https://doi.org/10.1016/j.cub.2006.02.065">resulting in myopia</a>. And it‚Äôs progressive. Blur leads to eye growth, which causes more blur, which makes the eye grow even larger, and so on. </p>

<p>Two recent studies featuring extensive surveys of children and their parents provide strong support for the idea that an <a href="https://doi.org/10.1186/s12889-022-14377-1">important driver of the uptick</a> in myopia is that <a href="https://doi.org/10.1111/aos.14980">people are spending more time</a> focusing on objects immediately in front of our eyes, whether a screen, a book or a drawing pad. The more time we spend focusing on something within arm‚Äôs length of our faces, dubbed ‚Äúnear work,‚Äù the greater the odds of having myopia. </p>

<p>So as much as <a href="https://www.cbc.ca/news/canada/excessive-screen-use-eyes-myopia-1.6815857">people might blame new technologies like smartphones</a> and too much ‚Äúscreen time‚Äù for hurting our eyes, the truth is even activities as valuable as reading a good book can affect your eyesight.</p>

<h2>Outside light keeps myopia at bay</h2>

<p>Other research has shown that this unnatural eye growth can be interrupted by sunlight.</p>

<p>A 2022 study, for example, found that myopia rates <a href="https://doi.org/10.1186/s12889-022-14377-1">were more than four times greater</a> for children who didn‚Äôt spend much time outdoors ‚Äì say, once or twice a week ‚Äì compared with those who were outside daily. At the same time, kids who spent more than three hours a day while not at school reading or looking at a screen close-up were four times more likely to have myopia than those who spent an hour or less doing so. </p>

<p>In another paper, from 2012, researchers <a href="https://www.doi.org/10.1016/j.ophtha.2012.04.020">conducted a meta-analysis of seven studies</a> that compared duration of time spent outdoors with myopia incidence. They also found that more time spent outdoors was associated with lower myopia incidence and progression. The odds of developing myopia dropped by 2% for each hour spent outside per week. </p>

<p>Other researchers have reported similar effects and argued for <a href="https://doi.org/10.1159/000501937">much more time outdoors</a> and changes in early-age schooling to reduce myopia prevalence. </p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/LAkFtka3UFw?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>‚ÄòWhy so many people need glasses now.‚Äô</span></figcaption>
          </figure>

<h2>What‚Äôs driving the epidemic</h2>

<p>That still doesn‚Äôt explain why it‚Äôs on the rise so rapidly.</p>

<p>Globally, a <a href="https://www.doi.org/10.1097/MD.0000000000014777">big part of this is due to the rapid development</a> and industrialization of countries in East Asia over the last 50 years. Around that time, young people began spending more time in classrooms reading and focusing on other objects very close to their eyes and less time outdoors. </p>

<p>This is also what researchers <a href="https://doi.org/10.1111/opo.12879">observed in the North American Arctic</a> after World War II, when schooling was mandated for Indigenous people. Myopia rates for Inuit went from the single digits before the 1950s to upwards of 70% by the 1970s as all children began attending schools for the first time.</p>

<p>Countries in Western Europe, <a href="https://doi.org/10.1001/archophthalmol.2009.303">North America</a> and Australia have shown <a href="https://doi.org/10.1097/OPX.0000000000000069">increased rates of myopia</a> in recent years but nothing approaching what has been observed recently in <a href="https://doi.org/10.1016/j.preteyeres.2017.09.004">China, Japan, Singapore and a few other East Asian countries</a>. The two main factors identified as leading to increased myopia are <a href="https://www.chinasmack.com/chinese-school-desks-with-railings-prevent-near-sightedness">increased reading</a> and other activities that require focusing on an object close to one‚Äôs eyes and a <a href="https://doi.org/10.1371/journal.pone.0181772">reduction in time spent outdoors</a>.</p>

<p>The surge in myopia cases will likely have its worst effects 40 or 50 years from now because <a href="https://doi.org/10.1186/s12889-022-14377-1">it takes time</a> for the young people being diagnosed with nearsightedness now to experience the most severe vision problems.</p>

<h2>Treating myopia</h2>

<p>Fortunately, just a few minutes a day with glasses or contact lenses that correct for blur <a href="https://doi.org/10.1016/s0042-6989(98)00304-6">stops the progression of myopia</a>, which is why early vision testing and vision correction are important to limit the development of myopia. Eye checks for children are mandatory in some countries, <a href="https://www.orthoptics.org.uk/patients-and-public/childrens-vision-screening/">such as the U.K.</a> and <a href="http://en.moe.gov.cn/news/press_releases/202404/t20240408_1124412.html">now China</a>, as well as <a href="https://nationalcenter.preventblindness.org/vision-screening-requirements-by-state/">most U.S. states</a>.</p>

<p>People with with high myopia, however, have <a href="https://doi.org/10.3390/ijerph16142595">increased risk of blindness and other severe eye problems</a>, such as retinal detachment, in which the retina pulls away from the the back of the eye. The chances of myopia-related <a href="https://www.webmd.com/eye-health/macular-degeneration/what-is-myopic-macular-degeneration">macular degeneration</a> increase by <a href="https://doi.org/10.1111/opo.12945">40% for each diopter of myopia</a>. A diopter is a unit of measurement used in eye prescriptions.</p>

<p>But there appear to be two sure-fire ways to offset or delay these effects: Spend less time focusing on objects close to your face, like books and smartphones, and spend more time outside in the bright, natural light. Given the first one is difficult advice to take in our modern age, the next best thing is taking frequent breaks ‚Äì or perhaps spend more time reading and scrolling outside in the sun.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I now lack the juice to fuel the bluster to conceal that I am a simpleton (332 pts)]]></title>
            <link>https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/</link>
            <guid>40148563</guid>
            <pubDate>Wed, 24 Apr 2024 19:32:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/">https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/</a>, See on <a href="https://news.ycombinator.com/item?id=40148563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							        
									<p><span itemprop="articleBody"><p>Forty years ago, Padgett Powell‚Äôs erudite coming of age novel <a href="https://bookshop.org/a/132/9781936787722" target="_blank"><em>Edisto</em></a> was released and introduced readers to a 12-year-old literary prodigy named Simons Everson Manigault. Following an acrimonious separation between the ‚ÄúDuchess‚Äù and the ‚ÄúProgenitor‚Äù (Simons‚Äô parents), the young boy finds himself living in the Manigault&nbsp;summer home in Edisto, South Carolina while his mother descends into alcoholism.</p>
<p>With his domestic reality crumbling to its foundations, Simons spends most of his time at the Baby Grand, a Black nightclub whose patrons take a shine to the young truant. When the Manigault maid‚Äôs biracial grandson arrives in Edisto looking for his mother, Simons names him ‚ÄúTaurus‚Äù and the name sticks. The unlikely pair develop a friendship, ushering Simons into the world of mid-century American race relations, the sexual revolution, and the infelicitous vortex of confusion that is puberty.</p>
<p>In addition to celebrating <em>Edisto‚Äôs</em> milestone anniversary this year, Powell will be releasing <em>Blasphemy and Other Ancestors </em>(Gordon Hill Press), a collaborative book co-authored with myself, Darius James, and Lee Henderson about the tag end of existence and the abasements that memory holds in store for characters living outside of their time.</p>
<p>I corresponded with Powell to discuss the relationship between cornpone and Flann O‚ÄôBrien, the ‚Äúrotten taste of America‚Äù informing literary culture, and building a career around the ‚Äúfey interface between believing in the South and making fun of believing in the South.‚Äù</p>
<p><strong>*</strong></p>
<p><strong>Jean Marc Ah-Sen: </strong>What was the central attraction of writing <em>Edisto</em>, a bildungsroman that explored Black and white race relations in the South? Why do you think so many writers feel compelled to start their careers writing about emotional and intellectual maturation, and to which characteristics of the coming-of-age novel do you attribute its pride of place among a broadly defined readership?</p>
<span>The attractive characteristic of a young narrator is the absurdity of it and the license of it.</span>
<p><strong>Padgett Powell:</strong> Let me warn us that these questions are too <em>recherche</em> for me. I now lack the juice to fuel the bluster to conceal that I am a simpleton.</p>
<p>A professor in college was roundly pregnant on a Monday, absent Wednesday, and giving her lecture on ‚ÄúThe Miller‚Äôs Tale‚Äù on Friday with the baby on her hip. I thought ‚ÄúWhat if that little bastard picks this stuff up and knows Chaucer when he‚Äôs five?‚Äù My own brother had a good mouth on him, there was already the mother in front of me‚Äîthe novel was there for the writing. The cerebral cogitation was done. Just Strunk &amp; White some sentences and connect them head to tail and throw in everything you‚Äôve ever seen or heard. Done.</p>
<p>You don‚Äôt write about ‚Äúemotional and intellectual maturation.‚Äù The attractive characteristic of a young narrator is the absurdity of it and the license of it. Huck Finn is a 14-year-old uneducated antebellum white boy in Mississippi? Huck Finn is Mark Twain being as smart as Mark Twain was. Huck Finn turns him loose. The absurdity of the proposition is like lightning.</p>
<p><strong>JMA: </strong><em>Edisto</em> explored the legacy and aftermath of the reconstruction era all the way into the 1960s. Donald Barthelme in particular praised you for writing about things readers had never heard before between Black and white characters. Did you have a sense that books written about a similar milieu before or around the time of <em>Edisto‚Äôs</em> publication were characteristic of a mealy-mouthedness when it came to racial politics?</p>
<p><strong>PP:</strong> I am innocent of anything written along these lines or the spectrum of candor in them. Because I was arrested for my underground newspaper <em>Tough Shit</em> in high school and the principal sent it to my college to dematriculate me from it, and I had as a result narrated the events of my arrest to four eminences at that college, the Dean of Men there put me in a dorm room with the odd Black boy out because he figured I was radical enough to be liberal enough to handle early integration.</p>
<p>‚ÄúI didn‚Äôt want some redneck to eat him up,‚Äù he put it to me three weeks into the semester. I said I wouldn‚Äôt. Jinx took me to his bar‚Äîit‚Äôs in the book, verisimilitudinously. I saw some low country Black life behind some doors. We‚Äôd had a long-term maid, a complicated woman‚Äîin the book as Theenie, verbatim. I saw some mullet fishing in Florida where a woman berated a fellow for his sloth; ‚ÄúYou so slow, no wonder your wife left you.‚Äù His name was Buckwheat, a name I could not alter or drop, as prudence would have suggested; she called him Wheat, and when he said, ‚ÄúShe din‚Äô leave me, she died,‚Äù the woman yelled, ‚ÄúThe ultimate leff!‚Äù If these are things not heard before, it is only because no one has listened and written them down. You could not publish them in America today because of liberal-editing racism.</p>
<p><strong>JMA: </strong>Twelve years after the release of <em>Edisto</em>, you returned to the world of the Manigault family with <em>Edisto Revisited</em>. What were your motivations for dropping back into the land of mullet fishing, moonshine, and professorial mores during Simons‚Äô university years? Did you always have a sense that there was more to Simons‚Äô story that warranted revisiting, or was there some realization that came afterwards that signaled the attractive possibilities of the story continuing in a sequel?</p>
<p><strong>PP:</strong> I had no sense of more to tell, certainly no sense that more was merited, but it was what I could write at the time and I wrote it. Let me lean us up on Flannery O‚ÄôConnor, our late racist goddesshead: ‚ÄúWhen I told you to write what is easy I meant what is possible. It is never easy.‚Äù If I have misquoted her, it is because my brain has little spots of something in it.</p>
<p><strong>JMA: </strong>Your career has been described as participating in the American Southern literary tradition. Was this an association you felt honored by, or perhaps something that you were suspicious of? Do you think that writing embodying the principles of the American South needs to be constantly evolving, or is it something that needs to be carefully curated, and whose boundaries must be clearly defined, in order for it to endure?</p>
<p><strong>PP:</strong> It might be fun to tear it all up after the Jews Will Not Replace Us boys in their khakis protest, holding copies of <em>Absalom! Absalom!</em> upside down in the style of Trump with his Bible with duped General Milley at his side. It could all go into the big smelter with the Bobbie E. Lee bronze. But then some smartass would invent another plantation house, another confederate widow, another lost utterancer of the not yet lost cause.</p>
<p>I have made a career of dancing without dancing in the fey interface between believing in the South and making fun of believing in the South, which is why no one has ever heard of me. It‚Äôs a lame-ass position. The proper term is chicken-shit.</p>
<p>Who would object if clubists wanted to shove you into a cubbyhole with Faulkner and O‚ÄôConnor and their queer son Tennessee and too straight son Walker and what-litter-is-he-from son Don? Not I. And my God, Barry Hannah got more out of the whiskey oracle than anyone dead. I do not like the sentimental blood-and-grits crowd and I do not like the apotheosis of Story as Panacea, the from-farm-to-porch menu. Cornpone. No.</p>
<p>Southern writing, not often actually defined, means a deep-down knowing that people are beat to shit. An earnest suspicion of earnestness, a recognition and denial of whippedness. I am now spinning cornpone myself. End of the foregoing. Let‚Äôs go read some Flann O‚ÄôBrien. Those brothers are whipped for real.</p>
<p><strong>JMA: </strong>The book that you are perhaps most known for is <a href="https://bookshop.org/a/132/9780061859434" target="_blank"><em>The Interrogative Mood</em>, <em>A </em><em>Novel?</em></a> which is entirely written in the form of meditative questions‚Äî‚ÄúIf you were to participate in a spice war, what spice would you fight for?‚Äù is my personal favorite. Did you conceive the book as a rascally wedge that could be placed between experimental and commercial fiction? Or was the book perhaps an effort to assert the primacy of artistic questioning over the fatuousness of shopworn opinions?</p>
<p><strong>PP:</strong> You continue to try to flatter. But this is sharp flattery. It moves me to pomposity: experimental fiction means no more or less than fiction whose central thrust in not made-up people doing made-up things. Let‚Äôs call that MUPDMUT. With some liberty, Mupdeemut. Experimental fiction may of course have Mupdeemut in it, but not as the thrust of it‚Äîsomething beyond our believing in Mupdeemut is at hand.</p>
<p>When Hulga‚Äôs leg is stolen by a Bible salesman, we are to believe it. When our friend Colby has gone too far and is to be hanged, we are not to believe it. We have the pleasure of seeing Colby in his anguish, but we have a larger or smaller pleasure of distraction from the dictate to pretend this horseshit actually happens. That is the ‚Äúexperiment.‚Äù</p>
<p>Does the imperative to not believe exceed the pleasure of the imperative to believe? Donald Barthelme believed it did if the writing still contained emotional payoff. O‚ÄôConnor would have said, did say, to hell with it. ‚ÄúIf [the Devil] is only a symbol, to hell with it.‚Äù The imperative to believe is at one level rather childish, as in Once upon a time‚Ä¶ This is why Coleridge had the wit to call it a ‚Äúsuspension of disbelief,‚Äù not precisely an imperative to believe. What an upgrade to be told, ‚ÄúDon‚Äôt <em>believe</em> this, you morons.‚Äù What you do, mischievously, is believe <em>more</em>. At which point the ‚Äúexperiment‚Äù has succeeded.</p>
<p><em>The Int. Mood</em> goes way too far, in Colby terms, and dispenses with Mupdeemut altogether, except for the occasional Jimi Hendrix‚Äôs being offered a BLT as he affects to play you a tune. There is no history of intellection in its conception or intent and no prefiguring in its execution (Huck Finn shows you prefigurating for a book like <em>Edisto</em>).</p>
<p>I received an email from a colleague who wanted me to talk to the Dean that opened, ‚ÄúIs it time for us to have a chat with the dean? Are we remembering what was promised us, last spring, at lunch? Are we going to let history repeat itself?‚Äù I suffered pique at this and wrote back, ‚ÄúAre your emotions pure? Are your nerves adjustable? How do you stand in relation to the potato? Should it still be Constantinople?‚Äù</p>
<p>The pleasure in this was extreme. I thought how funny it would be‚ÄîReply All‚Äîfor her to receive 600 of these questions, and wrote 600 of them, and then could not stop and wrote 142 pages of them. I saw the ‚Äúrules‚Äù immediately, using her model, but exaggerating the forces. Relieve the silly with the grave, the arch with the colloquial, perfect the overt non-sequitur, watch rhythm, let each sentence deliver its impact‚Äîa stonking of someone who would presume write your ass with questions as annoying as they were. Marvelous fun, therapeutic because I was fair exercising some deep contours in my shallow brain, and I felt fine every time I wrote a batch of these things, which I began to liken to thousands of redundant missiles like those we have in our nuclear silos.</p>
<p><strong>JMA: </strong>Your prose tends to be voice-driven and characterized by a kind of malapert urbanity. Can you talk about how this stylized way of writing developed, and if it was an artistic response to things you were reading (whether inhospitably or with a deal of enthusiasm)?</p>
<p><strong>PP:</strong> I am ignorant of ‚Äúmalapert‚Äù but I do get ‚Äúurbanity.‚Äù Here is as an almost certainly impertinent answer that I do not intend to be impertinent: I learned to write the English I have written by taking three years of Latin, in the putatively desolate educational backwater of Jacksonville, Florida, ending in the tenth grade translating <em>The Aeneid</em>. I was in homeroom sitting with Allen Collins of Lynyrd Skynyrd. We was gettin‚Äô it. We did not know we was gettin‚Äô it.</p>
<p><strong>JMA: </strong>Does the prose voice that you adopt develop in parallel to the thematic concerns that you will tackle in a given work, or does it emerge as a result of other considerations?</p>
<p><strong>PP:</strong> It emerges with no consideration for anything but the next correct word.</p>
<p><strong>JMA:</strong> The destiny of all books is to become unmoored from the time which birthed them, and as new readers discover them, their relationship can become not just tinged, but entirely defined by a sense of presentism. You spent a large part of your career teaching at the University of Florida Creative Writing program, and I‚Äôm wondering how you would address this reality when and if it occurred in the classroom? Is there, in point of fact, a ‚Äúright‚Äù and ‚Äúwrong‚Äù way to read?</p>
<p><strong>PP:</strong> We read formative work asking only what might make it better, by which I meant power in the writing. As I came to the end, the students seemed to have been coached toward a new kind of ‚Äúbetter‚Äù that meant what was less offensive, and the offense was a multi-headed, surprising beast. One student got in trouble with others when he created a character named Phone Ho. I was mystified by all this and got away rather than try to breast the tide.</p>
<p>I was not going to be able to teach writing, if I ever had taught it. I was turned in for use of the phrase ‚Äútsunami of inclusivity.‚Äù The phrase was examined for ‚Äúracial content.‚Äù It was judged to be empty of racial content. A prior student suggested I use ‚Äúpoliticalicity‚Äù as in ‚Äútsunami of politicalicity‚Äù and I paid him $20 for the word, inserted the phrase, and retired. Please see my students Kevin Wilson and Chris Bachelder, and Kevin Canty and Chris Adrian. There are more. These are just my Kevins and my Chrises, as Trump would put it. God are we doomed.</p>
<span>The destiny of all books is to become unmoored from the time which birthed them.</span>
<p><strong>JMA: </strong>Your latest work will be the novelette ‚ÄúThe New Book‚Äù in our omnibus book <em>Blasphemy and Other Ancestors</em>. Your offering concerns a man of letters taking on an assistant and training him in the righteous arts of romance, but it also features a metafictionally aware narrator playing against a hypothetical reader‚Äôs reservations about events unfolding in Florida. I‚Äôm curious if this was a way to express frustration with the sensibilities of modern readership or literary criticism?</p>
<p><strong>PP:</strong> I think not. What I recall was writing a fairly comprehensible sketch in the South-satire genre, kind of my schtick, getting tired of my schtick, and for relief sliding into something untenably surreal in which even I could not keep straight what I was talking about. So I shet that thing down. My hero turned into Ted Turner, and Monteagle, Tennessee became the Philippines in WWII, and a girl at Walmart turned into Vanna White and I was doomed.</p>
<p><strong>JMA: </strong>In an industry that routinely heaps indignity after indignity on its practitioners, what has been the most startling development that you have encountered in recent years while releasing your books? Was it an issue arising as a matter of course from past frustrations, or did it spring from some unprecedented corner of the industry?</p>
<p><strong>PP:</strong> It sprang from the unprecedented corner of my own publisher. My book <em>Indigo</em> had been edited and copyedited by two astute, eminent editors, was set to roll, when a ‚Äúsensitivity editor‚Äù was brought in because someone in marketing at the house was not ‚Äúcomfortable representing the book.‚Äù (For the record I never saw any evidence that anyone represented the book)</p>
<p>The sensitivity editor, who I suspect was given four times the money I was given for the book, fell to with their sensitivity broadaxe. In a long true account of a dust-up at a restaurant in old Austin, not new Austin, a Black man on my roofing crew came to my defense and knocked out a white restaurant manager, who was at the moment presuming to assault me. Willie had noticed that the manager had Black back-up and felt I should too. ‚ÄúOld Padge need him some brothers too,‚Äù he would explain later.</p>
<p>The piece was essentially a portrait of a hero, Willie Ebert Brown, in a terrain of racial relations that had hope in it. The sentence that announced the Black back-up for the manager was this: ‚ÄúA sturdy-looking Black guy came out of the kitchen.‚Äù This is choice low fruit for a sensitivity editor. ‚ÄúObjectifying description,‚Äù she wrote, ‚Äúthat may invoke associations with slavery.‚Äù</p>
<p>I should have desisted publishing the book, but I am a chicken-shit person and I really wanted a book with a beautiful photo of an indigo snake on its cover. My celebration of Willie was thrown out; my invocation of slavery (to which who objects, its absurdity aside?) was one of a hundred other crimes in the piece. Liberal racism had its way: remove racism by removing race.</p>
<p>There is not a person of color in my book except a very positive small tribute to Barack Obama as a tool by which we might argue the French can slow their roll about how racist we are and they aren‚Äôt. How that was not deemed racist is a wonder, because it somewhat is. It‚Äôs not a wonder: liberal racism is a photo-negative argument. I apologize for this rant. Chicken-shit and now tired too.</p>
<p><strong>JMA: </strong>For decades now, readers and writers alike have speculated about where the future of literature is headed, with some espousing the belief that literary fiction in particular is going the way of opera and ballet. I think it could be argued that anything betraying a high literary sensibility is already beholden to blue-blooded patronage and sponsorship, whether we are talking about arts grants and awards bodies or content subscription models like Substack or Patreon. Do you think that literary fiction can find mass appeal among readers or has its place always been in contradistinction to an upmarket reading sensibility?</p>
<p><strong>PP:</strong> Does ‚Äúan upmarket reading sensibility‚Äù mean people who buy books at the airport? I confess to feeling loose reading this question. Let‚Äôs do a loose answer: a really good book, with anomalies here and there, will not sell well to a mass American market. If you make money here, you have done something wrong. It‚Äôs the rotten taste of America, the same force that explains a Trump. We have problems way larger than a poor good writer and a successful conman at large in Washington.</p>
</span></p>
									
																		
																		
									<br><hr>
									
							    										
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['So hot you can't breathe': Extreme heat hits the Philippines (105 pts)]]></title>
            <link>https://www.japantimes.co.jp/news/2024/04/24/asia-pacific/philippines-extreme-heat/</link>
            <guid>40148012</guid>
            <pubDate>Wed, 24 Apr 2024 18:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.japantimes.co.jp/news/2024/04/24/asia-pacific/philippines-extreme-heat/">https://www.japantimes.co.jp/news/2024/04/24/asia-pacific/philippines-extreme-heat/</a>, See on <a href="https://news.ycombinator.com/item?id=40148012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jtarticle">
                                    <p><span>Manila ‚Äì </span></p><p>Extreme heat scorched the Philippines on Wednesday, forcing thousands of schools to suspend in-person classes and prompting warnings for people to limit the amount of time spent outdoors.</p><p>The months of March, April and May are typically the hottest and driest in the archipelago nation, but conditions this year have been exacerbated by the El Nino weather phenomenon.</p><p>"It's so hot you can't breathe," said Erlin Tumaron, 60, who works at a seaside resort in Cavite province, south of Manila, where the heat index reached 47 degrees Celsius on Tuesday.</p>
                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A feature-rich front-end drag-and-drop component library (311 pts)]]></title>
            <link>https://github.com/atlassian/pragmatic-drag-and-drop</link>
            <guid>40147883</guid>
            <pubDate>Wed, 24 Apr 2024 18:25:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/atlassian/pragmatic-drag-and-drop">https://github.com/atlassian/pragmatic-drag-and-drop</a>, See on <a href="https://news.ycombinator.com/item?id=40147883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto">Pragmatic drag and drop is a low level drag and drop toolchain that enables safe and successful usage of the browsers built in drag and drop functionality. Pragmatic drag and drop can be used with any view layer (<a href="https://react.dev/" rel="nofollow"><code>react</code></a>, <a href="https://svelte.dev/" rel="nofollow"><code>svelte</code></a>, <a href="https://vuejs.org/" rel="nofollow"><code>vue</code></a>, <a href="https://angular.io/" rel="nofollow"><code>angular</code></a> and so on). Pragmatic drag and drop is powering some of the biggest products on the web, including <a href="https://trello.com/" rel="nofollow">Trello</a>, <a href="https://www.atlassian.com/software/jira" rel="nofollow">Jira</a> and <a href="https://www.atlassian.com/software/confluence" rel="nofollow">Confluence</a>.</p>
<details>
    <summary>Capabilities</summary>
<p dir="auto">Pragmatic drag and drop consists of a few high level pieces:</p>
<ol dir="auto">
<li><strong>Low level drag and drop behavior</strong></li>
</ol>
<p dir="auto">Pragmatic drag and drop contains a core package, and a number of optional packages, that provide you the pieces to create <em>any</em> drag and drop experience.</p>
<p dir="auto">These pieces are unopinionated about visual language or accessibility, and have no dependency on the Atlassian Design System.</p>
<ul dir="auto">
<li><em>Tiny</em>: ~<code>4.7kB</code> core</li>
<li><em>Incremental</em>: Only use the pieces that you need</li>
<li><em>Headless</em>: Full rendering and style control</li>
<li><em>Framework agnostic</em>: Works with any frontend framework</li>
<li><em>Deferred compatible</em>: Delay the loading the core packages and optional packages in order to further improve page load speeds</li>
<li><em>Flexible</em>: create any experience you want, make any changes you want during a drag operation.</li>
<li><em>Works everywhere</em>: Full feature support in Firefox, Safari, and Chrome, iOS and Android</li>
<li><em>Virtualization support</em>: create any virtual experience you want!</li>
</ul>
<ol start="2" dir="auto">
<li><strong>Optional visual outputs</strong></li>
</ol>
<p dir="auto">We have created optional visual outputs (eg our drop indicator) to make it super fast for us to build consistent Atlassian user experiences. Non Atlassian consumers are welcome to use these outputs, create their own that copy the visual styling, or go a totally different direction.</p>
<ol start="3" dir="auto">
<li><strong>Optional assistive technology controls</strong></li>
</ol>
<p dir="auto">Not all users can achieve pointer based drag and drop experiences. In order to achieve fantastic experiences for assistive technology users, we provide a toolchain to allow you to quickly wire up performant assistive technology friendly flows for any experience.</p>
<p dir="auto">The optional assistive controls we provide are based on the Atlassian Design System. If you do not want to use the Atlassian Design System, you can use our guidelines and substitute our components with your own components, or you can go about accessibility in a different way if you choose.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is this repository?</h2><a id="user-content-what-is-this-repository" aria-label="Permalink: What is this repository?" href="#what-is-this-repository"></a></p>
<p dir="auto">This repository is currently one way mirror from our internal monorepo that contains all the code for Pragmatic drag and drop.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2182637/318564281-b45c2dfe-2c54-459e-a3e6-68b2342fe97b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM5OTk5MDYsIm5iZiI6MTcxMzk5OTYwNiwicGF0aCI6Ii8yMTgyNjM3LzMxODU2NDI4MS1iNDVjMmRmZS0yYzU0LTQ1OWUtYTNlNi02OGIyMzQyZmU5N2IucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDQyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA0MjRUMjMwMDA2WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWQwMTYyZTAzY2ZmNjAzZDhlNzE2OTc3MjYyM2M1OGM2OTU4ZTZlZjY3YWQ5MTgxZGYyYmEzZDk2YTY1NTVkZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.TYJ6omA7YyBaTEUgm2eXaNIyMQNOv_FUCnmLl9LciSA"><img src="https://private-user-images.githubusercontent.com/2182637/318564281-b45c2dfe-2c54-459e-a3e6-68b2342fe97b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM5OTk5MDYsIm5iZiI6MTcxMzk5OTYwNiwicGF0aCI6Ii8yMTgyNjM3LzMxODU2NDI4MS1iNDVjMmRmZS0yYzU0LTQ1OWUtYTNlNi02OGIyMzQyZmU5N2IucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDQyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA0MjRUMjMwMDA2WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWQwMTYyZTAzY2ZmNjAzZDhlNzE2OTc3MjYyM2M1OGM2OTU4ZTZlZjY3YWQ5MTgxZGYyYmEzZDk2YTY1NTVkZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.TYJ6omA7YyBaTEUgm2eXaNIyMQNOv_FUCnmLl9LciSA" alt="Diagram of how the mirror works" width="600px"></a>
</p>
<p dir="auto">The intention of this repository is to make public our code, but not to accept code contributions (at this stage). In the future we could explore setting up a two way mirror so that contributions to this repo can also make their way back to our monorepo. You are still welcome to raise issues or suggestions on this repository!</p>
<p dir="auto">All documentation and <code>npm</code> packages are public and available for use by everyone</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Can I use this with my own Design System?</h2><a id="user-content-can-i-use-this-with-my-own-design-system" aria-label="Permalink: Can I use this with my own Design System?" href="#can-i-use-this-with-my-own-design-system"></a></p>
<p dir="auto">Yep! Pragmatic drag and drop as a <a href="https://atlassian.design/components/pragmatic-drag-and-drop/core-package" rel="nofollow">small core package</a>, and then a range of <a href="https://atlassian.design/components/pragmatic-drag-and-drop/optional-package" rel="nofollow">optional packages</a>. Some of the optional packages have dependencies on styling solutions (eg <code>emotion</code>), view libraries (eg <code>react</code>) or on some additional Atlassian outputs (eg <code>@atlaskit/tokens</code>). We have separated out optional packages that have other dependencies so they can be easily swapped with your own pieces that use your own tech stack and visual outputs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Can I use my own design language?</h2><a id="user-content-can-i-use-my-own-design-language" aria-label="Permalink: Can I use my own design language?" href="#can-i-use-my-own-design-language"></a></p>
<p dir="auto">Yep! We have created some design guidelines which embody how we want to achieve drag and drop in our products, and some of those decisions are embodied in some optional packages. However, you are free to use whatever design language you like, including ours!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is <code>@atlaskit</code>?</h2><a id="user-content-what-is-atlaskit" aria-label="Permalink: What is @atlaskit?" href="#what-is-atlaskit"></a></p>
<p dir="auto">The Pragmatic drag and drop packages are published under the <code>@atlaskit</code> namespace on <code>npm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { draggable } from '@atlaskit/pragmatic-drag-and-drop/element/adapter';"><pre><span>import</span> <span>{</span> <span>draggable</span> <span>}</span> <span>from</span> <span>'@atlaskit/pragmatic-drag-and-drop/element/adapter'</span><span>;</span></pre></div>
<p dir="auto"><code>@atlaskit</code> is the <code>npm</code> namespace that we publish all of our public packages on from inside our internal monorepo. We <em>could</em> look at creating a separate namespace in the future just for Pragmatic drag and drop. If we do that, we'll release some tooling to help folks automatically switch over.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">Made with love by:</p>
<ul dir="auto">
<li><a href="https://twitter.com/alexandereardon" rel="nofollow">Alex Reardon</a></li>
<li><a href="https://twitter.com/DeclanWarn" rel="nofollow">Declan Warn</a></li>
<li><a href="https://twitter.com/lewishealey" rel="nofollow">Lewis Healey</a></li>
<li><a href="https://www.linkedin.com/in/elenimisthos/" rel="nofollow">Eleni Misthos</a></li>
<li><a href="https://soundcloud.com/jessebauer" rel="nofollow">Jesse Bauer</a></li>
<li><a href="https://twitter.com/MitchG23" rel="nofollow">Mitch Gavan</a></li>
<li><a href="https://twitter.com/michaelguitars7" rel="nofollow">Michael Abrahamian</a></li>
<li><a href="https://twitter.com/ReDrUmNZ" rel="nofollow">Tim Keir</a></li>
<li><a href="https://www.linkedin.com/in/gretarit/" rel="nofollow">Greta Ritchard</a></li>
<li><a href="https://www.atlassian.com/" rel="nofollow">Many other folks at Atlassian</a></li>
<li>Logo created by <a href="https://twitter.com/michelleholik" rel="nofollow">Michelle Holik</a> and <a href="https://twitter.com/vojta_holik" rel="nofollow">Vojta Holik</a></li>
</ul>
<p dir="auto">Pragmatic drag and drop stands on the shoulders of giants, including the folks who created the <a href="https://html.spec.whatwg.org/multipage/dnd.html" rel="nofollow">drag and drop specifications</a>, implemented drag and drop in browsers, and the many drag and drop libraries that came before this.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When do we stop finding new music? (327 pts)]]></title>
            <link>https://www.statsignificant.com/p/when-do-we-stop-finding-new-music</link>
            <guid>40147534</guid>
            <pubDate>Wed, 24 Apr 2024 17:50:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statsignificant.com/p/when-do-we-stop-finding-new-music">https://www.statsignificant.com/p/when-do-we-stop-finding-new-music</a>, See on <a href="https://news.ycombinator.com/item?id=40147534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png" width="624" height="400.92" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:514,&quot;width&quot;:800,&quot;resizeWidth&quot;:624,&quot;bytes&quot;:825644,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Say Anything (1989). Credit: 20th Century Studios.</figcaption></figure></div><p>I recently tried Spotify's new DJ feature in which an AI bot curates personalized listening sessions, introducing songs while explaining the intention behind its selections (much like a real-life disc jockey). Every four or five pieces, the bot interjects to set up its next block of music, ascribing a theme to these upcoming works. Here are some of my example introductions:</p><ul><li><p>"Next, we're gonna play some of your favorites from 2016."</p></li><li><p>"Here are some of your favorite indie rock songs from the 2010s."&nbsp; &nbsp;&nbsp;</p></li><li><p>"Up next, we have some music inspired by your love of 2000s hip-hop."</p></li></ul><p>With each DJ interlude, something became increasingly clear: my music taste had barely changed over the course of a decade. Armed with full knowledge of my musical interests, this AI agent had pinpointed my musical paralysis, packaging an algorithmic echo chamber of 2010s indie rock, 2000s pop, Bo Burnham, Blink-182, and Bruce Springsteen. Had my music taste stagnated?&nbsp; &nbsp; &nbsp;</p><p>This minor existential tailspin sent me down a Google rabbit hole‚ÄîI began frantically researching music paralysis and the science of sonic preference. Was this phenomenon of my own doing or a natural product of aging? Fortunately, the topic of song stagnation has been well-researched, aided by the robust datasets of streaming services.&nbsp;</p><p>So today, we'll explore how our relationship to music changes with age and the developmental phenomena driving our forever-shifting cultural tastes.</p><p>Open-earedness refers to an individual's desire and ability to listen and consider different sounds and musical styling. Research has shown that adolescents exhibit higher levels of open-earedness, with a greater willingness to explore and appreciate diverse musical genres. During these years of sonic exploration, music gets wrapped up in the emotion and identity formation of youth; as a result, the songs of our childhood prove wildly influential over our lifelong music tastes.</p><p><span>A New York Times analysis of Spotify data revealed that </span><a href="https://www.nytimes.com/2018/02/10/opinion/sunday/favorite-songs.html" rel="">our most-played songs often stem from our teenage years, particularly between the ages of 13 and 16</a><span>.</span></p><p>This finding has personal resonance, as I remember my cultural preferences being easily influenced during my pre-teen and early teenage years. For instance, I was twelve when Green Day released their landmark "American Idiot" album, a work that proved monumental in my relationship to music. Listening to the album's titular track felt like a supreme act of rebellion (for a twelve-year-old suburbanite). I was entranced by this song's iconoclastic spirit‚Äîcould they actually say, "f**k America?" &nbsp; &nbsp; &nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png" width="514" height="279.5934065934066" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:792,&quot;width&quot;:1456,&quot;resizeWidth&quot;:514,&quot;bytes&quot;:2637748,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>American Idiot Music Video: Credit: Reprise Records.</figcaption></figure></div><p>But "American Idiot" wasn't a true act of revolution. In fact, the album was produced and promoted by a multinational conglomerate with the intent of packaging seemingly transgressive pop-punk acts for my exact demographic. How was I so thoroughly seduced by this song? And yet, to this day, my visceral reaction to ‚ÄúAmerican Idiot‚Äù is still one of euphoria, despite my cynicism. I guess I have no choice but to love this song forever (thanks to pre-teen me).&nbsp;</p><p><span>Indeed, </span><a href="https://today.yougov.com/entertainment/articles/36462-best-decade-for-music-americans-poll-data?redirect_from=%2Ftopics%2Fentertainment%2Farticles-reports%2F2021%2F06%2F16%2Fbest-decade-for-music-americans-poll-data" rel="">YouGov survey data indicates a strong bias toward music from our teenage years</a><span>, a phenomenon that is consistent across generations. Every cohort believes that music was "better back in my day."&nbsp;&nbsp;</span></p><p>Ultimately, cultural preferences are subject to generational relativism, heavily rooted in the media of our adolescence. It's strange how much your 13-year-old self defines your lifelong artistic tastes. At this age, we're unable to drive, vote, drink alcohol, or pay taxes, yet we're old enough to cultivate enduring musical preferences.&nbsp;</p><p>The pervasive nature of music paralysis across generations suggests that the phenomenon's roots go beyond technology, likely stemming from developmental factors. So what changes as we age, and when does open-eardness decline?</p><p><strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">Survey</a></strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">&nbsp;</a><strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">research from European streaming service Deezer indicates that</a></strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">&nbsp;</a><strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">music discovery peaks at 24</a></strong><span>, with survey respondents reporting increased variety in their music rotation during this time. However, after this age, our ability to keep up with music trends typically declines, with respondents reporting significantly lower levels of discovery in their early thirties. Ultimately,</span><strong>&nbsp;the Deezer study pinpoints 31 as the age when musical tastes start to stagnate.</strong></p><p><span>These findings have been replicated across numerous analyses, including a study of Spotify user data from 2014. Produced from Spotify's internal dataset, this </span><a href="https://skynetandebert.com/2015/04/22/music-was-better-back-then-when-do-we-stop-keeping-up-with-popular-music/" rel="">research explores how tastes deviate from the mainstream with age</a><span>. In this analysis, a contemporary pop star like Dua Lipa would score a 1 (the most popular), and an artist further out of the zeitgeist like Led Zeppelin would rank somewhere in the 200s. The resulting visual is unnerving as we observe our cultural preferences (quite literally) spiral away from the mainstream as we grow older.</span></p><p><strong>This study identifies 33 as the tipping point for sonic stagnation</strong><span>, an age where artistic taste calcifies, increasingly deviating from contemporary works. But wait, there's more. Spotify data indicates that parents stray from the mainstream at an accelerated rate compared to empty nesters‚Äîa sort of "parent tax" on one's cultural relevancy.</span></p><p><span>But this stagnation goes beyond the popularity of our music selections; it's also the diversity across these works. From 30 onward, we listen to more music outside the mainstream and </span><a href="https://musicmachinery.com/2014/02/13/age-specific-listening/" rel="">sample fewer artists during streaming sessions</a><span>.</span></p><p>Reading these studies proved an existential body blow because I am 31, apparently on the precipice of becoming a musical dinosaur. I like to think I'm special‚Äîthat my high-minded dedication to culture makes me an exceptionally unique snowflake‚Äîbut apparently I'm just like everybody else. I turned 30, and now I'm in a musical rut, content to have an AI bot DJ pacify me with the songs of my youth.&nbsp;</p><p>I used to spend hours researching artists, scrutinizing my CD purchases, and, later, my iTunes selections. Musical exploration was an activity in and of itself; songs were more than background noise. Now, I'm stuck listening to James Blunt's "You're Beautiful" for the 1,000th time. What happened to me?</p><p><span>Music paralysis is the product of both biological trends and practical constraints. Deezer survey respondents who identified as being "in a musical rut" </span><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">cited numerous day-to-day limitations as cause for their stagnation, with the top three reasons being</a><span>:&nbsp;</span></p><ol><li><p>Overwhelmed by the amount of choice available: 19%</p></li><li><p>Having a demanding job: 16%</p></li><li><p>Caring for young children: 11%</p></li></ol><p>This first point regarding the paradox of choice is especially intriguing and would speak to streaming as some sort of societal ill, bombarding us with boundless content. It's easy to condemn Spotify for giving us too many options, but this complaint is likely emblematic of a broader developmental shift.&nbsp;</p><p><span>Context is critical to cultural discovery. An extensive cross-sectional study regarding musical attitudes and preferences from adolescence through middle age found that </span><a href="https://www.researchgate.net/publication/253337104_Music_Through_the_Ages_Trends_in_Musical_Engagement_and_Preferences_From_Adolescence_Through_Middle_Adulthood" rel="">our relationship with music drastically changes over time</a><span>. Surveying over 250,000 individuals, this study found:</span></p><ol><li><p>The degree of importance attributed to music declines with age, even though adults still consider music important.</p></li><li><p>Young people listen to music significantly more than middle-aged adults.</p></li><li><p>Young people listen to music in a wide variety of contexts and settings, whereas adults listen to music primarily in private contexts.</p></li></ol><p>The issue of music discovery does not originate from infinite choice; instead, this problem likely stems from decreased listenership and a waning commitment to exploration. Spending two hours a day combing through iTunes (now Spotify) is impractical. My priorities have changed, my emotional connection to music has changed, and I simply just don't have the time.&nbsp; &nbsp;</p><p>Indeed, this same cross-sectional study revealed that musical preferences are closely related to trends in psychosocial development. In this survey, researchers investigated how tastes vary across five dimensions as we age: intensity, contemporaneous, unpretentiousness, sophistication, and mellowness. The data they collected demonstrates a universality to our forever-changing relationship with music‚Äîit's natural to expect a progression in our preferences.&nbsp;</p><p>It's tempting to despair over these results, to accept changing cultural attitudes and the phenomenon of music paralysis as a predetermined truth. At the same time, stagnation is not a certainty. Research suggests that open-eardness and the discovery of new songs can be cultivated. Finding new music is a challenge, but it is achievable with dedicated time and effort. If we avoid the warm complacency of nostalgia, we can recapture our flare for music discovery.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png" width="616" height="369.6" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:720,&quot;width&quot;:1200,&quot;resizeWidth&quot;:616,&quot;bytes&quot;:1302433,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>High Fidelity (2000). Credit: Buena Vista Pictures.</figcaption></figure></div><p><span>My father "likes what he likes": Bruce Springsteen,&nbsp;</span><em>Field of Dreams</em><span>, The Washington Nationals, and consistently reminding me that Fleetwood Mac's&nbsp;</span><em>Rumours</em><span>&nbsp;was made after its bandmates divorced one another. Whenever I point out my dad's stubborn habits, he'll look at me, smile, and quote the immortal wisdom of Popeye: "I am what I am."&nbsp;&nbsp;</span></p><p>When I was younger, I strongly disliked this rationale. Surely, there is no fixed version of who we are. Humans are constantly evolving‚Äîperpetually engaged in self-discovery. But maybe this isn't the case for all facets of life.&nbsp; &nbsp;</p><p>The explore-exploit trade-off refers to the dilemma between seeking new information (exploring) and optimizing decisions based on known information (exploiting). Some examples of the explore-exploit trade-off include:&nbsp;</p><ul><li><p><strong>Restaurant selection</strong><span>: Do you find a new restaurant or return to your old haunts?&nbsp;</span></p></li><li><p><strong>Movies</strong><span>: Do you watch something new or re-watch an all-time favorite?&nbsp;&nbsp;</span></p></li><li><p><strong>Career</strong><span>: Should you keep your current job or look for a new one?</span></p></li></ul><p>In the case of music discovery, exploring would consist of finding new songs and subgenres, while exploiting would entail listening to already-beloved tunes.</p><p>The explore-exploit trade-off and an adjacent decision-making puzzle known as the optimal-stopping problem have prompted extensive research and the coining of a shortcut known as the 37% rule. This heuristic suggests we spend the first 37% of available search time exploring our options before settling on a preferred solution or selection.&nbsp;&nbsp;</p><p>In the case of musical preference, the current American lifespan averages 80 years; when we multiply this figure by 37%, we get 30 years‚Äîcoincidentally, the age at which music tastes stagnate. This back-of-the-envelope math could be interpreted in two ways:&nbsp;</p><ol><li><p><strong>I am going crazy</strong><span>: I see numbers and symbols that don't mean anything. The 37% rule is a vague heuristic that may not even apply to this case, and I am perceiving order from true randomness. </span></p></li><li><p><strong>30 is our optimal stopping point</strong><span>: Despite the 37% rule being a highly generalized heuristic, there is some merit to doubling down on our favorites after a sustained period of searching‚Äîa phenomenon that appears to be our default state. We spend 30 years exploring new music, and once we've sampled enough works, we reach an optimal stopping point, comfortable with our rotation of artists and songs.</span></p></li></ol><p>Maybe music paralysis is a feature, not a bug. Running on a never-ending treadmill of cultural exploration may be a recipe for discontent. There is nothing inherently wrong with "liking what you like." Is it my waning music discovery that's making me unhappy or the fact that I've yet to accept this reality?</p><p>Perhaps I should forsake sonic exploration and exploit my love of "American Idiot," 2010s indie rock, 2000s pop, Bo Burnham, Blink-182, and Bruce Springsteen, content to live in an algorithmic echo chamber curated by DJ‚Äîmy new AI savior.&nbsp;</p><div data-attrs="{&quot;url&quot;:&quot;https://www.statsignificant.com/p/when-do-we-stop-finding-new-music?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>This post is public so feel free to share it.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.statsignificant.com/p/when-do-we-stop-finding-new-music?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.statsignificant.com/p/when-do-we-stop-finding-new-music?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div><p><em><span>Want to chat about data and statistics? Have an interesting data project? Just want to say hi? Email </span><a href="http://daniel@statsignificant.com/" rel="">daniel@statsignificant.com</a></em><span>&nbsp; &nbsp;&nbsp; &nbsp;</span><strong>&nbsp;</strong><span>&nbsp; </span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TypeScript: Branded Types (169 pts)]]></title>
            <link>https://prosopo.io/articles/typescript-branding/</link>
            <guid>40146751</guid>
            <pubDate>Wed, 24 Apr 2024 16:48:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prosopo.io/articles/typescript-branding/">https://prosopo.io/articles/typescript-branding/</a>, See on <a href="https://news.ycombinator.com/item?id=40146751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong><a href="https://prosopo.io/articles/typescript-mapped-type-magic/">PART 1: TypeScript Mapped Type Magic</a></strong></p><p>Ahoy there TypeScript warriors! üëã Today we're extending our work in the <a href="https://prosopo.io/articles/typescript-mapped-type-magic/">TypeScript mapped types article</a> to provide <em>branding</em>. The previous article discussed how to use TypeScript mapped types in a nominal rather than structural nature.</p><pre><code><span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span>
<span>}</span>

<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span>
<span>}</span></code></pre><p>This is a fancy way of saying TypeScript is structural by default, i.e. it will see type <code>A</code> and <code>B</code> as equal when dealing with types. Making type <code>A</code> and <code>B</code> nominal would make TypeScript differentiate them apart, even though their structure is the same.</p><p>In this post, we're building on that work to produce a way to <em>brand</em> a type, providing an automated and easy-to-use way of making a type nominal. Branding focuses on the type system only, rather than introducing runtime fields like in the previous post, which is a major benefit over the previous approach.</p><h2>What's the problem?</h2><p>Branding, also known as opaque types, enable differentiation of types in TypeScript which otherwise would be classified as the same type. For example</p><pre><code>
<span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span>

<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span>
</code></pre><p><code>A</code> and <code>B</code> are structurally the same, ergo TypeScript accepts any instance of <code>A</code> or <code>B</code> in place of each other:</p><pre><code>
<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// absolutely fine, even though fn accepts types of A and obj is of type B!</span></code></pre><p>The function is looking for a value of type <code>A</code> as input, whereas we're passing it a value of type <code>B</code>. TypeScript compares the types structurally, and because they have exactly the same structure it deems this operation to be fine.</p><p>But what if we need to tell <code>A</code> and <code>B</code> apart? What if, conceptually speaking, they must be different? What if we're doing something fancy with <code>A</code> and <code>B</code> which TypeScript is unaware of but we require the types to be different? That's exactly the situation we found ourselves in lately!</p><p>We need branding to do exactly that.</p><h2>The solution</h2><p>Much like in the <a href="https://prosopo.io/articles/typescript-mapped-type-magic/">TypeScript mapped types article</a>, the key lies in creating a field with the name of a symbol to act as our <em>id</em>. However, with branding we only need this field at a type-level rather than the runtime-level. Since types are erased after compilation, we need to add this field to a type without altering the runtime data whatsoever. Casting, anyone?</p><p>First, lets introduce the <code>brand</code> field.</p><pre><code>
<span>const</span> brand <span>=</span> <span>Symbol</span><span>(</span><span>'brand'</span><span>)</span> <span>// keep this private!!</span>

<span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'A'</span>
<span>}</span></code></pre><p>Here we're adding the <code>brand</code> field to type <code>A</code>. The brand field name is a symbol, akin to a UUID. We use a symbol to ensure the <code>brand</code> field never clashes with any other field for <code>A</code>, because we'd be overwriting a field otherwise and introducing the worse kind of bugs: type bugs üêõ . We've set the brand to <code>'A'</code> at the moment, though this could be anything you desire. It's akin to the type name. Now let's compare <code>A</code> and <code>B</code> again:</p><pre><code>
<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// Error!</span></code></pre><p>Here's the error:</p><pre><code>Argument of type 'B' is not assignable to parameter of type 'A'.
  Property '[brand]' is missing in type 'B' but required in type '{ [brand]: "a"; }'.ts(2345)
</code></pre><p>TypeScript won't let us pass an instance of <code>B</code> to the function accepting <code>A</code> because it's missing the <code>brand</code> field - brilliant! <code>A</code> and <code>B</code> are now different types. But what about if <code>B</code> had its own brand?</p><pre><code>
<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'B'</span>
<span>}</span></code></pre><p>Note that we're using the same <code>brand</code> variable from before. It's important to keep this constant, otherwise we're declaring fields with different names!</p><p>Now lets try the function again:</p><pre><code>
<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// Error!</span></code></pre><p>And here's the error</p><pre><code>Argument of type 'B' is not assignable to parameter of type 'A'.
  Type 'B' is not assignable to type '{ [brand]: "A"; }'.
    Types of property '[brand]' are incompatible.
      Type '"B"' is not assignable to type '"A"'.ts(2345)
</code></pre><p>There we go! The error is saying that though both types have a <code>brand</code> field, the value for the brand is different for the two types, i.e. <code>'A' != 'B'</code>!</p><p>Let's see what happens if the <code>brand</code> is the same:</p><pre><code>

<span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'foobar'</span>
<span>}</span>

<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'foobar'</span>
<span>}</span>

<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// absolutely fine!</span>
</code></pre><p>No error! <code>A</code> and <code>B</code> are seen as interchangeable types because they're structurally the same, having the same fields <em>and</em> same brand value of <code>'foobar'</code>. Excellent!</p><h2>Make it generic!</h2><p>Awesome, so that works. But it's a toy example, not fit for production. Let's create a <code>Brand</code> type which can brand any type you wish:</p><pre><code><span>const</span> brand <span>=</span> <span>Symbol</span><span>(</span><span>'brand'</span><span>)</span> <span>// keep this private!</span>

<span>type</span> <span>Brand<span>&lt;</span><span>T</span><span>,</span> <span>U</span><span>&gt;</span></span> <span>=</span> <span>T</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>U</span>
<span>}</span></code></pre><p>This type is very simple, it takes your type <code>T</code> and adds a <code>brand</code> field with <code>U</code> being the brand value. Here's how to use it:</p><pre><code>
<span>type</span> <span>A_Unbranded</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span>

<span>type</span> <span><span>A</span></span> <span>=</span> Brand<span>&lt;</span>A_Unbranded<span>,</span> <span>'A'</span><span>&gt;</span> <span>// {</span>
<span>//     x: number;</span>
<span>//     y: boolean;</span>
<span>//     z: string;</span>
<span>// } &amp; {</span>
<span>//     [brand]: "A";</span>
<span>// }</span></code></pre><p>So now we can brand any type. For completeness, here's the same kind of thing to <em>remove</em> the brand and go back to plain ol' TypeScript types:</p><pre><code><span>type</span> <span>RemoveBrand<span>&lt;</span><span>T</span><span>&gt;</span></span> <span>=</span> <span>T</span><span>[</span>Exclude<span>&lt;</span><span>keyof</span> <span>T</span><span>,</span> <span>typeof</span> brand<span>&gt;</span><span>]</span></code></pre><p>And this will remove the <code>brand</code> field from any branded type. Also note that if the type is not branded, it will not be touched!</p><h2>Real world usage</h2><p>Let's put this into practice. We've got a class which needs branding to identify its type when dealing with <a href="https://prosopo.io/articles/typescript-mapped-type-magic/">mapped types</a>.</p><p>For simplicity, lets boil the class down to a <code>Dog</code> class:</p><pre><code>
<span>class</span> <span>Dog</span> <span>{</span>
    <span>constructor</span><span>(</span><span>public</span> name<span>:</span> <span>string</span><span>)</span> <span>{</span><span>}</span>
<span>}</span>

<span>type</span> <span>DogBranded</span> <span>=</span> Brand<span>&lt;</span>Dog<span>,</span> <span>'Dog'</span><span>&gt;</span>

<span>const</span> dog <span>=</span> <span>new</span> <span>DogBranded</span><span>(</span><span>'Spot'</span><span>)</span> <span>// Error!</span>
</code></pre><p>TypeScript won't let us construct a branded dog üò¢ . We're going to need to do some casting using the constructor to brand the <em>constructor</em> rather than the <em>class</em> itself.</p><pre><code>
<span>type</span> <span>Ctor<span>&lt;</span><span>T</span><span>&gt;</span></span> <span>=</span> <span>new</span> <span>(</span><span>...</span>args<span>:</span> <span>any</span><span>[</span><span>]</span><span>)</span> <span>=&gt;</span> <span>T</span>

<span>const</span> addBrand <span>=</span> <span>&lt;</span><span>T</span><span>&gt;</span><span>(</span>ctor<span>:</span> Ctor<span>&lt;</span><span>T</span><span>&gt;</span><span>,</span> name<span>:</span> <span>string</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> ctor <span>as</span> Ctor<span>&lt;</span>Brand<span>&lt;</span><span>T</span><span>,</span> <span>typeof</span> name<span>&gt;&gt;</span>
<span>}</span>

<span>const</span> DogBranded <span>=</span> <span>addBrand</span><span>(</span>Dog<span>,</span> <span>'Dog'</span><span>)</span>

<span>const</span> dog <span>=</span> <span>new</span> <span>DogBranded</span><span>(</span><span>'Spot'</span><span>)</span> <span>// ok</span></code></pre><p>The <code>addBrand</code> function takes a constructor of a class and casts it to a branded type. This essentially makes an alias for the <code>Dog</code> class which can be used in exactly the same way as the <code>Dog</code> class, e.g. calling <code>new</code> on it.</p><p>We can <code>export</code> the <code>DogBranded</code> type to allow the outer world to use our class whilst ensuring it's always branded:</p><pre><code><span>export</span> <span>type</span> <span>DogExported</span> <span>=</span> <span>typeof</span> DogBranded</code></pre><p>Likewise, we can do the same for brand removal:</p><pre><code>
<span>const</span> removeBrand <span>=</span> <span>&lt;</span><span>T</span><span>&gt;</span><span>(</span>value<span>:</span> <span>T</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> value <span>as</span> RemoveBrand<span>&lt;</span><span>T</span><span>&gt;</span>
<span>}</span></code></pre><p>This simply removes the brand by casting the type to a type mapped without the brand field.</p><p>And there we go: a sure-fire way to brand and un-brand your types in TypeScript üòÉ</p><p>We've published this work as a library which you can access via <a href="https://www.npmjs.com/package/@prosopo/ts-brand">NPM</a>!</p><p>At Prosopo, we're using TypeScript branding to fortify our types and do clever type mapping for our soon-to-be-released runtime type validator. Stay tuned for updates!</p><p><strong><a href="https://prosopo.io/articles/typescript-mapped-type-magic/">PART 1: TypeScript Mapped Type Magic</a></strong></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Borrow Checking, RC, GC, and the Eleven () Other Memory Safety Approaches (153 pts)]]></title>
            <link>https://verdagon.dev/grimoire/grimoire</link>
            <guid>40146615</guid>
            <pubDate>Wed, 24 Apr 2024 16:39:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://verdagon.dev/grimoire/grimoire">https://verdagon.dev/grimoire/grimoire</a>, See on <a href="https://news.ycombinator.com/item?id=40146615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
  

        <div>
          <div>
  

            <div>
    

              
    

              <p>The Memory Safety Grimoire, Part 1</p>
        

              <p><span>April 24, 2024</span>
        

                <span>&nbsp;‚Äî&nbsp;</span>
          

                
        

              </p>
      

            </div>
    
<section>
<p>
A fellow named Zeke came into my server one day.
</p>

</section>
<section>
<p>
<b>Zeke:</b> "Wait, so with generational references, we now have <b>four</b> ways to do memory safety?"
</p>
<p>
<b>Evan:</b> "In fact, there are <b>fourteen</b> by my count. Maybe more!" <a href="#note0" data-noteid="0">0</a>
</p>
<p>
<b>Zeke:</b> "Fourteen?!"
</p>

</section>
<section>
<p>
I've gotten so used to it that it's not surprising to me anymore, so it's always a delight to vicariously feel people's surprise when I tell them this.
</p>

</section>
<section>
<p>
<b>Evan:</b> "Indeed," and I proceed to show him <i>the grimoire</i> <a href="#note1" data-noteid="1">1</a> that I've kept secret all these years.
</p>
<p>
<b>Zeke:</b> "How did you find all these?!"
</p>

</section>
<section>
<p>
At this point, I likely told him some nonsense like "I just kept my eyes open and collected them over the years!" but I think that you, my dear reader, deserve to know <b>the truth!</b> <a href="#note2" data-noteid="2">2</a>
</p>

</section>
<section>
<p>
This article is the introduction to my secret collection of memory safety techniques, which I call the <b>memory safety grimoire</b>.
</p>

</section>
<section>
<p>
With this wisdom, one can see the vast hidden landscape of memory safety, get a hint about where the programming world might head in the next decades, and even design new memory safety approaches. <a href="#note3" data-noteid="3">3</a>
</p>

</section>
<section>
<p>
If you like this topic, check out this <a href="https://www.youtube.com/watch?v=UavYVf0UEoc">Developer Voices episode</a> where Kris Jenkins and I talked about linear types and regions!
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Borrow checking, RC, GC, and the Eleven (!) Other Memory Safety Approaches</p>
    
<ul>
</ul>

      </nav>
      
    

      <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
And I'd bet that someone on reddit or HN will comment on some I haven't heard before, and I'll have to change the title and add to the list!
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
 A grimoire is a cursed spellbook, like the necronomicon.
</p>
<p>
However, those of weak wills should be careful not to read grimoires... they might end up pursuing the dark arts for years.

</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
Or perhaps this entire article is just a clever ruse, the <a href="https://hpmor.com/chapter/35">mask behind the mask</a>, and the truth still remains a secret.
</p>

</section>
</div>


        </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="a-cursd-tome-and-ancient-memory-safety">
 A Curs√©d Tome, and Ancient Memory Safety</h2>
<p>
Mid-2023, a team of archaeologists discovered <a href="https://www.reuters.com/world/americas/ancient-maya-city-discovered-mexican-jungle-2023-06-21/">an ancient Mayan city in Campeche</a>. I was on the ground as the team's consulting software engineer, as the Mayans were known as some of the earliest and most powerful practitioners of the software arts.
</p>

</section>
<section>
<p>
The hours are long and there's always the chance of being kidnapped and ransomed by the marauding bands of <a href="https://www.fodors.com/world/mexico-and-central-america/mexico/yucatan-and-campeche-states/experiences/news/photos/10-fantastic-beasts-of-the-yucatan-and-where-to-find-them">white-nosed coatis</a>, <a href="#note4" data-noteid="4">4</a> but nobody asks me if I can add an RSS feed to a DBMS, so there's that. <a href="#note5" data-noteid="5">5</a>
</p>

</section>
<section>
<p>
Our leader Ivan was hoping that this ancient city might contain a fifth memory safety tome, similar to the ancient borrow checking codex that Graydon Hoare found in the <a href="https://www.theguardian.com/world/2016/nov/17/mexican-pyramid-has-two-more-inside-scientists-discover">Kukulkan pyramid</a> in 2016.
</p>

</section>
<section>
<p>
We made it to the central pyramid, and discovered a pedestal with a tattered tome, surprisingly intact after all this time. <a href="#note6" data-noteid="6">6</a> 
</p>

</section>
<section>
<p>
With my heart pounding, I approached the pedestal, looking closer at the inscriptions on the front. Sure enough, it had the Mayan symbols for "stack frame", "reference", and "region" on the front! We'd found it!
</p>

</section>

      </div>
  
<div>
    
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
The coatis probably wouldn't be so endangered if they robbed banks instead, like <a href="https://zeenews.india.com/india/bizzare-monkey-steals-bag-with-rs-4-lakh-throws-currency-notes-outside-registry-office-in-up-2332462.html">monkeys</a> and <a href="https://globalnews.ca/news/9560059/calgary-poisonous-snake-bank-robbery-re-arrest/">snakes</a> do. Their 180-degree ankles would be invaluable for heisting.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
Free cookies to anyone who got <a href="https://github.com/docker/cli/issues/267#issuecomment-695149477">the reference</a>!
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
Our team lead <a href="https://inah.gob.mx/boletines/descubren-antigua-ciudad-maya-campeche-la-nombran-ocomtun-columna-de-piedra">Ivan Spracj</a> explained that modern paper degrades much more quickly than the <a href="https://en.wikipedia.org/wiki/Amate">amate</a> paper the Mayans used. Their ancient techniques were better than ours, both in paper and memory safety.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="blending-techniques">
 Blending Techniques</h2>

</section>
<section>
<p>
Before this, we only had three choices for memory safety, each with it's own tradeoffs:
</p>
<ul>
<li>
Garbage collection <a href="#note7" data-noteid="7">7</a> is easy, flexible, has high throughput, but uses <a href="https://thenewstack.io/which-programming-languages-use-the-least-electricity/">more energy</a>, <a href="https://stackoverflow.com/a/764706/1424454">more memory</a>, and has nondeterministic pauses.
</li>
<li>
Reference counting is simple and uses less memory, but is slow and can leak cycles. <a href="#note8" data-noteid="8">8</a>
</li>
<li>
Borrow checking is faster and allows for aliasing inline data <a href="#note9" data-noteid="9">9</a>, but can cause complexity and can't do patterns like <a href="https://en.wikipedia.org/wiki/Observer_pattern">observers</a>, <a href="https://lwn.net/Articles/907876/">intrusive data structures</a>, many kinds of RAII, etc. <a href="#note10" data-noteid="10">10</a>
</li>
</ul>

</section>
<section>
<p>
But we've long suspected that the Mayans had ways to blend these together at a more fundamental level.
</p>

</section>
<section>
<p>
We've certainly tried blending them before, and we've even had some success. For example, to work around the borrow checker in Rust we can put an object in an <span>Rc&lt;RefCell&lt;T&gt;&gt;</span> to make it reference counted, though that just delays the borrow checker to later when we <span>borrow</span>/<span>borrow_mut</span> the contents. Did the Mayans have a way to <i>truly blend</i> the two approaches, like hinted on the walls of the Mayan <a href="https://www.livescience.com/maya-kingdom-discovered-in-mexico.html">Sak Tz'i' tablets</a>? <a href="#note11" data-noteid="11">11</a>
</p>

</section>
<section>
<p>
Some ancient writings also describe a way to make fast languages that are not only safe but also <i>correct</i> in a way that no languages are today <a href="#note12" data-noteid="12">12</a>, functional languages that use neither GC nor RC under the hood, <a href="#note13" data-noteid="13">13</a> and ways we can have unbounded reference counted objects <i>without a count integer</i>. <a href="#note14" data-noteid="14">14</a> How did they do all this?
</p>

</section>
<section>
<p>
This is why we were so excited to find this tome. Perhaps it had the answers!
</p>

</section>

      </div>
  
<div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
By "garbage collection", we're referring to tracing garbage collection.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
With good use of weak references, one can avoid the leaks.
</p>

</section>
</div>
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
"Inline data" means we can have a struct's memory live on the stack, or inside another struct's memory, or directly in an array next to the other arrays' elements' memory. This is the default in C, and impossible in e.g. Javascript.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
Luckily in Rust we can work around this limitation with reference counting!
</p>

</section>
</div>
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
Below I talk about how we can use regions to blend borrowing and reference counting to get the benefits of both worlds.
</p>

</section>
</div>
<div id="note12" data-noteid="12">
<p><span>12</span></p><section>
<p>
Except for <a href="https://borretti.me/article/introducing-austral">Austral</a>! It's safe because of borrow checking, and correct because it adds linear types. More on this below.
</p>

</section>
</div>
<div id="note13" data-noteid="13">
<p><span>13</span></p><section>
<p>
This is referring to Kindelia's <a href="https://github.com/HigherOrderCO/HVM">HVM</a> project!
</p>

</section>
</div>
<div id="note14" data-noteid="14">
<p><span>14</span></p><section>
<p>
See "Linear reference counting" below.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="impossibly-prophetic">
 Impossibly Prophetic</h2>
<p>
As I deciphered the first few pages, I was shocked to find that it was referencing <i>things that hadn't happened yet</i>.
</p>

</section>
<section>
<p>
It was referencing to elucent's <a href="https://degaz.io/blog/632020/post.html">Basil</a> language, Fernando's <a href="https://borretti.me/article/introducing-austral">Austral</a>, and Marco's <a href="http://forty2.is/">Forty2</a> language... and yet carbon dating tells us that the book is hundreds of years old!
</p>

</section>
<section>
<p>
Somehow, the Mayans were looking <i>forward in time</i> to techniques that were invented by people alive <i>today</i>. So maybe the Mayans were just time-traveling collectors, and this tome contains techniques from the recent past...
</p>
<p>
...and also the recent future. There's an entire half of this tome that seems to build on strange higher concepts that don't exist in our world yet. <a href="#note15" data-noteid="15">15</a> Other pages seem to mention laws we haven't yet discovered. <a href="#note16" data-noteid="16">16</a>
</p>

</section>

      </div>
  
<div>
    
<div id="note15" data-noteid="15">
<p><span>15</span></p><section>
<p>
Almost as if their CPU designs were slightly different than our own, in a key way that unlocked more possibilities. I'm still scratching my head on this one.
</p>

</section>
</div>
<div id="note16" data-noteid="16">
<p><span>16</span></p><section>
<p>
And there's one technique that I've tried to re-engineer thirty one (!) times without success: Hybrid-Generational Memory, one of my most elusive goals. I've gotten close by combining regions and generational references, but not in the automatic way that the Mayans seem to describe. Perhaps one of you can solve the rest of this puzzle!
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<h2 id="the-list">
 The List</h2>
<p>
To keep this post short, <a href="#note17" data-noteid="17">17</a> I'll assume the reader knows the basics of reference counting, (tracing) garbage collection, and knows how borrow checking works at a high level.
</p>
<p>
Even so, this is a <i>very</i> dense, compact overview of each technique, mainly meant as a starting point for further reading.
</p>
<p>
<b>Don't worry, I'll be posting many follow-up posts</b> (<a href="https://verdagon.dev/rss.xml">RSS</a>, <a href="https://reddit.com/r/vale">subreddit</a>) <b>that describe each one much more clearly and how it fits into the larger puzzle.</b> <a href="#note18" data-noteid="18">18</a>
</p>
<p>
Afterward, I'll also talk about the interesting gaps in the puzzle, and the hints that might lead to discovery there.
</p>
<p>
Without further ado, here's the list!
</p>

</section>
  
<div>
    
<div id="note17" data-noteid="17">
<p><span>17</span></p><section>
<p>
Because I've wasted all this space with the dramatic buildup, my bad!
</p>

</section>
</div>
<div id="note18" data-noteid="18">
<p><span>18</span></p><section>
<p>
I unfortunately can't give a timeline on this though, my health is a bit unstable lately.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>1: Move-only programming</b> was the most surprising one to me. In this, every object can only be known to one variable (or field or array element), and that one "owner" can give it up to transfer it to another variable, field, array element, or function parameter or return. In Java terms, only one reference can point to an object at any given time.
</p>
<p>
Some of you may recognize these as <a href="https://en.wikipedia.org/wiki/Substructural_type_system#Affine_types">affine types</a> (and also kind of <a href="https://en.wikipedia.org/wiki/Substructural_type_system#Linear_types">linear types</a>), but will be surprised to learn that we can <a href="https://verdagon.dev/blog/linear-types-borrowing">write entire programs</a> like this, without making any more references to any objects, as long as we're willing to go through some acrobatics. <a href="#note19" data-noteid="19">19</a>
</p>
<p>
Various languages build on this with different mechanisms: Rust adds <a href="https://doc.rust-lang.org/rust-by-example/scope/borrow.html">borrow checking</a>, Austral adds borrow checking and <a href="https://austral-lang.org/linear-types">linear typing</a>, and Vale has the <a href="https://vale.dev/linear-aliasing-model">linear-aliasing model</a>. I suspect the tome is hinting at other possible blends too. <a href="#note20" data-noteid="20">20</a>
</p>

</section>
  
<div>
    
<div id="note19" data-noteid="19">
<p><span>19</span></p><section>
<p>
For example, you can't just point to something that is currently in a hash map... you first have to temporarily remove it so you can read it.
</p>

</section>
</div>
<div id="note20" data-noteid="20">
<p><span>20</span></p><section>
<p>
Specifically, if we can add Pony-style <span>val</span> to it, we might get an interesting result.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>2: Reference counting</b> is fairly mainstream. Some will be surprised to learn that it can coexist with tracing GC (<a href="https://devguide.python.org/internals/garbage-collector/index.html">like in Python</a> and <a href="https://nim-lang.org/blog/2020/10/15/introduction-to-arc-orc-in-nim.html">Nim</a>), and we also learned that there's a <a href="https://courses.cs.washington.edu/courses/cse590p/05au/p50-bacon.pdf">whole spectrum</a> between the two.
</p>
<p>
And as it turns out, reference counting can be <a href="https://github.com/Verdagon/RegionsRCCellularAutomataBenchmark/blob/main/README.md">blended with immutable region borrowing</a> to greatly reduce its cache misses and make it data-race safe, something no language has done yet. <a href="#note21" data-noteid="21">21</a> <a href="#note22" data-noteid="22">22</a>
</p>

</section>
  
<div>
    
<div id="note21" data-noteid="21">
<p><span>21</span></p><section>
<p>
I couldn't resist prototyping this, so the Vale compiler actually has a flag that switches Vale from generational references to RC so we can see this in action. See <a href="https://github.com/Verdagon/RegionsRCCellularAutomataBenchmark/blob/main/README.md">this experimental repo</a> for more.
</p>

</section>
</div>
<div id="note22" data-noteid="22">
<p><span>22</span></p><section>
<p>
<a href="https://nim-lang.org/">Nim</a> could theoretically do this, but alas, I was unable to convince Araq that it was possible. I also thought for a while that Rust could do this, but it's unfortunately foiled by the <span>RefCell</span> escape hatch.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>3: Borrow checking</b> lets our code be as fast as C and even almost as safe as Haskell. <a href="#note23" data-noteid="23">23</a> It works by ensuring that we only use pointers temporarily (in certain scopes) and in restricted ways to ensure others won't change the data that you're reading.
</p>
<p>
<a href="https://borretti.me/article/introducing-austral">Austral</a> takes it a step further: it's not only safe, but also <i>correct</i> by adding <a href="https://en.wikipedia.org/wiki/Safety_and_liveness_properties">liveness</a> via linear types which any code can use to ensure that some future action will happen. This is a pattern I call <a href="https://verdagon.dev/blog/higher-raii-7drl">Higher RAII</a> in Vale, but I think it naturally occurs in any language with linear types. <a href="#note24" data-noteid="24">24</a>
</p>
<p>
If you're curious for more, check out this <a href="https://www.youtube.com/watch?v=UavYVf0UEoc">Developer Voices episode</a> where Kris Jenkins interviewed me on linear types and higher RAII.
</p>

</section>
  
<div>
    
<div id="note23" data-noteid="23">
<p><span>23</span></p><section>
<p>
I say almost because Rust's single-ownership nature sometimes introduces failure conditions that wouldn't exist in Haskell.
</p>

</section>
</div>
<div id="note24" data-noteid="24">
<p><span>24</span></p><section>
<p>
Haskell can have linear types too! I foresee a future where functional programming and linear types are actually the best choice for safety-critical systems that can handle nondeterministic GC pauses. And the Mayans mention a new way that we can nearly eliminate those pauses...
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>4: Arena-only programming</b> is where we never use malloc or free, and <a href="https://www.rfleury.com/p/untangling-lifetimes-the-arena-allocator">always use arenas instead</a>, even for function returns. This is a familiar paradigm to users of C, Ada, Zig, and especially Odin which has a way to <a href="https://odin-lang.org/docs/overview/#implicit-context-system">automatically decouple code from allocator strategy</a>.
</p>
<p>
As described, this is more of a memory <i>management</i> approach than a memory <i>safety</i> approach. However, <a href="https://en.wikipedia.org/wiki/Cyclone_(programming_language">Cyclone</a> and <a href="https://en.wikipedia.org/wiki/SPARK_(programming_language">Ada/SPARK</a> show us that we can track which pointers are pointing into which arenas, to prevent any use-after-frees. <a href="https://github.com/microsoft/verona">Verona</a> shows us that by combining arenas with regions (described below), we can take things even further. <a href="#note25" data-noteid="25">25</a> 
</p>

</section>
  
<div id="note25" data-noteid="25">
<p><span>25</span></p><section>
<p>
We could also combine arena-only programming with generational references, regions, constraint references, or MMM++.
</p>

</section>
</div>

    </div>
    <div>
      <section>
<p>
<b>5: Ada/SPARK</b> has a mechanism where a pointer cannot point to an object that is more deeply scoped than itself. If you imagine the stack growing to the right, <a href="#note26" data-noteid="26">26</a> pointers are only allowed to point left. If you really stretch your brain, this has some similarities to mutable value semantics or borrow checking. <a href="#note27" data-noteid="27">27</a>
</p>

</section>
  
<div id="note26" data-noteid="26">
<p><span>26</span></p><section>
<p>
"But Evan, stacks grow down!" <a href="https://memedrop.io/meme/ZRy5yVV68X7m">Listen here</a>, no it doesn't, nobody knows the orientation of the RAM chip in the computer.
</p>

</section>
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
<b>6: Regions</b> are surprisingly flexible and powerful. I first learned about them from <a href="https://www.ponylang.io/">Pony</a>'s <a href="https://tutorial.ponylang.io/reference-capabilities/guarantees.html#mutable-reference-capabilities">iso</a> keyword: an <span>iso</span>'d object (and its contents) are only reachable from your pointer; nobody else points at that object or anything the object contains. In other words, it establishes an isolated subgraph of objects, and you hold the only reference to the entire thing.
</p>
<p>
<a href="https://www.cs.drexel.edu/~csg63/papers/oopsla12.pdf">Colin Gordon</a> showed how we can "temporarily open" an isolated subgraph for a given scope, and afterward it would still be properly isolated.
</p>
<p>
I later wrote <a href="https://verdagon.dev/blog/zero-cost-refs-regions">an article</a> about how we could temporarily open an isolated subgraph and see it as an <b>immutable region</b> so to speak <a href="#note28" data-noteid="28">28</a> to <i>completely eliminate</i> the memory safety cost for references pointing into that immutable region.
</p>
<p>
In that article I also explored how we can use a <span>pure</span> function to <b>temporarily reinterpret all pre-existing regions as immutable</b>, removing a vast amount of overhead. In 2023, we <a href="https://verdagon.dev/blog/first-regions-prototype">completed the first prototype</a> showing this in action for generational references. It also <a href="https://github.com/Verdagon/RegionsRCCellularAutomataBenchmark/tree/main">helps reference counting approaches</a> too.
</p>
<p>
Other languages such as <a href="https://forty2.is/">Forty2</a> and <a href="https://github.com/microsoft/verona">Verona</a> are going all-in on regions, and you'll see why further below.
</p>

</section>
<section>
<p>
I'm thinking about separating "regions" into two separate simpler concepts in my writing: <b>regions</b> (a set of objects that can freely point to each other) and <b>region views</b> (a mutable or immutable view of a region). Region views are really what unlock regions' potential, I think. If anyone has opinions, <a href="https://verdagon.dev/grimoire/verdagon_epsa@verdagon.dev">drop me an email</a>!
</p>

</section>

      </div>
  
<div id="note28" data-noteid="28">
<p><span>28</span></p><section>
<p>
"Explicit locking" in the linked article.
</p>

</section>
</div>

    </div>
    <div>
      <section>
<p>
<b>7: Stack arenas</b> is an approach that's spiritually similar to arena-only programming, but it's automatic and does it for every stack frame. Elucent's <a href="https://degaz.io/blog/632020/post.html">Basil</a> used to do this! It wasn't efficient, but the Mayans mention something about combining it with other techniques to make it a <i>lot</i> faster. I can kind of see what they mean <a href="#note29" data-noteid="29">29</a> but I haven't seen anyone try it yet.
</p>

</section>
  
<div id="note29" data-noteid="29">
<p><span>29</span></p><section>
<p>
I <i>think</i> it's compatible with reference counting, and I'm fairly certain it's compatible with linear types.
</p>

</section>
</div>

    </div>
    <section>
<p>
<b>8: <a href="https://verdagon.dev/blog/generational-references">Generational References</a></b> is a technique that prevents use-after-frees by telling us whether a pointer is pointing at a valid object, by comparing a pointer's accompanying "remembered" generation number to the "current" generation number living in the object it's pointing at. We increment an object's generation number whenever we want to destroy it, preventing any future accesses. This approach is made much faster by <a href="https://verdagon.dev/blog/zero-cost-borrowing-regions-overview">regions</a>: we never have to do that comparison if the object is in a temporarily immutable region, which we can establish with a <span>pure</span> function or block.
</p>
<p>
I hope other languages start using the generational references approach. There are a couple attempts in Rust (<a href="https://github.com/Kile-Asmussen/genref">here</a> and <a href="https://docs.rs/generational-box/latest/generational_box/">here</a>), but the language's rules prevent them from doing the faster variant described below.
</p>

</section>
    <div>
      <section>
<p>
<b>9: Random Generational References</b> is a faster variant that lets us have "inline data", in other words it lets us put structs on the stack and inside arrays or other structs. This is similar to <a href="https://source.android.com/docs/security/test/memory-safety/arm-mte">memory tagging</a>, but much more reliable because of a wider tag (64 bits instead of 4) and when paired with perfect determinism, <a href="#note30" data-noteid="30">30</a> more secure. <a href="#note31" data-noteid="31">31</a>
</p>
<p>
This improvement is exciting to me because it lets the generation live right next to the object, and lets both live anywhere: on the stack, in an array, or inline inside another object. This makes it much faster in theory, because it means a program will incur less cache misses.
</p>
<p>
One can even blend this with <a href="https://verdagon.dev/blog/linear-types-borrowing">a technique that can reduce generation checks to zero</a> where desired and regions for eliminating them everywhere else.
</p>
<p>
I think this blend has a lot of potential, because it has the strengths of C++ (architectural simplicity <a href="#note32" data-noteid="32">32</a>) and Rust (memory safety) while being simpler and easier than both.
</p>
<p>
But I'm a bit biased of course, as any human would be about their own idea!
</p>

</section>
  
<div>
    
<div id="note30" data-noteid="30">
<p><span>30</span></p><section>
<p>
Perfect determinism is where the language doesn't introduce any features (e.g. reading uninitialized memory or casting pointers to integers) that could let nondeterminism leak into the program's logic. It's required for <a href="https://verdagon.dev/blog/perfect-replayability-prototyped">perfect replayability</a>
</p>

</section>
</div>
<div id="note31" data-noteid="31">
<p><span>31</span></p><section>
<p>
Specifically, it means that we can defend against side-channel attacks at the program's architectural level, by never letting any nondeterminism leak into any untrusted code.
</p>

</section>
</div>
<div id="note32" data-noteid="32">
<p><span>32</span></p><section>
<p>
This means we can organize our program how we want, without interference from upwardly viral constraints (like async/await or borrow checking) or immutability concerns (like in functional programming). A litmus test for a language's architectural simplicity is whether you can implement a basic observer. Languages that don't have it will tend to have less stable APIs and a lot more refactoring.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>10: MMM++</b> <a href="#note33" data-noteid="33">33</a> is where objects are allocated from global arrays, and slots in those arrays are released and reused for other objects of the same type, thus avoiding use-after-free's normal memory unsafety problems. See <a href="https://verdagon.dev/blog/myth-zero-overhead-memory-safety">Arrrlang</a> for a simple theoretical example, and one usually adds <a href="https://verdagon.dev/blog/when-to-use-memory-safe-part-1#the-safer-way-to-use-mmm-languages">other techniques too</a> to make a real paradigm out of it. This is similar to how a lot of embedded, safety-critical, and real-time software works today, <a href="#note34" data-noteid="34">34</a> though no language comprehensively enforces it yet.
</p>

</section>
  
<div>
    
<div id="note33" data-noteid="33">
<p><span>33</span></p><section>
<p>
I'm sure this has a better name, someone let me know!
</p>

</section>
</div>
<div id="note34" data-noteid="34">
<p><span>34</span></p><section>
<p>
Including many servers, databases, and games. For example, <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/main/docs/TIGER_STYLE.md#safety">TigerBeetleDB</a> has a similar set of rules.
</p>

</section>
</div>

        </div>

    </div>
    <section>
<p>
<b>11: Tracing garbage collection</b> is familiar to all of us, but there's a surprising twist: there's a secret way to make a garbage collector without the stop-the-world pauses! <a href="https://www.ponylang.io/">Pony</a> does this: by separating each actor into its own little world, each actor can do its own garbage collection without stopping the other ones. Its <a href="https://tutorial.ponylang.io/appendices/garbage-collection.html">ORCA</a> mechanism then enables sharing data between the worlds via an interesting reference counting message passing mechanism.
</p>
<p>
<a href="https://github.com/microsoft/verona">Verona</a> then takes this a step further by adding regions, giving the user more fine-grained control over when and where garbage collection might happen, and lets them use a regular bump allocator for a region instead if they wish.
</p>
<p>
If Verona or a new language allowed us to set the maximum memory for a GC'd region, that would make the entire approach <i>completely deterministic</i>, solving the biggest problem for garbage collection (in my opinion).
</p>
<p>
Don't tell anyone I said this, but I believe that 30 years from now, this blend is going to be the most widely used paradigm for servers.
</p>

</section>
    <div>
      <section>
<p>
<b>12: Interaction nets</b> are a <i>very</i> fast way to manage purely immutable data <i>without</i> garbage collection or reference counting. The <a href="https://github.com/HigherOrderCO/HVM">HVM</a> runtime implements this for Haskell. HVM starts with affine types (like move-only programming), but then adds an extremely efficient lazy <span>.clone()</span> primitive, so it can strategically clone objects instead of referencing them. Check out its <a href="https://github.com/HigherOrderCO/HVM/blob/master/guide/HOW.md">guide</a> to learn more! <a href="#note35" data-noteid="35">35</a>
</p>

</section>
  
<div id="note35" data-noteid="35">
<p><span>35</span></p><section>
<p>
And if someone has a better explanation, please send it to me! I don't understand interaction nets that well. I <i>think</i> it's actually a blend of automatic borrowing and cloning, but the guide says it's not really borrowing, so I'm not sure.
</p>

</section>
</div>

    </div>
    <section>
<p>
<b>13: Constraint references</b> is a blend of reference counting and single ownership (in the C++ sense, unrelated to borrow checking). In this approach, every object has a single owner, doesn't necessarily need to be on the heap, and has a counter for all references to it. When we try to destroy the object, we just assert that there are no other references to this object.
</p>
<p>
This is used surprisingly often. Some <a href="https://discord.com/channels/402956206529970177/402956206529970180/451828861861101569">game developers</a> have been using this for a long time, and it can be used as the memory safety model for an entire language like in <a href="https://web.archive.org/web/20220111001720/https://researcher.watson.ibm.com/researcher/files/us-bacon/Dingle07Ownership.pdf">Gel</a>. It supports a lot more patterns than borrow checking (intrusive data structures, graphs, observers, back-references, dependency references, callbacks, delegates, many forms of RAII, etc).
</p>
<p>
However, this checking is at run-time. Halting in release mode is often undesirable, so this technique shines the most when it's very targeted or when we can fall back to a different strategy in release mode.
</p>

</section>
    <div>
      <section>
<p>
<b>14: Linear reference counting</b> is an elusive concept, where we can completely eliminate the counter integer, and do all of the reference counting at compile time. No language can do this today, but there might be a way to get close with linear types. <a href="#note36" data-noteid="36">36</a> Basically, we have two types of linear reference:
</p>
<ul>
<li>
A "tine" reference remembers (in its type, at compile-time) L, the number of forks to get from the original value to here.
</li>
<li>
A "fork" reference holds the original value (or a tine reference <a href="#note37" data-noteid="37">37</a>), and remembers L and also N, the number of L+1 tine references created at the same time as this fork reference. Reclaiming the contents requires destroying this and all (N) of the L+1 tine references.
</li>
</ul>
<p>
I don't expect anyone to understand that rushed explanation, but I hope to write an article soon on this! <a href="#note38" data-noteid="38">38</a>
</p>
<p>
I'm not actually sure what kind of architectural restrictions it might impose, how situational it is, or if it even works at all. It's just something I came up with--I mean uh, <i>the grimoire</i> mentions--as a hypothetical avenue to explore.
</p>

</section>
  
<div>
    
<div id="note36" data-noteid="36">
<p><span>36</span></p><section>
<p>
Matthieu's <a href="https://github.com/matthieu-m/static-rc">static-rc</a> crate gets pretty close to this, but without linear types in Rust, it has to leak under certain conditions.
</p>

</section>
</div>
<div id="note37" data-noteid="37">
<p><span>37</span></p><section>
<p>
This is another difference between this idea and static-rc crate, I believe this will allow us to "borrow the borrow references" in objects, without lifetimes, rather than just on the stack.
</p>

</section>
</div>
<div id="note38" data-noteid="38">
<p><span>38</span></p><section>
<p>
I also talked about it a bit <a href="https://discord.com/channels/398263331808346123/734119020613075052/1135196844360736798">here</a> and <a href="https://discord.com/channels/398263331808346123/734119020613075052/1137411293310099546">here</a> and <a href="https://discord.com/channels/398263331808346123/734819934760075264/1141854334171222098">here</a>. If someone knows how to make better publicly-accessible discord logs, let me know!
</p>

</section>
</div>

        </div>

    </div>
    <section>
<p>
<b>15: Mutable value semantics</b> is a very interesting approach. Imagine a Java or Swift where every object has exactly one reference pointing to it at any given time (similar to move-only programming) but that reference can be lent out to a function call. It's like a Rust with no shared references (<span>&amp;</span>), only unique references (<span>&amp;mut</span>) which can't be stored in structs. It's simple, fast, and powerful, though we may have to <span>.clone()</span> more often than even Rust programs.
</p>
<p>
<a href="https://www.hylo-lang.org/">Hylo</a> uses mutable value semantics, with extra ergonomics like <span>subscript</span> on top to make it easier to work with. It's a very promising sweet spot on the performance vs. simplicity spectrum.
</p>

</section>
    <div>
      <section>
<p>
<b>16: <a href="https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/">CHERI</a></b> is a project that's attempting to make hardware and a compiler that can run languages like C in a memory-safe way. In CHERI, every 64-bit pointer also comes with a 64-bit "capability" which expresses what can be done with that pointer, to achieve spatial memory safety. <a href="https://ieeexplore.ieee.org/document/9152640">Cornucopia</a> adds temporal memory safety to that with special allocators that don't reuse memory in a page until it's empty and all of the existing capabilities have been revoked <a href="#note39" data-noteid="39">39</a> via an application-wide memory sweep done concurrently in the background.
</p>
<p>
If a new language used a system like this plus some techniques to prevent use-after-free on the stack, it could have a brand new memory safety model nobody's seen before.
</p>

</section>
  
<div id="note39" data-noteid="39">
<p><span>39</span></p><section>
<p>
This is an important memory safety concept: Memory unsafety comes not from use-after-free, but <i>use-after-reuse</i>. In fact, even that's too loose; memory unsafety comes from "use after shape change", which I'll explain later in the grimoire.
</p>

</section>
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
<b>17: Neverfree</b> doesn't really count, but I'll mention it as a bonus item just for fun. Basically, just don't call <span>free</span>! If you never <span>free</span> memory, you can't use-after-free, which instantly solves the hardest part of memory safety. <a href="#note40" data-noteid="40">40</a> The idea is from this famous <a href="https://devblogs.microsoft.com/oldnewthing/20180228-00/?p=98125">email conversation</a>:
</p>
<p>
Norman Cohen said:
</p>
<p>
The only programs I know of with deliberate memory leaks are those whose executions are short enough, and whose target machines have enough virtual memory space, that running out of memory is not a concern. (This class of programs includes many student programming exercises and some simple applets and utilities; it includes few if any embedded or safety-critical programs.)
</p>
<p>
Kent Mitchell replied:
</p>
<p>
I was once working with a customer who was producing on-board software for a missile. In my analysis of the code, I pointed out that they had a number of problems with storage leaks. Imagine my surprise when the customers chief software engineer said "Of course it leaks". He went on to point out that they had calculated the amount of memory the application would leak in the total possible flight time for the missile and then doubled that number. They added this much additional memory to the hardware to "support" the leaks. Since the missile will explode when it hits its target or at the end of its flight, the ultimate in garbage collection is performed without programmer intervention.
</p>
<p>
It kind of makes sense in a way. If you have a program that uses all the memory all the way until the end (like <span>sort</span>), why not skip the expensive <span>free</span>s and let the OS clean it up when the process exits? You can't use-after-free if you never <span>free</span>!
</p>

</section>
<section>
<p>
Wait a minute, this list goes to 17, yet the intro only mentions 14! I actually did that because a couple might overlap <a href="#note41" data-noteid="41">41</a> and a couple of them are half-approaches <a href="#note42" data-noteid="42">42</a>, and that last one is just here for fun. Besides, as I learn more approaches and add them to the list, the title will get more and more out of date anyway.
</p>

</section>

      </div>
  
<div>
    
<div id="note40" data-noteid="40">
<p><span>40</span></p><section>
<p>
One might need to also add some bounds checking and a few other measures, but it's a start!
</p>

</section>
</div>
<div id="note41" data-noteid="41">
<p><span>41</span></p><section>
<p>
 Ada/SPARK might be a blend of MMM++ and arena-only programming, perhaps. I haven't used Ada/SPARK, so let me know!
</p>

</section>
</div>
<div id="note42" data-noteid="42">
<p><span>42</span></p><section>
<p>
 It could be said that regions on its own isn't really a memory safety approach, and it could be said that arena-only programming is just a memory <i>management</i> technique. But hey, when you put those two halves together you get <a href="https://github.com/microsoft/verona">Verona</a>'s memory safety approach, so together they probably count as one.
</p>


</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="what-do-we-do-with-this-avalanche-of-knowledge">
 What do we do with this avalanche of knowledge?</h2>
<p>
Perhaps someone, after reading this article, will go forth and <b>design a new memory safety blend!</b> It's not impossible, I even used this grimoire to <a href="https://verdagon.dev/blog/vale-memory-safe-cpp">make a theoretical blend for C++</a>.
</p>

</section>
<section>
<p>
The world needs more memory safety blends and techniques! Especially ones that let us have better architectures, more simplicity, and less constraints. And who knows, searching for new techniques and blends might lead to interesting spinoff features, like Vale's <a href="https://verdagon.dev/blog/perfect-replayability-prototyped">perfect replayability</a> and <a href="https://verdagon.dev/blog/seamless-fearless-structured-concurrency">concurrency without data-coloring</a>.
</p>

</section>
<section>
<p>
We often fall into a mental trap where we optimistically believe that we've solved everything there is to solve, and pessimistically believe there's nothing left to discover. That mental trap is a mind-killer, because we can't discover new things if we aren't open to their existence.
</p>
<p>
In fact, one of my favorite cognitive science tricks is to convince myself that there is a better solution and it's <i>just barely</i> within reach if I just give it a little more thought. For some reason, that removes the mental barriers and lets one truly, fully explore. <a href="#note43" data-noteid="43">43</a>
</p>

</section>
<section>
<p>
If someone were to ask me why we should keep looking, I'd show them the unique strengths of each paradigm:
</p>
<ul>
<li>
RC's weak pointers let us easily know <a href="#note44" data-noteid="44">44</a> when another object's logical lifetime has ended, which is a surprisingly common need when you're looking out for it.
</li>
<li>
C and C++ let us use intrusive data structures, like no other language can. <a href="#note45" data-noteid="45">45</a>
</li>
<li>
Austral and Vale's linear types allow for <a href="https://verdagon.dev/blog/higher-raii-7drl">Higher RAII</a>, which lets compilers prevent a lot of logic problems.
</li>
<li>
GC is the easiest, and depending on one's definitions, the safest too. <a href="#note46" data-noteid="46">46</a>
</li>
</ul>
<p>
...and then I'd show them the whole list of approaches, and how many ways there are to blend them together.
</p>

</section>
<section>
<p>
With that in mind, it's pretty clear that memory safety is truly a wide-open world, waiting to be explored!
</p>

</section>

      </div>
  
<div>
    
<div id="note43" data-noteid="43">
<p><span>43</span></p><section>
<p>
This is a great technique in algorithm interviews, by the way.
</p>

</section>
</div>
<div id="note44" data-noteid="44">
<p><span>44</span></p><section>
<p>
In other languages, we need some sort of central tracking data structure to pull this off.
</p>

</section>
</div>
<div id="note45" data-noteid="45">
<p><span>45</span></p><section>
<p>
GC'd languages generally don't allow long-lived references to inline data, and Rust's borrow checker <a href="https://lwn.net/Articles/907876/">prevents intrusive data structures</a>
</p>

</section>
</div>
<div id="note46" data-noteid="46">
<p><span>46</span></p><section>
<p>
 It's a tricky topic. When one thinks not just about memory safety but about safety in general, a null-safe functional GC'd language has an edge over other approaches, even over borrow checking which forces long-term-referrable objects into central collections which have their own potential edge cases.

</p>

</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="more-in-the-grimoire">
 More in the Grimoire</h2>
<p>
The above list is not complete, of course. There are some half-deciphered hints and building blocks in the grimoire that might be able to assist memory safety models in new ways.
</p>

</section>
<section>
<p>
Beware: We don't know which of these techniques actually help memory safety, and which summon ancient demons. Proceed at your own risk!
</p>

</section>
<section>
<p>
Here's just a handful:
</p>
<ul>
<li>
<b><a href="https://engineering.backtrace.io/2021-08-04-slitter-a-slab-allocator-that-trusts-but-verifies/">Type stability</a></b> shows us that use-after-free isn't the enemy, but rather a simplistic approximation of the enemy. The real memory safety problems arise when we access some memory after we've released and <i>reused it for something of a different type.</i> <a href="#note47" data-noteid="47">47</a>
</li>
<li>
<b>Final references</b> (like in Java) can help a lot in designing memory safety models. I won't explain too much here, but <a href="https://verdagon.dev/grimoire/verdagon_epsa@verdagon.dev">email</a> or discord me (Verdagon) and I can explain there. I dare not write publicly about what these unlock for memory safety, for what it would do to the world.
</li>
<li>
<b>Unique References</b>, in other words, guaranteeing that you have the only usable reference to an object, has been the key breakthrough in more approaches than I can count, including borrow checking, mutable value semantics, move-only programming, etc. There are even techniques that can make any object temporarily unique (like <a href="https://news.ycombinator.com/item?id=15294334">how Swift's inout works</a>, or how in generational references we can just temporarily change the generation). <a href="#note48" data-noteid="48">48</a>
</li>
<li>
<b>Change detectors</b> is a mechanism that will track at run-time whether something's been changed. Java collections <a href="https://stackoverflow.com/a/34629665/1424454">use a modCount</a> to prevent modifying while iterating, and one could conceivably use this to assist in memory safety as well.
</li>
<li>
<b>Check-on-set</b> is a pattern where we check at run-time if we're allowed to modify an object in a certain way. The best example of this how we can <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze">freeze</a> a Javascript object, and whenever we modify an object, the runtime will assert it's not frozen. Anything that can guarantee an object immutable could be used for a memory safety approach.
</li>
<li>
<b>Thread isolation</b> is where we guarantee that an object is only visible to one thread at a given time. This property has helped enable borrow checking, generational references, Vale's immutable region borrowing, and faster forms of reference counting. It's likely important to other potential memory safety approaches.
</li>
<li>
<b>Page Headers</b> are where an allocator can strategically put metadata about an object at the top of its 4096-byte page.
</li>
<li>
<b>Fat pointers</b> is where some other data always accompanies a pointer. The biggest example of this is Rust's <a href="https://stackoverflow.com/questions/57754901/what-is-a-fat-pointer">trait references</a> and Vale uses it for its <a href="https://verdagon.dev/blog/generational-references">generational references</a> memory safety approach.
</li>
<li>
<b><a href="https://www.linaro.org/blog/top-byte-ignore-for-fun-and-memory-savings/">Top-byte ignore</a></b> refers to how some CPUs ignore the top byte of any particular pointer, so you can conveniently put anything you want there. You can even simulate top-byte-ignore on other systems by manually masking that byte off before dereferencing. This can be used to e.g. store how far the reference count integer is, so that you can point to the interior of a reference counted object. There are more arcane ways to use bits in the middle and end too. <a href="#note49" data-noteid="49">49</a>
</li>
<li>
And many more, hopefully in upcoming articles!
</li>
</ul>

</section>
<section>
<p>
You would be surprised how many little tricks can be used to complete or assist new memory safety models.
</p>

</section>
<section>
<p>
If you know of any more memory safety techniques, or want to see in-progress decipherings, then come on over to the #grimoire channel in the <a href="https://discord.com/invite/SNB8yGH">Vale discord</a>.
</p>

</section>

      </div>
  
<div>
    
<div id="note47" data-noteid="47">
<p><span>47</span></p><section>
<p>
"Shape stability" takes that a step further: we can reuse e.g. an integer's memory for a float and still not trigger memory unsafety, so really the problem is when we confuse a pointer for an integer or vice versa.
</p>

</section>
</div>
<div id="note48" data-noteid="48">
<p><span>48</span></p><section>
<p>
 Easter egg note!
</p>
<p>
<a href="https://en.wikipedia.org/wiki/William_Windsor_%28goat%29">William "Billy" Windsor I</a> is a <a href="https://en.wikipedia.org/wiki/Cashmere_goat">cashmere goat</a> who served as lance corporal in the British Army's <a href="https://en.wikipedia.org/wiki/Royal_Welsh">Royal Welsh</a> 1st Battalion from 2001 until 2009.
</p>
<p>
He was demoted to rank <a href="https://en.wikipedia.org/wiki/Fusilier">fusilier</a> for three months for inappropriate behaviour during the 2006 <a href="https://en.wikipedia.org/wiki/Queen%27s_Official_Birthday">Queen's Official Birthday</a> celebrations while on active duty with the battalion on Cyprus.
</p>
<p>
If you read this note, mention "that one lance corporal goat" anywhere on HN or reddit! <a href="https://youtu.be/-UBgNREvlIo">Nobody will believe you</a>.
</p>
<p>
(Cheers to <a href="https://news.ycombinator.com/item?id=36691658">cbsmith</a>, <a href="https://news.ycombinator.com/item?id=36692089">kubanczyk</a>, <a href="https://www.reddit.com/r/programming/comments/14wu830/comment/jrklcry/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">TheGoldenMinion</a>, <a href="https://news.ycombinator.com/item?id=36691564">lovich</a>, <a href="https://www.reddit.com/r/programming/comments/14wu830/comment/jrkmjiw/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">padraig_oh</a>, and <a href="https://news.ycombinator.com/item?id=36691737">leksak</a> for the <a href="https://verdagon.dev/blog/easter-egg-notes">last one</a>!)

</p>

</section>
</div>
<div id="note49" data-noteid="49">
<p><span>49</span></p><section>
<p>
We can also use the lower bits if we know the alignment of the data we're pointing to. We might even be able to use the bits in the middle by manually specifying the address <span>mmap</span> should give us.
</p>

</section>
</div>

        </div>

    </div>
    <div>
  
<section>
<h2 id="thats-all">
 That's all!</h2>
<p>
I hope you enjoyed this article! It represents my findings after a decade of searching and designing, so I hope it helps a lot of people out there.
</p>

</section>
<section>
<p>
In the next post, I'll talk about how we can blend reference counting with some of the above techniques to drastically reduce their overhead and add fearless concurrency, so keep an eye out on our <a href="https://verdagon.dev/rss.xml">RSS feed</a>, <a href="https://twitter.com/vale_pl">twitter</a>, <a href="https://discord.gg/SNB8yGH">discord server</a>, or <a href="https://reddit.com/r/vale">subreddit</a>!
</p>

</section>
<section>
<p>
Donations and sponsorships for Vale are currently paused, but if you like these articles, please <a href="https://www.doc.govt.nz/kakapo-donate">Donate to KƒÅkƒÅp≈ç Recovery</a> and let me know. I love those birds, let's save them!
</p>

</section>
<section>
<p>
Cheers,
</p>
<p>
- Evan Ovadia
</p>


</section>

      </div>
    <section>
<h2 id="thank-you">
 Thank you!</h2>
<p>
I want to give a huge thanks to <a href="https://github.com/aweagel">Arthur Weagel</a>, <a href="https://github.com/KirilMihaylov">Kiril Mihaylov</a>, <a href="https://github.com/radekm">Radek Miƒçek</a>, <a href="https://github.com/Geomitron">Geomitron</a>, <a href="https://github.com/chiuzon">Chiuzon</a>, <a href="https://github.com/soupertonic">Felix Scholz</a>, <a href="https://github.com/linkmonitor">Joseph Jaoudi</a>, <a href="https://github.com/lupuchard">Luke Puchner-Hardman</a>, <a href="https://github.com/tootoobeepbeep">Jonathan Zielinski</a>, <a href="https://github.com/albinkc">Albin Kocheril Chacko</a>, <a href="https://github.com/ezschemi">Enrico Zschemisch</a>, <a href="https://github.com/Svintooo">Svintooo</a>, <a href="https://github.com/tstack">Tim Stack</a>, <a href="https://github.com/kripken">Alon Zakai</a>, <a href="https://github.com/rovaughn">Alec Newman</a>, <a href="https://github.com/Shnatsel">Sergey Davidoff</a>, <a href="https://github.com/linuxy">Ian (linuxy)</a>, <a href="https://github.com/Ivo-Balbaert/">Ivo Balbaert</a>, <a href="https://github.com/pierrec">Pierre Curto</a>, <a href="https://github.com/loveJesus">Love Jesus</a>, <a href="https://github.com/jryans">J. Ryan Stinnett</a>, <a href="https://github.com/cdinu">Cristian Dinu</a>, and <a href="https://github.com/lasernoises">Florian Plattner</a> (plus a very generous anonymous donor!) for sponsoring Vale over all these years.
</p>
<p>
My recent medical troubles may have forced me to stop coding for a while and led me to pause donations and sponsorships, but your support all this time is still giving me spirit and strength. My recovery is going well (I'm able to write articles again!) so hopefully I'll be back to 100% soon!

</p>

</section>
    
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Stainless SDK Generator (200 pts)]]></title>
            <link>https://www.stainlessapi.com/blog/announcing-the-stainless-sdk-generator</link>
            <guid>40146505</guid>
            <pubDate>Wed, 24 Apr 2024 16:34:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stainlessapi.com/blog/announcing-the-stainless-sdk-generator">https://www.stainlessapi.com/blog/announcing-the-stainless-sdk-generator</a>, See on <a href="https://news.ycombinator.com/item?id=40146505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Stainless generates the official client libraries for OpenAI, Anthropic, Cloudflare, and more. Today, we‚Äôre making the Stainless SDK generator available to every developer with a REST API.</p><p>During our private beta, we‚Äôve been able to help millions of developers integrate faster and more reliably with the latest features of some of the world‚Äôs most powerful and exciting APIs.</p><p>The Stainless SDK generator accepts an OpenAPI specification and uses it to produce quality SDKs in multiple programming languages. As your API evolves, our automated generator continuously pushes changes, ensuring that your SDKs remain up-to-date‚Äîeven as you make <a href="https://app.stainlessapi.com/docs/guides/patch-custom-code" target="_blank">arbitrary custom edits</a> to the generated code.</p><p>Here‚Äôs a quick, real-world example of the code we can do for you, and how you configure it with Stainless:<br>‚Äç</p><div>



<pre><code>
import Cloudflare from "cloudflare";

async function main() {
  const cloudflare = new Cloudflare();
  const zone = await cloudflare.zones.create({
    account: { id: "xxx" },
    name: "example.com",
    type: "full",
  });
}
</code>
</pre>




<pre><code>
resources:
  zones:
    methods:
      create: post /v1/zones
</code>
</pre>

</div><p><em><br>See the source code for these endpoints in </em><a href="https://github.com/cloudflare/cloudflare-typescript/blob/54faa1bd35ae5f394e37e8ac7f75c36f738baff9/src/resources/zones/zones.ts#L27-L34" target="_blank"><em>TypeScript</em></a><em>, </em><a href="https://github.com/cloudflare/cloudflare-python/blob/77cd2adc0ea0e48fb7419dfe6d48a7a5af78f35c/src/cloudflare/resources/zones/zones.py#L129-L177" target="_blank"><em>Python</em></a><em>, and </em><a href="https://github.com/cloudflare/cloudflare-go/blob/21580812b4a3fb3f215ea1f539c2c14e2fa123bb/zones/zone.go#L50-L61" target="_blank"><em>Go</em></a><em>.</em><br></p><p>‚Äç</p><div><blockquote>‚ÄúThe decision to use Stainless has allowed us to move our focus from building the generation engine to instead building high-quality schemas to describe our services. <p>In the span of a few months, we have gone from inconsistent, manually maintained SDKs to automatically shipping over 1,000 endpoints across three language SDKs with hands-off updates.‚Äù</p><p><em>Jacob Bednarz, API Platform Tech Lead, Cloudflare (</em><a href="https://blog.cloudflare.com/lessons-from-building-an-automated-sdk-pipeline" target="blank"><em>see blog post</em></a><em>)</em></p></blockquote></div><p>‚Äç</p><h2><strong>Backstory: scaling SDKs at Stripe</strong></h2><p>From <a href="https://web.archive.org/web/20111213031731/https://stripe.com/" target="_blank">the very first day that stripe.com existed on the internet</a>, SDKs were a big part of the pitch to developers. Today, well over 90% of Stripe developers make well over 90% of requests to the Stripe API through the SDKs. As the front door to the API, the SDKs are how developers think about Stripe‚Äîto most people, it‚Äôs <code>stripe.charges.create()</code>, not <code>POST /v1/charges</code>.</p><p>Personally, I hadn‚Äôt appreciated this until I joined Stripe in 2017‚Äîbut by then, the growing scope of the Stripe API had exceeded our capacity to build SDKs by hand sustainably. Making manual changes across 7 different programming languages whenever we shipped a new endpoint was toilsome and error-prone.</p><p>Not only that, TypeScript had eaten the world. Now, developers expect typeahead and documentation-on-hover directly in their text editor. Building SDKs that support comprehensive static types in a variety of languages was totally unthinkable without code generation.</p><p>The team had spent over a year exploring existing open-source code generation tools before concluding that none could meet Stripe‚Äôs quality standards. Most codegen tools either work in only one language or just use string templating, which leaves you constantly fiddling with issues like trailing commas in Go and invalid indentation in Python. We needed to build our own codegen tool that enabled us to ‚Äúlearn once, write everywhere‚Äù and easily produce clean, correct code across all our languages.</p><p>Over a weekend, I hacked together a surprising mashup of JSX and the internals of prettier to enable product developers to quickly template quality code that came well-formatted out of the box. Over the next several months, dozens of engineers helped convert the SDKs to codegen, matching our carefully handcrafted code byte for byte.</p><p>By later that year, I was pairing with a colleague to <a href="https://twitter.com/stripe/status/1222944951853432832" target="_blank">produce the first official TypeScript definitions</a> for the Stripe API.</p><p>‚Äç</p><h2><strong>Scaling SDKs for everybody</strong>‚Äç</h2><p>After I left Stripe, engineers kept asking me how to build great SDKs for their API. I didn‚Äôt have a great answer‚Äîmost companies don‚Äôt have several engineer-years lying around to build whole a suite of high-quality code generators spanning a range of popular languages.</p><p>In early 2022, I set out to bootstrap a company, and Lithic became our first customer, making Stainless ramen-profitable from day one. Their head of product had previously been the PM of SDKs at Plaid, where she‚Äôd seen firsthand both how valuable SDKs are and how hard it is to codegen decent ones with the openapi-generator.</p><p>Despite the allure of a small, bootstrapped company, I felt bad limiting its impact to the small number of clients I could handle by myself. What‚Äôs more, I also got asked how to keep OpenAPI specs up-to-date and valid, how to evolve API versions, how to design RESTful pagination, how to set up API Keys, and a million other problems my old team had already solved at Stripe.</p><p>Eventually it became clear that the world needed a comprehensive developer platform‚Äîfrom docs to request logs to rate-limiting‚Äîthat could enable REST to live up to its potential.</p><p>Sequoia soon became our first investor, shortly followed by great angels like Cristina Cordova, Guillermo Rauch, Calvin French-Owen, and dozens more.</p><p>There was clearly a huge opportunity to advance the whole REST ecosystem and help a ton of people ship better APIs.</p><p>‚Äç</p><h2><strong>Advancing the API ecosystem</strong></h2><p>APIs are the dendrites of the internet. Literally all internet software connects through APIs‚Äîthey make up the vast majority of internet traffic.</p><p>Today, the API ecosystem is deeply fragmented:</p><ol role="list"><li>GraphQL. Great for frontends, but not built for server-to-server interactions and hasn‚Äôt worked out well for public APIs.</li><li>gRPC. Great for microservices, but doesn‚Äôt work for frontends and is unpopular for public APIs.</li><li>REST. Works for frontends, microservices, and public APIs. It‚Äôs simple, flexible, and aligned with web standards‚Äîbut also messy and hard to get right.</li></ol><p>Engineering organizations should be able to use one API technology for everything‚Äîtheir frontends, their microservices, and their public API‚Äîand have a good experience everywhere.</p><p>At Stainless, rather than trying to fit GraphQL or gRPC into the square holes they weren‚Äôt designed for‚Äîor invent some new 15th standard‚Äîwe are staunch believers that ‚ÄúREST done right‚Äù can deliver this vision.</p><p>We want to build great open-source standards and tooling that bring the benefits of GraphQL (types, field selection/expansion, standards) and gRPC (types, speed, versioning) to REST.</p><p>When Stainless REST is realized, you‚Äôll be able to start building a full-stack application using our API layer and have at least as good of a frontend experience as you would have had with GraphQL. When you add a Go microservice, you‚Äôll be able to interconnect with typed clients, efficient packets, and low latency. And then‚Äîuniquely‚Äîwhen your biggest customer asks you for an external API, you‚Äôll be able to just say ‚Äúyes‚Äù and change <code>internal(true)</code> to <code>internal(false)</code> instead of rewriting the whole thing.</p><p>Today, our SDK announcement tackles the most salient problem with REST: type safety.</p><p>Our next project is building out a development framework that enables users to ship quality, typesafe REST APIs from any TypeScript backend. With the upcoming Stainless API framework, you declare the shape and behavior of your API in declarative TypeScript code and get an OpenAPI specification, documentation, and typed frontend client without a build step.</p><p>We‚Äôre building the framework around REST API design conventions that support rich pagination, consistent errors, field inclusion and selection, and normalized caching on the frontend. These conventions, influenced by best practices at Stripe, can help your team achieve consistent, high-quality results without untold hours of bikeshedding.</p></div><div><h2><strong>Building Stainless</strong></h2><div><blockquote>‚ÄúThe cool part about this is that you can define your API once and get client libraries in every language for free, whether you are an expert in those languages or not. <p> It‚Äôs rare that a startup will have people who know Python, Node, Ruby, Rust, Go, Java, etc, etc. But now they can market to all those developers at once.‚Äù
</p><p><em>Calvin French-Owen, co-founder, Segment</em></p></blockquote></div><p>Producing a good SDK is more involved than many developers may realize, especially when relying on code generation. The details matter, and it‚Äôs not just about pretty code‚Äîit‚Äôs about making the right choices and balancing some challenging tradeoffs between the characteristics of REST APIs and the idioms of the language at hand.</p><p>Here are a few generic examples:</p><ul role="list"><li>How do you handle response enums in Java? The obvious approach can result in crashes when adding a new variant in the future.</li><li>If your API introduces a union type, how do you express that in Go, given that the language does not have a standard way to express union types?</li><li>If unexpected data comes back from the server‚Äîwhether due to a beta feature, an edge case, or a bug‚Äîhow do you expose that data to the user? Should the client library treat it like an error? Is there an idiomatic way to achieve this across every programming language? Finding a good solution requires carefully weighing conflicting type safety and runtime safety considerations.</li><li>Should you automatically retry on 429 or 503 errors? How quickly? What if the API is experiencing a production outage?</li><li>What should you call the method for <code>/v1/invoices/{id}/void</code> in a Java client library? (hint: it can‚Äôt be <code>void</code>).</li></ul><p>Note that last problem can‚Äôt simply be decided by a machine‚Äîit requires context about the rest of the API, and must be decided by a human (even if an LLM can offer a first guess).</p><p>The <code>void</code> endpoint example is obviously an edge case, but the general question of what to name each method and type is as pernicious as it is pedestrian. If an SDK generator infers all names directly from the OpenAPI specification‚Äîparticularly a specification generated from other sources‚Äîusers may be confronted with nonsensical types like <code>AccountWrapperConfigurationUnionMember4</code> that raise questions about your company‚Äôs overall engineering quality.</p><p>If you ship an SDK without first addressing these issues, you risk locking yourself into design blunders that you may not be able to resolve later without breaking backwards compatibility in ways that are highly disruptive to users.</p><p>We shared the <code>void</code> example above because it is easy to understand, but there are a range of potential pitfalls that are even more subtle and abstruse that inevitably arise in non-trivial APIs. We can build tools to identify such issues, but deciding how to resolve them is often beyond the scope of what can be achieved with automation‚Äîeven with AI. You need a human being with relevant context and sound judgement to assess the options and make an informed decision.</p><p>From experience, we knew that thoughtful SDK development is a lot more difficult than it seems‚Äîauditing every single type name in a typical, medium-sized API requires scanning through tens of thousands of lines of code.</p><p>To enable every developer to ship with the same level of care that we devote to our enterprise clients, we created an SDK Studio that highlights potential problems and makes it easy to quickly scan through all the things you may want to review before shipping a v1:</p><figure><p><img src="https://assets-global.website-files.com/662240109faccc0cefd740ae/66225e04b91b2310f4740bc2_Screenshot_2024-03-27_at_3.49.35_PM.png" loading="lazy" alt=""></p><figcaption>The Stainless SDK Studio</figcaption></figure><p>To start using the Stainless SDK generator, all you need is an OpenAPI specification.</p><p>Within a few minutes, you‚Äôll get alpha SDKs you can publish to package managers‚Äîand after a bit of polishing, something you‚Äôre proud to release as v1.0.0.</p><p>To get started, check out <a href="https://app.stainlessapi.com/docs/" target="_blank">our documentation</a> or <a href="https://app.stainlessapi.com/login" target="_blank">connect your GitHub account</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US bans TikTok owner ByteDance, will prohibit app in US unless it is sold (110 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/04/biden-signs-bill-to-ban-tiktok-if-chinese-owner-bytedance-doesnt-sell/</link>
            <guid>40146203</guid>
            <pubDate>Wed, 24 Apr 2024 16:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/04/biden-signs-bill-to-ban-tiktok-if-chinese-owner-bytedance-doesnt-sell/">https://arstechnica.com/tech-policy/2024/04/biden-signs-bill-to-ban-tiktok-if-chinese-owner-bytedance-doesnt-sell/</a>, See on <a href="https://news.ycombinator.com/item?id=40146203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Get outta here    ‚Äî
</h4>
            
            <h2 itemprop="description">Bill gives ByteDance 270 days to sell TikTok or app loses access to US market.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/tiktok-800x502.jpg" alt="A TikTok app icon on a phone screen.">
      <figcaption><p>Getty Images | Chesnot </p></figcaption>  </figure>

  




<!-- cache hit 344:single/related:64de479a699749d7c72ce7bf35fcda82 --><!-- empty -->
<p>The Senate last night approved a bill that orders TikTok owner ByteDance to sell the company within 270 days or lose access to the US market. The House had already passed the bill, and President Biden signed it into law today.</p>
<p>The "Protecting Americans From Foreign Adversary Controlled Applications Act" was approved as part of a <a href="https://www.congress.gov/bill/118th-congress/house-bill/815/text">larger appropriations bill</a> that provides aid to Ukraine, Israel, and Taiwan. It passed in a <a href="https://www.senate.gov/legislative/LIS/roll_call_votes/vote1182/vote_118_2_00154.htm">79-18 vote</a>. Biden last night issued a <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2024/04/23/statement-from-president-joe-biden-on-senate-passage-of-the-national-security-package/">statement</a> saying he will sign the appropriations bill into law "as soon as it reaches my desk." He signed the bill into law today, the White House <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2024/04/24/bill-signed-h-r-815/">announced</a>.</p>
<p>The bill classifies TikTok as a "foreign adversary controlled application" and gives the Chinese company ByteDance 270 days to sell it to another entity. Biden can extend the deadline by up to 90 days if a sale is in progress.</p>
<p>TikTok would maintain access to the US market if the president determines that the divestiture "would result in the relevant foreign adversary controlled application no longer being controlled by a foreign adversary." The same divestiture-or-sale requirement would apply to other applications subsequently designated as being controlled by foreign adversaries.</p>
<p>If ByteDance doesn't sell TikTok, app stores in the US would have to drop the app, and Internet hosting services would be prohibited from providing services that enable distribution of TikTok in the US. Companies that violate the prohibition would have to pay civil penalties.</p>                                            
                                                        
<h2>ByteDance will fight law in court</h2>
<p>"Congress is not acting to punish ByteDance, TikTok, or any other individual company," Senate Commerce Committee Chair Maria Cantwell (D-Wash.) said, <a href="https://apnews.com/article/tiktok-ban-congress-bill-1c48466df82f3684bd6eb21e61ebcb8d">according to the Associated Press</a>. "Congress is acting to prevent foreign adversaries from conducting espionage, surveillance, maligned operations, harming vulnerable Americans, our servicemen and women, and our US government personnel."</p>
<p><a href="https://www.reuters.com/world/us/senators-hope-tiktok-will-remain-business-us-under-new-owner-2024-04-23/">Reuters quoted</a> Sen. Ed Markey (D-Mass.) as saying the bill is "really just a TikTok ban" and that "censorship is not who we are as a people. We should not downplay or deny this trade-off." Senator Ron Wyden (D-Ore.) expressed concern that the bill "provides broad authority that could be abused by a future administration to violate Americans' First Amendment rights."</p>
<p>Despite those statements, Markey and Wyden both voted in favor of the appropriations bill that includes the TikTok-inspired law.</p>
<p>ByteDance has said it will file a lawsuit in an attempt to block the law. "This legislation is a clear violation of the First Amendment rights of TikTok's 170 million American users," Michael Beckerman, TikTok's public policy head in the US, <a href="https://arstechnica.com/tech-policy/2024/04/tiktok-ready-to-move-to-the-courts-to-prevent-ban-in-us/">reportedly</a> told staff in a memo after the House vote on Saturday. "We'll continue to fight... This is the beginning, not the end of this long process."</p>
<p>In a <a href="https://twitter.com/TikTokPolicy/status/1783149300471525637">statement</a> today, TikTok said it "will ultimately prevail" in court and that "we have invested billions of dollars to keep US data safe and our platform free from outside influence and manipulation."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snowflake Arctic Instruct (128x3B MoE), largest open source model (279 pts)]]></title>
            <link>https://replicate.com/snowflake/snowflake-arctic-instruct</link>
            <guid>40146088</guid>
            <pubDate>Wed, 24 Apr 2024 16:09:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://replicate.com/snowflake/snowflake-arctic-instruct">https://replicate.com/snowflake/snowflake-arctic-instruct</a>, See on <a href="https://news.ycombinator.com/item?id=40146088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  















<div data-react-placeholder="APIPlayground">
    <div>
        <p>
          <h2>Input</h2>
        </p>
      </div>
    
    <div>
          <p>
            <h2>Output</h2>
          </p>
        </div>
  </div>



















<section id="pricing">
  <a id="performance"></a>

  <h4>Pricing</h4>

  <p>
    This language model is priced by how many input tokens are sent as inputs and how many output tokens are generated.
  </p>

  

  <p>
    Check out
    <a href="https://replicate.com/docs/billing#language-models">our docs</a>
    for more information about how per-token pricing works on Replicate.
  </p>
</section>




<article>
  <p id="readme">
    <h4>Readme</h4>
    
  </p>
  
  <div>
    <h2 id="demo-app">Demo App</h2>
<p>Want to chat with Arctic? <a href="https://arctic.streamlit.app/" rel="nofollow">Try the Streamlit demo app.</a></p>
<h2 id="model-details">Model Details</h2>
<p>Arctic is a dense-MoE Hybrid transformer architecture pre-trained from scratch by the Snowflake AI 
Research Team. We are releasing model checkpoints for both the base and instruct-tuned versions of 
Arctic under an Apache-2.0 license. This means you can use them freely in your own research, 
prototypes, and products. Please see our blog 
<a href="https://www.snowflake.com/blog/arctic-open-and-efficient-foundation-language-models-snowflake" rel="nofollow">Snowflake Arctic: The Best LLM for Enterprise AI ‚Äî Efficiently Intelligent, Truly Open</a> 
for more information on Arctic and links to other relevant resources such as our series of cookbooks 
covering topics around training your own custom MoE models, how to produce high-quality training data, 
and much more.</p>
<ul>
<li><a href="https://huggingface.co/Snowflake/snowflake-arctic-base/" rel="nofollow">Arctic-Base</a></li>
<li><a href="https://huggingface.co/Snowflake/snowflake-arctic-instruct/" rel="nofollow">Arctic-Instruct</a></li>
<li><a href="https://arctic.streamlit.app/" rel="nofollow">Arctic Demo App</a></li>
</ul>
<p>For the latest details about Snowflake Arctic including tutorials, etc. please refer to our github repo: <a href="https://github.com/Snowflake-Labs/snowflake-arctic" rel="nofollow">https://github.com/Snowflake-Labs/snowflake-arctic</a></p>
<p><strong>Model developers</strong> Snowflake AI Research Team</p>
<p><strong>License</strong> Apache-2.0</p>
<p><strong>Input</strong> Models input text only.</p>
<p><strong>Output</strong> Models generate text and code only.</p>
<p><strong>Model Release Date</strong> April, 24th 2024.</p>
<h2 id="model-architecture">Model Architecture</h2>
<p>Arctic combines a 10B dense transformer model with a residual 128x3.66B MoE MLP resulting in 480B 
total and 17B active parameters chosen using a top-2 gating. For more details about Arctic‚Äôs model
Architecture, training process, data, etc. <a href="https://www.snowflake.com/en/data-cloud/arctic/cookbook/" rel="nofollow">see our series of cookbooks</a>.</p>
  </div>
  
</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Biden signs TikTok 'ban' bill into law, starting clock for ByteDance to divest (665 pts)]]></title>
            <link>https://www.theverge.com/2024/4/24/24139036/biden-signs-tiktok-ban-bill-divest-foreign-aid-package</link>
            <guid>40145963</guid>
            <pubDate>Wed, 24 Apr 2024 15:59:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/4/24/24139036/biden-signs-tiktok-ban-bill-divest-foreign-aid-package">https://www.theverge.com/2024/4/24/24139036/biden-signs-tiktok-ban-bill-divest-foreign-aid-package</a>, See on <a href="https://news.ycombinator.com/item?id=40145963">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>President Joe Biden signed a foreign aid package that includes a <a href="https://www.theverge.com/2024/4/23/24137638/senate-passes-tiktok-ban-bill-divest-bytedance-foreign-aid">bill that would ban TikTok if China-based parent company ByteDance fails to divest</a> the app within a year.</p></div><p>The divest-or-ban bill is now law, starting the clock for ByteDance to make its move. The company has an initial nine months to sort out a deal, though the president could extend that another three months if he sees progress.</p><p>While just recently the legislation seemed like it would stall out in the Senate after being passed as a standalone bill in the House, political maneuvering helped usher it through to Biden‚Äôs desk. The House packaged the TikTok bill ‚Äî which upped the timeline for divestment from the six months allowed in the earlier version ‚Äî with foreign aid to US allies, which effectively forced the Senate to consider the measures together. The longer divestment period also seemed to get some lawmakers who were on the fence on board.</p><p>TikTok spokesperson Alex Haurek said in a statement that the company plans to challenge the law in the courts, which could ultimately extend the timeline should the courts delay enforcement pending a resolution. There also remains the question of how China will respond and whether it would let ByteDance sell TikTok and, most importantly, its coveted algorithm that keeps users coming back to the app.</p><p>‚ÄúAs we continue to challenge this unconstitutional ban, we will continue investing and innovating to ensure TikTok remains a space where Americans of all walks of life can safely come to share their experiences, find joy, and be inspired,‚Äù Haurek said.&nbsp;</p><p>‚ÄúMake no mistake, this is a ban,‚Äù TikTok CEO Shou Chew said in a video posted on TikTok Wednesday, objecting to some lawmakers‚Äô assertions that they just want to see the platform disconnected from Chinese ownership. ‚ÄúA ban on TikTok and a ban on you and your voice.‚Äù</p><p><em><strong>Update, April 24th: </strong>The article has been updated with an official statement from a TikTok spokesperson and its CEO.</em></p></div></div>]]></description>
        </item>
    </channel>
</rss>