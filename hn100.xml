<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 01 Sep 2024 20:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Americans' love affair with big cars is killing them (164 pts)]]></title>
            <link>https://www.economist.com/interactive/united-states/2024/08/31/americans-love-affair-with-big-cars-is-killing-them</link>
            <guid>41418562</guid>
            <pubDate>Sun, 01 Sep 2024 17:18:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/interactive/united-states/2024/08/31/americans-love-affair-with-big-cars-is-killing-them">https://www.economist.com/interactive/united-states/2024/08/31/americans-love-affair-with-big-cars-is-killing-them</a>, See on <a href="https://news.ycombinator.com/item?id=41418562">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>    <main>   <div><p><body-text><!-- HTML_TAG_START --><span data-caps="initial">W</span><small>itnesses said</small> the driver showed no signs of slowing down. On June 3rd Nicole Louthain and her six-year-old daughter were stopped at a red light in Grand Forks, North Dakota when they were struck from behind by Travis Bell. Such crashes are not uncommon—around 10,000 rear-end collisions occur in America every day. What made this one noteworthy was that the vehicles involved were so unevenly matched. Ms Louthain was driving a Ford Focus, a compact car weighing around 3,000lb (1,360kg), whereas Mr Bell was in a 7,000lb Ram 3500 “heavy duty” pickup. Alas, the disparity proved deadly. Although Mr Bell was not harmed, Ms Louthain suffered serious injuries. (Court documents later showed that Mr Bell had been drinking.) Her daughter Katarina was air-lifted to a nearby hospital where she died two days later.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->The crash in Grand Forks helps to illustrate a sad truth about America’s roads. For all the safety features available in cars today to help them avoid crashes, when they happen they are still often determined by the laws of physics. When two vehicles collide, it is usually the heavier one that prevails. This advantage has changed little over time. Thirty years ago when a passenger car crashed with a <a href="https://www.economist.com/united-states/2023/04/20/rural-americans-are-importing-tiny-japanese-pickup-trucks">pickup truck</a> or sport-utility vehicle (<small>SUV</small>), the driver of the car was roughly four times as likely to die; today this driver dies around three times as often. Critics say this is too high a price to pay for roomier interiors and more powerful engines. Carmakers insist they are giving consumers what they want. An analysis by <i>The Economist</i> shows that weight remains a critical factor in car crashes in America. Reining in <a href="https://www.economist.com/the-economist-explains/2024/03/11/why-american-cars-are-so-big">the heaviest vehicles</a> would save lives.<!-- HTML_TAG_END --> </body-text> </p> </div> <figure><ai2sveltewrap> </ai2sveltewrap>  </figure><div><p><body-text><!-- HTML_TAG_START -->Mismatches between big and small cars on America’s roads are not new. In the 1960s the 1,400lb Mini Cooper shared the road with the 5,000lb Cadillac Fleetwood and the 5,500lb Lincoln Continental. But whereas today heavier vehicles attract the bulk of the criticism, back then it was lighter ones that drew scrutiny. Indeed many cars of the time were woefully unsafe. In 1969 America’s National Highway Safety Bureau conducted crash tests on a Subaru 360 and a King Midget, two sub-1,000lb “mini-cars”. When pitted against vehicles twice their size, the tiny cars crumpled like soda cans.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Over the years policymakers struggled to solve this mismatch, or “incompatibility”, problem. Often, they made things worse. When Congress set fuel-efficiency standards in the wake of the oil shocks of the 1970s, cars were swiftly downsized. Within ten years cars shed 1,000lb; trucks dropped 500lb. Although these changes saved motorists money at the pump, they also led to more traffic fatalities. A paper published in 1989 by researchers at the Brookings Institution and the Harvard School of Public Health estimated that the shift towards smaller, lighter cars in the 1970s and 1980s boosted fatalities by 14-27%. A report released in 2002 by America’s National Research Council concluded that the downsizing of America’s fleet led to thousands of unnecessary deaths.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->As cars got bigger, regulators shifted their focus from the lightest vehicles to the heaviest ones. The impetus for this was the rise of <small>SUV</small>s. Between 1990 and 2005 the market share of such vehicles in America grew from 6% to 26%, pushing up the weight of an average new car from 3,400lb to nearly 4,100lb. As suburban soccer moms traded in their station wagons for Ford Expeditions, many felt safer. And they were right. “One of the reasons the roads are much safer is because vehicles... [are] bigger and they’re heavier than they were,” Adrian Lund of the Insurance Institute for Highway Safety (<small>IIHS</small>), an industry research organisation, told conference-goers in 2011. The Competitive Enterprise Institute, a think-tank, even advocated supersizing America’s fleet to improve safety, writing in the <i>Wall Street Journal</i> that large vehicles are “the solution, not the problem”.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->But researchers quickly learned that the extra protection provided by heavier vehicles comes at the expense of others on the road. In a paper published in 2004 Michelle White of the University of California, San Diego estimated that for every deadly crash avoided by an <small>SUV</small> or pickup truck, there were an additional 4.3 among other drivers, pedestrians and cyclists. Another paper in 2012 by Shanjun Li of Resources for the Future, a think-tank, estimated that when a car crashes with an <small>SUV</small> or pickup, rather than another car, the driver’s fatality rate increased by 31%. In 2014 Michael Anderson and Maximilian Auffhammer of the University of California, Berkeley estimated that when two cars crash, a 1,000lb increase in the weight of one vehicle raised the fatality rate in the other by 47%.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Researchers also found that the safety benefits of vehicle weight suffer from diminishing returns. This means that, once vehicles reach a certain weight, packing on more pounds provides little additional safety, while inflicting more harm on others. “At some point heavy vehicles cost more lives…than they save,” wrote Brian O’Neill and Sergey Kyrychenko of the <small>IIHS</small> in 2004. This makes intuitive sense, says Mr Anderson of Berkeley. “Once you outweigh the other guy by a factor of two times, is adding 200 pounds more really going to make a difference for you? Probably not. But it’ll make sure that he gets completely destroyed.”<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->So how big is too big? At what point do the costs of the heaviest vehicles—measured in lives lost—vastly exceed their benefits? To answer this question, <i>The Economist</i> compiled ten years’ worth of crash data from more than a dozen states. Like the data compiled by Messrs Anderson and Auffhammer, our figures come from reports filed by police officers, who are tasked with recording information about car crashes when called to the scene. Although all states collect such data, we focus on those that collect the most detailed figures and share them with researchers. The resulting dataset, which covers more than a third of America’s population, provides us with a sample that is both big and representative.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->In total, our dataset includes millions of crashes across 14 states between 2013 and 2023. Although accident reports vary from state to state, most of the crashes in our database include information about the location of the crash, the number of cars involved, each passenger’s age and gender, whether they were wearing seatbelts and the types of injuries that they suffered. To obtain the curb weight of each vehicle, we collected the vehicle identification numbers (<small>VINs</small>) included in each crash report, and then matched them to vehicle specs data from VinAudit, an auto-data provider. Combining these data yielded roughly 10m crashes. After dropping observations with missing data, we were left with around 7.5m two-vehicle crashes involving more than 15m cars.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->What do these data tell us about the relationship between vehicle weight and road safety?<!-- HTML_TAG_END --> </body-text> </p> </div> <div><p><body-text><!-- HTML_TAG_START -->The heaviest 1% of vehicles in our dataset—those weighing around 6,800lb—suffer 4.1 “own-car deaths” per 10,000 crashes, on average, compared with around 6.6 for cars in the middle of our sample weighing 3,500lb, and 15.8 for the lightest 1% of vehicles weighing just 2,300lb. But heavy cars are also far more dangerous to other drivers. The heaviest vehicles in our data were responsible for 37 “partner-car deaths” per 10,000 crashes, on average, compared with 5.7 for median-weight cars and 2.6 for the lightest cars.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->To estimate this relationship more precisely, and control for potential sources of bias, we conducted a regression analysis of our sample of 7.5m two-vehicle crashes. We found that getting into a crash with a vehicle that is 1,000lb heavier is associated with a 0.06-percentage-point increase in the probability of suffering a fatality, even after controlling for the curb weight of one’s own car, the age and gender of the driver, the population density of the crash location and whether the passengers were wearing seatbelts. Given that the probability of suffering a fatality in a two-vehicle crash is 0.09%, on average, this suggests that getting hit by an additional 1,000lbs of steel and aluminium—roughly the difference between a Toyota Camry and a Ford Explorer—boosts the likelihood of death by 66%.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->As for the weight at which the social costs of driving a heavier vehicle exceed the benefits, the evidence is clear. Vehicles in the top 10% of our sample—those weighing at least 5,000lb—are involved in roughly 26 deaths per 10,000 crashes, on average, including 5.9 in their own car and 20.2 in partner vehicles. For vehicles in the next-heaviest 10% of our sample—those weighing between 4,500lb and 5,000lb—the equivalent figures are 5.4 and 10.3 deaths per 10,000 crashes. A back-of-the-envelope estimate suggests that if the heaviest tenth of vehicles in America’s fleet were downsized to this lighter weight class, road fatalities in multi-car crashes—which totaled 19,081 in 2023—could be reduced by 12%, or 2,300, without sacrificing the safety of any cars involved.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Given these figures, you might expect carmakers to be slamming the brakes on production of their heaviest <small>SUV</small>s and pickups. In fact, they are pressing on the accelerator. Official figures from the Environmental Protection Agency show that the average new car in America weighs more than 4,400lb (compared with 3,300lb in the European Union and 2,600lb in Japan). In 2023 vehicles weighing more than 5,000lb accounted for a whopping 31% of new cars, up from 22% five years earlier.<!-- HTML_TAG_END --> </body-text> </p> </div> <figure><ai2sveltewrap> </ai2sveltewrap>  </figure><div><p><body-text><!-- HTML_TAG_START -->It would be easy to blame car-buyers for this trend but Mr Anderson says that Americans looking for a new car face a cold-war-style “arms race”. “As you see the vehicle fleet around you getting heavier, then you want to protect yourself rationally by buying a bigger and heavier car.” Such rational individual decisions have led to a suboptimal outcome for society as a whole.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->When asked to comment on <i>The Economist</i>’s findings, representatives from the big three car manufacturers pointed to safety features that help drivers avoid crashes, rather than those that make them less deadly. “Vehicle weight doesn’t solely determine crash performance,” Mike Levine, a Ford spokesman, wrote in an email, highlighting crash-avoidance technologies such as automatic emergency braking and front and rear “brake assist”. General Motors pointed out that carmakers have improved the compatibility of their vehicles over the years, citing a voluntary deal struck by manufacturers in 2003, more than twenty years ago. Stellantis (whose biggest shareholder part-owns <i>The Economist</i>’s parent company) declined to comment except to say that the company’s vehicles “meet or exceed all applicable federal safety standards”.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->Regulators are ill-equipped to fix the problem. America’s tax system subsidises heavier vehicles by setting more lenient fuel-efficiency standards for light trucks, and allowing bosses who purchase heavy-duty vehicles for business purposes to deduct part of the cost from their taxable income. The National Highway Traffic Safety Administration (<small>NHTSA</small>), America’s top auto-safety agency, uses a five-star rating system to score crash performance, but only takes account of the safety of the occupants of the vehicle in question, not that of other drivers. “Our rating system reflects a bias towards the occupant,” explains Laura Sandt of the Highway Safety Research Centre at the University of North Carolina, “it is not designed to rate the car in terms of its holistic safety effects.” The <small>NHTSA</small> declined to comment on <i>The Economist</i>’s findings.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->There are signs that Americans may be wising up. A survey conducted last year by YouGov, a pollster, found that 41% of Americans think that <small>SUV</small>s and pickup trucks have become too big; 49% said such vehicles are more dangerous for other cars and 50% said they endanger cyclists and pedestrians. Researchers are raising the alarm. Since 1989 the <small>IIHS</small> has regularly published the driver-fatality rates of popular car models. In 2023, for the first time, the group also estimated the rate at which cars kill drivers in other vehicles. Policymakers are starting to take notice too. “I’m concerned about the increased risk of severe injury and death for all road users from heavier curb weights,” Jennifer Homendy, chair of the National Transportation Safety Board, said in a speech last year.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->But the odds that carmakers curb their heaviest, most dangerous vehicles are slim. American car-buyers value safety, but mainly for themselves, not society as a whole. And although regulators are tasked with protecting consumers, they rarely do so at the expense of choice, no matter how deadly the consequences. “There may be a certain point where you say, ‘You know what, passenger vehicles shouldn't be weighing this much,’” says Raul Arbelaez of the <small>IIHS</small>’s Vehicle Research Centre. “But it would, politically, be really hard to gain any momentum on that.” Finally the shift towards <a href="https://www.economist.com/business/2024/04/07/think-tesla-is-in-trouble-pity-even-more-its-wannabe-ev-rivals">electric power</a> is likely to increase their weight further, as battery-powered vehicles tend to be heavier than their internal-combustion equivalents.<!-- HTML_TAG_END --> </body-text> </p> </div><div><p><body-text><!-- HTML_TAG_START -->“Manufacturers are playing by the book,” says Mark Chung of the National Safety Council, a non-profit. “They’re making a business decision, and it’s a rational decision. Unless they’re forced to think differently, they’re not going to. So I think this is where our federal partners really need to step up.”<span data-ornament="ufinish">■</span><!-- HTML_TAG_END --> </body-text> </p> </div><div><p>Sources: </p><body-text><!-- HTML_TAG_START -->State governments; VinAudit; <i>The Economist</i><!-- HTML_TAG_END --> </body-text> </div>  </main>  
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple and Nvidia in talks to invest in ChatGPT (123 pts)]]></title>
            <link>https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30</link>
            <guid>41418302</guid>
            <pubDate>Sun, 01 Sep 2024 16:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30">https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30</a>, See on <a href="https://news.ycombinator.com/item?id=41418302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="descriptionStoryId"><p>Apple and Nvidia are reportedly in talks to invest in OpenAI, the company behind ChatGPT, as part of a new fundraising round. This round could potentially value OpenAI at over $100 billion, according to media reports.</p>

<p>The Wall Street Journal reported that Apple is exploring the possibility of joining the funding round, while Bloomberg News indicated Nvidia’s potential involvement. This comes after news that Thrive Capital, a venture capital firm, is planning to invest around $1 billion in OpenAI, leading the current fundraising efforts.</p><div><h4>Related Articles</h4><div><ul><li><a target="_blank" title="OpenAI launches fine-tuning for GPT-4o, unlocking enhanced performance and customisation" href="https://www.businesstoday.in/technology/news/story/openai-launches-fine-tuning-for-gpt-4o-unlocking-enhanced-performance-and-customisation-442518-2024-08-22">OpenAI launches fine-tuning for GPT-4o, unlocking enhanced performance and customisation</a></li><li><a target="_blank" title="Ex-Google CEO thinks company's ‘work-life balance’ mentality is why it is losing AI race to startups like OpenAI" href="https://www.businesstoday.in/technology/news/story/ex-google-ceo-thinks-companys-work-life-balance-mentality-is-why-it-is-losing-ai-race-to-startups-like-openai-441535-2024-08-14">Ex-Google CEO thinks company's ‘work-life balance’ mentality is why it is losing AI race to startups like OpenAI</a></li></ul></div></div>

<p>OpenAI has become increasingly integral to Apple’s AI strategy. In June, Apple introduced OpenAI’s chatbot, ChatGPT, to its devices under the initiative called “Apple Intelligence.” Additionally, Apple is reportedly set to gain an observer role on OpenAI’s board, highlighting the deepening relationship between the two companies.</p>

<p>Microsoft, OpenAI’s largest investor with over $10 billion already committed, is also expected to participate in this new funding round. However, the specific amounts that Apple, Nvidia, and Microsoft are planning to invest have not been disclosed.</p>

<p>OpenAI’s rising valuation is a result of the intense competition in the AI sector, which intensified after the launch of ChatGPT in late 2022. This launch spurred companies across various industries to pour billions into AI technology to stay competitive. Earlier this year, OpenAI was valued at $80 billion following a tender offer led by Thrive Capital, where the firm sold existing shares.<br>
&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a Leading Chain of Psychiatric Hospitals Traps Patients (166 pts)]]></title>
            <link>https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html</link>
            <guid>41417284</guid>
            <pubDate>Sun, 01 Sep 2024 14:33:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html">https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html</a>, See on <a href="https://news.ycombinator.com/item?id=41417284">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Linkpreview, see how your sites looks in social media and chat apps (180 pts)]]></title>
            <link>https://linkpreview.xyz</link>
            <guid>41416714</guid>
            <pubDate>Sun, 01 Sep 2024 13:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linkpreview.xyz">https://linkpreview.xyz</a>, See on <a href="https://news.ycombinator.com/item?id=41416714">Hacker News</a></p>
<div id="readability-page-1" class="page"><!--teleport start anchor--><!--teleport anchor--><div id="__nuxt"><!--[--><div><!--[--><header><div><svg fill="none" height="48" viewBox="0 0 48 48" width="48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><filter id="a" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse" height="54" width="48" x="0" y="-3"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend in="SourceGraphic" in2="BackgroundImageFix" mode="normal" result="shape"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="-3"></feOffset><feGaussianBlur stdDeviation="1.5"></feGaussianBlur><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.1 0"></feColorMatrix><feBlend in2="shape" mode="normal" result="effect1_innerShadow_3051_46941"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="3"></feOffset><feGaussianBlur stdDeviation="1.5"></feGaussianBlur><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0.1 0"></feColorMatrix><feBlend in2="effect1_innerShadow_3051_46941" mode="normal" result="effect2_innerShadow_3051_46941"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feMorphology in="SourceAlpha" operator="erode" radius="1" result="effect3_innerShadow_3051_46941"></feMorphology><feOffset></feOffset><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0.0627451 0 0 0 0 0.0941176 0 0 0 0 0.156863 0 0 0 0.24 0"></feColorMatrix><feBlend in2="effect2_innerShadow_3051_46941" mode="normal" result="effect3_innerShadow_3051_46941"></feBlend></filter><filter id="b" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse" height="42" width="36" x="6" y="5.25"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feMorphology in="SourceAlpha" operator="erode" radius="1.5" result="effect1_dropShadow_3051_46941"></feMorphology><feOffset dy="2.25"></feOffset><feGaussianBlur stdDeviation="2.25"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0.141176 0 0 0 0 0.141176 0 0 0 0 0.141176 0 0 0 0.1 0"></feColorMatrix><feBlend in2="BackgroundImageFix" mode="normal" result="effect1_dropShadow_3051_46941"></feBlend><feBlend in="SourceGraphic" in2="effect1_dropShadow_3051_46941" mode="normal" result="shape"></feBlend></filter><linearGradient id="c" gradientUnits="userSpaceOnUse" x1="24" x2="26" y1=".000001" y2="48"><stop offset="0" stop-color="#fff" stop-opacity="0"></stop><stop offset="1" stop-color="#fff" stop-opacity=".12"></stop></linearGradient><linearGradient id="d" gradientUnits="userSpaceOnUse" x1="24" x2="24" y1="9" y2="39"><stop offset="0" stop-color="#fff" stop-opacity=".8"></stop><stop offset="1" stop-color="#fff" stop-opacity=".5"></stop></linearGradient><linearGradient id="e" gradientUnits="userSpaceOnUse" x1="24" x2="24" y1="0" y2="48"><stop offset="0" stop-color="#fff" stop-opacity=".12"></stop><stop offset="1" stop-color="#fff" stop-opacity="0"></stop></linearGradient><clipPath id="f"><rect height="48" rx="12" width="48"></rect></clipPath><g filter="url(#a)"><g clip-path="url(#f)"><rect fill="#0c111d" height="48" rx="12" width="48"></rect><path d="m0 0h48v48h-48z" fill="url(#c)"></path><g filter="url(#b)"><path clip-rule="evenodd" d="m15 9c-3.3137 0-6 2.6863-6 6v18c0 3.3137 2.6863 6 6 6h18c3.3137 0 6-2.6863 6-6v-18c0-3.3137-2.6863-6-6-6zm2.25 11.625h7.4733l-8.7991 8.7992 2.6516 2.6516 8.7992-8.7991v7.4733h3.75v-12c0-1.0355-.8395-1.875-1.875-1.875h-12z" fill="url(#d)" fill-rule="evenodd"></path></g></g><rect height="46" rx="11" stroke="url(#e)" stroke-width="2" width="46" x="1" y="1"></rect></g></svg><p>LinkPreview</p></div><div><!--[--><a href="https://supersaas.dev/" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!----><!--]--><!--[--><img src="https://supersaas.dev/logo.png" alt="Supersaas"><!--]--><!--[--><!----><!--]--><!--]--></a><!--]--><!--[--><!--]--></div></header><div><form data-n-ids="{&quot;np6cif8hBbo-0&quot;:&quot;np6cif8hBbo-0&quot;}"><!--[--><!--]--></form><!----></div><!--[--><p><a href="https://supersaas.dev/" target="_blank"><img src="https://essentials.supersaas.dev/supersaas-banner.png" alt="Supersaas"></a></p><!--]--><!--]--></div><!--]--><section aria-label="Notifications alt+T" tabindex="-1"><!--[--><ol data-sonner-toaster="" dir="ltr" tabindex="-1" data-theme="light" data-rich-colors="false" data-y-position="top" data-x-position="center"><!--[--><!--]--></ol><!--]--></section><!--teleport start--><!--teleport end--></div>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The web's clipboard, and how it stores data of different types (128 pts)]]></title>
            <link>https://alexharri.com/blog/clipboard</link>
            <guid>41415866</guid>
            <pubDate>Sun, 01 Sep 2024 11:02:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexharri.com/blog/clipboard">https://alexharri.com/blog/clipboard</a>, See on <a href="https://news.ycombinator.com/item?id=41415866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><p>If you've been using computers for a while, you probably know that the clipboard can store multiple types of data (images, rich text content, files, and so on). As a software developer, it started frustrating me that I didn't have a good understanding of how the clipboard stores and organizes data of different types.</p>
<p>I recently decided to unveil the mystery that is the clipboard and wrote this post using my learnings. We'll focus on the web clipboard and its APIs, though we'll also touch on how it interacts with operating system clipboards.</p>
<p>We'll start by exploring the web's clipboard APIs and their history. The clipboard APIs have some interesting limitations around data types, and we'll see how some companies have worked around those limitations. We'll also look at some proposals that aim to resolve those limitations (most notably, <a target="_blank" href="https://github.com/w3c/editing/blob/gh-pages/docs/clipboard-pickling/explainer.md">Web Custom Formats</a>).</p>
<p>If you've ever wondered how the web's clipboard works, this post is for you.</p>
<h2>Using the async Clipboard API</h2>
<p>If I copy some content from a website and paste it into Google Docs, some of its formatting is retained, such as links, font size, and color.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/copy-paste-rich-content.png"></p>
<p>But if I open VS Code and paste it there, only the raw text content is pasted.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/copy-paste-into-vscode.png"></p>
<p>The clipboard serves these two use cases by allowing information to be stored in multiple <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#list-of-representations"><em>representations</em></a> associated with MIME types. The W3C Clipboard spec <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandates</a> that for writing to and reading from the clipboard, these three data types must be supported:</p>
<ul>
<li><code>text/plain</code> for plain text.</li>
<li><code>text/html</code> for HTML.</li>
<li><code>image/png</code> for PNG images.</li>
</ul>
<p>So when I pasted before, Google Docs read the <code>text/html</code> representation and used that to retain the rich text formatting. VS Code only cares about the raw text and reads the <code>text/plain</code> representation. Makes sense.</p>
<p>Reading a specific representation via the async Clipboard API's <code>read</code> method is quite straightforward:</p>
<div><pre><p><span>const</span><span> items </span><span>=</span><span> </span><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>read</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>for</span><span> </span><span>(</span><span>const</span><span> item </span><span>of</span><span> items</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>item</span><span>.</span><span>types</span><span>.</span><span>includes</span><span>(</span><span>"text/html"</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> blob </span><span>=</span><span> </span><span>await</span><span> item</span><span>.</span><span>getType</span><span>(</span><span>"text/html"</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> html </span><span>=</span><span> </span><span>await</span><span> blob</span><span>.</span><span>text</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Writing multiple representations to the clipboard via <code>write</code> is a bit more involved, but still relatively straightforward. First, we construct <code>Blob</code>s for each representation that we want to write to the clipboard:</p>
<div><pre><p><span>const</span><span> textBlob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>"Hello, world"</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"text/plain"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> htmlBlob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>"Hello, &lt;em&gt;world&lt;em&gt;"</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"text/html"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Once we have the blobs, we pass them to a new <code>ClipboardItem</code> in a key-value store with the data types as the keys and the blobs as the values:</p>
<div><pre><p><span>const</span><span> clipboardItem </span><span>=</span><span> </span><span>new</span><span> </span><span>ClipboardItem</span><span>(</span><span>{</span><span></span></p><p><span>  </span><span>[</span><span>textBlob</span><span>.</span><span>type</span><span>]</span><span>:</span><span> textBlob</span><span>,</span><span></span></p><p><span>  </span><span>[</span><span>htmlBlob</span><span>.</span><span>type</span><span>]</span><span>:</span><span> htmlBlob</span><span>,</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Note: <!-- -->I like that <code>ClipboardItem</code> accepts a key-value store. It nicely aligns with the idea of using a data structure that makes illegal states unrepresentable, as discussed in <a target="_blank" href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/#:~:text=Use%20a%20data%20structure%20that%20makes%20illegal%20states%20unrepresentable">Parse, don't validate</a>.</p>
<p>Finally, we invoke <code>write</code> with our newly constructed <code>ClipboardItem</code>:</p>
<div><pre><p><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>write</span><span>(</span><span>[</span><span>clipboardItem</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div>
<h3>What about other data types?</h3>
<p>HTML and images are cool, but what about general data interchange formats like JSON? If I were writing an application with copy-paste support, I could imagine wanting to write JSON or some binary data to the clipboard.</p>
<p>Let's try to write JSON data to the clipboard:</p>
<div><pre><p><span></span><span>const</span><span> json </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> message</span><span>:</span><span> </span><span>"Hello"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> blob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>json</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"application/json"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> clipboardItem </span><span>=</span><span> </span><span>new</span><span> </span><span>ClipboardItem</span><span>(</span><span>{</span><span> </span><span>[</span><span>blob</span><span>.</span><span>type</span><span>]</span><span>:</span><span> blob </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>write</span><span>(</span><span>[</span><span>clipboardItem</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Upon running this, an exception is thrown:</p>
<div><pre><p><span>Failed to execute 'write' on 'Clipboard':</span></p><p><span>  Type application/json not supported on write.</span></p></pre></div>
<p>Hmm, what's up with that? Well, the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#dom-clipboard-write">spec</a> for <code>write</code> tells us that data types other than <code>text/plain</code>, <code>text/html</code>, and <code>image/png</code> must be rejected:</p>
<blockquote>
<p>If <em>type</em> is not in the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandatory data types</a> list, then reject [...] and abort these steps.</p>
</blockquote>
<p>Interestingly, the <code>application/json</code> MIME type was in the mandatory data types list from <a target="_blank" href="https://www.w3.org/TR/2012/WD-clipboard-apis-20120223/#mandatory-data-types-1">2012</a> to <a target="_blank" href="https://www.w3.org/TR/2021/WD-clipboard-apis-20210806/#mandatory-data-types-x">2021</a> but was removed from the spec in <a target="_blank" href="https://github.com/w3c/clipboard-apis/pull/155">w3c/clipboard-apis#155</a>. Prior to that change, the lists of mandatory data types were much longer, with 16 mandatory data types for reading from the clipboard, and 8 for writing to it. After the change, only <code>text/plain</code>, <code>text/html</code>, and <code>image/png</code> remained.</p>
<p>This change was made after browsers opted not to support many of the mandatory types due to <a target="_blank" href="https://webkit.org/blog/8170/clipboard-api-improvements/#custom-mime-types:~:text=into%20web%20pages.-,Custom%20MIME%20Types,-Because%20the%20system">security concerns</a>. This is reflected by a warning in the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandatory data types</a> section in the spec:</p>
<blockquote>
<p>Warning! The data types that untrusted scripts are allowed to write to the clipboard are limited as a security precaution.</p>
<p>Untrusted scripts can attempt to exploit security vulnerabilities in local software by placing data known to trigger those vulnerabilities on the clipboard.</p>
</blockquote>
<p>Okay, so we can only write a limited set of data types to the clipboard. But what's that about "<em>untrusted</em> scripts"? Can we somehow run code in a "trusted" script that lets us write other data types to the clipboard?</p>
<h3>The isTrusted property</h3>
<p>Perhaps the "trusted" part refers to the <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Event/isTrusted"><code>isTrusted</code> property on events</a>. <code>isTrusted</code> is a read-only property that is only set to true if the event was dispatched by the user agent.</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>e</span><span>.</span><span>isTrusted</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span></span></p></pre></div>
<p>Being "dispatched by the user agent" means that it was triggered by the user, such as a copy event triggered by the user pressing <span><span>Command</span><code title="Command"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.3 4V6.3H4C2.72975 6.3 1.7 5.27026 1.7 4C1.7 2.72975 2.72975 1.7 4 1.7C5.27026 1.7 6.3 2.72975 6.3 4Z" stroke="currentColor" stroke-width="1.4"></path><path d="M4 11.7H6.3V14C6.3 15.2703 5.27026 16.3 4 16.3C2.72975 16.3 1.7 15.2703 1.7 14C1.7 12.7297 2.72975 11.7 4 11.7Z" stroke="currentColor" stroke-width="1.4"></path><path d="M14 6.3H11.7V4C11.7 2.72975 12.7297 1.7 14 1.7C15.2703 1.7 16.3 2.72975 16.3 4C16.3 5.27026 15.2703 6.3 14 6.3Z" stroke="currentColor" stroke-width="1.4"></path><path d="M11.7 11.7H14C15.2703 11.7 16.3 12.7297 16.3 14C16.3 15.2703 15.2703 16.3 14 16.3C12.7297 16.3 11.7 15.2703 11.7 14V11.7Z" stroke="currentColor" stroke-width="1.4"></path><rect x="6.3" y="6.3" width="5.4" height="5.4" stroke="currentColor" stroke-width="1.4"></rect></svg></code>&nbsp;<code title="C">C</code></span>. This is in contrast to a synthetic event programmatically dispatched via <code>dispatchEvent()</code>:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"e.isTrusted is "</span><span> </span><span>+</span><span> e</span><span>.</span><span>isTrusted</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>dispatchEvent</span><span>(</span><span>new</span><span> </span><span>ClipboardEvent</span><span>(</span><span>"copy"</span><span>)</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Let's look at the clipboard events and see whether they allow us to write arbitrary data types to the clipboard.</p>
<h2>The Clipboard Events API</h2>
<p>A <code>ClipboardEvent</code> is dispatched for copy, cut, and paste events, and it contains a <code>clipboardData</code> property of type <code>DataTransfer</code>. The <code>DataTransfer</code> object is used by the Clipboard Events API to hold multiple representations of data.</p>
<p>Writing to the clipboard in a <code>copy</code> event is very straightforward:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/plain"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/html"</span><span>,</span><span> </span><span>"Hello, &lt;em&gt;world&lt;/em&gt;"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>And reading from the clipboard in a <code>paste</code> event is just as simple:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"paste"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>const</span><span> html </span><span>=</span><span> e</span><span>.</span><span>clipboardData</span><span>.</span><span>getData</span><span>(</span><span>"text/html"</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>html</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Now for the big question: can we write JSON to the clipboard?</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> json </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> message</span><span>:</span><span> </span><span>"Hello"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"application/json"</span><span>,</span><span> json</span><span>)</span><span>;</span><span> </span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>No exception is thrown, but did this actually write the JSON to the clipboard? Let's verify that by writing a paste handler that iterates over all of the entries in the clipboard and logs them out:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"paste"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> item </span><span>of</span><span> e</span><span>.</span><span>clipboardData</span><span>.</span><span>items</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> </span><span>{</span><span> kind</span><span>,</span><span> type </span><span>}</span><span> </span><span>=</span><span> item</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>kind </span><span>===</span><span> </span><span>"string"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      item</span><span>.</span><span>getAsString</span><span>(</span><span>(</span><span>content</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>{</span><span> type</span><span>,</span><span> content </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Adding both of these handlers and invoking copy-paste results in the following being logged:</p>
<div><pre><p><span>{</span><span> </span><span>"type"</span><span>:</span><span> </span><span>"application/json"</span><span>,</span><span> content</span><span>:</span><span> </span><span>"{\"message\":\"Hello\"}"</span><span> </span><span>}</span><span></span></p></pre></div>
<p>It works! It seems that <code>clipboardData.setData</code> does not restrict data types in the same manner as the async <code>write</code> method does.</p>
<p>But... why? Why can we read and write arbitrary data types using <code>clipboardData</code> but not when using the async Clipboard API?</p>
<h3>History of <code>clipboardData</code></h3>
<p>The relatively new async Clipboard API was added to the spec in <a target="_blank" href="https://www.w3.org/TR/2017/WD-clipboard-apis-20170929/">2017</a>, but <code>clipboardData</code> is <em>much</em> older than that. A W3C draft for the Clipboard API from <a target="_blank" href="https://www.w3.org/TR/2006/WD-clipboard-apis-20061115/">2006</a> defines <code>clipboardData</code> and its <code>setData</code> and <code>getData</code> methods (which shows us that MIME types were not being used at that point):</p>
<blockquote>
<p><code>setData()</code> This takes one or two parameters. The first must be set to either 'text' or 'URL' (case-insensitive).</p>
<p><code>getData()</code> This takes one parameter, that allows the target to request a specific type of data.</p>
</blockquote>
<p>But it turns out that <code>clipboardData</code> is even older than the 2006 draft. Look at this quote from the "Status of this Document" section:</p>
<blockquote>
<p>In large part [this document] describes the functionalities as implemented in Internet Explorer...</p>
<p>The intention of this document is [...] to specify what actually works in current browsers, or [be] a simple target for them to improve interoperability, rather than adding new features.</p>
</blockquote>
<p>This <a target="_blank" href="https://www.arstdesign.com/articles/clipboardexploit.html">2003 article</a> details how, at the time, in Internet Explorer 4 and above, you could use <code>clipboardData</code> to read the user's clipboard without their consent. Since Internet Explorer 4 was released in 1997 it seems that the <code>clipboardData</code> interface is at least 26 years old at the time of writing.</p>
<p>MIME types entered the <a target="_blank" href="https://www.w3.org/TR/2011/WD-clipboard-apis-20110412/">spec in 2011</a>:</p>
<blockquote>
<p>The <em>dataType</em> argument is a string, for example but not limited to a MIME type...</p>
</blockquote>
<blockquote>
<p>If a script calls getData('text/html')...</p>
</blockquote>
<p>At the time, the spec had not determined which data types should be used:</p>
<blockquote>
<p>While it is possible to use any string for setData()'s type argument, sticking to common types is recommended.</p>
<p>[Issue] Should we list some "common types"?</p>
</blockquote>
<p>Being able to use <em>any</em> string for <code>setData</code> and <code>getData</code> still holds today. This works perfectly fine:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"foo bar baz"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"paste"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> content </span><span>=</span><span> e</span><span>.</span><span>clipboardData</span><span>.</span><span>getData</span><span>(</span><span>"foo bar baz"</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>content</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>content</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>If you paste this code snippet into your DevTools and then hit copy and paste, you will see the message "Hello, world" logged to your console.</p>
<p>The reason for the Clipboard Events API's <code>clipboardData</code> allowing us to use any data type seems to be a historical one. <em>"Don't break the web"</em>.</p>
<h3>Revisiting isTrusted</h3>
<p>Let's consider this sentence from the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#mandatory-data-types-x">mandatory data types</a> section again:</p>
<blockquote>
<p>The data types that untrusted scripts are allowed to write to the clipboard are limited as a security precaution.</p>
</blockquote>
<p>So what happens if we attempt to write to the clipboard in a synthetic (untrusted) clipboard event?</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/plain"</span><span>,</span><span> </span><span>"Hello"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>dispatchEvent</span><span>(</span><span>new</span><span> </span><span>ClipboardEvent</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>  clipboardData</span><span>:</span><span> </span><span>new</span><span> </span><span>DataTransfer</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>This runs successfully, but it doesn't modify the clipboard. This is the expected behavior <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#integration-with-other-scripts-and-events">as explained in the spec</a>:</p>
<blockquote>
<p>Synthetic cut and copy events <em>must not</em> modify data on the system clipboard.</p>
</blockquote>
<blockquote>
<p>Synthetic paste events <em>must not</em> give a script access to data on the real system clipboard.</p>
</blockquote>
<p>So only copy and paste events dispatched by the user agent are allowed to modify the clipboard. Makes total sense—I wouldn't want websites to freely read my clipboard contents and steal my passwords.</p>
<hr>
<p>To summarize our findings so far:</p>
<ul>
<li>The async Clipboard API introduced in 2017 restricts which data types can be written to and read from the clipboard. However, it can read from and write to the clipboard at any time, given that the user has granted permission to do so (and the <a target="_blank" href="https://www.w3.org/TR/clipboard-apis/#privacy-async">document is focused</a>).</li>
<li>The older Clipboard Events API has no real restrictions on which data types can be written to and read from the clipboard. However, it can only be used in copy and paste event handlers triggered by the user agent (i.e. when <code>isTrusted</code> is true).</li>
</ul>
<p>It seems that using the Clipboard Events API is the only way forward if you want to write data types to the clipboard that are not just plain text, HTML, or images. It's much less restrictive in that regard.</p>
<p>But what if you want to build a Copy button that writes non-standard data types to the clipboard? It doesn't seem like you'd be able to use the Clipboard Events API if the user did not trigger a copy event. Right?</p>
<h2>Building a copy button that writes arbitrary data types</h2>
<p>I went and tried out Copy buttons in different web applications and inspected what was written to the clipboard. It yielded interesting results.</p>
<p>Google Docs has a Copy button which can be found in their right-click menu.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-copy-button.png" width="480"></p>
<p>This copy button writes three representations to the clipboard:</p>
<ul>
<li><code>text/plain</code>,</li>
<li><code>text/html</code>, and</li>
<li><code>application/x-vnd.google-docs-document-slice-clip+wrapped</code></li>
</ul>
<p>Note: <!-- -->The third representation contains JSON data.</p>
<p>They're writing a custom data type to the clipboard, which means that they aren't using the async Clipboard API. How are they doing that through a click handler?</p>
<p>I ran the profiler, hit the copy button, and inspected the results. It turns out that clicking the copy button triggers a call to <code>document.execCommand("copy")</code>.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-exec-command.png"></p>
<p>This was surprising to me. My first thought was <em>"Isn't <code>execCommand</code> the old, deprecated way of copying text to the clipboard?"</em>.</p>
<p>Yes, it is, but Google uses it for a reason. <code>execCommand</code> is special in that it allows you to programmatically dispatch a trusted copy event <em>as if</em> the user invoked the copy command themselves.</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"e.isTrusted is "</span><span> </span><span>+</span><span> e</span><span>.</span><span>isTrusted</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>document</span><span>.</span><span>execCommand</span><span>(</span><span>"copy"</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Note: <!-- -->Safari requires an active selection for <code>execCommand("copy")</code> to dispatch a copy event. That selection can be faked by adding a non-empty input element to the DOM and selecting it prior to invoking <code>execCommand("copy")</code>, after which the input can be removed from the DOM.</p>
<p>Okay, so using <code>execCommand</code> allows us to write arbitrary data types to the clipboard in response to click events. Cool!</p>
<p>What about paste? Can we use <code>execCommand("paste")</code>?</p>
<h2>Building a paste button</h2>
<p>Let's try the Paste button in Google Docs and see what it does.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-paste-button.png" width="480"></p>
<p>On my Macbook, I got a popup telling me that I need to install an extension to use the paste button.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-paste-popup.png" width="650"></p>
<p>But oddly, on my Windows laptop, the paste button just worked.</p>
<p>Weird. Where does the inconsistency come from? Well, whether or not the paste button will work can be checked by running <code>queryCommandSupported("paste")</code>:</p>
<div><pre><p><span>document</span><span>.</span><span>queryCommandSupported</span><span>(</span><span>"paste"</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>On my Macbook, I got <code>false</code> on Chrome and Firefox, but <code>true</code> on Safari.</p>
<p>Safari, being privacy-conscious, required me to confirm the paste action. I think that's a really good idea. It makes it very explicit that the website will read from your clipboard.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/google-docs-paste-confirm.png" width="650"></p>
<p>On my Windows laptop, I got <code>true</code> on Chrome and Edge, but <code>false</code> on Firefox. The inconsistency with Chrome is surprising. Why does Chrome allow <code>execCommand("paste")</code> on Windows but not macOS? I wasn't able to find any info on this.</p>
<p>I find it surprising that Google doesn't attempt to fall back to the async Clipboard API when <code>execCommand("paste")</code> is unavailable. Even though they wouldn't be able to read the <code>application/x-vnd.google-[...]</code> representation using it, the HTML representation contains internal IDs that could be used.</p>
<div><pre><p><span></span><span>&lt;</span><span>meta</span><span> </span><span>charset</span><span>=</span><span>"</span><span>utf-8</span><span>"</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>b</span><span> </span><span>id</span><span>=</span><span>"</span><span>docs-internal-guid-[guid]</span><span>"</span><span> </span><span>style</span><span>=</span><span>"</span><span>...</span><span>"</span><span>&gt;</span><span></span></p><p><span>  </span><span>&lt;</span><span>span</span><span> </span><span>style</span><span>=</span><span>"</span><span>...</span><span>"</span><span>&gt;</span><span>Copied text</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;/</span><span>b</span><span>&gt;</span><span></span></p></pre></div>
<hr>
<p>Another web application with a paste button is Figma, and they take a completely different approach. Let's see what they're doing.</p>
<h2>Copy and Paste in Figma</h2>
<p>Figma is a web-based application (their native app uses <a target="_blank" href="https://www.electronjs.org/">Electron</a>). Let's see what their copy button writes to the clipboard.</p>
<p><img src="https://alexharri.com/images/posts/clipboard/figma-copy-button.png" width="480"></p>
<p>Figma's copy button writes two representations to the clipboard: <code>text/plain</code> and <code>text/html</code>. This was surprising to me at first. How would Figma represent their various layout and styling features in plain HTML?</p>
<p>But looking at the HTML, we see two empty <code>span</code> elements with <code>data-metadata</code> and <code>data-buffer</code> properties:</p>
<div><pre><p><span>&lt;</span><span>meta</span><span> </span><span>charset</span><span>=</span><span>"</span><span>utf-8</span><span>"</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>div</span><span>&gt;</span><span></span></p><p><span>  </span><span>&lt;</span><span>span</span><span> </span><span>data-metadata</span><span>=</span><span>"</span><span>&lt;!--(figmeta)eyJma[...]9ifQo=(/figmeta)--&gt;</span><span>"</span><span>&gt;</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p><p><span>  </span><span>&lt;</span><span>span</span><span> </span><span>data-buffer</span><span>=</span><span>"</span><span>&lt;!--(figma)ZmlnL[...]P/Ag==(/figma)--&gt;</span><span>"</span><span>&gt;</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></p><p><span></span><span>&lt;</span><span>span</span><span> </span><span>style</span><span>=</span><span>"</span><span>white-space</span><span>:</span><span>pre-wrap</span><span>;</span><span>"</span><span>&gt;</span><span>Text</span><span>&lt;/</span><span>span</span><span>&gt;</span><span></span></p></pre></div>
<p>Note: <!-- -->The <code>data-buffer</code> string is ~26,000 characters for an empty frame. After that, the length of <code>data-buffer</code> seems to grow linearly with the amount of content that was copied.</p>
<p>Looks like base64. The <code>eyJ</code> start is a clear indication of <code>data-metadata</code> being a base64 encoded JSON string. Running <code>JSON.parse(atob())</code> on <code>data-metadata</code> yields:</p>
<div><pre><p><span>{</span><span></span></p><p><span>  </span><span>"fileKey"</span><span>:</span><span> </span><span>"4XvKUK38NtRPZASgUJiZ87"</span><span>,</span><span></span></p><p><span>  </span><span>"pasteID"</span><span>:</span><span> </span><span>1261442360</span><span>,</span><span></span></p><p><span>  </span><span>"dataType"</span><span>:</span><span> </span><span>"scene"</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Note: <!-- -->I've replaced the real <code>fileKey</code> and <code>pasteID</code>.</p>
<p>But what about the big <code>data-buffer</code> property? Base64 decoding it yields the following:</p>
<div><pre><p><span>fig-kiwiF\x00\x00\x00\x1CK\x00\x00µ½\v\x9CdI[...]\x197Ü\x83\x03</span></p></pre></div>
<p>Looks like a binary format. After a bit of digging—using <code>fig-kiwi</code> as a clue—I discovered that this is the <a target="_blank" href="https://github.com/evanw/kiwi">Kiwi message format</a> (created by Figma's co-founder and former CTO, <a target="_blank" href="https://github.com/evanw">Evan Wallace</a>), which is used to encode <code>.fig</code> files.</p>
<p>Since Kiwi is a schema-based format, it seemed like we wouldn't be able to parse this data without knowing the schema. However, lucky for us, Evan created a <a target="_blank" href="https://github.com/evanw/kiwi/issues/17#issuecomment-1937797254">public <code>.fig</code> file parser</a>. Let's try plugging the buffer into that!</p>
<p>To convert the buffer into a <code>.fig</code> file, I wrote a small script to generate a Blob URL:</p>
<div><pre><p><span>const</span><span> base64 </span><span>=</span><span> </span><span>"ZmlnL[...]P/Ag=="</span><span>;</span><span></span></p><p><span></span><span>const</span><span> blob </span><span>=</span><span> </span><span>base64toBlob</span><span>(</span><span>base64</span><span>,</span><span> </span><span>"application/octet-stream"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>URL</span><span>.</span><span>createObjectURL</span><span>(</span><span>blob</span><span>)</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>I then downloaded the resulting blob as a <code>.fig</code> file, uploaded that to the <code>.fig</code> file parser, and voilà:</p>
<p><img src="https://alexharri.com/images/posts/clipboard/figma-data.png" width="620"></p>
<p>So copying in Figma works by creating a small Figma file, encoding that as a base64, placing the resulting base64 string into the <code>data-buffer</code> attribute of an empty HTML <code>span</code> element, and storing that in the user's clipboard.</p>
<h3>The benefits of copy-pasting HTML</h3>
<p>This seemed a bit silly to me at first, but there is a strong benefit to taking that approach. To understand why, consider how the web-based Clipboard API interacts with the various operating system Clipboard APIs.</p>
<p>Windows, macOS, and Linux all offer different formats for writing data to the clipboard. If you want to write HTML to the clipboard, <a target="_blank" href="https://learn.microsoft.com/en-us/windows/win32/dataxchg/html-clipboard-format">Windows has <code>CF_HTML</code></a> and <a target="_blank" href="https://developer.apple.com/documentation/appkit/nspasteboard/pasteboardtype/1529057-html">macOS has <code>NSPasteboard.PasteboardType.html</code></a>.</p>
<p>All of the operating systems offer types for "standard" formats (plain text, HTML, and PNG images). But which OS format should the browser use when the user attempts to write an arbitrary data type like <code>application/foo-bar</code> to the clipboard?</p>
<p>There isn't a good match, so the browser doesn't write that representation to common formats on the OS clipboard. Instead, that representation only exists within a custom browser-specific clipboard format on the OS clipboard. This results in being able to copy and paste arbitrary data types across browser tabs, but <em>not</em> across applications.</p>
<p>This is why using the common data types <code>text/plain</code>, <code>text/html</code> and <code>image/png</code> is so convenient. They are mapped to common OS clipboard formats and as such can be easily read by other applications, which makes copy/paste work across applications. In Figma's case, using <code>text/html</code> enables copying a Figma element from <code>figma.com</code> in the browser and then pasting it into the native Figma app, and vice versa.</p>
<h2>What do browsers write to the clipboard for custom data types?</h2>
<p>We've learned that we can write and read custom data types to and from the clipboard across browser tabs, but not across applications. But what exactly are browsers writing to the native OS clipboard when we write custom data types to the web clipboard?</p>
<p>I ran the following in a <code>copy</code> listener in each of the major browsers on my Macbook:</p>
<div><pre><p><span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"copy"</span><span>,</span><span> </span><span>(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  e</span><span>.</span><span>preventDefault</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/plain"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"text/html"</span><span>,</span><span> </span><span>"&lt;em&gt;Hello, world&lt;/em&gt;"</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"application/json"</span><span>,</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> type</span><span>:</span><span> </span><span>"Hello, world"</span><span> </span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>  e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>"foo bar baz"</span><span>,</span><span> </span><span>"Hello, world"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>I then inspected the clipboard using <a target="_blank" href="https://apps.apple.com/us/app/pasteboard-viewer/id1499215709">Pasteboard Viewer</a>. Chrome adds four entries to the Pasteboard:</p>
<ul>
<li><code>public.html</code> contains the HTML representation.</li>
<li><code>public.utf8-plain-text</code> contains the plain text representation.</li>
<li><code>org.chromium.web-custom-data</code> contains the custom representations.</li>
<li><code>org.chromium.source-url</code> contains the URL of the web page where the copy was performed.</li>
</ul>
<p>Looking at the <code>org.chromium.web-custom-data</code>, we see the data we copied:</p>
<p><img src="https://alexharri.com/images/posts/clipboard/pasteboard-chrome.png"></p>
<p>I imagine the accented "î" and inconsistent line breaks are the result of some delimiters being displayed incorrectly.</p>
<p>Firefox creates the <code>public.html</code> and <code>public.utf8-plain-text</code> entries as well, but writes the custom data to <code>org.mozilla.custom-clipdata</code>. It does not store the source URL like Chrome does.</p>
<p>Safari, as you might expect, also creates the <code>public.html</code> and <code>public.utf8-plain-text</code> entries. It writes the custom data to <code>com.apple.WebKit.custom-pasteboard-data</code> and, interestingly, it also stores the full list of representations (including plain text and HTML) and source URL there.</p>
<p>Note: <!-- -->Safari allows copy-pasting custom data types across browser tabs if the source URL (domain) is the same, but not across different domains. This limitation does not seem to be present in Chrome or Firefox (even though Chrome stores the source URL).</p>
<h2>Raw Clipboard Access for the Web</h2>
<p>A proposal for <a target="_blank" href="https://github.com/WICG/raw-clipboard-access/blob/f58f5cedc753d55c77994aa05e75d5d2ad7344a7/explainer.md">Raw Clipboard Access</a> was created in 2019, which proposed an API for giving web applications raw read and write access to the native OS clipboards.</p>
<p>This excerpt from the <a target="_blank" href="https://chromestatus.com/feature/5682768497344512">Motivation section on chromestatus.com</a> for the Raw Clipboard Access feature highlights the benefits rather succinctly:</p>
<blockquote>
<p>Without Raw Clipboard Access [...] web applications are generally limited to a small subset of formats, and are unable to interoperate with the long tail of formats. For example, Figma and Photopea are unable to interoperate with most image formats.</p>
</blockquote>
<p>However, the Raw Clipboard Access proposal ended up not being taken further due to <a target="_blank" href="https://github.com/WICG/raw-clipboard-access/blob/f58f5cedc753d55c77994aa05e75d5d2ad7344a7/explainer.md#stakeholder-feedback--opposition">security concerns</a> around exploits such as remote code execution in native applications.</p>
<p>The most recent proposal for writing custom data types to the clipboard is the Web Custom Formats proposal (often referred to as pickling).</p>
<h2>Web Custom Formats (Pickling)</h2>
<p>In 2022, Chromium implemented support for <a target="_blank" href="https://developer.chrome.com/blog/web-custom-formats-for-the-async-clipboard-api">Web Custom Formats</a> in the async Clipboard API.</p>
<p>It allows web applications to write custom data types via the async Clipboard API by prefixing the data type with <code>"web "</code>:</p>
<div><pre><p><span></span><span>const</span><span> json </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> message</span><span>:</span><span> </span><span>"Hello, world"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> jsonBlob </span><span>=</span><span> </span><span>new</span><span> </span><span>Blob</span><span>(</span><span>[</span><span>json</span><span>]</span><span>,</span><span> </span><span>{</span><span> type</span><span>:</span><span> </span><span>"application/json"</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>const</span><span> clipboardItem </span><span>=</span><span> </span><span>new</span><span> </span><span>ClipboardItem</span><span>(</span><span>{</span><span></span></p><p><span>  </span><span>[</span><span>`</span><span>web </span><span>${</span><span>jsonBlob</span><span>.</span><span>type</span><span>}</span><span>`</span><span>]</span><span>:</span><span> jsonBlob</span><span>,</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>navigator</span><span>.</span><span>clipboard</span><span>.</span><span>write</span><span>(</span><span>[</span><span>clipboardItem</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>These are read using the async Clipboard API like any other data type:</p>
<div><pre><p><span>const</span><span> items </span><span>=</span><span> </span><span>await</span><span> navigator</span><span>.</span><span>clipboard</span><span>.</span><span>read</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>for</span><span> </span><span>(</span><span>const</span><span> item </span><span>of</span><span> items</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>item</span><span>.</span><span>types</span><span>.</span><span>includes</span><span>(</span><span>"web application/json"</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> blob </span><span>=</span><span> </span><span>await</span><span> item</span><span>.</span><span>getType</span><span>(</span><span>"web application/json"</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> json </span><span>=</span><span> </span><span>await</span><span> blob</span><span>.</span><span>text</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>What's more interesting is what is written to the native clipboard. When writing web custom formats, the following is written to the native OS clipboard:</p>
<ul>
<li>A mapping from the data types to clipboard entry names</li>
<li>Clipboard entries for each data type</li>
</ul>
<p>On macOS, the mapping is written to <code>org.w3.web-custom-format.map</code> and its content looks like so:</p>
<div><pre><p><span>{</span><span></span></p><p><span>  </span><span>"application/json"</span><span>:</span><span> </span><span>"org.w3.web-custom-format.type-0"</span><span>,</span><span></span></p><p><span>  </span><span>"application/octet-stream"</span><span>:</span><span> </span><span>"org.w3.web-custom-format.type-1"</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>The <code>org.w3.web-custom-format.type-[index]</code> keys correspond to entries on the OS clipboard containing the unsanitized data from the blobs. This allows native applications to look at the mapping to see if a given representation is available and then read the unsanitized content from the corresponding clipboard entry.</p>
<p>Note: <!-- -->Windows and Linux <a target="_blank" href="https://github.com/dway123/clipboard-pickling/blob/bce5101564d379f48f11839e2c141ee51438e13c/explainer.md#os-interaction-format-naming">use a different naming convention</a> for the mapping and clipboard entries.</p>
<p>This avoids the security issues around raw clipboard access since web applications cannot write unsanitized data to whatever OS clipboard format they want to. That comes with an interoperability trade-off that is explicitly listed in the <a target="_blank" href="https://github.com/dway123/clipboard-pickling/blob/bce5101564d379f48f11839e2c141ee51438e13c/explainer.md#non-goals">Pickling for Async Clipboard API spec</a>:</p>
<blockquote>
<h4>Non-goals</h4>
<p>Allow interoperability with legacy native applications, without update. This was explored in a raw clipboard proposal, and may be explored further in the future, but comes with significant security challenges (remote code execution in system native applications).</p>
</blockquote>
<p>This means that native applications need to be updated for clipboard interop with web applications when using custom data types.</p>
<p>Web Custom Formats have been available in Chromium-based browsers since 2022, but other browsers have not implemented this proposal yet.</p>
<h2>Final words</h2>
<p>As of right now, there isn't a great way to write custom data types to the clipboard that works across all browsers. Figma's approach of placing base64 strings into an HTML representation is crude but effective in that it circumvents the plethora of limitations around the clipboard API. It seems like a good approach to take if you need to transmit custom data types via the clipboard.</p>
<p>I find the Web Custom Formats proposal promising, and I hope it becomes implemented by all of the major browsers. It seems like it would enable writing custom data types to the clipboard in a secure and practical manner.</p>
<p>Thanks for reading! I hope this was interesting.</p>
<p>— Alex Harri</p><div><p>Mailing list</p><div><p>To be notified of new posts, subscribe to my mailing list.</p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anarchy in Sudan has spawned the world’s worst famine in 40 years (220 pts)]]></title>
            <link>https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years</link>
            <guid>41415819</guid>
            <pubDate>Sun, 01 Sep 2024 10:48:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years">https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years</a>, See on <a href="https://news.ycombinator.com/item?id=41415819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><p><span><a href="https://www.economist.com/briefing" data-analytics="sidebar:section"><span>Briefing</span></a></span><span> | <!-- -->An intensifying calamity</span></p><h2>Anarchy in Sudan has spawned the world’s worst famine in 40 years</h2><h2>Millions are likely to perish</h2></section><section><figure><img alt="Sudanese refugees wait for food distribution at a camp in Chad" fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg"><figcaption><span>Photograph: Panos Pictures/ Sven Torfinn</span></figcaption></figure></section><div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">I</span><small>T IS OFFICIAL</small>: for only the third time in the past 20 years, the <small>UN</small> has declared a full-blown famine. The declaration concerns a refugee camp called Zamzam, on the outskirts of the city of el-Fasher in Sudan. As long ago as April, Médecins Sans Frontières, a charity, estimated that every two hours a child in the camp was dying from starvation or disease—and since then the situation has got worse.</p></section><p>This article appeared in the Briefing section of the print edition under the headline “An intensifying calamity”</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Sudan: Why its catastrophic war is the world’s problem" loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the August 31st 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-08-31" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Einstein's Other Theory of Everything (125 pts)]]></title>
            <link>https://nautil.us/einsteins-other-theory-of-everything-823245/</link>
            <guid>41415647</guid>
            <pubDate>Sun, 01 Sep 2024 10:09:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/einsteins-other-theory-of-everything-823245/">https://nautil.us/einsteins-other-theory-of-everything-823245/</a>, See on <a href="https://news.ycombinator.com/item?id=41415647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>E</span>instein finished his masterwork, the theory of general relativity, in 1915. He was 37 years old and would live for another 40 years. He spent these decades in the attempt to explain that everything—matter, energy, and even ourselves—were simply deformations of spacetime.&nbsp;</p><p>Einstein, feeling that his theory of general relativity was incomplete, wanted to develop a unified field theory—a framework that would combine space and time with energy and matter. (Indeed, it was Einstein who coined the term “unified theory.”) He ultimately failed. But I have begun to wonder if his idea, as ambitious as it was startling, isn’t worth revisiting.</p>
      
    <p>Einstein built his unified theory off of general relativity, which says that gravity is a property of spacetime. This is often depicted with a marble that weighs down a rubber sheet. The rubber sheet is spacetime, the marble’s mass provides gravity. If a smaller marble rolls by the larger one, it will not roll in a straight line. It will roll in a curve as if it was attracted to the bigger marble. You need that marble to cause the curvature in the first place. It’s the same in Einstein’s general relativity: You need spacetime <em>and</em> matter in it to describe what we see happening in the universe.</p><p>Einstein seems to have tried to find a theory in which there is <em>only</em> spacetime and <em>no</em> matter—and in which we only interpret some of the spacetime as matter. He wanted to find equations that would have solutions that correspond to the fundamental particles of nature, such as electrons.</p>
          <blockquote>
<p>Einstein and Rosen assumed the black hole has no inside and instead connects two universes.</p>
</blockquote><p>When Einstein set out to find this theory, in the first half of the 20th century, physicists’ knowledge of the properties of matter and how it behaved were incomplete. Today, we know of four fundamental interactions. Beside gravity, there’s electromagnetism and the strong and weak nuclear interactions. But in the early 20th century, the strong nuclear interaction had not yet been discovered, and the theory for the weak nuclear interaction had not yet been developed. Einstein therefore really only had two interactions to work with to make sense of matter: gravity and electromagnetism. The gravitational force law, also known as Newton’s law, is similar to that for electric charges, known as Coulomb’s law. And because Einstein had been so successful with describing gravity as the curvature of space, he wondered whether electromagnetism could be described in much the same way.</p><p>In 1919, Einstein published a <a href="https://einsteinpapers.press.princeton.edu/vol7-trans/96" target="_blank" rel="noreferrer noopener">paper</a> titled “Do gravitational fields play an essential role in the structure of the elementary particles of matter?” The idea he pursued in the paper was to take a modified version of general relativity, with different field equations, then add electromagnetism and ask whether this would give rise to solutions that could be interpreted as particles.</p><p>The conclusion he arrived at is: No, this doesn’t work because the quantity that could be interpreted as mass could take on any value, whereas the particles that matter are made of have very specific values.</p>
          <p>In 1923, he published another paper in which he basically said that his previous idea to make matter from spacetime didn’t work because there were some equations missing. He then proposed some equations that might do the job … but again concluded that this doesn’t work</p><p>In 1925, he published yet <em>another</em> paper in which he said that he had been trying for two years to combine electromagnetism with gravity, and it didn’t work.&nbsp;</p><p>But Einstein had another clue for his unified theory: black holes.</p><p>You see, as soon as Einstein had finished his theory of general relativity, the German physicist and astronomer Karl Schwarzschild discovered a solution to Einstein’s equations that described what we now call black holes. But this solution has singularities, places where some quantities take on infinite values. Einstein thought that this couldn’t be right. Singularities shouldn’t happen in reality. And if his theory allowed those, then there was something wrong with it. He therefore tried to use the requirement that singularities should be absent to go back and find solutions that would describe elementary particles.</p>
          <p>But he made a mistake there. In Schwarzschild’s black hole solution, there isn’t just one singularity, but two. One is at the horizon of the black hole, the other in the center. We know today that the singularity at the horizon does not correspond to any physically measurable quantity. It’s a mathematical artifact that can be removed. Einstein tried to find a way to remove this singularity that wasn’t there. (You’d think that physicists would have learned from this that it’s a mistake to go on about the properties of unobservable quantities, but still, it’s the same mistake that led to all these wrong predictions for the Large Hadron Collider. But I digress.)</p><blockquote>
<p>I want to call this Einstein’s Other Theory of Everything: that matter is really just made of spacetime.</p>
</blockquote><div><p>Einstein’s quest to get rid of black hole singularities is what led to his famous paper with Nathan Rosen in 1935, in which they introduced what is now called an Einstein-Rosen bridge. They assumed the black hole has no inside and instead connects two universes. It’s the simplest known example of a wormhole.</p><p>But they didn’t write the paper to introduce wormholes. Einstein and Rosen thought these wormholes were elementary particles. After they’d constructed their bridge, they wrote very clearly, “We see now in the given solution, free from singularities, the mathematical representation of an elementary particle (neutrons or neutrinos).”</p></div><div><p>They then went on to add electric charges and interpreted those as charged particles. Now, we know today that neutrons are not elementary particles, they are made of smaller particles (quarks and gluons). But this wasn’t the main problem with the idea. The main problem is that one can calculate the size of the bridge, or wormhole, or whatever you want to call it, from its mass. And that’d tell you that the “size” of a neutron would be about 10<sup>-52</sup> centimeters. That’s more than 30 orders of magnitude smaller than its actual size. For other elementary particles, this becomes even more extreme.</p><p>This means that if elementary particles were wormholes or black holes, they would be much smaller than the quantum uncertainty that we measure. (Stephen Hawking also taught us that they’d be unstable, but again, Einstein couldn’t have known this.)</p></div>
          <div><p>In any case, he didn’t pursue this idea further. Instead, he pursued a different direction which he had proposed in 1925: that the properties of matter are encoded in the relations between different locations in spacetime, an approach that he dubbed “tele-parallelism.” It is this tele-parallelism that later became known as Einstein’s unified field theory. It has, however, little to do with his original idea.</p><p>This teleparallel approach to a unified field theory was not pursued after Einstein’s death in 1955. Because by then it had become clear that it wasn’t compatible with the new things that physicists had discovered, such as the weak and strong nuclear forces.</p></div><p>That said, I find it somewhat surprising—and maybe even concerning—that physicists have also thrown out Einstein’s original idea, that I want to call his Other Theory of Everything: that matter is really just made of spacetime, curved in a particular way. The notion has survived in some areas of physics, where such objects are known as “solitons”—or noise-free subsystems—but mostly it’s been given up.&nbsp;</p><p>It has been replaced by a different idea of unification, that matter and spacetime are both made of something else, such as, for example, strings or loops or networks.</p><p>So why am I returning to this old story? Primarily because I think it’s interesting what Einstein, undoubtedly one of the most intelligent people to walk on this planet, did with much of his life. But also because I don’t want Einstein’s idea—about what we and the universe might be made out of—to be forgotten. <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p>
          <p><em>Lead image: Muhammad suryanto / Shutterstock</em></p>              
                            <ul>
                                      <li>
                      <div>
                        <h6>
                          Sabine Hossenfelder                        </h6>
                        <p>
                          Posted on <time datetime="2024-08-30T10:39:35-05:00">August 30, 2024</time>
                        </p>
                      </div>
                                                <p>
                            Sabine Hossenfelder is a theoretical physicist at the Munich Center for Mathematical Philosophy, in Germany, focusing on modifications of general relativity, phenomenological quantum gravity, and the foundations of quantum mechanics. She is the creative director of the YouTube channel <a href="https://www.youtube.com/channel/UC1yNl2E66ZzKApQdRuTQ4tw">“Science without the gobbledygook”</a> where she talks about recent scientific developments and debunks hype. Her latest book is <i><a href="https://www.penguinrandomhouse.com/books/616868/existential-physics-by-sabine-hossenfelder/">Existential Physics: A Scientist’s Guide to Life’s Biggest Questions</a></i>. Follow her on X (formerly known as Twitter) <a href="https://twitter.com/skdh">@skdh</a>.                          </p>
                                            </li>
                                  </ul>
            <div>
  <p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
    <h4>Get the Nautilus newsletter</h4>
    <p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
  </div>

  
</div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Honey, I shrunk {fmt}: bringing binary size to 14k and ditching the C++ runtime (199 pts)]]></title>
            <link>https://vitaut.net/posts/2024/binary-size/</link>
            <guid>41415238</guid>
            <pubDate>Sun, 01 Sep 2024 08:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vitaut.net/posts/2024/binary-size/">https://vitaut.net/posts/2024/binary-size/</a>, See on <a href="https://news.ycombinator.com/item?id=41415238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div v-pre=""><p><img src="https://vitaut.net/img/kennedy.jpg#floatright" alt="" title="We do this not because it is easy, but because we thought it would be easy."></p><p><a href="https://github.com/fmtlib/fmt">The {fmt} formatting library</a> is known for its small binary footprint,
often producing code that is several times smaller per function call compared
to alternatives like IOStreams, Boost Format, or, somewhat ironically,
tinyformat. This is mainly achieved through careful application of type erasure
on various levels, which effectively minimizes template bloat.</p><p>Formatting arguments are passed via type-erased <code>format_args</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>vformat</span><span>(</span><span>string_view</span> <span>fmt</span><span>,</span> <span>format_args</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>string</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>template</span> <span>&lt;</span><span>typename</span><span>...</span> <span>T</span><span>&gt;</span>
</span></span><span><span><span>auto</span> <span>format</span><span>(</span><span>format_string</span><span>&lt;</span><span>T</span><span>...</span><span>&gt;</span> <span>fmt</span><span>,</span> <span>T</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>string</span> <span>{</span>
</span></span><span><span>  <span>return</span> <span>vformat</span><span>(</span><span>fmt</span><span>,</span> <span>fmt</span><span>::</span><span>make_format_args</span><span>(</span><span>args</span><span>...));</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>As you can see, <code>format</code> delegates all its work to <code>vformat</code>, which is not a
template.</p><p>Output iterators and other output types are also type-erased through a specially
designed buffer API.</p><p>This approach confines template usage to a minimal top-level layer, leading to
both a smaller binary size and <a href="https://vitaut.net/posts/2024/faster-cpp-compile-times/">faster build times</a>.</p><p>For example, the following code:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>// test.cc
</span></span></span><span><span><span></span><span>#include</span> <span>&lt;fmt/base.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>  <span>fmt</span><span>::</span><span>print</span><span>(</span><span>"The answer is {}."</span><span>,</span> <span>42</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>compiles to just</p><pre tabindex="0"><code>.LC0:
        .string "The answer is {}."
main:
        sub     rsp, 24
        mov     eax, 1
        mov     edi, OFFSET FLAT:.LC0
        mov     esi, 17
        mov     rcx, rsp
        mov     rdx, rax
        mov     DWORD PTR [rsp], 42
        call    fmt::v11::vprint(fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::basic_format_args&lt;fmt::v11::context&gt;)
        xor     eax, eax
        add     rsp, 24
        ret
</code></pre><p><a href="https://godbolt.org/z/PMKdPPnYn">godbolt</a></p><p>It is much smaller than the equivalent IOStreams code and comparable to that
of <code>printf</code>:</p><pre tabindex="0"><code>.LC0:
        .string "The answer is %d."
main:
        sub     rsp, 8
        mov     esi, 42
        mov     edi, OFFSET FLAT:.LC0
        xor     eax, eax
        call    printf
        xor     eax, eax
        add     rsp, 8
        ret
</code></pre><p><a href="https://godbolt.org/z/soTjfno71">godbolt</a></p><p>Unlike <code>printf</code>, {fmt} offers full runtime type safety. Errors in format strings
can be caught at compile time, and even when the format string is determined at
runtime, errors are managed through exceptions, preventing undefined behavior,
memory corruption, and potential crashes. Additionally, {fmt} calls are
generally more efficient, particularly when using positional arguments, which C
varargs are not well-suited for.</p><p>Back in 2020, I dedicated some time to <a href="https://vitaut.net/posts/2020/reducing-library-size/">optimizing the library size</a>,
successfully reducing it to under 100kB (just ~57kB with <code>-Os -flto</code>).
A lot has changed since then. Most notably, {fmt} now uses the exceptional
<a href="https://github.com/jk-jeon/dragonbox">Dragonbox</a> algorithm for floating-point formatting, kindly
contributed by its author, Junekey Jeon. Let’s explore how these changes have
impacted the binary size and see if further reductions are possible.</p><p>But why, some say, the binary size? Why choose this as our goal?</p><p>There has been considerable interest in using {fmt} on memory-constrained
devices, see e.g. <a href="https://github.com/fmtlib/fmt/issues/758">#758</a> and <a href="https://github.com/fmtlib/fmt/issues/1226">#1226</a> for just two examples from
the distant past. A particularly intriguing use case is retro computing, with
people using {fmt} on systems like Amiga (<a href="https://github.com/fmtlib/fmt/issues/4054">#4054</a>).</p><p>We’ll apply the same methodology as in <a href="https://vitaut.net/posts/2020/reducing-library-size/">previous work</a>, examining the
executable size of a program that uses {fmt}, as this is most relevant to end
users. All tests will be conducted on an aarch64 Ubuntu 22.04 system with GCC
11.4.0.</p><p>First, let’s establish the baseline: what is the binary size for the latest
version of {fmt} (11.0.2)?</p><pre tabindex="0"><code>$ git checkout 11.0.2
$ g++ -Os -flto -DNDEBUG -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 75K Aug 30 19:24 a.out
</code></pre><p>The resulting binary size is 75kB (stripped). The positive takeaway is that
despite numerous developments over the past four years, the size has not
significantly regressed.</p><p>Now, let’s explore potential optimizations. One of the first adjustments you
might consider is disabling locale support. All the formatting in {fmt} is
locale-independent by default (which breaks with the C++’s tradition of having
wrong defaults), but it is still available as an opt in via the <code>L</code> format
specifier. It can be disabled in a somewhat obscure way via the
<code>FMT_STATIC_THOUSANDS_SEPARATOR</code> macro:</p><pre tabindex="0"><code>$ g++ -Os -flto -DNDEBUG "-DFMT_STATIC_THOUSANDS_SEPARATOR=','" \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 71K Aug 30 19:25 a.out
</code></pre><p>Disabling locale support reduces the binary size to 71kB.</p><p>Next, let’s examine the results using our trusty tool, <a href="https://github.com/google/bloaty">Bloaty</a>:</p><pre tabindex="0"><code>$ bloaty -d symbols a.out

    FILE SIZE        VM SIZE
 --------------  --------------
  43.8%  41.1Ki  43.6%  29.0Ki    [121 Others]
   6.4%  6.04Ki   8.1%  5.42Ki    fmt::v11::detail::do_write_float&lt;&gt;()
   5.9%  5.50Ki   7.5%  4.98Ki    fmt::v11::detail::write_int_noinline&lt;&gt;()
   5.7%  5.32Ki   5.8%  3.88Ki    fmt::v11::detail::write&lt;&gt;()
   5.4%  5.02Ki   7.2%  4.81Ki    fmt::v11::detail::parse_replacement_field&lt;&gt;()
   3.9%  3.69Ki   3.7%  2.49Ki    fmt::v11::detail::format_uint&lt;&gt;()
   3.2%  3.00Ki   0.0%       0    [section .symtab]
   2.7%  2.50Ki   0.0%       0    [section .strtab]
   2.3%  2.12Ki   2.9%  1.93Ki    fmt::v11::detail::dragonbox::to_decimal&lt;&gt;()
   2.0%  1.89Ki   2.4%  1.61Ki    fmt::v11::detail::write_int&lt;&gt;()
   2.0%  1.88Ki   0.0%       0    [ELF Section Headers]
   1.9%  1.79Ki   2.5%  1.66Ki    fmt::v11::detail::write_float&lt;&gt;()
   1.9%  1.78Ki   2.7%  1.78Ki    [section .dynstr]
   1.8%  1.72Ki   2.4%  1.62Ki    fmt::v11::detail::format_dragon()
   1.8%  1.68Ki   1.5%    1016    fmt::v11::detail::format_decimal&lt;&gt;()
   1.6%  1.52Ki   2.1%  1.41Ki    fmt::v11::detail::format_float&lt;&gt;()
   1.6%  1.49Ki   0.0%       0    [Unmapped]
   1.5%  1.45Ki   2.2%  1.45Ki    [section .dynsym]
   1.5%  1.45Ki   2.0%  1.31Ki    fmt::v11::detail::write_loc()
   1.5%  1.44Ki   2.2%  1.44Ki    [section .rodata]
   1.5%  1.40Ki   1.1%     764    fmt::v11::detail::do_write_float&lt;&gt;()::{lambda()#2}::operator()()
 100.0%  93.8Ki 100.0%  66.6Ki    TOTAL
</code></pre><p>Unsurprisingly, a significant portion of the binary size is dedicated to numeric
formatting, particularly floating-point numbers. FP formatting also relies on
sizable tables, which aren’t shown here. But what if floating-point support
isn’t required? {fmt} provides a way to disable it, though the method is
somewhat ad hoc and doesn’t extend to other types.</p><p>The core issue is that formatting functions need to be aware of all formattable
types. Or do they? This is true for <code>printf</code> as defined by the C standard, but
not necessarily for {fmt}. {fmt} supports an extension API that allows
formatting arbitrary types without knowing the complete set of types in advance.
While built-in and string types are handled specially for performance reasons,
focusing on binary size might warrant a different approach. By removing this
special handling and routing every type through the extension API, you can avoid
paying for types you don’t use.</p><p>I did an experimental <a href="https://github.com/fmtlib/fmt/commit/377cf20">implementation of this idea</a>. With the
<code>FMT_BUILTIN_TYPES</code> macro set to 0, only <code>int</code> is handled specially, and all
other types go through the general extension API. We still need to know about
<code>int</code> for dynamic width and precision, for example</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>fmt</span><span>::</span><span>print</span><span>(</span><span>"{:{}}</span><span>\n</span><span>"</span><span>,</span> <span>"hello"</span><span>,</span> <span>10</span><span>);</span> <span>// prints "hello     "
</span></span></span></code></pre></div><p>This gives you the “don’t pay for what you don’t use” model, though it comes
with a slight increase in per-call binary size. If you do format floating-point
numbers or other types, the relevant code will still be included in the build.
While it’s possible to make the FP implementation smaller, we won’t delve into
that here.</p><p>With <code>FMT_BUILTIN_TYPES=0</code>, the binary size in our example reduced to 31kB,
representing a substantial improvement:</p><pre tabindex="0"><code>$ git checkout 377cf20
$ g++ -Os -flto -DNDEBUG \
      "-DFMT_STATIC_THOUSANDS_SEPARATOR=','" -DFMT_BUILTIN_TYPES=0 \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 31K Aug 30 19:37 a.out
</code></pre><p>However, the updated Bloaty results reveal some lingering locale artifacts,
such as <code>digit_grouping</code>:</p><pre tabindex="0"><code>$ bloaty -d fullsymbols a.out

    FILE SIZE        VM SIZE
 --------------  --------------
  41.8%  18.0Ki  39.7%  11.0Ki    [84 Others]
   6.4%  2.77Ki   0.0%       0    [section .symtab]
   5.3%  2.28Ki   0.0%       0    [section .strtab]
   4.6%  1.99Ki   6.9%  1.90Ki    fmt::v11::detail::format_handler&lt;char&gt;::on_format_specs(int, char const*, char const*)
   4.4%  1.88Ki   0.0%       0    [ELF Section Headers]
   4.1%  1.78Ki   5.8%  1.61Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int_noinline&lt;char, fmt::v11::basic_appender&lt;char&gt;, unsigned int&gt;(fmt::v11::basic_appender&lt;char&gt;, fmt::v11::detail::write_int_arg&lt;unsigned int&gt;, fmt::v11::format_specs const&amp;, fmt::v11::detail::locale_ref) (.constprop.0)
   3.7%  1.60Ki   5.8%  1.60Ki    [section .dynstr]
   3.5%  1.50Ki   4.8%  1.34Ki    void fmt::v11::detail::vformat_to&lt;char&gt;(fmt::v11::detail::buffer&lt;char&gt;&amp;, fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::detail::vformat_args&lt;char&gt;::type, fmt::v11::detail::locale_ref) (.constprop.0)
   3.5%  1.49Ki   4.9%  1.35Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int&lt;fmt::v11::basic_appender&lt;char&gt;, unsigned __int128, char&gt;(fmt::v11::basic_appender&lt;char&gt;, unsigned __int128, unsigned int, fmt::v11::format_specs const&amp;, fmt::v11::detail::digit_grouping&lt;char&gt; const&amp;)
   3.1%  1.31Ki   4.7%  1.31Ki    [section .dynsym]
   3.0%  1.29Ki   4.2%  1.15Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int&lt;fmt::v11::basic_appender&lt;char&gt;, unsigned long, char&gt;(fmt::v11::basic_appender&lt;char&gt;, unsigned long, unsigned int, fmt::v11::format_specs const&amp;, fmt::v11::detail::digit_grouping&lt;char&gt; const&amp;)
</code></pre><p>After disabling these artifacts in commits <a href="https://github.com/fmtlib/fmt/commit/e582d37">e582d37</a> and
<a href="https://github.com/fmtlib/fmt/commit/b3ccc2d">b3ccc2d</a>, and introducing a more user-friendly option to opt out via
the <code>FMT_USE_LOCALE</code> macro, the binary size drops to 27kB:</p><pre tabindex="0"><code>$ git checkout b3ccc2d
$ g++ -Os -flto -DNDEBUG -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 27K Aug 30 19:38 a.out
</code></pre><p>The library includes several areas where size is traded off for speed.
For example, consider this function used to compute the number of decimal
digits:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>do_count_digits</span><span>(</span><span>uint32_t</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span><span>// An optimization by Kendall Willets from https://bit.ly/3uOIQrB.
</span></span></span><span><span><span>// This increments the upper 32 bits (log10(T) - 1) when &gt;= T is added.
</span></span></span><span><span><span></span><span>#  define FMT_INC(T) (((sizeof(#T) - 1ull) &lt;&lt; 32) - T)
</span></span></span><span><span><span></span>  <span>static</span> <span>constexpr</span> <span>uint64_t</span> <span>table</span><span>[]</span> <span>=</span> <span>{</span>
</span></span><span><span>      <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>          <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>          <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>           <span>// 8
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>         <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>         <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>          <span>// 64
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>        <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>        <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>         <span>// 512
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>       <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>       <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>        <span>// 4096
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>       <span>// 32k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>     <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>     <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>      <span>// 256k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>    <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>    <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>     <span>// 2048k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>   <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>   <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>    <span>// 16M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>  <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>  <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>   <span>// 128M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span>  <span>// 1024M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>)</span>                        <span>// 4B
</span></span></span><span><span><span></span>  <span>};</span>
</span></span><span><span>  <span>auto</span> <span>inc</span> <span>=</span> <span>table</span><span>[</span><span>__builtin_clz</span><span>(</span><span>n</span> <span>|</span> <span>1</span><span>)</span> <span>^</span> <span>31</span><span>];</span>
</span></span><span><span>  <span>return</span> <span>static_cast</span><span>&lt;</span><span>int</span><span>&gt;</span><span>((</span><span>n</span> <span>+</span> <span>inc</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>The table used here is 256 bytes. There isn’t a one-size-fits-all solution,
and changing it unconditionally might negatively impact other use cases.
Fortunately, we have a fallback implementation of this function for scenarios
where <code>__builtin_clz</code> is unavailable, such as with <code>constexpr</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span> <span>constexpr</span> <span>auto</span> <span>count_digits_fallback</span><span>(</span><span>T</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span>  <span>int</span> <span>count</span> <span>=</span> <span>1</span><span>;</span>
</span></span><span><span>  <span>for</span> <span>(;;)</span> <span>{</span>
</span></span><span><span>    <span>// Integer division is slow so do it for a group of four digits instead
</span></span></span><span><span><span></span>    <span>// of for every digit. The idea comes from the talk by Alexandrescu
</span></span></span><span><span><span></span>    <span>// "Three Optimization Tips for C++". See speed-test for a comparison.
</span></span></span><span><span><span></span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>10</span><span>)</span> <span>return</span> <span>count</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>100</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>1</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>1000</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>2</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>10000</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>3</span><span>;</span>
</span></span><span><span>    <span>n</span> <span>/=</span> <span>10000u</span><span>;</span>
</span></span><span><span>    <span>count</span> <span>+=</span> <span>4</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>All that remains is to provide users with control over when to use the fallback
implementation via (you guessed it) another configuration macro,
<code>FMT_OPTIMIZE_SIZE</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>count_digits</span><span>(</span><span>uint32_t</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span><span>#ifdef FMT_BUILTIN_CLZ
</span></span></span><span><span><span></span>  <span>if</span> <span>(</span><span>!</span><span>is_constant_evaluated</span><span>()</span> <span>&amp;&amp;</span> <span>!</span><span>FMT_OPTIMIZE_SIZE</span><span>)</span> <span>return</span> <span>do_count_digits</span><span>(</span><span>n</span><span>);</span>
</span></span><span><span><span>#endif
</span></span></span><span><span><span></span>  <span>return</span> <span>count_digits_fallback</span><span>(</span><span>n</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>With this and a few similar adjustments, we reduced the binary size to 23kB:</p><pre tabindex="0"><code>$ git checkout 8e3da9d
$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 23K Aug 30 19:41 a.out
</code></pre><p>We could likely reduce the binary size even further with additional tweaks,
but let’s address the elephant in the room which is, of course, the C++ standard
library. What’s the point of optimizing the size when you end up getting
a megabyte or two of the C++ runtime?</p><p>While {fmt} relies minimally on the standard library, is it possible to
remove it completely as a dependency? One obvious problem is exceptions and
those can be disabled via <code>FMT_THROW</code>, e.g. by defining it to <code>abort</code>.
In general it is not recommended but it might be OK for some use cases
especially considering that most errors are caught at compile time.</p><p>Let’s try it out and compile with <code>-nodefaultlibs</code> and exceptions disabled:</p><pre tabindex="0"><code>$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      '-DFMT_THROW(s)=abort()' -fno-exceptions test.cc src/format.cc \
      -nodefaultlibs -lc

/usr/bin/ld: /tmp/cc04DFeK.ltrans0.ltrans.o: in function `fmt::v11::basic_memory_buffer&lt;char, 500ul, std::allocator&lt;char&gt; &gt;::grow(fmt::v11::detail::buffer&lt;char&gt;&amp;, unsigned long)':
&lt;artificial&gt;:(.text+0xaa8): undefined reference to `std::__throw_bad_alloc()'
/usr/bin/ld: &lt;artificial&gt;:(.text+0xab8): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: &lt;artificial&gt;:(.text+0xaf8): undefined reference to `operator delete(void*, unsigned long)'
/usr/bin/ld: /tmp/cc04DFeK.ltrans0.ltrans.o: in function `fmt::v11::vprint_buffered(_IO_FILE*, fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::basic_format_args&lt;fmt::v11::context&gt;) [clone .constprop.0]':
&lt;artificial&gt;:(.text+0x18c4): undefined reference to `operator delete(void*, unsigned long)'
collect2: error: ld returned 1 exit status
</code></pre><p>Amazingly, this approach mostly works. The only remaining dependency on the C++
runtime comes from <code>fmt::basic_memory_buffer</code>, which is a small stack-allocated
buffer that can grow into dynamic memory if necessary.</p><p><code>fmt::print</code> can write directly into the <code>FILE</code> buffer and generally
doesn’t require dynamic allocation. So we could remove the dependency on
<code>fmt::basic_memory_buffer</code> from <code>fmt::print</code>. However, since it may be used
elsewhere, a better solution is to replace the default allocator with one that
uses <code>malloc</code> and <code>free</code> instead of <code>new</code> and <code>delete</code>.</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span> <span>struct</span> <span>allocator</span> <span>{</span>
</span></span><span><span>  <span>using</span> <span>value_type</span> <span>=</span> <span>T</span><span>;</span>
</span></span><span><span>
</span></span><span><span>  <span>T</span><span>*</span> <span>allocate</span><span>(</span><span>size_t</span> <span>n</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>FMT_ASSERT</span><span>(</span><span>n</span> <span>&lt;=</span> <span>max_value</span><span>&lt;</span><span>size_t</span><span>&gt;</span><span>()</span> <span>/</span> <span>sizeof</span><span>(</span><span>T</span><span>),</span> <span>""</span><span>);</span>
</span></span><span><span>    <span>T</span><span>*</span> <span>p</span> <span>=</span> <span>static_cast</span><span>&lt;</span><span>T</span><span>*&gt;</span><span>(</span><span>malloc</span><span>(</span><span>n</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>)));</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>!</span><span>p</span><span>)</span> <span>FMT_THROW</span><span>(</span><span>std</span><span>::</span><span>bad_alloc</span><span>());</span>
</span></span><span><span>    <span>return</span> <span>p</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span>
</span></span><span><span>  <span>void</span> <span>deallocate</span><span>(</span><span>T</span><span>*</span> <span>p</span><span>,</span> <span>size_t</span><span>)</span> <span>{</span> <span>free</span><span>(</span><span>p</span><span>);</span> <span>}</span>
</span></span><span><span><span>};</span>
</span></span></code></pre></div><p>This reduces binary size to just 14kB:</p><pre tabindex="0"><code>$ git checkout c0fab5e
$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      '-DFMT_THROW(s)=abort()' -fno-exceptions test.cc src/format.cc \
      -nodefaultlibs -lc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 14K Aug 30 19:06 a.out
</code></pre><p>Considering that a C program with an empty <code>main</code> function is 6kB on this
system, {fmt} now adds less than 10kB to the binary.</p><p>We can also easily verify that it no longer depends on the C++ runtime:</p><pre tabindex="0"><code>$ ldd a.out
        linux-vdso.so.1 (0x0000ffffb0738000)
        libc.so.6 =&gt; /lib/aarch64-linux-gnu/libc.so.6 (0x0000ffffb0530000)
        /lib/ld-linux-aarch64.so.1 (0x0000ffffb06ff000)
</code></pre><p>Hope you found this interesting and happy embedded formatting!</p><hr id="EOF"><p>Last modified on 2024-08-30</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E Ink faces growing competition in the "paper-like" display space (137 pts)]]></title>
            <link>https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/</link>
            <guid>41415144</guid>
            <pubDate>Sun, 01 Sep 2024 08:09:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/">https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/</a>, See on <a href="https://news.ycombinator.com/item?id=41415144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="post-171433"><div><div><p><em><p>Disclosure: Some links on this page are monetized by the <a rel="nofollow" href="http://go.skimlinks.com/?id=32X105&amp;xs=1&amp;url=http://skimlinks.com">Skimlinks</a>, <a rel="nofollow" href="https://affiliate-program.amazon.com/welcome">Amazon</a>, <a rel="nofollow" href="https://rakutenadvertising.com/">Rakuten Advertising, and </a><a rel="no follow" href="https://partnernetwork.ebay.com/">eBay</a>, affiliate programs, and Liliputing may earn a commission if you make a purchase after clicking on those links. All prices are subject to change, and this article only reflects the prices available at time of publication.</p></em></p></div><p>For the past few decades, E Ink has dominated the market for the paper-like displays found in eBook readers and other devices. The screens are high-contrast, easy to view indoors or outdoors, don’t require a backlight, don’t reflect glare, and consume very little power.</p><p>But E Ink displays also have slow screen refresh rates, limited support for color (on models that support any color at all), and generally aren’t very useful for high-motion graphics like videos or games. So while there are a handful of companies producing <a href="https://liliputing.com/tag/e-ink-phone/">E Ink smartphones</a> and <a href="https://liliputing.com/tag/e-ink-tablet/">tablets</a>, they tend to be niche devices. And now we’re seeing a growing number of companies offering products with reflective LCD displays or similar technology that offer some of the paper-like qualities of E Ink, but which are more suitable for animation and video.</p><figure id="attachment_171436" aria-describedby="caption-attachment-171436"><img fetchpriority="high" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-415x500.jpg" alt="" width="415" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-415x500.jpg 415w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-332x400.jpg 332w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-125x150.jpg 125w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-768x925.jpg 768w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-400x482.jpg 400w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02.jpg 1200w" sizes="(max-width: 415px) 100vw, 415px"><figcaption id="caption-attachment-171436">Hannspree HannsNote 2 with ecoVISION Paper Display</figcaption></figure><p>Reflective LCD displays don’t have a backlight and instead reflect ambient light, allowing you to use them without any additional illumination as long as you’re in a brightly lit environment. If you want to make a tablet or another device with a reflective LCD that can be used in dimmer environments, you’ll want to add some front-lights that shine onto the screen… much the way most modern eReaders with E Ink displays have front lighting.</p><p>But while reflective LCD technology has been around for decades, the screens don’t tend to look as bright or vibrant as the transmissive LCDs (with backlights) or OLED screens that have become more common in recent years.</p><p>Recently several companies have decided to try to make&nbsp;<em>better</em> reflective screens though, in an effort to offer an alternative to E Ink that can be used as a paper-like screen for reading and writing, but which also supports full-motion graphics for video, smooth scrolling, and other applications.</p><p>One effort that’s gotten a lot of attention this year is the <a href="https://liliputing.com/daylight-computer-dc-1-is-a-799-tablet-with-a-live-paper-display-designed-to-be-easy-on-the-eyes-but-not-the-wallet/"><strong>Daylight Computer DC-1</strong></a>, which has a “Live Paper” display that’s a black and white IGZO LCD display with a 60 Hz refresh rate and an amber-colored backlight (that can be turned entirely off when you don’t need it).</p><p><img decoding="async" src="https://liliputing.com/wp-content/uploads/2024/05/dc1_02-762x500.jpg" alt="" width="762" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/05/dc1_02-762x500.jpg 762w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-400x262.jpg 400w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-150x98.jpg 150w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-768x504.jpg 768w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02.jpg 1200w" sizes="(max-width: 762px) 100vw, 762px"></p><p><a href="https://daylightcomputer.com/" rel="nofollow"><strong>Daylight</strong></a> is a startup that’s pushing the DC-1 as a tablet that can do more than a typical eReader, while still offering a comfortable viewing experience indoors or outdoors. It has a 10.5 inch display with support for touch and Wacom EMR pen input and the tablet runs a custom version of Android. It’s also expensive, with <a href="https://daylightcomputer.com/cart" rel="nofollow">a $729 price tag</a>.</p><p>If that price tag seems too steep, there’s always TCL’s <a href="https://www.tcl.com/global/en/tcl-nxtpaper-technology" rel="nofollow"><strong>NXTPAPER</strong></a> display technology. The company has been using its full-color, glare-free matte displays on a handful of smartphones and tablets over the past few years. I’ve seen mixed reports on whether this is technically a reflective LCD or not, but while TCL tends to use these displays on relatively affordable devices with budget or mid-range specs, the <a href="https://www.zdnet.com/article/i-gave-away-my-kindle-and-ipad-within-hours-of-testing-this-tablet/" rel="nofollow">screens tend to get positive reviews</a> from folks who are comparing them to E Ink.</p><figure id="attachment_165542" aria-describedby="caption-attachment-165542"><img loading="lazy" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-749x500.jpg" alt="" width="749" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-749x500.jpg 749w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-400x267.jpg 400w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-150x100.jpg 150w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-768x513.jpg 768w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g.jpg 1200w" sizes="(max-width: 749px) 100vw, 749px"><figcaption id="caption-attachment-165542">TCL NXTPAPER 10 5G</figcaption></figure><p>A TCL NXTPAPER 5G Android tablet with a 10.4 inch display currently <a href="https://fave.co/3MtxTqI" rel="nofollow">sells for $240 at Verizon</a>, making it pricier than an <a href="https://amzn.to/3AKts8d" rel="nofollow">Amazon Kindle Paperwhite</a>, but comparable to the list price for an <a href="https://amzn.to/3yOsA20" rel="nofollow">Amazon Fire Max 11</a>.</p><p>One of the more recent entries into this space is HannSpree’s <strong><a href="https://www.hannspree.eu/about-ecovision-paper-display/" rel="nofollow">ecoVISION Paper Display</a></strong> technology, which also offers “fast, full-colour performance,” energy efficiency, and “true 8-bit, non-FRC, flicker-free, and low blue light features” that are said to “help reduce eye strain.”</p><p>One of the first devices featuring this display has the <a href="https://www.hannspree.com/hannsnote2" rel="nofollow"><strong>Hannspree HannsNote 2</strong></a>.&nbsp; It’s a device that the company is positioning as an eReader, but it’s basically an Android tablet with a 10 inch, 1600 x 1200 pixel (200 ppi), 60 Hz display and USI 2.0 stylus support.</p><figure id="attachment_171438" aria-describedby="caption-attachment-171438"><img loading="lazy" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-415x500.jpg" alt="" width="415" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-415x500.jpg 415w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-332x400.jpg 332w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-125x150.jpg 125w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-768x925.jpg 768w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-400x482.jpg 400w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05.jpg 1200w" sizes="(max-width: 415px) 100vw, 415px"><figcaption id="caption-attachment-171438">Hannspree HannsNote 2 with ecoVISION Paper Display</figcaption></figure><p>It also has a Rockchip RK3566 quad-core ARM Cortex-A55 processor, 4GB of RAM, 64GB of storage, and an Android 13-based operating system. The Google Play store comes pre-loaded.</p><p>Interestingly one thing the HannsNote 2 lacks? A front-light. It’s meant to be used&nbsp;<em>only</em> with ambient lighting, which should make it easy to use outdoors or in brightly lit rooms. But if you want to read in the dark you’ll probably need a clip-on booklight.</p><p>The tablet doesn’t seem to be available for purchase in the US, but it’s sold in Europe <a href="https://fave.co/4dK2vjM" rel="nofollow">for about 315€</a>.</p><p><iframe loading="lazy" title="RLCD Color E-Paper Tablet: HannsNote 2 First Look" width="780" height="439" src="https://www.youtube.com/embed/0d7gc8xflHI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p><p>HannSpree has also announced plans to launch a series of “<a href="https://www.prnewswire.com/news-releases/hannspree-unveils-ecovision-paper-display-at-ifa-2024-302233719.html" rel="nofollow">next-generation e-readers</a>” soon, with ecoVISION displays, Android 14 software, and 10 inch or 7.8 inch displays, as well as other products including a 23.8 inch monitor digital signage featuring up to a 28-inch ecoVISION display.</p><div id="custom_html-9"><p>Liliputing's primary sources of revenue are advertising and affiliate links (if you click the "<a target="_blank" rel="nofollow noopener" href="https://www.amazon.com/Best-Sellers-Computers-Accessories/zgbs/pc/ref=as_li_ss_tl?_encoding=UTF8&amp;linkCode=ll2&amp;tag=liliputing_shop-20&amp;linkId=93aaf7ba4e36ed56d46003558471548d">Shop</a>" button at the top of the page and buy something on Amazon, for example, we'll get a small commission).</p><p>But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping.</p><h3>Contribute to our <a href="https://www.patreon.com/bradlinder">Patreon campaign</a></h3><p> <em>or...</em></p><h3>Contribute via <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=PTBQ9EKAYTZBS&amp;source=url">PayPal</a></h3><p> * If you <em>are</em> using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a <a target="blank_" href="https://liliputing.com/2020/09/ublock-origin-how-to-hide-googles-script-blocking-warning-for-websites-using-funding-choices.html" rel="noopener">guide that may help you disable it.</a></p></div><div id="blog_subscription-2"><p> Join 9,573 other subscribers</p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Godot on iPad, Toolbars, Importers, Embedding, Debugger (128 pts)]]></title>
            <link>https://blog.la-terminal.net/godot-on-ipad-summer-update/</link>
            <guid>41415077</guid>
            <pubDate>Sun, 01 Sep 2024 07:50:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.la-terminal.net/godot-on-ipad-summer-update/">https://blog.la-terminal.net/godot-on-ipad-summer-update/</a>, See on <a href="https://news.ycombinator.com/item?id=41415077">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>This is a long-due update on porting Godot to the iPad. &nbsp;Shortly after my last blog post covering the development work on May 29th, Apple held its WWDC 2024 conference. &nbsp; I went into the conference with gusto, expecting to fully embrace all the iOS 18 APIs. I already knew by then that I would not complete the port before iOS 18 became widely available.</p><p>One thing I was not counting on was Apple releasing FinalCut Pro for the iPad, a professional video editing tool. It looked nice on the videos, but I did not expect it to be such a revelation from a UX perspective. While I have been following the Apple Human Interface Guidelines guidance and trying to mimic what other iPad system applications do, FinalCut Pro is packed with small details that have informed Godot for iPad ever since. &nbsp;&nbsp;</p><p>The app itself is glorious and a delight to use, and not being a user interface designer, I did not quite understand what made the app feel so good. &nbsp; A few things were more or less obvious like the Final Cut Pro controls for selecting values:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725137064781_image.png" alt="" loading="lazy" width="640" height="334"><figcaption><span>FinalCut Pro's numeric input.</span></figcaption></figure><p>On the surface, this property editor felt better. Most edits can be done with your finger by dragging the value, and fine editing is possible by tapping on the number, which would bring a text editor. While I already had a little popup that would come up when editing a number, my editor defaulted to having a TextField, so it would always trigger the keyboard to pop up to edit.</p><p>I had completely missed the now obvious benefit of using a custom data entry popup, which was to avoid getting a system keyboard, one that has all sorts of letters and takes a large chunk of the screen, purely to enter numbers. It is obvious in retrospect, but it was not obvious when I was coding it.</p><p>I fell in love with these slide controls. The above one can edit values on a fixed range, but some editors would scroll, and I spent a few weeks reimplementing them and getting the behavior to match it; here are a few of them:</p><figure data-kg-thumbnail="https://blog.la-terminal.net/content/media/2024/08/252bace3f38a89a2_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.la-terminal.net/content/media/2024/08/252bace3f38a89a2.mp4" poster="https://img.spacergif.org/v1/672x900/0a/spacer.png" width="672" height="900" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:15</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>My new data entry controls, attempting to follow the FinalCut Pro idioms.</span></p></figcaption>
        <img src="https://blog.la-terminal.net/content/media/2024/08/252bace3f38a89a2_thumb.jpg"></figure><p>But beyond these very obvious changes, something more subtle was going on. &nbsp; This is what my test code for a potpourri of properties looked like before I looked at Final Cut Pro:</p><figure><img src="https://files.mastodon.social/media_attachments/files/112/754/487/057/645/000/original/666868d31af3e7e3.png" alt="" loading="lazy" width="732" height="2112"></figure><p>What made Final Cut Pro look so much better was a combination of things:</p><ul><li>Font sizes for sections, labels and values</li><li>Color scheme used for labels and values</li><li>Tasteful grouping and padding of elements</li><li>Removal of the&nbsp;“lock”&nbsp;icon for linked properties from this screen and moving them directly to the data input</li></ul><p>So I set out with Preview and the Digital Color meter to match the colors, font sizes and spacing of the property editors to improve this user experience, and within a few days, I had something that looked a little bit better:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725137815878_image.png" alt="" loading="lazy" width="812" height="1600"></figure><p>And now, rather than using a popup to edit each value, I now offer an editor that can take care of all the grouped values at once - and the value linkage is now done entirely on this editor. &nbsp; Additionally, a description is shown at the top, plus a “Reset”&nbsp;option, similar to Final Cut Pro:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725137940198_image.png" alt="" loading="lazy" width="838" height="1362"></figure><p>Then, I noticed that FinalCut Pro did not shy away from nesting values to edit, where I would try to flatten everything out. &nbsp; Here, I had to come up with my idiom, as I expect that some users would not want to dig deeper into the hierarchy to edit values, so I allow users to&nbsp;“pin”&nbsp;a subgroup&nbsp;(I&nbsp;hijack Godot’s existing system for expanding a subtree for this):</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725138413447_image.png" alt="" loading="lazy" width="742" height="368"></figure><p>Tapping the pin button would put that subgroup in the container.</p><p>The work on the new controls and the polishing of the property editor took about a month. &nbsp; I think that it was a worthwhile investment to make the user interface better suited for touch. &nbsp; What surprised me was how big of an upgrade using the proper font sizes, hierarchy of colors and accents brought to the app.</p><p>Another upgrade I did to the inspector during the summer is supporting nested property editing. &nbsp; Once I embraced the FinalCut Pro approach of navigation for properties, it came naturally, and now you can edit those properties by simply tapping on the object as well as rendering previews of some properties. In this case, you can see the material for the mesh:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725144211229_image.png" alt="" loading="lazy" width="1156" height="2066"><figcaption><span>Resource Previews in the Inspector</span></figcaption></figure><h2 id="embedded-windows">Embedded Windows</h2><p>As I have shared over the past year, Godot on iPad is made up of the Godot engine embedded inside SwiftUI, and it started looking like this:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725139189530_image.png" alt="" loading="lazy" width="2728" height="2038"><figcaption><span>An older version of Godot on iPad, showing the underlying editor running.</span></figcaption></figure><p>An older version of Godot on iPad shows the underlying editor running.Above, you can see that Godot is still running in full screen, but with a few of the Godot pads removed on both sides. The center of the screen still contains the Godot tab-based scene selector, the toolbar, the per-view menu&nbsp;(itsays“Perspective”), and the bottom bar, which contains various tools.</p><p>While this works, I wanted more control over what would be displayed here, so rather than lay things on top of Godot, I wanted to extract a view and fully control it. &nbsp; In my case, I wanted the editor's surface but none of the additional elements. &nbsp; In other cases, I wanted to embed some property controls directly into the property editor.</p><p>The Migeran team developed a set of Godot patches that allow me to do this embedding, and I am using them to revamp the user interface.</p><p>The first use was to re-host the top editor and the bottom bar directly and then control their display as a group. &nbsp; Then, I graduated to rehosting every single tap on the bottom bar so I could start incrementally rewriting each of those tabs into SwiftUI.</p><p>First, I replaced the Output Pad, which looks like this on the desktop:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725139592542_image.png" alt="" loading="lazy" width="1228" height="498"><figcaption><span>Godot Desktop Output Pad</span></figcaption></figure><p>With this version:</p><figure><img src="https://blog.la-terminal.net/content/images/2024/08/F6iVjkNQ.jpg" alt="" loading="lazy" width="2000" height="591" srcset="https://blog.la-terminal.net/content/images/size/w600/2024/08/F6iVjkNQ.jpg 600w, https://blog.la-terminal.net/content/images/size/w1000/2024/08/F6iVjkNQ.jpg 1000w, https://blog.la-terminal.net/content/images/size/w1600/2024/08/F6iVjkNQ.jpg 1600w, https://blog.la-terminal.net/content/images/2024/08/F6iVjkNQ.jpg 2000w" sizes="(min-width: 1200px) 1200px"><figcaption><span>Godot on iPad Output Pad</span></figcaption></figure><p>To avoid taking up a whole row for text filtering, I allow each tab to have an optional tool that can be displayed on the right side of the user interface, like in this case.</p><p>It also shows some inspiration taken from LogicPro, another one of Apple’s professional tools for the iPad. &nbsp; In this case, I have replaced a difficult-to-grab&nbsp;“splitter”&nbsp;common in Godot with an explicit handle that the user can drag to grow the region, tap to expand, or dismiss with a flick.</p><p>Similarly, the native Godot debugger went on a user interface diet, as I do not have the space available:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725140554713_image.png" alt="" loading="lazy" width="1454" height="588"></figure><p>This time, I drew inspiration from Xcode and Swift Playgrounds. In this case, I collapsed the thread selector to one Picker that allows you to jump to different threads. The entire stack frames pane is also replaced by a single picker&nbsp;(here,showing&nbsp;hello:10), and the variables are shown on the left side, similar to Xcode. &nbsp;&nbsp;</p><p>Another Xcode-inspired idea is that the variables and the output live side by side and can be toggled on and on using the small controls at the bottom of the screen:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725140664442_image.png" alt="" loading="lazy" width="2092" height="752"></figure><p>The next big chunk of work this summer was to provide alternatives to the toolbars and menus used in Godot 3D and 2D editors. I started with the same principle: to be in control of those user interface elements and make them suitable for use on the iPad&nbsp;(and&nbsp;soon on the VisionPro). &nbsp;&nbsp;</p><p>Initially, I felt like I could use the embedding technology to reuse the menus as-is because they were tappable enough. &nbsp; But once I looked at them, I realized they were too busy, had very long lists of data, and would work poorly on the iPad. &nbsp; This shows a partial view of the various toolbar elements for the 3D editor and what they unfold to:</p><figure><img src="https://files.mastodon.social/media_attachments/files/112/883/661/063/563/770/original/24dcab2a69e9306b.png" alt="" loading="lazy" width="2004" height="2076"><figcaption><span>The Godot Menus and Options for the 3D editor</span></figcaption></figure><p>This is what the toolbar looks like now after the iPad-ification was done:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725141991249_image.png" alt="" loading="lazy" width="1248" height="730"></figure><p>I enjoyed turning a modal settings box for the Field of View, Near Clip Distance and Far Clip Distance into a live setting, so you can immediately see the changes happen. &nbsp; This view is still using the old sliders, but will soon be replaced with the new sliders that I cooked up.</p><p>Merging the six different viewport options into a single line saved plenty of vertical space, and merging those settings into the general-purpose settings and letting the user configure them there saved two icon slots on the toolbar for Light and Environment.</p><p>Had I designed this six months ago, I would have made the configuration for Light and Environment a long-press action on the light and environment buttons. But the more I use the app and the more professional apps I use on the iPad, I realize that long-press actions are useful for power users, but they are just not discoverable. I am being more mindful and considerate about my users by moving away from this idiom. &nbsp;Very demure.</p><p>And this is what I did with the per-view menus:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142140383_image.png" alt="" loading="lazy" width="1382" height="1036"></figure><p>I might add some icons to the labels, but these look fine to me now.</p><p>A similar exercise was necessary for the 2D surface:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142451978_image.png" alt="" loading="lazy" width="1630" height="774"></figure><p>It did not seem like I could re-host those user interface elements, it just did not feel right after the 3D user interface had gotten that big upgrade.</p><p>So this is what the 2D toolbar turned into:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142787835_image.png" alt="" loading="lazy" width="1150" height="720"></figure><p>My goal was to preserve all the features available in Godot and surface them in an iPad-friendly way without sacrificing any functionality. If I had telemetry for which features users were using, I could have left a few things out, but generally, I erred on the side of not leaving things out. &nbsp;&nbsp;</p><p>There are two small exceptions, and I made them only after reading the commit that introduced the feature and the discussion on the GitHub issue—they looked like relatively fringe features that had little use. But hopefully, during the public TestFlight, folks will inform me if I made a mistake.</p><p>You can tell that I worked hard to preserve all the functionality but also organize the features in a way that would be simpler to find:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725142810630_image.png" alt="" loading="lazy" width="1508" height="1056"></figure><p>You might have noticed the&nbsp;“Control:&nbsp;Anchors” toolbar there. It turns out that I got more than I bargained for. Godot has additional&nbsp;“toolbars”&nbsp;that can be loaded into the toolbar depending on the object that you are editing, so I had to support not only the basics but also other custom toolbars. &nbsp;&nbsp;</p><p>As Godot allows scripts and extensions to add elements to the Toolbar, I am replacing the known element toolbars with my own. If I encounter one kind that I do not support, I will merely&nbsp;“re-host”&nbsp;the Godot-native control in the user interface.</p><p>That said, my goal is to cover all the popular toolbars from the start so that none of the native ones are exposed and to fall back to the embedded situation when necessary.</p><p>I feel like I can do slightly better organization of these properties for Godot on iPad because of the additional user interface elements available at my disposal, like the Picker above or the visual cues for grouping. &nbsp; This is a feeling that I got repeatedly during this exercise. The spectrum of tools available in SwiftUI gave me a richer vocabulary to express the capabilities than the controls that come with Godot - I hope to publish a list of&nbsp;“nice&nbsp;to haves” so the Godot folks can bring that into mainline Godot.</p><p>Lastly, I realized that the toolbars are taking some precious space on the user interface, and they might get in the way of your work. &nbsp; I remembered that Apple had a talk some years ago about&nbsp;“<a href="https://developer.apple.com/videos/play/wwdc2018/803/?ref=blog.la-terminal.net" rel="noreferrer nofollow noopener">Fluid</a><a href="https://developer.apple.com/videos/play/wwdc2018/803/?ref=blog.la-terminal.net" rel="noreferrer nofollow noopener">&nbsp;Interfaces</a>” that covered this scenario, for what they called the&nbsp;“Picture&nbsp;in Picture View”. &nbsp; The description starts after minute 41 of the talk.</p><p>So I brought that user interface idiom to the toolbars, allowing users to&nbsp;“flick”&nbsp;the toolbar to one of the four corners of the user interface to get out of the way:</p><figure data-kg-thumbnail="https://blog.la-terminal.net/content/media/2024/08/ScreenRecording_08-31-2024-18-28-08_1_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.la-terminal.net/content/media/2024/08/ScreenRecording_08-31-2024-18-28-08_1.MP4" poster="https://img.spacergif.org/v1/1920x1342/0a/spacer.png" width="1920" height="1342" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:13</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>Moving the toolbar around</span></p></figcaption>
        <img src="https://blog.la-terminal.net/content/media/2024/08/ScreenRecording_08-31-2024-18-28-08_1_thumb.jpg"></figure><h2 id="other-work">Other Work</h2><p>Miroslav has been an invaluable partner in this SwiftUI adventure, and while he had initially just focused on the SwiftUI components, he has recently taken over rewriting many of the full-screen importers for Godot. &nbsp; We realized early on that some of the importers in Godot were great, but again, they would take up all the space and did not fit at all in the iPad, it was not even possible to reach all the elements of the UI.</p><p>He rewrote the Scene Importer and the Audio Importer, which were large projects on their own:</p><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725146091645_image.png" alt="" loading="lazy" width="2388" height="1668"><figcaption><span>Scene Importer, the sidebar is closed.</span></figcaption></figure><figure><img src="https://paper-attachments.dropboxusercontent.com/s_BF3AD6EA8C16ADCDBFFBE2C86A5DC3002F99676ABA007444AD8B02E5E9853638_1725146031864_image.png" alt="" loading="lazy" width="2388" height="1668"><figcaption><span>Audio Importer</span></figcaption></figure><h2 id="next-steps">Next Steps</h2><p>One thing that has been bothering me is how to activate/deactivate panels on such a small screen, and I had my share of poor man’s hacks. &nbsp; Logic Pro introduced me to an idiom&nbsp;(and&nbsp;while it is in FinalCut Pro, I was not paying enough attention to see it): small icons at the bottom of the screen. &nbsp; I spent the last week redoing my bottom bar to incorporate this idiom.</p><p>I lack a&nbsp;“Scene&nbsp;Switcher”&nbsp;(what&nbsp;Godot has in tabs). &nbsp;The way to switch scenes is to select the file directly, but that feels clunky, so that is next.</p><p>In addition to these two high-level topics, I have some fifty-nine other small bugs that need to be fixed before this is suitable for a TestFlight, and I hope to finalize those in September.&nbsp;</p><p>My hope is that while I collect feedback for this beta and fix bugs, I can look into integrating Apple Pencil support, spend some quality time on the touch interactions for it, and make sure that Godot on iPad really shines as a touch-first experience.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Founder Mode (645 pts)]]></title>
            <link>https://paulgraham.com/foundermode.html</link>
            <guid>41415023</guid>
            <pubDate>Sun, 01 Sep 2024 07:35:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/foundermode.html">https://paulgraham.com/foundermode.html</a>, See on <a href="https://news.ycombinator.com/item?id=41415023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/founder-mode-1.gif" width="118" height="18" alt="Founder Mode"><span size="2" face="verdana">September 2024<p>At a YC event last week Brian Chesky gave a talk that everyone who
was there will remember. Most founders I talked to afterward said
it was the best they'd ever heard. Ron Conway, for the first time
in his life, forgot to take notes. I'm not going to try to reproduce
it here. Instead I want to talk about a question it raised.</p><p>The theme of Brian's talk was that the conventional wisdom about
how to run larger companies is mistaken. As Airbnb grew, well-meaning
people advised him that he had to run the company in a certain way
for it to scale. Their advice could be optimistically summarized
as "hire good people and give them room to do their jobs." He
followed this advice and the results were disastrous. So he had to
figure out a better way on his own, which he did partly by studying
how Steve Jobs ran Apple. So far it seems to be working. Airbnb's
free cash flow margin is now among the best in Silicon Valley.</p><p>The audience at this event included a lot of the most successful
founders we've funded, and one after another said that the same
thing had happened to them. They'd been given the same advice about
how to run their companies as they grew, but instead of helping
their companies, it had damaged them.</p><p>Why was everyone telling these founders the wrong thing? That was
the big mystery to me. And after mulling it over for a bit I figured
out the answer: what they were being told was how to run a company
you hadn't founded — how to run a company if you're merely a
professional manager. But this m.o. is so much less effective that
to founders it feels broken. There are things founders can do that
managers can't, and not doing them feels wrong to founders, because
it is.</p><p>In effect there are two different ways to run a company: founder
mode and manager mode. Till now most people even in Silicon Valley
have implicitly assumed that scaling a startup meant switching to
manager mode. But we can infer the existence of another mode from
the dismay of founders who've tried it, and the success of their
attempts to escape from it.</p><p>There are as far as I know no books specifically about founder mode.
Business schools don't know it exists. All we have so far are the
experiments of individual founders who've been figuring it out for
themselves. But now that we know what we're looking for, we can
search for it. I hope in a few years founder mode will be as well
understood as manager mode. We can already guess at some of the
ways it will differ.</p><p>The way managers are taught to run companies seems to be like modular
design in the sense that you treat subtrees of the org chart as
black boxes. You tell your direct reports what to do, and it's up
to them to figure out how. But you don't get involved in the details
of what they do. That would be micromanaging them, which is bad.</p><p>Hire good people and give them room to do their jobs. Sounds great
when it's described that way, doesn't it? Except in practice, judging
from the report of founder after founder, what this often turns out
to mean is: hire professional fakers and let them drive the company
into the ground.</p><p>One theme I noticed both in Brian's talk and when talking to founders
afterward was the idea of being gaslit. Founders feel like they're
being gaslit from both sides — by the people telling them they
have to run their companies like managers, and by the people working
for them when they do. Usually when everyone around you disagrees
with you, your default assumption should be that you're mistaken.
But this is one of the rare exceptions. VCs who haven't been founders
themselves don't know how founders should run companies, and C-level
execs, as a class, include some of the most skillful liars in the
world.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span><p>Whatever founder mode consists of, it's pretty clear that it's going
to break the principle that the CEO should engage with the company
only via his or her direct reports. "Skip-level" meetings will
become the norm instead of a practice so unusual that there's a
name for it. And once you abandon that constraint there are a huge
number of permutations to choose from.</p><p>For example, Steve Jobs used to run an annual retreat for what he
considered the 100 most important people at Apple, and these were
not the 100 people highest on the org chart. Can you imagine the
force of will it would take to do this at the average company? And
yet imagine how useful such a thing could be. It could make a big
company feel like a startup. Steve presumably wouldn't have kept
having these retreats if they didn't work. But I've never heard of
another company doing this. So is it a good idea, or a bad one? We
still don't know. That's how little we know about founder mode.
</p><span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>Obviously founders can't keep running a 2000 person company the way
they ran it when it had 20. There's going to have to be some amount
of delegation. Where the borders of autonomy end up, and how sharp
they are, will probably vary from company to company. They'll even
vary from time to time within the same company, as managers earn
trust. So founder mode will be more complicated than manager mode.
But it will also work better. We already know that from the examples
of individual founders groping their way toward it.</p><p>Indeed, another prediction I'll make about founder mode is that
once we figure out what it is, we'll find that a number of individual
founders were already most of the way there — except that in doing
what they did they were regarded by many as eccentric or worse.
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>Curiously enough it's an encouraging thought that we still know so
little about founder mode. Look at what founders have achieved
already, and yet they've achieved this against a headwind of bad
advice. Imagine what they'll do once we can tell them how to run
their companies like Steve Jobs instead of John Sculley.</p><p><b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
The more diplomatic way of phrasing this statement would be
to say that experienced C-level execs are often very skilled at
managing up. And I don't think anyone with knowledge of this world
would dispute that.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
If the practice of having such retreats became so widespread
that even mature companies dominated by politics started to do it,
we could quantify the senescence of companies by the average depth
on the org chart of those invited.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
I also have another less optimistic prediction: as soon as
the concept of founder mode becomes established, people will start
misusing it. Founders who are unable to delegate even things they
should will use founder mode as the excuse. Or managers who aren't
founders will decide they should try act like founders. That may
even work, to some extent, but the results will be messy when it
doesn't; the modular approach does at least limit the damage a bad
CEO can do.<span color="888888"><b>Thanks</b> to Brian Chesky, Patrick Collison, 
Ron Conway, Jessica
Livingston, Elon Musk, Ryan Petersen, Harj Taggar, and Garry Tan
for reading drafts of this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playstation 2 GS emulation – the final frontier of Vulkan compute emulation (192 pts)]]></title>
            <link>https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/</link>
            <guid>41413662</guid>
            <pubDate>Sun, 01 Sep 2024 02:14:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/">https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/</a>, See on <a href="https://news.ycombinator.com/item?id=41413662">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-754">
	
	<!-- .entry-header -->

	<div>
		<p>As you may, or may not know, I wrote paraLLEl-RDP back in 2020. It aimed at implementing the N64 RDP in Vulkan compute. Lightning fast, and extremely accurate, plus the added support of up-scaling on top. I’m quite happy how it turned out. Of course, the extreme accuracy was due to Angrylion being used as reference and I could aim for bit-exactness against that implementation.</p>
<p>Since then, there’s been the lingering idea of doing the same thing, but for PlayStation 2. Until now, there’s really only been one implementation in town, GSdx, which has remained the state-of-the-art for 20 years.</p>
<p><a href="https://github.com/Arntzen-Software/parallel-gs">paraLLEl-GS</a> is actually not the first compute implementation of the PS2 GS. An attempt was made back in 2014 for OpenCL as far as I recall, but it was never completed. At the very least, I cannot find it in the current upstream repo anymore.</p>
<p>The argument for doing compute shader raster on PS2 is certainly weaker than on N64. Angrylion was – and is – extremely slow, and N64 is extremely sensitive to accuracy where hardware acceleration with graphics APIs is impossible without serious compromises. PCSX2 on the other hand has a well-optimized software renderer, and a pretty solid graphics-based renderer, but that doesn’t mean there aren’t issues. The software renderer does not support up-scaling for example, and there are a myriad bugs and glitches with the graphics-based renderer, especially with up-scaling. As we’ll see, the PS2 GS is quite the nightmare to emulate in its own way.</p>
<p>My main motivation here is basically “because I can”. I already had a project lying around that did “generic” compute shader rasterization. I figured that maybe we could retro-fit this to support PS2 rendering.</p>
<p>I didn’t work on this project alone. My colleague, Runar Heyer, helped out a great deal in the beginning to get this started, doing all the leg-work to study the PS2 from various resources, doing the initial prototype implementation and fleshing out the Vulkan GLSL to emulate PS2 shading. Eventually, we hit some serious roadblocks in debugging various games, and the project was put on ice for a while since I was too drained dealing with horrible D3D12 game debugging day in and day out. The last months haven’t been a constant fire fight, so I’ve finally had the mental energy to finish it.</p>
<p>My understanding of the GS is mostly based on what Runar figured out, and what I’ve seen by debugging games. The GSdx software renderer does not seem like it’s hardware bit-accurate, so we were constantly second-guessing things when trying to compare output. This caused a major problem when we had the idea of writing detailed tests that directly compared against GSdx software renderer, and the test-driven approach fell flat very quickly. As a result, paraLLEl-GS isn’t really aiming for bit-accuracy against hardware, but it tries hard to avoid obvious accuracy issues at the very least.</p>
<h2>Basic GS overview</h2>
<p>Again, this is based on my understanding, and it might not be correct. 😀</p>
<h3>GS is a pixel-pushing monster</h3>
<p>The GS is infamous for its insane fill-rate and bandwidth. It could push over a billion pixels per second (in theory at least) back in 2000 which was nuts. While the VRAM is quite small (4 MiB), it was designed to be continuously streamed into using the various DMA engines.</p>
<p>Given the extreme fill-rate requirements, we have to design our renderer accordingly.</p>
<h3>GS pixel pipeline is very basic, but quirky</h3>
<p>In many ways, the GS is actually simpler than N64 RDP. Single texture, and a single cycle combiner, where N64 had a two stage combiner + two stage blender. Whatever AA support is there is extremely basic as well, where N64 is delightfully esoteric. The parts of the pixel pipeline that is painful to implement with traditional graphics APIs is:</p>
<h4>Blending goes beyond 1.0</h4>
<p>Inherited from PS1, 0x80 is treated as 1.0, and it can go all the way up to 0xff (almost 2). Shifting by 7 is easier than dividing by 255 I suppose. I’ve seen some extremely ugly workarounds in PCSX2 before to try working around this since UNORM formats cannot support this as is. Textures are similar, where alpha &gt; 1.0 is representable.</p>
<p>There is also wrapping logic that can be used for when colors or alpha goes above 0xFF.</p>
<h4>Destination alpha testing</h4>
<p>The destination alpha can be used as a pseudo-stencil of sorts, and this is extremely painful without programmable blending. I suspect this was added as PS1 compatibility, since PS1 also had this strange feature.</p>
<h4>Conditional blending</h4>
<p>Based on the alpha, it’s possible to conditionally disable blending. Quite awkward without programmable blending … This is another PS1 compat feature. With PS1, it can be emulated by rendering every primitive twice with state changes in-between, but this quickly gets impractical with PS2.</p>
<h4>Alpha correction</h4>
<p>Before alpha is written out, it’s possible to OR in the MSB. Essentially forcing alpha to 1. It is not equivalent to alphaToOne however, since it’s a bit-wise OR of the MSB.</p>
<h4>Alpha test can partially discard</h4>
<p>A fun thing alpha tests can do is to partially discard. E.g. you can discard just color, but keep the depth write. Quite nutty.</p>
<h4>AA1 – coverage-to-alpha – can control depth write per pixel</h4>
<p>This is also kinda awkward. The only anti-alias PS2 has is AA1 which is a coverage-to-alpha feature. Supposedly, less than 100% coverage should disable depth writes (and blending is enabled), but the GSdx software renderer behavior here is extremely puzzling. I don’t really understand it yet.</p>
<h4>32-bit fixed-point Z</h4>
<p>I’ve still yet to see any games actually using this, but technically, it has D32_UINT support. Fun! From what I could grasp, GSdx software renderer implements this with FP64 (one of the many reasons I refuse to believe GSdx is bit-accurate), but FP64 is completely impractical on GPUs. When I have to, I’ll implement this with fixed-point math. 24-bit Z and 16-bit should be fine with FP32 interpolation I think.</p>
<h4>Pray you have programmable blending</h4>
<p>If you’re on a pure TBDR GPU most of this is quite doable, but immediate mode desktop GPUs quickly degenerates into ROV or per-pixel barriers after every primitive to emulate programmable blending, both which are horrifying for performance. Of course, with compute we can make our own TBDR to bypass all this. 🙂</p>
<h3>D3D9-style raster rules</h3>
<p>Primitives are fortunately provided in a plain form in clip-space. No awkward N64 edge equations here. The VU1 unit is supposed to do transforms and clipping, and emit various per-vertex attributes:</p>
<p>X/Y: 12.4 unsigned fixed-point<br>
Z: 24-bit or 32-bit uint<br>
FOG: 8-bit uint<br>
RGBA: 8-bit, for per-vertex lighting<br>
STQ: For perspective correct texturing with normalized coordinates. Q = 1 / w, S = s * Q, T = t * Q. Apparently the lower 8-bits of the mantissa are clipped away, so bfloat24? Q can be negative, which is always fun. No idea how this interacts with Inf and NaN …<br>
UV: For non-perspective correct texturing. 12.4 fixed-point un-normalized.</p>
<ul>
<li>Triangles are top-left raster, just like modern GPUs.</li>
<li>Pixel center is on integer coordinate, just like D3D9. (This is a common design mistake that D3D10+ and GL/Vulkan avoids).</li>
<li>Lines use Bresenham’s algorithm, which is not really feasible to upscale, so we have to fudge it with rect or parallelogram.</li>
<li>Points snap to nearest pixel. Unsure which rounding is used though … There is no interpolation ala gl_PointCoord.</li>
<li>Sprites are simple quads with two coordinates. STQ or UV can be interpolated and it seems to assume non-rotated coordinates. To support rotation, you’d need 3 coordinates to disambiguate.</li>
</ul>
<p>All of this can be implemented fairly easily in normal graphics APIs, as long as we don’t consider upscaling. We have to rely on implementation details in GL and Vulkan, since these APIs don’t technically guarantee top-left raster rules.</p>
<p>Since X/Y is unsigned, there is an XY offset that can be applied to center the viewport where you want. This means the effective range of X/Y is +/- 4k pixels, a healthy guard band for 640×448 resolutions.</p>
<h3>Vertex queue</h3>
<p>The GS feels very much like old school OpenGL 1.0 with glVertex3f and friends. It even supports TRIANGLE_FAN! Amazing … RGBA, STQ and various registers are set, and every XYZ register write forms a vertex “kick” which latches vertex state and advances the queue. An XYZ register write may also be a drawing kick, which draws a primitive if the vertex queue is sufficiently filled. The vertex queue is managed differently depending on the topology. The semantics here seem to be pretty straight forward where strip primitives shift the queue by one, and list primitives clear the queue. Triangle fans keep the first element in the queue.</p>
<h3>Fun swizzling formats</h3>
<p>A clever idea is that while rendering to 24-bit color or 24-bit depth, there is 8 bits left unused in the MSBs. You can place textures there, because why not. 8H, 4HL, 4HH formats support 8-bit and 4-bit palettes nicely.</p>
<p>Pixel coordinates on PS2 are arranged into “pages”, which are 8 KiB, then subdivided into 32 blocks, and then, the smaller blocks are swizzled into a layout that fits well with a DDA-style renderer. E.g. for 32-bit RGBA, a page is 64×32 pixels, and 32 8×8 blocks are Z-order swizzled into that page.</p>
<h3>Framebuffer cache and texture cache</h3>
<p>There is a dedicated cache for framebuffer rendering and textures, one page’s worth. Games often abuse this to perform feedback loops, where they render on top of the pixels being sampled from. This is the root cause of extreme pain. N64 avoided this problem by having explicit copies into TMEM (and not really having the bandwidth to do elaborate feedback effects), and other consoles rendered to embedded SRAM (ala a tiler GPU), so these feedbacks aren’t as painful, but the GS is complete YOLO. Dealing with this gracefully is probably the biggest challenge. Combined with the PS2 being a bandwidth monster, developers knew how to take advantage of copious blending and blurring passes …</p>
<h3>Texturing</h3>
<p>Texturing on the GS is both very familar, and arcane.</p>
<p>On the plus side, the texel-center is at half-pixel, just like modern APIs. It seems like it has 4-bit sub-texel precision instead of 8 however. This is easily solved with some rounding. It also seems to have floor-rounding instead of nearest-rounding for bi-linear.</p>
<p>The bi-linear filter is a normal bi-linear. No weird 3-point N64 filter here.</p>
<p>On the weirder side, there are two special addressing modes.</p>
<p>REGION_CLAMP supports an arbitrary clamp inside a texture atlas (wouldn’t this be nice in normal graphics APIs? :D). It also works with REPEAT, so you can have REPEAT semantics on border, but then clamp slightly into the next “wrap”. This is trivial to emulate.</p>
<p>REGION_REPEAT is … worse. Here we can have custom bit-wise computation per coordinate. So something like u’ = (u &amp; MASK) | FIX. This is done per-coordinate in bi-linear filtering, which is … painful, but solvable. This is another weird PS1 feature that was likely inherited for compatibility. At least on PS1, there was no bi-linear filtering to complicate things 🙂</p>
<p>Mip-mapping is also somewhat curious. Rather than relying on derivatives, the log2 of interpolated Q factor, along with some scaling factors are used to compute the LOD. This is quite clever, but I haven’t really seen any games use it. The down-side is that triangle-setup becomes rather complex if you want to account for correct tri-linear filtering, and it cannot support e.g. anisotropic filtering, but this is 2000, who cares! Not relying on derivatives is a huge boon for the compute implementation.</p>
<p>Formats are always “normalized” to RGBA8_UNORM. 5551 format is expanded to 8888 without bit-replication. There is no RGBA4444 format.</p>
<p>It’s quite feasible to implement the texturing with plain bindless.</p>
<h3>CLUT</h3>
<p>This is a 1 KiB cache that holds the current palette. There is an explicit copy step from VRAM into that CLUT cache before it can be used. Why hello there, N64 TMEM!</p>
<p>The CLUT is organized such that it can hold one full 256 color palette in 32-bit colors. On the other end, it can hold 32 palettes of 16 colors at 16 bpp.</p>
<h3>TEXFLUSH</h3>
<p>There is an explicit command that functions like a “sync and invalidate texture cache”. In the beginning I was hoping to rely on this to guide the hazard tracking, but oh how naive I was. In the end, I simply had to ignore TEXFLUSH. Basically, there are two styles of caching we could take with GS.</p>
<p>With “maximal” caching, we can assume that frame buffer caches and texture caches are infinitely large. The only way a hazard needs to be considered is after an explicit flush. This … breaks hard. Either games forget to use TEXFLUSH (because it happened to work on real hardware), or they TEXFLUSH way too much.</p>
<p>With “minimal” caching, we assume there is no caching and hazards are tracked directly. Some edge case handling is considered for feedback loops.</p>
<p>I went with “minimal”, and I believe GSdx did too.</p>
<h3>Poking registers with style – GIF</h3>
<p>The way to interact with the GS hardware is through the GIF, which is basically a unit that reads data and pokes the correct hardware registers. At the start of a GIF packet, there is a header which configures which registers should be written to, and how many “loops” there are. This maps very well to mesh rendering. We can consider something like one “loop” being:</p>
<ul>
<li>Write RGBA vertex color</li>
<li>Write texture coordinate</li>
<li>Write position with draw kick</li>
</ul>
<p>And if we have 300 vertices to render, we’d use 300 loops. State registers can be poked through the Address + Data pair, which just encodes target register + 64-bit payload. It’s possible to render this way too of course, but it’s just inefficient.</p>
<p>Textures are uploaded through the same mechanism. Various state registers are written to set up transfer destinations, formats, etc, and a special register is nudged to transfer 64-bit at a time to VRAM.</p>
<h2>Hello Trongle – GS</h2>
<p>If you missed the brain-dead simplicity of OpenGL 1.0, this is the API for you! 😀</p>
<p>For testing purposes, I added a tool to generate a .gs dump format that PCSX2 can consume. This is handy for comparing implementation behavior.</p>
<p>First, we program the frame buffer and scissor:</p>
<pre>TESTBits test = {};
test.ZTE = TESTBits::ZTE_ENABLED;
test.ZTST = TESTBits::ZTST_GREATER; // Inverse Z, LESS is not supported.
iface.write_register(RegisterAddr::TEST_1, test);

FRAMEBits frame = {};
frame.FBP = 0x0 / PAGE_ALIGNMENT_BYTES;
frame.PSM = PSMCT32;
frame.FBW = 640 / BUFFER_WIDTH_SCALE;
iface.write_register(RegisterAddr::FRAME_1, frame);

ZBUFBits zbuf = {};
zbuf.ZMSK = 0; // Enable Z-write
zbuf.ZBP = 0x118000 / PAGE_ALIGNMENT_BYTES;
iface.write_register(RegisterAddr::ZBUF_1, zbuf);

SCISSORBits scissor = {};
scissor.SCAX0 = 0;
scissor.SCAY0 = 0;
scissor.SCAX1 = 640 - 1;
scissor.SCAY1 = 448 - 1;
iface.write_register(RegisterAddr::SCISSOR_1, scissor);</pre>
<p>Then we nudge some registers to draw:</p>
<pre>struct Vertex
{
    PackedRGBAQBits rgbaq;
    PackedXYZBits xyz;
} vertices[3] = {};

for (auto &amp;vert : vertices)
{
   vert.rgbaq.A = 0x80;
   vert.xyz.Z = 1;
}

vertices[0].rgbaq.R = 0xff;
vertices[1].rgbaq.G = 0xff;
vertices[2].rgbaq.B = 0xff;

vertices[0].xyz.X = p0.x &lt;&lt; SUBPIXEL_BITS;
vertices[0].xyz.Y = p0.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.X = p1.x &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.Y = p1.y &lt;&lt; SUBPIXEL_BITS;
vertices[2].xyz.X = p2.x &lt;&lt; SUBPIXEL_BITS;
vertices[2].xyz.Y = p2.y &lt;&lt; SUBPIXEL_BITS;

PRIMBits prim = {};
prim.TME = 0; // Turn off texturing.
prim.IIP = 1; // Interpolate RGBA (Gouraud shading)
prim.PRIM = int(PRIMType::TriangleList);

static const GIFAddr addr[] = { GIFAddr::RGBAQ, GIFAddr::XYZ2 };
constexpr uint32_t num_registers = sizeof(addr) / sizeof(addr[0]);
constexpr uint32_t num_loops = sizeof(vertices) / sizeof(vertices[0]);
iface.write_packed(prim, addr, num_registers, num_loops, vertices);</pre>
<p>This draws a triangle. We provide coordinates directly in screen-space.</p>
<p>And finally, we need to program the CRTC. Most of this is just copy-pasta from whatever games tend to do.</p>
<pre>auto &amp;priv = iface.get_priv_register_state();

priv.pmode.EN1 = 1;
priv.pmode.EN2 = 0;
priv.pmode.CRTMD = 1;
priv.pmode.MMOD = PMODEBits::MMOD_ALPHA_ALP;
priv.smode1.CMOD = SMODE1Bits::CMOD_NTSC;
priv.smode1.LC = SMODE1Bits::LC_ANALOG;
priv.bgcolor.R = 0x0;
priv.bgcolor.G = 0x0;
priv.bgcolor.B = 0x0;
priv.pmode.SLBG = PMODEBits::SLBG_ALPHA_BLEND_BG;
priv.pmode.ALP = 0xff;
priv.smode2.INT = 1;

priv.dispfb1.FBP = 0;
priv.dispfb1.FBW = 640 / BUFFER_WIDTH_SCALE;
priv.dispfb1.PSM = PSMCT32;
priv.dispfb1.DBX = 0;
priv.dispfb1.DBY = 0;
priv.display1.DX = 636; // Magic values that center the screen.
priv.display1.DY = 50; // Magic values that center the screen.
priv.display1.MAGH = 3; // scaling factor = MAGH + 1 = 4 -&gt; 640 px wide.
priv.display1.MAGV = 0;
priv.display1.DW = 640 * 4 - 1;
priv.display1.DH = 448 - 1;

dump.write_vsync(0, iface);
dump.write_vsync(1, iface);</pre>
<p>When the GS is dumped, we can load it up in PCSX2 and voila:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump.png"><img fetchpriority="high" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1024x674.png" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1024x674.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-300x198.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-768x506.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1536x1012.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump.png 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>And here’s the same .gs dump is played through parallel-gs-replayer with RenderDoc. For debugging, I’ve spent a lot of time making it reasonably convenient. The images are debug storage images where I can store before and after color, depth, debug values for interpolants, depth testing state, etc, etc. It’s super handy to narrow down problem cases. The render pass can be split into 1 or more triangle chunks as needed.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc.png"><img decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1024x596.png" alt="" width="660" height="384" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1024x596.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-300x175.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-768x447.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1536x894.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-2048x1192.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>To add some textures, and flex the capabilities of the CRTC a bit, we can try uploading a texture:</p>
<pre>int chan;
auto *buf = stbi_load("/tmp/test.png", &amp;w, &amp;h, &amp;chan, 4);
iface.write_image_upload(0x300000, PSMCT32, w, h, buf,
                         w * h * sizeof(uint32_t));
stbi_image_free(buf);

TEX0Bits tex0 = {};
tex0.PSM = PSMCT32;
tex0.TBP0 = 0x300000 / BLOCK_ALIGNMENT_BYTES;
tex0.TBW = (w + BUFFER_WIDTH_SCALE - 1) / BUFFER_WIDTH_SCALE;
tex0.TW = Util::floor_log2(w - 1) + 1;
tex0.TH = Util::floor_log2(h - 1) + 1;
tex0.TFX = COMBINER_DECAL;
tex0.TCC = 1; // Use texture alpha as blend alpha
iface.write_register(RegisterAddr::TEX0_1, tex0);

TEX1Bits tex1 = {};
tex1.MMIN = TEX1Bits::LINEAR;
tex1.MMAG = TEX1Bits::LINEAR;
iface.write_register(RegisterAddr::TEX1_1, tex1);

CLAMPBits clamp = {};
clamp.WMS = CLAMPBits::REGION_CLAMP;
clamp.WMT = CLAMPBits::REGION_CLAMP;
clamp.MINU = 0;
clamp.MAXU = w - 1;
clamp.MINV = 0;
clamp.MAXV = h - 1;
iface.write_register(RegisterAddr::CLAMP_1, clamp);</pre>
<p>While PS2 requires POT sizes for textures, REGION_CLAMP is handy for NPOT. Super useful for texture atlases.</p>
<pre>struct Vertex
{
    PackedUVBits uv;
    PackedXYZBits xyz;
} vertices[2] = {};

for (auto &amp;vert : vertices)
    vert.xyz.Z = 1;

vertices[0].xyz.X = p0.x &lt;&lt; SUBPIXEL_BITS;
vertices[0].xyz.Y = p0.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.X = p1.x &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.Y = p1.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].uv.U = w &lt;&lt; SUBPIXEL_BITS;
vertices[1].uv.V = h &lt;&lt; SUBPIXEL_BITS;

PRIMBits prim = {};
prim.TME = 1; // Turn on texturing.
prim.IIP = 0;
prim.FST = 1; // Use unnormalized coordinates.
prim.PRIM = int(PRIMType::Sprite);

static const GIFAddr addr[] = { GIFAddr::UV, GIFAddr::XYZ2 };
constexpr uint32_t num_registers = sizeof(addr) / sizeof(addr[0]);
constexpr uint32_t num_loops = sizeof(vertices) / sizeof(vertices[0]);
iface.write_packed(prim, addr, num_registers, num_loops, vertices);</pre>
<p>Here we render a sprite with un-normalized coordinates.</p>
<p>Finally, we use the CRTC to do blending against white background.</p>
<pre>priv.pmode.EN1 = 1;
priv.pmode.EN2 = 0;
priv.pmode.CRTMD = 1;
priv.pmode.MMOD = PMODEBits::MMOD_ALPHA_CIRCUIT1;
priv.smode1.CMOD = SMODE1Bits::CMOD_NTSC;
priv.smode1.LC = SMODE1Bits::LC_ANALOG;
priv.bgcolor.R = 0xff;
priv.bgcolor.G = 0xff;
priv.bgcolor.B = 0xff;
priv.pmode.SLBG = PMODEBits::SLBG_ALPHA_BLEND_BG;
priv.smode2.INT = 1;

priv.dispfb1.FBP = 0;
priv.dispfb1.FBW = 640 / BUFFER_WIDTH_SCALE;
priv.dispfb1.PSM = PSMCT32;
priv.dispfb1.DBX = 0;
priv.dispfb1.DBY = 0;
priv.display1.DX = 636; // Magic values that center the screen.
priv.display1.DY = 50; // Magic values that center the screen.
priv.display1.MAGH = 3; // scaling factor = MAGH + 1 = 4 -&gt; 640 px wide.
priv.display1.MAGV = 0;
priv.display1.DW = 640 * 4 - 1;
priv.display1.DH = 448 - 1;</pre>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/vk.png"><img decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/vk-1024x590.png" alt="" width="660" height="380" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/vk-1024x590.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-300x173.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-768x443.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-1536x886.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/vk.png 2005w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Glorious 256×179 logo 😀</p>
<h2>Implementation details</h2>
<h3>The rendering pipeline</h3>
<p>Before we get into the page tracker, it’s useful to define a rendering pipeline where synchronization is implied between each stage.</p>
<ul>
<li>Synchronize CPU copy of VRAM to GPU. This is mostly unused, but happens for save state load, or similar</li>
<li>Upload data to VRAM (or perform local-to-local copy)</li>
<li>Update CLUT cache from VRAM</li>
<li>Unswizzle VRAM into VkImages that can be sampled directly, and handle palettes as needed, sampling from CLUT cache</li>
<li>Perform rendering</li>
<li>Synchronize GPU copy of VRAM back to CPU. This will be useful for readbacks. Then CPU should be able to unswizzle directly from a HOST_CACHED_BIT buffer as needed</li>
</ul>
<p>This pipeline matches what we expect a game to do over and over:</p>
<ul>
<li>Upload texture to VRAM</li>
<li>Upload palette to VRAM</li>
<li>Update CLUT cache</li>
<li>Draw with texture
<ul>
<li>Trigger unswizzle from VRAM into VkImage if needed</li>
<li>Begins building a “render pass”, a batch of primitives</li>
</ul>
</li>
</ul>
<p>When there are no backwards hazards here, we can happily keep batching and defer any synchronization. This is critical to get any performance out of this style of renderer.</p>
<p>Some common hazards here include:</p>
<h4>Copy to VRAM which was already written by copy</h4>
<p>This is often a false positive, but we cannot track per-byte. This becomes a simple copy barrier and we move on.</p>
<h4>Copy to VRAM where a texture was sampled from, or CLUT cache read from</h4>
<p>Since the GS has a tiny 4 MiB VRAM, it’s very common that textures are continuously streamed in, sampled from, and thrown away. When this is detected, we have to submit all vram copy work, all texture unswizzle work and then begin a new batch. Primitive batches are not disrupted.</p>
<p>This means we’ll often see:</p>
<ul>
<li>Copy xN</li>
<li>Barrier</li>
<li>Unswizzle xN</li>
<li>Barrier</li>
<li>Copy xN</li>
<li>Barrier</li>
<li>Unswizzle xN</li>
<li>Barrier</li>
<li>Rendering</li>
</ul>
<h4>Sample texture that was rendered to</h4>
<p>Similar, but here we need to flush out everything. This basically breaks the render pass and we start another one. Too many of these is problematic for performance obviously.</p>
<h4>Copy to VRAM where rendering happened</h4>
<p>Basically same as sampling textures, this is a full flush.</p>
<p>Other hazards are ignored, since they are implicitly handled by our pipeline.</p>
<h3>Page tracker</h3>
<p>Arguably, the hardest part of GS emulation is dealing with hazards. VRAM is read and written to with reckless abandon and any potential read-after-write or write-after-write hazard needs to be dealt with. We cannot rely on any game doing this for us, since PS2 GS just deals with sync in most cases, and TEXFLUSH is the only real command games will use (or forget to use).</p>
<p>Tracking per byte is ridiculous, so my solution is to first subdivide the 4 MiB VRAM into pages. A page is the unit for frame buffers and depth buffers, so it is the most meaningful place to start.</p>
<h4>PageState</h4>
<p>On page granularity, we track:</p>
<ul>
<li>Pending frame buffer write?</li>
<li>Pending frame buffer read? (read-only depth)</li>
</ul>
<p>Textures and VRAM copies have 256 byte alignment, and to avoid a ton of false positives, we need to track on a per-block basis. There are 32 blocks per page, so a u32 bit-mask is okay.</p>
<ul>
<li>VRAM copy writes</li>
<li>VRAM copy reads</li>
<li>Pending read into CLUT cache or VkImage</li>
<li>Blocks which have been clobbered by any write, on next texture cache invalidate, throw away images that overlap</li>
</ul>
<p>As mentioned earlier, there are also cases where you can render to 24-bit color, while sampling from the upper 8-bits without hazard. We need to optimize for that case too, so there is also:</p>
<ul>
<li>A write mask for framebuffers</li>
<li>A read mask for textures</li>
</ul>
<p>In the example above, FB write mask is 0xffffff and texture cache mask is 0xff000000. No overlap, no invalidate 😀</p>
<p>For host access, there are also timeline semaphore values per page. These values state which sync point to wait for if the host desires mapped read or mapped write access. Mapped write access may require more sync than mapped read if there are pending reads on that page.</p>
<h4>Caching textures</h4>
<p>Every page contains a list of VkImages which have been associated with it. When a page’s textures has been invalidated, the image is destroyed and has to be unswizzled again from VRAM.</p>
<p>There is a one-to-many relationship with textures and pages. A texture may span more than one page, and it’s enough that only one page is clobbered before the texture is invalidated.</p>
<p>Overall, there are a lot of micro-details here, but the important things to note here is that conservative and simple tracking will not work on PS2 games. Tracking at a 256 byte block level and considering write/read masks is critical.</p>
<h4>Special cases</h4>
<p>There are various situations where we may have false positives due to how textures work. Since textures are POT sized, it’s fairly common for e.g. a 512×448 texture of a render target to be programmed as a 512×512 texture. The unused region should ideally be clamped out with REGION_CLAMP, but most games don’t. A render target might occupy those unused pages. As long as the game’s UV coordinates don’t extend into the unused red zone, there are no hazards, but this is very painful to track. We would have to analyze every single primitive to detect if it’s sampling into the red zone.</p>
<p>As a workaround, we ignore any potential hazard in that red zone, and just pray that a game isn’t somehow relying on ridiculous spooky-action-at-a-distance hazards to work in the game’s favor.</p>
<p>There are more spicy special cases, especially with texture sampling feedback, but that will be for later.</p>
<h3>Updating CLUT in a batched way</h3>
<p>Since we want to batch texture uploads, we have to batch CLUT uploads too. To make this work, we have 1024 copies of CLUT, a ring buffer of snapshots.</p>
<p>One workgroup loops through the updates and writes them to an SSBO. I did a similar thing for N64 RDP’s TMEM update, where TMEM was instanced. Fortunately, CLUT update is <strong>far</strong> simpler than TMEM update.</p>
<pre>shared uint tmp_clut[512];

// ...

// Copy from previous instance to allow a
// CLUT entry to be partially overwritten and used later
uint read_index = registers.read_index * CLUT_SIZE_16;
tmp_clut[gl_LocalInvocationIndex] =
    uint(clut16.data[read_index]);
tmp_clut[gl_LocalInvocationIndex + 256u] =
    uint(clut16.data[read_index + 256u]);
barrier();

for (uint i = 0; i &lt; registers.clut_count; i++)
{
  // ...
  if (active_lane)
  {
    // update tmp_clut. If 256 color, all threads participate.
    // 16 color update is a partial update.
  }

  // Flush current CLUT state to SSBO.
  barrier();
  clut16.data[gl_LocalInvocationIndex + clut.instance * CLUT_SIZE_16] =
    uint16_t(tmp_clut[gl_LocalInvocationIndex]);
  clut16.data[gl_LocalInvocationIndex + clut.instance * CLUT_SIZE_16 + 256u] =
    uint16_t(tmp_clut[gl_LocalInvocationIndex + 256u]);
  barrier();
}</pre>
<p>One potential optimization is that for 256 color / 32 bpp updates, we can parallelize the CLUT update, since nothing from previous iterations will be preserved, but the CLUT update time is tiny anyway.</p>
<h3>Unswizzling textures from VRAM</h3>
<p>Since this is Vulkan, we can just allocate a new VkImage, suballocate it from VkDeviceMemory and blast it with a compute shader.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/upload.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/upload-1024x576.png" alt="" width="660" height="371" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/upload-1024x576.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-300x169.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-768x432.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-1536x864.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-2048x1152.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Using Vulkan’s specialization constants, we specialize the texture format and all the swizzling logic becomes straight forward code.</p>
<p>REGION_REPEAT shenanigans is also resolved here, so that the ubershader doesn’t have to consider that case and do manual bilinear filtering.</p>
<p>Even for render targets, we roundtrip through the VRAM SSBO. There is not really a point going to the length of trying to forward render targets into textures. Way too many bugs to squash and edge cases to think about.</p>
<h3>Triangle setup and binning</h3>
<p>Like paraLLEl-RDP, paraLLEl-GS is a tile-based renderer. Before binning can happen, we need triangle setup. As inputs, we provide attributes in three arrays.</p>
<h5>Position</h5>
<pre>struct VertexPosition
{
  ivec2 pos;
  float z;     // TODO: Should be uint for 32-bit Z.
  int padding; // Free real-estate?
};</pre>
<h5>Per-Vertex attributes</h5>
<pre>struct VertexAttribute
{
  vec2 st;
  float q;
  uint rgba; // unpackUnorm4x8
  float fog; // overkill, but would be padding anyway
  u16vec2 uv;
};</pre>
<h5>Per-primitive attributes</h5>
<pre>struct PrimitiveAttribute
{
  i16vec4 bb; // Scissor
  // Index into state UBO, as well as misc state bits.
  uint state;
  // Texture state which should be scalarized. Affects code paths.
  // Also holds the texture index (for bindless).
  uint tex;
  // Texture state like lod scaling factors, etc.
  // Does not affect code paths.
  uint tex2;  
  uint alpha; // AFIX / AREF
  uint fbmsk;
  uint fogcol;
};</pre>
<p>For rasterization, we have a straight forward barycentric-based rasterizer. It is heavily inspired by <a href="https://fgiesen.wordpress.com/2011/07/06/a-trip-through-the-graphics-pipeline-2011-part-6/">https://fgiesen.wordpress.com/2011/07/06/a-trip-through-the-graphics-pipeline-2011-part-6/</a>, which in turn is based on <a href="https://www.cs.drexel.edu/~david/Classes/Papers/comp175-06-pineda.pdf">A Parallel Algorithm for Polygon Rasterization (Paneda, 1988)</a> and describes the “standard” way to write a rasterizer with parallel hardware. Of course, the PS2 GS is DDA, i.e. a scanline rasterizer, but in practice, this is just a question of nudging ULPs of precision, and since I’m not aware of a bit-exact description of the GS’s DDA, this is fine. paraLLEl-RDP implements the raw DDA form for example. It’s certainly possible if we <strong>have</strong> to.</p>
<p>As an extension to a straight-forward triangle rasterizer, I also need to support parallelograms. This is used to implement wide-lines and sprites. Especially wide-line is kinda questionable, but I’m not sure it’s possible to fully solve up-scaling + Bresenham in the general case. At least I haven’t run into a case where this really matters.</p>
<p>Evaluating coverage and barycentric I/J turns into something like this:</p>
<pre>bool evaluate_coverage_single(PrimitiveSetup setup,
  bool parallelogram, 
  ivec2 parallelogram_offset,
  ivec2 coord, inout float i, inout float j)
{
  int a = idot3(setup.a, coord);
  int b = idot3(setup.b, coord);
  int c = idot3(setup.c, coord);

  precise float i_result = float(b) * setup.inv_area + setup.error_i;
  precise float j_result = float(c) * setup.inv_area + setup.error_j;
  i = i_result;
  j = j_result;

  if (parallelogram &amp;&amp; a.x &lt; 0)
  {
    b += a + parallelogram_offset.x;
    c += a + parallelogram_offset.y;
    a = 0;
  }

  return all(greaterThanEqual(ivec3(a, b, c), ivec3(0)));
}</pre>
<p>inv_area is computed in a custom fixed-point RCP, which is ~24.0 bit accurate. Using the standard GPU RCP would be bad since it’s just ~22.5 bit accurate and not consistent across implementations. There is no reason to skimp on reproducibility and accuracy, since we’re not doing work per-pixel.</p>
<p>error_i and error_j terms are caused by the downsampling of the edge equations and tie-break rules. As a side effect of the GS’s [-4k, +4k] pixel range, the range of the cross-product requires 33-bit in signed integers. By downsampling a bit, we can get 32-bit integer math to work just fine with 8 sub-pixel accuracy for super-sampling / multi-sampling. Theoretically, this means our upper up-sampling limit is 8×8, but that’s ridiculous anyway, so we’re good here.</p>
<p>The parallelogram offsets are very small numbers meant to nudge the tie-break rules in our favor as needed. The exact details of the implementation escape me. I wrote that code years ago. It’s not very hard to derive however.</p>
<p>Every primitive gets a struct of transformed attributes as well. This is only read if we actually end up shading a primitive, so it’s important to keep this separate to avoid polluting caches with too much garbage.</p>
<pre>struct TransformedAttributes
{
  vec4 stqf0;
  vec4 stqf1;
  vec4 stqf2;
  uint rgba0;
  uint rgba1;
  uint rgba2;
  uint padding;
  vec4 st_bb;
};</pre>
<p>Using I/J like this will lead to small inaccuracies when interpolating primitives which expect to land exactly on the top-left corner of a texel with NEAREST filtering. To combat this, a tiny epsilon offset is used when snapping texture coordinates. Very YOLO, but what can you do. As far as I know, hardware behavior is sub-texel floor, not sub-texel round.</p>
<pre>precise vec2 uv_1 = uv * scale_1;

// Want a soft-floor here, not round behavior.
const float UV_EPSILON_PRE_SNAP = 1.0 / 16.0;
// We need to bias less than 1 / 512th texel, so that linear filter will RTE to correct subpixel.
// This is a 1 / 1024th pixel bias to counter-act any non-POT inv_scale_1 causing a round-down event.
const float UV_EPSILON_POST_SNAP = 16.0 / 1024.0;

if (sampler_clamp_s)
  uv_1.x = texture_clamp(uv_1.x, region_coords.xz, LOD_1);
if (sampler_clamp_t)
  uv_1.y = texture_clamp(uv_1.y, region_coords.yw, LOD_1);

// Avoid micro-precision issues with UV and flooring + nearest.
// Exact rounding on hardware is somwhat unclear.
// SotC requires exact rounding precision and is hit particularly bad.
// If the epsilon is too high, then FF X save screen is screwed over,
// so ... uh, ye.
// We likely need a more principled approach that is actually HW accurate in fixed point.
uv_1 = (floor(uv_1 * 16.0 + UV_EPSILON_PRE_SNAP) + UV_EPSILON_POST_SNAP) *
       inv_scale_1 * 0.0625;</pre>
<h3>Binning</h3>
<p>This is mostly uninteresting. Every NxN pixel block gets an array of u16 primitive indices to shade. This makes the maximum number of primitives per render pass 64k, but that’s enough for PS2 games. Most games I’ve seen so far tend to be between 10k and 30k primitives for the “main” render pass, but I haven’t tested the real juggernauts of primitive grunt yet, but even so, having to do a little bit of incremental rendering isn’t a big deal.</p>
<p>NxN is usually 32×32, but it can be dynamically changed depending on how heavy the geometry load is. For large resolutions and high primitive counts, the binning and memory cost is unacceptable if the resolution is just 16×16 for example. One subgroup is responsible for iterating through all primitives in a block.</p>
<p>Since binning and triangle is state-less, triangle-setup and binning for back-to-back passes are batched up nicely to avoid lots of silly barriers.</p>
<h3>The ubershader</h3>
<p>A key difference between N64 and PS2 is fill-rate and per-pixel complexity. For N64, the ideal approach is to specialize the rasterizing shader, write out per-pixel color + depth + coverage + etc, then merge that data in a much simpler ubershader that only needs to consider depth and blend state rather than full texturing state and combiner state. This is very bandwidth intensive on the GPU, but the alternative is the slowest ubershader written by man. We’re saved by the fact that N64 fill-rate is abysmal. <a href="https://www.youtube.com/watch?v=GC_jLsxZ7nw">Check out this video by Kaze to see how horrible it is</a>.</p>
<p>The GS is a quite different beast. Fill-rate is very high, and per-pixel complexity is fairly low, so a pure ubershader is viable. We can also rely on bindless this time around too, so texturing complexity becomes a fraction of what I had to deal with on N64.</p>
<h4>Fine-grained binning</h4>
<p>Every tile is 4×4, 4×8 and 8×8 for subgroup sizes 16, 32 and 64 respectively. For super-sampling it’s even smaller (it’s 4×4 / 4×8 / 8×8 in the higher resolution domain instead).</p>
<p>In the outer loop, we pull in up to SubgroupSize’s worth of primitives, and bin them in parallel.</p>
<pre>for (int i = 0; i &lt; tile.coarse_primitive_count;
     i += int(gl_SubgroupSize))
{
  int prim_index = i + int(gl_SubgroupInvocationID);
  bool is_last_iteration = i + int(gl_SubgroupSize) &gt;= 
                           tile.coarse_primitive_count;

  // Bin primitives to tile.
  bool binned_to_tile = false;
  uint bin_primitive_index;
  if (prim_index &lt; tile.coarse_primitive_count)
  {
    bin_primitive_index = 
      uint(coarse_primitive_list.data[
           tile.coarse_primitive_list_offset + prim_index]);
    binned_to_tile = primitive_intersects_tile(bin_primitive_index);
  }

  // Iterate per binned primitive, do per pixel work now.
  // Scalar loop.
  uvec4 work_ballot = subgroupBallot(binned_to_tile);</pre>
<p>In the inner loop, we can do a scalarized loop which checks coverage per-pixel, one primitive at a time.</p>
<pre>// Scalar data
uint bit = subgroupBallotFindLSB(work_ballot);

if (gl_SubgroupSize == 64)
{
  if (bit &gt;= 32)
    work_ballot.y &amp;= work_ballot.y - 1;
  else
    work_ballot.x &amp;= work_ballot.x - 1;
}
else
{
  work_ballot.x &amp;= work_ballot.x - 1;
}

shade_primitive_index = subgroupShuffle(bin_primitive_index, bit);</pre>
<h4>Early Z</h4>
<p>We can take advantage of early-Z testing of course, but we have to be careful if there are rasterized pixels we haven’t resolved yet, and there are Z-writes in flight. In this case we have to defer to late Z to perform test.</p>
<pre>// We might have to remove opaque flag.
bool pending_z_write_can_affect_result =
  (pixel.request.z_test || !pixel.request.z_write) &amp;&amp;
  pending_shade_request.z_write;

if (pending_z_write_can_affect_result)
{
  // Demote the pixel to late-Z,
  // it's no longer opaque and we cannot discard earlier pixels.
  // We need to somehow observe the previous results.
  pixel.opaque = false;
}</pre>
<h4>Deferred on-tile shading</h4>
<p>Since we’re an uber-shader, all pixels are “on-chip”, i.e. in registers, so we can take advantage of culling pixels that won’t be visible anyway. The basic idea here is that after rasterization, if a pixel is considered opaque, it will simply replace the shading request that exists for that framebuffer coordinate. It won’t be visible at all anyway.</p>
<h4>Lazy pixel shading</h4>
<p>We only need to perform shading when we really have to, i.e., we’re shading a pixel that depends on the previous pixel’s results. This can happen for e.g. alpha test (if test fails, we preserve existing data), color write masks, or of course, alpha blending.</p>
<p>If our pixel remains opaque, we can just kill the pending pixel shade request. Very nice indeed. The gain here wasn’t as amazing as I had hoped since PS2 games love blending, but it helps culling out a lot of shading work.</p>
<pre>if (pixel.request.coverage &gt; 0)
{
  need_flush = !pixel.opaque &amp;&amp; pending_shade_request.coverage &gt; 0;

  // If there is no hazard, we can overwrite the pending pixel.
  // If not, defer the update until we run a loop iteration.
  if (!need_flush)
  {
    set_pending_shade_request(pixel.request, shade_primitive_index);
    pixel.request.coverage = 0;
    pixel.request.z_write = false;
  }
}</pre>
<p>If we have flushes that need to happen, we do so if one pixel needs it. It’s just as fast to resolve all pixels anyway.</p>
<pre>// Scalar branch
if (subgroupAny(need_flush))
{
  shade_resolve();
  if (has_work &amp;&amp; pixel.request.coverage &gt; 0)
    set_pending_shade_request(pixel.request, shade_primitive_index);
}</pre>
<p>The resolve is a straight forward waterfall loop that stays in uniform control flow to be well defined on devices without maximal reconvergence support.</p>
<pre>while (subgroupAny(has_work))
{
  if (has_work)
  {
    uint state_index =
      subgroupBroadcastFirst(pending_shade_request.state);
    uint tex = subgroupBroadcastFirst(prim_tex);
    if (state_index == pending_shade_request.state &amp;&amp; prim_tex == tex)
    {
      has_work = false;
      shade_resolve(pending_primitive_index, state_index, tex);
    }
  }
}</pre>
<p>This scalarization ensures that all branches on things like alpha test mode, blend modes, etc, are purely scalar, and GPUs like that. Scalarizing on the texture index is technically not that critical, but it means we end up hitting the same branches for filtering modes, UBOs for scaling factors are loaded uniformly, etc.</p>
<p>When everything is done, the resulting framebuffer color and depth is written out to SSBO. GPU bandwidth is kept to a minimum, just like a normal TBDR renderer.</p>
<h3>Super-sampling</h3>
<p>Just implementing single sampled rendering isn’t enough for this renderer to be really useful. The software renderer is certainly quite fast, but not fast enough to keep up with intense super-sampling. We can fix that now.</p>
<p>For e.g. 8x SSAA, we keep 10 versions of VRAM on the GPU.</p>
<ul>
<li>1 copy represents the single-sampled VRAM. It is super-sampled.</li>
<li>1 copy represents the reference value for single-sampled VRAM. This allows us to track when we should discard the super-samples and splat the single sample to all. This can happen if someone copies to VRAM over a render target for whatever reason.</li>
<li>8 copies which each represent the super-samples. Technically, we can reconstruct a higher resolution image from these samples if we really want to, but only the CRTC could easily do that.</li>
</ul>
<p>When rendering super-sampled, we load the single-sampled VRAM and reference. If they match, we load the super-sampled version. This is important for cases where we’re doing incremental rendering.</p>
<p>On tile completion we use clustered subgroup ops to do multi-sample resolve, then write out the super-samples, and the two single-sampled copies.</p>
<pre>uvec4 ballot_color = subgroupBallot(fb_color_dirty);
uvec4 ballot_depth = subgroupBallot(fb_depth_dirty);

// No need to mask, we only care about valid ballot for the
// first sample we write-back.
if (NUM_SAMPLES &gt;= 16)
{
  ballot_color |= ballot_color &gt;&gt; 8u;
  ballot_depth |= ballot_depth &gt;&gt; 8u;
}

if (NUM_SAMPLES &gt;= 8)
{
  ballot_color |= ballot_color &gt;&gt; 4u;
  ballot_depth |= ballot_depth &gt;&gt; 4u;
}

if (NUM_SAMPLES &gt;= 4)
{
  ballot_color |= ballot_color &gt;&gt; 2u;
  ballot_depth |= ballot_depth &gt;&gt; 2u;
}

ballot_color |= ballot_color &gt;&gt; 1u;
ballot_depth |= ballot_depth &gt;&gt; 1u;

// GLSL does not accept cluster reduction as spec constant.
if (NUM_SAMPLES == 16)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 16) / 16.0);
else if (NUM_SAMPLES == 8)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 8) / 8.0);
else if (NUM_SAMPLES == 4)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 4) / 4.0);
else
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 2) / 2.0);

fb_color_dirty = subgroupInverseBallot(ballot_color);
fb_depth_dirty = subgroupInverseBallot(ballot_depth);</pre>
<p>The main advantage of super-sampling over straight up-scaling is that up-scaling will still have jagged edges, and super-sampling retains a coherent visual look where 3D elements have similar resolution as UI elements. One of my pet peeves is when UI elements have a significantly different resolution from 3D objects and textures. HD texture packs can of course alleviate that, but that’s a very different beast.</p>
<p>Super-sampling also lends itself very well to CRT post-processing shading, which is also a nice bonus.</p>
<h3>Dealing with super-sampling artifacts</h3>
<p>It’s a fact of life that super-sampling always introduces horrible artifacts if not handled with utmost care. Mitigating this is arguably easier with software renderers over traditional graphics APIs, since we’re not limited by the fixed function interpolators. These tricks won’t make it perfect by any means, but it greatly mitigates jank in my experience, and I already fixed many upscaling bugs that GSdx Vulkan backend does not solve as we shall see later.</p>
<h4>Sprite primitives should always render at single-rate</h4>
<p>Sprites are always UI elements or similar, and games do not expect us to up-scale them. Doing so either results in artifacts where we sample outside the intended rect, or we risk overblurring the image if bilinear filtering is used.</p>
<p>The trick here is just to force-snap the pixel coordinate we use when rasterizing and interpolating. This is very inefficient of course, but UI shouldn’t take up the entire screen. And if it does (like in a menu), the GPU load is tiny anyway.</p>
<pre>const uint SNAP_RASTER_BIT = (1u &lt;&lt; STATE_BIT_SNAP_RASTER);
const uint SNAP_ATTR_BIT = (1u &lt;&lt; STATE_BIT_SNAP_ATTRIBUTE);

if (SUPER_SAMPLE &amp;&amp; (prim_state &amp; SNAP_RASTER_BIT) != 0)
  fb_pixel = tile.fb_pixel_single_rate;

res.request.coverage = evaluate_coverage(
  prim, fb_pixel, i, j,
  res.request.multisample, SAMPLING_RATE_DIM_LOG2);</pre>
<h4>Flat primitives should interpolate at single-pixel coordinate</h4>
<p>Going further, we can demote SSAA interpolation to MSAA center interpolation dynamically. Many UI elements are unfortunately rendered with normal triangles, so we have to be a bit more careful. This snap only affects attribute interpolation, not Z of course.</p>
<pre>res.request.st_bb = false;
if (SUPER_SAMPLE &amp;&amp;
    (prim_state &amp; (SNAP_RASTER_BIT | SNAP_ATTR_BIT)) == SNAP_ATTR_BIT)
{
  vec2 snap_ij = evaluate_barycentric_ij(
    prim.b, prim.c, prim.inv_area,
    prim.error_i, prim.error_j, tile.fb_pixel_single_rate,
    SAMPLING_RATE_DIM_LOG2);

  i = snap_ij.x;
  j = snap_ij.y;
  res.request.st_bb = true;
}</pre>
<p>Here, we snap interpolation to the top-left pixel. This fixes any artifacts for primitives which align their rendering to a pixel center, but some games are mis-aligned, so this snapping can cause texture coordinates to go outside the expected area. To clean this up, we compute a bounding box of final texture coordinates. Adding bounding boxes can technically cause notorious block-edge artifacts, but that was mostly a thing on PS1 since emulators like to convert nearest sampling to bilinear.</p>
<p>The heuristic for this is fairly simple. If perspective is used, if all vertices in a triangle have exact same Q, we assume it’s a flat UI primitive. The primitive’s Z coordinates must also match. This is done during triangle setup on the GPU. There can of course be false positives here, but it should be rare. In my experience this hack works well enough in the games I tried.</p>
<h2>Results</h2>
<p>Here’s a good example of up-sampling going awry in PCSX2. This is with Vulkan backend:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1024x674.jpg" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1024x674.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-300x198.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-768x506.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1536x1012.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts.jpg 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Notice the bloom on the glass being mis-aligned and a subtle (?) rectangular pattern being overlaid over the image. This is caused by a post-processing pass rendering in a page-like pattern, presumably to optimize for GS caching behavior.</p>

<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>With 8x SSAA in paraLLEl-GS it looks like this instead. There is FSR1 post-upscale in effect here which changes the look a bit, but the usual trappings of bad upscale cannot be observed here. This is another reason to do super-sample; texture mis-alignment has a tendency to fix itself.</p>
<p>Also, if you’re staring at the perf numbers, this is RX 7600 in a low power state :’)</p>
<p>Typical UI issues can be seen in games as well. Here’s native resolution:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>and 4x upscale, which … does not look acceptable.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>This UI is tricky to render in upscaled mode, since it uses triangles, but the MSAA snap trick above works well and avoids all artifacts. With straight upscale, this is hard to achieve in normal graphics APIs since you’d need interpolateAtOffset beyond 0.5 pixels, which isn’t supported. Perhaps you could do custom interpolation with derivatives or something like that, but either way, this glitch can be avoided. The core message is basically to never upscale UI beyond plain nearest neighbor integer scale. It just looks bad.</p>
<p>There are cases where PCSX2 asks for high blending accuracy. One example is MGS2, and I found a spot where GPU perf is murdered. My desktop GPU cannot keep 60 FPS here at 4x upscale. PCSX2 asks you to turn up blend-accuracy for this game, but …</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1024x621.jpg" alt="" width="660" height="400" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1024x621.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-300x182.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-768x466.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1536x932.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2.jpg 1747w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>What happens here is we hit the programmable blending path with barrier between every primitive. Ouch! This wouldn’t be bad for the tiler mobile GPUs, but for a desktop GPU, it is where perf goes to die. The shader in question does subpassLoad and does programmable blending as expected. Barrier, tiny triangle, barrier, tiny triangle, hnnnnnnng.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/ouch.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1024x576.png" alt="" width="660" height="371" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1024x576.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-300x169.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-768x432.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1536x864.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-2048x1152.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>paraLLEl-GS on the other hand always runs with 100% blend accuracy (assuming no bugs of course). Here’s 16xSSAA (equivalent to 4x upscale). This is just 25 W and 17% GPU utilization on RX 7600. Not bad.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Other difficult cases include texture sampling feedback. One particular case I found was in Valkyrie Profile 2.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1024x621.jpg" alt="" width="660" height="400" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1024x621.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-300x182.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-768x466.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1536x932.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2.jpg 1747w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>This game has a case where it’s sampling it’s own pixel’s alpha as a palette index. Quirky as all hell, and similar to MGS2 there’s a barrier between every pixel.</p>
<p>In paraLLEl-GS, this case is detected, and we emit a magical texture index, which resolved to just looking at in-register framebuffer color instead. Programmable blending go brr. These cases have to be checked per primitive, which is quite rough on CPU time, but it is what it is. If we don’t hit the good path, GPU performance completely tanks.</p>
<p>The trick here is to analyze the effective UV coordinates, and see if UV == framebuffer position. If we fall off this path, we have to go via texture uploads, which is bad.</p>
<pre>ivec2 uv0_delta = uv0 - pos[0].pos;
ivec2 uv1_delta = uv1 - pos[1].pos;
ivec2 min_delta = min(uv0_delta, uv1_delta);
ivec2 max_delta = max(uv0_delta, uv1_delta);

if (!quad)
{
  ivec2 uv2_delta = uv2 - pos[2].pos;
  min_delta = min(min_delta, uv2_delta);
  max_delta = max(max_delta, uv2_delta);
}

int min_delta2 = min(min_delta.x, min_delta.y);
int max_delta2 = max(max_delta.x, max_delta.y);

// The UV offset must be in range of [0, 2^SUBPIXEL_BITS - 1].
// This guarantees snapping with NEAREST.
// 8 is ideal. That means pixel centers during interpolation
// will land exactly in the center of the texel.
// In theory we could allow LINEAR if uv delta was
// exactly 8 for all vertices.
if (min_delta2 &lt; 0 || max_delta2 &gt;= (1 &lt;&lt; SUBPIXEL_BITS))
  return ColorFeedbackMode::Sliced;

// Perf go brrrrrrr.
return ColorFeedbackMode::Pixel;</pre>
<pre>if (feedback_mode == ColorFeedbackMode::Pixel)
{
  mark_render_pass_has_texture_feedback(ctx.tex0.desc);
  // Special index indicating on-tile feedback.
  // We could add a different sentinel for depth feedback.
  // 1024k CLUT instances and 32 sub-banks. Fits in 15 bits.
  // Use bit 15 MSB to mark feedback texture.
  return (1u &lt;&lt; (TEX_TEXTURE_INDEX_BITS - 1u)) |
         (render_pass.clut_instance * 32 + uint32_t(ctx.tex0.desc.CSA));
}</pre>
<p>It’s comfortably full-speed on PCSX2 here, despite the copious number of barriers, but paraLLEl-GS is reasonably close perf-wise, actually. At 8x SSAA.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1024x709.jpg" alt="" width="660" height="457" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1024x709.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-300x208.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-768x532.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1536x1064.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs.jpg 1708w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Overall, we get away with 18 render pass barriers instead of 500+ which was the case without this optimization. You may notice the interlacing artifacts on the swirlies. Silly game has a progressive scan output, but downsamples it on its own to a field before hitting CRTC, hnnnnng 🙁 Redirecting framebuffer locations in CRTC might work as a per-game hack, but either way, I still need to consider a better de-interlacer. Some games actually render explicitly in fields (640×224), which is very annoying.</p>
<p>This scene in the MGS2 intro also exposes some funny edge cases with sampling.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>To get the camo effect, it’s sampling its own framebuffer as a texture, with overlapping coordinates, but not pixel aligned, so this raises some serious questions about caching behavior. PCSX2 doesn’t seem to add any barriers here, and I kinda had to do the same thing. It looks fine to me compared to software renderer at least.</p>
<pre>if (feedback_mode == ColorFeedbackMode::Sliced)
{
  // If game explicitly clamps the rect to a small region,
  // it's likely doing well-defined feedbacks.
  // E.g. Tales of Abyss main menu ping-pong blurs.
  // This code is quite flawed,
  // and I'm not sure what the correct solution is yet.
  if (desc.clamp.desc.WMS == CLAMPBits::REGION_CLAMP &amp;&amp;
      desc.clamp.desc.WMT == CLAMPBits::REGION_CLAMP)
  {
    ivec4 clamped_uv_bb(
      int(desc.clamp.desc.MINU),
      int(desc.clamp.desc.MINV),
      int(desc.clamp.desc.MAXU),
      int(desc.clamp.desc.MAXV));

    ivec4 hazard_bb(
      std::max&lt;int&gt;(clamped_uv_bb.x, bb.x),
      std::max&lt;int&gt;(clamped_uv_bb.y, bb.y),
      std::min&lt;int&gt;(clamped_uv_bb.z, bb.z),
      std::min&lt;int&gt;(clamped_uv_bb.w, bb.w));

    cache_texture = hazard_bb.x &gt; hazard_bb.z ||
                    hazard_bb.y &gt; hazard_bb.w;
  }
  else
  {
    // Questionable,
    // but it seems almost impossible to do this correctly and fast.
    // Need to emulate the PS2 texture cache exactly,
    // which is just insane.
    // This should be fine.
    cache_texture = false;
  }
}</pre>
<p>If we’re in a mode where texture points directly to the frame buffer we should relax the hazard tracking a bit to avoid 2000+ barriers. This is clearly spooky since Tales of Abyss’s bloom effect as shown earlier depends on this to be well behaved, but in that case, at least it uses REGION_CLAMP to explicitly mark the ping-pong behavior. I’m not sure what the proper solution is here.</p>
<p>The only plausible solution to true bit-accuracy with real hardware is to emulate the caches directly, one pixel at a time. You can kiss performance good bye in that case.</p>
<p>One of the worst stress tests I’ve found so far has to be Shadow of the Collosus. Just in the intro, we can make the GPU kneel down to 24 FPS with maximum blend accuracy on PCSX2, at just 2x upscale! Even with normal blending accuracy, it is extremely heavy during the intro cinematic.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1024x674.png" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1024x674.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-300x198.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-768x506.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1536x1012.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy.png 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>At 8x SSAA, perf is still looking pretty good for paraLLEl-GS, but it’s clearly sweating now.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-1024x717.jpg" alt="" width="660" height="462" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-1024x717.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-300x210.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-768x538.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc.jpg 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>We’re actually still CPU bound on the geometry processing. Optimizing the CPU code hasn’t been a huge priority yet. There’s unfortunately a lot of code that has to run per-primitive, where hazards can happen around every corner that has to be dealt with somehow. I do some obvious optimizations, but it’s obviously not as well-oiled as PCSX2 in that regard.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1024x611.png" alt="" width="660" height="394" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1024x611.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-300x179.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-768x458.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1536x917.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600.png 1766w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<h3>Deck?</h3>
<p>It seems fast enough to comfortably do 4x SSAA. Maybe not in SotC, but … hey. 😀</p>
<h2>What now?</h2>
<p>For now, the only real way to test this is through GS dumps. <a href="https://github.com/Arntzen-Software/parallel-gs/blob/main/misc/0001-Add-an-ad-hoc-GS-stream-format.patch">There’s a hack-patch for PCSX2</a> that lets you dump out a raw GS trace, which can be replayed. This works via mkfifo as a crude hack to test in real-time, but some kind of integration into an emulator needs to happen at some point if this is to turn into something that’s useful for end users.</p>
<p>There’s guaranteed to be a million bugs lurking since the PS2 library is ridiculously large and there’s only so much I can be arsed to test myself. At least, paraLLEl-GS has now become my preferred way to play PS2 games, so I can say mission complete.</p>
<p>A potential use case for this is due to its standalone library nature, it may be useful as very old-school rendering API for the old greybeards around that still yearn for the day of PS2 programming for whatever reason :p</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Taming the beast that is the Django ORM – An introduction (138 pts)]]></title>
            <link>https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/</link>
            <guid>41413641</guid>
            <pubDate>Sun, 01 Sep 2024 02:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/">https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/</a>, See on <a href="https://news.ycombinator.com/item?id=41413641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><img src="https://www.davidhang.com/_astro/1.UiFfZ6wR_IHH0Y.webp" alt="man fighting dragon which represents the django orm" width="1024" height="1024" loading="lazy" decoding="async"></p>
<p>The material this blog post was originally developed from was a bunch of slides
used for a skill share presentation I gave at my workplace <span>@</span> <a href="https://coreplan.io/">coreplan.io</a>.</p>
<p>I have 3+ years of experience with Django, with it being the main framework that
underpins the backend of CorePlan’s main SaaS product. It is a mature, batteries
included framework that has been around for a while now. One particular powerful
yet dangerous feature of Django is the ORM. This is a Django specific ORM which
cannot be separated from the rest of the framework. The other major python ORM
is SQLAlchemy which can be used with other python web frameworks, but is an
independent tool.</p>
<p>Below are some of the things that I have learned about the Django ORM, how it
compares to raw SQL and gotchas that you should be aware of when using it.</p>
<hr>
<h2 id="what-is-an-orm-object-relational-mapper">What is an ORM (Object Relational Mapper)?</h2>
<ul>
<li>Abstraction over SQL to interact with databases</li>
</ul>
<p>Code -&gt; SQL</p>
<pre tabindex="0" data-language="python"><code><span><span>Hole.objects.all()</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> FROM</span><span> drilling_hole;</span></span>
<span></span></code></pre>
<hr>
<h2 id="why-use-an-orm---pros">Why use an ORM? - Pros</h2>
<ul>
<li>Abstraction over SQL, no need to write raw SQL (plus and minus)</li>
<li>Portability - Can change out database engines easily !?
<ul>
<li>Probably not true, often will rely on db specific features e.g. postgres jsonb, triggers, etc</li>
</ul>
</li>
<li>Direct mapping from db to models</li>
<li>Automatic schema generation
<ul>
<li>Migrations are automatically generated</li>
</ul>
</li>
<li>Security
<ul>
<li>abstracts away enough that sql injection is less likely</li>
</ul>
</li>
</ul>
<hr>
<h2 id="why-use-an-orm---cons">Why use an ORM? - Cons</h2>
<ul>
<li>Abstraction over SQL…
<ul>
<li>Hides the underlying SQL</li>
<li>Can be difficult to debug</li>
<li>Lazy loading can cause N+1 queries without the developer realising</li>
<li>Harder to onboard new developers if they haven’t used Django before</li>
</ul>
</li>
<li>Performance
<ul>
<li>Generated sql be slower than crafted SQL</li>
</ul>
</li>
</ul>
<hr>
<h2 id="fundamentals">Fundamentals</h2>
<ul>
<li>Models = Tables</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span># drilling/models.py</span></span>
<span></span>
<span><span>from</span><span> django.db </span><span>import</span><span> models</span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>    name </span><span>=</span><span> models.TextField()</span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="sql"><code><span><span>CREATE</span><span> TABLE</span><span> drilling_hole</span><span> (</span></span>
<span><span>    id </span><span>SERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span><span>    name</span><span> VARCHAR</span><span>(</span><span>100</span><span>)</span></span>
<span><span>);</span></span>
<span></span></code></pre>
<hr>
<h2 id="migrations">Migrations</h2>
<pre tabindex="0" data-language="bash"><code><span><span>python</span><span> manage.py</span><span> makemigrations</span><span> # generate migration files</span></span>
<span><span>python</span><span> manage.py</span><span> migrate</span><span> # apply migrations</span></span>
<span></span>
<span><span>python</span><span> manage.py</span><span> drilling</span><span> --empty</span><span> # generate empty file for data migration</span></span>
<span></span></code></pre>
<p><a href="https://docs.djangoproject.com/en/dev/topics/migrations/">https://docs.djangoproject.com/en/dev/topics/migrations/</a></p>
<hr>

<h2 id="querying">Querying</h2>
<ul>
<li><code>ActiveRecord</code> pattern - ala Ruby on Rails style</li>
<li>QuerySets (<code>Hole.objects.all()</code>)
<ul>
<li>lazy</li>
<li>chainable</li>
<li>cached when iterated over multiple times <a href="https://docs.djangoproject.com/en/dev/topics/db/queries/#caching-and-querysets">!?</a>
<ul>
<li>I would not recommend relying on this because it hard to comprehend when it is cached and when it is not when you are reading code</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>name</span><span>=</span><span>"cheese"</span><span>) </span><span># not evaluated yet</span></span>
<span><span>holes_qs </span><span>=</span><span> holes_qs.filter(</span><span>depth__gt</span><span>=</span><span>100</span><span>) </span><span># still not evaluated</span></span>
<span></span>
<span><span>list</span><span>(holes_qs) </span><span># evaluated</span></span>
<span><span>list</span><span>(holes_qs) </span><span># cached</span></span>
<span></span>
<span><span>holes_qs[</span><span>2</span><span>] </span><span># not cached</span></span>
<span><span>holes_qs.first() </span><span># not cached</span></span>
<span><span>holes_qs.get(</span><span>id</span><span>=</span><span>1</span><span>) </span><span># not cached</span></span>
<span></span></code></pre>
<hr>
<h2 id="where">WHERE</h2>
<ul>
<li><code>WHERE</code> clause ≈ <code>filter()</code></li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>name</span><span>=</span><span>"cheese"</span><span>)</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> </span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>WHERE</span><span> drilling_hole</span><span>.</span><span>name</span><span> =</span><span> 'cheese'</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="where-across-tables">WHERE across tables?</h2>
<ul>
<li>But how do you do a left/inner join? With the ORM it isn’t done declaratively, but implicitly</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>pad__name</span><span>=</span><span>"cheese board"</span><span>)</span></span>
<span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> </span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>INNER JOIN</span><span> drilling_pad </span><span>ON</span><span> drilling_hole</span><span>.</span><span>pad_id</span><span> =</span><span> drilling_pad</span><span>.</span><span>id</span></span>
<span><span>WHERE</span><span> drilling_pad</span><span>.</span><span>name</span><span> =</span><span> 'cheese board'</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="where-other-conditionals">WHERE other conditionals</h2>
<ul>
<li><code>filter(name="cheese")</code> -&gt; <code>filter(name__exact="cheese")</code> -&gt; <code>WHERE name = 'cheese'</code></li>
<li><code>filter(name__iexact="cheese")</code> -&gt; <code>WHERE name ILIKE 'cheese'</code></li>
<li><code>filter(name__contains="cheese")</code> -&gt; <code>WHERE name LIKE '%cheese%'</code></li>
<li><code>filter(name__icontains="cheese")</code> -&gt; <code>WHERE name ILIKE '%cheese%'</code></li>
<li><code>filter(name__in=["cheese", "board"])</code> -&gt; <code>WHERE name IN ('cheese', 'board')</code></li>
<li><code>filter(name__gt=100)</code> -&gt; <code>WHERE name &gt; 100</code> etc</li>
<li><code>filter(name__isnull=True)</code> -&gt; <code>WHERE name IS NULL</code>
<ul>
<li>At least for postgres shouldn’t <code>name = None</code>, <a href="https://www.postgresql.org/docs/current/functions-comparison.html">null != null</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="as">AS</h2>
<ul>
<li><code>annotate</code> ≈ <code>AS</code></li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.annotate(</span><span>this_thang</span><span>=</span><span>F(</span><span>"pad__name"</span><span>))</span></span>
<span><span>hole </span><span>=</span><span> holes_qs.first()</span></span>
<span><span>print</span><span>(hole.this_thang)</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  *</span><span> , </span></span>
<span><span>  drilling_pad</span><span>.</span><span>name</span><span> AS</span><span> this_thang</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>INNER JOIN</span><span> "drilling_pad"</span><span> ON</span><span> (</span><span>"drilling_hole"</span><span>.</span><span>"pad_id"</span><span> =</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>)</span></span>
<span></span>
<span></span></code></pre>
<hr>
<h2 id="subqueries">Subqueries</h2>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Project</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  project </span><span>=</span><span> models.ForeignKey(Project, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span># find pads that are on project_id=1</span></span>
<span><span>hole_subquery </span><span>=</span><span> Hole.objects.filter(</span><span>project_id</span><span>=</span><span>1</span><span>).values(</span><span>"pk"</span><span>)</span></span>
<span><span>pad_qs </span><span>=</span><span> Pad.objects.filter(</span><span>hole__in</span><span>=</span><span>Subquery(hole_subquery))</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>,</span></span>
<span><span> "drilling_pad"</span><span>.</span><span>"name"</span></span>
<span><span>FROM</span><span> "drilling_pad"</span></span>
<span><span> INNER JOIN</span><span> "drilling_hole"</span><span> ON</span><span> (</span><span>"drilling_pad"</span><span>.</span><span>"id"</span><span> =</span><span> "drilling_hole"</span><span>.</span><span>"pad_id"</span><span>)</span></span>
<span><span>WHERE</span><span> "drilling_hole"</span><span>.</span><span>"id"</span><span> IN</span><span> (</span></span>
<span><span>  SELECT</span><span> U0.</span><span>"id"</span></span>
<span><span>  FROM</span><span> "drilling_hole"</span><span> U0</span></span>
<span><span>  WHERE</span><span> U0.</span><span>"project_id"</span><span> =</span><span> 1</span></span>
<span><span> )</span></span>
<span></span></code></pre>
<hr>

<p>Correlated subqueries are where the inner query depends on outer query</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span># include the hole id of any hole that has a foreign key to the pad</span></span>
<span><span>hole_subquery </span><span>=</span><span> Hole.objects.filter(</span><span>pad_id</span><span>=</span><span>OuterRef(</span><span>"pk"</span><span>)).values(</span><span>"pk"</span><span>)</span></span>
<span><span>pad_qs </span><span>=</span><span> Pad.objects.annotate(</span><span>hole_id</span><span>=</span><span>Subquery(hole_subquery))</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>,</span></span>
<span><span> "drilling_pad"</span><span>.</span><span>"name"</span><span>,</span></span>
<span><span> (</span></span>
<span><span>  SELECT</span><span> U0.</span><span>"id"</span></span>
<span><span>  FROM</span><span> "drilling_hole"</span><span> U0</span></span>
<span><span>  WHERE</span><span> U0.</span><span>"pad_id"</span><span> =</span><span> (</span><span>"drilling_pad"</span><span>.</span><span>"id"</span><span>)</span></span>
<span><span> ) </span><span>AS</span><span> "hole_id"</span></span>
<span><span>FROM</span><span> "drilling_pad"</span></span>
<span></span></code></pre>
<hr>
<h2 id="performance-improvements">Performance improvements</h2>
<ul>
<li>Reduce N+1
<ul>
<li>You typically want to reduce N+1 queries because they have communication
overhead</li>
<li><code>select_related</code></li>
<li><code>prefetch_related</code></li>
<li>You also might choose to use <code>annotate()</code> instead of <code>select_related</code>
because select related pulls all the data for the associated table when you
might only need one column. That associated might have a jsonb column which
contains a lot of unnecessary data that you don’t need.</li>
</ul>
</li>
</ul>
<hr>

<pre tabindex="0" data-language="python"><code><span><span>holes </span><span>=</span><span> Hole.objects.all()</span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes:</span></span>
<span><span>  print</span><span>(hole.pad.name) </span><span># N+1 queries</span></span>
<span></span>
<span><span>holes </span><span>=</span><span> Hole.objects.select_related(</span><span>"pad"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes:</span></span>
<span><span>  print</span><span>(hole.pad.name) </span><span># no extra query</span></span>
<span></span>
<span></span></code></pre>
<hr>

<p>You would use prefetch related when you are not pulling a direct foreign key
such a many-to-many relationship like below.</p>
<p><img src="https://www.davidhang.com/_astro/2.Cd5VA_n2_Z22TJnn.svg" alt="width:400px" width="340" height="465" loading="lazy" decoding="async"></p>
<pre tabindex="0" data-language="python"><code><span></span>
<span><span>class</span><span> Faculty</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Course</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  faculty </span><span>=</span><span> models.ForeignKey(Faculty, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Student</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  courses </span><span>=</span><span> models.ManyToManyField(Course, </span><span>through</span><span>=</span><span>"Enrolment"</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Enrolment</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  course </span><span>=</span><span> models.ForeignKey(Course, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  student </span><span>=</span><span> models.ForeignKey(Student, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  grade </span><span>=</span><span> models.FloatField()</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span><span>"courses"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.courses.all():</span></span>
<span><span>    print</span><span>(course.name) </span><span># no extra query</span></span>
<span><span>    print</span><span>(course.faculty.name) </span><span># extra query</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span></span>
<span><span>  Prefetch(</span></span>
<span><span>    "courses"</span><span>, </span></span>
<span><span>    queryset</span><span>=</span><span>Course.objects.select_related(</span><span>"faculty"</span><span>)</span></span>
<span><span>  )</span></span>
<span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.courses.all():</span></span>
<span><span>    print</span><span>(course.name) </span><span># no extra query</span></span>
<span><span>    print</span><span>(course.faculty.name) </span><span># no extra query</span></span>
<span></span></code></pre>
<hr>
<h2 id="to_attr">to_attr</h2>
<p><code>to_attr</code> can be used to make “filtered” relationships available on the instance.</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Enrolment</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  course </span><span>=</span><span> models.ForeignKey(Course, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  student </span><span>=</span><span> models.ForeignKey(Student, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  grade </span><span>=</span><span> models.FloatField()</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span></span>
<span><span>  Prefetch(</span></span>
<span><span>    "course"</span><span>, </span></span>
<span><span>    queryset</span><span>=</span><span>Course.objects.filter(</span><span>grade__gt</span><span>=</span><span>80.0</span><span>).select_related(</span><span>"faculty"</span><span>), </span><span>to_attr</span><span>=</span><span>"hd_courses"</span></span>
<span><span>  )</span></span>
<span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.hd_courses.all():</span></span>
<span><span>    ...</span></span>
<span></span></code></pre>
<hr>
<h2 id="multiple-instances-when-filtering-across-many-to-many">Multiple instances when filtering across many-to-many</h2>
<p>One gotcha is selecting across a many-to-many relationship can return multiple of the same instances.</p>
<p><img src="https://www.davidhang.com/_astro/3.DMAdguVG_TLkyj.webp" alt="data model showing many to many relationship" width="530" height="810" loading="lazy" decoding="async"></p>
<pre tabindex="0" data-language="python"><code><span><span>Student.objects.filter(</span><span>courses__faculty__name</span><span>=</span><span>"Science"</span><span>) </span><span># inner join returns duplicated rows</span></span>
<span><span>&lt;</span><span>QuerySet [</span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>, </span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>]</span><span>&gt;</span></span>
<span></span>
<span><span>Student.objects.filter(</span><span>courses__faculty__name</span><span>=</span><span>"Science"</span><span>).distinct()</span></span>
<span><span>&lt;</span><span>QuerySet [</span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>]</span><span>&gt;</span></span>
<span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span></span>
<span><span>  "testing_student"</span><span>.</span><span>"id"</span><span>, </span></span>
<span><span>  "testing_student"</span><span>.</span><span>"name"</span><span> </span></span>
<span><span>FROM</span><span> </span></span>
<span><span>  "testing_student"</span><span> </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_enrolment"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_student"</span><span>.</span><span>"id"</span><span> =</span><span> "testing_enrolment"</span><span>.</span><span>"student_id"</span><span>) </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_course"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_enrolment"</span><span>.</span><span>"course_id"</span><span> =</span><span> "testing_course"</span><span>.</span><span>"id"</span><span>) </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_faculty"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_course"</span><span>.</span><span>"faculty_id"</span><span> =</span><span> "testing_faculty"</span><span>.</span><span>"id"</span><span>)</span></span>
<span><span>WHERE</span><span> </span></span>
<span><span>  "testing_faculty"</span><span>.</span><span>"name"</span><span> =</span><span> 'Science'</span></span>
<span></span></code></pre>
<hr>
<h2 id="gotchas-and-other-funky-stuff">Gotchas and other Funky stuff</h2>
<ul>
<li>Model instances when retrieved will try to populate all columns, if column
removed in migration, and the worker still up exception occurs
<ul>
<li><code>get()</code> or <code>first()</code></li>
<li><code>for hole in Hole.objects.all()</code></li>
</ul>
</li>
<li>This can make migrations hard, as older workers will be requesting columns that might have been removed or renamed which will cause errors</li>
<li>There are ways to do down-timeless migrations but are bit <a href="https://hackernoon.com/deleting-a-column-from-a-django-model-on-production">funky and multi
step</a></li>
<li>Recommendation is to avoid deleting or renaming columns</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.annotate(</span><span>this_thang</span><span>=</span><span>F(</span><span>"pad__name"</span><span>)).get()</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  drilling_hole</span><span>.</span><span>name</span><span>, </span><span>-- pulls all columns </span></span>
<span><span>  drilling_hole</span><span>.</span><span>pad_id</span><span>,</span></span>
<span><span>  drilling_pad</span><span>.</span><span>name</span><span> AS</span><span> this_thang</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>WHERE</span><span> drilling_pad</span><span>.</span><span>name</span><span> =</span><span> 'cheese board'</span><span>;</span></span>
<span><span>LIMIT</span><span> 1</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="values">Values</h2>
<ul>
<li>So how do you to only retrieve certain columns?</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.values(</span><span>"name"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes_qs:</span></span>
<span><span>  print</span><span>(</span><span>type</span><span>(hole)) </span><span># dict</span></span>
<span><span>  # not `Hole` object, hence no class functions, no lazy loading e.g. can't access `hole.pad.name`</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  drilling_hole</span><span>.</span><span>name</span><span>, </span><span>-- only pulls name and maps it to a python dictionary object</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span></span></code></pre>
<ul>
<li>Less data sent down the wire, but no lazy loading and no class functions as
the data is a python dictionary</li>
</ul>
<hr>
<h2 id="other-options">Other options</h2>
<ul>
<li><code>only()</code> and <code>defer()</code></li>
<li>Will retrieve model instances, but won’t retrieve all fields</li>
<li>Values not declared when accessed on the model are lazy loaded</li>
<li>Would not recommend to be used regularly, very high chance of N+1</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.only(</span><span>"pad_id"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes_qs:</span></span>
<span><span>  print</span><span>(hole.pad_id) </span><span># no extra query</span></span>
<span><span>  print</span><span>(hole.name) </span><span># name will be lazy loaded, N+1 queries</span></span>
<span></span></code></pre>
<hr>
<h3 id="how-do-you-know-what-sql-is-being-generated">How do you know what SQL is being generated?</h3>
<ul>
<li><code>print(queryset.query)</code></li>
<li><a href="https://github.com/jazzband/django-debug-toolbar">Django Debug Toolbar</a></li>
<li><a href="https://kolo.app/">Kolo</a></li>
</ul>
<hr>
<h2 id="updating-rows">Updating rows</h2>
<p>There are three typical ways to update a row in the database.</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>instance </span><span>=</span><span> Hole.objects.create(</span><span>name</span><span>=</span><span>"cheese"</span><span>)</span></span>
<span></span>
<span><span># save()</span></span>
<span><span>instance.name </span><span>=</span><span> "board"</span></span>
<span><span>instance.save()</span></span>
<span></span>
<span><span># update()</span></span>
<span><span>Model.objects.filter(</span><span>name</span><span>=</span><span>"board"</span><span>).update(</span><span>name</span><span>=</span><span>"board2"</span><span>)</span></span>
<span></span>
<span><span># bulk_update()</span></span>
<span><span>instance.name </span><span>=</span><span> "board3"</span></span>
<span><span>instances_to_update </span><span>=</span><span> [instance]</span></span>
<span><span>Model.objects.bulk_update(instances_to_update, [</span><span>"name"</span><span>])</span></span>
<span></span></code></pre>
<hr>
<h2 id="problems-with-updates">Problems with updates</h2>
<ul>
<li><code>update()</code> and <code>bulk_update()</code> do not trigger <code>save()</code> method on the model</li>
<li>built in django signals (publish/subscribe pattern), there are post_save and pre_save signals which can be triggered when calling <code>save()</code>
<ul>
<li><code>update()</code> and <code>bulk_update()</code> do not trigger those signals…</li>
</ul>
</li>
<li><code>updated_at</code> column would not normally be updated when calling <code>update()</code> or
<code>bulk_update()</code> but if queryset is a descendant of <code>CoreplanQuerySet</code> then it will.</li>
</ul>
<hr>

<ul>
<li>Pagination / order_by
<ul>
<li>Not a Django ORM thing, but a Django ORM hides the implementation detail,
which may lead to unexpected result</li>
<li>Page pagination is default in DRF list views and implemented with <code>LIMIT</code> and <code>OFFSET</code> in SQL</li>
</ul>
</li>
</ul>
<p><code>?page_size=10&amp;page=3</code></p>
<pre tabindex="0" data-language="plaintext"><code><span><span>SELECT * </span></span>
<span><span>FROM drilling_hole </span></span>
<span><span>LIMIT 10 </span></span>
<span><span>OFFSET 20;</span></span>
<span><span></span></span></code></pre>
<p>Anything wrong with this query?</p>
<ul>
<li>There is no deterministic guarantee that the same 10 rows will be returned each time.</li>
<li>A plain <code>SELECT</code> in postgres (may be different in different dbs) provides no
guarantee of order, unless <code>ORDER BY</code> is specified</li>
<li>It often appears to return in insertion/<code>id</code> order, but that is not guaranteed
in postgres</li>
<li>Model Meta <code>ordering</code> may set a default order, but sometimes tht is <a href="https://docs.djangoproject.com/en/dev/releases/2.2/#features-deprecated-in-2-2">ignored</a></li>
<li>For list views you should to provide a deterministic order_by</li>
<li><code>order_by(name)</code> is not enough if name is not unique
<ul>
<li><code>order_by(name, id)</code> is required, because id is unique</li>
</ul>
</li>
<li>This can been the the cause of some flaky tests issues where lists are
returned seemingly in insertion order and asserted to return in id order</li>
</ul>
<hr>
<p>Thanks for reading! I hope this has been useful to you. There are definitely
more particularities and gotchas to be aware of when using the Django ORM and
Django in general but I think these are the most common ones.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AirTags key to discovery of Houston's plastic recycling deception (145 pts)]]></title>
            <link>https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception</link>
            <guid>41413174</guid>
            <pubDate>Sun, 01 Sep 2024 00:38:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception">https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception</a>, See on <a href="https://news.ycombinator.com/item?id=41413174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-hero" aria-labelledby="hero-cap" role="figure">
                          <p id="hero-cap" title="Apple employs an advanced robot named Daisy to disassemble old iPhones.">Apple employs an advanced robot named Daisy to disassemble old iPhones.</p>
                                    <p><a href="https://photos5.appleinsider.com/gallery/60877-125351-Unknown-xl.jpg">
              <img fetchpriority="high" src="https://photos5.appleinsider.com/gallery/60877-125351-Unknown-xl.jpg" alt="">
            </a>
                      </p></div><div>
          <p>One Houston resident was suspicious of the city's "all plastic accepted" recycling program, and used <a href="https://appleinsider.com/inside/airtags" title="AirTag" data-kpt="1">AirTags</a> to discover where the plastic waste actually ended up.
</p><p>Deason, who regularly recycles her packaging and other waste, began to have doubts about the city's plastic recycling program. Houston's program boasted of being able to accept even types of plastic that aren't normally considered recyclable.
</p><p>Curious as to where the plastic was going, she bought a set of AirTags, and included them in various bags of her plastic recycling. Of the bags she tracked, nearly all of them went to a company called Wright Waste Management, located in nearby Harris County.
</p><p>The company is not approved to store plastic waste, and has failed three fire inspections.
</p><p>CBS News correspondent Ben Tracy <a href="https://www.khou.com/article/news/local/houston-recycling-tracking-device-plastic/">referred</a> to Deason as "the James Bond of plastic recycling" for her initiative. Aerial footage showed that the facility had large piles of plastic waste as tall as 10 feet high.
</p><p>Deason said she thought that the company simply storing the unrecyclable plastic waste was "kind of strange." She later contacted Houston's Director of Solid Waste Management Mark Wilfalk, to ask about the discrepancy.
</p><p>When shown the drone footage, Wilfalk admitted "it's not the most desirable-looking site." He promised Deason he'd investigate the problems that caused Wright Waste Management to fail the fire inspections.
</p><p>Wilfalk later acknowledged that the city had collected some 250 tons of plastic since the end of 2022. He revealed that none of it had been recycled as of yet.
</p><p>"We're gonna stockpile it for now," he admitted. "We're gonna see what happens."
</p><p>By contrast, Apple has been an <a href="https://appleinsider.com/articles/24/04/16/apple-highlights-device-recycling-iphone-trade-in-and-the-removal-of-leather-for-earth-day" title="Apple's environmental efforts">industry leader</a> in reducing its use of plastic. It uses paper for packaging, and metal rather than plastic for its computer line.
</p><p>It does use some plastic for products such as its <a href="https://appleinsider.com/inside/airpods" title="AirPods" data-kpt="1">AirPods</a> earbuds. It has invested in robotics to help recycle old Apple products.
</p><p>Houston, as it turns out, is waiting on a promised sorting facility to open, where the stored recycling will be sorted and treated. The company behind the sorting facility, Cyclix, says it has developed a method to create recyclable pellets out of the plastic waste.
</p><p>However, only a fraction of these pellets can be made into new plastic. Most will be melted and turned into fuel that is burned, adding to carbon emissions.
</p><p>California Attorney General Rob Bonta has been investigating Cyclix owner and plastic manufacturer ExxonMobil's claims regarding plastic recycling in that state. He has characterized Cyclix's claims of plastic recycling are largely fictional.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building LLMs from the Ground Up: A 3-Hour Coding Workshop (819 pts)]]></title>
            <link>https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up</link>
            <guid>41412256</guid>
            <pubDate>Sat, 31 Aug 2024 21:45:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up">https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up</a>, See on <a href="https://news.ycombinator.com/item?id=41412256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>If you’d like to spend a few hours this weekend to dive into Large Language Models (LLMs) and understand how they work, I've prepared a 3-hour coding workshop presentation on implementing, training, and using LLMs.</p><div id="youtube2-quh7z1q7-uc" data-attrs="{&quot;videoId&quot;:&quot;quh7z1q7-uc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/quh7z1q7-uc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>Below, you'll find a table of contents to get an idea of what this video covers (the video itself has clickable chapter marks, allowing you to jump directly to topics of interest):</p><p>0:00 – Workshop overview</p><p>2:17 – Part 1: Intro to LLMs</p><p>9:14 – Workshop materials</p><p>10:48 – Part 2: Understanding LLM input data</p><p>23:25 – A simple tokenizer class</p><p>41:03 – Part 3: Coding an LLM architecture</p><p>45:01 – GPT-2 and Llama 2</p><p>1:07:11 – Part 4: Pretraining</p><p>1:29:37 – Part 5.1: Loading pretrained weights</p><p>1:45:12 – Part 5.2: Pretrained weights via LitGPT</p><p>1:53:09 – Part 6.1: Instruction finetuning</p><p>2:08:21 – Part 6.2: Instruction finetuning via LitGPT</p><p>02:26:45 – Part 6.3: Benchmark evaluation</p><p>02:36:55 – Part 6.4: Evaluating conversational performance</p><p>02:42:40 – Conclusion</p><p>It's a slight departure from my usual text-based content, but the last time I did this a few months ago, it was so well-received that I thought it might be nice to do another one!</p><p><strong>Happy viewing!</strong></p><ol><li><p><a href="https://mng.bz/M96o" rel="">Build an LLM from Scratch book</a></p></li><li><p><a href="https://github.com/rasbt/LLMs-from-scratch" rel="">Build an LLM from Scratch GitHub repository</a></p></li><li><p><a href="https://github.com/rasbt/LLM-workshop-2024" rel="">GitHub repository with workshop code</a></p></li><li><p><a href="https://lightning.ai/lightning-ai/studios/llms-from-the-ground-up-workshop" rel="">Lightning Studio for this workshop</a></p></li><li><p><a href="https://github.com/Lightning-AI/litgpt" rel="">LitGPT GitHub repository</a></p></li></ol></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A brief history of barbed wire fence telephone networks (109 pts)]]></title>
            <link>https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/</link>
            <guid>41412221</guid>
            <pubDate>Sat, 31 Aug 2024 21:41:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/">https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/</a>, See on <a href="https://news.ycombinator.com/item?id=41412221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
							<main id="main" role="main">

					
						
<article id="post-4658">
	<!-- .entry-header -->

	<div>
		
<p>If you look at <a href="https://loriemerson.net/2024/03/14/table-of-contents-for-other-networks-a-radical-technology-sourcebook/">the table of contents</a> for my book, <em>Other Networks: A Radical Technology Sourcebook</em>, you’ll see that entries on networks before/outside the internet are arranged first by underlying infrastructure and then chronologically. You’ll also notice that within the section on wired networks, there are two sub-sections: one for electrical wire and another for barbed wire. Even though the barbed wire section is quite short, it was one of the most fascinating to research and write about – mostly because the history of using barbed wire to communicate is surprisingly long and almost entirely undocumented, even though barbed wire fence phones in particular were an essential part of early- to mid-twentieth century rural life in many parts of the U.S. and Canada! </p>



<p>While I was researching barbed wire fence phones and wondering whether any artists had been intrepid enough to experiment with this other network, I came across <a href="https://philipbpeters.com/">Phil Peters</a> and <a href="https://davidrueter.com/">David Rueter</a>‘s work “Barbed Wire Fence Telephone” which they installed in a Chicago gallery in 2015. libi striegl (Managing Director of the <a href="http://mediaarchaeologylab.com/">Media Archaeology Lab</a> through which we run many of our <a href="http://othernetworks.net/">Other Networks</a> projects) and I decided we should see if we can get Peters and Rueter to re-install their barbed wire fence telephone on the CU Boulder campus…to our delight and surprise, they said yes. But even more delightful and surprising was the fact that the college I’m now based in, the College of Media, Communication, and Information (CMCI), was enthusiastically supportive of our ask to install this fence phone network in a university classroom! In fact, not only was CMCI supportive in principle, they helped fund the project and staff members even helped us drill holes, put up fence posts, and string barbed wire. Phil and libi (with modest assistance from me) wrapped up the installation of “<a href="https://othernetworks.net/2024/08/02/barbed-wire-fence-telephone-ii/">Barbed Wire Fence Telephone II</a>” on Thursday August 29th and on Friday August 30th Phil gave a group of about 20 people a hands-on demo of this ad hoc network.</p>



<p>Since so little documentation exists online about the history of this important communication network, below I include the introduction I wrote for the section on barbed wire along with the entry on barbed wire fence phones. I admit I hope someone adds this information to Wikipedia and cites either this post or <em>Other Networks: A Radical Technology Sourcebook</em> (forthcoming in 2025 by Anthology Editions). </p>



<p>***</p>



<p><strong>Barbed Wire Networks</strong></p>



<p>Barbed wire was originally proposed as an inexpensive and potentially painful material that could be used to create a fence and thus act as a deterrent to keep livestock within a confined area and/or to keep out intruders. Alan Krell documents numerous designs for wire that featured barbs throughout the 19th century, including one proposed by French inventor Léonce Eugène Grassin-Baledans in 1860 for a “Grating of wire-work for fences and other purposes.” The first patent in the U.S. for a wire fence featuring barbs was given to Lucien B. Smith from Kent, Ohio (U.S.) in 1867. Illinois farmer Joseph Glidden submitted a patent for an improved version of barbed wire in 1874 which has since become the dominant design. As Reviel Netz puts it, after this point the physical control of wide open spaces was largely complete. Many farmers objected to the cruelty built into barbed wire, the way in which the fencing meant cattle drives were no longer possible, and the way it marked the end of seemingly free and open public land; notably they formed anti-barbed-wire associations and pleaded with legislators and government officials to enact laws limiting or regulating the use of the wire. Nonetheless, as the price of wire fell from twenty cents per pound in 1874 to two cents a pound by 1893, few ranchers could afford any other type of fencing material. By the 1890s, the barbed wire industry had become wealthy enough and powerful enough that they effectively quelled all opposition to the wire. The availability of inexpensive barbed wire, especially across the western U.S. in the late 19th century, largely made it possible to keep larger herds of livestock than had been possible up to that point. It also played a significant role in “settling” the American west by violently asserting individual ownership over land that was already occupied by Native Americans.</p>



<p>Appropriately nicknamed ‘the devil’s rope,’ barbed wire is made from steel (later coated in zinc, a zinc-aluminum alloy, or a kind of polymer coating such as polyvinyl chloride) and single or double barbs placed roughly four to six inches apart. To erect a fence, one only needs barbed wire, posts, and materials to afix the wire to the posts. Finally, although this section focuses on its use as a cooperative, non-commercial form of telecommunications network, it is also worth noting the frequent use barbed wire for trench warfare or as a security measure atop walls or buildings.</p>



<p>Sources: Alan Krell, <em>The Devil’s Rope: A Cultural History of Barbed Wire</em> (Reaktion Books, 2002); Léonce Eugène Grassin-Baledans, “Grating of wire-work for fences and other purposes,” France Patent 45827; Lucien B. Smith, “Wire Fence,” US Patent 66182A (25 June 1867); Joseph Glidden, “Improvement in Wire Fences,” US Patent 157124A (27 OCtober 1873); Reviel Netz, <em>Barbed Wire: An Ecology of Modernity</em> (Wesleyan University Press, 2009)</p>



<p><strong>53. Fence Phones</strong></p>



<p>Country of Origin: U.S.A.</p>



<p>Creator(s): unknown</p>



<p>Earliest Known Use: roughly 1893</p>



<p>Basic Materials: copper wire, barbed wire, posts, fasteners (such as nails or staples), insulators (such as porcelain knobs, glass bottles, leather, corn cobs, cow horns), battery-powered telephone handsets</p>



<p>Description: A fence phone, also referred to as a barbed wire fence phone or squirrel lines, is the use of “smooth” (presumably copper) wire running from a house to nearby barbed wire fencing to create an informal, ad hoc, cooperative, non-commercial, local telephone network. Two key developments in the 1890s led to its adoption primarily by farmers, ranchers, and those living in rural or isolated areas especially in the U.S. and Canada: the widespread availability and inexpensiveness of barbed wire in the 1890s; and the erosion of Alexander Graham Bell’s patent monopoly in 1893 and 1894 which, according to Robert MacDougall, led to the sudden explosion of 80 to 90 independent telephone companies manufacturing telephone sets that could be used outside of the burgeoning Bell telephone system. According to Ronald Kline, the sudden explosion of independent telphone companies in turn set into motion the independent telephone movement. Not only had Bell largely neglected to provide those in rural areas with telephone service in favor of focusing on those in urban areas, but early Bell telephone owners were also intent on controlling telephone usage. Writes MacDougall, “Bell’s early managers sought to limit frivolous telephoning, especially undignified activities like courting or gossiping over the telephone, and to control certain groups of users, like women, children, and servants, who were thought to be particular offenders.” By contrast, according to Kline, the independent telephone companies recognized it would be too expensive to build lines in rural areas and they instead openly “advised farm people to buy their own telephone equipment, build their own lines, and create cooperatives to bring phones to the countryside.”</p>



<p>In need of a practical way to overcome social isolation; communicate emergencies, weather, and crop prices; and chafing under attempts to curtail free speech, ranchers and farmers began to take advantage of the growing ubiquity of both telephone sets and barbed wire fencing. They would hook up telephones to wire strung from their homes to a nearby fence; at the time, telephones had their own battery which produced a DC current that could carry a voice signal; turning a crank on the phone would generate an AC current to produce a ring at the end of the line. Bob Holmes elaborates on the process: “the barbed wire networks had no central exchange, no operators–and no monthly bill. Instead of ringing through the exchange to a single address, every call made every phone on the system ring. Soon each household had its own personal ringtone…but anyone could pick up…Talk was free, and so people soon began to ‘hang out’ on the phone.” The fence phone lines could also be used to broadcast urgent information to everyone on the line. Reportedly, the quality of the signal traveling over the heavy wire was excellent, but weather would frequently cause short circuits which locals attempted to fix with anything that could serve as an insulator (such as leather straps, corn cobs, cow horns, or glass bottles).</p>


<div>
<figure><img data-attachment-id="4669" data-permalink="https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/fencephones3/" data-orig-file="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png" data-orig-size="1124,1487" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fencePhones3" data-image-description="" data-image-caption="" data-medium-file="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png?w=227" data-large-file="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png?w=750" tabindex="0" role="button" width="774" height="1023" src="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png?w=774" alt="black and white photograph of a pan in a suit and bowler hat standing in front of a barbed wire fence talking on the phone"><figcaption>from “A CHEAP TELEPHONE SYSTEM FOR FARMERS”, <em>Scientific American</em> 82:13 (MARCH 31, 1900), p. 196</figcaption></figure></div>


<p>There are newspaper reports of ranchers and farmers using fence phones in U.S. states such as California, Texas, New Mexico, Colorado, Kansas, Iowa, Nebraska, Indiana, Minnesota, Ohio, Pennsylvania, New York, Montana, South Dakota and also parts of Canada. For example, a 1902 issue of the Chicago-based magazine Telephony reported on a barbed wire fence telephone network that operated between Broomfield and Golden, Colorado (U.S.A.) over a distance of 25 miles and which cost roughly $10 to build. The line was used for a “woman operator” to notify a worker at the end of the line “when to send down a head of water and how much.” The author notes one “peculiar feature of this system is that only the operator can begin the talk. When it is decided to send down water the operator calls up the man at the headgate and gives him specific instructions, which he must follow. If he has anything to say he must say it then or hold his peace till he is called up again, for it is not a circuit system and only the Broomfield office can call up. This gives the lady the advantage of being able to shut off the other fellow at will and of getting in the last word.” The fence phone systems also seemed to thrive in areas known for having cooperatives, especially related to farming. The model of a cooperative network particularly thrived throughout the 1920s as farmers experienced economic depression some years before the Great Depression. For example, according to David Sicilia, farmers in Montana created the Montana East Line Telephone Association to which they each contributed $25 plus several dollars a year for maintenance along with telephone sets, batteries, wire, and insulators.</p>



<p>Anecdotally, fence phones were still being used throughout the 1970s and perhaps even later. C.F. Eckhardt describes calling his parents who lived in rural Texas and still used a fence phone; their number was simply 37, designated on the small local network by three long rings and one short ring.</p>



<p>Sources: Alan Krell, <em>The Devil’s Rope: A Cultural History of Barbed Wire</em> (Reaktion Books, 2002); David B. Sicilia, “How the West Was Wired,” Inc.com (15 June 1997); Early W. Hayter, <em>Free Range and Fencing</em>, Vol. 3 (Kansas State Teachers College of Emporia Department of English, 1960); Robert MacDougall, <em>The People’s Network: The Political Economy of the Telephone in the Gilded Age</em> (University of Pennsylvania Press, 2014); Ronald Kline, <em>Consumers in the Country: Technology and Social Change in Rural America</em> (Johns Hopkins University Press, 2002); “A CHEAP TELEPHONE SYSTEM FOR FARMERS,” <em>Scientific American</em>, 82:13 (31 March 1900); “Bloomfield’s Barbed Wire System,” <em>Telephony: An Illustrated Monthly Telephone Journal</em> 4:6 (December 1902); Bob Holmes, “Wired Wild West: Cowpokes chatted on fence-wire phones,” <em>New Scientist</em> (17 December 2013); C. F. Eckhardt, “Before Maw Bell: Rural Telephone Systems in the West,” Texasescapes.com (2008); Phil Peters, “Barbed Wire Fence Telephone,” <a href="https://philipbpeters.com/" rel="nofollow">https://philipbpeters.com/</a> (2014)</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
							<!-- .navigation -->
	
						
					
				</main><!-- #main -->
			</div></div>]]></description>
        </item>
    </channel>
</rss>