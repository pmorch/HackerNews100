<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 29 Sep 2024 14:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Building a robust frontend using progressive enhancement (183 pts)]]></title>
            <link>https://www.gov.uk/service-manual/technology/using-progressive-enhancement</link>
            <guid>41686715</guid>
            <pubDate>Sun, 29 Sep 2024 11:54:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">https://www.gov.uk/service-manual/technology/using-progressive-enhancement</a>, See on <a href="https://news.ycombinator.com/item?id=41686715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-module="govspeak">
      <p>For users to experience a quality service it must be built in a robust way.</p>

<p>Progressive enhancement is a way of building websites and applications based on the idea that you should make your page work with HTML first.</p>

<p>Only after this can you add anything else like Cascading Style Sheets (CSS) and JavaScript.</p>

<p>All government services must follow progressive enhancement, even if part of the service or a parent service needs JavaScript</p>

<p>Building your service using progressive enhancement will:</p>

<ul>
  <li>
    <p>ensure your service is robust and of a high quality</p>
  </li>
  <li>
    <p>make it more likely your service will work <a href="https://www.gov.uk/service-manual/technology/designing-for-different-browsers-and-devices">regardless of which browser or device is being used</a></p>
  </li>
  <li>
    <p>mean your service’s most basic functionality will work and meet the core needs of the user</p>
  </li>
  <li>
    <p>improve accessibility by encouraging best practices like <a rel="external" href="https://html.com/semantic-markup/">writing semantic markup</a>
help users with device or connectivity limitations to use your service</p>
  </li>
</ul>

<p>If you are using a ‘commercial off the shelf’ (COTS) solution or asking an external supplier to build the service, you should consider including this in your requirements as part of your <a href="https://www.gov.uk/guidance/define-your-purchasing-strategy">purchasing strategy</a>.</p>

<h2 id="start-with-html">Start with HTML</h2>

<p>Government services should be functional using only HTML. This includes services such as:</p>

<ul>
  <li>
    <p>transactional services, for example forms that let the user provide information to government</p>
  </li>
  <li>
    <p><a rel="external" href="https://insidegovuk.blog.gov.uk/2016/10/27/making-it-easier-to-understand-smart-answer-logic/">smart answers</a>, for example the <a href="https://www.gov.uk/register-a-birth">Registering a birth abroad</a> service</p>
  </li>
  <li>
    <p>content-based websites, for example GOV.UK’s <a href="https://www.gov.uk/foreign-travel-advice">foreign travel advice</a> page</p>
  </li>
</ul>

<p>The HTML layer is fault-tolerant by design. The browser ignores markup that it does not understand and continues to parse it as best as it can.</p>

<p>This means that older browsers will be very likely to be able to load the HTML for your service, even if there are bugs in the HTML or you use features that only exist in more modern browsers.</p>



<h2 id="using-css">Using CSS</h2>

<p>You can style your service using CSS to make it look like GOV.UK.</p>

<p>The CSS layer is reasonably fault-tolerant. This means the browser will ignore individual declarations that it does not understand, for example if you use a property that only exists in newer browsers.</p>

<p>Be aware that the browser will ignore the entire ruleset if it encounters a selector that it does not understand.</p>

<p>There are also <a href="#css-fail">other reasons why the CSS may fail to load</a>.</p>

<p>Avoid techniques such as ‘CSS-in-JS’ to ensure that your site still looks correct even if the JavaScript fails to load.</p>

<h2 id="using-javascript">Using JavaScript</h2>

<p>JavaScript can be used to add interactive elements to your service.</p>

<p>The JavaScript layer is not fault-tolerant. If your JavaScript uses a syntax or calls an API that is not supported in the user’s browser, it will error and the rest of the JavaScript will not run.</p>

<p>There are <a href="#css-fail">other reasons why the JavaScript may fail to load or run</a>.</p>

<p>If your service is not designed with this in mind, users may be unable to use it.</p>

<p>You can increase the chances that your JavaScript will work correctly in all browsers by:</p>

<ul>
  <li>
    <p>using <a rel="external" href="https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing/Cross_browser_testing/Feature_detection">feature detection</a> for browser APIs</p>
  </li>
  <li>
    <p>including <a rel="external" href="https://developer.mozilla.org/en-US/docs/Glossary/Polyfill">polyfills</a> for newer browser features</p>
  </li>
  <li>
    <p>transpiling your JavaScript to a common syntax that your target browsers can understand</p>
  </li>
  <li>
    <p>using automated tests or linters</p>
  </li>
  <li>
    <p>doing regular manual testing, including testing with older or lower-powered devices</p>
  </li>
</ul>

<p>Transpilation and polyfills can significantly increase the size of your JavaScript. You should consider the trade offs involved and revisit these decisions regularly as browser usage changes.</p>

<p>Where possible the JavaScript should enhance HTML and CSS that provides the same core functionality. For example, an autocomplete could enhance a  element, or something similar. This still lets the user do what they need to do, even if the JavaScript fails.</p>

<h3 id="alternatives-to-javascript">Alternatives to JavaScript</h3>

<p>If you believe your service can only be built using JavaScript, you should think about using simpler solutions that are built using HTML and CSS and will meet user needs.</p>

<p>For example, if you want to use use JavaScript to provide interactive graphs, other options are to:</p>

<ul>
  <li>
    <p>display the data in a table</p>
  </li>
  <li>
    <p>allow the data to be exported so that it can analysed in another application</p>
  </li>
  <li>
    <p>pre-render the graphs as images</p>
  </li>
</ul>

<p>If the core functionality of your service cannot be provided without JavaScript, you’ll need to consider how users can access your service through other channels. This might be telephone calls or in-person visits to offices.</p>

<h3 id="using-client-side-javascript-frameworks">Using client-side JavaScript frameworks</h3>

<p>If your service is mostly built using components from the <a rel="external" href="https://design-system.service.gov.uk/">GOV.UK Design System</a> and doesn’t have a complex user interface, you do not need to use a client-side JavaScript framework.</p>

<p>The components in the <a rel="external" href="https://design-system.service.gov.uk/">GOV.UK Design System</a> include <a rel="external" href="https://frontend.design-system.service.gov.uk/import-javascript">how to import JavaScript</a> to your service without the need for a framework.</p>

<p>If you do choose to use client-side <a rel="external" href="https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing/Client-side_JavaScript_frameworks">JavaScript frameworks</a>, be aware that although they can be helpful when building a service with a complex user interface, they can introduce problems.</p>

<p>Using a client-side JavaScript framework can:</p>

<ul>
  <li>
    <p>increase the overall size of your code base and push processing to the client-side, causing performance issues for users with a slower network connection or lower powered device</p>
  </li>
  <li>
    <p>create a reliance on third-party code that your developers do not have control over, requiring you to make major changes to your service in order to stay up to date with changes in the framework</p>
  </li>
  <li>
    <p>make it difficult to find people with the skills required to maintain the code, if the framework’s loses popularity over time</p>
  </li>
</ul>

<p>If you use a JavaScript framework you should:</p>

<ul>
  <li>
    <p>be able to justify with evidence, how using JavaScript would benefit users</p>
  </li>
  <li>
    <p>be aware of any negative impacts and be able to mitigate them</p>
  </li>
  <li>
    <p>consider whether the benefits of using it outweigh the potential problems</p>
  </li>
  <li>
    <p>only use the framework for parts of the user interface that cannot be built using HTML and CSS alone</p>
  </li>
  <li>
    <p>design each part of the user interface as a separate component</p>
  </li>
</ul>

<p>Having separate components means that if the JavaScript fails to load, it will only be that single component that fails. The rest of the page will load as normal.</p>

<p>If you use JavaScript, it should only be used to enhance the HTML and CSS so users can still use the service if the JavaScript fails.</p>

<h3 id="css-fail">Reasons why CSS or JavaScript may fail to load or run</h3>

<p>CSS and JavaScript can fail to load or run because of, for example:</p>

<ul>
  <li>
    <p>temporary network errors</p>
  </li>
  <li>
    <p>third-party browser extensions like ad blockers</p>
  </li>
  <li>
    <p>third-party supplier downtime, such as when using a content delivery network
DNS lookup failures</p>
  </li>
  <li>
    <p>bugs introduced by browser updates</p>
  </li>
  <li>
    <p>bugs introduced in third party JavaScript intentionally running on the same page
corporate firewalls blocking, removing or changing content (large institutions like banks or government departments may use these)</p>
  </li>
  <li>
    <p>mobile network providers changing content to speed up load times and reduce bandwidth usage</p>
  </li>
  <li>
    <p>personal firewalls or antivirus software changing or blocking content</p>
  </li>
  <li>
    <p>the use of unsecure connections, where internet providers insert their own code into the page that accidentally conflicts with your own</p>
  </li>
</ul>

<p>Some users may deliberately turn off features in their browsers. You should respect their decision and make sure those users can still use your service.</p>

<h2 id="single-page-applications">Single page applications</h2>

<p>Do not build your service as a single-page application (SPA). This is where the loading of pages within your service is handled by JavaScript, rather than the browser.</p>

<p>Single page applications rarely bring benefits and can make the service inaccessible because:</p>

<ul>
  <li>
    <p>users of assistive technology would be unaware of changes in context, for example when moving to a new page</p>
  </li>
  <li>
    <p>it would fail to handle focus when moving between pages</p>
  </li>
  <li>
    <p>the user would be unable to navigate using the back or forward buttons in their browser</p>
  </li>
  <li>
    <p>users would be unable to recover from an error, for example if there is an interruption to their network connection</p>
  </li>
</ul>

<h2 id="testing-your-service">Testing your service</h2>

<p>If any components in your service rely heavily on JavaScript or JavaScript frameworks you will need to make sure they:</p>

<ul>
  <li>
    <p>work on a wide range of browsers and devices</p>
  </li>
  <li>
    <p>work with <a href="https://www.gov.uk/service-manual/technology/testing-with-assistive-technologies">assistive technologies</a></p>
  </li>
  <li>
    <p>are <a href="https://www.gov.uk/service-manual/technology/how-to-test-frontend-performance">tested to ensure good performance</a></p>
  </li>
</ul>





<ul>
  <li>
    <p><a rel="external" href="https://gdstechnology.blog.gov.uk/2016/09/19/why-we-use-progressive-enhancement-to-build-gov-uk/">Why we use progressive enhancement to build GOV.UK</a></p>
  </li>
  <li>
    <p><a href="https://www.gov.uk/service-manual/technology/designing-for-different-browsers-and-devices">Designing for different devices</a></p>
  </li>
  <li>
    <p><a href="https://www.gov.uk/service-manual/technology/how-to-test-frontend-performance">How to test for front end performance</a></p>
  </li>
  <li>
    <p><a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/understanding-wcag">Understanding WCAG 2.2</a></p>
  </li>
</ul>

</div><div data-module="gem-toggle">
        <div>
            
              <dl>
                <dt>Last update:</dt>
                <dd>
                  <time datetime="2024-09-27T10:04:16+01:00">
  27 September 2024
</time>
<p>
  Updated to include the use of JavaScript in progressive enhancement and the potential impact on user experience.
</p>

                </dd>
              </dl>
        </div>
          <p>
            <a href="#full-history" data-controls="full-history" data-toggled-text="- Hide all page updates (3)" data-expanded="false" data-module="ga4-event-tracker" data-ga4-event="{&quot;event_name&quot;:&quot;select_content&quot;,&quot;type&quot;:&quot;content history&quot;,&quot;section&quot;:&quot;Footer&quot;}" data-ga4-expandable="" role="button" aria-controls="full-history" aria-expanded="false">
                + Show all page updates (3)
            </a>
          </p>
          <ol id="full-history" aria-live="polite" role="region">
              <li>
                <time datetime="2019-12-16T12:34:57+00:00">
  16 December 2019
</time>
<p>
  Added browser update bugs to the list of reasons why JavaScript or CSS might fail to load
</p>

              </li>
              <li>
                <time datetime="2019-05-21T14:53:33+01:00">
  21 May 2019
</time>
<p>
  Updated to reflect progressive enhancement's effect on a service's resilience, plus clarified guidance on building more complex services that use JavaScript
</p>

              </li>
              <li>
                <time datetime="2016-05-23T17:53:11+01:00">
  23 May 2016
</time>
<p>
  Guidance first published
</p>

              </li>
          </ol>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Floating megabomb heaves to near the English coast (163 pts)]]></title>
            <link>https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/</link>
            <guid>41685917</guid>
            <pubDate>Sun, 29 Sep 2024 08:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/">https://cepa.org/article/floating-megabomb-heaves-to-near-the-english-coast/</a>, See on <a href="https://news.ycombinator.com/item?id=41685917">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>The MV Ruby, a ship carrying a highly explosive Russian cargo, is damaged and looking for a port. Whether or not this is hybrid warfare, the threat is clear. </p><div>
					
<p>The Maltese-registered cargo ship, carrying 20,000 tons of explosive ammonium nitrate, triggered alarm bells in Western capitals when the vessel sustained damage and began to seek permission to unload its lethal cargo.</p>



<p>She is currently seaworthy but <a href="https://www.vesselfinder.com/vessels/details/9626390">unmoving</a> some miles off the coast of Kent, to the east of London, and just outside UK territorial waters.</p>



<p>Spurning the obvious solution of a return to Russia, where she loaded at <a href="https://theloadstar.com/baltic-ports-bar-damaged-ruby-now-in-the-channel-due-to-dangerous-cargo/">Kandalaksha</a> in late August, the damaged vessel embarked on an odyssey of attempted entry to European ports, beginning at the Norwegian anchorage of Tromsø, a naval base that she was <a href="https://www.thebarentsobserver.com/security/trouble-vessel-has-departed-tromso-but-future-uncertain/166105">ordered to leave</a> on September 4. <em>Ruby</em> then sought permission to dock at Klaipėda in Lithuania, a critical NATO reinforcement facility in time of crisis and war.</p>



<p><a href="https://www.lrt.lt/en/news-in-english/19/2358770/ship-with-russian-chemicals-will-not-be-allowed-into-klaipeda-port-pm">Lithuania refused</a> because of the dangerous nature of the cargo. If 20,000 tons of ammonium nitrate were to detonate, it would obliterate the center of any port city — the blast would be equal to <a href="https://x.com/TomSharpe134/status/1839706939292340394">a third</a> of the 1945 Hiroshima bomb. That would be a repeat of the <a href="https://interconnectedrisks.org/disasters/beirut-explosion">devastating explosion</a> of the same substance in Beirut in 2020, although <em>Ruby</em> is carrying seven times more ammonium nitrate.</p>



<p>While Lithuanian authorities announced there was no evidence of malicious intent against the country’s national security, they noted that when dealing with Russia, or other unfriendly international actors, states should always be cautious.</p>



<p>Alongside its war against Ukraine, the Kremlin has long pursued an aggressive hybrid strategy aimed at spreading chaos and destabilization through disinformation, interference in elections, and support for anti-Western political parties. But there has been a substantial uptick in recent months, including serious <a href="https://cepa.org/article/wake-up-nato-its-sabotage/">acts of sabotage</a>.</p>



<p>The shift in its strategy in the Baltic states from “classical” hybrid warfare to more “kinetic” approaches — not just propaganda and cyber-attacks, has now shifted to physical action on the ground.</p>



<p>The physical <a href="https://cepa.org/article/wake-up-nato-its-sabotage/">sabotage</a> includes acts such as a fire at an IKEA storage facility in Lithuania, which helped fuel false narratives about the safety and <a href="https://www.lrytas.lt/english/society/2024/05/20/news/suspicious-fires-in-neighbouring-countries-may-also-affect-lithuania-warn-of-exceptionally-high-risk-in-these-areas-31970773">reliability of foreign investments</a>, while cyber-attacks on power grids, water supply, and communication networks have also been used alongside <a href="https://breakingdefense.com/2024/01/as-baltics-see-spike-in-gps-jamming-nato-must-respond/">GPS jamming</a> to disrupt people’s everyday lives.</p>



<p>The Baltic states are NATO members, meaning an outright military attack would likely trigger collective defense under Article 5; hybrid threats are designed to <a href="https://www.rand.org/content/dam/rand/pubs/research_reports/RR1500/RR1577/RAND_RR1577.pdf">avoid direct confrontation</a> that would result in a military response.</p>



<p>Others have also been targeted. In August, German officials were reportedly <a href="https://www.yahoo.com/news/germany-issues-air-freight-security-124233351.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9kdWNrZHVja2dvLmNvbS8&amp;guce_referrer_sig=AQAAAI7U-SIzAuGpSS3nm-XDz6tBdh_TfpkrwPg0JyMZjxFrhnoE64vawL3OIEZ1IyHJMP5rFU-y7v4_bns8l9geTcSQB5LgDoc3Ssql0HTJbkNFOJIdiLgj2-cMjNgM_BsvTqILfMWdkciF5ttwDBYLbdiD5w_TjKjiqSXAhcw2ReO3">concerned</a> that Russia was responsible for incendiary devices on international air parcels. German trains have also been hit by sabotage attacks.</p>



<p>In this atmosphere of heightened tension, should a ship carrying ammonium nitrate be interpreted as a hybrid threat? Potentially, yes, but it is important to walk between the dual traps of either neglecting emerging problems or labeling all incidents as deliberate.</p>



<div id="" data-block="newsletter">
				<p>
			Get the Latest		</p>
		
				<p>
			Sign up to receive regular emails and stay informed about CEPA's work.		</p>
		
		
				
		
	</div>



<p>Ammonium nitrate is highly explosive, especially when exposed to fire or contamination, so strict safety protocols are followed, including controlled unloading in designated safe zones, continuous monitoring, and emergency response plans. The International Maritime Dangerous Goods (IMDG) Code contains strict guidelines for the substance, and compliance <a href="https://maritimecyprus.com/2024/02/13/maritime-risk-focus-fire-risk-transporting-ammonium-nitrate-on-ships-2/?fbclid=IwZXh0bgNhZW0CMTAAAR0gaAfxgb4cPqACkSeDUrPozngdelgXYMfyAJtpch0AdWnELvTxqak_0Ns_aem_Z3WV9axAHJsY-GEiw6htpg">helps prevent accidents</a> during transport and emergency repairs.</p>



<p>Allowing <em>Ruby</em> to dock in Klaipėda would have created a significant security risk as the cargo would be a direct physical threat to a critical infrastructure hub, making it <a href="https://interconnectedrisks.org/disasters/beirut-explosion?fbclid=IwZXh0bgNhZW0CMTAAAR0Vs01fWN1rgTraRB3k5Mu-LtIi9QLdcdEHcqyVdMokcBGKRM1VrGk909U_aem_0puSxWdOtt-mUJ-SFjezAw">a potential trigger for destabilization</a> if exploited by hostile actors.</p>



<p>Klaipėda is vitally important to Lithuania and NATO in several strategic areas — military logistics, energy security, and regional power stability.</p>



<p>It is a key hub for transporting military equipment and personnel and essential for NATO and the US’s reinforcement capabilities in the Baltic region. This would be particularly crucial in scenarios where <a href="https://www.washingtoninstitute.org/policy-analysis/lebanons-port-risks-need-action-against-substandard-ships?fbclid=IwZXh0bgNhZW0CMTAAAR1NyS4ertPZsq8Sh3acDs3eMzbTlfm3ms8hpFvctRbfgTWeCsa5AVTSuRY_aem_RAnwf4CrCLdHKiaU0kiUxQ">the Suwałki Corridor</a>, the narrow land strip connecting Poland and Lithuania, was under threat as the port would ensure NATO’s operational readiness in the region.</p>



<p>The port also hosts the only large-scale <a href="https://www.kn.lt/en/long-term-operation-of-klaipeda-lng-terminal/4841">LNG terminal</a> in the Baltic states, which enables the import of LNG as an alternative to Russian gas and is a cornerstone of Lithuania’s energy security strategy. A security incident could disrupt supplies for the whole region.</p>



<p>As if that wasn’t enough, Klaipėda plays a significant role in regional power connectivity through <a href="https://www.nsenergybusiness.com/analysis/featurecompletion-of-nordbalt-and-litpol-closes-the-baltic-ring-4847289/">the NordBalt power cable</a>, which links Lithuania with Sweden and is crucial for maintaining the stability of the Baltic power grid.</p>



<p>Given these strategic roles, any threat to Klaipėda, whether from mismanagement of a dangerous cargo or a deliberate act, has far-reaching implications for regional security and energy stability.</p>



<p>The <em>Ruby</em> episode underscores how hybrid threats can potentially evolve to include kinetic elements. The complexity of attribution, combined with Klaipėda’s strategic significance, makes it a potential flashpoint for regional security.</p>



<p>To prevent such situations, robust intelligence-sharing, surveillance and maritime security protocols must be robust. Authorities should also be vigilant about the origins and intentions of vessels requesting access.</p>



<p>Refusing or accepting such ships can have diplomatic repercussions, and denying entry might strain relations with the country of registration or cargo origin, especially if they are allies or significant trade partners. However, allowing such a vessel to dock could expose the host country to security and safety risks.</p>



<p>Effective communication and <a href="https://www.washingtoninstitute.org/policy-analysis/lebanons-port-risks-need-action-against-substandard-ships?fbclid=IwZXh0bgNhZW0CMTAAAR3avSbMFXY1Xk2Ih0c8mlk5PDRpb4zoiZgufrIgjDUnDTLl9Z3nkc5_Twg_aem_CKUZxLnjknsooj-9qgYI6A">adherence to international protocols</a> are essential to navigate these diplomatic challenges, highlighting the need for a balanced approach to security, diplomatic and legal considerations.</p>



<p><em>Eitvydas Bajarūnas is an ambassador in the Ministry of Foreign Affairs of the Republic of Lithuania, and currently a Center for Europe Policy Analysis (CEPA) Visiting Fellow. Assessments and views expressed in the article are those of the author and should not be treated as the official position of the MFA of the Republic of Lithuania.</em></p>



<p><span dir="ltr"><a aria-label="Link Europe’s Edge" title="https://cepa.org/insights-analysis/commentary/europes-edge/" rel="noreferrer noopener" href="https://cepa.org/insights-analysis/commentary/europes-edge/" target="_blank"><i>Europe’s Edge</i></a><i>&nbsp;is CEPA’s online journal covering critical topics on the foreign policy docket across Europe and North America. All opinions are those of the author and do not necessarily represent the position or views&nbsp;of the institutions they represent&nbsp;or the Center for European Policy Analysis.</i></span></p>



<div id="" data-block="featured-post">
				<a href="https://cepa.org/event/cepa-forum/cepa-forum-2024/2024-leadership-awards-dinner/" target="">
									<p><img decoding="async" src="https://cepa.org/wp-content/uploads/2023/05/092922-Embassy-of-the-Czech-Republic-053-1400x2100.jpg">
				</p>
							</a>
				
			</div>




<div id="" data-block="newsletter">
				<p>
			Europe's Edge		</p>
		
				<p>
			CEPA’s online journal covering critical topics on the foreign policy docket across Europe and North America.		</p>
		
					<p><a href="https://cepa.org/insights-analysis/commentary/europes-edge/" target="">
				Read More			</a>
		
		
	</p></div>

									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Too much efficiency makes everything worse (2022) (530 pts)]]></title>
            <link>https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html</link>
            <guid>41684082</guid>
            <pubDate>Sun, 29 Sep 2024 01:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html">https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html</a>, See on <a href="https://news.ycombinator.com/item?id=41684082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <meta charset="utf-8">
<!-- Google tag (gtag.js) -->



<pre>Increased efficiency can sometimes, counterintuitively, lead to worse outcomes. 
This is true almost everywhere.  
We will name this phenomenon the strong version of [Goodhart's law](https://en.wikipedia.org/wiki/Goodhart%27s_law). 
As one example, more efficient centralized tracking of student progress by standardized testing 
seems like such a good idea that well-intentioned laws [mandate it](https://en.wikipedia.org/wiki/No_Child_Left_Behind_Act). 
However, testing also incentivizes schools to focus more on teaching students to test well, and less on teaching broadly useful skills.
As a result, it can cause overall educational outcomes to become worse. Similar examples abound, in politics, economics, health, science, and many other fields.

This same counterintuitive relationship between efficiency and outcome occurs in machine learning, where it is called overfitting.
Overfitting is heavily studied, somewhat theoretically understood, and has well known mitigations.
This connection between the strong version of Goodhart's law in general, and overfitting in machine learning, provides a new 
lens for understanding bad outcomes, and new ideas for fixing them.


Overfitting and Goodhart's law
==========================

In machine learning (ML), **overfitting** is a pervasive phenomenon. We want to train an ML model to achieve some goal. We can't directly fit the model to the goal, so we instead train the model using some proxy which is *similar* to the goal.

![](/assets/cartoon-conversation.png width="300px" border="1")

For instance,
as an occasional computer vision researcher,
my 
goal is sometimes to
prove that my new image classification model works well.
I accomplish this by measuring its accuracy, after asking 
it to label images (is this image a cat or a dog or a frog or a truck or a ...)
from a standardized 
[test dataset of images](https://paperswithcode.com/dataset/cifar-10).
I'm not allowed to train my model on the test dataset though (that would be cheating), 
so I instead train the model on a *proxy* dataset, called the training dataset.
I also can't directly target prediction accuracy during training[^accuracytarget], so I instead target a *proxy* objective which is only related to accuracy.
So rather than training my model on the goal I care about -- classification accuracy on a test dataset -- I instead train it using a *proxy objective* on a *proxy dataset*.

At first everything goes as we hope -- the proxy improves, and since the goal is similar to the proxy, it also improves.

![](/assets/cartoon-early.png width="444px" border="1")

As we continue optimizing the proxy though, we eventually exhaust the useable similarity between proxy and goal. The proxy keeps on getting better, but the goal stops improving. In machine learning we call this overfitting, but it is also an example of Goodhart's law.

![](/assets/cartoon-mid.png width="444px" border="1")

[Goodhart's law](https://en.wikipedia.org/wiki/Goodhart%27s_law) states that, *when a measure becomes a target, it ceases to be a good measure*[^strathern]. 
Goodhart proposed this in the context of monetary policy, but it applies far more broadly. In the context of overfitting in machine learning, it describes how the proxy objective we optimize ceases to be a good measure of the objective we care about.

The strong version of Goodhart's law: as we become too efficient, the thing we care about grows worse
==========================

If we keep on optimizing the proxy objective, even after our goal stops improving, something more worrying happens. The goal often starts getting *worse*, even as our proxy objective continues to improve. Not just a little bit worse either -- often the goal will diverge towards infinity.

This is an [extremely](https://www.cs.princeton.edu/courses/archive/spring16/cos495/slides/ML_basics_lecture6_overfitting.pdf) [general](https://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/ml-lecture02.pdf) [phenomenon](https://scholar.google.com/scholar?hl=en&amp;q=overfitting) in machine learning. It mostly doesn't matter what our goal and proxy are, or what model architecture we use[^overfittinggenerality]. If we are very efficient at optimizing a proxy, then we make the thing it is a proxy for grow worse.

![](/assets/cartoon-late.png width="444px" border="1")

Though this pheonomenon is often discussed, it doesn't seem to be named[^notoverfitting]. Let's call it **the strong version of Goodhart's law**[^strongunintended]. 
We can state it as:
&gt; *When a measure becomes a target,
&gt; if it is effectively optimized,
&gt; then the thing it is designed to measure will grow worse.*

Goodhart's law says that if you optimize a proxy, eventually the goal you care about will stop improving. 
The strong version of Goodhart's law differs 
in that it says that as you over-optimize, the goal you care about won't just stop improving,
but will instead grow much worse than if you had done nothing at all.

Goodhart's law applies well beyond economics, where it was originally proposed. Similarly, the strong version of Goodhart's law applies well beyond machine learning. I believe it can help us understand failures in economies, governments, and social systems.

Increasing efficiency and overfitting are happening everywhere
==========================

Increasing efficiency is permeating almost every aspect of our society. If the thing that is being made more efficient is beneficial, then the increased efficiency makes the world a better place (overall, the world [seems to be becoming a better place](https://ourworldindata.org/a-history-of-global-living-conditions-in-5-charts)). If the thing that is being made more efficient is socially harmful, then the consequences of greater efficiency are scary or depressing (think mass surveillance, or robotic weapons). What about the most common case though -- where the thing we are making more efficient is related, but not identical, to beneficial outcomes? What happens when we get better at something which is merely correlated with outcomes we care about?

In that case, we can overfit, the same as we do in machine learning. The outcomes we care about will improve for a while ... and then they will grow dramatically worse.

Below are a few, possibly facile, examples applying this analogy.

&gt; **Goal:** Educate children well  <br>
&gt; **Proxy:** [Measure student and school performance](https://en.wikipedia.org/wiki/No_Child_Left_Behind_Act) on standardized tests <br>
&gt; **Strong version of Goodhart's law leads to:** Schools narrowly focus on teaching students to answer questions like those on the test, at the expense of the underlying skills the test is intended to measure

&gt; **Goal:** Rapid progress in science  <br>
&gt; **Proxy:** Pay researchers a [cash bonus for every publication](https://www.science.org/content/article/cash-bonuses-peer-reviewed-papers-go-global) <br>
&gt; **Strong version of Goodhart's law leads to:** Publication of incorrect or incremental results, collusion between reviewers and authors, research paper mills

&gt; **Goal:** A well-lived life    <br>
&gt; **Proxy:** Maximize the reward pathway in the brain    <br>
&gt; **Strong version of Goodhart's law leads to:** Substance addiction, gambling addiction, days lost to doomscrolling Twitter

&gt; **Goal:** Healthy population  <br>
&gt; **Proxy:** Access to nutrient-rich food  <br>
&gt; **Strong version of Goodhart's law leads to:** Obesity epidemic

&gt; **Goal:** Leaders that act in the best interests of the population  <br>
&gt; **Proxy:** Leaders that have the most support in the population <br>
&gt; **Strong version of Goodhart's law leads to:** Leaders whose expertise and passions center narrowly around manipulating public opinion at the expense of social outcomes

&gt; **Goal:** An informed, thoughtful, and involved populace  <br>
&gt; **Proxy:** The ease with which people can share and find ideas  <br>
&gt; **Strong version of Goodhart's law leads to:** Filter bubbles, conspiracy theories, parasitic memes, escalated tribalism

&gt; **Goal:** Distribution of labor and resources based upon the needs of society  <br>
&gt; **Proxy:** Capitalism  <br>
&gt; **Strong version of Goodhart's law leads to:** Massive wealth disparities (with incomes ranging from hundreds of dollars per year to hundreds of dollars per second), with [more than a billion](https://hdr.undp.org/en/2020-MPI ) people living in poverty

&gt; **Goal:** The owners of Paperclips Unlimited, LLC, become wealthy  <br>
&gt; **Proxy:** Number of paperclips made by the AI-run manufacturing plant <br>
&gt; **Strong version of Goodhart's law leads to:** The entire solar system, including the company owners, being [converted to paperclips](https://www.lesswrong.com/tag/paperclip-maximizer)

As an exercise for the reader, you can think about how the strong version of Goodhart's law would apply to other efficiencies, like the ones in this list:
~~~ none
telepresence and virtual reality
personalized medicine
gene therapy
tailoring marketing messages to the individual consumers or voters who will find them most actionable
predicting the outcome of elections
writing code
artificial intelligence
reducing slack in supply chains
rapidly disseminating ideas
generating entertainment
identifying new products people will buy
raising livestock
trading securities
extracting fish from the ocean
constructing cars
~~~
[Listing [greater-efficiency]: Some additional diverse things we are getting more efficient at. For most of these, initial improvements were broadly beneficial, but getting too good at them could cause profound negative consequences.]


How do we mitigate the problems caused by overfitting and the strong version of Goodhart's law?
==========================
If overfitting is useful as an analogy, it will be because some of the approaches that improve it in machine learning also transfer to other domains. Below, I review some of the most effective techniques from machine learning, and share some thoughts about how they might transfer.

+ **<span>Mitigation</span>: Better align proxy goals with desired outcomes.** In machine learning this often means carefully collecting training examples which are as similar as possible to the situation at test time. Outside of machine learning, this means changing the proxies we have control over -- e.g. laws, incentives, and social norms -- so that they directly encourage behavior that better aligns with our goals. This is the standard approach used to (try to) engineer social systems.

+ **<span>Mitigation</span>: Add regularization penalties to the system.**  In machine learning, this is often performed by [penalizing the squared magnitude of parameters](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization), so that they stay small. Importantly, regularization doesn't need to directly target undesirable behavior. Almost anything that penalizes deviations of a model from typicality works well. Outside of machine learning, anything that penalizes complexity, or adds friction or extra cost to a system, can be viewed as regularization. Some example ideas:
  + Add a billing mechanism to SMTP, so there's a small cost for every email.
  + Use a progressive tax code, so that unusual success is linked to disproportionately greater cost
  + Charge a court fee proportional to the squared (exponentiated?) number of lawsuits initiated by an organization, so that unusual use of the court system leads to unusual expenses
  + Tax the number of bits of information stored about users

+ **<span>Mitigation</span>: Inject noise into the system.** In machine learning, this involves adding random jitter to the inputs, parameters, and internal state of a model. The unpredictability resulting from this noise makes overfitting far more difficult. Here are some ideas for how to improve outcomes by injecting noise outside of machine learning:
  + Stack rank all the candidates for a highly competitive school or job. Typically, offers would be made to the top-k candidates. Instead, make offers probabilistically, with probability proportional to $\left(\right.$[approx # top tier candidates] $+$ [candidate's stack rank]$\left.\right)^{-1}$. Benefits include: greater diversity of accepted candidates; less ridiculous resources spent by the candidates tuning their application, and by application reviewers reviewing the applications, since small changes in assessed rank only have a small effect on outcome probabilities; occasionally you will draw a longshot candidate that is more likely to fail, but also more likely to succeed in an unconventional and unusually valuable way.
  + Randomly time quizzes and tests in a class, rather than giving them on pre-announced dates, so that students study to understand the material more, and cram (i.e., overfit) for the test less.
  + Require securities exchanges to add random jitter to the times when they process trades, with a standard deviation of about a second. (An efficient market is great. Building a global financial system out of a chaotic nonstationary dynamical system with a characteristic timescale more than six orders of magnitude faster than human reaction time is just asking for trouble.)
  + Randomize details of the electoral system on voting day, in order to prevent candidates from overfitting to incidental details of the current electoral system (e.g. by taking unreasonable positions that appeal to a pivotal minority). For instance randomly select between ranked choice or first past the post ballots, or randomly rescale the importance of votes from different districts. (I'm not saying all of these are *good* ideas. Just ... ideas.)

+ **<span>Mitigation</span>: Early stopping.** In machine learning, it's common to monitor a third metric, besides training loss and test performance, which we call validation loss. When the validation loss starts to get worse, we stop training, even if the training loss is still improving. This is the single most effective tool we have to prevent catastrophic overfitting. Here are some ways early stopping could be applied outside of machine learning:
  + Sharply limit the time between a call for proposals and submission date, so that proposals better reflect pre-existing readiness, and to avoid an effect where increasing resources are poured into proposal generation, rather than being used to create something useful
  + Whenever stock volatility rises above a threshold, suspend all market activity
  + The use of antitrust law to split companies that are preventing competition in a market
  + Estimate the importance of a decision in $$. When the value of the time you have already spent analyzing the decision approaches that value, make a snap decision.
  + Freeze the information that agents are allowed to use to achieve their goals. Press blackouts in the 48 hours before an election might fall under this category.

One of the best understood *causes* of extreme overfitting is that the expressivity of the model being trained *too closely matches* the complexity of the proxy task. 
When the model is very weak, it can only make a little bit of progress on the task, and it doesn’t exhaust the similarity between the goal and the proxy. 
When the model is extremely strong and expressive, it can optimize the proxy objective in isolation, without inducing extreme behavior on other objectives. 
When the model's expressivity roughly matches the task complexity (e.g., the number of parameters is no more than a few orders of magnitude higher or lower than the number of training examples), then it can only do well on the proxy task by doing *extreme things everywhere else*. See Figure [capacity] for a demonstration of this idea on a simple task. 
This cause of overfitting motivates two final, diametrically opposed, methods for mitigating the strong version of Goodhart’s law.

+ **<span>Mitigation</span>: Restrict capabilities / capacity.** In machine learning, this is often achieved by making the model so small that it's incapable of overfitting. In the broader world, we could similarly limit the capacity of organizations or agents. Examples include:
  + Campaign finance limits
  + Set a maximum number of people that can work in companies of a given type. e.g. allow only 10 people to work in any lobbying group
  + Set the maximum number of parameters, or training compute, that any AI system can use.
 
+ **<span>Mitigation</span>: Increase capabilities / capacity.** In machine learning, if a model is made very big, it often has enough capacity to overfit to the training data without making performance on the test data worse. In the broader world, this would correspond to developing capabilities that are so great that there is no longer any tradeoff required between performance on the goal and the proxy. Examples include:
  + Obliterate all privacy, and make all the information about all people, governments, and other organizations available to everyone all the time, so that everyone can have perfect trust of everyone else. This could be achieved by legislating that every database be publicly accessible, and by putting cameras in every building. (to be clear -- from my value system, this would be a dystopian scenario)
  + Invest in basic research in clean energy
  + Develop as many complex, inscrutable, and diverse market trading instruments as possible, vesting on as many timescales as possible. (In nature, more complex ecosystems are more stable. Maybe there is a parallel for markets?)
  + Use the largest, most compute and data intensive, AI model possible in every scenario 😮[^gobig]

This last mitigation of just continuing to increase capabilities works surprisingly well in machine learning.
It is also a path of least resistance. 
Trying to fix our institutions by blindly making them better at pursuing misaligned goals is a terrible idea though.

Parting thoughts
==========================

The strong version of Goodhart's law underlies most of my personal fears around AI (expect a future blog post about my AI fears!). 
If there is one thing AI will enable, it is greater efficiency, on almost all tasks, over a very short time period. 
We are going to need to simultaneously deal with massive numbers of diverse unwanted side effects, 
just as our ability to collaborate on solutions is also disrupted.

There's a lot of opportunity to *research* solutions to this problem. 
If you are a scientist looking for research ideas which are pro-social, 
and have the potential to create a whole new field, you should consider
building formal (mathematical) bridges between results on overfitting
in machine learning, and problems in economics, political science, management science, operations research, and elsewhere[^researchideas].
This is a goldmine waiting to be tapped. (I might actually be suggesting here that we should invent the field of [psychohistory](https://en.wikipedia.org/wiki/Psychohistory), and that overfitting phenomena will have a big role in that field.)

The more our social systems break due to the strong version of Goodhart's law, 
the less we will be able to take the concerted rational action required to fix them.
Hopefully naming, and better understanding, the phenomenon will help push in the opposite direction. 

<br>

![Figure [capacity]: **Models often suffer from the strong version of Goodhart's law, and overfit catastrophically, when their complexity is well matched to the complexity of the proxy task.** If a model is instead much more or much less capable than required, it will overfit less. Here, models are trained to map from a one-dimensional input $x$ to a one-dimensional output $y$. All models are trained on the same 10 datapoints, in red. The model with 4 parameters is too weak to exactly fit the datapoints, but it smoothly approximates them. The model with 10,000 parameters is strong enough to easily fit all the datapoints, and also smoothly interpolate between them. The model with 10 parameters is exactly strong enough to fit the datapoints, but it can only contort itself to do so by behaving in extreme ways away from the training data. If asked to predict $y$ for a new value of $x$, the 10 parameter model would perform extremely poorly. For details of this toy experiment, which uses linear random feature models, see this [colab notebook](https://colab.research.google.com/drive/1mAqCsCE-6biiFxQu8swlc5MygmI9lMJA?usp=sharing).](/assets/size-mitigation.png width="290px" border="1")

<br>

[^accuracytarget]: Accuracy is not differentiable, which makes it impossible to target by naive gradient descent training. It is usually replaced during training by a proxy of softmax-cross-entropy loss, which is differentiable. There are blackbox training methods which can directly target accuracy, but they are inefficient and rarely used.

[^strathern]: This modern phrasing is due to Marilyn Strathern. 
Goodhart originally phrased the observation as the more clunky 
*any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes*. 

[^overfittinggenerality]: This glosses over a lot of variation. For instance, there is an entire subfield which studies the qualitative differences in overfitting in underparameterized, critically parameterized, and overparameterized models. Despite this variation, the core observation --  that when we train on a proxy our target gets better for a while, but then grows worse -- holds broadly. 

[^notoverfitting]: It's not simply overfitting. Overfitting refers to the proxy becoming better than the goal, not to the goal growing worse in an absolute sense. There are other related, but not identical, concepts -- for instance [perverse incentives](https://en.wikipedia.org/wiki/Perverse_incentive), [Campbell's law](https://en.wikipedia.org/wiki/Campbell%27s_law), the [Streisand effect](https://en.wikipedia.org/wiki/Streisand_effect), the [law of unintended consequences](https://en.wikipedia.org/wiki/Unintended_consequences), [Jevons paradox](https://en.m.wikipedia.org/wiki/Jevons_paradox), and the concept of [negative externalities](https://en.m.wikipedia.org/wiki/Externality#Negative). [Goodhart's curse](https://arbital.com/p/goodharts_curse/) is perhaps the closest. However, the definition of Goodhart's curse incorporates not only the phenomenon, but also a specific mechanism, and the mechanism is incorrect[^Goodhartcurse]. *Edit 2022/11/9: Andrew Hundt [suggests](https://twitter.com/athundt/status/1589591738792177664) that similar observations that optimization isn't always desirable have been made in the social sciences, and gives specific examples of "The New Jim Code" and "[Weapons of Math Destruction](https://en.m.wikipedia.org/wiki/Weapons_of_Math_Destruction)". Kiran Vodrahalli [points out](https://mathstodon.xyz/@kiranvodrahalli/109300676096306738) connections to robust optimization and the "[price of robustness](https://www.robustopt.com/references/Price%20of%20Robustness.pdf)." [Leo Gao](https://bmk.sh/) points me at a [recent paper](https://arxiv.org/abs/2210.10760) which uses the descriptive term "overoptimization" for this phenomenon, which I think is good.*

[^strongunintended]: I also considered calling it the strong law of unintended consequences -- it's not just that there are unexpected side effects, but that that the more effectively you accomplish your task, the more those side effects will act against your original goal.

[^gobig]: Note that for suficiently strong AI, limitations on its capabilities might be determined by the laws of physics, rather than by its compute scale or training dataset size. So if you're worried about misaligned AGI, this mitigation may offer no comfort.

[^researchideas]: For instance, take PAC Bayes bounds from statistical learning theory, and use them to predict the optimal amount of power unions should have, in order to maximize the wealth of workers in an industry. Or, estimate the spectrum of candidate-controllable and uncontrollable variables in political contests, to predict points of political breakdown. (I'm blithely suggesting these examples as if they would be easy, and are well formed in their description. Of course, neither is true -- actually doing this would require hard work and brilliance in some ratio.)

[^Goodhartcurse]: The [definition of Goodhart's curse](https://arbital.com/p/goodharts_curse/) includes [the optimizer's curse](https://www.semanticscholar.org/paper/The-Optimizer's-Curse%3A-Skepticism-and-Postdecision-Smith-Winkler/28cfed594544215673db802dce79b8c12d3ab5ab) as its causal mechanism. This is where the word 'curse' comes from in its name. 
If an objective $u$ is an imperfect proxy for a goal objective $v$, the optimizer's curse explains why optimizing $u$ finds an anomalously good $u$, and makes the *gap* between $u$ and $v$ grow large. It doesn't explain why optimizing $u$ makes $v$ grow worse in an absolute sense. That is, the optimizer's curse provides motivation for why Goodhart's law occurs. It does not provide motivation for why the strong version of Goodhart's law occurs. (As I briefly discuss elsewhere in the post, one common causal mechanism for $v$ growing worse is that it's expressivity is too closely matched to the complexity of the task it is performing. This is a very active research area though, and our understanding is both incomplete and actively changing.)
<p>

-----
<br>

Thank you to Asako Miyakawa and Katherine Lee for providing feedback on earlier drafts of this post.

</p></pre>

<!-- Markdeep: -->





  </div><p><small>
BibTeX entry for post:<br>
<tt>

@misc{sohldickstein20221106,<br>
   author = {Sohl-Dickstein, Jascha},<br>
   title = {{ Too much efficiency makes everything worse: overfitting and the strong version of Goodhart's law }},<br>
   howpublished = "\url{https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html}",<br>
   date    = {2022-11-06}<br>
}
</tt>
</small>

  </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on the Crystal Language (131 pts)]]></title>
            <link>https://wiki.alopex.li/CrystalNotes</link>
            <guid>41683815</guid>
            <pubDate>Sun, 29 Sep 2024 00:16:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.alopex.li/CrystalNotes">https://wiki.alopex.li/CrystalNotes</a>, See on <a href="https://news.ycombinator.com/item?id=41683815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><div id="TOC">
<ul>
<li><a href="#first-impressions">First impressions</a></li>
<li><a href="#object-stuff">Object stuff</a></li>
<li><a href="#type-system-stuff">Type system stuff</a></li>
<li><a href="#stdlib-stuff">Stdlib stuff</a></li>
<li><a href="#other-random-bits">Other random bits</a></li>
<li><a href="#things-to-look-at-later">Things to look at later</a></li>
<li><a href="#conclusions">Conclusions</a></li>
</ul>
</div>

<p>A friend talked me into trying out the <a href="https://crystal-lang.org/">Crystal programming language</a>, and
then another friend talked me into starting a <a href="https://hg.sr.ht/~icefox/casual-benchmarks">little project</a>
that Crystal would be good for, so here’s the traditional rambling
thoughts on it. Written in September 2024, using Crystal 1.13. Also note
that I’ve used almost no statically-typed language besides Rust for like
8 years, so I am <em>very</em> Rust-brained these days.</p>
<h2 id="first-impressions">First impressions</h2>
<ul>
<li>Language started in 2014</li>
<li>Overarching idea: Strongly-typed Ruby (with lots of type
inference)</li>
<li>This means Everything Is An Object, which always feels wrong to me
these days, but like Ruby it’s a fairly good implementation of the idea.
You can have standalone functions and whatever and it works fine.</li>
<li>Programs are just compiled to native executables through LLVM.
Compilation isn’t instant, but it’s Fast Enough for me so far.</li>
<li>No repl that I’ve found, but also no <code>main()</code> function,
writing bare statements in a toplevel file executes them from start to
end. Sounds like a potential liability to me, with order of file imports
changing side effects, but it sure is convenient to learn with.</li>
<li>The tutorial also has editable and executable online code blocks,
which is an excellent way to play around</li>
<li>Has a good range of useful-but-less-common built-in types like sets,
symbols/atoms, tuples and closures, so the creator is no fool</li>
<li>Reasonably modern package/build manager: <code>shards</code>. Uses
yaml for the file format unfortunately, but oh well.</li>
<li>Decent project-blessed Debian packages and the usual (bad)
<code>curl ... | sudo sh</code> style install script, which I eyeballed
and is not at this time a rootkit. Its .deb is hosted on opensuse.org,
which feels weird; someday I should actually learn anything about SuSE
besides “RPM based, I tried it in 2005 and it didn’t work well on my PC
at the time”</li>
<li>Tutorial is really minimal, be prepared to just read through the
reference once you get through the bare essentials</li>
<li>The reference is pretty good though</li>
<li>Where the hell are for loops??? Oh they don’t exist, you use
<code>10.each do |x| ... end</code> like Ruby. Sure, why not.</li>
<li>Reasonable ecosystem of libs, seemingly mostly decentralized like Go
but <code>shards</code> has at least the framework for different package
sources, so if someone makes a centralized Crystal package lib and it
gets popular it can just be added as another option. Standard lib is
more of the maximalist style, has a bunch of handy script-y things in
it.</li>
<li>Compiles to static-ish binaries with LLVM. So it’s not a scripting
language per se, but… scripting-language-coded, I suppose.</li>
<li>Was sold to me as having very good FFI and macro metaprogramming,
which sounds useful.</li>
</ul>
<h2 id="object-stuff">Object stuff</h2>
<ul>
<li>It splits apart <code>new</code> to allocate memory and
<code>initialize</code> to initialize it like Objective C does, which is
always nice to see. Usually unnecessary, but nice to see.</li>
<li>Class variables are all private, everything is done through
accessors. There’s freely-available overloads for operators like
<code>=[]</code> for <code>x[y] = z</code>, and more shortcuts (which
turn out to be <a href="https://crystal-lang.org/api/1.13.2/Object.html#property%28%2Anames%2C%26block%29-macro">macros</a>)
for defining accessors.</li>
<li>Does the Ruby annotation thing where <code>foo</code> is local var,
<code>@foo</code> is instance var, <code>@@foo</code> is class var,
which feels weird but after using it for a while I actually kinda like
it.</li>
<li>Oooooh all constants start with capital letters… and all
types/classes start with capital letters… so all types are constants at
runtime. Classy. …No, not that kind of <code>class</code>-y. Dammit that
wasn’t supposed to be a pun! Go away!</li>
<li>Structs are value-typed classes, like in C#. IMO this is a worse
design than just having explicit references, but fine for 2014 when the
language was created.</li>
<li>There’s a feature called “splat assignment” which just seems like
weaksauce pattern matching. Looks useful, but why not just have pattern
matching? Splat assignment probably evolved out of Python’s
<code>*</code> function argument swizzling operators.</li>
<li>Has some nice shortcut syntax for designing your own collections
types, so <code>{1 =&gt; :foo, 2 =&gt; :bar}</code> makes the builtin
<code>Hash</code> type, but you can write
<code>MyType{1 =&gt; :foo, 2 =&gt; :bar}</code> and it will desugar to
<code>MyType.new(); MyType[1] = :foo; MyType[2] = :bar;</code> Feels a
bit like C# there, nice option to have.</li>
</ul>
<h2 id="type-system-stuff">Type system stuff</h2>
<ul>
<li>You (almost) never need to add type annotations to vars and function
args/returns to make the program typecheck, but you always have the
option to add them so it typechecks the way you want,, which is
good</li>
<li>It looks like it does some form of global type inference, which
sounds somewhat ad-hoc compared to OCaml-y HM but seems to work fine in
practice (so far).</li>
<li>The type inference allows unions of types like Typescript does, such
as <code>Int | String</code>.</li>
<li>Variables are declared by being assigned to, which to me feels a
little unnecessarily sloppy but usually works okay in practice. The
<code>@</code> sigils help a bit.</li>
<li>Variables can be reassigned with a value of a different type, which
is a little bold. So you can do <code>a = 3; a = "hi"</code> and it
works. Not sure yet how hazardous this is in practice. I assume it types
<code>a</code> as <code>Int32 | String</code> in that case? Yep; if you
declare the type of a variable <code>a : Int32 = 3; a = "hi"</code> then
it complains that the type of <code>a</code> is <code>Int32</code> but
you’re trying to use it as if it were <code>Int32 | String</code>.
Writing <code>a : Int32 | String = 3; a = "hi"</code> works just
fine.</li>
<li>This is also how uninitialized variables work. Uninitialized vars
have type <code>Nil</code>, which has only one value <code>nil</code>,
which then interacts with other types like normal. So an uninitialized
variable that is later set to a <code>String</code> has type
<code>Nil | String</code>.</li>
<li>So if you don’t want this to happen, you can always just give a
variable a type. And if you don’t do that, but screw something up, it
will get caught next time that variable is used with a function that has
typed args.</li>
<li>That feels <em>very</em> much like Typescript’s type system. Now, TS
is a little infamously unsound, which means you can write contradictions
in it; invalid programs can typecheck successfully. In practice this is
<em>seldom</em> too much of a problem in TS, afaik, but definitely can
fuck you up sometimes. I have no idea whether Crystal is unsound or not,
since its logic around types and objects and stuff seems different from
TS’s approach, which is shaped by needing to interoperate with the
abject sadness that is JS. Would be interesting to learn more about
it!</li>
<li>In general subtyping (such as OO inheritance) and union types (like
<code>Int | String</code>) are places where type systems get Hard, and
are areas of active research. So having Crystal wandering around this
design space is pretty neat from a language creator’s point of
view.</li>
<li>There are also real generics, haven’t touched them much yet but they
seem to do the job?</li>
<li>There’s the usual zoo of OO features like private/protected methods,
covariance and contravariance, virtual and abstract types, etc. I’m
happy to ignore them when possible.</li>
</ul>
<h2 id="stdlib-stuff">Stdlib stuff</h2>
<ul>
<li>Woohoo, batteries! Fun change from Rust. There’s hash functions in
there! JSON parser/writer! A smol HTTP server! Bignums! Tempfiles!</li>
<li>Oops, looks like its tempfile lib is written in library code in the
style of <code>mktemp(3)</code>, instead of calling the OS’s
<code>mkstemp(3)</code> or equivalent. So it just finds a filename that
doesn’t exist and then opens it separately, letting an attacker create a
new file which they can read at that location between those two steps.
Uh, have fun with your temporary files leading to exploitable race
conditions guys.</li>
<li>Digging through the Crystal issue tracker for this problem shows
multiple attempts to try to make this better done at different times by
different people, none of which seem to have been Good Enough. It’s a
pretty good example of the downsides of a batteries-included library,
tbh. Trying not to break shit is hard work.</li>
<li>The stdlib’s <code>OptionParser</code> is hella better than a C/bash
<code>argparse</code>-like API but it could be better still. I wish it
were more declarative and a little more opinionated, like Rust’s
<code>clap</code> or <code>argh</code>.</li>
<li>Oh I take it back, there’s no way I can find to just tell
<code>OptionParser</code> “this command line flag is necessary”. WTF?
It’s basically “wire your own state machine” like Python’s lame-ass
<code>argparse</code>. Maybe I should write a new command line parser
lib.</li>
<li>Oh, there’s already a bunch already written. A disadvantage of
Crystal’s Go-style package management where everything is in its own
repo, vs.&nbsp;Rust-style where there’s a blessed <code>crates.io</code> or
equivalent: it’s hard to know where to go to find packages. There
appears to be a decent (if commercial) curated list at <a href="https://crystal.libhunt.com/">https://crystal.libhunt.com/</a>. <a href="https://github.com/mrrooijen/commander">commander</a> and <a href="https://github.com/jwaldrip/admiral.cr">admiral</a> seem close to
what I want, though there’s plenty of others.</li>
<li>Annoying as this is, I <em>love</em> that there’s a good language
out there that makes decisions <em>different</em> from my habitual
Rust/Python/Elixir ecosystem. Tradeoffs are worth exploring.</li>
</ul>
<p>Okay I hate writing this ’cause I’ve been having fun up until now,
but the stdlib honestly needs some help. I had this code:</p>
<pre><code>testdir = Dir.new(testdir_path)
LANGUAGES.each do |name, lang|
  Dir.cd(testdir_path)
  # Iterate through subdirs
  testdir.each_child do |subdir|
    puts "Processing stuff in #{subdir}"
    do_stuff(testdir_path / subdir)
  end
end</code></pre>
<p>First off, <code>Dir#each_child()</code> returns a
<code>String</code>, not a <code>Path</code> or a <code>Dir</code> or
<code>File</code> object. Okay fine, paths are fucking cursed no matter
what. But it turns out that the <code>Dir</code> object <em>is</em> an
iterator, instead of what I expected, which was
<code>Dir#each_child</code> <em>creating</em> an iterator. So for the
first run of the outer loop it would iterate through the subdirectories
of <code>testdir_path</code>, and <code>do_stuff()</code> in each one.
Then for the <em>next</em> run of the outer loop it calls
<code>testdir.each_child()</code> again… which is already at the end of
the iterator, so it just bloody runs zero times. Want to iterate through
the directory again? Gotta call <code>testdir.rewind()</code> first. Is
this in the docs? Only if you look at the <code>rewind()</code> method
and understand that this is a possibility; otherwise you just gotta
figure it out the hard way like I did. Apparently this (like a lot of
the rest of the Crystal stdlib) is inherited from Ruby, but that doesn’t
mean it’s a good idea.</p>
<p>THIS is why you need an immutable-first language with move semantics
and borrowing, dammit! People ask me what Rust is good for if you are
happy to have a GC? Shit like this, that’s what.</p>
<p>Fine, Crystal isn’t that language, but still. But for as good as
Crystal itself is, it deserves to have the stdlib that doesn’t result in
me tripping across three separate footguns while writing what is, in the
end, a 300-line “I didn’t want to write a shell script” program. That’s
not great. Asking a good lang designer to also be a good stdlib designer
is a pretty tall order, but fortunately lib improvements are the sort of
work that can be done by a community more easily than core lang design.
Someone with intimate knowledge of the Rust stdlib and all the horrible
footguns its incredibly labyrinthine design tries to avoid, and the
intestinal fortitude to rewrite major parts of a stdlib, please help
Crystal out.</p>
<h2 id="other-random-bits">Other random bits</h2>
<ul>
<li>You can make functions with named args and call them like
<code>some_method 10, w: 1, y: 2, z: 3</code>. Heh, more Objective C
lineage – I don’t <em>think</em> Ruby does that? Oops it does; I think I
last touched Ruby in like 2012. Either way, classy. Feels like how
Elixir writes DSL’s out of functions, but in a good way. Probably not a
coincidence, since they’re both Ruby-ish syntax.</li>
<li>Yep, you can use the “splat operator” in function args and it’s
exactly like Python’s arg swizzle operators. Always a nice feature for a
dynamic-ish language, and one of the fun things that is just really
fucking annoying to do sensibly in a For Realsies Static language like
Rust. Even when it’s statically typed and compiled to native code, being
able to have the language say “yeah we just use lots of dynamic dispatch
and/or reflection here, it’s fine” is pretty convenient at times.</li>
<li>Oh shit, there’s no sum types! Heck, no <em>wonder</em> this feels
weird to write in. There’s enums, which is nice, but they are very
explicitly limited to integers and intended for flags and stuff. If you
really wanted Rust-style sum types you could fake them easily enough,
but that always Feels Bad. No real pattern matching either, so you it’s
more annoying to use the “tuple of symbol + value” style of sum types
that’s ubiquitous in Elixir or Erlang.</li>
<li>Modules are first-class values, huh. And have some relation to
classes. Again I am reminded of one of my more mind-bending moments
while learning Ruby, which was reading something along the lines of “the
<code>Module</code> class of <code>Module</code> is a subclass of the
<code>Class</code> class of <code>Class</code>.” Good times.</li>
<li>The <code>crystal</code> binary comes with some handy tools built
in, with the command <code>crystal tool</code>. There’s fairly mundane
things like a formatter and a macro-expander, and also slightly more
uncommon but interesting bits like something that prints out the full
class tree for a program, or shows the implementations possible for an
overloaded method call.</li>
<li>The <code>require</code> file import statement is mostly file-based,
vs Rust or Elixir’s more abstract module tree knowing where it
<em>expects</em> to find files. There’s still some default search paths
that result in a particular file layout in a multi-file project, but it
seems to be more of a suggestion than a rule. Files also all share the
same namespace by default, if you want nested namespaces you just make
the file <code>foo/bar.cr</code> contain your code inside
<code>module Foo::Bar ... end</code> . Feels a little oldschool compared
to more abstract systems, like the concept is “C includes done
properly”, but it seems to work fine. Meshes decently with the
scripting-language vibe, you can just kinda throw files together if you
want to.</li>
<li>There’s some auto-casting of numerical types, but it’s very
conservative compared to say C or Python 2. It only can occur in
function args or class initialization as well, which is an interesting
choice.</li>
<li>Error handling is fairly mundane exceptions, so far.</li>
<li>Crystal’s tools for dealing with <code>Nil</code> are kinda
interesting. The type <code>String?</code> is a shortcut for
<code>String | Nil</code>. <code>Nil</code> is falsey, but has a little
syntactic sugar to it: if you have a value <code>x</code> of type
<code>String?</code> you can write
<code>if x do_stuff_with(x) end</code> and the <code>x</code> inside the
if block is of type <code>String</code>. It’s smart enough to do the
opposite too; if you write
<code>if !x do_stuff(x) else do_other_stuff(x) end</code> then inside
the “if” part <code>x</code> is type <code>Nil</code>, and inside the
“else” part <code>x</code> is type <code>String</code>. So I guess it’s
a case/pattern match on the type, really, but a very handy one. Very
alien to my brain used to Rust’s <code>Option</code>’s; Crystal once
again does something that <em>feels</em> like how you’d write stuff in a
dynamic language, but makes it type safe.</li>
<li>The shortcuts for properties in class constructors are very
convenient. Rust could learn some things there, tbh.</li>
</ul>
<h2 id="things-to-look-at-later">Things to look at later</h2>
<ul>
<li>Reflection</li>
<li>FFI</li>
<li>Error handling</li>
<li>Macros</li>
<li>Generics (in more depth)</li>
<li>Can you magically return/break out of iterator functions like you
can in Ruby?</li>
<li>Threads/fibers?</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>I still think the world really needs a solid, immutable-first and
functional-first scripting/glue language, and Crystal isn’t that. But it
<em>is</em> a solid, well-considered OO language with a static type
system that feels as low-friction as a dynamic one. So give Crystal a go
next time you’re sick of writing your bajillion’th Python/Ruby/JS
script. It steals lots of stuff from Ruby, but the stuff it adds is very
solid so far.</p><div id="categoryList"><ul><li><a href="https://wiki.alopex.li/_category/writing">writing</a></li><li><a href="https://wiki.alopex.li/_category/programming">programming</a></li><li><a href="https://wiki.alopex.li/_category/languages">languages</a></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notion's mid-life crisis (195 pts)]]></title>
            <link>https://www.jjinux.com/2024/09/notions-mid-life-crisis.html</link>
            <guid>41683577</guid>
            <pubDate>Sat, 28 Sep 2024 23:14:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jjinux.com/2024/09/notions-mid-life-crisis.html">https://www.jjinux.com/2024/09/notions-mid-life-crisis.html</a>, See on <a href="https://news.ycombinator.com/item?id=41683577">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX launches mission for 2 NASA astronauts who are stuck on the ISS (286 pts)]]></title>
            <link>https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b</link>
            <guid>41683306</guid>
            <pubDate>Sat, 28 Sep 2024 22:11:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b">https://apnews.com/article/spacex-launch-boeing-nasa-stuck-astronauts-e179d0dc6c77d224278fd0430148ff8b</a>, See on <a href="https://news.ycombinator.com/item?id=41683306">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>CAPE CANAVERAL, Fla. (AP) — SpaceX <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/boeing-spacex-nasa-astronauts-starliner-e4e81e5a6c23dee2f8f72260ddea011c">launched a rescue mission</a></span> for the two stuck astronauts at the International Space Station on Saturday, sending up a downsized crew to bring them home but not until next year.</p><p>The capsule rocketed into orbit to fetch the test pilots whose <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/nasa-stuck-astronauts-boeing-starliner-92dca67a1fbecf05f5f0e6e2e79afc3b">Boeing spacecraft returned to Earth empty</a></span> earlier this month because of safety concerns. The switch in rides left it to NASA’s Nick Hague and Russia’s Alexander Gorbunov to retrieve <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/stuck-astronauts-boeing-starliner-nasa-1933b64f91ba06713e57446e2dbee1c4">Butch Wilmore and Suni Williams</a></span>. </p><p>Because NASA rotates space station crews approximately every six months, this newly launched flight with two empty seats reserved for Wilmore and Williams won’t return until late February. Officials said there wasn’t a way to bring them back earlier on SpaceX without interrupting other scheduled missions.</p><p>By the time they return, the pair will have logged more than eight months in space. They expected to be gone just a week when they signed up for Boeing’s first astronaut flight that launched in June.</p>
    

<p>NASA ultimately decided that Boeing’s Starliner was too risky after a cascade of thruster troubles and helium leaks marred its trip to the orbiting complex. The space agency cut two astronauts from this SpaceX launch to make room on the Dragon capsule’s return leg for Wilmore and Williams.</p>



<p>Wilmore and Williams watched the liftoff via a live link sent to the space station, prompting a cheer of “Go Dragon!” from Williams, NASA deputy program manager Dina Contella said.</p>
    
<p>Williams has been promoted to commander of the space station, which will soon be back to its normal population of seven. Once Hague and Gorbunov arrive on Sunday, four astronauts living there since March can leave in their own SpaceX capsule. Their homecoming was delayed a month by Starliner’s turmoil.</p><p>Hague noted before the flight that change is the one constant in human spaceflight.</p><p>“There’s always something that is changing. Maybe this time it’s been a little more visible to the public,” he said.</p>
    

<p>Hague was thrust into the commander’s job for the rescue mission based on his experience and handling of a launch emergency six years ago. The Russian rocket failed shortly after liftoff, and the capsule carrying him and a cosmonaut catapulted off the top to safety.</p><p>Rookie NASA astronaut Zena Cardman and veteran space flier Stephanie Wilson were pulled from this flight after NASA opted to go with SpaceX to bring the stuck astronauts home. Promised a future space mission, both were at NASA’s Kennedy Space Center, taking part in the launch livestream. Gorbunov remained on the flight under an exchange agreement between NASA and the Russian Space Agency.</p><p>“Every crewed launch that I have ever watched has really brought me a lot of emotion. This one today was especially unique,” a teary-eyed Cardman said following the early afternoon liftoff. “It was hard not to watch that rocket lift off without thinking, ‘That’s my rocket and that’s my crew.’ ”</p><p>Moments before liftoff, Hague paid tribute to his two colleagues left behind: “Unbreakable. We did it together.” Once in orbit, he called it a ”sweet ride” and thanked everyone who made it possible.</p>
    

<p>Earlier, Hague acknowledged the challenges of launching with half a crew and returning with two astronauts trained on another spacecraft. </p><p>“We’ve got a dynamic challenge ahead of us,” Hague said after arriving from Houston last weekend. “We know each other and we’re professionals and we step up and do what’s asked of us.”</p><p>SpaceX has long been the leader in NASA’s commercial crew program, established as the space shuttles were retiring more than a decade ago. SpaceX beat Boeing in delivering astronauts to the space station in 2020, and it is now up to 10 crew flights for NASA.</p><p>Boeing has struggled with a variety of issues over the years, repeating a Starliner test flight with no one on board after the first one veered off course. The Starliner that left Wilmore and Williams in space landed without any issues in the New Mexico desert on Sept. 6, and has since returned to Kennedy Space Center. A week ago, Boeing’s defense and space chief was replaced.</p>
    

<p>Delayed by Hurricane Helene pounding Florida, the latest SpaceX liftoff marked the first for astronauts from Launch Complex 40 at Cape Canaveral Space Force Station. SpaceX took over the old Titan rocket pad nearly two decades ago and used it for satellite and station cargo launches, while flying crews from Kennedy’s former Apollo and shuttle pad next door. The company wanted more flexibility as more Falcon rockets soared.</p><h2>___</h2><p>The Associated Press Health and Science Department receives support from the Howard Hughes Medical Institute’s Science and Educational Media Group. The AP is solely responsible for all content. </p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Discord stores trillions of messages (325 pts)]]></title>
            <link>https://discord.com/blog/how-discord-stores-trillions-of-messages</link>
            <guid>41683293</guid>
            <pubDate>Sat, 28 Sep 2024 22:07:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discord.com/blog/how-discord-stores-trillions-of-messages">https://discord.com/blog/how-discord-stores-trillions-of-messages</a>, See on <a href="https://news.ycombinator.com/item?id=41683293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="heading-1"><p>In 2017, we wrote a blog post on <a href="https://discord.com/blog/how-discord-stores-billions-of-messages">how we store billions of messages.</a> We shared our journey of how we started out using MongoDB but migrated our data to Cassandra because we were looking for a database that was scalable, fault-tolerant, and relatively low maintenance. We knew we’d be growing, and we did!</p><p>We wanted a database that grew alongside us, but hopefully, its maintenance needs wouldn’t grow alongside our storage needs. Unfortunately, we found that to not be the case — our Cassandra cluster exhibited serious performance issues that required increasing amounts of effort to just maintain, not improve.</p><p>Almost six years later, we’ve changed a lot, and how we store messages has changed as well.<br>‍</p></div><div id="heading-2"><h2>Our Cassandra Troubles</h2><p>We stored our messages in a database called cassandra-messages. As its name suggests, it ran Cassandra, and it stored messages. In 2017, we ran 12 Cassandra nodes, storing billions of messages.</p><p>At the beginning of 2022, it had 177 nodes with trillions of messages. To our chagrin, it was a high-toil system — our on-call team was frequently paged for issues with the database, latency was unpredictable, and we were having to cut down on maintenance operations that became too expensive to run.</p><p>What was causing these issues? First, let’s take a look at a message.</p><p>The CQL statement above is a minimal version of our message schema. Every ID we use is a <a href="https://blog.twitter.com/engineering/en_us/a/2010/announcing-snowflake">Snowflake</a>, making it chronologically sortable. We partition our messages by the channel they’re sent in, along with a bucket, which is a static time window. This partitioning means that, in Cassandra, all messages for a given channel and bucket will be stored together and replicated across three nodes (or whatever you’ve set the replication factor).</p><p>Within this partitioning lies a potential performance pitfall: a server with just a small group of friends tends to send orders of magnitude fewer messages than a server with hundreds of thousands of people.</p><p>In Cassandra, reads are more expensive than writes. Writes are appended to a commit log and written to an in memory structure called a memtable that is eventually flushed to disk. Reads, however, need to query the memtable and potentially multiple SSTables (on-disk files), a more expensive operation. Lots of concurrent reads as users interact with servers can hotspot a partition, which we refer to imaginatively as a “hot partition”. &nbsp;The size of our dataset when combined with these access patterns led to struggles for our cluster.</p><p>When we encountered a hot partition, it frequently affected latency across our entire database cluster. One channel and bucket pair received a large amount of traffic, and latency in the node would increase as the node tried harder and harder to serve traffic and fell further and further behind.</p><p>Other queries to this node were affected as the node couldn’t keep up. Since we perform reads and writes with quorum consistency level, all queries to the nodes that serve the hot partition suffer latency increases, resulting in broader end-user impact.</p><p>Cluster maintenance tasks also frequently caused trouble. We were prone to falling behind on compactions, where Cassandra would compact SSTables on disk for more performant reads. Not only were our reads then more expensive, but we’d also see cascading latency as a node tried to compact.</p><p>We frequently performed an operation we called the “gossip dance”, where we’d take a node out of rotation to let it compact without taking traffic, bring it back in to pick up hints from Cassandra’s hinted handoff, and then repeat until the compaction backlog was empty. We also spent a large amount of time tuning the JVM’s garbage collector and heap settings, because GC pauses would cause significant latency spikes.<br>‍</p></div><div id="heading-3"><h2>Changing Our Architecture</h2><p>Our messages cluster wasn’t our only Cassandra database. We had several other clusters, and each exhibited similar (though perhaps not as severe) faults.</p><p>In our <a href="https://discord.com/blog/how-discord-stores-billions-of-messages">previous iteration of this post</a>, we mentioned being intrigued by ScyllaDB, a Cassandra-compatible database written in C++. Its promise of better performance, faster repairs, stronger workload isolation via its shard-per-core architecture, and a garbage collection-free life sounded quite appealing.</p><p>Although ScyllaDB is most definitely not void of issues, it is void of a garbage collector, since it’s written in C++ rather than Java. Historically, our team has had many issues with the garbage collector on Cassandra, from GC pauses affecting latency, all the way to super long consecutive GC pauses that got so bad that an operator would have to manually reboot and babysit the node in question back to health. These issues were a huge source of on-call toil, and the root of many stability issues within our messages cluster.</p><p>After experimenting with ScyllaDB and observing improvements in testing, we made the decision to migrate all of our databases. While this decision could be a blog post in itself, the short version is that by 2020, we had migrated every database but one to ScyllaDB.</p><p>The last one? Our friend, cassandra-messages.</p><p>Why hadn’t we migrated it yet? To start with, it’s a big cluster. With trillions of messages and nearly 200 nodes, any migration was going to be an involved effort. Additionally, we wanted to make sure our new database could be the best it could be as we worked to tune its performance. We also wanted to gain more experience with ScyllaDB in production, using it in anger and learning its pitfalls.</p><p>We also worked to improve ScyllaDB performance for our use cases. In our testing, we discovered that the performance of reverse queries was insufficient for our needs. We execute a reverse query when we attempt a database scan in the opposite order of a table’s sorting, such as when we scan messages in ascending order. The ScyllaDB team prioritized improvements and implemented performant reverse queries, removing the last database blocker in our migration plan.</p><p>We were suspicious that slapping a new database on our system wasn’t going to make everything magically better. Hot partitions can still be a thing in ScyllaDB, and so we also wanted to invest in improving our systems upstream of the database to help shield and facilitate better database performance.<br>‍</p></div><div id="heading-4"><h2>Data Services Serving Data</h2><p>With Cassandra, we struggled with hot partitions. High traffic to a given partition resulted in unbounded concurrency, leading to cascading latency in which subsequent queries would continue to grow in latency. If we could control the amount of concurrent traffic to hot partitions, we could protect the database from being overwhelmed.</p><p>To accomplish this task, we wrote what we refer to as data services — intermediary services that sit between our API monolith and our database clusters. When writing our data services, we chose a language we’ve been using <a href="https://discord.com/blog/why-discord-is-switching-from-go-to-rust">more and more at Discord</a>: Rust! We’d used it for a few projects previously, and it lived up to the hype for us. It gave us fast C/C++ speeds without having to sacrifice safety.</p><p>Rust touts fearless concurrency as one of its main benefits — the language should make it easy to write safe, concurrent code. Its libraries also were a great match for what we were intending to accomplish. The <a href="https://tokio.rs/">Tokio ecosystem</a> is a tremendous foundation for building a system on asynchronous I/O, and the language has driver support for both Cassandra and ScyllaDB.</p><p>Additionally, we found it a joy to code in with the help the compiler gives you, the clarity of the error messages, the language constructs, and its emphasis on safety. We became quite fond of how once it compiled, it generally works. Most importantly, however, it lets us say we rewrote it in Rust (meme cred is very important).</p><p>Our data services sit between the API and our ScyllaDB clusters. They contain roughly one gRPC endpoint per database query and intentionally contain no business logic. The big feature our data services provide is request coalescing. If multiple users are requesting the same row at the same time, we’ll only query the database once. The first user that makes a request causes a worker task to spin up in the service. Subsequent requests will check for the existence of that task and subscribe to it. That worker task will query the database and return the row to all subscribers.</p><p>This is the power of Rust in action: it made it easy to write safe concurrent code.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/6406629e7ba3569d3c32c8ed_Example%201%402x.png" loading="lazy" alt=""></p></figure><p>Let’s imagine a big announcement on a large server that notifies @everyone: users are going to open the app and read the message, sending tons of traffic to the database. Previously, this might lead to a hot partition, and on-call would potentially need to be paged to help the system recover. With our data services, we’re able to significantly reduce traffic spikes against the database.</p><p>The second part of the magic here is upstream of our data services. We implemented consistent hash-based routing to our data services to enable more effective coalescing. For each request to our data service, we provide a routing key. For messages, this is a channel ID, so all requests for the same channel go to the same instance of the service. This routing further helps reduce the load on our database.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/640662a51e3e13599d292404_Example%202%402x.png" loading="lazy" alt=""></p></figure><p>These improvements help a lot, but they don’t solve all of our problems. We’re still seeing hot partitions and increased latency on our Cassandra cluster, just not quite as frequently. It buys us some time so that we can prepare our new optimal ScyllaDB cluster and execute the migration.<br>‍</p></div><div id="heading-5"><h2>A Very Big Migration</h2><p>Our requirements for our migration are quite straightforward: we need to migrate trillions of messages with no downtime, and we need to do it quickly because while the Cassandra situation has somewhat improved, we’re frequently firefighting.</p><p>Step one is easy: we provision a new ScyllaDB cluster using our <a href="https://discord.com/blog/how-discord-supercharges-network-disks-for-extreme-low-latency">super-disk storage topology</a>. By using Local SSDs for speed and leveraging RAID to mirror our data to a persistent disk, we get the speed of attached local disks with the durability of a persistent disk. With our cluster stood up, we can begin migrating data into it.</p><p>Our first draft of our migration plan was designed to get value quickly. We’d start using our shiny new ScyllaDB cluster for newer data using a cutover time, and then migrate historical data behind it. It adds more complexity, but what every large project needs is additional complexity, right?</p><p>We begin dual-writing new data to Cassandra and ScyllaDB and concurrently begin to provision ScyllaDB’s Spark migrator. It requires a lot of tuning, and once we get it set up, we have an estimated time to completion: three months.</p><p>That timeframe doesn’t make us feel warm and fuzzy inside, and we’d prefer to get value faster. We sit down as a team and brainstorm ways we can speed things up, until we remember that we’ve written a fast and performant database library that we could potentially extend. We elect to engage in some meme-driven engineering and rewrite the data migrator in Rust.</p><p>In an afternoon, we extended our data service library to perform large-scale data migrations. It reads token ranges from a database, checkpoints them locally via SQLite, and then firehoses them into ScyllaDB. We hook up our new and improved migrator and get a new estimate: nine days! If we can migrate data this quickly, then we can forget our complicated time-based approach and instead flip the switch for everything at once.</p><p>We turn it on and leave it running, migrating messages at speeds of up to 3.2 million per second. Several days later, we gather to watch it hit 100%, and we realize that it’s stuck at 99.9999% complete (no, really). Our migrator is timing out reading the last few token ranges of data because they contain gigantic ranges of tombstones that were never compacted away in Cassandra. We compact that token range, and seconds later, the migration is complete!</p><p>We performed automated data validation by sending a small percentage of reads to both databases and comparing results, and everything looked great. The cluster held up well with full production traffic, whereas Cassandra was suffering increasingly frequent latency issues. We gathered together at our team onsite, flipped the switch to make ScyllaDB the primary database, and ate celebratory cake!<br>‍</p></div><div id="heading-6"><h2>Several Months Later…</h2><p>We switched our messages database over in May 2022, but how’s it held up since then?</p><p>It’s been a quiet, well-behaved database (it’s okay to say this because I’m not on-call this week). We’re not having weekend-long firefights, nor are we juggling nodes in the cluster to attempt to preserve uptime. It’s a much more efficient database — we’re going from running 177 Cassandra nodes to just 72 ScyllaDB nodes. Each ScyllaDB node has 9 TB of disk space, up from the average of 4 TB per Cassandra node.</p><p>Our tail latencies have also improved drastically. For example, fetching historical messages had a p99 of between 40-125ms on Cassandra, with ScyllaDB having a nice and chill 15ms p99 latency, and message insert performance going from 5-70ms p99 on Cassandra, to a steady 5ms p99 on ScyllaDB. Thanks to the aforementioned performance improvements, we’ve unlocked new product use cases now that we have confidence in our messages database.</p><p>At the end of 2022, people all over the world tuned in to watch the World Cup. One thing we discovered very quickly was that goals scored showed up in our monitoring graphs. This was very cool because not only is it neat to see real-world events show up in your systems, but this gave our team an excuse to watch soccer during meetings. We weren’t “watching soccer during meetings”, we were “proactively monitoring our systems’ performance.”</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/6406587246a8ce1cfe8f105f_Screen%20Shot%202023-02-27%20at%205.44.56%20PM.png" loading="lazy" alt=""></p></figure><p>We can actually tell the story of the World Cup Final via our message send graph. The match was tremendous. Lionel Messi was trying to check off the last accomplishment in his career and cement his claim to being the greatest of all time and lead Argentina to the championship, but in his way stood the massively talented Kylian Mbappe and France.</p><p>Each of the nine spikes in this graph represents an event in the match.</p><ol role="list"><li>Messi hits a penalty, and Argentina goes up 1-0.</li><li>Argentina scores again and goes up 2-0.</li><li>It’s halftime. There’s a sustained fifteen-minute plateau as users chat about the match.</li><li>The big spike here is because Mbappe scores for France and scores again 90 seconds later to tie it up!</li><li>It’s the end of regulation, and this huge match is going to extra time.</li><li>Not much happens in the first half of extra time, but we reach halftime and users are chatting.</li><li>Messi scores again, and Argentina takes the lead!</li><li>Mbappe strikes back to tie it up!</li><li>It’s the end of extra time, we’re heading to penalty kicks!</li><li>Excitement and stress grow throughout the shootout until France misses and Argentina doesn’t! Argentina wins!</li></ol><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/64065884c4a34e2bcb7b470d_Screen%20Shot%202023-02-27%20at%205.52.07%20PM.png" loading="lazy" alt=""></p><figcaption>Coalesced messages per second</figcaption></figure><p>People all over the world are stressed watching this incredible match, but meanwhile, Discord and the messages database aren’t breaking a sweat. We’re way up on message sends and handling it perfectly. &nbsp;With our Rust-based data services and ScyllaDB, we’re able to shoulder this traffic and provide a platform for our users to communicate.</p><p>We’ve built a system that can handle trillions of messages, and if this work is something that excites you, <a href="https://discord.com/careers">check out our careers page</a>. We’re hiring!<br>‍</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: htmgo - build simple and scalable systems with golang + htmx (108 pts)]]></title>
            <link>https://htmgo.dev</link>
            <guid>41683144</guid>
            <pubDate>Sat, 28 Sep 2024 21:34:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://htmgo.dev">https://htmgo.dev</a>, See on <a href="https://news.ycombinator.com/item?id=41683144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>introduction:</strong></p>
<p>htmgo is a lightweight pure go way to build interactive websites / web applications using go &amp; htmx.</p>
<p>By combining the speed &amp; simplicity of go + hypermedia attributes (<a href="https://htmx.org/">htmx</a>) to add interactivity to websites, all conveniently wrapped in pure go, you can build simple, fast, interactive websites without touching javascript. All compiled to a <strong>single deployable binary</strong>.</p>
<pre tabindex="0"><code><span><span><span>func</span> <span>IndexPage</span>(ctx <span>*</span>h.RequestContext) <span>*</span>h.Page {
</span></span><span><span>  now <span>:=</span> time.<span>Now</span>()
</span></span><span><span>  <span>return</span> h.<span>NewPage</span>(
</span></span><span><span>    h.<span>Div</span>(
</span></span><span><span>      h.<span>Class</span>(<span>"flex gap-2"</span>),
</span></span><span><span>      h.<span>TextF</span>(<span>"the current time is %s"</span>, now.<span>String</span>())
</span></span><span><span>    )
</span></span><span><span>  )
</span></span><span><span>}
</span></span></code></pre><p><strong>core features:</strong></p>
<ol>
<li>deployable single binary</li>
<li>live reload (rebuilds css, go, ent schema, and routes upon change)</li>
<li>automatic page and partial registration based on file path</li>
<li>built in tailwindcss support, no need to configure anything by default</li>
<li>plugin architecture to include optional plugins to streamline development, such as <a href="http://entgo.io/">http://entgo.io</a></li>
<li>custom <a href="https://github.com/maddalax/htmgo/tree/b610aefa36e648b98a13823a6f8d87566120cfcc/framework/assets/js/htmxextensions">htmx extensions</a> to reduce boilerplate with common tasks</li>
</ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Britain buys semiconductor factory for defence purposes (190 pts)]]></title>
            <link>https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/</link>
            <guid>41683098</guid>
            <pubDate>Sat, 28 Sep 2024 21:23:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/">https://ukdefencejournal.org.uk/britain-buys-semiconductor-factory-for-defence-purposes/</a>, See on <a href="https://news.ycombinator.com/item?id=41683098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3>The UK government has acquired a semiconductor factory in Newton Aycliffe, County Durham, in a move to strengthen the defence supply chain and support the Armed Forces.</h3><p><strong>This facility is the only secure site in the UK capable of manufacturing gallium arsenide semiconductors, a vital component in military platforms such as fighter jets.</strong></p><p>Defence Secretary John Healey visited the site, which was previously owned by Coherent Inc. and will now be known as Octric Semiconductors UK. The acquisition is expected to secure up to 100 skilled jobs in the North East and safeguard a critical part of the UK’s defence infrastructure.</p><p><em>“Semiconductors are at the forefront of the technology we rely upon today, and will be crucial in securing our military’s capabilities for tomorrow.</em><br> <em>This acquisition is a clear signal that our government will back British defence production. We’ll protect and grow our UK Defence supply chain, supporting North East jobs, safeguarding crucial tech for our Armed Forces and boosting our national security.”</em></p><p>Semiconductors are an essential component of modern electronics, from phones and computers to military applications. The government has stated that this acquisition will enhance the UK’s defence capabilities and increase its industrial capacity, with plans to invest further in the facility over the coming years.</p><p>The acquisition comes ahead of an Investment Summit aimed at strengthening the UK’s trading relations and supporting high-quality jobs at home.</p><p>With global semiconductor demand rising, this move positions the UK to meet future technological needs, including advancements in artificial intelligence, quantum technologies, and 6G.</p><h3>Background</h3><p>In 2023, Coherent, the former owner of the Newton Aycliffe semiconductor facility, announced plans to cut over 100 jobs due to a drop in business demand, leaving the future of the site in doubt. With the facility’s long history of ownership changes since it first opened in 1991, there were growing concerns about whether it could continue producing the crucial semiconductor components needed for industries like defence and aerospace.</p><p>The recent government acquisition is a key move to secure the future of this vital facility. By stepping in, the government is protecting jobs and ensuring the production of important semiconductors used in military applications, such as boosting fighter jet capabilities. This not only stabilises the plant after last year’s uncertainty but also strengthens the UK’s ability to maintain control over critical technology in the defence sector.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse-engineering a three-axis attitude indicator from the F-4 fighter plane (185 pts)]]></title>
            <link>http://www.righto.com/2024/09/f4-attitude-indicator.html</link>
            <guid>41681514</guid>
            <pubDate>Sat, 28 Sep 2024 17:05:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.righto.com/2024/09/f4-attitude-indicator.html">http://www.righto.com/2024/09/f4-attitude-indicator.html</a>, See on <a href="https://news.ycombinator.com/item?id=41681514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-3021491939457609983" itemprop="description articleBody">
<p>We recently received an attitude indicator for the F-4 fighter plane, an instrument that
uses a rotating ball to show the aircraft's orientation and direction.
In a normal aircraft, the artificial horizon shows the orientation in two axes (pitch and roll), but the F-4 indicator
uses a rotating ball to show the orientation in three axes, adding azimuth (yaw).<span id="fnref:fdai"><a href="#fn:fdai">1</a></span>
It wasn't obvious to me how the ball could rotate in three axes: how could it turn in every direction and still remain
attached to the instrument?</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/indicator.jpg"><img alt="The attitude indicator. The &quot;W&quot; forms a stylized aircraft. In this case, it indicates that the aircraft is climbing slightly. Photo from CuriousMarc." height="472" src="https://static.righto.com/images/f4-attitude-indicator/indicator-w450.jpg" title="The attitude indicator. The &quot;W&quot; forms a stylized aircraft. In this case, it indicates that the aircraft is climbing slightly. Photo from CuriousMarc." width="450"></a></p><p>The attitude indicator. The "W" forms a stylized aircraft. In this case, it indicates that the aircraft is climbing slightly. Photo from CuriousMarc.</p>
<p>We disassembled the indicator, reverse-engineered its 1960s-era circuitry, fixed some problems,<span id="fnref:problems"><a href="#fn:problems">2</a></span> and
got it spinning. The video clip below shows the indicator rotating around three axes.
In this blog post, I discuss the mechanical and electrical construction of this indicator.
(The quick explanation is that the ball is really two hollow half-shells attached to the internal mechanism at the "poles"; the shells rotate while the "equator" remains stationary.)</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/uKzj5shVtlo?si=l9hPqevRy1niHm28" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<h2>The F-4 aircraft</h2>
<p>The indicator was used in the F-4 Phantom II<span id="fnref:phantom-ii"><a href="#fn:phantom-ii">3</a></span>
so the pilot could keep track of the aircraft's orientation during high-speed maneuvers.
The F-4 was a supersonic fighter manufactured from 1958 to 1981.
Over 5000 were produced, making it the most-produced American supersonic aircraft ever.
It was the main US fighter jet in the Vietnam War, operating from aircraft carriers.
The F-4 was still used in the 1990s during the Gulf War,
suppressing air defenses in the "Wild Weasel" role.
The F-4 was capable of carrying nuclear bombs.<span id="fnref:nuclear"><a href="#fn:nuclear">4</a></span></p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/phantom.jpg"><img alt="An F-4G Phantom II Wild Weasel aircraft. From National Archives." height="215" src="https://static.righto.com/images/f4-attitude-indicator/phantom-w500.jpg" title="An F-4G Phantom II Wild Weasel aircraft. From National Archives." width="500"></a></p>
<p>The F-4 was a two-seat aircraft, with the radar intercept office controlling radar and weapons
from a seat behind the pilot.
Both cockpits had a panel crammed with instruments, with additional instruments and controls on the sides.
As shown below, the pilot's panel had the three-axis attitude indicator in the central position, just below the reddish radar scope, reflecting its importance.<span id="fnref:standby"><a href="#fn:standby">5</a></span>
(The rear cockpit had a simpler two-axis attitude indicator.)</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/cockpit2.jpg"><img alt="The cockpit of the F-4C Phantom II, with the attitude indicator in the center of the panel. Click this photo (or any other) for a larger version. Photo from National Museum of the USAF." height="359" src="https://static.righto.com/images/f4-attitude-indicator/cockpit2-w500.jpg" title="The cockpit of the F-4C Phantom II, with the attitude indicator in the center of the panel. Click this photo (or any other) for a larger version. Photo from National Museum of the USAF." width="500"></a></p><p>The cockpit of the F-4C Phantom II, with the attitude indicator in the center of the panel. Click this photo (or any other) for a larger version. Photo from <a href="https://www.nationalmuseum.af.mil/Visit/Museum-Exhibits/Fact-Sheets/Display/Article/196051/mcdonnell-douglas-f-4c-phantom-ii/">National Museum of the USAF</a>.</p>
<h2>The attitude indicator mechanism</h2>
<p>The ball inside the indicator shows the aircraft's position in three axes.
The roll axis indicates the aircraft's angle if it rolls side-to-side along its axis of flight.
The pitch axis indicates the aircraft's angle if it pitches up or down.
Finally, the azimuth axis indicates the compass direction that the aircraft is heading,
changed by the aircraft's turning left or right (yaw).
The indicator also has moving needles and status flags, but in this post I'm focusing
on the rotating ball.<span id="fnref:features"><a href="#fn:features">6</a></span></p>
<p>The indicator uses three motors to move the ball.
The roll motor (below) is attached to the frame of the indicator, while the pitch and azimuth motors are
inside the ball.
The ball is held in place by the roll gimbal, which is attached to the ball mechanism at the top
and bottom pivot points.
The roll motor turns the roll gimbal and thus the ball, providing a clockwise/counterclockwise
movement.
The roll control transformer provides position feedback.
Note the numerous wires on the roll gimbal, connected to the mechanism inside the ball.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/indicator-diagram.jpg"><img alt="The attitude indicator with the cover removed." height="572" src="https://static.righto.com/images/f4-attitude-indicator/indicator-diagram-w700.jpg" title="The attitude indicator with the cover removed." width="700"></a></p><p>The attitude indicator with the cover removed.</p>
<p>The diagram below shows the mechanism inside the ball, after removing the hemispherical
shells of the ball.
When the roll gimbal is rotated, this mechanism rotates with it.
The pitch motor causes the entire mechanism to rotate around the pitch axis (horizontal here), which is attached along the "equator".
The azimuth motor and control transformer are behind the pitch components, not visible in this photo.
The azimuth motor turns the vertical shaft.
The two hollow hemispheres of the ball attach to the top and bottom of the shaft.
Thus, the azimuth motor rotates the ball shells around the azimuth axis, while the mechanism itself
remains stationary.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/mechanism-diagram.jpg"><img alt="The components of the ball mechanism." height="537" src="https://static.righto.com/images/f4-attitude-indicator/mechanism-diagram-w700.jpg" title="The components of the ball mechanism." width="700"></a></p><p>The components of the ball mechanism.</p>
<p>Why doesn't the wiring get tangled up as the ball rotates?
The solution is two sets of slip rings to implement the electrical connections.
The photo below shows the first slip ring assembly, which handles rotation around the roll axis.
These slip rings connect the stationary part of the instrument to the
rotating roll gimbal.
The black base and the vertical wires are attached to the instrument,
while the striped shaft in the middle rotates with the ball assembly housing.
Inside the shaft, wires go from the circular metal contacts to
the roll gimbal.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/sliprings.jpg"><img alt="The first set of slip rings. Yes, there is damage on one of the slip ring contacts." height="339" src="https://static.righto.com/images/f4-attitude-indicator/sliprings-w500.jpg" title="The first set of slip rings. Yes, there is damage on one of the slip ring contacts." width="500"></a></p><p>The first set of slip rings. Yes, there is damage on one of the slip ring contacts.</p>
<p>Inside the ball, a second set of slip rings
provides the electrical connection between the
wiring on the roll gimbal and the ball mechanism.
The photo below shows the connections to these slip rings, handling rotation around
the pitch axis (horizontal in this photo).
(The slip rings themselves are inside and are not visible.)
The shaft sticking out of the assembly rotates around the azimuth (yaw) axis. The ball hemisphere is attached to the metal disk.
The azimuth axis does not require slip rings since only the ball shells rotates; the electronics remain stationary.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/sliprings2.jpg"><img alt="Connections for the second set of slip rings." height="327" src="https://static.righto.com/images/f4-attitude-indicator/sliprings2-w350.jpg" title="Connections for the second set of slip rings." width="350"></a></p><p>Connections for the second set of slip rings.</p>
<h2>The servo loop</h2>
<p>In this section, I'll explain how the motors are controlled by servo loops.
The attitude indicator is driven by an external gyroscope, receiving electrical signals indicating the roll, pitch, and azimuth positions.
As was common in 1960s avionics, the signals are transmitted from synchros, which use three wires to indicate an angle.
The motors inside the attitude indicator rotate until the indicator's angles for the three axes match the input angles.</p>
<p>Each motor is controlled by a servo loop, shown below.
The goal is to rotate the output shaft to an angle that exactly matches the input angle,
specified by the three synchro wires.
The key is a device called a control transformer, which takes the three-wire input angle and a physical shaft rotation, and
generates an error signal indicating the difference between the desired angle and the physical angle.
The amplifier drives the motor in the appropriate direction until the error signal drops to zero.
To improve the dynamic response of the servo loop, the tachometer signal is used as a negative feedback voltage.
This ensures that the motor slows as the system gets closer to the right position, so the motor doesn't overshoot the position and oscillate.
(This is sort of like a PID controller.)</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/servo-diagram.jpg"><img alt="This diagram shows the structure of the servo loop, with a feedback loop ensuring that the rotation angle of the output shaft matches the input angle." height="228" src="https://static.righto.com/images/f4-attitude-indicator/servo-diagram-w600.jpg" title="This diagram shows the structure of the servo loop, with a feedback loop ensuring that the rotation angle of the output shaft matches the input angle." width="600"></a></p><p>This diagram shows the structure of the servo loop, with a feedback loop ensuring that the rotation angle of the output shaft matches the input angle.</p>
<p>In more detail, the external gyroscope unit contains synchro transmitters, small devices that convert the angular position of a shaft
into AC signals on three wires.
The photo below shows a typical synchro, with the input shaft on the top and five wires
at the bottom: two for power and three for the output.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/synchro.jpg"><img alt="A synchro transmitter." height="324" src="https://static.righto.com/images/f4-attitude-indicator/synchro-w200.jpg" title="A synchro transmitter." width="200"></a></p><p>A synchro transmitter.</p>
<p>Internally, the synchro has a rotating winding called the rotor that is driven with 400 Hz AC.
Three fixed stator windings provide the three AC output signals. As the shaft rotates, the phase and voltage of the
output signals changes, indicating the angle.
(Synchros may seem bizarre, but they were extensively used in the 1950s and 1960s to
transmit angular information in ships and aircraft.)</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/synchro-schematic.png"><img alt="The schematic symbol for a synchro transmitter or receiver." height="240" src="https://static.righto.com/images/f4-attitude-indicator/synchro-schematic-w250.png" title="The schematic symbol for a synchro transmitter or receiver." width="250"></a></p><p>The schematic symbol for a synchro transmitter or receiver.</p>
<p>The attitude indicator uses control transformers to process these input signals.
A control transformer is similar to a synchro in appearance and construction, but it is wired differently.
The three stator windings receive the inputs and the rotor winding provides the error output.
If the rotor angle of the synchro transmitter and control transformer are the same, the signals cancel out and there is
no error output.
But as the difference between the two shaft angles increases, the rotor winding produces an error signal. The phase of the
error signal indicates the direction of error.</p>
<p>The next component is the motor/tachometer, a special motor that was often used in avionics servo loops.
This motor is more complicated than a regular electric motor.
The motor is powered by 115 volts AC, 400-Hertz, but this isn't sufficient to get the motor spinning.
The motor also has two low-voltage AC control windings. Energizing a control winding will cause the
motor to spin in one direction or the other.</p>
<p>The motor/tachometer unit also contains a tachometer to measure its rotational speed, for use in a feedback loop.
The tachometer is driven by another 115-volt AC winding and generates a low-voltage AC signal proportional to the rotational speed
of the motor.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/motor-disassembled.jpg"><img alt="A motor/tachometer similar (but not identical) to the one in the attitude indicator)." height="262" src="https://static.righto.com/images/f4-attitude-indicator/motor-disassembled-w500.jpg" title="A motor/tachometer similar (but not identical) to the one in the attitude indicator)." width="500"></a></p><p>A motor/tachometer similar (but not identical) to the one in the attitude indicator).</p>
<p>The photo above shows a motor/tachometer with the rotor removed.
The unit has many wires because of its multiple windings.
The rotor has two drums. The drum on the left, with the spiral stripes, is for the motor. This drum is a "squirrel-cage rotor",
which spins due to induced currents.
(There are no electrical connections to the rotor; the drums interact with the windings through magnetic fields.)
The drum on the right is the tachometer rotor; it induces a signal in the output winding proportional to the speed due to eddy currents.
The tachometer signal is at 400 Hz like the driving signal, either in phase or 180º out of phase, depending on the direction
of rotation.
For more information on how a motor/generator works, see my <a href="https://www.righto.com/2024/02/bendix-cadc-servomotor-tachometer.html">teardown</a>.</p>
<h2>The amplifier</h2>
<p>The motors are powered by an amplifier assembly that contains three separate error amplifiers,
one for each axis.
I had to reverse engineer the amplifier assembly in order to get the indicator working.
The assembly mounts on the back of the attitude indicator and connects to one of the
indicator's round connectors. Note the cutout in the lower left of the amplifier assembly to
provide access to the second connector on the back of the indicator.
The aircraft connects to the indicator through
the second connector and the indicator passes the input signals to the amplifier through
the connector shown above.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/amplifier-unit.jpg"><img alt="The amplifier assembly." height="451" src="https://static.righto.com/images/f4-attitude-indicator/amplifier-unit-w450.jpg" title="The amplifier assembly." width="450"></a></p><p>The amplifier assembly.</p>
<p>The amplifier assembly contains three amplifier boards (for roll, pitch, and azimuth),
a DC power supply board, an AC transformer,
and a trim potentiometer.<span id="fnref:supply"><a href="#fn:supply">7</a></span>
The photo below shows the amplifier assembly mounted on the back of the instrument.
At the left, the AC transformer produces the motor control voltage and powers the power supply board,
mounted vertically on the right.
The assembly has three identical amplifier boards; the middle board has been unmounted to show the components.
The amplifier connects to the instrument through a round connector below the transformer.
The round connector at the upper left is on the instrument case (not the amplifier) and provides the connection between the
aircraft and the instrument.<span id="fnref:case-connector"><a href="#fn:case-connector">8</a></span></p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/amplifier-mounted.jpg"><img alt="The amplifier assembly mounted on the back of the instrument. We are feeding test signals to the connector in the upper left." height="600" src="https://static.righto.com/images/f4-attitude-indicator/amplifier-mounted-w450.jpg" title="The amplifier assembly mounted on the back of the instrument. We are feeding test signals to the connector in the upper left." width="450"></a></p><p>The amplifier assembly mounted on the back of the instrument. We are feeding test signals to the connector in the upper left.</p>
<p>The photo below shows one of the three amplifier boards. The construction is unusual, with some components stacked on top of
other components to save space.
Some of the component leads are long and protected with clear plastic sleeves.
The board is connected to the rest of the amplifier assembly through a bundle of point-to-point wires, visible on the left.
The round pulse transformer in the middle has five colorful wires coming out of it.
At the right are the two transistors that drive the motor's control windings, with two capacitors between them.
The transistors are mounted on a heat sink that is screwed down to the case of the amplifier assembly for cooling.
The board is covered with a conformal coating to protect it from moisture or contaminants.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/amplifier-board.jpg"><img alt="One of the three amplifier boards." height="344" src="https://static.righto.com/images/f4-attitude-indicator/amplifier-board-w500.jpg" title="One of the three amplifier boards." width="500"></a></p><p>One of the three amplifier boards.</p>
<p>The function of each amplifier board is to generate the two control signals so the motor rotates in the appropriate direction
based on the error signal fed into the amplifier.
The amplifier also uses the tachometer output from the motor unit to slow the motor as the error signal decreases, preventing
overshoot.
The inputs to the amplifier are 400 hertz AC signals, with the phase indicating positive or negative error.
The outputs drive the two control windings of the motor, determining which direction the motor rotates.</p>
<p>The schematic for the amplifier board is below. 
The two transistors on the left amplify the error and tachometer signals, driving the pulse transformer.
The outputs of the pulse transformer will have opposite phase, driving the output transistors for opposite halves of
the 400 Hz cycle.
One of the transistors will be in the right phase to turn on and pull the motor control AC to ground, while the other
transistor will be in the wrong phase.
Thus, the appropriate control winding will be activated (for half the cycle), causing the motor to spin in the desired direction.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/amplifier-schematic.jpg"><img alt="Schematic of one of the three amplifier boards. (Click for a larger version.)" height="354" src="https://static.righto.com/images/f4-attitude-indicator/amplifier-schematic-w600.jpg" title="Schematic of one of the three amplifier boards. (Click for a larger version.)" width="600"></a></p><p>Schematic of one of the three amplifier boards. (Click for a larger version.)</p>
<p>It turns out that there are two versions of the attitude indicator that use incompatible amplifiers.
I think that the motors for the newer indicators have a single control winding rather than two.
Fortunately, the connectors are keyed differently so you can't attach the wrong amplifier.
The second amplifier (below) looks slightly more modern (1980s) with a double-sided circuit board and more components in place of the
pulse transformer.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/amplifier2.jpg"><img alt="The second type of amplifier board." height="449" src="https://static.righto.com/images/f4-attitude-indicator/amplifier2-w500.jpg" title="The second type of amplifier board." width="500"></a></p><p>The second type of amplifier board.</p>
<h2>The pitch trim circuit</h2>
<p>The attitude indicator has a pitch trim knob in the lower right, although the knob was missing from ours.
The pitch trim adjustment turns out to be rather complicated.
In level flight, an aircraft may have its nose angled up or down slightly to achieve the desired angle of attack.
The pilot wants the attitude indicator to show level flight, even though the aircraft is slightly angled, so the indicator can be
adjusted with the pitch trim knob.
However, the problem is that a fighter plane may, for instance, do a vertical 90º climb. In this case, the attitude indicator
should show the actual attitude and ignore the pitch trim adjustment.</p>
<p>I found a <a href="https://patents.google.com/patent/US2941305A">1957 patent</a> that explained how this is implemented.
The solution is to "fade out" the trim adjustment when the aircraft moves away from horizontal flight.
This is implemented with a special multi-zone potentiometer that is controlled by the pitch angle.</p>
<p>The schematic below shows how the pitch trim signal is generated from the special pitch angle potentiometer and the
pilot's pitch trim adjustment.
Like most signals in the attitude indicator, the pitch trim is a 400 Hz AC signal, with the phase indicating positive or
negative.
Ignoring the pitch angle for a moment, the drive signal into the transformer will be AC.
The split windings of the transformer will generate a positive phase and a negative phase signal. Adjusting the pitch
trim potentiometer lets the pilot vary the trim signal from positive to zero to negative, applying the desired correction to
the indicator.</p>
<p><a href="https://static.righto.com/images/f4-attitude-indicator/pitch-trim.jpg"><img alt="The pitch trim circuit. Based on the patent." height="226" src="https://static.righto.com/images/f4-attitude-indicator/pitch-trim-w600.jpg" title="The pitch trim circuit. Based on the patent." width="600"></a></p><p>The pitch trim circuit. Based on <a href="https://patents.google.com/patent/US2941305A">the patent</a>.</p>
<p>Now, look at the complex pitch angle potentiometer. It has alternating resistive and conducting segments, with AC fed into opposite
sides. (Note that +AC and -AC refer to the phase, not the voltage.) Because the resistances are equal, the AC signals will cancel out at the top and the bottom, yielding 0 volts on those segments.
If the aircraft is roughly horizontal, the potentiometer wiper will pick up the positive-phase AC and feed it into the
transformer, providing the desired trim adjustment as described previously.
However, if the aircraft is climbing nearly vertically, the wiper will pick up the 0-volt signal, so there will be no
pitch trim adjustment.
For an angle range in between, the resistance of the potentiometer will cause the pitch trim signal to smoothly fade out.
Likewise, if the aircraft is steeply diving, the wiper will pick up the 0 signal at the bottom, removing the pitch trim.
And if the aircraft is inverted, the wiper will pick up the negative AC phase, causing the pitch trim adjustment to be
applied in the opposite direction.</p>
<h2>Conclusions</h2>
<p>The attitude indicator is a key instrument in any aircraft, especially important when
flying in low visibility.
The F-4's attitude indicator goes beyond the artificial horizon indicator in a typical
aircraft, adding a third axis to show the aircraft's heading.
Supporting a third axis makes the instrument much more complicated, though.
Looking inside the indicator reveals how the ball rotates in three axes while still remaining
firmly attached.</p>
<p>Modern fighter planes avoid complex electromechanical instruments. Instead, they
provide a "glass cockpit" with most data provided digitally on screens.
For instance, the F-35's console replaces all the instruments with a wide <a href="https://www.militaryaerospace.com/sensors/article/14276510/panoramic-display-f-35-cockpit-avionics">panoramic touchscreen</a> displaying the
desired information in color.
Nonetheless, mechanical instruments have a special charm, despite their impracticality.</p>
<p>For more, follow me on
Mastodon as <a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="274c4249544f4e55554e414167484b43455e534254095457464442">[email&nbsp;protected]</span></a>
or <a href="http://www.righto.com/feeds/posts/default">RSS</a>. (I've given up on Twitter.)
I worked on this project with CuriousMarc and Eric Schlapfer, so expect a
video at some point. Thanks to John Pumpkinhead and another collector for supplying the indicators
 and amplifiers.</p>
<h2>Notes and references</h2>
<p>Specifications<span id="fnref:specifications"><a href="#fn:specifications">9</a></span></p>
<!-- Lots of cockpit info: http://aviation.watergeek.eu/f4j-panel.html -->



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[REPL for Dart (103 pts)]]></title>
            <link>https://github.com/fzyzcjy/dart_interactive</link>
            <guid>41681284</guid>
            <pubDate>Sat, 28 Sep 2024 16:33:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/fzyzcjy/dart_interactive">https://github.com/fzyzcjy/dart_interactive</a>, See on <a href="https://news.ycombinator.com/item?id=41681284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://github.com/fzyzcjy/dart_interactive">dart_interactive</a></h2><a id="user-content-dart_interactive" aria-label="Permalink: dart_interactive" href="#dart_interactive"></a></p>
<p dir="auto"><a href="https://pub.dev/packages/interactive" rel="nofollow"><img src="https://camo.githubusercontent.com/26b69028358139b1825003682b906b06613a936b3fa2abbff859e44d4b203393/68747470733a2f2f696d672e736869656c64732e696f2f7075622f762f696e7465726163746976652e737667" alt="Flutter Package" data-canonical-src="https://img.shields.io/pub/v/interactive.svg"></a>
<a href="https://github.com/fzyzcjy/dart_interactive/actions/workflows/ci.yaml"><img src="https://github.com/fzyzcjy/dart_interactive/actions/workflows/ci.yaml/badge.svg" alt="CI"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/fzyzcjy/dart_interactive/master/doc/logo.svg"><img src="https://raw.githubusercontent.com/fzyzcjy/dart_interactive/master/doc/logo.svg" alt=""></a></p>
<p dir="auto">A lot of sibling languages have a REPL, and is quite helpful in everyday usage, while Dart did not have it (even though it was the <a href="https://github.com/dart-lang/sdk/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc">7th</a> highest-voted request). So here it comes!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Features</h2><a id="user-content--features" aria-label="Permalink: 🚀 Features" href="#-features"></a></p>
<p dir="auto">A full-featured REPL (interactive shell), with:</p>
<ul dir="auto">
<li>Use any third-party package freely</li>
<li>Auto hot-reload code anywhere, with state preserved</li>
<li>Supports full grammar in REPL</li>
<li>Play with existing code side-by-side</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Demo</h2><a id="user-content--demo" aria-label="Permalink: 📚 Demo" href="#-demo"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Demo 1: Demonstrate features</h3><a id="user-content-demo-1-demonstrate-features" aria-label="Permalink: Demo 1: Demonstrate features" href="#demo-1-demonstrate-features"></a></p>
<ol dir="auto">
<li>Use 3rd party package</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content=">>> !dart pub add path // normal shell command
>>> import 'package:path/path.dart'; // normal import
>>> join('directory', 'file.txt') // use it (`join` is a function in 3rd party package `path`)
directory/file.txt"><pre><span>&gt;&gt;&gt;</span> <span>!</span>dart pub add path <span>// normal shell command</span>
<span>&gt;&gt;&gt;</span> import <span>'package:path/path.dart'</span>; <span>// normal import</span>
<span>&gt;&gt;&gt;</span> <span>join</span>(<span>'directory'</span>, <span>'file.txt'</span>) <span>// use it (`join` is a function in 3rd party package `path`)</span>
directory<span>/</span>file.txt</pre></div>
<ol start="2" dir="auto">
<li>Auto hot-reload</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content=">>> import 'a.dart';
>>> myFunc()
hello, tom
// ... change content of `a.dart` ...
>>> myFunc()
hello, alex"><pre><span>&gt;&gt;&gt;</span> import <span>'a.dart'</span>;
<span>&gt;&gt;&gt;</span> <span>myFunc</span>()
hello, tom
<span>// ... change content of `a.dart` ...</span>
<span>&gt;&gt;&gt;</span> <span>myFunc</span>()
hello, alex</pre></div>
<ol start="3" dir="auto">
<li>Support full grammar</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content=">>> a = 10;
// support rich grammar
>>> int g() => a++; class A {} class B {}
... class C extends A implements B {
...   int b = 20;
...   int f() { int c = 30; a++; b++; c++; return a+b+c+g(); }
... }
>>> c = C()
>>> c.f()
74
// support redefine class/method/...
>>> class C extends A implements B { int b = 20; int f() => b; }
>>> c.f()
21"><pre><span>&gt;&gt;&gt;</span> a <span>=</span> <span>10</span>;
<span>// support rich grammar</span>
<span>&gt;&gt;&gt;</span> <span>int</span> <span>g</span>() <span>=&gt;</span> a<span>++</span>; <span>class</span> <span>A</span> {} <span>class</span> <span>B</span> {}
... <span>class</span> <span>C</span> <span>extends</span> <span>A</span> <span>implements</span> <span>B</span> {
...   <span>int</span> b <span>=</span> <span>20</span>;
...   <span>int</span> <span>f</span>() { <span>int</span> c <span>=</span> <span>30</span>; a<span>++</span>; b<span>++</span>; c<span>++</span>; <span>return</span> a<span>+</span>b<span>+</span>c<span>+</span><span>g</span>(); }
... }
<span>&gt;&gt;&gt;</span> c <span>=</span> <span>C</span>()
<span>&gt;&gt;&gt;</span> c.<span>f</span>()
<span>74</span>
<span>// support redefine class/method/...</span>
<span>&gt;&gt;&gt;</span> <span>class</span> <span>C</span> <span>extends</span> <span>A</span> <span>implements</span> <span>B</span> { <span>int</span> b <span>=</span> <span>20</span>; <span>int</span> <span>f</span>() <span>=&gt;</span> b; }
<span>&gt;&gt;&gt;</span> c.<span>f</span>()
<span>21</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Demo 2: Sample workflow</h3><a id="user-content-demo-2-sample-workflow" aria-label="Permalink: Demo 2: Sample workflow" href="#demo-2-sample-workflow"></a></p>
<p dir="auto">Surely, you do not <em>have to</em> use it like this. It is just a workflow that I personally feel comfortable when working with IPython/Juypter.</p>
<p dir="auto">Suppose we have <code>my_app.dart</code> with some code, probably edited inside an IDE:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class Counter {
  int count = 0;
  String greet() => 'Hi Tom, you have count $count!';
}"><pre><span>class</span> <span>Counter</span> {
  <span>int</span> count <span>=</span> <span>0</span>;
  <span>String</span> <span>greet</span>() <span>=&gt;</span> <span>'Hi Tom, you have count $<span>count</span>!'</span>;
}</pre></div>
<p dir="auto">Play with it a bit:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ interactive --directory path/to/my/package
>>> import 'my_app.dart';
>>> counter = Counter();
>>> counter.count = 10;
>>> counter.greet()
Hi Tom, you have count 10!
>>> counter.count = 20;
>>> counter.greet()
Hi Tom, you have count 20!"><pre>$ interactive <span>--</span>directory path<span>/</span>to<span>/</span>my<span>/</span>package
<span>&gt;&gt;&gt;</span> import <span>'my_app.dart'</span>;
<span>&gt;&gt;&gt;</span> counter <span>=</span> <span>Counter</span>();
<span>&gt;&gt;&gt;</span> counter.count <span>=</span> <span>10</span>;
<span>&gt;&gt;&gt;</span> counter.<span>greet</span>()
<span>Hi</span> <span>Tom</span>, you have count <span>10</span><span>!</span>
<span>&gt;&gt;&gt;</span> counter.count <span>=</span> <span>20</span>;
<span>&gt;&gt;&gt;</span> counter.<span>greet</span>()
<span>Hi</span> <span>Tom</span>, you have count <span>20</span><span>!</span></pre></div>
<p dir="auto">Then we realize something wrong and want to change it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(change &quot;Tom&quot; to &quot;Alex&quot; inside `my_app.dart`)"><pre>(change <span>"Tom"</span> to <span>"Alex"</span> inside `my_app.dart`)</pre></div>
<p dir="auto">Continue playing with it (auto hot reloaded, and state preserved):</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> counter.greet()
Hi Alex, you have count 20!"><pre><span>&gt;&gt;&gt;</span> counter.<span>greet</span>()
<span>Hi</span> <span>Alex</span>, you have count <span>20</span><span>!</span></pre></div>
<p dir="auto">We can also use all dependencies in the package as well, since the REPL code is just like a normal code file in this package.</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> import 'package:whatever_package';
>>> functionInWhateverPackage();"><pre><span>&gt;&gt;&gt;</span> import <span>'package:whatever_package'</span>;
<span>&gt;&gt;&gt;</span> <span>functionInWhateverPackage</span>();</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎼 Getting started</h2><a id="user-content--getting-started" aria-label="Permalink: 🎼 Getting started" href="#-getting-started"></a></p>
<p dir="auto">Install (just standard procedure of installing global dart packages):</p>
<div dir="auto" data-snippet-clipboard-copy-content="dart pub global activate interactive"><pre>dart pub global activate interactive</pre></div>
<p dir="auto">Use (just a normal binary):</p>

<p dir="auto">And play with it :)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Detailed functionality list</h2><a id="user-content-detailed-functionality-list" aria-label="Permalink: Detailed functionality list" href="#detailed-functionality-list"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Expressions</h3><a id="user-content-expressions" aria-label="Permalink: Expressions" href="#expressions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> a = 'Hello'; b = ' world!'; 
>>> '$a, $b'                   
Hello,  world!"><pre><span>&gt;&gt;&gt;</span> a <span>=</span> <span>'Hello'</span>; b <span>=</span> <span>' world!'</span>; 
<span>&gt;&gt;&gt;</span> <span>'$<span>a</span>, $<span>b</span>'</span>                   
<span>Hello</span>,  world<span>!</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Statements</h3><a id="user-content-statements" aria-label="Permalink: Statements" href="#statements"></a></p>

<p dir="auto">(All methods, not only <code>print</code>)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Functions</h3><a id="user-content-functions" aria-label="Permalink: Functions" href="#functions"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Define and redefine</h4><a id="user-content-define-and-redefine" aria-label="Permalink: Define and redefine" href="#define-and-redefine"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> String f() => 'old';
>>> f()
old
>>> String f() => 'new';
>>> f()
new"><pre><span>&gt;&gt;&gt;</span> <span>String</span> <span>f</span>() <span>=&gt;</span> <span>'old'</span>;
<span>&gt;&gt;&gt;</span> <span>f</span>()
old
<span>&gt;&gt;&gt;</span> <span>String</span> <span>f</span>() <span>=&gt;</span> <span>'new'</span>;
<span>&gt;&gt;&gt;</span> <span>f</span>()
<span>new</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Use local and global variables</h4><a id="user-content-use-local-and-global-variables" aria-label="Permalink: Use local and global variables" href="#use-local-and-global-variables"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> a = 10;
>>> int f() { int b = 20; a++; b++; return a+b; }
>>> f() 
32
>>> f()
33"><pre><span>&gt;&gt;&gt;</span> a <span>=</span> <span>10</span>;
<span>&gt;&gt;&gt;</span> <span>int</span> <span>f</span>() { <span>int</span> b <span>=</span> <span>20</span>; a<span>++</span>; b<span>++</span>; <span>return</span> a<span>+</span>b; }
<span>&gt;&gt;&gt;</span> <span>f</span>() 
<span>32</span>
<span>&gt;&gt;&gt;</span> <span>f</span>()
<span>33</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Classes</h3><a id="user-content-classes" aria-label="Permalink: Classes" href="#classes"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Define and redefine, preserving states</h4><a id="user-content-define-and-redefine-preserving-states" aria-label="Permalink: Define and redefine, preserving states" href="#define-and-redefine-preserving-states"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> class C { int a = 10; int f() => a * 2; }
>>> c = C(); print(c.f());
20
>>> class C { int a = 1000; int f() => a * 3; }
>>> c.f()
30"><pre><span>&gt;&gt;&gt;</span> <span>class</span> <span>C</span> { <span>int</span> a <span>=</span> <span>10</span>; <span>int</span> <span>f</span>() <span>=&gt;</span> a <span>*</span> <span>2</span>; }
<span>&gt;&gt;&gt;</span> c <span>=</span> <span>C</span>(); <span>print</span>(c.<span>f</span>());
<span>20</span>
<span>&gt;&gt;&gt;</span> <span>class</span> <span>C</span> { <span>int</span> a <span>=</span> <span>1000</span>; <span>int</span> <span>f</span>() <span>=&gt;</span> a <span>*</span> <span>3</span>; }
<span>&gt;&gt;&gt;</span> c.<span>f</span>()
<span>30</span></pre></div>
<p dir="auto">Remark: This follows the Dart hot reload semantics.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Extends and implements</h4><a id="user-content-extends-and-implements" aria-label="Permalink: Extends and implements" href="#extends-and-implements"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> class A { int f() => 10; } class B extends A { int f() => 20; }
>>> A().f() + B().f()
30
>>> class B implements A { int f() => 30; }
>>> A().f() + B().f()
40"><pre><span>&gt;&gt;&gt;</span> <span>class</span> <span>A</span> { <span>int</span> <span>f</span>() <span>=&gt;</span> <span>10</span>; } <span>class</span> <span>B</span> <span>extends</span> <span>A</span> { <span>int</span> <span>f</span>() <span>=&gt;</span> <span>20</span>; }
<span>&gt;&gt;&gt;</span> <span>A</span>().<span>f</span>() <span>+</span> <span>B</span>().<span>f</span>()
<span>30</span>
<span>&gt;&gt;&gt;</span> <span>class</span> <span>B</span> <span>implements</span> <span>A</span> { <span>int</span> <span>f</span>() <span>=&gt;</span> <span>30</span>; }
<span>&gt;&gt;&gt;</span> <span>A</span>().<span>f</span>() <span>+</span> <span>B</span>().<span>f</span>()
<span>40</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Use local variables, fields, and global variables</h4><a id="user-content-use-local-variables-fields-and-global-variables" aria-label="Permalink: Use local variables, fields, and global variables" href="#use-local-variables-fields-and-global-variables"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> a = 10;
>>> class C { int b = 20; int f() { int c = 30; a++; b++; c++; return a+b+c; } }
>>> c = C(); print(c.f()); print(c.f());
63
65"><pre><span>&gt;&gt;&gt;</span> a <span>=</span> <span>10</span>;
<span>&gt;&gt;&gt;</span> <span>class</span> <span>C</span> { <span>int</span> b <span>=</span> <span>20</span>; <span>int</span> <span>f</span>() { <span>int</span> c <span>=</span> <span>30</span>; a<span>++</span>; b<span>++</span>; c<span>++</span>; <span>return</span> a<span>+</span>b<span>+</span>c; } }
<span>&gt;&gt;&gt;</span> c <span>=</span> <span>C</span>(); <span>print</span>(c.<span>f</span>()); <span>print</span>(c.<span>f</span>());
<span>63</span>
<span>65</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Add libraries as dependency</h3><a id="user-content-add-libraries-as-dependency" aria-label="Permalink: Add libraries as dependency" href="#add-libraries-as-dependency"></a></p>
<p dir="auto">Use <code>!dart pub add package_name</code>, just like what is done in Python (Jupyter/IPython).</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> join('directory', 'file.txt')
(...error, since have not added that dependency...)
>>> !dart pub add path
Resolving dependencies...

+ path 1.8.2

Changed 1 dependency!

>>> join('directory', 'file.txt')
(...error, since have imported it...)
>>> import 'package:path/path.dart';
>>> join('directory', 'file.txt')   
directory/file.txt"><pre><span>&gt;&gt;&gt;</span> <span>join</span>(<span>'directory'</span>, <span>'file.txt'</span>)
(...error, since have not added that dependency...)
<span>&gt;&gt;&gt;</span> <span>!</span>dart pub add path
<span>Resolving</span> dependencies...

<span>+</span> path <span>1.8</span>.<span>2</span>

<span>Changed</span> <span>1</span> dependency<span>!</span>

<span>&gt;&gt;&gt;</span> <span>join</span>(<span>'directory'</span>, <span>'file.txt'</span>)
(...error, since have imported it...)
<span>&gt;&gt;&gt;</span> import <span>'package:path/path.dart'</span>;
<span>&gt;&gt;&gt;</span> <span>join</span>(<span>'directory'</span>, <span>'file.txt'</span>)   
directory<span>/</span>file.txt</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Imports</h3><a id="user-content-imports" aria-label="Permalink: Imports" href="#imports"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Built-in package</h4><a id="user-content-built-in-package" aria-label="Permalink: Built-in package" href="#built-in-package"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> Random().nextInt(100)
(some error outputs here, because it is not imported)
>>> import &quot;dart:math&quot;;
>>> Random().nextInt(100)
9"><pre><span>&gt;&gt;&gt;</span> <span>Random</span>().<span>nextInt</span>(<span>100</span>)
(some error outputs here, because it <span>is</span> not imported)
<span>&gt;&gt;&gt;</span> import <span>"dart:math"</span>;
<span>&gt;&gt;&gt;</span> <span>Random</span>().<span>nextInt</span>(<span>100</span>)
<span>9</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Third party package</h4><a id="user-content-third-party-package" aria-label="Permalink: Third party package" href="#third-party-package"></a></p>
<p dir="auto">Note: If it has not been added to dependency, please follow instructions above and use <code>!dart pub add path</code> to add it.</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> join('directory', 'file.txt')
(...error, since have imported it...)
>>> import 'package:path/path.dart';
>>> join('directory', 'file.txt')   
directory/file.txt"><pre><span>&gt;&gt;&gt;</span> <span>join</span>(<span>'directory'</span>, <span>'file.txt'</span>)
(...error, since have imported it...)
<span>&gt;&gt;&gt;</span> import <span>'package:path/path.dart'</span>;
<span>&gt;&gt;&gt;</span> <span>join</span>(<span>'directory'</span>, <span>'file.txt'</span>)   
directory<span>/</span>file.txt</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multiple in one go</h3><a id="user-content-multiple-in-one-go" aria-label="Permalink: Multiple in one go" href="#multiple-in-one-go"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> int g() => 42; class C { int a = 10; int f() => a * 2; }
>>> C().f() + g()
62"><pre><span>&gt;&gt;&gt;</span> <span>int</span> <span>g</span>() <span>=&gt;</span> <span>42</span>; <span>class</span> <span>C</span> { <span>int</span> a <span>=</span> <span>10</span>; <span>int</span> <span>f</span>() <span>=&gt;</span> a <span>*</span> <span>2</span>; }
<span>&gt;&gt;&gt;</span> <span>C</span>().<span>f</span>() <span>+</span> <span>g</span>()
<span>62</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi line if not ended</h3><a id="user-content-multi-line-if-not-ended" aria-label="Permalink: Multi line if not ended" href="#multi-line-if-not-ended"></a></p>
<p dir="auto">(The <code>...</code>, instead of <code>&gt;&gt;&gt;</code>, appears in the two lines, because the package detects it is not finished.)</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> class C {
...   int a = 10;
... }
>>> "><pre><span>&gt;&gt;&gt;</span> <span>class</span> <span>C</span> {
...   <span>int</span> a <span>=</span> <span>10</span>;
... }
<span>&gt;&gt;&gt;</span> </pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run commands</h3><a id="user-content-run-commands" aria-label="Permalink: Run commands" href="#run-commands"></a></p>
<p dir="auto">Use prefix <code>!</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> !whoami
tom
>>> !date
2022-10-22 ...outputs..."><pre><span>&gt;&gt;&gt;</span> <span>!</span>whoami
tom
<span>&gt;&gt;&gt;</span> <span>!</span>date
<span>2022</span><span>-</span><span>10</span><span>-</span><span>22</span> ...outputs...</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Execute within environment of existing package</h3><a id="user-content-execute-within-environment-of-existing-package" aria-label="Permalink: Execute within environment of existing package" href="#execute-within-environment-of-existing-package"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="interactive --directory path/to/your/package"><pre>interactive <span>--</span>directory path<span>/</span>to<span>/</span>your<span>/</span>package</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Implementation</h2><a id="user-content-implementation" aria-label="Permalink: Implementation" href="#implementation"></a></p>
<p dir="auto">General:</p>
<ul dir="auto">
<li>Create a blank package and an isolate as execution workspace</li>
<li>Extract imports/classes/functions/etc using analyzer, with replacing when it has the same name, and synthesize a dart file - thus supports rich Dart feature</li>
<li>Trigger Dart's hot-reload after the dart file is updated</li>
<li>Use analyzer to distinguish expressions/statements/compilation-units and do corresponding transformation</li>
<li>The only thing to let Dart VM service to evaluate is <code>generatedMethod()</code>, and do not evaluate anything more</li>
<li>Adding dependencies is as simple as running standard shell command</li>
</ul>
<p dir="auto">As for "global" variables:</p>
<ul dir="auto">
<li>Indeed implemented by a field variable</li>
<li>Statements: Make it inside <code>extension on dynamic { Object? generatedMethod() { ...the statements... } }</code> to access it seamlessly</li>
<li>Functions: Convert functions to extension methods on dynamic to access it seamlessly</li>
<li>Classes: Synthesize getters/setters in classes, and delegate to the field variables, whenever there is a potential access to global variable to access it seamlessly</li>
</ul>
<p dir="auto">TODO more implementation discussions if people are interested (above is so brief)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Known Issues</h2><a id="user-content-known-issues" aria-label="Permalink: Known Issues" href="#known-issues"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Windows non-WSL terminal</h4><a id="user-content-windows-non-wsl-terminal" aria-label="Permalink: Windows non-WSL terminal" href="#windows-non-wsl-terminal"></a></p>
<p dir="auto">Because of Dart's bug (<a data-error-text="Failed to load title" data-id="1125363060" data-permission-text="Title is private" data-url="https://github.com/dart-lang/sdk/issues/48329" data-hovercard-type="issue" data-hovercard-url="/dart-lang/sdk/issues/48329/hovercard" href="https://github.com/dart-lang/sdk/issues/48329">dart-lang/sdk#48329</a>), the upstream <code>cli_repl</code> package does not work well on Windows. The issues vary from terminal to terminal, but generally speaking, backspace doesn't work, we cannot move on the command line with arrows nor Ctrl+B/F, and no command history with arrows or ^P/^N either.</p>
<p dir="auto">Since <code>dart_interactive</code> depends on it, it is suggested to use <a href="https://learn.microsoft.com/en-us/windows/wsl/install" rel="nofollow">WSL</a> or *nix.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Command history</h4><a id="user-content-command-history" aria-label="Permalink: Command history" href="#command-history"></a></p>
<p dir="auto">Command history is not yet saved between sessions. However, this is implementable, and feel free to create an issue or PR.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Some errors will lead to <code>Hot reload failed</code></h4><a id="user-content-some-errors-will-lead-to-hot-reload-failed" aria-label="Permalink: Some errors will lead to Hot reload failed" href="#some-errors-will-lead-to-hot-reload-failed"></a></p>
<p dir="auto">Currently, some user mistakes will produce <code>Hot reload failed</code> error instead of the actual error. It will break the next command or the whole REPL. If you can't evaluate something simple as "1" after two tries, you can restart quickly with Ctrl/Cmd+D, Up Arrow and Enter in most terminals.</p>
<details>
<summary>Example</summary>
<div data-snippet-clipboard-copy-content=">>> 1
1
>>> print() // <----- oops, argument is not optional
[WARNING 2024-03-13 01:50:18.419137] Error: Hot reload failed, maybe because code has syntax error?
>>> 1
[WARNING 2024-03-13 01:50:20.464239] Error: Hot reload failed, maybe because code has syntax error?
>>> 1
[WARNING 2024-03-13 01:50:20.464239] Error: Hot reload failed, maybe because code has syntax error?"><pre><code>&gt;&gt;&gt; 1
1
&gt;&gt;&gt; print() // &lt;----- oops, argument is not optional
[WARNING 2024-03-13 01:50:18.419137] Error: Hot reload failed, maybe because code has syntax error?
&gt;&gt;&gt; 1
[WARNING 2024-03-13 01:50:20.464239] Error: Hot reload failed, maybe because code has syntax error?
&gt;&gt;&gt; 1
[WARNING 2024-03-13 01:50:20.464239] Error: Hot reload failed, maybe because code has syntax error?
</code></pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Contributors</h2><a id="user-content--contributors" aria-label="Permalink: ✨ Contributors" href="#-contributors"></a></p>

<p dir="auto"><a href="#contributors-"><img src="https://camo.githubusercontent.com/a6259a788bf467c1f433d54c95c94ef835dd44bb43d4f81bc270971613acb6b1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c5f636f6e7472696275746f72732d392d6f72616e67652e7376673f7374796c653d666c61742d737175617265" alt="All Contributors" data-canonical-src="https://img.shields.io/badge/all_contributors-9-orange.svg?style=flat-square"></a></p>

<p dir="auto">Thanks goes to these wonderful people (<a href="https://allcontributors.org/docs/en/emoji-key" rel="nofollow">emoji key</a>):</p>



<markdown-accessiblity-table><table>
  <tbody>
    <tr>
      <td><a href="https://github.com/fzyzcjy"><img src="https://avatars.githubusercontent.com/u/5236035?v=4?s=100" width="100px;" alt="fzyzcjy"><br><sub><b>fzyzcjy</b></sub></a><br><a href="https://github.com/fzyzcjy/dart_interactive/commits?author=fzyzcjy" title="Code">💻</a> <a href="https://github.com/fzyzcjy/dart_interactive/commits?author=fzyzcjy" title="Documentation">📖</a> <a href="#ideas-fzyzcjy" title="Ideas, Planning, &amp; Feedback">🤔</a></td>
      <td><a href="https://mrale.ph/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/131846?v=4?s=100" width="100px;" alt="Vyacheslav Egorov"><br><sub><b>Vyacheslav Egorov</b></sub></a><br><a href="#ideas-mraleph" title="Ideas, Planning, &amp; Feedback">🤔</a></td>
      <td><a href="https://blackhc.net/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/729312?v=4?s=100" width="100px;" alt="Andreas Kirsch"><br><sub><b>Andreas Kirsch</b></sub></a><br><a href="#ideas-BlackHC" title="Ideas, Planning, &amp; Feedback">🤔</a></td>
      <td><a href="https://manichord.com/blog" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/71999?v=4?s=100" width="100px;" alt="Maksim Lin"><br><sub><b>Maksim Lin</b></sub></a><br><a href="#ideas-maks" title="Ideas, Planning, &amp; Feedback">🤔</a></td>
      <td><a href="https://github.com/Keithcat1"><img src="https://avatars.githubusercontent.com/u/47483928?v=4?s=100" width="100px;" alt="Keithcat1"><br><sub><b>Keithcat1</b></sub></a><br><a href="https://github.com/fzyzcjy/dart_interactive/commits?author=Keithcat1" title="Code">💻</a></td>
      <td><a href="https://vegardit.com/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/426959?v=4?s=100" width="100px;" alt="Sebastian Thomschke"><br><sub><b>Sebastian Thomschke</b></sub></a><br><a href="https://github.com/fzyzcjy/dart_interactive/commits?author=sebthom" title="Code">💻</a></td>
      <td><a href="https://github.com/arcanemachine"><img src="https://avatars.githubusercontent.com/u/3351767?v=4?s=100" width="100px;" alt="arcanemachine"><br><sub><b>arcanemachine</b></sub></a><br><a href="https://github.com/fzyzcjy/dart_interactive/commits?author=arcanemachine" title="Code">💻</a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/davidmartos96"><img src="https://avatars.githubusercontent.com/u/22084723?v=4?s=100" width="100px;" alt="David Martos"><br><sub><b>David Martos</b></sub></a><br><a href="https://github.com/fzyzcjy/dart_interactive/commits?author=davidmartos96" title="Code">💻</a></td>
      <td><a href="https://github.com/Chematronix"><img src="https://avatars.githubusercontent.com/u/6773039?v=4?s=100" width="100px;" alt="Chematronix"><br><sub><b>Chematronix</b></sub></a><br><a href="https://github.com/fzyzcjy/dart_interactive/commits?author=Chematronix" title="Documentation">📖</a></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>



<p dir="auto">More specifically, thanks for all these contributions:</p>
<ul dir="auto">
<li><a href="https://github.com/mraleph">@mraleph</a> (Dart team): <a href="https://github.com/dart-lang/sdk/issues/39965#issuecomment-854854283" data-hovercard-type="issue" data-hovercard-url="/dart-lang/sdk/issues/39965/hovercard">Pointing</a> out Dart exposes hot reload and expression evaluation.</li>
<li><a href="https://github.com/BlackHC">@BlackHC</a>: Prior <a href="https://github.com/BlackHC/dart_repl">proof of concept</a> and <a href="https://medium.com/dartlang/evolving-dart-repl-poc-233440a35e1f" rel="nofollow">article</a> on the problem of creating a REPL.</li>
<li><a href="https://github.com/maks">@maks</a>: Prior <a href="https://github.com/maks/dart_repl">prototype</a> as <a href="https://github.com/dart-lang/sdk/issues/39965#issuecomment-1287953021" data-hovercard-type="issue" data-hovercard-url="/dart-lang/sdk/issues/39965/hovercard">an update-to-Dart-2</a> of @BlackHC's prototype.</li>
<li><a href="https://github.com/davidmartos96">@davidmartos96</a>: Fix package import bug. Fix windows hot reload bug. Update analyze.</li>
<li><a href="https://github.com/Keithcat1">@Keithcat1</a>: Partially fix printing object.</li>
<li><a href="https://github.com/sebthom">@sebthom</a>: Use unused TCP port.</li>
<li><a href="https://github.com/arcanemachine">@arcanemachine</a>: Pin dependency.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The perils of transition to 64-bit time_t (251 pts)]]></title>
            <link>https://blogs.gentoo.org/mgorny/2024/09/28/the-perils-of-transition-to-64-bit-time_t/</link>
            <guid>41681266</guid>
            <pubDate>Sat, 28 Sep 2024 16:31:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.gentoo.org/mgorny/2024/09/28/the-perils-of-transition-to-64-bit-time_t/">https://blogs.gentoo.org/mgorny/2024/09/28/the-perils-of-transition-to-64-bit-time_t/</a>, See on <a href="https://news.ycombinator.com/item?id=41681266">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2218">
	<!-- .entry-header -->

	
	
	<div>
		<p>In the <a href="https://blogs.gentoo.org/mgorny/2024/09/23/overview-of-cross-architecture-portability-problems/">Overview of cross-architecture portability problems</a>, I have dedicated a section to the problems resulting from use of 32-bit <kbd>time_t</kbd> type.  This design decision, still affecting Gentoo systems using glibc, means that 32-bit applications will suddenly start failing in horrible ways in 2038: they will be getting <kbd>-1</kbd> error instead of the current time, they won’t be able to <kbd>stat()</kbd> files.  In one word: complete mayhem will emerge.</p>
<p>There is a general agreement that the way forward is to change <kbd>time_t</kbd> to a 64-bit type.  Musl has already switched to that, glibc supports it as an option.  A number of other distributions such as Debian have taken the leap and switched.  Unfortunately, source-based distributions such as Gentoo don’t have it that easy.  So we are still debating the issue and experimenting, trying to figure out a maximally safe upgrade path for our users.</p>
<p>Unfortunately, that’s nowhere near trivial.  Above all, we are talking about a breaking ABI change.  It’s all-or-nothing.  If a library uses <kbd>time_t</kbd> in its API, everything linking to it needs to use the same type width.  In this post, I’d like to explore the issue in detail — why is it so bad, and what we can do to make it safer.<br>
<span id="more-2218"></span></p>
<h2>Going back to Large File Support</h2>
<p>Before we get into the time64 change, as I’m going to shortly call it, we need to go back in history a bit and consider another similar problem: Large File Support.</p>
<p>Long story short, originally 32-bit architectures specify two important file-related types that were 32 bits wide: <kbd>off_t</kbd> used to specify file offsets (signed to support relative offsets) and <kbd>ino_t</kbd> used to specify inode numbers.  This had two implications: you couldn’t open files larger than 2&nbsp;GiB, and you couldn’t open files whose inode numbers exceeded 32-bit unsigned integer range.</p>
<p>To resolve this problem, Large File Support was introduced.  It involved replacing these two types with 64-bit variants, and on glibc it is still optional today.  In its case, we didn’t take the leap and transitioned globally.  Instead, packages generally started enabling LFS support upstream — also taking care to resolve any ABI breakage in the process.  While many packages did that, we shouldn’t consider the problem solved.</p>
<p>The important point here is that time64 support in glibc requires LFS to be used.  This makes sense — if we are going to break stuff, we may as well solve both problems.</p>
<h2>What ABIs are we talking about?</h2>
<p>To put it simply, we have three possible sub-ABIs here:</p>
<ol>
<li>the original ABI with 32-bit types,</li>
<li>LFS: 64-bit <kbd>off_t</kbd> and <kbd>ino_t</kbd>, 32-bit <kbd>time_t</kbd>,</li>
<li>time64: LFS + 64-bit <kbd>time_t</kbd>.</li>
</ol>
<p>What’s important here is that a single glibc build remains compatible with all three variants.  However, libraries that use these types in their API are not.</p>
<p>Today, 32-bit systems roughly use a mix of the first and second ABI — the latter including packages that enabled LFS explicitly.  For the future, our goal is to focus on the third option.  We are not concerned about providing full-LFS systems with 32-bit <kbd>time_t</kbd>.</p>
<h2>Why the ABI change is so bad?</h2>
<p>Now, the big deal is that we are replacing a 32-bit type with a 64-bit type, in place.  Unlike with LFS, glibc does not provide any transitional API that could be used to enable new functions while preserving backwards compatibility — it’s all-or-nothing.</p>
<p>Let’s consider structures.  If a structure contains <kbd>time_t</kbd> with its natural 32-bit alignment, then there’s no padding for the type to extend to.  Inevitable, all fields will have to shift to make room for the new type.  Let’s consider a trivial example:</p>
<pre>struct {
    int a;
    time_t b;
    int c;
};</pre>
<p>With 32-bit <kbd>time_t</kbd>, the offset of <kbd>c</kbd> is 8.  With the 64-bit type, it’s 12.  If you mix binaries using different <kbd>time_t</kbd> width, they’re inevitably are going to read or wrong the wrong fields!  Or perhaps even read or write out of bounds!</p>
<p>Let’s just look at the size of <kbd>struct stat</kbd>, as an example of structure that uses both file and time-related types.  On plain 32-bit x86 glibc it’s 88 byte long.  With LFS, it’s 96 byte long (size and inode number fields are expanded).  With LFS + time64, it’s 108 byte long (three timestamps are expanded).</p>
<p>However, you don’t even need to use structures.  After all, we are talking about x86 where function parameters are passed on stack.  If one of the parameters is <kbd>time_t</kbd>, then positions of all parameters on stack change, and we find ourselves seeing the exact same problem!  Consider the following prototype:</p>
<pre>extern void foo(int a, time_t b, int c);</pre>
<p>Let’s say we’re calling it as <kbd>foo(1, 2, 3)</kbd>.  With 32-bit types, the call looks like the following:</p>
<pre>	pushl	$3
	pushl	$2
	pushl	$1
	call	foo@PLT</pre>
<p>However, with 64-bit <kbd>time_t</kbd>, it changes to:</p>
<pre>	pushl	$3
	pushl	$0
	pushl	$2
	pushl	$1
	call	foo@PLT</pre>
<p>An additional 32-bit value (zero) is pushed between the “old” <kbd>b</kbd> and <kbd>c</kbd>.  Once again, if we mix both kinds of binaries, they are going to fail to read the parameters correctly!</p>
<p>So yeah, it’s a big deal.  And right now, there are no real protections in place to prevent mixing these ABIs.  So what you actually may get is runtime breakage, potentially going as far as to create security issues.</p>
<p>You don’t have to take my word for it.  You can reproduce it yourself on x86/amd64 easily enough.  Let’s take the more likely case of a time32 program linked against a library that has been rebuilt for time64:</p>
<pre>$ cat &gt;libfoo.c &lt;&lt;EOF
#include &lt;stdio.h&gt;
#include &lt;time.h&gt;

void foo(int a, time_t b, int *c) {
   printf("a = %d\n", a);
   printf("b = %lld", (long long) b);
   printf("%s", ctime(&amp;b));
   printf("c = %d\n", *c);
}
EOF
$ cat &gt;foo.c &lt;&lt;EOF
#include &lt;stddef.h&gt;
#include &lt;time.h&gt;

extern void foo(int a, time_t b, int *c);

int main() {
    int three = 3;
    foo(1, time(NULL), &amp;three);
    return 0;
}
EOF
$ cc -m32 libfoo.c -shared -o libfoo.so
$ cc -m32 foo.c -o foo -Wl,-rpath,. libfoo.so
$ ./foo
a = 1
b = 1727154919
Tue Sep 24 07:15:19 2024
c = 3
$ cc -m32 -D_FILE_OFFSET_BITS=64 -D_TIME_BITS=64 \
  libfoo.c -shared -o libfoo.so
$ ./foo 
a = 1
b = -34556652301432063
Thu Jul 20 06:16:17 -1095054749
c = 771539841</pre>
<p>On top of that, the source-first nature of Gentoo amplifies these problems.  An average binary distribution rebuilds all binary packages — and then the user upgrades the system in a single, relatively atomic step.  Sure, if someone uses third-party repositories or has locally built programs that link to system libraries, problems can emerge but the process is relatively safe.</p>
<p>On the other hand, in Gentoo we are talking about rebuilding <kbd>@world</kbd> while breaking ABI in place.  For a start, we are talking around prolonged periods of time between two packages being rebuilt when they would actually be mixing incompatible ABI.  Then, there is a fair risk that some rebuild will fail and leave your system half-transitioned with no easy way out.  Then, there is a real risk that cyclic dependencies will actually make rebuild impossible — rebuilding a dependency will break build-time tools, preventing stuff from being rebuilt.  It’s a true horror.</p>
<h2>What can we do to make it safer?</h2>
<p>Our deliberations currently revolve about three ideas, that are semi-related, though not inevitably dependent one upon another:</p>
<ol>
<li>Changing the platform tuple (<kbd>CHOST</kbd>) for the new ABIs, to clearly distinguish them from the baseline 32-bit ABI.</li>
<li>Changing the libdir for the new ABIs, effectively permitting the rebuilt libraries to be installed independently of the original versions.</li>
<li>Introducing an binary-level ABI distinction that could prevent binaries using different sub-ABI to be linked to one another.</li>
</ol>
<p>The subsequent sections will focus on each of these changes in detail.  Note that all the values used there are just examples, and not necessarily the strings used in a final solution.</p>
<h2>The platform tuple change</h2>
<p>The platform tuple (generally referenced through the <kbd>CHOST</kbd> variable) identifies the platform targeted by the toolchain.  For example, it is used as a part of GCC/binutils install paths, effectively allowing toolchains for multiple targets to be installed simultaneously.  In clang, it can be used to switch between supported cross-compilation targets, and can control the defaults to match the specified ABI.  In Gentoo, it is also used to uniquely identify ABIs for the purpose of multilib support.  Because of that, we require that no two co-installable ABIs share the same tuple.</p>
<p>A tuple consists of four parts, separated by hyphens: architecture, vendor, operating system and libc.  Of these, vendor is generally freeform but the other three are restricted to some degree.  A few semi-equivalent examples of tuples used for 32-bit x86 platform include:</p>
<pre>i386-pc-linux-gnu
i686-pc-linux-gnu
i686-unknown-linux-gnu</pre>
<p>Historically, two approaches were used to introduce new ABIs.  Either the vendor field was changed, or an additional ABI specification was appended to the libc field.  For example, Gentoo historically used two different kind of tuples for ARM ABIs with hardware floating-point unit:</p>
<pre>armv7a-hardfloat-linux-gnueabi
armv7a-unknown-linux-gnueabihf</pre>
<p>The former approach was used earlier, to avoid incompatibility problems resulting from altering other tuple fields.  However, as these were fixed and upstreams normalized on the latter solution, Gentoo followed suit.</p>
<p>Similarly, the discussion of time64 ABIs resurfaced the same dilemma: should we just “abuse” the vendor field for this, or instead change libc field and fix packages?  The main difference is that the former is “cleaner” as a downstream solution limited to Gentoo, while the latter generally opens up discussions about interoperability.  Therefore, the options look like:</p>
<pre>i686-gentoo_t64-linux-gnu
i686-pc-linux-gnut64
armv7a-gentoo_t64-linux-gnueabihf
armv7a-unknown-linux-gnueabihft64</pre>
<p>Fortunately, changing the tuple should not require much patching.  The GNU toolchain and GNU build system both ignore everything following “gnu” in the libc field.  Clang will require patching — but upstream is likely to accept our patches, and we will want to make patches anyway, as they will permit clang to automatically choose the right ABI based on the tuple.</p>
<h2>The libdir change</h2>
<p>The term “libdir” refers to the base name of the library install directory.  Having different libdirs, and therefore separate library install directories, makes it possible to build multilib systems, i.e. installing multiple ABI variations of libraries on a single system, and making it possible to run executables for different ABIs.  For example, this is what makes it possible to run 32-bit x86 executables on amd64 systems.</p>
<p>The libdir values are generally specified in the ABI.  Naturally, the baseline value is plain <kbd>lib</kbd>.  As a historical convention (since 32-bit architectures were first), usually 32-bit platforms (arm, ppc, x86) use <kbd>lib</kbd>, whereas their more modern 64-bit counterparts (amd64, arm64, ppc64) use <kbd>lib64</kbd> — even if a particular architecture never really supported multilib on Gentoo.</p>
<p>Architectures that support multiple ABIs also define different libdirs.  For example, the additional x32 ABI on x86 uses <kbd>libx32</kbd>.  MIPS n32 ABI uses <kbd>lib32</kbd> (with plain <kbd>lib</kbd> defining the o32 ABI).</p>
<p>Now, we are considering changing the libdir value for time64 variants of 32-bit ABIs, for example from <kbd>lib</kbd> to <kbd>libt64</kbd>.  This would make it possible to install the rebuilt libraries separately from the old libraries, effectively bringing three advantages:</p>
<ol>
<li>reducing the risk of time64 executables accidentally linking to time32 libraries,</li>
<li>enabling Portage’s <kbd>preserved-libs</kbd> feature to preserve time32 libraries once the respective packages have been rebuilt for time64, and before their reverse dependencies have been rebuilt,</li>
<li>optionally, making it possible to use a time32 + time64 multilib profiles, that could be used to preserve compatibility with prebuilt time32 applications linking to system libraries.</li>
</ol>
<p>In my opinion, the second point is a killer feature.  As I’ve mentioned before, we are talking about the kind of migration that would break executables for a prolonged time on production systems, and possibly break build-time tools, preventing the rebuild from proceeding further.  By preserving original libraries, we are minimizing the risk of actual breakage, since the existing executables will keep using the time32 libraries until they are rebuilt and linked to the time64 libraries.</p>
<p>The libdir change is definitely going to require some toolchain patching.  We may want to also consider special-casing glibc, as the same set of glibc libraries is valid for all of the sub-ABIs we were considering.  However, we will probably want a separate <kbd>ld.so</kbd> executable, as it would need to load libraries from the correct libdir, and then we will want to set <kbd>.interp</kbd> in time64 executables to reference the time64 <kbd>ld.so</kbd>.</p>
<p>Note that due to how multilib is designed in Gentoo, a proper multilib support for this (i.e. the third point) requires a unique platform tuple for the ABI as well — so that specific aspect is dependent on the tuple change.</p>
<h2>Ensuring binary incompatibility</h2>
<p>In general, you can’t mix binaries using different ABIs.  For example, if you try to link a 64-bit program to a 32-bit library, the linker will object:</p>
<pre>$ cc foo.c libfoo.so 
/usr/lib/gcc/x86_64-pc-linux-gnu/14/../../../../x86_64-pc-linux-gnu/bin/ld: libfoo.so: error adding symbols: file in wrong format
collect2: error: ld returned 1 exit status</pre>
<p>Similarly, the dynamic loader will refuse to use a 32-bit library with 64-bit program:</p>
<pre>$ ./foo 
./foo: error while loading shared libraries: libfoo.so: wrong ELF class: ELFCLASS32</pre>
<p>There a few mechanisms that are used for this.  As demonstrated above, architectures with 32-bit and 64-bit ABIs use two distinct ELF classes (<kbd>ELFCLASS32</kbd> and <kbd>ELFCLASS64</kbd>).  Additionally, some architectures use different machine identifiers (<kbd>EM_386</kbd> vs. <kbd>EM_X86_64</kbd>, <kbd>EM_PPC</kbd> vs. <kbd>EM_PPC64</kbd>).  The x32 bit ABI on x86 “abuses” this by declaring its binaries as <kbd>ELFCLASS32 + EM_X86_64</kbd> (and therefore distinct from <kbd>ELFCLASS32 + EM_386</kbd> and from <kbd>ELFCLASS64 + EM_X86_64</kbd>).</p>
<p>Both ARM and MIPS use the flags field (it is a bit-field with architecture-specific flags) to distinguish different ABIs (hardfloat vs. softfloat, n32 ABI on MIPS…).  Additionally, both feature a dedicated attribute section — and again, the linker refuses to link incompatible object files.</p>
<p>It may be desirable to implement a similar mechanism for time32 and time64 systems.  Unfortunately, it’s not a trivial task.  It doesn’t seem that there is a reusable generic mechanism that could be used for that.  On top of that, we need a solution that would fit a fair number of different architectures.  It seems that the most reasonably solution right now would be to add a new ELF note section dedicated to this feature, and implement complete toolchain support for it.</p>
<p>However, whatever we decide to do, we need to take into consideration that the user may want to disable it.  Particularly, there is a fair number of prebuilt software that have no sources available, and it may continue working correctly against system libs, provided it does not call into any API using <kbd>time_t</kbd>.  The cure of unconditionally preventing them from working might be worse than the disease.</p>
<p>On the bright side, it should be possible to create a non-fatal QA check for this without much hacking, provided that we go with separate libdirs.  We can distinguish time64 executables by their <kbd>.interp</kbd> section, pointing to the dynamic loader in the appropriate libdir, and then verify that time32 programs will not load any libraries from <kbd>libt64</kbd>, and that time64 programs will not load any libraries directly from <kbd>lib</kbd>.</p>
<h2>What about old prebuilt applications?</h2>
<p>So far we were concerned about packages that are building from sources.  However, there is still a fair number of old applications, usually proprietary, that are available only as prebuilt binaries — particularly for x86 and PowerPC architectures.  These packages are going to face two problems: firstly, compatibility issues with system libraries, and secondly, the y2k38 problem itself.</p>
<p>For the compatibility problem, we have a reasonably good solution already.  Since we already had to make them work on amd64, we have a multilib layout in place, along with necessary machinery to build multiple library versions.  In fact, given that the primary purpose of multilib is compatibility with old software, it’s not even clear if there is much of a point in switching amd64 multilib to use time64 for 32-bit binaries.  Either way, we can easily extend our multilib machinery to distinguish the regular <kbd>abi_x86_32</kbd> target from <kbd>abi_x86_t64</kbd> (and we probably should do that anyway), and then create new multilib x86 profiles that would support both ABIs.</p>
<p>The second part is much harder.  Obviously, as soon as we’re past the 2038 cutoff date, all 32-bit programs — using system libraries or not — will simply start failing in horrible ways.  One possibility is to work with <a rel="external" href="https://github.com/wolfcw/libfaketime">faketime</a> to control the system clock.  Another is to run a whole VM that’s moved back in time.</p>
<h2>Summary</h2>
<p>As 2038 is approaching, 32-bit applications exercising 32-bit <kbd>time_t</kbd> are up to stop working.  At this point, it is pretty clear that the only way forward is to rebuild these applications with 64-bit <kbd>time_t</kbd> (and while at it, force <abbr title="Large File Support">LFS as well).  Unfortunately, that’s not a trivial task since it involves an ABI change, and mixing time32 and time64 programs and libraries can lead to horrible runtime bugs.</abbr></p>
<p>While the exact details are still in the making, the proposed changes revolve around three ideas that can be implemented independently to some degree: changing the platform tuple (<kbd>CHOST</kbd>), changing libdir and preventing accidentally mixing time32 and time64 binaries.</p>
<p>The tuple change is mostly a more formal way of distinguishing builds for the regular time32 ABI (e.g. <kbd>i686-pc-linux-gnu</kbd>) from ones specifically targeting time64 (e.g. <kbd>i686-pc-linux-gnut64</kbd>).  It should be relatively harmless and easy to carry out, with minimal amount of fixing necessary.  For example, clang will need to be updated to accept new tuples.</p>
<p>The libdir change is probably the most important of all, as it permits a breakage-free transition, thanks to Portage’s <kbd>preserved-libs</kbd> feature.  Long story short, time64 libraries get installed to a new libdir (e.g. <kbd>libt64</kbd>), and the original time32 libraries remain in <kbd>lib</kbd> until the applications using them are rebuilt.  Unfortunately, it’s a bit harder to implement — it requires toolchain changes, and ensuring that all software correctly respects libdir.  The extra difficulty is that with this change alone, the dynamic loader won’t ignore time32 libraries if e.g. <kbd>-Wl,-rpath,/usr/lib</kbd> is injected somewhere.</p>
<p>The incompatibility part is quite important, but also quite difficult.  Ideally, we’d like to stop the linker from trying to accidentally link time32 libraries with time64 programs, and likewise the dynamic loader from trying to load them.  Unfortunately, so far we weren’t able to come up with a realistic way of doing that, short of actually making some intrusive changes to the toolchain.  On the positive side, writing a QA check to detect accidental mixing at build time shouldn’t be that hard.</p>
<p>Doing all three should enable us to provide a clean and relatively safe transition path for 32-bit Gentoo systems using glibc.  However, these only solve problems for packages built from source.  Prebuilt 32-bit applications, particularly proprietary software like old games, can’t be helped that way.  And even if time64 changes won’t break them via breaking the ABI compatibility with system libraries, then year 2038 will.  Unfortunately, there does not seem to be a good solution to that, short of actually running them with faked system time, one way or another.</p>
<p>Of course, all of this is still only a rough draft.  A lot may still change, following experiments, discussion and patch submission.</p>
<h2>Acknowledgements</h2>
<p>I would like to thank the following people for proof-reading and suggestions, and for their overall work towards time64 support in Gentoo: Arsen Arsenović, Andreas K. Hüttel, Sam James and Alexander Monakov.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Autossh – automatically restart SSH sessions and tunnels (163 pts)]]></title>
            <link>https://github.com/Autossh/autossh</link>
            <guid>41681110</guid>
            <pubDate>Sat, 28 Sep 2024 16:09:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Autossh/autossh">https://github.com/Autossh/autossh</a>, See on <a href="https://news.ycombinator.com/item?id=41681110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><pre>autossh Version 1.4
-------------------

Building and Installing Autossh
--------------------------------

With version 1.4, autossh now uses autoconf. So the build procedure
is now the well-known:

	./configure
	make
	make install

Look at autossh.host for an example wrapper script.


Usage
-----
	autossh [-M &lt;port&gt;[:echo_port]] [-f] [SSH OPTIONS]

Description
-----------

autossh is a program to start a copy of ssh and monitor it, restarting
it as necessary should it die or stop passing traffic.

The original idea and the mechanism were from rstunnel (Reliable SSH
Tunnel). With version 1.2 the method changed: autossh now uses ssh to
construct a loop of ssh forwardings (one from local to remote, one
from remote to local), and then sends test data that it expects to get
back. (The idea is thanks to Terrence Martin.) 

With version 1.3, a new method is added (thanks to Ron Yorston): a
port may be specified for a remote echo service that will echo back
the test data. This avoids the congestion and the aggravation of
making sure all the port numbers on the remote machine do not
collide. The loop-of -forwardings method remains available for
situations where using an echo service may not be possible.

autossh has only three arguments of its own:

 -M &lt;port&gt;[:echo_port], to specify the base monitoring port to use, or
	alternatively, to specify the monitoring port and echo service
	port to use. 

	When no echo service port is specified, this port and the port 
	immediately above it (port# + 1) should be something nothing 
	else is using. autossh will send test data on the base monitoring 
	port, and receive it back on the port above. For example, if you 
	specify "-M 20000", autossh will set up forwards so that it can 
	send data on port 20000 and receive it back on 20001.

	Alternatively a port for a remote echo service may be
	specified. This should be port 7 if you wish to use the
	standard inetd echo service.  When an echo port is specified,
	only the specified monitor port is used, and it carries the
	monitor message in both directions.

	Many people disable the echo service, or even disable inetd,
	so check that this service is available on the remote
	machine. Some operating systems allow one to specify that the
	service only listen on the localhost (loopback interface),
	which would suffice for this use.

	The echo service may also be something more complicated:
	perhaps a daemon that monitors a group of ssh tunnels.

	-M 0 will turn the monitoring off, and autossh will only
	restart ssh on ssh exit.

	For example, if you are using a recent version of OpenSSH, you 
	may wish to explore using the ServerAliveInterval and 
	ServerAliveCountMax options to have the SSH client exit if it 
	finds itself no longer connected to the server. In many ways 
	this may be a better solution than the monitoring port.

 -f     Causes autossh to drop to the background before running ssh. The
        -f flag is stripped from arguments passed to ssh. Note that there
        is a crucial difference between the -f with autossh, and -f
        with ssh: when used with autossh, ssh will be *unable* to ask for
        passwords or passphrases. When -f is used, the "starting gate"
        time (see AUTOSSH_GATETIME) will be set to 0.

 -V     to have autossh display its version and exit.

All other arguments are passed to ssh. There are a number of
other settings, but these are all controlled through environment
variables. ssh seems to be appropriating more and more letters for
options, and this seems the easiest way to avoid collisions.

autossh tries to distinguish the manner of death of the ssh process it
is monitoring and act appropriately. The rules are:

   - If the ssh process exited normally (for example, someone typed
     "exit" in an interactive session), autossh exits rather than 
     restarting;
   - If autossh itself receives a SIGTERM, SIGINT, or a SIGKILL
     signal, it assumes that it was deliberately signalled, and exits
     after killing the child ssh process;
   - If autossh itself receives a SIGUSR1 signal, it will kill the child
     ssh process and start a new one;
   - Periodically (by default every 10 minutes), autossh attempts to pass
     traffic on the monitor forwarded port. If this fails, autossh will
     kill the child ssh process (if it is still running) and start a new
     one; 
   - If the child ssh process dies for any other reason, autossh will
     attempt to start a new one.

Startup behaviour:

   - If the ssh session fails with an exit status of 1 on the very first 
     try, autossh will assume that there is some problem with syntax or
     the connection setup, and will exit rather than retrying;
   - There is now a "starting gate" time. If the first ssh process fails 
     within the first few seconds of being started, autossh assumes that 
     it never made it "out of the starting gate", and exits. This is to handle
     initial failed authentication, connection, etc. This time is 30 seconds
     by default, and can be adjusted (see the AUTOSSH_GATETIME environment
     variable below).
   - NOTE: If AUTOSSH_GATETIME is set to 0, then BOTH of the above
           behaviours are disabled. This is useful for, for example,
	   having autossh start on boot. The "starting gate" time is
	   also set to 0 with the -f flag to autossh is used.

Continued failures:

   - If the ssh connection fails and attempts to restart it fail in
     quick succession, autossh will start delaying its attempts to
     restart, gradually backing farther and farther off up to a
     maximum interval of the autossh poll time (usually 10 minutes).
     autossh can be "prodded" to retry by signalling it, perhaps with
     SIGHUP ("kill -HUP").

Connection Setup
----------------

As connections must be established unattended, the use of autossh
requires that some form of automatic authentication be set up. The use
of RSAAuthentication with ssh-agent is the recommended method. The
example wrapper script attempts to check if there is an agent running
for the current environment, and to start one if there isn't.

It cannot be stressed enough that you must make sure ssh works on its
own, that you can set up the session you want before you try to
run it under autossh.

If you are tunnelling and using an older version of ssh that does not
support the -N flag, you should upgrade (your version has security
flaws). If you can't upgrade, you may wish to do as rstunnel does, and
give ssh a command to run, such as "sleep 99999999999".

Disabling connection monitoring
-------------------------------

A monitor port value of "0" ("autossh -M 0") will disable use of
the monitor ports; autossh will then only react to signals and the
death of the ssh process.

Environment Variables
---------------------

The following environment variables can be set:

    AUTOSSH_DEBUG	  - sets logging level to LOG_DEBUG, and if
			    the operating system supports it, sets
			    syslog to duplicate log entries to stderr.
    AUTOSSH_FIRST_POLL	  - time to initial poll (default is as 
			    AUTOSSH_POLL below).
    AUTOSSH_GATETIME      - how long ssh must be up before we consider
	                    it a successful connection. Default is 30
			    seconds. If set to 0, then this behaviour
			    is disabled, and as well, autossh will retry
			    even on failure of first attempt to run ssh.
    AUTOSSH_LOGFILE	  - sets autossh to use the named log file,
			    rather than syslog.
    AUTOSSH_LOGLEVEL	  - log level, they correspond to the levels 
			    used by syslog; so 0-7 with 7 being the
			    chattiest.
    AUTOSSH_MAXLIFETIME   - Sets the maximum number of seconds the process 
			    should live for before killing off the ssh child 
			    and exiting.
    AUTOSSH_MAXSTART	  - specifies how many times ssh should be started.
			    A negative number means no limit on the number 
			    of times ssh is started. The default value is -1.
    AUTOSSH_MESSAGE	  - append a custom message to the echo string (max 64
			    bytes).
    AUTOSSH_NTSERVICE     - when set to "yes" , setup autossh to run as an 
			    NT service under cygrunsrv. This adds the -N flag
			    for ssh if not already set, sets the log output 
			    to stdout, and changes the behaviour on ssh exit 
			    so that it will restart even on a normal exit.
    AUTOSSH_PATH	  - path to the ssh executable, in case
			    it is different than that compiled in.
    AUTOSSH_PIDFILE	  - write autossh pid to specified file.
    AUTOSSH_POLL	  - poll time in seconds; default is 600.
    			    Changing this will also change the first
			    poll time, unless AUTOSSH_FIRST_POLL is
			    used to set it to something different.
			    If the poll time is less than twice the 
			    network timeouts (default 15 seconds) the 
			    network timeouts will be adjusted downward 
			    to 1/2 the poll time.
    AUTOSSH_PORT	  - set monitor port. Mostly in case ssh
			    appropriates -M at some time. But because
			    of this possible use, AUTOSSH_PORT overrides
			    the -M flag.

SSH Options
------------------

There are two particular OpenSSH options that are useful when using
autossh:

1) ExitOnForwardFailure=yes on the client side to make sure forwardings
have succeeded when autossh assumes the connection is setup properly.

2) ClientAliveInterval on the server side to make sure the listening
socket is closed on the server side if the connection closes on the
client side.

Logging and Syslog
------------------

autossh logs to syslog using the LOG_USER facility. Your syslog may
have to be configured to accept messages for this facility. This is
usually done in /etc/syslog.conf.

-- 
Kudos and raspberries to harding [at] motd.ca
</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Little Typer (2018) (166 pts)]]></title>
            <link>https://thelittletyper.com/</link>
            <guid>41680621</guid>
            <pubDate>Sat, 28 Sep 2024 14:54:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thelittletyper.com/">https://thelittletyper.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41680621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pie">
<h2>Getting Pie</h2>
<p>
An implementation of Pie is available from the Racket package system. To install Pie, first install a recent version of <a href="https://racket-lang.org/">Racket</a>. Open DrRacket and select "Install Package" from the "File" menu. In the package name field, type <code>pie</code> and then click the "Install" button.
</p>
<p>
To use Pie, begin a file with <code>#lang pie</code> in DrRacket.
</p>
<h2>Errata</h2><p>
There are <a href="https://thelittletyper.com/errata.html">known errata</a>.
</p></div></div>]]></description>
        </item>
    </channel>
</rss>