<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 02 Feb 2025 17:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Lume – OS lightweight CLI for MacOS & Linux VMs on Apple Silicon. (148 pts)]]></title>
            <link>https://github.com/trycua/lume</link>
            <guid>42908061</guid>
            <pubDate>Sun, 02 Feb 2025 11:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trycua/lume">https://github.com/trycua/lume</a>, See on <a href="https://news.ycombinator.com/item?id=42908061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><strong>lume</strong> is a lightweight Command Line Interface and local API server to create, run and manage macOS and Linux virtual machines (VMs) with near-native performance on Apple Silicon, using Apple's <code>Virtualization.Framework</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run prebuilt macOS images in just 1 step</h3><a id="user-content-run-prebuilt-macos-images-in-just-1-step" aria-label="Permalink: Run prebuilt macOS images in just 1 step" href="#run-prebuilt-macos-images-in-just-1-step"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/trycua/lume/blob/main/img/cli.png"><img src="https://github.com/trycua/lume/raw/main/img/cli.png" alt="lume cli"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="lume run macos-sequoia-vanilla:latest"><pre>lume run macos-sequoia-vanilla:latest</pre></div>
<p dir="auto">For a python interface, check out <a href="https://github.com/trycua/pylume">pylume</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="lume <command>

Commands:
  lume create <name>            Create a new macOS or Linux VM
  lume run <name>               Run a VM
  lume ls                       List all VMs
  lume get <name>               Get detailed information about a VM
  lume set <name>               Modify VM configuration
  lume stop <name>              Stop a running VM
  lume delete <name>            Delete a VM
  lume pull <image>             Pull a macOS image from container registry
  lume clone <name> <new-name>  Clone an existing VM
  lume images                   List available macOS images in local cache
  lume ipsw                     Get the latest macOS restore image URL
  lume prune                    Remove cached images
  lume serve                    Start the API server

Options:
  --help     Show help [boolean]
  --version  Show version number [boolean]

Command Options:
  create:
    --os <os>            Operating system to install (macOS or linux, default: macOS)
    --cpu <cores>        Number of CPU cores (default: 4)
    --memory <size>      Memory size, e.g., 8GB (default: 4GB)
    --disk-size <size>   Disk size, e.g., 50GB (default: 40GB)
    --display <res>      Display resolution (default: 1024x768)
    --ipsw <path>        Path to IPSW file or 'latest' for macOS VMs

  run:
    --no-display         Do not start the VNC client app
    --shared-dir <dir>   Share directory with VM (format: path[:ro|rw])
    --mount <path>       For Linux VMs only, attach a read-only disk image

  set:
    --cpu <cores>        New number of CPU cores
    --memory <size>      New memory size
    --disk-size <size>   New disk size

  delete:
    --force              Force deletion without confirmation

  pull:
    --registry <url>     Container registry URL (default: ghcr.io)
    --organization <org> Organization to pull from (default: trycua)

  serve:
    --port <port>        Port to listen on (default: 3000)"><pre>lume <span>&lt;</span>command<span>&gt;</span>

Commands:
  lume create <span>&lt;</span>name<span>&gt;</span>            Create a new macOS or Linux VM
  lume run <span>&lt;</span>name<span>&gt;</span>               Run a VM
  lume ls                       List all VMs
  lume get <span>&lt;</span>name<span>&gt;</span>               Get detailed information about a VM
  lume <span>set</span> <span>&lt;</span>name<span>&gt;</span>               Modify VM configuration
  lume stop <span>&lt;</span>name<span>&gt;</span>              Stop a running VM
  lume delete <span>&lt;</span>name<span>&gt;</span>            Delete a VM
  lume pull <span>&lt;</span>image<span>&gt;</span>             Pull a macOS image from container registry
  lume clone <span>&lt;</span>name<span>&gt;</span> <span>&lt;</span>new-name<span>&gt;</span>  Clone an existing VM
  lume images                   List available macOS images <span>in</span> <span>local</span> cache
  lume ipsw                     Get the latest macOS restore image URL
  lume prune                    Remove cached images
  lume serve                    Start the API server

Options:
  --help     Show <span>help</span> [boolean]
  --version  Show version number [boolean]

Command Options:
  create:
    --os <span>&lt;</span>os<span>&gt;</span>            Operating system to install (macOS or linux, default: macOS)
    --cpu <span>&lt;</span>cores<span>&gt;</span>        Number of CPU cores (default: 4)
    --memory <span>&lt;</span>size<span>&gt;</span>      Memory size, e.g., 8GB (default: 4GB)
    --disk-size <span>&lt;</span>size<span>&gt;</span>   Disk size, e.g., 50GB (default: 40GB)
    --display <span>&lt;</span>res<span>&gt;</span>      Display resolution (default: 1024x768)
    --ipsw <span>&lt;</span>path<span>&gt;</span>        Path to IPSW file or <span><span>'</span>latest<span>'</span></span> <span>for</span> macOS VMs

  run:
    --no-display         Do not start the VNC client app
    --shared-dir <span>&lt;</span>dir<span>&gt;</span>   Share directory with VM (format: path[:ro<span>|</span>rw])
    --mount <span>&lt;</span>path<span>&gt;</span>       For Linux VMs only, attach a read-only disk image

  set:
    --cpu <span>&lt;</span>cores<span>&gt;</span>        New number of CPU cores
    --memory <span>&lt;</span>size<span>&gt;</span>      New memory size
    --disk-size <span>&lt;</span>size<span>&gt;</span>   New disk size

  delete:
    --force              Force deletion without confirmation

  pull:
    --registry <span>&lt;</span>url<span>&gt;</span>     Container registry URL (default: ghcr.io)
    --organization <span>&lt;</span>org<span>&gt;</span> Organization to pull from (default: trycua)

  serve:
    --port <span>&lt;</span>port<span>&gt;</span>        Port to listen on (default: 3000)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap trycua/lume
brew install lume"><pre>brew tap trycua/lume
brew install lume</pre></div>
<p dir="auto">You can also download the <code>lume.pkg.tar.gz</code> archive from the <a href="https://github.com/trycua/lume/releases">latest release</a>, extract it, and install the package manually.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prebuilt Images</h2><a id="user-content-prebuilt-images" aria-label="Permalink: Prebuilt Images" href="#prebuilt-images"></a></p>
<p dir="auto">Pre-built images are available on <a href="https://github.com/orgs/trycua/packages">ghcr.io/trycua</a>.
These images come with an SSH server pre-configured and auto-login enabled.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Image</th>
<th>Tag</th>
<th>Description</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>macos-sequoia-vanilla</code></td>
<td><code>latest</code>, <code>15.2</code></td>
<td>macOS Sonoma 15.2</td>
<td>40GB</td>
</tr>
<tr>
<td><code>macos-sequoia-xcode</code></td>
<td><code>latest</code>, <code>15.2</code></td>
<td>macOS Sonoma 15.2 with Xcode command line tools</td>
<td>50GB</td>
</tr>
<tr>
<td><code>ubuntu-noble-vanilla</code></td>
<td><code>latest</code>, <code>24.04.1</code></td>
<td><a href="https://ubuntu.com/download/server/arm" rel="nofollow">Ubuntu Server for ARM 24.04.1 LTS</a> with Ubuntu Desktop</td>
<td>20GB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">For additional disk space, resize the VM disk after pulling the image using the <code>lume set &lt;name&gt; --disk-size &lt;size&gt;</code> command.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local API Server</h2><a id="user-content-local-api-server" aria-label="Permalink: Local API Server" href="#local-api-server"></a></p>
<p dir="auto"><code>lume</code> exposes a local HTTP API server that listens on <code>http://localhost:3000/lume</code>, enabling automated management of VMs.</p>

<p dir="auto">For detailed API documentation, please refer to <a href="https://github.com/trycua/lume/blob/main/docs/API-Reference.md">API Reference</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<ul dir="auto">
<li><a href="https://github.com/trycua/lume/blob/main/docs/API-Reference.md">API Reference</a></li>
<li><a href="https://github.com/trycua/lume/blob/main/docs/Development.md">Development</a></li>
<li><a href="https://github.com/trycua/lume/blob/main/docs/FAQ.md">FAQ</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome and greatly appreciate contributions to lume! Whether you're improving documentation, adding new features, fixing bugs, or adding new VM images, your efforts help make lume better for everyone. For detailed instructions on how to contribute, please refer to our <a href="https://github.com/trycua/lume/blob/main/CONTRIBUTING.md">Contributing Guidelines</a>.</p>
<p dir="auto">Join our <a href="https://discord.gg/8p56E2KJ" rel="nofollow">Discord community</a> to discuss ideas or get assistance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">lume is open-sourced under the MIT License - see the <a href="https://github.com/trycua/lume/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Trademarks</h2><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">Apple, macOS, and Apple Silicon are trademarks of Apple Inc. Ubuntu and Canonical are registered trademarks of Canonical Ltd. This project is not affiliated with, endorsed by, or sponsored by Apple Inc. or Canonical Ltd.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers over time</h2><a id="user-content-stargazers-over-time" aria-label="Permalink: Stargazers over time" href="#stargazers-over-time"></a></p>
<p dir="auto"><a href="https://starchart.cc/trycua/lume" rel="nofollow"><img src="https://camo.githubusercontent.com/561442573e1c2212a9bfb1ba7e7bb847cfbf6f205c18769dbb73f4ea9cd1dd24/68747470733a2f2f7374617263686172742e63632f7472796375612f6c756d652e7376673f76617269616e743d6164617074697665" alt="Stargazers over time" data-canonical-src="https://starchart.cc/trycua/lume.svg?variant=adaptive"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse-engineering and analysis of SanDisk High Endurance microSDXC card (2020) (173 pts)]]></title>
            <link>https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</link>
            <guid>42907766</guid>
            <pubDate>Sun, 02 Feb 2025 10:32:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/">https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</a>, See on <a href="https://news.ycombinator.com/item?id=42907766">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><strong>TL;DR – The SanDisk High Endurance cards use SanDisk/Toshiba <a href="https://www.tomshardware.com/news/wd-sandisk-bics3-64-layer-3d-nand,32328.html" target="_blank" rel="noopener">3D TLC Flash</a>. It took way, way more work than it should have to figure this out (thanks for nothing, SanDisk!).<br>
In contrast, the SanDisk MAX Endurance uses the same 3D TLC in pMLC (pseudo-multi-level cell) mode.</strong></p><p>In a <a href="https://ripitapart.com/2019/08/17/unboxing-and-review-of-sandisk-64gb-microsdxc-high-endurance-card/" target="_blank" rel="noopener">previous blog post</a>, I took a look at SanDisk’s microSD cards that were aimed for use in write-intensive applications like dash cameras. In that post I took a look at its performance metrics, and speculated about what sort of NAND Flash memory is used inside. SanDisk doesn’t publish any detailed specifications about the cards’ internal workings, so that means I have no choice but to reverse-engineer the <del>can of worms</del> card myself.</p><p>In the hopes of uncovering more information, I sent an email to SanDisk’s support team asking about what type of NAND Flash they are using in their High Endurance lineup of cards, alongside endurance metrics like P/E (Program/Erase) cycle counts and total terabytes written (TBW). Unfortunately, the SanDisk support rep couldn’t provide a satisfactory answer to my questions, as they’re not able to provide any information that’s not listed in their public spec sheets. They said that all of their cards use MLC Flash, which I guess is correct if you call TLC Flash 3-bit MLC (which Samsung does).</p><div>
<blockquote><p>Dear Jason,</p>
<p>Thank you for contacting SanDisk® Global customer care. We really appreciate you being a part of our SanDisk® family.</p>
<p>I understand that you wish to know more about the SanDisk® High Endurance video monitoring card, as such please allow me to inform you that all our SanDisk® memory cards uses Multi level cell technology (MLC) flash. However, the read/write cycles for the flash memory is not published nor documented only the read and write speed in published as such they are 100 MB/S &amp; 40 MB/s. The 64 GB card can record Full HD video up to 10,000 hours. To know more about the card you may refer to the link below:</p>
<p><a title="Click to follow link: https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" href="https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" target="_blank" rel="noopener">SANDISK HIGH ENDURANCE VIDEO MONITORING microSD CARD</a></p>
<p>Best regards,<br>
Allan B.<br>
SanDisk® Global Customer Care</p></blockquote>
<p>I’ll give them a silver star that says “You Tried” at least.</p>
<h2>Anatomy of an SD Card</h2>
<p>While (micro)SD cards feel like a solid monolithic piece of technology, they’re made up of multiple different chips, each performing a different role. A basic SD card will have a controller that manages the NAND Flash chips and communicates with the host (PC, camera, etc.), and the NAND Flash itself (made up of 1 or more Flash dies). Bunnie Huang’s blog, Bunnie Studios, has an excellent article on the internals of SD cards, including counterfeits and how they’re made – check it out <a href="https://www.bunniestudios.com/blog/?p=3554" target="_blank" rel="noopener">here</a>.</p>
<div data-shortcode="caption" id="attachment_2132"><p><a href="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png"><img aria-describedby="caption-attachment-2132" data-attachment-id="2132" data-permalink="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/sd-card-anatomy/" data-orig-file="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png" data-orig-size="268,476" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SD Card Anatomy" data-image-description="<p>Block diagram of a typical SD card.</p>
" data-image-caption="<p>Block diagram of a typical SD card.</p>
" data-medium-file="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=169" data-large-file="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=268" src="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=584" alt="SD Card Anatomy" srcset="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png 268w, https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=84&amp;h=150 84w" sizes="(max-width: 268px) 100vw, 268px"></a></p><p id="caption-attachment-2132">Block diagram of a typical SD card.</p></div>
<p>MicroSD cards often (but not always!) include test pads, used to program/test the NAND Flash during manufacture. These can be exploited in the case of <a href="https://blog.acelaboratory.com/pc-3000-flash-monolith-pinout-research.html" target="_blank" rel="noopener">data recovery</a>, or to reuse microSD cards that have a defective controller or firmware by turning the card into a piece of raw NAND Flash – check out Gough Lui’s adventures <a href="https://goughlui.com/2015/04/05/teardown-optimization-comsol-8gb-usb-flash-stick-au6989sn-gt-sdtnrcama-008g/" target="_blank" rel="noopener">here</a>. Note that there is no set standard for these test pads (even for the same manufacturer!), but there are common patterns for some manufacturers like SanDisk that make reverse-engineering easier.</p>
<h2>Crouching Controller, Hidden Test Pads</h2>
<p>microSD cards fall into a category of “monolithic” Flash devices, as they combine a controller and raw NAND Flash memory into a single, inseparable package. Many manufacturers break out the Flash’s data bus onto hidden (and nearly completely undocumented) test pads, which some other memory card and USB drive manufacturers take advantage of to make cheap storage products using failed parts; the controller can simply be electrically disabled and the Flash is then used as if it were a regular chip.</p>
<p>In the case of SanDisk cards, there is very limited information on their cards’ test pad pinouts. Each generation has slight differences, but the layout is mostly the same. <del>These differences can be fatal, as the power and ground connections are sometimes reversed (this spells instant death for a chip if its power polarity is mixed up!).</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>Upon further review, I might have accidentally created a discrepancy between the leaked pinouts online, versus my own documentation in terms of power polarity; see the “Test Pad Pinout” section.</em></p>
<p>My card (and many of their higher-end cards – that is, not their Ultra lineup) features test pads that aren’t covered by solder mask, but are instead covered by some sort of screen-printed epoxy with a laser-etched serial number on top. With a bit of heat and some scraping, I was able to remove the (very brittle) coating on top of the test pads; this also removed the serial number which I believe is an anti-tamper measure by SanDisk.</p>

		
		

<p>After cleaning off any last traces of the epoxy coating, I was greeted with the familiar SanDisk test pad layout, plus a few extra on the bottom.</p>
<h2>Building the Breakout Board</h2>
<p>The breakout board is relatively simple in concept: for each test pad, bring out a wire that goes to a bigger test point for easier access, and wire up the normal SD bus to an SD connector to let the controller do its work with twiddling the NAND Flash bus. Given how small each test pad is (and how many), things get a bit… messy.</p>

		
		

<p>I started by using double-side foam adhesive tape to secure the SD card to a piece of perfboard. I then tinned all of the pads and soldered a small 1uF ceramic capacitor across the card’s power (Vcc) and ground (GND) test pads. Using 40-gauge (0.1 mm, or 4-thousandths of an inch!) magnet wire, I mapped each test pad to its corresponding machine-pin socket on the perfboard. Including the extra test pads, that’s a total of 28 tiny wires!</p>
<p>For the SD connector side of things, I used a flex cable for the <a href="http://xtc2clip.org/how-it-works" target="_blank" rel="noopener">XTC 2 Clip</a> (a tool used to service HTC Android devices), as it acted as a flexible “remote SD card” and broke out the signals to a small ribbon cable. I encased the flex cable with copper tape to act as a shield against electrical noise and to provide physical reinforcement, and soldered the tape to the outer pads on the perfboard for reinforcement. The ribbon cable end was then tinned and each SD card’s pin was wired up with magnet wire. The power lines were then broken out to an LED and resistor to indicate when the card was receiving power.</p>
<h2>Bus Analysis</h2>
<p>With all of the test pads broken out to an array of test pins, it was time to make sense of what pins are responsible for accessing the NAND Flash inside the card.</p>
<h2>Test Pad Pinout</h2>
<div data-shortcode="caption" id="attachment_2165"><p><a href="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png"><img aria-describedby="caption-attachment-2165" data-attachment-id="2165" data-permalink="https://ripitapart.com/sandisk-high-endurance-microsd-test-pad-pinout/" data-orig-file="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png" data-orig-size="1666,935" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SanDisk High Endurance microSD Test Pad Pinout" data-image-description="<p>Diagram of the test pads on SanDisk’s High Endurance microSD card.</p>
" data-image-caption="<p>Diagram of the test pads on SanDisk’s High Endurance microSD card.</p>
" data-medium-file="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300" data-large-file="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584" src="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584&amp;h=328" alt="Diagram of the test pads on SanDisk's High Endurance microSD card." width="584" height="328" srcset="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584 584w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1168 1168w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=150 150w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300 300w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=768 768w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1024 1024w" sizes="(max-width: 584px) 100vw, 584px"></a></p><p id="caption-attachment-2165">Diagram of the test pads on SanDisk’s High Endurance microSD card. (click to enlarge)</p></div>
<p>The overall test pad pinout was the same for other microSD cards from SanDisk<del>, but there were some differences, primarily regarding the layout of the power pads; notably, <strong>the </strong><strong>main power pins are backwards</strong>! This can destroy the card if you’re not careful when applying power.</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>I might actually have just gotten my own documentation mixed up in terms of the power and ground test pads. Regardless, one should always be careful to ensure the correct power polarity is sent to a device.</em></p>
<p>I used my <a href="https://www.dreamsourcelab.com/shop/logic-analyzer/dslogic-plus/" target="_blank" rel="noopener">DSLogic Plus</a> logic analyzer to analyze the signals on all of the pins. Since the data pinout was previously discovered, the hard part of figuring out what each line represented (data bus, control, address, command, write-protect, ready/busy status) was already done for me. However, not all of the lines were immediately evident as the pinouts I found online only included the bare minimum of lines to make the NAND Flash accessible, with one exception being a control line that places the controller into a reset state and releases its control of the data lines (this will be important later on).</p>
<p>By sniffing the data bus at the DSLogic’s maximum speed (and using its 32 MB onboard buffer RAM), I was able to get a clear snapshot of the commands being sent to the NAND Flash from the controller during initialization.</p>
<h2>Bus Sniffing &amp; NAND I/O 101 (writing commands, address, reading data)</h2>
<p>In particular, I was looking for two commands: RESET (0xFF), and READ ID (0x90). When looking for a command sequence, it’s important to know how and when the data and control lines change. I will try to explain it step-by-step, but if you’re interested there is an <a href="https://user.eng.umd.edu/~blj/CS-590.26/micron-tn2919.pdf" target="_blank" rel="noopener">introductory white paper</a> by Micron that explains all of the fundamentals of NAND Flash with much more information about how NAND Flash works.</p>

		
		

<p>When a RESET command is sent to the NAND Flash, first the /CE (Chip Select, Active Low) line is pulled low. Then the CLE (Command Latch Enable) line is pulled high; the data bus is set to its intended value of 0xFF (all binary ones); then the /WE (Write Enable, Active Low) line is pulsed from high to low, then back to high again (the data bus’ contents are committed to the chip when the /WE line goes from low to high, known as a “rising edge”); the CLE line is pulled back low to return to its normal state. The Flash chip will then pull its R/B (Ready/Busy Status) line low to indicate it is busy resetting itself, then releases the line back to its high state when it’s finished.</p>
<p>The READ ID command works similarly, except after writing the command with 0x90 (binary 1001 0000) on the data bus, it then pulls the ALE (Address Latch Enable) line high instead of CLE, and writes 0x00 (all binary zeroes) by pulsing the /WE line low. The chip transfers its internally programmed NAND Flash ID into its internal read register, and the data is read out from the device on each rising edge of the /RE (Read Enable, Active Low) line; for most devices this is 4 to 8 bytes of data.</p>
<h2>NAND Flash ID</h2>
<p>For each NAND Flash device, it has a (mostly) unique ID that identifies the manufacturer, and other functional data that is defined by that manufacturer; in other words, only the manufacturer ID, assigned by the <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="noopener">JEDEC Technology Association</a>, is well-defined.</p>
<p>The first byte represents the Flash manufacturer, and the rest (2 to 6 bytes) define the device’s characteristics, as set out by the manufacturer themselves. Most NAND vendors are very tight-lipped when it comes to datasheets, and SanDisk (and by extension, Toshiba/Kioxia) maintain very strict control, save for some slightly outdated leaked Toshiba datasheets. Because the two aforementioned companies share their NAND fabrication facilities, we can reasonably presume the data structures in the vendor-defined bytes can be referenced against each other.</p>
<p>In the case of the SanDisk High Endurance 128GB card, it has a NAND Flash ID of 0x45 48 9A B3 7E 72 0D 0E. Some of these values can be compared against a <a href="http://www.datasheet.hk/view_download.php?id=2027929&amp;file=0515%5Ctc58teg5dcjtai0_7779332.pdf" target="_blank" rel="noopener">Toshiba datasheet</a>:</p>
<table>
<thead>
<tr>
<th>Byte Value (Hex)</th>
<th>Description/Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>45</td>
<td>
<ul>
<li>Manufacturer: SanDisk</li>
</ul>
</td>
</tr>
<tr>
<td>48</td>
<td>
<ul>
<li>I/O voltage: Presumed 1.8 volts (measured with multimeter)</li>
<li>Device capacity: Presumed 128 GB&nbsp;(unable to confirm against datasheet)</li>
</ul>
</td>
</tr>
<tr>
<td>9A</td>
<td>
<ul>
<li>NAND type: TLC (Triple-Level Cell / 3 bits per cell)</li>
<li>Flash dies per /CE: 4 (card uses four 32GB Flash chips internally)</li>
</ul>
</td>
</tr>
<tr>
<td>B3</td>
<td>
<ul>
<li>Block size: 12 MiB (768 pages per block) excluding spare area (determined outside datasheet)</li>
<li>Page size: 16,384 bytes / 16 kiB excluding spare area</li>
</ul>
</td>
</tr>
<tr>
<td>7E</td>
<td>
<ul>
<li>Planes per /CE: 8 (2 planes per die)</li>
</ul>
</td>
</tr>
<tr>
<td>72</td>
<td>
<ul>
<li>Interface type: Asynchronous</li>
<li>Process geometry: BiCS3 3D NAND (determined outside datasheet)</li>
</ul>
</td>
</tr>
<tr>
<td>0D</td>
<td>
<ul>
<li>Unknown (no information listed in datasheet)</li>
</ul>
</td>
</tr>
<tr>
<td>0E</td>
<td>
<ul>
<li>Unknown (no information listed in datasheet)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Although not all byte values could be conclusively determined, I was able to determine that the <strong>SanDisk High Endurance cards use <a href="https://www.tomshardware.com/news/wd-sandisk-bics3-64-layer-3d-nand,32328.html" target="_blank" rel="noopener">BiCS3 3D TLC NAND Flash</a></strong>, but at least it is <strong>3D NAND</strong> which improves endurance dramatically compared to traditional/planar NAND. Unfortunately, from this information alone, I cannot determine whether the card’s controller takes advantage of any SLC caching mechanisms for write operations.</p>
<p>The chip’s process geometry was determined by looking up the first four bytes of the Flash ID, and cross-referencing it to a line from a configuration file in Silicon Motion’s <a href="https://www.usbdev.ru/files/smi/" target="_blank" rel="noopener">mass production tools</a> for their <a href="http://www.siliconmotion.com/download.php?t=U0wyRnpjMlYwY3k4eU1ERTVMekV3THpBNUwzQnliMlIxWTNReE16Z3lNamd4TWpVMkxuQmtaajA5UFZOTk16STNNU0J3Y205a2RXTjBJR0p5YVdWbUM%3D" target="_blank" rel="noopener">SM3271</a> USB Flash drive controller, and their <a href="http://en.siliconmotion.com/download/product-brief/SM2258XT_Product_Brief_ENG_Q1109.pdf" target="_blank" rel="noopener">SM2258XT</a> DRAM-less SSD controller. These tools revealed supposed part numbers of SDTNAIAMA-256G and SDUNBIEMM-32G respectively, but I don’t think this is accurate for the specific Flash configuration in this card.</p>
<h2>External Control</h2>
<p>I wanted to make sure that I was getting the correct ID from the NAND Flash, so I rigged up a Texas Instruments <a href="https://www.ti.com/tool/MSP-EXP430FR2433" target="_blank" rel="noopener">MSP430FR2433 development board</a> and wrote some (very) rudimentary code to send the required RESET and READ ID commands, and attempt to extract any extra data from the chip’s hidden JEDEC Parameter Page along the way.</p>
<p>My first roadblock was that the MSP430 would reset every time it attempted to send the RESET command, suggesting that too much current was being drawn from the MSP430 board’s limited power supply. This can occur during <a href="https://en.wikipedia.org/wiki/Bus_contention" target="_blank" rel="noopener">bus contention</a>, where two devices “fight” each other when trying to set a certain digital line both high and low at the same time. I was unsure what was going on, since publicly-available information didn’t mention how to disable the card’s built-in controller (doing so would cause it to <a href="https://en.wikipedia.org/wiki/Three-state_logic#Tri-state_Buffer" target="_blank" rel="noopener">tri-state</a> the lines, effectively “letting go” of the NAND bus and allowing another device to take control).</p>
<p>I figured out that the A1 test pad (see diagram) was the controller’s reset line (pulsing this line low while the card was running forced my card reader to power-cycle it), and by holding the line low, the controller would release its control of the NAND Flash bus entirely. After this, my microcontroller code was able to read the Flash ID correctly and consistently.</p>
<div data-shortcode="caption" id="attachment_2122"><p><a href="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png"><img aria-describedby="caption-attachment-2122" data-attachment-id="2122" data-permalink="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/sandisk-he-128gb-nand-flash-id/" data-orig-file="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png" data-orig-size="877,375" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SanDisk High Endurance SD Card NAND Flash ID" data-image-description="" data-image-caption="<p>Reading out the card’s Flash ID with my own microcontroller code.</p>
" data-medium-file="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=300" data-large-file="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=584" src="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=584" alt="Reading out the card's Flash ID with my own microcontroller code." srcset="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png 877w, https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=150&amp;h=64 150w, https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=300&amp;h=128 300w, https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=768&amp;h=328 768w" sizes="(max-width: 877px) 100vw, 877px"></a></p><p id="caption-attachment-2122">Reading out the card’s Flash ID with my own microcontroller code.</p></div>
<h2>JEDEC Parameter Page… or at least what SanDisk made of it!</h2>
<p>The JEDEC Parameter Page, if present, contains detailed information on a Flash chip’s characteristics with far greater detail than the NAND Flash ID – and it’s well-standardized so parsing it would be far easier. However, it turns out that SanDisk decided to ignore the standard format, and decided to use their own proprietary Parameter Page format! Normally the page starts with the ASCII string “JEDEC”, but I got a repeating string of “SNDK” (corresponding with their <a href="https://www.marketbeat.com/stocks/NASDAQ/SNDK/" target="_blank" rel="noopener">stock symbol</a>) with other data that didn’t correspond to anything like the JEDEC specification! Oh well, it was worth a try.</p>
<p>I collected the data with the same Arduino sketch as shown above, and pulled 1,536 bytes’ worth of data; I wrote a quick <a href="https://ideone.com/eLclhy#stdin" target="_blank" rel="noopener">program on Ideone</a> to provide a nicely-formatted hex dump of the first 512 bytes of the Parameter Page data:</p>
<pre>Offset 00:01:02:03:04:05:06:07:08:09:0A:0B:0C:0D:0E:0F 0123456789ABCDEF
------ --+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-- ----------------
0x0000 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B SNDKSNDKSNDKSNDK
0x0010 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B SNDKSNDKSNDKSNDK
0x0020 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 ..... ...H.....A
0x0030 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 Hcj..... ...H...
0x0040 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 ..AHcj..... ...H
0x0050 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 .....AHcj..... .
0x0060 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 ..H.....AHcj....
0x0070 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 . ...H.....AHcj.
0x0080 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 .... ...H.....AH
0x0090 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 cj..... ...H....
0x00A0 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A .AHcj..... ...H.
0x00B0 B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 ....AHcj..... ..
0x00C0 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 .H.....AHcj.....
0x00D0 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08  ...H.....AHcj..
0x00E0 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 ... ...H.....AHc
0x00F0 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 j..... ...H.....
0x0100 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 AHcj..... ...H..
0x0110 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 ...AHcj..... ...
0x0120 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 H.....AHcj..... 
0x0130 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 ...H.....AHcj...
0x0140 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A .. ...H.....AHcj
0x0150 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 ..... ...H.....A
0x0160 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 Hcj..... ...H...
0x0170 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 ..AHcj..... ...H
0x0180 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 .....AHcj..... .
0x0190 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 ..H.....AHcj....
0x01A0 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 . ...H.....AHcj.
0x01B0 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 .... ...H.....AH
0x01C0 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 cj..... ...H....
0x01D0 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A .AHcj..... ...H.
0x01E0 B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 ....AHcj..... ..
0x01F0 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 .H.....AHcj.....</pre>
<p>Further analysis with my DSLogic showed that the controller itself requests a total of 4,128 bytes (4 kiB + 32 bytes) of Parameter Page data, which is filled with the same repeating data as shown above.</p>
<h3>Reset Quirks</h3>
<p>When looking at the logic analyzer data, I noticed that the controller sends the READ ID command twice, but the first time it does so without resetting the Flash (which should normally be done as soon as the chip is powered up!). The data that the Flash returned was… strange to say the least.</p>
<table>
<thead>
<tr>
<th>Byte Value (Hex)</th>
<th>Interpreted Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>98</td>
<td>
<ul>
<li>Manufacturer: Toshiba</li>
</ul>
</td>
</tr>
<tr>
<td>00</td>
<td>
<ul>
<li>I/O voltage: Unknown (no data)</li>
<li>Device capacity: Unknown (no data)</li>
</ul>
</td>
</tr>
<tr>
<td>90</td>
<td>
<ul>
<li>NAND type: SLC (Single-Level Cell / 1 bit per cell)</li>
<li>Flash dies per /CE: 1</li>
</ul>
</td>
</tr>
<tr>
<td>93</td>
<td>
<ul>
<li>Block size: 4 MB excluding spare area</li>
<li>Page size: 16,384 bytes / 16 kiB excluding spare area</li>
</ul>
</td>
</tr>
<tr>
<td>76</td>
<td>
<ul>
<li>Planes per /CE: 2</li>
</ul>
</td>
</tr>
<tr>
<td>72</td>
<td>
<ul>
<li>Interface type: Asynchronous</li>
<li>Process geometry: 70 nm planar</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>This confused me initially when I was trying to find the ID from the logic capture alone; after talking to a contact who has experience in NAND Flash data recovery, they said this is expected for SanDisk devices, which make liberal use of vendor-proprietary commands and data structures. If the fourth byte is to be believed, it says the block size is 4 megabytes, which I think is plausible for a modern Flash device. The rest of the information doesn’t really make any sense to me apart from the first byte indicating the chip is made by Toshiba.</p>
<h2>Conclusion</h2>
<p>I shouldn’t have to go this far in hardware reverse-engineering to just ask a simple question of what Flash SanDisk used in their high-endurance card. You’d think they would be proud to say they use 3D NAND for higher endurance and reliability, but I guess not!</p>
<h2>Downloads</h2>
<p>For those that are interested, I’ve included the logic captures of the card’s activity shortly after power-up. I’ve also included the (very crude) Arduino sketch that I used to read the NAND ID and Parameter Page data manually:</p>
<ul>
<li><a href="https://www.dropbox.com/s/8yolkc756q37mnh/sandisk%20he%20128%20power%20on.dsl?dl=0" target="_blank" rel="noopener">Logic capture #1</a></li>
<li><a href="https://www.dropbox.com/s/hhkl3c0jyk366c3/sandisk%20he%20128%20power%20on%202.dsl?dl=0" target="_blank" rel="noopener">Logic capture #2</a></li>
<li><a href="https://github.com/ginbot86/2433_nandflashtest" target="_blank" rel="noopener">NAND I/O Arduino sketch</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Analyzing the codebase of Caffeine: a high performance caching library (127 pts)]]></title>
            <link>https://adriacabeza.github.io/2024/07/12/caffeine-cache.html</link>
            <guid>42907488</guid>
            <pubDate>Sun, 02 Feb 2025 09:37:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adriacabeza.github.io/2024/07/12/caffeine-cache.html">https://adriacabeza.github.io/2024/07/12/caffeine-cache.html</a>, See on <a href="https://news.ycombinator.com/item?id=42907488">Hacker News</a></p>
Couldn't get https://adriacabeza.github.io/2024/07/12/caffeine-cache.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Life Is More Than an Engineering Problem – Interview with Ted Chiang (206 pts)]]></title>
            <link>https://lareviewofbooks.org/article/life-is-more-than-an-engineering-problem/</link>
            <guid>42907268</guid>
            <pubDate>Sun, 02 Feb 2025 08:53:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lareviewofbooks.org/article/life-is-more-than-an-engineering-problem/">https://lareviewofbooks.org/article/life-is-more-than-an-engineering-problem/</a>, See on <a href="https://news.ycombinator.com/item?id=42907268">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><div><h2>Julien Crockett speaks with Ted Chiang about the search for a perfect language, the state of AI, and the future direction of technology.</h2><div><p><img loading="lazy" decoding="async" data-nimg="fill" sizes="
          (max-width: 768px) 100vw, 
          (max-width: 960px) 750px, 
          750px
        " srcset="https://cdn.lareviewofbooks.org/unsafe/640x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 640w, https://cdn.lareviewofbooks.org/unsafe/750x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 750w, https://cdn.lareviewofbooks.org/unsafe/828x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 828w, https://cdn.lareviewofbooks.org/unsafe/1080x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 1080w, https://cdn.lareviewofbooks.org/unsafe/1200x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 1200w, https://cdn.lareviewofbooks.org/unsafe/1920x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 1920w, https://cdn.lareviewofbooks.org/unsafe/2048x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 2048w, https://cdn.lareviewofbooks.org/unsafe/3840x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 3840w" src="https://cdn.lareviewofbooks.org/unsafe/3840x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg"></p></div></div><p><em>This interview is part of </em><a rel="" target="_self" href="https://lareviewofbooks.org/feature/the-rules-we-live-by/"><em>The Rules We Live By,</em></a><em> a series devoted to asking what it means to be a human living by an ever-evolving set of rules. The series is made up of conversations with those who dictate, think deeply about, and seek to bend or break the rules we live by.</em></p><p>¤</p><p><em>“ONCE IN A WHILE,” Ted Chiang tells me, “an idea keeps coming back over a period of months or even years. […] I start asking, is there an interesting philosophical question that might be illuminated by this idea?” To read Chiang is to experience a master world-builder critically exploring philosophical questions in new ways—from how we should care for an artificial being to what would be the consequence of having a perfect record of the past.</em></p><p><em>Lately, Chiang has trained his eye on artificial intelligence. And Chiang’s takes haven’t gone unnoticed. In a </em><a rel="" target="_self" href="https://lareviewofbooks.org/article/how-to-raise-your-artificial-intelligence-a-conversation-with-alison-gopnik-and-melanie-mitchell/"><em>conversation</em></a><em> I had earlier this year with computer scientist Melanie Mitchell and psychologist Alison Gopnik, they each referenced Chiang when searching for the right framework to discuss AI.</em></p><p><em>Chiang has a knack for descriptively illustrating his points. For example, when discussing whether LLMs might one day develop subjective experience, he explains: “It’s like imagining that a printer could actually feel pain because it can print bumper stickers with the words ‘Baby don’t hurt me’ on them. It doesn’t matter if the next version of the printer can print out those stickers faster, or if it can format the text in bold red capital letters instead of small black ones. Those are indicators that you have a more capable printer but not indicators that it is any closer to actually feeling anything.”</em></p><p><em>For me, the essence of Chiang’s work, however, isn’t his critical take on technology. It’s his humanism—the way he brings to the fore the mundane reality behind existential questions and moments of societal change. It is perhaps for this reason that his work resonates with so many.</em></p><p><em>In our conversation, we discuss how Chiang picks his subjects, the historical search for a perfect language, the state of AI, and what it would take for Chiang to become hopeful about the direction of technology.</em></p><p>¤</p><p><strong>JULIEN CROCKETT: The idea for this interview came from a conversation I had with computer scientist Melanie Mitchell and psychologist Alison Gopnik, in which they referenced your work when describing the state of artificial intelligence and its possible futures. Why do you think scientists and engineers look to your work to explain their own?</strong></p><p><strong>TED CHIANG:</strong> I was actually surprised that my name popped up. I think it was mostly just a coincidence that you interviewed two people who have found that my work resonates with their own. They might be outliers, compared to scientists as a whole.</p><p><strong>What about the other way around—has scientific progress had an effect on the direction of your work?</strong></p><p>I don’t think there has been a clear impact of recent scientific research on my fiction. My stories are mostly motivated by philosophical questions, many of which are not particularly new. Sometimes the way I investigate a philosophical question is inflected by recent developments in science or technology, but the recent developments probably aren’t the motivating impulse.</p><p><strong>Your stories cover a wide range of topics, but I see a through line in your focus on how humans react to societal change—whether it’s a discovery that mathematics is actually inconsistent, as in your 1991 story “Division by Zero,” or a world where we raise robots as children, as in your 2010 novella </strong><em><strong>The Lifecyle of Software Objects</strong></em><strong>. What draws you to a topic?</strong></p><p>Most of the time, when ideas come to me, they leave my attention very quickly. But once in a while, an idea keeps coming back over a period of months or even years. I take that as a signal that I should pay attention and think about the idea in a more intentional way. What that usually means is that I start asking, “Is there an interesting philosophical question that might be illuminated by this idea?” If I can identify that philosophical question, then I can start thinking about different ways a story might help me dramatize it.</p><p><strong>Why is science fiction the best vehicle for you to explore ideas?</strong></p><p>The ideas that most interest me just lean in a science-fictional direction. I certainly think that contemporary mimetic fiction is capable of investigating philosophical questions, but the philosophical questions that I find myself drawn to require more speculative scenarios. In fact, when philosophers pose thought experiments, the scenarios they describe often have a science-fictional feel; they need a significant departure from reality to highlight the issue they’re getting at. When a philosophical thought experiment is supposed to be set in the actual world, the situation often has a contrived quality. For example, the famous “trolley problem” is supposedly set in the actual world, but it describes a situation that is extremely artificial; in the real world, we have safeguards precisely to avoid situations like that.</p><p><strong>What role does science play in your stories? Or, asked another way, what are the different roles played by science and magic in fiction?</strong></p><p>Some people think of science as a body of facts, and the facts that science has collected are important to our modern way of life. But you can also think about science as a process, as a way of understanding the universe. You can write fiction that is consistent with the specific body of facts we have, or you can write fiction that reflects the scientific worldview, even if it is not consistent with that body of facts. For example, take a story where there is faster-than-light travel. Faster-than-light travel is impossible, but the story can otherwise reflect the general worldview of science: the idea that the universe is an extremely complicated machine, and through careful observation, we can deduce the principles by which this machine works and then apply what we’ve learned to develop technology based on those principles. Such a story is faithful to the scientific worldview, so I would argue that it’s a science fiction story even if it is not consistent with the body of facts we currently have.</p><p>By contrast, magic implies a different understanding of how the universe works. Magic is hard to define. A lot of people would say magic definitionally cannot have rules, and that’s one popular way of looking at it. But I have a different take—I would say that magic is evidence that the universe knows you’re a person. It’s not that magic cannot have rules; it’s that the rules are more like the patterns of human psychology or of interactions between people. Magic means that the universe is behaving not as a giant machine but as something that is aware of you as a person who is different from other people, and that people are different from things. At some level, the universe responds to your intentions in a way that the laws of physics as we understand them don’t.</p><p>These are two very different ways of understanding how the universe works, and fiction can engage in either one. Science needs to adhere to the scientific worldview, but fiction is not an engineering project. The author can choose whichever one is better suited to their goals.</p><p><strong>Your work often explores the way tools mediate our relationship with reality. One such tool is language. You write about language perhaps most popularly in “Story of Your Life” (1998), the basis for the film </strong><em><strong>Arrival</strong></em><strong> (2016), but also in “Understand” (1991), exploring what would happen if we had a medical treatment for increasing intelligence. Receiving the treatment after an accident, the main character grows frustrated by the limits of conventional language:</strong></p><br><blockquote><strong>I’m designing a new language. I’ve reached the limits of conventional languages, and now they frustrate my attempts to progress further. They lack the power to express concepts that I need, and even in their own domain, they’re imprecise and unwieldy. They’re hardly fit for speech, let alone thought. […]</strong></blockquote><blockquote><strong>&nbsp;</strong></blockquote><blockquote><strong>I’ll reevaluate basic logic to determine the suitable atomic components for my language. This language will support a dialect coexpressive with all of mathematics, so that any equation I write will have a linguistic equivalent.</strong></blockquote><p><strong>Do you think there could be a “better” language? Or is it just mathematics?</strong></p><p>Umberto Eco wrote a book called <em>The Search for the Perfect Language</em> (1994), which is a history of the idea that there exists a perfect language. At one point in history, scholars believed the perfect language was the language that Adam and Eve spoke in the Garden of Eden or the language angels speak. Later on, scholars shifted to the idea that it was possible to construct an artificial language that was perfect, in the sense that it would be completely unambiguous and bear a direct relationship to reality.</p><p>Modern linguistics holds that this idea is nonsensical. It’s foundational to our modern conception of language that the relationship between any given word and the concept it is assigned to is arbitrary. But I think that many of us can relate to the desire for a language that expresses exactly what we mean unambiguously. We’ve all tried to convey something and wished there were a word for it, but that’s not a problem of English or French or German—that’s a problem of language itself. And even though I know a perfect language is impossible, the idea continues to fascinate me.</p><p>As for the question of whether mathematics could be a better language, the reason that mathematics is useful is precisely what makes it unsuitable as a general language. Mathematics is extremely precise, but it’s limited to a specific domain. Scientists who speak different languages can use the same mathematics, but they still have to rely on their native languages when they publish a paper; they can’t say everything they need to say with equations alone. Language has to support every type of communication that humans engage in, from debates between politicians to pillow talk between lovers. That’s not what mathematics is for. We could be holding this conversation in any human language that we both understand, but we couldn’t hold it in mathematical equations. As soon as you try and modify mathematics so that it can do those things, it ceases to be mathematics.</p><p><strong>I grew up in a French household, and I often feel that there are French words and expressions that better capture what I want to express than any English word or expression could.</strong></p><p>Eco writes that when European scholars were arguing about what language Adam and Eve spoke, each one typically argued in favor of the language he himself spoke. So Flemish scholars said that Adam and Eve obviously must have spoken Flemish, because Flemish is the most perfect expression of human thought.</p><p><strong>Funny. Another tool increasingly mediating our relationship with society and reality is artificial intelligence. You’ve written skeptically about how modern AI systems are being implemented, and one metaphor you use to describe large language models (LLMs) is as </strong><a rel="" target="_self" href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web"><strong>“a blurry JPEG of the web.”</strong></a><strong> What do you mean?</strong></p><p>When we use a search engine, we get verbatim quotes from text on the internet and also a link to the original web page. A search engine gives us information directly from the horse’s mouth. LLMs are like a search engine that rephrases information instead of giving it verbatim or pointing you to the original source. In some respects, that is really cool, but they’re not rephrasing it reliably. It’s like asking a question and getting an answer back from someone who read the answer but didn’t really understand it and is trying to rephrase it to the best of their ability. I call LLMs a blurry JPEG because they give a low-resolution version of the internet. If you are using the internet to find information, which is what most of us use the internet for, it doesn’t really make sense to go with the low-resolution version when we have conventional search engines that point you to the actual information itself.</p><p>It’s entertaining to be able to ask a question and get an answer back in a conversational form, but LLMs are not being marketed as entertainment devices. They’re being marketed as products that will answer your questions accurately, and that’s not what LLMs are doing.</p><p><strong>Do you think that LLMs will become useful tools that can reliably answer questions?</strong></p><p>I don’t want to say LLMs are only good for entertainment; there are many respects in which LLMs are genuinely amazing. The fact that they can rephrase something in any style of prose is fascinating; no one would have predicted that statistical models of all the text on the internet would be capable of that. But predicting the most likely next word is different from having correct information about the world, which is why LLMs are not a reliable way to get the answers to questions, and I don’t think there is good evidence to suggest that they will become reliable. Over the past couple of years, there have been some papers published suggesting that training LLMs on more data and throwing more processing power at the problem provides diminishing returns in terms of performance. They can get better at reproducing patterns found online, but they don’t become capable of actual reasoning; it seems that the problem is fundamental to their architecture. And you can bolt tools onto the side of an LLM, like giving it a calculator it can use when you ask it a math problem, or giving it access to a search engine when you want up-to-date information, but putting reliable tools under the control of an unreliable program is not enough to make the controlling program reliable. I think we will need a different approach if we want a truly reliable question answerer.</p><p><strong>Modern AI systems are one tool in a long line of tools that help us approximate reality. We seem to easily ascribe attributes of ourselves, such as thought and reasoning, to these tools. For example, we regularly describe the brain as a computer and vice versa. Why do you think we see ourselves in our tools?</strong></p><p>There was a time when people compared the brain to a telephone switchboard. The brain is the most complex thing we have ever encountered, and when the telephone switchboard was the most complicated machine we had ever built, we naturally used it as a metaphor when trying to understand what the brain is. But that doesn’t actually tell us anything about how the brain works. The fact that we can now build computers doesn’t mean that the brain is more like a computer than a telephone switchboard. There are many ways in which it is obvious that the brain is not like a computer, but because the computer metaphor is so prevalent, we overlook those differences. Computers consist of software running on hardware, but there is no distinction between software and hardware in biological systems. If you were to apply that metaphor to any other organ in the body, it would seem absurd. For example, “My liver was running this old program, but all I needed to do was update the software and now my liver is functioning much better, even though the hardware is the same.” No one says that. It’s not a useful way of thinking about the liver, and it is not a useful way of thinking about the brain either.</p><p>By the same token, because we imagine that computers are like brains, we are tempted to think of computers as intelligent and engaged in thinking. When we do that, we’re taking this metaphor way too literally. What telephone switchboards did was not so readily mappable to something people do, and that probably deterred people from imagining that a telephone switchboard was engaged in reasoning. But LLMs can generate plausible text, which totally throws us for a loop. LLMs are not engaged in reasoning any more than a telephone switchboard was, but their ability to simulate conversation makes it far easier to imagine that they are.</p><p><strong>You wrote an article called </strong><a rel="" target="_self" href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art"><strong>“Why A.I. Isn’t Going to Make Art”</strong></a><strong> where you argue that generative artificial intelligence reduces the amount of intention in the world because, by using AI tools, we lose the opportunity to make the choices necessary for creating art. What impact are AI tools having on artists and their artwork?</strong></p><p>I should note that I didn’t pick the title of the essay; if I had, I might have called it something like “Why AI Won’t Make Art Easy to Make.” Many people would have you believe that the process of making art and the end result can be easily separated, but I don’t believe they can be. I was talking with someone who is very excited about AI-generated imagery, and she said, “Let’s imagine, for the sake of argument, that AI can make better art than humans. In that scenario, do you think that we should reject AI art simply to protect the livelihood of human artists?” I responded, “I’m not going to grant you that premise, because that is the question under debate. You are framing the hypothetical in a way that assumes the conclusion.” I don’t believe it’s meaningful to say that something is better art absent any context of how it was created. Art is all about context. It’s not an activity like tightening bolts, where I don’t really care whether someone used a conventional wrench or a pneumatic wrench, as long as the bolts are tight.</p><p>As for the impact on artists, I’d say the primary effect of AI tools is that they encourage the idea that art is no different from tightening bolts. Artists have always had to deal with commercial considerations, but it’s probably a more pressing issue now than ever before. The impulse to view everything in terms of efficiency, of reducing costs and maximizing output, is radically overapplied in the modern world. There are certain situations in which that is an appropriate framing, but art cannot be understood that way. Arguably the most important parts of our lives should not be approached with this attitude. Some of this attitude comes from the fact that the people making AI tools are engineers viewing everything from an engineering perspective, but it’s also that, as a culture, we have adopted this way of thinking as the default.</p><p><strong>In French, we would call engineers viewing everything as an engineering problem a “professional deformity.” But an issue perhaps tangentially related to viewing everything as a wrench is “the alignment problem.” Your novella </strong><em><strong>The Lifecycle of Software Objects</strong></em><strong> has been referenced in this context. For example, Alison Gopnik talks about how one way to “align” artificial intelligence with our goals and values could be the same way we align each new generation of humans, through caregiving.</strong></p><p>I don’t like the phrase “the alignment problem.” It’s not clear to me that it refers to something meaningful—or at least that the phrase refers to something that is new and meaningfully different from the broader problems of how to be a good person and how to build a good society. For example, when corporations behave badly, should we consider that an alignment problem? Most of the conversation around the alignment problem suggests that it’s a technical problem, something that can be addressed by implementing a better algorithm or by solving the right equations. But why, for example, do large corporations behave so much worse than most of the people who work for them? I think most of the people who work for large corporations are, to varying degrees, unhappy with the effect those corporations have on the world. Why is that? And could that be fixed by solving a math problem? I don’t think so.</p><p>People who talk about aligning AI with human values imagine that if we could somehow solve this programming problem, then everything would be okay. I don’t see how that follows at all. Imagine you have some hypothetical AI that is better at accomplishing tasks than humans and that does exactly what you tell it to do. Do you want ExxonMobil to have such an AI at its disposal? That doesn’t sound good. Conversely, imagine a hypothetical AI that does what is best for the world as a whole, even if human beings are asking it to do something else. Who would buy such an AI? Certainly not ExxonMobil. I can’t see any corporation buying software that ignores the instructions of humans and does what is best for the world. If that were something that corporations were interested in, do you think they’d be behaving the way they are now?</p><p><strong>But there is something intuitively appealing about the idea of taking what we know about raising children and applying it to an intelligent system, like an AI system, that seems to learn—even if it might not learn in the same way we do.</strong></p><p>The question of whether we can teach AI our values the way parents teach children their values is a very interesting one to me, philosophically. An extremely common ethical guideline is that you should treat others the way you would like to be treated, and this is something that parents try to impress upon their children. When parents do that, they are asking children to put themselves in another person’s place and imagine what their emotional reaction would be, and children often can’t or don’t want to do this, which is why it can take a while for children to learn to play well with others. What would it mean for a machine to do that? We have no idea how to build a machine capable of that. And even if you successfully teach a child to play well with others, that is no guarantee that the child will become an adult who contributes to a good society. The executives of ExxonMobil were almost certainly taught this ethical guideline at some point, and look how well that turned out.</p><p><strong>Could there be value, though, in treating an AI system as more of a partner—something or someone with whom we develop a relationship—rather than merely as a tool?</strong></p><p>It all depends on what you mean by “relationship.” If you’re a woodworker, you might develop emotional associations with a set of chisels you’ve used for years, and in some sense that’s a “relationship,” but it’s entirely different from the relationship you have with people. You might make sure you keep your chisels sharp and rust-free, and say that you’re treating them with respect, but that’s entirely different from the respect you owe to your colleagues. One way to clarify this is to remember that people have their own preferences, while things do not. To respect your colleagues means to pay attention to their preferences and interests and balance them against your own; when they do this to you in return, you have a good relationship. By contrast, your chisel has no preferences; it doesn’t want to be sharp. When you keep it sharp, you are doing so because it will help you do good work or because it gives you a feeling of satisfaction to know that it’s sharp. Either way, you are only serving your own interests, and that’s fine because a chisel is just a tool. If you don’t keep it sharp, you are only harming yourself. By contrast, if you don’t respect your colleagues, there is a problem beyond the fact that it might make your job harder; you do them harm because you are ignoring their preferences. That’s why we consider it wrong to treat a person like a tool; by acting as if they don’t have preferences, you are dehumanizing them.</p><p>AI systems lack preferences; that is true of the systems we have now, and it will be true of any system we build in the foreseeable future. The companies that sell AI systems might benefit if you develop an emotional relationship with their product, so they might create the illusion that AI systems have preferences. But any attempt to encourage people to treat AI systems with respect should be understood as an attempt to make people defer to corporate interests. It might have value to corporations, but there is no value for you.</p><p><strong>In </strong><em><strong>The Lifecycle of Software Objects</strong></em><strong>, the humans develop deep emotional relationships with their digital agents. What characteristics do those digital agents have that make such relationships possible?</strong></p><p>The digital entities in that story have genuine interests and preferences. The premise of the story is that, even though they’re digital, they are in a certain sense alive and have subjective experience. If you’re a responsible pet owner, you will inconvenience yourself to fulfill your pet’s needs, both their physical needs and their psychological ones. The human characters in the story recognize that they have a similar responsibility to their digital pets. They even come to realize that they can’t escape those responsibilities by simply suspending their digital pets the way you might put your laptop in hibernate mode. As an analogy, imagine that you could put your dog or cat into hibernate mode whenever you left on a trip. Your dog or cat might not notice, but even if they did, they might not mind. Now imagine that you could put your child into hibernate mode whenever you were too busy to spend time with them. Your child would absolutely notice, and even if you told them it was for their own good, they would make certain inferences about how much you valued them. That’s the situation the human characters in the story find themselves in.</p><p><strong>Could AI systems one day have those characteristics?</strong></p><p>I believe it’s theoretically possible for us to build digital entities that have subjective experience, inasmuch as I don’t think there’s a physical law that prevents it. We don’t currently have a good idea of how to build such entities. I don’t think we’re going to create them accidentally, because the AI systems we’re building right now are not even heading in the right direction. LLMs are not going to develop subjective experience no matter how big they get. It’s like imagining that a printer could actually feel pain because it can print bumper stickers with the words “Baby don’t hurt me” on them. It doesn’t matter if the next version of the printer can print out those stickers faster, or if it can format the text in bold red capital letters instead of small black ones. Those are indicators that you have a more capable printer but not indicators that it is any closer to actually feeling anything.</p><p><strong>The technology we use also impacts our relationships with one another. In your 2013 story “The Truth of Fact, the Truth of Feeling,” you investigate the unintended consequences that Remem—a product that creates a perfect record of the past—has on human relationships. It seems like the takeaway from your story is that some things are more important than truth</strong>.</p><p>I wouldn’t say that some things are more important than truth. What I was hoping to convey with that story is that there is value in knowing what actually happened, but that is not the end of the discussion. Ideally, we should be able to acknowledge what actually happened without that being the last word on the subject.</p><p><strong>How does that work at a societal level?</strong></p><p>Take the Truth and Reconciliation Commission in South Africa after the fall of apartheid. The truth is essential; it is the only basis from which you can move forward productively. You cannot deny what happened and expect a healthy society to result from that. But once everyone has admitted what they did, there is the opportunity for forgiveness. Society can decide whether punishment is called for and what form it should take; in certain situations, maybe admitting one’s guilt is enough. Once you’ve achieved some kind of reconciliation, it becomes possible to move forward.</p><p><strong>I want to end by asking whether you are optimistic about the future. When I’ve asked this question in previous interviews, some have responded that they are optimistic because it’s a moral duty; it’s what we must be if we want to create a better future. Do you view optimism or hope in this way?</strong></p><p>As usual, we need to be specific about what we mean by “optimism” and “pessimism.” Some people believe that everything will work out fine and we don’t need to devote energy to considering bad outcomes. I think this attitude is extremely common in the tech industry. That’s a kind of optimism, and I definitely don’t fall into that camp. By contrast, some people believe that bad outcomes are inevitable and there’s nothing we can do prevent them. Some might call that pessimism, but I’d say that’s closer to fatalism.</p><p>I think we need to think about the possible bad outcomes and work to mitigate them; if we do that, we have a chance of preventing them from coming to pass. I don’t know if that’s optimism, unless everything except fatalism is optimism. I suppose it might be a moral duty to not be fatalistic. We have to believe that our actions have the potential to make a difference because if we don’t believe that, we won’t take any action at all.</p><p>You can also consider this question within the narrower context of technological development, and ask whether one thinks that the risk of bad outcomes is serious enough that we should slow down our pursuit of new technologies. In this framing, optimists are the ones who say no, the risks aren’t that serious, while pessimists are the ones who say yes, the risks are very serious. My stance on this has probably shifted in a negative direction over time, primarily because of my growing awareness of how often technology is used for wealth accumulation. I don’t think capitalism will solve the problems that capitalism creates, so I’d be much more optimistic about technological development if we could prevent it from making a few people extremely rich.</p><p>¤</p><p><em>Ted Chiang’s fiction has won four Hugo, four Nebula, and four Locus Awards, and has been featured in&nbsp;The Best American Short Stories. His debut collection,&nbsp;</em>Stories of Your Life and Others<em> (2002), has been translated into 21 languages. He was born in Port Jefferson, New York, and currently lives near Seattle.</em></p><p>¤</p><p><em>Featured image: Cover of </em>The Lifecycle of Software Objects<em>, illustration by Christian Pearce.</em></p><div><p>LARB Contributor</p><p>Julien Crockett is an intellectual property attorney and the science and law editor at the <em>Los Angeles Review of Books</em>. He runs the <em>LARB</em> column <a rel="" target="_self" href="https://lareviewofbooks.org/feature/the-rules-we-live-by/">The Rules We Live By,</a> exploring what it means to be a human living by an ever-evolving set of rules.</p></div><section><h3>LARB Staff Recommendations</h3><ul><li><article><h2><a href="https://lareviewofbooks.org/article/the-technologies-that-remake-us-on-ted-chiangs-exhalation-stories/">The Technologies That Remake Us: On Ted Chiang’s “Exhalation: Stories”</a></h2><p>“Exhalation: Stories” is a stunning achievement in speculative fiction, from an author whose star will only continue to rise.</p></article></li><li><article><h2><a href="https://lareviewofbooks.org/article/how-to-raise-your-artificial-intelligence-a-conversation-with-alison-gopnik-and-melanie-mitchell/">How to Raise Your Artificial Intelligence: A Conversation with Alison Gopnik and Melanie Mitchell</a></h2><p>Julien Crockett interviews Alison Gopnik and Melanie Mitchell about complexity and learning in AI systems, and our roles as caregivers.</p><p><span><a href="https://lareviewofbooks.org/contributor/julien-crockett/">Julien Crockett</a></span><span>May 31, 2024</span></p></article></li></ul></section><div><h4><a href="https://lareviewofbooks.org/donate/">Did you enjoy this article?</a></h4><hr><p>LARB depends on the support of readers to publish daily without a paywall. Please support the continued work of our writers and staff by making a tax-deductible donation today!</p></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CDC orders mass retraction of research across all science and medicine journals (754 pts)]]></title>
            <link>https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction</link>
            <guid>42905937</guid>
            <pubDate>Sun, 02 Feb 2025 04:52:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction">https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction</a>, See on <a href="https://news.ycombinator.com/item?id=42905937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em>I believe we are breaking news some news here. To help sustain independent journalism and analysis, please support Inside Medicine. Thanks for reading…</em></p><p><span>The CDC has instructed its scientists to retract or pause the publication of any research manuscript being considered by </span><em>any medical or scientific journal</em><span>, not merely its own internal periodicals, </span><em>Inside Medicine </em><span>has learned. The move aims to ensure that no “forbidden terms” appear in the work. The policy includes manuscripts that are in the revision stages at journal (but not officially accepted) and those already accepted for publication but not yet live. </span></p><p>In the order, CDC researchers were instructed to remove references to or mentions of a list of forbidden terms: “Gender, transgender, pregnant person, pregnant people, LGBT, transsexual, non-binary, nonbinary, assigned male at birth, assigned female at birth, biologically male, biologically female,” according to an email sent to CDC employees (see below).”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png" width="215" height="296.3633241758242" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2007,&quot;width&quot;:1456,&quot;resizeWidth&quot;:215,&quot;bytes&quot;:6395981,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>A screenshot of a CDC email shared with </span><em>Inside Medicine</em><span> of a list of terms that must be removed from any CDC-authored manuscript being seriously considered or “in press” (but not yet online or in print) at any medical or scientific journal.</span></figcaption></figure></div><p><span>The policy goes beyond the previously </span><a href="https://insidemedicine.substack.com/p/uganda-confirms-a-new-ebola-outbreak" rel="">reported</a><span> pause of the CDC’s own publications, including </span><em>Morbidity and Mortality Weekly Report </em><span>(MMWR), which has seen two issues go unreleased since January 16, marking the first publication gap of any kind in approximately 60 years. </span><em>Emerging infectious Diseases</em><span> and </span><em>Preventing Chronic Disease</em><span>, the CDC’s other major publications, also remain under lock and key, but have not yet been affected because they are monthly releases and both were released as scheduled in January, prior to President Trump’s inauguration. The policy also goes beyond the general communications gag order that already prevents any CDC scientist from submitting any new scientific findings to the public. </span></p><p><span>The edict applies to both any previously submitted manuscript under consideration and those accepted but not yet published. For example, if CDC scientists previously submitted a manuscript to </span><em>The New England Journal of Medicine, The Journal of the American Medical Association, </em><span>or any other publication, the article must be stopped and reviewed. (These are hypothetical, but are examples of major journals where CDC officials often publish.)</span></p><p><span>How many manuscripts are affected is unclear, but it could be many. Most manuscripts include simple demographic information about the populations or patients studied, which typically includes gender (and which is frequently used interchangeably with sex). That means just about any major study would fall under the censorship regime of the new policy, including studies on Covid-19, cancer, heart disease, </span><em>or anything else,</em><span> let alone anything that the administration considers to be “woke ideology.” </span></p><p>Meanwhile, chaos and fear are already guiding decisions. While the policy is only meant to apply to work that might be seen as conflicting with President Trump’s executive orders, CDC experts don’t know how to interpret that. Do papers that describe disparities in health outcomes fall into “woke ideology” or not? Nobody knows, and everyone is scared that they’ll be fired. This is leading to what Germans call “vorauseilender Gehorsam,” or “preemptive obedience,” as one non-CDC scientist commented. </p><p>“I’ve got colleagues pulling papers over Table 1 concerns,” an official told me. (Table 1 refers to basic demographic information about the study populations included in research papers, rather than actual results.) Indeed, many studies include demographic information about sexual orientation. For example, a study describing mpox outcomes would likely include basic statistics in tables summarizing the percentage of patients who were vaccinated and were lesbian, gay, transgender, or otherwise. This information can be highly impactful during an outbreak, as it helps clinicians develop policies on who to vaccinate (given limited doses, as is the case with mpox), and even to whom scarce and limited supplies of tests and treatments should be offered to maximize benefits. </p><p>It is not necessarily the case that researchers who have submitted articles but who have not yet received an official decision from a journal need to actively recall them, however. But if a journal sends an article back for revisions, the authors would at that point have to cleanse the document of any “problematic language.” Of course, at that point, the gag order already in place would halt any resubmission. </p><p data-attrs="{&quot;url&quot;:&quot;https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>What can and cannot go forward appears to require approval by a Trump political appointee, an explicit requirement for any public health communications under the Trump Administration’s gag order. That’s slowing many things down. At present, there is only one political appointee in the entire CDC, acting Director Susan Monarez (plus her personal assistant, who is not a scientist). It’s unclear if some decisions may be devolved to lower officials. For example, if a paper is pulled because it simply mentions gender, it is unknown if anyone other than Monarez possesses the authority to approve its resubmission. </p><p>“How can one person vet all of this?” another official asked, “especially one who, [like Monarez], came from an agency of, what, 130 people?”</p><p>And yet, that seems to be the theme of the new administration: a few privileged individuals have been handed enormous authority, creating a backlog of decisions that may end up being fairly arbitrarily determined.</p><p data-attrs="{&quot;url&quot;:&quot;https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recent results show that LLMs struggle with compositional tasks (259 pts)]]></title>
            <link>https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/</link>
            <guid>42905453</guid>
            <pubDate>Sun, 02 Feb 2025 03:21:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/">https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/</a>, See on <a href="https://news.ycombinator.com/item?id=42905453">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>On December 17, 1962,&nbsp; <em>Life International</em> published <a href="https://www.researchgate.net/publication/341189675_Is_Einstein's_Puzzle_Over-Specified">a logic puzzle</a> consisting of 15 sentences describing five houses on a street. Each sentence was a clue, such as “The Englishman lives in the red house” or “Milk is drunk in the middle house.” Each house was a different color, with inhabitants of different nationalities, who owned different pets, and so on. The story’s headline asked: “Who Owns the Zebra?” Problems like this one have proved to be a measure of the abilities — limitations, actually — of today’s machine learning models.</p>
<p>Also known as Einstein’s puzzle or riddle (likely an apocryphal attribution), the problem tests a certain kind of multistep reasoning. <a href="https://nouhadziri.github.io/">Nouha Dziri</a>, a research scientist at the Allen Institute for AI, and her colleagues recently set transformer-based large language models (LLMs), such as ChatGPT, to work on such tasks — and largely found them wanting. “They might not be able to reason beyond what they have seen during the training data for hard tasks,” Dziri said. “Or at least they do an approximation, and that approximation can be wrong.”</p>
<p>Einstein’s riddle requires composing a larger solution from solutions to subproblems, which researchers call a compositional task. Dziri’s team showed that LLMs that have only been trained to predict the next word in a sequence — which is most of them — are <a href="https://arxiv.org/abs/2305.18654">fundamentally limited</a> in their ability to solve compositional reasoning tasks. Other researchers have shown that transformers, the neural network architecture used by most LLMs, have hard mathematical bounds when it comes to solving such problems. Scientists have had some successes pushing transformers past these limits, but those increasingly look like short-term fixes. If so, it means there are fundamental computational caps on the abilities of these forms of artificial intelligence — which may mean it’s time to consider other approaches.</p>
<p>“The work is really motivated to help the community make this decision about whether transformers are really the architecture we want to embrace for universal learning,” said <a href="https://cims.nyu.edu/~andrewgw/">Andrew Wilson</a>, a machine learning expert at New York University who was not involved with this study.</p>
<h2><strong>Success Begets Scrutiny</strong></h2>

<p>Ironically, LLMs have only themselves to blame for this discovery of one of their limits. “The reason why we all got curious about whether they do real reasoning is because of their amazing capabilities,” Dziri said. They dazzled on tasks involving natural language, despite the seeming simplicity of their training. During the training phase, an LLM is shown a fragment of a sentence with the last word obscured (though technically it isn’t always a single word). The model predicts the missing information and then “learns” from its mistakes.</p>
<p>The largest LLMs — OpenAI’s o1 and GPT-4, Google’s Gemini, Anthropic’s Claude — train on almost all the available data on the internet. As a result, the LLMs end up learning the syntax of, and much of the semantic knowledge in, written language. Such “pre-trained” models can be further trained, or fine-tuned, to complete sophisticated tasks <a href="https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/">far beyond</a> simple sentence completion, such as summarizing a complex document or generating code to play a computer game. The results were so powerful that the models seemed, at times, <a href="https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/">capable of reasoning</a>. Yet they also failed in ways both obvious and surprising.</p>
<p>“On certain tasks, they perform amazingly well,” Dziri said. “On others, they’re shockingly stupid.”</p>
<figure>
    <p><img width="1834" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-scaled.jpg" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-scaled.jpg 1834w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-1232x1720.jpg 1232w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-373x520.jpg 373w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-768x1072.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-1100x1536.jpg 1100w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-1467x2048.jpg 1467w" sizes="(max-width: 1834px) 100vw, 1834px">    </p>
            <figcaption>
                            <p>Nouha Dziri and her team helped show the difficulty current AI systems have with certain kinds of reasoning tasks.</p>
            <p>Allen Institute for AI</p>
        </figcaption>
    </figure>

<p>Take basic multiplication. Standard LLMs, such as ChatGPT and GPT-4, fail badly at it. In early 2023 when Dziri’s team asked GPT-4 to multiply two three-digit numbers, it initially succeeded only 59% of the time. When it multiplied two four-digit numbers, accuracy fell to just 4%.</p>
<p>The team also tested the LLMs on tasks like Einstein’s riddle, where it also had limited success. GPT-4 always got the right answer when the puzzle involved two houses with two attributes per house. But the accuracy fell to 10% when the complexity of the puzzle increased to four houses with four attributes per house. For the original version in <em>Life International</em> — five houses, each with five attributes — the success rate was 0%.</p>
<p>Dziri’s team thought that maybe the LLMs simply hadn’t seen enough examples in their training data, so they fine-tuned GPT-3 on 1.8 million examples of multiplying two numbers. Then, when they showed it new problems, the LLM aced them — but only if they were sufficiently similar to what it had seen during training. For example, the training data included the multiplication of two three-digit numbers, and of a two-digit number with a four-digit number, but when the model was asked to multiply a four-digit number with a three-digit number, it succeeded only 2% of the time. “If they are truly reasoning and understanding certain tasks, they should get the implicit algorithm,” Dziri said. That’s not what her team saw. “That raises a lot of questions about how LLMs perform tasks and whether they’re doing true reasoning.”</p>
<p>The team observed the same pattern when it came to solving Einstein’s riddle: GPT-3 failed when asked to answer bigger versions of the puzzle compared to the ones it was fine-tuned on. “It’s mimicking something that it has seen, but it doesn’t have full understanding of it,” Dziri said.</p>
<h2><strong>Hard Limits</strong></h2>

<p>As Dziri and her co-authors were finalizing their results, a different team was taking another approach to understanding why LLMs struggled with compositional tasks. <a href="https://www.cs.columbia.edu/~binghuip/">Binghui Peng</a>, at the time a doctoral student at Columbia University, was working with one of his advisers, Christos Papadimitriou, and colleagues to understand why LLMs “hallucinate,” or generate factually incorrect information. Peng, now a postdoctoral researcher at Stanford University, suspected it was because transformers seem to lack the “capability of composition.”</p>
<p>To understand why, imagine we feed an LLM two pieces of information: The father of Frédéric Chopin was Nicolas Chopin, and Nicolas Chopin was born on April 15, 1771. If we then ask it, “What is the birth date of Frédéric Chopin’s father?” the LLM would have to answer by composing, or putting together, the different facts. In effect, it would need to answer the following nested question: “What is the birth date of (Who is the father of (Frédéric Chopin)?)?” If the LLM predicts the wrong words as an answer, it’s said to have hallucinated — in this case, possibly as a result of failing to solve the compositional task.</p>
<p>Peng wanted to test this hunch. His team started by studying the properties of a simple transformer, one with only a single layer, which learns to “pay attention” to the ordering and position of a sentence’s words when trying to predict the next word. (Modern LLMs have scores of such layers.) The team <a href="https://arxiv.org/abs/2402.08164">established a link</a> between the complexity of the transformer layer and the “domain size,” or the number of bits required to represent the questions. By focusing on this simple model, they proved a mathematical bound. “If the total number of parameters in this one-layer transformer is less than the size of a domain, then transformers provably cannot solve the compositional task,” Peng said. In other words, an LLM with only one transformer layer was clearly and mathematically limited.</p>
<p>While this was a strong theoretical result, its practical implications weren’t clear, because modern LLMs are so much more complex. “It’s not easy to extend our proof,” Peng said. So his team used a different approach to study the abilities of more complicated transformers: They turned to computational complexity theory, which studies problems in terms of the resources, such as time and memory, needed to solve them.</p>
<figure>
    <p><img width="2560" height="2133" src="https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-scaled.jpg" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-scaled.jpg 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-1720x1433.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-520x433.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-768x640.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-1536x1280.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-2048x1707.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">    </p>
            <figcaption>
                            <p>Binghui Peng is part of a team that showed transformers, which underlie most large language models, have inherent mathematical limits to their abilities.</p>
            <p>Courtesy of Binghui Peng</p>
        </figcaption>
    </figure>

<p>They ended up using a well-known conjecture to show that the computational power of even multilayer transformers is limited when it comes to solving complicated compositional problems. Then, in December 2024, Peng and colleagues at the University of California, Berkeley <a href="https://arxiv.org/abs/2412.02975">posted a proof</a> — without relying on computational complexity conjectures — showing that multilayer transformers indeed cannot solve certain complicated compositional tasks. Basically, some compositional problems will always be beyond the ability of transformer-based LLMs.</p>
<p>“If your model gets larger, you can solve much harder problems,” Peng said. “But if, at the same time, you also scale up your problems, it again becomes harder for larger models.” This suggests that the transformer architecture has inherent limitations.</p>
<h2><strong>Pushing the Boundaries</strong></h2>

<p>To be clear, this is not the end of LLMs. Wilson of NYU points out that despite such limitations, researchers are beginning to augment transformers to help them better deal with, among other problems, arithmetic. For example, <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>, a computer scientist at the University of Maryland, and his colleagues <a href="https://arxiv.org/abs/2405.17399">added a twist</a> to how they presented numbers to a transformer that was being trained to add, by embedding extra “positional” information in each digit. As a result, the model could be trained on 20-digit numbers and still reliably (with 98% accuracy) add 100-digit numbers, whereas a model trained without the extra positional embedding was only about 3% accurate. “This suggests that maybe there are some basic interventions that you could do,” Wilson said. “That could really make a lot of progress on these problems without needing to rethink the whole architecture.”</p>
<p>Another way to overcome an LLM’s limitations, beyond just increasing the size of the model, is to provide a step-by-step solution of a problem within the prompt, a technique known as <a href="https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321/">chain-of-thought</a> prompting. Empirical studies have shown that this approach can give an LLM such as GPT-4 a newfound ability to solve more varieties of related tasks. It’s not exactly clear why, which has led many researchers to study the phenomenon. “We were curious about why it’s so powerful and why you can do so many things,” said <a href="https://haotianye.com/">Haotian Ye</a>, &nbsp;a doctoral student at Stanford University.</p>
<p>When Ye was still an undergraduate at Peking University, he and his colleagues <a href="https://arxiv.org/abs/2305.15408">modeled the behavior of transformers</a> with and without chain-of-thought prompting. Their proof, using another branch of computer science called circuit complexity theory, established how chain-of-thought prompting essentially turns a large problem into a sequence of smaller problems, making it possible for transformers to tackle more complex compositional tasks. “That means … it can solve some problems that lie in a wider or more difficult computational class,” Ye said.</p>
        
        
<p>But, Ye cautions, their result does not imply that real-world models will actually solve such difficult problems, even with chain-of-thought. The work focused on what a model is theoretically capable of; the specifics of how models are trained dictate how they can come to achieve this upper bound.</p>
<p>Ultimately, as impressive as these results are, they don’t contradict the findings from Dziri’s and Peng’s teams. LLMs are fundamentally matching the patterns they’ve seen, and their abilities are constrained by mathematical boundaries. Embedding tricks and chain-of-thought prompting simply extends their ability to do more sophisticated pattern matching. The mathematical results imply that you can always find compositional tasks whose complexity lies beyond a given system’s abilities. Even some newer “state-space models,” which have been touted as more powerful alternatives to transformers, <a href="https://arxiv.org/abs/2405.16674">show similar limitations</a>.</p>
<p>On the one hand, these results don’t change anything for most people using these tools. “The general public doesn’t care whether it’s doing reasoning or not,” Dziri said. But for the people who build these models and try to understand their capabilities, it matters. “We have to really understand what’s going on under the hood,” she said. “If we crack how they perform a task and how they reason, we can probably fix them. But if we don’t know, that’s where it’s really hard to do anything.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tools for 2025 (111 pts)]]></title>
            <link>http://yosemitesam.ch/3-tools-for-2025/</link>
            <guid>42904966</guid>
            <pubDate>Sun, 02 Feb 2025 02:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://yosemitesam.ch/3-tools-for-2025/">http://yosemitesam.ch/3-tools-for-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=42904966">Hacker News</a></p>
Couldn't get http://yosemitesam.ch/3-tools-for-2025/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Musk aides gain access to sensitive Treasury payment system (103 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/</link>
            <guid>42904200</guid>
            <pubDate>Sun, 02 Feb 2025 00:38:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/">https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/</a>, See on <a href="https://news.ycombinator.com/item?id=42904200">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Avoid ISP Routers (285 pts)]]></title>
            <link>https://routersecurity.org/ISProuters.php</link>
            <guid>42903576</guid>
            <pubDate>Sat, 01 Feb 2025 23:17:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://routersecurity.org/ISProuters.php">https://routersecurity.org/ISProuters.php</a>, See on <a href="https://news.ycombinator.com/item?id=42903576">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>&nbsp; 

<p>In my opinion, you are <b>safest</b> using <i>both</i> a modem and a router that <i>you purchased</i> on your own. That is, <b>avoid  
  equipment from your ISP</b>. I say this for a number of reasons:   </p><ul>
  
<li> The devices shipped by ISPs suffer from a general level of incompetence both in their initial configuration and ongoing maintenance. 
	  If nothing else, just the fact that an ISP would install a device with the default password, tells you everything you need to know about 
	  their  interest in your security.</li>
<li>Security and convenience are always at odds with each other. Most likely an ISP will configure a router for maximum convenience to cut down on tech support calls, which cost them money. </li>
<li>Spying: We have seen that ISPs, at times, co-operate with spy agencies and governments. Even without outside influence, an ISP may well put a 
	        backdoor in the devices they give to their customers, if for no other reason than to make their life easier in some way. In this article, <a href="https://harrisonsand.com/your-isp-is-spying-on-you/">Your ISP is Probably Spying On You</a> (Feb. 2018) Harrison Sand found his router 
			was collecting information about LAN side devices and sending it the ISP.</li>		
<li>Don't be a prime target. Any router provided by an ISP to millions of customers is a prime target for bad guys and spies. More 
	     bang for the hacking buck. You are safer using a less popular device.</li>

		 <li>Many ISPs want to implement public WiFi networks in your home and there is no reason to assume these are done securely.  For my 
	    take on Comcast see <a href="http://www.computerworld.com/article/2476444/mobile-security/comcast-xfinity-wifi--just-say-no.html">Comcast XFINITY WiFi: 
		  Just say no</a>.    Cablevision is <a href="https://www.techdirt.com/articles/20150721/10254131714/cablevision-follows-comcast-down-compulsory-wifi-hotspot-rabbit-hole.shtml">doing
		   the same thing</a>, which prompted Timothy Geigner to write: "This sort of news should serve to do nothing other than compel anyone who wishes
		   to remain a Cablevision customer to buy their own router and modem". See also <a href="http://betanews.com/2016/01/27/one-in-three-home-routers-will-double-as-a-public-hotspot-by-2017/">One in three home routers will double as a public
		   hotspot by 2017</a>.  According to <a href="https://www.juniperresearch.com/press/press-releases/1-in-3-home-wi-fi-routers-to-double-as-public-hots">Juniper  Research</a> the term for this is a "homespot router".</li>		   
<li>Sometimes equipment from an ISP is locked down. I have heard of cases where customers could not change a password  and where the DNS servers could not be 	 changed. I am told that in England, BT Business Hub and Sky Broadband prevent you from modifying the DNS servers and that much of France is also prevented from changing them. I ran into a Comcast-provided Arris TG1682G gateway where I could not <a href="http://m.setuprouter.com/router/arris/tg1682g/ip-address.htm">change the LAN IP address</a> of the box. I could change the subnet, but the router was always device number one which makes it a sitting duck for assorted router attacks.</li>	  
	<li>The ability to update the firmware may also be locked down. You should have full control over firmware updates.</li>	 
	<li>Backup: an ISP will give one device. Should it fail at an inopportune time, you will be off-line until you get them to issue a replacement. When you own your own 
	      hardware, you can buy a second modem and/or a router for emergency backup.</li> 
	<li>It may well be cheaper in the long run to buy your own hardware</li></ul>  

<p>As to the last point,  some ISPs charge a rental fee for the box they provide, be it just a modem or a full fledged gateway.  
     Buying your own will pay for itself soon enough. Time Warner customers looking to buy their own modem can purchase one from <a href="http://www.timewarnercable.com/en/support/internet/topics/buy-your-modem.html">this list</a> or <a href="http://www.timewarnercable.com/en/enjoy/better-twc/internet/internet-modems.html">this one</a>. Comcast users should 
   review <a href="http://mydeviceinfo.comcast.net/">mydeviceinfo.comcast.net</a>. </p> 
   
<p>October 11, 2024: My opinion is that of someone in the US and thus it may only be valid in the US. As a country, we are trending to very big companies in many different areas.  Internet Service Providers are part of this trend. Many (very likely most) people in the US are served by a single ISP. Different areas of the US have virtual monopolies when it comes to high speed Internet access. An ISP with a virtual monopoly has no motivation to do a good job. Their customers are captives. Their only goal is making money, so it is to be expected that they would provide the cheapest hardware that does the job. And, since added security will always result in more tech support calls, and these calls cost the ISP money, it is reasonable to expect that security is not a priority. If you live in a country with real competition for high speed Internet access, things might be better. </p> 
   
<p>In June 2022, on a financial Forum, someone asked <a href="https://www.bogleheads.org/forum/viewtopic.php?p=6722588">Which is the best (most secure) home internet router for the money?</a>. One response hit home: 
 <i>"I've been on the vendor side selling networking equipment to carriers and cable companies. Their priorities for customer premises equipment (consumer) are cost, remote management and cost. Not to say their routers are bad, but you can do better."</i> To re-phrase that, ISPs want cheap routers that they can control.</p> 
 
   
<h3>ISPs SCREWING UP</h3>

<p>May 2, 2023: This is not about security, but it does show how little Spectrum cares about the boxes they give out to customers<br>
<a href="https://www.dailydot.com/news/spectrum-router-filled-with-roaches/">'Somebody had to see that before they shipped it out': Spectrum customer receives router with a live roach colony inside</a> by Jack Alban for Daily Dot. About a posting by TikToker user Fleur who was sent a router infested with cockroaches.</p>  

 <p>In November 2021, we learned of a DNS rebinding flaw in <a href="https://www.bbc.com/news/technology-59332840">six million</a> Sky routers (they are a large ISP in the U.K.). Adding insult to injury, Sky took 18 months to fix the problem and often ignored the company that found and reported the flaw, Pen Test Partners. See <a href="https://www.pentestpartners.com/security-blog/skyfail-6-million-routers-left-exposed/">SkyFail. 6 million routers left exposed</a>. </p> 
 
<p>In September 2021 we learned that  Virgin Media failed to fix a reported flaw in their routers for over two years. See: <a href="https://www.pcmag.com/news/virgin-media-routers-left-vpn-users-vulnerable-since-at-least-2019">Virgin Media Routers Left VPN Users Vulnerable Since at Least 2019</a> by   Nathaniel Mott for PC Magazine. </p>
	
<p>A privacy issue with IP Version 6 (IPv6) was disclosed at a <a href="https://www.blackhat.com/us-21/briefings/schedule/#ipvseeyou-exploiting-leaked-identifiers-in-ipv-for-street-level-geolocation-22889">BlackHat presentation</a> in August 2021. It is not a flaw in IPv6, instead it is lazy, stupid, ignorant choices made by assorted ISPs that continue to include a MAC address as part of the public IPv6 address. We have known for 20 years that this is a bad idea. Yet, ISPs continue to do it. For the details see <a href="https://www.tomsguide.com/news/home-gateway-geolocation-bh21">Your Wi-Fi router could tell everyone where you live - here's what you can do about it</a> by Paul Wagenseil of Toms Guide. Researchers found over 12 million routers/gateways that included a MAC address (which should be private) in the public IPv6 address. In the US they found more than 1 million Comcast Xfinity gateway routers with this design flaw. </p>
 
<p>  In May 2019, British ISP Sky Broadband updated their broadband hubs and knocked some customers off-line. Specifically, if the customer had configured the device to use DNS servers not from Sky Broadband. It seems the latest update also removed the ability to change DNS servers altogether. See <a href="https://www.theregister.co.uk/2019/04/29/sky_bricks_broadband_hubs/">Sky customers moan: Our broadband hubs are bricking it</a> and read the many comments.</p>

<p>In December 2018, <a href="https://www.tenable.com/security/research/tra-2019-17">Tenable found three bugs</a> in a Verizon FIOS router/gateway. Reading the Disclosure Timeline tells you all you need to know - not to use hardware provided by Verizon. For one thing, Verizon did not write the firmware, so they have to farm out the bug fix. Then, two bugs are dealt with by one group, while the third bug is dealt with by another group. Two bugs were already known but had not been fixed. Verizon's response was slow and bureaucratic and they have no plans to say anything publicly about the bugs.</p>
 
<p>In May 2018, we learned that <a href="https://www.zdnet.com/article/comcast-bug-leaks-xfinity-home-addresses-wireless-passwords/">Comcast website bug leaks Xfinity customer data</a>. The Comcast website (register.be.xfinity.com/activate), which was/is used by customers to set up their home services, could be hacked to display a customers home address, Wi-Fi network name and Wi-Fi password. And, not just display, an attacker could also change the SSID and/or Wi-Fi password. But, the issue was only for customers using equipment from Comcast. Those with their own routers were safe. An attacker only need to provide the  customer account number and their house or apartment number. If you lived at 123 Main Street, all the attacker needed to know was 123. Comcast claimed they fixed the problem, but we have no idea how long this vulnerability has existed.</p> 

<p>Then, in June 2018, we learned of <a href="https://www.zdnet.com/article/comcast-fixes-another-xfinity-website-data-leak/">another data leak by Comcast</a>. Any device on the network of a Comcast customer, could call an API and learn the account number, the customer's home address, the account type, and any services enabled on the line. </p>

<p><a href="https://motherboard.vice.com/en_us/article/mbkgn8/dont-rent-a-modem-from-comcast">For the Love of God, Stop Renting Routers From Comcast</a> by 
Karl Bode May 24 2018. On the one hand, this article brings up many different and valid points, both financial and technical. On the other hand, the author seems clueless about the difference between a router a modem and a gateway.</p>

<p>Talk Talk is a British ISP and telco. In May 2018, their routers were <a href="https://www.indigofuzz.com/article.php?docid=talktalk1430">confirmed vulnerable</a>    to the classic WPS pin code attack, first seen back in 2011. You can't make this stuff up. The flaw was discovered by a company called IndigoFuzz using a Windows program called Dumpper.</p>


<p>Another British ISP, EE, distributes gateways (combination modem and router) with a backdoor account. This came to light in October 2018, see  <a href="https://www.theregister.co.uk/2018/10/26/ee_4gee_hh70_ssh_backdoor/">this article</a> from The Register. The backdoor account in their 4GEE HH70 gateways was accessible via SSH from the LAN (inside) side of the router. Worse, when the problem was reported to EE they blew it off, until The Register got involved. Even after the bad publicity, it was still not clear whether a patch had been rolled out or not. Eventually, The Register learned that EE had issued a patch, but customers have to install the new firmware themselves.</p> 
   
<p>In November 2017, a <a href="https://arstechnica.com/information-technology/2017/11/internet-paralyzing-mirai-botnet-comes-roaring-back-with-new-strain/">new botnet was discovered</a> that abused flaws in ZyXEL devices. Bad guys could remotely login to the routers/gateways using a default userid/password because a port was left open. In addition, the devices also had a hard coded superuser password, which gave attackers root privileges. Roughly 100,000 infected devices were detected, almost all of them in Argentina, specifically in the network of Telefonica de Argentina. Obviously, the ISP is at fault for giving so many of their customers devices with the same passwords.</p> 

<p>In September 2017, ESET reported that some ISPs (in two countries they refused to name) appear to be co-operating in the distribution of spyware. 
 <a href="https://www.welivesecurity.com/2017/09/21/new-finfisher-surveillance-campaigns/">New FinFisher surveillance campaigns: Internet providers involved?</a> by Filip Kafka Sept. 21,  2017. Quoting: <i>"New surveillance campaigns utilizing FinFisher, infamous spyware known also as FinSpy and sold to governments and their agencies worldwide, are in the wild ... some of these variants have been using a cunning, previously-unseen infection vector with strong indicators of major internet service provider (ISP) involvement ...  FinFisher is marketed as a law enforcement tool and is believed to have been used also by oppressive regimes ... What’s new ... in terms of distribution is the attackers' use of a man-in-the-middle attack with the "man" in the middle most likely operating at the ISP level ... When the ...  target of surveillance is about to download one of several popular (and legitimate) applications, they are redirected to a version of that application infected with FinFisher. The applications we have seen being misused to spread FinFisher are WhatsApp, Skype, Avast, WinRAR, VLC Player and some others ...  the legitimate download link [is] being replaced by a malicious one ... "</i></p>
   
<p><img src="https://routersecurity.org/pix/isp.box.hacking.sm.jpg">At the DEF CON 25 conference in the summer of 2017  Marc Newlin, Logan Lamb and Chris Grayson spoke about <a href="https://www.youtube.com/watch?v=LxfsT4wLAfU">Wirelessly Tapping Home Networks</a>. They found 26 bugs in ISP provided hardware, both gateways and set-top boxes. Bugs were found in devices from Cisco, Arris, Technicolor, Motorola and Xfinity.  They found multiple un-authenticated remote code execution flaws, the worst of all possible bugs. Software maintenance of the devices was also poor: patches take months to deploy, official bug reports are not filed and, of course, customers (victims?) are told nothing about the problems.<br clear="all"></p>

<p>"Securing home routers is not an easy task and may require some technical knowledge. A good start is properly selecting a home router - this means avoiding free routers included in internet plans... " from <a href="https://www.trendmicro.de/cloud-content/us/pdfs/security-intelligence/white-papers/wp-securing-your-home-routers.pdf">Securing 
  Your Home Routers</a> by Trend Micro sometime in 2017.</p>   
   
 <p>In December 2016, Scott Helme wrote <a href="https://scotthelme.co.uk/my-ubiquiti-home-network/">My Ubiquiti Home Network</a> about upgrading from consumer routers to Ubiquiti. But, he lead with his thoughts about ISP provided equipment. </p>
 <p> <i>"I've never used the equipment provided by my ISP and have always used my own ... I've always been a bit of a tech geek and I like having things with extra features ... but there are some other more genuine needs. ISP (Internet Service Provider) provided equipment usually has one main factor driving the choice of hardware, <b>cost</b>. They want it to be as cheap as possible because purchasing the device and giving it to you is eating into their profits ... low cost usually means low quality in other areas than hardware too, like security. My previous ISP, EE, sent me a BrightBox router when I signed up that [had] several <a href="https://scotthelme.co.uk/ee-brightbox-router-hacked/">serious security vulnerabilities</a> ... Following their (very late) patching efforts there were <a href="https://scotthelme.co.uk/ee-brightbox-router-patched-still-vulnerable/">yet more vulnerabilities</a>. 
 I could go on and on listing the issues with ISP kit, a story even popped up on The Register about 1 million German routers being compromised whilst writing this blog, but I think you get the idea. This isn't to say other hardware will be perfect, of course it won't be, but I'd seen enough and wanted rid."</i></p> 
   
<p>In Australia in <b>October 2016</b> an ISP gave out <a href="http://www.theregister.co.uk/2016/10/27/good_luck_securing_things_when_users_assume_stuff_just_works/">routers with default userid/passwords</a>  and "remarkably similar SSIDs." The article argues that: "It isn't terribly difficult to load up factory firmware that generates a random password, assigns it to a device, then prints a label with that information to go into the box with the gadget. It's more work than just slapping a default username and password into the software - but not much. And the cost, amortised against tens of thousands of units, can't be more than a penny or two."</p>  
 
 <p>Lucian Constantin, of IDG News Service, has been covering routers for Computerworld, PC World and others for a few years. On June 2, 2015, <a href="http://www.itworld.com/article/2930295/security/new-soho-router-security-audit-uncovers-over-60-flaws-in-22-models.html">writing in ITworld</a>,  about a bunch of router flaws he said:</p>
<p> <i>"Past research has shown that the security of ISP-provided routers is often worse than that  of off-the-shelf  ones. Many such devices are configured for remote administration to allow ISPs to remotely update their settings or troubleshoot connection problems.  This exposes the routers' management interfaces along with any vulnerabilities in them to the Internet, increasing the risk of exploitation. Even though  ISPs have the ability to remotely update the firmware on the routers they distribute to customers, they often don't and in some cases the users can't  do it either because they only have restricted access on the devices."</i></p> 

<p>In Nov. 2015 Bernardo Rodrigues wrote <a href="https://w00tsec.blogspot.com.au/2015/11/arris-cable-modem-has-backdoor-in.html">ARRIS Cable Modem has a Backdoor in the Backdoor</a>. The buggy devices are the Arris TG862A, TG860A, and DG860A. To be clear, these are not modems, they are gateways (combination modem and router). They suffer from XSS and CSRF vulnerabilities, hard-coded passwords, and a backdoor in a backdoor.  The backdoor can be used to enable Telnet and SSH remotely via a hidden HTTP interface or with custom SNMP MIBs. Estimates are that more than 600,000 externally accessible devices are vulnerable. Initially, Arris blew this off. Eventually CERT/CC was able to get their attention. For more, see the <a href="https://routersecurity.org/bugs.php">Router Bugs</a> page under November 2015.</p>  
 
<p>Verizon was giving new customers routers configured to use WEP years and years and years after WEP was known to be insecure. It's nice to be a monopoly. In November 2014 the FTC <a href="https://www.ftc.gov/system/files/documents/closing_letters/verizon-communications-inc./141112verizonclosingletter.pdf">wrote a letter</a> to a Verizon rep saying "<i>... the Division of Privacy and Identity Protection has conducted an investigation into possible violations of Section 5 of the Federal Trade Commission Act by ...   Verizon Communications.  The investigation considered whether Verizon engaged in unfair or deceptive acts or practices by failing to secure, in a reasonable and appropriate manner, the routers it provided to its High Speed Internet (DSL) and FiOS customers ...  Verizon regularly shipped routers to consumers with the default security set to an outdated encryption standard known as WEP. Due to certain weaknesses in WEP, the IEEE deprecated this standard in 2004 in favor of a new
standard known as WPA and later, WPA2. However, until recently, Verizon continued to ship some router models with the WEP encryption standard. As a result, many Verizon customers ... [are] vulnerable to hackers.</i>" Writing the letter was all the FTC did.  Clearly you can't trust Verizon with your router security.</p>

 
<h3>TR-069</h3>

<p>Another big security issue involves remote configuration of the router/modem provided by an ISP. Assorted mechanisms used by ISPs to update their devices in your home or office have been abused by bad guys to hack the devices. One remote update mechanism is a protocol with two names: TR-069 and CWMP. More than once, bugs in this protocol have been abused. </p>

<p>In November 2016, about 900,000 customers of Deutsche Telekom were knocked off-line by router problems. <a href="http://www.computerworld.com/article/3145003/internet/blame-the-isps-rather-than-the-routers.html">My blog on this attack</a>, which started with a new variant of the Mirai malware, detailed the mistakes ISPs made to get to the point where Mirai could cause so much damage. They left an open TCP/IP port undefended, and then quickly blocked it once the s..t hit the fan. Some ISP-supplied routers were running a TR-064 server that was open to the public, a huge configuration mistake. And, some routers locked up when the had to deal with the many incoming connection attempts created by the malware.</p> 
 
<p>Another example of TR-069 incompetence came to light in April 2017. <a href="https://www.wordfence.com/blog/2017/04/check-your-router/">Wordfence wrote</a> that "Your ISP should not allow someone from the public internet to connect to your router's port 7547." Well, duh. They wrote that Shoden reports over 41 million home routers with port 7547 open to the public internet. They also found over 10,000 infected home routers in Algeria and over 11,000 hacked home routers in India that they attribute to port 7547 being open.</p> 
   
<p>TR-069 was also abused in 2014. A story, by Lucian Constantin back in August  2014 is frightening. See <a href="http://www.computerworld.com/article/2491042/malware-vulnerabilities/home-routers-supplied-by-isps-can-be-compromised-en-masse.html">Home routers supplied by ISPs can be compromised en masse</a>. As of 2011, there are 147 million TR-069-enabled devices online listening on TCP port 7547.  These devices communicate with Auto Configuration Servers (ACS) operated by ISPs for assorted network management tasks. Many times a router can not close the port. If an attacker hacks into an ACS server then lots of bad stuff can happen. According to Shahar Tal, a security researcher at Check Point Software, ACS servers can be easily taken over by bad guys. The TR-069 specification recommends the use of HTTPS  but he found that insecure HTTP is used about 80 percent of the time, opening routers up to man-in-the-middle attacks. TR-069 requires authentication from the device to the ACS, but the username and password is typically shared and easily extracted. Check Point also tested several ACS servers and found critical remote code execution vulnerabilities in them. </p> 
  
<p>Open ports on ISP provided hardware are not limited to the TR-069 protocol. In September 2017, security firm Nomotion blogged about AT&amp;T U-Verse gateway devices with two open ports. One was for SSH, the other (TCP port 49152) allowed WAN side attackers to bypass the firewall. This was in addition to three hard coded backdoor accounts they discovered. The blog has a great title: <a href="https://www.nomotion.net/blog/sharknatto/">SharknAT&amp;To</a>. Adding insult to injury, was the reaction from AT&amp;T. Despite being publicly shamed, they said nothing about these security problems for two weeks (as of Sept 13, 2017). They have no shame and are doing their best to keep their customers ignorant of this. Arris, said they are looking into it and then went silent. For more see the <a href="https://routersecurity.org/bugs.php">Router Bugs</a> page under September 2017.</p>   

<p>HD Moore, chief security architect at Rapid7, and the creator of Metasploit, also <a href="http://www.darkreading.com/vulnerabilities---threats/no-end-in-sight-for-exposed-internet-of-things-other-devices/d/d-id/1320913">weighed  in on this</a>  on June 17, 2015. Rapid7 runs  Project Sonar, which scans the Internet for vulnerable devices. They find that things are getting worse.   On reason, cited by Moore is   <i>"that a few dozen Internet service providers are rolling out broadband devices such as home routers without  properly vetting or properly configuring the security..."</i></p>
  
  <p> ------------------ </p>

<p>Besides security, there is the issue of <b>honesty</b>. Time Warner Cable, a.k.a Spectrum and Charter was <a href="https://ag.ny.gov/sites/default/files/summons_and_complaint.pdf">sued in New York State</a> in early 2017 for lying about the download speeds their customers were getting. In <a href="https://backchannel.com/the-alternate-facts-of-cable-companies-f0cd1e10e66">The Alternate Facts of Cable Companies</a> Harvard professor Susan Crawford writes:</p>
<p><i>"Based on the company's own documents and statements, it appears that just about everything it has been saying since 2012 to New York State residents about their internet access and data services is untrue. And not untrue in some grey, shadowy way - just untrue. The company's 2.5 million New York subscribers (of its 22 million nationwide) have been told they are getting X (in terms of download and upload speeds) when actually they are getting a lot less than X."</i></p>
<p>How was Charter/Spectrum/Time Warner Cable cheating? Three ways: <i>" ... squeezing more households into an inadequate number of narrow, shared neighborhood data connections; squeezing connections between Spectrum's network and other networks; and squeezing consumers who should have gotten upgraded household equipment."</i></p><p> 

The lawsuit was settled in December 2018 with Charter/Spectrum coughing up $176 Million. In an <a href="https://www.techdirt.com/articles/20181218/07445741254/nys-record-176-million-settlement-with-charter-crap-broadband-highlights-cables-growing-monopoly.shtml">article about this</a>, Karl Bode, of Techdirt wrote: <i>"The suit also highlights how Charter at least considered gaming the results of a program the FCC has traditionally used to measure real-world broadband speeds using custom-firmware embedded routers in consumer volunteer homes."</i>. 


</p><p>In the U.S., high speed broadband is <a href="https://www.techdirt.com/articles/20180314/09251639423/cable-industry-is-quietly-securing-massive-monopoly-over-american-broadband.shtml">pretty much a monopoly</a> everywhere. An ISP without competition has no motivation to do a good job, they are only motivated by profit. Yet another reason not to use their hardware, when possible.</p>

<p>One advantage of the new consumer focused mesh routers,  like eero, AmpliFi and Google Wifi, is that the routers themselves can run speed tests. Eero seems to do one every day. AmpliFi and Google Wifi keep a history of the speed tests, so trends are easily spotted. Eero does not keep a history. </p>
   
<p>Finally, there is a big difference between routers so don't expect to buy the perfect router for your needs right out of the box. If possible, buy a 
  router from a place that will take it back.</p>
   
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Philip Low Unmasking Musk (190 pts)]]></title>
            <link>https://bsky.app/profile/brainking.bsky.social/post/3lgsco7cdnc26</link>
            <guid>42903336</guid>
            <pubDate>Sat, 01 Feb 2025 22:54:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/brainking.bsky.social/post/3lgsco7cdnc26">https://bsky.app/profile/brainking.bsky.social/post/3lgsco7cdnc26</a>, See on <a href="https://news.ycombinator.com/item?id=42903336">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[RLHF Book (332 pts)]]></title>
            <link>https://rlhfbook.com/</link>
            <guid>42902936</guid>
            <pubDate>Sat, 01 Feb 2025 22:11:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rlhfbook.com/">https://rlhfbook.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42902936">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>A short introduction to RLHF and post-training
focused on language models.</p><div>
  <h2>Abstract</h2>
  <p>Reinforcement learning from human feedback (RLHF) has become an
  important technical and storytelling tool to deploy the latest machine
  learning systems. In this book, we hope to give a gentle introduction
  to the core methods for people with some level of quantitative
  background. The book starts with the origins of RLHF – both in recent
  literature and in a convergence of disparate fields of science in
  economics, philosophy, and optimal control. We then set the stage with
  definitions, problem formulation, data collection, and other common
  math used in the literature. We detail the detail the popular
  algorithms and future frontiers of RLHF.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Macrodata Refinement (485 pts)]]></title>
            <link>https://lumon-industries.com/</link>
            <guid>42902691</guid>
            <pubDate>Sat, 01 Feb 2025 21:46:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lumon-industries.com/">https://lumon-industries.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42902691">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    
    
    
    
    
    <p>Loading...</p>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[A bookmarklet to kill sticky headers (2013) (181 pts)]]></title>
            <link>https://alisdair.mcdiarmid.org/kill-sticky-headers/</link>
            <guid>42902395</guid>
            <pubDate>Sat, 01 Feb 2025 21:12:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alisdair.mcdiarmid.org/kill-sticky-headers/">https://alisdair.mcdiarmid.org/kill-sticky-headers/</a>, See on <a href="https://news.ycombinator.com/item?id=42902395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
  

  <article>
    <header>
      
    </header>

    <p>There is currently a trend for using sticky headers on websites. There's even <a href="http://www.hellobar.com/">a sticky header web startup</a>.</p>
<p>I hate sticky headers. <em>I want to kill sticky headers.</em></p>
<p>So I made this bookmarklet. Drag the link to your bookmarks bar:</p>
<p>Kill Sticky</p>


<p>I use an 11" MacBook Air, which means that I don't have much vertical screen space. The 50 pixels taken up by the sticky header could have been three lines of text.</p>
<p>I also normally scroll down using the space key, which scrolls just less than one full viewport at a time. When you cover up part of your content with a sticky element, that means that the space key scrolls too far down. Then I lose my position and have to scroll back up.</p>
<p>Finally, I just don't care right now about navigating your website, or following you on Twitter. I'm trying to read. Let me focus on that for now, please.</p>
<h2 id="how-the-bookmarklet-works">How the bookmarklet works</h2>
<p>It's really simple, because <a href="http://www.w3.org/TR/selectors-api/#examples"><code>querySelectorAll</code></a> is awesome. <a href="https://gist.github.com/alisdair/5670341">Here's the source</a>:</p>
<pre><code>(<span><span>function</span> (<span></span>) </span>{ 
  <span>var</span> i, elements = <span>document</span>.querySelectorAll(<span>'body *'</span>);

  <span>for</span> (i = <span>0</span>; i &lt; elements.length; i++) {
    <span>if</span> (getComputedStyle(elements[i]).position === <span>'fixed'</span>) {
      elements[i].parentNode.removeChild(elements[i]);
    }
  }
})();
</code></pre>
<p>The bookmarklet just finds all fixed-position elements on the page, and removes them. This might remove the navigation, but if you need it back, just hit refresh. That's why I created a bookmarklet and not a custom user-stylesheet or browser plugin: this is the simplest way to solve the problem.</p>


  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phyllis Fong, who was investigating Neuralink, "forcefully removed " (231 pts)]]></title>
            <link>https://timesofindia.indiatimes.com/technology/tech-news/phyllis-fong-who-was-investigating-elon-musks-brain-implant-startup-neuralink-forcefully-removed-from-office-after-refusing-termination-order/articleshow/117800543.cms</link>
            <guid>42902355</guid>
            <pubDate>Sat, 01 Feb 2025 21:09:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timesofindia.indiatimes.com/technology/tech-news/phyllis-fong-who-was-investigating-elon-musks-brain-implant-startup-neuralink-forcefully-removed-from-office-after-refusing-termination-order/articleshow/117800543.cms">https://timesofindia.indiatimes.com/technology/tech-news/phyllis-fong-who-was-investigating-elon-musks-brain-implant-startup-neuralink-forcefully-removed-from-office-after-refusing-termination-order/articleshow/117800543.cms</a>, See on <a href="https://news.ycombinator.com/item?id=42902355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-articlebody="1"><div data-ua-type="1" onclick="stpPgtnAndPrvntDefault(event)"><p><img src="https://static.toiimg.com/thumb/msid-117800527,imgsize-34070,width-400,resizemode-4/117800527.jpg" alt="Phyllis Fong, who was investigating Elon Musk's brain implant startup Neuralink, &quot;forcefully removed from office&quot; after refusing termination order" decoding="async" fetchpriority="high"></p></div><p>Security personnel escorted the US Department of Agriculture’s inspector general from her office this week after she refused to comply with her dismissal by the Trump administration, sources familiar with the situation told Reuters.<br>Phyllis Fong</p><!-- --><p>, who had served in the department for 22 years, informed colleagues that she planned to remain in her position despite being terminated by the White House.</p><div><h2>Budget 2025 Updates</h2><ul><li><a href="https://timesofindia.indiatimes.com/business/india-business/new-tax-regime-vs-old-tax-regime-after-budget-2025-income-tax-slabs-and-rates-comparison-explained-which-tax-regime-is-better-for-middle-class-salaried-taxpayers/articleshow/117824985.cms" index="0" commonstate="[object Object]" frmappuse="1">New vs old income tax regime after Budget 2025: Post income tax slab changes, which tax regime is better for salaried middle class taxpayers?</a></li><li><a href="https://timesofindia.indiatimes.com/business/india-business/latest-income-tax-slabs-fy-2025-26-budget-2025-tax-slabs-rates-under-new-income-tax-regime-standard-deduction-personal-taxation-after-budget-2025-full-details-faqs-answered/articleshow/117821239.cms" index="1" commonstate="[object Object]" frmappuse="1">Latest income tax slabs FY 2025-26</a></li><li><a href="https://timesofindia.indiatimes.com/business/india-business/income-tax-slabs-2025-26-live-updates-budget-2025-new-tax-regime-vs-old-regime-tax-rates-standard-deduction-section-80c-latest-income-tax-slab-changes-tax-announcements/liveblog/117809100.cms" index="2" commonstate="[object Object]" frmappuse="1">Income Tax Slabs Budget 2025 Live Updates: No income tax up to Rs 12 lakh income</a></li></ul></div><p>According to sources, she argued that the administration had not followed the proper procedures. Fong previously served as the first chairperson of </p><!-- --><p>CIGIE</p><!-- --><p> from 2008 to 2014, according to her USDA biography.</p><p>In an email to colleagues, reportedly reviewed by Reuters, Fong cited the independent Council of the Inspectors General on Integrity and Efficiency, stating that the council had determined the termination notices did not adhere to legal requirements and were therefore not effective.</p><p data-pos="12"><h2>What White House said on Phyllis Fong's termination<br></h2></p><p>The White House defended the dismissals of Fong and other inspectors general, claiming that "these rogue, partisan bureaucrats... have been relieved of their duties to make way for qualified individuals who will uphold the rule of law and protect Democracy."</p><p>As USDA’s inspector general, Fong oversaw a broad range of responsibilities, including consumer food safety, audits, and investigations into the Agriculture Department, as well as enforcement of animal welfare laws. The USDA has been central to concerns over the spread of bird flu, which has affected cattle and poultry and resulted in a fatality in Louisiana.<br>In 2022, Fong’s office launched an investigation into <a href="https://timesofindia.indiatimes.com/topic/elon-musk" styleobj="[object Object]" commonstate="[object Object]" frmappuse="1">Elon Musk</a>’s brain implant company, </p><!-- --><p>Neuralink</p><!-- --><p>, which remains ongoing, sources said. In recent years, the office has also investigated animal abuse at research dog breeders and the listeria outbreak linked to Boar’s Head, among other issues.<br>Fong was among 17 federal watchdogs dismissed by Trump recently a move critics described as a "Friday-night purge." </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oracle Cloud deleting active user accounts without possibility for data recovery (214 pts)]]></title>
            <link>https://mastodon.de/@ErikUden/113930010311998246</link>
            <guid>42901897</guid>
            <pubDate>Sat, 01 Feb 2025 20:24:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.de/@ErikUden/113930010311998246">https://mastodon.de/@ErikUden/113930010311998246</a>, See on <a href="https://news.ycombinator.com/item?id=42901897">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Python 3, Pygame, and Debian Bookworm on the Miyoo A30 (142 pts)]]></title>
            <link>https://www.jtolio.com/2025/02/py3-pygame-miyoo-a30/</link>
            <guid>42901616</guid>
            <pubDate>Sat, 01 Feb 2025 19:57:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jtolio.com/2025/02/py3-pygame-miyoo-a30/">https://www.jtolio.com/2025/02/py3-pygame-miyoo-a30/</a>, See on <a href="https://news.ycombinator.com/item?id=42901616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  

<p>What if I told you you can get a full Linux computer with WiFi and a GPU in a
small, pocket form factor for about <a href="https://docs.google.com/spreadsheets/d/1x_PmVHiQNHyw5t05peEDG1DcCKDCvH_UPd3p7yCw4xg/edit">$30 USD on AliExpress</a>? You might say “but what about the new tariffs?” and I’d say “oof, oh right, okay who knows, but it’s probably still pretty cheap!” (Edit: looks like you can get one for about $40 now).</p>

<p>It wasn’t a big hit with the
retro handheld gaming community, but the
<a href="https://retrocatalog.com/retro-handhelds/miyoo-a30">Miyoo A30</a> has a 4 core
Cortex A7 with a Mali-400 MP GPU, 512 MB of RAM, WiFi, and an incredible little
640x480 IPS screen. It has enough power to emulate many
Nintendo 64 games, but that’s not what I bought it for.
In fact, I bought two so my son and I could make networked multiplayer games
together.</p>

<div>
  <figure>
    
        <img src="https://www.jtolio.com/images/a30.jpg">
    
    
</figure>

</div>


<p>I already have a <a href="https://github.com/jtolio/viricide">game I made in Pygame</a> back in
college, so naturally, I wanted to first get modern Python 3 and Pygame working on
it.</p>

<p>If you want to ignore my work log and just skip to the files, at the bottom
I have premade files for you so you can install Python programs on your Miyoo
A30 by just copying some things onto your SD card.</p>

<h2 id="game-plan:8d57e4422a6e5ed1f965c5d347001476">Game plan</h2>

<ul>
<li>Install the latest software and software drivers on the Miyoo A30</li>
<li>Get Debian running in a chroot</li>
<li>Override drivers so the hardware works</li>
<li>Tell spruceOS how to start the programs</li>
</ul>

<h3 id="upgrading-the-miyoo-a30:8d57e4422a6e5ed1f965c5d347001476">Upgrading the Miyoo A30</h3>

<p>First step, the software that comes on this little device is garbage, so you want to
replace that.</p>

<p>The internet
seems to think that <a href="https://spruceui.github.io/">spruceOS</a> is currently the best
custom image you can get for the A30, and it is quite nice. It doesn’t come with
Python or Pygame, but it does come with firmware upgrade software (so that your WiFi
drivers are the latest), and also comes with all of the latest and greatest
emulators optimally configured if that’s your thing.</p>

<p>The only downside with running spruceOS is it still uses a Linux 3.x kernel. Using
the provided kernel is a good call since it has the best driver support for the
hardware, but Linux 3.x is missing some syscalls some Debian Bookworm software now
takes for granted. This means that Debian Bookworm’s <code>apt-get</code> won’t work, but
that’s okay, many other things still work, including <code>venv</code> and <code>pip</code>.</p>

<h3 id="debian-in-a-chroot:8d57e4422a6e5ed1f965c5d347001476">Debian in a chroot</h3>

<p>On my laptop, I used <code>debootstrap</code> to create a folder with a Debian system ready to
be configured.</p>

<pre><code>sudo debootstrap --arch=armhf --foreign --variant=minbase --include python3,python3-venv,python3-pip,python3-requests,python3-pygame,nano bookworm ~/miyoo-bookworm/
</code></pre>

<p>Since <code>apt-get</code> doesn’t work, if you’re doing this yourself, make sure to include
any packages you want in your Debian installation in the list above.</p>

<p>Then, on the Miyoo A30, in spruceOS’s advanced configuration, I enabled SSH,
SSHed to the device, then created an ext4 filesystem on the SD card and mounted
it:</p>

<pre><code>dd if=/dev/zero of=bookworm-python3.img bs=4096 count=$((1024*256))
mkfs.ext4 bookworm-python3.img
mkdir bookworm-python3
mount -o loop bookworm-python3.img bookworm-python3
</code></pre>

<p>Then, I <code>scp</code>ed all of the contents of my laptop’s <code>miyoo-bookworm</code> folder into
that new loopback mountpoint.</p>

<p>Finally, I ran this on the Miyoo to finish the Debian installation:</p>

<pre><code>chroot bookworm-python3
/debootstrap/debootstrap --second-stage
</code></pre>

<p>Tada! Debian works! Python works!</p>

<h3 id="graphics-and-input-drivers:8d57e4422a6e5ed1f965c5d347001476">Graphics and input drivers</h3>

<p>Okay, so Pygame doesn’t really work yet, since the Debian installation doesn’t
have the right SDL drivers or GPU drivers. The spruceOS installation does
though.</p>

<p>Inside the Debian filesystem, I made <code>/usr/local/lib/miyoo-overrides</code>. Then I
copied the following libraries from the spruceOS parent filesystem’s
<code>/usr/lib/miyoo</code> folder into the Debian filesystem’s <code>miyoo-overrides</code> folder
that I just made: <code>libEGL.so*</code>, <code>libGLESv1_CM.so*</code>, <code>libGLESv2.so*</code>, <code>libMali.so</code>, <code>libSDL2-2.0.so*</code>, and <code>libudev.so*</code>. Note that all of the <code>libEGL</code> and <code>libGLES</code> libraries are actually just symlinks to <code>libMali.so</code>.</p>

<p>I reentered the chroot and ran:</p>

<pre><code>echo /usr/local/lib/miyoo-overrides/ &gt; /etc/ld.so.conf.d/00-miyoo-overrides.conf
ldconfig
</code></pre>

<p>This makes it so all programs inside the chroot can find the spruceOS provided
video and input libraries.</p>

<h3 id="get-the-python-apps-to-show-up-in-spruceos:8d57e4422a6e5ed1f965c5d347001476">Get the Python apps to show up in spruceOS</h3>

<p>First we need a tool for safely entering the chroot while still having all of
the kernel devices and filesystems show up appropriately. Here is
<code>run-inside.sh</code> which will start a program inside the chroot, making sure it
is set up right.</p>

<pre><code>#!/bin/sh

BASE=/mnt/SDCARD/bookworm-python3.img
ROOT=/mnt/SDCARD/bookworm-python3

mount &gt; /tmp/current-mounts
if ! grep -q $ROOT /tmp/current-mounts; then
  mkdir -p $ROOT
  mount -o loop $BASE $ROOT
  for dir in /dev /proc /sys /tmp /dev/pts /mnt/SDCARD; do
    mkdir -p $ROOT$dir
    mount -o loop $dir $ROOT$dir
  done
  mkdir -p $ROOT/mnt/root
  mount -o loop / $ROOT/mnt/root
fi

rm /tmp/current-mounts

command="$1"
shift
if [ "x$command" == "x" ]; then
  command="/bin/bash"
fi

exec chroot $ROOT/ /usr/bin/env \
  LD_LIBRARY_PATH= \
  PATH=/usr/sbin:/usr/bin:/sbin:/bin \
  SHELL=/bin/bash \
  "$command" "$@"
</code></pre>

<p>Now, we need a sample Pygame app. I used <a href="https://github.com/pcorbel/hello-miyoo/blob/main/app/app.py">this one</a> for testing. I put this project’s <code>app.py</code>
on my SD card.</p>

<p>Finally, you need to make a script on the SD card inside <code>Roms/PORTS</code>. Here
is <code>hello-miyoo.sh</code>:</p>

<pre><code>#!/bin/sh

exec /mnt/SDCARD/run-inside.sh python3 /mnt/SDCARD/app.py
</code></pre>

<p>When you next open your Miyoo spruceOS UI, There will be an entry named after
this script (<code>hello-miyoo</code>) in the “Ports” section of the “Games” category!</p>

<h2 id="what-doesn-t-work:8d57e4422a6e5ed1f965c5d347001476">What doesn’t work</h2>

<p>Mostly, this works great! All of the buttons are recognized by Pygame,
Pygame gets GPU acceleration, sound works, etc.</p>

<p>Unfortunately, the screen is rotated 90 degrees. With some other spruceOS
provided builds of libSDL2, the screen isn’t rotated, but GPU acceleration is
disabled and many other things are broken.</p>

<p>If anyone has an idea of how to fix this, please <a href="https://www.jtolio.com/contact/">let me know!</a></p>

<p>For now, I am simply using Pygame to rotate my screen another 90 degrees.</p>

<h2 id="all-the-files:8d57e4422a6e5ed1f965c5d347001476">All the files</h2>

<ul>
<li><a href="https://link.storjshare.io/s/jxrcn4q6yfstkrkmub4p46eghppa/miyoo-a30/bookworm-python3.img.gz">bookworm-python3.img.gz</a> - 384MiB when extracted, the full Debian Bookworm install that comes with Python 3, Pygame, and Miyoo drivers.</li>
<li><a href="https://link.storjshare.io/s/jxrcn4q6yfstkrkmub4p46eghppa/miyoo-a30/run-inside.sh">run-inside.sh</a> - The tool for safely mounting and entering the Debian Bookworm image.</li>
<li><a href="https://link.storjshare.io/s/jxrcn4q6yfstkrkmub4p46eghppa/miyoo-a30/sammygame.zip">sammygame.zip</a> - a small Sokoban game featuring my son’s hamster.</li>
<li><a href="https://link.storjshare.io/s/jxrcn4q6yfstkrkmub4p46eghppa/miyoo-a30/run-app.sh">run-app.sh</a> - An example script for placement in the spruceOS <code>Roms/PORTS</code> folder.</li>
</ul>

<p>Comments on <a href="https://news.ycombinator.com/item?id=42901616">Hacker News</a> or <a href="https://www.reddit.com/r/miyooa30/comments/1ifen8a/python_3_pygame_and_debian_bookworm_on_the_miyoo/">Reddit</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The origin and unexpected evolution of the word "mainframe" (117 pts)]]></title>
            <link>https://www.righto.com/2025/02/origin-of-mainframe-term.html</link>
            <guid>42901184</guid>
            <pubDate>Sat, 01 Feb 2025 19:11:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2025/02/origin-of-mainframe-term.html">https://www.righto.com/2025/02/origin-of-mainframe-term.html</a>, See on <a href="https://news.ycombinator.com/item?id=42901184">Hacker News</a></p>
Couldn't get https://www.righto.com/2025/02/origin-of-mainframe-term.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube audio quality – How good does it get? (2022) (113 pts)]]></title>
            <link>https://www.audiomisc.co.uk/YouTube/SpotTheDifference.html</link>
            <guid>42901182</guid>
            <pubDate>Sat, 01 Feb 2025 19:11:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.audiomisc.co.uk/YouTube/SpotTheDifference.html">https://www.audiomisc.co.uk/YouTube/SpotTheDifference.html</a>, See on <a href="https://news.ycombinator.com/item?id=42901182">Hacker News</a></p>
<div id="readability-page-1" class="page">
<br><hr>
<p>YouTube Audio Quality - How Good Does it Get?</p>
<hr>
<p>
You Tube is clearly used by a very large number of people. In general, they will be interested in watching videos of various types of content. One specific purpose is that it gets used to distribute, and make people aware of, audio recordings. A conversation on the “Pink Fish” webforum devoted to music and audio set me wondering about the technical quality of the audio that is on offer from You Tube (YT) videos. The specific comment which drew my attention was a claim that the ‘opus’ audio codec gives better results than the ’aac / mp4’ alternative. So I decided to investigate...</p>

<p>
Ideally to assess this requires a copy of what was uploaded to YT as a ‘source’ version which can then be compared with what YT then make available as output. By coincidence I had also quite recently joined the Ralph Vaughan-Williams Society (RVWSoc). They have been putting videos up onto YT which provide excerpts of the recordings they sell on Audio CDs. These proved excellent ‘tasters’ for anyone who wants to know what they are recording and releasing. And when I asked, they kindly provided me with some examples to help me investigate this issue of YT audio quality and codec choice.</p>

<p>
For the sake of simplicity I’ll ignore the video aspect of this entirely and only discuss the audio side. The RVWSoc kindly let me have ‘source uploaded’ copies of two examples. The choice of audio formats that YT offered for these videos are as follows:</p>
<br>

<div><p>
Pan’s Anniversary<br>
Available audio formats for HZHVTr1w6L8:<br>
ID&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EXT&nbsp;&nbsp;|&nbsp;ACODEC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ABR&nbsp;&nbsp;ASR&nbsp;&nbsp;&nbsp;&nbsp;MORE&nbsp;INFO<br>
------------------------------------------------------------<br>
139-dash&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.5&nbsp;&nbsp;49k&nbsp;22050Hz&nbsp;DASH&nbsp;audio,&nbsp;m4a_dash<br>
140-dash&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.2&nbsp;130k&nbsp;44100Hz&nbsp;DASH&nbsp;audio,&nbsp;m4a_dash<br>
251-dash&nbsp;webm&nbsp;|&nbsp;opus&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;153k&nbsp;48000Hz&nbsp;DASH&nbsp;audio,&nbsp;webm_dash<br>
139&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.5&nbsp;&nbsp;48k&nbsp;22050Hz&nbsp;low,&nbsp;m4a_dash<br>
140&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.2&nbsp;129k&nbsp;44100Hz&nbsp;medium,&nbsp;m4a_dash<br>
251&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;webm&nbsp;|&nbsp;opus&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;135k&nbsp;48000Hz&nbsp;medium,&nbsp;webm_dash</p><p>

VW&nbsp;on&nbsp;Brass<br>
Available&nbsp;audio&nbsp;formats&nbsp;for&nbsp;KsILRbZtTwc:<br>

ID&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EXT&nbsp;&nbsp;|&nbsp;ACODEC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ABR&nbsp;&nbsp;ASR&nbsp;&nbsp;&nbsp;&nbsp;MORE&nbsp;INFO<br>
------------------------------------------------------------<br>
139-dash&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.5&nbsp;&nbsp;50k&nbsp;22050Hz&nbsp;DASH&nbsp;audio,&nbsp;m4a_dash<br>
140-dash&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.2&nbsp;130k&nbsp;44100Hz&nbsp;DASH&nbsp;audio,&nbsp;m4a_dash<br>
251-dash&nbsp;webm&nbsp;|&nbsp;opus&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;149k&nbsp;48000Hz&nbsp;DASH&nbsp;audio,&nbsp;webm_dash<br>
139&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.5&nbsp;&nbsp;48k&nbsp;22050Hz&nbsp;low,&nbsp;m4a_dash<br>
140&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m4a&nbsp;&nbsp;|&nbsp;mp4a.40.2&nbsp;129k&nbsp;44100Hz&nbsp;medium,&nbsp;m4a_dash<br>
251&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;webm&nbsp;|&nbsp;opus&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;136k&nbsp;48000Hz&nbsp;medium,&nbsp;webm_dash</p></div>

<p>
The ‘ID’ numbers refer to the audio streams. Other ID values would produce a video of a user-chosen resolution, etc., normally accompanied by one of the above types of audio stream. </p>

<p>
One aspect of this stands out immediately. This is the variety of audio sample rate  (ASR)  options on offer. However in each case only <span>one</span> version of a RVWSoc video was uploaded, at a sample rate chosen by the RVWSoc. I had expected to see a choice of  YT output audio codecs (compression systems), but was quite surprised, in particular, to see ASRs as low as 22·05k on offer as that means the YT audio would then have a frequency range that only extends to about 10kHz!</p>

<p>
Given the main interest here is in determining what choice may deliver highest YT output audio quality I decided that analysis should focus on the higher, more conventional rates – 48k and 44k1. In addition, the above shows that – since in each case only one source file (and hence only one sample rate) was uploaded – some of the above YT output versions at 48k or 44k1 have also been thorough a sample rate conversion in addition to a codec conversion. That introduces another factor that may degrade sound quality! In this case I had copies of what had been uploaded, so could determine which of the YT output versions had been though such a rate conversion.  For the present examination, I will therefore limit investigation to the YT output that maintains the same ASR as the source that was uploaded, so as to dodge this added conversion. Unfortunately, in general YT <span>users</span> probably won’t know which output version may have dodged this particular potential bullet! Choosing the least-tampered-with output therefore may be a challenge in practice for YT users.</p>

<p>
Pan’s Anniversary  [48k ASR 194 kb/s aac(LC) source audio]</p>
<p>
I’ll begin the detailed comparisons with the video of an excerpt from the CD titled,“Pan’s Anniversary”. The version uploaded contains the audio in the form encoded in the aac(LC) codec at a bitrate of 194 kb/s and using a sample rate of 48k. The audio lasts 4 mins 54·88 sec. The table below compares this with the same aspects of the high ABR versions offered by YT.</p>
<br>
<div>
<table>
<tbody><tr><td>version
</td>
<td>codec
</td>
<td>ABR
</td>
<td>bitrate (kb/s)
</td>
<td>duration (m:s)
</td>
</tr>
<tr><td>source
</td>
<td>aac(LC)
</td>
<td>48k
</td>
<td>194
</td>
<td>4:54·88
</td>
</tr>
<tr><td>YT-140
</td>
<td>aac(LC)
</td>
<td>44k1
</td>
<td>127 fltp
</td>
<td>4:54·94
</td>
</tr>
<tr><td>YT-251
</td>
<td>opus
</td>
<td>48k
</td>
<td>135 fltp
</td>
<td>4:54·90
</td>
</tr></tbody></table>
</div>

<p>
We can see that YT-140 uses the same codec as the source, but alters the information bitrate, and the ASR. YT-251 transcodes the input aac(LC) into the opus codec, but doesn’t alter the sample rate. <span>Both</span> of the YT versions are of longer duration than the source uploaded. By loading the files into Audacity and examining the waveforms by eye it became clear that the YT versions were not time-aligned with each other, or with the source.</p>

<p>
To avoid any changes caused by alteration of the ABR I decided to concentrate on comparing the source version with YT-251 – i.e. where the output uses the opus codec, not aac, but maintain’s the source sample rate. Having chosen matching sample rates the simplest and easiest was to check how similar two versions are is to time-align them and then subtract, sample by sample, each sample in a sequence in one version from the nominally ‘same instant’ matching one in the other. If the patterns are the same, the result is a series of zero-valued samples. If they don’t match we get a ‘difference’ pattern. However, before we can do this we have to determine the correct time-offset to align the sample sequences of the two versions.</p>

<p>
In some cases that can be fairly obvious from looking at the sample patterns using a program like Audacity. But in other cases this is hard to see with enough clarity to determine with complete precision. Fortunately, we can use a mathematical method known as <span>cross-correlation</span> to show us the time alignment of similar waveform patterns. (See  <a href="https://en.wikipedia.org/wiki/Cross-correlation">https://en.wikipedia.org/wiki/Cross-correlation </a>  if you want to know more about cross correlation.) This also can show us where the best alignment may occur in terms of any offset between the two patterns of samples being cross correlated.</p>
<p><br>
<img src="https://www.audiomisc.co.uk/YouTube/Fig1.png" alt="Fig1.png - 54Kb" width="1000" height="544">
</p>

<p>
The above graph shows the result of cross correlating a section of the source and YT-251 versions of the audio. (The red and blue lines show the Left and Right channels of the stereo.) The results cover offsets over a range of +/- 800 samples. The process used 180,000 successive sample pairs from each set of samples. i.e. about 3·75 sec of audio from each. The best alignment is indicated by the location of the largest peak. If the sample sequences were already aligned this would happen at an offset = 0. However here we can see that the YT-251 version is ‘late’ by just over 300 samples.</p>

<p>
<img src="https://www.audiomisc.co.uk/YouTube/Fig2.png" alt="Fig2.png - 40Kb" width="1000" height="542">
</p><p><br>
Zooming in, we can see that the peak is at an offset of -312 samples. Which at 48k sample rate corresponds to YT-251 being 6·5 milliseconds late. Having determined this I could trim 312 samples from the start of each channel of YT-251 and this aligned the two series of samples. (I also then had to trim the end to make them of equal length.) Once this was done it becomes possible to run though the samples and take a sample-by-sample difference between the source version and YT-251. This different set then details how the YT-251 output differs from the source version.</p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig3.png" alt="Fig3.png - 105Kb" width="1000" height="560"></p></div><p>
The graph above shows how the rms audio power level of the audio varies with time. The red and blue lines show the levels in the Pan’s Anniversary source file. The grey and purple lines show the power levels versus time obtained from subtracting the source file sample values from the audio samples from YT-251. Ideally, we’d wish to find a subtraction like this producing a series of zeros as the difference samples. This is because such a result would tell us that the output was identical to the input and going via YT had not changed the audio at all! However in practice the above results show this clearly is <span>not</span> the case! There is a residual ‘error’ which is typically somewhere around 20dB below the input (and output) musical level. </p>

<p>
In traditional terms for audio, 20dB would be regarded as a <span>very</span> poor signal/noise ratio. And if the change was considered as being equivalent to conventional distortion it would be assumed to indicate a level of around 10% distortion! So it represents a rather underwhelming result. However a more benign interpretation may be that it arises as a result of the process applied by YT slightly altering the overall amplitudes of the waveforms so they don’t quite match in size – hence leave a non-zero difference when the input and output are subtracted. With this in mind we can compare the input and output samples using other methods that aren’t sensitive to an overall change in signal pattern levels.</p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig4.png" alt="Fig4.png - 51Kb" width="1000" height="569"></p></div><p>
The above graph compares the input and output files in terms of Crest Factor. This measures the peak-rms power level difference of the waveform shapes defined by the series of samples. The red/blue lines show the Left and Right channel results for the source file sent to YT. The orange/green lines the equivalent results for YT-251. To obtain these results each set of samples was divided up into a series 0·1 Sec sections. The peak and rms power level of each was calculated, and the above shows how often a given value was obtained, grouped into 1dB wide statistical ‘bins’. For a pure sinewave the peak/rms crest factor is 3dB. i.e. the peak levels of a sinewave are 3dB larger than the rms power. For well recorded music from acoustic instruments the Crest Factor tends to be in the range from a few dB up to well over 10dB for the most ‘spiky’ waveforms.</p>

<p>
The result is interesting as we can see that the YT-251 output clearly exhibits a <span>different</span> Crest Factor distribution to the source file. It seems doubtful this could be produced by a simple change in the overall signal pattern level. (e.g. a volume control does change the overall level, but it should not change the <span>shape</span> of the audio waveform, and hence should leave the Crest Factor unaltered. (If it <span>did</span> alter this, you’d be advised to replace the control with one that worked properly!) It is particularly curious that the Crest factor seems to be increased by having the audio pass though the YT processing. Although possibly this may arise due to an input which is aac(LC) coded being transcoded into ‘opus’ codec form. OTOH perhaps YT apply some form of ‘tarting up’ to make audio ‘sound better’...</p>

<p>
<img src="https://www.audiomisc.co.uk/YouTube/Fig5.png" alt="Fig5.png - 85Kb" width="1000" height="556">
</p><p><br>
A more familiar way to show the character of an audio recording is to plot its spectrum. The above graph shows the spectrum of the Pan ‘source’ file and of the series of samples obtained by subtracting the YT-251 output sample series. We can then say that - at any given frequency - the bigger the gap between these plotted line, the closer the YT-251 output is to the source supplied to YT. Looking at the graph we can then see that the results indicate that the faithfulness of the YT-251 result to the input is at its best at low frequencies where the gap is widest and the contributions to the overall signal level are greatest. However at higher frequencies the level of the error becomes a larger fraction of the input. And above about 16kHz the error level quite similar to the input level. The implication being that the original details in the source above about have essentially been lost. They may have been replaced by something generated to ‘fake’ this lost information in a plausible manner.</p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig6.png" alt="Fig6.png - 72Kb" width="1000" height="556"></p></div><p>
In fact, if we compare the spectra of the input with that of the output we can see that  the YT-251 output using the opus codec has essentially removed anything from the source that was above 20 kHz. This is replaced by an HF ‘noise floor’ produced via a process like dithering, probably employed to suppress quantisation distortion, etc. We can also see that the source, although at a 48k sample rate, has a sharp cutoff at just over 22 kHz. This indicates that that although what was submitted to YT was at 48k sample rate it was actually generated from a 44k1 (i.e. audio CD rate) version. The behaviour of the above spectra may well be another sign of changes that also produced the change in the typical Crest Factor distribution.</p>

<p>
Having applied the above analysis to an example that produced a YT output using the opus codec we can now examine another example which uses aac for the output to compare that with the use of opus.</p>
<p>
Vaughan-Williams on Brass [44k1 ABR 127 kb/s aac(LC)]</p>
<p>
In this case the choice of source file had an aac audio content at an ASR of 44k1. This was chosen to match the sample rate of YT-140 and thus avoid any sample rate resampling effects. As with the previous “Pan’s Anniversary” example the YT-140 output was of a different duration to the source file, and not sample-aligned. So as before, I edited the output samples to trim them to a sample-aligned series that matched the timing of the source version.</p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig7.png" alt="Fig7.png - 86Kb" width="1000" height="556"></p></div><p>
The graph above shows the time-averaged spectra of the source file and the difference between this and the YT-140 output.  This represents the residual error level </p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig8.png" alt="Fig8.png - 102Kb" width="1000" height="560"></p></div><p>
As with the earlier YT-251 example, the above shows the source signal level versus time, and the level versus of time of the sample-by-sample difference between the source and the YT output (now YT-140) level. In this case the error level seems to be around -30 to -35dB compared with the source which is an improvement on the earlier YT-251 example. Viewed as distortion it would be equivalent to a level of around 3% or less.</p>

<p>
More broadly speaking, the results look similar to the previous example. However...</p>

<p><img src="https://www.audiomisc.co.uk/YouTube/Fig9.png" alt="Fig9.png - 78Kb" width="1000" height="556"><br>
</p><p>
...when we compare the actual spectra of the input and output we find that the output now has its high-frequency range cropped off at just under 16kHz! This is distinctly lower than the range present in the 44k1 sample rate aac <span>input</span> submitted to YT. </p>

<p>
It is also worth noting that although the YT-251 example’s output spectrum seems to extend to around 20kHz we found that the part above about 15kHz looked like being ‘all error’! i.e. not the source HF details but some sort of facsimile!</p>

<p>
Overall therefore, we might judge the YT-140 example to be, technically, more accurate than the YT-251 example. But to tell if this result was a general one we’d need to examine more examples. And given the changes in the applied high-frequency cut-off, we might also find that allowing the sample rate to altered might, overall, yield a different outcome! So the above results are interesting, but raise further questions which deserve future investigations.</p>

<p>
BBC iPlayer as a comparison [48k ASR 320 kb/s aac]</p>
<p>
In 2017 the BBC experimented with streaming BBC Radio 3 using flac in parallel with their standard iPlayer output formats. They did this for two reasons. One was to assess the practical requirements they would need to support if it became a standard. The other was to investigate if it produced audibly ‘better’ results. Some programmes were parallel streamed in days leading up to the Proms of that year. And almost all of the Proms were also streamed in flac format as well as their usual 320k aac format. As it wasn’t a formal service some special arrangements were needed for someone to receive the flac stream version. However given some advance notice I was able to use a modified version of the ffmpeg utility to capture examples of the flac stream for comparison with the aac. Having looked at the above YT examples it may be useful to compare them with the results from a BBC example.</p>

<p>
Since the flac stream essentially represents the LPCM input to the BBC’s aac encoder they can serve as an example of what is possible if we compare and and contrast them with the above results of examining the YT output. For the sake of illustration I’ve chosen a section of a “Record Review” programme on R3.</p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig10.png" alt="Fig10.png - 83Kb" width="1000" height="556"></p></div><p>
The above shows the time averaged spectra for a 5-min section of the program whilst music was being played. Here the source is taken from the flac data, and the output is taken from the 320k aac. These were then sample time-aligned so it was also possible to generate a sample-by-sample difference set of values and plot the spectrum of the residual ‘error’ pattern. i.e. the above can now be compared with the previous spectra for the YT examples. When this is done we can see that the error residual is somewhat lower relative to the source and output than in the YT examples – particularly at and above a few kHz. The output also effectively extends to higher frequencies than the YT examples. In addition we can see that the error level remains low over a wider range of frequencies than the YT examples.</p>
<br>
<div><p><img src="https://www.audiomisc.co.uk/YouTube/Fig11.png" alt="Fig11.png - 103Kb" width="1000" height="560"></p></div><p>
The above plots the audio levels of the source versus time, and also the residual level of the difference (error) between the source and output for the same section of programme. Again, this is better than the results for YT. In this BBC example the difference error level is around 40dB below the signal level. Again, this is nominally poor if it were a standard noise level or distortion result where it would look like a distortion level of around 1%. But it is better than the YT examples – as, of course, we’d hope given the higher bitrate (320k) employed by the BBC! (The BBC eventually decided that flac streaming wasn’t required, although some audiophiles have disagreed with them and regret the decision to stay with 320k aac.)</p>

<p>
More evidence would be needed to be confident in drawing reliable general conclusions. It is also worth adding that the BBC now limit the audio for the video streams to a maximum of just 128k aac as they judge that to be fine for video, even of musical events. Despite streaming Proms via R3 at 320k, their TV video streams of the same events are limited to 128k aac. So there does seem to be an assumption that video somehow reduces the need for more accurate audio. That may be so, but the above examination does perhaps serve as a pointer to the possibility that the audio quality of YT’s output is being limited  from an audiophile’s POV by their offered choice of birates/codecs. So this general area may be worth further examination...</p>


<p><i>J. C. G. Lesurf&nbsp;&nbsp;<br>
24th July 2022</i>&nbsp;&nbsp;<br></p>
<p>&nbsp;&nbsp;I’d like to thank the RVW Society for kindly providing me with source copies of files for the purpose of the comparisons. You can find out more about the Society and their CD releases on the Albion label here: <a href="https://rvwsociety.com/" name="https:/rvwsociety.com/">The Ralph Vaughan Williams Society.</a>
<br>
</p><hr>
<div>
<p><a href="https://www.audiomisc.co.uk/index.html"><img src="https://www.audiomisc.co.uk/ambut.gif" alt="ambut.gif - 3891 bytes" width="161" height="51"></a></p><hr>
</div>



<br>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ESP32 RC Cars (202 pts)]]></title>
            <link>https://github.com/mattsroufe/esp32_rc_cars</link>
            <guid>42901007</guid>
            <pubDate>Sat, 01 Feb 2025 18:51:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mattsroufe/esp32_rc_cars">https://github.com/mattsroufe/esp32_rc_cars</a>, See on <a href="https://news.ycombinator.com/item?id=42901007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ESP32 RC Cars</h2><a id="user-content-esp32-rc-cars" aria-label="Permalink: ESP32 RC Cars" href="#esp32-rc-cars"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mattsroufe/esp32_rc_cars/blob/main/car_photo.jpeg"><img src="https://github.com/mattsroufe/esp32_rc_cars/raw/main/car_photo.jpeg" alt=""></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mattsroufe/esp32_rc_cars/blob/main/screenshot.png"><img src="https://github.com/mattsroufe/esp32_rc_cars/raw/main/screenshot.png" alt=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo video" href="#demo-video"></a></p>
<p dir="auto"><a href="https://youtu.be/OubYFXmvA1E" rel="nofollow">https://youtu.be/OubYFXmvA1E</a></p>
<p dir="auto">This project demonstrates an ESP32-based remote-controlled camera system capable of transmitting live video streams over WebSockets and controlling motors and servos. A Python server application manages WebSocket communication and provides a web interface to view and control the ESP32 devices.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Live video streaming from an ESP32-CAM to a web server.</li>
<li>Remote control of a motor and a servo via WebSocket commands.</li>
<li>Automatic timeout to reset motor and servo to default states.</li>
<li>Dynamic multi-client video feed canvas on the server.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware Requirements</h2><a id="user-content-hardware-requirements" aria-label="Permalink: Hardware Requirements" href="#hardware-requirements"></a></p>
<ul dir="auto">
<li>ESP32-CAM (AI Thinker module or compatible board).</li>
<li>Motor and servo connected to appropriate GPIO pins.</li>
<li>Stable 5V power supply for the ESP32-CAM.</li>
<li>Optional SD card (if required for other functionalities).</li>
<li>Wi-Fi network for communication.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Software Requirements</h2><a id="user-content-software-requirements" aria-label="Permalink: Software Requirements" href="#software-requirements"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ESP32 Code</h3><a id="user-content-esp32-code" aria-label="Permalink: ESP32 Code" href="#esp32-code"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Libraries</h4><a id="user-content-libraries" aria-label="Permalink: Libraries" href="#libraries"></a></p>
<ul dir="auto">
<li><code>WiFi.h</code> for Wi-Fi connectivity.</li>
<li><code>ArduinoWebsockets.h</code> for WebSocket communication.</li>
<li><code>esp_camera.h</code> for ESP32-CAM camera control.</li>
<li><code>ServoControl.h</code> and <code>Esc.h</code> for controlling the servo and motor.</li>
<li><code>Arduino.h</code> for standard Arduino functions.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python Server</h3><a id="user-content-python-server" aria-label="Permalink: Python Server" href="#python-server"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Dependencies</h4><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<p dir="auto">Install the following Python libraries:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip3 install aiohttp opencv-python numpy"><pre>pip3 install aiohttp opencv-python numpy</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ESP32 Firmware</h3><a id="user-content-esp32-firmware" aria-label="Permalink: ESP32 Firmware" href="#esp32-firmware"></a></p>
<ol dir="auto">
<li>Modify the <code>secrets.h</code> file to include your Wi-Fi credentials and WebSocket server URL:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="#define WIFI_SSID &quot;YourWiFiSSID&quot;
#define WIFI_PASSWORD &quot;YourWiFiPassword&quot;
#define WS_SERVER_URL &quot;ws://YourServerIP:Port&quot;"><pre>#<span>define</span> <span>WIFI_SSID</span> <span><span>"</span>YourWiFiSSID<span>"</span></span>
#<span>define</span> <span>WIFI_PASSWORD</span> <span><span>"</span>YourWiFiPassword<span>"</span></span>
#<span>define</span> <span>WS_SERVER_URL</span> <span><span>"</span>ws://YourServerIP:Port<span>"</span></span></pre></div>
<ol start="2" dir="auto">
<li>Ensure the GPIO pins for the camera module, motor, and servo match your hardware setup:</li>
</ol>
<ul dir="auto">
<li>Camera GPIO pins are pre-configured for the AI Thinker ESP32-CAM board.</li>
<li>Update motor and servo pins if necessary.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python Server</h3><a id="user-content-python-server-1" aria-label="Permalink: Python Server" href="#python-server-1"></a></p>
<ol dir="auto">
<li>Place the server script in a directory with an <code>index.html</code> file for the web interface.</li>
<li>Start the server:</li>
</ol>

<p dir="auto">The server will be accessible on <code>http://localhost:8080/</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ESP32</h3><a id="user-content-esp32" aria-label="Permalink: ESP32" href="#esp32"></a></p>
<ol dir="auto">
<li>Upload the provided sketch to your ESP32-CAM using the Arduino IDE or a compatible platform.</li>
<li>Monitor the serial output to ensure successful connection to Wi-Fi and the WebSocket server.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Server</h3><a id="user-content-server" aria-label="Permalink: Server" href="#server"></a></p>
<ol dir="auto">
<li>Run the Python server script.</li>
<li>Open the web interface in a browser to view the live video streams.</li>
<li>Send control commands via the WebSocket connection.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">WebSocket Commands</h3><a id="user-content-websocket-commands" aria-label="Permalink: WebSocket Commands" href="#websocket-commands"></a></p>
<ul dir="auto">
<li><code>MOTOR:&lt;speed&gt;</code>: Set motor speed (-255 to 255).</li>
<li><code>SERVO:&lt;angle&gt;</code>: Set servo angle (0 to 180).</li>
<li><code>CONTROL:&lt;speed&gt;:&lt;angle&gt;</code>: Control both motor speed and servo angle simultaneously.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical Details</h2><a id="user-content-technical-details" aria-label="Permalink: Technical Details" href="#technical-details"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ESP32 Initialization</h3><a id="user-content-esp32-initialization" aria-label="Permalink: ESP32 Initialization" href="#esp32-initialization"></a></p>
<ul dir="auto">
<li><strong>Wi-Fi</strong>: Connects to the specified Wi-Fi network.</li>
<li><strong>Camera</strong>: Configures the ESP32-CAM with the appropriate settings for video streaming.</li>
<li><strong>WebSocket</strong>: Establishes a WebSocket connection with the server.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Timeout Handling</h3><a id="user-content-timeout-handling" aria-label="Permalink: Timeout Handling" href="#timeout-handling"></a></p>
<p dir="auto">If no control commands are received within a predefined timeout period, the motor speed resets to <code>0</code>, and the servo angle resets to <code>90</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python Server</h3><a id="user-content-python-server-2" aria-label="Permalink: Python Server" href="#python-server-2"></a></p>
<ul dir="auto">
<li>Handles WebSocket communication with multiple ESP32 clients.</li>
<li>Processes incoming video frames and dynamically arranges them in a grid.</li>
<li>Streams the grid of video frames to the web interface.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Connection Issues</strong>:</p>
<ul dir="auto">
<li>Verify Wi-Fi credentials in <code>secrets.h</code>.</li>
<li>Check that the WebSocket server is running and accessible.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Video Stream Issues</strong>:</p>
<ul dir="auto">
<li>Ensure proper power supply to the ESP32-CAM.</li>
<li>Verify camera initialization settings.</li>
</ul>
</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is open-source and available under the MIT License.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribution</h2><a id="user-content-contribution" aria-label="Permalink: Contribution" href="#contribution"></a></p>
<p dir="auto">Feel free to submit issues or pull requests to improve the application!</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>