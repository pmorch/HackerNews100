<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 31 Jan 2025 11:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hacker News for Gamedev (110 pts)]]></title>
            <link>https://gamedev.city/</link>
            <guid>42885520</guid>
            <pubDate>Fri, 31 Jan 2025 07:56:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gamedev.city/">https://gamedev.city/</a>, See on <a href="https://news.ycombinator.com/item?id=42885520">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="inside">


      

<ol>
<li id="story_b6unru" data-shortid="b6unru">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://irokaru.github.io/pixel-scaler/" rel="ugc noreferrer">Pixel art upscaler with a nice algorithm</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="2D, 3D and everything in between" href="https://gamedev.city/t/art">art</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/irokaru.github.io">irokaru.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2025-01-29 15:19:08 -0600">38 hours ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_b6unru">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Firokaru.github.io%2Fpixel-scaler%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Firokaru.github.io%2Fpixel-scaler%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Firokaru.github.io%2Fpixel-scaler%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/b6unru/pixel_art_upscaler_with_nice_algorithm">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_hfyy4d" data-shortid="hfyy4d">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.youtube.com/watch?v=HPqGaIMVuLs" rel="ugc noreferrer">Surface-Stable Fractal Dithering</a>
    </span>
      <a title="A new form of dithering I call Surface-Stable Fractal Dithering.Released it as open source along with this explainer video of how it works.

Find the shader source and example project here:
https://github.com/runevision/Dither3D
https://blog.runevision.com" href="https://gamedev.city/s/hfyy4d/surface_stable_fractal_dithering">☶</a>
      <span>
          <a title="you want to share a video or a link that contains a video " href="https://gamedev.city/t/video">video</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/youtube.com">youtube.com</a></p><div>
        <p><a href="https://gamedev.city/~hayes"><img srcset="https://gamedev.city/avatars/hayes-16.png 1x, https://gamedev.city/avatars/hayes-32.png 2x" alt="hayes avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/hayes-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~hayes">hayes</a>

        <span title="2025-01-24 10:38:52 -0600">6 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_hfyy4d">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DHPqGaIMVuLs">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DHPqGaIMVuLs">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DHPqGaIMVuLs">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/hfyy4d/surface_stable_fractal_dithering">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_giuycn" data-shortid="giuycn">
<div>
  <div>
      <p>9</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://github.com/libsdl-org/SDL/releases/tag/release-3.2.0" rel="ugc noreferrer">SDL 3 it's officially released (3.2.0)</a>
    </span>
      <span>
          <a title="something related to recent events, releases or announcements" href="https://gamedev.city/t/news">news</a>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/github.com">github.com</a></p><div>
        <p><a href="https://gamedev.city/~Andre-LA"><img srcset="https://gamedev.city/avatars/Andre-LA-16.png 1x, https://gamedev.city/avatars/Andre-LA-32.png 2x" alt="Andre-LA avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/Andre-LA-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~Andre-LA">Andre-LA</a>

        <span title="2025-01-21 14:14:30 -0600">9 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_giuycn">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Flibsdl-org%2FSDL%2Freleases%2Ftag%2Frelease-3.2.0">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fgithub.com%2Flibsdl-org%2FSDL%2Freleases%2Ftag%2Frelease-3.2.0">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fgithub.com%2Flibsdl-org%2FSDL%2Freleases%2Ftag%2Frelease-3.2.0">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/giuycn/sdl_3_it_s_officially_released_3_2_0">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_vlpdv7" data-shortid="vlpdv7">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://ssno.cc/posts/reversing-tac-1-4-2025/" rel="ugc noreferrer">Reverse Engineering Call Of Duty Anti-Cheat (Black Ops Cold War)</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/ssno.cc">ssno.cc</a></p><div>
        <p><a href="https://gamedev.city/~Mew"><img srcset="https://gamedev.city/avatars/Mew-16.png 1x, https://gamedev.city/avatars/Mew-32.png 2x" alt="Mew avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/Mew-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~Mew">Mew</a>

        <span title="2025-01-20 23:48:21 -0600">10 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_vlpdv7">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fssno.cc%2Fposts%2Freversing-tac-1-4-2025%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fssno.cc%2Fposts%2Freversing-tac-1-4-2025%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fssno.cc%2Fposts%2Freversing-tac-1-4-2025%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/vlpdv7/reverse_engineering_call_duty_anti_cheat">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_bsy8d5" data-shortid="bsy8d5">
<div>
  <div>
      <p>6</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://github.com/terrehbyte/awesome-devblogs" rel="ugc noreferrer">A curated list of gamedev related devblogs</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/github.com">github.com</a></p><div>
        <p><a href="https://gamedev.city/~Valden"><img srcset="https://gamedev.city/avatars/Valden-16.png 1x, https://gamedev.city/avatars/Valden-32.png 2x" alt="Valden avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/Valden-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~Valden">Valden</a>

        <span title="2025-01-20 05:12:33 -0600">11 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_bsy8d5">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Fterrehbyte%2Fawesome-devblogs">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fgithub.com%2Fterrehbyte%2Fawesome-devblogs">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fgithub.com%2Fterrehbyte%2Fawesome-devblogs">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/bsy8d5/curated_list_gamedev_related_devblogs">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_5drqoa" data-shortid="5drqoa">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.riotgames.com/en/news/tech-blog-cpu-usage" rel="ugc noreferrer">Riot Tech Blog: Improving Performance by Streamlining League’s Server Selection</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="admin, operations and general information about the industry" href="https://gamedev.city/t/industry">industry</a>
      </span>
        <a href="https://gamedev.city/domains/riotgames.com">riotgames.com</a></p><div>
        <p><a href="https://gamedev.city/~ironcutter24"><img srcset="https://gamedev.city/avatars/ironcutter24-16.png 1x, https://gamedev.city/avatars/ironcutter24-32.png 2x" alt="ironcutter24 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ironcutter24-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ironcutter24">ironcutter24</a>

        <span title="2025-01-19 02:18:09 -0600">12 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_5drqoa">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.riotgames.com%2Fen%2Fnews%2Ftech-blog-cpu-usage">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.riotgames.com%2Fen%2Fnews%2Ftech-blog-cpu-usage">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.riotgames.com%2Fen%2Fnews%2Ftech-blog-cpu-usage">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/5drqoa/riot_tech_blog_improving_performance_by">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_3n89kw" data-shortid="3n89kw">
<div>
  <div>
      <p>8</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://bsky.app/profile/gamemakerstoolkit.com/post/3lfr7fg65dk24" rel="ugc noreferrer">Ludum Dare events cancelled for 2025, as host is struggling financially</a>
    </span>
      <a title="Let's support Mike and Ludum Dare!

https://www.patreon.com/c/mikekasprzak/about" href="https://gamedev.city/s/3n89kw/ludum_dare_events_cancelled_for_2025_as">☶</a>
      <span>
          <a title="something that's hosted on a social media platform" href="https://gamedev.city/t/social-media">social-media</a>
          <a title="anything related or using generative AI" href="https://gamedev.city/t/ai">ai</a>
          <a title="admin, operations and general information about the industry" href="https://gamedev.city/t/industry">industry</a>
      </span>
        <a href="https://gamedev.city/domains/bsky.app">bsky.app</a></p><div>
        <p><a href="https://gamedev.city/~ShadowMitia"><img srcset="https://gamedev.city/avatars/ShadowMitia-16.png 1x, https://gamedev.city/avatars/ShadowMitia-32.png 2x" alt="ShadowMitia avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ShadowMitia-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ShadowMitia">ShadowMitia</a>

        <span title="2025-01-15 13:27:13 -0600">15 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_3n89kw">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fbsky.app%2Fprofile%2Fgamemakerstoolkit.com%2Fpost%2F3lfr7fg65dk24">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fbsky.app%2Fprofile%2Fgamemakerstoolkit.com%2Fpost%2F3lfr7fg65dk24">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fbsky.app%2Fprofile%2Fgamemakerstoolkit.com%2Fpost%2F3lfr7fg65dk24">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/3n89kw/ludum_dare_events_cancelled_for_2025_as">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_fbh5aq" data-shortid="fbh5aq">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.patreon.com/posts/how-do-i-record-34759149" rel="ugc noreferrer">How does Kev record a .gif for this twitter thing?</a>
    </span>
      <span>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/patreon.com">patreon.com</a></p><div>
        <p><a href="https://gamedev.city/~taletronic"><img srcset="https://gamedev.city/avatars/taletronic-16.png 1x, https://gamedev.city/avatars/taletronic-32.png 2x" alt="taletronic avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/taletronic-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~taletronic">taletronic</a>

        <span title="2025-01-13 01:32:42 -0600">18 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_fbh5aq">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.patreon.com%2Fposts%2Fhow-do-i-record-34759149">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.patreon.com%2Fposts%2Fhow-do-i-record-34759149">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fhow-do-i-record-34759149">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/fbh5aq/how_does_kev_record_gif_for_this_twitter">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_la00m1" data-shortid="la00m1">
<div>
  <div>
      <p>6</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.youtube.com/watch?v=DYWTw19_8r4" rel="ugc noreferrer">Introducing Clay - High Performance UI Layout in C</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="you want to share a video or a link that contains a video " href="https://gamedev.city/t/video">video</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/youtube.com">youtube.com</a></p><div>
        <p><a href="https://gamedev.city/~slembcke"><img srcset="https://gamedev.city/avatars/slembcke-16.png 1x, https://gamedev.city/avatars/slembcke-32.png 2x" alt="slembcke avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/slembcke-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~slembcke">slembcke</a>

        <span title="2025-01-11 23:18:32 -0600">19 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_la00m1">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDYWTw19_8r4">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDYWTw19_8r4">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDYWTw19_8r4">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/la00m1/introducing_clay_high_performance_ui">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_zquctz" data-shortid="zquctz">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://dd3d.dmitriysalnikov.ru/docs/1.4.5/index.html" rel="ugc noreferrer">Godot addon to draw debug lines in 2D and 3D</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="" href="https://gamedev.city/t/godot">godot</a>
      </span>
        <a href="https://gamedev.city/domains/dd3d.dmitriysalnikov.ru">dd3d.dmitriysalnikov.ru</a></p><div>
        <p><a href="https://gamedev.city/~grej"><img srcset="https://gamedev.city/avatars/grej-16.png 1x, https://gamedev.city/avatars/grej-32.png 2x" alt="grej avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/grej-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~grej">grej</a>

        <span title="2025-01-10 12:22:53 -0600">20 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_zquctz">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fdd3d.dmitriysalnikov.ru%2Fdocs%2F1.4.5%2Findex.html">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fdd3d.dmitriysalnikov.ru%2Fdocs%2F1.4.5%2Findex.html">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fdd3d.dmitriysalnikov.ru%2Fdocs%2F1.4.5%2Findex.html">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/zquctz/godot_addon_draw_debug_lines_2d_3d">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_3u7dkb" data-shortid="3u7dkb">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://racenis.github.io/tram-sdk/why.html" rel="ugc noreferrer">Tramway SDK: a Quake, GoldSrc or Source like engine/framework</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="you are sharing a game engine" href="https://gamedev.city/t/engine">engine</a>
      </span>
        <a href="https://gamedev.city/domains/racenis.github.io">racenis.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2025-01-07 19:57:29 -0600">23 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_3u7dkb">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fracenis.github.io%2Ftram-sdk%2Fwhy.html">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fracenis.github.io%2Ftram-sdk%2Fwhy.html">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fracenis.github.io%2Ftram-sdk%2Fwhy.html">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/3u7dkb/tramway_sdk_quake_goldsrc_source_like">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_m7i7vc" data-shortid="m7i7vc">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://blurbusters.com/blur-busters-open-source-display-initiative-refresh-cycle-shaders/" rel="ugc noreferrer">Blur Busters Open Source Display Initiative – Refresh Cycle Shaders - Blur Busters</a>
    </span>
      <span>
          <a title="2D, 3D and everything in between" href="https://gamedev.city/t/art">art</a>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/blurbusters.com">blurbusters.com</a></p><div>
        <p><a href="https://gamedev.city/~berru"><img srcset="https://gamedev.city/avatars/berru-16.png 1x, https://gamedev.city/avatars/berru-32.png 2x" alt="berru avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/berru-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~berru">berru</a>

        <span title="2025-01-05 03:02:20 -0600">26 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_m7i7vc">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fblurbusters.com%2Fblur-busters-open-source-display-initiative-refresh-cycle-shaders%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fblurbusters.com%2Fblur-busters-open-source-display-initiative-refresh-cycle-shaders%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fblurbusters.com%2Fblur-busters-open-source-display-initiative-refresh-cycle-shaders%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/m7i7vc/blur_busters_open_source_display">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_7ajlzt" data-shortid="7ajlzt">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://github.com/s-macke/VoxelSpace" rel="ugc noreferrer">VoxelSpace: Terrain rendering algorithm in less than 20 lines of code</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="articles or resources related to the history and development of the industry" href="https://gamedev.city/t/game-history">game-history</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/github.com">github.com</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2025-01-04 13:50:56 -0600">26 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_7ajlzt">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fgithub.com%2Fs-macke%2FVoxelSpace">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fgithub.com%2Fs-macke%2FVoxelSpace">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fgithub.com%2Fs-macke%2FVoxelSpace">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/7ajlzt/voxelspace_terrain_rendering_algorithm">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_vbpmbd" data-shortid="vbpmbd">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://realfix.substack.com/p/handmade-engine-survey-results" rel="ugc noreferrer">Handmade Engine Survey Results</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="you are sharing a game engine" href="https://gamedev.city/t/engine">engine</a>
      </span>
        <a href="https://gamedev.city/domains/realfix.substack.com">realfix.substack.com</a></p><div>
        <p><a href="https://gamedev.city/~lessa"><img srcset="https://gamedev.city/avatars/lessa-16.png 1x, https://gamedev.city/avatars/lessa-32.png 2x" alt="lessa avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/lessa-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~lessa">lessa</a>

        <span title="2025-01-02 03:06:20 -0600">29 days ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_vbpmbd">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Frealfix.substack.com%2Fp%2Fhandmade-engine-survey-results">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Frealfix.substack.com%2Fp%2Fhandmade-engine-survey-results">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Frealfix.substack.com%2Fp%2Fhandmade-engine-survey-results">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/vbpmbd/handmade_engine_survey_results">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_dd3wcg" data-shortid="dd3wcg">
<div>
  <div>
      <p>1</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://sevencrane.itch.io/vapor-trails/devlog/432175/ghost-ai-for-andromeda" rel="ugc noreferrer">Ghost AI for Andromeda</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
      </span>
        <a href="https://gamedev.city/domains/sevencrane.itch.io">sevencrane.itch.io</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-31 17:37:36 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_dd3wcg">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fsevencrane.itch.io%2Fvapor-trails%2Fdevlog%2F432175%2Fghost-ai-for-andromeda">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fsevencrane.itch.io%2Fvapor-trails%2Fdevlog%2F432175%2Fghost-ai-for-andromeda">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fsevencrane.itch.io%2Fvapor-trails%2Fdevlog%2F432175%2Fghost-ai-for-andromeda">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/dd3wcg/ghost_ai_for_andromeda">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_p5gzzh" data-shortid="p5gzzh">
<div>
  <div>
      <p>4</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://audiomass.co/" rel="ugc noreferrer">AudioMass: In-browser audio editor similar to Audacity</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="sound and music" href="https://gamedev.city/t/audio">audio</a>
      </span>
        <a href="https://gamedev.city/domains/audiomass.co">audiomass.co</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-29 12:50:27 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_p5gzzh">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Faudiomass.co%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Faudiomass.co%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Faudiomass.co%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/p5gzzh/audiomass_browser_audio_editor_similar">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_4xul27" data-shortid="4xul27">
<div>
  <div>
      <p>3</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://allusion-app.github.io/" rel="ugc noreferrer">Allusion - Visual Library Manager</a>
    </span>
      <span>
          <a title="Free and open source resources are always apreciated!" href="https://gamedev.city/t/open-source">open-source</a>
          <a title="art galleries or pieces that are exceptionally good or interesting - do not post your own art" href="https://gamedev.city/t/art-reference">art-reference</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/allusion-app.github.io">allusion-app.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-23 15:12:48 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_4xul27">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fallusion-app.github.io%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fallusion-app.github.io%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fallusion-app.github.io%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/4xul27/allusion_visual_library_manager">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_oelkvo" data-shortid="oelkvo">
<div>
  <div>
      <p>9</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://ldtk.io/" rel="ugc noreferrer">LDtk: A modern 2D level editor from the director of Dead Cells</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/ldtk.io">ldtk.io</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-22 08:26:42 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_oelkvo">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fldtk.io%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fldtk.io%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fldtk.io%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/oelkvo/ldtk_modern_2d_level_editor_from_director">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_mbiw21" data-shortid="mbiw21">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://youtu.be/69Ukg2BqIk0" rel="ugc noreferrer">how does an indie game get made?</a>
    </span>
      <span>
          <a title="you want to share a video or a link that contains a video " href="https://gamedev.city/t/video">video</a>
          <a title="analysis, theories and studies related to a specific game or group of games" href="https://gamedev.city/t/game-analysis">game-analysis</a>
      </span>
        <a href="https://gamedev.city/domains/youtu.be">youtu.be</a></p><div>
        <p><a href="https://gamedev.city/~cuca"><img srcset="https://gamedev.city/avatars/cuca-16.png 1x, https://gamedev.city/avatars/cuca-32.png 2x" alt="cuca avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/cuca-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~cuca">cuca</a>

        <span title="2024-12-22 16:10:36 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_mbiw21">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fyoutu.be%2F69Ukg2BqIk0">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fyoutu.be%2F69Ukg2BqIk0">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fyoutu.be%2F69Ukg2BqIk0">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/mbiw21/how_does_indie_game_get_made">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_pytqxu" data-shortid="pytqxu">
<div>
  <div>
      <p>5</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://trenchbroom.github.io/" rel="ugc noreferrer">TrenchBroom: FOSS level editor for the Quake-engine (Can be used in Unity, Godot, Unreal, etc)</a>
    </span>
      <span>
          <a title="2D, 3D and everything in between" href="https://gamedev.city/t/art">art</a>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
          <a title="tools that are useful to everyone" href="https://gamedev.city/t/dev-tools">dev-tools</a>
      </span>
        <a href="https://gamedev.city/domains/trenchbroom.github.io">trenchbroom.github.io</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-14 02:33:06 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_pytqxu">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Ftrenchbroom.github.io%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Ftrenchbroom.github.io%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Ftrenchbroom.github.io%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/pytqxu/trenchbroom_foss_level_editor_for_quake">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_so96zy" data-shortid="so96zy">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://indiegames101.com/blog/2023-10-20-from-game-idea-to-game-concept/" rel="ugc noreferrer">From game idea to game concept</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
      </span>
        <a href="https://gamedev.city/domains/indiegames101.com">indiegames101.com</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-12 22:17:29 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_so96zy">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Findiegames101.com%2Fblog%2F2023-10-20-from-game-idea-to-game-concept%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Findiegames101.com%2Fblog%2F2023-10-20-from-game-idea-to-game-concept%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Findiegames101.com%2Fblog%2F2023-10-20-from-game-idea-to-game-concept%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/so96zy/from_game_idea_game_concept">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_0gmxv5" data-shortid="0gmxv5">
<div>
  <div>
      <p>2</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://mikejsavage.co.uk/geometry-clipmaps/" rel="ugc noreferrer">Geometry clipmaps: simple terrain rendering with level of detail</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/mikejsavage.co.uk">mikejsavage.co.uk</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-12 11:15:42 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_0gmxv5">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fmikejsavage.co.uk%2Fgeometry-clipmaps%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fmikejsavage.co.uk%2Fgeometry-clipmaps%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fmikejsavage.co.uk%2Fgeometry-clipmaps%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/0gmxv5/geometry_clipmaps_simple_terrain">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_kiazeh" data-shortid="kiazeh">
<div>
  <div>
      <p>8</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://lostgarden.com/2018/01/24/cozy-games/comment-page-1/" rel="ugc noreferrer">What is a ‘Cozy’ game?</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
          <a title="analysis, theories and studies related to a specific game or group of games" href="https://gamedev.city/t/game-analysis">game-analysis</a>
      </span>
        <a href="https://gamedev.city/domains/lostgarden.com">lostgarden.com</a></p><div>
        <p><a href="https://gamedev.city/~isadora"><img srcset="https://gamedev.city/avatars/isadora-16.png 1x, https://gamedev.city/avatars/isadora-32.png 2x" alt="isadora avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/isadora-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~isadora">isadora</a>

        <span title="2024-12-11 15:32:19 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_kiazeh">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Flostgarden.com%2F2018%2F01%2F24%2Fcozy-games%2Fcomment-page-1%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Flostgarden.com%2F2018%2F01%2F24%2Fcozy-games%2Fcomment-page-1%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Flostgarden.com%2F2018%2F01%2F24%2Fcozy-games%2Fcomment-page-1%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/kiazeh/what_is_cozy_game">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_wkxfjj" data-shortid="wkxfjj">
<div>
  <div>
      <p>6</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://thebookofshaders.com/" rel="ugc noreferrer">The Book of Shaders</a>
    </span>
      <span>
          <a title="interesting resources for programmers" href="https://gamedev.city/t/code">code</a>
          <a title="graphics tech behind game visuals, from basic rendering to complex effects." href="https://gamedev.city/t/graphics">graphics</a>
      </span>
        <a href="https://gamedev.city/domains/thebookofshaders.com">thebookofshaders.com</a></p><div>
        <p><a href="https://gamedev.city/~saint11"><img srcset="https://gamedev.city/avatars/saint11-16.png 1x, https://gamedev.city/avatars/saint11-32.png 2x" alt="saint11 avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/saint11-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~saint11">saint11</a>

        <span title="2024-12-11 13:20:48 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_wkxfjj">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fthebookofshaders.com%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fthebookofshaders.com%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fthebookofshaders.com%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/wkxfjj/book_shaders">
              no comments</a>
          </span>

    </p></div>
  </div>
</div>

</li>

<li id="story_wtkjfm" data-shortid="wtkjfm">
<div>
  <div>
      <p>3</p>
  </div>
  <div>
    <p><span role="heading" aria-level="1">
        <a href="https://www.charliecleveland.com/ugliness-needed/" rel="ugc noreferrer">Ugliness Needed</a>
    </span>
      <span>
          <a title="game design" href="https://gamedev.city/t/design">design</a>
      </span>
        <a href="https://gamedev.city/domains/charliecleveland.com">charliecleveland.com</a></p><div>
        <p><a href="https://gamedev.city/~ncharlie"><img srcset="https://gamedev.city/avatars/ncharlie-16.png 1x, https://gamedev.city/avatars/ncharlie-32.png 2x" alt="ncharlie avatar" loading="lazy" decoding="async" src="https://gamedev.city/avatars/ncharlie-16.png" width="16" height="16"></a>
          <span> via </span>
        <a href="https://gamedev.city/~ncharlie">ncharlie</a>

        <span title="2024-12-10 15:00:47 -0600">1 month ago</span>

          <span> | </span>
          <span>
            
            <label for="archive_wtkjfm">archive</label>
            <div>
              <p><a href="https://web.archive.org/web/3/https%3A%2F%2Fwww.charliecleveland.com%2Fugliness-needed%2F">Archive.org</a>
              <a href="https://archive.today/https%3A%2F%2Fwww.charliecleveland.com%2Fugliness-needed%2F">Archive.today</a>
              <a href="https://ghostarchive.org/search?term=https%3A%2F%2Fwww.charliecleveland.com%2Fugliness-needed%2F">Ghostarchive</a>
            </p></div>
          </span>
          <span>
            <span> | </span>
            <a role="heading" aria-level="2" href="https://gamedev.city/s/wtkjfm/ugliness_needed">
              1 comment</a>
          </span>

    </p></div>
  </div>
</div>

</li>

</ol>



<div>

    <p><a href="https://gamedev.city/page/2">Page 2 &gt;&gt;</a>
</p></div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hydro: Distributed Programming Framework for Rust (104 pts)]]></title>
            <link>https://hydro.run/docs/hydro/</link>
            <guid>42885087</guid>
            <pubDate>Fri, 31 Jan 2025 06:11:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hydro.run/docs/hydro/">https://hydro.run/docs/hydro/</a>, See on <a href="https://news.ycombinator.com/item?id=42885087">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><div><article><div><header></header>
<p>Hydro is a high-level distributed programming framework for Rust. Hydro can help you quickly write scalable distributed services that are correct by construction. Much like Rust helps with memory safety, Hydro helps with <a href="https://hydro.run/docs/hydro/correctness"><strong>distributed safety</strong></a>. Hydro also makes it easy to get started by running your distributed programs in either testing or deployment modes.</p>
<p>Hydro is a distributed dataflow language, powered by the high-performance single-threaded <a href="https://hydro.run/docs/dfir/">DFIR runtime</a>. Unlike traditional architectures such as actors or RPCs, Hydro offers <em>choreographic</em> APIs, where expressions and functions can describe computation that takes place across many locations. It also integrates with <a href="https://hydro.run/docs/deploy/">Hydro Deploy</a> to make it easy to deploy and run distributed Hydro programs either locally or in the cloud.</p>
<p>Hydro uses a two-stage compilation approach. Hydro programs are standard Rust programs, which first run on the developer's laptop to generate a <em>deployment plan</em>. This plan is then compiled to DFIR to generate individual binaries for each machine in the distributed system (enabling zero-overhead abstractions), which are then deployed to the cloud using the generated plan along with specifications of cloud resources.</p>
<p>Hydro has been used to write a variety of high-performance distributed systems, including implementations of classic distributed protocols such as two-phase commit and Paxos. Work is ongoing to develop a distributed systems standard library that will offer these protocols and more as reusable components.</p>
<div><p><span><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</p><p>The docs for Hydro are still a work in progress. If you have any questions or run into bugs, please file an issue on the <a href="https://github.com/hydro-project/hydro" target="_blank" rel="noopener noreferrer">Hydro GitHub repository</a>.</p></div></div></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mini-R1: Reproduce DeepSeek R1 "Aha Moment" (176 pts)]]></title>
            <link>https://www.philschmid.de/mini-deepseek-r1</link>
            <guid>42884834</guid>
            <pubDate>Fri, 31 Jan 2025 05:03:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.philschmid.de/mini-deepseek-r1">https://www.philschmid.de/mini-deepseek-r1</a>, See on <a href="https://news.ycombinator.com/item?id=42884834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The release of Deepseek R1 shocked the industry. Why? Well, DeepSeek-R1 is an open model that rivals OpenAI's o1 in complex reasoning tasks, introduced using Group Relative Policy Optimization (GRPO) and RL-focused multi-stage training approach. They not only released the model, but also a research paper on how they did it.</p>
<p>In the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2501.12948">paper</a> they described an "aha moment" when using pure RL to train the model. During this phase, DeepSeek-R1-Zero (the first test of DeepSeek-R1) learns to allocate more thinking time to a problem by reevaluating its initial approach without any human feedback or data describing how to do it.  They describe this as an "aha moment" as:</p>
<blockquote>
<p>This behavior is not only a testament to the model’s growing reasoning abilities but also a captivating example of how reinforcement learning can lead to unexpected and sophisticated outcomes.</p>
</blockquote>
<p>In this blog post we want to recreate the small "aha moment" of DeepSeek-R1 using Group Relative Policy Optimization (GRPO) and the Countdown Game. We will train an open model using reinforcement learning trying to teach it self-verification and search abilities all on its own to solve the Countdown Game.
The Countdown game is a numbers puzzle where players use a set of randomly drawn numbers and basic arithmetic operations (+, -, ×, ÷) to reach or get as close as possible to a target number.</p>
<div><pre><code>Target Number: 952
Available Numbers: 25, 50, 75, 100, 3, 6

(100 × (3 × 3)) + (50 + 6 / 3) = 952
</code></pre></div>
<p>The blog post includes an interactive code which you can run in a Jupyter Notebook on how to train a model using GRPO and Q-Lora. This is a great way to learn how to use TRL and GRPO, but it is very slow and requires a lot of compute. Additionally, I added a <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/scripts/run_r1_grpo.py">script</a> and instructions to run the training on Node with multiple GPUs or a SLURM cluster.</p>
<ol>
<li><a href="#1-setup-the-development-environment">Setup the development environment</a></li>
<li><a href="#2-generate-training-samples-with-reasoning-prefix-from-the-countdown-game">Generate training samples with reasoning prefix from the Countdown Game</a></li>
<li><a href="#3-train-the-model-using-grpo-educational-part">Train the model using GRPO (Educational part)</a></li>
<li><a href="#4-distributed-training-example-for-grpo-using-deepspeed-and-vllm">Distributed Training example for GRPO using Deepspeed and vLLM</a></li>
<li><a href="#5-results-and-training-observations">Results and Training Observations</a></li>
</ol>
<p><em>Note: This blog is inspired by <a target="_blank" rel="noopener noreferrer" href="https://x.com/jiayi_pirate/status/1882839370505621655">Jiayi Pan</a> who initially explored the idea and proofed it with a small model.</em></p>
<p>But Before we start, let's take a look at the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">Group Relative Policy Optimization (GRPO)</a> and understand how it works.</p>
<p><strong>Group Relative Policy Optimization (GRPO)</strong></p>
<p>Group Relative Policy Optimization (GRPO) is a reinforcement learning algorithm to improve the reasoning capabilities of LLMs. It was introduced in the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">DeepSeekMath</a> paper in the context of mathematical reasoning. GRPO modifies the traditional Proximal Policy Optimization (PPO) by eliminating the need for a value function model. Instead, it estimates baselines from group scores, reducing memory usage and computational overhead. GRPO, now also used by the Qwen team, can be used with rule/binary-based Rewards as well as General Reward Models to improve models on helpfulness.</p>
<ol>
<li><strong>Sampling</strong>: Generate multiple outputs for each prompt using the current policy</li>
<li><strong>Reward Scoring</strong>: Each generation is scored using a reward function, could be (rule-based or outcome-based)</li>
<li><strong>Advantage Calculation</strong>: The average reward of the generated outputs is used as a baseline. The advantage of each solution within the group is then computed relative to this baseline. The reward is normalized within a group.</li>
<li><strong>Policy Optimization</strong>: The policy tries to maximize the GRPO objective, which includes the calculated advantages and a KL divergence term. This is different from how PPO implements the KL term within the reward.</li>
</ol>
<p><img src="https://www.philschmid.de/static/blog/mini-deepseek-r1/grpo.png" alt="grpo.png"></p>
<h2 id="1-setup-the-development-environment">1. Setup the development environment</h2>
<p>Our first step is to install Hugging Face Libraries and Pytorch, vllm, and trl, transformers and datasets. If you haven't heard of trl yet, don't worry. It is a new library on top of transformers and datasets, which makes it easier to fine-tune, rlhf, align open LLMs.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span># Install Pytorch &amp; other libraries, make sure to match your GPU driver version</span></span>
<span data-line=""><span>%</span><span>pip install </span><span>"torch==2.5.1"</span><span> tensorboard </span><span>"setuptools&lt;71.0.0"</span><span>  --</span><span>index</span><span>-</span><span>url https:</span><span>//</span><span>download.pytorch.org</span><span>/</span><span>whl</span><span>/</span><span>cu121</span></span>
<span data-line=""> </span>
<span data-line=""><span># Install flash-attn</span></span>
<span data-line=""><span>%</span><span>pip install flash</span><span>-</span><span>attn </span></span>
<span data-line=""> </span>
<span data-line=""><span># Install Hugging Face libraries</span></span>
<span data-line=""><span>%</span><span>pip install  </span><span>--</span><span>upgrade \</span></span>
<span data-line=""><span>  "transformers==4.48.1"</span><span> \</span></span>
<span data-line=""><span>  "datasets==3.1.0"</span><span> \</span></span>
<span data-line=""><span>  "accelerate==1.3.0"</span><span> \</span></span>
<span data-line=""><span>  "hf-transfer==0.1.9"</span><span> \</span></span>
<span data-line=""><span>  "deepspeed==0.15.4"</span><span> \</span></span>
<span data-line=""><span>  "trl==0.14.0"</span></span>
<span data-line=""> </span>
<span data-line=""><span># install vLLM </span></span>
<span data-line=""><span>%</span><span>pip install </span><span>"vllm==0.7.0"</span></span>
<span data-line=""> </span>
<span data-line=""><span>## IMPORTANT: If you want to run the notebook and the interactive cells you also need to install the following libraries:</span></span>
<span data-line=""><span># But first read it the blog post and then decide as they might conflict with the libraries for distributed training. </span></span>
<span data-line=""><span># %pip install "peft==0.14.0" "bitsandbytes==0.45.0"</span></span>
<span data-line=""> </span></code></pre></div></figure>
<p><em>Note: you may need to restart the kernel to use updated packages.</em></p>
<p>We will use the <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/models">Hugging Face Hub</a> as a remote model versioning service. This means we will automatically push our model, logs and information to the Hub during training. You must register on the <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/join">Hugging Face</a> for this. After you have an account, we will use the <code>login</code> util from the <code>huggingface_hub</code> package to log into our account and store our token (access key) on the disk.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>from</span><span> huggingface_hub </span><span>import</span><span> login</span></span>
<span data-line=""> </span>
<span data-line=""><span>login(</span><span>token</span><span>=</span><span>""</span><span>, </span><span>add_to_git_credential</span><span>=</span><span>True</span><span>) </span><span># ADD YOUR TOKEN HERE</span></span></code></pre></div></figure>
<h2 id="2-generate-training-samples-with-reasoning-prefix-from-the-countdown-game">2. Generate training samples with reasoning prefix from the Countdown Game</h2>
<p>We are going to use the <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4">Jiayi-Pan/Countdown-Tasks-3to4</a> dataset, which contains samples with 3 to 4 numbers and solutions.</p>
<p>As Model we are going to use <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/Qwen/Qwen2.5-3B-Instruct">Qwen/Qwen2.5-3B-Instruct</a> which is a 3B parameter instruction tuned model. This makes it easier to showcase the "aha moment" as it already follows the prompt format. But you can use the base version of Qwen or other models as well. <a target="_blank" rel="noopener noreferrer" href="https://x.com/jiayi_pirate/status/1882839487417561307">Jiayi-Pan</a> explored that the model needs to have a certain quality to be able to learn the reasoning process, starting with &gt; 1.5B parameters.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>from</span><span> transformers </span><span>import</span><span> AutoTokenizer</span></span>
<span data-line=""><span>from</span><span> datasets </span><span>import</span><span> load_dataset</span></span>
<span data-line=""> </span>
<span data-line=""><span># Load dataset from Hugging Face Hub</span></span>
<span data-line=""><span>dataset_id </span><span>=</span><span> "Jiayi-Pan/Countdown-Tasks-3to4"</span></span>
<span data-line=""><span>dataset </span><span>=</span><span> load_dataset(dataset_id, </span><span>split</span><span>=</span><span>"train"</span><span>)</span></span>
<span data-line=""><span># select a random subset of 50k samples</span></span>
<span data-line=""><span>dataset </span><span>=</span><span> dataset.shuffle(</span><span>seed</span><span>=</span><span>42</span><span>).select(</span><span>range</span><span>(</span><span>50000</span><span>))</span></span>
<span data-line=""> </span>
<span data-line=""><span># Load tokenizer from Hugging Face Hub to format the dataset to our "r1" prompt </span></span>
<span data-line=""><span>tokenizer </span><span>=</span><span> AutoTokenizer.from_pretrained(</span><span>"Qwen/Qwen2.5-3B-Instruct"</span><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span># gemerate r1 prompt with a prefix for the model to already start with the thinking process</span></span>
<span data-line=""><span>def</span><span> generate_r1_prompt</span><span>(numbers, target):</span></span>
<span data-line=""><span>    r1_prefix </span><span>=</span><span> [{</span></span>
<span data-line=""><span>        "role"</span><span>: </span><span>"system"</span><span>,</span></span>
<span data-line=""><span>        "content"</span><span>: </span><span>"You are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer."</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>      { </span></span>
<span data-line=""><span>        "role"</span><span>: </span><span>"user"</span><span>,</span></span>
<span data-line=""><span>        "content"</span><span>: </span><span>f</span><span>"Using the numbers </span><span>{</span><span>numbers</span><span>}</span><span>, create an equation that equals </span><span>{</span><span>target</span><span>}</span><span>. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in &lt;think&gt; &lt;/think&gt; tags. And return the final equation and answer in &lt;answer&gt; &lt;/answer&gt; tags, for example &lt;answer&gt; (1 + 2) / 3 = 1 &lt;/answer&gt;."</span></span>
<span data-line=""><span>      },</span></span>
<span data-line=""><span>      {</span></span>
<span data-line=""><span>        "role"</span><span>: </span><span>"assistant"</span><span>,</span></span>
<span data-line=""><span>        "content"</span><span>: </span><span>"Let me solve this step by step.</span><span>\n</span><span>&lt;think&gt;"</span></span>
<span data-line=""><span>      }]</span></span>
<span data-line=""><span>    return</span><span> {</span><span>"prompt"</span><span>: tokenizer.apply_chat_template(r1_prefix, </span><span>tokenize</span><span>=</span><span>False</span><span>, </span><span>continue_final_message</span><span>=</span><span>True</span><span>), </span><span>"target"</span><span>: target}</span></span>
<span data-line=""> </span>
<span data-line=""><span># convert our dataset to the r1 prompt</span></span>
<span data-line=""><span>dataset </span><span>=</span><span> dataset.map(</span><span>lambda</span><span> x: generate_r1_prompt(x[</span><span>"nums"</span><span>], x[</span><span>"target"</span><span>]))</span></span>
<span data-line=""> </span>
<span data-line=""><span># split the dataset into train and test</span></span>
<span data-line=""><span>train_test_split </span><span>=</span><span> dataset.train_test_split(</span><span>test_size</span><span>=</span><span>0.1</span><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>train_dataset </span><span>=</span><span> train_test_split[</span><span>"train"</span><span>]</span></span>
<span data-line=""><span>test_dataset </span><span>=</span><span> train_test_split[</span><span>"test"</span><span>]</span></span></code></pre></div></figure>
<h2 id="3-train-the-model-using-grpo-educational-part">3. Train the model using GRPO (Educational part)</h2>
<p><em>Note: Section 3 is shows the basic on how to use TRL and GRPO. If you want to run the interactive cells you need to install <code>bitsandbytes</code> and <code>peft</code> as they are required for the <code>Trainer</code> class. This section is mostly for educational purposes.</em></p>
<p>TRL supports Group Relative Policy Optimization (GRPO) through a dedicated <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/docs/trl/main/en/grpo_trainer">GRPOTrainer</a> for aligning LLMs from preference data, as described in <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</a>. The <code>GRPOTrainer</code> is a subclass of the <code>Trainer</code> from the <code>transformers</code> library and supports all the same features, including logging, checkpointing, distributed training, and parameter efficient fine-tuning (PEFT).</p>
<p>The <code>GRPOTrainer</code> supports generic Outcome Reward Models (ORM) and custom reward functions, that can be used to implement Rule-Based Reward Models. In the Deepseek R1 paper they implemented Rule-Based Reward Models to verify the correctness of the generated solutions. In our exmaple we are going to do a similar approach, where we will create 2 reward functions that:</p>
<ol>
<li><strong>Format Reward</strong>: Checks if the generated format is correct <code>&lt;think&gt; [thinking] &lt;/think&gt;&lt;answer&gt; [answer] &lt;/answer&gt;</code></li>
<li><strong>Accuracy Reward</strong>: Extracts the equation from the <code>&lt;answer&gt;</code> tag and evaluates it against the target and if every number is used once.</li>
</ol>
<p><em>Note: Correct <code>&lt;answer&gt;</code> in our example includes the equation, for example <code>&lt;answer&gt; 55 + 36 - 7 - 19 &lt;/answer&gt;</code></em></p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>import</span><span> re</span></span>
<span data-line=""> </span>
<span data-line=""><span>def</span><span> format_reward_func</span><span>(completions, target, </span><span>**</span><span>kwargs):</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    Format: &lt;think&gt;...&lt;/think&gt;&lt;answer&gt;...&lt;/answer&gt;</span></span>
<span data-line=""><span>    Args:</span></span>
<span data-line=""><span>        completions (list[str]): Generated outputs</span></span>
<span data-line=""><span>        target (list[str]): Expected answers</span></span>
<span data-line=""><span>      </span></span>
<span data-line=""><span>      Returns:</span></span>
<span data-line=""><span>          list[float]: Reward scores</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    rewards </span><span>=</span><span> []</span></span>
<span data-line=""> </span>
<span data-line=""><span>    for</span><span> completion, gt </span><span>in</span><span> zip</span><span>(completions, target):</span></span>
<span data-line=""> </span>
<span data-line=""><span>      try</span><span>:</span></span>
<span data-line=""><span>        # add synthetic &lt;think&gt; as its already part of the prompt and prefilled for the assistant to more easily match the regex</span></span>
<span data-line=""><span>        completion </span><span>=</span><span> "&lt;think&gt;"</span><span> +</span><span> completion        </span></span>
<span data-line=""><span>        # Check if the format is correct</span></span>
<span data-line=""><span>        regex </span><span>=</span><span> r</span><span>"</span><span>^</span><span>&lt;think&gt;</span><span>([</span><span>^</span><span>&lt;]</span><span>*</span><span>(?:</span><span>&lt;</span><span>(?!</span><span>/</span><span>?</span><span>think&gt;</span><span>)</span><span>[</span><span>^</span><span>&lt;]</span><span>*</span><span>)</span><span>*</span><span>)</span><span>&lt;</span><span>\/</span><span>think&gt;</span><span>\n</span><span>&lt;answer&gt;</span><span>([\s\S]</span><span>*?</span><span>)</span><span>&lt;</span><span>\/</span><span>answer&gt;</span><span>$</span><span>"</span></span>
<span data-line=""> </span>
<span data-line=""><span>        match </span><span>=</span><span> re.search(regex, completion, re.</span><span>DOTALL</span><span>) </span></span>
<span data-line=""><span>        # if the format is not correct, reward is 0</span></span>
<span data-line=""><span>        if</span><span> match </span><span>is</span><span> None</span><span> or</span><span> len</span><span>(match.groups()) </span><span>!=</span><span> 2</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>        else</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>1.0</span><span>)</span></span>
<span data-line=""><span>      except</span><span> Exception</span><span>:</span></span>
<span data-line=""><span>        rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>    return</span><span> rewards</span></span>
<span data-line=""> </span>
<span data-line=""><span>def</span><span> equation_reward_func</span><span>(completions, target, nums, </span><span>**</span><span>kwargs):</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    Evaluates completions based on:</span></span>
<span data-line=""><span>    2. Mathematical correctness of the answer</span></span>
<span data-line=""> </span>
<span data-line=""><span>    Args:</span></span>
<span data-line=""><span>        completions (list[str]): Generated outputs</span></span>
<span data-line=""><span>        target (list[str]): Expected answers</span></span>
<span data-line=""><span>        nums (list[str]): Available numbers</span></span>
<span data-line=""><span>    </span></span>
<span data-line=""><span>    Returns:</span></span>
<span data-line=""><span>        list[float]: Reward scores</span></span>
<span data-line=""><span>    """</span></span>
<span data-line=""><span>    rewards </span><span>=</span><span> []</span></span>
<span data-line=""><span>    for</span><span> completion, gt, numbers </span><span>in</span><span> zip</span><span>(completions, target, nums):</span></span>
<span data-line=""><span>      try</span><span>:</span></span>
<span data-line=""><span>        # add synthetic &lt;think&gt; as its already part of the prompt and prefilled for the assistant to more easily match the regex</span></span>
<span data-line=""><span>        completion </span><span>=</span><span> "&lt;think&gt;"</span><span> +</span><span> completion</span></span>
<span data-line=""><span>        # Check if the format is correct</span></span>
<span data-line=""><span>        match </span><span>=</span><span> re.search(</span><span>r</span><span>"</span><span>&lt;answer&gt;</span><span>(.</span><span>*?</span><span>)</span><span>&lt;</span><span>\/</span><span>answer&gt;</span><span>"</span><span>, completion)</span></span>
<span data-line=""><span>        if</span><span> match </span><span>is</span><span> None</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>            continue</span></span>
<span data-line=""><span>        # Extract the "answer" part from the completion</span></span>
<span data-line=""><span>        equation </span><span>=</span><span> match.group(</span><span>1</span><span>).strip()</span></span>
<span data-line=""><span>        # Extract all numbers from the equation</span></span>
<span data-line=""><span>        used_numbers </span><span>=</span><span> [</span><span>int</span><span>(n) </span><span>for</span><span> n </span><span>in</span><span> re.findall(</span><span>r</span><span>'</span><span>\d</span><span>+</span><span>'</span><span>, equation)]</span></span>
<span data-line=""><span>        </span></span>
<span data-line=""><span>        # Check if all numbers are used exactly once</span></span>
<span data-line=""><span>        if</span><span> sorted</span><span>(used_numbers) </span><span>!=</span><span> sorted</span><span>(numbers):</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>            continue</span></span>
<span data-line=""><span>        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace</span></span>
<span data-line=""><span>        allowed_pattern </span><span>=</span><span> r</span><span>'</span><span>^[\d+</span><span>\-</span><span>*/().\s]</span><span>+</span><span>$</span><span>'</span></span>
<span data-line=""><span>        if</span><span> not</span><span> re.match(allowed_pattern, equation):</span></span>
<span data-line=""><span>           rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>           continue</span></span>
<span data-line=""><span>        </span></span>
<span data-line=""><span>        # Evaluate the equation with restricted globals and locals</span></span>
<span data-line=""><span>        result </span><span>=</span><span> eval</span><span>(equation, {</span><span>"__builtins__"</span><span>: </span><span>None</span><span>}, {})</span></span>
<span data-line=""><span>        # Check if the equation is correct and matches the ground truth</span></span>
<span data-line=""><span>        if</span><span> abs</span><span>(</span><span>float</span><span>(result) </span><span>-</span><span> float</span><span>(gt)) </span><span>&lt;</span><span> 1e-5</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>1.0</span><span>)</span></span>
<span data-line=""><span>        else</span><span>:</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>)</span></span>
<span data-line=""><span>      except</span><span> Exception</span><span>:</span></span>
<span data-line=""><span>            # If evaluation fails, reward is 0</span></span>
<span data-line=""><span>            rewards.append(</span><span>0.0</span><span>) </span></span>
<span data-line=""><span>    return</span><span> rewards</span></span></code></pre></div></figure>
<p>Lets try our reward function with a sample.</p>
<p><em>Note: None of the example starts with <code>&lt;think&gt;</code> as we added it synthetically to the prompt.</em></p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>correct_sample_1 </span><span>=</span><span> """We need to find an equation using the numbers 19, 36, 55, and 7</span></span>
<span data-line=""><span>exactly once, with basic arithmetic operations, that equals 65. One possible</span></span>
<span data-line=""><span>combination is 55 + 36 - 19 + 7... &lt;/think&gt;</span></span>
<span data-line=""> </span>
<span data-line=""><span>&lt;answer&gt; 55 + 36 - 7 - 19 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""><span>correct_sample_2 </span><span>=</span><span> """ ... &lt;/think&gt;</span></span>
<span data-line=""> </span>
<span data-line=""><span>&lt;answer&gt; 55 + 36 - 7 - 19 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""><span>wrong_format </span><span>=</span><span> """User: Using the numbers [19, 36, 55, 7], create an equation that equals 65."""</span></span>
<span data-line=""> </span>
<span data-line=""><span>wrong_format_2 </span><span>=</span><span> """To find the equation that equals 79 using the numbers 95, 78, 6, 88, I'll start by adding 88 and 95:                      </span></span>
<span data-line=""><span>95 + 88 = 183                                                                                                              </span></span>
<span data-line=""><span>Now, let's subtract 104 from 183 to get 79:</span></span>
<span data-line=""><span>183 - 104 = 79</span></span>
<span data-line=""><span>&lt;think&gt; 183 - 104 = 79 &lt;/think&gt;&lt;think&gt; 183 - 104 = 79 &lt;/think&gt;&lt;answer&gt; 183 - 104 = 79 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""><span>wrong_result </span><span>=</span><span> """ ... &lt;/think&gt;</span></span>
<span data-line=""> </span>
<span data-line=""><span>&lt;answer&gt; 55 + 36 - 7 - 18 &lt;/answer&gt;"""</span></span>
<span data-line=""> </span>
<span data-line=""> </span>
<span data-line=""><span>test_rewards </span><span>=</span><span> format_reward_func(</span><span>completions</span><span>=</span><span>[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result], </span><span>target</span><span>=</span><span>[</span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>], </span><span>nums</span><span>=</span><span>[[</span><span>19</span><span>, </span><span>36</span><span>, </span><span>55</span><span>, </span><span>7</span><span>]] </span><span>*</span><span> 5</span><span>)</span></span>
<span data-line=""><span>assert</span><span> test_rewards </span><span>==</span><span> [</span><span>1.0</span><span>, </span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>, </span><span>1.0</span><span>], </span><span>"Reward function is not working"</span></span>
<span data-line=""><span>test_rewards </span><span>=</span><span> equation_reward_func(</span><span>completions</span><span>=</span><span>[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result], </span><span>target</span><span>=</span><span>[</span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>, </span><span>"65"</span><span>], </span><span>nums</span><span>=</span><span>[[</span><span>19</span><span>, </span><span>36</span><span>, </span><span>55</span><span>, </span><span>7</span><span>]] </span><span>*</span><span> 5</span><span>)</span></span>
<span data-line=""><span>assert</span><span> test_rewards </span><span>==</span><span> [</span><span>1.0</span><span>, </span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>], </span><span>"Reward function is not working"</span></span></code></pre></div></figure>
<p>This looks good, now lets define our remaining training parameters, create a trainer and start training.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span>from</span><span> trl </span><span>import</span><span> GRPOConfig, GRPOTrainer, get_peft_config, ModelConfig</span></span>
<span data-line=""> </span>
<span data-line=""><span># our model we are going to use as policy </span></span>
<span data-line=""><span>model_config </span><span>=</span><span> ModelConfig(</span></span>
<span data-line=""><span>    model_name_or_path</span><span>=</span><span>"Qwen/Qwen2.5-3B-Instruct"</span><span>,</span></span>
<span data-line=""><span>    torch_dtype</span><span>=</span><span>"bfloat16"</span><span>,</span></span>
<span data-line=""><span>    attn_implementation</span><span>=</span><span>"flash_attention_2"</span><span>,</span></span>
<span data-line=""><span>    use_peft</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>    load_in_4bit</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span># Hyperparameters</span></span>
<span data-line=""><span>training_args </span><span>=</span><span> GRPOConfig(</span></span>
<span data-line=""><span>    output_dir</span><span>=</span><span>"qwen-r1-aha-moment"</span><span>,</span></span>
<span data-line=""><span>    learning_rate</span><span>=</span><span>5e-7</span><span>,</span></span>
<span data-line=""><span>    lr_scheduler_type</span><span>=</span><span>"cosine"</span><span>,</span></span>
<span data-line=""><span>    logging_steps</span><span>=</span><span>10</span><span>,</span></span>
<span data-line=""><span>    max_steps</span><span>=</span><span>100</span><span>,</span></span>
<span data-line=""><span>    per_device_train_batch_size</span><span>=</span><span>1</span><span>,</span></span>
<span data-line=""><span>    gradient_accumulation_steps</span><span>=</span><span>1</span><span>,</span></span>
<span data-line=""><span>    gradient_checkpointing</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>    gradient_checkpointing_kwargs</span><span>=</span><span>{</span><span>"use_reentrant"</span><span>: </span><span>False</span><span>},</span></span>
<span data-line=""><span>    bf16</span><span>=</span><span>True</span><span>,</span></span>
<span data-line=""><span>    # GRPO specific parameters</span></span>
<span data-line=""><span>    max_prompt_length</span><span>=</span><span>256</span><span>,</span></span>
<span data-line=""><span>    max_completion_length</span><span>=</span><span>1024</span><span>, </span><span># max length of the generated output for our solution</span></span>
<span data-line=""><span>    num_generations</span><span>=</span><span>2</span><span>,</span></span>
<span data-line=""><span>    beta</span><span>=</span><span>0.001</span><span>,</span></span>
<span data-line=""><span>    </span></span>
<span data-line=""><span>)</span></span>
<span data-line=""><span>trainer </span><span>=</span><span> GRPOTrainer(</span></span>
<span data-line=""><span>    model</span><span>=</span><span>model_config.model_name_or_path,</span></span>
<span data-line=""><span>    reward_funcs</span><span>=</span><span>[format_reward_func, equation_reward_func],</span></span>
<span data-line=""><span>    args</span><span>=</span><span>training_args,</span></span>
<span data-line=""><span>    train_dataset</span><span>=</span><span>train_dataset,</span></span>
<span data-line=""><span>    eval_dataset</span><span>=</span><span>test_dataset,</span></span>
<span data-line=""><span>    peft_config</span><span>=</span><span>get_peft_config(model_config),</span></span>
<span data-line=""><span>)</span></span></code></pre></div></figure>
<p>We can start our training by calling the <code>train</code> method on the trainer instance.</p>
<p><em>Note: Reinforcement Training is very slow and compute intensive. Running a single step on 1x L4 with Q-LoRA, Batch size of 1 and only 2 generations per samples takes &gt;20 minutes.</em></p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="python" data-theme="github-dark github-light"><span data-line=""><span># Train and push the model to the Hub</span></span>
<span data-line=""><span>trainer.train()</span></span>
<span data-line=""><span># Save model</span></span>
<span data-line=""><span>trainer.save_model(training_args.output_dir)</span></span></code></pre></div></figure>
<h2 id="4-distributed-training-example-for-grpo-using-deepspeed-and-vllm">4. Distributed Training example for GRPO using Deepspeed and vLLM</h2>
<p>More than 20 minutes per step with only 2 generations per sample is not feasible. We need to scale up our training. Hugging Face TRL added support for distributed training with Deepspeed and using vLLM for faster generation. I preprared a <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/scripts/run_r1_grpo.py">run_r1_grpo.py</a> script and a <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml">receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml</a> config file to run the training.</p>
<p>This configuration is tested and validated on a Node with 4x H100 80GBs, where a single step takes around 45-60s, as we can leverage vLLM for generation and DeepSpeed for distributed training. Therefore we need to make sure we correctly set the <code>num_processes</code> to the number of GPUs you have - 1 as the last one will be used with vLLM for Generation. If you are using more GPUS you need to change the <code>vllm_device</code> in the config file to last index GPU, e.g. if you have 8 GPUs you need to set <code>vllm_device=7</code> and your <code>num_processes</code> to 7.</p>
<p>command to run the training:</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="bash" data-theme="github-dark github-light"><span data-line=""><span>accelerate</span><span> launch</span><span> --num_processes</span><span> 3</span><span> --config_file</span><span> configs/accelerate_configs/deepspeed_zero3.yaml</span><span> scripts/run_r1_grpo.py</span><span> --config</span><span> receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml</span></span></code></pre></div></figure>
<p>With the optimized distributed training a single step with 8 generations per sample on 4x H100 80GBs takes around 45-60s. The full training for 450 steps takes around 6 hours.</p>
<h2 id="5-results-and-training-observations">5. Results and Training Observations</h2>
<p>The script saves random completions to the <code>completion_samples</code> folder, which you can use to inspect the model's progress. It includes <code>completion_samples.txt</code> and <code>success_completion_samples.txt</code>. The <code>completion_samples.txt</code> includes all completions, while the <code>success_completion_samples.txt</code> which correctly solves the equation. Below you can find the interesating training obeserations on how the performance changes over time, as well as the Tensornoard logs and successfull reasoning samples.</p>
<p>The model with checkpoints for every 25th step can be found at <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/philschmid/qwen-2.5-3b-r1-countdown">philschmid/qwen-2.5-3b-r1-countdown</a>.</p>
<h3 id="hyperparameters">Hyperparameters</h3>
<p>I started the experiment using the hyperparameters from the <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2402.03300">DeepSeekMath</a> paper with a learning rate of 1e-6 and a beta (KL coefficient) of 0.04, which led to unstable training runs after around 150 steps. I ran some small ablations and decreased both the learning rate to 5e-7 and the beta to 0.001, based on a test from <a target="_blank" rel="noopener noreferrer" href="https://hijkzzz.notion.site/unraveling-rlhf-and-its-variants-engineering-insights#147d9a33ecc9806090f3d5c749d31f05">OpenRLHF</a>. I coulnd't test how increasing the <code>num_generations</code> from 8 to 64 would affect the training. 64 is the generation value, which was used in the DeepSeekMath paper. All other parameters can be found in the <a target="_blank" rel="noopener noreferrer" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/receipes/grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml">grpo-qwen-2.5-3b-deepseek-r1-countdown.yaml</a> config file.</p>
<h3 id="training-observations">Training Observations:</h3>
<ul>
<li>At ~50 steps the model has learned the correct format <code>&lt;think&gt;...&lt;/think&gt;\n&lt;answer&gt;...&lt;/answer&gt;</code>.</li>
<li>At 100 steps the success rate for solving the equation is around 25%. The model starts to "reason" with words see examples below.</li>
<li>At 200 steps the performance seems to converge much slower and we are at ~40% success rate. The model starts to learn a new "format" where it solves the equation similar to how you would do it programmatically, by trying different combinations and reviewing the results, see "Successfull Reasoning Samples between step 200 and 450".</li>
<li>At 450 steps we have 50% success rate for solving the equation. The performance still improves slowly and the model kept its new format form from step 200.</li>
</ul>
<p>I have 3 potential assumptions why the model shifts from "word reasoning" to "programmatic execution":</p>
<ol>
<li>Qwen 2.5 3B is not strong enough or to small, Deepseek mentions that you need a very strong base model.</li>
<li>The reward functions are not good enough defined and it reward hacks the model to solve the equation. We could try to force it to use words, e.g. having a number to word frequency condition. (We don't know much about the reward functions from Deepseek)</li>
<li>Only training on the Countdown Game tasks might force the model naturally to learn the most effective way to solve the equation as no other formats are required.</li>
<li>We didn't train the model long enough, in the R1 paper they showed visuals of training for over 8000 steps.</li>
</ol>
<h4 id="tensorboard-results">Tensorboard Results</h4>
<p><img src="https://www.philschmid.de/static/blog/mini-deepseek-r1/tensorboard-r1.png" alt="Qwen R1 Tensorboard results"></p>
<h4 id="successfull-reasoning-samples-up-to-step-200">Successfull Reasoning Samples up to step 200</h4>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to think about the numbers we have: 14, 70, and 80. To get 85, I think 80 might be a good starting point because it's right in between 85. If I subtract or add 80, it won't lead to 85 easily. Next, 70 seems to be a good intermediate number, especially to use in conjunction with 14. </span></span>
<span data-line=""><span>Now, I can think about different combinations using addition, subtraction and multiplication/division. If I take 80 - 70 = 10, which is not needed. So, I need to find a way to use 14. If I subtract 14 from 80, I get 66, which still isn't 85. If I subtract 70 from 80, I get 10 again, this isn't constructive yet. </span></span>
<span data-line=""><span>Multiplication could create numbers larger than the target 85. Let's consider division: If I divide 70 by 14, I get 5. Then if I add this result to 80, I get 85. This combination seems promising: 80 - (70 / 14) = 80 - 5 = 75, this still isn't quite right. Let me correct my approach: Let's use division and then addition. If I take 80 / (70 / 14) → 80 / 5 = 16, and then 80 - 16 = 64, still incorrect. Let me simplify: 80 / (70 / 14) → 80 / 5 = 16, and then 80 - 16 gives 64 again, let me correct: 80 - (70 / 14) → 80 - 5 = 75, but I need 85. Thus I will use the combinations in a slightly different order to insert numbers: I get 80 + (70 / 14) = 80 + 5 = 85&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 80 + (70 / 14) &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to consider how I can use the numbers 1, 21, and 90 to reach 68. I can try different combinations of operations. Let's try to use subtraction and addition. If I subtract 90 from 21, I get -69, which is too far from 68. Now, if I add 1 to 90, I get 91, which is also not right. Another way is to see what happens if I subtract 21 from 90, which gives me 69. This is closer but still not 68. Let me use multiplication instead of subtraction. 90 * 1 = 90. Now, if I try to reduce this slightly by subtracting 21, I am not getting close to 68.</span></span>
<span data-line=""><span>Now, let's try another multiplication. I'll think of 1 * (larger value) + (smaller value). Let's try 1 * 90 + 21. This evaluates to 90 + 21 = 111, which is too much. Instead, I will try: 90 / 1 + 21 - 7. But this gives a division by 7, which seems complex. Let's re-evaluate: I'll use 1 to divide 21: 21 / 1 = 21. Now, subtract 21 from 90, and add 1, we have 90 - 21 = 69, using one...</span></span>
<span data-line=""><span>Hey, wait on re-evaluating I will subtract 21 from 90, and include 1 to complete the solution: 90 - (21 + 1) which would be 68.&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 90 - (21 + 1) &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to consider the numbers we have: 59, 80, and 66. I need to use these numbers to get 45. Let's try to use subtraction first since it can quickly reduce large numbers.</span></span>
<span data-line=""><span>Let's see if we can get close by subtracting or adding these numbers. If I subtract 66 from 80, I get 14. Then I need to make this 14 equal 45 when combined with 59. That gives me 14 + 59 = 73, which is too high.</span></span>
<span data-line=""><span>Now let's try adding numbers. If I add 59 and 66, I get 125. Then I would need to subtract 80 from 125 to get 45, but 80 is too large to fit well with this.</span></span>
<span data-line=""><span>Let me try a different approach. What if I subtract 66 from 80 first and then add 59? That would be 14 + 59 = 73, which is still not 45.</span></span>
<span data-line=""><span>Hmm, I need to think of another combination. What if I start with 59 and then add 80 and subtract 66? That would be (59 + 80) - 66, let me calculate it. That equals 139 - 66, which is 73.</span></span>
<span data-line=""><span>That's still not 45, so let me try rearranging it slightly: maybe 80 - 66 + 59 would be closer to 45. Calculating again: 80 - 66 is 14, then adding 59 gives 73.</span></span>
<span data-line=""><span>This way doesn't work either. Let's flip this: maybe (59 + 66) - 80. Let me check: that's 125 - 80, which equals 45.&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt;(59 + 66) - 80&lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I need to find a combination of the numbers 61, 4, 94, and 21 that can be manipulated using basic arithmetic operations to equal 50. One way to approach this is to look for numbers that can be used to reach a target number close to 50 and then adjust with the remaining numbers.</span></span>
<span data-line=""><span>Let's try combining 94 and 21 first:</span></span>
<span data-line=""><span>94 + 21 = 115</span></span>
<span data-line=""><span>Now, we need to get from 115 to 50. We can try subtracting 65:</span></span>
<span data-line=""><span>115 - 65 = 50</span></span>
<span data-line=""><span>Now we need to find a way to get 65 using the remaining numbers 61 and 4. We can try:</span></span>
<span data-line=""><span>61 - 4 = 57</span></span>
<span data-line=""><span>Now we need to get from 57 to 65. Adding 8 would give us that:</span></span>
<span data-line=""><span>57 + 8 = 65</span></span>
<span data-line=""><span>So, we need to find a way to get 8 using 61 and 4. We can try:</span></span>
<span data-line=""><span>61 - 94 = -36</span></span>
<span data-line=""><span>This is negative, so let's try dividing:</span></span>
<span data-line=""><span>61 / 94 = 0.648987...</span></span>
<span data-line=""><span>This is not helping, so let's try multiplication and division in a different way:</span></span>
<span data-line=""><span>(61 - 4) * (94 / 21) = 57 * 4.476... = 254.4</span></span>
<span data-line=""><span>This is not working either. Let's try a different approach:</span></span>
<span data-line=""><span>(94 - 61) = 33</span></span>
<span data-line=""><span>Now we have:</span></span>
<span data-line=""><span>33 + 21 = 54</span></span>
<span data-line=""><span>We need to adjust from 54 to 50, so we can:</span></span>
<span data-line=""><span>54 - 4 = 50</span></span>
<span data-line=""><span>So, the equation becomes:</span></span>
<span data-line=""><span>(94 - 61) + (21 - 4) = 50</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt;(94 - 61) + (21 - 4)&lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; First, I'll consider the possibility of directly subtracting two numbers to get close to 31. If I subtract 57 from 63, I get 7. Now, if I subtract this 7 from 25, I get 25 - 7 = 18. Far from 31, so this doesn't work.</span></span>
<span data-line=""><span>Next, let's try adding and subtracting. Dividing 63 by 25 will give a decimal, so that's unlikely to work. Now, let's see if adding and subtracting in another order could work. For example, let's try 63 - 25, and then we see this gets us 38. Now, we need a way to get to 31 from here. Subtracting 7 from 38 would work, but we can't figure out how to create that 7 from the given numbers.</span></span>
<span data-line=""><span>Hmm, let me try to incorporate all numbers by adding and subtracting. If I try 63 + 25, I get 88. This is quite far from 31, but if 88 - 57, I get 31 exactly!</span></span>
<span data-line=""><span>This seems to be the equation: 63 + 25 - 57 equals 31.</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 63 + 25 - 57 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<h4 id="successfull-reasoning-samples-between-step-200-and-450">Successfull Reasoning Samples between step 200 and 450</h4>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; We need to use the numbers 39, 16, and 55 with basic arithmetic operations to get 78. Let's try different combinations:</span></span>
<span data-line=""><span>- 55 + 39 - 16 = 84 - 16 = 68 (too low)</span></span>
<span data-line=""><span>- 55 + 16 - 39 = 71 - 39 = 32 (too low)</span></span>
<span data-line=""><span>- 55 - 16 + 39 = 39 + 39 = 78 (this works)</span></span>
<span data-line=""><span>So, the equation is 55 - 16 + 39 = 78. &lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 55 - 16 + 39 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; We need to use the numbers 21, 5, and 40 with basic arithmetic operations to get 24. Let's try different combinations:</span></span>
<span data-line=""><span>- 21 - 5 - 40 = -15</span></span>
<span data-line=""><span>- 21 - 5 + 40 = 56</span></span>
<span data-line=""><span>- 21 + 5 - 40 = -14</span></span>
<span data-line=""><span>- 21 * 5 / 40 = 2.1 (not an integer, let's try another)</span></span>
<span data-line=""><span>- 40 * 5 / 21 = 9.52 (not 24)</span></span>
<span data-line=""><span>- 40 / 5 - 21 = 9 - 21 = -12</span></span>
<span data-line=""><span>- 5 * 40 / 21 = 100 / 21 ~= 4.76 (not 24)</span></span>
<span data-line=""><span>- 5 + 40 - 21 = 24 ! This works.</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 5 + 40 - 21 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="xml" data-theme="github-dark github-light"><span data-line=""><span>&lt;</span><span>think</span><span>&gt; We need to use the numbers 75, 99, 62, and 34 with basic arithmetic operations to get 72. Let's try different combinations:</span></span>
<span data-line=""><span>- 99 - 75 + 62 - 34 = 92 - 34 = 58 (too high)</span></span>
<span data-line=""><span>- 99 - 75 - 62 + 34 = 24 - 62 + 34 = -38 + 34 = -4 (too low)</span></span>
<span data-line=""><span>- 99 + 75 - 62 - 34 = 174 - 96 = 78 (too high)</span></span>
<span data-line=""><span>- 99 + 75 - 62 + 34 = 174 + 34 - 62 = 208 - 62 = 146 (too high)</span></span>
<span data-line=""><span>- 99 - 75 + 62 + 34 = 24 + 96 = 120 (too high)</span></span>
<span data-line=""><span>- 75 + 99 - 62 - 34 = 174 - 96 = 78 (too high)</span></span>
<span data-line=""><span>- 75 + 99 - 62 + 34 = 174 + 34 - 62 = 208 - 62 = 146 (too high)</span></span>
<span data-line=""><span>- 75 + 62 - 99 + 34 = 137 - 99 + 34 = 38 + 34 = 72</span></span>
<span data-line=""><span>So, 75 + 62 - 99 + 34 equals 72.</span></span>
<span data-line=""><span>&lt;/</span><span>think</span><span>&gt;</span></span>
<span data-line=""><span>&lt;</span><span>answer</span><span>&gt; 75 + 62 - 99 + 34 &lt;/</span><span>answer</span><span>&gt;</span></span></code></pre></div></figure>
<h2 id="conclusion">Conclusion</h2>
<p>The release of DeepSeek R1 and its research paper might be breakpoint for the open-science and open-source development. Just a week after DeepSeek release, we've been able to reproduce a simple version of R1 learned "reasoning" using GRPO and the Countdown Game. While our implementation focuses on a specific task rather than general reasoning and convergence into a very specific "reasoning" format, it shows that the method is working.</p>
<p>In our mini R1 experiment we used GRPO, with two rule-based reward but already required significant compute: 4 H100 GPUs running for 6 hours to complete just 450 training steps on a 3B parameter model. This gives us an idea of the compute needs that you will need to scale Reinforcement Learning. Deepseek ran a 671B model for over 8000 steps and they probably did many ablations.</p>
<p>Looking in to 2025, it's clear that we are on the cusp of even more significant progress. RL will become more accessible and user-friendly, more researchers and developers will explore its potential, but also require amount of more compute as before and compared to supervised fine-tuning.</p>
<p>I am excited for 2025. If you are have any question or ideas feel free to reach out to me.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[sixos: A nix OS without systemd [video] (141 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd</link>
            <guid>42884727</guid>
            <pubDate>Fri, 31 Jan 2025 04:35:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd">https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd</a>, See on <a href="https://news.ycombinator.com/item?id=42884727">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[TopoNets: High performing vision and language models with brain-like topography (156 pts)]]></title>
            <link>https://arxiv.org/abs/2501.16396</link>
            <guid>42884338</guid>
            <pubDate>Fri, 31 Jan 2025 02:58:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2501.16396">https://arxiv.org/abs/2501.16396</a>, See on <a href="https://news.ycombinator.com/item?id=42884338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2501.16396">View PDF</a>
    <a href="https://arxiv.org/html/2501.16396v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Neurons in the brain are organized such that nearby cells tend to share similar functions. AI models lack this organization, and past efforts to introduce topography have often led to trade-offs between topography and task performance. In this work, we present TopoLoss, a new loss function that promotes spatially organized topographic representations in AI models without significantly sacrificing task performance. TopoLoss is highly adaptable and can be seamlessly integrated into the training of leading model architectures. We validate our method on both vision (ResNet-18, ResNet-50, ViT) and language models (GPT-Neo-125M, NanoGPT), collectively TopoNets. TopoNets are the highest-performing supervised topographic models to date, exhibiting brain-like properties such as localized feature processing, lower dimensionality, and increased efficiency. TopoNets also predict responses in the brain and replicate the key topographic signatures observed in the brain's visual and language cortices. Together, this work establishes a robust and generalizable framework for integrating topography into leading model architectures, advancing the development of high-performing models that more closely emulate the computational strategies of the human brain.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Mayukh Deb [<a href="https://arxiv.org/show-email/3224565a/2501.16396" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 27 Jan 2025 01:09:59 UTC (38,378 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Jane Street accidentally built a better build system for OCaml (253 pts)]]></title>
            <link>https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/</link>
            <guid>42881724</guid>
            <pubDate>Thu, 30 Jan 2025 20:14:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/">https://blog.janestreet.com/how-we-accidentally-built-a-better-build-system-for-ocaml-index/</a>, See on <a href="https://news.ycombinator.com/item?id=42881724">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>A “build system” is one of the most important tools in a developer’s
toolbox. Roughly, it figures out how to create runnable programs from
a bunch of different source files by calling out to the compiler,
setting up and executing test suites, and so on. Because you interact
with it daily, above all it has to be <a href="https://xkcd.com/303/">fast</a> –
but it also has to be flexible.</p>

<p>Around 2012 we were growing dissatisfied with OMake, then one of
OCaml’s standard build systems, and decided to build our own; we
called this new system Jenga. It worked quite well for us, and we
thought the broader community might find it useful. So we decided to
release Jenga. We hoped that when other people tried it, they’d like
it, and maybe even contribute back to it. Releasing it would also make
it easier for us to open source our code.</p>

<p>Ha! What actually happened is that nobody really wanted to use Jenga.
For one thing it didn’t work on Windows. But also, to adopt Jenga was
in effect to adopt the whole “Jane Street way” of building OCaml. The
adoption of Jenga by those we hoped to embrace it was weak enough that
we actually decided to <em>un</em>-open source it. And so we were back to the
same place as before.</p>

<p>By 2016 we had had enough of this, and decided to make a simple
cross-platform tool, called Jbuilder, that would allow external users
to build our code without having to adopt Jenga in full, and would
release us from the obligation of rewriting our builds in
<a href="https://github.com/ocaml/ocamlbuild">OCamlbuild</a>, then an emerging
standard for building OCaml projects.</p>

<p>Jbuilder understood the <code>jbuild</code> files that Jenga used for build
configuration and simply executed all required compilation commands in
a topological order. It wasn’t a build system in the usual sense: it
would simply re-execute all commands every time (instead of only
re-executing commands whose inputs have changed).</p>

<h3 id="jbuilder-gets-popular-and-becomes-dune"><strong>Jbuilder gets popular and becomes “Dune”</strong></h3>

<p>Then something strange happened. People <em>loved</em> Jbuilder. They started
using it to build not just our packages but their own, too. At first
we didn’t really understand this. Jbuilder wasn’t a real build system,
after all. It was just meant to be a little compatibility shim.</p>

<p>What we realized, eventually, was that the compelling feature was
speed. It turned out that Jbuilder was really a lot faster than the
other options, compiling our projects something like 5x faster than
OCamlbuild. That, plus the system being portable and easy to hack on,
were the things that mattered for early adopters and contributors.</p>

<p>So, in collaboration with <a href="https://www.linkedin.com/company/ocaml-labs-consultancy-ltd/?originalSubdomain=uk">OCaml
Labs</a>
(and today, <a href="https://tarides.com/">Tarides</a>), we started working on
making Jbuilder into more of a real build system, adding more of the
features that would be required for it to be a useful tool for the
broader open-source world.</p>

<p>And then, we ran into another problem. The name.</p>

<p>It turned out there was already a Borland Java IDE called
“<a href="https://en.wikipedia.org/wiki/JBuilder">JBuilder</a>.”  The system was
long defunct, and we even went to the trouble of finding the current
owners of the copyright and asking them if they’d mind us using the
name.  But, no dice.</p>

<p>So we decided to pick a new name.  We did <a href="https://discuss.ocaml.org/t/new-name-for-jbuilder">a bit of community
outreach</a>, and “Dune”
emerged as the winning name.</p>

<p>In the meantime, Dune’s popularity had exploded. People really began
using it in earnest, and we found ourselves in a somewhat ridiculous,
self-inflicted situation: we now had two full build systems to
maintain and support.</p>

<h3 id="jenga-vs-dune"><strong>Jenga vs. Dune</strong></h3>

<p>It became clear to us that Dune was the better system—a rethought
design, faster for most people’s builds, with wider adoption, and a
better API and user experience—which brought up the question “when
will we migrate Jane Street onto Dune?” Considering the provenance
of the tool this felt like an absurd question, but oh well, that’s
where we’d ended up.</p>

<p>The answer was inevitably “next year,” since the build systems team
had plenty to work on simply keeping up with our growing codebase. (In
2016, when Dune started, we had 4M lines of OCaml code; today we have
65M, plus 5M lines of Python.) A migration to Dune was daunting enough
that we never quite fully embarked on the mission. But it wasn’t <em>so</em>
daunting to keep us from estimating, aspirationally, that it might
well happen in the next six to twelve months.</p>

<p>It was only last year that we decided to finally rip the band-aid off.
We’d grown the build systems team to five full-time engineers, so we
felt that we finally had the strength to tackle this monster we’d been
afraid of for so long.</p>

<h3 id="dune-subsumes-jenga-within-jane-street"><strong>Dune subsumes Jenga within Jane Street</strong></h3>

<p>One large chunk of work we didn’t really appreciate in the beginning was
just making Dune scale to our huge codebase. Dune was quite fast
externally—but that’s in part because most users built relatively tiny
things compared to Jane Street’s 70M-line repository.</p>

<p>And Jenga hadn’t stood still, either. Over a decade, we had improved
the implementation to deal with the growth of our codebase. That
produced a system that was pretty well-optimized for scale, and
carefully tailored to our monorepo’s requirements.  Now, much of that
good optimization work had to be translated to Dune.</p>

<p>There were more mundane problems. The build system is called by a
variety of different workflows, notably, from three different
editors—Vim, Emacs, and VSCode.  Each one sadly had its own custom
integrations with Jenga that had to be migrated to use Dune one by
one.</p>

<p>But after more than a year of focused work we’re finally done: our
codebase is now built by Dune. At the time of the switch, Dune’s
performance was across the board as good or better than Jenga’s, and
much better in some cases. In particular, builds where most of the
build work is already in the cache (which is a surprisingly common
case!) have gotten 2-3x faster.</p>

<p>A lot of what we’ve done to improve Dune’s performance will get open
sourced, and some already has. We’re keen not to end up with two build
systems again—a Jane Street fork of Dune and the external Dune—so
we’re putting a lot of thought and energy into upstreaming our changes
where we can.</p>

<p>Dune is a very good foundation for doing new things. Some of that is
because Dune’s codebase is simpler and easier to work with; some
because we can just focus on one system. But, features like
distributed builds, shallow builds (also known as <a href="https://blog.bazel.build/2023/10/06/bwob-in-bazel-7.html#what-is-build-without-the-bytes">“builds without the
bytes”</a>),
and cached loading of the build graph itself are all closer in reach
than ever.</p>

<p>The exciting thing going forward is that we have a single system and
our velocity in improving it is going way up. The team has also grown
to 12 full-time engineers, in New York, London and Singapore, which
means we’re now working on Dune 24 hours a day.</p>

<p>It’s been a long and sometimes meandering path, and certainly hasn’t
unfolded the way we might have planned.  But we think that the end
result is good for OCaml’s build-system story, both within and beyond
Jane Street’s walls.</p>

        </div><p>Andrey joined Jane Street London in 2019, and in 2025 moved to the Singapore office to
grow the Tools and Compilers team in Asia. Before Jane Street, Andrey was an academic
at Newcastle University, UK, where he studied functional programming and asynchronous
circuits.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stats – macOS system monitor in your menu bar (315 pts)]]></title>
            <link>https://github.com/exelban/stats</link>
            <guid>42881342</guid>
            <pubDate>Thu, 30 Jan 2025 19:37:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/exelban/stats">https://github.com/exelban/stats</a>, See on <a href="https://news.ycombinator.com/item?id=42881342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Stats</h2><a id="user-content-stats" aria-label="Permalink: Stats" href="#stats"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png"><img src="https://github.com/exelban/stats/raw/master/Stats/Supporting%20Files/Assets.xcassets/AppIcon.appiconset/icon_256x256.png" width="120"></a></p>
<p dir="auto"><a href="https://github.com/exelban/stats/releases"><img src="https://camo.githubusercontent.com/c0b7c8837b8f05167af0febd37cc3b775b8916072c3d1ce432c10fbbd8dc626f/68747470733a2f2f7365726869792e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f4769746875625f7265706f2f73746174732f6d656e757325334676322e332e322e706e673f7631" alt="Stats" data-canonical-src="https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/menus%3Fv2.3.2.png?v1"></a>
<a href="https://github.com/exelban/stats/releases"><img src="https://camo.githubusercontent.com/d8438fa217f3a8b4411eff42d5141cdc18e6087feb797a5477f3fc179597b342/68747470733a2f2f7365726869792e73332e65752d63656e7472616c2d312e616d617a6f6e6177732e636f6d2f4769746875625f7265706f2f73746174732f706f7075707325334676322e332e322e706e673f7633" alt="Stats" data-canonical-src="https://serhiy.s3.eu-central-1.amazonaws.com/Github_repo/stats/popups%3Fv2.3.2.png?v3"></a></p>
<p dir="auto">macOS system monitor in your menu bar</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Manual</h3><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
<p dir="auto">You can download the latest version <a href="https://github.com/exelban/stats/releases/latest/download/Stats.dmg">here</a>.
This will download a file called <code>Stats.dmg</code>. Open it and move the app to the application folder.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homebrew</h3><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>
<p dir="auto">To install it using Homebrew, open the Terminal app and type:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto">Stats is supported on the released macOS version starting from macOS 10.15 (Catalina).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Stats is an application that allows you to monitor your macOS system.</p>
<ul dir="auto">
<li>CPU utilization</li>
<li>GPU utilization</li>
<li>Memory usage</li>
<li>Disk utilization</li>
<li>Network usage</li>
<li>Battery level</li>
<li>Fan's control (not maintained)</li>
<li>Sensors information (Temperature/Voltage/Power)</li>
<li>Bluetooth devices</li>
<li>Multiple time zone clock</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQs</h2><a id="user-content-faqs" aria-label="Permalink: FAQs" href="#faqs"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How do you change the order of the menu bar icons?</h3><a id="user-content-how-do-you-change-the-order-of-the-menu-bar-icons" aria-label="Permalink: How do you change the order of the menu bar icons?" href="#how-do-you-change-the-order-of-the-menu-bar-icons"></a></p>
<p dir="auto">macOS decides the order of the menu bar items not <code>Stats</code> - it may change after the first reboot after installing Stats.</p>
<p dir="auto">To change the order of any menu bar icon - macOS Mojave (version 10.14) and up.</p>
<ol dir="auto">
<li>Hold down ⌘ (command key).</li>
<li>Drag the icon to the desired position on the menu bar.</li>
<li>Release ⌘ (command key)</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">What if you don't see sensors (M1 macs)?</h3><a id="user-content-what-if-you-dont-see-sensors-m1-macs" aria-label="Permalink: What if you don't see sensors (M1 macs)?" href="#what-if-you-dont-see-sensors-m1-macs"></a></p>
<p dir="auto">Sensors data on the first generation of M1 mac could be obtained only from HID services. It's disabled by default because it consumes a lot of CPU and energy. You can enable it in the Sensors module settings with the option <code>HID sensors</code>.</p>
<p dir="auto">It's only valid for M1 Apple Silicon macs. If you don't see sensors on another mac, please open an issue for that.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to show the CPU frequency?</h3><a id="user-content-how-to-show-the-cpu-frequency" aria-label="Permalink: How to show the CPU frequency?" href="#how-to-show-the-cpu-frequency"></a></p>
<p dir="auto">The CPU frequency is available only on Intel-based macs. You need to have installed <a href="https://www.intel.com/content/www/us/en/developer/articles/tool/power-gadget.html" rel="nofollow">Intel Power Gadget</a> (IPG) for that. It allows receiving the CPU frequency from the IPG driver. There is no way to obtain a CPU frequency on Apple silicon macs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to reduce energy impact or CPU usage of Stats?</h3><a id="user-content-how-to-reduce-energy-impact-or-cpu-usage-of-stats" aria-label="Permalink: How to reduce energy impact or CPU usage of Stats?" href="#how-to-reduce-energy-impact-or-cpu-usage-of-stats"></a></p>
<p dir="auto">Stats tries to be efficient as it's possible. But reading some data periodically is not a cheap task. Each module has its own "price". So, if you want to reduce energy impact from the Stats you need to disable some Stats modules. The most inefficient modules are Sensors and Bluetooth. Disabling these modules could reduce CPU usage and power efficiency by up to 50% in some cases.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why my issue was closed without any response?</h3><a id="user-content-why-my-issue-was-closed-without-any-response" aria-label="Permalink: Why my issue was closed without any response?" href="#why-my-issue-was-closed-without-any-response"></a></p>
<p dir="auto">Most probably because it's a duplicated issue and there is an answer to the question, report, or proposition. Please use a search by closed issues to get an answer.
So, if your issue was closed without any response, most probably it already has a response.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fan control</h3><a id="user-content-fan-control" aria-label="Permalink: Fan control" href="#fan-control"></a></p>
<p dir="auto">Fan control is in legacy mode. It does not receive any updates or fixes. It's not dropped from the app just because in the old Macs it works pretty acceptable. I'm open to accepting fixed or improvements (via PR) for this feature in case someone would like to help with that. But have no option and time to provide support for this feature.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported languages</h2><a id="user-content-supported-languages" aria-label="Permalink: Supported languages" href="#supported-languages"></a></p>
<ul dir="auto">
<li>English</li>
<li>Polski</li>
<li>Українська</li>
<li>Русский</li>
<li>中文 (简体) (thanks to <a href="https://github.com/chenguokai">chenguokai</a>, <a href="https://github.com/Tai-Zhou">Tai-Zhou</a>, and <a href="https://github.com/Jerry23011">Jerry</a>)</li>
<li>Türkçe (thanks to <a href="https://github.com/yusufozgul">yusufozgul</a>)</li>
<li>한국어 (thanks to <a href="https://github.com/escapeanaemia">escapeanaemia</a> and <a href="https://github.com/iamhslee">iamhslee</a>)</li>
<li>German (thanks to <a href="https://github.com/natterstefan">natterstefan</a> and <a href="https://github.com/aneitel">aneitel</a>)</li>
<li>中文 (繁體) (thanks to <a href="https://github.com/iamch15542">iamch15542</a> and <a href="https://github.com/jrthsr700tmax">jrthsr700tmax</a>)</li>
<li>Spanish (thanks to <a href="https://github.com/jcconca">jcconca</a>)</li>
<li>Vietnamese (thanks to <a href="https://github.com/xuandung38">HXD.VN</a>)</li>
<li>French (thanks to <a href="https://github.com/RomainLt">RomainLt</a>)</li>
<li>Italian (thanks to <a href="https://github.com/gmcinalli">gmcinalli</a>)</li>
<li>Portuguese (Brazil) (thanks to <a href="https://github.com/marcelochaves95">marcelochaves95</a> and <a href="https://github.com/pedroserigatto">pedroserigatto</a>)</li>
<li>Norwegian Bokmål (thanks to <a href="https://github.com/rubjo">rubjo</a>)</li>
<li>日本語 (thanks to <a href="https://github.com/treastrain">treastrain</a>)</li>
<li>Portuguese (Portugal) (thanks to <a href="https://github.com/AdamModus">AdamModus</a>)</li>
<li>Czech (thanks to <a href="https://github.com/mpl75">mpl75</a>)</li>
<li>Magyar (thanks to <a href="https://github.com/moriczr">moriczr</a>)</li>
<li>Bulgarian (thanks to <a href="https://github.com/zbrox">zbrox</a>)</li>
<li>Romanian (thanks to <a href="https://github.com/razluta">razluta</a>)</li>
<li>Dutch (thanks to <a href="https://github.com/ngohungphuc">ngohungphuc</a>)</li>
<li>Hrvatski (thanks to <a href="https://github.com/milotype">milotype</a>)</li>
<li>Danish (thanks to <a href="https://github.com/casperes1996">casperes1996</a> and <a href="https://github.com/aleksanderbl29">aleksanderbl29</a>)</li>
<li>Catalan (thanks to <a href="https://github.com/davidalonso">davidalonso</a>)</li>
<li>Indonesian (thanks to <a href="https://github.com/yooody">yooody</a>)</li>
<li>Hebrew (thanks to <a href="https://github.com/BadSugar">BadSugar</a>)</li>
<li>Slovenian (thanks to <a href="https://github.com/zigapovhe">zigapovhe</a>)</li>
<li>Greek (thanks to <a href="https://github.com/sudoxcess">sudoxcess</a> and <a href="https://github.com/vaionicle">vaionicle</a>)</li>
<li>Persian (thanks to <a href="https://github.com/ShawnAlisson">ShawnAlisson</a>)</li>
<li>Slovenský (thanks to <a href="https://github.com/martinbernat">martinbernat</a>)</li>
<li>Thai (thanks to <a href="https://github.com/apiphoomchu">apiphoomchu</a>)</li>
<li>Estonian (thanks to <a href="https://github.com/postylem">postylem</a>)</li>
<li>Hindi (thanks to <a href="https://github.com/patiljignesh">patiljignesh</a>)</li>
<li>Finnish (thanks to <a href="https://github.com/eightscrow">eightscrow</a>)</li>
</ul>
<p dir="auto">You can help by adding a new language or improving the existing translation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/exelban/stats/blob/master/LICENSE">MIT License</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California Law Enforcement Misused State Databases More Than 7k Times in 2023 (462 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023</link>
            <guid>42880807</guid>
            <pubDate>Thu, 30 Jan 2025 18:48:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023">https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023</a>, See on <a href="https://news.ycombinator.com/item?id=42880807">Hacker News</a></p>
Couldn't get https://www.eff.org/deeplinks/2025/01/california-police-misused-state-databases-more-7000-times-2023: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[1996 "Authentic" Beta Pokemon Cards Exposed as 2024 Prints via Printer Dots (531 pts)]]></title>
            <link>https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421</link>
            <guid>42880704</guid>
            <pubDate>Thu, 30 Jan 2025 18:38:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421">https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421</a>, See on <a href="https://news.ycombinator.com/item?id=42880704">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Many of the Pokemon playtest cards were likely printed in 2024">
      
      <meta itemprop="datePublished" content="2025-01-27T01:19:25Z">
        <meta itemprop="articleSection" content="Articles">
      <meta itemprop="keywords" content="prototype">
      


          <div id="post_1">
            <div>
              

                

              <p><span>
                  <time datetime="2025-01-27T01:19:25Z">
                    January 27, 2025,  1:19am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-30T20:21:34Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              
<h2><a name="p-695383-about-the-tracking-dots-1" href="#p-695383-about-the-tracking-dots-1"></a>About the tracking dots</h2>
<p>Most home and office printers add metadata to printed sheets in the form of very tiny yellow dots (sometimes called a machine identification code) that can’t be seen with the naked eye. The layout of the dots are different between printer brands and some don’t leave any at all. Information like serial number and sometime the print time is encoded in these dots. They can act as a “signature” for the printer that law enforcement uses as document forensic evidence (like in cases of forged currency).</p>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd.png" data-download-href="https://efour.b-cdn.net/uploads/default/9dc46977f44696c14a8056aee3cb3b70769819dd" title="Example of yellow tracking dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_469x485.png" alt="Example of yellow tracking dots" data-base62-sha1="mvFLXIMZajZuTKxFqhV5zci9v3f" width="469" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_469x485.png, https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_703x727.png 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/9/d/9dc46977f44696c14a8056aee3cb3b70769819dd_2_938x970.png 2x"></a></div>
<p>To view the dots you need to a magnifying glass or high resolution image and you need to adjust the colour channels to emphasize the yellow. More info: <a href="https://www.elitefourum.com/t/how-to-find-yellow-dots-in-prototypes-diy-guide/52544">How to Find Yellow Dots in Prototypes - DIY Guide</a></p>
<p>Important note:</p>
<blockquote>
<p>The dots are printed on by the kind of printers you and I would buy. Things like magazines, posters, <strong>and real Pokemon cards will not have dots</strong>. They are printed by large industrial offset printers.</p>
</blockquote>
<h2><a name="p-695383-how-to-read-the-dots-2" href="#p-695383-how-to-read-the-dots-2"></a>How to read the dots</h2>
<p>Different brands use different dot encoding patterns, and not all of these can be decoded. The companies don’t reveal this information so any known pattern has been cracked by someone from the general public.</p>
<p>The most well known of these is was broken in 2005 and often referred to as the <a href="https://w2.eff.org/Privacy/printers/docucolor/">“Xerox DocuColor” code</a> - named for the printer models used to discover it. Some brands other than Xerox also use this same pattern.</p>
<p>In this case, a 15x8 grid repeats like a checkerboard across the entire printed sheet. Each repeated grid has the same dots. The columns represent binary numbers For example, the eighth column encodes the year in binary. “2024” would appear as “011000” which is 24 in binary.</p>
<div>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/d01b574face250a2964b871f86659a2c739dbd79" title="Eevee example"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79_2_573x484.jpeg" alt="Eevee example" data-base62-sha1="tGZTi5G2uBiDrWYLjlAs9ZyX329" width="573" height="484" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79_2_573x484.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79_2_859x726.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/original/3X/d/0/d01b574face250a2964b871f86659a2c739dbd79.jpeg 2x" data-dominant-color="8C8C8C"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/5/a57b3e4784b33462f8a02f3d0007399ea0b487bb.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a57b3e4784b33462f8a02f3d0007399ea0b487bb" title="Xerox DocuColor code"><img src="https://efour.b-cdn.net/uploads/default/original/3X/a/5/a57b3e4784b33462f8a02f3d0007399ea0b487bb.jpeg" alt="Xerox DocuColor code" data-base62-sha1="nBUPt1ufUzc2WdeVSU8YzNjXChd" width="512" height="384"></a></div>
</div>
<p>If you have a “Xerox DocuColor” style code, you can use <a href="https://www.elitefourum.com/u/mika">@mika</a>’s decoder implementation here to decode it: <a href="https://www.elitefourum.com/t/yellow-dot-decoder-fake-prototype-playtest-cards/52472">Yellow Dot Decoder - Fake Prototype Playtest Cards</a></p>
<h2><a name="p-695383-tracking-dots-on-the-prototype-pokemon-cards-3" href="#p-695383-tracking-dots-on-the-prototype-pokemon-cards-3"></a>Tracking dots on the “prototype” Pokemon cards</h2>
<p>A slew of cards that were originally believed to be early prototype and cards used for playtesting have been appearing in public auction starting in 2024. Most are believed to trace back to Takumi Akabane - someone who was involved in the early development of the TCG.</p>
<p>Because these cards are printed from a home/office printer, many of them have tracking dots. And many have a dot patter that suggest a print date in 2024.</p>
<div>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f" title="Beta playtest"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_690x442.jpeg" alt="Beta playtest" data-base62-sha1="5nrCp9FFDk9WkwaR8XFXfliakEf" width="690" height="442" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_690x442.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_1035x663.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/2/5/25b1577fcbf93464ec1dd16f5ac86d1ecce5177f_2_1380x884.jpeg 2x" data-dominant-color="B9BAB2"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/de5d65a6e3d94154fbf5260988dc25b96e1f7e04" title="Beta playtest dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_690x481.jpeg" alt="Beta playtest dots" data-base62-sha1="vJ86fiYoHH1H0EXweu4kSqZa2WM" width="690" height="481" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_690x481.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_1035x721.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/e/de5d65a6e3d94154fbf5260988dc25b96e1f7e04_2_1380x962.jpeg 2x" data-dominant-color="7A6584"></a></div>
</div>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/fdd0d5e157c769690bac28dd8405c9721e2bb0c3" title="Dot pattern"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_690x372.jpeg" alt="Dot pattern" data-base62-sha1="Adme8fO7Dy03Egh5qOc8JZAy6fV" width="690" height="372" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_690x372.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_1035x558.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/f/d/fdd0d5e157c769690bac28dd8405c9721e2bb0c3_2_1380x744.jpeg 2x" data-dominant-color="94788E"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f.png" data-download-href="https://efour.b-cdn.net/uploads/default/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f" title="Dot pattern decoded"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_535x485.png" alt="Dot pattern decoded" data-base62-sha1="6mBPlfx8Nvv55TW5IaL7PwOQxxJ" width="535" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_535x485.png, https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_802x727.png 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/2/c/2c9b57a300664e6bc7a1eb83c456aac6bcfb2d6f_2_1070x970.png 2x" data-dominant-color="0E0E0E"></a></div>
<p>Note the decoding result. We see this serial number reoccur across many cards.<br>
<img src="https://efour.b-cdn.net/uploads/default/optimized/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761_2_690x46.png" alt="image" data-base62-sha1="fYe7oXZEdkg8gPmcEM0rwhiUqSB" width="690" height="46" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761_2_690x46.png, https://efour.b-cdn.net/uploads/default/optimized/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761_2_1035x69.png 1.5x, https://efour.b-cdn.net/uploads/default/original/3X/6/f/6fef7f423366310e609fdb218a7caf204566a761.png 2x" data-dominant-color="1D1D1D"></p>
<p>Checking the dots like the above example can be done using public images if they are sufficiently high resolution. Such as <a href="https://sales-history.fanaticscollect.com/items/PREMIER13649">this</a> signed one where the autograph was witnessed by CGC:</p>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f" title="1996 Pokemon Japanese Beta Playtest Mounted On Card Eevee AUTO CGC 10 GEM MINT"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_287x485.jpeg" alt="1996 Pokemon Japanese Beta Playtest Mounted On Card Eevee AUTO CGC 10 GEM MINT" data-base62-sha1="bcYu62gYh0s3KxacexhI8IaLPIj" width="287" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_287x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_430x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/4/e/4e8f678dfce2ea8d99f6fded64d4fa4d2557222f_2_574x970.jpeg 2x" data-dominant-color="948B8F"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a1b58f2c10a74dbcf8c49d18780d33f65677a66e" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_627x485.jpeg" alt="image" data-base62-sha1="n4xRqhvPAt1Qe20rYdLSTCXnFMO" width="627" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_627x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_940x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/a/1/a1b58f2c10a74dbcf8c49d18780d33f65677a66e_2_1254x970.jpeg 2x" data-dominant-color="ACA9A9"></a></div>
<p>The dots reveal the 2024 year and the same printer serial number.</p>
<h2><a name="p-695383-variant-breakdown-4" href="#p-695383-variant-breakdown-4"></a>Variant breakdown</h2>
<p>The development of the Pokemon TCG was an iterative process, and many prototype and playtest variants have surfaced. Based on evidence inherent in the cards, this is what I can put together to the best of my ability</p>
<blockquote>
<p>Note: only Alpha playtest and Beta presentation have any documented evidence of their existence that predates 2024</p>
</blockquote>
<h2><a name="p-695383-alpha-prototypes-5" href="#p-695383-alpha-prototypes-5"></a>Alpha prototypes</h2>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a4512f1764633bde48c845a270f01c69f0e3e7a9" title="Alpha prototype (HQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_148x242.jpeg" alt="Alpha prototype (HQ)" data-base62-sha1="nrCeWgTHLWgdDdFG7VRaJxmO42J" width="148" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_148x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_222x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/a/4/a4512f1764633bde48c845a270f01c69f0e3e7a9_2_296x484.jpeg 2x" data-dominant-color="ABAAAA"></a></div> <div><a href="https://efour.b-cdn.net/uploads/default/original/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad" title="Alpha prototypes (LQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_144x242.jpeg" alt="Alpha prototypes (LQ)" data-base62-sha1="2Pizsn0exyM8urlenOCeV7FIyPX" width="144" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_144x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_216x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/1/3/13d0de7c94f89f0eca1915f8eb5a56e4d6c8e8ad_2_288x484.jpeg 2x" data-dominant-color="A7A7AA"></a></div>
<ul>
<li>there are no yellow tracking dots since they were printed in b&amp;w</li>
<li>2 variants, we can call them HQ and LQ: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/8">Many of the Pokemon playtest cards were likely printed in 2024 - #8 by pfm</a></li>
<li>easily distinguished by the background</li>
<li>there is one set of HQ, all other copies appear to be LQ</li>
<li>LQ appear to be copies of HQ, as they pick up the same printing artifacts seen on the HQ version.</li>
</ul>
<p>HQ: inconclusive.<br>
LQ: likely a copy of HQ, when the copy was made is inconclusive.</p>
<h2><a name="p-695383-alpha-prototypes-6" href="#p-695383-alpha-prototypes-6"></a>Alpha prototypes</h2>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/680a9e1ae5c0b31ed6bcd069cc417a75523123fb" title="Alpha prototype with 1996 dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_145x242.jpeg" alt="Alpha prototype with 1996 dots" data-base62-sha1="eQop6USu0XzLds97q8UbPQ5PMIr" width="145" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_145x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_217x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/6/8/680a9e1ae5c0b31ed6bcd069cc417a75523123fb_2_290x484.jpeg 2x" data-dominant-color="8B8E7F"></a></div> <div><a href="https://efour.b-cdn.net/uploads/default/original/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/a67bca55b4ab4def189c6f31c4d90edb2482465d" title="Alpha prototype with Konica Minolta-style dots"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_148x242.jpeg" alt="Alpha prototype with Konica Minolta-style dots" data-base62-sha1="nKMtK7omUOX1qNSqi57rYW62RRz" width="148" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_148x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_222x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/a/6/a67bca55b4ab4def189c6f31c4d90edb2482465d_2_296x484.jpeg 2x" data-dominant-color="A4A7A3"></a></div>
<ul>
<li>Most carry a unique dot pattern (different from beta) <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/18">Many of the Pokemon playtest cards were likely printed in 2024 - #18 by pfm</a></li>
<li>Likely from a Konica Minolta (Japanese brand) or Epson printer <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/421">Many of the Pokemon playtest cards were likely printed in 2024 - #421 by pfm</a></li>
<li>Some copies have BOTH alpha dots and “xerox” dots that can be dated. The hypothesis is that some alpha cards were scanned/copied (picking up alpha dots) and reprinted in 2024: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/143">Many of the Pokemon playtest cards were likely printed in 2024 - #143 by pfm</a></li>
<li>the alpha with inflated pop reports are more likely to have the double pattern (many trainers): <a href="https://www.cgccards.com/population-report/tcg/pok%C3%A9mon/2/test-prints-oddities-other/692/alpha-playtest-thick-lines/13952?populationID=1288703">https://www.cgccards.com/population-report/tcg/pokémon/2/test-prints-oddities-other/692/alpha-playtest-thick-lines/13952?populationID=1288703</a></li>
<li>a small handful have noticeably higher quality backs such as the three starters and this gyarados: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/59">Many of the Pokemon playtest cards were likely printed in 2024 - #59 by pfm</a></li>
</ul>
<p>High quality back:  dated to 1996 for the three starters<br>
Alpha pattern only: inconclusive.<br>
Double dot pattern: all observed copies so far have 2024 dots</p>
<h2><a name="p-695383-beta-playtest-7" href="#p-695383-beta-playtest-7"></a>Beta playtest</h2>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/dfa320261105937b9a5517ad96ed1567b5982003" title="Beta playtest (HQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_144x242.jpeg" alt="Beta playtest (HQ)" data-base62-sha1="vUnYbXZqNu0PKhDMj4dPJrOyOUX" width="144" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_144x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_216x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa320261105937b9a5517ad96ed1567b5982003_2_288x484.jpeg 2x" data-dominant-color="8B9098"></a></div> <div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/d90c9616be1c6a6faf70715f6038128eae99431a" title="Beta playtest (LQ)"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_148x242.jpeg" alt="Beta playtest (LQ)" data-base62-sha1="uY6zMhLB07I2TWjLaHOa4472LLs" width="148" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_148x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_222x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/9/d90c9616be1c6a6faf70715f6038128eae99431a_2_296x484.jpeg 2x" data-dominant-color="9EA4B2"></a></div>
<ul>
<li>two variants, HQ and LQ: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/299">Many of the Pokemon playtest cards were likely printed in 2024 - #299 by pfm</a></li>
<li>HQ has yet to be observed with any dots</li>
<li>LQ has always been observed with 2024 dots</li>
<li>there only only appears to be 1 HQ beta per Pokemon, implying the vast majority of betas have 2024 dots</li>
<li>HQ betas have subtle traces of the alpha pattern on the back, suggesting that the HQ beta back was scanned/copied from a card that has the alpha print pattern - this implies the HQ betas were printed after the alphas and the authenticity is contingent on the authenticity of the alphas: <a href="https://www.elitefourum.com/t/many-of-the-pokemon-playtest-cards-were-likely-printed-in-2024/52421/745">Many of the Pokemon playtest cards were likely printed in 2024 - #745 by pfm</a></li>
<li>it is unlikely that the LQ are simply scans/copies of HQ given that not a single print artifact or dirt spec has yet been observed to be transferred from HQ to LQ</li>
</ul>
<p>HQ beta: inconclusive<br>
LQ beta: all observed copies so far have 2024 dots</p>
<h2><a name="p-695383-delta-prototypes-and-alpha-presentation-8" href="#p-695383-delta-prototypes-and-alpha-presentation-8"></a>Delta prototypes and Alpha presentation</h2>
<ul>
<li>I haven’t said too much about these yet but so far they all look similar to LQ beta and all observed copies so far have 2024 dots</li>
</ul>
<h2><a name="p-695383-beta-presentation-9" href="#p-695383-beta-presentation-9"></a>Beta presentation</h2>
<ul>
<li>No hi-res scan available yet, but I see no evidence of dots so far</li>
<li>They match well with the corocoro images and the print quality suggests a different printer was used for these than anything mentioned so far</li>
<li>inconclusive so far</li>
</ul>
<h2><a name="p-695383-acknowledgements-10" href="#p-695383-acknowledgements-10"></a>Acknowledgements</h2>
<p>Thanks to <a href="https://www.elitefourum.com/u/tediorso">@tediorso</a> for suggesting this avenue of investigation.<br>
Thanks to <a href="https://www.elitefourum.com/u/mika">@mika</a> <a href="https://www.elitefourum.com/u/linkdu83">@linkdu83</a> and <a href="https://www.elitefourum.com/u/humanforscale">@HumanForScale</a> for helping with data collection and analysis<br>
Thanks to <a href="https://www.elitefourum.com/u/banks">@BANKS</a> for working on information summary</p>
            </div>

            

                
          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Dyl"><span itemprop="name">Dyl</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:40:25Z">
                    January 27, 2025,  1:40am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:40:25Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Holy Shit</p>
<p><img src="https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExazV6dXMyZXkyajI2c2tjN21yc2c5b2ZyNm10ZHNpdXJnbGNqOGpqYyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/IO0gM5bNgCuZFWkQPF/giphy.webp" width="480" height="480" title="Episode 7 Wow GIF by Wrexham AFC - Find &amp; Share on GIPHY"></p>
            </div>

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Are any of these 2024 prints raw or have they been “authenticated”?</p>

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/casual"><span itemprop="name">casual</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:45:22Z">
                    January 27, 2025,  1:45am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:45:22Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Incredible research.</p>
<p>What a dangerous game people are playing buying these, pkonno really DID have a printer in his basement.</p>
            </div>

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/BANKS"><span itemprop="name">BANKS</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:04Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:04Z">
              <span itemprop="position">6</span>
              </span>
            </p>
            <p>Taking into consideration the personal stake that you have in these cards, you’re the goat</p>

            

          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/lyleberr"><span itemprop="name">lyleberr</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:47Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:47Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <p>Does it have to be a scan or can you do this from a photo of a playtest? Does it have to have color?</p>

            

          </div>
          <div id="post_8" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/pfm"><span itemprop="name">pfm</span></a>
                
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:50Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:50Z">
              <span itemprop="position">8</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Another observation I want to mention.</p>
<p>The alpha prototypes were likely designed in a tool called ClarisWorks 4 which was available in 1995.</p>
<p>Here I emulated an old mac and ran it:</p>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/2/d/2d23a2c16129614341eb58c419ac14666af37fef.png" data-download-href="https://efour.b-cdn.net/uploads/default/2d23a2c16129614341eb58c419ac14666af37fef" title="clarisworks_pikachu"><img src="https://efour.b-cdn.net/uploads/default/original/3X/2/d/2d23a2c16129614341eb58c419ac14666af37fef.png" alt="clarisworks_pikachu" data-base62-sha1="6rjPNqWkOuMhmIMeGN9SReKng4f" width="644" height="484"></a></div>
<p>When looking at alpha prototypes there is clearly a set that is higher quality than the others. Consider Pikachu</p>

<p>Consider the dots in the background:</p>
<div data-masonry-gallery="">
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/9259b7e71edc6e0e223c70e24df2f16044c635a3" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_647x485.jpeg" alt="image" data-base62-sha1="kSFVKkv9znEPcLJf4jwyzwKkEBd" width="647" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_647x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_970x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/9/2/9259b7e71edc6e0e223c70e24df2f16044c635a3_2_1294x970.jpeg 2x" data-dominant-color="E0DFE3"></a></div><br>
<div><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_637x485.jpeg" alt="image" data-base62-sha1="vUvkM1DuN5goEgm2cpCMK7lOZTd" width="637" height="485" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_637x485.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_955x727.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/f/dfa6901400bfbc639fecf3eb999e79f1fc57e1b3_2_1274x970.jpeg 2x" data-dominant-color="DDDCE2"></a></div>
</div>
<p>Also note the shared print artifact that goes through the “Pikachu” text.</p>
<p>It’s not limited to Pikachu.</p>

            </div>

            

          </div>
          <div id="post_9" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/casual"><span itemprop="name">casual</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:46:53Z">
                    January 27, 2025,  1:46am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:46:53Z">
              <span itemprop="position">9</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Personally, I think it makes sense to go after the grading companies here</p>
<p>This is a disaster</p>
<p>They should be fully refunding people</p>
            </div>

            

          </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/pfm"><span itemprop="name">pfm</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:47:13Z">
                    January 27, 2025,  1:47am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:47:13Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            

            

          </div>
          <div itemprop="comment" id="post_11" itemscope="" itemtype="http://schema.org/Comment"><a href="https://efour.b-cdn.net/uploads/default/original/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/da4481234122cefc0f58c78442cae136fb5e1f6c" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_245x242.jpeg" alt="image" data-base62-sha1="v8SReEYq9rNAiDadtyZu2hidIHW" width="245" height="242" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_245x242.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_367x363.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/d/a/da4481234122cefc0f58c78442cae136fb5e1f6c_2_490x484.jpeg 2x" data-dominant-color="876E78"></a></div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/ddk"><span itemprop="name">ddk</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:49:58Z">
                    January 27, 2025,  1:49am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:49:58Z">
              <span itemprop="position">12</span>
              </span>
            </p>
            <p>The tragic irony of pfm believing in these cards for months only to be the one to discover the truth behind them…</p>

            

          </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Proud of you <a href="https://www.elitefourum.com/u/pfm">@pfm</a>. You didn’t have to release this and yet you did all the same. You solved one of the biggest mysteries this hobby has seen in years. If anyone was going to do it, it was going to be you.</p>

            

          </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Dirge"><span itemprop="name">Dirge</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:51:17Z">
                    January 27, 2025,  1:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:51:17Z">
              <span itemprop="position">14</span>
              </span>
            </p>
            <div itemprop="text">
              <p>I am stunned and impressed beyond words. Holy shit.</p>
<p>Does this mean they’re all fakes or just some of them?</p>
            </div>

            

          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/BANKS"><span itemprop="name">BANKS</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:51:21Z">
                    January 27, 2025,  1:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:51:21Z">
              <span itemprop="position">15</span>
              </span>
            </p>
            <p>That’s what separates Greek heroes from timmys, PFM went the distance</p>

            

          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Will"><span itemprop="name">Will</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:51:35Z">
                    January 27, 2025,  1:51am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:51:35Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <p>Great analysis as always pfm, amazing stuff</p>

            

          </div>
          <div id="post_17" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Alec"><span itemprop="name">Alec</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:54:08Z">
                    January 27, 2025,  1:54am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:54:08Z">
              <span itemprop="position">17</span>
              </span>
            </p>
            <p>I think the most reasonable take is some are certainly not 1995/1996 playtest cards as we’ve been led to believe, and the rest are at least questionable.</p>

            

          </div>
          <div id="post_18" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/pfm"><span itemprop="name">pfm</span></a>
                
              </span></p>

              <p><span>
                  <time itemprop="datePublished" datetime="2025-01-27T01:56:47Z">
                    January 27, 2025,  1:56am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T01:56:47Z">
              <span itemprop="position">18</span>
              </span>
            </p></div>
            <div itemprop="text">
              
<p>I’m still digging into it. All I can say is that I’ve seen evidence of 3 different printers for the coloured variants and one of them has 2024 in the metadata (majority of the beta). The majority of the alpha have a different set of print dots.</p>
<p>for example:<br>
</p><div><a href="https://efour.b-cdn.net/uploads/default/original/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c.jpeg" data-download-href="https://efour.b-cdn.net/uploads/default/47a6b0190821d32e8a3d909e6359843596a7a21c" title="image"><img src="https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_690x395.jpeg" alt="image" data-base62-sha1="adR1HS0CPjkcR1XaLMVbIVDHeXy" width="690" height="395" srcset="https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_690x395.jpeg, https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_1035x592.jpeg 1.5x, https://efour.b-cdn.net/uploads/default/optimized/3X/4/7/47a6b0190821d32e8a3d909e6359843596a7a21c_2_1380x790.jpeg 2x" data-dominant-color="D38FCD"></a></div>
<p>I have a guess at the printer brand. I don’t believe print time is encoded but the printer model should be in there.</p>
<p>In other words:</p>
<ul>
<li>High quality beta = no dots</li>
<li>Low quality beta = dots in the OP</li>
<li>Alpha playtest = dots above</li>
</ul>
<p>This is my general observation, there are exceptions</p>
            </div>

            

          </div>
          <div itemprop="comment" id="post_19" itemscope="" itemtype="http://schema.org/Comment">
              <p>Well there you go. I won’t speak in absolutes as it still seems like there is some information to come, but if this proves to reflect the entirety of the playtest cards it can’t be seen as anything other than an epic failure of CGC’s authentication practices.</p>

<p>This was the original problem with the cards, that we had to rely on “trust me bro” from CGC and Akabane, with none of the in-depth analysis that CGC is known for. Because they didn’t do it, pfm had to, and digs up very questionable results.</p>
<p>I am hard pressed to imagine a more disingenuous and exploitative process. It appears like these cards and their release were deliberately engineered to fool the community. CGC at best was negligent in their duty as a grading company, and at worst was complicit in the process.</p>
            </div>
          <div id="post_20" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://www.elitefourum.com/u/Dirge"><span itemprop="name">Dirge</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-01-27T02:01:24Z">
                    January 27, 2025,  2:01am
                  </time>
                  <meta itemprop="dateModified" content="2025-01-27T02:01:24Z">
              <span itemprop="position">20</span>
              </span>
            </p>
            <p>Should I be impressed that you managed to do all this or should I be horrified that CGC didn’t have the means to catch this?</p>

            

          </div>
          <div id="post_21" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>At times like these, I’m glad I’m risk adverse. I wanted to get some but there were too many unanswered questions.</p>

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google offering 'voluntary exit' for employees working on Pixel, Android (102 pts)]]></title>
            <link>https://9to5google.com/2025/01/30/pixel-android-voluntary-exit-employees/</link>
            <guid>42880529</guid>
            <pubDate>Thu, 30 Jan 2025 18:21:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2025/01/30/pixel-android-voluntary-exit-employees/">https://9to5google.com/2025/01/30/pixel-android-voluntary-exit-employees/</a>, See on <a href="https://news.ycombinator.com/item?id=42880529">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5google.com/wp-content/uploads/sites/4/2024/08/google-hq-logo-4.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2024/08/google-hq-logo-4.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2024/08/google-hq-logo-4.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2024/08/google-hq-logo-4.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2024/08/google-hq-logo-4.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p><a href="https://9to5google.com/2024/04/18/google-platform-and-devices-team-android-pixel-hardware/">Last year</a>, the teams responsible for Pixel hardware and Android software were merged into one division, and Google today announced a “voluntary exit program” for employees working in the Platforms &amp; Devices group.</p>



<p>SVP Rick Osterloh sent out a memo to employees this morning about the “voluntary exit program,” and the company confirmed to <em>9to5Google</em> that this is happening.</p>



<p>This program applies to US employees working on Platforms &amp; Devices, which includes Android (Auto, TV, Wear OS, XR), Chrome, ChromeOS, Google Photos, Google One, Pixel, Fitbit, and Nest. Google has many people around the world working on these products, but today’s announcement is just for those stateside.</p>



<p>Meanwhile, this is not a company-wide offer that applies to Search, AI, or other groups, though Alphabet’s new CFO <a href="https://9to5google.com/2024/10/29/alphabet-q3-2024-earnings/">last October</a> said “driving further efficiencies” was a key priority.</p>	
	



<p>Separately, software and hardware were already two very large organizations, with some overlap. Now that things have settled in recent months, employees have a better idea of their roles. Osterloh said the division received questions about the possibility of voluntary exits since the Pixel-Android merger. Not offering people the option to leave in advance was a complaint about how Google handled past layoffs.</p>



<p>The memo frames this exit program as being beneficial for those who might not be aligned or passionate about the combined organization’s mission or are having difficulty with their roles, and hybrid working requirements.&nbsp;</p>



<p>In leaving Google, employees will get a severance package, with more details internally coming soon. From what we learned, this program does not coincide with any product roadmap changes.&nbsp;</p>



<p>Before the merger, the Google hardware division last January switched to a <a href="https://9to5google.com/2024/01/10/google-reorganizing-hardware/">functional organization model</a> where there is one team (and leader) for teams like hardware engineering across Pixel, Nest, and Fitbit. At the same time, a few hundred roles were cut. The broader unification in April was designed to “speed up decision-making” internally.&nbsp;</p>



<p>In offering this program today, Google wants employees “to be deeply committed to our mission and focused on building great products, with speed and efficiency.” The statement also makes reference to “tremendous momentum” and “so much important work ahead.” Google’s full statement is below.</p>



<blockquote>
<p>The Platforms &amp; Devices team is offering a voluntary exit program that provides US-based Googlers working on this team the ability to voluntarily leave the company with a severance package. This comes after we brought two large organizations together last year. There’s tremendous momentum on this team and with so much important work ahead, we want everyone to be deeply committed to our mission and focused on building great products, with speed and efficiency.</p>
</blockquote>



<p><em>Updating…</em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/4jF54XN"><img src="https://9to5google.com/wp-content/uploads/sites/4/2025/01/Banner-2-dbrand-9to5-dbrand-S25U-ghost-banner.png" alt="" width="1024" height="205"></a></p></div>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quaternions and spherical trigonometry (112 pts)]]></title>
            <link>https://terrytao.wordpress.com/2024/12/19/quaternions-and-spherical-trigonometry/</link>
            <guid>42880242</guid>
            <pubDate>Thu, 30 Jan 2025 17:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terrytao.wordpress.com/2024/12/19/quaternions-and-spherical-trigonometry/">https://terrytao.wordpress.com/2024/12/19/quaternions-and-spherical-trigonometry/</a>, See on <a href="https://news.ycombinator.com/item?id=42880242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>
 Hamilton’s <a href="https://en.wikipedia.org/wiki/Quaternion">quaternion number</a> system <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\mathbb{H}}"> is a non-commutative extension of the complex numbers, consisting of numbers of the form <img src="https://s0.wp.com/latex.php?latex=%7Bt+%2B+xi+%2B+yj+%2B+zk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bt+%2B+xi+%2B+yj+%2B+zk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bt+%2B+xi+%2B+yj+%2B+zk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{t + xi + yj + zk}"> where <img src="https://s0.wp.com/latex.php?latex=%7Bt%2Cx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bt%2Cx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bt%2Cx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{t,x,y,z}"> are real numbers, and <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i,j,k}"> are anti-commuting square roots of <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-1}"> with <img src="https://s0.wp.com/latex.php?latex=%7Bij%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bij%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bij%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{ij=k}">, <img src="https://s0.wp.com/latex.php?latex=%7Bjk%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bjk%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bjk%3Di%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{jk=i}">, <img src="https://s0.wp.com/latex.php?latex=%7Bki%3Dj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bki%3Dj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bki%3Dj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{ki=j}">. While they are non-commutative, they do keep many other properties of the complex numbers: 

</p><ul> <li> Being non-commutative, the quaternions do not form a field. However, they are still a <a href="https://en.wikipedia.org/wiki/Division_ring">skew field</a> (or division ring): multiplication is associative, and every non-zero quaternion has a unique multiplicative inverse. </li><li> Like the complex numbers, the quaternions have a conjugation <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Coverline%7Bt%2Bxi%2Byj%2Bzk%7D+%3A%3D+t-xi-yj-zk%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Coverline%7Bt%2Bxi%2Byj%2Bzk%7D+%3A%3D+t-xi-yj-zk%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Coverline%7Bt%2Bxi%2Byj%2Bzk%7D+%3A%3D+t-xi-yj-zk%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \overline{t+xi+yj+zk} := t-xi-yj-zk,"></p>
 although this is now an <a href="https://en.wikipedia.org/wiki/Antihomomorphism">antihomomorphism</a> rather than a homomorphism: <img src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7Bqr%7D+%3D+%5Coverline%7Br%7D%5C+%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7Bqr%7D+%3D+%5Coverline%7Br%7D%5C+%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Coverline%7Bqr%7D+%3D+%5Coverline%7Br%7D%5C+%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\overline{qr} = \overline{r}\ \overline{q}}">. One can then split up a quaternion <img src="https://s0.wp.com/latex.php?latex=%7Bt+%2B+xi+%2B+yj+%2B+zk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bt+%2B+xi+%2B+yj+%2B+zk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bt+%2B+xi+%2B+yj+%2B+zk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{t + xi + yj + zk}"> into its real part <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{t}"> and imaginary part <img src="https://s0.wp.com/latex.php?latex=%7Bxi%2Byj%2Bzk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bxi%2Byj%2Bzk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bxi%2Byj%2Bzk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{xi+yj+zk}"> by the familiar formulae <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D+q+%3A%3D+%5Cfrac%7Bq+%2B+%5Coverline%7Bq%7D%7D%7B2%7D%3B+%5Cquad+%5Cmathrm%7BIm%7D+q+%3A%3D+%5Cfrac%7Bq+-+%5Coverline%7Bq%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D+q+%3A%3D+%5Cfrac%7Bq+%2B+%5Coverline%7Bq%7D%7D%7B2%7D%3B+%5Cquad+%5Cmathrm%7BIm%7D+q+%3A%3D+%5Cfrac%7Bq+-+%5Coverline%7Bq%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D+q+%3A%3D+%5Cfrac%7Bq+%2B+%5Coverline%7Bq%7D%7D%7B2%7D%3B+%5Cquad+%5Cmathrm%7BIm%7D+q+%3A%3D+%5Cfrac%7Bq+-+%5Coverline%7Bq%7D%7D%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \mathrm{Re} q := \frac{q + \overline{q}}{2}; \quad \mathrm{Im} q := \frac{q - \overline{q}}{2}"></p>
 (though we now leave the imaginary part purely imaginary, as opposed to dividing by <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i}"> in the complex case). </li><li> The inner product <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+q%2C+r+%5Crangle+%3A%3D+%5Cmathrm%7BRe%7D+q+%5Coverline%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+q%2C+r+%5Crangle+%3A%3D+%5Cmathrm%7BRe%7D+q+%5Coverline%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+q%2C+r+%5Crangle+%3A%3D+%5Cmathrm%7BRe%7D+q+%5Coverline%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle q, r \rangle := \mathrm{Re} q \overline{r}"></p>
 is symmetric and positive definite (with <img src="https://s0.wp.com/latex.php?latex=%7B1%2Ci%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%2Ci%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%2Ci%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1,i,j,k}"> forming an orthonormal basis). Also, for any <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{q}">, <img src="https://s0.wp.com/latex.php?latex=%7Bq+%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bq+%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bq+%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{q \overline{q}}"> is real, hence equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+q%2C+q+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Clangle+q%2C+q+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Clangle+q%2C+q+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\langle q, q \rangle}">. Thus we have a norm <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Cq%7C+%3D+%5Csqrt%7Bq%5Coverline%7Bq%7D%7D+%3D+%5Csqrt%7B%5Clangle+q%2Cq+%5Crangle%7D+%3D+%5Csqrt%7Bt%5E2+%2B+x%5E2+%2B+y%5E2+%2B+z%5E2%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Cq%7C+%3D+%5Csqrt%7Bq%5Coverline%7Bq%7D%7D+%3D+%5Csqrt%7B%5Clangle+q%2Cq+%5Crangle%7D+%3D+%5Csqrt%7Bt%5E2+%2B+x%5E2+%2B+y%5E2+%2B+z%5E2%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7Cq%7C+%3D+%5Csqrt%7Bq%5Coverline%7Bq%7D%7D+%3D+%5Csqrt%7B%5Clangle+q%2Cq+%5Crangle%7D+%3D+%5Csqrt%7Bt%5E2+%2B+x%5E2+%2B+y%5E2+%2B+z%5E2%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  |q| = \sqrt{q\overline{q}} = \sqrt{\langle q,q \rangle} = \sqrt{t^2 + x^2 + y^2 + z^2}."></p>
 Since the real numbers commute with all quaternions, we have the multiplicative property <img src="https://s0.wp.com/latex.php?latex=%7B%7Cqr%7C+%3D+%7Cq%7C+%7Cr%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Cqr%7C+%3D+%7Cq%7C+%7Cr%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Cqr%7C+%3D+%7Cq%7C+%7Cr%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|qr| = |q| |r|}">. In particular, the unit quaternions <img src="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%3A%3D+%5C%7B+q+%5Cin+%5Cmathbb%7BH%7D%3A+%7Cq%7C%3D1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%3A%3D+%5C%7B+q+%5Cin+%5Cmathbb%7BH%7D%3A+%7Cq%7C%3D1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%3A%3D+%5C%7B+q+%5Cin+%5Cmathbb%7BH%7D%3A+%7Cq%7C%3D1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{U(1,\mathbb{H}) := \{ q \in \mathbb{H}: |q|=1\}}"> (also known as <img src="https://s0.wp.com/latex.php?latex=%7BSU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BSU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BSU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{SU(2)}">, <img src="https://s0.wp.com/latex.php?latex=%7BSp%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BSp%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BSp%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{Sp(1)}">, or <img src="https://s0.wp.com/latex.php?latex=%7BSpin%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BSpin%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BSpin%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{Spin(3)}">) form a compact group. </li><li> We have the <a href="https://en.wikipedia.org/wiki/Trace_(linear_algebra)#Cyclic_property">cyclic trace property</a> <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D%28qr%29+%3D+%5Cmathrm%7BRe%7D%28rq%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D%28qr%29+%3D+%5Cmathrm%7BRe%7D%28rq%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D%28qr%29+%3D+%5Cmathrm%7BRe%7D%28rq%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \mathrm{Re}(qr) = \mathrm{Re}(rq)"></p>
 which allows one to take adjoints of left and right multiplication: <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+qr%2C+s+%5Crangle+%3D+%5Clangle+q%2C+s%5Coverline%7Br%7D%5Crangle%3B+%5Cquad+%5Clangle+rq%2C+s+%5Crangle+%3D+%5Clangle+q%2C+%5Coverline%7Br%7Ds+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+qr%2C+s+%5Crangle+%3D+%5Clangle+q%2C+s%5Coverline%7Br%7D%5Crangle%3B+%5Cquad+%5Clangle+rq%2C+s+%5Crangle+%3D+%5Clangle+q%2C+%5Coverline%7Br%7Ds+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+qr%2C+s+%5Crangle+%3D+%5Clangle+q%2C+s%5Coverline%7Br%7D%5Crangle%3B+%5Cquad+%5Clangle+rq%2C+s+%5Crangle+%3D+%5Clangle+q%2C+%5Coverline%7Br%7Ds+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle qr, s \rangle = \langle q, s\overline{r}\rangle; \quad \langle rq, s \rangle = \langle q, \overline{r}s \rangle"></p>
 </li><li> As <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i,j,k}"> are square roots of <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-1}">, we have the usual Euler formulae <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+i+%5Csin+%5Ctheta%2C+e%5E%7Bj%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+j+%5Csin+%5Ctheta%2C+e%5E%7Bk%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+k+%5Csin+%5Ctheta&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+i+%5Csin+%5Ctheta%2C+e%5E%7Bj%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+j+%5Csin+%5Ctheta%2C+e%5E%7Bk%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+k+%5Csin+%5Ctheta&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+i+%5Csin+%5Ctheta%2C+e%5E%7Bj%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+j+%5Csin+%5Ctheta%2C+e%5E%7Bk%5Ctheta%7D+%3D+%5Ccos+%5Ctheta+%2B+k+%5Csin+%5Ctheta&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i\theta} = \cos \theta + i \sin \theta, e^{j\theta} = \cos \theta + j \sin \theta, e^{k\theta} = \cos \theta + k \sin \theta"></p>
 for real <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\theta}">, together with other familiar formulae such as <img src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7Be%5E%7Bi%5Ctheta%7D%7D+%3D+e%5E%7B-i%5Ctheta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7Be%5E%7Bi%5Ctheta%7D%7D+%3D+e%5E%7B-i%5Ctheta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Coverline%7Be%5E%7Bi%5Ctheta%7D%7D+%3D+e%5E%7B-i%5Ctheta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\overline{e^{i\theta}} = e^{-i\theta}}">, <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%28%5Calpha%2B%5Cbeta%29%7D+%3D+e%5E%7Bi%5Calpha%7D+e%5E%7Bi%5Cbeta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%28%5Calpha%2B%5Cbeta%29%7D+%3D+e%5E%7Bi%5Calpha%7D+e%5E%7Bi%5Cbeta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%28%5Calpha%2B%5Cbeta%29%7D+%3D+e%5E%7Bi%5Calpha%7D+e%5E%7Bi%5Cbeta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{e^{i(\alpha+\beta)} = e^{i\alpha} e^{i\beta}}">, <img src="https://s0.wp.com/latex.php?latex=%7B%7Ce%5E%7Bi%5Ctheta%7D%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7Ce%5E%7Bi%5Ctheta%7D%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7Ce%5E%7Bi%5Ctheta%7D%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{|e^{i\theta}| = 1}">, etc. 
</li></ul><p>

 We will use these sorts of algebraic manipulations in the sequel without further comment.
</p><p>
The unit quaternions <img src="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%3D+%5C%7B+q+%5Cin+%5Cmathbb%7BH%7D%3A+%7Cq%7C%3D1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%3D+%5C%7B+q+%5Cin+%5Cmathbb%7BH%7D%3A+%7Cq%7C%3D1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%3D+%5C%7B+q+%5Cin+%5Cmathbb%7BH%7D%3A+%7Cq%7C%3D1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{U(1,\mathbb{H}) = \{ q \in \mathbb{H}: |q|=1\}}"> act on the imaginary quaternions <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+xi+%2B+yj+%2B+zk%3A+x%2Cy%2Cz+%5Cin+%7B%5Cbf+R%7D%5C%7D+%5Cequiv+%7B%5Cbf+R%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5C%7B+xi+%2B+yj+%2B+zk%3A+x%2Cy%2Cz+%5Cin+%7B%5Cbf+R%7D%5C%7D+%5Cequiv+%7B%5Cbf+R%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5C%7B+xi+%2B+yj+%2B+zk%3A+x%2Cy%2Cz+%5Cin+%7B%5Cbf+R%7D%5C%7D+%5Cequiv+%7B%5Cbf+R%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\{ xi + yj + zk: x,y,z \in {\bf R}\} \equiv {\bf R}^3}"> by conjugation: </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v+%5Cmapsto+q+v+%5Coverline%7Bq%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v+%5Cmapsto+q+v+%5Coverline%7Bq%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v+%5Cmapsto+q+v+%5Coverline%7Bq%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  v \mapsto q v \overline{q}."></p><p>
 This action is by orientation-preserving isometries, hence by rotations. It is not quite faithful, since conjugation by the unit quaternion <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-1}"> is the identity, but one can show that this is the only loss of faithfulness, reflecting the well known fact that <img src="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%5Cequiv+SU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%5Cequiv+SU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29+%5Cequiv+SU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{U(1,\mathbb{H}) \equiv SU(2)}"> is a double cover of <img src="https://s0.wp.com/latex.php?latex=%7BSO%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BSO%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BSO%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{SO(3)}">.
</p><p>
For instance, for any real <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\theta}">, conjugation by <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%2F2%29+%2B+i+%5Csin%28%5Ctheta%2F2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%2F2%29+%2B+i+%5Csin%28%5Ctheta%2F2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%2F2%29+%2B+i+%5Csin%28%5Ctheta%2F2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{e^{i\theta/2} = \cos(\theta/2) + i \sin(\theta/2)}"> is a rotation by <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\theta}"> around <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i}">: <a name="id0"></a></p><p><a name="id0"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+i+e%5E%7B-i%5Ctheta%2F2%7D+%3D+i+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+i+e%5E%7B-i%5Ctheta%2F2%7D+%3D+i+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+i+e%5E%7B-i%5Ctheta%2F2%7D+%3D+i+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i\theta/2} i e^{-i\theta/2} = i \ \ \ \ \ (1)"></a></p><a name="id1"><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+j+e%5E%7B-i%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%29+j+-+%5Csin%28%5Ctheta%29+k+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+j+e%5E%7B-i%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%29+j+-+%5Csin%28%5Ctheta%29+k+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+j+e%5E%7B-i%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%29+j+-+%5Csin%28%5Ctheta%29+k+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i\theta/2} j e^{-i\theta/2} = \cos(\theta) j - \sin(\theta) k \ \ \ \ \ (2)"></p>
</a> <a name="id2"><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+k+e%5E%7B-i%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%29+k+%2B+%5Csin%28%5Ctheta%29+j.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+k+e%5E%7B-i%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%29+k+%2B+%5Csin%28%5Ctheta%29+j.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%5Ctheta%2F2%7D+k+e%5E%7B-i%5Ctheta%2F2%7D+%3D+%5Ccos%28%5Ctheta%29+k+%2B+%5Csin%28%5Ctheta%29+j.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i\theta/2} k e^{-i\theta/2} = \cos(\theta) k + \sin(\theta) j. \ \ \ \ \ (3)"></p>
</a><p> Similarly for cyclic permutations of <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%2Cj%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i,j,k}">. The doubling of the angle here can be explained from the Lie algebra fact that <img src="https://s0.wp.com/latex.php?latex=%7B%5Bi%2Cj%5D%3Dij-ji%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Bi%2Cj%5D%3Dij-ji%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Bi%2Cj%5D%3Dij-ji%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[i,j]=ij-ji}"> is <img src="https://s0.wp.com/latex.php?latex=%7B2k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B2k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B2k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{2k}"> rather than <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}">; it also closely related to the aforementioned double cover. We also of course have <img src="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%5Cequiv+Spin%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%5Cequiv+Spin%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%5Cequiv+Spin%283%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{U(1,\mathbb{H})\equiv Spin(3)}"> acting on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\mathbb{H}}"> by left multiplication; this is known as the <a href="https://en.wikipedia.org/wiki/Spinor">spinor representation</a>, but will not be utilized much in this post. (Giving <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\mathbb{H}}"> the right action of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{{\bf C}}"> makes it a copy of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{{\bf C}^2}">, and the spinor representation then also becomes the standard representation of <img src="https://s0.wp.com/latex.php?latex=%7BSU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BSU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BSU%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{SU(2)}"> on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{{\bf C}^2}">.)
</p><p>
Given how quaternions relate to three-dimensional rotations, it is not surprising that one can also be used to recover the basic laws of <a href="https://en.wikipedia.org/wiki/Spherical_trigonometry">spherical trigonometry</a> – the study of spherical triangles on the unit sphere. This is fairly well known, but it took a little effort for me to locate the required arguments, so I am recording the calculations here.
</p><p>
The first observation is that every unit quaternion <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{q}"> induces a unit tangent vector <img src="https://s0.wp.com/latex.php?latex=%7Bqj%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bqj%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bqj%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{qj\overline{q}}"> on the unit sphere <img src="https://s0.wp.com/latex.php?latex=%7BS%5E2+%5Csubset+%7B%5Cbf+R%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BS%5E2+%5Csubset+%7B%5Cbf+R%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BS%5E2+%5Csubset+%7B%5Cbf+R%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{S^2 \subset {\bf R}^3}">, located at <img src="https://s0.wp.com/latex.php?latex=%7Bqi%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bqi%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bqi%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{qi\overline{q} \in S^2}">; the third unit vector <img src="https://s0.wp.com/latex.php?latex=%7Bqk%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bqk%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bqk%5Coverline%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{qk\overline{q}}"> is then another tangent vector orthogonal to the first two (and oriented to the left of the original tangent vector), and can be viewed as the cross product of <img src="https://s0.wp.com/latex.php?latex=%7Bqi%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bqi%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bqi%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{qi\overline{q} \in S^2}"> and <img src="https://s0.wp.com/latex.php?latex=%7Bqj%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bqj%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bqj%5Coverline%7Bq%7D+%5Cin+S%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{qj\overline{q} \in S^2}">. Right multplication of this quaternion then corresponds to various natural operations on this unit tangent vector:
</p>


<p>
Now suppose one has a spherical triangle with vertices <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A,B,C}">, with the spherical arcs <img src="https://s0.wp.com/latex.php?latex=%7BAB%2C+BC%2C+CA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BAB%2C+BC%2C+CA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BAB%2C+BC%2C+CA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{AB, BC, CA}"> subtending angles <img src="https://s0.wp.com/latex.php?latex=%7Bc%2C+a%2C+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%2C+a%2C+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%2C+a%2C+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c, a, b}"> respectively, and the vertices <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A,B,C}"> subtending angles <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\alpha,\beta,\gamma}"> respectively; suppose also that <img src="https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{ABC}"> is oriented in an anti-clockwise direction for sake of discussion. Observe that if one starts at <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> with a tangent vector oriented towards <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}">, advances that vector by <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c}">, and then rotates by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi - \beta}">, the tangent vector now at <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}"> and pointing towards <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{C}">. If one advances by <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a}"> and rotates by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi - \gamma}">, one is now at <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{C}"> pointing towards <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}">; and if one then advances by <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{b}"> and rotates by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi+-+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi - \alpha}">, one is back at <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> pointing towards <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}">. This gives the fundamental relation <a name="ident"></a></p><p><a name="ident"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bkc%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+1+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bkc%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+1+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bkc%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+1+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{kc/2} e^{i(\pi-\beta)/2} e^{ka/2} e^{i(\pi-\gamma)/2} e^{kb/2} e^{i(\pi-\alpha)/2} = 1 \ \ \ \ \ (4)"></a></p><p><a name="ident">
</a> relating the three sides and three equations of this triangle. (<em>A priori</em>, due to the lack of faithfulness of the <img src="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{U(1,\mathbb{H})}"> action, the right-hand side could conceivably have been <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-1}"> rather than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1}">; but for extremely small triangles the right-hand side is clearly <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1}">, and so by continuity it must be <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1}"> for all triangles.) Indeed, a moments thought will reveal that the condition <a href="#ident">(4)</a> is necessary and sufficient for the data <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a,b,c,\alpha,\beta,\gamma}"> to be associated with a spherical triangle. Thus one can view <a href="#ident">(4)</a> as a “master equation” for spherical trigonometry: in principle, it can be used to derive all the other laws of this subject.
</p><blockquote><b>Remark 1</b>  The law <a href="#ident">(4)</a> has an evident symmetry <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%29+%5Cmapsto+%28%5Cpi-%5Calpha%2C%5Cpi-%5Cbeta%2C%5Cpi-%5Cgamma%2C%5Cpi-a%2C%5Cpi-b%2C%5Cpi-c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%29+%5Cmapsto+%28%5Cpi-%5Calpha%2C%5Cpi-%5Cbeta%2C%5Cpi-%5Cgamma%2C%5Cpi-a%2C%5Cpi-b%2C%5Cpi-c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%29+%5Cmapsto+%28%5Cpi-%5Calpha%2C%5Cpi-%5Cbeta%2C%5Cpi-%5Cgamma%2C%5Cpi-a%2C%5Cpi-b%2C%5Cpi-c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(a,b,c,\alpha,\beta,\gamma) \mapsto (\pi-\alpha,\pi-\beta,\pi-\gamma,\pi-a,\pi-b,\pi-c)}">, which corresponds to the operation of replacing a spherical triangle with its dual triangle. Also, there is nothing particularly special about the choice of imaginaries <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i,k}"> in <a href="#ident">(4)</a>; one can conjugate <a href="#ident">(4)</a> by various quaternions and replace <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%2Ck%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i,k}"> here by any other orthogonal pair of unit quaternions. </blockquote>

<blockquote><b>Remark 2</b>  If we work in the small scale regime, replacing <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a,b,c}"> by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+a%2C+%5Cvarepsilon+b%2C+%5Cvarepsilon+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+a%2C+%5Cvarepsilon+b%2C+%5Cvarepsilon+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+a%2C+%5Cvarepsilon+b%2C+%5Cvarepsilon+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon a, \varepsilon b, \varepsilon c}"> for some small <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon>0}">, then we expect spherical triangles to behave like Euclidean triangles. Indeed, <a href="#ident">(4)</a> to zeroth order becomes <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i(\pi-\beta)/2} e^{i(\pi-\gamma)/2} e^{i(\pi-\alpha)/2} = 1"></p>
 which reflects the classical fact that the sum of angles of a Euclidean triangle is equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi}">. To first order, one obtains <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%2B+a+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%2B+b+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%2B+a+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%2B+b+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%2B+a+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%2B+b+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  c + a e^{i(\pi-\gamma)/2} e^{i(\pi-\alpha)/2} + b e^{i(\pi-\alpha)/2} = 0"></p>
 which reflects the evident fact that the vector sum of the sides of a Euclidean triangle sum to zero. (Geometrically, this correspondence reflects the fact that the action of the (projective) quaternion group on the unit sphere converges to the action of the special Euclidean group <img src="https://s0.wp.com/latex.php?latex=%7BSE%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BSE%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BSE%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{SE(2)}"> on the plane, in a suitable asymptotic limit.) </blockquote>

<p>
The identity <a href="#ident">(4)</a> is an identity of two unit quaternions; as the unit quaternion group <img src="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BU%281%2C%5Cmathbb%7BH%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{U(1,\mathbb{H})}"> is three-dimensional, this thus imposes three independent constraints on the six real parameters <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%2C%5Calpha%2C%5Cbeta%2C%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a,b,c,\alpha,\beta,\gamma}"> of the spherical triangle. One can manipulate this constraint in various ways to obtain various trigonometric identities involving some subsets of these six parameters. For instance, one can rearrange <a href="#ident">(4)</a> to get <a name="piba"></a></p><p><a name="piba"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%3D+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%3D+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%3D+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i(\pi-\beta)/2} e^{ka/2} e^{i(\pi-\gamma)/2} = e^{-kc/2} e^{-i(\pi-\alpha)/2} e^{-kb/2}. \ \ \ \ \ (5)"></a></p><p><a name="piba">
</a> Conjugating by <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{i}"> to reverse the sign of <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{k}">, we also have </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%3D+e%5E%7Bkc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkb%2F2%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%3D+e%5E%7Bkc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkb%2F2%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%3D+e%5E%7Bkc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkb%2F2%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{i(\pi-\beta)/2} e^{-ka/2} e^{i(\pi-\gamma)/2} = e^{kc/2} e^{-i(\pi-\alpha)/2} e^{kb/2}."></p><p>
 Taking the inner product of both sides of these identities, we conclude that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D%2C+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D%2C+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D%2C+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{i(\pi-\beta)/2} e^{ka/2} e^{i(\pi-\gamma)/2}, e^{i(\pi-\beta)/2} e^{-ka/2} e^{i(\pi-\gamma)/2} \rangle"></p><p>
 is equal to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D%2C+e%5E%7Bkc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkb%2F2%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D%2C+e%5E%7Bkc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkb%2F2%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D%2C+e%5E%7Bkc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkb%2F2%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{-kc/2} e^{-i(\pi-\alpha)/2} e^{-kb/2}, e^{kc/2} e^{-i(\pi-\alpha)/2} e^{kb/2} \rangle."></p><p>
 Using the various properties of inner product, the former expression simplifies to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BRe%7D+e%5E%7Bka%7D+%3D+%5Ccos+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BRe%7D+e%5E%7Bka%7D+%3D+%5Ccos+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BRe%7D+e%5E%7Bka%7D+%3D+%5Ccos+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\mathrm{Re} e^{ka} = \cos a}">, while the latter simplifies to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D+%5Clangle+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D%2C+e%5E%7Bkc%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D+%5Clangle+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D%2C+e%5E%7Bkc%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathrm%7BRe%7D+%5Clangle+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D%2C+e%5E%7Bkc%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \mathrm{Re} \langle e^{-i(\pi-\alpha)/2} e^{-kb} e^{i(\pi-\alpha)/2}, e^{kc} \rangle."></p><p>
 We can write <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bkc%7D+%3D+%5Ccos+c+%2B+%28%5Csin+c%29+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bkc%7D+%3D+%5Ccos+c+%2B+%28%5Csin+c%29+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Be%5E%7Bkc%7D+%3D+%5Ccos+c+%2B+%28%5Csin+c%29+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{e^{kc} = \cos c + (\sin c) k}"> and </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+%5Ccos+b+-+%28%5Csin+b%29+%28%5Ccos%28%5Cpi-%5Calpha%29+k+%2B+%5Csin%28%5Cpi-%5Calpha%29+j%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+%5Ccos+b+-+%28%5Csin+b%29+%28%5Ccos%28%5Cpi-%5Calpha%29+k+%2B+%5Csin%28%5Cpi-%5Calpha%29+j%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+%3D+%5Ccos+b+-+%28%5Csin+b%29+%28%5Ccos%28%5Cpi-%5Calpha%29+k+%2B+%5Csin%28%5Cpi-%5Calpha%29+j%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{-i(\pi-\alpha)/2} e^{-kb} e^{i(\pi-\alpha)/2} = \cos b - (\sin b) (\cos(\pi-\alpha) k + \sin(\pi-\alpha) j)"></p><p>
 so on substituting and simplifying we obtain </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+b+%5Ccos+c+%2B+%5Csin+b+%5Csin+c+%5Ccos+%5Calpha+%3D+%5Ccos+a&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+b+%5Ccos+c+%2B+%5Csin+b+%5Csin+c+%5Ccos+%5Calpha+%3D+%5Ccos+a&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+b+%5Ccos+c+%2B+%5Csin+b+%5Csin+c+%5Ccos+%5Calpha+%3D+%5Ccos+a&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \cos b \cos c + \sin b \sin c \cos \alpha = \cos a"></p><p>
 which is the <a href="https://en.wikipedia.org/wiki/Spherical_law_of_cosines">spherical cosine rule</a>. Note in the infinitesimal limit (replacing <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a,b,c}"> by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+a%2C+%5Cvarepsilon+b%2C+%5Cvarepsilon+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+a%2C+%5Cvarepsilon+b%2C+%5Cvarepsilon+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+a%2C+%5Cvarepsilon+b%2C+%5Cvarepsilon+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon a, \varepsilon b, \varepsilon c}">) this rule becomes the familiar Euclidean cosine rule </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%5E2+%3D+b%5E2+%2B+c%5E2+-+2bc+%5Ccos+%5Calpha.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%5E2+%3D+b%5E2+%2B+c%5E2+-+2bc+%5Ccos+%5Calpha.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%5E2+%3D+b%5E2+%2B+c%5E2+-+2bc+%5Ccos+%5Calpha.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  a^2 = b^2 + c^2 - 2bc \cos \alpha."></p>

<p>
In a similar fashion, from <a href="#piba">(5)</a> we see that the quantity </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+i+e%5E%7B-i%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D%2C+k+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+i+e%5E%7B-i%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D%2C+k+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+i+e%5E%7B-i%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D%2C+k+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{i(\pi-\beta)/2} e^{ka/2} e^{i(\pi-\gamma)/2} i e^{-i(\pi-\gamma)/2} e^{-ka/2} e^{-i(\pi-\beta)/2}, k \rangle"></p><p>
 is equal to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkc%2F2%7D%2C+k+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkc%2F2%7D%2C+k+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkc%2F2%7D%2C+k+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{-kc/2} e^{-i(\pi-\alpha)/2} e^{-kb/2} i e^{kb/2} e^{i(\pi-\alpha)/2} e^{kc/2}, k \rangle."></p><p>
 The first expression simplifies by <a href="#id0">(1)</a> and properties of the inner product to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bka%2F2%7D+i+e%5E%7B-ka%2F2%7D%2C+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D+k+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+%5Crangle%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bka%2F2%7D+i+e%5E%7B-ka%2F2%7D%2C+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D+k+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+%5Crangle%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bka%2F2%7D+i+e%5E%7B-ka%2F2%7D%2C+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D+k+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+%5Crangle%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{ka/2} i e^{-ka/2}, e^{-i(\pi-\beta)/2} k e^{i(\pi-\beta)/2} \rangle,"></p><p>
 which by <a href="#id1">(2)</a>, <a href="#id2">(3)</a> simplifies further to <img src="https://s0.wp.com/latex.php?latex=%7B-%5Csin+a+%5Csin+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-%5Csin+a+%5Csin+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-%5Csin+a+%5Csin+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-\sin a \sin \beta}">. Similarly, the second expression simplifies to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+%2C+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+k+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D%5Crangle%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+%2C+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+k+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D%5Crangle%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+%2C+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+k+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D%5Crangle%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{-kb/2} i e^{kb/2} , e^{i(\pi-\alpha)/2} k e^{-i(\pi-\alpha)/2}\rangle,"></p><p>
 which by <a href="#id1">(2)</a>, <a href="#id2">(3)</a> simplifies to <img src="https://s0.wp.com/latex.php?latex=%7B-%5Csin+b+%5Csin+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B-%5Csin+b+%5Csin+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B-%5Csin+b+%5Csin+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{-\sin b \sin \alpha}">. Equating the two and rearranging, we obtain </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Csin+%5Calpha%7D%7B%5Csin+a%7D+%3D+%5Cfrac%7B%5Csin+%5Cbeta%7D%7B%5Csin+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Csin+%5Calpha%7D%7B%5Csin+a%7D+%3D+%5Cfrac%7B%5Csin+%5Cbeta%7D%7B%5Csin+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Csin+%5Calpha%7D%7B%5Csin+a%7D+%3D+%5Cfrac%7B%5Csin+%5Cbeta%7D%7B%5Csin+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \frac{\sin \alpha}{\sin a} = \frac{\sin \beta}{\sin b}"></p><p>
 which is the <a href="https://en.wikipedia.org/wiki/Law_of_sines#The_spherical_law_of_sines">spherical sine rule</a>. Again, in the infinitesimal limit we obtain the familiar Euclidean sine rule </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Csin+%5Calpha%7D%7Ba%7D+%3D+%5Cfrac%7B%5Csin+%5Cbeta%7D%7Bb%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Csin+%5Calpha%7D%7Ba%7D+%3D+%5Cfrac%7B%5Csin+%5Cbeta%7D%7Bb%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Csin+%5Calpha%7D%7Ba%7D+%3D+%5Cfrac%7B%5Csin+%5Cbeta%7D%7Bb%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \frac{\sin \alpha}{a} = \frac{\sin \beta}{b}."></p>

<p>
As a variant of the above analysis, we have from <a href="#piba">(5)</a> again that </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+i+e%5E%7B-i%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D%2C+j+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+i+e%5E%7B-i%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D%2C+j+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+e%5E%7Bka%2F2%7D+e%5E%7Bi%28%5Cpi-%5Cgamma%29%2F2%7D+i+e%5E%7B-i%28%5Cpi-%5Cgamma%29%2F2%7D+e%5E%7B-ka%2F2%7D+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D%2C+j+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{i(\pi-\beta)/2} e^{ka/2} e^{i(\pi-\gamma)/2} i e^{-i(\pi-\gamma)/2} e^{-ka/2} e^{-i(\pi-\beta)/2}, j \rangle"></p><p>
 is equal to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkc%2F2%7D%2C+j+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkc%2F2%7D%2C+j+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-kc%2F2%7D+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7Bkc%2F2%7D%2C+j+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{-kc/2} e^{-i(\pi-\alpha)/2} e^{-kb/2} i e^{kb/2} e^{i(\pi-\alpha)/2} e^{kc/2}, j \rangle."></p><p>
 As before, the first expression simplifies to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bka%2F2%7D+i+e%5E%7B-ka%2F2%7D%2C+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D+j+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bka%2F2%7D+i+e%5E%7B-ka%2F2%7D%2C+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D+j+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7Bka%2F2%7D+i+e%5E%7B-ka%2F2%7D%2C+e%5E%7B-i%28%5Cpi-%5Cbeta%29%2F2%7D+j+e%5E%7Bi%28%5Cpi-%5Cbeta%29%2F2%7D+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{ka/2} i e^{-ka/2}, e^{-i(\pi-\beta)/2} j e^{i(\pi-\beta)/2} \rangle"></p><p>
 which equals <img src="https://s0.wp.com/latex.php?latex=%7B%5Csin+a+%5Ccos+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Csin+a+%5Ccos+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Csin+a+%5Ccos+%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\sin a \cos \beta}">. Meanwhile, the second expression can be rearranged as </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D%2C+e%5E%7Bkc%2F2%7D+j+e%5E%7B-kc%2F2%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D%2C+e%5E%7Bkc%2F2%7D+j+e%5E%7B-kc%2F2%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D%2C+e%5E%7Bkc%2F2%7D+j+e%5E%7B-kc%2F2%7D+%5Crangle.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \langle e^{-i(\pi-\alpha)/2} e^{-kb/2} i e^{kb/2} e^{i(\pi-\alpha)/2}, e^{kc/2} j e^{-kc/2} \rangle."></p><p>
 By <a href="#id1">(2)</a>, <a href="#id2">(3)</a> we can simplify to </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++e%5E%7B-i%28%5Cpi-%5Calpha%29%2F2%7D+e%5E%7B-kb%2F2%7D+i+e%5E%7Bkb%2F2%7D+e%5E%7Bi%28%5Cpi-%5Calpha%29%2F2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  e^{-i(\pi-\alpha)/2} e^{-kb/2} i e^{kb/2} e^{i(\pi-\alpha)/2} "></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%3D+%28%5Ccos+b%29+i+-+%28%5Csin+b%29+%5Ccos%28%5Cpi-%5Calpha%29+j+%2B+%28%5Csin+b%29+%5Csin%28%5Cpi-%5Calpha%29+k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%3D+%28%5Ccos+b%29+i+-+%28%5Csin+b%29+%5Ccos%28%5Cpi-%5Calpha%29+j+%2B+%28%5Csin+b%29+%5Csin%28%5Cpi-%5Calpha%29+k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%3D+%28%5Ccos+b%29+i+-+%28%5Csin+b%29+%5Ccos%28%5Cpi-%5Calpha%29+j+%2B+%28%5Csin+b%29+%5Csin%28%5Cpi-%5Calpha%29+k+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle= (\cos b) i - (\sin b) \cos(\pi-\alpha) j + (\sin b) \sin(\pi-\alpha) k "></p><p>
 and so the inner product is <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccos+b+%5Csin+c+-+%5Ccos+b+%5Csin+c+%5Ccos+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Ccos+b+%5Csin+c+-+%5Ccos+b+%5Csin+c+%5Ccos+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ccos+b+%5Csin+c+-+%5Ccos+b+%5Csin+c+%5Ccos+%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\cos b \sin c - \cos b \sin c \cos \alpha}">, leading to the “<a href="https://en.wikipedia.org/wiki/Spherical_trigonometry#Five-part_rules">five part rule</a>” </p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+b+%5Csin+c+-+%5Csin+b+%5Ccos+c+%5Ccos+%5Calpha+%3D+%5Csin+a+%5Ccos+%5Cbeta.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+b+%5Csin+c+-+%5Csin+b+%5Ccos+c+%5Ccos+%5Calpha+%3D+%5Csin+a+%5Ccos+%5Cbeta.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+b+%5Csin+c+-+%5Csin+b+%5Ccos+c+%5Ccos+%5Calpha+%3D+%5Csin+a+%5Ccos+%5Cbeta.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \cos b \sin c - \sin b \cos c \cos \alpha = \sin a \cos \beta."></p><p>
 In the case of a right-angled triangle <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3D%5Cpi%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3D%5Cpi%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cbeta%3D%5Cpi%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\beta=\pi/2}">, this simplifies to one of <a href="https://en.wikipedia.org/wiki/Spherical_trigonometry#Napier's_rules_for_right_spherical_triangles">Napier’s rules</a></p><a name="example"><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+%5Calpha+%3D+%5Cfrac%7B%5Ctan+c%7D%7B%5Ctan+b%7D%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+%5Calpha+%3D+%5Cfrac%7B%5Ctan+c%7D%7B%5Ctan+b%7D%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+%5Calpha+%3D+%5Cfrac%7B%5Ctan+c%7D%7B%5Ctan+b%7D%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \cos \alpha = \frac{\tan c}{\tan b}, \ \ \ \ \ (6)"></p>
</a><p> which in the infinitesimal limit is the familiar <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccos+%5Calpha+%3D+%5Cfrac%7Bc%7D%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Ccos+%5Calpha+%3D+%5Cfrac%7Bc%7D%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Ccos+%5Calpha+%3D+%5Cfrac%7Bc%7D%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\cos \alpha = \frac{c}{b}}">. The other rules of Napier can be derived in a similar fashion.
</p><blockquote><b>Example 3</b>  One application of Napier’s rule <a href="#example">(6)</a> is to determine the <a href="https://en.wikipedia.org/wiki/Sunrise_equation">sunrise equation</a> for when the sun rises and sets at a given location on the Earth, and a given time of year. For sake of argument let us work in summer, in which the <a href="https://en.wikipedia.org/wiki/Declination">declination</a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\delta}"> of the Sun is positive (due to axial tilt, it reaches a maximum of <img src="https://s0.wp.com/latex.php?latex=%7B23.5%5E%5Ccirc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B23.5%5E%5Ccirc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B23.5%5E%5Ccirc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{23.5^\circ}"> at the summer solstice). Then the Sun subtends an angle of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi/2-\delta}"> from the pole star (<a href="https://en.wikipedia.org/wiki/Polaris">Polaris</a> in the northern hemisphere, <a href="https://en.wikipedia.org/wiki/Sigma_Octantis">Sigma Octantis</a> in the southern hemisphere), and appears to rotate around that pole star once every <img src="https://s0.wp.com/latex.php?latex=%7B24%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B24%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B24%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{24}"> hours. On the other hand, if one is at a latitude <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\phi}">, then the pole star an elevation of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\phi}"> above the horizon. At extremely high latitudes <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\phi > \pi/2-\delta}">, the sun will never set (a phenomenon known as “<a href="https://en.wikipedia.org/wiki/Midnight_sun">midnight sun</a>“); but in all other cases, at sunrise or sunset, the sun, pole star, and horizon point below the pole star will form a right-angled spherical triangle, with hypotenuse subtending an angle <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi%2F2-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi/2-\delta}"> and vertical side subtending an angle <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\phi}">. The angle subtended by the pole star in this triangle is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi-%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cpi-%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cpi-%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\pi-\omega}">, where <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\omega}"> is the <a href="https://en.wikipedia.org/wiki/Hour_angle#Solar">solar hour angle</a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\omega}"> – the angle that the sun deviates from its noon position. Equation <a href="#example">(6)</a> then gives the <em>sunrise equation</em> <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos%28%5Cpi-%5Comega%29+%3D+%5Cfrac%7B%5Ctan+%5Cphi%7D%7B%5Ctan%28%5Cpi%2F2-%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos%28%5Cpi-%5Comega%29+%3D+%5Cfrac%7B%5Ctan+%5Cphi%7D%7B%5Ctan%28%5Cpi%2F2-%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos%28%5Cpi-%5Comega%29+%3D+%5Cfrac%7B%5Ctan+%5Cphi%7D%7B%5Ctan%28%5Cpi%2F2-%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \cos(\pi-\omega) = \frac{\tan \phi}{\tan(\pi/2-\delta)}"></p>
 or equivalently <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+%5Comega+%3D+-+%5Ctan+%5Cphi+%5Ctan+%5Cdelta.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+%5Comega+%3D+-+%5Ctan+%5Cphi+%5Ctan+%5Cdelta.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ccos+%5Comega+%3D+-+%5Ctan+%5Cphi+%5Ctan+%5Cdelta.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  \cos \omega = - \tan \phi \tan \delta."></p>
 A similar rule determines the time of sunset. In particular, the number of daylight hours in summer (assuming one is not in the midnight sun scenario <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2+-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2+-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2+-%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\phi > \pi/2 -\delta}">) is given by <p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++24+-+%5Cfrac%7B24%7D%7B%5Cpi%7D+%5Cmathrm%7Barccos%7D%28%5Ctan+%5Cphi+%5Ctan+%5Cdelta%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++24+-+%5Cfrac%7B24%7D%7B%5Cpi%7D+%5Cmathrm%7Barccos%7D%28%5Ctan+%5Cphi+%5Ctan+%5Cdelta%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++24+-+%5Cfrac%7B24%7D%7B%5Cpi%7D+%5Cmathrm%7Barccos%7D%28%5Ctan+%5Cphi+%5Ctan+%5Cdelta%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="\displaystyle  24 - \frac{24}{\pi} \mathrm{arccos}(\tan \phi \tan \delta)."></p>
 The situation in winter is similar, except that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\delta}"> is now negative, and <a href="https://en.wikipedia.org/wiki/Polar_night">polar night</a> (no sunrise) occurs when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2%2B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2%2B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cphi+%3E+%5Cpi%2F2%2B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\phi > \pi/2+\delta}">. </blockquote>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Karsa (YC W25) – Buy and save stablecoins internationally (110 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42879661</link>
            <guid>42879661</guid>
            <pubDate>Thu, 30 Jan 2025 16:59:38 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42879661">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42879661: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Is Down (113 pts)]]></title>
            <link>https://www.githubstatus.com</link>
            <guid>42877995</guid>
            <pubDate>Thu, 30 Jan 2025 14:29:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.githubstatus.com">https://www.githubstatus.com</a>, See on <a href="https://news.ycombinator.com/item?id=42877995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <!-- postmortem -->

    <!-- incident updates -->
      <p><strong>Resolved</strong> -
      	<span>On January 23, 2025, between 9:49 and 17:00 UTC, the available capacity of large hosted runners was degraded.  On average, 26% of jobs requiring large runners had a &gt;5min delay getting a runner assigned.  This was caused by the rollback of a configuration change and a latent bug in event processing, which was triggered by the mixed data shape that resulted from the rollback.  The processing would reprocess the same events unnecessarily and cause the background job that manages large runner creation and deletion to run out of resources.  It would automatically restart and continue processing, but the jobs were not able to keep up with production traffic.  We mitigated the impact by using a feature flag to bypass the problematic event processing logic.  While these changes had been rolling out in stages over the last few months and had been safely rolled back previously, an unrelated change prevented rollback from causing this problem in earlier stages.<p>We are reviewing and updating the feature flags in this event processing workflow to ensure that we have high confidence in rollback in all rollout stages.  We are also improving observability of the event processing to reduce the time to diagnose and mitigate similar issues going forward.</p></span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">17:27</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We are seeing recovery with the latest mitigation. Queue time for a very small percentage of larger runner jobs are still longer than expected so we are monitoring those for full recovery before going green.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">17:03</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We are actively applying mitigations to help improve larger runner start times. We are currently seeing delays starting about 25% of larger runner jobs.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">16:25</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We are still actively investigating a slowdown in larger runner assignment and are working to apply additional mitigations.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">15:33</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We're still applying mitigations to unblock queueing Actions in large runners. We are monitoring for full recovery.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">14:53</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We are applying further mitigations to fix the issues with delayed queuing for Actions jobs in large runners. We continue to monitor for full recovery.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">14:17</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We are investigating further mitigations for queueing Actions jobs in large runners. We continue to watch telemetry and are monitoring for full recovery.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">13:42</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>We've applied a mitigation to fix the issues with queuing and running Actions jobs. We are seeing improvements in telemetry and are monitoring for full recovery.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">13:09</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>The team continues to apply mitigations for issues with some Actions jobs delayed being enqueued for larger runners seen by a small number of customers. We will continue providing updates on the progress towards full mitigation.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">12:36</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>The team continues to apply mitigations for issues with some Actions jobs delayed being enqueued for larger runners. We will continue providing updates on the progress towards full mitigation.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">12:03</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>The team continues to investigate issues with some Actions jobs delayed being enqueued for larger runners. We will continue providing updates on the progress towards mitigation.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">11:31</var> UTC
        </small>
      </p>
      <p><strong>Update</strong> -
      	<span>The team continues to investigate issues with some Actions jobs having delays in being queued for larger runners. We will continue providing updates on the progress towards mitigation.</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">10:58</var> UTC
        </small>
      </p>
      <p><strong>Investigating</strong> -
      	<span>We are investigating reports of degraded performance for Actions</span>

        <br>

        <small>
            Jan <var data-var="date">23</var>, <var data-var="time">10:25</var> UTC
        </small>
      </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral Small 3 (585 pts)]]></title>
            <link>https://mistral.ai/news/mistral-small-3/</link>
            <guid>42877860</guid>
            <pubDate>Thu, 30 Jan 2025 14:16:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/mistral-small-3/">https://mistral.ai/news/mistral-small-3/</a>, See on <a href="https://news.ycombinator.com/item?id=42877860">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we’re introducing Mistral Small 3, a latency-optimized 24B-parameter model released under the Apache 2.0 license.</p><p><img src="https://mistral.ai/images/news/mistral-small-3/up-and-to-the-left.png" alt="Detailed benchmarks" width="77%"></p><p>Mistral Small 3 is competitive with larger models such as Llama 3.3 70B or Qwen 32B, and is an excellent open replacement for opaque proprietary models like GPT4o-mini. Mistral Small 3 is on par with Llama 3.3 70B instruct, while being more than 3x faster on the same hardware.</p><p>Mistral Small 3 is a pre-trained and instructed model catered to the ‘80%’ of generative AI tasks—those that require robust language and instruction following performance, with very low latency.</p><p>We designed this new model to saturate performance at a size suitable for local deployment. Particularly, Mistral Small 3 has far fewer layers than competing models, substantially reducing the time per forward pass. At over 81% accuracy on MMLU and 150 tokens/s latency, Mistral Small is currently the most efficient model of its category.</p><p>We’re releasing both a pretrained and instruction-tuned checkpoint under Apache 2.0. The checkpoints can serve as a powerful base for accelerating progress. Note that Mistral Small 3 is neither trained with RL nor synthetic data, so is earlier in the model production pipeline than models like Deepseek R1 (a great and complementary piece of open-source technology!). It can serve as a great base model for building accrued reasoning capacities. We look forward to seeing how the open-source community adopts and customizes it.</p><h3 id="performance">Performance</h3><h4 id="human-evaluations">Human Evaluations</h4><p><img src="https://mistral.ai/images/news/mistral-small-3/mistral-small-3-human-evals.png" alt="Detailed benchmarks" width="77%"></p><p>We conducted side by side evaluations with an external third-party vendor, on a set of over 1k proprietary coding and generalist prompts. Evaluators were tasked with selecting their preferred model response from anonymized generations produced by Mistral Small 3 vs another model. We are aware that in some cases the benchmarks on human judgement starkly differ from publicly available benchmarks, but have taken extra caution in verifying a fair evaluation. We are confident that the above benchmarks are valid.</p><h4 id="instruct-performance">Instruct performance</h4><p>Our instruction tuned model performs competitively with open weight models three times its size and with proprietary GPT4o-mini model across Code, Math, General knowledge and Instruction following benchmarks.</p><p><img src="https://mistral.ai/images/news/mistral-small-3/mistral-instruct-knowledge.png" alt="Detailed benchmarks" width="77%"></p><p><img src="https://mistral.ai/images/news/mistral-small-3/mistral-instruct-code-math.png" alt="Detailed benchmarks" width="77%"></p><p><img src="https://mistral.ai/images/news/mistral-small-3/mistral-instruct-IF.png" alt="Detailed benchmarks" width="77%"></p><p>Performance accuracy on all benchmarks were obtained through the same internal evaluation pipeline - as such, numbers may vary slightly from previously reported performance (<a href="https://qwenlm.github.io/blog/qwen2.5-llm/">Qwen2.5-32B-Instruct</a>, <a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct">Llama-3.3-70B-Instruct</a>, <a href="https://huggingface.co/google/gemma-2-27b-it">Gemma-2-27B-IT</a>). Judge based evals such as Wildbench, Arena hard and MTBench were based on gpt-4o-2024-05-13.</p><h4 id="pretraining-performance">Pretraining performance</h4><p><img src="https://mistral.ai/images/news/mistral-small-3/mistral-base-benchmarks.png" alt="Detailed benchmarks" width="77%"></p><p><img src="https://mistral.ai/images/news/mistral-small-3/mistral-base-mmlu-int.png" alt="Detailed benchmarks" width="77%"></p><p>Mistral Small 3, a 24B model, offers the best performance for its size class and rivals with models three times larger such as Llama 3.3 70B.</p><h3 id="when-to-use-mistral-small-3">When to use Mistral Small 3</h3><p>Across our customers and community, we are seeing several distinct use cases emerge for pre-trained models of this size:</p><ul><li>Fast-response conversational assistance: Mistral Small 3 excels in scenarios where quick, accurate responses are critical. This includes virtual assistants in many scenarios where users expect immediate feedback and near real-time interactions.</li><li>Low-latency function calling: Mistral Small 3 is able to handle rapid function execution when used as part of automated or agentic workflows.</li><li>Fine-tuning to create subject matter experts: Mistral Small 3 can be fine-tuned to specialize in specific domains, creating highly accurate subject matter experts. This is particularly useful in fields like legal advice, medical diagnostics, and technical support, where domain-specific knowledge is essential.</li><li>Local inference: Particularly beneficial for hobbyists and organizations handling sensitive or proprietary information. When quantized, Mistral Small 3 can be run privately on a single RTX 4090 or a Macbook with 32GB RAM.</li></ul><p>Our customers are evaluating Mistral Small 3 across multiple industries, including:</p><ul><li>Financial services customers for fraud detection</li><li>Healthcare providers for customer triaging</li><li>Robotics, automotive, and manufacturing companies for on-device command and control</li><li>Horizontal use cases across customers include virtual customer service, and sentiment and feedback analysis.</li></ul><h3 id="using-mistral-small-3-on-your-preferred-tech-stack">Using Mistral Small 3 on your preferred tech stack</h3><p>Mistral Small 3 is now available on la Plateforme as <code>mistral-small-latest</code> or <code>mistral-small-2501</code>. Explore our <a href="https://docs.mistral.ai/">docs</a> to learn how to use our models for text generation.</p><p>We are also excited to collaborate with Hugging Face, Ollama, Kaggle, Together AI, and Fireworks AI to make the model available on their platforms starting today:</p><ul><li><a href="https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501">Hugging Face</a> (<a href="https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501">base model</a>)</li><li><a href="https://ollama.com/library/mistral-small">Ollama</a></li><li><a href="https://www.kaggle.com/models/mistral-ai/mistral-small-24b">Kaggle</a></li><li><a href="https://www.together.ai/blog/mistral-small-3-api-now-available-on-together-ai-a-new-category-leader-in-small-models">Together AI</a></li><li><a href="https://fireworks.ai/models/fireworks/mistral-small-24b-instruct-2501">Fireworks AI</a></li><li>Coming soon on NVIDIA NIM, Amazon SageMaker, Groq, Databricks and Snowflake</li></ul><h3 id="the-road-ahead">The road ahead</h3><p>It’s been exciting days for the open-source community! Mistral Small 3 complements large open-source reasoning models like the recent releases of DeepSeek, and can serve as a strong base model for making reasoning capabilities emerge.</p><p>Among many other things, expect small and large Mistral models with boosted reasoning capabilities in the coming weeks. Join the journey if you’re keen (we’re hiring), or beat us to it by hacking Mistral Small 3 today and making it better!</p><h3 id="open-source-models-at-mistral">Open-source models at Mistral</h3><p><strong>We’re renewing our commitment to using Apache 2.0 license for our general purpose models, as we progressively move away from MRL-licensed models</strong>. As with Mistral Small 3, model weights will be available to download and deploy locally, and free to modify and use in any capacity. These models will also be made available through a serverless API on <a href="https://console.mistral.ai/">la Plateforme</a>, through our on-prem and VPC deployments, customisation and orchestration platform, and through our inference and cloud partners. Enterprises and developers that need specialized capabilities (increased speed and context, domain specific knowledge, task-specific models like code completion) can count on additional commercial models complementing what we contribute to the community.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Note on the Relationship Between Artificial Intelligence and Human Intelligence (494 pts)]]></title>
            <link>https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html</link>
            <guid>42877709</guid>
            <pubDate>Thu, 30 Jan 2025 14:01:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html">https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html</a>, See on <a href="https://news.ycombinator.com/item?id=42877709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										<td>
										
										
										
										
<p><span color="#663300"> 
          [</span><a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_ge.html">DE</a><span color="#663300"> 
          - 
          <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_en.html">EN</a> - 
          <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_sp.html">ES</a> - 
          <a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua-et-nova_it.html">IT</a>] </span></p> 
										
										
										
										
<p><span color="#663300">DICASTERY FOR THE DOCTRINE OF THE FAITH</span><b><br>
</b><span color="#663300">DICASTERY FOR CULTURE AND EDUCATION</span></p>

<p><span color="#663300" size="4"><b>ANTIQUA ET NOVA</b></span></p>
<p><span color="#663300"><b><i>Note</i> on the Relationship Between <br>
Artificial Intelligence and Human Intelligence</b></span></p>

<p>I. <b> <a name="Introduction">Introduction</a></b></p>
<p>1.&nbsp; With wisdom both ancient and new (cf. Mt. 13:52), we are called to reflect on 
the current challenges and opportunities posed by scientific and technological 
advancements, particularly by the recent development of Artificial Intelligence 
(AI). The Christian tradition regards the gift of intelligence as an essential aspect 
of how humans are created “in the image of God” (Gen. 1:27). Starting from an 
integral vision of the human person and the biblical calling to “till” and 
“keep” the earth (Gen. 2:15), the Church emphasizes that this gift of 
intelligence should be expressed through the responsible use of reason and 
technical abilities in the stewardship of the created world. </p>
<p>2. The Church encourages the advancement of science, technology, the arts, and 
other forms of human endeavor, viewing them as part of the “collaboration of man 
and woman with God in perfecting the visible creation.”<a name="_ftnref1" title="" href="#_ftn1">[1]</a> As Sirach affirms, God “gave skill to human beings, that he might be 
glorified in his marvelous works” (Sir. 38:6). Human abilities and creativity 
come from God and, when used rightly, glorify God by reflecting his wisdom and 
goodness. In light of this, when we ask ourselves what it means to “be human,” 
we cannot exclude a consideration of our scientific and technological abilities.</p>
<p>3. It is within this perspective that the present <i>Note</i> addresses the 
anthropological and ethical challenges raised by AI—issues that are particularly 
significant, as one of the goals of this technology is <i>to imitate the human 
intelligence that designed it. </i>For instance, unlike many other human 
creations, AI can be trained on the results of human creativity and then 
generate new “artifacts” with a level of speed and skill that often rivals or 
surpasses what humans can do, such as producing text or images indistinguishable 
from human compositions. This raises critical concerns about AI’s potential role 
in the growing crisis of truth in the public forum. Moreover, this technology is 
designed to learn and make certain choices autonomously, adapting to new 
situations and providing solutions not foreseen by its programmers, and thus, it 
raises fundamental questions about ethical responsibility and human safety, with 
broader implications for society as a whole. This new situation has prompted 
many people to reflect on what it means to be human and the role of humanity in 
the world.</p>
<p>4. Taking all this into account, there is broad consensus that AI marks a new and 
significant phase in humanity’s engagement with technology, placing it at the 
heart of what Pope Francis has described as an “epochal change.”<a name="_ftnref2" title="" href="#_ftn2">[2]</a> Its impact is felt globally and in a wide range of areas, including 
interpersonal relationships, education, work, art, healthcare, law, warfare, and 
international relations. As AI advances rapidly toward even greater 
achievements, it is critically important to consider its anthropological and 
ethical implications. This involves not only mitigating risks and preventing 
harm but also ensuring that its applications are used to promote human progress 
and the common good.</p>
<p>5. To contribute positively to the discernment regarding AI, and in response to 
Pope Francis’ call for a renewed “wisdom of heart,”<a name="_ftnref3" title="" href="#_ftn3">[3]</a> the Church offers its experience through the anthropological and ethical 
reflections contained in this <i>Note</i>. Committed to its active role in the 
global dialogue on these issues, the Church invites those entrusted with 
transmitting the faith—including parents, teachers, pastors, and bishops—to 
dedicate themselves to this critical subject with care and attention. While this 
document is intended especially for them, it is also meant to be accessible to a 
broader audience, particularly those who share the conviction that scientific 
and technological advances should be directed toward serving the human person 
and the common good.<a name="_ftnref4" title="" href="#_ftn4">[4]</a></p>
<p>6. To this end, the document begins by distinguishing between concepts of 
intelligence in AI and in human intelligence. It then explores the Christian 
understanding of human intelligence, providing a framework rooted in the 
Church’s philosophical and theological tradition. Finally, the document offers 
guidelines to ensure that the development and use of AI uphold human dignity and 
promote the integral development of the human person and society.</p>
<p>II. <b> <a name="What_is_Artificial_Intelligence">What is Artificial Intelligence?</a></b></p>
<p>7. The concept of “intelligence” in AI has evolved over time, drawing on a range of 
ideas from various disciplines. While its origins extend back centuries, a 
significant milestone occurred in 1956 when the American computer scientist John 
McCarthy organized a summer workshop at Dartmouth University to explore the 
problem of “Artificial Intelligence,” which he defined as “that of making a 
machine behave in ways that would be called intelligent if a human were so 
behaving.”<a name="_ftnref5" title="" href="#_ftn5"> [5]</a> This workshop launched a research program focused on designing machines 
capable of performing tasks typically associated with the human intellect and 
intelligent behavior.</p>
<p>8. Since then, AI research has advanced rapidly, leading to the development of 
complex systems capable of performing highly sophisticated tasks.<a name="_ftnref6" title="" href="#_ftn6">[6]</a> These so-called “narrow AI” systems are typically designed to handle 
specific and limited functions, such as translating languages, predicting the 
trajectory of a storm, classifying images, answering questions, or generating 
visual content at the user’s request. While the definition of “intelligence” in 
AI research varies, most contemporary AI systems—particularly those using 
machine learning—rely on statistical inference rather than logical deduction. By 
analyzing large datasets to identify patterns, AI can “predict”<a name="_ftnref7" title="" href="#_ftn7">[7]</a> outcomes and propose new approaches, mimicking some cognitive processes 
typical of human problem-solving. Such achievements have been made possible 
through advances in computing technology (including neural networks, 
unsupervised machine learning, and evolutionary algorithms) as well as hardware 
innovations (such as specialized processors). Together, these technologies 
enable AI systems to respond to various forms of human input, adapt to new 
situations, and even suggest novel solutions not anticipated by their original 
programmers.<a name="_ftnref8" title="" href="#_ftn8">[8]</a></p>
<p>9. Due to these rapid advancements, many tasks once managed exclusively by humans 
are now entrusted to AI. These systems can augment or even supersede what humans 
are able to do in many fields, particularly in specialized areas such as data 
analysis, image recognition, and medical diagnosis. While each “narrow AI” 
application is designed for a specific task, many researchers aspire to develop 
what is known as “Artificial General Intelligence” (AGI)—a single system capable 
of operating across all cognitive domains and performing any task within the 
scope of human intelligence. Some even argue that AGI could one day achieve the 
state of “superintelligence,” surpassing human intellectual capacities, or 
contribute to “super-longevity” through advances in biotechnology. Others, 
however, fear that these possibilities, even if hypothetical, could one day 
eclipse the human person, while still others welcome this potential 
transformation.<a name="_ftnref9" title="" href="#_ftn9">[9]</a></p>
<p>10. Underlying this and 
many other perspectives on the subject is the implicit assumption that the term 
“intelligence” can be used in the same way to refer to both human intelligence 
and AI. Yet, this does not capture the full scope of the concept. In the case of humans, 
intelligence is a faculty that pertains to the person in his or her entirety, 
whereas in the context of AI, “intelligence” is understood functionally, often 
with the presumption that the activities characteristic of the human mind can be 
broken down into digitized steps that machines can replicate.<a name="_ftnref10" title="" href="#_ftn10">[10]</a></p>
<p>11. This functional 
perspective is exemplified by the “Turing Test,” which considers a machine 
“intelligent” if a person cannot distinguish its behavior from that of a human.<a name="_ftnref11" title="" href="#_ftn11">[11]</a> However, in this context, the term “behavior” refers only to the 
performance of specific intellectual tasks; it does not account for the full 
breadth of human experience, which includes abstraction, emotions, creativity, 
and the aesthetic, moral, and religious sensibilities. Nor does it encompass the 
full range of expressions characteristic of the human mind. Instead, in the case 
of AI, the “intelligence” of a system is evaluated methodologically, but also 
reductively, based on its<i> ability to produce appropriate responses—in this 
case, those associated with the human intellect—regardless of how those 
responses are generated</i>.</p>
<p>12. AI’s advanced features 
give it sophisticated abilities to <i>perform tasks</i>, but not the ability to
<i>think</i>.<a name="_ftnref12" title="" href="#_ftn12">[12]</a> This distinction is crucially important, as the way “intelligence” is 
defined inevitably shapes how we understand the relationship between human 
thought and this technology.<a name="_ftnref13" title="" href="#_ftn13">[13]</a> To appreciate this, one must recall the richness of the philosophical 
tradition and Christian theology, which offer a deeper and more comprehensive 
understanding of intelligence—an understanding that is central to the Church’s 
teaching on the nature, dignity, and vocation of the human person.<a name="_ftnref14" title="" href="#_ftn14">[14]</a></p>
<p>III. <b> <a name="Intelligence_in_the_Philosophical">Intelligence in the Philosophical</a> and Theological Tradition</b></p>
<p><i><a name="Rationality">Rationality</a></i></p>
<p>13. From the dawn of human 
self-reflection, the mind has played a central role in understanding what it 
means to be “human.” Aristotle observed that “all people by nature desire to 
know.”<a name="_ftnref15" title="" href="#_ftn15">[15]</a> This knowledge, with its capacity for abstraction that grasps the nature 
and meaning of things, sets humans apart from the animal world.<a name="_ftnref16" title="" href="#_ftn16">[16]</a> As philosophers, theologians, and psychologists have examined the exact 
nature of this intellectual faculty, they have also explored how humans 
understand the world and their unique place within it. Through this exploration, 
the Christian tradition has come to understand the human person as a being 
consisting of both body and soul—deeply connected to this world and yet 
transcending it.<a name="_ftnref17" title="" href="#_ftn17">[17]</a></p>
<p>14. In the classical 
tradition, the concept of intelligence is often understood through the 
complementary concepts of “reason” (<i>ratio</i>) and “intellect” (<i>intellectus</i>). 
These are not separate faculties but, as Saint Thomas Aquinas explains, they are 
two modes in which the same intelligence operates: “The term <i>intellect</i> is 
inferred from the inward grasp of the truth, while the name <i>reason</i> is 
taken from the inquisitive and discursive process.”<a name="_ftnref18" title="" href="#_ftn18">[18]</a> This concise description highlights the two fundamental and complementary 
dimensions of human intelligence. <i>Intellectus</i> refers to the intuitive 
grasp of the truth—that is, apprehending it with the “eyes” of the mind—which 
precedes and grounds argumentation itself. <i>Ratio</i> pertains to reasoning 
proper: the discursive, analytical process that leads to judgment. Together, 
intellect and reason form the two facets of the act of <i>intelligere</i>, “the 
proper operation of the human being as such.”<a name="_ftnref19" title="" href="#_ftn19">[19]</a></p>
<p>15. Describing the human 
person as a “rational” being does not reduce the person to a specific mode of 
thought; rather, it recognizes that the ability for intellectual understanding 
shapes and permeates all aspects of human activity.<a name="_ftnref20" title="" href="#_ftn20"> [20]</a> Whether exercised well or poorly, this capacity is an intrinsic aspect of 
human nature. In this sense, the “term ‘rational’ encompasses all the capacities 
of the human person,” including those related to “knowing and understanding, as 
well as those of willing, loving, choosing, and desiring; it also includes all 
corporeal functions closely related to these abilities.”<a name="_ftnref21" title="" href="#_ftn21"> [21]</a>&nbsp;This comprehensive perspective underscores how, in the human person, 
created in the “image of God,” reason is integrated in a way that elevates, 
shapes, and transforms both the person’s will and actions.<a name="_ftnref22" title="" href="#_ftn22"> [22]</a></p>
<p><i><a name="Embodiment">Embodiment</a></i></p>
<p>16. Christian thought 
considers the intellectual faculties of the human person within the framework of 
an integral anthropology that views the human being as essentially embodied. In 
the human person, spirit and matter “are not two natures united, but rather 
their union forms a single nature.”<a name="_ftnref23" title="" href="#_ftn23">[23]</a>&nbsp;In other words, the soul is not merely the immaterial “part” of the person 
contained within the body, nor is the body an outer shell housing an intangible 
“core.” Rather, the entire human person is simultaneously both material and 
spiritual. This understanding reflects the teaching of Sacred Scripture, which 
views the human person as a being who lives out relationships with God and 
others (and thus, an authentically spiritual dimension) within and through this 
embodied existence.<a name="_ftnref24" title="" href="#_ftn24">[24]</a>&nbsp;The profound meaning of this condition is further illuminated by the 
mystery of the Incarnation, through which God himself took on our flesh and 
“raised it up to a sublime dignity.”<a name="_ftnref25" title="" href="#_ftn25">[25]</a></p>
<p>17. Although deeply rooted 
in bodily existence, the human person transcends the material world through the 
soul, which is “almost on the horizon of eternity and time.”<a name="_ftnref26" title="" href="#_ftn26">[26]</a>&nbsp;The intellect's capacity for transcendence and the self-possessed freedom 
of the will belong to the soul, by which the human person “shares in the light 
of the divine mind.”<a name="_ftnref27" title="" href="#_ftn27">[27]</a>&nbsp;Nevertheless, the human spirit does not exercise its normal mode of 
knowledge without the body.<a name="_ftnref28" title="" href="#_ftn28">[28]</a>&nbsp;In this way, the intellectual faculties of the human person are an 
integral part of an anthropology that recognizes that the human person is a 
“unity of body and soul.”<a name="_ftnref29" title="" href="#_ftn29">[29]</a>&nbsp;Further aspects of this understanding will be developed in what follows.</p>
<p><i><a name="Relationality">Relationality</a></i></p>
<p>18. &nbsp;Human 
beings are “ordered by their very nature to interpersonal communion,”<a name="_ftnref30" title="" href="#_ftn30">[30]</a> 
&nbsp;possessing the capacity to know one another, to give themselves in love, and to 
enter into communion with others. Accordingly, human intelligence is not an 
isolated faculty but is exercised in relationships, finding its fullest 
expression in dialogue, collaboration, and solidarity. We learn with others, and 
we learn through others.</p>
<p>19. The relational orientation of the human person is ultimately grounded in the 
eternal self-giving of the Triune God, whose love is revealed in creation and 
redemption.<a name="_ftnref31" title="" href="#_ftn31">[31]</a>&nbsp;The human person is “called to share, by knowledge and love, in God’s own 
life.”<a name="_ftnref32" title="" href="#_ftn32">[32]</a></p>
<p>20. This vocation to 
communion with God is necessarily tied to the call to communion with others. 
Love of God cannot be separated from love for one’s neighbor (cf. 1 Jn. 4:20; 
Mt. 22:37-39). By the grace of sharing God’s life, Christians are also called to 
imitate Christ’s outpouring gift (cf. 2 Cor. 9:8-11; Eph. 5:1-2) by following 
his command to “love one another, as I have loved you” (Jn.&nbsp;13:34).<a name="_ftnref33" title="" href="#_ftn33">[33]</a>&nbsp;Love and service, echoing the divine life of self-giving, transcend 
self-interest to respond more fully to the human vocation (cf. 1 Jn. 2:9). Even 
more sublime than knowing many things is the commitment to care for one another, 
for if “I understand all mysteries and all knowledge 
[...] but do not have love, I am nothing” (1 Cor. 13:2).</p>
<p><i><a name="Relationship_with_the_Truth">Relationship with the Truth</a></i></p>
<p>21. Human intelligence is ultimately “God’s gift fashioned for the assimilation of 
truth.”<a name="_ftnref34" title="" href="#_ftn34">[34]</a>In the dual sense of <i>intellectus</i>-<i>ratio</i>, it enables the person to 
explore realities that surpass mere sensory experience or utility, since “the 
desire for truth is part of human nature itself. It is an innate property of 
human reason to ask why things are as they are.”<a name="_ftnref35" title="" href="#_ftn35">[35]</a>&nbsp;Moving beyond the limits of empirical data, human intelligence can “with 
genuine certitude attain to reality itself as knowable.”<a name="_ftnref36" title="" href="#_ftn36">[36]</a>&nbsp;While reality remains only partially known, the desire for truth “spurs 
reason always to go further; indeed, it is as if reason were overwhelmed to see 
that it can always go beyond what it has already achieved.”<a name="_ftnref37" title="" href="#_ftn37">[37]</a>&nbsp;Although Truth in itself transcends the boundaries of human intelligence, 
it irresistibly attracts it.<a name="_ftnref38" title="" href="#_ftn38">[38]</a>&nbsp;Drawn by this attraction, the human person is led to seek “truths of a 
higher order.”<a name="_ftnref39" title="" href="#_ftn39">[39]</a></p>
<p>22. &nbsp;This innate drive toward the pursuit of truth is especially evident in the 
distinctly human capacities for semantic understanding and creativity,<a name="_ftnref40" title="" href="#_ftn40">[40]</a>&nbsp;through which this search unfolds in a “manner that is appropriate to the 
social nature and dignity of the human person.”<a name="_ftnref41" title="" href="#_ftn41">[41]</a>&nbsp;Likewise, a steadfast orientation to the truth is essential for charity to 
be both authentic and universal.<a name="_ftnref42" title="" href="#_ftn42">[42]</a></p>
<p>23. The search for truth 
finds its highest expression in openness to realities that transcend the 
physical and created world. In God, all truths attain their ultimate and original meaning.<a name="_ftnref43" title="" href="#_ftn43">[43]</a>&nbsp;Entrusting oneself to God is a “fundamental decision that engages the 
whole person.”<a name="_ftnref44" title="" href="#_ftn44">[44]</a><a name="_Hlk181548087">
</a>In this way, the human person becomes fully what he 
or she is called to be: “the intellect and the will display their spiritual 
nature,” enabling the person “to act in a way that realizes personal freedom to 
the full.”<a name="_ftnref45" title="" href="#_ftn45">[45]</a></p>
<p><i><a name="Stewardship_of_the_World">Stewardship of the World</a></i></p>
<p>24. The Christian faith 
understands creation as the free act of the Triune God, who, as Saint 
Bonaventure of Bagnoregio explains, creates “not to increase his glory, but to 
show it forth and to communicate it.”<a name="_ftnref46" title="" href="#_ftn46">[46]</a>&nbsp;Since God creates according to his Wisdom (cf. Wis. 9:9; Jer. 10:12), 
creation is imbued with an intrinsic order that reflects God’s plan (cf. Gen. 1; 
Dan. 2:21-22; Is. 45:18; Ps. 74:12-17; 104),<a name="_ftnref47" title="" href="#_ftn47">[47]</a>&nbsp;within which God has called human beings to assume a unique role: <i>to</i>
<i>cultivate and care for the world</i>.<a name="_ftnref48" title="" href="#_ftn48">[48]</a></p>
<p>25. Shaped by the Divine 
Craftsman, humans live out their identity as beings made <i>in imago Dei</i> by 
“keeping” and “tilling” (cf. Gen. 2:15) creation—using their intelligence and 
skills to care for and develop creation in accord with God’s plan.<a name="_ftnref49" title="" href="#_ftn49">[49]</a>&nbsp;In this, human intelligence reflects the Divine 
Intelligence that created all things (cf. Gen. 1-2; Jn. 1),<a name="_ftnref50" title="" href="#_ftn50">[50]</a>&nbsp;continuously sustains them, and guides them to their ultimate purpose in 
him.<a name="_ftnref51" title="" href="#_ftn51">[51]</a>&nbsp;Moreover, human beings are called to develop their abilities in science 
and technology, for through them, God is glorified (cf<i>. </i>Sir.<i> </i>
38:6). Thus, in a proper relationship with creation, humans, on the one hand, 
use their intelligence and skill to cooperate with God in guiding creation 
toward the purpose to which he has called it.<a name="_ftnref52" title="" href="#_ftn52">[52]</a> On the other hand, creation itself, as Saint Bonaventure observes, helps 
the human mind to “ascend gradually to the supreme Principle, who is God.”<a name="_ftnref53" title="" href="#_ftn53">[53]</a></p>
<p><i><a name="An_Integral">An Integral</a> Understanding of Human Intelligence</i></p>
<p>26. In this context, human 
intelligence becomes more clearly understood as a faculty that forms an integral 
part of how the whole person engages with reality. Authentic engagement requires 
embracing the full scope of one’s being: spiritual, cognitive, embodied, and 
relational.</p>
<p>27. This engagement with 
reality unfolds in various ways, as each person, in his or her multifaceted 
individuality<a name="_ftnref54" title="" href="#_ftn54">[54]</a>, seeks to understand the world, relate to others, solve problems, express 
creativity, and pursue integral well-being through the harmonious interplay of 
the various dimensions of the person’s intelligence.<a name="_ftnref55" title="" href="#_ftn55">[55]</a>&nbsp;This involves logical and linguistic abilities but can also encompass 
other modes of interacting with reality. Consider the work of an artisan, who 
“must know how to discern, in inert matter, a particular form that others cannot 
recognize”<a name="_ftnref56" title="" href="#_ftn56">[56]</a>&nbsp;and bring it forth through insight and practical skill. Indigenous peoples 
who live close to the earth often possess a profound sense of nature and its 
cycles.<a name="_ftnref57" title="" href="#_ftn57">[57]</a>&nbsp;Similarly, a friend who knows the right word to say or a person adept at 
managing human relationships exemplifies an intelligence that is “the fruit of 
self-examination, dialogue and generous encounter between persons.”<a name="_ftnref58" title="" href="#_ftn58">[58]</a>&nbsp;As Pope Francis observes, “in this age of artificial intelligence, we 
cannot forget that poetry and love are necessary to save our humanity.”<a name="_ftnref59" title="" href="#_ftn59">[59]</a></p>
<p>28. At the heart of the 
Christian understanding of intelligence is the integration of truth into the 
moral and spiritual life of the person, guiding his or her actions in light of 
God’s goodness and truth. According to God’s plan, 
intelligence, in its fullest sense, also includes the ability to savor what is 
true, good, and beautiful. As the twentieth-century 
French poet Paul Claudel expressed, “intelligence is nothing without delight.”<a name="_ftnref60" title="" href="#_ftn60">[60]</a> 
Similarly, Dante, upon reaching the highest heaven in <i>Paradiso</i>, testifies 
that the culmination of this intellectual delight is found in the “light 
intellectual full of love, love of true good filled with joy, joy which 
transcends every sweetness.”<a name="_ftnref61" title="" href="#_ftn61">[61]</a></p>
<p>29. A proper understanding 
of human intelligence, therefore, cannot be reduced to the mere acquisition of 
facts or the ability to perform specific tasks. Instead, it involves the 
person’s openness to the ultimate questions of life and reflects an orientation 
toward the True and the Good.<a name="_ftnref62" title="" href="#_ftn62">[62]</a>&nbsp;As an expression of the divine image within the person, human intelligence 
has the ability to access the totality of being, contemplating existence in its 
fullness, which goes beyond what is measurable, and grasping the meaning of what 
has been understood. For believers, this capacity includes, in a particular way, 
the ability to grow in the knowledge of the mysteries of God by using reason to 
engage ever more profoundly with revealed truths (<i>intellectus fidei</i>).<a name="_ftnref63" title="" href="#_ftn63">[63]</a>&nbsp;True intelligence is shaped by divine love, which “is poured forth in our 
hearts by the Holy Spirit” (Rom. 5:5). From this, it follows that human 
intelligence possesses an essential <i>contemplative </i>dimension, an unselfish 
openness to the True, the Good, and the Beautiful, beyond any utilitarian 
purpose.</p>
<p><i><a name="The_Limits_of_AI">The Limits of AI</a></i></p>
<p>30. In light of the 
foregoing discussion, the differences between human intelligence and current AI 
systems become evident. While AI is an extraordinary technological achievement capable of imitating 
certain outputs associated with human intelligence, it operates by performing 
tasks, achieving goals, or making decisions based on quantitative data and 
computational logic. For example, with its analytical power, AI excels at 
integrating data from a variety of fields, modeling complex systems, and 
fostering interdisciplinary connections. In this way, it can help experts 
collaborate in solving complex problems that “cannot be dealt with from a single 
perspective or from a single set of interests.”<a name="_ftnref64" title="" href="#_ftn64">[64]</a></p>
<p>31. However, even as AI 
processes and simulates certain expressions of intelligence, it remains 
fundamentally confined to a logical-mathematical framework, which imposes 
inherent limitations. Human intelligence, in contrast, develops organically 
throughout the person’s physical and psychological growth, shaped by a myriad of 
lived experiences in the flesh. Although advanced AI systems can “learn” through processes such as machine 
learning, this sort of training is fundamentally different from the 
developmental growth of human intelligence, which is shaped by embodied 
experiences, including sensory input, emotional responses, social interactions, 
and the unique context of each moment. These elements shape and form individuals 
within their personal history.<b></b>In contrast, AI, lacking a physical body, relies on computational reasoning and 
learning based on vast datasets that include recorded human experiences and 
knowledge. </p>
<p>32. Consequently, although 
AI can simulate aspects of human reasoning and perform specific tasks with incredible speed and efficiency, its computational 
abilities represent only a fraction of the broader capacities of the human mind. 
For instance, AI cannot currently replicate moral discernment or the ability to 
establish authentic relationships. Moreover, human intelligence is situated 
within a personally lived history of intellectual and moral formation that 
fundamentally shapes the individual’s perspective, encompassing the physical, emotional, social, moral, 
and spiritual dimensions of life. Since AI cannot offer this fullness of 
understanding, approaches that rely solely on this technology or treat it as the 
primary means of interpreting the world can lead to “a loss of appreciation for 
the whole, for the relationships between things, and for the broader horizon.”<a name="_ftnref65" title="" href="#_ftn65">[65]</a></p>
<p>33. Human intelligence is 
not primarily about completing functional tasks but about understanding and 
actively engaging with reality in all its dimensions; it is also capable of 
surprising insights. Since AI lacks the richness of corporeality, relationality, 
and the openness of the human heart to truth and goodness, its capacities—though 
seemingly limitless—are incomparable with the human ability to grasp reality. So 
much can be learned from an illness, an embrace of reconciliation, and even a 
simple sunset; indeed, many experiences we have as humans open new horizons and 
offer the possibility of attaining new wisdom. No device, working solely with 
data, can measure up to these and countless other experiences present in our 
lives.</p>
<p>34. Drawing an overly 
close equivalence between human intelligence and AI risks succumbing to a 
functionalist perspective, where people are valued based on the work they can 
perform. However, a person’s worth does not depend on possessing specific 
skills, cognitive and technological achievements, or individual success, but on 
the person’s inherent dignity, grounded in being created in the image of God.<a name="_ftnref66" title="" href="#_ftn66">[66]</a>&nbsp;This dignity remains intact in all circumstances, including 
for those unable 
to exercise their abilities, whether it be an unborn child, an unconscious 
person, or an older person who is suffering.<a name="_ftnref67" title="" href="#_ftn67"> [67]</a>&nbsp;It 
also underpins the tradition of human rights (and, in particular, 
what are now called “neuro-rights”), which represent “an important point of 
convergence in the search for common ground”<a name="_ftnref68" title="" href="#_ftn68">[68]</a>&nbsp;and can, thus, serve as a fundamental ethical guide in discussions on the 
responsible development and use of AI.</p>
<p>35. Considering all these 
points, as Pope Francis observes, “the very use of the word ‘intelligence’” in 
connection with AI “can prove misleading”<a name="_ftnref69" title="" href="#_ftn69">[69]</a>&nbsp;and risks overlooking what is most precious in the human person. In light 
of this, AI should not be seen as <i>an artificial form </i>of<i> </i>human 
intelligence but as<i> a product </i>of<i> </i>it.<a name="_ftnref70" title="" href="#_ftn70">[70]</a></p>
<p>IV. <b> <a name="The_Role_of_Ethics">The Role of Ethics</a> in Guiding the Development and Use of AI</b></p>
<p>36. Given these 
considerations, one can ask how AI can be understood within God’s plan. To answer this, it is important to recall that 
techno-scientific activity is not neutral in character but is a <i>human </i>
endeavor that engages the humanistic and cultural dimensions of human 
creativity.<a name="_ftnref71" title="" href="#_ftn71">[71]</a></p>
<p>37. Seen as a fruit of the 
potential inscribed within human intelligence,<a name="_ftnref72" title="" href="#_ftn72">[72]</a>&nbsp;scientific inquiry and the development of technical skills are part of the 
“collaboration of man and woman with God in perfecting the visible creation.”<a name="_ftnref73" title="" href="#_ftn73">[73]</a>&nbsp;At the same time, all scientific and technological achievements are, 
ultimately, gifts from God.<a name="_ftnref74" title="" href="#_ftn74">[74]</a>&nbsp;Therefore, human beings must always use their abilities in view of the 
higher purpose for which God has granted them.<a name="_ftnref75" title="" href="#_ftn75">[75]</a></p>
<p>38. We can gratefully 
acknowledge how technology has “remedied countless evils which used to harm and 
limit human beings,”<a name="_ftnref76" title="" href="#_ftn76">[76]</a>&nbsp;a fact for which we should rejoice. Nevertheless, not all technological 
advancements in themselves represent genuine human progress.<a name="_ftnref77" title="" href="#_ftn77">[77]</a>&nbsp;The Church is particularly opposed to those applications that threaten the 
sanctity of life or the dignity of the human person.<a name="_ftnref78" title="" href="#_ftn78">[78]</a>&nbsp;Like any human endeavor, technological development must be directed to 
serve the human person and contribute to the pursuit of “greater justice, more 
extensive fraternity, and a more humane order of social relations,” which are 
“more valuable than advances in the technical field.”<a name="_ftnref79" title="" href="#_ftn79">[79]</a>&nbsp;Concerns about the ethical implications of technological development are 
shared not only within the Church but also among many scientists, technologists, 
and professional associations, who increasingly call for ethical reflection to 
guide this development in a responsible way. </p>
<p>39. To address these 
challenges, it is essential to emphasize <i>the importance of moral 
responsibility grounded in the dignity and vocation of the human person</i>. 
This guiding principle also applies to questions concerning AI. In this context, 
the ethical dimension takes on primary importance because it is people who 
design systems and determine the purposes for which they are used.<a name="_ftnref80" title="" href="#_ftn80">[80]</a>&nbsp;Between a machine and a human being, only the latter is truly a moral 
agent—a subject of moral responsibility who exercises freedom in his or her 
decisions and accepts their consequences.<a name="_ftnref81" title="" href="#_ftn81">[81]</a>&nbsp;It is not the machine but the human who is in relationship with truth and 
goodness, guided by a moral conscience that calls the person “to love and to do 
what is good and to avoid evil,”<a name="_ftnref82" title="" href="#_ftn82">[82]</a>&nbsp;bearing witness to “the authority of truth in reference to the supreme 
Good to which the human person is drawn.”<a name="_ftnref83" title="" href="#_ftn83">[83]</a>&nbsp;Likewise, between a machine and a human, only the human can be 
sufficiently self-aware to the point of listening and following the voice of 
conscience, discerning with prudence, and seeking the good that is possible in 
every situation.<a name="_ftnref84" title="" href="#_ftn84">[84]</a>&nbsp;In fact, all of this also belongs to the person’s exercise of 
intelligence.</p>
<p>40. Like any product of 
human creativity, AI can be directed toward positive or negative ends.<a name="_ftnref85" title="" href="#_ftn85">[85]</a>&nbsp;When used in ways that respect human dignity and promote the well-being of 
individuals and communities, it can contribute positively to the human vocation.
Yet, as in all areas where humans are called to make 
decisions, the shadow of evil also looms here. Where human freedom allows for 
the possibility of choosing what is wrong, the moral evaluation of this 
technology will need to take into account how it is directed and used.</p>
<p>41. At the same time, it 
is not only the ends that are ethically significant but also the means employed 
to achieve them. Additionally, the overall vision and understanding of the human 
person embedded within these systems are important to consider as well. 
Technological products reflect the worldview of their developers, owners, users, 
and regulators,<a name="_ftnref86" title="" href="#_ftn86">[86]</a>&nbsp;and have the power to “shape the world and engage consciences on the level 
of values.”<a name="_ftnref87" title="" href="#_ftn87">[87]</a>&nbsp;On a societal level, some technological developments could also reinforce 
relationships and power dynamics that are inconsistent with a proper 
understanding of the human person and society. </p>
<p>42. Therefore, the ends 
and the means used in a given application of AI, as well as the overall vision 
it incorporates, must all be evaluated to ensure they respect human dignity and 
promote the common good.<a name="_ftnref88" title="" href="#_ftn88">[88]</a>&nbsp;As Pope Francis has stated, “the intrinsic dignity of every man and every 
woman” must be “the key criterion in evaluating emerging technologies; these 
will prove ethically sound to the extent that they help respect that dignity and 
increase its expression at every level of human life,”<a name="_ftnref89" title="" href="#_ftn89">[89]</a>&nbsp;including in the social and economic spheres. In this sense, human 
intelligence plays a crucial role not only in designing and producing technology 
but also in directing its use in line with the authentic good of the human 
person.<a name="_ftnref90" title="" href="#_ftn90">[90]</a>&nbsp;The responsibility for managing this wisely pertains to every level of 
society, guided by the principle of subsidiarity and other principles of 
Catholic Social Teaching. </p>
<p><i><a name="Helping_Human">Helping Human</a> Freedom and Decision-Making</i></p>
<p>43. The commitment to 
ensuring that <i>AI always supports and promotes the supreme value of the 
dignity of every human being and the fullness of the human vocation</i> serves 
as a criterion of discernment for developers, owners, operators, and regulators 
of AI, as well as to its users. It remains valid for every application of the 
technology at every level of its use.</p>
<p>44. An evaluation of the 
implications of this guiding principle could begin by considering the importance 
of <i>moral responsibility. </i>Since full moral causality belongs only to <i>
personal</i> agents, not artificial ones, it is crucial to be able to identify 
and define who bears responsibility for the processes involved in AI, 
particularly those capable of learning, correction, and reprogramming. While 
bottom-up approaches and very deep neural networks enable AI to solve complex 
problems, they make it difficult to understand the processes that lead to the 
solutions they adopted. This complicates accountability since if an AI 
application produces undesired outcomes, determining who is responsible becomes 
difficult. To address this problem, attention needs to be given to the nature of
<i>accountability </i>processes in complex, highly automated settings, where 
results may only become evident in the medium to long term. For this, it is 
important that ultimate responsibility for decisions made using AI rests with 
the human decision-makers and that there is accountability for the use of AI at 
each stage of the decision-making process.<a name="_ftnref91" title="" href="#_ftn91">[91]</a></p>
<p>45. In addition to 
determining who is responsible, it is essential to identify the objectives 
given to AI systems. Although these systems may use unsupervised autonomous 
learning mechanisms and sometimes follow paths that humans cannot reconstruct, 
they ultimately pursue goals that humans have assigned to them and are governed 
by processes established by their designers and programmers. Yet, this presents 
a challenge because, as AI models become increasingly capable of independent 
learning, the ability to maintain control over them to ensure that such 
applications serve human purposes may effectively diminish. This raises the 
critical question of how to ensure that AI systems are ordered for the good of 
people and not against them. </p>
<p>46. While responsibility 
for the ethical use of AI systems starts with those who develop, produce, 
manage, and oversee such systems, it is also shared by those who use them. As Pope 
Francis noted, the machine “makes a technical choice among several possibilities 
based either on well-defined criteria or on statistical inferences. Human 
beings, however, not only choose, but in their hearts are capable of deciding.”<a name="_ftnref92" title="" href="#_ftn92">[92]</a>&nbsp;Those who use AI to accomplish a task and follow its results create a 
context in which they are ultimately responsible for the power they have 
delegated. Therefore, insofar as AI can assist humans in making decisions, the 
algorithms that govern it should be trustworthy, secure, robust enough to handle 
inconsistencies, and transparent in their operation to mitigate biases and 
unintended side effects.<a name="_ftnref93" title="" href="#_ftn93">[93]</a>&nbsp;Regulatory frameworks should ensure that all legal entities remain 
accountable for the use of AI and all its consequences, with appropriate 
safeguards for transparency, privacy, and accountability.<a name="_ftnref94" title="" href="#_ftn94">[94]</a>&nbsp;Moreover, those using AI should be careful not to become overly dependent 
on it for their decision-making, a trend that increases contemporary society’s 
already high reliance on technology.</p>
<p>47. The Church’s moral and 
social teaching provides resources to help ensure that AI is used in a way that 
preserves human agency. Considerations about justice, for example, should also 
address issues such as fostering just social dynamics, upholding international 
security, and promoting peace. By exercising prudence, individuals and 
communities can discern ways to use AI to benefit humanity while avoiding 
applications that could degrade human dignity or harm the environment. In this 
context, the concept of responsibility should be understood not only in its most 
limited sense but as a “responsibility for the care for others, which is more 
than simply accounting for results achieved.”<a name="_ftnref95" title="" href="#_ftn95">[95]</a></p>
<p>48. Therefore, AI, like 
any technology, can be part of a conscious and responsible answer to humanity’s 
vocation to the good. However, as previously discussed, AI must be directed by 
human intelligence<i> </i>to align with this vocation, ensuring it respects the 
dignity of the human person. Recognizing this “exalted dignity,” the Second 
Vatican Council affirmed that “the social order and its development must 
invariably work to the benefit of the human person.”<a name="_ftnref96" title="" href="#_ftn96">[96]</a>&nbsp;In light of this, the use of AI, as Pope Francis said, must be 
“accompanied by an ethic inspired by a vision of the common good, an ethic of 
freedom, responsibility, and fraternity, capable of fostering the full 
development of people in relation to others and to the whole of creation.”<a name="_ftnref97" title="" href="#_ftn97">[97]</a></p>
<p>V. <b> <a name="Specific_Questions">Specific Questions</a></b></p>
<p>49. Within this general 
perspective, some observations follow below to illustrate how the preceding 
arguments can help provide an ethical orientation in practical situations, in 
line with the “wisdom of heart” that Pope Francis has proposed.<a name="_ftnref98" title="" href="#_ftn98">[98]</a> 
While not exhaustive, this discussion is offered in service of the dialogue that 
considers how AI can be used to uphold the dignity of the human person and 
promote the common good.<a name="_ftnref99" title="" href="#_ftn99">[99]</a></p>
<p><i><a name="AI_and_Society">AI and Society</a></i></p>
<p>50. As Pope Francis 
observed, “the inherent dignity of each human being and the fraternity that 
binds us together as members of the one human family must undergird the 
development of new technologies and serve as indisputable criteria for 
evaluating them before they are employed<a name="_Int_Zt1Jg2IN">.”</a><a name="_ftnref100" title="" href="#_ftn100">[100]</a></p>
<p>51. Viewed through this 
lens, AI could “introduce important innovations in agriculture, education and 
culture, an improved level of life for entire nations and peoples, and the 
growth of human fraternity and social friendship,” and thus be “used to promote 
integral human development.”<a name="_ftnref101" title="" href="#_ftn101">[101]</a>&nbsp;AI could also help organizations identify those in need and counter 
discrimination and marginalization. These and other similar applications of this 
technology could contribute to human development and the common good.<a name="_ftnref102" title="" href="#_ftn102">[102]</a></p>
<p>52. However, while AI 
holds many possibilities for promoting the good, it can also hinder or even 
counter human development and the common good. Pope Francis has noted that 
“evidence to date suggests that digital technologies have increased inequality 
in our world. Not just differences in material wealth, which are also 
significant, but also differences in access to political and social influence.”<a name="_ftnref103" title="" href="#_ftn103">[103]</a>&nbsp;In this sense, AI could be used to perpetuate marginalization and 
discrimination, create new forms of poverty, widen the “digital divide,” and 
worsen existing social inequalities.<a name="_ftnref104" title="" href="#_ftn104">[104]</a></p>
<p>53. Moreover, the 
concentration of the power over mainstream AI applications in the hands of a few 
powerful companies raises significant ethical concerns. Exacerbating this 
problem is the inherent nature of AI systems, where no single individual can 
exercise complete oversight over the vast and complex datasets used for 
computation. This lack of well-defined accountability creates the risk that AI 
could be manipulated for personal or corporate gain or to direct public opinion 
for the benefit of a specific industry. Such entities, motivated by their own 
interests, possess the capacity to exercise “forms of control as subtle as they 
are invasive, creating mechanisms for the manipulation of consciences and of the 
democratic process.”<a name="_ftnref105" title="" href="#_ftn105">[105]</a></p>
<p>54. &nbsp;Furthermore, there is 
the risk of AI being used to promote what Pope Francis has called the 
“technocratic paradigm,” which perceives all the world’s problems as solvable 
through technological means alone.<a name="_ftnref106" title="" href="#_ftn106">[106]</a>&nbsp;In this paradigm, human dignity and fraternity are often set aside in the 
name of efficiency, “as if reality, goodness, and truth automatically flow from 
technological and economic power as such.”<a name="_ftnref107" title="" href="#_ftn107">[107]</a>&nbsp;Yet, human dignity and the common good must never be violated for the sake 
of efficiency,<a name="_ftnref108" title="" href="#_ftn108">[108]</a>&nbsp;for “technological developments that do not lead to an improvement in the 
quality of life of all humanity, but on the contrary, aggravate inequalities and 
conflicts, can never count as true progress.”<a name="_ftnref109" title="" href="#_ftn109">[109]</a>&nbsp;Instead, AI should be put “at the service of another type of progress, one 
which is healthier, more human, more social, more integral.”<a name="_ftnref110" title="" href="#_ftn110">[110]</a></p>
<p>55. Achieving 
this objective requires a deeper reflection on the relationship between autonomy 
and responsibility. Greater autonomy heightens each person’s responsibility 
across various aspects of communal life. For Christians, the foundation of this 
responsibility lies in the recognition that all human capacities, including the 
person’s autonomy, come from God and are meant to be used in the service of 
others<a name="_Int_JUdzKSa4">.</a><a name="_ftnref111" title="" href="#_ftn111">[111]</a>&nbsp;Therefore, rather than merely pursuing economic or technological 
objectives, AI should serve “the common good of the entire human family,” which 
is “the sum total of social conditions that allow people, either as groups or as 
individuals, to reach their fulfillment more fully and more easily.”<a name="_ftnref112" title="" href="#_ftn112">[112]</a></p>
<p><i><a name="AI_and_Human_Relationships">AI and Human Relationships</a></i></p>
<p>56. The Second Vatican 
Council observed that “by his innermost nature man is a social being; and if he 
does not enter into relations with others, he can neither live nor develop his 
gifts.”<a name="_ftnref113" title="" href="#_ftn113">[113]</a>&nbsp;This conviction underscores that living in society is intrinsic to the 
nature and vocation of the human person.<a name="_ftnref114" title="" href="#_ftn114">[114]</a>&nbsp;As social beings, we seek relationships that involve mutual exchange and 
the pursuit of truth, in the course of which, people “share with each other the 
truth they have discovered, or think they have discovered, in such a way that 
they help one another in the search for truth.”<a name="_ftnref115" title="" href="#_ftn115">[115]</a></p>
<p>57. &nbsp;Such a quest, along 
with other aspects of human communication, presupposes encounters and mutual 
exchange between individuals shaped by their unique histories, thoughts, 
convictions, and relationships. Nor can we forget that human intelligence is a 
diverse, multifaceted, and complex reality: individual and social, rational and 
affective, conceptual and symbolic. Pope Francis underscores this dynamic, 
noting that “together, we can seek the truth in dialogue, in relaxed 
conversation or in passionate debate. To do so calls for perseverance; it 
entails moments of silence and suffering, yet it can patiently embrace the 
broader experience of individuals and peoples. […] The process of building 
fraternity, be it local or universal, can only be undertaken by spirits that are 
free and open to authentic encounters.”<a name="_ftnref116" title="" href="#_ftn116">[116]</a></p>
<p>58. It is in this context 
that one can consider the challenges AI poses to human relationships. Like other 
technological tools, AI has the potential to foster connections within the human 
family. However, it could also hinder a true encounter with reality and, 
ultimately, lead people to “a deep and melancholic dissatisfaction with 
interpersonal relations, or a harmful sense of isolation.”<a name="_ftnref117" title="" href="#_ftn117">[117]</a>&nbsp;Authentic human relationships require the richness of being with others in 
their pain, their pleas, and their joy.<a name="_ftnref118" title="" href="#_ftn118">[118]</a>&nbsp;Since human intelligence is expressed and enriched also in interpersonal 
and embodied ways, authentic and spontaneous encounters with others are 
indispensable for engaging with reality in its fullness.</p>
<p>59. Because “true wisdom 
demands an encounter with reality,”<a name="_ftnref119" title="" href="#_ftn119">[119]</a>&nbsp;the rise of AI introduces another challenge. Since AI can effectively 
imitate the products of human intelligence, the ability to know when one is 
interacting with a human or a machine can no longer be taken for granted. 
Generative AI can produce text, speech, images, and other advanced outputs that 
are usually associated with human beings. Yet, it must be understood for what it 
is: a tool, not a person.<a name="_ftnref120" title="" href="#_ftn120">[120]</a>&nbsp;This distinction is often obscured by the language used by practitioners, 
which tends to anthropomorphize AI and thus blurs the line between human and 
machine. </p>
<p>60. Anthropomorphizing AI 
also poses specific challenges for the development of children, potentially 
encouraging them to develop patterns of interaction that treat human 
relationships in a transactional manner, as one would relate to a chatbot. Such 
habits could lead young people to see teachers as mere dispensers of information 
rather than as mentors who guide and nurture their intellectual and moral 
growth. Genuine relationships, rooted in empathy and a steadfast commitment to 
the good of the other, are essential and irreplaceable in fostering the full 
development of the human person. </p>
<p>61. In this context, it is 
important to clarify that, despite the use of anthropomorphic language, no AI 
application can genuinely experience empathy. Emotions cannot be reduced to 
facial expressions or phrases generated in response to prompts; they reflect the 
way a person, as a whole, relates to the world and to his or her own life, with 
the body playing a central role. True empathy requires the ability to listen, 
recognize another’s irreducible uniqueness, welcome their otherness, and grasp 
the meaning behind even their silences.<a name="_ftnref121" title="" href="#_ftn121">[121]</a>&nbsp;Unlike the realm of analytical judgment in which AI excels, true empathy 
belongs to the relational sphere. It involves intuiting and apprehending the 
lived experiences of another while maintaining the distinction between self and 
other.<a name="_ftnref122" title="" href="#_ftn122">[122]</a>&nbsp;While AI can simulate empathetic responses, it cannot replicate the 
eminently personal and relational nature of authentic empathy.<a name="_ftnref123" title="" href="#_ftn123">[123]</a></p>
<p>62. In light of the above, 
it is clear why misrepresenting AI as a person should always be avoided; doing 
so for fraudulent purposes is a grave ethical violation that could erode social 
trust. Similarly, using AI to deceive in other contexts—such as in education or 
in human relationships, including the sphere of sexuality—is also to be 
considered immoral and requires careful oversight to prevent harm, maintain 
transparency, and ensure the dignity of all <a name="_Int_d05vIJmL">people.</a><a name="_ftnref124" title="" href="#_ftn124">[124]</a></p>
<p>63. &nbsp;In an increasingly 
isolated world, some people have turned to AI in search of deep human 
relationships, simple companionship, or even emotional bonds. However, while 
human beings are meant to experience authentic relationships, AI can only 
simulate them. Nevertheless, such relationships with 
others are an integral part of how a person grows to become who he or she is 
meant to be. If AI is used to help people foster genuine connections 
between people, it can contribute positively to the full realization of the 
person. Conversely, if we replace relationships with God and with others with 
interactions with technology, we risk replacing authentic relationality with a 
lifeless image (cf. Ps. 106:20; Rom. 1:22-23). Instead of retreating into 
artificial worlds, we are called to engage in a committed and intentional way 
with reality, especially by identifying with the poor and suffering, consoling 
those in sorrow, and forging bonds of communion with all. </p>
<p><i><a name="AI,_the_Economy,_and_Labor">AI, the Economy, and Labor</a></i></p>
<p>64. Due to its 
interdisciplinary nature, AI is being increasingly integrated into economic and 
financial systems. Significant investments are currently being made not only in 
the technology sector but also in energy, finance, and media, particularly in 
the areas of marketing and sales, logistics, technological innovation, 
compliance, and risk management. At the same time, AI’s applications in these 
areas have also highlighted its ambivalent nature, as a source of tremendous 
opportunities but also profound risks. A first real critical point in this area 
concerns the possibility that—due to the concentration of AI applications in the 
hands of a few corporations—only those large companies would benefit from the 
value created by AI rather than the businesses that use it.</p>
<p>65. Other broader aspects 
of AI’s impact on the economic-financial sphere must also be carefully examined, 
particularly concerning the interaction between concrete reality and the digital 
world. One important consideration in this regard involves the coexistence of 
diverse and alternative forms of economic and financial institutions within a 
given context. This factor should be encouraged, as it can bring benefits in how 
it supports the real economy by fostering its development and stability, 
especially during times of crisis. Nevertheless, it should be stressed that 
digital realities, not restricted by any spatial bonds, tend to be more 
homogeneous and impersonal than communities rooted in a particular place and a 
specific history, with a common journey characterized by shared values and 
hopes, but also by inevitable disagreements and divergences. This diversity is 
an undeniable asset to a community’s economic life. Turning over the economy and 
finance entirely to digital technology would reduce this variety and richness. 
As a result, many solutions to economic problems that can be reached through 
natural dialogue between the involved parties may no longer be attainable in a 
world dominated by procedures and only the appearance of nearness.</p>
<p>66. Another area where AI 
is already having a profound impact is the world of work. As in many other 
fields, AI is driving fundamental transformations across many professions, with 
a range of effects. On the one hand, it has the potential to enhance expertise 
and productivity, create new jobs, enable workers to focus on more innovative 
tasks, and open new horizons for creativity and innovation. </p>
<p>67. However, while AI 
promises to boost productivity by taking over mundane tasks, it frequently 
forces workers to adapt to the speed and demands of machines rather than 
machines being designed to support those who work. As a result, contrary to the 
advertised benefits of AI, current approaches to the technology can 
paradoxically <i>deskill</i> workers, subject them to automated surveillance, 
and relegate them to rigid and repetitive tasks. The need to keep up with the 
pace of technology can erode workers’ sense of agency and stifle
the innovative abilities they are expected to bring to 
their work.<a name="_ftnref125" title="" href="#_ftn125">[125]</a> </p>
<p>68. AI is currently 
eliminating the need for some jobs that were once performed by humans. If AI is 
used to replace human workers rather than complement them, there is a 
“substantial risk of disproportionate benefit for the few at the price of the 
impoverishment of many.”<a name="_ftnref126" title="" href="#_ftn126">[126]</a> 
Additionally, as AI becomes more powerful, there is an associated risk that 
human labor may lose its value in the economic realm. This is the logical 
consequence of the technocratic paradigm: a world of humanity enslaved to 
efficiency, where, ultimately, the cost of humanity 
must be cut. Yet, human lives are intrinsically valuable, independent of their 
economic output. Nevertheless, the “current model,” Pope Francis explains, “does 
not appear to favor an investment in efforts to help the slow, the weak, or the 
less talented to find opportunities in life.”<a name="_ftnref127" title="" href="#_ftn127">[127]</a> 
In light of this, “we cannot allow a tool as powerful and indispensable as 
Artificial Intelligence to reinforce such a paradigm, but rather, we must make 
Artificial Intelligence a bulwark against its expansion.”<a name="_ftnref128" title="" href="#_ftn128"> [128]</a></p>
<p>69. It is important to 
remember that “the order of things must be subordinate to the order of persons, 
and not the other way around.”<a name="_ftnref129" title="" href="#_ftn129">[129]</a> 
Human work must not only be at the service of profit but at “the service of the 
whole human person […] taking into account the person’s material needs and the 
requirements of his or her intellectual, moral, spiritual, and religious life.”<a name="_ftnref130" title="" href="#_ftn130">[130]</a> 
In this context, the Church recognizes that work is “not only a means of earning 
one’s daily bread” but is also “an essential dimension of social life” and “a 
means […] of personal growth, the building of healthy relationships, 
self-expression and the exchange of gifts. Work gives us a sense of shared 
responsibility for the development of the world, and ultimately, for our life as 
a people.”<a name="_ftnref131" title="" href="#_ftn131">[131]</a></p>
<p>70. &nbsp;Since work is a “part 
of the meaning of life on this earth, a path to growth, human development and 
personal fulfillment,” “the goal should not be that technological progress 
increasingly replaces human work, for this would be detrimental to humanity”<a name="_ftnref132" title="" href="#_ftn132">[132]</a>—rather, 
it should promote human labor. Seen in this light, AI should assist, not 
replace, human judgment. Similarly, it must never degrade creativity or reduce 
workers to mere “cogs in a machine.” Therefore, “respect for the dignity of 
laborers and the importance of employment for the economic well-being of 
individuals, families, and societies, for job security and just wages, ought to 
be a high priority for the international community as these forms of technology 
penetrate more deeply into our workplaces.”<a name="_ftnref133" title="" href="#_ftn133">[133]</a></p>
<p><i><a name="AI_and_Healthcare">AI and Healthcare</a></i></p>
<p>71. As participants in 
God’s healing work, healthcare professionals have the vocation and 
responsibility to be “guardians and servants of human life.”<a name="_ftnref134" title="" href="#_ftn134">[134]</a> 
Because of this, the healthcare profession carries an “intrinsic and undeniable 
ethical dimension,” recognized by the Hippocratic Oath, which obliges physicians 
and healthcare professionals to commit themselves to having “absolute respect 
for human life and its sacredness.”<a name="_ftnref135" title="" href="#_ftn135">[135]</a> 
Following the example of the Good Samaritan, this commitment is to be carried 
out by men and women “who reject the creation of a society of exclusion, and act 
instead as neighbors, lifting up and rehabilitating the fallen for the sake of 
the common good.”<a name="_ftnref136" title="" href="#_ftn136">[136]</a></p>
<p>72. Seen in this light, AI 
seems to hold immense potential in a variety of applications in the medical 
field, such as assisting the diagnostic work of healthcare providers, 
facilitating relationships between patients and medical staff, offering new 
treatments, and expanding access to quality care also for those who are isolated 
or marginalized. In these ways, the technology could enhance the “compassionate 
and loving closeness”<a name="_ftnref137" title="" href="#_ftn137">[137]</a> that 
healthcare providers are called to extend to the sick and suffering.</p>
<p>73. However, if AI is used 
not to enhance but to replace the relationship between patients and healthcare 
providers—leaving patients to interact with a machine rather than a human 
being—it would reduce a crucially important human relational structure to a 
centralized, impersonal, and unequal framework. Instead of encouraging 
solidarity with the sick and suffering, such applications of AI would risk 
worsening the loneliness that often accompanies illness, especially in the 
context of a culture where “persons are no longer seen as a paramount value to 
be cared for and respected.”<a name="_ftnref138" title="" href="#_ftn138">[138]</a> 
This misuse of AI would not align with respect for the dignity of the human 
person and solidarity with the suffering.</p>
<p>74. Responsibility for the 
well-being of patients and the decisions that touch upon their lives are at the 
heart of the healthcare profession. This accountability requires medical 
professionals to exercise all their skill and intelligence in making 
well-reasoned and ethically grounded choices regarding those entrusted to their 
care, always respecting the inviolable dignity of the patients and the need for 
informed consent. As a result, decisions regarding patient treatment and the 
weight of responsibility they entail must always remain with the human person 
and should never be delegated to AI.<a name="_ftnref139" title="" href="#_ftn139">[139]</a></p>
<p>75. In addition, using AI 
to determine who should receive treatment based predominantly on economic 
measures or metrics of efficiency represents a particularly problematic instance 
of the “technocratic paradigm” that must be rejected.<a name="_ftnref140" title="" href="#_ftn140">[140]</a> 
For, “optimizing resources means using them in an ethical and fraternal way, and 
not penalizing the most fragile.”<a name="_ftnref141" title="" href="#_ftn141">[141]</a> 
Additionally, AI tools in healthcare are “exposed to forms of bias and 
discrimination,” where “systemic errors can easily multiply, producing not only 
injustices in individual cases but also, due to the domino effect, real forms of 
social inequality.”<a name="_ftnref142" title="" href="#_ftn142">[142]</a></p>
<p>76. The integration of AI 
into healthcare also poses the risk of amplifying other existing disparities in 
access to medical care. As healthcare becomes increasingly oriented toward 
prevention and lifestyle-based approaches, AI-driven solutions may inadvertently 
favor more affluent populations who already enjoy better access to medical 
resources and quality nutrition. This trend risks reinforcing a “medicine for 
the rich” model, where those with financial means benefit from advanced 
preventative tools and personalized health information while others struggle to 
access even basic services. To prevent such inequities, equitable frameworks are 
needed to ensure that the use of AI in healthcare does not worsen existing 
healthcare inequalities but rather serves the common good. </p>
<p><i><a name="AI_and_Education">AI and Education</a></i></p>
<p>77. The words of the 
Second Vatican Council remain fully relevant today: “True education strives to 
form individuals with a view toward their final end and the good of the society 
to which they belong.”<a name="_ftnref143" title="" href="#_ftn143">[143]</a> As 
such, education is “never a mere process of passing on facts and intellectual 
skills: rather, its aim is to contribute to the person’s holistic formation in 
its various aspects (intellectual, cultural, spiritual, etc.), including, for 
example, community life and relations within the academic community,”<a name="_ftnref144" title="" href="#_ftn144">[144]</a> 
in keeping with the nature and dignity of the human person.</p>
<p>78. This approach involves 
a commitment to cultivating the mind, but always as a part of the integral 
development of the person: “We must break that idea of education which holds 
that educating means filling one’s head with ideas. That is the way we educate 
automatons, cerebral minds, not people. Educating is taking a risk in the 
tension between the mind, the heart, and the hands.”<a name="_ftnref145" title="" href="#_ftn145">[145]</a></p>
<p>79. At the center of this 
work of forming the whole human person is the indispensable relationship between 
teacher and student. Teachers do more than convey knowledge; they model 
essential human qualities and inspire the joy of discovery.<a name="_ftnref146" title="" href="#_ftn146">[146]</a> 
Their presence motivates students both through the content they teach and the 
care they demonstrate for their students. This bond fosters trust, mutual 
understanding, and the capacity to address each person’s unique dignity and 
potential. On the part of the student, this can generate a genuine desire to 
grow. The physical presence of a teacher creates a relational dynamic that AI 
cannot replicate, one that deepens engagement and nurtures the student’s 
integral development.</p>
<p>80. In this context, AI 
presents both opportunities and challenges. If used in a prudent manner, within 
the context of an existing teacher-student relationship and ordered to the 
authentic goals of education, AI can become a valuable educational resource by 
enhancing access to education, offering tailored support, and providing 
immediate feedback to students. These benefits could enhance the learning 
experience, especially in cases where individualized attention is needed, or 
educational resources are otherwise scarce. </p>
<p>81. Nevertheless, an 
essential part of education is forming “the intellect to reason well in all 
matters, to reach out towards truth, and to grasp it,”<a name="_ftnref147" title="" href="#_ftn147">[147]</a> 
while helping the “language of the head” to grow harmoniously with the “language 
of the heart” and the “language of the hands.”<a name="_ftnref148" title="" href="#_ftn148">[148]</a> 
This is all the more vital in an age marked by technology, in which “it is no 
longer merely a question of ‘using’ instruments of communication, but of living 
in a highly digitalized culture that has had a profound impact on […] our 
ability to communicate, learn, be informed and enter into relationship with 
others.”<a name="_ftnref149" title="" href="#_ftn149">[149]</a> However, instead of 
fostering “a cultivated intellect,” which “brings with it a power and a grace to 
every work and occupation that it undertakes,”<a name="_ftnref150" title="" href="#_ftn150">[150]</a> 
the extensive use of AI in education could lead to the students’ increased 
reliance on technology, eroding their ability to perform some skills 
independently and worsening their dependence on screens.<a name="_ftnref151" title="" href="#_ftn151">[151]</a> 
</p>
<p>82. Additionally, while 
some AI systems are designed to help people develop their critical thinking 
abilities and problem-solving skills, many others merely provide answers instead 
of prompting students to arrive at answers themselves or write text for 
themselves.<a name="_ftnref152" title="" href="#_ftn152">[152]</a>&nbsp;Instead of training young people how to amass information and generate 
quick responses, education should encourage “the responsible use of freedom to 
face issues with good sense and intelligence.”<a name="_ftnref153" title="" href="#_ftn153">[153]</a>&nbsp;Building on this, “education in the use of forms of artificial 
intelligence should aim above all at promoting critical thinking. Users of all 
ages, but especially the young, need to develop a discerning approach to the use 
of data and content collected on the web or produced by artificial intelligence 
systems. Schools, universities, and scientific societies are challenged to help 
students and professionals to grasp the social and ethical aspects of the 
development and uses of technology.”<a name="_ftnref154" title="" href="#_ftn154">[154]</a></p>
<p>83. As Saint John Paul II 
recalled, “in the world today, characterized by such rapid developments in 
science and technology, the tasks of a Catholic University assume an ever 
greater importance and urgency.”<a name="_ftnref155" title="" href="#_ftn155">[155]</a>&nbsp;In a particular way, Catholic universities are urged to be present as 
great laboratories of hope at this crossroads of history. In an 
inter-disciplinary and cross-disciplinary key, they are urged to engage “with 
wisdom and creativity”<a name="_ftnref156" title="" href="#_ftn156">[156]</a>&nbsp;in careful research on this phenomenon, helping to draw out the salutary 
potential within the various fields of science and reality, and guiding them 
always towards ethically sound applications that clearly serve the cohesion of 
our societies and the common good, reaching new frontiers in the dialogue 
between faith and reason. </p>
<p>84. Moreover, it should be noted that current AI 
programs have been known to provide biased or fabricated information, which can 
lead students to trust inaccurate content. This problem “not only runs the risk 
of legitimizing fake news and strengthening a dominant culture’s advantage, but, 
in short, it also undermines the educational process itself.”<a name="_ftnref157" title="" href="#_ftn157">[157]</a>&nbsp;With time, clearer distinctions may emerge between proper and improper 
uses of AI in education and research. Yet, a decisive guideline is that the use 
of AI should always be transparent and never misrepresented.</p>
<p><i><a name="AI,_Misinformation">AI, Misinformation</a>, Deepfakes, and Abuse</i></p>
<p>85. AI could be used as an 
aid to human dignity if it helps people understand complex concepts or directs 
them to sound resources that support their search for the truth.<a name="_ftnref158" title="" href="#_ftn158">[158]</a></p>
<p>86. However, AI also 
presents a serious risk of generating manipulated content and false information, 
which can easily mislead people due to its resemblance to the truth. Such 
misinformation might occur unintentionally, as in the case of AI 
“hallucination,” where a generative AI system yields results that appear real 
but are not. Since generating content that mimics human artifacts is central to 
AI’s functionality, mitigating these risks proves challenging. Yet, the 
consequences of such aberrations and false information can be quite grave. For 
this reason, all those involved in producing and using AI systems should be 
committed to the truthfulness and accuracy of the information processed by such 
systems and disseminated to the public. </p>
<p>87. While AI has a latent 
potential to generate false information, an even more troubling problem lies in 
the deliberate misuse of AI for manipulation. This can occur when individuals or 
organizations intentionally generate and spread false content with the aim to 
deceive or cause harm, such as “deepfake” images, videos, and audio—referring to 
a false depiction of a person, edited or generated by an AI algorithm. The 
danger of deepfakes is particularly evident when they are used to target or harm 
others. While the images or videos themselves may be artificial, the damage they 
cause is real, leaving “deep scars in the hearts of those who suffer it” and 
“real wounds in their human dignity.”<a name="_ftnref159" title="" href="#_ftn159">[159]</a></p>
<p>88. On a broader scale, by 
distorting “our relationship with others and with reality,”<a name="_ftnref160" title="" href="#_ftn160">[160]</a>&nbsp;AI-generated fake media can gradually undermine the foundations of 
society. This issue requires careful regulation, as misinformation—especially 
through AI-controlled or influenced media—can spread unintentionally, fueling 
political polarization and social unrest. When society becomes indifferent to 
the truth, various groups construct their own versions of “facts,” weakening the 
“reciprocal ties and mutual dependencies”<a name="_ftnref161" title="" href="#_ftn161">[161]</a>&nbsp;that underpin the fabric of social life. As deepfakes cause people to 
question everything and AI-generated false content erodes trust in what they see 
and<b> </b>hear, polarization and conflict will only grow. Such widespread 
deception is no trivial matter; it strikes at the core of humanity, dismantling 
the foundational trust on which societies are built.<a name="_ftnref162" title="" href="#_ftn162">[162]</a></p>
<p>89. Countering AI-driven 
falsehoods is not only the work of industry experts—it requires the efforts of 
all people of goodwill. “If technology is to serve human dignity and not harm 
it, and if it is to promote peace rather than violence, then the human community 
must be proactive in addressing these trends with respect to human dignity and 
the promotion of the good.”<a name="_ftnref163" title="" href="#_ftn163">[163]</a>&nbsp;Those who produce and share AI-generated content should always exercise 
diligence in verifying the truth of what they disseminate and, in all cases, 
should “avoid the sharing of words and images that are degrading of human 
beings, that promote hatred and intolerance, that debase the goodness and 
intimacy of human sexuality or that exploit the weak and vulnerable.”<a name="_ftnref164" title="" href="#_ftn164">[164]</a>&nbsp;This calls for the ongoing prudence and careful discernment of all users 
regarding their activity online.<a name="_ftnref165" title="" href="#_ftn165">[165]</a></p>
<p><i><a name="AI,_Privacy">AI, Privacy</a>, and Surveillance</i></p>
<p>90. &nbsp;Humans are inherently 
relational, and the data each person generates in the digital world can be seen 
as an objectified expression of this relational nature. Data conveys not only 
information but also personal and relational knowledge, which, in an 
increasingly digitized context, can amount to power over the individual. 
Moreover, while some types of data may pertain to public aspects of a person’s 
life, others may touch upon the individual’s interiority, perhaps even their 
conscience. Seen in this way, privacy plays an essential role in protecting the 
boundaries of a person’s inner life, preserving their freedom to relate to 
others, express themselves, and make decisions without undue control. This 
protection is also tied to the defense of religious freedom, as surveillance can 
also be misused to exert control over the lives of believers and how they 
express their faith.</p>
<p>91. It is appropriate, 
therefore, to address the issue of privacy from a concern for the legitimate 
freedom and inalienable dignity of the human person “in all circumstances.”<a name="_ftnref166" title="" href="#_ftn166">[166]</a> 
The Second Vatican Council included the right “to safeguard privacy” among the 
fundamental rights “necessary for living a genuinely human life,” a right that 
should be extended to all people on account of their “sublime dignity.”<a name="_ftnref167" title="" href="#_ftn167">[167]</a> 
Furthermore, the Church has also affirmed the right to the legitimate respect 
for a private life in the context of affirming the person’s right to a good 
reputation, defense of their physical and mental integrity, and freedom from 
harm or undue intrusion<a name="_ftnref168" title="" href="#_ftn168">[168]</a>—essential 
components of the due respect for the intrinsic dignity of the human person.<a name="_ftnref169" title="" href="#_ftn169">[169]</a></p>
<p>92. Advances in AI-powered 
data processing and analysis now make it possible to infer patterns in a 
person’s behavior and thinking from even a small amount of information, making 
the role of data privacy even more imperative as a safeguard for the dignity and 
relational nature of the human person. As Pope Francis observed, “while closed 
and intolerant attitudes towards others are on the rise, distances are otherwise 
shrinking or disappearing to the point that the right to privacy scarcely 
exists. Everything has become a kind of spectacle to be examined and inspected, 
and people’s lives are now under constant surveillance.”<a name="_ftnref170" title="" href="#_ftn170">[170]</a></p>
<p>93. While there can be 
legitimate and proper ways to use AI in keeping with human dignity and the 
common good, using it for surveillance aimed at exploiting, restricting others’ 
freedom, or benefitting a few at the expense of the many is unjustifiable. The 
risk of surveillance overreach must be monitored by appropriate regulators to 
ensure transparency and public accountability. Those responsible for 
surveillance should never exceed their authority, which must always favor the 
dignity and freedom of every person as the essential basis of a just and humane 
society.</p>
<p>94. Furthermore, 
“fundamental respect for human dignity demands that we refuse to allow the 
uniqueness of the person to be identified with a set of data.”<a name="_ftnref171" title="" href="#_ftn171">[171]</a> 
This especially applies when AI is used to evaluate individuals or groups based 
on their behavior, characteristics, or history—a practice known as “social 
scoring”: “In social and economic decision-making, we should be cautious about 
delegating judgments to algorithms that process data, often collected 
surreptitiously, on an individual’s makeup and prior behavior. Such data can be 
contaminated by societal prejudices and preconceptions. A person’s past behavior 
should not be used to deny him or her the opportunity to change, grow, and 
contribute to society. We cannot allow algorithms to limit or condition respect 
for human dignity, or to exclude compassion, mercy, forgiveness, and above all, 
the hope that people are able to change.”<a name="_ftnref172" title="" href="#_ftn172">[172]</a> 
</p>
<p><i><a name="AI_and_the_Protection">AI and the Protection</a> of Our Common Home</i></p>
<p>95. AI has many promising 
applications for improving our relationship with our “common home,” such as 
creating models to forecast extreme climate events, proposing engineering 
solutions to reduce their impact, managing relief operations, and predicting 
population shifts.<a name="_ftnref173" title="" href="#_ftn173">[173]</a> 
Additionally, AI can support sustainable agriculture, optimize energy usage, and 
provide early warning systems for public health emergencies. These advancements 
have the potential to strengthen resilience against climate-related challenges 
and promote more sustainable development.</p>
<p>96. At the same time, 
current AI models and the hardware required to support them consume vast amounts 
of energy and water, significantly contributing to CO<sub>2</sub> emissions and 
straining resources. This reality is often obscured by the way this technology 
is presented in the popular imagination, where words such as “the cloud”<a name="_ftnref174" title="" href="#_ftn174"> [174]</a>&nbsp;can give the impression that data is stored and processed in an intangible 
realm, detached from the physical world. However, “the cloud” is not an ethereal 
domain separate from the physical world; as with all computing technologies, it 
relies on physical machines, cables, and energy. The same is true of the 
technology behind AI. As these systems grow in 
complexity, especially large language models (LLMs), they require ever-larger 
datasets, increased computational power, and greater storage infrastructure. 
Considering the heavy toll these technologies take on the environment, it is 
vital to develop sustainable solutions that reduce their impact on our common 
home.</p>
<p>97. &nbsp;Even then, as Pope 
Francis teaches, it is essential “that we look for solutions not only in 
technology but in a change of humanity.”<a name="_ftnref175" title="" href="#_ftn175">[175]</a> 
A complete and authentic understanding of creation recognizes that the value of 
all created things cannot be reduced to their mere utility. Therefore, a fully 
human approach to the stewardship of the earth rejects the distorted 
anthropocentrism of the technocratic paradigm, which seeks to “extract 
everything possible” from the world,<a name="_ftnref176" title="" href="#_ftn176"> [176]</a> 
and rejects the “myth of progress,” which assumes that “ecological problems will 
solve themselves simply with the application of new technology and without any 
need for ethical considerations or deep change.”<a name="_ftnref177" title="" href="#_ftn177">[177]</a> 
Such a mindset must give way to a more holistic approach that respects the order 
of creation and promotes the integral good of the human person while 
safeguarding our common home.<a name="_ftnref178" title="" href="#_ftn178"> [178]</a> 
</p>
<p><i><a name="AI_and_Warfare">AI and Warfare</a></i></p>
<p>98. The Second Vatican 
Council and the consistent teaching of the Popes since then have insisted that 
peace is not merely the absence of war and is not limited to maintaining a 
balance of powers between adversaries. Instead, in the words of Saint Augustine, 
peace is “the tranquility of order.”<a name="_ftnref179" title="" href="#_ftn179"> [179]</a>&nbsp;Indeed, peace cannot be attained without safeguarding the goods of 
persons, free communication, respect for the dignity of persons and peoples, and 
the assiduous practice of fraternity. Peace is the work of justice and the 
effect of charity and cannot be achieved through force alone; instead, it must 
be principally built through patient diplomacy, the active promotion of justice, 
solidarity, integral human development, and respect for the dignity of all 
people.<a name="_ftnref180" title="" href="#_ftn180">[180]</a>&nbsp;In this way, the tools used to maintain peace should never be allowed to 
justify injustice, violence, or oppression. Instead, they should always be 
governed by a “firm determination to respect other people and nations, along 
with their dignity, as well as the deliberate practice of fraternity.”<a name="_ftnref181" title="" href="#_ftn181">[181]</a></p>
<p>99. While AI’s analytical 
abilities could help nations seek peace and ensure security, the “weaponization 
of Artificial Intelligence” can also be highly problematic. Pope Francis has 
observed that “the ability to conduct military operations through remote control 
systems has led to a lessened perception of the devastation caused by those 
weapon systems and the burden of responsibility for their use, resulting in an 
even more cold and detached approach to the immense tragedy of war.”<a name="_ftnref182" title="" href="#_ftn182">[182]</a>&nbsp;Moreover, the ease with which autonomous weapons make war more viable 
militates against the principle of war as a last resort in legitimate 
self-defense,<a name="_ftnref183" title="" href="#_ftn183">[183]</a>&nbsp;potentially increasing the instruments of war well beyond the scope of 
human oversight and precipitating a destabilizing arms race, with catastrophic 
consequences for human rights.<a name="_ftnref184" title="" href="#_ftn184">[184]</a></p>
<p>100. In particular, Lethal Autonomous Weapon 
Systems, which are capable of identifying and striking targets without direct 
human intervention, are a “cause for grave ethical concern” because they lack 
the “unique human capacity for moral judgment and ethical decision-making.”<a name="_ftnref185" title="" href="#_ftn185">[185]</a>&nbsp;For this reason, Pope Francis has urgently called for a reconsideration of 
the development of these weapons and a prohibition on their use, starting with 
“an effective and concrete commitment to introduce ever greater and proper human 
control. No machine should ever choose to take the life of a human being.”<a name="_ftnref186" title="" href="#_ftn186">[186]</a></p>
<p>101. Since it is a small step from machines that 
can kill autonomously with precision to those capable of large-scale 
destruction, some AI researchers have expressed concerns that such technology 
poses an “existential risk” by having the potential to act in ways that could 
threaten the survival of entire regions or even of humanity itself. This danger 
demands serious attention, reflecting the long-standing concern about 
technologies that grant war “an uncontrollable destructive power over great 
numbers of innocent civilians,”<a name="_ftnref187" title="" href="#_ftn187">[187]</a>&nbsp;without even sparing children. In this context, the call from <i>
<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a></i> to “undertake an evaluation of war with an entirely new attitude”<a name="_ftnref188" title="" href="#_ftn188">[188]</a>&nbsp;is more urgent than ever.</p>
<p>102. At the same time, while the theoretical risks 
of AI deserve attention, the more immediate and pressing concern lies in how 
individuals with malicious intentions might misuse this technology.<a name="_ftnref189" title="" href="#_ftn189">[189]</a>&nbsp;Like any tool, AI is an extension of human power, and while its future 
capabilities are unpredictable, humanity’s past actions provide clear warnings. 
The atrocities committed throughout history are enough to raise deep concerns 
about the potential abuses of AI.</p>
<p>103. Saint John Paul II observed that “humanity 
now has instruments of unprecedented power: we can turn this world into a 
garden, or reduce it to a pile of rubble.”<a name="_ftnref190" title="" href="#_ftn190">[190]</a>&nbsp;Given this fact, the Church reminds us, in the words of Pope Francis, that 
“we are free to apply our intelligence towards things evolving positively,” or 
toward “decadence and mutual destruction.”<a name="_ftnref191" title="" href="#_ftn191">[191]</a>&nbsp;To prevent humanity from spiraling into self-destruction,<a name="_ftnref192" title="" href="#_ftn192">[192]</a>&nbsp;there must be a clear stand against all applications of technology that 
inherently threaten human life and dignity. This commitment requires careful 
discernment about the use of AI, particularly in military defense applications, 
to ensure that it always respects human dignity and serves the common good. The 
development and deployment of AI in armaments should be subject to the highest 
levels of ethical scrutiny, governed by a concern for human dignity and the 
sanctity of life.<a name="_ftnref193" title="" href="#_ftn193">[193]</a></p>
<p><i><a name="AI_and_Our">AI and Our</a> Relationship with God</i></p>
<p>104. Technology offers remarkable tools to oversee 
and develop the world’s resources. However, in some cases, humanity is increasingly ceding control of these 
resources to machines. Within some circles of scientists and futurists, there is 
optimism about the potential of artificial general intelligence (AGI), a 
hypothetical form of AI that would match or surpass human intelligence and bring 
about unimaginable advancements. Some even speculate that AGI could achieve 
superhuman capabilities. At the same time, as society drifts away from a 
connection with the transcendent, some are tempted to turn to AI in search of 
meaning or fulfillment—longings that can only be truly satisfied in communion 
with God.<a name="_ftnref194" title="" href="#_ftn194">[194]</a></p>
<p>105. However, <i>the presumption of substituting 
God for an artifact of human making is idolatry</i>, a practice Scripture 
explicitly warns against (e.g., Ex. 20:4; 32:1-5; 34:17). Moreover, AI may prove 
even more seductive than traditional idols for, unlike idols that “have mouths 
but do not speak; eyes, but do not see; ears, but do not hear” (Ps. 115:5-6), AI 
can “speak,” or at least gives the illusion of doing so (cf. Rev. 13:15). Yet, 
it is vital to remember that AI is but a pale reflection of humanity—it is 
crafted by human minds, trained on human-generated material, responsive to human 
input, and sustained through human labor. AI cannot possess many of the 
capabilities specific to human life, and it is also fallible. By turning to AI 
as a perceived “Other” greater than itself, with which to share existence and 
responsibilities, humanity risks creating a substitute for God. However, it is 
not AI that is ultimately deified and worshipped, but humanity itself—which, in 
this way, becomes enslaved to its own work.<a name="_ftnref195" title="" href="#_ftn195">[195]</a> 
</p>
<p>106. While AI has the potential to serve humanity 
and contribute to the common good, it remains a creation of human hands, bearing 
“the imprint of human art and ingenuity” (Acts 17:29). It must never be ascribed 
undue worth. As the Book of Wisdom affirms: “For a man made them, and one whose 
spirit is borrowed formed them; for no man can form a god which is like himself. 
He is mortal, and what he makes with lawless hands is dead, for he is better 
than the objects he worships since he has life, but they never have” (Wis. 
15:16-17). </p>
<p>107. In contrast, human beings, “by their interior 
life, transcend the entire material universe; they experience this deep 
interiority when they enter into their own heart, where God, who probes the 
heart, awaits them, and where they decide their own destiny in the sight of 
God.”<a name="_ftnref196" title="" href="#_ftn196">[196]</a> It is within the 
heart, as Pope Francis reminds us, that each individual discovers the 
“mysterious connection between self-knowledge and openness to others, between 
the encounter with one’s personal uniqueness and the willingness to give oneself 
to others.”<a name="_ftnref197" title="" href="#_ftn197">[197]</a> Therefore, it is 
the heart alone that is “capable of setting our other powers and passions, and 
our entire person, in a stance of reverence and loving obedience before the 
Lord,”<a name="_ftnref198" title="" href="#_ftn198">[198]</a> who “offers to treat 
each one of us as a ‘Thou,’ always and forever.”<a name="_ftnref199" title="" href="#_ftn199">[199]</a> 
</p>
<p>VI. <b> <a name="Concluding_Reflections">Concluding Reflections</a></b></p>
<p>108. Considering the various challenges posed by 
advances in technology, Pope Francis emphasized the need for growth in “human 
responsibility, values, and conscience,” proportionate to the growth in the 
potential that this technology brings<a name="_ftnref200" title="" href="#_ftn200">[200]</a>—recognizing that “with an increase in human power comes a broadening of 
responsibility on the part of individuals and communities.”<a name="_ftnref201" title="" href="#_ftn201">[201]</a></p>
<p>109. At the same time, the “essential and 
fundamental question” remains “whether in the context of this progress man, as 
man, is becoming truly better, that is to say, more mature spiritually, more 
aware of the dignity of his humanity, more responsible, more open to others, 
especially the neediest and the weakest, and readier to give and to aid all.”<a name="_ftnref202" title="" href="#_ftn202">[202]</a></p>
<p>110. As a result, it is crucial to know how to 
evaluate individual applications of AI in particular contexts to determine 
whether its use promotes human dignity, the vocation of the human person, and 
the common good. As with many technologies, the effects of the various uses of 
AI may not always be predictable from their inception. As these applications and 
their social impacts become clearer, appropriate responses should be made at all 
levels of society, following the principle of subsidiarity. Individual users, 
families, civil society, corporations, institutions, governments, and 
international organizations should work at their proper levels to ensure that AI 
is used for the good of all. </p>
<p>111. A significant challenge and opportunity for 
the common good today lies in considering AI within a framework of relational 
intelligence, which emphasizes the interconnectedness of individuals and 
communities and highlights our shared responsibility for fostering the integral 
well-being of others. The twentieth-century philosopher Nicholas Berdyaev 
observed that people often blame machines for personal and social problems; 
however, “this only humiliates man and does not correspond to his dignity,” for 
“it is unworthy to transfer responsibility from man to a machine.”<a name="_ftnref203" title="" href="#_ftn203">[203]</a> 
Only the human person can be morally responsible, and the challenges of a 
technological society are ultimately <i>spiritual</i> in nature. Therefore, 
facing those challenges “demands an intensification of spirituality.”<a name="_ftnref204" title="" href="#_ftn204">[204]</a></p>
<p>112. A further point to consider is the call, 
prompted by the appearance of AI on the world stage, for a <i>renewed 
appreciation of all that is human</i>. Years ago, the 
French Catholic author Georges Bernanos warned that “the danger is not in the 
multiplication of machines, but in the ever-increasing number of men accustomed 
from their childhood to desire only what machines can give.”<a name="_ftnref205" title="" href="#_ftn205">[205]</a> 
This challenge is as true today as it was then, as the rapid pace of 
digitization risks a “digital reductionism,” where non-quantifiable aspects of 
life are set aside and then forgotten or even deemed irrelevant because they 
cannot be computed in formal terms. AI should be used only as a tool to 
complement human intelligence rather than replace its richness.<a name="_ftnref206" title="" href="#_ftn206">[206]</a> Cultivating those aspects of human life that transcend computation is 
crucial for preserving “an authentic humanity” that “seems to dwell in the midst 
of our technological culture, almost unnoticed, like a mist seeping gently 
beneath a closed door.”<a name="_ftnref207" title="" href="#_ftn207">[207]</a></p>
<p><i><a name="True_Wisdom">True Wisdom</a></i></p>
<p>113. The vast expanse of the world’s knowledge is 
now accessible in ways that would have filled past generations with awe. 
However, to ensure that advancements in knowledge do not become humanly or 
spiritually barren, one must go beyond the mere accumulation of data and strive 
to achieve true wisdom.<a name="_ftnref208" title="" href="#_ftn208">[208]</a></p>
<p>114. This wisdom is the gift that humanity needs 
most to address the profound questions and ethical challenges posed by AI: “Only 
by adopting a spiritual way of viewing reality, only by recovering a wisdom of 
the heart, can we confront and interpret the newness of our time.”<a name="_ftnref209" title="" href="#_ftn209">[209]</a>&nbsp;Such “wisdom of the heart” is “the virtue that enables us to integrate the 
whole and its parts, our decisions and their consequences.” It “cannot be sought 
from machines,” but it “lets itself be found by those who seek it and be seen by 
those who love it; it anticipates those who desire it, and it goes in search of 
those who are worthy of it (cf. Wis 6:12-16).”<a name="_ftnref210" title="" href="#_ftn210">[210]</a></p>
<p>115. In a world marked by AI, we need the grace of 
the Holy Spirit, who “enables us to look at things with God’s eyes, to see 
connections, situations, events and to uncover their real meaning.”<a name="_ftnref211" title="" href="#_ftn211">[211]</a></p>
<p>116. Since a “person’s perfection is measured not 
by the information or knowledge they possess, but by the depth of their 
charity,”<a name="_ftnref212" title="" href="#_ftn212">[212]</a>&nbsp;how we incorporate AI “to include the least of our brothers and sisters, 
the vulnerable, and those most in need, will be the true measure of our 
humanity.”<a name="_ftnref213" title="" href="#_ftn213">[213]</a>&nbsp;The “wisdom of the heart” can illuminate and guide the human-centered use 
of this technology to help promote the common good, care for our “common home,” 
advance the search for the truth, foster integral human development, favor human 
solidarity and fraternity, and lead humanity to its ultimate goal: happiness and 
full communion with God.<a name="_ftnref214" title="" href="#_ftn214">[214]</a></p>
<p>117. From this perspective of wisdom, believers 
will be able to act as moral agents capable of using this technology to promote 
an authentic vision of the human person and society.<a name="_ftnref215" title="" href="#_ftn215">[215]</a>&nbsp;This should be done with the understanding that technological progress is 
part of God’s plan for creation—an activity that we are called to order toward 
the Paschal Mystery of Jesus Christ, in the continual search for the True and 
the Good.</p>
<p><i>The Supreme Pontiff, Francis, at the Audience granted on 14 January 2025 to the 
undersigned Prefects and Secretaries of the Dicastery for the Doctrine of the 
Faith and the Dicastery for Culture and Education, approved this </i>Note<i> and ordered its publication.</i></p>
<p>Given in Rome, at the offices of the Dicastery for the Doctrine of the Faith and 
the Dicastery for Culture and Education, on 28 January 2025, the Liturgical 
Memorial of Saint Thomas Aquinas, Doctor of the Church.</p>

<div>
	<table>
		<tbody><tr>
			<td>Víctor Manuel Card. Fernández <br>
			Prefect</td>
			<td>José Card. Tolentino de Mendonça<br>
			Prefect</td>
		</tr>
		<tr>
			<td>&nbsp;</td>
			<td>&nbsp;</td>
		</tr>
		<tr>
			<td>Msgr. Armando Matteo<br>
			Secretary, Doctrinal Section</td>
			<td>Most Rev. Paul Tighe<br>
			Secretary, Culture Section </td>
		</tr>
	</tbody></table>
</div>

<p><i>Ex audientia die 14 ianuarii 2025<br>
Franciscus</i><br clear="all">
			</p>
			
<p><b>Contents</b></p>
<p><b>I. <a href="#Introduction">Introduction</a></b></p>
<p><b>II. <a href="#What_is_Artificial_Intelligence">What is Artificial Intelligence?</a></b></p>
<p><b>III. <a href="#Intelligence_in_the_Philosophical">Intelligence in the Philosophical and Theological Tradition</a></b></p>
<blockquote>
	<p><a href="#Rationality">Rationality</a></p>
	<p><a href="#Embodiment">Embodiment</a></p>
	<p><a href="#Relationality">Relationality</a></p>
	<p><a href="#Relationship_with_the_Truth">Relationship with the Truth</a></p>
	<p><a href="#Stewardship_of_the_World">Stewardship of the World</a></p>
	<p><a href="#An_Integral">An Integral Understanding of Human Intelligence</a></p>
	<p><a href="#The_Limits_of_AI">The Limits of AI</a></p>
</blockquote>
<p><b>IV. <a href="#The_Role_of_Ethics">The Role of Ethics in Guiding the Development and Use of AI</a></b></p>
<blockquote>
	<p><a href="#Helping_Human">Helping Human Freedom and Decision-Making</a></p>
</blockquote>
<p><b>V. <a href="#Specific_Questions">Specific Questions</a></b></p>
<blockquote>
	<p><a href="#AI_and_Society">AI and Society</a></p>
	<p><a href="#AI_and_Human_Relationships">AI and Human Relationships</a></p>
	<p><a href="#AI,_the_Economy,_and_Labor">AI, the Economy, and Labor</a></p>
	<p><a href="#AI_and_Healthcare">AI and Healthcare</a></p>
	<p><a href="#AI_and_Education">AI and Education</a></p>
	<p><a href="#AI,_Misinformation">AI, Misinformation, Deepfakes, and Abuse</a></p>
	<p><a href="#AI,_Privacy">AI, Privacy, and Surveillance</a></p>
	<p><a href="#AI_and_the_Protection">AI and the Protection of Our Common Home</a></p>
	<p><a href="#AI_and_Warfare">AI and Warfare</a></p>
	<p><a href="#AI_and_Our">AI and Our Relationship with God</a></p>
</blockquote>
<p><b>VI. <a href="#Concluding_Reflections">Concluding Reflections</a></b></p>
<blockquote>
	<p><a href="#True_Wisdom">True Wisdom</a></p>
</blockquote>
<div>
	&nbsp;<hr size="1">
	<p><a name="_ftn1" title="" href="#_ftnref1">[1]</a>&nbsp;<i>Catechism of the Catholic Church</i>, par. 378. See also Second Vatican Ecumenical Council, 
Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 34: <i>AAS</i> 
58 (1966), 1052-1053.</p>
	
	
	<p><a name="_ftn4" title="" href="#_ftnref4">[4]</a>&nbsp;Cf. <i>Catechism of the Catholic Church</i>, par. 2293; Second Vatican Ecumenical Council, 
Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 35: <i>AAS
</i>58 (1966), 1053.</p>
	<p><a name="_ftn5" title="" href="#_ftnref5">[5]</a>&nbsp;J. McCarthy, <i>et al</i>., “A Proposal for the Dartmouth Summer Research 
Project on Artificial Intelligence” (31 August 1955), 
http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html (accessed: 21 October 2024).</p>
	
	<p><a name="_ftn7" title="" href="#_ftnref7">[7]</a>&nbsp;Terms in this document describing the outputs or processes of AI are used 
figuratively to explain its operations and are not intended to anthropomorphize 
the machine.</p>
	
	<p><a name="_ftn9" title="" href="#_ftnref9">[9]</a>&nbsp;Here, one can see the primary positions of the “transhumanists” and the 
“posthumanists.” <i>Transhumanists</i> argue that technological advancements 
will enable humans to overcome their biological limitations and enhance both 
their physical and cognitive abilities. <i>Posthumanists</i>, on the other hand, 
contend that such advances will ultimately alter human identity to the extent 
that humanity itself may no longer be considered truly “human.” Both views rest 
on a fundamentally negative perception of human corporality, which treats the 
body more as an obstacle than as an integral part of the person’s identity and 
call to full realization. Yet, this negative view of the body is inconsistent 
with a proper understanding of human dignity. While the Church supports genuine 
scientific progress, it affirms that human dignity is rooted in “the person as 
an inseparable unity of body and soul.” Thus, “dignity is also inherent in each 
person’s body, which participates in its own way in being <i>in</i> <i>imago Dei</i>” 
(Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>[8 April 2024], par. 18).</p>
	<p><a name="_ftn10" title="" href="#_ftnref10">[10]</a>&nbsp;This approach reflects a functionalist perspective, which reduces the 
human mind to its functions and assumes that its functions can be entirely 
quantified in physical or mathematical terms. However, even if a future AGI were 
to appear truly intelligent, it would still remain functional in nature.</p>
	<p><a name="_ftn11" title="" href="#_ftnref11">[11]</a>&nbsp;Cf. A.M. Turing, “Computing Machinery and Intelligence,” <i>Mind </i>59 
(1950) 443-460.</p>
	<p><a name="_ftn12" title="" href="#_ftnref12">[12]</a>&nbsp;If “thinking” is attributed to machines, it must 
be clarified that this refers to calculative thinking rather than critical 
thinking. Similarly, if machines are said to operate using logical thinking, it 
must be specified that this is limited to computational logic. On the other 
hand, by its very nature, human thought is a creative process that eludes 
programming and transcends constraints.</p>
	<p><a name="_ftn13" title="" href="#_ftnref13">[13]</a>&nbsp;On the foundational role of language in shaping understanding, cf. M. Heidegger,
<i>Über den Humanismus</i>, Klostermann, Frankfurt am Main 1949 (en. tr. “Letter 
on Humanism,” in <i>Basic Writings: Martin Heidegger</i>, Routledge, London ‒ 
New York 2010, 141-182). </p>
	<p><a name="_ftn14" title="" href="#_ftnref14">[14]</a>&nbsp;For further discussion of these anthropological and theological 
foundations, see AI Research Group of the Centre for Digital Culture of the Dicastery for Culture 
and Education, <i>Encountering Artificial Intelligence: Ethical and 
Anthropological Investigations</i>&nbsp;(Theological Investigations of Artificial 
Intelligence 1), M.J. Gaudet, N. Herzfeld, P. Scherz, J.J. Wales, eds., <i>
Journal of Moral Theology</i>, Pickwick, Eugene 2024, 43-144.</p>
	<p><a name="_ftn15" title="" href="#_ftnref15">[15]</a>&nbsp;Aristotle, <i>Metaphysics</i>, I.1, 980 a 21.</p>
	<p><a name="_ftn16" title="" href="#_ftnref16">[16]</a> Cf. Augustine, <i>De Genesi ad litteram </i>III, 20, 30: PL 34, 292: “Man is 
made in the image of God in relation to that [faculty] by which he is superior 
to the irrational animals. Now, this [faculty] is reason itself, or the ‘mind,’ 
or ‘intelligence,’ whatever other name it may more suitably be given”;<b> </b>Id.,
<i>Enarrationes in Psalmos </i>54, 3: PL 36, 629: “When considering all that 
they have, humans discover that they are most distinguished from animals 
precisely by the fact they possess intelligence.” This is also reiterated by 
Saint Thomas Aquinas, who states that “man is the most perfect of all earthly 
beings endowed with motion, and his proper and natural operation is 
intellection,” by which man abstracts from things and “receives in his mind 
things actually intelligible” (Thomas Aquinas, <i>Summa Contra Gentiles </i>II, 
76).</p>
	<p><a name="_ftn17" title="" href="#_ftnref17">[17]</a>&nbsp;Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 15: <i>AAS </i>58 (1966), 1036.</p>
	<p><a name="_ftn18" title="" href="#_ftnref18">[18]</a>&nbsp;Aquinas, <i>Summa Theologiae</i>, II-II, q. 49, a. 5, ad 3. Cf. <i>ibid</i>., 
I, q. 79; II-II, q. 47, a. 3; II-II, q. 49, a. 2. For a contemporary perspective 
that echoes elements of the classical and medieval distinction between these two 
modes of cognition, cf. D. Kahneman, <i>Thinking, Fast and Slow</i>, New York<i>
</i>2011. </p>
	<p><a name="_ftn19" title="" href="#_ftnref19">[19]</a>&nbsp;Aquinas, <i>Summa Theologiae</i>, I, q. 76, a. 1, <i>resp</i>. 
	</p>
	<p><a name="_ftn20" title="" href="#_ftnref20">[20]</a>&nbsp;Cf. Irenaeus of Lyon, <i>Adversus Haereses</i>,<i> </i>V, 6, 1: PG 7(2), 
1136-1138.</p>
	<p><a name="_ftn21" title="" href="#_ftnref21">[21]</a>&nbsp;Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), par. 9. Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a></i> 
(3 October 2020), par. 213: <i>AAS </i>112 (2020), 1045: “The intellect can 
investigate the reality of things through reflection, experience and dialogue, 
and come to recognize in that reality, which transcends it, the basis of certain 
universal moral demands.”</p>
	
	<p><a name="_ftn23" title="" href="#_ftnref23">[23]</a>&nbsp;<i>Catechism of the Catholic Church</i>, par. 365. Cf. Aquinas, <i>Summa 
Theologiae</i>, I, q. 75, a. 4, resp.</p>
	<p><a name="_ftn24" title="" href="#_ftnref24">[24]</a>&nbsp;Indeed, Sacred Scripture “generally considers the human person as a being 
who exists in the body and is unthinkable outside of it” (Pontifical Biblical Commission,
<i><a href="https://www.vatican.va/roman_curia/congregations/cfaith/pcb_documents/rc_con_cfaith_doc_20190930_cosa-e-luomo_sp.pdf">“Che cosa è l’uomo?” (Sal 8,5): Un itinerario di antropologia biblica</a> </i>[30 
September 2019], par. 19). Cf. <i>ibid</i>., pars. 20-21, 43-44, 48. </p>
	<p><a name="_ftn25" title="" href="#_ftnref25">[25]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 22: <i>AAS </i>58 (1966), 1042: Cf. Congregation for the Doctrine of the Faith, 
Instruction <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_con_cfaith_doc_20081208_dignitas-personae_en.html">Dignitas Personae</a> </i>(8 September 2008), par. 7: <i>AAS </i>100 
(2008), 863: “Christ did not disdain human bodiliness, but instead fully 
disclosed its meaning and value.”</p>
	<p><a name="_ftn26" title="" href="#_ftnref26">[26]</a>&nbsp;Aquinas, <i>Summa Contra Gentiles</i> II, 81.</p>
	<p><a name="_ftn27" title="" href="#_ftnref27">[27]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 15: <i>AAS </i>58 (1966), 1036.</p>
	<p><a name="_ftn28" title="" href="#_ftnref28">[28]</a>&nbsp;Cf. Aquinas<i>, Summa Theologiae </i>I, q. 89, a. 1, <i>resp</i>.: “to be 
separated from the body is not in accordance with [the soul’s] nature […] and 
hence it is united to the body in order that it may have an existence and an 
operation suitable to its nature.”</p>
	<p><a name="_ftn29" title="" href="#_ftnref29">[29]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 14: <i>AAS </i>58 (1966), 1035. Cf. Dicastery for the Doctrine of the Faith, Declaration 
		<i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), par. 18.</p>
	
	<p><a name="_ftn31" title="" href="#_ftnref31">[31]</a>&nbsp;Cf. Congregation for the Doctrine of the Faith, Instruction <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_con_cfaith_doc_20081208_dignitas-personae_en.html">Dignitas Personae</a> </i>(8 September 2008), pars. 5, 8; Dicastery for the Doctrine of the Faith, Declaration 
		<i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), pars. 15, 24, 53-54.</p>
	<p><a name="_ftn32" title="" href="#_ftnref32">[32]</a>&nbsp;<i>Catechism of the Catholic Church</i>, par. 356. Cf. <i>ibid.</i>, par. 
221.</p>
	<p><a name="_ftn33" title="" href="#_ftnref33">[33]</a>&nbsp;Cf. Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), pars. 13, 26-27.</p>
	<p><a name="_ftn34" title="" href="#_ftnref34">[34]</a>&nbsp;Congregation for the Doctrine of the Faith, Instruction <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_con_cfaith_doc_19900524_theologian-vocation_en.html">Donum Veritatis</a></i> 
(24 May 1990), 6: <i>AAS</i> 82 (1990), 1552. Cf. John Paul II, Encyclical <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_06081993_veritatis-splendor.html">Veritatis Splendor</a> </i>(6 August 1993), par. 109: <i>AAS </i>85 (1993), 1219. 
Cf. Pseudo-Dionysius, <i>De divinis nominibus, </i>VII, 2: PG 3, 868B-C: “Human 
souls also possess reason and with it they circle in discourse around the truth 
of things. […] [O]n account of the manner in which they are capable of 
concentrating the many into the one, they too, in their own fashion and as far 
as they can, are worthy of conceptions like those of the angels” (en. tr. <i>
Pseudo-Dionysius: The Complete Works</i>, Paulist Press, New York – Mahwah 1987, 
106-107).</p>
	<p><a name="_ftn35" title="" href="#_ftnref35">[35]</a>&nbsp;John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091998_fides-et-ratio.html">Fides et Ratio</a></i> (14 September 1998), 
par. 3: <i>AAS </i>91 (1999), 7.</p>
	<p><a name="_ftn36" title="" href="#_ftnref36">[36]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 15: <i>AAS </i>58 (1966), 1036.</p>
	<p><a name="_ftn37" title="" href="#_ftnref37">[37]</a>&nbsp;John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091998_fides-et-ratio.html">Fides et Ratio</a></i> (14 September 1998), 
par. 42: <i>AAS </i>91 (1999), 38. Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a></i> (3 October 2020), par. 208: <i>AAS </i>112 (2020), 1043: “the human 
mind is capable of transcending immediate concerns and grasping certain truths 
that are unchanging, as true now as in the past. As it peers into human nature, 
reason discovers universal values derived from that same nature”; <i>ibid</i>., 
par. 184: <i>AAS </i>112 (2020), 1034.</p>
	<p><a name="_ftn38" title="" href="#_ftnref38">[38]</a>&nbsp;Cf. B. Pascal, <i>Pensées</i>, no. 267 (ed. Brunschvicg): “The last 
proceeding of reason is to recognize that there is an infinity of things which 
are beyond it” (en. tr. <i>Pascal’s Pensées</i>, E.P. Dutton, New York 1958, 
77).</p>
	<p><a name="_ftn39" title="" href="#_ftnref39">[39]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 15: <i>AAS </i>58 (1966), 1036. Cf. Congregation for the Doctrine of the Faith,
		<i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_con_cfaith_doc_20071203_nota-evangelizzazione_en.html">Doctrinal Note on Some 
Aspects of Evangelization</a></i> (3 December 2007), par. 
4: <i>AAS</i> 100 (2008), 491-492.</p>
	<p><a name="_ftn40" title="" href="#_ftnref40">[40]</a>&nbsp;Our <i>semantic capacity</i> allows us to understand messages in any form 
of communication in a manner that both takes into account and transcends their 
material or empirical structures (such as computer code). Here, intelligence 
becomes a wisdom that “enables us to look at things with God’s eyes, to see 
connections, situations, events and to uncover their real meaning” (Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/messages/communications/documents/20240124-messaggio-comunicazioni-sociali.html">Message for the LVIII World Day of Social Communications</a> </i> 
		[24 January 2024]:
<i>L’Osservatore Romano</i>, 24 January 2024, 8). Our <i>creativity</i> enables 
us to generate new content or ideas, primarily by offering an original viewpoint 
on reality. Both capacities depend on the existence of a personal subjectivity 
for their full realization.</p>
	<p><a name="_ftn41" title="" href="#_ftnref41">[41]</a>&nbsp;Second Vatican Ecumenical Council, Declaration <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_decl_19651207_dignitatis-humanae_en.html">Dignitatis Humanae</a></i>
(7 December 1965), par. 3: <i>AAS </i>58 (1966), 931. </p>
	<p><a name="_ftn42" title="" href="#_ftnref42">[42]</a>&nbsp;Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a></i> (3 October 2020), 
par. 184: <i>AAS</i> 112 (2020), 1034: “Charity, when accompanied by a 
commitment to the truth, is much more than personal feeling […]. Indeed, its 
close relation to truth fosters its universality and preserves it from being 
‘confined to a narrow field devoid of relationships.’ […] Charity’s openness to 
truth thus protects it from ‘a fideism that deprives it of its human and 
universal breadth.’” The internal quotes are from Benedict XVI, Encyclical 
Letter <i>
		<a href="https://www.vatican.va/content/benedict-xvi/en/encyclicals/documents/hf_ben-xvi_enc_20090629_caritas-in-veritate.html">Caritas in Veritate</a></i> (29 June 2009), pars. 2-4: <i>AAS</i> 101 
(2009), 642-643. </p>
	
	
	<p><a name="_ftn45" title="" href="#_ftnref45">[45]</a>&nbsp;John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091998_fides-et-ratio.html">Fides et Ratio</a></i> (14 September 1998), 
par. 13: <i>AAS</i> 91 (1999), 15.</p>
	<p><a name="_ftn46" title="" href="#_ftnref46">[46]</a>&nbsp;Bonaventure, <i>In II Librum Sententiarum</i>, d. I, p. 2, a. 2, q. 1; as 
quoted in <i>Catechism of the Catholic Church</i>, par. 293. Cf. <i>ibid.</i>, 
par. 294. </p>
	<p><a name="_ftn47" title="" href="#_ftnref47">[47]</a>&nbsp;Cf. <i>Catechism of the Catholic Church</i>, pars. 295, 299, 302. 
Bonaventure likens the universe to “a book reflecting, representing, and 
describing its Maker,” the Triune God who grants existence to all things (<i>Breviloquium</i> 
2.12.1). Cf. Alain de Lille, <i>De Incarnatione Christi</i>, PL 210, 579a: “<i>Omnis 
mundi creatura quasi liber et pictura nobis est et speculum.</i>”</p>
	<p><a name="_ftn48" title="" href="#_ftnref48">[48]</a>&nbsp;Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 67:
<i>AAS </i>107 (2015), 874; John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091981_laborem-exercens.html">Laborem Exercens</a> </i>(14 September 1981), par. 6: <i>AAS </i>73 (1981), 589-592; Second Vatican Ecumenical Council, 
Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), pars. 33-34: <i>
AAS </i>58 (1966), 1052-1053; International Theological Commission, <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/cti_documents/rc_con_cfaith_doc_20040723_communion-stewardship_en.html">Communion and Stewardship: Human 
Persons Created in the Image of God</a> </i>(2004), 
par. 57: “human beings occupy a unique place in the universe according to the 
divine plan: they enjoy the privilege of sharing in the divine governance of 
visible creation. […] Since man’s place as ruler is in fact a participation in 
the divine governance of creation, we speak of it here as a form of 
stewardship.”</p>
	<p><a name="_ftn49" title="" href="#_ftnref49">[49]</a>&nbsp;Cf. John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_06081993_veritatis-splendor.html">Veritatis Splendor</a> </i>(6 August 
1993), pars. 38-39: <i>AAS </i>85 (1993), 1164-1165.</p>
	<p><a name="_ftn50" title="" href="#_ftnref50">[50]</a> Cf.&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), pars. 33-34: <i>AAS </i>58 (1966), 1052-1053. This 
idea is also reflected in the creation account, where God brings creatures to 
Adam “to see what he would call them. And whatever [he] called every living 
creature, that was its name” (Gen. 2:19), an action that demonstrates the active 
engagement of human intelligence in the stewardship of God’s creation. Cf. John Chrysostom,
<i>Homiliae in Genesim</i>, XIV, 17-21: PG 53, 116-117.</p>
	<p><a name="_ftn51" title="" href="#_ftnref51">[51]</a>&nbsp;Cf. <i>Catechism of the Catholic Church</i>, par. 301. 
	</p>
	<p><a name="_ftn52" title="" href="#_ftnref52">[52]</a>&nbsp;Cf. <i>Catechism of the Catholic Church</i>, par. 302.</p>
	<p><a name="_ftn53" title="" href="#_ftnref53">[53]</a>&nbsp;Bonaventure, <i>Breviloquium </i>2.12.1. Cf. <i>ibid</i>., 2.11.2.</p>
	
	
	
	<p><a name="_ftn57" title="" href="#_ftnref57">[57]</a>&nbsp;Cf. Francis, Post-Synodal Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20200202_querida-amazonia.html">Querida Amazonia</a> </i>(2 
February 2020), par. 41: <i>AAS</i> 112 (2020), 246; Id., Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 146: <i>AAS </i>107 (2015), 906.</p>
	<p><a name="_ftn58" title="" href="#_ftnref58">[58]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 47: <i>
AAS </i>107 (2015), 864. Cf. Id., Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit Nos</a> </i>(24 
October 2024), pars. 17-24: <i>L’Osservatore Romano</i>, 24 October 2024, 5; Id., 
Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par. 47-50: <i>AAS </i>
112 (2020), 985-987.</p>
	<p><a name="_ftn59" title="" href="#_ftnref59">[59]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit Nos</a></i> (24 October 2024), par. 20:
<i>L’Osservatore Romano</i>, 24 October 2024, 5.</p>
	<p><a name="_ftn60" title="" href="#_ftnref60">[60]</a>&nbsp;P. Claudel, <i>Conversation sur Jean Racine</i>, Gallimard, Paris 1956, 
32: “<i>L’intelligence n’est rien sans la délectation</i>.” Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit Nos</a> </i>(24 October 2024), par. 13:
<i>L’Osservatore Romano</i>, 24 October 2024, 5: “The mind and the will are put 
at the service of the greater good by sensing and savoring truths.”</p>
	<p><a name="_ftn61" title="" href="#_ftnref61">[61]</a>&nbsp;Dante, <i>Paradiso</i>, Canto XXX: “<i>luce intellettüal, piena d’amore; / 
amor di vero ben, pien di letizia; / letizia che trascende ogne dolzore</i>” 
(en. tr. <i>The Divine Comedy of Dante Alighieri</i>, C.E. Norton, tr., Houghton 
Mifflin, Boston 1920, 232).</p>
	<p><a name="_ftn62" title="" href="#_ftnref62">[62]</a>&nbsp;Cf. Second Vatican Ecumenical Council, Declaration <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_decl_19651207_dignitatis-humanae_en.html">Dignitatis Humanae</a></i>
(7 December 1965), par. 3: <i>AAS </i>58 (1966), 931: “[T]he highest norm of 
human life is the divine law itself—eternal, objective and universal, by which 
God orders, directs and governs the whole world and the ways of the human 
community according to a plan conceived in his wisdom and love. God has enabled 
man to participate in this law of his so that, under the gentle disposition of 
divine providence, many may be able to arrive at a deeper and deeper knowledge 
of unchangeable truth.” Also cf. Id., Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 16: <i>AAS </i>58 (1966), 1037.</p>
	<p><a name="_ftn63" title="" href="#_ftnref63">[63]</a>&nbsp;Cf. First Vatican Council, Dogmatic Constitution <i>
		<a href="https://www.vatican.va/content/pius-ix/la/documents/constitutio-dogmatica-dei-filius-24-aprilis-1870.html">Dei Filius</a></i> (24 
April 1870), ch. 4, DH 3016. </p>
	<p><a name="_ftn64" title="" href="#_ftnref64">[64]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 110: <i>
AAS </i>107 (2015), 892. </p>
	<p><a name="_ftn65" title="" href="#_ftnref65">[65]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 110: <i>
AAS </i>107 (2015), 891. Cf. Id., Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a></i> (3 
October 2020), par. 204: <i>AAS </i>112 (2020), 1042.</p>
	<p><a name="_ftn66" title="" href="#_ftnref66">[66]</a>&nbsp;Cf. John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_01051991_centesimus-annus.html">Centesimus Annus</a> </i>(1 May 1991), 
par. 11: <i>AAS </i>83 (1991), 807: “God has imprinted his own image and 
likeness on man (cf. Gen 1:26), conferring upon him an incomparable dignity […]. 
In effect, beyond the rights which man acquires by his own work, there exist 
rights which do not correspond to any work he performs, but which flow from his 
essential dignity as a person.” Cf. Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2024/june/documents/20240614-g7-intelligenza-artificiale.html">Address at the G7 Session on 
Artificial Intelligence in Borgo Egnazia (Puglia)</a></i> (14 June 2024): <i>L’Osservatore Romano</i>, 14 June 2024, 3-4.</p>
	<p><a name="_ftn67" title="" href="#_ftnref67">[67]</a>&nbsp;Cf. Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), par. 8. Cf. <i>ibid., </i>par. 9; Congregation for the Doctrine of the Faith, 
Instruction <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_con_cfaith_doc_20081208_dignitas-personae_en.html">Dignitas Personae</a> </i>(8 September 2008), par. 22.</p>
	
	
	<p><a name="_ftn70" title="" href="#_ftnref70">[70]</a>&nbsp;In this sense, “Artificial Intelligence” is understood as a technical term 
to indicate this technology, recalling that the expression is also used to 
designate the field of study and not only its applications.</p>
	<p><a name="_ftn71" title="" href="#_ftnref71">[71]</a>&nbsp;Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), pars. 34-35: <i>AAS </i>58 (1966), 1052-1053; John Paul II, 
Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_01051991_centesimus-annus.html">Centesimus Annus</a> </i>(1 May 1991), par. 51: <i>AAS </i>83 
(1991), 856-857.</p>
	<p><a name="_ftn72" title="" href="#_ftnref72">[72]</a>&nbsp;For example, see the encouragement of scientific exploration in Albertus Magnus 
(<i>De Mineralibus</i>, II, 2, 1) and the appreciation for the mechanical arts 
in Hugh of St. Victor (<i>Didascalicon</i>, I, 9). These writers, among a long 
list of other Catholics engaged in scientific research and technological 
exploration, illustrate that “faith and science can be united in charity, 
provided that science is put at the service of the men and woman of our time and 
not misused to harm or even destroy them” (Francis, <i>A<a href="https://www.vatican.va/content/francesco/en/speeches/2024/june/documents/20240620-specola-vaticana.html">ddress to Participants 
in the 2024 Lemaître Conference of the Vatican Observatory</a> </i>[20 June 2024]:
<i>L’Osservatore Romano</i>,<i> </i>20 June 2024, 8). Cf. Second Vatican Ecumenical Council, 
Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 36: <i>AAS
</i>58 (1966), 1053-1054; John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091998_fides-et-ratio.html">Fides et Ratio</a></i>  
(14 September 1998), pars. 2, 106: <i>AAS </i>91 (1999), 6-7.86-87.</p>
	<p><a name="_ftn73" title="" href="#_ftnref73">[73]</a>&nbsp;<i>Catechism of the Catholic Church</i>, par. 378.</p>
	<p><a name="_ftn74" title="" href="#_ftnref74">[74]</a>&nbsp;Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 34: <i>AAS </i>58 (1966), 1053.</p>
	<p><a name="_ftn75" title="" href="#_ftnref75">[75]</a>&nbsp;Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 35: <i>AAS </i>58 (1966), 1053.</p>
	<p><a name="_ftn76" title="" href="#_ftnref76">[76]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 102: <i>
AAS </i>107 (2015), 888.</p>
	<p><a name="_ftn77" title="" href="#_ftnref77">[77]</a>&nbsp;Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a></i> (24 May 2015), par. 105:
<i>AAS </i>107 (2015), 889; Id., Encyclical <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a></i> (3 October 2020), par. 27: <i>AAS </i>112 (2020), 978; Benedict XVI, 
Encyclical <i>
		<a href="https://www.vatican.va/content/benedict-xvi/en/encyclicals/documents/hf_ben-xvi_enc_20090629_caritas-in-veritate.html">Caritas in Veritate</a></i> (29 June 2009), par. 23: <i>AAS </i>101 
(2009), 657-658.</p>
	<p><a name="_ftn78" title="" href="#_ftnref78">[78]</a>&nbsp;Cf. Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), pars. 38-39, 47; Congregation for the Doctrine of the Faith, 
Instruction <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_con_cfaith_doc_20081208_dignitas-personae_en.html">Dignitas Personae</a> </i>(8 September 2008), <i>passim</i>.</p>
	<p><a name="_ftn79" title="" href="#_ftnref79">[79]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 35: <i>
AAS </i>58 (1966), 1053. Cf. <i>Catechism of the Catholic Church</i>, par 2293.</p>
	
	<p><a name="_ftn81" title="" href="#_ftnref81">[81]</a>&nbsp;Cf. <i>Catechism of the Catholic Church</i>, par. 1749: “Freedom makes man 
a moral subject. When he acts deliberately, man is, so to speak, the father of 
his acts.”</p>
	<p><a name="_ftn82" title="" href="#_ftnref82">[82]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 16: <i>AAS </i>58 (1966), 1037. Cf.<i> 
Catechism of the Catholic Church</i>, par. 1776.</p>
	<p><a name="_ftn83" title="" href="#_ftnref83">[83]</a>&nbsp;<i>Catechism of the Catholic Church</i>, par. 1777.</p>
	<p><a name="_ftn84" title="" href="#_ftnref84">[84]</a>&nbsp;Cf. <i>Catechism of the Catholic Church</i>, pars. 1779-1781; Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2023/march/documents/20230327-minerva-dialogues.html">Address to the Participants in the “Minerva Dialogues”</a></i> (27 March 2023): <i>
AAS </i>115 (2023), 463, where the Holy Father encouraged efforts “to ensure 
that technology remains human-centered, ethically grounded and directed toward 
the good.”</p>
	<p><a name="_ftn85" title="" href="#_ftnref85">[85]</a>&nbsp;Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), 
par. 166: <i>AAS </i>112 (2020), 1026-1027; Id., <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2024/september/documents/20240923-plenaria-accademia-scienze.html">Address to the Plenary 
Assembly of the Pontifical Academy of Sciences</a> </i>(23 September 2024): <i>L’Osservatore 
</i>Romano, 23 September 2024, 10. On the role of human agency in choosing a 
wider aim (<i>Ziel</i>) that then informs the particular purpose (<i>Zweck</i>) 
for which each technological application is created, cf. F. Dessauer, <i>Streit 
um die Technik</i>, Herder-Bücherei, Freiburg i. Br. 1959, 70-71.</p>
	<p><a name="_ftn86" title="" href="#_ftnref86">[86]</a>&nbsp;Cf. Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2024/june/documents/20240614-g7-intelligenza-artificiale.html">Address at the G7 Session on 
Artificial Intelligence in Borgo Egnazia (Puglia)</a></i> (14 June 2024): <i>L’Osservatore Romano</i>, 14 June 2024, 4: 
“Technology is born for a purpose and, in its impact on human society, always 
represents a form of order in social relations and an arrangement of power, thus 
enabling certain people to perform specific actions while preventing others from 
performing different ones. In a more or less explicit way, this constitutive 
power-dimension of technology always includes the worldview of those who 
invented and developed it.”</p>
	
	
	
	
	<p><a name="_ftn91" title="" href="#_ftnref91">[91]</a>&nbsp;Cf. Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2024/june/documents/20240614-g7-intelligenza-artificiale.html">Address at the G7 Session on 
Artificial Intelligence in Borgo Egnazia (Puglia)</a></i> (14 June 2024): <i>L’Osservatore Romano</i>, 14 June 2024, 2: 
“Faced with the marvels of machines, which seem to know how to choose 
independently, we should be very clear that decision-making […] must always be 
left to the human person. We would condemn humanity to a future without hope if 
we took away people’s ability to make decisions about themselves and their 
lives, by dooming them to depend on the choices of machines.”</p>
	
	<p><a name="_ftn93" title="" href="#_ftnref93">[93]</a>&nbsp;The term “bias” in this document refers to <i>algorithmic bias</i> 
(systematic and consistent errors in computer systems that may 
disproportionately prejudice certain groups in unintended ways) or <i>learning 
bias</i> (which will result in training on a biased data set) and not the “<i>bias 
vector</i>” in neural networks (which is a parameter used to adjust the output 
of “neurons” to adjust more accurately to the data).</p>
	<p><a name="_ftn94" title="" href="#_ftnref94">[94]</a>&nbsp;Cf. Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2023/march/documents/20230327-minerva-dialogues.html">Address to the Participants in the “Minerva Dialogues”</a></i>  
(27 March 2023): <i>AAS </i>115 (2023), 464, where the Holy Father affirmed the 
growth in consensus “on the need for development processes to respect such 
values as inclusion, transparency, security, equity, privacy and reliability,” 
and also welcomed “the efforts of international organizations to regulate these 
technologies so that they promote genuine progress, contributing, that is, to a 
better world and an integrally higher quality of life.”</p>
	
	<p><a name="_ftn96" title="" href="#_ftnref96">[96]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965)<i>, </i>par. 
26: <i>AAS </i>58 (1966), 1046-1047.</p>
	
	<p><a name="_ftn98" title="" href="#_ftnref98">[98]</a>&nbsp;Cf. Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/messages/communications/documents/20240124-messaggio-comunicazioni-sociali.html">Message for the LVIII World Day of Social Communications</a></i> 
(24 January 2024): <i>L’Osservatore Romano</i>, 24 January 2024, 8. For further 
discussion of the ethical questions raised by AI from a Catholic perspective, 
see AI Research Group of the Centre for Digital Culture of the Dicastery for Culture 
and Education, <i>Encountering Artificial Intelligence: Ethical and 
Anthropological Investigations </i>(Theological Investigations of Artificial 
Intelligence 1), M.J. Gaudet, N. Herzfeld, P. Scherz, J.J. Wales, eds., <i>
Journal of Moral Theology</i>, Pickwick, Eugene 2024, 147-253.</p>
	<p><a name="_ftn99" title="" href="#_ftnref99">[99]</a>&nbsp;On the importance of dialogue in a pluralist society oriented toward a 
“robust and solid social ethics,” see Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), pars. 211-214: <i>AAS </i>112 (2020), 1044-1045. 
	</p>
	
	<p><a name="_ftn101" title="" href="#_ftnref101">[101]</a>&nbsp;Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html">Message for the LVII World Day of 
Peace</a> </i>(1 January 2024), par. 6:<i>&nbsp;L’Osservatore Romano</i>,<i>&nbsp;</i>14 December 2023, 3. 
Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965)<i>, </i>par. 26: <i>AAS </i>58 (1966), 1046-1047.</p>
	<p><a name="_ftn102" title="" href="#_ftnref102">[102]</a> Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 112: <i>
AAS </i>107 (2015), 892-893. </p>
	
	<p><a name="_ftn104" title="" href="#_ftnref104">[104]</a> Cf.&nbsp;Pontifical Council for Social Communications, <i>
		<a href="https://www.vatican.va/roman_curia/pontifical_councils/pccs/documents/rc_pc_pccs_doc_20020228_ethics-internet_en.html">Ethics in Internet</a> </i>
(22 February 2002), par. 10. </p>
	
	<p><a name="_ftn106" title="" href="#_ftnref106">[106]</a> Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), pars. 105-114:
<i>AAS </i>107 (2015), 889-893; Id., Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/20231004-laudate-deum.html">Laudate Deum</a> </i>(4 October 2023), pars. 20-33: <i>AAS</i> 115 (2023), 1047-1050. </p>
	<p><a name="_ftn107" title="" href="#_ftnref107">[107]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 105: <i>AAS</i> 107 
(2015), 889. Cf. Id., Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/20231004-laudate-deum.html">Laudate Deum</a> </i>(4 October 
2023), pars. 20-21: <i>AAS </i>115<i> </i>(2023), 1047. </p>
	
	
	<p><a name="_ftn110" title="" href="#_ftnref110">[110]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 112: <i>AAS </i>107 
(2015), 892.</p>
	<p><a name="_ftn111" title="" href="#_ftnref111">[111]</a>&nbsp;Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), 
pars. 101, 103, 111, 115, 167:<i> AAS </i>112 (2020), 1004-1005, 1007-1009, 
1027.</p>
	<p><a name="_ftn112" title="" href="#_ftnref112">[112]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 26: <i>AAS </i>58 (1966), 1046-1047; cf. Leo XIII, 
Encyclical Letter <i>
		<a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html">Rerum Novarum</a> </i>(15 May 1891), par. 35: <i>Acta Leonis 
XIII</i>,<i> </i>11 (1892), 123. </p>
	<p><a name="_ftn113" title="" href="#_ftnref113">[113]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 12: <i>AAS </i>58 (1966), 1034. </p>
	<p><a name="_ftn114" title="" href="#_ftnref114">[114]</a>&nbsp;Cf. Pontifical Council for Justice and Peace, <i>Compendium of the Social 
Doctrine of the Church</i> (2004), par. 149.</p>
	<p><a name="_ftn115" title="" href="#_ftnref115">[115]</a>&nbsp;Second Vatican Ecumenical Council, Declaration <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_decl_19651207_dignitatis-humanae_en.html">Dignitatis Humanae</a> </i>
(7 December 1965), par. 3: <i>AAS </i>58 (1966), 931. Cf. Francis, Encyclical 
Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par. 50: <i>AAS </i>112 (2020), 
986-987.</p>
	<p><a name="_ftn116" title="" href="#_ftnref116">[116]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par. 
50: <i>AAS </i>112 (2020), 986-987.</p>
	<p><a name="_ftn117" title="" href="#_ftnref117">[117]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 47: <i>AAS </i>107 
(2015), 865. Cf. Id., Post-Synodal Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20190325_christus-vivit.html">Christus Vivit</a></i> (25 March 
2019), pars. 88-89: <i>AAS </i>111 (2019), 413-414.</p>
	<p><a name="_ftn118" title="" href="#_ftnref118">[118]</a>&nbsp;Cf. Francis, Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#Yes_to_the_new_relationships_brought_by_Christ">Evangelii Gaudium</a></i> (24 November 
2013), par. 88: <i>AAS</i> 105 (2013), 1057.</p>
	<p><a name="_ftn119" title="" href="#_ftnref119">[119]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par. 
47: <i>AAS </i>112 (2020), 985.</p>
	
	<p><a name="_ftn121" title="" href="#_ftnref121">[121]</a>&nbsp;Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), 
par. 50: <i>AAS </i>112 (2020), 986-987.</p>
	<p><a name="_ftn122" title="" href="#_ftnref122">[122]</a>&nbsp;Cf. E. Stein, 
		<i>Zum Problem der Einfühlung</i>, Buchdruckerei des Waisenhauses, Halle 1917 (en. tr. <i>On the Problem of Empathy</i>, ICS Publications, Washington D.C. 
1989).</p>
	<p><a name="_ftn123" title="" href="#_ftnref123">[123]</a>&nbsp;Cf. Francis, Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#Yes_to_the_new_relationships_brought_by_Christ">Evangelii Gaudium</a></i> (24 November 
2013), par. 88: <i>AAS</i> 105 (2013), 1057: “[Many people] want their 
interpersonal relationships provided by sophisticated equipment, by screens and 
systems which can be turned on and off on command. Meanwhile, the Gospel tells 
us constantly to run the risk of a face-to-face encounter with others, with 
their physical presence which challenges us, with their pain and their pleas, 
with their joy which infects us in our close and continuous interaction. True 
faith in the incarnate Son of God is inseparable from self-giving, from 
membership in the community, from service, from reconciliation with others.” 
Also cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 24: <i>AAS </i>58 (1966), 1044-1045.</p>
	<p><a name="_ftn124" title="" href="#_ftnref124">[124]</a>&nbsp;Cf. Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a></i> (8 April 2024), 
par. 1.</p>
	
	
	<p><a name="_ftn127" title="" href="#_ftnref127">[127]</a>&nbsp;Francis, Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#Concern_for_the_vulnerable">Evangelii Gaudium</a> </i>(24 November 2013), par. 209:
<i>AAS </i>105 (2013), 1107.</p>
	
	<p><a name="_ftn129" title="" href="#_ftnref129">[129]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 26: <i>
AAS </i>58 (1966), 1046-1047.; as quoted in <i>Catechism of the Catholic Church</i>, 
par. 1912. Cf. John XXIII, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-xxiii/en/encyclicals/documents/hf_j-xxiii_enc_15051961_mater.html">Mater et Magistra</a></i> (15 May 
1961), par. 219: <i>AAS </i>53 (1961), 453. </p>
	<p><a name="_ftn130" title="" href="#_ftnref130">[130]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par 64: <i>AAS
</i>58 (1966), 1086.</p>
	<p><a name="_ftn131" title="" href="#_ftnref131">[131]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par. 162: <i>AAS </i>
112 (2020), 1025. Cf. John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091981_laborem-exercens.html">Laborem Exercens</a> </i>(14 September 1981), par. 6: <i>AAS </i>73 (1981), 591: “work is ‘for man’ and 
not man ‘for work.’ Through this conclusion one rightly comes to recognize the 
pre-eminence of the subjective meaning of work over the objective one.”</p>
	<p><a name="_ftn132" title="" href="#_ftnref132">[132]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 128: <i>AAS </i>107 
(2015), 898. Cf. Id., Post-Synodal Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20160319_amoris-laetitia.html">
		Amoris Laetitia</a></i>  
(19 March 2016), par. 24: <i>AAS </i>108 (2016), 319-320.</p>
	
	<p><a name="_ftn134" title="" href="#_ftnref134">[134]</a>&nbsp;John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_25031995_evangelium-vitae.html">Evangelium Vitae</a></i> (25 March 1995), 
par. 89: <i>AAS </i>87 (1995), 502.</p>
	
	
	
	
	
	
	<p><a name="_ftn141" title="" href="#_ftnref141">[141]</a>&nbsp;Francis, <i>Address to the Participants at the Meeting Sponsored by the 
Charity and Health Commission of the Italian Bishops’ Conference </i>(10 
February 2017): <i>AAS </i>109 (2017), 243. Cf. <i>ibid</i>., 242-243: “If there 
is a sector in which the throwaway culture is manifest, with its painful 
consequences, it is that of healthcare. When a sick person is not placed in the 
center or their dignity is not considered, this gives rise to attitudes that can 
lead even to speculation on the misfortune of others. And this is very grave! 
[…] The application of a business approach to the healthcare sector, if 
indiscriminate […] may risk discarding human beings.”</p>
	
	<p><a name="_ftn143" title="" href="#_ftnref143">[143]</a>&nbsp;Second Vatican Ecumenical Council, Declaration <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_decl_19651028_gravissimum-educationis_en.html">Gravissimum Educationis</a> </i>(28 October 1965), par. 1: <i>AAS
</i>58 (1966), 729.</p>
	<p><a name="_ftn144" title="" href="#_ftnref144">[144]</a>&nbsp;Congregation for Catholic Education, <i>Instruction on the Use of Distance Learning in Ecclesiastical Universities 
and Faculties</i>, I. Cf. Second Vatican Ecumenical Council, Declaration <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_decl_19651028_gravissimum-educationis_en.html">Gravissimum Educationis</a> </i>(28 October 1965), par. 1: <i>AAS </i>58 (1966), 
729; Francis, <i><span size="4">
		<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/papa-francesco_20151208_messaggio-xlix-giornata-mondiale-pace-2016.html">Message for the LXIX World Day of Peace</a></span></i> (1 January 2016), 
6: <i>AAS</i> 108 (2016), 57-58.</p>
	
	<p><a name="_ftn146" title="" href="#_ftnref146">[146]</a>&nbsp;Cf. Paul VI, Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/paul-vi/en/apost_exhortations/documents/hf_p-vi_exh_19751208_evangelii-nuntiandi.html">Evangelii Nuntiandi</a></i> (8 December 1975), 
par. 41: <i>AAS </i>68 (1976), 31, quoting Id., <i>Address to the Members of the 
“Consilium de Laicis”</i> (2 October 1974): <i>AAS</i> 66 (1974), 568: “if [the 
contemporary person] does listen to teachers, it is because they are witnesses.”</p>
	<p><a name="_ftn147" title="" href="#_ftnref147">[147]</a> J.H. Newman, <i>The Idea of a University Defined and Illustrated</i>, Discourse 
6.1, London 1873<sup>3</sup>, 125-126.</p>
	
	<p><a name="_ftn149" title="" href="#_ftnref149">[149]</a>&nbsp;Francis, Post-Synodal Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20190325_christus-vivit.html">Christus Vivit</a></i> (25 March 2019), par. 
86: <i>AAS </i>111 (2019), 413, quoting the XV Ordinary General Assembly of the Synod of Bishops,
		<a href="https://www.vatican.va/roman_curia/synod/documents/rc_synod_doc_20181027_doc-final-instrumentum-xvassemblea-giovani_en.html">
<i>Final Document</i> (27 October 2018)</a>, par. 21: <i>AAS </i>110 (2018), 1592.</p>
	<p><a name="_ftn150" title="" href="#_ftnref150">[150]</a> J.H. Newman, <i>The Idea of a University Defined and Illustrated</i>, Discourse 
7.6, Basil Montagu Pickering, London 1873<sup>3</sup>, 167.</p>
	<p><a name="_ftn151" title="" href="#_ftnref151">[151]</a> Cf. Francis, Post-Synodal Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20190325_christus-vivit.html">Christus Vivit</a></i> (25 March 
2019), par. 88: <i>AAS </i>111 (2019), 413.</p>
	<p><a name="_ftn152" title="" href="#_ftnref152">[152]</a> In a 2023 policy document about the use of generative AI in education and 
research, UNESCO notes: “One of the key questions [of the use of generative AI 
(GenAI) in education and research] is whether humans can possibly cede basic 
levels of thinking and skill-acquisition processes to AI and rather concentrate 
on higher-order thinking skills based on the outputs provided by AI. Writing, 
for example, is often associated with the structuring of thinking. With GenAI 
[…], humans can now start with a well-structured outline provided by GenAI. Some 
experts have characterized the use of GenAI to generate text in this way as 
‘writing without thinking’” (UNESCO, <i>Guidance for Generative AI in Education 
and Research </i>[2023], 37-38). The German-American philosopher Hannah Arendt 
foresaw such a possibility in her 1959 book, <i>The Human Condition</i>, and 
cautioned: “If it should turn out to be true that knowledge (in the sense of 
know-how) and thought have parted company for good, then we would indeed become 
the helpless slaves, not so much of our machines as of our know-how” (Id., <i>
The Human Condition</i>, University of Chicago Press, Chicago 2018<sup>2</sup>, 
3). </p>
	<p><a name="_ftn153" title="" href="#_ftnref153">[153]</a>&nbsp;Francis, Post-Synodal Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20160319_amoris-laetitia.html">
		Amoris Laetitia</a></i> (19 March 2016), 
par. 262: <i>AAS </i>108 (2016), 417. </p>
	<p><a name="_ftn154" title="" href="#_ftnref154">[154]</a>&nbsp;Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html">Message for the LVII World Day of 
Peace</a></i> (1 January 2024), par. 7: <i>L’Osservatore Romano</i>, 14 December 2023, 3; 
cf. Id., Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 167: <i>AAS
</i>107 (2015), 914. </p>
	<p><a name="_ftn155" title="" href="#_ftnref155">[155]</a>&nbsp;John Paul II, Apostolic Constitution <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/apost_constitutions/documents/hf_jp-ii_apc_15081990_ex-corde-ecclesiae.html">Ex Corde Ecclesiae</a></i> (15 August 
1990), 7: <i>AAS</i> 82 (1990), 1479.</p>
	<p><a name="_ftn156" title="" href="#_ftnref156">[156]</a>&nbsp;Francis, Apostolic Constitution <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_constitutions/documents/papa-francesco_costituzione-ap_20171208_veritatis-gaudium.html">Veritatis Gaudium</a></i> (29 January 
2018), 4c: <i>AAS</i> 110 (2018), 9-10.</p>
	
	<p><a name="_ftn158" title="" href="#_ftnref158">[158]</a>&nbsp;For example, it might help people access the “array of resources for 
generating greater knowledge of truth” contained in the works of philosophy (John Paul II, 
Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091998_fides-et-ratio.html">Fides et Ratio</a></i> [14 September 1998], par. 3: <i>AAS </i>
91 [1999], 7). Cf. <i>ibid</i>., par. 4: <i>AAS </i>91 (1999), 7-8.</p>
	<p><a name="_ftn159" title="" href="#_ftnref159">[159]</a>&nbsp;Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), par. 43. Cf. <i>ibid.</i>, pars. 61-62.</p>
	
	<p><a name="_ftn161" title="" href="#_ftnref161">[161]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par 25: <i>AAS
</i>58 (1966), 1053; cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 
October 2020), <i>passim</i>: <i>AAS </i>112 (2020), 969-1074.</p>
	<p><a name="_ftn162" title="" href="#_ftnref162">[162]</a>&nbsp;Cf. Francis., Post-Synodal Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20190325_christus-vivit.html">Christus Vivit</a></i> (25 March 
2019), par. 89: <i>AAS </i>111 (2019), 414; John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_14091998_fides-et-ratio.html">Fides et Ratio</a></i> (14 September 1998), par. 25: <i>AAS </i>91 (1999), 25-26: 
“People cannot be genuinely indifferent to the question of whether what they 
know is true or not. […] It is this that Saint Augustine teaches when he writes: 
‘I have met many who wanted to deceive, but none who wanted to be deceived’”; 
quoting Augustine, <i>Confessiones</i>, X, 23, 33: PL 32, 794.</p>
	<p><a name="_ftn163" title="" href="#_ftnref163">[163]</a>&nbsp;Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a></i> 
(4 April 2024), par. 62.</p>
	
	
	<p><a name="_ftn166" title="" href="#_ftnref166">[166]</a>&nbsp;Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a></i> 
(4 April 2024), pars. 1, 6, 16, 24. </p>
	<p><a name="_ftn167" title="" href="#_ftnref167">[167]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a></i>, (7 December 1965), par. 26: <i>AAS </i>58 (1966), 1046. Cf. Leo XIII, 
Encyclical Letter<i>
		<a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html">Rerum Novarum</a></i> (15 May 1891), par. 40: <i>Acta Leonis 
XIII</i>,<i> </i>11 (1892), 127: “no man may with impunity violate that human 
dignity which God himself treats with great reverence”; as quoted in John Paul II, 
Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_01051991_centesimus-annus.html">Centesimus Annus</a> </i>(1 May 1991), par. 9: <i>AAS </i>83 
(1991), 804.</p>
	
	<p><a name="_ftn169" title="" href="#_ftnref169">[169]</a>&nbsp;Cf. Permanent Observer Mission of the Holy See to the United Nations, <i>
Holy See Statement to the Thematic Discussion on Other Disarmament Measures and 
International Security</i> (24 October 2022): “Upholding human dignity in 
cyberspace obliges States to also respect the right to privacy, by shielding 
citizens from intrusive surveillance and allowing them to safeguard their 
personal information from unauthorized access.”</p>
	<p><a name="_ftn170" title="" href="#_ftnref170">[170]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par. 
42: <i>AAS </i>112 (2020), 984.</p>
	
	
	<p><a name="_ftn173" title="" href="#_ftnref173">[173]</a>&nbsp;The 2023 <i>Interim Report</i> of the United Nations AI Advisory Body<i>
</i>identified a list of “early promises of AI helping to address climate 
change” (United Nations AI Advisory Body, <i>Interim Report: Governing AI for 
Humanity</i> [December 2023], 3). The document observed that, “taken together 
with predictive systems that can transform data into insights and insights into 
actions, AI-enabled tools may help develop new strategies and investments to 
reduce emissions, influence new private sector investments in net zero, protect 
biodiversity, and build broad-based social resilience” (<i>ibid</i>.).</p>
	<p><a name="_ftn174" title="" href="#_ftnref174">[174]</a>&nbsp;“The cloud” refers to a network of physical servers throughout the world 
that enables users to store, process, and manage their data remotely.</p>
	<p><a name="_ftn175" title="" href="#_ftnref175">[175]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 9: <i>
AAS </i>107 (2015), 850.</p>
	<p><a name="_ftn176" title="" href="#_ftnref176">[176]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 106: <i>
AAS </i>107 (2015), 890. </p>
	<p><a name="_ftn177" title="" href="#_ftnref177">[177]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 60: <i>
AAS </i>107 (2015), 870. </p>
	<p><a name="_ftn178" title="" href="#_ftnref178">[178]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), pars. 3, 13:
<i>AAS </i>107 (2015), 848.852.</p>
	<p><a name="_ftn179" title="" href="#_ftnref179">[179]</a>&nbsp;Augustine, <i>De Civitate Dei</i>, XIX, 13, 1: PL 41, 640.</p>
	<p><a name="_ftn180" title="" href="#_ftnref180">[180]</a>&nbsp;Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), pars.&nbsp;77-82: <i>AAS </i>58 (1966), 1100-1107; Francis, 
Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), pars.&nbsp;256-262: <i>
AAS </i>112 (2020), 1060-1063; Dicastery for the Doctrine of the Faith, 
Declaration<i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(4 April 2024), pars. 38-39; <i>Catechism of 
the Catholic Church</i>, pars. 2302-2317.</p>
	<p><a name="_ftn181" title="" href="#_ftnref181">[181]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par.&nbsp;78: <i>AAS </i>58 (1966), 1101.</p>
	
	<p><a name="_ftn183" title="" href="#_ftnref183">[183]</a>&nbsp;Cf.<b> </b><i>Catechism of the Catholic Church</i>, pars. 2308-2310. 
	</p>
	<p><a name="_ftn184" title="" href="#_ftnref184">[184]</a> Cf. Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), pars.&nbsp;80-81: <i>AAS </i>58 (1966), 1103-1105.</p>
	
	<p><a name="_ftn186" title="" href="#_ftnref186">[186]</a>&nbsp;Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/speeches/2024/june/documents/20240614-g7-intelligenza-artificiale.html">Address at the G7 Session on 
Artificial Intelligence in Borgo Egnazia (Puglia)</a></i> (14 June 2024): <i>L’Osservatore Romano</i>, 14 June 2024, 2. Cf. Permanent Observer Mission of the Holy See to the United Nations,
<i>Holy See Statement to Working Group II on Emerging Technologies at the UN 
Disarmament Commission </i>(3 April 2024): “The development and use of lethal 
autonomous weapons systems (LAWS) that lack the appropriate human control would 
pose fundamental ethical concerns, given that LAWS can never be morally 
responsible subjects capable of complying with international humanitarian law.”</p>
	<p><a name="_ftn187" title="" href="#_ftnref187">[187]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a> </i>(3 October 2020), par.&nbsp;258: 
<i>AAS </i>112 (2020), 1061. Cf. Second Vatican Ecumenical Council, Pastoral 
Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 80: <i>AAS </i>58 
(1966), 1103-1104. </p>
	<p><a name="_ftn188" title="" href="#_ftnref188">[188]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 80: <i>AAS </i>58 (1966), 1103-1104.</p>
	<p><a name="_ftn189" title="" href="#_ftnref189">[189]</a>&nbsp;Cf. Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html">Message for the LVII World Day of 
Peace</a> </i>(1 January 
2024), par. 6: <i>L’Osservatore Romano</i>,<i>&nbsp;</i>14 December 2023, 3: 
“Nor can we ignore the possibility of sophisticated weapons ending up in the 
wrong hands, facilitating, for instance, terrorist attacks or interventions 
aimed at destabilizing the institutions of legitimate systems of government. In 
a word, the world does not need new technologies that contribute to the unjust 
development of commerce and the weapons trade and consequently end up promoting 
the folly of war.”</p>
	
	<p><a name="_ftn191" title="" href="#_ftnref191">[191]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 79: <i>
AAS </i>107 (2015), 878.</p>
	<p><a name="_ftn192" title="" href="#_ftnref192">[192]</a>&nbsp;Cf. Benedict XVI, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/benedict-xvi/en/encyclicals/documents/hf_ben-xvi_enc_20090629_caritas-in-veritate.html">Caritas in Veritate</a> </i> (29 June 
2009), par. 51: <i>AAS </i>101 (2009), 687.</p>
	<p><a name="_ftn193" title="" href="#_ftnref193">[193]</a>&nbsp;Cf. Dicastery for the Doctrine of the Faith, Declaration <i>
		<a href="https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20240402_dignitas-infinita_en.html">Dignitas 
Infinita</a> </i>(8 April 2024), pars. 38-39. </p>
	<p><a name="_ftn194" title="" href="#_ftnref194">[194]</a>&nbsp;Cf.&nbsp;Augustine, <i>Confessiones</i>, I, 1, 1: PL 32, 661.</p>
	<p><a name="_ftn195" title="" href="#_ftnref195">[195]</a>&nbsp;Cf. John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_30121987_sollicitudo-rei-socialis.html">Sollicitudo Rei Socialis</a> </i>(30 
December 1987), par. 28: <i>AAS </i>80 (1988), 548: “[T]here is a better 
understanding today that the mere accumulation of goods and services […] is not 
enough for the realization of human happiness. Nor, in consequence, does the 
availability of the many real benefits provided in recent times by science and 
technology, including the computer sciences, bring freedom from every form of 
slavery. On the contrary, […] unless all the considerable body of resources and 
potential at man’s disposal is guided by a moral understanding and by an 
orientation towards the true good of the human race, it easily turns against man 
to oppress him.” Cf. <i>ibid.</i>, pars. 29, 37: <i>AAS </i>80 (1988), 
550-551.563-564.</p>
	<p><a name="_ftn196" title="" href="#_ftnref196">[196]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 14: <i>AAS </i>58 (1966), 1036.</p>
	<p><a name="_ftn197" title="" href="#_ftnref197">[197]</a>&nbsp;Francis, Encyclical Letter<i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit Nos</a> </i>(24 October 2024), par. 18:
<i>L’Osservatore Romano</i>, 24 October 2024, 5. </p>
	<p><a name="_ftn198" title="" href="#_ftnref198">[198]</a>&nbsp;Francis, Encyclical Letter<i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit Nos</a> </i>(24 October 2024), par. 27:
<i>L’Osservatore Romano</i>, 24 October 2024, 6. </p>
	<p><a name="_ftn199" title="" href="#_ftnref199">[199]</a>&nbsp;Francis, Encyclical Letter<i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/20241024-enciclica-dilexit-nos.html">Dilexit Nos</a> </i>(24 October 2024), par. 25:
<i>L’Osservatore Romano</i>, 24 October 2024, 5-6. </p>
	<p><a name="_ftn200" title="" href="#_ftnref200">[200]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 105: <i>AAS </i>107 
(2015), 889. Cf. R. Guardini, <i>Das Ende der Neuzeit</i>, Würzburg 1965<sup>9</sup>, 
87 ff. (en. tr. <i>The End of the Modern World</i>, Wilmington 1998, 82-83).</p>
	<p><a name="_ftn201" title="" href="#_ftnref201">[201]</a>&nbsp;Second Vatican Ecumenical Council, Pastoral Constitution <i>
		<a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et 
Spes</a> </i>(7 December 1965), par. 34: <i>AAS </i>58 (1966), 1053.</p>
	<p><a name="_ftn202" title="" href="#_ftnref202">[202]</a>&nbsp;John Paul II, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/john-paul-ii/en/encyclicals/documents/hf_jp-ii_enc_04031979_redemptor-hominis.html">Redemptor Hominis</a> </i>(4 March 1979), 
par. 15: <i>AAS </i>71 (1979), 287-288.</p>
	<p><a name="_ftn203" title="" href="#_ftnref203">[203]</a>&nbsp;N. Berdyaev, “Man and Machine,” in C. Mitcham – R. Mackey, eds., <i>
Philosophy and Technology: Readings in the Philosophical Problems of Technology</i>, 
New York 1983<sup>2</sup>, 212-213.</p>
	<p><a name="_ftn204" title="" href="#_ftnref204">[204]</a>&nbsp;N. Berdyaev, “Man and Machine,” 210. 
	</p>
	<p><a name="_ftn205" title="" href="#_ftnref205">[205]</a>&nbsp;G. Bernanos, “La révolution de la liberté” (1944), in Id., <i>Le Chemin de 
la Croix-des-Âmes</i>, Rocher 1987, 829.</p>
	
	<p><a name="_ftn207" title="" href="#_ftnref207">[207]</a>&nbsp;Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 112: <i>
AAS </i>107 (2015), 892-893.</p>
	<p><a name="_ftn208" title="" href="#_ftnref208">[208]</a>&nbsp;Cf. Bonaventure, <i>Hex. </i>XIX, 3; Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html">Fratelli Tutti</a></i> (3 October 2020), par. 50: <i>AAS </i>112 (2020), 986: “The 
flood of information at our fingertips does not make for greater wisdom. Wisdom 
is not born of quick searches on the internet nor is it a mass of unverified 
data. That is not the way to mature in the encounter with truth.”</p>
	
	
	
	<p><a name="_ftn212" title="" href="#_ftnref212">[212]</a>&nbsp;Francis, Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20180319_gaudete-et-exsultate.html#An_intellect_without_God_and_without_flesh">Gaudete et Exsultate</a></i> (19 March 2018), par. 37: <i>
AAS </i>110 (2018), 1121. </p>
	<p><a name="_ftn213" title="" href="#_ftnref213">[213]</a>&nbsp;Francis, <i>
		<a href="https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html">Message for the LVII World Day of 
Peace</a></i> (1 January 2024), par. 6: <i>L’Osservatore Romano</i>, 14 December 2023, 3. 
Cf. Id., Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 112: <i>AAS
</i>107 (2015), 892-893; Id., Apostolic Exhortation <i>
		<a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20180319_gaudete-et-exsultate.html#The_limits_of_reason">Gaudete et Exsultate</a></i> 
(19 March 2018), par. 46:<i> AAS </i>110 (2018), 1123-1124.</p>
	<p><a name="_ftn214" title="" href="#_ftnref214">[214]</a> Cf. Francis, Encyclical Letter <i>
		<a href="https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html">Laudato Si’</a> </i>(24 May 2015), par. 112: <i>
AAS </i>107 (2015), 892-893.</p>
	
</div>
										</td>
												</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A history of APL in the USSR (1991) (107 pts)]]></title>
            <link>https://dl.acm.org/doi/10.1145/130647.130656</link>
            <guid>42877430</guid>
            <pubDate>Thu, 30 Jan 2025 13:18:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/doi/10.1145/130647.130656">https://dl.acm.org/doi/10.1145/130647.130656</a>, See on <a href="https://news.ycombinator.com/item?id=42877430">Hacker News</a></p>
<div id="readability-page-1" class="page"><article xmlns="http://www.w3.org/1999/xhtml" data-design="pill" data-theme="article" data-type="article" vocab="http://schema.org/" typeof="ScholarlyArticle" lang="en" dir="ltr"><header data-extent="frontmatter"><div><p><a href="#tab-contributors" data-id="article-authors-viewall">Authors Info &amp; Claims</a></p><div><p><span>Published</span>: <span>01 December 1991</span> <a href="#core-history">Publication History</a></p><a data-target="crossmark" href="#" title="Check for updates on crossmark" data-doi="10.1145/130647.130656" data-id="article-info-crossmark"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 290 58" height="27px" role="presentation"><path fill="url(#horizontal_crossmark)" stroke="#948F8F" stroke-miterlimit="10" stroke-width=".75" d="M287 1H3a2 2 0 0 0-2 2v52a2 2 0 0 0 2 2h284a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2Z"></path><path fill="#535353" d="M80.3 23.58a6.395 6.395 0 0 0-.55-1.43 3.92 3.92 0 0 0-2.19-1.86 5.099 5.099 0 0 0-1.71-.29 5 5 0 0 0-2.46.58 4.831 4.831 0 0 0-1.69 1.54 6.921 6.921 0 0 0-1 2.19 10.16 10.16 0 0 0 0 5 6.921 6.921 0 0 0 1 2.19 4.83 4.83 0 0 0 1.69 1.5 5 5 0 0 0 2.46.58 4.44 4.44 0 0 0 1.85-.36 4.12 4.12 0 0 0 1.38-1c.39-.436.695-.942.9-1.49A7.094 7.094 0 0 0 80.4 29h3a8.46 8.46 0 0 1-.69 2.92 7.179 7.179 0 0 1-1.59 2.29 7 7 0 0 1-2.35 1.49 8.14 8.14 0 0 1-3 .52 8.43 8.43 0 0 1-3.59-.74 7.88 7.88 0 0 1-2.69-2 9.001 9.001 0 0 1-1.69-3 11.41 11.41 0 0 1 0-7.23 9.001 9.001 0 0 1 1.69-3 8.001 8.001 0 0 1 2.69-2 8.3 8.3 0 0 1 3.59-.75 9.44 9.44 0 0 1 2.83.41c.866.242 1.68.642 2.4 1.18A6.229 6.229 0 0 1 82.65 21a6.66 6.66 0 0 1 .78 2.58H80.3ZM85.9 17.9h2.85v6.63h.05a4.15 4.15 0 0 1 1.56-1.46 4.61 4.61 0 0 1 2.31-.59 4.83 4.83 0 0 1 3.33 1.1 4.21 4.21 0 0 1 1.22 3.3v8.88H94.4v-8.13a3.51 3.51 0 0 0-.65-2.21 2.36 2.36 0 0 0-1.87-.69 3.1 3.1 0 0 0-1.3.26 2.821 2.821 0 0 0-1 .73A3.41 3.41 0 0 0 89 26.8a3.88 3.88 0 0 0-.23 1.33v7.63H85.9V17.9ZM102.47 30c-.002.491.069.98.21 1.45.131.448.348.866.64 1.23a3.08 3.08 0 0 0 1.08.84 3.543 3.543 0 0 0 1.55.31 3.431 3.431 0 0 0 2-.54c.541-.402.94-.966 1.14-1.61h2.7A5.349 5.349 0 0 1 109.7 35a5.715 5.715 0 0 1-1.74.85 7 7 0 0 1-2 .29 6.848 6.848 0 0 1-2.7-.5 5.577 5.577 0 0 1-2-1.4A5.953 5.953 0 0 1 100 32a8.748 8.748 0 0 1-.41-2.75 7.768 7.768 0 0 1 .44-2.61 6.67 6.67 0 0 1 1.25-2.17 5.863 5.863 0 0 1 4.56-2 5.79 5.79 0 0 1 2.74.64c.783.41 1.466.986 2 1.69a6.824 6.824 0 0 1 1.16 2.41c.264.905.352 1.852.26 2.79h-9.53Zm6.65-1.87a4.605 4.605 0 0 0-.29-1.3c-.148-.4-.368-.77-.65-1.09a3.22 3.22 0 0 0-1-.75 3 3 0 0 0-1.31-.29 3.431 3.431 0 0 0-1.36.26 3.108 3.108 0 0 0-1 .73 3.594 3.594 0 0 0-.7 1.09 3.798 3.798 0 0 0-.29 1.35h6.65-.05ZM122.88 27.15a2.666 2.666 0 0 0-1-1.81 3.14 3.14 0 0 0-2-.61c-.4.005-.798.07-1.18.19-.435.136-.83.376-1.15.7a3.92 3.92 0 0 0-.87 1.43 6.783 6.783 0 0 0-.35 2.39c.002.539.065 1.076.19 1.6.113.509.316.993.6 1.43.273.41.635.752 1.06 1a3 3 0 0 0 1.58.39 2.872 2.872 0 0 0 2.06-.77 3.596 3.596 0 0 0 1-2.18h2.85a6.26 6.26 0 0 1-1.91 3.86 5.83 5.83 0 0 1-4 1.34 6.61 6.61 0 0 1-2.69-.51 5.695 5.695 0 0 1-2-1.4 6.001 6.001 0 0 1-1.21-2.11 8.279 8.279 0 0 1-.41-2.65 8.987 8.987 0 0 1 .4-2.72 6.237 6.237 0 0 1 1.2-2.21 5.614 5.614 0 0 1 2-1.47 6.7 6.7 0 0 1 2.79-.54 7.801 7.801 0 0 1 2.14.29 5.634 5.634 0 0 1 1.8.86c.529.386.969.88 1.29 1.45a5 5 0 0 1 .6 2.07h-2.85l.06-.02ZM128.13 17.9H131V28l5.15-5.22h3.5l-5 4.75 5.42 8.17h-3.47l-4-6.27-1.6 1.7v4.63h-2.85V17.9h-.02ZM147.15 22.83h2.13v-1.08a5.505 5.505 0 0 1 .3-2c.161-.456.436-.862.8-1.18.33-.273.721-.462 1.14-.55.44-.094.89-.141 1.34-.14a8.158 8.158 0 0 1 2 .18v2.24a4.113 4.113 0 0 0-.59-.11 6.343 6.343 0 0 0-.74 0 1.74 1.74 0 0 0-1 .27 1.204 1.204 0 0 0-.41 1.08v1.33h2.42V25h-2.42v10.8h-2.85V25h-2.12v-2.17ZM162.23 36.1a6.999 6.999 0 0 1-2.76-.51 5.877 5.877 0 0 1-2-1.41 5.998 5.998 0 0 1-1.33-2.18 8.775 8.775 0 0 1 0-5.48 6.008 6.008 0 0 1 1.27-2.15 5.894 5.894 0 0 1 2-1.41A7.71 7.71 0 0 1 165 23a5.894 5.894 0 0 1 2 1.41 6.003 6.003 0 0 1 1.28 2.15c.585 1.78.585 3.7 0 5.48a5.99 5.99 0 0 1-3.28 3.54 7.002 7.002 0 0 1-2.77.52Zm0-2.25a3.268 3.268 0 0 0 1.65-.4c.447-.262.83-.621 1.12-1.05.304-.444.528-.938.66-1.46a6.581 6.581 0 0 0 0-3.31 4.416 4.416 0 0 0-.66-1.46 3.526 3.526 0 0 0-1.15-1 3.6 3.6 0 0 0-3.3 0 3.526 3.526 0 0 0-1.15 1 4.414 4.414 0 0 0-.66 1.46 6.558 6.558 0 0 0 0 3.31c.132.522.356 1.016.66 1.46a3.47 3.47 0 0 0 1.15 1.05 3.26 3.26 0 0 0 1.68.4ZM171.13 22.83h2.67v2.5c.097-.362.264-.701.49-1 .251-.341.547-.647.88-.91a4.404 4.404 0 0 1 1.14-.66 3.41 3.41 0 0 1 1.28-.25c.23-.013.46-.013.69 0h.39v2.79l-.61-.09a5.173 5.173 0 0 0-.61 0 3.278 3.278 0 0 0-1.36.29 3.131 3.131 0 0 0-1.11.85 4.171 4.171 0 0 0-.75 1.39 6 6 0 0 0-.28 1.9v6.15h-2.85V22.83h.03ZM198.22 35.75h-2.8V34a3.907 3.907 0 0 1-1.56 1.56 4.25 4.25 0 0 1-2.11.59 4.742 4.742 0 0 1-3.75-1.31 5.537 5.537 0 0 1-1.12-3.84v-8.2h2.85v7.92a3.503 3.503 0 0 0 .65 2.4 2.38 2.38 0 0 0 1.83.7 3.599 3.599 0 0 0 1.5-.27 2.66 2.66 0 0 0 1-.74c.259-.326.444-.705.54-1.11a5.79 5.79 0 0 0 .16-1.4v-7.5h2.85v12.95h-.04ZM201.3 22.83h2.7v1.75a3.523 3.523 0 0 1 1.72-1.58 5.568 5.568 0 0 1 2.33-.49 6.17 6.17 0 0 1 2.66.54 5.246 5.246 0 0 1 1.89 1.47c.515.65.899 1.394 1.13 2.19.257.87.385 1.773.38 2.68.001.851-.114 1.7-.34 2.52a6.568 6.568 0 0 1-1 2.16 5.002 5.002 0 0 1-4.21 2.06c-.419 0-.837-.036-1.25-.11a5.39 5.39 0 0 1-1.2-.36A4.737 4.737 0 0 1 205 35a3.567 3.567 0 0 1-.81-.91v6.45h-2.89V22.83Zm10 6.47c0-.574-.078-1.146-.23-1.7a4.606 4.606 0 0 0-.67-1.46 3.475 3.475 0 0 0-1.12-1 3.06 3.06 0 0 0-1.55-.39A3.141 3.141 0 0 0 205 26a5.518 5.518 0 0 0-1 3.3c-.004.611.077 1.22.24 1.81.138.523.38 1.012.71 1.44a3.55 3.55 0 0 0 1.14 1 3.242 3.242 0 0 0 1.54.35 3.18 3.18 0 0 0 1.65-.4c.438-.25.817-.59 1.11-1 .299-.44.513-.931.63-1.45a7.38 7.38 0 0 0 .23-1.75h.05ZM228.67 35.75H226V34a3.38 3.38 0 0 1-1.67 1.61 5.668 5.668 0 0 1-2.33.49 6.17 6.17 0 0 1-2.66-.54 5.307 5.307 0 0 1-1.89-1.46 6.254 6.254 0 0 1-1.12-2.19 9.48 9.48 0 0 1-.37-2.71 8.67 8.67 0 0 1 .47-3 6.058 6.058 0 0 1 1.26-2.1 4.89 4.89 0 0 1 1.8-1.21 5.738 5.738 0 0 1 2.06-.39c.412 0 .824.037 1.23.11.413.073.815.194 1.2.36.38.166.736.381 1.06.64.32.255.594.562.81.91V17.9h2.85v17.85h-.03Zm-10-6.33c-.001.55.069 1.098.21 1.63.13.511.35.996.65 1.43.288.414.668.757 1.11 1a3.241 3.241 0 0 0 1.6.38 3.199 3.199 0 0 0 1.64-.4 3.398 3.398 0 0 0 1.13-1.05c.297-.447.517-.94.65-1.46.14-.542.211-1.1.21-1.66a5.227 5.227 0 0 0-1-3.35 3.175 3.175 0 0 0-2.61-1.2 3.23 3.23 0 0 0-1.69.41 3.478 3.478 0 0 0-1.12 1.07 4.494 4.494 0 0 0-.62 1.5 7.871 7.871 0 0 0-.11 1.7h-.05ZM242.6 32.88c-.018.258.03.516.14.75a.577.577 0 0 0 .54.23h.3c.135-.002.269-.019.4-.05v2l-.39.11-.49.08-.5.08h-.42a2.75 2.75 0 0 1-1.45-.35 1.731 1.731 0 0 1-.75-1.23 4.998 4.998 0 0 1-2.09 1.2 8.224 8.224 0 0 1-2.39.38 5.861 5.861 0 0 1-1.67-.24 4.394 4.394 0 0 1-1.41-.7 3.35 3.35 0 0 1-1-1.18 3.624 3.624 0 0 1-.36-1.66 3.84 3.84 0 0 1 .44-2 3.246 3.246 0 0 1 1.15-1.17 5.195 5.195 0 0 1 1.6-.61c.593-.127 1.19-.223 1.79-.29a14.77 14.77 0 0 1 1.47-.21 6.896 6.896 0 0 0 1.24-.21c.318-.077.611-.236.85-.46a1.286 1.286 0 0 0 .31-.94 1.458 1.458 0 0 0-.26-.9A1.759 1.759 0 0 0 239 25a2.807 2.807 0 0 0-.86-.25 6.941 6.941 0 0 0-.9-.06 3.58 3.58 0 0 0-2 .5 2 2 0 0 0-.87 1.55h-2.85c.021-.73.227-1.442.6-2.07.338-.54.797-.996 1.34-1.33a5.475 5.475 0 0 1 1.84-.7c.692-.134 1.395-.2 2.1-.2.632 0 1.262.067 1.88.2a5.337 5.337 0 0 1 1.66.65 3.6 3.6 0 0 1 1.19 1.16c.314.525.47 1.129.45 1.74v6.65l.02.04Zm-2.85-3.6a3.45 3.45 0 0 1-1.6.51c-.667.06-1.3.147-1.9.26a6.137 6.137 0 0 0-.87.21 2.64 2.64 0 0 0-.75.38c-.22.164-.395.38-.51.63a2.129 2.129 0 0 0-.19.94c-.011.29.085.575.27.8.182.215.407.388.66.51.269.128.555.216.85.26.277.05.558.076.84.08a4.63 4.63 0 0 0 1-.12 3.418 3.418 0 0 0 1-.43 2.73 2.73 0 0 0 .81-.76 1.93 1.93 0 0 0 .32-1.14v-2.14l.07.01ZM244.37 22.83h2.15V19h2.85v3.88h2.58V25h-2.58v6.9a7.064 7.064 0 0 0 0 .77c.016.194.074.381.17.55a.84.84 0 0 0 .41.34 2 2 0 0 0 .75.11h.6c.203-.01.404-.04.6-.09v2.2l-.93.1a8.403 8.403 0 0 1-.92 0 6.33 6.33 0 0 1-1.81-.21 2.421 2.421 0 0 1-1.08-.62 2.15 2.15 0 0 1-.52-1 7.791 7.791 0 0 1-.16-1.42V25h-2.15v-2.17h.04ZM256.22 30c-.002.491.069.98.21 1.45.131.448.348.866.64 1.23a3.08 3.08 0 0 0 1.08.84 3.543 3.543 0 0 0 1.55.31 3.431 3.431 0 0 0 2-.54c.541-.402.94-.966 1.14-1.61h2.7a5.352 5.352 0 0 1-2.1 3.26 5.715 5.715 0 0 1-1.74.85 7 7 0 0 1-2 .29 6.848 6.848 0 0 1-2.7-.5 5.577 5.577 0 0 1-2-1.4 5.947 5.947 0 0 1-1.21-2.18 8.754 8.754 0 0 1-.41-2.75 7.758 7.758 0 0 1 .44-2.61 6.67 6.67 0 0 1 1.25-2.17 5.863 5.863 0 0 1 4.56-2 5.79 5.79 0 0 1 2.74.64c.783.41 1.466.986 2 1.69a6.824 6.824 0 0 1 1.16 2.41c.243.916.308 1.87.19 2.81h-9.5V30Zm6.65-1.87a4.605 4.605 0 0 0-.29-1.3c-.148-.4-.368-.77-.65-1.09a3.22 3.22 0 0 0-1-.75 3 3 0 0 0-1.31-.29 3.431 3.431 0 0 0-1.36.26 3.108 3.108 0 0 0-1 .73 3.575 3.575 0 0 0-.7 1.09 3.798 3.798 0 0 0-.29 1.35h6.65-.05ZM270 31.6a2.154 2.154 0 0 0 .95 1.75c.607.35 1.3.524 2 .5.304-.002.608-.022.91-.06a3.943 3.943 0 0 0 1-.24c.286-.105.54-.28.74-.51a1.23 1.23 0 0 0 .26-.89 1.261 1.261 0 0 0-.4-.9 2.779 2.779 0 0 0-1-.56 9.315 9.315 0 0 0-1.34-.36l-1.5-.33a14.219 14.219 0 0 1-1.54-.42 4.937 4.937 0 0 1-1.33-.68 3.12 3.12 0 0 1-.94-1.09 3.472 3.472 0 0 1-.35-1.64 2.94 2.94 0 0 1 .51-1.76 3.913 3.913 0 0 1 1.3-1.15 5.66 5.66 0 0 1 1.75-.61 10.316 10.316 0 0 1 1.84-.17 8.418 8.418 0 0 1 1.91.21 5.19 5.19 0 0 1 1.65.69c.496.318.916.741 1.23 1.24.341.559.55 1.188.61 1.84h-3a1.783 1.783 0 0 0-.94-1.37 3.892 3.892 0 0 0-1.69-.35 6.093 6.093 0 0 0-.71 0 3.327 3.327 0 0 0-.78.19 1.642 1.642 0 0 0-.61.4 1 1 0 0 0-.25.69 1.093 1.093 0 0 0 .36.85c.294.245.634.428 1 .54.437.153.885.274 1.34.36l1.55.33a20.9 20.9 0 0 1 1.53.42c.479.157.931.386 1.34.68.41.277.751.643 1 1.07.255.494.379 1.045.36 1.6a3.48 3.48 0 0 1-.52 2 4.15 4.15 0 0 1-1.36 1.3 6.19 6.19 0 0 1-1.86.73 9.435 9.435 0 0 1-2 .23 8.823 8.823 0 0 1-2.26-.27 5.265 5.265 0 0 1-1.8-.84 4 4 0 0 1-1.2-1.4 4.445 4.445 0 0 1-.46-2h2.7v-.02Z"></path><path fill="#C72914" d="m21.94 38.74 18.12-12.08v-14.5H21.94v26.58Z"></path><path fill="#EF3340" d="M40.06 38.74 21.94 26.66v-14.5h18.12v26.58Z"></path><path fill="#3EB1C8" d="M31 9a20 20 0 1 0 0 40 20 20 0 0 0 0-40Zm0 35.1a15.1 15.1 0 1 1 0-30.2 15.1 15.1 0 0 1 0 30.2Z"></path><path fill="#FFC72C" d="M42.09 39.23A15.09 15.09 0 0 1 17 23.38l-4.2-2.64a20 20 0 0 0 33.49 21.14l-4.2-2.65Z"></path><defs><linearGradient id="horizontal_crossmark" x1="145" x2="145" y1="7.33" y2="56.82" gradientUnits="userSpaceOnUse"><stop stop-color="#fff"></stop><stop offset="1" stop-color="#c4c4c4"></stop></linearGradient></defs></svg></a></div></div></header><div id="abstracts" data-extent="frontmatter"><p><img alt="First page of PDF" src="https://dl.acm.org/cms/10.1145/130647.130656/asset/134a1e0e-7959-4e32-8552-334b7b850684/assets/130647.130656.fp.png" loading="lazy"></p></div><section id="backmatter" role="doc-bibliography" data-extent="backmatter"><h2>References</h2><div role="list"><div role="listitem" data-has="label"><p>[1]</p><div id="ref-00001"><p>[1] S. P. Prokhorov, "The Implementation of APL/BESM-6 System"; Programming, Moscow, 6, 1977.</p></div></div><div role="listitem" data-has="label"><p>[2]</p><div id="ref-00002"><p>[2] E. T. Semenova, A. L. Semenov, "APL/MEI"; Programming Languages, Moscow, Vol. 2, 1975.</p></div></div><div role="listitem" data-has="label"><p>[3]</p><div id="ref-00003"><p>[3] A. I. Miroshnikov, A. I. Troyan, "APL 2.0"; Technical report of LIIAN, Leningrad, 1981.</p></div></div><div role="listitem" data-has="label"><p>[4]</p><div id="ref-00004"><p>[4] I. I. Malashinin, A. I. Kononov "Implementation of APL for ES Computer"; Applied Informatics, Moscow, Vol. 1, 1981.</p></div></div><div role="listitem" data-has="label"><p>[5]</p><div id="ref-00005"><p>[5] O. P. Luksha, G. A. Reimarov, "APL Computers In Teaching; New Approach," DIALOG-87 Conference proceedings, Tbilisi, 1988.</p></div></div><div role="listitem" data-has="label"><p>[6]</p><div id="ref-00006"><p>[6] O. P. Luksha, A. A. Pogorely, "Optimal Plans of the Experiment for the Investigation of Dissolution Kinetics"; Plant Laboratory, Moscow, Vol. 54, 10, 1988.</p></div></div><div role="listitem" data-has="label"><p>[7]</p><div id="ref-00007"><p>[7] L. Gilman, A. Rose, "APL An Interactive Approach"; Translation into Russian, MIR, Moscow, 1979.</p></div></div><div role="listitem" data-has="label"><p>[8]</p><div id="ref-00008"><p>[8] A. V. Kondrashev, "The Implementation of APL for SM Computers"; Programming, Moscow, 1, 1986.</p></div></div><div role="listitem" data-has="label"><p>[9]</p><div id="ref-00009"><p>[9] A. V. Barmin, M. I. Kaganov, A. V. Kondrashev, "DVK As A Personal APL Machine"; Microprocessor Means And Systems, Moscow, 4, 1989.</p></div></div><div role="listitem" data-has="label"><p>[10]</p><div id="ref-00010"><p>[10] A. V. Kondrashev, "The Family of Soviet APL Systems"; APL Quote Quad, Vol. 20, 4, 1990.</p></div></div><div role="listitem" data-has="label"><p>[11]</p><div id="ref-00011"><p>[11] A. O. Skomorokhov, D. A. Lucyanov, "APL Technology of Modelling of Local Systems For NPP Diagnostics; The Experience of Application and the Review of the Software Products"; Report #C-89-32 (USSR) at the Scientific Technical Seminar of "Interatom-Energo," Moscow, June, 1989.</p></div></div><div role="listitem" data-has="label"><p>[12]</p><div id="ref-00012"><p>[12] A. V. Kondrashev, V. M. Kupriyanov, O. P. Luksha, A. I. Miroshnikov, A. O. Skomorokhov, "The World of APL Language"; Computing Technique And Its Usage, Znanie, Moscow, Vol. 4, 1990.</p></div></div><div role="listitem" data-has="label"><p>[13]</p><div id="ref-00013"><p>[13] James A. Brown, Sandra Pakin, Raymond P. Polivka, "APL2 at a Glance," Prentice Hall, Englewood Cliffs, New Jersey, 1988.</p></div></div></div></section><div><div id="core-collateral-info" role="tabpanel"><header><h2>Information &amp; Contributors</h2></header><section id="tab-information" aria-labelledby="information" role="tabpanel"><h3>Information</h3><section><h4>Published In</h4>



        
        <div><p><img src="https://dl.acm.org/cms/asset/c0f43c3b-756d-47d0-9ace-a40576b6216d/1354923.cover.jpg" data-src="/cms/asset/c0f43c3b-756d-47d0-9ace-a40576b6216d/1354923.cover.jpg" alt="cover image ACM SIGAPL APL Quote Quad" height="171" width="132"></p><div><p><span>ACM SIGAPL APL Quote Quad</span>&nbsp;<span> Volume 22, Issue 2</span></p><p>Russian focus issue</p><p>Dec. 1991</p><p>26  pages</p></div></div>
<p>Copyright © 1991 Authors.</p></section><section><h4>Publisher</h4><div><p>Association for Computing Machinery</p><p>New York, NY, United States</p></div></section><section id="core-history"><h4>Publication History</h4><p><b>Published</b>: 01 December 1991</p><p>Published in&nbsp;SIGAPL&nbsp;<span property="isPartOf" typeof="PublicationVolume">Volume <span property="volumeNumber">22</span></span>, <span property="isPartOf" typeof="PublicationIssue">Issue <span property="issueNumber">2</span></span></p></section><section><h4>Check for updates</h4><a data-target="crossmark" href="#" title="Check for updates on crossmark" data-doi="10.1145/130647.130656" data-id="article-info-crossmark"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" height="36px" role="presentation"><rect x="5" y="5" width="90" height="90" rx="2" ry="2"></rect><polygon points="35.95 65.11 64.05 46.38 64.05 23.91 35.95 23.91 35.95 65.11"></polygon><polygon points="64.05 65.11 35.95 46.38 35.95 23.91 64.05 23.91 64.05 65.11"></polygon><path d="M50,19A31,31,0,1,0,81,50,31,31,0,0,0,50,19Zm0,54.41A23.41,23.41,0,1,1,73.41,50,23.41,23.41,0,0,1,50,73.41Z"></path><path d="M67.18,65.86a23.38,23.38,0,0,1-38.9-24.57l-6.49-4.1A31,31,0,0,0,73.69,70Z"></path><defs><linearGradient id="no_text_crossmark" x1="50" y1="15.18" x2="50" y2="94.72" gradientUnits="userSpaceOnUse"><stop stop-color="#fff"></stop><stop offset="1" stop-color="#c4c4c4"></stop></linearGradient></defs></svg></a></section><section><h4>Qualifiers</h4><ul><li>Article</li></ul></section></section><section id="tab-contributors" aria-labelledby="contributors" role="tabpanel"><h3>Contributors</h3>









    
    
        <div data-widget-def="acmPublicationContributorsWidget" data-widget-id="774172a5-8222-4087-8d6e-7a1a17ded31e"><p><img src="https://dl.acm.org/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif"></p></div>
    

<section><h4>Other Metrics</h4></section></section></div><div id="core-collateral-metrics" role="tabpanel"><header><h2>Bibliometrics &amp; Citations</h2></header><section id="tab-metrics-inner" aria-labelledby="metrics-inner" role="tabpanel"><h3>Bibliometrics</h3><section>



        
            <h4>
                Article Metrics
            </h4>
        
        <div><ul><li><a href="#tab-citations">View Citations</a></li><li></li></ul><ul><li><span>Downloads (Last 12 months)</span><span>55</span></li><li><span>Downloads (Last 6 weeks)</span><span>8</span></li></ul><p><span>Reflects downloads up to 27 Jan 2025</span></p></div>
</section><section><h4>Other Metrics</h4></section></section><section id="tab-citations" aria-labelledby="citations" role="tabpanel"><h3>Citations</h3><div><ul data-pagesize="10" data-more="Show More Cited By" data-total="1"><li><span><span>Hui R</span><span>Kromberg M</span></span><span>(2020)</span><span>APL since 1978</span><span>Proceedings of the ACM on Programming Languages</span><span>10.1145/3386319</span><span><b>4</b><span>:HOPL</span></span><span>(1-108)</span><span>Online publication date: 12-Jun-2020</span></li></ul></div></section></div><div id="core-collateral-fulltext-options" role="tabpanel"><header><h2>View Options</h2></header><div tabindex="0"><h3>View options</h3><section><h4> <abbr title="Portable Document Format">PDF</abbr></h4><p>View or Download as a PDF file.</p><a href="https://dl.acm.org/doi/pdf/10.1145/130647.130656" aria-label="View PDF" title="View PDF"><span>PDF</span></a></section><section><h4> <abbr title="Electronic Reader">eReader</abbr></h4><p>View online with <abbr title="Electronic Reader">eReader</abbr>.</p><a href="https://dl.acm.org/doi/epdf/10.1145/130647.130656" aria-label="View online with eReader" title="View online with eReader"><span>eReader</span></a></section></div><!-- Its needed to duplicate this for PB check Collateral.js as well--><div tabindex="-1"><div><h4>Login options</h4><div><p>Check if you have access through your login credentials or your institution to get full access on this article.</p><p><a title="Sign in" href="https://dl.acm.org/action/showLogin?redirectUri=%2Fdoi%2F10.1145%2F130647.130656">Sign in</a></p></div></div><div><h4>Full Access</h4></div></div></div><p id="core-collateral-figures" role="tabpanel"><header><h2>Figures</h2></header><!-- There is no content. --></p><p id="core-collateral-tables" role="tabpanel"><header><h2>Tables</h2></header><!-- There is no content. --></p><p id="core-collateral-media" role="tabpanel"><header><h2>Media</h2></header><!-- There is no content. --></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Audiocube – A 3D DAW for Spatial Audio (205 pts)]]></title>
            <link>https://www.audiocube.app</link>
            <guid>42877399</guid>
            <pubDate>Thu, 30 Jan 2025 13:12:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.audiocube.app">https://www.audiocube.app</a>, See on <a href="https://news.ycombinator.com/item?id=42877399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="siteWrapper">
      
      

      












  




      <main id="page" role="main">
        
          
<article id="sections" data-page-sections="65b3b6e1b2fd050adf61b14a">
  
  
    
    


  
  


<section data-test="page-section" data-section-theme="black-bold" data-section-id="678d2cb08dbda17fa2c972f0" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;backgroundImage&quot;: {
                        &quot;id&quot;: &quot;679990a24ce06c5bb487966e&quot;,
                        &quot;recordType&quot;: 2,
                        &quot;addedOn&quot;: 1738117282260,
                        &quot;updatedOn&quot;: 1738117285871,
                        &quot;workflowState&quot;: 1,
                        &quot;publishOn&quot;: 1738117282260,
                        &quot;authorId&quot;: &quot;6111afdce1647b38b8e47725&quot;,
                        &quot;systemDataId&quot;: &quot;d447cb51-fe63-4fa3-9bd5-a529ead4a0e3&quot;,
                        &quot;systemDataVariants&quot;: &quot;4253x1898,100w,300w,500w,750w,1000w,1500w,2500w&quot;,
                        &quot;systemDataSourceType&quot;: &quot;JPG&quot;,
                        &quot;filename&quot;: &quot;Web BG COlor Gradient 2-min.jpg&quot;,
                        &quot;mediaFocalPoint&quot;: {
                          &quot;x&quot;: 0.5188284518828452,
                          &quot;y&quot;: 1.0,
                          &quot;source&quot;: 3
                        },
                        &quot;colorData&quot;: {
                          &quot;topLeftAverage&quot;: &quot;380f69&quot;,
                          &quot;topRightAverage&quot;: &quot;006baf&quot;,
                          &quot;bottomLeftAverage&quot;: &quot;020005&quot;,
                          &quot;bottomRightAverage&quot;: &quot;000716&quot;,
                          &quot;centerAverage&quot;: &quot;0c1842&quot;,
                          &quot;suggestedBgColor&quot;: &quot;151c57&quot;
                        },
                        &quot;urlId&quot;: &quot;mo045m3laajctetldta0za2146udgh&quot;,
                        &quot;title&quot;: &quot;&quot;,
                        &quot;body&quot;: null,
                        &quot;likeCount&quot;: 0,
                        &quot;commentCount&quot;: 0,
                        &quot;publicCommentCount&quot;: 0,
                        &quot;commentState&quot;: 2,
                        &quot;unsaved&quot;: false,
                        &quot;author&quot;: {
                          &quot;id&quot;: &quot;6111afdce1647b38b8e47725&quot;,
                          &quot;displayName&quot;: &quot;Ark Audio&quot;,
                          &quot;firstName&quot;: &quot;Ark&quot;,
                          &quot;lastName&quot;: &quot;Audio&quot;,
                          &quot;avatarUrl&quot;: &quot;https://images.squarespace-cdn.com/content/v2/namespaces/memberAccountAvatars/libraries/6111afdce1647b38b8e47725/c5536852-a1ad-4783-bb65-4997a9313eeb/noah+m+head.png?format=300w&quot;,
                          &quot;bio&quot;: &quot;&quot;,
                          &quot;avatarAssetUrl&quot;: &quot;https://images.squarespace-cdn.com/content/v2/namespaces/memberAccountAvatars/libraries/6111afdce1647b38b8e47725/c5536852-a1ad-4783-bb65-4997a9313eeb/noah+m+head.png?format=300w&quot;
                        },
                        &quot;assetUrl&quot;: &quot;https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg&quot;,
                        &quot;contentType&quot;: &quot;image/jpeg&quot;,
                        &quot;items&quot;: [ ],
                        &quot;pushedServices&quot;: { },
                        &quot;pendingPushedServices&quot;: { },
                        &quot;originalSize&quot;: &quot;4253x1898&quot;,
                        &quot;recordTypeLabel&quot;: &quot;image&quot;
                      },
                      &quot;imageOverlayOpacity&quot;: 0.0,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false,
                        &quot;type&quot;: &quot;soft-corners&quot;,
                        &quot;width&quot;: {
                          &quot;unit&quot;: &quot;vw&quot;,
                          &quot;value&quot;: 100.0
                        },
                        &quot;height&quot;: {
                          &quot;unit&quot;: &quot;vw&quot;,
                          &quot;value&quot;: 6.0
                        },
                        &quot;isFlipX&quot;: false,
                        &quot;isFlipY&quot;: true,
                        &quot;offset&quot;: {
                          &quot;unit&quot;: &quot;px&quot;,
                          &quot;value&quot;: 0.0
                        },
                        &quot;stroke&quot;: {
                          &quot;style&quot;: &quot;none&quot;,
                          &quot;color&quot;: {
                            &quot;type&quot;: &quot;SITE_PALETTE_COLOR&quot;,
                            &quot;sitePaletteColor&quot;: {
                              &quot;colorName&quot;: &quot;darkAccent&quot;,
                              &quot;alphaModifier&quot;: 1.0
                            }
                          },
                          &quot;thickness&quot;: {
                            &quot;unit&quot;: &quot;px&quot;,
                            &quot;value&quot;: 6.0
                          },
                          &quot;dashLength&quot;: {
                            &quot;unit&quot;: &quot;px&quot;,
                            &quot;value&quot;: 5.0
                          },
                          &quot;gapLength&quot;: {
                            &quot;unit&quot;: &quot;px&quot;,
                            &quot;value&quot;: 5.0
                          },
                          &quot;linecap&quot;: &quot;square&quot;
                        }
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section="">
  <div>
    
      
        
        
          





  



<p><img alt="" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg" data-image-dimensions="4253x1898" data-image-focal-point="0.5188284518828452,1.0" data-load="false" elementtiming="nbf-background" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg" width="4253" height="1898" sizes="(max-width: 799px) 200vw, 100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/d447cb51-fe63-4fa3-9bd5-a529ead4a0e3/Web+BG+COlor+Gradient+2-min.jpg?format=2500w 2500w" fetchpriority="high" loading="eager" decoding="async" data-loader="sqs"></p>
      
    
    </div>
  <div data-fluid-engine="true"><div data-block-type="23" id="block-e36654e20c3f4c8caa4e"><p><span> A Standalone 3D Audio Workstation</span></p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-1a43bf9a82d886939b37">
  <h2><strong>Create Totally Immersive Audio</strong></h2><p>Audiocube is a <span><strong>3D DAW </strong></span>— unleash a new dimension of sonic creativity in your music and sound design.</p><p><span>No credit card required </span></p>
</div></div>
  
</section>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678a64fd4447dd78577938cd" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-block-type="23" id="block-8ae57b83ce94115f62ef"><p>
  <h2>Unlock a new <span>sonic dimension...</span></h2>
</p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0}}" id="block-a6b210f96707920e509b">
  <p><span><strong>✅ An Intuitive Workflow</strong></span></p><p><span>Instantly import audio files, process and spatialize your sounds, then record and export your project as a HD .wav file. </span></p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0}}" id="block-95acb798e3bc7804bd9e">
  <p><span><strong>✅ More Power Than VST Plugins</strong></span></p><p><span>As a standalone app, Audiocube offers tools, workflows, and processes that go beyond the capabilities of VST plugins.</span></p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0}}" id="block-273debcc074593c4e333">
  <p><span><strong>✅ Support You Can Count On</strong></span></p><p><span>Our responsive support team ensures you’ll never feel stuck, with help available whenever you need it. </span></p>
</div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black" data-section-id="678a663da217376b315c1f4b" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1737122899196_29878">
  <h4><span><strong>1000+ sound designers &amp; musicians </strong></span>are using Audiocube for audio spatialization and experimentation</h4><p><strong>Featured on</strong></p>
</div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="100.35249787285767" data-block-type="5" id="block-9d1feb521afac4eded5c">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg" width="512" height="512" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e47d6e88-4946-4e3a-ade3-1364e3a4da85/-1386445_20220419426.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="83.8257691136156" data-block-type="5" id="block-79d0ba19132b025a764d">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png" data-image-dimensions="200x200" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png" width="200" height="200" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c3ba0dcd-9426-4ec9-b855-f8a09a9e9ee5/kvraudio-dark-200x200-www.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="100.35249787285767" data-block-type="5" id="block-1a49b67cb21167e74aa3">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg" data-image-dimensions="900x900" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg" width="900" height="900" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/69e37cff-c78f-495e-a9c3-2e1f54a360c2/unnamed.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="100.38910505836576" data-block-type="5" id="block-yui_3_17_2_1_1737122899196_60232">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png" data-image-dimensions="225x225" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png" width="225" height="225" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5b8e74f4-d094-4c6d-97e3-6314989793a4/download.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="73.69454610372222" data-block-type="5" id="block-247b8ef1633b7fa21f34">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg" data-image-dimensions="696x522" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg" width="696" height="522" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/c8b829e2-c7b3-4376-856f-844b9d8bdd33/music-tech-news-banner%402000x1500-696x522.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="58.21874338904167" data-block-type="5" id="block-a2714f1a3993d2bff038">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg" data-image-dimensions="2463x1269" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg" width="2463" height="1269" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3eb663d9-a9bd-4c05-a286-be1a1a1c860e/Logo_audiofanzine2013.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678a7e6c8b4c0060b5d45f38" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1737122899196_90321">
  <p>Audio Spatialization &amp; Experimentation</p><h3>Are 2D plugins really the best way to work with 3D audio? </h3><p><span>Try it free!</span></p>
</div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="91.84070137711427" data-block-type="5" id="block-yui_3_17_2_1_1737122899196_98079">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png" data-image-dimensions="964x721" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png" width="964" height="721" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/5d784c27-b4d5-4836-9f8f-759c116cd22a/spatial+audio+plguin+2d.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-block-type="5" id="block-949e0332446ec4ad2aa6">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png" data-image-dimensions="877x638" data-image-focal-point="0.7242697242697242,0.6080760095011877" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png" width="877" height="638" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/51fb8d27-5111-46a2-ab8a-5f7807244435/audio+range+editor.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0}}" id="block-70fa9a9f9142a94c399b">
  <h4><span>Audiocube provides </span><span><span><strong>total spatial freedom</strong></span></span></h4><p><span>A dedicated 3D audio engine gives you  a level of control, depth, and freedom that 2D software can’t.</span></p><p><span>✅ Total freedom of source and listener placement<br>✅ Natural &amp; customizable acoustic simulation<br>✅ Quick and easy for 3D audio creation</span></p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:20.0}}" id="block-yui_3_17_2_1_1737122899196_102143">
  <h4><span>2D interfaces are bad for 3D audio production</span></h4><p><span> 2D DAWs and plugins don’t have the level of depth and freedom you need to fulfill your creative vision</span></p><p><span>❌ VSTs only offer a fixed listening perspective <br>❌ 2D software creates a barrier between creativity <br>❌ Fiddly, difficult, and time consuming </span></p>
</div></div>

  
    
    


  
  


<div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-2d08f58c542ffcd69821" data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678a857b6dcf924e58753f83" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section="">
  <h3>How To Easily Spatialize Audio In 2 Minutes</h3><p>Audiocube is a 3D audio engine that expands your immersive audio workflow with a deep set of spatial and experimental tools. </p><p><strong>Stop wasting time</strong> with fiddly VST plugins and 2D DAWs</p><p><span>Try it free!</span></p>
</div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678a8a05e5a1d940b92f8c89" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1737122899196_270664">
                
            
            
            
            
            
            
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg" data-image-dimensions="582x496" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg" width="582" height="496" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 37.5vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/35bee2b7-27a7-4fb1-bd29-b70f47baa29d/Library+Panel+copy.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-49b95a2e9aa84b35a9b5">

<p>
  <h4>Import Your Audio Files</h4>
</p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-6e8faf3da0186b7ba764">

<p>Instantly fill your audio library with your own file collection, or download our included 2GB+ (and growing) custom sample packs  </p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-ae57d85ea8a1139c46cb">
  <p><strong>📁 Flexible Browser</strong></p><p>Easily import, manage, and browse your audio file collection</p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-bc5529ee44fbae9c4006">
  <p><strong>📯2GB+ Samples Included </strong></p><p>Download our collections of custom made samples, including synths, drums, textures, field recordings and more…</p>
</div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678a8c09b9b359721e0e5a4a" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="81.60929214712567" data-block-type="5" id="block-69b804bc29fe2fb398d0">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg" data-image-dimensions="1451x602" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg" width="1451" height="602" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/83273785-1dd3-4988-8f5f-823602f4fe73/logic+boxes+new+audiocube+device.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-f67d3eb298a491f7a3cf">

<p>Create sound sources and devices, and place them exactly where you want them</p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-7c6d61c30c2598345998">

<p>
  <h4>Place Sounds &amp; Devices</h4>
</p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-e9d47b3f37bfe482d876">
  <p><strong>🔊 </strong><a href="https://www.audiocube.app/features#:~:text=Seven%20Powerful%20Devices" target="_blank"><strong>7 Unique Device </strong></a><strong>Types</strong></p><p>Samplers, Emitters, Tickers, Logic Boxes, Ambience Nodes, FX Zones, Soundwalls each provide powerful functionality. </p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-ac17c184cb447c409dae">
  <p><span><strong>✥</strong></span><strong>Total Placement Freedom</strong></p><p>Place your sources and listening position wherever you want in the scene. Automate their movement over time. </p>
</div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678d2e6abcfe336df342ff30" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-block-type="5" id="block-5fe8a804ebee8afaac92">
                
            
            
            
            
            
            
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png" data-image-dimensions="467x761" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png" width="467" height="761" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 25vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/439438ff-ce9a-4152-acd9-36ecbff00631/spatial+acoustics+editor.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-8962350ae11a03f54005">

<p>
  <h4>Adjust the Acoustic Engine</h4>
</p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-f034be6b067557ffd273">

<p>Tweak and customize the acoustic simulation algorithm to capture the type of spatialization and sonic rendering required for your project. </p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-a40b58f437cd0fc9be57">
  <p><strong>🔊 Advanced Acoustics</strong></p><p>Get full control over how the acoustic engine processes reflections, occlusion, air absortion, depth, and more.</p>
</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-f48433f9de4c5f5993dc">
  <p><strong>🎧 HRTF Binauralization</strong></p><p>Use a detailed Binaural process to capture a perfectly immersive spatial audio scene for headphone listening. </p>
</div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678d3230a5264926a5cf2fc0" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-block-type="5" id="block-c80ede10f1827c6ada43">
                
            
            
            
            
            
            
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg" data-image-dimensions="855x334" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg" width="855" height="334" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 29.166666666666668vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/ec1233c3-b421-4206-9be9-05b91028e9b4/record+in+progress.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-9ff9f6e975ed6446369f">

<p>Use a flexible mixer and mastering effects for some final coloration, then export your finished audio. </p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-7d918bcc184e24461e87">

<p>
  <h4>Mix, Master, and Export</h4>
</p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:10.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:10.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:10.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:10.0}}" id="block-594b8498682a4f688a7d">

<p><span><em>“Your binauralization algorithm sounds incredible! It sounds so much more natural than Dear VR PRo's HRTF VST."</em> </span></p>




















  
  
    
  



</div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-block-type="5" id="block-5765cd9957d5028d9c8b">
                
            
            
            
            
            
            
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png" data-image-dimensions="935x1031" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png" width="935" height="1031" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 20.833333333333336vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/e661609d-2e66-4206-9ef7-e071010d8358/Audiocube+Effects.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black" data-section-id="678a87ee7226647bfd45f84e" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1737122899196_241143">
  <p><span><strong>Cross-Platform and Fully Standalone</strong></span></p><h4><strong>Easy to Learn, with Powerful Depth</strong></h4><p>Audiocube is easy to set up and requires no other software. It includes a 2GB+ sound library, an intuitive interface, and personal support. </p><p>Your purchase includes both Windows and Mac versions. </p><p><a href="https://www.audiocube.app/features" target="_blank">Discover More Features</a></p>
</div><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1737122899196_244829">
                
            
            
            
            
            
            
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png" data-image-dimensions="3164x2062" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png" width="3164" height="2062" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 54.166666666666664vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/fb358681-16b0-491e-90c5-d82344c5f15a/light+overview++copy-min.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="678d36703b4bfd0459b3fe3a" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;backgroundColor&quot;: &quot;&quot;,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 1,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-a54990e25a6283162856">

<p>
  <h3><strong>You’re 2 Minutes Away From Creating More Immersive Music</strong></h3>
</p>




















  
  



</div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-6939ba93509572acc20a">
  <p>Stand out from the crowd with <strong>deeper, immersive, and more natural sounding audio</strong>. Whether you’re making music or working on sound design don’t miss out on the realism you need.</p><p><strong>Expand your sound with Audiocube!<p>✅ No other software required - Mac or Windows</p></strong></p><p><strong>✅ Extensive tutorials and rapid support</strong></p><p><strong>✅ Try Audiocube For Free</strong></p>
</div><div data-block-type="23" id="block-00e233ab00ec649b9a13">


  <meta charset="UTF-8">
  <title>Enhanced Abstract Floating Popup</title>
  
  <!-- Font Awesome CDN for Icons -->
  
  
  <!-- Enhanced Popup Styles -->
  



  <!-- Enhanced Abstract Floating Popup Container -->
  

  <!-- JavaScript to Handle Close Button and Popup Logic -->
  


</div></div>

  
    
    


  
  


<div data-fluid-engine="true" data-test="page-section" data-section-theme="black-bold" data-section-id="67537cdecddaf7368e7332b9" data-controller="SectionWrapperController" data-current-styles="{
                      &quot;imageOverlayOpacity&quot;: 0.15,
                      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                      &quot;sectionHeight&quot;: &quot;section-height--custom&quot;,
                      &quot;customSectionHeight&quot;: 1,
                      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                      &quot;customContentWidth&quot;: 50,
                      &quot;sectionTheme&quot;: &quot;black-bold&quot;,
                      &quot;sectionAnimation&quot;: &quot;none&quot;,
                      &quot;backgroundMode&quot;: &quot;image&quot;
                    }" data-current-context="{
                      &quot;video&quot;: {
                        &quot;playbackSpeed&quot;: 0.5,
                        &quot;filter&quot;: 2,
                        &quot;filterStrength&quot;: 0,
                        &quot;zoom&quot;: 0,
                        &quot;videoSourceProvider&quot;: &quot;none&quot;
                      },
                      &quot;backgroundImageId&quot;: null,
                      &quot;backgroundMediaEffect&quot;: {
                        &quot;type&quot;: &quot;none&quot;
                      },
                      &quot;divider&quot;: {
                        &quot;enabled&quot;: false
                      },
                      &quot;typeName&quot;: &quot;page&quot;
                    }" data-animation="none" data-fluid-engine-section=""><div data-animation-role="image" data-test="image-block-fluid-outer-wrapper" data-aspect-ratio="104.98490439449849" data-block-type="5" id="block-yui_3_17_2_1_1737304558178_132097">
                
            
            
            
            
            
            
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png" data-image="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png" data-image-dimensions="3164x2062" data-image-focal-point="0.13750101882794033,0.472059007375922" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png" width="3164" height="2062" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65b3b3cd8a8cd17472028226/3fc72628-1321-4a55-b232-e0edc137d951/fairlight+small+autoo+copy+2-min.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"></p>
          
              </div><div data-blend-mode="NORMAL" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-396619f85ac85b18b89f">
  <p><span><strong>Unlock a deeper level of creative freedom</strong></span></p><h2><strong>It’s Not Just Another VST Plugin…</strong></h2><p>Audiocube is a standalone 3D DAW, built with a custom audio, physics, and graphical engine - enabling more depth and control than any plugin. </p><p>Move your workflow away from a cluttered and compromised VST-based setup, and embrace a modern solution for immersive audio creation and exploration. </p>
</div></div>

  
</article>


          

          
            
          
        
      </main>
      
        

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LibreOffice 400M Downloads, and Counting (197 pts)]]></title>
            <link>https://blog.documentfoundation.org/blog/2025/01/30/400-million-downloads-and-counting/</link>
            <guid>42876998</guid>
            <pubDate>Thu, 30 Jan 2025 11:59:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.documentfoundation.org/blog/2025/01/30/400-million-downloads-and-counting/">https://blog.documentfoundation.org/blog/2025/01/30/400-million-downloads-and-counting/</a>, See on <a href="https://news.ycombinator.com/item?id=42876998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<article>
			<div id="content_box">
							
														<header>
								
								
							</header><!--.headline_area-->
							<div>
								<p><a href="https://blog.documentfoundation.org/wp-content/uploads/2025/01/libreofficedownloadsperyear.png"><img fetchpriority="high" decoding="async" src="https://blog.documentfoundation.org/wp-content/uploads/2025/01/libreofficedownloadsperyear.png" alt="" width="761" height="410" srcset="https://blog.documentfoundation.org/wp-content/uploads/2025/01/libreofficedownloadsperyear.png 761w, https://blog.documentfoundation.org/wp-content/uploads/2025/01/libreofficedownloadsperyear-300x162.png 300w" sizes="(max-width: 761px) 100vw, 761px"></a></p>
<p>The histogram says it all.</p>
<p>First, rapid growth between 2011 and 2014 to 30 million downloads, despite the fierce hostility of the project created to kill LibreOffice.</p>
<p>Then a few years of stagnation, at a time when it seemed that desktop office suites were destined to die, and fashion was driving users to the cloud.</p>
<p>Then the upswing, when even the most fashionable users realised that desktop office suites would never die and would coexist with the cloud.</p>
<p>In 2019, a series of attacks on the download counter – no data is collected other than the click on the DOWNLOAD button – led to a barely credible increase (the figure you see has already been cleaned up as much as possible).</p>
<p>After 2019, a slow but inexorable growth to over 35 million downloads – and 400 million downloads since 2011, with an average of 28.6 million downloads per year – in 2024.</p>
<p>Thanks to everyone: those who developed LibreOffice, those who helped improve it, and those who downloaded it to use it.</p>
<h3><a href="https://www.libreoffice.org/download/">Click here to download LibreOffice</a></h3>
																							</div>
						</div>
		</article>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interview with DeepSeek Founder: We're Done Following. It's Time to Lead (122 pts)]]></title>
            <link>https://thechinaacademy.org/interview-with-deepseek-founder-were-done-following-its-time-to-lead/</link>
            <guid>42876940</guid>
            <pubDate>Thu, 30 Jan 2025 11:47:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thechinaacademy.org/interview-with-deepseek-founder-were-done-following-its-time-to-lead/">https://thechinaacademy.org/interview-with-deepseek-founder-were-done-following-its-time-to-lead/</a>, See on <a href="https://news.ycombinator.com/item?id=42876940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Try Premium Member for Free with a <span>7-Day</span> Trial</p></div><h2>Editor’s Note:</h2><p>Silicon Valley is reeling. A seismic shift in AI dominance is underway, and all eyes are on China. In January 2025, DeepSeek-R1—an open-source inference model from Chinese AI firm DeepSeek—sent shockwaves through the tech world by matching OpenAI’s top-tier performance at 1/30th the API cost, all while embracing full openness.</p><p>With just $6 million, China built one of the world’s finest AI models, dwarfing the billions spent by Meta, Google, and Microsoft. Already, global users—especially individuals and SMEs—are flocking to DeepSeek-R1, retraining it as their foundational model.</p><p>This Eastern-led revolution is forcing a global reckoning: What if AI’s future isn’t forged in Silicon Valley?</p><p>Translated from a July 2024 interview with DeepSeek founder Liang Wenfeng—conducted shortly after the company’s open-source V2 model catapulted it to fame—this rare dialogue unveils how a Chinese startup dared to leapfrog giants and redefine innovation’s rules.</p><p><img decoding="async" src="https://thechinaacademy.org/wp-content/uploads/2025/01/33412227540b40718a0eaf36d96890d3_batchwm.png" alt="" data-href=""><span>This post-85s entrepreneur appeared on Xinwen Lianbo (CCTV News) as the founder of the AI startup DeepSeek, participating in a high-level national symposium and delivering a speech.<br></span></p><h2>How Was the First Shot in the Price War Fired?</h2><p><strong>An Yong (Interviewer)</strong>: After the release of the DeepSeek V2 model, it quickly triggered a fierce price war in the large model industry. Some say you are a disruptor in the market.</p><p><strong>Liang Wenfeng (DeepSeek Founder)</strong>: We never intended to be a disruptor; it just happened by accident.</p><p><strong>An Yong: </strong>Were you surprised by this outcome?</p><p><strong>Liang Wenfeng:</strong> Very surprised. We didn’t expect pricing to be such a sensitive issue. We were simply following our own pace, calculating costs, and setting prices accordingly. <strong>Our principle is neither to sell at a loss nor to seek excessive profits. </strong>The current pricing allows for a modest profit margin above our costs.</p><p><strong>An Yong: </strong>Five days later, Zhipu AI followed suit, and soon after, ByteDance, Alibaba, Baidu, and Tencent joined the race.</p><p><strong>Liang Wenfeng: </strong>Zhipu AI lowered prices for an entry-level product, while their flagship models remain expensive. ByteDance was the first to truly match our price for a flagship model, which then pressured others to follow. Since large companies have much higher model costs than us, we never imagined anyone would operate at a loss. It ended up mirroring the internet era’s subsidy-driven logic.</p><p><strong>An Yong:</strong> From an outsider’s perspective, price cuts seem like a tactic to grab users—typical of internet-era competition.</p><p><strong>Liang Wenfeng: </strong>Grabing users wasn’t our primary goal. We reduced prices because, <strong>first, while exploring next-generation model structures, our costs decreased; second, we believe that both AI and API services should be affordable and accessible to everyone.</strong></p><p><strong>An Yong: </strong>Before this, most Chinese companies simply copied the Llama model structure to develop applications. Why did you choose to focus on model structure instead?</p><p><strong>Liang Wenfeng:</strong> If the goal is to develop applications, adopting Llama’s structure to quickly launch a product is a reasonable choice. However, our goal is AGI (Artificial General Intelligence), which requires us to explore new model structures to achieve superior capabilities within limited resources. This is foundational research for scaling up. Beyond architecture, we’ve studied data curation and human-like reasoning—all reflected in our models. Also, Llama’s training efficiency and inference costs lag behind cutting-edge global standards by about two generations.</p><p><strong>An Yong:</strong> Where does this generational gap come from?</p><p><strong>Liang Wenfeng:</strong> First, there’s a gap in training efficiency. We estimate that China’s best models likely require twice the compute power to match top global models due to structural and training dynamics gaps. Data efficiency is also half as effective, meaning we need twice the data and compute for equivalent results. Combined, that’s four times the resources. Our goal is to continuously narrow these gaps.</p><p><strong>An Yong: </strong>Most Chinese firms pursue both models and applications. Why is DeepSeek focusing solely on research?</p><p><strong>Liang Wenfeng: </strong>Because we believe the most important thing right now is to participate global innovation. For years, Chinese companies have been accustomed to leveraging technological innovations developed elsewhere and monetizing them through applications. But this isn’t sustainable. <strong>This time, our goal isn’t quick profits but advancing the technological frontier to drive ecosystem growth.</strong></p><p><strong>An Yong: </strong>The prevailing belief from the internet and mobile internet eras is that the U.S. leads in innovation, while China excels at applications.</p><p><strong>Liang Wenfeng:</strong> We believe that with economic development, China must gradually transition from being a beneficiary to a contributor, rather than continuing to ride on the coattails of others. Over the past 30 years of the IT revolution, we barely participated in core tech innovation.</p><p>We’ve grown accustomed to Moore’s Law “falling from the sky”—waiting 18 months for better hardware and software. Scaling Law is treated similarly. However, these advancements are the result of generations of relentless effort by Western-led technology communities. Because we haven’t been actively involved in this process, we’ve come to overlook its significance.</p><h2>The Real Gap Lies in Originality, Not Just Time</h2><p><strong>An Yong: </strong>Why did DeepSeek V2 surprise many in Silicon Valley?</p><p><strong>Liang Wenfeng: </strong>Among the daily innovations in the U.S., this is quite ordinary. Their surprise stems from seeing a Chinese company join their game as an innovator, not just a follower—which is what most Chinese firms are accustomed to.</p><p><strong>An Yong: </strong>But in China’s context, prioritizing pure innovation seems almost a luxury. Developing large models is capital-intensive. Not every company can afford to focus solely on research without commercializing first.</p><p><strong>Liang Wenfeng: </strong>Innovation is undoubtedly costly, and <strong>our past tendency to adopt existing technologies was tied to China’s earlier developmental stage. But today, China’s economic scale and the profits of giants like ByteDance and Tencent are globally significant. What we lack isn’t capital but confidence and the ability to organize high-caliber talent for effective innovation.</strong></p><p><strong>An Yong: </strong>Why do Chinese companies, even well-funded giants, often prioritize rapid commercialization?</p><p><strong>Liang Wenfeng: </strong>For three decades, we’ve emphasized profit over innovation. Innovation isn’t purely business-driven; it requires curiosity and creative ambition.<strong> We’re shackled by old habits, but this is a phase.</strong></p><p><strong>An Yong:</strong> But DeepSeek is a business, not a nonprofit research lab. If you innovate and open-source your breakthroughs—like the MLA architecture innovation releasing in May—won’t competitors quickly copy them? Where’s your moat?</p><p><strong>Liang Wenfeng:</strong> In disruptive tech, closed-source moats are fleeting. Even OpenAI’s closed-source model can’t prevent others from catching up.</p><p>Therefore, our real moat lies in our team’s growth—accumulating know-how, fostering an innovative culture. Open-sourcing and publishing papers don’t result in significant losses. <strong>For technologists, being followed is rewarding. Open-source is cultural, not just commercial. Giving back is an honor, and it attracts talent.</strong></p><p><strong>An Yong: </strong>How do you respond to market-driven views like those of Zhu Xiaohu (who advocates prioritizing immediate commercialization over foundational AI research, dismisses AGI as impractical)?</p><p><strong>Liang Wenfeng: </strong>Zhu’s logic suits short-term profit ventures, but the most enduringly profitable U.S. companies are tech giants built on long-term R&amp;D.</p><p><strong>An Yong: </strong>But in AI, pure technical lead isn’t enough. What larger goal is DeepSeek betting on?</p><p><strong>Liang Wenfeng: </strong>We believe that China’s AI cannot remain a follower forever. Often, we say there’s a one- or two-year gap between Chinese and American AI, but the real gap is between originality and imitation. If this doesn’t change, China will always be a follower. Some explorations are unavoidable.</p><p><strong>NVIDIA’s dominance isn’t just its effort—it’s the result of Western tech ecosystems collaborating on roadmaps for next-gen tech. China needs similar ecosystems. Many domestic chips fail because they lack supportive tech communities and rely on secondhand insights. Someone must step onto the frontier.</strong></p><h2>More Investment Doesn’t Always Fuel More Innovation</h2><p><strong>An Yong: </strong>DeepSeek currently exudes an idealistic vibe reminiscent of OpenAI’s early days, and you’re open-source. Do you plan to transition to a closed-source model in the future, as OpenAI and Mistral have done?</p><p><strong>Liang Wenfeng:</strong> <strong>We won’t go closed-source. We believe that establishing a robust technology ecosystem matters more.</strong></p><p><strong>An Yong: </strong>Are there fundraising plans? Media reports suggest Huanfang<a href="#references" target="" rel="noopener">【1】</a> &nbsp;aims to spin off DeepSeek for an IPO. Silicon Valley AI startups inevitably align with big players—will you follow?.</p><p><strong>Liang Wenfeng:</strong> <strong>No short-term plans. Our challenge has never been money; it’s the embargo on high-end chips.</strong></p><p><strong>An Yong: </strong>Many argue AGI requires bold alliances and visibility, unlike quantitative investing, which thrives in secrecy. Do you agree?</p><p><strong>Liang Wenfeng: </strong>More investment doesn’t necessarily result in more innovation. If that were the case, big tech companies would have monopolized all innovation.</p><p><strong>An Yong: </strong>Are you avoiding applications because DeepSeek lacks operational expertise?</p><p><strong>Liang Wenfeng: </strong>We believe that the current stage is a period of technological innovation, not application explosion. In the long term, we aim to establish an ecosystem where the industry directly uses our technologies and outputs. Others develop B2B/B2C services on our models while we focus on foundational research. If a complete industry chain forms, there’s no need for us to develop applications ourselves. That said, if necessary, we are fully capable of doing so. However, research and innovation will always remain our top priority.</p><p><strong>An Yong: </strong>Why would clients choose DeepSeek’s API over big players’?</p><p><strong>Liang Wenfeng: </strong>The future world will likely be one of specialized division of labor. Foundational AI models require continuous innovation, and big companies have their limits—they may not always be the best fit for this role.</p><p><strong>An Yong:</strong> But can technology alone create a significant competitive gap? You’ve said there are no absolute “secrets.”</p><p><strong>Liang Wenfeng:</strong> <strong>Secrets don’t exist, but replication takes time and cost. NVIDIA GPUs have no hidden magic—yet catching up requires rebuilding teams and chasing their next-gen tech. That’s the real moat.</strong></p><p><strong>An Yong: </strong>After your price cuts, ByteDance was the first to follow, suggesting they felt threatened. How do you view the new competitive landscape between startups and giants?</p><p><strong>Liang Wenfeng: </strong>To be honest, we don’t really care about it. Lowering prices was just something we did along the way. Providing cloud services isn’t our main goal—achieving AGI is. So far, we haven’t seen any groundbreaking solutions. Giants have users, but their cash cows also shackle them, making them ripe for disruption.</p><p><strong>An Yong: </strong>What do you think the endgame looks like for the six other major AI startups in China?</p><p><strong>Liang Wenfeng: </strong>Maybe 2-3 survive. All are burning cash now. Those with clear focus and operational discipline will endure. Others will pivot. Value never vanishes; they will take on new forms.</p><p><strong>An Yong: </strong>What’s your core philosophy when it comes to competition?</p><p><strong>Liang Wenfeng: </strong>I focus on whether something elevates societal efficiency and whether we can find our strength in the industry value chain. As long as the ultimate goal boosts efficiency, it’s valid. Many aspects are just temporary phases—over-focusing on them will only lead to confusion.<br>V2 Model: Built Entirely by Homegrown Talent</p><p><strong>An Yong: </strong>ack Clark, former policy lead at OpenAI and co-founder of Anthropic, remarked that DeepSeek has hired “some of those inscrutable wizards” who built DeepSeek V2. What defines these people?</p><p><strong>Liang Wenfeng: </strong>No “inscrutable wizards” here—just fresh graduates from top universities, PhD candidates (even fourth- or fifth-year interns), and young talents with a few years of experience.</p><p><strong>An Yong: </strong>Many major AI companies are keen on recruiting talent from overseas. Some believe that the top 50 AI talents globally are unlikely to be working for Chinese companies. Where does your team come from?</p><p><strong>Liang Wenfeng: V2 was built entirely by domestic talent. The global top 50 might not be in China today, but we aim to cultivate our own.</strong></p><p><strong>An Yong: </strong>How did the MLA innovation emerge? We heard that the idea initially stemmed from a young researcher’s personal interest.</p><p><strong>Liang Wenfeng: </strong>After summarizing the key evolutionary patterns of the mainstream Attention architecture, he had a sudden inspiration to design an alternative. However, turning an idea into reality is a long journey. We assembled a team and spent months validating it.</p><p><strong>An Yong: </strong>This kind of organic creativity seems tied to your flat organizational structure. In Huanfang, you avoided top-down mandates. But for AGI—a high-uncertainty frontier—do you impose more management?</p><p><strong>Liang Wenfeng: </strong>DeepSeek remains entirely bottom-up. We also do not preassign roles; natural division of labor emerges. Everyone brings unique experiences and ideas, and they don’t need to be pushed. When they encounter challenges, they naturally pull others in for discussions. However, once an idea shows potential, we do allocate resources from the top down.</p><p><strong>An Yong: </strong>We’ve heard that DeepSeek operates with remarkable flexibility in allocating computing resources and personnel.</p><p><strong>Liang Wenfeng: </strong>There are no limits on accessing compute resources or team members. If someone has an idea, they can tap into our training clusters anytime without approval. Additionally, since we don’t have rigid hierarchical structures or departmental barriers, people can collaborate freely as long as there’s mutual interest.</p><p><strong>An Yong: </strong>Such loose management relies on hiring intensely driven individuals. It’s said that DeepSeek excels at identifying exceptional talent based on non-traditional criteria.</p><p><strong>Liang Wenfeng:</strong> Our hiring standards have always been based on passion and curiosity. Many of our team members have unique and interesting backgrounds. Their hunger for research far outweighs monetary concerns.</p><p><strong>An Yong: </strong>Transformer was born in Google’s AI Lab, and ChatGPT emerged from OpenAI. In your opinion, how do corporate AI labs differ from startups in fostering innovation?</p><p><strong>Liang Wenfeng:</strong> Whether it’s Google’s labs, OpenAI, or even AI labs at Chinese tech giants, they all provide significant value. The fact that OpenAI eventually delivered breakthroughs was partly historical chance.</p><p><strong>An Yong: </strong>So is innovation largely a matter of chance? Your office layout includes meeting rooms with doors that can be easily opened on both sides. Your colleagues mentioned that this design allows for “serendipity,” reminiscent of the Transformer story—where a passerby overheard a discussion and helped shape it into a universal framework.</p><p><strong>Liang Wenfeng: I believe innovation is, first and foremost, a matter of belief. Why is Silicon Valley so innovative? Because they dare to try. When ChatGPT debuted, China lacked confidence in frontier research. From investors to major tech firms, many felt the gap was too wide and focused instead on applications. But innovation requires confidence, and young people tend to have more of it.</strong></p><p><strong>An Yong: </strong>Unlike other AI companies that actively seek funding and media attention, DeepSeek remains relatively quiet. How do you ensure that DeepSeek becomes the top choice for people looking to work in AI?</p><p><strong>Liang Wenfeng: Because we are tackling the hardest problems. The most attractive thing for top-tier talent is the opportunity to solve the world’s toughest challenges. In fact, top talent in China is often underestimated because hardcore innovation is rare, which means they rarely get recognized. We offer what they crave.</strong></p><p><strong>An Yong: </strong>The recent OpenAI event did not feature GPT-5, leading many to believe that the industry’s technological curve is slowing down, and some have begun questioning Scaling Law. What’s your perspective?</p><p><strong>Liang Wenfeng:</strong> We remain optimistic. The industry’s progress is still in line with expectations. OpenAI isn’t divine; they can’t lead forever.</p><p><strong>An Yong:</strong> How long do you think it will take to achieve AGI? Before V2, you released code/math models and switched from dense to MoE<a href="#references" target="" rel="noopener">【2】</a> . What’s your roadmap?</p><p><strong>Liang Wenfeng:</strong> It could take two years, five years, or ten years—but it will happen within our lifetime. As for our roadmap, there’s no consensus even within our company. However, we are placing our bets on three directions:</p><p><strong>1. Mathematics and code,</strong> which serve as a natural testbed for AGI—much like Go, they are enclosed, verifiable systems where self-learning could lead to high intelligence.</p><p>2.	<strong>Multimodality</strong>, where the AI engages with the real world to learn.</p><p>3.	<strong>Natural language</strong> itself, which is fundamental to human-like intelligence.</p><p>We are open to all possibilities.</p><p><strong>An Yong:</strong> What do you envision as the endgame for large AI models?</p><p><strong>Liang Wenfeng:</strong> There will be specialized companies providing foundational models and services, forming a long value chain of specialized divisions. More players will emerge to meet society’s diverse needs on top of these foundations.</p><h2>All Strategies Are Products of the Past</h2><p><strong>An Yong: </strong>Over the past year, China’s large model startup landscape has seen many changes. For instance, Wang Huiwen<a href="#references" target="" rel="noopener">【3】</a> , who was highly active early on, exited midway, while newer entrants are beginning to differentiate themselves.</p><p><strong>Liang Wenfeng:</strong> Wang Huiwen took on all the losses himself, allowing others to exit unscathed. He made a decision that was most unfavorable to himself but beneficial to everyone else. I truly admire his integrity.</p><p><strong>An Yong: </strong>Where do you currently focus most of your energy?</p><p><strong>Liang Wenfeng: </strong>My main focus is on researching the next generation of large models. There are still many unresolved challenges.</p><p><strong>An Yong: </strong>Many other AI startups insist on balancing both model development and applications, since technical leads aren’t permanent. Why is DeepSeek confident in focusing solely on research? Is it because your models still lag?</p><p><strong>Liang Wenfeng: </strong>All strategies are products of the past generation and may not hold true in the future. Discussing AI’s future profitability using the commercial logic of the internet era is like comparing Tencent’s early days to General Electric or Coca-Cola—it’s essentially carving a boat to mark a sword’s position, an outdated approach.</p><p><strong>An Yong: </strong>Huanfang had strong technological and innovative genes, and its growth seemed relatively smooth. Is this why you remain optimistic?</p><p><strong>Liang Wenfeng: </strong>Huanfang, to some extent, strengthened our confidence in technology-driven innovation, but it wasn’t all smooth sailing. We went through a long accumulation process. People only saw what happened after 2015, but in reality, we had been working on it for 16 years.</p><p><strong>An Yong: </strong>Returning to original innovation: With the economy slowing and capital cooling, will this stifle groundbreaking R&amp;D?</p><p><strong>Liang Wenfeng: </strong>Not necessarily. The restructuring of China’s industrial landscape will increasingly rely on deep-tech innovation. As quick-profit opportunities vanish, more will embrace real innovation.</p><p><strong>An Yong: </strong>So you’re optimistic about this?</p><p><strong>Liang Wenfeng: </strong>I grew up in the 1980s in a fifth-tier city in Guangdong. My father was a primary school teacher. In the 1990s, there were plenty of opportunities to make money in Guangdong. Many parents would come to our home and argue that studying was useless. But looking back now, perspectives have changed. Making money isn’t as easy as it used to be—not even driving a taxi is a viable option anymore. Within just one generation, things have shifted.</p><p><strong>Hardcore innovation will only increase in the future. It’s not widely understood now because society as a whole needs to learn from reality. When this society starts celebrating the success of deep-tech innovators, collective perceptions will change. We just need more real-world examples and time to allow that process to unfold.</strong></p><p>References</p><div id="source_link"><p>【1】Huanfang: A quantitative investment firm and early DeepSeek backer.</p><p>【2】MoE: Mixture of Experts, an architecture that improves model efficiency by activating specialized subnetworks. &nbsp;</p><p>【3】 Wang Huiwen: Co-founder of Meituan, who briefly entered the AI race in 2023 before exiting.</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>