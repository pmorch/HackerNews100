<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 11 Aug 2023 22:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Sam Bankman-Fried Sent Back to Jail After Leaking Diary of Ex-Lover (214 pts)]]></title>
            <link>https://themessenger.com/business/sbf-thrown-in-jail-for-tampering-with-star-witness-in-upcoming-fraud-trial</link>
            <guid>37093163</guid>
            <pubDate>Fri, 11 Aug 2023 19:50:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://themessenger.com/business/sbf-thrown-in-jail-for-tampering-with-star-witness-in-upcoming-fraud-trial">https://themessenger.com/business/sbf-thrown-in-jail-for-tampering-with-star-witness-in-upcoming-fraud-trial</a>, See on <a href="https://news.ycombinator.com/item?id=37093163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>FTX founder Sam Bankman-Fried is <a href="https://cms.themessenger.com/news/feds-seek-to-revoke-sam-bankman-frieds-bond-after-prosecutors-say-he-leaked-ex-girlfriends-letters" target="_blank" rel="noreferrer noopener">being thrown in jail</a> pending his upcoming trial on fraud charges after a federal judge concluded Friday his <a href="https://themessenger.com/news/sam-bankman-fried-faces-federal-judge-over-allegations-he-leaked-his-ex-girlfriends-letters" target="_blank" rel="noreferrer noopener">airing of private musings </a>from a key prosecution cooperator amounted to witness intimidation and jury tampering.</p><p>"Witness tampering and obstruction poses a danger to community and risk of such activities would support pretrial detention," U.S. District Judge Lewis Kaplan said at the bail violation hearing. While Bankman-Fried had a First Amendment right to proclaim his innocence, the judge said, free speech protections do not cover communications intended to intimidate or tamper with witnesses, a felony.</p><div><p>Bankman-Fried was immediately taken into custody in the courtroom by U.S. marshals following the ruling. He removed his shoelaces, tie and jacket and handed them to his defense lawyer before being escorted from the courtroom. His lawyers asked the judge to suspend the ruling pending appeal,  but their request was denied. They declined comment as they left court. </p><p>The one-time Crypto King, Bankman-Fried had previously been allowed to remain free pending trial, confined to home detention at his parents' house in Palo Alto, California on $250 million bond. The trial is scheduled to begin in October and expected to last at least a month.</p><p><a href="https://themessenger.com/news/feds-seek-to-revoke-sam-bankman-frieds-bond-after-prosecutors-say-he-leaked-ex-girlfriends-letters" target="_blank" rel="noreferrer noopener">The personal notes by Caroline Ellison</a>, his ex-girlfriend and the chief executive of Alameda Research, a hedge fund affiliated with FTX that traded on the crypto exchange, were written in the months before it collapsed last fall. They described how her fizzled romantic relationship with Bankman-Fried left her unhappy and disengaged from her job. They were featured in an article in July in The New York Times. </p><p>Kaplan said he found the writings "extremely personal and intimate" and that they  "portrayed Ms. Ellison in an unfavorable light." By leaking them, he concluded, Bankman-Fried "intended at least in part to harass Ellison and influence her testimony."</p></div><p>Ellison pleaded guilty in December to charges stemming from her role in FTX’s collapse. She has agreed to testify against Bankman-Fried during his trial in a bid for a more lenient sentence, and prosecutors have said in court filings that she is an important witness for their case.</p><figure><p><span><img alt="Caroline Ellison, former CEO of Alameda Research" sizes="100vw" srcset="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=640&amp;q=75 640w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=750&amp;q=75 750w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=828&amp;q=75 828w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=1080&amp;q=75 1080w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=1200&amp;q=75 1200w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=1920&amp;q=75 1920w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=2048&amp;q=75 2048w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=3840&amp;q=75 3840w" src="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F08%2FCaroline-Ellison-081123-1024x573.jpg&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><span>Caroline Ellison, former CEO of Alameda Research and the star witness at the U.S. trial against Sam Bankman-Fried.</span><span>Caroline Ellison/Twitter/X</span></figcaption></figure><div><p>Lawyers for Bankman-Fried did not deny that he shared the writings with the Times, but maintain he had a right to do so and that the article was already in progress and informed by other sources. Mark Cohen, Bankman-Fried's attorney, said during the hearing that prosecutors lacked evidence of intent to   intimidate Ellison, and said their claim was based on a "thin record with a lot of spin." </p><p>After the writings appeared in the Times, Kaplan signed a gag order barring Bankman-Fried from speaking to the news media. But prosecutors sought the additional step of having Bankman-Fried jailed pending his trial, saying his sharing of Ellison’s musings amounted to intimidating a witness and tampering with the jury pool. Prosecutor Danielle Sassoon said his actions amounted to a "deliberate evasion of his bail conditions." </p><p>In court filings, prosecutors have noted Bankman-Fried was already warned by the judge for contacting a different prosecution witness on an encrypted messaging service early in the case and saying he hoped they could have a “constructive relationship.” During the hearing, Kaplan also concluded that the earlier contact amounted to an attempt to influence a witness. </p><p>FTX imploded amid disclosures that Alameda had borrowed $10 billion in customer funds on deposit at FTX and used the money to back high-risk trading positions that ultimately turned against it. FTX filed for bankruptcy in November and Bankman-Fried resigned as chief executive.</p><p>Prosecutors accuse Bankman-Fried, 31, of cheating investors and stealing deposits from customers of FTX, one of the world’s largest cryptocurrency exchanges before its collapse in November. He is accused of squandering the money backing the risky trades placed by Alameda, as well as on political contributions and a lavish lifestyle.</p><p>Bankman-Fried has been in prolific contact with journalists covering the collapse of FTX and his criminal case, according to court filings. Over a period of serval months, he logged more than 1,000 calls with reporters, and has also been in frequent contact with the author Michael Lewis, who is writing a book about the matter.</p><p>It was not immediately clear where Bankman-Fried would be held in custody pending trial. Prosecutors said they had looked into arrangements with the Putnam County jail in upstate New York where he would have better access to trial preparation materials via computer, but Judge Kaplan said he believed there would be similar access at the federal jail in Brooklyn. The issue was not resolved during the hearing. Kaplan noted the Brooklyn lock-up is "not on anybody's list of five-star facilities."</p></div><figure><p><span><img alt="Sam Bankman-Fried, Caroline Ellison" sizes="100vw" srcset="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=640&amp;q=75 640w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=750&amp;q=75 750w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=828&amp;q=75 828w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=1080&amp;q=75 1080w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=1200&amp;q=75 1200w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=1920&amp;q=75 1920w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=2048&amp;q=75 2048w, https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=3840&amp;q=75 3840w" src="https://themessenger.com/_next/image?url=https%3A%2F%2Fcms.themessenger.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fsam-bankman-fried-caroline-ellison-072623-1024x682.jpg&amp;w=3840&amp;q=75" decoding="async" data-nimg="fill" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><figcaption><span>Sam Bankman-Fried is going back to jail after leaking former girlfriend Caroline Ellison's personal diary pages to the New York Times.</span><span>Michael M. Santiago/Getty Images; Caroline Ellison/Twitter</span></figcaption></figure></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge to revoke bail for FTX founder Sam Bankman-Fried over witness tampering (207 pts)]]></title>
            <link>https://www.cnbc.com/2023/08/11/judge-to-revoke-bail-for-ftx-founder-sam-bankman-fried-over-witness-tampering.html</link>
            <guid>37092861</guid>
            <pubDate>Fri, 11 Aug 2023 19:28:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/08/11/judge-to-revoke-bail-for-ftx-founder-sam-bankman-fried-over-witness-tampering.html">https://www.cnbc.com/2023/08/11/judge-to-revoke-bail-for-ftx-founder-sam-bankman-fried-over-witness-tampering.html</a>, See on <a href="https://news.ycombinator.com/item?id=37092861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Sam Bankman-Fried will head to jail on Friday after a judge sided with a request by federal prosecutors to revoke the FTX founder's bail over alleged witness tampering. Bankman-Fried was remanded to custody directly from a court hearing in New York. </p><p>Judge Lewis Kaplan denied Bankman-Fried's request for delayed detention pending an appeal. Unless the appeal is successful, he is expected to remain in custody until his criminal trial, which is due to begin on Oct. 2.</p><p>"My conclusion is there is probable cause to believe the defendant tried to tamper with witnesses at least twice," said Judge Kaplan during his ruling.</p><p>As the court marshals took Bankman-Fried into custody at the end of the hearing, the defendant took off his blazer, tie, emptied his pockets, and appeared to remove his shoes. Bankman-Fried's parents were both in the gallery. His mother had her face buried in her hands for much of Judge Kaplan's lengthy ruling.</p><p>The government requested that Bankman-Fried be remanded to a jail in Putnam, New York, where he'd have access to a laptop with internet access for defense preparation, as opposed to sending him to Brooklyn's Metropolitan Detention Center, the facility closest to the courthouse that has limited internet access for prisoners. </p><p>Since his <a href="https://www.cnbc.com/2022/12/12/ftx-founder-sam-bankman-fried-arrested-in-the-bahamas-after-us-files-criminal-charges.html">arrest in December</a>, Bankman-Fried had been out on a <a href="https://www.cnbc.com/2022/12/22/ftx-founder-sam-bankman-fried-to-be-released-on-250-million-bail.html">$250 million bail package</a> which requires him to remain at his parents' Palo Alto, California house.</p><p>Bankman-Fried's court appearance on Friday is the latest in a series of pre-trial hearings related to the ex-billionaire's continued dealings with the press – exchanges which the Justice Department characterizes as a "pattern of witness tampering and evading his bail conditions."&nbsp;</p><p>Judge Kaplan previously issued a direct and stern warning to Bankman-Fried in July over his conversations with the media.</p><p>Members of the press, including counsel for The New York Times and the Reporters Committee for Freedom of the Press, had filed letters objecting to Bankman-Fried's detention, citing free speech concerns. Defense attorneys had similarly argued that Bankman-Fried was asserting his first amendment right and did not violate any terms of his bail conditions by speaking with journalists.</p><p>The defense had also been hoping that the discovery process would help Bankman-Fried's case.</p><p>Lawyers representing the former FTX chief stipulated that with Bankman-Fried jailed, he would not be able to properly prepare for his trial due to the mountainous amounts of discovery documents only accessible via a computer with internet access.</p><p>In the motion requesting Bankman-Fried's detention, the government said that, over the last several months, the defendant had sent over 100 emails to the media and had made over 1,000 phone calls to members of the press. The final straw, according to prosecutors, was Bankman-Fried leaking private diary entries of his ex-girlfriend, Caroline Ellison, to the New York Times.&nbsp;<a href="https://www.cnbc.com/2022/12/22/ftxs-gary-wang-alamedas-caroline-ellison-plead-guilty-to-federal-charges-cooperating-with-prosecutors.html">Ellison pleaded guilty</a> to federal charges in Dec. 2022.</p><p>Ellison, who is also the former chief executive of Bankman-Fried's failed crypto hedge fund, Alameda Research, has been cooperating with the government since December and is expected to be a star witness for the prosecution.&nbsp;</p><p>During his 33-minute ruling, Judge Kaplan walked through his rationale as to why probable cause for witness tampering had been met by the prosecution, adding that Bankman-Fried's contribution to the Ellison story was designed to "hurt" and "discredit" a witness.</p><p>"Faced with a series of conditions meant to limit the defendant's use of the internet and the phone, the defendant pivoted to in-person machinations," the prosecution said of Bankman-Fried, whose revised bail conditions include restricted internet access and a ban from smartphone use.&nbsp;</p><p>The government added that Bankman-Fried had over 100 phone calls with one of the authors of the Times story prior to publication – many of which lasted for approximately 20 minutes.&nbsp;</p><p>The prosecution described the effort by Bankman-Fried – who faces several wire and securities fraud charges related to the alleged multibillion-dollar FTX fraud – as an attempt to discredit Ellison, characterizing it as a "means of indirect witness intimidation through the press."&nbsp;</p><p>It is an argument that proved sufficient to convince Judge Kaplan to send Bankman-Fried to jail ahead of his trial.</p><p><a href="https://www.cnbc.com/2023/07/27/prosecutors-drop-another-charge-against-ftxs-sam-bankman-fried.html">The prosecution has had to cull charges twice</a> to comply with an extradition agreement inked with The Bahamas – where Bankman-Fried was previously held in custody. The government told the Judge in a letter that next week it plans to file a new superseding indictment.</p><p><em><strong>This story is developing. Please check back for updates.</strong></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wendelstein 7-X: Gigajoule energy turnover generated for eight minutes (236 pts)]]></title>
            <link>https://www.ipp.mpg.de/5322229/01_23</link>
            <guid>37092212</guid>
            <pubDate>Fri, 11 Aug 2023 18:36:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ipp.mpg.de/5322229/01_23">https://www.ipp.mpg.de/5322229/01_23</a>, See on <a href="https://news.ycombinator.com/item?id=37092212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  
  
  <p>After successful recommissioning in autumn 2022, the Greifswald nuclear fusion experiment has surpassed an important target.</p>
  

  

  <p><em>In 2023, an energy turnover of 1 gigajoule was targeted. Now the researchers have even achieved 1.3 gigajoules and a new record for discharge time on Wendelstein 7-X: the hot plasma could be maintained for eight minutes.</em></p>
  
  
<figure data-description="<em>Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world.</em>" data-picture="base64;<picture class="" data-iesrc="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--b0247d6c23f223b06f3aa20c0639626e3e49b5da" data-alt="Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world." data-class=""><source media="(max-width: 767px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--833b362de076d38ef744d026930908ba8f6b9df7 414w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--21a9553670cc621e6f6c955a6a10224d8433a189 375w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--42f026cc8ddbb4b28070b2b9e4519914ac68716a 320w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--6b5a92f7780bf49811ac40a746c08bc18d205ac9 411w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--b112792b348543ab5a71df61f43a9a705fe802ed 480w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--9deda45ffcce0563811fb15a830b5cafdff119f9 360w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--3f63153b9156f71644d4fe9af773cbf0e48a3f07 828w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--9f77c287612452bc53e2369b134ef8a6f06a843c 750w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--eb0e323986e3afe14247750b01861d6d1feb4398 640w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--51544e8cc80e8b270ccfd0eb1cc0d15b7cd152bc 822w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--ea2b2d353aef8059b450f955b16099d6bfa5a1a1 960w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--31ef326529acf99383b1465626d6a840330b2572 720w" sizes="100vw" type="image/webp" /><source media="(max-width: 767px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--0c88268b1ba34a6ec7ac230b37a73d2ebae83ca5 414w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--2e09626286e215ccad3f7358ca6a6d53143537df 375w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--4d566f90bedff8d19f9957103ebfaec944a97e11 320w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--b165242f0e35cc405e6a31ae7acfec01ce746864 411w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--b863c098cc9dac243aa2a1b39b17f0d36d7e7ecb 480w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--278d77702d45da284772344b32be9fad62b4e1bd 360w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--af81490a3e49a1290d65b4a6e3959ac85f34d29f 828w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--527fac808e98d2f911820aab93189c65f5370174 750w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--ae5945ec6fefb574515c9a42cbb2edffd6043c39 640w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--d9d354ede1d12e4b3326fb277974396dd5e26bf5 822w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--f46033176fd61d502403147a4326f409a428fa0b 960w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--62122e4c9bd0d7cd880b66abacdd316a82b2854e 720w" sizes="100vw" type="image/jpeg" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjIxMzl9--99255bfb2a6cf75876d95df1465aba247ba5a30a 900w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIyMTM5fQ%3D%3D--ad579a615cf1b31e4c6f5b83fa23f7b3e51baf70 1800w" sizes="900px" type="image/webp" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMjEzOX0%3D--8ab0f04077bbd1ea17639b5863728b1f42473e21 900w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--3a7be48997eb365d04b6edf485fa80bb8709b144 1800w" sizes="900px" type="image/jpeg" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMjEzOX0%3D--8bb18d72c4acbd9a269c43acde086b273b1b3b0f 1200w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIyMTM5fQ%3D%3D--bb43354f86e920dbad6a0650045742e43e2ec3c8 2400w" sizes="1200px" type="image/webp" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--bbecc64a7630d0a01e975cb8ea07aaaccef4189d 1200w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--4c05b1f5fdbbff38b5b7c7da244f16159d70db6b 2400w" sizes="1200px" type="image/jpeg" /><source media="(min-width: 1200px)" srcset="/5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMjEzOX0%3D--2e34224009713570c6763c13d33488e6302f94cf 1400w, /5322139/original-1677070409.webp?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIyMTM5fQ%3D%3D--bc8fa37afd1888b3ed7fd5d85b71822ef1880835 2800w" sizes="1400px" type="image/webp" /><source media="(min-width: 1200px)" srcset="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--b0247d6c23f223b06f3aa20c0639626e3e49b5da 1400w, /5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--0b42d792eb5ee6354b3a4c8be4407eedc73622df 2800w" sizes="1400px" type="image/jpeg" /><img alt="Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world." class="" title="Experiment hall with Wendelstein 7-X in Greifswald. The fusion facility is the most modern and largest stellarator in the world." src="/5322139/original-1677070409.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjIxMzl9--b0247d6c23f223b06f3aa20c0639626e3e49b5da" /></picture>">
      
      

    
</figure>

<p>During the three-year completion work that ended last summer, Wendelstein 7-X was primarily equipped with water cooling for the wall elements and an upgraded heating system. The latter can now couple twice as much power into the plasma as before. Since then, the nuclear fusion experiment can be operated in new parameter ranges. "We are now exploring our way towards ever higher energy values," explained Prof. Dr. Thomas Klinger, head of the Stellarator Transport and Dynamics Division at the Max Planck Institute for Plasma Physics (IPP) in Greifswald. "In doing so, we have to proceed step by step so as not to overload and damage the facility."</p><p>On 15 February 2023, the researchers reached a new milestone: for the first time, they were able to achieve an energy turnover of 1.3 gigajoules in this device. This was 17 times higher than the best value achieved before the conversion (75 megajoules). The energy turnover results from the coupled heating power multiplied by the duration of the discharge. Only if it is possible to couple large amounts of energy continuously into the plasma and also remove the resulting heat, a power plant operation is possible.</p>
<figure data-description="<em>Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius.</em>" data-picture="base64;<picture class="" data-iesrc="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c0bc07b445deab3742505837d26da3d00e024d62" data-alt="Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius." data-class=""><source media="(max-width: 767px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--11f2e06fd9a085fe2aefe781627b42aa76c10f07 414w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--f3d29d934d79b8a370fa47d91a6056dd4da40dc4 375w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--557e81f93ea47c1c4403a32f0737d390b12505ad 320w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--d2a3c28a74403cab515d8557c0cc1d6bbf77ae5a 411w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--52b4f2cc362eb72823f26d139e930644d5ceb5f8 480w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--7eef544d9263ae64c64645af101c53fb5ee3c227 360w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--3068217804b9061157424dcf3b1111aea5464f83 828w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--d801fafb99755b440c62fbadca03cf4e65383dd9 750w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--632c5d0c720159fbc558f5b4cb74dc8fa7eb23e1 640w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--02d8ceea94e2e51e65ba2ceaaa004ffb79071243 822w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--f993bddb58a1cfec29b948bb305a6717f2313a7b 960w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--fb06e9af5ae197b83781fd5132943f688b7abe41 720w" sizes="100vw" type="image/webp" /><source media="(max-width: 767px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NDE0LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--9b50aed8c8b831b6514c1ce4a4e6dee89b8a660e 414w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6Mzc1LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--ce360e45b2a9b6dcc7378ca943def962975da94d 375w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--fee4b7854529d4bf6a0b2bceab4e44d1440b99e2 320w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NDExLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--61e87750903b5a1e85511a850c3ac2c4135abcc6 411w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NDgwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--07f1a24c7d3e459017fce2c670592d1e57ec4678 480w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MzYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--3f72497b9c3dd152de831979129d4311dd450a3a 360w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6ODI4LCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--f99b9436477eeaa8e8c86479ee11b2238f25e46e 828w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NzUwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--a46a64e2b67059b6a1bdb51f9899162fcf3611b2 750w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NjQwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--c3fea48347b9518f89b37aba8e644ecc125ee3ad 640w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6ODIyLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--75ee5c0a058ea0ee6fa83c5487b6918dac57a7e9 822w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6OTYwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--1ca8abb813b68f93eb2dd7d63df42a8bfcb0cd92 960w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6NzIwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--2e77b89c30b6652271a70d574efd8e578457084d 720w" sizes="100vw" type="image/jpeg" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6IndlYnAiLCJvYmpfaWQiOjUzMjMxNTN9--33b448b21da5ce24459699cc5665affa2ba49c7d 900w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIzMTUzfQ%3D%3D--25ffa139b6b1f6ed7c0ab1a3e40545666d41583e 1800w" sizes="900px" type="image/webp" /><source media="(min-width: 768px) and (max-width: 991px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6OTAwLCJmaWxlX2V4dGVuc2lvbiI6ImpwZyIsIm9ial9pZCI6NTMyMzE1M30%3D--55def98633d17e2f3cc8b003c9496030fe47981e 900w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--dc59f175373535e2f2ff5bab14ac5d1d6392a00c 1800w" sizes="900px" type="image/jpeg" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMzE1M30%3D--bf85bf540587ba20be56e104367cfb575b34425f 1200w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIzMTUzfQ%3D%3D--8e4da926c339cb2b1580b2ebd9903e124af99741 2400w" sizes="1200px" type="image/webp" /><source media="(min-width: 992px) and (max-width: 1199px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTIwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--6d82a2bc2ce8706ab983b139d15a6bd74f550fd7 1200w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MjQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--4ee520281e1f92906f77e503d3fcebd90f4b5242 2400w" sizes="1200px" type="image/jpeg" /><source media="(min-width: 1200px)" srcset="/5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwicXVhbGl0eSI6ODYsIm9ial9pZCI6NTMyMzE1M30%3D--7875e667dfd2d7da0226fb641cd30af46f3d76c6 1400w, /5323153/original-1677072465.webp?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJ3ZWJwIiwib2JqX2lkIjo1MzIzMTUzfQ%3D%3D--f83ac6afe616bb79e9a7c9d862e16a34dd820905 2800w" sizes="1400px" type="image/webp" /><source media="(min-width: 1200px)" srcset="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c0bc07b445deab3742505837d26da3d00e024d62 1400w, /5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MjgwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c887e5330c861c004a63a582c4dab16b1bf32f1c 2800w" sizes="1400px" type="image/jpeg" /><img alt="Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius." class="" title="Infrared image from the vacuum vessel of Wendelstein 7-X. The picture does NOT show the plasma itself, but the temperature distribution at the water-cooled divertor baffles. The divertor baffles are used to dissipate the heat from the plasma. A defined line in the centre, the so-called strike line, is clearly visible. This is where the plasma touches the divertor and the temperature is highest. In individual areas, temperatures of up to 600 degrees Celsius are reached (red areas). The divertor tiles can withstand temperatures of up to 1200 degrees Celsius." src="/5323153/original-1677072465.jpg?t=eyJ3aWR0aCI6MTQwMCwiZmlsZV9leHRlbnNpb24iOiJqcGciLCJvYmpfaWQiOjUzMjMxNTN9--c0bc07b445deab3742505837d26da3d00e024d62" /></picture>">
      
      

    
</figure>

<p><strong>The plasma discharge lasted eight minutes</strong><br>Particularly heat-resistant divertor baffle plates are used to dissipate the largest heat flows at Wendelstein 7-X. They are part of the inner wall, which is now cooled by a system of 6.8 kilometres of water pipes since the completion of the device. No other fusion facility in the world currently has such a comprehensively cooled inner wall. The plasma heating consists of three components: the newly installed ion heating, the heating by neutral particle injection and electron microwave heating. For the current record, the electron microwave heating system was particularly important because it delivers large amounts of power over periods of several minutes. The energy turnover of 1.3 gigajoule was achieved with an average heating power of 2.7 megawatts, whereby the discharge lasted 480 seconds. This is also a new record for Wendelstein 7-X and one of the best values worldwide. Before the completion works, Wendelstein 7-X achieved maximum plasma times of 100 seconds at much lower heating power.</p><p>Within a few years, the plan is to increase the energy turnover at Wendelstein 7-X to 18 gigajoules, with the plasma then being kept stable for half an hour.</p><p>&nbsp;<strong>Background to nuclear fusion</strong><br>The goal of fusion research is to develop a climate and environmentally friendly power plant. Similar to the sun, it is to generate energy from the fusion of atomic nuclei. The Max Planck Institute for Plasma Physics is pursuing the path of magnetic fusion. Because the fusion fire only ignites at temperatures above 100 million degrees, the fuel – a thin hydrogen plasma – must not come into contact with cold vessel walls. Held by magnetic fields, it floats almost contact-free inside a vacuum chamber. The magnetic cage of Wendelstein 7-X is created by a ring of 50 superconducting magnetic coils. It is a stellarator-type facility in which the special shapes of the coils are the result of sophisticated optimisation calculations. With the help of these coils, the quality of plasma confinement in a stellarator should reach the level of competing tokamak-type facilities<strong>.</strong></p>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RFC 9446 Reflections on Ten Years Past the Snowden Revelations (125 pts)]]></title>
            <link>https://www.rfc-editor.org/rfc/rfc9446.html</link>
            <guid>37091989</guid>
            <pubDate>Fri, 11 Aug 2023 18:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rfc-editor.org/rfc/rfc9446.html">https://www.rfc-editor.org/rfc/rfc9446.html</a>, See on <a href="https://news.ycombinator.com/item?id=37091989">Hacker News</a></p>
<div id="readability-page-1" class="page">

<table>
<thead><tr>
<td>RFC 9446</td>
<td>Ten Years After</td>
<td>July 2023</td>
</tr></thead>
<tfoot><tr>
<td>Farrell, et al.</td>
<td>Informational</td>
<td>[Page]</td>
</tr></tfoot>
</table>


<h2 id="rfcnum">RFC 9446</h2>

<section id="section-abstract">
      <h2 id="abstract"><a href="#abstract">Abstract</a></h2>
<p id="section-abstract-1">This memo contains the thoughts and recountings of events that
transpired during and after the release of information about the United States National Security Agency (NSA)
by Edward Snowden in 2013.  There are four perspectives: that of someone 
who was involved with sifting through the information to responsibly 
inform the public, that of a security area director of the IETF, that of a human 
rights expert, and that of a computer science and affiliate law professor. The purpose 
of this memo is to provide some historical perspective, while at the 
same time offering a view as to what security and privacy challenges 
the technical community should consider.  These essays do not represent a consensus view, but that of the individual authors.<a href="#section-abstract-1">¶</a></p>
</section>
<section id="status-of-memo">
        <h2 id="name-status-of-this-memo">
<a href="#name-status-of-this-memo">Status of This Memo</a>
        </h2>
<p id="section-boilerplate.1-1">
            This document is not an Internet Standards Track specification; it is
            published for informational purposes.<a href="#section-boilerplate.1-1">¶</a></p>
<p id="section-boilerplate.1-2">
            This is a contribution to the RFC Series, independently of any
            other RFC stream.  The RFC Editor has chosen to publish this
            document at its discretion and makes no statement about its value
            for implementation or deployment.  Documents approved for
            publication by the RFC Editor are not candidates for any level of
            Internet Standard; see Section 2 of RFC 7841.<a href="#section-boilerplate.1-2">¶</a></p>
<p id="section-boilerplate.1-3">
            Information about the current status of this document, any
            errata, and how to provide feedback on it may be obtained at
            <span><a href="https://www.rfc-editor.org/info/rfc9446">https://www.rfc-editor.org/info/rfc9446</a></span>.<a href="#section-boilerplate.1-3">¶</a></p>
</section>
<section id="copyright">
        <h2 id="name-copyright-notice">
<a href="#name-copyright-notice">Copyright Notice</a>
        </h2>
<p id="section-boilerplate.2-1">
            Copyright (c) 2023 IETF Trust and the persons identified as the
            document authors. All rights reserved.<a href="#section-boilerplate.2-1">¶</a></p>
<p id="section-boilerplate.2-2">
            This document is subject to BCP 78 and the IETF Trust's Legal
            Provisions Relating to IETF Documents
            (<span><a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a></span>) in effect on the date of
            publication of this document. Please review these documents
            carefully, as they describe your rights and restrictions with
            respect to this document.<a href="#section-boilerplate.2-2">¶</a></p>
</section>
<section id="toc">
        <a href="#" onclick="scroll(0,0)">▲</a><h2 id="name-table-of-contents">
<a href="#name-table-of-contents">Table of Contents</a>
        </h2>
<nav><ul>
<li id="section-toc.1-1.1">
            <p id="section-toc.1-1.1.1"><a href="#section-1">1</a>.&nbsp;&nbsp;<a href="#name-introduction">Introduction</a></p>
</li>
          <li id="section-toc.1-1.2">
            <p id="section-toc.1-1.2.1"><a href="#section-2">2</a>.&nbsp;&nbsp;<a href="#name-bruce-schneier-snowden-ten-">Bruce Schneier: Snowden Ten Years Later</a></p>
</li>
          <li id="section-toc.1-1.3">
            <p id="section-toc.1-1.3.1"><a href="#section-3">3</a>.&nbsp;&nbsp;<a href="#name-stephen-farrell-ietf-and-in">Stephen Farrell: IETF and Internet Technical Community Reaction</a></p>
</li>
          <li id="section-toc.1-1.4">
            <p id="section-toc.1-1.4.1"><a href="#section-4">4</a>.&nbsp;&nbsp;<a href="#name-farzaneh-badii-did-snowdens">Farzaneh Badii: Did Snowden's Revelations Help with Protecting Human Rights on the Internet?</a></p>
</li>
          <li id="section-toc.1-1.5">
            <p id="section-toc.1-1.5.1"><a href="#section-5">5</a>.&nbsp;&nbsp;<a href="#name-steven-m-bellovin-governmen">Steven M. Bellovin: Governments and Cryptography: The Crypto Wars</a></p>
<ul>
<li id="section-toc.1-1.5.2.1">
                <p id="section-toc.1-1.5.2.1.1"><a href="#section-5.1">5.1</a>.&nbsp;&nbsp;<a href="#name-historical-background">Historical Background</a></p>
</li>
              <li id="section-toc.1-1.5.2.2">
                <p id="section-toc.1-1.5.2.2.1"><a href="#section-5.2">5.2</a>.&nbsp;&nbsp;<a href="#name-the-crypto-wars-begin">The Crypto Wars Begin</a></p>
</li>
              <li id="section-toc.1-1.5.2.3">
                <p id="section-toc.1-1.5.2.3.1"><a href="#section-5.3">5.3</a>.&nbsp;&nbsp;<a href="#name-the-battle-is-joined">The Battle Is Joined</a></p>
</li>
              <li id="section-toc.1-1.5.2.4">
                <p id="section-toc.1-1.5.2.4.1"><a href="#section-5.4">5.4</a>.&nbsp;&nbsp;<a href="#name-the-hidden-battle">The Hidden Battle</a></p>
</li>
              <li id="section-toc.1-1.5.2.5">
                <p id="section-toc.1-1.5.2.5.1"><a href="#section-5.5">5.5</a>.&nbsp;&nbsp;<a href="#name-whither-the-ietf">Whither the IETF?</a></p>
</li>
            </ul>
</li>
          <li id="section-toc.1-1.6">
            <p id="section-toc.1-1.6.1"><a href="#section-6">6</a>.&nbsp;&nbsp;<a href="#name-security-considerations">Security Considerations</a></p>
</li>
          <li id="section-toc.1-1.7">
            <p id="section-toc.1-1.7.1"><a href="#section-7">7</a>.&nbsp;&nbsp;<a href="#name-iana-considerations">IANA Considerations</a></p>
</li>
          <li id="section-toc.1-1.8">
            <p id="section-toc.1-1.8.1"><a href="#section-8">8</a>.&nbsp;&nbsp;<a href="#name-informative-references">Informative References</a></p>
</li>
          <li id="section-toc.1-1.9">
            <p id="section-toc.1-1.9.1"><a href="#appendix-A"></a><a href="#name-acknowledgments">Acknowledgments</a></p>
</li>
          <li id="section-toc.1-1.10">
            <p id="section-toc.1-1.10.1"><a href="#appendix-B"></a><a href="#name-authors-addresses">Authors' Addresses</a></p>
</li>
        </ul>
</nav>
</section>
<section id="introduction">
      <h2 id="name-introduction">
<a href="#section-1">1. </a><a href="#name-introduction">Introduction</a>
      </h2>
<p id="section-1-1">On June 6th, 2013, an article appeared in <em>The Guardian</em> <span>[<a href="#Guard2013">Guard2013</a>]</span>
that was the beginning of a series of what have come to be known as
the Snowden revelations, describing certain activities of the United
States National Security Agency (NSA).  These activities included,
amongst others: secret court orders; secret agreements for the receipt
of so-called "meta-information" that includes source, destination, and
timing of communications; and tapping of communications lines.  The
breathtaking scope of the operations shocked the Internet technical
community and resulted in a sea change within the IETF, IAB,
and other standards organizations.<a href="#section-1-1">¶</a></p>
<p id="section-1-2">Now that some years have passed, it seems appropriate to reflect on that
period of time and to consider what effect the community's actions had,
where security has improved, how the threat surface has evolved, what
areas haven't improved, and where the community might invest future
efforts.<a href="#section-1-2">¶</a></p>
<p id="section-1-3">Bruce Schneier begins this compendium of individual essays by bringing
us back to 2013, recalling how it was for him and others to report
what was happening, and the mindset of those involved.  Next, Stephen
Farrell reviews the technical community's reactions and in particular
the reactions of the IETF community, technical advances, and where
threats remain.  Then Farzaneh Badii discusses the impact of those
advances -- or lack thereof -- on human rights.  Finally Steven
M. Bellovin puts the Snowden revelations into an ever-evolving
historical context of secrets and secret stealing that spans
centuries, closing with some suggestions for IETF.<a href="#section-1-3">¶</a></p>
<p id="section-1-4">Readers are invited to consider what impact we as a community have
had, what challenges remain, and what positive contribution the
technical community can and should make to address security and
privacy of citizens of the world.<a href="#section-1-4">¶</a></p>
<p id="section-1-5">-- Eliot Lear, Independent Submissions Editor for the RFC Series<a href="#section-1-5">¶</a></p>
</section>
<section id="bruce-schneier-snowden-ten-years-later">
      <h2 id="name-bruce-schneier-snowden-ten-">
<a href="#section-2">2. </a><a href="#name-bruce-schneier-snowden-ten-">Bruce Schneier: Snowden Ten Years Later</a>
      </h2>
<p id="section-2-1">In 2013 and 2014, I wrote extensively about new revelations regarding
NSA surveillance based on the documents provided by Edward
Snowden. But I had a more personal involvement as well.<a href="#section-2-1">¶</a></p>
<p id="section-2-2">I wrote the essay below in September 2013. <em>The New Yorker</em> agreed to
publish it, but <em>The Guardian</em> asked me not to. It was
scared of UK law enforcement and worried that this essay would
reflect badly on it. And given that the UK police would raid its
offices in July 2014, it had legitimate cause to be worried.<a href="#section-2-2">¶</a></p>
<p id="section-2-3">Now, ten years later, I offer this as a time capsule of what those
early months of Snowden were like.<a href="#section-2-3">¶</a></p>
<blockquote id="section-2-4">
        <p id="section-2-4.1">It's a surreal experience, paging through hundreds of top-secret NSA
documents. You're peering into a forbidden world: strange, confusing,
and fascinating all at the same time.<a href="#section-2-4.1">¶</a></p>
<p id="section-2-4.2">I had flown down to Rio de Janeiro in late August at the request of
Glenn Greenwald. He had been working on the Edward Snowden archive for
a couple of months, and had a pile of more technical documents that he
wanted help interpreting. According to Greenwald, Snowden also thought
that bringing me down was a good idea.<a href="#section-2-4.2">¶</a></p>
<p id="section-2-4.3">It made sense. I didn't know either of them, but I have been writing
about cryptography, security, and privacy for decades. I could
decipher some of the technical language that Greenwald had difficulty
with, and understand the context and importance of various
document. And I have long been publicly critical of the NSA's
eavesdropping capabilities. My knowledge and expertise could help
figure out which stories needed to be reported.<a href="#section-2-4.3">¶</a></p>
<p id="section-2-4.4">I thought about it a lot before agreeing. This was before David
Miranda, Greenwald's partner, was detained at Heathrow airport by the
UK authorities; but even without that, I knew there was a risk. I fly
a lot -- a quarter of a million miles per year -- and being put on a TSA
list, or being detained at the US border and having my electronics
confiscated, would be a major problem. So would the FBI breaking into my
home and seizing my personal electronics. But in the end, that made me
more determined to do it.<a href="#section-2-4.4">¶</a></p>
<p id="section-2-4.5">I did spend some time on the phone with the attorneys recommended to
me by the ACLU and the EFF. And I talked about it with my partner,
especially when Miranda was detained three days before my departure.
Both Greenwald and his employer, <em>The Guardian</em>, are careful about whom
they show the documents to. They publish only those portions essential
to getting the story out. It was important to them that I be a
co-author, not a source. I didn't follow the legal reasoning, but the
point is that <em>The Guardian</em> doesn't want to leak the documents to
random people. It will, however, write stories in the public interest,
and I would be allowed to review the documents as part of that
process. So after a Skype conversation with someone at <em>The Guardian</em>, I
signed a letter of engagement.<a href="#section-2-4.5">¶</a></p>
<p id="section-2-4.6">And then I flew to Brazil.<a href="#section-2-4.6">¶</a></p>
<p id="section-2-4.7">I saw only a tiny slice of the documents, and most of what I saw was
surprisingly banal. The concerns of the top-secret world are largely
tactical: system upgrades, operational problems owing to weather,
delays because of work backlogs, and so on. I paged through weekly
reports, presentation slides from status meetings, and general
briefings to educate visitors. Management is management, even inside
the NSA. Reading the documents, I felt as though I were sitting through
some of those endless meetings.<a href="#section-2-4.7">¶</a></p>
<p id="section-2-4.8">The meeting presenters try to spice things up. Presentations regularly
include intelligence success stories. There were details -- what had been
found, and how, and where it helped -- and sometimes there were attaboys
from "customers" who used the intelligence. I'm sure these are
intended to remind NSA employees that they're doing good. It
definitely had an effect on me. Those were all things I want the NSA
to be doing.<a href="#section-2-4.8">¶</a></p>
<p id="section-2-4.9">There were so many code names. Everything has one: every program,
every piece of equipment, every piece of software. Sometimes code
names had their own code names. The biggest secrets seem to be the
underlying real-world information: which particular company
MONEYROCKET is; what software vulnerability EGOTISTICALGIRAFFE -- really,
I am not making that one up -- is; how TURBINE works. Those secrets
collectively have a code name -- ECI, for exceptionally compartmented
information -- and almost never appear in the documents. Chatting with
Snowden on an encrypted IM connection, I joked that the NSA cafeteria
menu probably has code names for menu items. His response: "Trust me
when I say you have no idea."<a href="#section-2-4.9">¶</a></p>
<p id="section-2-4.10">Those code names all come with logos, most of them amateurish and a
lot of them dumb. Note to the NSA: take some of that more than
ten-billion-dollar annual budget and hire yourself a design
firm. Really; it'll pay off in morale.<a href="#section-2-4.10">¶</a></p>
<p id="section-2-4.11">Once in a while, though, I would see something that made me stop,
stand up, and pace around in circles. It wasn't that what I read was
particularly exciting, or important. It was just that it was
startling. It changed -- ever so slightly -- how I thought about the world.<a href="#section-2-4.11">¶</a></p>
<p id="section-2-4.12">Greenwald said that that reaction was normal when people started
reading through the documents.<a href="#section-2-4.12">¶</a></p>
<p id="section-2-4.13">Intelligence professionals talk about how disorienting it is living on
the inside. You read so much classified information about the world's
geopolitical events that you start seeing the world differently. You
become convinced that only the insiders know what's really going on,
because the news media is so often wrong. Your family is
ignorant. Your friends are ignorant. The world is ignorant. The only
thing keeping you from ignorance is that constant stream of classified
knowledge. It's hard not to feel superior, not to say things like "If
you only knew what we know" all the time. I can understand how General
Keith Alexander, the director of the NSA, comes across as so
supercilious; I only saw a minute fraction of that secret world, and I
started feeling it.<a href="#section-2-4.13">¶</a></p>
<p id="section-2-4.14">It turned out to be a terrible week to visit Greenwald, as he was
still dealing with the fallout from Miranda's detention. Two other
journalists, one from <em>The Nation</em> and the other from <em>The Hindu</em>, were
also in town working with him. A lot of my week involved Greenwald
rushing into my hotel room, giving me a thumb drive of new stuff to
look through, and rushing out again.<a href="#section-2-4.14">¶</a></p>
<p id="section-2-4.15">A technician from <em>The Guardian</em> got a search capability working while I
was there, and I spent some time with it. Question: when you're given
the capability to search through a database of NSA secrets, what's the
first thing you look for? Answer: your name.<a href="#section-2-4.15">¶</a></p>
<p id="section-2-4.16">It wasn't there. Neither were any of the algorithm names I knew, not
even algorithms I knew that the US government used.<a href="#section-2-4.16">¶</a></p>
<p id="section-2-4.17">I tried to talk to Greenwald about his own operational security. It
had been incredibly stupid for Miranda to be traveling with NSA
documents on the thumb drive. Transferring files electronically is
what encryption is for. I told Greenwald that he and Laura Poitras
should be sending large encrypted files of dummy documents back and
forth every day.<a href="#section-2-4.17">¶</a></p>
<p id="section-2-4.18">Once, at Greenwald's home, I walked into the backyard and looked for
TEMPEST receivers hiding in the trees. I didn't find any, but that
doesn't mean they weren't there. Greenwald has a lot of dogs, but I
don't think that would hinder professionals. I'm sure that a bunch of
major governments have a complete copy of everything Greenwald
has. Maybe the black bag teams bumped into each other in those early
weeks.<a href="#section-2-4.18">¶</a></p>
<p id="section-2-4.19">I started doubting my own security procedures. Reading about the NSA's
hacking abilities will do that to you. Can it break the encryption on
my hard drive? Probably not. Has the company that makes my encryption
software deliberately weakened the implementation for it?
Probably. Are NSA agents listening in on my calls back to the US? Very
probably. Could agents take control of my computer over the Internet
if they wanted to? Definitely. In the end, I decided to do my best and
stop worrying about it. It was the agency's documents, after all. And
what I was working on would become public in a few weeks.<a href="#section-2-4.19">¶</a></p>
<p id="section-2-4.20">I wasn't sleeping well, either. A lot of it was the sheer magnitude of
what I saw. It's not that any of it was a real surprise. Those of us
in the information security community had long assumed that the NSA
was doing things like this. But we never really sat down and figured
out the details, and to have the details confirmed made a big
difference. Maybe I can make it clearer with an analogy. Everyone
knows that death is inevitable; there's absolutely no surprise about
that. Yet it arrives as a surprise, because we spend most of our lives
refusing to think about it. The NSA documents were a bit like
that. Knowing that it is surely true that the NSA is eavesdropping on
the world, and doing it in such a methodical and robust manner, is
very different from coming face-to-face with the reality that it is
and the details of how it is doing it.<a href="#section-2-4.20">¶</a></p>
<p id="section-2-4.21">I also found it incredibly difficult to keep the secrets.
<em>The Guardian</em>'s process is slow and methodical. I move much faster. I
drafted stories based on what I found. Then I wrote essays about those
stories, and essays about the essays. Writing was therapy; I would
wake up in the wee hours of the morning, and write an essay. But that
put me at least three levels beyond what was published.<a href="#section-2-4.21">¶</a></p>
<p id="section-2-4.22">Now that my involvement is out, and my first essays are out, I feel a
lot better. I'm sure it will get worse again when I find another
monumental revelation; there are still more documents to go through.<a href="#section-2-4.22">¶</a></p>
<p id="section-2-4.23">I've heard it said that Snowden wants to damage America. I can say
with certainty that he does not. So far, everyone involved in this
incident has been incredibly careful about what is released to the
public. There are many documents that could be immensely harmful to
the US, and no one has any intention of releasing them. The documents
the reporters release are carefully redacted. Greenwald and I
repeatedly debated with <em>The Guardian</em> editors the newsworthiness of story
ideas, stressing that we would not expose government secrets simply
because they're interesting.<a href="#section-2-4.23">¶</a></p>
<p id="section-2-4.24">The NSA got incredibly lucky; this could have ended with a massive
public dump like Chelsea Manning's State Department cables. I suppose
it still could. Despite that, I can imagine how this feels to the NSA.
It's used to keeping this stuff behind multiple levels of security:
gates with alarms, armed guards, safe doors, and military-grade
cryptography. It's not supposed to be on a bunch of thumb drives in
Brazil, Germany, the UK, the US, and who knows where else, protected
largely by some random people's opinions about what should or should
not remain secret. This is easily the greatest intelligence failure in
the history of ever. It's amazing that one person could have had so
much access with so little accountability, and could sneak all of this
data out without raising any alarms. The odds are close to zero that
Snowden is the first person to do this; he's just the first person to
make public that he did. It's a testament to General Alexander's power
that he hasn't been forced to resign.<a href="#section-2-4.24">¶</a></p>
<p id="section-2-4.25">It's not that we weren't being careful about security, it's that our
standards of care are so different. From the NSA's point of view,
we're all major security risks, myself included. I was taking notes
about classified material, crumpling them up, and throwing them into
the wastebasket. I was printing documents marked "TOP
SECRET/COMINT/NOFORN" in a hotel lobby. And once, I took the wrong
thumb drive with me to dinner, accidentally leaving the unencrypted
one filled with top-secret documents in my hotel room. It was an
honest mistake; they were both blue.<a href="#section-2-4.25">¶</a></p>
<p id="section-2-4.26">If I were an NSA employee, the policy would be to fire me for that alone.<a href="#section-2-4.26">¶</a></p>
<p id="section-2-4.27">Many have written about how being under constant surveillance changes
a person. When you know you're being watched, you censor yourself. You
become less open, less spontaneous. You look at what you write on your
computer and dwell on what you've said on the telephone, wonder how it
would sound taken out of context, from the perspective of a
hypothetical observer. You're more likely to conform. You suppress
your individuality. Even though I have worked in privacy for decades,
and already knew a lot about the NSA and what it does, the change was
palpable. That feeling hasn't faded. I am now more careful about what
I say and write. I am less trusting of communications technology. I am
less trusting of the computer industry.<a href="#section-2-4.27">¶</a></p>
<p id="section-2-4.28">After much discussion, Greenwald and I agreed to write three stories
together to start. All of those are still in progress. In addition, I
wrote two commentaries on the Snowden documents that were recently
made public. There's a lot more to come; even Greenwald hasn't looked
through everything.<a href="#section-2-4.28">¶</a></p>
<p id="section-2-4.29">Since my trip to Brazil (one month before), I've flown back to the US
once and domestically seven times -- all without incident. I'm not on any
list yet. At least, none that I know about.<a href="#section-2-4.29">¶</a></p>
</blockquote>
<p id="section-2-5">As it happened, I didn't write much more with Greenwald or 
<em>The Guardian</em>. Those two had a falling out, and by the time everything
settled and both began writing about the documents
independently -- Greenwald at the newly formed website <em>The Intercept</em> -- I
got cut out of the process somehow. I remember hearing that Greenwald
was annoyed with me, but I never learned the reason. We haven't spoken
since.<a href="#section-2-5">¶</a></p>
<p id="section-2-6">Still, I was happy with the one story I was part of: how the NSA hacks
Tor. I consider it a personal success that I pushed <em>The Guardian</em> to
publish NSA documents detailing QUANTUM. I don't think that would have
gotten out any other way. And I still use those pages today when I
teach cybersecurity to policymakers at the Harvard Kennedy School.<a href="#section-2-6">¶</a></p>
<p id="section-2-7">Other people wrote about the Snowden files, and wrote a lot. It was a
slow trickle at first, and then a more consistent flow. Between
Greenwald, Bart Gellman, and <em>The Guardian</em> reporters, there ended up
being steady stream of news. (Bart brought in Ashkan Soltani to help
him with the technical aspects, which was a great move on his part,
even if it cost Ashkan a government job later.) More stories were
covered by other publications.<a href="#section-2-7">¶</a></p>
<p id="section-2-8">It started getting weird. Both Greenwald and Gellman held documents
back so they could publish them in their books. Jake Appelbaum, who
had not yet been accused of sexual assault by multiple women, was
working with Poitras. He partnered with <em>Der Spiegel</em> to release an implant
catalog from the NSA's Tailored Access Operations group. To this day,
I am convinced that the document was not in the Snowden archives:
that Jake got it somehow, and it was released with the implication
that it was from Edward Snowden. I thought it was important enough
that I started writing about each item in that document in my blog:
"NSA Exploit of the Week." That got my website blocked by the DoD: I
keep a framed print of the censor's message on my wall.<a href="#section-2-8">¶</a></p>
<p id="section-2-9">Perhaps the most surreal document disclosures were when artists
started writing fiction based on the documents. This was in 2016, when
Laura Poitras built a secure room in New York to house the
documents. By then, the documents were years out of date.  And now
they're over a decade out of date. (They were leaked in 2013, but most
of them were from 2012 or before.)<a href="#section-2-9">¶</a></p>
<p id="section-2-10">I ended up being something of a public ambassador for the
documents. When I got back from Rio, I gave talks at a private
conference in Woods Hole, the Berkman Center at Harvard, something
called the Congress on Privacy and Surveillance in Geneva, events at
both CATO and New America in DC, an event at the University of
Pennsylvania, an event at EPIC, a "Stop Watching Us" rally in DC,
the RISCS conference in London, the ISF in Paris, and...then...at the
IETF meeting in Vancouver in November 2013. (I remember little of
this; I am reconstructing it all from my calendar.)<a href="#section-2-10">¶</a></p>
<p id="section-2-11">What struck me at the IETF was the indignation in the room, and the
calls to action. And there was action, across many fronts. We
technologists did a lot to help secure the Internet, for example.<a href="#section-2-11">¶</a></p>
<p id="section-2-12">The government didn't do its part, though. Despite the public outcry,
investigations by Congress, pronouncements by President Obama, and
federal court rulings, I don't think much has changed. The NSA
canceled a program here and a program there, and it is now more public
about defense. But I don't think it is any less aggressive about
either bulk or targeted surveillance. Certainly its government
authorities haven't been restricted in any way. And surveillance
capitalism is still the business model of the Internet.<a href="#section-2-12">¶</a></p>
<p id="section-2-13">And Edward Snowden? We were in contact for a while on Signal. I
visited him once in Moscow, in 2016. And I had him do a guest
lecture to my class at Harvard for a few years, remotely by
Jitsi. Afterwards, I would hold a session where I promised to answer
every question he would evade or not answer, explain every response he
did give, and be candid in a way that someone with an outstanding
arrest warrant simply cannot. Sometimes I thought I could channel
Snowden better than he could.<a href="#section-2-13">¶</a></p>
<p id="section-2-14">But now it's been a decade. Everything he knows is old and out of
date. Everything we know is old and out of date. The NSA suffered an
even worse leak of its secrets by the Russians, under the guise of the
Shadow Brokers, in 2016 and 2017. The NSA has rebuilt. It again has
capabilities we can only surmise.<a href="#section-2-14">¶</a></p>
</section>
<section id="stephen-farrell-ietf-and-internet-technical-community-reaction">
      <h2 id="name-stephen-farrell-ietf-and-in">
<a href="#section-3">3. </a><a href="#name-stephen-farrell-ietf-and-in">Stephen Farrell: IETF and Internet Technical Community Reaction</a>
      </h2>
<p id="section-3-1">In 2013, the IETF and, more broadly, the Internet technical, security, and
privacy research communities, were surprised by the surveillance and attack
efforts exposed by the Snowden revelations <span>[<a href="#Timeline">Timeline</a>]</span>. While the
potential for such was known, it was the scale and pervasiveness of the
activities disclosed that was alarming and, I think it fair to say, quite
annoying, for very many Internet engineers.<a href="#section-3-1">¶</a></p>
<p id="section-3-2">As for the IETF's reaction, informal meetings during the July 2013 IETF meeting
in Berlin indicated that IETF participants considered that these revelations
showed that we needed to do more to improve the security and privacy properties
of IETF protocols, and to help ensure deployments made better use of the
security and privacy mechanisms that already existed. In August, the IETF set up
a new mailing list <span>[<a href="#Perpass">Perpass</a>]</span>, which became a useful venue for triaging
proposals for work on these topics. At the November 2013 IETF meeting, there
was a lively and very well attended plenary session <span>[<a href="#Plenary-video">Plenary-video</a>]</span> on
"hardening the Internet" against such attacks, followed by a "birds of a
feather" session <span>[<a href="#Perpass-BoF">Perpass-BoF</a>]</span> devoted to more detailed discussion of possible
actions in terms of new working groups, protocols, and Best Current Practice
(BCP) documents that could help improve matters.  This was followed in
February/March 2014 by a joint IAB/W3C workshop on "strengthening the Internet
against pervasive monitoring" <span>[<a href="#STRINT">STRINT</a>]</span> held in London and attended by 150
engineers (still the only IAB workshop in my experience where we needed a
waiting list for people after capacity for the venue was reached!). The STRINT
workshop report was eventually published as <span>[<a href="#RFC7687">RFC7687</a>]</span> in 2015, but in the
meantime, work proceeded on a BCP document codifying
that the IETF community considered that "pervasive monitoring is an attack"
<span>[<a href="#RFC7258">RFC7258</a>]</span> (aka BCP 188). The IETF Last Call discussion for that short
document included more than 1000 emails -- while there was broad agreement on
the overall message, a number of IETF participants considered enshrining that
message in the RFC Series and IETF processes controversial. In any case, the
BCP was published in May 2014. The key statement on which rough consensus was
reached is in the abstract of RFC 7258 and says "Pervasive monitoring is a
technical attack that should be mitigated in the design of IETF protocols,
where possible." That document has since been referenced <span>[<a href="#Refs-to-7258">Refs-to-7258</a>]</span> by
many IETF working groups and RFCs as justifying additional work on security and
privacy. Throughout that period and beyond, the repercussions of the Snowden
revelations remained a major and ongoing agenda item for both of the IETF's
main technical management bodies, the IAB and the IESG (on which I served at
the time).<a href="#section-3-2">¶</a></p>
<p id="section-3-3">So far, I've only described the processes with which the IETF dealt with
the attacks, but there was, of course, also much technical work started by IETF
participants that was at least partly motivated by the Snowden revelations.<a href="#section-3-3">¶</a></p>
<p id="section-3-4">In November 2013, a working group was established to document better practices
for using TLS in applications <span>[<a href="#UTA">UTA</a>]</span> so that deployments would be less at risk
in the face of some of the attacks related to stripping TLS or having
applications misuse TLS APIs or parameters.  Similar work was done later to update
recommendations for use of cryptography in other protocols in the CURDLE 
Working Group <span>[<a href="#CURDLE">CURDLE</a>]</span>.  The CURDLE Working Group was, to an extent, created to
enable use of a set of new elliptic curves that had been documented by the IRTF
Crypto Forum Research Group <span>[<a href="#CFRG">CFRG</a>]</span>. That work in turn had been partly
motivated by (perhaps ultimately unfounded) concerns about elliptic curves
defined in NIST standards, following the DUAL_EC_DRBG debacle <span>[<a href="#Dual-EC">Dual-EC</a>]</span> 
(described further below) where a
NIST random number generator had been deliberately engineered to produce output
that could be vulnerable to NSA attack.<a href="#section-3-4">¶</a></p>
<p id="section-3-5">Work to develop a new version of TLS was started in 2014, mainly due to
concerns that TLS 1.2 and earlier version implementations had been shown to be
vulnerable to a range of attacks over the years. The work to develop TLS 1.3
<span>[<a href="#RFC8446">RFC8446</a>]</span> also aimed to encrypt more of the handshake so as to
expose less information to network observers -- a fairly direct result of the
Snowden revelations.  Work to further improve TLS in this respect continues
today using the so-called Encrypted Client Hello (ECH) mechanism <span>[<a href="#I-D.ietf-tls-esni">TLS-ECH</a>]</span>
to remove one of the last privacy leaks present in current TLS.<a href="#section-3-5">¶</a></p>
<p id="section-3-6">Work on ECH was enabled by significant developments to encrypt DNS traffic,
using DNS over TLS (DoT) <span>[<a href="#RFC7858">RFC7858</a>]</span> or DNS Queries over HTTPS (DoH) <span>[<a href="#RFC8484">RFC8484</a>]</span>, which also started as a result of
the Snowden revelations. Prior to that, privacy hadn't really been considered
when it came to DNS data or (more importantly) the act of accessing DNS data.
The trend towards encrypting DNS traffic represents a significant change for
the Internet, both in terms of reducing cleartext, but also in terms of moving
points-of-control. The latter aspect was, and remains, controversial, but the
IETF did its job of defining new protocols that can enable better DNS privacy.
Work on HTTP version 2 <span>[<a href="#RFC9113">RFC9113</a>]</span> and QUIC <span>[<a href="#RFC9000">RFC9000</a>]</span> further demonstrates
the trend in the IETF towards always encrypting protocols as the new norm, at
least at and above the transport layer.<a href="#section-3-6">¶</a></p>
<p id="section-3-7">Of course, not all such initiatives bore fruit; for example, attempts to define
a new MPLS encryption mechanism <span>[<a href="#I-D.ietf-mpls-opportunistic-encrypt">MPLS-OPPORTUNISTIC-ENCRYPT</a>]</span>
foundered due to a lack of interest and the existence of the already deployed
IEEE Media Access Control Security (MACsec) scheme. But there has been a fairly clear trend towards trying to
remove cleartext from the Internet as a precursor to provide improved privacy
when considering network observers as attackers.<a href="#section-3-7">¶</a></p>
<p id="section-3-8">The IETF, of course, forms only one part of the broader Internet technical
community, and there were many non-IETF activities triggered by the Snowden
revelations, a number of which also eventually resulted in new IETF work to
standardise better security and privacy mechanisms developed elsewhere.<a href="#section-3-8">¶</a></p>
<p id="section-3-9">In 2013, the web was largely unencrypted despite HTTPS being relatively
usable, and that was partly due to problems using the Web PKI at scale. The
Let's Encrypt initiative <span>[<a href="#LE">LE</a>]</span> issued its first certificates in 2015 as
part of its aim to try to move the web
towards being fully encrypted, and it has been extremely successful in helping
achieve that goal.  Subsequently, the automation protocols developed for
Let's Encrypt were standardised in the IETF's ACME Working Group <span>[<a href="#ACME">ACME</a>]</span>.<a href="#section-3-9">¶</a></p>
<p id="section-3-10">In 2013, most email transport between mail servers was cleartext,
directly enabling some of the attacks documented in the Snowden documents.
Significant effort by major mail services and MTA software developers since
then have resulted in more than 90% of email being encrypted between mail
servers, and various IETF protocols have been defined in order to improve that
situation, e.g., SMTP MTA Strict Transport Security (MTA-STS) <span>[<a href="#RFC8461">RFC8461</a>]</span>.<a href="#section-3-10">¶</a></p>
<p id="section-3-11">Lastly, MAC addresses have historically been long-term fixed values visible to
local networks (and beyond), which enabled some tracking attacks that were
documented in the Snowden documents <span>[<a href="#Toronto">Toronto</a>]</span>. 
Implementers, vendors, and the IEEE 802
standards group recognised this weakness and started work on MAC address
randomisation that in turn led to the IETF's MADINAS Working Group <span>[<a href="#MADINAS">MADINAS</a>]</span>, which
aims to ensure randomised MAC addresses can be used on the Internet without
causing unintentional harm.
There is also a history of IETF work on deprecating MAC-address-based IPv6 interface identifiers
and advocating pseudorandom identifiers and temporary addresses, some of
which pre-dates Snowden <span>[<a href="#RFC7217">RFC7217</a>]</span> <span>[<a href="#RFC8064">RFC8064</a>]</span> <span>[<a href="#RFC8981">RFC8981</a>]</span>.<a href="#section-3-11">¶</a></p>
<p id="section-3-12">In summary, the significantly large volume of technical work pursued in the
IETF and elsewhere as a result of the Snowden revelations has focussed on two
main things: decreasing the amount of plaintext that remains visible to network
observers and secondly reducing the number of long-term identifiers that enable
unexpected identification or re-identification of devices or users. This work
is not by any means complete, nor is deployment universal, but significant
progress has been made, and the work continues even if the level of annoyance
at the attack has faded somewhat over time.<a href="#section-3-12">¶</a></p>
<p id="section-3-13">One should also note that there has been pushback against these improvements
in security and privacy and the changes they cause for deployments. That has
come from more or less two camps: those on whom these improvements force
change tend to react badly, but later figure out how to adjust, and 
those who seemingly prefer not to strengthen security so as to, for
example, continue to achieve what they call "visibility" even in the face of the
many engineers who correctly argue that such an anti-encryption approach
inevitably leads to worse security overall. The recurring nature of this kind
of pushback is nicely illustrated by <span>[<a href="#RFC1984">RFC1984</a>]</span>. That informational document
was published in 1996 as an IETF response to an early iteration of the
perennial "encryption is bad" argument. In 2015, the unmodified 1996 text was
upgraded to a BCP (BCP 200) as the underlying arguments have
not changed, and will not change.<a href="#section-3-13">¶</a></p>
<p id="section-3-14">Looking back on all the above from a 2023 vantage point, I think that, as a
community of Internet engineers, we got a lot right, but that today there's way
more that needs to be done to better protect the security and privacy of people
who use the Internet. In particular, we (the technical community) haven't done
nearly as good a job at countering surveillance capitalism <span>[<a href="#Zubhoff2019">Zubhoff2019</a>]</span>, which has exploded
in the last decade. In part, that's because many of the problems are outside of
the scope of bodies such as the IETF. For example, intrusive backend sharing
of people's data for advertising purposes can't really be mitigated via
Internet protocols.<a href="#section-3-14">¶</a></p>
<p id="section-3-15">However, I also think that the real annoyance felt with respect to the Snowden
revelations is (in general) not felt nearly as much when it comes to the legal
but hugely privacy-invasive activities of major employers of Internet
engineers.<a href="#section-3-15">¶</a></p>
<p id="section-3-16">It's noteworthy that RFC 7258 doesn't consider that bad actors are limited to
governments, and personally, I think many advertising industry schemes for
collecting data are egregious examples of pervasive monitoring and hence ought
also be considered an attack on the Internet that ought be mitigated where
possible.  However, the Internet technical community clearly hasn't acted in
that way over the last decade.<a href="#section-3-16">¶</a></p>
<p id="section-3-17">Perhaps that indicates that Internet engineers and the bodies in which they
congregate need to place much more emphasis on standards for ethical behaviour
than has been the case for the first half-century of the Internet.  And while
it would be good to see the current leaders of Internet bodies work to make
progress in that regard, at the time of writing, it sadly seems more likely that
government regulators will be the ones to try force better behaviour. That of
course comes with a significant risk of having regulations that stymie the kind
of permissionless innovation that characterised many earlier Internet
successes.<a href="#section-3-17">¶</a></p>
<p id="section-3-18">So while we got a lot right in our reaction to Snowden's revelations,
currently, we have a "worse" Internet.  Nonetheless, I do still hope to see a
sea change there, as the importance of real Internet security and privacy for
people becomes utterly obvious to all, even the most hard-core capitalists and
government signals intelligence agencies.  That may seem naive, but I remain
optimistic that, as a fact-based community, we (and eventually our employers)
will recognise that the lesser risk is to honestly aim to provide the best
security and privacy practically possible.<a href="#section-3-18">¶</a></p>
</section>
<section id="farzaneh-badii-did-snowdens-revelations-help-with-protecting-human-rights-on-the-internet">
      <h2 id="name-farzaneh-badii-did-snowdens">
<a href="#section-4">4. </a><a href="#name-farzaneh-badii-did-snowdens">Farzaneh Badii: Did Snowden's Revelations Help with Protecting Human Rights on the Internet?</a>
      </h2>
<p id="section-4-1">It is very difficult to empirically measure the effect of Snowden's
revelations on human rights and the Internet. Anecdotally, we have
been witnessing dominant regulatory and policy approaches that impact
technologies and services that are at the core of protecting human
rights on the Internet. (A range of European Union laws aims to
address online safety or concentration of data. There are many more
regulations that have an impact on the Internet <span>[<a href="#Masnick2023">Masnick2023</a>]</span>.) There
has been little progress in fixing technical and policy issues that
help enable human rights. The Snowden revelations did not
revolutionize the Internet governance and
technical approaches to support human rights such as freedom
of expression, freedom of association and assembly, and privacy. It did not decrease the number of 
Internet shutdowns nor the eagerness of authoritarian (and even to some extent democratic) countries to territorialize the Internet. 
In some cases, the governments argued that they should have more data sovereignty or Internet sovereignty. Perhaps the revelations helped with the evolution of some technical and policy aspects.<a href="#section-4-1">¶</a></p>
<p id="section-4-2">After Snowden's revelations 10 years ago, engineers and advocates at
the IETF responded in a few
ways. One prominent response was the issuance of a BCP 
document, "Pervasive Monitoring Is an Attack" <span>[<a href="#RFC7258">RFC7258</a>]</span> by
Farrell and Tschofenig. The responses to the Snowden revelations did not
mean that IETF had lost sight of issues such as privacy and
surveillance. There were instances of resistance to surveillance in
the past by engineers (we do not delve into how successful that was in
protecting human rights). However, historically, many engineers believed
that widespread and habitual surveillance was too expensive to be
practical. The revelations proved them wrong.<a href="#section-4-2">¶</a></p>
<p id="section-4-3">Rights-centered activists were also involved with the IETF before the
revelations. For example, staff from Center for Democracy and
Technology (CDT) was undertaking work at the IETF (and was a member of
the Internet Architecture Board) and held workshops about the
challenges of creating privacy-protective protocols and systems. The
technical shortcomings that were exploited by the National Security
Agency to carry out mass-scale surveillance were recognized by the
IETF before the Snowden revelations <span>[<a href="#Garfinkel1995">Garfinkel1995</a>]</span> <span>[<a href="#RFC6462">RFC6462</a>]</span>. In
2012, Joy Liddicoat and Avri Doria wrote a report for the Internet Society
that extensively discussed the processes and principles of human
rights and Internet protocols <span>[<a href="#Doria2012">Doria2012</a>]</span>.<a href="#section-4-3">¶</a></p>
<p id="section-4-4">Perhaps the Snowden revelations brought more attention to the IETF and
its work as it related to important issues, such as privacy and
freedom of expression. It might have also expedited and helped with
more easily convening the Human Rights Protocol Considerations
Research Group (HRPC) in the Internet Research Task Force (IRTF) in July 2015. The HRPC RG was originally co-chaired
by Niels ten Oever (who worked at Article 19 at the time) and Internet
governance activist Avri Doria.
The charter of the HRPC RG states that
the group was established: "to research whether standards and
protocols can enable, strengthen or threaten human rights, as defined
in the Universal Declaration of Human Rights (UDHR) and the International Covenant on Civil and Political
Rights (ICCPR)."<a href="#section-4-4">¶</a></p>
<p id="section-4-5">During the past decade, a few successful strides were made to create
protocols that, when and if implemented, aim at protecting privacy of
the users, as well as help with reducing pervasive surveillance. These
efforts were in keeping with the consensus of the IETF found in RFC
7258.  Sometimes these protocols have anti-censorship qualities as
well. A few examples immediately come to mind: 1) the encryption of DNS
queries (for example, DNS over HTTPS), 2) ACME protocol underpinning
the Let's Encrypt initiative, and 3) Registration Data Access Protocol
(RDAP) <span>[<a href="#RFC7480">RFC7480</a>]</span> <span>[<a href="#RFC7481">RFC7481</a>]</span> <span>[<a href="#RFC8056">RFC8056</a>]</span> <span>[<a href="#RFC9082">RFC9082</a>]</span> <span>[<a href="#RFC9083">RFC9083</a>]</span> <span>[<a href="#RFC9224">RFC9224</a>]</span>. (It is debatable that RDAP had anything to do with
the Snowden revelations, but it is still a good example and is finally
being implemented.)<a href="#section-4-5">¶</a></p>
<p id="section-4-6">The DNS Queries over HTTPS protocol aimed to encrypt DNS queries. Four
years after RFC 7258, DoH was developed to tackle both active and
passive monitoring of DNS queries. It is also a tool that can help
with combatting censorship. Before the revelations, DNS query privacy
would have been controversial due to being expensive or unnecessary, but the 
Snowden revelations made it more plausible. 
Let's Encrypt was not an Internet protocol, but it was an initiative that aimed to encrypt the web, and later on
some of the automation protocols were standardized in the IETF ACME
Working Group. RDAP could solve a
long-term problem: redacting the domain name registrants' (and IP
address holders') sensitive, personal data but at the same time
enabling legitimate access to the information. As to the work of HRPC
Research Group, it has so far issued <span>[<a href="#RFC8280">RFC8280</a>]</span> by ten Oever and
Cath and a number of informational Internet-Drafts.<a href="#section-4-6">¶</a></p>
<p id="section-4-7">While we cannot really argue that all the movements and privacy-preserving 
protocols and initiatives that enable protecting human
rights at the infrastructure layer solely or directly result from the Snowden
revelations, I think it is safe to say that the revelations helped
with expediting the resolution of some of the "technical" hesitations
that had an effect on fixing Internet protocols that enabled
protection of human rights.<a href="#section-4-7">¶</a></p>
<p id="section-4-8">Unfortunately, the Snowden revelations have not yet helped us
meaningfully with adopting a human rights approach. We can't agree on
prioritizing human rights in our Internet communities for a host of
reasons. This could be due to: 1) human rights are sometimes in
conflict with each other; 2) it is simply not possible to mitigate the
human right violation through the Internet protocol; 3) it is not
obvious for the engineers in advance how the Internet protocol
contributes to enabling human rights protections, or precisely what they ought to do; 
 4) the protocol is already there, but market, law, and a
host of other societal and political issues do not allow for
widespread implementation.<a href="#section-4-8">¶</a></p>
<p id="section-4-9">IETF did not purposefully take a long time to adopt and implement protocols that
enabled human rights. There were technical and political issues that
created barriers. For example, as WHOIS was not capable of accommodating a tiered-access option, 
the IETF community attempted a few times before to create a protocol that would disclose the necessary
information of IP holders and domain name registrants while at the
same time protecting their data (Cross Registry Internet Service Protocol (CRISP) and later on Internet Registry Information Service (IRIS) are the
examples). However, IRIS was technically very difficult to implement. It was not until RDAP was developed and the
General Data Protection Regulation (GDPR) was enacted that Internet
Corporation for Assigned Names and Numbers had to consider instructing
registries and registrars to implement RDAP and its community had to
come up with a privacy-compliant policy.  Overall, a host of
regulatory and market incentives can halt or slow down the
implementation of human-rights-enabling protocols and implementation
could depend on other organizations with their own political and
stakeholder conflicts. Sometimes the protocol is available, but the regulatory framework and
the market do not allow for implementation. 
Sometimes the surrounding context includes 
practical dimensions that are easy to overlook in a purely engineering-focused argument.<a href="#section-4-9">¶</a></p>
<p id="section-4-10">
A curious example of this is sanctions regimes that target transactions involving
economically valuable assets.  As a result, sanctions might limit
sanctioned nations' and entities' access to IPv4 resources (because the existence of
a resale market for these addresses causes acquiring them to be
interpreted as buying something of value), though the same consideration
may not apply to IPv6 address resources.  But IPv6 adoption itself
depends on a host of complex factors that are by no means limited to
technical comparisons of the properties of IPv4 and IPv6.  Someone
focused only on technical features of protocols may devise an elegant
solution but be surprised both by deployment challenges and unintended
downstream effects.
Sometimes there are arguments over implementation of a protocol
because as it is perceived, while it can protect freedom of expression
and reduce surveillance, it can hamper other human rights. For
instance, the technical community and some network operators still have doubts about the implementation of DNS over HTTPS,
despite its potential to circumvent 
censorship and its ability to encrypt DNS queries. The arguments against
implementation of DoH include protection of children online and lack
of law enforcement access to data.<a href="#section-4-10">¶</a></p>
<p id="section-4-11">We must acknowledge that sometimes the technical solutions that we use
that protect one right (for example, encryption to protect the right to
privacy or to prevent surveillance) could potentially affect technical
and policy solutions that try to protect other human rights (for
example, encryption could prevent financial institutions from
monitoring employees' network activities to detect fraudulent
behavior). Acknowledging and identifying these conflicts can help us
come up with alternative techniques that could protect human rights
while not hampering other technical solutions such as
encryption. Where such alternative techniques are not possible,
acknowledging the shortcoming could clarify and bring to light the
trade-offs that we have accepted in our Internet system.<a href="#section-4-11">¶</a></p>
<p id="section-4-12">Ironically, we advocate for connectivity and believe expressing
oneself on the Internet is a human right, but when a war erupts, we
resort to tools that impact that very concept. For example, some
believe that, by imposing sanctions on critical properties of the Internet,
we can punish the perpetrators of a war. The Regional Internet
Registries that are in charge of registration of IP addresses have
shown resilience to these requests.  However, some tech companies (for
example, Cogent <span>[<a href="#Roth2022">Roth2022</a>]</span>) decided not to serve sanctioned countries
and overcomplied with sanctions. Overcompliance with sanctions could
hamper ordinary people's access to the Internet <span>[<a href="#Badii2023">Badii2023</a>]</span>.<a href="#section-4-12">¶</a></p>
<p id="section-4-13">Perhaps we can solve some of these problems by undertaking a thorough
impact assessment and contextualization to reveal how and why Internet
protocols affect human rights (something Fidler and I argued
for <span>[<a href="#Badii2021">Badii2021</a>]</span>). Contextualization and
impact assessment can reveal how each Internet protocol or each line
of code, in which systems, have an impact on which and whose human
rights.<a href="#section-4-13">¶</a></p>
<p id="section-4-14">The HRPC RG (which I am a part of) and the larger human rights and
policy analyst communities are still struggling to analyze legal,
social, and market factors alongside the protocols to have a good
understanding of what has an impact and what has to be changed. It is
hard, but it is not impossible. If we thoroughly document and research
the lifecycle of an Internet protocol and contextualize it, we might
have a better understanding of which
parts of the protocol to fix and how to fix them in order to protect human rights.<a href="#section-4-14">¶</a></p>
<p id="section-4-15">Overall, the revelations did, to some extent, contribute to the
evolution of our ideas and perspectives. Our next step should be to
undertake research on the impact of Internet systems (including
Internet protocols) on human rights, promote the implementation of
protocols good for human rights through policy and advocacy, and focus
on which technical parts we can standardize to help with more
widespread implementation of human-rights-enabling Internet protocols.<a href="#section-4-15">¶</a></p>
</section>
<section id="steven-m-bellovin-governments-and-cryptography-the-crypto-wars">
      <h2 id="name-steven-m-bellovin-governmen">
<a href="#section-5">5. </a><a href="#name-steven-m-bellovin-governmen">Steven M. Bellovin: Governments and Cryptography: The Crypto Wars</a>
      </h2>
<section id="historical-background">
        <h3 id="name-historical-background">
<a href="#section-5.1">5.1. </a><a href="#name-historical-background">Historical Background</a>
        </h3>
<p id="section-5.1-1">It's not a secret: many governments in the world don't like it when
people encrypt their traffic. More precisely, they like strong
cryptography for themselves but not for others, whether those others
are private citizens or other countries. But the history is longer and
more complex than that.<a href="#section-5.1-1">¶</a></p>
<p id="section-5.1-2">For much of written history, both governments and individuals used
cryptography to protect their messages. To cite just one famous
example, Julius Caesar is said to have encrypted messages by shifting
letters in the alphabet by 3 <span>[<a href="#Kahn1996">Kahn1996</a>]</span>. In modern parlance, 3 was
the key, and each letter was encrypted with<a href="#section-5.1-2">¶</a></p>
<p id="section-5.1-3">
            C[i] = (P[i] + 3) mod 23<a href="#section-5.1-3">¶</a></p>
<p id="section-5.1-4">(The Latin alphabet of his time had only 23 letters.)
Known
Arabic writings on cryptanalysis go back to at least the 8th century;
their sophistication shows that encryption was reasonably commonly
used. In the 9th century, Abū Yūsuf Yaʻqūb ibn ʼIsḥāq aṣ-Ṣabbāḥ 
al-Kindī developed and wrote about frequency analysis as a way to
crack ciphers <span>[<a href="#Borda2011">Borda2011</a>]</span> <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-4">¶</a></p>
<p id="section-5.1-5">In an era of minimal literacy, though, there wasn't that much use of
encryption, simply because most people could neither read nor
write. Governments used encryption for diplomatic messages, and
cryptanalysts followed close behind. The famed Black Chambers of the
Renaissance era read messages from many different governments, while
early cryptographers devised stronger and stronger ciphers
<span>[<a href="#Kahn1996">Kahn1996</a>]</span>. In Elizabethan times in England, Sir Francis Walsingham's
intelligence agency intercepted and decrypted messages from Mary,
Queen of Scots; these messages formed some of the strongest evidence
against her and eventually led to her execution <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-5">¶</a></p>
<p id="section-5.1-6">This pattern continued for centuries. In the United States, Thomas
Jefferson invented the so-called wheel cipher in the late 18th
century; it was reinvented about 100 years later by Étienne Bazeries
and used as a standard American military cipher well into World War II
<span>[<a href="#Kahn1996">Kahn1996</a>]</span>. Jefferson and other statesmen of the late 18th and early 19th centuries regularly used
cryptography when communicating with each other. An encrypted message
was even part of the evidence introduced in Aaron Burr's 1807 trial
for treason <span>[<a href="#Kerr2020">Kerr2020</a>]</span> <span>[<a href="#Kahn1996">Kahn1996</a>]</span>. Edgar Allan Poe claimed that he
could cryptanalyze any message sent to him <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-6">¶</a></p>
<p id="section-5.1-7">The telegraph era upped the ante. In the US, just a year after
Samuel Morse deployed his first telegraph line between Baltimore and
Washington, his business partner, Francis Smith, published a codebook
to help customers protect their traffic from prying eyes
<span>[<a href="#Smith1845">Smith1845</a>]</span>.  In 1870, Britain nationalized its domestic telegraph network;
in response, Robert Slater published a more sophisticated codebook
<span>[<a href="#Slater1870">Slater1870</a>]</span>. On the government side, Britain took advantage of its
position as the central node in the world's international telegraphic
networks to read a great deal of traffic passing through the country
<span>[<a href="#Headrick1991">Headrick1991</a>]</span> <span>[<a href="#Kennedy1971">Kennedy1971</a>]</span>. They used this ability strategically,
too -- when war broke out in 1914, the British Navy cut Germany's
undersea telegraph cables, forcing them to use radio; an intercept of
the so-called Zimmermann telegram, when cryptanalyzed, arguably led to
American entry into the war and thence to Germany's defeat. Once the
US entered the war, it required users of international telegraph
lines to deposit copies of the codebooks they used for compression, so
that censors could check messages for prohibited content <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-7">¶</a></p>
<p id="section-5.1-8">In Victorian Britain, private citizens, often lovers, used encryption
in newspapers' personal columns to communicate without their parents'
knowledge. Charles Wheatstone and Charles Babbage used to solve these
elementary ciphers routinely for their own amusement <span>[<a href="#Kahn1996">Kahn1996</a>]</span>.<a href="#section-5.1-8">¶</a></p>
<p id="section-5.1-9">This pattern continued for many years. Governments regularly used
ciphers and codes, while other countries tried to break them; private
individuals would sometimes use encryption but not often, and rarely
well. But the two World Wars marked a sea change, one that would soon
reverberate into the civilian world.<a href="#section-5.1-9">¶</a></p>
<p id="section-5.1-10">The first World War featured vast troop movements by all parties; this
in turn required a lot of encrypted communications, often by telegraph
or radio. These messages were often easily intercepted in
bulk. Furthermore, the difficulty of encrypting large volumes of
plaintext led to the development of a variety of mechanical encryption
devices, including Germany's famed Enigma machine. World War II
amplified both trends. It also gave rise to machine-assisted
cryptanalysis, such as the United Kingdom's bombes (derived from an
earlier Polish design) and Colossus machine, and the American's device
for cracking Japan's PURPLE system. The US also used punch
card-based tabulators to assist in breaking other Japanese codes, such
as the Japanese Imperial Navy's JN-25 <span>[<a href="#Kahn1996">Kahn1996</a>]</span> <span>[<a href="#Rowlett1998">Rowlett1998</a>]</span>.<a href="#section-5.1-10">¶</a></p>
<p id="section-5.1-11">These developments set the stage for the postwar SIGINT (Signals
Intelligence) environment. Many intragovernmental messages were sent by
radio, making them easy to intercept; advanced cryptanalytic machines
made cryptanalysis easier. Ciphers were getting stronger, though, and
government SIGINT agencies did not want to give up their access to
data. While there were undoubtedly many developments, two are well
known.<a href="#section-5.1-11">¶</a></p>
<p id="section-5.1-12">The first involved CryptoAG, a Swedish (and later Swiss) manufacturer
of encryption devices. The head of that company, Boris Hagelin, was a
friend of William F. Friedman, a pioneering American
cryptologist. During the 1950s, CryptoAG sold its devices to other
governments; apparently at Friedman's behest, Hagelin weakened the
encryption in a way that let the NSA read the traffic <span>[<a href="#Miller2020">Miller2020</a>]</span>.<a href="#section-5.1-12">¶</a></p>
<p id="section-5.1-13">The story involving the British is less well-documented and less
clear. When some of Britain's former colonies gained their
independence, the British government gave them captured, war-surplus
Enigma machines to protect their own traffic. Some authors contend
that this was deceptive, in that these former colonies did not realize
that the British could read Enigma-protected traffic; others claim
that this was obvious but that these countries didn't care: Britain
was no longer their enemy; it was neighboring countries they were
worried about. Again, though, this concerned governmental use of
encryption <span>[<a href="#Kahn1996">Kahn1996</a>]</span> <span>[<a href="#Baldwin2022">Baldwin2022</a>]</span>. There was still little private
use.<a href="#section-5.1-13">¶</a></p>
</section>
<section id="the-crypto-wars-begin">
        <h3 id="name-the-crypto-wars-begin">
<a href="#section-5.2">5.2. </a><a href="#name-the-crypto-wars-begin">The Crypto Wars Begin</a>
        </h3>
<p id="section-5.2-1">The modern era of conflict between an individual's desire for privacy and
the government desires to read traffic began around 1972. The grain
harvest in the USSR had failed; since relations between the Soviet
Union and the United States were temporarily comparatively warm, the
Soviet grain company -- an arm of the Soviet government, of
course -- entered into negotiations with private American
companies. Unknown to Americans at the time, Soviet intelligence was
intercepting the phone calls of the American negotiating teams. In
other words, private companies had to deal with state actors as a
threat. Eventually, US intelligence learned of this and came to a
realization: the private sector needed strong cryptography, too, to
protect American national interests <span>[<a href="#Broad1982">Broad1982</a>]</span> <span>[<a href="#Johnson1998">Johnson1998</a>]</span>. This
underscored the need for strong cryptography to protect American
civilian traffic -- but the SIGINT people were unhappy at the thought of
more encryption that they couldn't break.<a href="#section-5.2-1">¶</a></p>
<p id="section-5.2-2">Meanwhile, the US was concerned about protecting 
unclassified data <span>[<a href="#Landau2014">Landau2014</a>]</span>. In 1973 and again in 1974, the
National Bureau of Standards (NBS) put out a call for a strong, modern
encryption algorithm. IBM submitted Lucifer, an internally developed
algorithm based on what has become known as a 16-round Feistel network. The
original version used a long key.
It seemed quite strong, so NBS sent it off to the NSA to
get their take. The eventual design, which was adopted in 1976 as the
Data Encryption Standard (DES), differed in some important ways from
Lucifer. 
First, the so-called S-boxes, the source of the cryptologic
strength of DES, were changed, and were now demonstrably not composed of
random integers. Many researchers alleged that the S-boxes contained
an NSA back door. It took nearly 20 years for the truth to come out: the
S-boxes were in fact strengthened, not weakened. Most likely, IBM
independently discovered the attack now known as differential
cryptanalysis, though some scholars suspect that the NSA told them
about it. The nonrandom S-boxes protected against this attack. The
second change, though, was clearly insisted on by the NSA: the key size
was shortened, from Lucifer's 112 bits to DES's 56 bits. We now know
that the NSA wanted a 48-bit key size, while IBM wanted 64 bits; they
compromised at 56 bits.<a href="#section-5.2-2">¶</a></p>
<p id="section-5.2-3">Whitfield Diffie and Martin Hellman, at Stanford University, wondered
about the 56-bit keys. In 1979, they published a paper demonstrating
that the US government, but few others, could afford to build a
brute-force cracking machine, one that could try all 2<sup>56</sup> possible
keys to crack a message. NSA denied tampering with the design; a
Senate investigating committee found that assertion to be correct, but did
not discuss the shortened key length issue.<a href="#section-5.2-3">¶</a></p>
<p id="section-5.2-4">This, however, was not Diffie and Hellman's greatest contribution to
cryptology. A few years earlier, they had published a paper inventing what
is now known as public key cryptography.
(In fact, public key encryption had been invented a few years earlier
at UK Government Communications Headquarters (GCHQ), but they kept their discovery classified until 1997.)
In 1978, Ronald Rivest, Adi
Shamir, and Leonard Adleman devised the RSA algorithm, which made it
usable. (An NSA employee, acting on his own, sent a letter warning
that academic conferences on cryptology might violate US export
laws.)<a href="#section-5.2-4">¶</a></p>
<p id="section-5.2-5">Around the same time, George Davida at the University of Wisconsin
applied for a patent on a stream cipher; the NSA slapped a secrecy
order on the application. This barred him from even talking about his
invention. The publicity was devastating; the NSA had to back down.<a href="#section-5.2-5">¶</a></p>
<p id="section-5.2-6">The Crypto Wars had thus begun: civilians were inventing strong
encryption systems, and the NSA was tampering with them or trying to
suppress them. Bobby Inman, the then-director of the NSA, tried
creating a voluntary review process for academic papers, but very few
researchers were interested in participating <span>[<a href="#Landau1988">Landau1988</a>]</span>.<a href="#section-5.2-6">¶</a></p>
<p id="section-5.2-7">There were few major public battles during the 1980s because there
were few new major use cases for civilian cryptography during that
time. There was one notable incident, though: Shamir, Amos Fiat, and
Uriel Feige invented zero-knowledge proofs and applied for a US
patent. In response, the US Army slapped a secrecy order on the
patent. After a great deal of public outrage and intervention by, of
all organizations, the NSA, the order was lifted on very narrow
grounds: the inventors were not American, and they had been discussing
their work all over the world <span>[<a href="#Landau1988">Landau1988</a>]</span>.<a href="#section-5.2-7">¶</a></p>
<p id="section-5.2-8">In the 1990s, though, everything changed.<a href="#section-5.2-8">¶</a></p>
</section>
<section id="the-battle-is-joined">
        <h3 id="name-the-battle-is-joined">
<a href="#section-5.3">5.3. </a><a href="#name-the-battle-is-joined">The Battle Is Joined</a>
        </h3>
<p id="section-5.3-1">There were three major developments in cryptography in the early
1990s. First, Phil Zimmermann released PGP (Pretty Good Privacy), a
package to encrypt email messages. In 1993, AT&amp;T planned to release
the TSD-3600, an easy-to-use phone encryptor aimed at business
travelers. Shortly after that, the Netscape Communications Corporation released SSL
(Secure Socket Layer) as a way to enable web-based commerce using
their browser and web server. All of these were seen as threats by the
NSA and the FBI.<a href="#section-5.3-1">¶</a></p>
<p id="section-5.3-2">PGP was, at least arguably, covered by what was known as ITAR, the
International Trafficking in Arms Regulations -- under American law,
encryption software was regarded as a weapon, so exports required a
license. It was also alleged to infringe the patents on the RSA
algorithm. Needless to say, both issues were problematic for what was
intended to be open source software. Eventually, the criminal
investigation into Zimmermann's role in the spread of PGP overseas was
dropped, but the threat of such investigations remained to deter
others <span>[<a href="#Levy2001">Levy2001</a>]</span>.<a href="#section-5.3-2">¶</a></p>
<p id="section-5.3-3">The TSD-3600 was another matter. AT&amp;T was a major corporation that did
not want to pick a fight with the US government, but international
business travelers were seen as a major market for the device. At the
government's "request", the DES chip was replaced with what was known
as the Clipper chip. The Clipper chip used Skipjack, a cipher with
80-bit keys; it was thus much stronger against brute-force attacks
than DES. However, it provided "key escrow". Without going into any
details, the key escrow mechanism allowed US government
eavesdroppers to consult a pair of (presumably secure) internal
databases and decrypt all communications protected by the chip. The
Clipper chip proved to be extremely unpopular with industry; that AT&amp;T
Bell Labs' Matt Blaze found a weakness in the design <span>[<a href="#Blaze1994">Blaze1994</a>]</span>, one
that let you use Skipjack without the key escrow feature, didn't help
its reputation.<a href="#section-5.3-3">¶</a></p>
<p id="section-5.3-4">The third major development, SSL, was even trickier. SSL was aimed at
e-commerce, and of course Netscape wanted to be able to sell its
products outside the US. That would require an export license, so they
made a deal with the government: non-American users would receive a
version that used 40-bit keys, a key length far shorter than what the
NSA had agreed to 20 years earlier. (To get ahead of the story: there
was a compromise mode of operation, wherein an export-grade browser
could use strong encryption when talking to a financial
institution. This hybrid mode led to cryptographic weaknesses
discovered some 20 years later <span>[<a href="#Adrian2015">Adrian2015</a>]</span>.)<a href="#section-5.3-4">¶</a></p>
<p id="section-5.3-5">Technologists and American industry pushed back. The IETF adopted the
Danvers Doctrine, described in <span>[<a href="#RFC3365">RFC3365</a>]</span>:<a href="#section-5.3-5">¶</a></p>
<blockquote id="section-5.3-6">
          <p id="section-5.3-6.1">At the 32cd [sic] IETF held in Danvers, Massachusetts during April of 1995
the IESG asked the plenary for a consensus on the strength of security
that should be provided by IETF standards.  Although the immediate
issue before the IETF was whether or not to support "export" grade
security (which is to say weak security) in standards the question
raised the generic issue of security in general.<a href="#section-5.3-6.1">¶</a></p>
<p id="section-5.3-6.2">The overwhelming consensus was that the IETF should standardize on the
use of the best security available, regardless of national policies.
This consensus is often referred to as the "Danvers Doctrine".<a href="#section-5.3-6.2">¶</a></p>
</blockquote>
<p id="section-5.3-7">Then American companies started losing business to their overseas
competitors, who did not have to comply with US export laws. All of
this led to what seemed like a happy conclusion: the US government
drastically loosened its export rules for cryptographic software. All
was well -- or so it seemed...<a href="#section-5.3-7">¶</a></p>
</section>

<section id="whither-the-ietf">
        <h3 id="name-whither-the-ietf">
<a href="#section-5.5">5.5. </a><a href="#name-whither-the-ietf">Whither the IETF?</a>
        </h3>
<p id="section-5.5-1">Signal intelligence agencies, not just the NSA, but its peers around
the globe -- most major countries have their own -- are not going to go
away. The challenges that have beset the NSA are common to all such
agencies, and their solutions are likely the same. The question is
what should be done to protect individual privacy. A number of strong
democracies, such as Australia and the United Kingdom, are, in
a resumption of the Crypto Wars,
moving to restrict encryption. Spurred on by complaints from the FBI
and other law enforcement agencies, the US Congress frequently
considers bills to do the same.<a href="#section-5.5-1">¶</a></p>
<p id="section-5.5-2">The IETF has long had a commitment to strong, ubiquitous
encryption. This is a good thing. It needs to continue, with
cryptography and other security features designed into protocols from
the beginning. But there is also a need for maintenance. Parameters
such as key lengths and modulus sizes age; a value that is acceptable
today may not be 10 years hence. (We've already seen apparent problems
from 1024-bit moduli specified in an RFC, an RFC that was not modified
when technology improved enough that attacking encryption based on
them had become feasible <span>[<a href="#Adrian2015">Adrian2015</a>]</span>.) The IETF can do nothing about
the code that vendors ship or that sites use, but it can alert the
world that it thinks things have changed.<a href="#section-5.5-2">¶</a></p>
<p id="section-5.5-3">Cryptoagility is of increasing importance. In the next very few years,
we will have so-called post-quantum algorithms. Both protocols and key
lengths will need to change, perhaps drastically. Is the IETF ready?
What will happen to, say, DNSSEC if key lengths become drastically
longer? Backwards compatibility will remain important, but that, of
course, opens the door to other attacks. We've long thought about
them; we need to be sure that our mechanisms work -- we've
been surprised in the past <span>[<a href="#BellovinRescorla2006">BellovinRescorla2006</a>]</span>.<a href="#section-5.5-3">¶</a></p>
<p id="section-5.5-4">We also need to worry more about metadata. General Michael Hayden,
former director of both the NSA and the CIA, once remarked, "We kill
people based on metadata" <span>[<a href="#Ferran2014">Ferran2014</a>]</span>. But caution is necessary;
attempts to hide metadata can have side effects. To give a trivial
example, Tor is quite strong, but if your exit node is in a different
country than you are in, web sites that use IP geolocation may present
their content in a language foreign to you.
Some sites even block connections from known Tor exit nodes.
More generally, many
attempts to hide metadata involve trusting a different party; that
party may turn out to be untrustworthy or it may itself become a
target of attack. As another prominent IETFer has remarked,
"Insecurity is like entropy; you can't destroy it, but you can move it
around." The IETF has done a lot; it needs to do more. And remember
that the risk here is not just governments acting directly, it's also
private companies that collect the data and sell it to all comers.<a href="#section-5.5-4">¶</a></p>
<p id="section-5.5-5">Finally, the IETF must remember that its middle name is
"Engineering". To me, one of the attributes of engineering is the art
of picking the right solution in an over-constrained
environment. Intelligence agencies won't go away, nor will national
restrictions on cryptography. We have to pick the right path while
staying true to our principles.<a href="#section-5.5-5">¶</a></p>
</section>
</section>
<section id="security-considerations">
      <h2 id="name-security-considerations">
<a href="#section-6">6. </a><a href="#name-security-considerations">Security Considerations</a>
      </h2>
<p id="section-6-1">Each or any of the authors may have forgotten or omitted things
or gotten things wrong. We're sorry if that's the case, but that's
in the nature of a look-back such as this. Such flaws almost 
certainly won't worsen security or privacy, though.<a href="#section-6-1">¶</a></p>
</section>
<section id="iana-considerations">
      <h2 id="name-iana-considerations">
<a href="#section-7">7. </a><a href="#name-iana-considerations">IANA Considerations</a>
      </h2>
<p id="section-7-1">This document has no IANA actions.<a href="#section-7-1">¶</a></p>
</section>
<section id="section-8">
      <h2 id="name-informative-references">
<a href="#section-8">8. </a><a href="#name-informative-references">Informative References</a>
      </h2>
<dl>
<dt id="ACME">[ACME]</dt>
      <dd>
<span>IETF</span>, <span>"Automated Certificate Management Environment (acme)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/acme/about/">https://datatracker.ietf.org/wg/acme/about/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Adrian2015">[Adrian2015]</dt>
      <dd>
<span>Adrian, D.</span>, <span>Bhargavan, K.</span>, <span>Durumeric, Z.</span>, <span>Gaudry, P.</span>, <span>Green, M.</span>, <span>Halderman, J. A.</span>, <span>Heninger, N.</span>, <span>Springhall, D.</span>, <span>Thomé, E.</span>, <span>Valenta, L.</span>, <span>VanderSloot, B.</span>, <span>Wustrow, E.</span>, <span>Zanella-Béguelin, S.</span>, and <span>P. Zimmermann</span>, <span>"Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice"</span>, <span>CCS '15: Proceedings of the 22th ACM Conference on Computer and Communications Security</span>, <time datetime="2015-10">October 2015</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/2810103.2813707">https://dl.acm.org/doi/10.1145/2810103.2813707</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Badii2021">[Badii2021]</dt>
      <dd>
<span>Badiei, F.</span>, <span>Fidler, B.</span>, and <span>The Pennsylvania State University Press</span>, <span>"The Would-Be Technocracy: Evaluating Efforts to Direct and Control Social Change with Internet Protocol Design"</span>, <span>Journal of Information Policy, vol. 11, pp. 376-402</span>, <span>DOI 10.5325/jinfopoli.11.2021.0376</span>, <time datetime="2021-12">December 2021</time>, <span>&lt;<a href="https://doi.org/10.5325/jinfopoli.11.2021.0376">https://doi.org/10.5325/jinfopoli.11.2021.0376</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Badii2023">[Badii2023]</dt>
      <dd>
<span>Badiei, F.</span>, <span>"Sanctions and the Internet"</span>, <span>Digital Medusa</span>, <time datetime="2023">2023</time>, <span>&lt;<a href="https://digitalmedusa.org/wp-content/uploads/2023/05/SanctionsandtheInternet-DigitalMedusa.pdf">https://digitalmedusa.org/wp-content/uploads/2023/05/SanctionsandtheInternet-DigitalMedusa.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Baldwin2022">[Baldwin2022]</dt>
      <dd>
<span>Baldwin, M.</span>, <span>"Did Britain sell Enigmas postwar?"</span>, <span>Dr. Enigma</span>, <time datetime="2022-03">March 2022</time>, <span>&lt;<a href="https://drenigma.org/2022/03/02/did-britain-sell-enigmas-postwar/">https://drenigma.org/2022/03/02/did-britain-sell-enigmas-postwar/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="BellovinRescorla2006">[BellovinRescorla2006]</dt>
      <dd>
<span>Bellovin, S. M.</span> and <span>E. K. Rescorla</span>, <span>"Deploying a New Hash Algorithm"</span>, <span>Proceedings of NDSS '06</span>, <time datetime="2006-02">February 2006</time>, <span>&lt;<a href="https://www.cs.columbia.edu/~smb/papers/new-hash.pdf">https://www.cs.columbia.edu/~smb/papers/new-hash.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Blaze1994">[Blaze1994]</dt>
      <dd>
<span>Blaze, M.</span>, <span>"Protocol Failure in the Escrowed Encryption Standard"</span>, <span>CCS '94: Proceedings of Second ACM Conference on Computer and Communications Security</span>, <time datetime="1994">1994</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/191177.191193">https://dl.acm.org/doi/10.1145/191177.191193</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Borda2011">[Borda2011]</dt>
      <dd>
<span>Borda, M.</span>, <span>"Fundamentals in Information Theory and Coding"</span>, <span>Springer-Berlin</span>, <time datetime="2011-05">May 2011</time>. </dd>
<dd></dd>
<dt id="Broad1982">[Broad1982]</dt>
      <dd>
<span>Broad, W. J.</span>, <span>"Evading the Soviet Ear at Glen Cove"</span>, <span>Science, 217:4563, pp. 910-911</span>, <time datetime="1982-09">September 1982</time>, <span>&lt;<a href="https://www.science.org/doi/abs/10.1126/science.217.4563.910">https://www.science.org/doi/abs/10.1126/science.217.4563.910</a>&gt;</span>. </dd>
<dd></dd>
<dt id="CFRG">[CFRG]</dt>
      <dd>
<span>IRTF</span>, <span>"Crypto Forum (cfrg)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/rg/cfrg/about/">https://datatracker.ietf.org/rg/cfrg/about/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Checkoway2016">[Checkoway2016]</dt>
      <dd>
<span>Checkoway, S.</span>, <span>Maskiewicz, J.</span>, <span>Garman, C.</span>, <span>Fried, J.</span>, <span>Cohney, S.</span>, <span>Green, M.</span>, <span>Heninger, N.</span>, <span>Weinmann, R. P.</span>, <span>Rescorla, E.</span>, and <span>Hovav Shacham</span>, <span>"A Systematic Analysis of the Juniper Dual EC Incident"</span>, <span>CCS '16: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 468-479</span>, <time datetime="2016-10">October 2016</time>, <span>&lt;<a href="https://dl.acm.org/citation.cfm?id=2978395">https://dl.acm.org/citation.cfm?id=2978395</a>&gt;</span>. </dd>
<dd></dd>
<dt id="CURDLE">[CURDLE]</dt>
      <dd>
<span>IETF</span>, <span>"CURves, Deprecating and a Little more Encryption (curdle)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/curdle/about/">https://datatracker.ietf.org/wg/curdle/about/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Curtiz">[Curtiz]</dt>
      <dd>
<span>Curtiz, M.</span>, <span>Epstein, J. J.</span>, <span>Epstein, P. G.</span>, and <span>H. Koch</span>, <span>"Casablanca"</span>, <span>Warner Bros. Pictures</span>, <time datetime="1942-11">November 1942</time>. </dd>
<dd></dd>
<dt id="Doria2012">[Doria2012]</dt>
      <dd>
<span>Liddicoat, J.</span> and <span>A. Doria</span>, <span>"Human Rights and Internet Protocols: Comparing Processes and Principles"</span>, <span>The Internet Society</span>, <time datetime="2012-12">December 2012</time>, <span>&lt;<a href="https://www.internetsociety.org/resources/doc/2012/human-rights-and-internet-protocols-comparing-processes-and-principles/">https://www.internetsociety.org/resources/doc/2012/human-rights-and-internet-protocols-comparing-processes-and-principles/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Dual-EC">[Dual-EC]</dt>
      <dd>
<span>Bernstein, D.</span>, <span>Lange, T.</span>, and <span>R. Niederhagen</span>, <span>"Dual EC: A Standardized Back Door"</span>, <time datetime="2016-07">July 2016</time>, <span>&lt;<a href="https://eprint.iacr.org/2015/767.pdf">https://eprint.iacr.org/2015/767.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Ferran2014">[Ferran2014]</dt>
      <dd>
<span>Ferran, L.</span>, <span>"Ex-NSA Chief: "We Kill People Based on Metadata""</span>, <span>ABC News</span>, <time datetime="2014-05">May 2014</time>, <span>&lt;<a href="https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata">https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Garfinkel1995">[Garfinkel1995]</dt>
      <dd>
<span>Garfinkel, S.</span>, <span>"PGP: Pretty Good Privacy"</span>, <span>O'Reilly and Associates</span>, <time datetime="1995-01">January 1995</time>. </dd>
<dd></dd>
<dt id="Guard2013">[Guard2013]</dt>
      <dd>
<span>Greenwald, G.</span>, <span>"NSA collecting phone records of millions of Verizon customers daily"</span>, <span>The Guardian</span>, <time datetime="2013-06">June 2013</time>. </dd>
<dd></dd>
<dt id="Headrick1991">[Headrick1991]</dt>
      <dd>
<span>Headrick, D. R.</span>, <span>"The Invisible Weapon: Telecommunications and International Politics, 1851-1945"</span>, <span>Oxford University Press</span>, <time datetime="1991">1991</time>. </dd>
<dd></dd>
<dt id="Johnson1998">[Johnson1998]</dt>
      <dd>
<span>Johnson, T. R.</span>, <span>"American Cryptology During the Cold War, 1945-1989; Book III: Retrenchment and Reform, 1972-1980"</span>, <span>Center for Cryptologic History, NSA</span>, <time datetime="1998">1998</time>, <span>&lt;<a href="https://www.nsa.gov/portals/75/documents/news-features/declassified-documents/cryptologic-histories/cold_war_iii.pdf">https://www.nsa.gov/portals/75/documents/news-features/declassified-documents/cryptologic-histories/cold_war_iii.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Kahn1996">[Kahn1996]</dt>
      <dd>
<span>Kahn, D.</span>, <span>"The Codebreakers: The Comprehensive History of Secret Communication from Ancient Times to the Internet"</span>, <span>2nd Edition</span>, <span>Scribner</span>, <time datetime="1996">1996</time>. </dd>
<dd></dd>
<dt id="Kennedy1971">[Kennedy1971]</dt>
      <dd>
<span>Kennedy, P. M.</span>, <span>"Imperial cable communications and strategy, 1870-1914"</span>, <span>English Historical Review, 86:341, pp. 728-752</span>, <span>Oxford University Press</span>, <time datetime="1971-10">October 1971</time>, <span>&lt;<a href="https://www.jstor.org/stable/563928">https://www.jstor.org/stable/563928</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Kerr2020">[Kerr2020]</dt>
      <dd>
<span>Kerr, O. S.</span>, <span>"Decryption Originalism: The Lessons of Burr"</span>, <span>Harvard Law Review, 134:905</span>, <time datetime="2021-01">January 2021</time>, <span>&lt;<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3533069">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3533069</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Kostyuk2022">[Kostyuk2022]</dt>
      <dd>
<span>Kostyuk, N.</span> and <span>S. Landau</span>, <span>"Dueling over DUAL_EC_DRBG: The Consequences of Corrupting a Cryptographic Standardization Process"</span>, <span>Harvard National Security Journal, 13:2, pp. 224-284</span>, <time datetime="2022-06">June 2022</time>, <span>&lt;<a href="https://www.harvardnsj.org/wp-content/uploads/sites/13/2022/06/Vol13Iss2_Kostyuk-Landau_Dual-EC-DRGB.pdf">https://www.harvardnsj.org/wp-content/uploads/sites/13/2022/06/Vol13Iss2_Kostyuk-Landau_Dual-EC-DRGB.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Landau1988">[Landau1988]</dt>
      <dd>
<span>Landau, S.</span>, <span>"Zero Knowledge and the Department of Defense"</span>, <span>Notices of the American Mathematical Society, 35:1, pp. 5-12</span>, <time datetime="1988-01">January 1988</time>, <span>&lt;<a href="https://privacyink.org/pdf/Zero_Knowledge.pdf">https://privacyink.org/pdf/Zero_Knowledge.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Landau2014">[Landau2014]</dt>
      <dd>
<span>Landau, S.</span>, <span>"Under the Radar: NSA's Efforts to Secure Private-Sector Telecommunications Infrastructure"</span>, <span>Journal of National Security Law &amp; Policy, 7:3</span>, <time datetime="2014-09">September 2014</time>, <span>&lt;<a href="https://jnslp.com/wp-content/uploads/2015/03/NSA%E2%80%99s-Efforts-to-Secure-Private-Sector-Telecommunications-Infrastructure_2.pdf">https://jnslp.com/wp-content/uploads/2015/03/NSA%E2%80%99s-Efforts-to-Secure-Private-Sector-Telecommunications-Infrastructure_2.pdf</a>&gt;</span>. </dd>
<dd></dd>
<dt id="LE">[LE]</dt>
      <dd>
<span>Aas, J.</span>, <span>Barnes, R.</span>, <span>Case, B.</span>, <span>Durumeric, Z.</span>, <span>Eckersley, P.</span>, <span>Flores-López, A.</span>, <span>Halderman, A.</span>, <span>Hoffman-Andrews, J.</span>, <span>Kasten, J.</span>, <span>Rescorla, E.</span>, <span>Schoen, S. D.</span>, and <span>B. Warren</span>, <span>"Let's Encrypt: An Automated Certificate Authority to Encrypt the Entire Web"</span>, <span>CCS '19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security</span>, <time datetime="2019-11">November 2019</time>, <span>&lt;<a href="https://dl.acm.org/doi/pdf/10.1145/3319535.3363192">https://dl.acm.org/doi/pdf/10.1145/3319535.3363192</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Levy2001">[Levy2001]</dt>
      <dd>
<span>Levy, S.</span>, <span>"Crypto: How the Code Rebels Beat the Government-Saving Privacy in the Digital Age"</span>, <span>Penguin Publishing Group</span>, <time datetime="2001-01">January 2001</time>. </dd>
<dd></dd>
<dt id="MADINAS">[MADINAS]</dt>
      <dd>
<span>IETF</span>, <span>"MAC Address Device Identification for Network and Application Services (madinas)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/madinas/about">https://datatracker.ietf.org/wg/madinas/about</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Masnick2023">[Masnick2023]</dt>
      <dd>
<span>Masnick, M.</span>, <span>"The Unintended Consequences of Internet Regulation"</span>, <span>Copia</span>, <time datetime="2023-04">April 2023</time>, <span>&lt;<a href="https://copia.is/library/unintended-consequences/">https://copia.is/library/unintended-consequences/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Miller2020">[Miller2020]</dt>
      <dd>
<span>Miller, G.</span>, <span>"The intelligence coup of the century"</span>, <span>The Washington Post</span>, <time datetime="2020-02">February 2020</time>, <span>&lt;<a href="https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/">https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Moore2015">[Moore2015]</dt>
      <dd>
<span>Moore, H. D.</span>, <span>"CVE-2015-7755: Juniper ScreenOS Authentication Backdoor"</span>, <span>Rapid7</span>, <time datetime="2015-12">December 2015</time>, <span>&lt;<a href="https://www.rapid7.com/blog/post/2015/12/20/cve-2015-7755-juniper-screenos-authentication-backdoor/">https://www.rapid7.com/blog/post/2015/12/20/cve-2015-7755-juniper-screenos-authentication-backdoor/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="I-D.ietf-mpls-opportunistic-encrypt">[MPLS-OPPORTUNISTIC-ENCRYPT]</dt>
      <dd>
<span>Farrel, A.</span> and <span>S. Farrell</span>, <span>"Opportunistic Security in MPLS Networks"</span>, <span>Work in Progress</span>, <span>Internet-Draft, draft-ietf-mpls-opportunistic-encrypt-03</span>, <time datetime="2017-03-28">28 March 2017</time>, <span>&lt;<a href="https://datatracker.ietf.org/doc/html/draft-ietf-mpls-opportunistic-encrypt-03">https://datatracker.ietf.org/doc/html/draft-ietf-mpls-opportunistic-encrypt-03</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Perpass">[Perpass]</dt>
      <dd>
<span>IETF</span>, <span>"perpass mailing list"</span>, <span>&lt;<a href="https://mailarchive.ietf.org/arch/browse/perpass/">https://mailarchive.ietf.org/arch/browse/perpass/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Perpass-BoF">[Perpass-BoF]</dt>
      <dd>
<span>IETF</span>, <span>"perpass BoF -- Handling Pervasive Monitoring in the IETF"</span>, <span>IETF 88 Proceedings</span>, <time datetime="2013-11">November 2013</time>, <span>&lt;<a href="https://www.ietf.org/proceedings/88/perpass.html">https://www.ietf.org/proceedings/88/perpass.html</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Plenary-video">[Plenary-video]</dt>
      <dd>
<span>"IETF 88 Technical Plenary: Hardening The Internet"</span>, <span>YouTube video, 2:37:28, posted by "IETF - Internet Engineering Task Force"</span>, <time datetime="2013-11">November 2013</time>, <span>&lt;<a href="https://www.youtube.com/watch?v=oV71hhEpQ20&amp;pp=ygUQaWV0ZiA4OCBwbGVuYXJ5IA%3D%3D">https://www.youtube.com/watch?v=oV71hhEpQ20&amp;pp=ygUQaWV0ZiA4OCBwbGVuYXJ5IA%3D%3D</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Refs-to-7258">[Refs-to-7258]</dt>
      <dd>
<span>IETF</span>, <span>"References to RFC7258"</span>, <span>&lt;<a href="https://datatracker.ietf.org/doc/rfc7258/referencedby/">https://datatracker.ietf.org/doc/rfc7258/referencedby/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC1984">[RFC1984]</dt>
      <dd>
<span>IAB</span> and <span>IESG</span>, <span>"IAB and IESG Statement on Cryptographic Technology and the Internet"</span>, <span>BCP 200</span>, <span>RFC 1984</span>, <span>DOI 10.17487/RFC1984</span>, <time datetime="1996-08">August 1996</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc1984">https://www.rfc-editor.org/info/rfc1984</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC3365">[RFC3365]</dt>
      <dd>
<span>Schiller, J.</span>, <span>"Strong Security Requirements for Internet Engineering Task Force Standard Protocols"</span>, <span>BCP 61</span>, <span>RFC 3365</span>, <span>DOI 10.17487/RFC3365</span>, <time datetime="2002-08">August 2002</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc3365">https://www.rfc-editor.org/info/rfc3365</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC6462">[RFC6462]</dt>
      <dd>
<span>Cooper, A.</span>, <span>"Report from the Internet Privacy Workshop"</span>, <span>RFC 6462</span>, <span>DOI 10.17487/RFC6462</span>, <time datetime="2012-01">January 2012</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc6462">https://www.rfc-editor.org/info/rfc6462</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7217">[RFC7217]</dt>
      <dd>
<span>Gont, F.</span>, <span>"A Method for Generating Semantically Opaque Interface Identifiers with IPv6 Stateless Address Autoconfiguration (SLAAC)"</span>, <span>RFC 7217</span>, <span>DOI 10.17487/RFC7217</span>, <time datetime="2014-04">April 2014</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7217">https://www.rfc-editor.org/info/rfc7217</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7258">[RFC7258]</dt>
      <dd>
<span>Farrell, S.</span> and <span>H. Tschofenig</span>, <span>"Pervasive Monitoring Is an Attack"</span>, <span>BCP 188</span>, <span>RFC 7258</span>, <span>DOI 10.17487/RFC7258</span>, <time datetime="2014-05">May 2014</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7258">https://www.rfc-editor.org/info/rfc7258</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7480">[RFC7480]</dt>
      <dd>
<span>Newton, A.</span>, <span>Ellacott, B.</span>, and <span>N. Kong</span>, <span>"HTTP Usage in the Registration Data Access Protocol (RDAP)"</span>, <span>STD 95</span>, <span>RFC 7480</span>, <span>DOI 10.17487/RFC7480</span>, <time datetime="2015-03">March 2015</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7480">https://www.rfc-editor.org/info/rfc7480</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7481">[RFC7481]</dt>
      <dd>
<span>Hollenbeck, S.</span> and <span>N. Kong</span>, <span>"Security Services for the Registration Data Access Protocol (RDAP)"</span>, <span>STD 95</span>, <span>RFC 7481</span>, <span>DOI 10.17487/RFC7481</span>, <time datetime="2015-03">March 2015</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7481">https://www.rfc-editor.org/info/rfc7481</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7687">[RFC7687]</dt>
      <dd>
<span>Farrell, S.</span>, <span>Wenning, R.</span>, <span>Bos, B.</span>, <span>Blanchet, M.</span>, and <span>H. Tschofenig</span>, <span>"Report from the Strengthening the Internet (STRINT) Workshop"</span>, <span>RFC 7687</span>, <span>DOI 10.17487/RFC7687</span>, <time datetime="2015-12">December 2015</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7687">https://www.rfc-editor.org/info/rfc7687</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC7858">[RFC7858]</dt>
      <dd>
<span>Hu, Z.</span>, <span>Zhu, L.</span>, <span>Heidemann, J.</span>, <span>Mankin, A.</span>, <span>Wessels, D.</span>, and <span>P. Hoffman</span>, <span>"Specification for DNS over Transport Layer Security (TLS)"</span>, <span>RFC 7858</span>, <span>DOI 10.17487/RFC7858</span>, <time datetime="2016-05">May 2016</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc7858">https://www.rfc-editor.org/info/rfc7858</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8056">[RFC8056]</dt>
      <dd>
<span>Gould, J.</span>, <span>"Extensible Provisioning Protocol (EPP) and Registration Data Access Protocol (RDAP) Status Mapping"</span>, <span>RFC 8056</span>, <span>DOI 10.17487/RFC8056</span>, <time datetime="2017-01">January 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8056">https://www.rfc-editor.org/info/rfc8056</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8064">[RFC8064]</dt>
      <dd>
<span>Gont, F.</span>, <span>Cooper, A.</span>, <span>Thaler, D.</span>, and <span>W. Liu</span>, <span>"Recommendation on Stable IPv6 Interface Identifiers"</span>, <span>RFC 8064</span>, <span>DOI 10.17487/RFC8064</span>, <time datetime="2017-02">February 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8064">https://www.rfc-editor.org/info/rfc8064</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8280">[RFC8280]</dt>
      <dd>
<span>ten Oever, N.</span> and <span>C. Cath</span>, <span>"Research into Human Rights Protocol Considerations"</span>, <span>RFC 8280</span>, <span>DOI 10.17487/RFC8280</span>, <time datetime="2017-10">October 2017</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8280">https://www.rfc-editor.org/info/rfc8280</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8446">[RFC8446]</dt>
      <dd>
<span>Rescorla, E.</span>, <span>"The Transport Layer Security (TLS) Protocol Version 1.3"</span>, <span>RFC 8446</span>, <span>DOI 10.17487/RFC8446</span>, <time datetime="2018-08">August 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8446">https://www.rfc-editor.org/info/rfc8446</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8461">[RFC8461]</dt>
      <dd>
<span>Margolis, D.</span>, <span>Risher, M.</span>, <span>Ramakrishnan, B.</span>, <span>Brotman, A.</span>, and <span>J. Jones</span>, <span>"SMTP MTA Strict Transport Security (MTA-STS)"</span>, <span>RFC 8461</span>, <span>DOI 10.17487/RFC8461</span>, <time datetime="2018-09">September 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8461">https://www.rfc-editor.org/info/rfc8461</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8484">[RFC8484]</dt>
      <dd>
<span>Hoffman, P.</span> and <span>P. McManus</span>, <span>"DNS Queries over HTTPS (DoH)"</span>, <span>RFC 8484</span>, <span>DOI 10.17487/RFC8484</span>, <time datetime="2018-10">October 2018</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8484">https://www.rfc-editor.org/info/rfc8484</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC8981">[RFC8981]</dt>
      <dd>
<span>Gont, F.</span>, <span>Krishnan, S.</span>, <span>Narten, T.</span>, and <span>R. Draves</span>, <span>"Temporary Address Extensions for Stateless Address Autoconfiguration in IPv6"</span>, <span>RFC 8981</span>, <span>DOI 10.17487/RFC8981</span>, <time datetime="2021-02">February 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8981">https://www.rfc-editor.org/info/rfc8981</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9000">[RFC9000]</dt>
      <dd>
<span>Iyengar, J., Ed.</span> and <span>M. Thomson, Ed.</span>, <span>"QUIC: A UDP-Based Multiplexed and Secure Transport"</span>, <span>RFC 9000</span>, <span>DOI 10.17487/RFC9000</span>, <time datetime="2021-05">May 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9000">https://www.rfc-editor.org/info/rfc9000</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9082">[RFC9082]</dt>
      <dd>
<span>Hollenbeck, S.</span> and <span>A. Newton</span>, <span>"Registration Data Access Protocol (RDAP) Query Format"</span>, <span>STD 95</span>, <span>RFC 9082</span>, <span>DOI 10.17487/RFC9082</span>, <time datetime="2021-06">June 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9082">https://www.rfc-editor.org/info/rfc9082</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9083">[RFC9083]</dt>
      <dd>
<span>Hollenbeck, S.</span> and <span>A. Newton</span>, <span>"JSON Responses for the Registration Data Access Protocol (RDAP)"</span>, <span>STD 95</span>, <span>RFC 9083</span>, <span>DOI 10.17487/RFC9083</span>, <time datetime="2021-06">June 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9083">https://www.rfc-editor.org/info/rfc9083</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9113">[RFC9113]</dt>
      <dd>
<span>Thomson, M., Ed.</span> and <span>C. Benfield, Ed.</span>, <span>"HTTP/2"</span>, <span>RFC 9113</span>, <span>DOI 10.17487/RFC9113</span>, <time datetime="2022-06">June 2022</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9113">https://www.rfc-editor.org/info/rfc9113</a>&gt;</span>. </dd>
<dd></dd>
<dt id="RFC9224">[RFC9224]</dt>
      <dd>
<span>Blanchet, M.</span>, <span>"Finding the Authoritative Registration Data Access Protocol (RDAP) Service"</span>, <span>STD 95</span>, <span>RFC 9224</span>, <span>DOI 10.17487/RFC9224</span>, <time datetime="2022-03">March 2022</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9224">https://www.rfc-editor.org/info/rfc9224</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Roth2022">[Roth2022]</dt>
      <dd>
<span>Roth, E.</span>, <span>"Internet backbone provider shuts off service in Russia"</span>, <span>The Verge</span>, <time datetime="2022-03">March 2022</time>, <span>&lt;<a href="https://www.theverge.com/2022/3/5/22962822/internet-backbone-provider-cogent-shuts-off-service-russia">https://www.theverge.com/2022/3/5/22962822/internet-backbone-provider-cogent-shuts-off-service-russia</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Rowlett1998">[Rowlett1998]</dt>
      <dd>
<span>Rowlett, F. B.</span>, <span>"The Story of Magic, Memoirs of an American Cryptologic Pioneer"</span>, <span>Aegean Park Press</span>, <time datetime="1998">1998</time>. </dd>
<dd></dd>
<dt id="Slater1870">[Slater1870]</dt>
      <dd>
<span>Slater, R.</span>, <span>"Telegraphic Code, to Ensure Secresy in the Transmission of Telegrams"</span>, <span>First Edition</span>, <span>W.R. Gray</span>, <time datetime="1870">1870</time>, <span>&lt;<a href="https://books.google.com/books?id=MJYBAAAAQAAJ">https://books.google.com/books?id=MJYBAAAAQAAJ</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Smith1845">[Smith1845]</dt>
      <dd>
<span>Smith, F. O.</span>, <span>"The Secret Corresponding Vocabulary: Adapted for Use to Morse's Electro-Magnetic Telegraph, and Also in Conducting Written Correspondence, Transmitted by the Mails, or Otherwise"</span>, <span>Thurston, Isley &amp; Company</span>, <time datetime="1845">1845</time>, <span>&lt;<a href="https://books.google.com/books?id=Z45clCxsF7EC">https://books.google.com/books?id=Z45clCxsF7EC</a>&gt;</span>. </dd>
<dd></dd>
<dt id="STRINT">[STRINT]</dt>
      <dd>
<span>W3C</span> and <span>IAB</span>, <span>"A W3C/IAB workshop on Strengthening the Internet Against Pervasive Monitoring (STRINT)"</span>, <time datetime="2014-03">March 2014</time>, <span>&lt;<a href="https://www.w3.org/2014/strint/">https://www.w3.org/2014/strint/</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Timeline">[Timeline]</dt>
      <dd>
<span>Wikipedia</span>, <span>"Global surveillance disclosures (2013-present)"</span>, <time datetime="2023-07">July 2023</time>, <span>&lt;<a href="https://en.wikipedia.org/w/index.php?title=Global_surveillance_disclosures_(2013%E2%80%93present)&amp;oldid=1161557819">https://en.wikipedia.org/w/index.php?title=Global_surveillance_disclosures_(2013%E2%80%93present)&amp;oldid=1161557819</a>&gt;</span>. </dd>
<dd></dd>
<dt id="I-D.ietf-tls-esni">[TLS-ECH]</dt>
      <dd>
<span>Rescorla, E.</span>, <span>Oku, K.</span>, <span>Sullivan, N.</span>, and <span>C. A. Wood</span>, <span>"TLS Encrypted Client Hello"</span>, <span>Work in Progress</span>, <span>Internet-Draft, draft-ietf-tls-esni-16</span>, <time datetime="2023-04-06">6 April 2023</time>, <span>&lt;<a href="https://datatracker.ietf.org/doc/html/draft-ietf-tls-esni-16">https://datatracker.ietf.org/doc/html/draft-ietf-tls-esni-16</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Toronto">[Toronto]</dt>
      <dd>
<span>Memmott, M.</span>, <span>"Canada Used Airport Wi-Fi To Track Travelers, Snowden Leak Alleges"</span>, <span>NPR</span>, <time datetime="2014-01">January 2014</time>, <span>&lt;<a href="https://www.npr.org/sections/thetwo-way/2014/01/31/269418375/airport-wi-fi-used-to-track-travelers-snowden-leak-alleges">https://www.npr.org/sections/thetwo-way/2014/01/31/269418375/airport-wi-fi-used-to-track-travelers-snowden-leak-alleges</a>&gt;</span>. </dd>
<dd></dd>
<dt id="UTA">[UTA]</dt>
      <dd>
<span>IETF</span>, <span>"Using TLS in Applications (uta)"</span>, <span>&lt;<a href="https://datatracker.ietf.org/wg/uta/about">https://datatracker.ietf.org/wg/uta/about</a>&gt;</span>. </dd>
<dd></dd>
<dt id="Zubhoff2019">[Zubhoff2019]</dt>
    <dd>
<span>Zuboff, S.</span>, <span>"The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power"</span>, <span>PublicAffairs</span>, <span>ISBN 9781781256855</span>, <time datetime="2019-01">January 2019</time>. </dd>
<dd></dd>
</dl>
</section>
<section id="acknowledgments">
      <h2 id="name-acknowledgments">
<a href="#name-acknowledgments">Acknowledgments</a>
      </h2>
<p id="appendix-A-1"><span>Susan Landau</span> added many valuable comments to <span>Steve Bellovin</span>'s essay.<a href="#appendix-A-1">¶</a></p>
<p id="appendix-A-2">We thank <span>Carsten Bormann</span>, <span>Brian Carpenter</span>, <span>Wendy Grossman</span>, <span>Kathleen Moriarty</span>,
<span>Jan Schaumann</span>, <span>Seth David Schoen</span>, and <span>Paul Wouters</span> for comments and review of this text, though
that of course doesn't mean that they necessarily agree with the text.<a href="#appendix-A-2">¶</a></p>
<p id="appendix-A-3">This document was created at the behest of <span>Eliot Lear</span>, who also 
cat herded and did some editing.<a href="#appendix-A-3">¶</a></p>
</section>
<section id="authors-addresses">
      <h2 id="name-authors-addresses">
<a href="#name-authors-addresses">Authors' Addresses</a>
      </h2>
<address>
        <p><span>Stephen Farrell</span></p>
<p><span>Trinity College, Dublin</span></p>
<p><span>Ireland</span></p>

</address>
<address>
        <p><span>Farzaneh Badii</span></p>
<p><span>Digital Medusa</span></p>

</address>
<address>
        <p><span>Bruce Schneier</span></p>
<p><span>Harvard University</span></p>
<p><span>United States of America</span></p>

</address>
<address>
        <p><span>Steven M. Bellovin</span></p>
<p><span>Columbia University</span></p>
<p><span>United States of America</span></p>

</address>
</section>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Squeeze the hell out of the system you have (213 pts)]]></title>
            <link>https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/#like-2777</link>
            <guid>37091983</guid>
            <pubDate>Fri, 11 Aug 2023 18:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/#like-2777">https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/#like-2777</a>, See on <a href="https://news.ycombinator.com/item?id=37091983">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2777">
	<div>
			
<p>About a year ago, I raised a red flag with colleagues and managers about Postgres performance. Our database was struggling to keep up with the load generated by our monolithic SaaS application. CPU utilization was riding between 60 and 80%, and at least once it spiked to 100%, causing a brief outage.</p>



<p>Now, we had been kicking the can down the road with respect to Postgres capacity for a long time. When the database looked too busy, we’d replace it with a bigger instance and move on. This saved us a lot of time and allowed us to focus on other things, like building features, which was great.</p>



<p>But this time, it wasn’t possible to scale the DB server vertically: we were already on the biggest instance. And we were about to overload that instance.</p>



<p>Lots of schemes were floated. Foremost among them:</p>



<ul>
<li><strong>Shard writes.</strong> Spin up a cluster of independent databases, and write data to one or the other according to some partitioning strategy.</li>



<li><strong>Do micro-services.</strong> Split up the monolith into multiple interconnected services, each with its own data store that could be scaled on its own terms.</li>
</ul>



<p>Both of these options are cool! A strong case can be made for either one on its merits. With write sharding, we could potentially increase our capacity by 2 or even 3 orders of magnitude. With micro-services, we’d be free to use “the right tool for the job,” picking data stores optimized to the requirements of each service workload. Either branch of the skill tree would offer exciting options for fault tolerance and operational resilience.</p>



<p>Either way, everyone had to agree: we’d outgrown our old, naïve implementation. Onward and upward! We can do hard things!</p>



<p>In situations like this, presented with a dazzling array of next-generation architecture options that can be built to last us through the decade, it’s easy to forget what our goal was: to get database performance under control.</p>



<h2>Complexity costs attention.</h2>



<p>Sometimes, leaps in complexity must be made. It’s generally a good problem to have. If enough demand is being placed on your system to render obsolete your existing technology, then even more growth is probably on the horizon! If you can just put in the investment and build the more advanced architecture now, then you’ll be looking at a bright future of unconstrained year-over-year success.</p>



<p>But don’t just consider the implementation cost. The real cost of increased complexity – often the much larger cost – is attention.</p>



<p>If you decide to shard across databases, then not only must you pay the money-, time-, and opportunity cost of building out the new architecture: <em>you must also take the new complexity into account in every subsequent technical decision</em>. Want to shard writes? Fine, but this complicates every future decision about backups, monitoring, migrations, the ORM, and network topology (just to name a few). And don’t get me started on micro-services.</p>



<p>Just think about how massive these costs are. How much feature delivery will have to be delayed or foregone to support the additional architectural complexity?</p>



<h2>Always squeeze first</h2>



<p>We should always put off significant complexity increases as long as possible.</p>



<p>When complexity leaps are on the table, there’s usually also an opportunity to <strong>squeeze</strong> some extra juice out of the system you have. By tweaking the workload, tuning performance, or supplementing the system in some way, you may be able to add months or even years of runway. When viable, these options are always preferable to building out a next-gen system.</p>



<p>Let’s return to the example of the overloaded Postgres instance. In that case, what we ended up doing was twofold:</p>



<ol>
<li>Two engineers (me and my colleague Ted – but mostly Ted) spent about 3 months working primarily on database performance issues. There was no silver bullet. We used our telemetry to identify heavy queries, dug into the (Rails) codebase to understand where they were coming from, and optimized or eliminated them. We also tuned a lot of Postgres settings.</li>



<li>Two more engineers cut a path through the codebase to run certain expensive read-only queries on a replica DB. This effort bore fruit around the same time as (1), when we offloaded our single most frequent query (a <code>SELECT</code> triggered by polling web clients).</li>
</ol>



<p>These two efforts together reduced the maximum weekly CPU usage on the database from 90% to 30%.</p>



<p>Now we can sleep at night. We have a huge amount of room to grow, both in terms of CPU headroom and our ability to shed load from the primary. And furthermore, since our work touched many parts of the codebase and demanded collaboration with lots of different devs, we now have a strong distributed knowledge base about the existing system. We’re well positioned to squeeze it even more if need be.</p>



<h2>This doesn’t mean complexity is bad</h2>



<p>Of course, I’m not saying complexity is bad. It’s necessary. Some day we’ll reach a fundamental limit of our database architecture, and before that day arrives, we’ll need to make a jump in complexity.</p>



<p>But until then, because we <strong>squeezed first</strong>, we get to keep working with the most boring system possible. This is by far the cheaper and more practical option.</p>
					</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infisical – open-source HashiCorp Vault alternative (167 pts)]]></title>
            <link>https://github.com/Infisical/infisical</link>
            <guid>37090754</guid>
            <pubDate>Fri, 11 Aug 2023 16:44:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Infisical/infisical">https://github.com/Infisical/infisical</a>, See on <a href="https://news.ycombinator.com/item?id=37090754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Infisical/infisical/blob/main/img/logoname-black.svg#gh-light-mode-only"><img width="300" src="https://github.com/Infisical/infisical/raw/main/img/logoname-black.svg#gh-light-mode-only" alt="infisical"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/Infisical/infisical/blob/main/img/logoname-white.svg#gh-dark-mode-only"><img width="300" src="https://github.com/Infisical/infisical/raw/main/img/logoname-white.svg#gh-dark-mode-only" alt="infisical"></a>
</h2>
<p dir="auto"><b>Open-source, end-to-end encrypted secret management platform</b>: distribute secrets/configs across your team/infrastructure and prevent secret leaks.</p>

<h4 tabindex="-1" dir="auto">
  <a href="https://infisical.com/slack" rel="nofollow">Slack</a> |
  <a href="https://infisical.com/" rel="nofollow">Infisical Cloud</a> |
  <a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow">Self-Hosting</a> |
  <a href="https://infisical.com/docs/documentation/getting-started/introduction" rel="nofollow">Docs</a> |
  <a href="https://www.infisical.com/" rel="nofollow">Website</a>
</h4>
<p dir="auto">
  <a href="https://infisical.com/docs/self-hosting/deployment-options/aws-ec2" rel="nofollow">
    <img src="https://github.com/Infisical/infisical/raw/main/.github/images/deploy-to-aws.png" width="137">
  </a>
  <a href="https://infisical.com/docs/self-hosting/deployment-options/digital-ocean-marketplace" alt="Deploy to DigitalOcean" rel="nofollow">
     <img width="200" alt="Deploy to DO" src="https://camo.githubusercontent.com/df21703b4229f8d44f76c2d56073657a4ab450ca4566ba5d24d05bf528c298f8/68747470733a2f2f7777772e6465706c6f79746f646f2e636f6d2f646f2d62746e2d626c75652e737667" data-canonical-src="https://www.deploytodo.com/do-btn-blue.svg">
  </a>
</p>
<h4 tabindex="-1" dir="auto">
  <a href="https://github.com/Infisical/infisical/blob/main/LICENSE">
    <img src="https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667" alt="Infisical is released under the MIT license." data-canonical-src="https://img.shields.io/badge/license-MIT-blue.svg">
  </a>
  <a href="https://github.com/infisical/infisical/blob/main/CONTRIBUTING.md">
    <img src="https://camo.githubusercontent.com/f9c5499f3a5e5a9516b9c40e700535d96426dd0dc32b3f4ba64164d87807ba2a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d57656c636f6d652d627269676874677265656e" alt="PRs welcome!" data-canonical-src="https://img.shields.io/badge/PRs-Welcome-brightgreen">
  </a>
  <a href="https://github.com/Infisical/infisical/issues">
    <img src="https://camo.githubusercontent.com/bbadcfc720476057ff7a528009bffd6245d516f7f6df853244b001deae6d1149/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f696e6669736963616c2f696e6669736963616c" alt="git commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/m/infisical/infisical">
  </a>
  <a href="https://cloudsmith.io/~infisical/repos/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/b990261c2dc971d42e655715009b43ee925f6836e4387cd2dd89cc6bdcdc918f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f776e6c6f6164732d3832312e386b2d6f72616e6765" alt="Cloudsmith downloads" data-canonical-src="https://img.shields.io/badge/Downloads-821.8k-orange">
  </a>
  <a href="https://infisical.com/slack" rel="nofollow">
    <img src="https://camo.githubusercontent.com/7b4b98387d228c64f516f16aed0674b7b9c3a32eb46e12504c51ab2777d6ab76/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230536c61636b2d626c756576696f6c6574" alt="Slack community channel" data-canonical-src="https://img.shields.io/badge/chat-on%20Slack-blueviolet">
  </a>
  <a href="https://twitter.com/infisical" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6ac3a29a944d2e32a8e0b0017a8d0b9365d9c4a32417380a105147165ab8d6b2/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f696e6669736963616c3f6c6162656c3d466f6c6c6f77" alt="Infisical Twitter" data-canonical-src="https://img.shields.io/twitter/follow/infisical?label=Follow">
  </a>
</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Infisical/infisical/blob/main/img/infisical_github_repo.png"><img src="https://github.com/Infisical/infisical/raw/main/img/infisical_github_repo.png" width="100%" alt="Dashboard"></a></p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto"><strong><a href="https://infisical.com/" rel="nofollow">Infisical</a></strong> is an open source, end-to-end encrypted secret management platform that teams use to centralize their secrets like API keys, database credentials, and configurations.</p>
<p dir="auto">We're on a mission to make secret management more accessible to everyone, not just security teams, and that means redesigning the entire developer experience from ground up.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li><strong><a href="https://infisical.com/docs/documentation/platform/project" rel="nofollow">User-friendly dashboard</a></strong> to manage secrets across projects and environments (e.g. development, production, etc.)</li>
<li><strong><a href="https://infisical.com/docs/sdks/overview" rel="nofollow">Client SDKs</a></strong> to fetch secrets for your apps and infrastructure on demand</li>
<li><strong><a href="https://infisical.com/docs/cli/overview" rel="nofollow">Infisical CLI</a></strong> to fetch and inject secrets into any framework in local development</li>
<li><strong><a href="https://infisical.com/docs/integrations/overview" rel="nofollow">Native integrations</a></strong> with platforms like GitHub, Vercel, Netlify, and more</li>
<li><a href="https://infisical.com/docs/documentation/getting-started/kubernetes" rel="nofollow"><strong>Automatic Kubernetes deployment secret reloads</strong></a></li>
<li><strong><a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow">Complete control over your data</a></strong> - host it yourself on any infrastructure</li>
<li><strong><a href="https://infisical.com/docs/documentation/platform/secret-versioning" rel="nofollow">Secret versioning</a></strong> and <strong><a href="https://github.com/Infisical/infisical/blob/main">Point-in-Time Recovery</a></strong> to version every secret and project state</li>
<li><strong><a href="https://infisical.com/docs/documentation/platform/audit-logs" rel="nofollow">Audit logs</a></strong> to record every action taken in a project</li>
<li><strong>Role-based Access Controls</strong> per environment</li>
<li><a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow"><strong>Simple on-premise deployments</strong> to AWS, Digital Ocean, and more</a></li>
<li><a href="https://infisical.com/docs/cli/scanning-overview" rel="nofollow"><strong>Secret Scanning and Leak Prevention</strong></a></li>
</ul>
<p dir="auto">And much more.</p>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">Check out the <a href="https://infisical.com/docs/getting-started/introduction" rel="nofollow">Quickstart Guides</a></p>
<table>
<thead>
<tr>
<th>Use Infisical Cloud</th>
<th>Deploy Infisical on premise</th>
</tr>
</thead>
<tbody>
<tr>
<td>The fastest and most reliable way to <br> get started with Infisical is signing up <br> for free to <a href="https://app.infisical.com/login" rel="nofollow">Infisical Cloud</a>.</td>
<td><a href="https://infisical.com/docs/self-hosting/deployment-options/aws-ec2" rel="nofollow"><img src="https://github.com/Infisical/infisical/raw/main/.github/images/deploy-to-aws.png" width="150"></a> <a href="https://infisical.com/docs/self-hosting/deployment-options/digital-ocean-marketplace" alt="Deploy to DigitalOcean" rel="nofollow"> <img width="217" alt="Deploy to DO" src="https://camo.githubusercontent.com/df21703b4229f8d44f76c2d56073657a4ab450ca4566ba5d24d05bf528c298f8/68747470733a2f2f7777772e6465706c6f79746f646f2e636f6d2f646f2d62746e2d626c75652e737667" data-canonical-src="https://www.deploytodo.com/do-btn-blue.svg"> </a> <br> View all <a href="https://infisical.com/docs/self-hosting/overview" rel="nofollow">deployment options</a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">Run Infisical locally</h3>
<p dir="auto">To set up and run Infisical locally, make sure you have Git and Docker installed on your system. Then run the command for your system:</p>
<p dir="auto">Linux/macOS:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Infisical/infisical &amp;&amp; cd &quot;$(basename $_ .git)&quot; &amp;&amp; cp .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up"><pre><span>git clone https://github.com/Infisical/infisical &amp;&amp; cd "$(basename $_ .git)" &amp;&amp; cp .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up</span></pre></div>
<p dir="auto">Windows Command Prompt:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Infisical/infisical &amp;&amp; cd infisical &amp;&amp; copy .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up"><pre><span>git clone https://github.com/Infisical/infisical &amp;&amp; cd infisical &amp;&amp; copy .env.example .env &amp;&amp; docker-compose -f docker-compose.yml up</span></pre></div>
<p dir="auto">Create an account at <code>http://localhost:80</code></p>
<h3 tabindex="-1" dir="auto">Scan and prevent secret leaks</h3>
<p dir="auto">On top managing secrets with Infisical, you can also <a href="https://github.com/Infisical/infisical/blob/main">scan for over 140+ secret types</a> in your files, directories and git repositories.</p>
<p dir="auto">To scan your full git history, run:</p>

<p dir="auto">Install pre commit hook to scan each commit before you push to your repository</p>
<div data-snippet-clipboard-copy-content="infisical scan install --pre-commit-hook"><pre><code>infisical scan install --pre-commit-hook
</code></pre></div>
<p dir="auto">Lean about Infisical's code scanning feature <a href="https://infisical.com/docs/cli/scanning-overview" rel="nofollow">here</a></p>
<h2 tabindex="-1" dir="auto">Open-source vs. paid</h2>
<p dir="auto">This repo available under the <a href="https://github.com/Infisical/infisical/blob/main/LICENSE">MIT expat license</a>, with the exception of the <code>ee</code> directory which will contain premium enterprise features requiring a Infisical license.</p>
<p dir="auto">If you are interested in managed Infisical Cloud of self-hosted Enterprise Offering, take a look at <a href="https://infisical.com/" rel="nofollow">our webiste</a> or <a href="https://cal.com/vmatsiiako/infisical-demo" rel="nofollow">book a meeting with us</a>:</p>
<p dir="auto"><a href="https://cal.com/vmatsiiako/infisical-demo" rel="nofollow"><img alt="Schedule a meeting" src="https://camo.githubusercontent.com/6bea259f3d52a136dc4c575ef7f30191ca3b508688c170e6a4363410324fce05/68747470733a2f2f63616c2e636f6d2f626f6f6b2d776974682d63616c2d6461726b2e737667" data-canonical-src="https://cal.com/book-with-cal-dark.svg"></a></p>
<h2 tabindex="-1" dir="auto">Security</h2>
<p dir="auto">Please do not file GitHub issues or post on our public forum for security vulnerabilities, as they are public!</p>
<p dir="auto">Infisical takes security issues very seriously. If you have any concerns about Infisical or believe you have uncovered a vulnerability, please get in touch via the e-mail address <a href="mailto:security@infisical.com">security@infisical.com</a>. In the message, try to provide a description of the issue and ideally a way of reproducing it. The security team will get back to you as soon as possible.</p>
<p dir="auto">Note that this security address should be used only for undisclosed vulnerabilities. Please report any security problems to us before disclosing it publicly.</p>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">Whether it's big or small, we love contributions. Check out our guide to see how to <a href="https://infisical.com/docs/contributing/overview" rel="nofollow">get started</a>.</p>
<p dir="auto">Not sure where to get started? You can:</p>
<ul dir="auto">
<li><a href="https://cal.com/tony-infisical/30-min-meeting-contributing" rel="nofollow">Book a free, non-pressure pairing session / code walkthrough with one of our teammates</a>!</li>
<li>Join our <a href="https://infisical.com/slack" rel="nofollow">Slack</a>, and ask us any questions there.</li>
<li>Join our <a href="https://us06web.zoom.us/j/82623506356" rel="nofollow">community calls</a> every Wednesday at 11am EST to ask any questions, provide feedback, hangout and more.</li>
</ul>
<h2 tabindex="-1" dir="auto">Resources</h2>
<ul dir="auto">
<li><a href="https://infisical.com/docs/documentation/getting-started/introduction" rel="nofollow">Docs</a> for comprehensive documentation and guides</li>
<li><a href="https://infisical.com/slack" rel="nofollow">Slack</a> for discussion with the community and Infisical team.</li>
<li><a href="https://github.com/Infisical/infisical">GitHub</a> for code, issues, and pull requests</li>
<li><a href="https://twitter.com/infisical" rel="nofollow">Twitter</a> for fast news</li>
<li><a href="https://www.youtube.com/@infisical_os" rel="nofollow">YouTube</a> for videos on secret management</li>
<li><a href="https://infisical.com/blog" rel="nofollow">Blog</a> for secret management insights, articles, tutorials, and updates</li>
<li><a href="https://www.notion.so/infisical/be2d2585a6694e40889b03aef96ea36b?v=5b19a8127d1a4060b54769567a8785fa" rel="nofollow">Roadmap</a> for planned features</li>
</ul>
<h2 tabindex="-1" dir="auto">Acknowledgements</h2>



<p dir="auto"><a href="https://github.com/dangtony98"><img src="https://avatars.githubusercontent.com/u/25857006?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/maidul98"><img src="https://avatars.githubusercontent.com/u/9300960?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/akhilmhdh"><img src="https://avatars.githubusercontent.com/u/31166322?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/reginaldbondoc"><img src="https://avatars.githubusercontent.com/u/7693108?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/mv-turtle"><img src="https://avatars.githubusercontent.com/u/78047717?s=96&amp;v=4" width="50" height="50" alt=""></a> <a href="https://github.com/gangjun06"><img src="https://avatars.githubusercontent.com/u/50910815?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/asheliahut"><img src="https://avatars.githubusercontent.com/u/945619?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/SH5H"><img src="https://avatars.githubusercontent.com/u/25437192?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/gmgale"><img src="https://avatars.githubusercontent.com/u/62303146?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/asharonbaltazar"><img src="https://avatars.githubusercontent.com/u/58940073?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/JoaoVictor6"><img src="https://avatars.githubusercontent.com/u/68869379?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/mocherfaoui"><img src="https://avatars.githubusercontent.com/u/37941426?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/cerrussell"><img src="https://avatars.githubusercontent.com/u/80227828?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/jon4hz"><img src="https://avatars.githubusercontent.com/u/26183582?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/edgarrmondragon"><img src="https://avatars.githubusercontent.com/u/16805946?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/arjunyel"><img src="https://avatars.githubusercontent.com/u/11153289?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/LemmyMwaura"><img src="https://avatars.githubusercontent.com/u/20738858?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Zamion101"><img src="https://avatars.githubusercontent.com/u/8071263?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Grraahaam"><img src="https://avatars.githubusercontent.com/u/72856427?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Neeraj138"><img src="https://avatars.githubusercontent.com/u/58552561?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/esau-morais"><img src="https://avatars.githubusercontent.com/u/55207584?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/animeshdas2000"><img src="https://avatars.githubusercontent.com/u/40542456?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/umrak11"><img src="https://avatars.githubusercontent.com/u/20104948?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/KunalSin9h"><img src="https://avatars.githubusercontent.com/u/82411321?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/ImBIOS"><img src="https://avatars.githubusercontent.com/u/41441643?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/sanyamjain04"><img src="https://avatars.githubusercontent.com/u/107163858?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Gabriellopes232"><img src="https://avatars.githubusercontent.com/u/74881862?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/naorpeled"><img src="https://avatars.githubusercontent.com/u/6171622?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Aashish-Upadhyay-101"><img src="https://avatars.githubusercontent.com/u/81024263?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/jonerrr"><img src="https://avatars.githubusercontent.com/u/73760377?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/kmlgkcy"><img src="https://avatars.githubusercontent.com/u/102428035?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/samsbg"><img src="https://avatars.githubusercontent.com/u/70488844?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/imakecodes"><img src="https://avatars.githubusercontent.com/u/35536648?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/bngmnn"><img src="https://avatars.githubusercontent.com/u/88746983?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/kimcore"><img src="https://avatars.githubusercontent.com/u/36142378?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/caioluis"><img src="https://avatars.githubusercontent.com/u/30005368?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/alisson-acioli"><img src="https://avatars.githubusercontent.com/u/12742051?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/adrianmarinwork"><img src="https://avatars.githubusercontent.com/u/118568289?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/arthurzenika"><img src="https://avatars.githubusercontent.com/u/445200?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/franky47"><img src="https://avatars.githubusercontent.com/u/1174092?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/hanywang2"><img src="https://avatars.githubusercontent.com/u/44352119?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/tobias-mintlify"><img src="https://avatars.githubusercontent.com/u/110702161?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/wjhurley"><img src="https://avatars.githubusercontent.com/u/15939055?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/alexdanilowicz"><img src="https://avatars.githubusercontent.com/u/29822597?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/0xflotus"><img src="https://avatars.githubusercontent.com/u/26602940?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/wanjohiryan"><img src="https://avatars.githubusercontent.com/u/71614375?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/nirga"><img src="https://avatars.githubusercontent.com/u/4224692?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/RashidUjang"><img src="https://avatars.githubusercontent.com/u/11313829?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/kanhaiya38"><img src="https://avatars.githubusercontent.com/u/54778773?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/HasanMansoor4"><img src="https://avatars.githubusercontent.com/u/68682354?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/jerriclynsjohn"><img src="https://avatars.githubusercontent.com/u/3236669?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/eltociear"><img src="https://avatars.githubusercontent.com/u/22633385?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/MatthewJohn"><img src="https://avatars.githubusercontent.com/u/1266262?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/sheensantoscapadngan"><img src="https://avatars.githubusercontent.com/u/65645666?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/yoobato"><img src="https://avatars.githubusercontent.com/u/1592319?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/xinity"><img src="https://avatars.githubusercontent.com/u/1799009?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/simonemargio"><img src="https://avatars.githubusercontent.com/u/22590804?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/Aqib-Rime"><img src="https://avatars.githubusercontent.com/u/116422706?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/ha-sante"><img src="https://avatars.githubusercontent.com/u/90225652?v=4" width="50" height="50" alt=""></a> <a href="https://github.com/5h4k4r"><img src="https://avatars.githubusercontent.com/u/56171149?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/quinton11"><img src="https://avatars.githubusercontent.com/u/70300837?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/afrieirham"><img src="https://avatars.githubusercontent.com/u/32460534?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/Stijn-Kuijper"><img src="https://avatars.githubusercontent.com/u/25306980?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/atimapreandrew"><img src="https://avatars.githubusercontent.com/u/60506711?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/satyamgupta1495"><img src="https://avatars.githubusercontent.com/u/51158766?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/RezaRahemtola"><img src="https://avatars.githubusercontent.com/u/49811529?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/JunedKhan101"><img src="https://avatars.githubusercontent.com/u/47941768?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/unkletayo"><img src="https://avatars.githubusercontent.com/u/48031746?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/agoodman1999"><img src="https://avatars.githubusercontent.com/u/113685729?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/Spelchure"><img src="https://avatars.githubusercontent.com/u/20704539?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/piyushchhabra"><img src="https://avatars.githubusercontent.com/u/12864227?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/PylotLight"><img src="https://avatars.githubusercontent.com/u/7006124?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/jorgeteixe"><img src="https://avatars.githubusercontent.com/u/45232371?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/chisom5"><img src="https://avatars.githubusercontent.com/u/22566806?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/zwkee"><img src="https://avatars.githubusercontent.com/u/109659187?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/raykeating"><img src="https://avatars.githubusercontent.com/u/29098307?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/khoa165"><img src="https://avatars.githubusercontent.com/u/46258781?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/pgaijin66"><img src="https://avatars.githubusercontent.com/u/8869096?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/Budhathoki356"><img src="https://avatars.githubusercontent.com/u/53488484?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/mswider"><img src="https://avatars.githubusercontent.com/u/37093293?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/parthvnp"><img src="https://avatars.githubusercontent.com/u/41171860?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/seonggwonyoon"><img src="https://avatars.githubusercontent.com/u/37574822?v=4" width="50" height="50" alt=""></a>
<a href="https://github.com/ChukwunonsoFrank"><img src="https://avatars.githubusercontent.com/u/62689166?v=4" width="50" height="50" alt=""></a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine-Tuning Llama-2: A Comprehensive Case Study for Tailoring Custom Models (174 pts)]]></title>
            <link>https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications</link>
            <guid>37090632</guid>
            <pubDate>Fri, 11 Aug 2023 16:34:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications">https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications</a>, See on <a href="https://news.ycombinator.com/item?id=37090632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><i>In this blog, we provide a thorough analysis and a practical guide for fine-tuning. We examine the Llama-2 models under three real-world use cases, and show that fine-tuning yields significant accuracy improvements across the board (in some niche cases, better than GPT-4). Experiments were carried out with this </i><a href="https://github.com/ray-project/ray/tree/master/doc/source/templates/04_finetuning_llms_with_deepspeed"><i><u>script</u></i></a><i>.</i></p><p>Large open language models have made significant progress in recent months, paving the way for commercially viable solutions that are suitable for enterprise applications. Notable among these are the Llama-2 and Falcon models. While powerful generalist language models like GPT-4 and Claude-2 provide quick access and rapid turnaround for projects, they often end up being an overkill for the requirements of many applications.</p><p>As an example, if the goal is to summarize support tickets and categorize issues into predetermined buckets, there's no need for a model capable of generating prose in the style of Shakespeare. Setting security concerns aside, employing GPT-4 for such tasks is akin to using a space shuttle for a cross-town commute. To support this claim, we study fine-tuning the Llama-2 model of various sizes on three tasks:&nbsp;</p><ul><li><p>Functional representations extracted from unstructured text (<a href="https://huggingface.co/datasets/GEM/viggo"><u>ViGGO</u></a>)</p></li><li><p>SQL generation (<a href="https://huggingface.co/datasets/b-mc2/sql-create-context"><u>SQL-create-context</u></a>)</p></li><li><p>Grade-school math question-answering (<a href="https://huggingface.co/datasets/gsm8k"><u>GSM8k</u></a>)</p></li></ul><p>We specifically show how on some tasks (e.g. SQL Gen or Functional Representation) we can fine-tune small Llama-2 models to become even better than GPT-4. At the same time, there are tasks like math reasoning and understanding that OSS models are just behind even after significant gains obtained by fine-tuning.</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/6jANVvQ0XG2OBFaJ82A4Rb/530191ff406a0bfae0aac04907348e97/Llama_2_models_performance_chart.png" alt="Llama 2 performance"></p></div><p><i>The performance gain of Llama-2 models obtained via fine-tuning on each task. The darker shade for each of the colors indicate the performance of the Llama-2-chat models with a baseline prompt. The purple shows the performance of GPT-4 with the same prompt. The stacked bar plots show the performance gain from fine-tuning the Llama-2 base models. In Functional representation and SQL gen tasks with fine-tuning we can achieve better performance than GPT-4 while on some other task like math reasoning, fine-tuned models, while improving over the base models, are still not able to reach GPT-4’s performance levels.</i></p><p>In particular we show that with the Llama-13b variant we observed an increase in accuracy from, 58% to 98% on functional representations, 42% to 89% on SQL generation, and 28% to 47% on GSM. All of these experiments are done using Anyscale fine-tuning and serving platforms as offered as part of <a href="https://app.endpoints.anyscale.com/"><u>Anyscale Endpoints</u></a>.&nbsp;</p><p>In addition to providing more quantitative results, this blog post will present a technical deep-dive into how you can leverage Llama-2 models for specialized tasks. We will discuss the correct problem formulation, the setup of evaluation pipelines, and much more. We will compare methods such as prompt-engineering &amp; few-shot prompting with fine-tuning, providing concrete pros and cons of each method along the way.</p><p>Fine-tuning these models is not a straightforward task. However, <a href="http://github.com/ray-project/ray"><u>Ray</u></a> and <a href="https://anyscale.com/"><u>Anyscale</u></a> offer unique capabilities that make this process faster, cheaper, and more manageable. Our mission is to enable enterprises to harness the latest advancements in AI as swiftly as possible.</p><p>We hope that the details covered in this post can help others elicit more value from their LLMs through an emphasis on data quality and evaluation procedures.&nbsp;</p><h2>Fine-Tuning Basics</h2><p>For all three tasks, we use standard full parameter fine-tuning techniques. Models are fine-tuned for next-token prediction, and all parameters in the model are subject to gradient updates. While there certainly are other techniques to train LLMs, such as freezing select transformer blocks and LoRA, to keep a narrow scope we keep the training technique itself constant from task to task.&nbsp;</p><p>Performing full parameter fine-tuning on models of this scale is no easy task. However, our lives can be made easier if we use the right combination of libraries. The script we used to produce the results in this blog post can be found <a href="https://github.com/ray-project/ray/tree/workspace_templates_2.6.1/doc/source/templates/04_finetuning_llms_with_deepspeed"><u>here</u></a>. Built on top of <a href="https://docs.ray.io/en/latest/train/train.html"><u>Ray Train</u></a>, <a href="https://github.com/microsoft/DeepSpeed"><u>Deepspeed</u></a>, and <a href="https://github.com/huggingface/accelerate"><u>Accelerate</u></a>, this script allows you to easily run any of the Llama-2 7B, 13B, or 70B models. We will go over a couple high-level details about the script in the following subsections, but we suggest you checkout the script itself for details on how to run it.&nbsp;&nbsp;</p><h3>General Training Flow</h3><p>Training these large scale models is very difficult without scaling your workload across multiple nodes. Our script centers around a singular training function in which gradient updates on the model actually occur:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span></code><span><span>def</span><span> </span><span>training_function</span><span>(</span><span>kwargs: </span><span>dict</span><span>):</span><span>
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>print</span><span>(</span><span>"training_function called"</span><span>)
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;…
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> epoch </span><span>in</span><span> </span><span>range</span><span>(num_epochs):
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.train()
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…
</span><span>
</span></code></pre></div><p>The key here is that this training function is run on each of the individual worker processes, possibly distributed across multiple machines. Within Ray Train, we use the <a href="https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html"><u>TorchTrainer</u></a> class which acts as a process dispatcher and scales this&nbsp; training loop across our cluster. We can let TorchTrainer know how many worker processes we want to use and how many resources would each process need:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code><span><span>scaling_config=air.ScalingConfig(
</span></span><span>&nbsp;&nbsp;&nbsp;...
</span><span>&nbsp;&nbsp;&nbsp;num_workers=args.num_devices,
</span><span><span>&nbsp;&nbsp;&nbsp;use_gpu=</span><span>True</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;resources_per_worker={</span><span>"GPU"</span><span>: </span><span>1</span><span>},
</span></span><span>),
</span><span>
</span></code></pre></div><p>From here, the main challenge is figuring out how to split the work across our individual training functions. Intuitively, there are two ways to "split"  the work when training a model: one could shard the model, gradients, and optimizer states across workers, and also shard the data across them. On the data side, Ray Train helps us manage the data ingestion and dataset sharding across the training loops. At the top of training loop, a worker can access the shard of the dataset delegated to it via:</p><div><pre><code><code><span>1
</span><span>2
</span></code><span><span>train_ds = session.get_dataset_shard(</span><span>"train"</span><span>)
</span></span><span><span>valid_ds = session.get_dataset_shard(</span><span>"valid"</span><span>)
</span></span><span>
</span></code></pre></div><p>Model sharding is done through DeepSpeed. DeepSpeed defines a strategy for how to split the model across nodes and when to offload compute and memory from GPU to CPU (we use ZeRO stage 3 with optimizer state offloading). Note that because different chunks of the model are delegated to different workers, if we want to access the model in its entirety on any one node (for example, if we want to checkpoint it), we would need to “unwrap” the model:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code><span><span>unwrapped_model = accelerator.unwrap_model(model)
</span></span><span>unwrapped_model.save_pretrained(
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;ckpt_path_epoch,
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;is_main_process=accelerator.is_main_process,
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;save_function=accelerator.save,
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;safe_serialization=</span><span>True</span><span>,
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;state_dict=accelerator.get_state_dict(model),
</span><span>)
</span><span>
</span></code></pre></div><h3>Special Tokens</h3><p>To perform fine-tuning effectively,&nbsp; data needs to be structured appropriately. Rather than having to prompt a task by describing it as instructions to the LLM, we can simply encode this in plain text by utilizing “special tokens”:</p><p>Before:</p><div><pre><code><code><span>1
</span><span>2
</span></code><span><span>{</span><span>"text"</span><span>: </span><span>"You are to solve the following math question. Please write 
</span></span><span><span>out your reasoning ... etc ... {question}\n{answer}"</span><span>}
</span></span><span>
</span></code></pre></div><p>After:</p><div><pre><code><code><span>1
</span></code><span><span>{</span><span>"text"</span><span>: </span><span>"&lt;START_Q&gt;{question}&lt;END_Q&gt;&lt;START_A&gt;{answer}&lt;END_A&gt;}
</span></span><span>
</span></code></pre></div><p>The special tokens allow us to easily encode the structure of our task, as well as providing a signal for when a model should stop producing output. With the example above, we can define “&lt;END_A&gt;” to be the stopping token. This will guarantee that the model will stop producing output when it is done with the task as opposed to waiting for it to output an end-of-sentence token.&nbsp;</p><p>The Llama tokenizer by default outputs 32000 unique token IDs. After adding the four special tokens above to the tokenizer, it will instead output 32004 unique IDs – “&lt;START_Q&gt;” will have an ID of 32000, “&lt;END_Q&gt;” will have an ID of 32001, and so forth. In our script, these special tokens are added like so:&nbsp;</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code><span><span>tokenizer = AutoTokenizer.from_pretrained(pretrained_path, ...)
</span></span><span><span>tokenizer.add_tokens(special_tokens, special_tokens=</span><span>True</span><span>)
</span></span><span><span></span><span># this will make new learnable parameters for specialized tokens</span><span>
</span></span><span><span>model.resize_token_embeddings(</span><span>len</span><span>(tokenizer))
</span></span><span>
</span></code></pre></div><h3>Compute Details</h3><p>For the 7B and 13B models, we used 16xA10Gs, and for the 70B model, we used 32xA10Gs (across 4x g5.48xlarge instances). When using Ray, there's no need to secure A100s to perform full-parameter fine-tuning on these models! The process is simply repeated for each task. Figures below show an example run based on a context length of 512, with a total of 3.7M effective tokens per epoch on GSM8k dataset.&nbsp;</p><p>We ran the training for a maximum of 10 epochs and selected the best checkpoint according to the minimum perplexity score on the validation set.</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1NHkYacCqQEDmHOx3fGJyt/f86fc3eff57937c027ae17f45bee2b9a/Llama_2_learning_curve.png" alt="Llama 2 learning curve"></p></div><p><i>The learning curves obtained from a full-parameter fine-tuning Llama-2 model of different sizes. From these plots you can clearly see when the training starts to overfit the data. Perplexity graphs are good indicators of when to stop the training.&nbsp;</i></p><h2>Functional Representation of Unstructured Text (ViGGO)</h2><p>The first task we examine is based on the <a href="https://huggingface.co/datasets/GEM/viggo"><u>ViGGO</u></a> dataset. It is an English data-to-text generation dataset with the data centering around video game opinions. The original task involves converting a “functional representation” (a set of attribute-values) into coherent text that incorporates those attributes. However, we will reverse this task: transforming unstructured text into a structured and parsable “functional representation”. This representation condenses the information present in the text and can be used for indexing and other downstream applications. While the domain is just video games, this general problem is one that many enterprises are keen to solve.&nbsp;</p><h3>Example Data Point</h3><p>Let's examine an example from this task to understand the level of difficulty it can present for an LLM:</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1Lu1XYpXDyFy6YjHxnBw8r/6b7a7f867a0ee0347fe8d519e63467d7/Text_and_Representation_Table.png" alt="Text and Representation Table"></p></div><p>Given a target sentence the model has to construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values. This function should describe the target string accurately and must be one of the following:</p><div><pre><code><code><span>1
</span><span>2
</span></code><span><span>[</span><span>'inform</span><span>', </span><span>'request</span><span>', </span><span>'give_opinion</span><span>', </span><span>'confirm</span><span>', </span><span>'verify_attribute</span><span>',
</span></span><span><span> </span><span>'suggest</span><span>', </span><span>'request_explanation</span><span>', </span><span>'recommend</span><span>', </span><span>'request_attribute</span><span>']
</span></span><span>
</span></code></pre></div><p>The attributes must be one of the following:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span></code><span><span>[</span><span>'name</span><span>', </span><span>'release_year</span><span>', </span><span>'esrb</span><span>', </span><span>'genres</span><span>', </span><span>'platforms</span><span>', </span><span>'available_on_steam</span><span>',
</span></span><span><span></span><span>'has_linux_release</span><span>', </span><span>'has_mac_release</span><span>', </span><span>'specifier</span><span>', </span><span>'rating</span><span>', </span><span>'player_perspective</span><span>',
</span></span><span><span></span><span>'has_multiplayer</span><span>', </span><span>'developer</span><span>', </span><span>'exp_release_date</span><span>']
</span></span><span>
</span></code></pre></div><p>Let's prompt a few models to see if they can get anywhere close to our intention. Here is the prompt we used:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span><span>66
</span><span>67
</span><span>68
</span><span>69
</span><span>70
</span><span>71
</span><span>72
</span></code><span><span>Given a target sentence construct the underlying meaning representation
</span></span><span>of the input sentence as a single function with attributes and attribute
</span><span>values. This function should describe the target string accurately and the
</span><span><span>function must be one of the following [</span><span>'inform</span><span>', </span><span>'request</span><span>', </span><span>'give_opinion</span><span>',
</span></span><span><span></span><span>'confirm</span><span>', </span><span>'verify_attribute</span><span>', </span><span>'suggest</span><span>', </span><span>'request_explanation</span><span>',
</span></span><span><span></span><span>'recommend</span><span>', </span><span>'request_attribute</span><span>'] .
</span></span><span>
</span><span>The attributes must be one of the following:
</span><span><span>[</span><span>'name</span><span>', </span><span>'exp_release_date</span><span>', </span><span>'release_year</span><span>', </span><span>'developer</span><span>', </span><span>'esrb</span><span>', </span><span>'rating</span><span>',
</span></span><span><span></span><span>'genres</span><span>', </span><span>'player_perspective</span><span>', </span><span>'has_multiplayer</span><span>', </span><span>'platforms</span><span>',
</span></span><span><span></span><span>'available_on_steam</span><span>', </span><span>'has_linux_release</span><span>', </span><span>'has_mac_release</span><span>', </span><span>'specifier</span><span>']
</span></span><span>The order your list the attributes within the function must follow the
</span><span><span>order listed above. For example the </span><span>'name</span><span>' attribute must always come 
</span></span><span><span>before the </span><span>'exp_release_date</span><span>' attribute, and so forth.
</span></span><span>
</span><span>For each attribute, fill in the corresponding value of the attribute 
</span><span>within brackets. A couple of examples are below. Note: you are to output
</span><span><span>the string after </span><span>"Output: "</span><span>. Do not include </span><span>"Output: "</span><span> in your answer.
</span></span><span>
</span><span><span>Example </span><span>1</span><span>)
</span></span><span><span>Sentence: Dirt: Showdown from </span><span>2012</span><span> is a sport racing game for the
</span></span><span><span>PlayStation, Xbox, PC rated E </span><span>10</span><span>+ (</span><span>for</span><span> Everyone </span><span>10</span><span> and Older). 
</span></span><span><span>It</span><span>'s</span><span> not available on Steam, Linux, or Mac.
</span></span><span><span>Output: inform(</span><span>name</span><span>[</span><span>Dirt:</span><span> Showdown], release_year[</span><span>2012</span><span>], 
</span></span><span><span>esrb[</span><span>E</span><span> </span><span>10</span><span>+ (</span><span>for</span><span> Everyone </span><span>10</span><span> and Older)], genres[</span><span>driving/racing</span><span>, sport],
</span></span><span><span>platforms[</span><span>PlayStation</span><span>, Xbox, PC], available_on_steam[</span><span>no</span><span>], 
</span></span><span><span>has_linux_release[</span><span>no</span><span>], has_mac_release[</span><span>no</span><span>])
</span></span><span>
</span><span><span>Example </span><span>2</span><span>)&nbsp;
</span></span><span><span>Sentence: Were there even any terrible games in </span><span>2014</span><span>?
</span></span><span><span>Output: request(</span><span>release_year</span><span>[</span><span>2014</span><span>], specifier[</span><span>terrible</span><span>])
</span></span><span>
</span><span><span>Example </span><span>3</span><span>)
</span></span><span>Sentence: Adventure games that combine platforming and puzzles 
</span><span>can be frustrating to play, but the side view perspective is 
</span><span><span>perfect for them. That</span><span>'s</span><span> why I enjoyed playing Little Nightmares.
</span></span><span><span>Output: give_opinion(</span><span>name</span><span>[</span><span>Little</span><span> Nightmares], rating[</span><span>good</span><span>],
</span></span><span><span>genres[</span><span>adventure</span><span>, platformer, puzzle], player_perspective[</span><span>side</span><span> view])
</span></span><span>
</span><span><span>Example </span><span>4</span><span>)
</span></span><span><span>Sentence: Since we</span><span>'re</span><span> on the subject of games developed by Telltale 
</span></span><span><span>Games, I</span><span>'m</span><span> wondering, have you played The Wolf Among Us?
</span></span><span><span>Output: recommend(</span><span>name</span><span>[</span><span>The</span><span> Wolf Among Us], developer[</span><span>Telltale</span><span> Games])
</span></span><span>
</span><span><span>Example </span><span>5</span><span>)&nbsp;
</span></span><span>Sentence: Layers of Fear, the indie first person point-and-click adventure game?
</span><span><span>Output: confirm(</span><span>name</span><span>[</span><span>Layers</span><span> of Fear], genres[</span><span>adventure</span><span>, indie,
</span></span><span><span>point-and-click], player_perspective[</span><span>first</span><span> person])	
</span></span><span>
</span><span><span>Example </span><span>6</span><span>)&nbsp;
</span></span><span>Sentence: I bet you like it when you can play games on Steam, like 
</span><span>Worms: Reloaded, right?	
</span><span><span>Output: suggest(</span><span>name</span><span>[</span><span>Worms:</span><span> Reloaded], available_on_steam[</span><span>yes</span><span>])
</span></span><span>
</span><span><span>Example </span><span>7</span><span>)
</span></span><span>Sentence: I recall you saying that you really enjoyed The Legend 
</span><span>of Zelda: Ocarina of Time. Are you typically a big fan of games
</span><span><span>on Nintendo rated E (</span><span>for</span><span> Everyone)?	
</span></span><span><span>Output: verify_attribute(</span><span>name</span><span>[</span><span>The</span><span> Legend of Zelda: Ocarina of Time],
</span></span><span><span>esrb[</span><span>E</span><span> (</span><span>for</span><span> Everyone)], rating[</span><span>excellent</span><span>], platforms[</span><span>Nintendo</span><span>])
</span></span><span>
</span><span><span>Example </span><span>8</span><span>)
</span></span><span><span>Sentence: So what is it about the games that were released in </span><span>2005</span><span> 
</span></span><span>that you find so excellent?	
</span><span><span>Output: request_explanation(</span><span>release_year</span><span>[</span><span>2005</span><span>], rating[</span><span>excellent</span><span>])
</span></span><span>
</span><span><span>Example </span><span>9</span><span>)
</span></span><span>Sentence: Do you think Mac is a better gaming platform than others?
</span><span><span>Output: request_attribute(</span><span>has_mac_release</span><span>[])
</span></span><span>
</span><span>Give the output for the following sentence:
</span><span>{input}
</span><span>
</span></code></pre></div><p><b>Input Query:</b> What's a really fast-paced game with multiplayer that you like to play?&nbsp;</p><p><b>Expected Output:</b> request(has_multiplayer[yes], specifier[fast-paced])</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/jJUBXq14oK7euDi1EnP0g/4ce0cac85dd079e70d1e3b0412090f90/Llama_2_models.png" alt="Llama 2 Models"></p></div><p>As observed, these models do not align well with our intended output. This particular task is not one that can be easily accomplished through prompt-engineering alone. Also notice the length of the input context being passed in for these models – this large input makes inference time for producing an output significantly longer than the input text itself. With all this in mind, we are interested in exploring how far we can push the limits of fine-tuning on this task.</p><h3>Why Might Fine-Tuning Be Promising?</h3><p>In one of our previous blog posts, we discussed the idea that "<a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts"><u>fine-tuning is for form, not facts</u></a>". So, does it make sense to expect fine-tuned models to outperform other methods such as prompt engineering or few-shot prompting on this particular task?</p><p>The answer to this question isn't straightforward and requires experimentation. However, there are a couple of key insightful questions that can guide you in formulating a hypothesis on whether fine-tuning could add substantial value for your specific use case:</p><ol><li><p><b>New Concepts:</b> Can we assume that the base model has encountered the concepts within this task (concepts related to video games, etc)&nbsp; in its pre-training data, or is this an entirely new concept? If it is a completely new concept (or fact), the chances of the model learning it through small-scale fine-tuning are quite low.</p></li><li><p><b>Promising few-shot:</b> Do you observe improvements when you employ few-shot prompting? This technique involves showing the model a few examples of inputs and outputs, then asking it to complete the answer following the same pattern. If you notice significant improvements, fine-tuning could potentially offer even better results. This is because fine-tuning allows you to incorporate far more examples into the model's internal neural network weights, rather than being constrained by context length and consuming tokens for the prompt prefix.</p></li><li><p><b>Token budget:</b> Even if prompt-engineering is working for you, you must provide the usually lengthy prompts as input for <b>every</b> request. This approach can quickly consume your token budget. In the long run, it might be more cost-effective to fine-tune a niche model specifically for that task, thereby saving money.</p></li></ol><p>This particular task revolves around pattern recognition, necessitating a basic grasp of language and underlying concepts but not demanding intricate logical reasoning.&nbsp; More importantly, this task is grounded, meaning all required "facts" for its output are already embedded in the input. It is&nbsp; evident that a lengthier input prompt incorporating examples aids the model's comprehension of our intent, and that's a good indicator that even fine-tuning smaller Llama-2 models could significantly enhance performance in addressing this task.</p><h3>Evaluation</h3><p>Evaluating this task can be done from a few angles. While this task is deterministic enough to warrant checking for an exact character match, this would not be a fair metric for the non-fine-tuned models. Instead, we first check if the output function is predicted correctly. From there, we also check if the attribute types are correct. The attribute types within the function follow a strict precedence and so we check that the model output adheres to this ordering. This is mentioned in the prompt for instruction-following models (i.e. GPT, llama-2-chat), so these models are expected to output attributes following this rule. This is a hard guideline to pick up from just a few examples and the model has to pay attention to the specific rule and understand the meaning behind it.&nbsp;</p><p>To speed up evaluation, we utilized Ray's <a href="https://docs.ray.io/en/latest/data/batch_inference.html">batch inference API</a> for scaling up inference in conjunction with Anyscale's <a href="https://github.com/ray-project/aviary">Aviary</a> for serving our customized LLMs. Utilizing these two components allowed us to chain LLM generation with postprocessing and distribute it across many machines. Investing time in a robust evaluation framework is extremely important, as it forms the foundation of any model development process.</p><h3>Results</h3><div><p><img src="https://images.ctfassets.net/xjan103pcp94/4iu1UgY7SBuPiuEYgPa7gr/1eac9c5dec1fe63bfe8e18b8194d7faf/Viggo_dataset.png" alt="Viggo Dataset"></p></div><p><i>Dark colors present chat model performance using the mentioned prompt. For GPT-4, we report both evaluations numbers: with and without attribute order importance. Fine-tuned models consistently achieve &gt;90% success rate in both evaluations methods, never diverging from the precedence rule.</i></p><p>Both the 7b and 13b models significantly improve in accuracy with fine-tuning. While GPT-4’s accuracy significantly drops when attribute precedence is considered, the outputs of the fine-tuned models always follow precedence and accuracy remains unchanged with this added evaluation constraint.</p><h3>Takeaways</h3><p>The ViGGO dataset highlights the strongest aspects of fine-tuning, and the results clearly back it up. When requiring structured form, fine-tuning can provide reliable and efficient means to accomplish your task. This task also shows that requiring a “structured form” does not just mean matching a simple regex or JSON format, tasks that perhaps can be accomplished with libraries like <a href="https://github.com/microsoft/guidance"><u>guidance</u></a>. With ViGGO, an LLM needs to determine whether an argument should be included or not, as well as ensuring that the order of the included arguments follows precedence.&nbsp;</p><p>There is also the argument of efficiency. Besides the fact that significantly more input tokens were required for the general models, the fine-tuned results were achieved with only the 7b &amp; 13b models. Serving a Llama 7b model is significantly cheaper than footing the bill for GPT-4 endpoint calls, especially as your service grows.&nbsp;</p><h2>SQL Generation with Llama-2 fine-tuned models</h2><p>The next task we examine is SQL generation. The goal is to convert natural language queries to a functional SQL query that can then be executed on your database. For this task we examine the <a href="https://huggingface.co/datasets/b-mc2/sql-create-context"><u>b-mc2/sql-create-context</u></a> dataset from Hugging Face, which is a combination of the <a href="https://huggingface.co/datasets/wikisql"><u>WikiSQL</u></a> and <a href="https://huggingface.co/datasets/spider"><u>Spider</u></a> datasets.&nbsp;</p><p>Each of the 78,577 data points consists of a natural language query, corresponding SQL CREATE TABLE statements, and then the SQL query corresponding to the natural language question. The goal of the LLM is to take in the natural language query and SQL CREATE TABLE statements as context, and produce a SQL output that can query the given SQL tables and produce an output that answers the natural language query.&nbsp;</p><h3>Example Data Point</h3><p>One issue specific to this dataset was incorrect ground truth SQL outputs that had to be filtered out. In many data points, attributes that were integers were labeled as VARCHARs in the CREATE TABLE statements:</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/cYFm1c3wBaJ3nxfifdF4U/3f5a5ada5b5238959a5387a80bbb6060/Example_Datapoint_Chart.png" alt="Example Datapoint Chart"></p></div><p>Note that the attribute “week” is defined as a string in the CREATE TABLE statement, however, is treated like an integer in the SQL query. To avoid resulting issues when testing, we filtered out all SQL queries that assumed an attribute was an integer, cutting the dataset from 70k data points to 45k data points. While this is a strong constraint on the dataset, the python SQL engine we were using did not have an easy way to type check between the CREATE TABLE and SQL query statements – unless we wanted to write an algorithm to parse through the AST and type check ourselves. Nonetheless, the resulting dataset was still challenging with plenty of tricky data points like the following:&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/47XvvreSp5HVtn3jMGclOm/3c72f0ce67abfebdd60331876eef4111/Another_Example_Datapoint_Chart.png" alt="Another Example Datapoint Chart"></p></div><h3>Why Might Fine-Tuning Be Promising?</h3><p>This task shares some similarities to ViGGO – the LLM is trying to output a structured representation of natural language, which in this case is SQL. Unlike ViGGO, this task is slightly more ambiguous as there can be several SQL queries that could output the correct answer when executed on a data table. Nonetheless, this task is a great fit for fine-tuning as success hinges on an LLM’s ability to learn the “structure” of SQL and convert natural language to this structure.&nbsp;&nbsp;</p><h3>Evaluation</h3><p>A major challenge with a SQL task like this is evaluation. Once the model has outputted a SQL query, how do we check if it is correct? One naive way would be to check character by character equivalence between the generated SQL code and the ground truth query provided by the dataset. This approach is sensitive to a lot of factors that can raise the number of false negatives. Another way is to check the equivalence of the abstract syntax tree (AST) of the two queries. However, this is also susceptible to things like order of variable names, etc. The last approach that would be the most reliable is to run the code on a fake dataset and check the equivalence of the outputs.</p><p>What we decided to do for this task is to use OpenAI's GPT-3.5 endpoint to generate unit tests for a few hundreds of these examples. GPT-3.5 is prompted to look at the question, the table schema, and the answer and generate a fake table with ten data points. This small data table can be used to compare and test the validity of an SQL query:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span></code><span><span>from</span><span> sqlglot.executor </span><span>import</span><span> execute
</span></span><span>
</span><span>gpt_data_table = {
</span><span><span>&nbsp;&nbsp;</span><span>"table_name_64"</span><span>: [
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;{
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"position"</span><span>: </span><span>"mayor"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"first_election"</span><span>: </span><span>"1988 as vice mayor 2009"</span><span>
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;...
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;{
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"position"</span><span>: </span><span>"mayor"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"first_election"</span><span>: </span><span>"2007 as councilor 2014"</span><span>
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;}
</span><span>&nbsp;&nbsp;]
</span><span>}
</span><span>
</span><span><span>&nbsp;model_sql = get_llama_response(sql_prompt.</span><span>format</span><span>(create_table=..., query=...))
</span></span><span><span>&nbsp;model_sql = model_sql[model_sql.find(</span><span>"&lt;SQL&gt;"</span><span>)+</span><span>len</span><span>(</span><span>"&lt;SQL&gt;"</span><span>):model_sql.find(</span><span>"&lt;/SQL&gt;"</span><span>)]
</span></span><span>&nbsp;model_sql = model_sql.lower()
</span><span>
</span><span><span></span><span>try</span><span>:
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;queryresult = execute(sql_query, tables=table)
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;modelresult = execute(model_sql, tables=table)
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>str</span><span>(queryresult) == </span><span>str</span><span>(modelresult):
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	</span><span># output is correct&nbsp;</span><span>
</span></span><span><span></span><span>except</span><span> Exception </span><span>as</span><span> e:&nbsp;
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>print</span><span>(e)
</span></span><span>
</span></code></pre></div><p>To ensure the quality of the GPT-3.5 generated data tables, we first executed the ground truth SQL query against it. If the resulting table was either empty, or the same length as the initial table, the example was discarded. This resulted in filtering out roughly 50% of the GPT produced data tables.&nbsp;</p><h3>Results</h3><p>Both the Llama-7b and 13b fine-tuned models outperform the 70b-chat and GPT-4 models. One common source of error for the Llama chat models was that it would not consistently put its output SQL within &lt;SQL&gt; tags as instructed by the prompt – this was more common in the 7b and 13b chat models than the 70b one.&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/3mqT3cT0OTVbB57Udt5U5x/1df7d2df8ba08b7fc78701df9bfe72c3/Various_models.png" alt="Various Models"></p></div><p><i>Dark colors present chat model performance. Fine-tuned models achieve ~90% success rate.</i></p><p>Note that some of the natural language queries in that SQL dataset were not perfect English. This noise from the dataset is likely to have slightly affected the GPT-4 results. It nonetheless highlights an important point about fine-tuning – that these models will quickly adapt to the quirks of&nbsp; a dataset, whatever those quirks may be.&nbsp;</p><h3>Takeaways</h3><p>In this example, both the 7b and 13b fine-tuned models outperformed GPT-4 as well as the 70b chat model. Also keep in mind that for every call to GPT and the Llama base chat models, a lengthy prompt needed to be fed in. Additionally, while this wasn’t an issue for GPT, the Llama chat models would often output hundreds of miscellaneous tokens that were unnecessary for the task, further slowing down their inference time (e.g. “Sure! Happy to help…”).</p><h2>Grade School Math reasoning (GSM8k)</h2><p>The final task we consider is GSM8k. This task is a standard academic benchmark for evaluating LLMs on math reasoning and understanding. The challenge of fine-tuning on this dataset differs from the previous two. As opposed to just learning structure, we wanted to see how much an LLM could improve its ability to reason on math problems.</p><h3>Example data point</h3><table><tbody><tr><td><p><b>Question</b></p></td><td><p><b>Answer</b></p></td></tr><tr><td><p>Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?</p></td><td><p>Natalia sold 48/2 = 24 clips in May. \n Natalia sold 48+24 = 72 clips altogether in April and May. \n#### 72</p></td></tr></tbody></table><p>While it would be impressive for an LLM to immediately produce the answer of 72, current LLMs are incapable of internalizing their "thought" process leading to the final answer. Instead, they must generate their "thought" process as part of the output, ensuring that the generation of each subsequent word is based on a solid reasoning process. The target answers in this dataset are formatted to outline the thought process, concluding with the final answer in the #### {answer} format for easy parsing.</p><p>This task necessitates that the language models not only understand simple calculations, but also know how to progress from the given assumptions to intermediate conclusions, and ultimately to a final answer. Thus, LLMs need a solid grasp of language (including the understanding of concepts and their interrelationships), as well as the ability to lay out a logical chain of thought. The interesting question here is how well do the chat-tuned models do on this task and how much can we gain with fine-tuning?&nbsp;</p><h3>Evaluation</h3><p>To effectively evaluate an LLM on this task, you need a reliable method to extract the final answer generated by the language model and compare it to the ground truth. While this isn’t an issue with fine-tuned models, a common challenge with general language models is their inability to consistently adhere to a desired output format, making it tricky to evaluate. There are various proposed solutions for constrained generation, such as <a href="https://github.com/microsoft/guidance"><u>guidance</u></a>, hinting at the constraints in the prompt, or providing few-shot examples. However, for the sake of simplicity and to ensure a specific output format for automating the evaluation process, we utilized <a href="https://openai.com/blog/function-calling-and-other-api-updates"><u>OpenAI's function calling API</u></a>.</p><p>The idea is to employ a gpt-4 or gpt-3.5-turbo model to process the generated response for LLMs that lack a predetermined output structure. Given the question, these models can extract the final answer without correcting it (if there are any errors). The following code demonstrates the extraction procedure:</p><div><pre><code><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span></code><span><span>def extract_number_from_text(question: str, text: str) -&gt; int:
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;## Use GPT</span><span>-3.5</span><span>-turbo's functional API to extract the number from the text
</span></span><span>
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;functions = [
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"name"</span><span>: </span><span>"report_answer"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"description"</span><span>: </span><span>"Reports the final answer from the text."</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"parameters"</span><span>: {
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"type"</span><span>: </span><span>"object"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"properties"</span><span>: {
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"number"</span><span>: {
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"type"</span><span>: </span><span>"integer"</span><span>,
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"description"</span><span>: ...
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>"required"</span><span>: [</span><span>"number"</span><span>],
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;]
</span><span>
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;resp = openai.ChatCompletion.create(
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model=</span><span>"gpt-3.5-turbo-0613"</span><span>,
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messages=[...],
</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functions=functions,
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;function_call={</span><span>"name"</span><span>: </span><span>"report_answer"</span><span>},
</span></span><span>&nbsp;&nbsp;&nbsp;&nbsp;)
</span><span>
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;resp_msg = resp[</span><span>"choices"</span><span>][</span><span>0</span><span>][</span><span>"message"</span><span>]
</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;function_args = json.loads(resp_msg[</span><span>"function_call"</span><span>][</span><span>"arguments"</span><span>])
</span></span><span>
</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;return function_args[</span><span>"number"</span><span>]
</span></span><span>
</span></code></pre></div><p>We instruct the gpt-3.5 model to read the question and utilize a function named report_answer, which accepts an integer number as its input. This approach ensures that the model will consistently output the final integer number found within the content generated by another model. For example if the model answers that “The answer is four” we can still parse the answer as answer = 4. We've tested this on the provided answers in the dataset to confirm its efficacy and ensure that it doesn't present any edge cases. The downside of this approach is that we need to pay for OpenAI tokens for evaluation.&nbsp;</p><p>It's worth noting that the fine-tuned models quickly learn to adhere to the pattern exhibited in the target answers and rarely deviate from it – even if the answer itself is incorrect, the output structure is very predictable. Therefore, when evaluating fine-tuned models, we simply apply the regex pattern of #### {answer} to the output generated by these models, eliminating the need for post processing with OpenAI endpoints saving money during evaluation.&nbsp;</p><h3>Why Might Fine-Tuning Be Promising?</h3><p>For this task, we believe that the model has been exposed to sufficient mathematical concepts during its pre-training phase. As such, it should be able to generalize from there, and fine-tuning should help in activating the appropriate mode of its internal knowledge. Additionally, if we examine the published benchmarks on Llama-2, it performs notably well on the GSM8k dataset with 8 few-shot examples, outperforming other models. This underscores the importance of extensive pre-training data. The question then becomes: Can we further improve these numbers through fine-tuning?<br></p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/7po1LGLgt5LzPCb3SFxH2h/b9aac7af2dc3eecd89318e31d60cb567/benchmark_compare_table.png" alt="Benchmark Llama 2 Table"></p></div><h3>Baselines</h3><p>Establishing the correct baselines is crucial for methodically measuring progress and the effectiveness of different approaches. For this test, we considered the following baselines:</p><ol><li><p>The reported 8-shot prompting approach using the base pre-trained models (note that we did not re-run these experiments ourselves; we are simply quoting the published results).</p></li><li><p>Several prompt-engineered templates for the chat-tuned Llama variants. These “chat-tuned” models were trained by Meta using <a href="https://huyenchip.com/2023/05/02/rlhf.html">RLHF</a> to function as general-purpose assistant models. If the RLHF training is conducted as rigorously as OpenAI's approach, we should expect high-quality results from these models as well. The following table presents a view of the prompt templates we used and illustrates how they differ from each other.</p></li></ol><div><p><img src="https://images.ctfassets.net/xjan103pcp94/13GoCLY3pAe2gVCIRUDaqB/b01dc6a842dda90c46b3a6d4b5cc7ee1/Comparison_with_Baseline.png" alt="Comparison with Baseline"></p></div><h3><br>Results</h3><div><p><img src="https://images.ctfassets.net/xjan103pcp94/1YaJFzh4W1HwCxeTLSIf75/f6603679a8f04c0d3a292c3980e856ef/GSM8k_Results_Across_Llama.png" alt="GSM8k Results Across Llama"></p></div><p><i>The fine-tuned 7b and 13b models have an improved accuracy by 10% when compared to their base counterparts. The margin is less when compared to the chat-tuned baselines, as these were likely trained with math examples in the chat-tuning process.&nbsp;</i></p><p>There a couple takeaways from these results:</p><ol><li><p><b>Fine-tuning the base model consistently enhances its performance on this specific task. </b>However, it may not necessarily yield results significantly better than those of the chat-tuned models. Keep in mind that the chat models were fine-tuned to be versatile, so determining whether they are sufficient for your task requires experimenting with different prompts.&nbsp;</p></li><li><p><b>Prompting the fine-tuned model does not always lead to better performance than the base model.</b> For instance, Llama-2-70B-chat could actually underperform relative to the base model with an 8-shot example prompt, while the fine-tuned model consistently does better than the 8-shot prompted base model.&nbsp;</p></li><li><p><b>Fine-tuned models for this task demonstrate superior performance across all model sizes</b>, while potentially costing significantly less than the other baselines during serving. For this task, you will be charged for all the tokens in the prompt for each request, but for fine-tuned models, you would effectively only pay for the number of tokens in the question. Depending on the serving traffic you are targeting, your overall cost could be lower while using a more performant, customized model.</p></li><li><p><b>Chat-tuned models performed better than the non-fine-tuned base model.</b> It is important to make the distinction between the chat-tuned model and the base pre-trained model. The chat-tuned models were likely trained with math examples in the chat-tuning process, resulting in better accuracy than the base model.&nbsp;</p></li></ol><h3>Further Improving Fine-Tuning Results</h3><p>While we do see improvements from fine-tuning across the board, we wanted to focus on Llama-13b and see if results could be further improved with standard fine-tuning techniques. The GSM8k training dataset is relatively small, with only 8k data points. Since learning to solve math problems is less straightforward than just learning to output answers in a specific format, we figured it was unlikely that just 8k data points would be sufficient in unlocking the full-potential of a Llama-13b model on this dataset.&nbsp;</p><p>With this in mind, we took the base Llama-13b model and first fine-tuned it on the MathQA dataset, before subsequently fine-tuning the model on the original GSM8k dataset. This extra round of fine-tuning resulted in a further 10% increase from the initial fine-tuned model results, adding up to a 20% increase from the base model.&nbsp;</p><div><p><img src="https://images.ctfassets.net/xjan103pcp94/35f5hYWemM3xoVftEH2GkP/be028fe2dc39707af59d238192875be5/Llama-13b_GSM8k_Accuracy.png" alt="Llama-13b GSM8k Accuracy."></p></div><p><i>Fine-tuning with just the GSM8k data yields a 10% improvement. Fine-tuning in two stages with both the MathQA and GSM8k datasets result in a cumulative 10% improvement.</i></p><p>While one might expect this to align with the classic “more data, better model” paradigm within machine learning, we found these results to be surprising given the nature of the MathQA dataset. MathQA is a collection of 30,000 question/answer pairs that are much noisier and of different structure than the GSM8K dataset. The answers are of poorer quality, and unlike GSM8k, the final answers in MathQA are multiple choice. As an example:</p><table><tbody><tr><td><p><b>Question</b></p></td><td><p><b>Answer Options</b></p></td><td><p><b>Answer</b></p></td></tr><tr><td><p>the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?</p></td><td><p>a ) rs . 400 , b ) rs . 300 , c ) rs . 500 , d ) rs . 350 , e ) none of these</p></td><td><p>explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = rs . 400 answer : option a</p></td></tr></tbody></table><p>Notice the odd spacing and compare the quality of this datapoint to the GSM8k question/answer pair from earlier:</p><table><tbody><tr><td><p><b>Question</b></p></td><td><p><b>Answer</b></p></td></tr><tr><td><p>Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?</p></td><td><p>Natalia sold 48/2 = 24 clips in May. \n Natalia sold 48+24 = 72 clips altogether in April and May. \n#### 72</p></td></tr></tbody></table><p>Stratifying the fine-tuning into two rounds was an effective way to leverage this MathQA dataset and yield a much better final result for the GSM8k dataset.</p><h3>Conclusion</h3><p>Hopefully going through these three examples should have convinced you that while closed-source models like GPT-4, Claude-2, etc. are strong enablers for prototyping and proving the initial value, they are not sufficient for running performant LLM apps in production. Fine-tuning LLMs for niche tasks is one of the promising solutions to elicit value out of LLMs for your business, not just because of privacy, but also latency, cost, and sometimes quality (e.g. in ViGGO and SQL examples). For fine-tuning your focus should be on collecting data and setting up evaluation pipelines that help you understand trade-offs between different solutions tied to your business, and not think about the infrastructure and intricacies of fine-tuning. At Anyscale we have built the best fine-tuning and serving solutions on top of Ray, so you can start repeating the same process outlined here on your own data and on your own cloud. Checkout <a href="https://app.endpoints.anyscale.com/"><u>Anyscale Endpoints</u></a> to learn more.<br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GSMA considers giving away mobile device locations through API (104 pts)]]></title>
            <link>https://www.gsma.com/futurenetworks/gsma-open-gateway-api-descriptions/</link>
            <guid>37090063</guid>
            <pubDate>Fri, 11 Aug 2023 15:49:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gsma.com/futurenetworks/gsma-open-gateway-api-descriptions/">https://www.gsma.com/futurenetworks/gsma-open-gateway-api-descriptions/</a>, See on <a href="https://news.ycombinator.com/item?id=37090063">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="wrapper" role="main">
    <article id="post-35494" class="page">
    


    <section>
    <p><img decoding="async" src="https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1.jpg" alt="Open Gateway APIs" width="858" height="288" srcset="https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1.jpg 858w, https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1-500x168.jpg 500w, https://www.gsma.com/futurenetworks/wp-content/uploads/2023/02/open-gateway-apis-1-1-768x258.jpg 768w" sizes="(max-width: 858px) 100vw, 858px"><br>
<a href="https://www.gsma.com/futurenetworks/gsma-open-gateway/">← Back to GSMA Open Gateway Home</a></p>
<p>The GSMA Open Gateway initiative launches with eight network APIs, including SIM Swap, Quality on Demand, Device Status, Number Verification, Simple Edge Discovery, One Time Password SMS, Carrier Billing – Check Out and Device Location. The initiative plans to launch further APIs throughout 2023.</p>
<p>They can be found in the CAMARA repository here&nbsp;<a href="https://github.com/camaraproject" target="_blank" rel="noopener">https://github.com/camaraproject</a></p>

<h3><b>SIM swap</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2">The API checks the last time that the SIM card associated with a mobile number (MSISDN) has changed. The response may be a timestamp or a yes/no for a defined period (e.g. last 24h).</td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><strong>Fraud prevention in banking:</strong> a bank may query the API when a transaction appears suspicious. The SIM swap information feeds into the bank risk decision engine and security measures are applied accordingly by the bank</li>
<li><strong>Fraud prevention for password reset (various sectors):</strong> password reset is often protected via a mobile verification e.g. SMS One Time Password. The online service provider may query the API to secure the mobile verification. A recent SIM swap may indicate a risk of account takeover fraud and the service provider can adapt the security measures accordingly.</li>
</ul>
</td>
<td>Increased security without additional friction for the user</td>
</tr>
</tbody>
</table>
<h3><b>Quality On Demand</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>The API allows an application developer to request stable latency (reduced jitter) or throughput for specified application data flows between application clients&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>and application servers. The developer chooses from a predefined set of&nbsp;</span><span>Quality of Service</span><span>&nbsp;Profiles (</span><span>i.e.</span><span>&nbsp;stable latency or different levels of throughput). The&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>API response confirms whether the network can fulfill the request.</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Remote control of machines and vehicles (e.g.&nbsp;Automated Guided Vehicles, drones,&nbsp;</b><b>robotic arm, factory production&nbsp;line</b><b>): </b><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>applications requiring remote control of&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>machines or vehicles require stable data throughput and low latency. The requirements&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>may change dynamically (</span><span>e.g.</span><span>&nbsp;piloting a drone vs drone transmitting video data) or&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>not&nbsp;(</span><span>e.g.</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>specialised</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>&nbsp;robotic arm or remote maintenance). The application requests the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>required Quality On Demand from the mobile network via the API each time the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>requirements change. The API can&nbsp;also apply over private networks and network slices.</span></span></li>
<li><b>Real-time media and entertainment (e.g. gaming, real-time streaming): </b>online gamers and viewers of real-time streaming media require a guaranteed level of quality to ensure good user experience. The application requests the required Quality on Demand from the mobile network via the API.</li>
</ul>
</td>
<td>Improved performance for applications.
<p>Minimised production line downtime. Factory floor flexibility.</p>
<p>Guaranteed quality may be critical for safety reasons (moving objects or vehicles).</p>
<p>Enhanced end-user experience.</p></td>
</tr>
</tbody>
</table>
<h3><b>Device status</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API checks connectivity status for a user equipment. In its current version, the API only checks the roaming status of a device. The response confirms&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>whether the device is roaming and the country it is in.&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li data-charcodes="8226" data-font="Arial,Sans-Serif" data-buautonum="8" data-margin="540" data-aria-posinset="1" data-aria-level="1"><b><span data-usefontface="false" data-contrast="none">Service delivery:&nbsp;</span></b><span data-usefontface="false" data-contrast="none">a content provider may need to enforce territory restrictions for their&nbsp;</span><span data-usefontface="false" data-contrast="none">content. For&nbsp;instance&nbsp;a broadcaster or streaming service may only have rights to&nbsp;</span><span data-usefontface="false" data-contrast="none">broadcast a piece of content in their domestic market. Through the Device status API,&nbsp;</span><span data-usefontface="false" data-contrast="none">the content provider can check that the end-user&nbsp;is located in&nbsp;the content provider&nbsp;</span><span data-usefontface="false" data-contrast="none">domestic&nbsp;market.&nbsp;</span>​</li>
<li data-charcodes="8226" data-font="Arial,Sans-Serif" data-buautonum="8" data-margin="540" data-aria-posinset="2" data-aria-level="1"><b><span data-usefontface="false" data-contrast="none">Fraud prevention (e.g.&nbsp;banking, payments, commerce):&nbsp;</span></b><span data-usefontface="false" data-contrast="none">a bank may query the API&nbsp;</span><span data-usefontface="false" data-contrast="none">upon detecting a transaction from an unexpected country. The roaming information feeds&nbsp;</span><span data-usefontface="false" data-contrast="none">into the bank risk decision engine and security measures are applied accordingly by the&nbsp;</span><span data-usefontface="false" data-contrast="none">bank.&nbsp;</span>​</li>
<li data-charcodes="8226" data-font="Arial,Sans-Serif" data-buautonum="8" data-margin="540" data-aria-posinset="3" data-aria-level="1"><b><i><span data-usefontface="false" data-contrast="none">Regulatory compliance:&nbsp;</span></i></b><i><span data-usefontface="false" data-contrast="none">a customer may need to be within a certain jurisdiction, or&nbsp;</span></i><i><span data-usefontface="false" data-contrast="none">outwith</span></i><i><span data-usefontface="false" data-contrast="none">&nbsp;others,&nbsp;in order for&nbsp;transactions to be&nbsp;</span></i><i><span data-usefontface="false" data-contrast="none">authorised</span></i>​</li>
</ul>
</td>
<td>Remote monitoring of IoT devices enables device management and performance.
<p>Decreased fraud risk without additional friction for the user.</p></td>
</tr>
</tbody>
</table>
<h3><b>Number Verification</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>The API enables the seamless authentication of the mobile device by the mobile network. The developer requests a check of the phone number of the device&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>being used to access its service. The API either confirms the comparison result (</span><span>i.e.</span><span>&nbsp;whether the user is using a device with the same&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>mobile phone</span><span>&nbsp;number&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>as&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-usefontface="false" data-contrast="none"><span>is declared</span><span>), or</span><span>&nbsp;returns the phone number.&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>App onboarding (banking app, social media, ride share, mobile wallet, …): </b>SMS One Time Password is widely used to prove that the user is in possession of the mobile device associated with the mobile number used for registration. However it adds friction to the user journey. The application can instead request a seamless authentication of the mobile device via the API.</li>
<li><b>App login: </b>in place of username/password, the application can request seamless authentication of the mobile device.</li>
<li><b>Application password reset: </b>the user journey often relies on SMS One Time Password. As in the app onboarding use case, the application can instead request a seamless authentication of the mobile device via the API.</li>
</ul>
</td>
<td>Improved seamless and faster user experience, hence improved conversion rates &amp; customer satisfaction
<p>Lower risk of compromise (by social engineering or interception)</p></td>
</tr>
</tbody>
</table>
<h3><b>Simple Edge Discovery</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API allows an application to discover the nearest Edge-Cloud node for it to connect to (may be telco edge cloud or&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>hyperscaler</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>&nbsp;edge cloud, whichever is&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>required).&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>All edge cloud use cases e.g. automotive, mixed/augmented reality, high resolution video streaming, cloud gaming, remote control of moving objects or vehicles</b>: for an application deployed in telco edge cloud or hyperscaler edge cloud, the device needs to be informed of the Edge-Cloud node to access. The application queries the API and is informed of the nearest Edge-Cloud node to connect to. It can then perform a DNS lookup to route traffic to this node.</li>
</ul>
</td>
<td>
<p data-ccp-props="{&quot;335551550&quot;:1,&quot;335551620&quot;:1,&quot;335559683&quot;:0,&quot;335559685&quot;:0,&quot;335559731&quot;:0,&quot;335559737&quot;:0,&quot;335562764&quot;:2,&quot;335562765&quot;:1,&quot;335562766&quot;:4,&quot;335562767&quot;:0,&quot;335562768&quot;:4,&quot;335562769&quot;:0}"><span data-scheme-color="@000000,," data-usefontface="true" data-contrast="none">Enables selection of and routing towards the nearest edge cloud&nbsp;</span><span data-scheme-color="@000000,," data-usefontface="true" data-contrast="none">node, generally&nbsp;</span><span data-usefontface="false" data-contrast="none">optimising network performance by minimising&nbsp;</span><span data-usefontface="false" data-contrast="none">propagation delay.&nbsp;</span>​</p>
<p data-ccp-props="{&quot;335551550&quot;:1,&quot;335551620&quot;:1,&quot;335559683&quot;:0,&quot;335559685&quot;:0,&quot;335559731&quot;:0,&quot;335559737&quot;:0,&quot;335562764&quot;:2,&quot;335562765&quot;:1,&quot;335562766&quot;:4,&quot;335562767&quot;:0,&quot;335562768&quot;:4,&quot;335562769&quot;:0}">​<span data-usefontface="false" data-contrast="none">More accurate selection based on Operator network topology&nbsp;</span><span data-usefontface="false" data-contrast="none">rather than geolocation.&nbsp;</span></p>
</td>
</tr>
</tbody>
</table>
<h3>One Time Password SMS</h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API delivers a short-lived&nbsp;</span><span>one time</span><span>&nbsp;password to&nbsp;</span><span>a mobile phone</span><span>&nbsp;number via SMS. The API then validates the code as input by the end-user into the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>service,&nbsp;</span><span>in order to</span><span>&nbsp;provide a proof of possession of the phone number.&nbsp;</span></span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Onboarding to digital service (banking, social media, gig economy, retail, …):</b> SMS One Time Password is used to prove that the user is in possession of the mobile device associated with the mobile number used for onboarding. This increases confidence for future uses of the mobile number and reduces instances of fake accounts creation.</li>
<li><b>High-value transactions: </b>in order to reduce payment fraud, the user may be asked to enter the OTP code sent to their registered mobile number.</li>
<li><b>Account management e.g. password reset: </b>to protect against account takeover, sensitive account management actions can be protected by requesting a second factor authentication by the end-user.</li>
</ul>
</td>
<td>End user familiarity.
<p>Increased security over single-factor authentication (username/password) or in card-not-present scenarios.</p>
<p>Prevent fake accounts creation (bots).</p></td>
</tr>
</tbody>
</table>
<h3><b>Carrier Billing – Check Out</b>​</h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API allows an online merchant to enable the purchase of third-party digital goods and to request payment against the user’s Operator carrier billing&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>system. The API enables several related operations to the purchase (triggering purchase and consulting information to follow up on fulfilment); and to the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>payment, in one step by requesting carrier billing payment or with additional steps to prepare the payment before confirming or cancelling it. The Operator&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>takes care of the billing.&nbsp;</span><span>Usually</span><span>&nbsp;the payment amount is added to the user’s phone bill or deducted from their prepaid balance and funds are paid to the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>merchant by the Operator.&nbsp;</span></span><span>​</span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Mobile payments across media, gaming, mobile services, ticketing, content, and other digital services: </b>when reaching checkout online, the user gets the option to pay by mobile. If chosen, the merchant requests payment via the Carrier Billing API. The payment amount is added to the user’s phone bill or deducted from their prepaid balance. The settlement from the mobile operator to the merchant takes place to cover all users’ payments over a defined period.</li>
</ul>
</td>
<td>Convenient and secure online payment solution for unbanked / underbanked users who cannot pay by credit card

<p>Increased conversion for merchants</p></td>
</tr>
</tbody>
</table>
<h3><b>Device Location</b></h3>
<table>
<tbody>
<tr>
<th colspan="2">API description</th>
</tr>
<tr>
<td colspan="2"><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>The API allows an application to check if a mobile device is in proximity of a given location. The API request contains the location to be checked and an&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>accuracy range in km (between 2km and 200km). The API response indicates whether the location is within the accuracy range of the last known location of&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>the MSISDN</span></span><span lang="EN-US" xml:lang="EN-US" data-scheme-color="@000000,," data-usefontface="true" data-contrast="none"><span>.&nbsp;</span></span><span>​</span></td>
</tr>
<tr>
<td>Use cases (examples)</td>
<td>Benefits</td>
</tr>
<tr>
<td>
<ul>
<li><b>Fraud prevention (banking, payments): </b>a bank may query the API upon detecting a cash withdrawal or credit card use attempt from an unexpected location. The location verification feeds into the bank risk decision engine and security measures are applied accordingly by the bank.</li>
<li><b>Traffic management of drones: </b>the Uncrewed Aircraft System Traffic Management or the drone operator can obtain drone location information from its GPS data, however this is vulnerable to jamming or spoofing. They can query the API to verify the drone location, e.g. for law enforcement purposes or to check compliance with approved flight plan.</li>
<li><b>Retail marketing:</b> a retailer Edge Application may query the API to verify that a user is close enough to a physical location before pushing a notification to them.</li>
<li><b>Protection of assets e.g. logistics, indoors factory tools (depending on available accuracy)</b>: the fleet manager can check if assets are in their expected location.</li>
</ul>
</td>
<td>Decreased fraud risk without additional friction for the user.
<p>Independent and reliable verification of the location reported by a drone GPS.</p>
<p>Geotargeted marketing</p></td>
</tr>
</tbody>
</table>
<span><a href="https://www.gsma.com/aboutus/legal/anti-trust-policy-statement/" target="_self">GSMA privacy policy&nbsp;<i></i></a></span>

    
    </section>
  </article>
  
	
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mpire: A Python package for easier and faster multiprocessing (108 pts)]]></title>
            <link>https://github.com/sybrenjansen/mpire</link>
            <guid>37089817</guid>
            <pubDate>Fri, 11 Aug 2023 15:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sybrenjansen/mpire">https://github.com/sybrenjansen/mpire</a>, See on <a href="https://news.ycombinator.com/item?id=37089817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">MPIRE (MultiProcessing Is Really Easy)</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sybrenjansen/mpire/workflows/Build/badge.svg?branch=master"><img alt="Build status" src="https://github.com/sybrenjansen/mpire/workflows/Build/badge.svg?branch=master"></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/sybrenjansen/mpire/workflows/Docs/badge.svg?branch=master"><img alt="Docs status" src="https://github.com/sybrenjansen/mpire/workflows/Docs/badge.svg?branch=master"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1033fea2d63358ff14ce80b822c956506b2ba36b8fe97f83ed9750c2792a7de2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d70697265"><img alt="Pypi status" src="https://camo.githubusercontent.com/1033fea2d63358ff14ce80b822c956506b2ba36b8fe97f83ed9750c2792a7de2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d70697265" data-canonical-src="https://img.shields.io/pypi/v/mpire"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4faf85fddc1f6489895661d067a66fa3923e06ce64ab4c11d12129c3c4cf27f0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6d70697265"><img alt="Python versions" src="https://camo.githubusercontent.com/4faf85fddc1f6489895661d067a66fa3923e06ce64ab4c11d12129c3c4cf27f0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6d70697265" data-canonical-src="https://img.shields.io/pypi/pyversions/mpire"></a></p>
<p dir="auto"><code>MPIRE</code>, short for MultiProcessing Is Really Easy, is a Python package for multiprocessing. <code>MPIRE</code> is faster in
most scenarios, packs more features, and is generally more user-friendly than the default multiprocessing package. It
combines the convenient map like functions of <code>multiprocessing.Pool</code> with the benefits of using copy-on-write shared
objects of <code>multiprocessing.Process</code>, together with easy-to-use worker state, worker insights, worker init and exit
functions, timeouts, and progress bar functionality.</p>
<p dir="auto">Full documentation is available at <a href="https://sybrenjansen.github.io/mpire/" rel="nofollow">https://sybrenjansen.github.io/mpire/</a>.</p>
<a name="user-content-features"></a>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Faster execution than other multiprocessing libraries. See <a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9" rel="nofollow">benchmarks</a>.</li>
<li>Intuitive, Pythonic syntax</li>
<li>Multiprocessing with <code>map</code>/<code>map_unordered</code>/<code>imap</code>/<code>imap_unordered</code>/<code>apply</code>/<code>apply_async</code> functions</li>
<li>Easy use of copy-on-write shared objects with a pool of workers (copy-on-write is only available for start method
<code>fork</code>)</li>
<li>Each worker can have its own state and with convenient worker init and exit functionality this state can be easily
manipulated (e.g., to load a memory-intensive model only once for each worker without the need of sending it through a
queue)</li>
<li>Progress bar support using <a href="https://tqdm.github.io/" rel="nofollow">tqdm</a></li>
<li>Progress dashboard support</li>
<li>Worker insights to provide insight into your multiprocessing efficiency</li>
<li>Graceful and user-friendly exception handling</li>
<li>Timeouts, including for worker init and exit functions</li>
<li>Automatic task chunking for all available map functions to speed up processing of small task queues (including numpy
arrays)</li>
<li>Adjustable maximum number of active tasks to avoid memory problems</li>
<li>Automatic restarting of workers after a specified number of tasks to reduce memory footprint</li>
<li>Nested pool of workers are allowed when setting the <code>daemon</code> option</li>
<li>Child processes can be pinned to specific or a range of CPUs</li>
<li>Optionally utilizes <a href="https://pypi.org/project/dill/" rel="nofollow">dill</a> as serialization backend through <a href="https://github.com/uqfoundation/multiprocess">multiprocess</a>, enabling parallelizing more exotic objects,
lambdas, and functions in iPython and Jupyter notebooks.</li>
</ul>
<p dir="auto">MPIRE has been tested on both Linux and Windows. There are a few minor known caveats for Windows users, which can be
found <a href="https://sybrenjansen.github.io/mpire/troubleshooting.html#windows" rel="nofollow">here</a>.</p>
<a name="user-content-installation"></a>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">Through pip (PyPi):</p>

<p dir="auto">MPIRE is also available through conda-forge:</p>
<div dir="auto" data-snippet-clipboard-copy-content="conda install -c conda-forge mpire"><pre>conda install -c conda-forge mpire</pre></div>
<a name="user-content-getting-started"></a>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">Suppose you have a time consuming function that receives some input and returns its results. Simple functions like these
are known as <a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel" rel="nofollow">embarrassingly parallel</a> problems, functions that require little to no effort to turn into a parallel
task. Parallelizing a simple function as this can be as easy as importing <code>multiprocessing</code> and using the
<code>multiprocessing.Pool</code> class:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import time
from multiprocessing import Pool

def time_consuming_function(x):
    time.sleep(1)  # Simulate that this function takes long to complete
    return ...

with Pool(processes=5) as pool:
    results = pool.map(time_consuming_function, range(10))"><pre><span>import</span> <span>time</span>
<span>from</span> <span>multiprocessing</span> <span>import</span> <span>Pool</span>

<span>def</span> <span>time_consuming_function</span>(<span>x</span>):
    <span>time</span>.<span>sleep</span>(<span>1</span>)  <span># Simulate that this function takes long to complete</span>
    <span>return</span> ...

<span>with</span> <span>Pool</span>(<span>processes</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>))</pre></div>
<p dir="auto">MPIRE can be used almost as a drop-in replacement to <code>multiprocessing</code>. We use the <code>mpire.WorkerPool</code> class and
call one of the available <code>map</code> functions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from mpire import WorkerPool

with WorkerPool(n_jobs=5) as pool:
    results = pool.map(time_consuming_function, range(10))"><pre><span>from</span> <span>mpire</span> <span>import</span> <span>WorkerPool</span>

<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>))</pre></div>
<p dir="auto">The differences in code are small: there's no need to learn a completely new multiprocessing syntax, if you're used to
vanilla <code>multiprocessing</code>. The additional available functionality, though, is what sets MPIRE apart.</p>
<a name="user-content-progress-bar"></a>
<h3 tabindex="-1" dir="auto">Progress bar</h3>
<p dir="auto">Suppose we want to know the status of the current task: how many tasks are completed, how long before the work is ready?
It's as simple as setting the <code>progress_bar</code> parameter to <code>True</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="with WorkerPool(n_jobs=5) as pool:
    results = pool.map(time_consuming_function, range(10), progress_bar=True)"><pre><span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>progress_bar</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">And it will output a nicely formatted <a href="https://tqdm.github.io/" rel="nofollow">tqdm</a> progress bar.</p>
<p dir="auto">MPIRE also offers a dashboard, for which you need to install additional <a href="https://sybrenjansen.github.io/mpire/install.html#dashboard" rel="nofollow">dependencies</a>. See <a href="https://sybrenjansen.github.io/mpire/usage/dashboard.html" rel="nofollow">Dashboard</a> for more
information.</p>
<a name="user-content-shared-objects"></a>
<h3 tabindex="-1" dir="auto">Shared objects</h3>
<p dir="auto">Note: Copy-on-write shared objects is only available for start method <code>fork</code>. For <code>threading</code> the objects are shared
as-is. For other start methods the shared objects are copied once for each worker, which can still be better than once
per task.</p>
<p dir="auto">If you have one or more objects that you want to share between all workers you can make use of the copy-on-write
<code>shared_objects</code> option of MPIRE.  MPIRE will pass on these objects only once for each worker without
copying/serialization. Only when you alter the object in the worker function it will start copying it for that worker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="def time_consuming_function(some_object, x):
    time.sleep(1)  # Simulate that this function takes long to complete
    return ...

def main():
    some_object = ...
    with WorkerPool(n_jobs=5, shared_objects=some_object) as pool:
        results = pool.map(time_consuming_function, range(10), progress_bar=True)"><pre><span>def</span> <span>time_consuming_function</span>(<span>some_object</span>, <span>x</span>):
    <span>time</span>.<span>sleep</span>(<span>1</span>)  <span># Simulate that this function takes long to complete</span>
    <span>return</span> ...

<span>def</span> <span>main</span>():
    <span>some_object</span> <span>=</span> ...
    <span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>, <span>shared_objects</span><span>=</span><span>some_object</span>) <span>as</span> <span>pool</span>:
        <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>progress_bar</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">See <a href="https://sybrenjansen.github.io/mpire/usage/workerpool/shared_objects.html" rel="nofollow">shared_objects</a> for more details.</p>
<a name="user-content-worker-initialization"></a>
<h3 tabindex="-1" dir="auto">Worker initialization</h3>
<p dir="auto">Workers can be initialized using the <code>worker_init</code> feature. Together with <code>worker_state</code> you can load a model, or
set up a database connection, etc.:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def init(worker_state):
    # Load a big dataset or model and store it in a worker specific worker_state
    worker_state['dataset'] = ...
    worker_state['model'] = ...

def task(worker_state, idx):
    # Let the model predict a specific instance of the dataset
    return worker_state['model'].predict(worker_state['dataset'][idx])

with WorkerPool(n_jobs=5, use_worker_state=True) as pool:
    results = pool.map(task, range(10), worker_init=init)"><pre><span>def</span> <span>init</span>(<span>worker_state</span>):
    <span># Load a big dataset or model and store it in a worker specific worker_state</span>
    <span>worker_state</span>[<span>'dataset'</span>] <span>=</span> ...
    <span>worker_state</span>[<span>'model'</span>] <span>=</span> ...

<span>def</span> <span>task</span>(<span>worker_state</span>, <span>idx</span>):
    <span># Let the model predict a specific instance of the dataset</span>
    <span>return</span> <span>worker_state</span>[<span>'model'</span>].<span>predict</span>(<span>worker_state</span>[<span>'dataset'</span>][<span>idx</span>])

<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>, <span>use_worker_state</span><span>=</span><span>True</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>task</span>, <span>range</span>(<span>10</span>), <span>worker_init</span><span>=</span><span>init</span>)</pre></div>
<p dir="auto">Similarly, you can use the <code>worker_exit</code> feature to let MPIRE call a function whenever a worker terminates. You can
even let this exit function return results, which can be obtained later on. See the <a href="https://sybrenjansen.github.io/mpire/usage/map/worker_init_exit.html" rel="nofollow">worker_init and worker_exit</a>
section for more information.</p>
<a name="user-content-worker-insights"></a>
<h3 tabindex="-1" dir="auto">Worker insights</h3>
<p dir="auto">When your multiprocessing setup isn't performing as you want it to and you have no clue what's causing it, there's the
worker insights functionality. This will give you insight in your setup, but it will not profile the function you're
running (there are other libraries for that). Instead, it profiles the worker start up time, waiting time and
working time. When worker init and exit functions are provided it will time those as well.</p>
<p dir="auto">Perhaps you're sending a lot of data over the task queue, which makes the waiting time go up. Whatever the case, you
can enable and grab the insights using the <code>enable_insights</code> flag and <code>mpire.WorkerPool.get_insights</code> function,
respectively:</p>
<div dir="auto" data-snippet-clipboard-copy-content="with WorkerPool(n_jobs=5, enable_insights=True) as pool:
    results = pool.map(time_consuming_function, range(10))
    insights = pool.get_insights()"><pre><span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>, <span>enable_insights</span><span>=</span><span>True</span>) <span>as</span> <span>pool</span>:
    <span>results</span> <span>=</span> <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>))
    <span>insights</span> <span>=</span> <span>pool</span>.<span>get_insights</span>()</pre></div>
<p dir="auto">See <a href="https://sybrenjansen.github.io/mpire/usage/workerpool/worker_insights.html" rel="nofollow">worker insights</a> for a more detailed example and expected output.</p>
<a name="user-content-timeouts"></a>
<h3 tabindex="-1" dir="auto">Timeouts</h3>
<p dir="auto">Timeouts can be set separately for the target, <code>worker_init</code> and <code>worker_exit</code> functions. When a timeout has been
set and reached, it will throw a <code>TimeoutError</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def init():
    ...

def exit_():
    ...

# Will raise TimeoutError, provided that the target function takes longer
# than half a second to complete
with WorkerPool(n_jobs=5) as pool:
    pool.map(time_consuming_function, range(10), task_timeout=0.5)

# Will raise TimeoutError, provided that the worker_init function takes longer
# than 3 seconds to complete or the worker_exit function takes longer than
# 150.5 seconds to complete
with WorkerPool(n_jobs=5) as pool:
    pool.map(time_consuming_function, range(10), worker_init=init, worker_exit=exit_,
             worker_init_timeout=3.0, worker_exit_timeout=150.5)"><pre><span>def</span> <span>init</span>():
    ...

<span>def</span> <span>exit_</span>():
    ...

<span># Will raise TimeoutError, provided that the target function takes longer</span>
<span># than half a second to complete</span>
<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>task_timeout</span><span>=</span><span>0.5</span>)

<span># Will raise TimeoutError, provided that the worker_init function takes longer</span>
<span># than 3 seconds to complete or the worker_exit function takes longer than</span>
<span># 150.5 seconds to complete</span>
<span>with</span> <span>WorkerPool</span>(<span>n_jobs</span><span>=</span><span>5</span>) <span>as</span> <span>pool</span>:
    <span>pool</span>.<span>map</span>(<span>time_consuming_function</span>, <span>range</span>(<span>10</span>), <span>worker_init</span><span>=</span><span>init</span>, <span>worker_exit</span><span>=</span><span>exit_</span>,
             <span>worker_init_timeout</span><span>=</span><span>3.0</span>, <span>worker_exit_timeout</span><span>=</span><span>150.5</span>)</pre></div>
<p dir="auto">When using <code>threading</code> as start method MPIRE won't be able to interrupt certain functions, like <code>time.sleep</code>.</p>
<p dir="auto">See <a href="https://sybrenjansen.github.io/mpire/usage/map/timeouts.html" rel="nofollow">timeouts</a> for more details.</p>
<a name="user-content-id4"></a>
<h2 tabindex="-1" dir="auto">Benchmarks</h2>
<p dir="auto">MPIRE has been benchmarked on three different benchmarks: numerical computation, stateful computation, and expensive
initialization. More details on these benchmarks can be found in this <a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9" rel="nofollow">blog post</a>. All code for these benchmarks can
be found in this <a href="https://github.com/sybrenjansen/multiprocessing_benchmarks">project</a>.</p>
<p dir="auto">In short, the main reasons why MPIRE is faster are:</p>
<ul dir="auto">
<li>When <code>fork</code> is available we can make use of copy-on-write shared objects, which reduces the need to copy objects
that need to be shared over child processes</li>
<li>Workers can hold state over multiple tasks. Therefore you can choose to load a big file or send resources over only
once per worker</li>
<li>Automatic task chunking</li>
</ul>
<p dir="auto">The following graph shows the average normalized results of all three benchmarks. Results for individual benchmarks
can be found in the <a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9" rel="nofollow">blog post</a>. The benchmarks were run on a Linux machine with 20 cores, with disabled hyperthreading
and 200GB of RAM. For each task, experiments were run with different numbers of processes/workers and results were
averaged over 5 runs.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/sybrenjansen/mpire/blob/master/images/benchmarks_averaged.png"><img alt="Average normalized bechmark results" src="https://github.com/sybrenjansen/mpire/raw/master/images/benchmarks_averaged.png"></a></p>
<a name="user-content-documentation"></a>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">See the full documentation at <a href="https://sybrenjansen.github.io/mpire/" rel="nofollow">https://sybrenjansen.github.io/mpire/</a> for information on all the other features of MPIRE.</p>
<p dir="auto">If you want to build the documentation yourself, please install the documentation dependencies by executing:</p>

<p dir="auto">or</p>

<p dir="auto">Documentation can then be build by using Python &lt;= 3.9 and executing:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python setup.py build_docs"><pre>python setup.py build_docs</pre></div>
<p dir="auto">Documentation can also be build from the <code>docs</code> folder directly. In that case <code>MPIRE</code> should be installed and
available in your current working environment. Then execute:</p>

<p dir="auto">in the <code>docs</code> folder.</p>

</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tailscale vs. Narrowlink (254 pts)]]></title>
            <link>https://narrowlink.com/docs/comparisons/tailscale</link>
            <guid>37089739</guid>
            <pubDate>Fri, 11 Aug 2023 15:24:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://narrowlink.com/docs/comparisons/tailscale">https://narrowlink.com/docs/comparisons/tailscale</a>, See on <a href="https://news.ycombinator.com/item?id=37089739">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Narrowlink and Tailscale are two open-source solutions with different architectures that enable secure remote access and connectivity across networks. They share some similarities but also have key differences in their architectures, features, and use cases.</p><h2 id="overview">Overview<a href="#overview" aria-label="Direct link to Overview" title="Direct link to Overview">​</a></h2><p><strong>Tailscale</strong> is a Software-as-a-Service (SaaS) platform that provides a zero-config VPN using the WireGuard protocol. It is partially open source and uses a peer-to-peer mesh architecture that connects devices through the Tailscale cloud services. Tailscale aims to be easy to use out of the box.</p><p><strong>Narrowlink</strong> is a self-hosted platform that consists of a gateway, agents, and clients acting as a proxy server. It uses a client-agent-gateway model to facilitate connectivity across restricted networks. Narrowlink is fully open source and designed to be flexible, transparent, and secure, and it can be deployed on your infrastructure.</p><p>Tailscale and Narrowlink are both excellent solutions for remote access and connectivity. However, Tailscale focuses on enabling access between different devices, while Narrowlink focuses on accessing services through agents as proxies.</p><h2 id="architecture">Architecture<a href="#architecture" aria-label="Direct link to Architecture" title="Direct link to Architecture">​</a></h2><p><strong>Narrowlink</strong> uses a centralized gateway to which clients and agents connect over HTTP/S protocols. The gateway handles routing and connections between agents behind firewalls/NAT and clients. Narrowlink does not have centralized configuration management to define agents, clients, access control policies, etc. The gateway is configured dynamically based on the tokens that agents and clients use, making it easy to scale and deploy.</p><p><strong>Tailscale</strong> devices connect directly to each other over WireGuard in a mesh architecture in a peer-to-peer fashion. Tailscale uses a centralized configuration management system to define devices, access control policies, etc. Traffic is routed through the Tailscale cloud services to facilitate connections between devices.</p><h2 id="open-source">Open Source<a href="#open-source" aria-label="Direct link to Open Source" title="Direct link to Open Source">​</a></h2><p><strong>Narrowlink</strong> is completely open source. All components, including the gateway, agents, and clients, are open source.</p><p><strong>Tailscale</strong> uses the open source WireGuard protocol, and its client apps are open source, but the coordination services are proprietary.</p><h2 id="security-and-privacy">Security and Privacy<a href="#security-and-privacy" aria-label="Direct link to Security and Privacy" title="Direct link to Security and Privacy">​</a></h2><p>Both Tailscale and Narrowlink are considered secure and private. Tailscale uses the WireGuard protocol and provides end-to-end encryption between devices by default. Narrowlink uses the HTTP/S protocol to transfer data between agents and clients to the gateway, which is encrypted by default. Since the data is transferred through the gateway, the gateway has access to the data. However, Narrowlink has implemented optional end-to-end encryption between agents and clients using the XChaCha20-Poly1305 cipher, adding an extra layer of security and privacy.</p><p>Due to the nature of the peer-to-peer architecture, the connection between Tailscale devices can be observed by the ISP and the Tailscale cloud services. However, the data itself is encrypted and cannot be read by the ISP or Tailscale cloud services. In Narrowlink, the ISP only observes the connections between agents or clients and the gateway, which are covered by the HTTPS protocol, appearing as normal web traffic, and the gateway has access to the connection data and info. However, if end-to-end encryption is enabled, the gateway cannot read the data.</p><p>Tailscale requires special permissions such as root/admin access to install and run the client app. It sometimes requires changing the OS and firewall configuration to enable IP forwarding. Narrowlink does not require any special permissions to install and run the agent and client for any of the functionalities.</p><h2 id="internet-sharing">Internet Sharing<a href="#internet-sharing" aria-label="Direct link to Internet Sharing" title="Direct link to Internet Sharing">​</a></h2><p>Both Tailscale and Narrowlink can be used to share internet access between devices. This concept is known as "exit node" in the Tailscale architecture. Tailscale needs to enable IP forwarding on the exit node device, which can lead to security issues as other computers within the same VLAN may use your computer as a gateway. In contrast, Narrowlink does not need to enable any sort of IP forwarding feature or change your firewall configurations, as it acts as a proxy. Additionally, you can apply ACLs to restrict access to the internet.</p><h2 id="access-control">Access Control<a href="#access-control" aria-label="Direct link to Access Control" title="Direct link to Access Control">​</a></h2><p>Both tools use ACLs to control access to devices and services. However, access control in Tailscale is limited in comparison to Narrowlink. Tailscale only supports IP-based ACLs. Narrowlink supports more granular ACLs, including IP, domain, port, and time-based whitelist and blacklist ACLs. Since Narrowlink accesses services through the agent, the ACLs can be applied to the external network that the agent is going to connect to. For example, you can share your network access with your friend while restricting access to specific services on your network or limiting them to access one of the services on the agent's network.</p><h2 id="self-hosted">Self-Hosted<a href="#self-hosted" aria-label="Direct link to Self-Hosted" title="Direct link to Self-Hosted">​</a></h2><p>Narrowlink is designed to be self-hosted on your infrastructure, providing more control and transparency over the data and traffic. Tailscale is a closed SaaS platform that must be used over the internet through their cloud coordination service.</p><h2 id="cdn-compatibility">CDN Compatibility<a href="#cdn-compatibility" aria-label="Direct link to CDN Compatibility" title="Direct link to CDN Compatibility">​</a></h2><p>Since Narrowlink uses HTTP/S protocols as a transport channel, it can be deployed behind a content delivery network (CDN) such as Cloudflare to improve performance. In other words, agents or clients can connect to the gateway through the CDN. Tailscale uses the WireGuard protocol, which is not compatible with CDNs.</p><h2 id="publishing-services">Publishing Services<a href="#publishing-services" aria-label="Direct link to Publishing Services" title="Direct link to Publishing Services">​</a></h2><p>Both Narrowlink and Tailscale can publish your local web services on the internet and automatically issue certificates for them. Tailscale calls this feature "Funnel," but this feature only works for HTTPS connections, and users must use Tailscale's infrastructure to publish their services, using Tailscale's domain (custom domains are not supported). Tailscale issues the certificate on the client machines, preventing the Tailscale infrastructure from decrypting your traffic and using an SNI proxy to route the traffic to the correct client. Narrowlink is more flexible in this case, offering three modes of operation for publishing web services on the internet:</p><ol><li>HTTP/S transparent proxy mode: In this mode, Narrowlink automatically issues and manages the certificates on the gateway, publishing your services on both HTTP and HTTPS protocols. In this mode, the gateway decrypts the TLS traffic and routes it to the correct agent. This mode is perfect for use behind CDNs and is useful for users who prioritize caching and performance over security.</li><li>SNI proxy mode: In this mode, Narrowlink relies on the SNI extension in the TLS protocol, similar to Tailscale, and does not decrypt the traffic. Certificate management should be performed by the users, and they can even use their custom certificate. This mode is useful for users who prioritize security over performance.</li><li>Mixed mode: In this mode, users can define that HTTP connections use the transparent proxy mode, and for TLS connections, it acts as SNI mode.</li></ol><p>Since Narrowlink is a self-hosted platform, you can use your custom domain and publish your web services on any port and protocol.</p><h2 id="network-performance">Network Performance<a href="#network-performance" aria-label="Direct link to Network Performance" title="Direct link to Network Performance">​</a></h2><p>Tailscale technically offers better network performance than Narrowlink due to its peer-to-peer architecture. However, the performance of Narrowlink is still good enough for most use cases. Narrowlink's performance depends on the bandwidth of the gateway and devices, while Tailscale's performance depends on the bandwidth of the devices. Narrowlink can also be deployed behind a CDN to utilize caching and enhance performance for publishing services.</p><h2 id="efficiency">Efficiency<a href="#efficiency" aria-label="Direct link to Efficiency" title="Direct link to Efficiency">​</a></h2><p>Narrowlink has better efficiency in terms of binary size, memory usage, and CPU usage. Narrowlink is written in Rust, while Tailscale is written in Go and C++ for most of its functionality. For example, the Tailscale client binary size is 46MB (tailscale 18MB, tailscale 28MB), while Narrowlink with libc and TLS library static linking is 3.5MB (Ubuntu x64).</p><h2 id="bottom-line">Bottom Line<a href="#bottom-line" aria-label="Direct link to Bottom Line" title="Direct link to Bottom Line">​</a></h2><p>When evaluating Narrowlink vs Tailscale, there are some key differences to consider that are important to understand. This bottom-line summary outlines the major distinctions between the two solutions:</p><ul><li>Tailscale focuses on direct peer-to-peer encrypted connections between devices, while Narrowlink focuses on accessing services through agent proxies.</li><li>Tailscale uses a SaaS model relying on its cloud coordination service, while Narrowlink is self-hosted for more customization and control.</li><li>Tailscale uses WireGuard for better raw throughput performance between devices, while Narrowlink has adequate performance for most use cases.</li><li>Narrowlink supports advanced ACLs, access to external networks, and custom proxy behaviors, while Tailscale has basic IP-based ACLs.</li><li>Narrowlink can be deployed behind CDNs, while Tailscale does not integrate with CDNs.</li><li>Narrowlink offers more flexibility in publishing and exposing services, while Tailscale is more limited.</li><li>Tailscale aims for easy out-of-the-box device connectivity, while Narrowlink offers more options and customizability.</li><li>Narrowlink has smaller binary sizes, lower resource usage, and avoids large dependencies.</li><li>Narrowlink provides additional security by tunneling all traffic through HTTPS to the gateway, while Tailscale uses WireGuard, which exposes some metadata.</li><li>Narrowlink is fully open source, while Tailscale is partially open source.</li></ul><p>In summary, Tailscale prioritizes peer-to-peer device connections with its architecture and SaaS model, while Narrowlink prioritizes self-hosted proxy access, ACL flexibility, customizability, and HTTP/S security at the potential cost of some performance depending on the gateway. Evaluate your specific needs to choose the right tool.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube-Dl Site Goes Offline as Hosting Provider Enforces Court-Ordered Ban (345 pts)]]></title>
            <link>https://torrentfreak.com/youtube-dl-site-goes-offline-as-hosting-provider-enforces-court-ordered-ban-230809/</link>
            <guid>37089545</guid>
            <pubDate>Fri, 11 Aug 2023 15:07:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/youtube-dl-site-goes-offline-as-hosting-provider-enforces-court-ordered-ban-230809/">https://torrentfreak.com/youtube-dl-site-goes-offline-as-hosting-provider-enforces-court-ordered-ban-230809/</a>, See on <a href="https://news.ycombinator.com/item?id=37089545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>

<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Lawsuits category archives." href="https://torrentfreak.com/category/lawsuits/"><span property="name">Lawsuits</span></a><meta property="position" content="2"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Apps and Sites category archives." href="https://torrentfreak.com/category/lawsuits/apps-and-sites/"><span property="name">Apps and Sites</span></a><meta property="position" content="3"></span> &gt; <span></span>
</p>
<p>
<span> </span>
Hosting provider Uberspace has taken down the website of YouTube-ripping software, youtube-dl. The removal is the result of a German court order in a copyright infringement lawsuit, filed by Sony, Warner and Universal. While Uberspace didn't host the open source software, it was held responsible for the website linking to the software hosted on developer platform GitHub.
</p>
</div><div>
<p><img decoding="async" src="https://torrentfreak.com/images/censored-300x220.png" alt="censortube" width="300" height="220" srcset="https://torrentfreak.com/images/censored-300x220.png 300w, https://torrentfreak.com/images/censored.png 960w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20220'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/censored-300x220.png 300w, https://torrentfreak.com/images/censored.png 960w" data-lazy-src="https://torrentfreak.com/images/censored-300x220.png">In 2020, the RIAA <a href="https://torrentfreak.com/riaas-youtube-dl-takedown-ticks-of-developers-and-githubs-ceo-201027/">infuriated</a> many players in the open source community by targeting YouTube-ripping tool, youtube-dl.</p>
<p>The RIAA sent a takedown notice to GitHub, claiming that the software bypassed technological protection measures, in violation of the DMCA. </p>
<p>GitHub initially complied but later changed course. After consulting legal experts, including those at the EFF, it <a href="https://github.com/ytdl-org/youtube-dl">restored</a> the <a href="https://youtube-dl.org/">youtube-dl</a> repository and launched a million-dollar defense fund to assist developers in similar disputes.</p>
<h2>Targeting youtube-dl’s Host</h2>
<p>This episode was a massive setback for the music industry, which had been fighting stream-ripping tools for years. However, instead of laying down their arms, Sony, Warner and Universal went after <a href="https://uberspace.de/en/">Uberspace</a>, youtube-dl’s website hosting company in Germany. </p>
<p>A German court previously ruled that stream-ripping software bypasses YouTube’s ‘rolling cipher’ download protection. This is seen as a circumvention of technical protection measures, a violation of intellectual property law in Europe. </p>
<p>Earlier this year this line of reasoning was also adopted by the district court of Hamburg. While the open source youtube-dl software is hosted on GitHub, Uberspace was <a href="https://torrentfreak.com/music-labels-win-legal-battle-against-youtube-dls-hosting-provider-230404/">held liable</a> as the host of the youtube-dl.org website because it linked to the developer platform. </p>
<p>In its defense, Uberspace argued that the protection can be circumvented using any regular web browser and in any case, the youtube-dl software has plenty of legal uses. These arguments failed to sway the court.</p>
<p>The court recognized that YouTube’s rolling cipher protection is far from perfect but concluded that it’s good enough to signal to average users that downloading content from YouTube is not permitted.</p>
<p>“[T]he average user must recognize that YouTube content, unlike media content on other websites, cannot be downloaded with a simple right-click and must be aware that this is achieved using technology on YouTube and that youtube-dl ‘overrides’ this protection. It is therefore to be assumed that the average user acts in bad faith,” the Hamburg Court <a href="https://openjur.de/u/2466945.html">wrote</a>.</p>
<h2>Ban Enforced</h2>
<p>The ruling was published in March but Uberspace wasn’t required to take action right away. The hosting company decided to appeal, which meant that the youtube-dl.org site remained online, unless the music companies posted a €20,000 bond.</p>
<p>Initially, it didn’t appear that the labels would enforce the order, but that changed a few days ago. The plaintiffs informed Uberspace that they had posted the security, leaving the company no other choice than to take the site offline. </p>
<p>Speaking with TorrentFreak, Uberspace owner Jonas Pasche says that his hands are tied. Failure to comply with the order would either result in a massive fine, or worse, a prison sentence.</p>
<p>“I received that information from the plaintiff’s side on July 27, with proof that they did the security deposit at a bank. So I no longer have a choice but to follow the judgment. Otherwise, I would face a fine of €250,000 or jail time,” Pasche notes.</p>
<center><img decoding="async" src="https://torrentfreak.com/images/youtube-host-block.jpg" alt="youtube-dl" width="600" height="282" srcset="https://torrentfreak.com/images/youtube-host-block.jpg 906w, https://torrentfreak.com/images/youtube-host-block-300x141.jpg 300w" sizes="(max-width: 600px) 100vw, 600px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20600%20282'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/youtube-host-block.jpg 906w, https://torrentfreak.com/images/youtube-host-block-300x141.jpg 300w" data-lazy-src="https://torrentfreak.com/images/youtube-host-block.jpg"></center>
<p>For several days, people who visited youtube-dl’s website saw a blocking notice instead, which is shown above. At the time of writing, the website doesn’t load at all. </p>
<h2>Appeal ‘Censorship’ Order</h2>
<p>Uberspace will continue the legal battle and is prepared to fight the order up to the highest court possible. If the appeal is successful, Pasche will gladly unblock the site.</p>
<p>“We are confident that a higher court will overturn the judgment of the Hamburg Regional Court, so we will be able to unblock the site as soon as this happens,” he says. </p>
<p>Uberspace is not the website’s domain registrar, so youtube-dl may yet decide to point its domain elsewhere. For now, that hasn’t happened. The software remains available <a href="https://github.com/ytdl-org/youtube-dl">on GitHub</a> where it also has a <a href="http://ytdl-org.github.io/youtube-dl/">dedicated website</a>.</p>
<p>The hosting company previously <a href="https://torrentfreak.com/youtube-dl-hosting-ban-paves-the-way-to-privatized-censorship-230411/">told us</a> that the Hamburg court’s ‘devastating’ order opens the door to privatized censorship, citing this threat as one of the main reasons to fight back.</p>
<p>“The consequences of this will be that hosting providers receiving complaints will most likely kick out their customers without a court ruling, for things that might be perfectly legal,” Pasche said at the time.</p>
<p>“This is a shameful day for the freedom of speech. It’s paving the way for privatized censorship. Do we as a society really want this? We strongly believe we’re on the right side of history here.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The crash of Air France flight 447 (2021) (158 pts)]]></title>
            <link>https://admiralcloudberg.medium.com/the-long-way-down-the-crash-of-air-france-flight-447-8a7678c37982</link>
            <guid>37089363</guid>
            <pubDate>Fri, 11 Aug 2023 14:53:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admiralcloudberg.medium.com/the-long-way-down-the-crash-of-air-france-flight-447-8a7678c37982">https://admiralcloudberg.medium.com/the-long-way-down-the-crash-of-air-france-flight-447-8a7678c37982</a>, See on <a href="https://news.ycombinator.com/item?id=37089363">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://admiralcloudberg.medium.com/?source=post_page-----8a7678c37982--------------------------------"><div aria-hidden="false"><p><img alt="Admiral Cloudberg" src="https://miro.medium.com/v2/resize:fill:88:88/2*pZPMtIONqtJYi2xHYD_Ivg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="f955"><em>Note: this accident was previously featured in episode 10 of the plane crash series on November 11th, 2017, prior to the series’ arrival on Medium. This article is written without reference to and supersedes the original.</em></p><figure><figcaption>Searchers recover the tail section of Air France flight 447 from the Atlantic on June 7th, 2009. (The Guardian)</figcaption></figure><p id="1d4b">In the early hours of the first of June 2009, Air France flight 447 from Rio de Janeiro to Paris disappeared in a radar dead zone over the mid-Atlantic. The Airbus A330 with 228 people on board had vanished into the night without a distress call, leaving behind little to explain its sudden and dramatic end. What could have brought down a modern passenger jet, flying for a world class airline, during what should have been the safest part of the flight? For two years, the world could only speculate, as search teams scoured a vast area of the ocean floor in search of the elusive black boxes.</p><p id="5a31">When the recorders were finally found in May 2011, they revealed a story at once more prosaic and more inexplicable than anyone had imagined. A brief interruption to their airspeed indications, lasting less than a minute, had thrown two trained Air France pilots into a state of paralyzed agitation. Through a series of increasingly misguided control inputs, they sent flight 447 plummeting towards the ocean, all the while trying desperately to understand what was wrong, only grasping too late that they themselves were the problem. How could such a thing happen? To this day, most people still struggle to understand it. But there is a reason, written between the lines of the cockpit voice recorder transcript, hidden away within the mysterious code that governs human behavior, a key to the secrets of the profoundly irrational. Its lessons could not be more important, even for those who believe themselves above the doomed crew of flight 447, as the boundary between the responsibilities of man and machine grows ever dimmer.</p><p id="fdfb">◊◊◊</p><figure><figcaption>A CGI image of flight 447 in its final hours. (PBS Nova)</figcaption></figure><p id="5f46">It’s 1:00 a.m., the middle of the Atlantic Ocean. 35,000 feet above the night-dark waves, dim overhead lights illuminate the cockpit of Air France flight 447. Captain Marc Dubois has headphones on, listening to opera. The pilot flying, First Officer Pierre-Cédric Bonin, stares dully at the instrument panel.</p><p id="cd58">Dubois hands Bonin his headset, and for a few moments they listen together. “All that’s missing is the whiskey!” Bonin eventually says, handing the headset back to his captain, one might imagine with a smile. Flight 447 flies on into the night. Red and green lights steady, white lights blinking. No one knows it, but they are passing into that strange realm between life and death, hurtling onward into the void, unaware that they have already walked for the last time among the living.</p><figure><figcaption>The pilots of flight 447, probably pictured in their license photos. (Original source unknown)</figcaption></figure><p id="8a2e">Three hours earlier in Rio de Janeiro, Brazil, 216 passengers and 12 crew boarded Air France flight 447 for an overnight flight to Paris. The plane was an Airbus A330, a fully fly-by-wire wide body jet with an impeccable safety record; since its introduction in 1994, the type had never had a fatal accident in passenger service. The flight crew consisted of 58-year-old Captain Marc Dubois, a veteran pilot with nearly 11,000 hours; 32-year-old First Officer Pierre-Cédric Bonin, an inexperienced copilot with 2,000 hours who had recently come up through Air France’s in-house training program; and 37-year-old Relief First Officer David Robert, who would fill in during the middle of the flight so that Captain Dubois could get his legally mandated rest. Robert had also learned to fly at Air France, but had since graduated to an executive position, and had joined the crew of flight 447 in order to keep his type rating. His landing in Rio de Janeiro during the inbound trip was his first in three months.</p><figure><figcaption>The route of flight 447. (Google + own work)</figcaption></figure><p id="0e24">For Air France pilots, the Rio de Janeiro rotation was a coveted trip, complete with a three-day layover at a beachside hotel in Copacabana. Pilots often spent their rest days partying, sightseeing, and restaurant-hopping. First Officer Bonin had brought his wife along for the ride, leaving their kids at home in France; Captain Dubois had also brought his girlfriend, an off-duty flight attendant and opera singer, with whom he had been seen out on the town the night before the flight. Dubois was said to have gotten just one hour of sleep before boarding flight 447.</p><p id="66c9">Although none of the pilots were well-rested, they also knew that their advanced plane could bail them out. Unlike older generations of jets, the A330 was designed to minimize the consequences of crew errors, incorporating flight envelope protections that would make it impossible for the pilots to pitch too steeply up or down, fly too fast or too slow, bank too far to one side, or generate G-loads that could overstress the airframe. Furthermore, thanks to the plane’s advanced flight management system, they could enter the entire flight plan before departure, and the plane would all but fly itself from just after takeoff until right before landing. The pilots’ job primarily consisted of tactical decision-making and monitoring the instruments.</p><figure><figcaption>F-GZCP, the aircraft involved in the accident. (Hansueli Krapf)</figcaption></figure><p id="f270">Flight 447 took off from Rio de Janeiro at 22:29 UTC, climbed to its cruising altitude of 35,000 feet, and proceeded northeast up the coast of Brazil. Bonin was the pilot flying, although he had little reason to touch the controls, and Dubois monitored the instruments. David Robert hung back in the crew quarters, trying to get some sleep before going on duty.</p><p id="c62d">As the flight passed off Natal and headed out into the Atlantic, the pilots mostly kept to themselves. Dubois pointed out the equator, and Bonin joked about “feeling the bump” as they passed over it. An hour passed. Everything seemed to be going smoothly.</p><p id="691f">At around 1:30 a.m. UTC, the Brazilian oceanic control center, Atlantico, contacted the crew and instructed them to remain at flight level 350–35,000 feet. “Eh, well there you are,” said Captain Dubois. Keying his mic, he replied to the controller, “Okay, will do.” It would be flight 447’s last communication with the outside world.</p><p id="7959">First Officer Bonin had been using the cockpit weather radar to observe a growing band of thunderstorms in their path, a region known as the Intertropical Convergence Zone, where thunderstorms are practically a permanent fixture. All the pilots on flight 447 had flown through it many times before, crossing over it twice on every trip to South America. But tonight Bonin seemed more nervous than usual. “We’ll soon ask to climb, surely,” he said, expressing his dissatisfaction with the controller’s order to stay at 35,000 feet, and his desire to get above the worst of the weather.</p><figure><figcaption>Satellite weather data from the Intertropical Convergence Zone at around midnight on the night of the accident, with flight 447’s designated airway overlaid. (BEA)</figcaption></figure><p id="a697">But Captain Dubois knew that there was no need to change altitude. In his judgment the weather was unlikely to be any better at 37,000 feet, the highest they could fly at their current weight, nor was it likely to be dangerous at any flight level. At most they could expect some mild turbulence or icing. And if they really needed to, then they could divert around it.</p><p id="3fba">“So we’ve got a… thing straight ahead,” Bonin said, sounding nervous.</p><p id="b6f3">“Yes, I saw that,” said Dubois.</p><p id="e82b">Eleven minutes later, Bonin said, “It looks like we’re entering the cloud cover.”</p><p id="37d2">Dubois had no comment.</p><p id="1128">“It would have been good to climb now, eh?” Bonin said.</p><p id="03ae">“Yeah, if it’s turbulence,” Dubois said, without the slightest hint of worry.</p><p id="9eba">Now deep in the oceanic sector, the plane was outside the radar range of any airport. Out here, planes were kept apart by keeping northbound traffic on odd flight levels and southbound traffic on even flight levels. But the next highest odd level, 37,000 feet, was close to their maximum altitude — maybe too close. Bonin suggested that they request a non-standard altitude of 36,000 feet.</p><p id="3aae">“We’ll wait a little, see if it goes that way,” Dubois replied.</p><p id="851e">Bright flashes of light streaked across the windscreen, the eerie glow of St. Elmo’s fire. The sound of ice crystals hitting the plane rose to a dull roar in the background.</p><figure><figcaption>St. Elmo’s Fire in an aircraft cockpit. (Beyond Clouds)</figcaption></figure><p id="66d7">At this point Captain Dubois decided it was time to turn in for the night. He rang the call button to summon First Officer Robert from the bunk room. To Bonin, he said, “Er, who’s doing the landing, is it you? Well, he’s going to take my place. You’re a PL, right?”</p><p id="211c">“Yeah,” said Bonin.</p><p id="36e8">This was the closest Dubois ever came to deciding who would be in command after he left the flight deck.</p><p id="d0da">Two minutes later, Robert entered the cockpit. “Did you sleep?” Bonin asked.</p><p id="3c09">“So-so,” Robert replied.</p><p id="f4e5">“You didn’t sleep?” Dubois interjected.</p><p id="7109">“He said so-so, so-so,” said Bonin.</p><p id="cf81">“Well, then I’m out of here,” said Dubois.</p><p id="ebd6">Bonin briefed Robert on the situation: they were cruising at 35,000 feet, there was a storm ahead but they couldn’t climb to 37,000. Their attempt to log on with the oceanic control system in Dakar, Senegal had failed, but this was not an uncommon occurrence and Bonin knew it. All around, nothing terribly unusual. Robert settled in for the next leg of the flight.</p><p id="07b4">About six minutes later, noting the storm cell in their path, Robert said, “Don’t you maybe want to go to the left a bit?”</p><p id="67ea">“Excuse me?”</p><p id="21a9">“You can possibly go a bit to the left,” Robert repeated.</p><p id="1b96">With two first officers in the cockpit, and the less experienced one at the controls, it was unclear who was in charge. Decisions seemed to be taken by mutual agreement. Bonin never replied to Robert’s suggestion, so nothing was done.</p><p id="c110">Now a smell of ozone started to seep into the cockpit, a not unusual phenomenon when flying through highly charged thunder clouds. But Bonin didn’t seem to recognize it, and it was making him nervous. The ozone, the Saint Elmo’s fire, the storms — none of it was out of the ordinary for a transatlantic crossing, but for some reason it was starting to get to him.</p><figure><figcaption>How ice blocks a pitot tube and affects airspeed readings. (boldmethod)</figcaption></figure><p id="7820">For the past several minutes, they had been flying through a cloud of high-altitude ice crystals within the upper reaches of the thundercloud. Normally this would not be a problem, but if the concentration of crystals is high enough, they can clog the pitot tubes — the airspeed sensors — faster than the built-in heaters can melt them. This is what occurred on flight 447.</p><p id="9cd1">The A330 has three pitot tubes, one each for the captain, the first officer, and the standby instruments. Each pitot tube measures the pressure of the oncoming air, which is then compared to the static pressure to derive the plane’s airspeed. This data in turn is used to calculate a number of other parameters, including Mach number, vertical speed, and altitude, which are all displayed instantaneously to the pilots. But if ice crystals clog the pitot tubes, air cannot enter them, causing the measured pressure to drop, which in turn causes a decrease in indicated airspeed.</p><p id="db2a">On flight 447, as all three pitot tubes filled up with ice, the airspeed readings quickly became invalid. Sensing a growing discrepancy between the three sources of airspeed data, at 2:10 a.m. and four seconds the autopilot disconnected with a sudden cavalry charge warning. The auto thrust shut off a split second later. Taken completely by surprise, First Officer Bonin announced, “I have the controls!” and reached for his side stick.</p><figure><figcaption>The principle of the “flight envelope.” (Philippe Goupil)</figcaption></figure><p id="2f79">Behind the scenes, the loss of valid airspeed data had triggered a shift in the Airbus’s complex flight control laws. In “normal law,” computers interpret pilots’ side stick inputs and move the control surfaces in accordance with what is reasonable at that altitude, speed, and configuration. This improves the handling of the airplane to such an extent that no particular skill is required to fly it gracefully. Normal law also comes with full flight envelope protections in roll, pitch, speed, and load factor.</p><p id="60d2">If sensor failures occur, the controls drop down a level to “alternate law.” This law contains several sub-laws with slightly different configurations, but in general, alternate law means that some or all computer moderation of control inputs remains, but flight envelope protections are removed. The autopilot and auto thrust cease to function.</p><p id="9209">In the event of further failures, the controls can enter direct law, in which there are no flight envelope protections and side stick inputs correspond directly to the position of the control surfaces, with no adjustment by the computer. This makes the airplane fly rather like a classic airliner, similar to most older Boeing models.</p><p id="1f51">When the airspeed readings became invalid on flight 447, the control law changed to “alternate 2B,” which is specific to loss of speed data. In this law, load factor protection remains, but there is no autopilot, no auto thrust, and no high or low speed protection; furthermore, lateral (roll) control functions as it does in direct law. All of this happened near instantaneously, leaving the pilots completely in control of the airplane with little advance warning.</p><p id="1809">As soon as the autopilot disconnected, turbulence caused the plane to roll eight degrees to the right; Bonin immediately grabbed the side stick and rolled it back to the left, his inputs rough and jerky. At the same time, he pulled back on the stick, putting the plane into a climb. The A330 began to ascend rapidly from its cruise altitude of 35,000 feet, zooming upward through the impenetrable blackness, as multiple alarms blared over the cockpit speakers.</p><figure><figcaption>How a stall works. (NASA)</figcaption></figure><p id="b9b7">Climbing while at high altitudes above 30,000 feet is something that requires care and consideration. At these altitudes, a plane’s maximum safe speed and minimum safe speed are quite close together (and at a certain height they will in fact meet, a zone that pilots call the “coffin corner”). Fundamentally, as angle of attack — the angle of the plane into the airstream — increases, lift increases, until it reaches the critical point and drops off rapidly, causing the plane to stall. Because the air is thin at high altitude and provides little lift, a higher speed is necessary to keep the plane airborne, and the critical angle of attack is very low. Pitching up even a few degrees could place the plane on the edge of a stall. And in fact, as Bonin pulled back on his stick, the plane’s stall warning activated for three seconds, informing him that the angle of attack, for a moment anyway, was dangerously high.</p><figure><figcaption>Flight data from the first 20 seconds after the start of the event. (BEA)</figcaption></figure><p id="7375">But the warning proved transient, and neither pilot recognized it. Robert asked, “What was that?”</p><p id="45b1">Bonin did not directly address the question. “We haven’t got a good… we haven’t got a good display of speed,” he said. A continuous C-chord pinged away in the background, warning that they had left their assigned altitude.</p><p id="134f">A number of warning messages had appeared on the computer screen, and Robert began to read them off in a disjointed, confused manner. None of them explicitly stated the cause of the failure, only the symptoms, including the disconnection of the autoflight systems and the switch to alternate law. By now, flight 447 was climbing through 37,000 feet, still going up, but decelerating alarmingly.</p><p id="49fb">Robert must have noticed their high pitch angle, because he said to Bonin, “Watch your speed, watch your speed!” But neither pilot had a valid airspeed reading.</p><p id="6272">“Okay, okay, okay, I’m going back down,” said Bonin, lowering the nose. But he didn’t lower it enough to stop climbing, and he reduced engine thrust, exacerbating the loss of airspeed even further.</p><p id="d7ca">“Go back down! According to that we’re going up,” Robert said, presumably pointing at their altitude readout. “According to all three you’re going up, so go back down.”</p><p id="8b43">“Okay.”</p><p id="a5bd">“You’re at… go back down!”</p><p id="908c">“It’s going, we’re going back down,” Bonin insisted, restoring engine thrust to maximum. But the plane kept climbing.</p><p id="1f90">Robert started switching Bonin’s instruments to alternate sources, but in a wholesale manner, indicating that he had not identified what instruments were actually faulty. Having done this, he started trying to summon Captain Dubois, ringing the call button with almost frenetic urgency. Clearly both pilots were in over their heads; only Dubois, it seemed, could help them. By now the airspeed indications had returned to normal, but the pilots had already set in motion a sequence of events which could not be undone.</p><figure><figcaption>Flight data from 46 seconds after the start of the event to 106 seconds after the start of the event. (BEA)</figcaption></figure><p id="c472">At that moment the plane’s angle of attack, now rising through ten degrees, again triggered the stall warning, and this time it didn’t go away. Accompanied by continuous clicking, an automated voice began to call out, “STALL! STALL!”</p><p id="96a3">Flight 447 reached a peak altitude of 38,000 feet, stalled, and began to descend. Nose high, engines straining, the plane started to accelerate downward, following a long descending arc that grew steeper with every passing second.</p><p id="b180">“STALL! STALL!”</p><p id="058c">Bonin was frantically trying to keep the wings level, but the disrupted airflow and his own jerky control inputs made this all but impossible. The plane swayed wildly from side to side, reaching bank angles of up to forty degrees. “Above all, try to touch the lateral controls as little as possible, eh?” Robert suggested.</p><p id="858f">“STALL! STALL!”</p><p id="9335">“I’m in TOGA, eh?” Bonin said, referring to takeoff/go around, the highest normal thrust setting. He didn’t seem to understand why, if he had engine power set to TOGA, they were descending.</p><p id="e87e">“Is he coming or not!?” Robert said, searching for some sign of the captain.</p><p id="545b">“STALL! STALL!”</p><p id="f8ba">“But we’ve got the engines, what’s happening?” Robert exclaimed. “Do you understand what’s happening or not?”</p><p id="faf9">“STALL! STALL!”</p><p id="c0cc">“I don’t have control of the airplane anymore now!” said Bonin. “I don’t have control of the airplane at all!” With the nose pitched up and the engines at max thrust, he simply couldn’t fathom why they weren’t climbing. Overwhelmed by the noise of the warnings, the terrifying vibrations, and the wildly fluctuating instrument readings, his brain seemed to shut down, paralyzed by confusion and fear.</p><figure><figcaption>A very basic diagram like this would have probably helped the pilots understand what the plane was doing. (Flying Magazine)</figcaption></figure><p id="d6ef">By now the plane was falling toward the ocean at a rate of 10,000 feet per minute, and accelerating. The angle of attack was more than forty degrees. The only way to recover was to push the nose down, regain airspeed, and then pull out at a lower altitude. But Bonin just kept pulling his side stick back, forcing the nose up.</p><p id="a0ee">“Controls to the left,” Robert said, still worried about their bank angle. Pressing the priority button on his side stick, he took control and locked out Bonin, but Bonin immediately pressed his own priority button and assumed control again.</p><p id="e752">“STALL! STALL!”</p><p id="36ba">Bonin said something which might be best translated as, “I have the impression that we’re going crazy fast.” His impression couldn’t have been further from the truth.</p><p id="b233">At that moment, Captain Dubois returned to the cockpit to find a scene of chaos. “Er, what are you doing?” he said, glancing around in an attempt to figure out what was going on.</p><p id="1d82">“What’s happening?” Robert asked. “I don’t know, I don’t know what’s happening!”</p><p id="cb00">“We’re losing control of the airplane,” said Bonin.</p><p id="6738">“We lost all control of the airplane, we don’t understand anything, we’ve tried everything!” Robert said, desperation in his voice. But in fact they had tried nothing at all.</p><p id="fdc3">“STALL! STALL!”</p><p id="ce0e">“I have a problem, it’s that I don’t have vertical speed indication,” said Bonin. His vertical speed indicator was working perfectly; he just didn’t believe what it said. “I have no more displays!” he opined, although again, all indications were correct and all his instruments were working.</p><p id="dc63">“We have no more displays!” Robert repeated.</p><p id="39a4">“I have the impression that we have some crazy speed, no?” Bonin said. “What do you think?”</p><p id="3913">“STALL! STALL!”</p><p id="7cbe">“So we’re still going down,” Bonin said.</p><p id="c627">“We’re pulling,” said Robert. “What do you think about it, what do you think — what do we need to do?”</p><p id="dba7">“There — I don’t know, it’s going down!” said Dubois. He had made no effort to assume control, continuing to look over his first officers’ shoulders instead.</p><p id="ed5c">As the plane plummeted toward the Atlantic Ocean, the pilots only became more confused and agitated. Recovery was already impossible; the fates of all on board were carved in stone. All that followed was a final, terrible fight to the death.</p><p id="e9ea">“The wings to flat horizon, the standby horizon!”</p><p id="bd2e">“The horizon!”</p><p id="eabb">“Speed?”</p><p id="00e3">“You’re climbing!”</p><p id="6d1e">“You’re going down, down, down!”</p><p id="2161">“Am I going down now?”</p><p id="fb74">“Go down!”</p><p id="2bcd">“No, you’re climbing!”</p><p id="1668">“I’m climbing, okay, so we’re going down!”</p><p id="7b1b">“STALL! STALL!”</p><p id="24cb">“Okay what are we here? On altitude, what do we have here?”</p><p id="f522">“…It’s impossible,” Captain Dubois said, completely baffled.</p><p id="bfb6">“STALL! STALL!”</p><p id="5bff">“What do you mean, on altitude?</p><p id="0a90">“Yeah yeah yeah, I’m going down no?”</p><p id="1954">“You’re going down, yes!”</p><p id="ba24">“Hey you, you’re in — get the wings horizontal!”</p><p id="b604">“Get the wings horizontal!”</p><p id="3ad0">“That’s what I’m trying to do! I’m at the limit with the roll!”</p><p id="9601">“We lost it all! I’ve got nothing here!”</p><p id="5f6b">“We’re there, we’re passing level 100!” Flight 447 was falling through 10,000 feet, still deeply stalled, headed straight into the jaws of oblivion.</p><p id="8381">“Wait, me — I have the controls!” Robert said. But Bonin didn’t stop pulling up.</p><p id="e18a">“What is… how come we’re continuing to go down right now?” Bonin asked.</p><p id="2435">“STALL! STALL!”</p><p id="4601">“Nine thousand feet!” Bonin cried out.</p><p id="e45d">“Climb, climb, climb, climb…” Robert said, as though trying to will the plane to stop falling.</p><p id="4d76">“But I’ve been at maximum nose up for a while!” said Bonin.</p><p id="c7ba">It was at that point that Captain Dubois finally understood what was happening. “No no no, don’t climb!” he shouted. But it was already much too late to intervene. Not even the most skilled pilot on earth could have saved them.</p><figure><figcaption>CGI animation of the stall and crash. (Mayday)</figcaption></figure><p id="c7cb">These final moments of Air France flight 447 would go down in aviation history as some of the most tragic and the most baffling.</p><p id="36cb">“So go down!” said Robert. “So give me the controls, the controls to me, controls to me!”</p><p id="47e5">“Go ahead, you have the controls!” said Bonin.</p><p id="a3b7">“STALL! STALL!”</p><p id="34eb">“Watch out, you’re pitching up there!” said Dubois. Incredibly, both Bonin and Robert were still hauling back on their side sticks.</p><p id="082a">“I’m pitching up,” said Robert.</p><p id="8003">“You’re pitching up!” Dubois shouted.</p><p id="e1b3">“Well we need to, we are at four thousand feet!” said Bonin. It was true, it was far too late to recover by pitching down. Not that it would matter anyway.</p><p id="a943">“PULL UP,” said the ground proximity warning system. “PULL UP! PULL UP!”</p><p id="4e23">“Go on, pull,” Dubois said. Was this comment a sardonic resignation to fate?</p><p id="1120">“PULL UP! PULL UP!”</p><p id="dcf5">“We’re going to crash!” Bonin cried out. “This can’t be true! But what’s happening?”</p><p id="d8af">“PULL UP! PULL UP!”</p><p id="c667">“Ten degrees pitch attitude,” Dubois drily commented. His would be the last words on the cockpit voice recording. Less than two seconds later, with a forward airspeed of just 107 knots and a descent rate of 11,000 feet per minute, Air France flight 447 slammed belly-first into the Atlantic Ocean. In a fraction of a second, like so many candles, 228 lives flickered and went out.</p><p id="0351">◊◊◊</p><figure><figcaption>A map from early in the search on the day of the crash. (BBC News)</figcaption></figure><p id="83a9">It would not be until 4:00 a.m. UTC, nearly two hours after the crash, that controllers in Senegal began to realize that they should have heard from Air France 447, but had not. They tried everything — contacting nearby control centers, asking other planes, asking Air France — but no one had spoken to flight 447 since shortly before 2:00 in the morning. At 4:59, having tried and failed to establish contact with flight 447 via satellite, an Air France dispatcher told the Dakar control center that something must be seriously wrong. 24 minutes later, fearing that the plane had gone down in the Atlantic, Brazil and Senegal issued an alert to rescue services, and the search for the plane began.</p><p id="cec1">The problem was that Air France flight 447 had apparently vanished within an area that had no radar coverage, no possibility of witnesses, and only spotty radio contact. No one knew exactly when or where the plane went down, and with each passing hour, any floating debris would drift farther from its point of origin. By the time the first search planes actually departed, more than ten hours had passed since the crash, and the debris was already scattering.</p><figure><figcaption>A Brazilian newspaper front page shows the faces of some of the missing. (Vanderlei Almeida)</figcaption></figure><p id="3b98">Meanwhile, investigators with France’s Bureau of Inquiry and Analysis (BEA) set up an elite team to investigate what promised to be the most complicated and most important accident in the history of French aviation. Although they didn’t have the airplane, they didn’t start with nothing: like all modern aircraft, the Airbus A330 regularly broadcasts data to the airline for diagnostic purposes. This system, known as ACARS, sent a burst of data approximately every ten minutes, with additional messages if certain warning conditions were met. The last regular message, sent at 2:10, indicated that there was a problem with the pitot-static system, the autopilot had disengaged, and the controls were in alternate law. Several additional messages sent between 2:10 and 2:14 indicated faults with the Air Data Reference units, the computers which process airspeed, and an abnormally high rate of descent. It was just enough to prompt speculation, but not enough to explain what had happened, or why.</p><figure><figcaption>A map of the surface search and its discoveries. (The New York Times)</figcaption></figure><p id="4123">One thing that investigators suspected from the very beginning was a problem with the pitot tubes. At the time of its disappearance, flight 447 was flying through storms in the intertropical convergence zone, the perfect conditions for pitot tube icing. This particular model of pitot tube had been shown on several occasions to experience ice accumulation greater than the heaters could remove, leading to a loss of airspeed data. In fact, Air France, Airbus, and the pitot tube manufacturer had been holding meetings on the matter since 2008, and earlier in 2009 a study had shown that a newer model of Thales pitot tube could significantly reduce the frequency of such incidents. Air France quickly ordered the new pitot tubes for all of its Airbus A330s, and the first airplane was retrofitted on May 30th, just hours before Air France flight 447 left Rio de Janeiro. Although the airline had been proactive, their efforts came ever so slightly too late for the 228 passengers and crew now presumed lost at sea.</p><figure><figcaption>Searchers recover the tail section of Air France flight 447 from the Atlantic on June 7th, 2009. (The Guardian)</figcaption></figure><p id="6baf">But to know how exactly frozen pitot tubes, a relatively minor malfunction, could have led to the catastrophic crash of a wide body jet with a flawless record, investigators needed the black boxes. Everyone knew that they would be hard to find — but few could have guessed just how difficult it would turn out to be.</p><p id="490d">By the afternoon of June 1st, French officials had already acknowledged that there was “no hope for survivors,” but the scope of the sea search only continued to increase. On June 2nd, a Brazilian plane spotted an apparent oil slick and light floating debris; on the 6th of June, two bodies were found, along with personal effects, and the plane’s vertical stabilizer was located on the 7th. In all, by the end of June searchers had found over 600 pieces of the airplane and the bodies of 50 victims, including Captain Dubois. Engineering analysis of the debris and autopsies of the victims revealed that the plane had impacted the water in a nearly flat pitch attitude with a high rate of descent, but again, investigators couldn’t say why. The answers, as ever, lay with the flight recorders.</p><figure><figcaption>Another view of the recovery of the tail section. (France24)</figcaption></figure><p id="1148">The A330’s two black boxes were equipped with pingers that could be detected by specialized equipment, but the batteries which powered the pingers were only rated to last 30 days. Although authorities moved quickly to bring in search ships capable of detecting the pingers, their chances of finding the black boxes inside the 30-day window were slim. With the plane likely resting at a depth of up to 4,000 meters, surface vessels would need to get very close to the site of the wreckage in order to pick up the signal, and with no radar record, it was impossible to know with any specificity where the plane had actually entered the water. It was unfortunately no surprise that the 30-day period went by with no sign of the black boxes.</p><p id="24d3">At that point, the search entered its third phase: a methodical sonar examination of an area extending 75 kilometers in all directions from the plane’s last known position, as reported by ACARS. Carried out between April and May 2010, this search failed to turn up any sign of the plane. All data indicated that the plane should have been within the search area, but covering every square kilometer in detail was difficult, and a more precise search would be needed.</p><p id="6695">The fourth phase began in the spring of 2011, focusing on areas not covered by the previous search within a limited 37-kilometer radius around the last known position. This search began on the 25 of March, and had been in progress for just seven days when sonar imagery detected the presence of a large debris field on the ocean floor. On the 3rd of April, a submarine equipped with a camera reached the debris field, returning images that left investigators speechless: after nearly two long years, there lay Air France flight 447, shattered on the barren floor of the abyssal plain, four kilometers beneath the Atlantic.</p><figure><figcaption>(BEA)</figcaption></figure><p id="93be">Examining the debris field inch by inch, searchers managed to find the flight recorders by the beginning of May, followed soon after by several substantial chunks of wreckage and the bodies of a further 104 passengers and crew. Another 74 bodies were never found, having apparently been lost to the sea.</p><p id="d481">The much-anticipated readout of the black boxes occurred at the BEA headquarters in Paris in May 2011. At long last, investigators listened, transfixed, to the voices of the doomed crew on that fateful night in 2009 — voices that some had doubted they would ever hear. But as those haunting conversations played out over the two hour tape, it became clear that the black boxes would raise just as many questions as they answered.</p><figure><figcaption>Photos of various parts of the airplane as they were found on the ocean floor. (BEA)</figcaption></figure><p id="4e88">By integrating the cockpit voice recorder and the flight data recorder, investigators were able to show that at the moment the airspeeds became invalid and the autopilot disconnected, First Officer Pierre-Cédric Bonin began to pull back on his side stick, raising the nose, and that he maintained this input almost continuously until impact. The data was indisputable; Bonin had stalled the airplane, sending it to its doom. But this explanation in fact explained very little. Every airline pilot should know that such inputs will lead to a stall, so why did Bonin seem to be oblivious to the danger?</p><figure><figcaption>The tail section of flight 447 is hauled aboard a salvage ship. (NBC News)</figcaption></figure><p id="01b8">Answering this question proved to be by far the most complicated part of the entire investigation. Understanding what went through the minds of the pilots requires a second-by-second analysis of the final four minutes of the flight, considering all of the disparate cues which each pilot was trying to assimilate.</p><p id="db4b">But first, it is critical to understand who Pierre-Cédric Bonin was as a pilot. In the popular consciousness, a pilot is a semi-heroic figure who flies a plane by hand, guiding it through all manner of dangers. Bonin was perhaps living proof that this type of pilot has not existed for decades.</p><p id="9e70">In fact, the job of a modern pilot on a plane like the A330 is far more abstract. The average A330 pilot will hand-fly an airplane for maybe four minutes out of every flight, and will pilot only two or three flights a week, sometimes fewer. The vast majority of their time is spent programming automation, monitoring computer activity, and making broad, tactical decisions about the flight. Physical skill is far less important than emotional intelligence, good memory, and an ability to communicate. And on a highly automated plane like the A330, it’s all but impossible to discover who possesses such physical skill in the first place.</p><figure><figcaption>Investigators lay out the recovered debris on the floor of a hangar for identification and analysis. (Der Spiegel)</figcaption></figure><p id="e26c">Physical, or traditional, piloting skills are typically developed through extensive experience flying small aircraft which have little or no automation. These aircraft force a pilot to develop an intuitive understanding of how airplanes behave in various regimes of flight, and anyone who cannot develop these skills will wash out at an early stage. Captain Marc Dubois no doubt had these skills: between 1977 and 1987, he obtained type ratings on no less than 17 different light aircraft and accrued thousands of hours flying them. If he had been in the pilot’s seat when the airspeed indicators failed on flight 447, there is little doubt that he would have reacted correctly: he surely had an intuitive understanding that, in the absence of any configuration changes, the plane will continue to fly on its previously established trajectory, even if all the instruments are lost — a sort of airman’s object permanence. He would have known that all he needed to do was nothing.</p><figure><figcaption>The tail section is loaded onto a truck in port for transportation to the evidence hangar. (CNN)</figcaption></figure><p id="5af4">Bonin, on the other hand, had a completely different background. He had followed a fast-track trajectory to the right seat of the Airbus A330, flying small planes just long enough to get his private and air transport pilot’s licenses before being inducted into Air France with just a couple hundred flight hours. He was immediately trained to fly the advanced fly-by-wire Airbus A320, before upgrading to the Airbus A340 and finally the A330, all of which were heavily automated. Any rudimentary “traditional” skills which he had gained during his brief time flying light aircraft would have quickly degraded. Although Bonin would have learned about the principles of aircraft dynamics in a classroom setting, such instruction is an order of magnitude less valuable than getting to feel the principles in action while at the controls of a fully mechanical airplane. Instead, he spent the next 2,000 flight hours watching as computers flew the jet on his behalf. His total time actually hand-flying an airliner couldn’t have been more than a couple dozen hours, all of them within the bounds of the flight envelope protections, which he knew made it impossible for him to lose control. If you asked him, Bonin probably could have told you what a stall is and how it works, but could he have identified one in real life?</p><figure><figcaption>A floating galley section was found, complete with intact drawers. (Reuters)</figcaption></figure><p id="2579">The extent of his stall-related training leaves room for doubt. Air France did not train its pilots on prevention or recovery from high altitude stalls, even though these have several fundamental differences from low-altitude stalls. If the stall warning activates during the initial climb away from an airport, a scenario which Bonin practiced many times in the A330 simulator, it is possible to avert the stall by applying maximum thrust and maintaining a nose up attitude of about twelve degrees. The denser air closer to sea level ensures that the plane is stable in such a configuration. But at 35,000 feet, this will not work: pitch angles as low as four or five degrees will be sufficient to activate the stall warning, and an actual stall will follow soon after.</p><p id="b21a">However, all of that is hypothetical, because nearly all of the time, Airbus aircraft cannot stall. The flight envelope protections simply will not allow any inputs which raise the angle of attack above the critical point, and with these protections in place, there isn’t even a stall warning, because a stall will not and cannot occur. A pilot can haul back on the side stick with all their might, and the plane will rear up to whatever angle the algorithms determine is safe. Nothing the pilot can do will make it pitch up more.</p><p id="3bf0">With these facts in mind, consider the scenario actually faced by the crew of flight 447. They were at high altitude where even a mild nose up input could quickly escalate into a stall. Bonin and Robert were probably only vaguely aware of this fact, which was rather esoteric in an environment where the flight envelope was clearly limited (although it was their duty to know it). And then suddenly all the protections vanish, as the loss of airspeed data forces the controls to slip into alternate law. After all, the computer can’t protect against a stall if it doesn’t know how fast the plane is going. Does Bonin know that the plane is in alternate law? And if he does, does he understand what that means? In theory it’s his job to know, but he doesn’t.</p><figure><figcaption>The complex interrelationship between measured and calculated flight parameters. (BEA)</figcaption></figure><p id="0355">At the moment that the airspeed data became invalid, a curious quirk of the plane’s internal calculations might have set the whole sequence of events in motion. Because of the location of the A330’s static ports, which measure the basic outside air pressure, the reading is somewhat affected by the plane’s airspeed, due to leakage of rushing air into the ports. Generally this results in a slightly elevated static pressure reading. Because static pressure increases as altitude decreases, this design quirk would cause the sensor to continually underestimate the plane’s altitude. To account for this, an algorithm applies a small correction to the static pressure reading based on the airspeed reported by the pitot tubes, in the process correcting the altitude to its true, higher value. But if the pitot tubes suddenly start reporting an erroneously low airspeed — say they’re blocked by ice — the size of the applied correction will be smaller, and the plane’s indicated altitude will decrease, even though it is in fact flying straight and level.</p><figure><figcaption>A recovery worker prepares the galley section for salvage. (The Guardian)</figcaption></figure><p id="9004">Consequently, at the moment the pitot tubes froze on Air France flight 447, the indicated altitude dropped by about 350 feet, and the vertical speed indicator briefly displayed a descent rate of 600 feet per minute. Bonin didn’t comment on these figures, so we can’t prove that he saw them. But if he did, it would explain his initial decision to pull the nose up: he probably thought the airplane was descending. And what did he think would happen if he pulled the nose up? Most likely, that the plane would climb at a protected angle, safely below the stall margin, no matter how hard he pulled back on the stick or how long he held it there. There was no need for such an extreme input, but it seems he was caught by the startle effect, feeling compelled to take drastic action, but without understanding what form that action should take, and believing that the computer would bail him out if he did something wrong.</p><p id="5538">It is somewhat more difficult to explain why Bonin kept pulling on the stick even after his instruments showed the plane passing back through its initial cruise altitude and continuing toward 37,000 feet. But his comments earlier in the flight, in which he repeatedly expressed a desire to climb above the weather, provide a possible reason. If he thought the plane would be out of the clouds at around 37,000 feet, and if he was concerned about the possibility of turbulence or other severe conditions inside the storm, his first instinct upon seeing the cascade of warnings might have been to try to escape from the area of bad weather. Perhaps he wanted to climb as high as the plane would let him, not knowing that all such protections had been withdrawn.</p><figure><figcaption>Another part of the galley was used to prove that the plane hit the water in a flat attitude. (BEA)</figcaption></figure><p id="6a2e">At the same time, there is considerable evidence that Bonin was more concerned about flying too fast than he was about flying too slow. Pilots in general were aware, to an almost superstitious extent, that exceeding the maximum operating speed could lead to the breakup of the airplane in flight, and that at high altitudes this maximum speed was not that much faster than the normal cruising speed. In fact, on an Airbus operating in normal law, the airspeed indicator in front of each pilot displays markers representing the maximum and minimum allowable speeds (as defined by the flight envelope protections), and the actual speed in cruise is usually much closer to the former than the latter. Many pilots, including Bonin, had probably developed a false belief that overspeed was a more pressing danger than stalling. In fact, it’s the other way around: in the 20 years leading up to the crash of flight 447, there had been considerably more crashes involving high-altitude stalls than crashes involving overspeed-related breakup.</p><p id="1e5a">In light of these assumptions, when Bonin saw the plane appearing to descend in the first seconds after the failure, his instinctive reaction may have been to protect the plane against entering an overspeed condition. Furthermore, when the max/min speed markers disappeared during the transition to alternate law, his sense of where these boundaries lay became uncertain. This uncertainty, and the irrational fear of flying too fast, may have pre-conditioned him to ignore cues which indicated that he was actually flying too slowly.</p><p id="4af9">It is also worth noting that Bonin and Robert had both undergone training on unreliable airspeed events, during which pilots were instructed to adopt a known power setting and pitch angle which would result in a stable flight path. However, much like the stall training, it was assumed that the most critical unreliable airspeed scenario is one which occurs at low altitude during initial climb. Although procedures for other phases of flight could be found in the manual, the training conditioned pilots to expect unreliable airspeed events during climb, to which they would respond with a steady nose-up pitch and high power setting that would ensure a shallow ascent. Such a response would be completely inappropriate in cruise.</p><figure><figcaption>A reconstruction of the warning messages the pilots would have seen during the event. (BEA)</figcaption></figure><p id="2f91">Investigators found that because of this conditioning, in a dozen or so previous cases of unreliable airspeed in cruise on the Airbus A330 and the similar A340, not a single crew had correctly identified the anomaly and applied the stabilization procedure. In one case, the pilot even applied nose-up inputs which triggered a stall warning, although deviation from the flight path was ultimately minimal. Therefore Bonin and Robert were not the exception in failing to initially identify the cause of the malfunctions and apply the known solution. In all of these cases, part of the problem was that in the actual events, the loss of speed data was accompanied by a series of alarms and warning messages which were not present in the simulator scenarios, and none of these messages explicitly stated that there was a problem with the pitot tubes, contributing to pilots’ difficulty identifying the root cause.</p><figure><figcaption>Debris lies of the floor of the hangar following recovery from the sea surface. (CNN)</figcaption></figure><p id="c7bf">Having pitched their plane up to the very brink of a stall, Bonin and Robert could have saved the day by reacting correctly to the stall warning which began to sound as the plane approached 38,000 feet. There are however several possible reasons why they ignored it. One is that their minds were already so saturated with information that they simply never heard it. Instrument indications were seemingly going haywire, nobody knew what instruments they could trust, the pilots were desperately trying to figure out what the plane was doing, the computer screen was covered in warning messages, and a continuous C-chord chime was running in the background. Scientific studies have shown that in such situations, the capacity of the human brain to tune out seemingly obvious auditory cues is considerable.</p><p id="ac72">Another possible reason is that the stall warning had previously activated for three seconds shortly after the disconnection of the autopilot, when Bonin initially pitched up. At that time the stall warning was unexpected and difficult for the pilots to rationalize. Crews involved in similar incidents reported that they assumed the brief stall warnings were generated by the erroneous airspeed readings, a not unreasonable interpretation which breaks down only when one learns that the stall warning calculations are based on angle of attack and do not incorporate any airspeed data. Thus, the stall warnings in all such cases were real. But in a situation where they were not expecting a stall warning, and in which they might have believed the plane could not stall, it’s not hard to imagine that Bonin and Robert heard the stall warning but simply didn’t believe it.</p><figure><figcaption>The tail section lies on the deck of a Brazilian navy ship following its recovery from the sea. (Der Spiegel)</figcaption></figure><p id="0f6b">At this point, Robert, despite his greater experience, failed to stop Bonin from stalling the airplane, even though he appeared to recognize that his fellow pilot was pitching up too steeply. Investigators noted that during most of the period between the onset of the event and the stall, Robert was trying to interpret the warning messages and was not directly paying attention to the flight path. Although he did tell Bonin to “go down,” Bonin’s halfhearted response was apparently enough to satisfy him, as he went right back to analyzing the problem. It is also worth noting that Robert had the same non-traditional piloting background as Bonin; he was likely operating on little sleep; and he had barely flown since being promoted into airline management. All things considered he was just as unprepared for the situation as Bonin was.</p><p id="ebb4">Once the airplane actually stalled, the crew of flight 447 found themselves beyond the scope of anything they had learned in training. Training scenarios never allowed the stall to fully develop, in part because the simulators in use at Air France could not faithfully simulate the behavior of the aircraft after exiting the normal flight envelope. The scenarios thus focused on preventing stalls, not recovering from them, and while the pilots likely knew in principle that they would need to pitch down to recover from a fully developed stall, this knowledge would have been purely academic in nature. Neither Bonin nor Robert had ever attempted such a maneuver, not in a simulator and definitely not in real life.</p><figure><figcaption>What the flight directors would have displayed during the periods when they were active during initial climb and stall. (BEA)</figcaption></figure><p id="5b05">This lack of practical knowledge combined with several conflicting cues to cement Bonin’s pre-established desire to pull up and climb. One of these cues came from the flight director, an overlay on the pilot’s attitude indicator which provides command bars that the pilot can follow in order to achieve a desired flight path. Normally the flight directors will disappear if the airspeed data becomes unreliable, and at first they did. But if the pilots don’t turn them off, they will come back as soon as two of the three Air Data Reference computers provide it with airspeed readings that are consistent with one another. On flight 447, the pilots never attempted to turn off the flight directors, and they came back as soon as the pitot tubes unfroze and the airspeed data became valid again, which occurred just before the onset of the stall. Not knowing the intentions of the crew, when the flight directors come online, they automatically instruct the pilot to maintain the current trajectory, until the pilot programs them to do otherwise. The result was that the flight directors re-engaged not in cruise mode, but in vertical speed mode with a target climb rate of 1,400 feet per minute — the exact rate at which flight 447 was climbing at that particular moment. From then on the flight directors, whenever they had valid data, instructed the pilots to attain an approximately 12-degree nose up attitude in order to reach this target vertical speed. Flight data indicates that at several points during the stall, Bonin may have been attempting to follow this erroneous flight director instruction.</p><figure><figcaption>A BEA investigator sorts wreckage in the hangar. (Eric Cabanis)</figcaption></figure><p id="d1cc">In fact, by coincidence the target pitch angle displayed by the flight director was almost exactly equal to the target pitch angle Bonin had learned to use while powering out of a low-altitude stall. This finding raises the question of whether Bonin thought that following the flight director would lead to the stabilization of the flight path. This interpretation is supported by Bonin’s comments to the effect that high power and a high pitch angle should cause them to climb. It seems likely that he not only thought he was flying the stall avoidance procedure, but that he believed the flight director was instructing him to do so as well. He apparently never recognized that the plane was already in a fully developed stall, and that this procedure was completely irrelevant to their actual situation.</p><p id="8ffe">During flight 447’s plunge toward the sea, the flight directors disappeared every time the forward airspeed dropped below 60 knots. This was because an airspeed below 60 knots while in flight is so anomalous that the computers are programmed to reject such a reading as false. Furthermore, at an angle of attack threshold which corresponded quite closely to 60 knots, the stall warning would cease for exactly the same reason. This created an unfortunate correlation, wherein Bonin would pitch up, the angle of attack and airspeed would exceed the rejection thresholds, the flight director would stop telling him to fly up, and the stall warning would cease; then if he attempted to pitch down, the angle of attack data would become valid again, the flight director would tell him to pitch up, and the stall warning would return. This perverse Pavlovian relationship could have subconsciously conditioned Bonin to believe that pitching down was causing the plane to approach the stall envelope, and that by pitching up he was actually protecting the plane against stalling. This violated basic aeronautical common sense, but by this point Bonin and common sense might as well have been on different planets.</p><figure><figcaption>BEA investigators present the black boxes. (CNN)</figcaption></figure><p id="ed6d">David Robert, had he taken decisive action, could perhaps have saved the plane if he had recognized that Bonin was causing the stall. At times he seemed aware that Bonin was pulling up, at times not; but many experts believe that the very design of the Airbus made it harder for him to understand his copilot’s actions. Unlike most other airliners, the control sticks on Airbus models are not mechanically linked and the pilots cannot directly feel what the other pilot is doing. Although this usually doesn’t present a problem — in the course of normal flight, pilots rarely touch the side stick —this can become a liability in an emergency situation involving a breakdown in communication. The design of the side stick assumes that the pilots are well-trained in crew resource management and are communicating their actions to one another, but this ideal appears dangerously naive in light of the confusion on the flight deck of Air France 447. Airbus has stuck to its guns, and no change of the side stick design appears imminent, but the debate rages on, and it is widely believed that a linked side stick could have allowed Robert to recognize and correct the situation well before Dubois arrived to bail him out.</p><p id="b70c">Unfortunately, by the time Captain Dubois entered the cockpit, the stall was already well advanced and their chances of survival were slim. Had he immediately recognized the problem, kicked Robert out of his seat, locked out Bonin from the controls, and executed a flawless stall recovery maneuver he might have saved the plane. But despite his expertise, he only seemed to realize what was happening shortly before impact. His difficulty understanding the situation could be explained by the first officers’ panic, the large number of extraneous indications and alarms, and the fact that he was operating on one hour of sleep. In theory, he should have seen that they were pitched up with the engines at high power and descending rapidly, a configuration that could only mean they were in a stall; there was no other explanation. But for whatever reason, he didn’t make the connection. In the fog of confusion, it took him too long to put two and two together, and by the time he did, he already knew there was no hope of recovery.</p><figure><figcaption>A BEA investigator presents the findings of the investigation. (Mehdi Fedouach)</figcaption></figure><p id="6a8d">In the end, there is no single interpretation of the situation which fully explains why Bonin did what he did. In all likelihood, his actions were the result of a confused mixture of conflicting ideas, which caused him to make decisions which were based on completely contradictory scenarios. Did he think they were in overspeed, or did he think he was applying a stall recovery procedure? The answer may not be either-or; in such a state of mind, rational thought tends to break down, and moment-by-moment instincts take over. It’s entirely possible that he held both opinions during the fatal descent, maybe even at the same time.</p><figure><figcaption>Flight attendants mourn their colleagues at a memorial service at the Notre Dame. (The Guardian)</figcaption></figure><p id="784d">Looking back on this bewildering body of evidence, the loss of Air France flight 447 kind of starts to make sense, in a distorted sort of way, like real life reflected in a funhouse mirror. We can start to see how a pilot who fundamentally does not understand his aircraft could fall into this trap, grasping wildly at trees without seeing the forest. What Bonin and Robert needed was aeronautical common sense, and they didn’t have it. It is so easy for those of us who have read about Air France flight 447 and similar accidents to point the finger and say the accident was Bonin’s fault, that he alone killed 227 other people. But such an accusation ignores the fact that Bonin was systematically underprepared for the situation in which he found himself. It is easy, from the vantage point of 2021, living in a world where Air France flight 447 has become one of the most studied accidents of all time, to say that he should have known better. And indeed he should have, but that’s not the point: the point is that Bonin was only a symptom of a deeper problem.</p><figure><figcaption>French Prime Minister Francois Fillion meets with Air France crews at a ceremony for the victims. (Antonio Scorza)</figcaption></figure><p id="d377">In fact, Air France flight 447 represented a turning point in how the global aviation industry approaches the subject of automation. There is no denying that automation has made flying much safer; the data supporting this conclusion is irrefutable. But amid the swift march of progress, it is important not to lose sight of the foundations on which that progress is built. Just like Alternate Law always lurks beneath Normal Law, underneath a layer of automation there lies the same need for traditional piloting skill that has always existed, and will continue to exist for the foreseeable future. We catch fewer glimpses into that realm than we used to, but it is still there, visible whenever something goes wrong with the automation. The fundamental paradox, one outlined by famed aviation author William Langewiesche, is this: the rarer such moments become, the harder it is to ensure that pilots are ready for them; and yet at the same time, their readiness becomes all the more important. After the crash of flight 447, solving this paradox became the foremost priority of aviation safety experts around the world, and the fruits of their efforts are only now becoming apparent.</p><figure><figcaption>A memorial to the victims of flight 447 evokes 228 transparent birds in flight. (Bertrand Langlois)</figcaption></figure><p id="dd0a">Today, flying is not the same as it was in 2009, when Dubois, Robert, and Bonin boarded their Airbus A330 for the last time. Training again emphasizes basic piloting skills and aeronautical common sense; high altitude stalls are a major training topic; and increased simulator fidelity has allowed the widespread introduction of Upset and Recovery Training, now mandatory in the United States and Europe, which confronts pilots with extreme situations and forces them to fly their way out. There are some pilots out there who still lack these skills, but there are surely fewer of them now than there were ten or fifteen years ago. A marked decline in the number of major airline accidents in the second half of the 2010s has testified to this fact. But it would be a mistake to believe that the problem is, or even can be, fully solved. As long as humans fly airplanes, some amount of information will always be lost while translating between man and machine, and from these imperfections spring the seeds of catastrophe. The next major crash of a large airliner, wherever it may occur, will almost certainly have something to do with the interaction between pilots and the automation that they oversee. In the meantime, it would be beneficial, even for those of us who are not pilots, to look on the events of Air France flight 447 and accept that we are human, that our capacity to err is unbound by reason, and that the best way to avoid disaster is to learn from the mistakes of others.</p><p id="0190">_______________________________________________________________</p><p id="c809"><a href="https://www.reddit.com/r/CatastrophicFailure/comments/q4ohcj/2009_the_crash_of_air_france_flight_447_analysis/?" rel="noopener ugc nofollow" target="_blank">Join the discussion of this article on Reddit!</a></p><p id="312a">Visit <a href="https://www.reddit.com/r/AdmiralCloudberg/" rel="noopener ugc nofollow" target="_blank">r/admiralcloudberg</a> to read and discuss over 200 similar articles.</p><p id="b17f">You can also <a href="https://www.patreon.com/Admiral_Cloudberg" rel="noopener ugc nofollow" target="_blank">support me on Patreon.</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Want to pwn a satellite? Turns out it's surprisingly easy (106 pts)]]></title>
            <link>https://www.theregister.com/2023/08/11/satellite_hacking_black_hat/</link>
            <guid>37088716</guid>
            <pubDate>Fri, 11 Aug 2023 13:56:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/08/11/satellite_hacking_black_hat/">https://www.theregister.com/2023/08/11/satellite_hacking_black_hat/</a>, See on <a href="https://news.ycombinator.com/item?id=37088716">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Black Hat</span> A study into the feasibility of hacking low-Earth orbit satellites has revealed that it's worryingly easy to do.</p>
<p>In a presentation at the <a target="_blank" href="https://www.theregister.com/special_features/blackhat_and_defcon">Black Hat security conference</a> in Las Vegas, Johannes Willbold, a PhD student at Germany's Ruhr University Bochum, <a target="_blank" rel="nofollow" href="https://www.blackhat.com/us-23/briefings/schedule/#houston-we-have-a-problem-analyzing-the-security-of-low-earth-orbit-satellites-32468">explained</a> he had been investigating the security of satellites. He studied three types of orbital machinery and found that many were utterly defenseless against remote takeover because they lack the most basic security systems.</p>
<p>"People think that satellites are secure," he said. "Those are expensive assets and they should have encryption and authentication. I assume that criminals think the same and they are too hard to target and you need to be some kind of cryptography genius. Maybe it wasn't a good idea to give this talk."</p>

    

<p>Satellite operators have been lucky so far. The prevailing wisdom is that hacking this kit would be prohibitively expensive due to the high cost of ground stations that communicate with the orbital birds, and that such hardware benefited from security by obscurity – that getting hold of the details of the firmware would be too difficult. Neither is true, the research indicates.</p>
<blockquote>

<p>Those are expensive assets and they should have encryption and authentication. I assume that criminals think the same and they are too hard to target</p>
</blockquote>
<p>For example, both AWS and Microsoft's Azure now offer Ground Station as a Service (GSaaS) to communicate with LEO satellites, so communication is simply a matter of plonking down a credit card. As for getting details on firmware, the commercial space industry has flourished in recent years and many of the components used on multiple platforms are easy to buy and study – Willbold estimated a hacker could build their own ground station for around $10,000 in parts.</p>
<p>As an academic, Willbold took a more direct approach. He just asked satellite operators for the relevant details for <a href="https://jwillbold.com/paper/willbold2023spaceodyssey.pdf" rel="nofollow">his paper</a> [PDF]. Some of them agreed (although he did have to sign an NDA in one case) and the results somewhat mirrored the early computing days, when security was sidelined because of the lack of computing power and memory.</p>

        


        

<p>He studied three different types of satellite: an ESTCube-1, a tiny CubeSat 2013 running an Arm Cortex-M3 processor, a larger CubeSat OPS-SAT operated by the European Space Agency as an orbital research platform, and the so-called Flying Laptop – a larger and more advanced satellite run by the Institute of Space Systems at the University of Stuttgart.</p>
<ul>

<li><a href="https://www.theregister.com/2023/08/10/viasat_reports_revenue_up_but/">Viasat probe into ailing $700M satellite casts shadow over Q1 results</a></li>

<li><a href="https://www.theregister.com/2023/04/26/kemba_walden_cybersecurity_space/">US National Cyber Director: Fending off cyber threats in space is 'urgent,' needs 'high level attention'</a></li>

<li><a href="https://www.theregister.com/2023/08/09/black_hat_def_con/">It's that time of the year again: The trinity of infosec conferences</a></li>
</ul>
<p>The results were depressing. Both the CubeSats failed at a most basic level, with no authentication protocols, and they were broadcasting signals without encryption. With some code Willbold would have been able to take over the satellites' basic control functions and lock out the legitimate owner, which he demonstrated during the talk with a simulation.</p>
<p>The Flying Laptop was a different case, however. It had basic security systems in place and tried to isolate core functions from interference. However, with some skill, code, and standard techniques, this satellite too proved vulnerable.</p>
<h3>Low priority</h3>
<p>Intrigued by the results, Willbold decided to dig deeper. He contacted developers working on sat systems to check the data, and got nine responses from devs who worked on a total of 132 satellites over their careers. This wasn't easy – it took four months to garner those responses.</p>
<p>The results showed that security systems were way down on the list of priorities when it comes to satellite design. Only two of the respondents had tried any kind of penetration testing. The problem, he opined, was that space science is such a rarefied field that the developers just didn't have the security skills to do a rigorous shakedown of a satellite in the first place.</p>
<div><p><img src="https://regmedia.co.uk/2023/06/03/comp_earth_moonlighter_satellite.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Composition of the Moonlighter satellite orbiting Earth"></p><h2 title="'World's first and only' orbiting infosec playpen due to blast off Sunday">Uncle Sam wants DEF CON hackers to pwn this Moonlighter satellite in space</h2>
<p><a href="https://www.theregister.com/2023/06/03/moonlighter_satellite_hacking/"><span>READ MORE</span></a></p></div>
<p>One surprising result was that the larger the satellite (and thus more expensive to build and launch), the more vulnerable it was. Larger machinery typically used more commercial off-the-shelf components and was thus more vulnerable since the code base was public, whereas smaller CubeSats tended to use custom code.</p>
<p>As for what would happen if a satellite was hijacked, Willbold suggested a number of alternatives. They could be used to transmit malicious information or code to targets on the ground, or to talk to other satellites in a constellation and subvert those too. In a worst-case scenario, a satellite could be moved to crash into another one, spewing debris all over orbit and potentially knocking out more systems.</p>
<p>When asked by <em>The Register</em> if it would be possible to retrofit security systems to satellites, Willbold wasn't hopeful.</p>

        

<p>"From a very technical perspective it would be possible. But realistically these systems are built on very tight margins," he said.</p>
<p>"They have planned these systems for every milliwatt of power that is used to run the satellite, so there is not the power budget on existing systems to run encryption or authentication. It's not practical." ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenTerraform – an MPL fork of Terraform after HashiCorp's license change (126 pts)]]></title>
            <link>https://github.com/diggerhq/open-terraform</link>
            <guid>37088591</guid>
            <pubDate>Fri, 11 Aug 2023 13:41:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/diggerhq/open-terraform">https://github.com/diggerhq/open-terraform</a>, See on <a href="https://news.ycombinator.com/item?id=37088591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Open Terraform</h2>
<p dir="auto">An open-source (MPL) fork of Hashicorp's Terraform following their <a href="https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license" rel="nofollow">change of license</a></p>
<p dir="auto">Created and maintained by <a href="https://github.com/diggerhq/digger">Digger.dev</a>, an open-source CI runner for infrastructure-as-code</p>
<blockquote>
<p dir="auto">The license change is not retroactive. This means all source code and releases prior to the change remain under the MPL 2.0 license. You may continue to use those versions indefinitely under the original license. (from <a href="https://www.hashicorp.com/license-faq#What-did-HashiCorp-announce-today-(Aug-10)" rel="nofollow">Hashicorp's blog</a>)</p>
</blockquote>
<ul dir="auto">
<li>HashiCorp's Website: <a href="https://www.terraform.io/" rel="nofollow">https://www.terraform.io</a></li>
<li>Forums: <a href="https://discuss.hashicorp.com/c/terraform-core" rel="nofollow">HashiCorp Discuss</a></li>
<li>Documentation: <a href="https://www.terraform.io/docs/" rel="nofollow">https://www.terraform.io/docs/</a></li>
<li>Tutorials: <a href="https://learn.hashicorp.com/terraform" rel="nofollow">HashiCorp's Learn Platform</a></li>
<li>Certification Exam: <a href="https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate" rel="nofollow">HashiCorp Certified: Terraform Associate</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1a4ed08978379480a9b1ca95d7f4cc8eb80b45ad47c056a7cfb5c597e9315ae5/68747470733a2f2f7777772e6461746f636d732d6173736574732e636f6d2f323838352f313632393934313234322d6c6f676f2d7465727261666f726d2d6d61696e2e737667"><img alt="Terraform" src="https://camo.githubusercontent.com/1a4ed08978379480a9b1ca95d7f4cc8eb80b45ad47c056a7cfb5c597e9315ae5/68747470733a2f2f7777772e6461746f636d732d6173736574732e636f6d2f323838352f313632393934313234322d6c6f676f2d7465727261666f726d2d6d61696e2e737667" width="600px" data-canonical-src="https://www.datocms-assets.com/2885/1629941242-logo-terraform-main.svg"></a></p>
<p dir="auto">Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.</p>
<p dir="auto">The key features of Terraform are:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Infrastructure as Code</strong>: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.</p>
</li>
<li>
<p dir="auto"><strong>Execution Plans</strong>: Terraform has a "planning" step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.</p>
</li>
<li>
<p dir="auto"><strong>Resource Graph</strong>: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.</p>
</li>
<li>
<p dir="auto"><strong>Change Automation</strong>: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.</p>
</li>
</ul>
<p dir="auto">For more information, refer to the <a href="https://www.terraform.io/intro" rel="nofollow">What is Terraform?</a> page on the Terraform website.</p>
<h2 tabindex="-1" dir="auto">Getting Started &amp; Documentation</h2>
<p dir="auto">Documentation is available on the <a href="https://www.terraform.io/" rel="nofollow">Terraform website</a>:</p>
<ul dir="auto">
<li><a href="https://www.terraform.io/intro" rel="nofollow">Introduction</a></li>
<li><a href="https://www.terraform.io/docs" rel="nofollow">Documentation</a></li>
</ul>
<p dir="auto">If you're new to Terraform and want to get started creating infrastructure, please check out our <a href="https://learn.hashicorp.com/terraform#getting-started" rel="nofollow">Getting Started guides</a> on HashiCorp's learning platform. There are also <a href="https://learn.hashicorp.com/terraform#operations-and-development" rel="nofollow">additional guides</a> to continue your learning.</p>
<p dir="auto">Show off your Terraform knowledge by passing a certification exam. Visit the <a href="https://www.hashicorp.com/certification/" rel="nofollow">certification page</a> for information about exams and find <a href="https://learn.hashicorp.com/terraform/certification/terraform-associate" rel="nofollow">study materials</a> on HashiCorp's learning platform.</p>
<h2 tabindex="-1" dir="auto">Developing Terraform</h2>
<p dir="auto">This repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on <a href="https://registry.terraform.io/" rel="nofollow">the Terraform Registry</a>. HashiCorp develops some providers, and others are developed by other organizations. For more information, see <a href="https://www.terraform.io/docs/extend/index.html" rel="nofollow">Extending Terraform</a>.</p>
<ul dir="auto">
<li>
<p dir="auto">To learn more about compiling Terraform and contributing suggested changes, refer to <a href="https://github.com/diggerhq/open-terraform/blob/main/.github/CONTRIBUTING.md">the contributing guide</a>.</p>
</li>
<li>
<p dir="auto">To learn more about how we handle bug reports, refer to the <a href="https://github.com/diggerhq/open-terraform/blob/main/BUGPROCESS.md">bug triage guide</a>.</p>
</li>
<li>
<p dir="auto">To learn how to contribute to the Terraform documentation in this repository, refer to the <a href="https://github.com/diggerhq/open-terraform/blob/main/website/README.md">Terraform Documentation README</a>.</p>
</li>
</ul>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto"><a href="https://github.com/hashicorp/terraform/blob/main/LICENSE">Mozilla Public License v2.0</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What HashiCorp’s license change means for our customers (207 pts)]]></title>
            <link>https://spacelift.io/blog/hashicorps-license-change</link>
            <guid>37088548</guid>
            <pubDate>Fri, 11 Aug 2023 13:37:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spacelift.io/blog/hashicorps-license-change">https://spacelift.io/blog/hashicorps-license-change</a>, See on <a href="https://news.ycombinator.com/item?id=37088548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>On August 10, </span><a href="https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license" target="_blank" rel="nofollow noopener"><span>HashiCorp announced</span></a><span> that they are changing the license on all their products to exclude use by direct competitors.</span></p></div><div><h2>What does it mean in practice?</h2>
<p><span>Beyond Terraform 1.5.5, direct HashiCorp competitors will be unable to incorporate the source code or embed or distribute newer versions of Terraform.</span></p>
</div><div><h2>How does it impact us?</h2>
<p><span>What we know for sure is that current versions of Terraform are, and will remain, unaffected, so there is no concern for your usage today. We are working with lawyers and experts to ensure we remain compliant going forward. We will provide updates soon.</span></p>
</div><div><h2>Can they do it?</h2>
<p><span>Yes, they can. They required every contributor to Terraform to sign a CLA that allowed this. Being legal does not make the move ethical or consistent with the ideals of open source software.</span></p>
</div><div><h2>They claim that we’re taking advantage of what they’re building. Are they right?</h2>
<p><span>Software is normally built in layers, and it’s not unusual to have commercial layers running on top of open source layers. Nobody is accusing GitHub of exploiting the Git ecosystem. In fact, much of the success of Git is due to the emergence of higher-level platforms like GitHub, Bitbucket, GitLab, and others. Competition in services on top of Terraform has recently driven much innovation as many of our own concepts eventually found their way to Terraform Cloud. It’s also worth remembering that Terraform itself is built on top of multiple open source libraries and an open source ecosystem. Without the volunteer work of hundreds of unpaid individuals, HashiCorp products would not be successful, there would be no ecosystem, and the company would not exist.</span></p>
</div></div><div><div><p><span><span></span><img alt="avatar_image_marcinw" srcset="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2Fb9ba5de8e05bd6d85824eb156694b0e1%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=64&amp;q=75 1x, https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2Fb9ba5de8e05bd6d85824eb156694b0e1%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75 2x" src="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2Fb9ba5de8e05bd6d85824eb156694b0e1%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><div><h3>Marcin Wyszynski</h3><p>Marcin is the co-founder and Chief Product Officer at Spacelift. Prior to founding Spacelift, he was an SRE and Production Engineer at Google and Facebook. He also consulted for European scaleups such as Deliveroo and Tier Mobility. He is the creator of geopoiesis.</p></div></div><div><p><span><span></span><img alt="avatar_image_pawel" srcset="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F8382b12eb2fa4be4e8510e7e6c3bf2f6%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=64&amp;q=75 1x, https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F8382b12eb2fa4be4e8510e7e6c3bf2f6%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75 2x" src="https://spacelift.io/_next/image?url=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F8382b12eb2fa4be4e8510e7e6c3bf2f6%3Fs%3D96%26d%3Dmm%26r%3Dg&amp;w=128&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><div><h3>Pawel Hytry</h3><p>Pawel is the CEO &amp; Co-Founder at Spacelift. Previously, he was the Co-Founder and Managing Director at FitPass Group. Pawel holds a degree in Operations &amp; Information Management from the University of Pennsylvania.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feral desert donkeys are digging wells, giving water to parched wildlife (178 pts)]]></title>
            <link>https://theconversation.com/feral-desert-donkeys-are-digging-wells-giving-water-to-parched-wildlife-159909</link>
            <guid>37087303</guid>
            <pubDate>Fri, 11 Aug 2023 11:06:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/feral-desert-donkeys-are-digging-wells-giving-water-to-parched-wildlife-159909">https://theconversation.com/feral-desert-donkeys-are-digging-wells-giving-water-to-parched-wildlife-159909</a>, See on <a href="https://news.ycombinator.com/item?id=37087303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In the heart of the world’s deserts – some of the most expansive wild places left on Earth – roam herds of feral donkeys and horses. These are the descendants of a once-essential but now-obsolete labour force. </p>

<p>These wild animals are generally considered <a href="https://nt.gov.au/environment/animals/feral-animals/feral-donkey">a threat to the natural environment</a>, and have been the target of mass eradication and lethal control programs in Australia. However, as we show in a <a href="https://science.sciencemag.org/cgi/doi/10.1126/science.abd6775">new research paper in Science</a>, these animals do something amazing that has long been overlooked: they dig wells — or “ass holes”. </p>

<p>In fact, we found that ass holes in North America — where feral donkeys and horses are widespread — dramatically increased water availability in desert streams, particularly during the height of summer when temperatures reached near 50℃. At some sites, the wells were the only sources of water. </p>

<figure>
            <a href="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397616/original/file-20210428-21-n4e3f6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Feral donkeys and horses dig wells to desert groundwater.</span>
              <span><span>Erick Lundgren</span></span>
            </figcaption>
          </figure>

<p>The wells didn’t just provide water for the donkeys and horses, but were also used by more than 57 other species, including numerous birds, other herbivores such as mule deer, and even mountain lions. (The lions are also predators of feral donkeys and <a href="https://www.nytimes.com/2018/05/12/sunday-review/let-mountain-lions-eat-horses.html">horses</a>.) </p>

<p>Incredibly, once the wells dried up some became nurseries for the germination and establishment of wetland trees.</p>

<figure>
            <a href="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=675&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=675&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=675&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=848&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=848&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=848&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397621/original/file-20210428-19-1egzibz.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Numerous species use equid wells. This includes mule deer (top left), scrub jays (middle left), javelina (bottom left), cottonwood trees (top right), and bobcats (bottom right).</span>
              <span><span>Erick Lundgren</span></span>
            </figcaption>
          </figure>

<h2>Ass holes in Australia</h2>

<p>Our research didn’t evaluate the impact of donkey-dug wells in arid Australia. But <a href="https://conbio.onlinelibrary.wiley.com/doi/10.1111/cobi.13447">Australia is home</a>  to most of the world’s feral donkeys, and it’s likely their wells support wildlife in similar ways.    </p>

<p>Across the Kimberley in Western Australia, helicopter pilots regularly saw strings of wells in dry streambeds. However, these all but disappeared as mass shootings since the late 1970s have driven donkeys <a href="https://www.abc.net.au/news/rural/2020-01-20/cost-benefit-analysis-of-culling-feral-donkeys-in-the-kimberley/11874064">near local extinction</a>. Only on <a href="https://www.kachana-station.com/projects/wild-donkey-project/">Kachana Station</a>, where the last of the Kimberley’s feral donkeys are protected, are these wells still to be found. </p>

<p>In Queensland, <a href="https://www.goodreads.com/book/show/2599093-they-all-ran-wild">brumbies</a> (feral horses) have been observed digging wells deeper than their own height to reach groundwater.</p>

<figure>
            <a href="https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="https://www.kachana-station.com/projects/wild-donkey-project/" data-src="https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=444&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=444&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=444&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=559&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=559&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397516/original/file-20210428-21-1y9ate5.JPG?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=559&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>Some of the last feral donkeys of the Kimberley.</span>
              <span><span>Arian Wallach</span></span>
            </figcaption>
          </figure>

<p>Feral horses and donkeys are not alone in this ability to maintain water availability through well digging. </p>

<p>Other equids — including mountain zebras, Grevy’s zebras and the kulan — dig wells. African and Asian elephants dig wells, too. These wells provide resources for other animal species, including the near-threatened <a href="https://www.goviinkhulan.com/english/our-projects/research/">argali</a> and the <a href="https://books.google.com/books/about/Tracking_Gobi_Grizzlies.html?id=paBHjgEACAAJ">mysterious Gobi desert grizzly bear</a> in Mongolia. </p>

<p>These animals, like most of the world’s remaining megafauna, <a href="https://advances.sciencemag.org/content/1/4/e1400103">are threatened</a> by human hunting and habitat loss.</p>

<figure>
            <a href="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=225&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=283&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397627/original/file-20210428-15-7k3eft.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Other megafauna dig wells, too, including kulans in central Asia, and African elephants.</span>
              <span><span>Petra Kaczensky, Richard Ruggiero</span></span>
            </figcaption>
          </figure>

<h2>Digging wells has ancient origins</h2>

<p>These declines are the modern continuation of an ancient pattern visible since humans left Africa during the late Pleistocene, beginning around 100,000 years ago. As our ancestors stepped foot on new lands, the largest animals <a href="https://theconversation.com/did-people-or-climate-kill-off-the-megafauna-actually-it-was-both-127803">disappeared</a>, most likely from human hunting, with contributions from climate change. </p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/giant-marsupials-once-migrated-across-an-australian-ice-age-landscape-84762">Giant marsupials once migrated across an Australian  Ice Age landscape</a>
    </strong>
  </em>
</p>
<hr>


<p>If their modern relatives dig wells, we presume many of these extinct megafauna may have also dug wells. In Australia, for example, a pair of <a href="https://www.abc.net.au/news/2020-02-07/water-diviner-wombats-bring-animals-to-water-hole/11937990">common wombats</a> were recently documented digging a 4m-deep well, which was used by numerous species, such as wallabies, emus, goannas and various birds, during a severe drought. This means ancient giant wombats (<em>Phascolonus gigas</em>) may have dug wells across the arid interior, too. </p>

<p>Likewise, a diversity of equids and elephant-like proboscideans that once roamed other parts of world, may have dug wells like their surviving relatives. </p>

<p>Indeed, these animals have left riddles in the soils of the Earth, such as the preserved remnants of a 13,500-year-old, 2m-deep well in western North America, perhaps dug by a mammoth during an ancient drought, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169555X1100314X">as a 2012 research paper proposes</a>.</p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/from-feral-camels-to-cocaine-hippos-large-animals-are-rewilding-the-world-83301">From feral camels to 'cocaine hippos', large animals are rewilding the world</a>
    </strong>
  </em>
</p>
<hr>


<h2>Acting like long-lost megafauna</h2>

<p>Feral equids are resurrecting this ancient way of life. While donkeys and horses were introduced to places like Australia, it’s clear they hold some curious resemblances to some of its great lost beasts. </p>

<p><a href="https://www.pnas.org/content/117/14/7871.short">Our previous research published in PNAS</a> showed introduced megafauna actually make Australia overall more functionally similar to the ancient past, prior to widespread human-caused extinctions. </p>

<figure>
            <p><img alt="" data-src="https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=258&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=258&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=258&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=324&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=324&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=324&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397643/original/file-20210428-13-1whsqw6.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p>
            <figcaption>
              <span>Donkeys share many similar traits with extinct giant wombats, who once may have dug wells in Australian drylands.</span>
              <span><span>Illustration by Oscar Sanisidro</span></span>
            </figcaption>
          </figure>

<p>For example, donkeys and feral horses have trait combinations (including diet, body mass, and digestive systems) that mirror those of the giant wombat. This suggests — in addition to potentially restoring well-digging capacities to arid Australia — they may also influence vegetation in similar ways. </p>

<p>Water is a limited resource, made even scarcer by farming, mining, climate change, and other human activities. With deserts predicted to spread, feral animals may provide unexpected gifts of life in drying lands.</p>

<figure>
            <a href="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=337&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=337&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=337&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=424&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/397696/original/file-20210428-17-ybw0wq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Feral donkeys, horses (mapped in blue), and other existing megafauna (mapped in red) may restore digging capacities to many drylands. Non-dryland areas are mapped in grey, and the projected expansion of drylands from climate change in yellow.</span>
              <span><span>Erick Lundgren/Science</span>, <span>Author provided</span></span>
            </figcaption>
          </figure>

<p>Despite these ecological benefits in desert environments, feral animals have long been denied the <a href="https://ro.uow.edu.au/asj/vol8/iss2/14/">care</a>, curiosity and <a href="https://theconversation.com/non-native-species-should-count-in-conservation-even-in-australia-127926">respect</a> native species deservedly receive. Instead, these animals are targeted by <a href="https://www.abc.net.au/religion/this-treatment-of-donkeys-makes-brutes-out-of-us/10101372">culling</a> programs for conservation and the meat industry. </p>

<p>However, there are signs of change. New fields such as <a href="https://www.uts.edu.au/research-and-teaching/our-research/centre-compassionate-conservation">compassionate conservation</a> and <a href="https://www.sydney.edu.au/arts/our-research/futurefix/multispecies-justice.html">multispecies justice</a> are expanding conservation’s <a href="https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/cobi.13126">moral world</a>, and challenging the idea that only native species matter.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shamir Secret Sharing (219 pts)]]></title>
            <link>https://max.levch.in/post/724289457144070144/shamir-secret-sharing-its-3am-paul-the-head-of</link>
            <guid>37087136</guid>
            <pubDate>Fri, 11 Aug 2023 10:38:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://max.levch.in/post/724289457144070144/shamir-secret-sharing-its-3am-paul-the-head-of">https://max.levch.in/post/724289457144070144/shamir-secret-sharing-its-3am-paul-the-head-of</a>, See on <a href="https://news.ycombinator.com/item?id=37087136">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Fastest Branchless Binary Search (284 pts)]]></title>
            <link>https://mhdm.dev/posts/sb_lower_bound/</link>
            <guid>37086796</guid>
            <pubDate>Fri, 11 Aug 2023 09:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mhdm.dev/posts/sb_lower_bound/">https://mhdm.dev/posts/sb_lower_bound/</a>, See on <a href="https://news.ycombinator.com/item?id=37086796">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You’re a busy person so I’ll first jump right to it. Here it is, the fastest general (and simple) binary search C++ implementation:</p><div><pre><code data-lang="C++"><span>template</span> <span>&lt;</span><span>class</span> <span>ForwardIt</span>, <span>class</span> <span>T</span>, <span>class</span> <span>Compare</span><span>&gt;</span>
<span>constexpr</span> ForwardIt sb_lower_bound(
      ForwardIt first, ForwardIt last, <span>const</span> T<span>&amp;</span> value, Compare comp) {
   <span>auto</span> length <span>=</span> last <span>-</span> first;
   <span>while</span> (length <span>&gt;</span> <span>0</span>) {
      <span>auto</span> rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      <span>if</span> (comp(first[length], value)) {
         first <span>+=</span> length <span>+</span> rem;
      }
   }
   <span>return</span> first;
}
</code></pre></div><p>Same function interface as <code>std::lower_bound</code>, but <strong>2x</strong> faster, and shorter. “branchless” because the <code>if</code> compiles down to a conditional move instruction rather than a branch/conditional jump. We will explore compiler options, even faster versions, fully branchless, and caveats towards the end of the article. There’s a significant <strong>update</strong> too. Oh and I’m sorry about just thrusting C++ code on you. Rude, I know. You don’t really need to know C++ to understand this article, just iterators (<code>first</code> and <code>last</code>), basically pointers to elements in an array, though note they can point one past the last array entry. Ignore <code>template</code>, <code>class</code>, <code>constexpr</code> and <code>&amp;</code>. If only there was a clean fast bare-metal language to write all this in.. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><h2 id="binary-search-intro">Binary search intro</h2><p>You have a sorted list and want to find where a <code>value</code> would fit. In C++ you’d use <code>std::lower_bound</code> which returns the first position (iterator) for which the comparison (usually <code>&lt;</code>) fails, or <code>last</code> if the comparison is true for all elements. Let’s write that, so surprise coding interview question! (In C++. Good luck.)</p><p>The <code>binary</code> in binary search comes from splitting up the list into two at some middle item and doing a comparison of the middle against the given <code>value</code>. Based on the comparison result we pick which of the two lists to keep looking in. We start with a list of some <code>length = last - first</code> that starts at the given iterator <code>first</code>. We need to have some loop that keeps going until the list is empty, i.e. <code>while (length &gt; 0)</code>. Pick the/a middle, at <code>length / 2</code> do a comparison and update the current list, which we’ll do by updating <code>first</code> and <code>length</code>. Here goes:</p><div><pre><code data-lang="C++"><span>// std_lower_bound()
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>if</span> (comp(first[half], value)) {
      first <span>+=</span> half <span>+</span> <span>1</span>;
      length <span>-=</span> half <span>+</span> <span>1</span>;
   } <span>else</span> {
      length <span>=</span> half;
   }
}
<span>return</span> first;
</code></pre></div><p>That was straight-forward. What we got was a slightly refactored version of <a href="https://github.com/gcc-mirror/gcc/blob/releases/gcc-13/libstdc%2B%2B-v3/include/bits/stl_algobase.h#L1467">what gcc/libstdc++ uses</a> or <a href="https://github.com/llvm/llvm-project/blob/release/16.x/libcxx/include/__algorithm/lower_bound.h#L36">what llvm/libc++ uses</a>. Roughly the same speed, even (sometimes) compiles down to the same assembly in the loop.</p><h2 id="branch-prediction">Branch prediction</h2><p>“What’s slow about this?” Not much but glad you asked, great question. Processors have gotten faster and faster over the years, and part of the reason why is <em>branch prediction</em>. Short explanation: for speed, the CPU attempts to execute instructions in parallel by dividing each instruction execution into multiple stages, say F-D-E-W (fetch, decode, execute, writeback). With a careful design it can make progress on multiple stages of different instructions (Example: instruction 5 in stage F, 6 in D, 7E, 8F) at the same time. The complication comes from branches in the code, i.e. conditional jump instructions, where depending on some result the next instruction is either X or Y. The CPU <em>predicts</em> one option, X, and starts running through the stages, eventually including the stages of say X+1 and X+2. When the result becomes available and it turns out it should have been Y, all the work on X, X+1 and X+2 is thrown away. Branch mispredictions are expensive because the CPU could have already made progress on Y, Y+1 and Y+2 instead.</p><p>Branch prediction is great, but not for binary search. It’s a search, and you only search for something if you don’t know exactly where it is, otherwise you’d just get it. Which means that <code>if (comp(first[half], value))</code> is unpredictable in common use of <code>std::lower_bound</code>.</p><p><img src="https://mhdm.dev/posts/sb_lower_bound/predictions.png" alt="A happy-go-lucky processor saying “my predictions fail only half the time!" "="">
Credit <a href="https://www.instagram.com/practicemakespink">@practicemakespink</a></p><p>Let’s help the processor.</p><p>-We:</p><div><pre><code data-lang="C++"><span>// bstd_lower_bound()
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>bool</span> compare <span>=</span> comp(first[half], value);
   <span>// No more ifs
</span><span></span>   first <span>=</span> compare <span>?</span> first <span>+</span> half <span>+</span> <span>1</span> <span>:</span> first;
   length <span>=</span> compare <span>?</span> length <span>-</span> half <span>-</span> <span>1</span> <span>:</span> half;
}
<span>return</span> first;
</code></pre></div><p>-Clang compiler: “That’s not how this works!”</p><p>-We: <code>-mllvm -x86-cmov-converter=false</code></p><p>-Clang compiler: “Yes, boss."<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><p>The result is 25% faster as it uses 2 conditional move instructions. Not bad. But turns out that <code>-mllvm -x86-cmov-converter=false</code>, which we’ll shorten to <code>-cmov</code>, speeds up <code>std::lower_bound</code> just as much because clang is smart enough to figure out how to convert the <code>if</code>/<code>else</code> to conditional moves. gcc doesn’t have such an option and generally just doesn’t care about what you want.</p><p>Overall, there’s currently no good way to tell either clang<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> or gcc<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> to use a conditional move in just a certain situation.I’m trying to not make this article about finicky compilers, so let’s move on.</p><h2 id="what-started-this">What started this</h2><p>Why are we even talking about speeding up binary searches anyway? Why am I roping you into this? Cause someone else roped me into this.</p><p><video muted="" autoplay="" loop="" src="https://mhdm.dev/posts/sb_lower_bound/rope.mp4" width="100%" title="Meeseeks blaming one another for being roped in | Rick and Morty" onclick="this.paused?this.play():this.pause()"></video>
<a href="https://www.adultswim.com/videos/rick-and-morty/meeseeks-and-destroy">Rick and Morty - Meeseeks and Destroy</a></p><p>I saw Malte Skarupke’s translation of “Shar’s algorithm” into a C++ binary search (<code>branchless_lower_bound</code>) and I couldn’t help but think “it’s not optimal”. Malte’s version sometimes compares <code>value</code> against the same element multiple times. So I wondered, what is the optimal ‘branchless’ binary search? That led to <code>sb_lower_bound</code> which is ~20% faster than <a href="https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/">Malte’s version of lower_bound that he tested as 2x faster than GCC</a>.</p><p>“What’s an ‘optimal’ binary search anyway?” Good question. I think a binary search is ‘optimal’ if it completes by doing the minimum number of comparisons. This is very useful when you have a (relatively) slow comparison function. Malte noted his version is slower than <code>std::lower_bound</code> for binary searching a large number of strings.</p><p>Looking at <code>std::lower_bound</code> it returns an iterator, which can point to any of the list elements but also one past the end. For a list of size <code>n</code> there are <code>n+1</code> possible options. Thus for a list of size <code>2<sup>k</sup>-1</code> there are <code>2<sup>k</sup></code> possible options. In this case the optimal number of comparisons is <code>k</code>. Provably so as being able to distinguish between all <code>2<sup>k</sup></code> options requires <code>k</code> bits of information, and each comparison gives us 1 bit of information (true vs false). Translating this case into code, we get:</p><div><pre><code data-lang="C++"><span>// Really fast but only works when length is a power of 2 minus 1
</span><span>// When not, it can result in out of bounds accesses like for
</span><span>// array [0, 1, 2, 3, 4, 5] and value 4
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   length <span>/=</span> <span>2</span>;
   <span>if</span> (comp(first[length], value)) {
      first <span>+=</span> length <span>+</span> <span>1</span>;
   }
}
<span>return</span> first;
</code></pre></div><p>With clang <code>-cmov</code> the loop compiles down to 6 instructions, one of which is <code>cmov</code>. The reason this (and Malte’s code) is so fast is that only updating <code>first</code> depends on the comparison result.</p><h2 id="sb_lower_bound"><code>sb_lower_bound</code></h2><p>Now let’s look at <code>sb_lower_bound</code> (named after <em>simple branchless</em>). It actually took me longer to stumble upon than faster versions (yet to be presented) as it’s not ‘optimal’.</p><div><pre><code data-lang="C++"><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> rem <span>=</span> length <span>%</span> <span>2</span>;
   length <span>/=</span> <span>2</span>;
   <span>if</span> (comp(first[length], value)) {
      first <span>+=</span> length <span>+</span> rem;
   }
}
<span>return</span> first;
</code></pre></div><p>Every time we split the list, the number of elements happens to be even, and comp returns true then we don’t skip over enough elements. For <code>n</code> elements, where <code>2<sup>k</sup> &lt;= n &lt; 2<sup>k+1</sup></code>, <code>sb_lower_bound</code> will always make <code>k+1</code> comparisons while <code>std::lower_bound</code> will either make <code>k</code> or <code>k+1</code> comparisons. On average <code>std::lower_bound</code> will make about <code>log2(n+1)</code> comparisons. Overall <code>sb_lower_bound</code> is faster as it has significantly fewer instructions in the loop. The comparison function has to be really slow for the difference between <code>k+1</code> and <code>log2(n+1)</code> number of comparisons to matter.</p><p>Second caveat is that currently, gcc does not emit branchless code for <code>sb_lower_bound</code> regardless of optimization level. It doesn’t emit branchless code for <code>std::lower_bound</code> either so they end up about as fast. We can try to write some inline assembly to force gcc to use <code>cmov</code> but there’s a tradeoff. The simple way results in more instructions than necessary. The alternative requires writing different assembly code for every possible type of <code>value</code> (int, float, etc.).</p><div><pre><code data-lang="C++"><span>// asm_lower_bound, works for x86 only
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> rem <span>=</span> length <span>%</span> <span>2</span>;
   length <span>/=</span> <span>2</span>;
   <span>auto</span> firstplus <span>=</span> first <span>+</span> length <span>+</span> rem;
   <span>// Does a comparison which sets some x86 FLAGS like CF or ZF
</span><span></span>   <span>bool</span> compare <span>=</span> comp(first[length], value);
   <span>// Inline assembly doesn't support passing bools straight into FLAGS
</span><span></span>   <span>// so we ask the compiler to copy it from FLAGS into a register
</span><span></span>   __asm__(
         <span>// Then we test the register, which sets ZF=!compare and CF=0
</span><span></span>         <span>// Reference: https://www.felixcloutier.com/x86/test
</span><span></span>         <span>"test %[compare],%[compare]</span><span>\n</span><span>"</span>
         <span>// cmova copies firstplus into first if ZF=0 and CF=0
</span><span></span>         <span>// Reference: https://www.felixcloutier.com/x86/cmovv
</span><span></span>         <span>"cmova %[firstplus],%[first]</span><span>\n</span><span>"</span>
         <span>:</span> [first] <span>"+r"</span>(first)
         <span>:</span> [firstplus] <span>"r"</span>(firstplus), [compare]<span>"r"</span>(compare)
   );
}
<span>return</span> first;
</code></pre></div><p>2x faster than the gcc version of <code>std::lower_bound</code>, but slightly slower than <code>sb_lower_bound</code> with clang <code>-cmov</code>. Presented just for demonstration purposes.</p><h2 id="more-optimal">More optimal</h2><p>I promised an even faster version in the intro. Here it is:</p><div><pre><code data-lang="C++"><span>// bb_lower_bound
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>// while length isn't a power of 2 minus 1
</span><span></span><span>while</span> (length <span>&amp;</span> (length <span>+</span> <span>1</span>)) {
   <span>auto</span> step <span>=</span> length <span>/</span> <span>8</span> <span>*</span> <span>6</span> <span>+</span> <span>1</span>; <span>// MAGIC
</span><span></span>   <span>if</span> (comp(first[step], value)) {
      first <span>+=</span> step <span>+</span> <span>1</span>;
      length <span>-=</span> step <span>+</span> <span>1</span>;
   } <span>else</span> {
      length <span>=</span> step;
      <span>break</span>;
   }
}
<span>while</span> (length <span>!=</span> <span>0</span>) {
   length <span>/=</span> <span>2</span>;
   <span>if</span> (comp(first[length], value)) {
      first <span>+=</span> length <span>+</span> <span>1</span>;
   }
}
<span>return</span> first;
</code></pre></div><p>Let’s quickly go over <code>length &amp; (length + 1)</code>. Example: <code>length</code> is <code>110011</code>, <code>length+1</code> is <code>110100</code>, <code>length &amp; (length+1)</code> is <code>110000</code>. Note how they always share their most significant <code>1</code> except for when <code>length+1</code> carries over all set bits. That case is when <code>length</code> is of the form <code>11..1</code>, i.e. power of 2 minus 1, in which case <code>length &amp; (length + 1)</code> will be 0. Slightly adapted from one of the bit twiddling tricks I remembered and there’s a (warning!) <a href="https://graphics.stanford.edu/~seander/bithacks.html">rabbit hole full of awesome tricks here</a>.</p><p>Let us call lengths ‘nice’ if they are powers of 2 minus 1. Earlier we found that for nice lengths we can have optimal searching. The original idea was that for non-nice length we split the search list not in half but in a way that we’ll quickly end up only searching sub-lists of nice lengths. This idea was not quite fast enough as it meant spending significant time just splitting up the list. The first compromise is that early <code>break</code>, which means the second <code>while</code> loop may (non-optimally) search past its original length; no out of bounds accesses though as this sub-list isn’t at the end of the full list. This compromise leads to a second compromise, that bit of MAGIC in selecting the <code>step</code> size. To be fast we want a large <code>step</code>, definitely <code>&gt;= length/2</code>, so we more often break out to the faster <code>while</code> loop. But not so large a <code>step</code> that almost equals <code>length</code> because we lose on what makes a binary search fast. We’d also prefer that the <code>step</code> is nice or has many <code>1</code>s in its binary representation, which makes the second <code>while</code> loop more optimal. The many <code>1</code>s is why the <code>step</code> is forced to be odd. Last but not least, we’d want <code>length - step - 1</code> to be nice.</p><p>I’ve tried quite a few variations. The most bitter sweet was <code>auto step = length &gt;&gt; 1; step |= step &gt;&gt; 1;</code> which I thought to be a good fast heuristic that balances the listed compromises, is very close to optimal but ultimately ended up slightly slower than MAGIC. Another issue is the ‘break’ makes it branchy.</p><p>One unexplored avenue is exhaustively searching for the fastest (yet still optimal) <code>step</code> for every length and storing that into a precomputed table. Then either deriving a good heuristic from said table or using it outright. With <code>sb_lower_bound</code> I’ve reached my good-enough point but you’re welcome to explore further :).</p><div><pre><code data-lang="C++"><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&amp;</span> (length <span>+</span> <span>1</span>)) {
   <span>auto</span> step <span>=</span> precomputed[length];
   <span>if</span> (comp(first[step], value)) {
      first <span>+=</span> step <span>+</span> <span>1</span>;
      length <span>-=</span> step <span>+</span> <span>1</span>;
   } <span>else</span> {
      length <span>=</span> step;
   }
}
<span>// ...
</span></code></pre></div><h2 id="more-branchless-more-better">More branchless, more better?</h2><p>Short answer: no. This section can be skipped but here’s the long answer: For <code>n</code> elements where <code>2<sup>k</sup> &lt;= n &lt; 2<sup>k+1</sup></code> <code>sb_lower_bound</code> will always do <code>k+1</code> comparisons. On a 64-bit machine that means at most 64 iterations of the <code>while (length &gt; 0)</code> loop. So it’s possible to write a “fully branchless” version that doesn’t have the <code>length</code> check by using a <code>switch</code> with intentional fall-through.</p><div><pre><code data-lang="C++">size_t length <span>=</span> last <span>-</span> first;
size_t rem;
<span>switch</span>(std<span>::</span>bit_width(length)) {
   <span>case</span> <span>64</span><span>:</span>
      rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      first <span>+=</span> comp(first[length], value) <span>*</span> (length <span>+</span> rem);
   <span>case</span> <span>63</span><span>:</span>
      rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      first <span>+=</span> comp(first[length], value) <span>*</span> (length <span>+</span> rem);
   <span>// ...
</span><span></span>   <span>case</span> <span>1</span><span>:</span>
      rem <span>=</span> length <span>%</span> <span>2</span>;
      length <span>/=</span> <span>2</span>;
      first <span>+=</span> comp(first[length], value) <span>*</span> (length <span>+</span> rem);
}
<span>return</span> first;
</code></pre></div><p>If you’re not familiar with <code>switch</code>, think of it as a jump into code. In our case to the exact place from which there are exactly the right number of comparisons left to do.</p><p>“Is it any faster?” No. Modern x86 processors handle loop conditions well as they’re predictable; we’re very likely to remain in the loop. And that’s good especially because it saves us from writing templates or macros or copy-paste-edit the 64 cases.</p><h2 id="spotlight-on-performance">Spotlight on Performance</h2><p><img src="https://mhdm.dev/posts/sb_lower_bound/performance.png" alt="Sketch of processor’s performance" title="Spotlight on Performance">
Credit <a href="https://www.instagram.com/practicemakespink">@practicemakespink</a></p><p>Average run time (ns):</p><table><thead><tr><th></th><th><code>std::lower_</code></th><th><code>branchless_lower_</code></th><th><code>asm_lower_</code></th><th><code>sb_lower_</code></th><th><code>sbm_lower_</code></th><th><code>bb_lower_</code></th></tr></thead><tbody><tr><td>gcc</td><td>80.68</td><td>43.65</td><td>54.92</td><td>77.22</td><td>34.19</td><td>75.64</td></tr><tr><td>clang</td><td>78.66</td><td>90.97</td><td>51.83</td><td>80.06</td><td>83.95</td><td>74.44</td></tr><tr><td>clang -cmov</td><td>61.30</td><td>43.43</td><td>54.32</td><td><strong>33.24</strong></td><td>35.54</td><td><strong>32.73</strong></td></tr></tbody></table><p>Geometric mean run time (ns):</p><table><thead><tr><th></th><th><code>std::lower_</code></th><th><code>branchless_lower_</code></th><th><code>asm_lower_</code></th><th><code>sb_lower_</code></th><th><code>sbm_lower_</code></th><th><code>bb_lower_</code></th></tr></thead><tbody><tr><td>gcc</td><td>62.44</td><td>25.55</td><td>32.35</td><td>59.67</td><td>20.62</td><td>57.93</td></tr><tr><td>clang</td><td>61.24</td><td>65.72</td><td>30.67</td><td>63.59</td><td>66.91</td><td>58.19</td></tr><tr><td>clang -cmov</td><td>39.17</td><td>25.14</td><td>31.21</td><td><strong>19.81</strong></td><td>20.91</td><td>21.33</td></tr></tbody></table><p>Runtimes in line chart form:</p><p><a href="https://mhdm.dev/posts/sb_lower_bound/runtimes.png"><img src="https://mhdm.dev/posts/sb_lower_bound/runtimes.png" alt="Runtimes"></a></p><p>“What’s <code>sbm_lower_bound</code>?” It’s basically <code>sb_lower_bound</code> but modified to trick gcc into generating a conditional move. The difference is switching from the <code>if</code> statement to <code>first += comp(first[length], value) * (length + rem)</code>. Use with comments and caution as the next version of gcc may undo this optimization.</p><p>Benchmarking commands showing compiler options:</p><div><pre><code data-lang="sh">g++-10 -std<span>=</span>c++20 -Wall -O2 -march<span>=</span>haswell test.cpp -o test <span>&amp;&amp;</span> ./test
clang++-10 -std<span>=</span>c++20 -Wall -O2 -march<span>=</span>haswell test.cpp -o test <span>&amp;&amp;</span> ./test
clang++-10 -std<span>=</span>c++20 -Wall -O2 -march<span>=</span>haswell -mllvm -x86-cmov-converter<span>=</span>false test.cpp -o test <span>&amp;&amp;</span> ./test
</code></pre></div><p><code>-march=native</code> or no <code>-march</code> did not significantly influence the rankings. Benchmarked on an intel i7 kaby lake.</p><h3 id="branch-mispredictions">Branch mispredictions</h3><p>We can look at branch mispredictions/misses using <code>perf</code>:</p><div><pre><code data-lang="sh"><span># clang</span>
perf stat ./test
<span># [..]</span>
         16,599.95 msec task-clock:u     <span>#    1.000 CPUs utilized</span>
<span># [..]</span>
    30,309,755,516      instructions:u   <span>#    0.53  insn per cycle</span>
     6,941,783,502      branches:u       <span>#  418.181 M/sec</span>
     1,203,569,540      branch-misses:u  <span>#   17.34% of all branches</span>
<span># clang -cmov</span>
perf stat ./test
<span># [..]</span>
         10,982.97 msec task-clock:u     <span>#    1.000 CPUs utilized</span>
<span># [..]</span>
    32,603,123,521      instructions:u   <span>#    0.90  insn per cycle</span>
     4,070,883,093      branches:u       <span>#  370.654 M/sec</span>
        35,954,999      branch-misses:u  <span>#    0.88% of all branches</span>
</code></pre></div><p><code>-cmov</code> removes ~2.9B branches and ~1.2B branch misses, so it removes branches that were mispredicted ~41% of the time. It’s close to the 50% we’d expect for purely unpredictable branches, if we had perfect randomness and benchmarking. In which case <code>-cmov</code> would result in an even higher improvement.</p><h3 id="performance-with-slower-comp">Performance with slower <code>comp()</code></h3><p>For somewhat realistic scenarios of binary searching with a slower <code>comp()</code> function I’ve thought of searching through ids, phone numbers, accounts and keywords. I’ve thus settled on testing searching 8-byte strings.</p><p>Average run time (ns):</p><table><thead><tr><th></th><th><code>std::lower_</code></th><th><code>branchless_lower_</code></th><th><code>sb_lower_</code></th><th><code>sbm_lower_</code></th><th><code>bb_lower_</code></th></tr></thead><tbody><tr><td>gcc</td><td><strong>160.01</strong></td><td>205.24</td><td>165.66</td><td>193.96</td><td>163.91</td></tr><tr><td>clang</td><td><strong>157.71</strong></td><td>178.77</td><td>162.68</td><td>166.00</td><td><strong>157.22</strong></td></tr><tr><td>clang -cmov</td><td><strong>156.06</strong></td><td>193.70</td><td>164.71</td><td>181.57</td><td>157.48</td></tr></tbody></table><p>In this case <code>std::lower_bound</code> is very slightly but consistently faster than <code>sb_lower_bound</code>. To always get the best performance it is possible for libraries to use <code>sb_lower_bound</code> whenever directly working on primitive types and <code>std::lower_bound</code> otherwise.</p><h2 id="assembly">Assembly</h2><p>No bare-metal code performance optimization is complete without looking at the generated assembly. However, feel free to skip this section.</p><div><pre><code data-lang="js"><span>Time</span><span>%</span> <span>|</span>      <span>instructions</span>

<span>// std::lower_bound, clang -cmov, hottest loop assembly
</span><span></span> <span>1.68</span> <span>│</span><span>20</span><span>:</span>   <span>mov</span>      <span>%</span><span>rsi</span>,<span>%</span><span>rcx</span>             <span>// rcx = length
</span><span></span> <span>3.20</span> <span>│</span>      <span>shr</span>      <span>%</span><span>rcx</span>                  <span>// rcx = length / 2
</span><span></span> <span>1.08</span> <span>│</span>      <span>mov</span>      <span>%</span><span>rcx</span>,<span>%</span><span>rdx</span>             <span>// rdx = length / 2
</span><span></span> <span>4.42</span> <span>│</span>      <span>not</span>      <span>%</span><span>rdx</span>                  <span>// rdx = binary_not(rdx) = -length / 2 - 1
</span><span></span> <span>2.85</span> <span>│</span>      <span>add</span>      <span>%</span><span>rsi</span>,<span>%</span><span>rdx</span>             <span>// rdx = length - length / 2 - 1
</span><span></span><span>63.41</span> <span>│</span>      <span>vucomiss</span> (<span>%</span><span>rax</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>xmm0</span>   <span>// Compare first[rcx] with value, sets FLAGS
</span><span></span> <span>0.21</span> <span>│</span>      <span>lea</span>      <span>0x4</span>(<span>%</span><span>rax</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>rsi</span> <span>// rsi = first + length / 2 + 1
</span><span></span><span>10.14</span> <span>│</span>      <span>cmova</span>    <span>%</span><span>rsi</span>,<span>%</span><span>rax</span>             <span>// first = compare_res ? first : rsi
</span><span></span> <span>4.87</span> <span>│</span>      <span>cmovbe</span>   <span>%</span><span>rcx</span>,<span>%</span><span>rdx</span>             <span>// rdx = not compare_res ? length / 2 : rdx
</span><span></span> <span>0.88</span> <span>│</span>      <span>mov</span>      <span>%</span><span>rdx</span>,<span>%</span><span>rsi</span>             <span>// rsi = rdx (new length)
</span><span></span> <span>0.33</span> <span>│</span>      <span>test</span>     <span>%</span><span>rdx</span>,<span>%</span><span>rdx</span>             <span>// Set FLAGS based on rdx
</span><span></span> <span>3.90</span> <span>│</span>    <span>↑</span> <span>jg</span>       <span>20</span>                    <span>// Jump to instruction 20 if rdx not zero
</span><span></span>
<span>// sb_lower_bound, clang -cmov, hottest loop assembly
</span><span></span> <span>4.21</span> <span>│</span><span>20</span><span>:</span>   <span>shr</span>      <span>%</span><span>rcx</span>                  <span>// rcx = length / 2
</span><span></span> <span>4.70</span> <span>│</span>      <span>and</span>      <span>$0x1</span>,<span>%</span><span>esi</span>             <span>// esi = length % 2
</span><span></span> <span>5.00</span> <span>│</span>      <span>add</span>      <span>%</span><span>rcx</span>,<span>%</span><span>rsi</span>             <span>// rsi = length / 2 + length % 2
</span><span></span><span>68.86</span> <span>│</span>      <span>vucomiss</span> (<span>%</span><span>rax</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>xmm0</span>   <span>// Compare first[rcx] with value, sets FLAGS
</span><span></span> <span>0.01</span> <span>│</span>      <span>lea</span>      (<span>%</span><span>rax</span>,<span>%</span><span>rsi</span>,<span>4</span>),<span>%</span><span>rdx</span>    <span>// rdx = first + length / 2 + length % 2
</span><span></span><span>11.69</span> <span>│</span>      <span>cmova</span>    <span>%</span><span>rdx</span>,<span>%</span><span>rax</span>             <span>// first = compare_res ? first : rdx
</span><span></span> <span>3.71</span> <span>│</span>      <span>mov</span>      <span>%</span><span>rcx</span>,<span>%</span><span>rsi</span>             <span>// rsi = length / 2
</span><span></span>      <span>│</span>      <span>test</span>     <span>%</span><span>rcx</span>,<span>%</span><span>rcx</span>             <span>// Set FLAGS based on rcx
</span><span></span> <span>0.02</span> <span>│</span>    <span>↑</span> <span>jne</span>      <span>20</span>                    <span>// Jump to instruction 20 if rcx not zero
</span><span></span>
<span>// branchless_lower_bound, clang -cmov, hottest loop assembly
</span><span></span> <span>3.04</span> <span>│</span><span>70</span><span>:</span>   <span>lea</span>      (<span>%</span><span>rdi</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>rax</span>    <span>// rax = first + length
</span><span></span><span>71.22</span> <span>│</span>      <span>vucomiss</span> (<span>%</span><span>rdi</span>,<span>%</span><span>rcx</span>,<span>4</span>),<span>%</span><span>xmm0</span>   <span>// Compare first[rcx] with value, sets FLAGS
</span><span></span><span>12.26</span> <span>│</span>      <span>cmova</span>    <span>%</span><span>rax</span>,<span>%</span><span>rdi</span>             <span>// first = compare_res ? first : rax
</span><span></span> <span>1.03</span> <span>│</span><span>7</span><span>d</span><span>:</span>   <span>shr</span>      <span>%</span><span>rcx</span>                  <span>// length /= 2, but note it also sets FLAGS
</span><span></span> <span>1.64</span> <span>│</span>    <span>↑</span> <span>jne</span>      <span>70</span>                    <span>// Jump to instruction 20 if length not zero
</span></code></pre></div><p>The <code>branchless_lower_bound</code> assembly is really short and clean. While that’s a good indicator of speed, <code>sb_lower_bound</code> wins out in the performance tests due to low overhead.</p><h2 id="conclusion">Conclusion</h2><p>If the slowest part of your program involves searching and/or comparisons that a processor would not be able to predict then try clang with <code>-mllvm -x86-cmov-converter=false</code> (if your processor is x86).</p><p>If you’d benefit from a faster binary search, try <code>sb_lower_bound</code> (or for gcc you could also try <a href="https://github.com/mh-dm/sb_lower_bound/blob/master/sbm_lower_bound.h"><code>sbm_lower_bound</code></a>). I’ve made it open source, MIT license.</p><p>If you want more articles like this, follow me <a href="https://twitter.com/_mhdm">@_mhdm</a> on Twitter (I don’t post often). Alternatively, you can <a href="https://mhdm.dev/index.xml">use RSS</a>.</p><p>Code, including benchmarking, is available at <a href="https://github.com/mh-dm/sb_lower_bound/">github.com/mh-dm/sb_lower_bound/</a>.</p><p>If you have ideas, thoughts, or something to add you can <a href="https://www.reddit.com/r/cpp/comments/14okto7/fastest_branchless_binary_search/">leave a comment here</a>.</p><h2 id="update">Update</h2><p>Following a fruitful comment by <a href="https://orlp.net/">orlp.net author</a>, <code>sb_lower_bound</code> can be refactored slightly to reduce the number of assembly instructions in the hot loop from 9 to 8.</p><div><pre><code data-lang="C++"><span>// sb_lower_bound refactored
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>if</span> (comp(first[half], value)) {
      <span>// length - half equals half + length % 2
</span><span></span>      first <span>+=</span> length <span>-</span> half;
   }
   length <span>=</span> half;
}
<span>return</span> first;
</code></pre></div><p>With <code>clang -cmov</code> there’s a slight speed up from ~33ns to ~32ns for the average run time.</p><h3 id="prefetching">Prefetching</h3><p>From comments there was a recommended method for a further speed-up, namely prefetching. Prefetching pulls particular parts of memory into cache (usually L1/L2) so that when prefetched data is actually needed the load only incurs L1/L2 cache latency (~4/12 cycles) vs slower cache (L3, ~40 cycles) or memory latency (~200 cycles). <a href="https://www.7-cpu.com/cpu/Skylake.html">Example timings</a>. For this there’s <code>__builtin_prefetch()</code> supported in both gcc and clang.</p><p>Say we’re going to check against the element at <code>length / 2</code>. We could prefetch at <code>length / 4</code> and <code>length * 3 / 4</code>. Or we could also prefetch at <code>length / 8</code> divisions, which is an extra 4 memory locations. For <code>length / 4</code> divisions, 1 out of every 2 prefetches will be wasted, doubling cache pressure. If also <code>length / 8</code> divisions, 5 out of every 6 prefetches will be wasted. There’s overhead in computing the locations and prefetching, overhead that will be significant in the hot loop we worked hard to make short.</p><p>Finally, if we’ve already made a few full searches the initial divisions are likely to be in the cache as many elements should fit in modern 256KB+ L2 caches.</p><p>When trying various prefetching strategies, none helped for under 256KB arrays, which is about what we expect. Long story short, here’s <code>sb_lower_bound</code> but with prefetching added in for 256KB+:</p><div><pre><code data-lang="C++"><span>// sbp_lower_bound
</span><span></span><span>auto</span> length <span>=</span> last <span>-</span> first;
<span>// Sized to roughly fit in L2 cache
</span><span></span><span>constexpr</span> <span>int</span> entries_per_256KB <span>=</span> <span>256</span> <span>*</span> <span>1024</span> <span>/</span> <span>sizeof</span>(T);
<span>if</span> (length <span>&gt;=</span> entries_per_256KB) {
   <span>constexpr</span> <span>int</span> num_per_cache_line <span>=</span> std<span>::</span>max(<span>64</span> <span>/</span> <span>int</span>(<span>sizeof</span>(T)), <span>1</span>);
   <span>while</span> (length <span>&gt;=</span> <span>3</span> <span>*</span> num_per_cache_line) {
      <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
      __builtin_prefetch(<span>&amp;</span>first[half <span>/</span> <span>2</span>]);
      <span>// length - half equals half + length % 2
</span><span></span>      <span>auto</span> first_half1 <span>=</span> first <span>+</span> (length <span>-</span> half);
      __builtin_prefetch(<span>&amp;</span>first_half1[half <span>/</span> <span>2</span>]);
      first <span>=</span> comp(first[half], value) <span>?</span> first_half1 : first;
      length <span>=</span> half;
   }
}
<span>while</span> (length <span>&gt;</span> <span>0</span>) {
   <span>auto</span> half <span>=</span> length <span>/</span> <span>2</span>;
   <span>auto</span> first_half1 <span>=</span> first <span>+</span> (length <span>-</span> half);
   first <span>=</span> comp(first[half], value) <span>?</span> first_half1 : first;
   length <span>=</span> half;
}
<span>return</span> first;
</code></pre></div><p>Tested in the same way as before, for sizes ranging up to ~4 million entries (or 16MB), there’s a further speed up from ~32ns to ~26ns average run time. At this point I should acknowledge that my original size stopping point happened to be too small. A case of a quick ‘should be larger than L3 cache size’ and a mistake in not following up. So let’s go much higher, now to ~128 million entries (or 512MB). We’re way past L3 but still in reasonable data set size.</p><p>Runtimes in line chart form:</p><p><a href="https://mhdm.dev/posts/sb_lower_bound/runtimes2.png"><img src="https://mhdm.dev/posts/sb_lower_bound/runtimes2.png" alt="Runtimes 2"></a></p><p>There’s some interesting stuff going on.</p><ul><li>Branchless <code>std::lower_bound</code> that’s generated with <code>clang -cmov</code> is slower than the branchy version at massive sizes. Modern cpus follow predicted branches including loading from memory (basically a prefetch) and speculatively executing on said data (basically a <a href="https://en.wikipedia.org/wiki/Transient_execution_CPU_vulnerability">security nightmare</a>).</li><li><code>sbpm_lower_bound</code> is the prefetching version of <code>sbm_lower_bound</code> which does a multiply with a boolean to trick gcc into generating branchless code.</li><li>We’re at ~2.3x faster average time comparing <code>std::lower_bound</code> (~161ns) to prefetched version (~71ns).</li></ul><h3 id="faster">Faster?</h3><h4 id="drop-in-replacement-for-stdlower_bound">Drop in replacement for <code>std::lower_bound</code></h4><p>There’s a performance graph bump/weirdness between 1-10 million elements so faster is possible in theory. In practice the prefetching code is getting messy and gaining magic constants. An exciting part for me in writing this post was the (small) probability of contributing back to <a href="https://gcc.gnu.org/contribute.html">gcc/libstdc++</a> and/or <a href="https://libcxx.llvm.org/Contributing.html">llvm/libc++</a>. I’ll stop here as that probability gets even smaller with added complexity.</p><h4 id="breaking-stdlower_bound-constraints">Breaking <code>std::lower_bound</code> constraints</h4><p>Comments also noted the interesting <a href="https://algorithmica.org/en/eytzinger">Eytzinger Binary Search</a> variant where the input array is reshaped (into a binary med-“heap”) for lookups to be cache friendly. I could ponder how fast a SIMD optimized K-ary tree could be, but no need to ponder: 7x to 15x faster than <code>std::lower_bound</code> (for 16-ary tree of ints) as presented by <a href="https://www.youtube.com/watch?v=1RIPMQQRBWk">Sergey Slotin at CppCon 2022</a>.</p><h4 id="footnotes">Footnotes</h4><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>BUT RUST.. Rust is fast but do you really want my first post to be <a href="https://doc.rust-lang.org/src/core/slice/mod.rs.html#2520">about unsafe code</a>? <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p>BUT ZIG.. There’s no binary search implementation in Zig that I could find, rather it calls to C++. <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>There’s always a <a href="https://m.xkcd.com/149/">relevant XKCD</a>. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li><li id="fn:4" role="doc-endnote"><p>With clang we could do <a href="https://clang.llvm.org/docs/LanguageExtensions.html#builtin-unpredictable"><code>__builtin_unpredictable</code></a><code>(comp(first[half], value))</code> but it does nothing (tested v10-13). <a href="#fnref:4" role="doc-backlink">↩︎</a></p></li><li id="fn:5" role="doc-endnote"><p>gcc has <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html#index-_005f_005fbuiltin_005fexpect_005fwith_005fprobability"><code>__builtin_expect_with_probability</code></a><code>(cond, 0, 0.5)</code> but it does nothing (tested v10). <a href="#fnref:5" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There is no hard takeoff (142 pts)]]></title>
            <link>https://geohot.github.io//blog/jekyll/update/2023/08/10/there-is-no-hard-takeoff.html</link>
            <guid>37086779</guid>
            <pubDate>Fri, 11 Aug 2023 09:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geohot.github.io//blog/jekyll/update/2023/08/10/there-is-no-hard-takeoff.html">https://geohot.github.io//blog/jekyll/update/2023/08/10/there-is-no-hard-takeoff.html</a>, See on <a href="https://news.ycombinator.com/item?id=37086779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Back in 2014, Elon Musk referred to AI as <a href="https://www.washingtonpost.com/news/innovations/wp/2014/10/24/elon-musk-with-artificial-intelligence-we-are-summoning-the-demon/">summoning the demon</a>. And it wasn’t hard to see that view. Soon, <a href="https://en.wikipedia.org/wiki/AlphaGo">Go agents</a> would beat top humans learning from self play. By the end of 2017, the <a href="https://arxiv.org/abs/1712.01815">same algorithm</a> mastered Chess and Shogi. By 2020, it didn’t even need tons of calls to the simulator, and could <a href="https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules">play Atari too</a>.</p>

<p>AI looked scary. It looked like it was one FOOM away from self playing and becoming superhuman at the universe. And yet, here we are in 2023 and self driving cars still don’t work.</p>

<p>Does becoming superhuman at the universe make any practical sense? The universe has so many orders of magnitude more states than any Go game. And I don’t even need math to illustrate this point, just imagine tiling the universe with as many very tiny Go boards as you can fit.</p>

<p>That’s a lot of Go boards. So many that the difference in complexity between Go and the Universe is not a matter of number, it’s a matter of kind. Every Go program operates at the stone level. Almost nothing predicting the world operates at the atom level.</p>

<hr>


<p>These modern self play systems like <a href="https://arxiv.org/pdf/1911.08265.pdf">MuZero</a> have some form of dynamics model, a function that given the current state of the world and an action, it predicts the next state. We also use these dynamics models <a href="https://twitter.com/comma_ai/status/1681491118536691712">at comma</a>. They are world models, and contain all the knowledge of how the world works inside of them.</p>

<p>GPT-4 is a dynamics model also, conditioned on the prior of the action space. And there’s an even simpler way to think about it. The loss function for dynamics is compression.</p>

<p><a href="http://www.hutter1.net/ai/">Compression is prediction is intelligence, intelligence is prediction is compression.</a> One of the coolest facts I ever learned. So, feed in the whole internet, build a compressive model, make it really really big, and you just won the universe?</p>

<hr>


<p>Not so fast. This approach can lead to <a href="https://chat.openai.com/">very neat applications</a>, but does it take over the world?</p>

<p>You want to get rich? Here’s an idea. Download all the historical stock market data. Get lots and lots of GPUs to train a huge model. Boom, predictor for the stock market. I look at prediction, I know which stocks go up! I buy the stocks that go up, I short the stocks that go down. With mega leverage, I am a billionaire by the end of the week! I can reinvest my billions in more GPUs for recursive self improvement. Nobody will stop me, I will take over the whole economy. How is nobody doing this?!?</p>

<p>Oh wait…every hedge fund bro is already doing this. And most of them aren’t billionaires. The problem is your model needs to include all the computers playing the market, and it also needs to include the other hedge fund bros themselves. This strategy only dominates if you have more compute than the whole market itself, which you don’t.</p>

<hr>


<p>In Go, your model doesn’t need to include other computers. Yes, you are playing against a computer that you are modeling, but the game itself is way too small to contain a Go playing computer. The other computer you are playing against is outside the universe. The rules of Go don’t include computers. The rules of Go are fixed in complexity.</p>

<p>On the other hand, your dynamics model of the universe must include computers. You’ll have to spend a lot of effort modeling them. Unless you have an absolutely staggering advantage, you aren’t going to figure them out from self play. The computers are active players, and they have a lot of compute. They might even be using it to try to model you!</p>

<p>Assuming <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">no untoward market intervention</a>, why would any one system ever have a large majority of the compute? Compute will be distributed in a <a href="https://en.wikipedia.org/wiki/Power_law">power law</a>.</p>

<p>The smart regulation isn’t capping the FLOPS in training runs. That’s creating a powder keg. If the FLOPS are artificially restricted, and one person breaks the restriction, you could end up with a single dominant system.</p>

<p>If you don’t want FOOM, you just need to prevent a 51% attack on compute.</p>

<hr>


<p>Now, if there’s one weird trick to 1e20x your efficiency, and only one group gets it, all bets are off. But this is never how things happen. Nobody has a 1e20x more efficient steam engine, it isn’t even possible.</p>

<p>Nobody has a 1e20x more efficient Bitcoin miner either, and I also doubt that’s possible, we just <a href="https://en.wikipedia.org/wiki/Thermodynamics">understand</a> steam engines a lot better, so for steam engines we <em>know</em>. More intelligence leads to more new tricks, but the tricks get harder and harder to find.</p>

<p>There’s low hanging fruit, you pick it, then you build tools to get the higher hanging fruit. You spend money on ladders, electric crane thingies, more and more money to get less and less fruit. Oil <a href="https://en.wikipedia.org/wiki/Petroleum_seep">used to be</a> just pouring out of the ground, now we go <a href="https://www.indelac.com/blog/introduction-to-oil-gas-offshore-drilling">to the bottom</a> of the ocean.</p>

<hr>


<p>A revolution is coming. The information revolution will do for intelligence what the industrial revolution did for energy. Most work (force*distance) used to be done by muscles, now it’s not. Most thinking used to be done by brains, soon it won’t be.</p>

<p>But it’s not going to happen overnight. It’ll happen on a nice exponential, like it already is. The universe is an unfathomable number of orders of magnitude more complex than the Go game. The universe includes the player. The universe includes the other players. Games don’t.</p>

<p><img src="https://geohot.github.io/blog/assets/images/trolley.jpg" height="250"></p>

<p>Unless we build a terrifying powder keg, there is no FOOM. Let the markets cook.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Artificial General Intelligence – A gentle introduction (240 pts)]]></title>
            <link>https://cis.temple.edu/~pwang/AGI-Intro.html</link>
            <guid>37086308</guid>
            <pubDate>Fri, 11 Aug 2023 08:15:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cis.temple.edu/~pwang/AGI-Intro.html">https://cis.temple.edu/~pwang/AGI-Intro.html</a>, See on <a href="https://news.ycombinator.com/item?id=37086308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="ltr" id="sites-canvas-main"><center><span size="5"><b><br>
</b></span></center>
<center>
<span size="5"><b>Artificial General Intelligence</b></span></center>
<center>
<span size="4">— A gentle introduction</span></center>
<center><span size="4"><br>
</span></center>
<center>
<i><a href="http://www.cis.temple.edu/%7Epwang/" rel="nofollow">Pei Wang</a></i>
</center>
<p><span><span size="2">[This page contains up-to-date information about the field of Artificial General Intelligence (AGI), collected and organized according to my judgment, though efforts are made to avoid personal biases.] </span></span></p>
<div><p><span size="2"><div><p>Contents</p><ol><li><a href="#TOC-From-AI-to-AGI"><strong>1 </strong>From AI to AGI</a><ol><li><a href="#TOC-AI:-in-different-directions-and-through-seasonal-cycles"><strong>1.1 </strong>AI: in different directions, and through seasonal cycles</a></li><li><a href="#TOC-A-new-spring"><strong>1.2 </strong>A new spring</a></li><li><a href="#TOC-It-s-summer-again"><strong>1.3 </strong>It's summer again</a></li></ol></li><li><a href="#TOC-AGI-Basics"><strong>2 </strong>AGI Basics</a><ol><li><a href="#TOC-What-is-AGI"><strong>2.1 </strong>What is AGI</a></li><li><a href="#TOC-Limitations-and-objections"><strong>2.2 </strong>Limitations and objections</a></li><li><a href="#TOC-Strategies-and-techniques"><strong>2.3 </strong>Strategies and techniques</a></li><li><a href="#TOC-The-ethics-of-AGI"><strong>2.4 </strong>The ethics of AGI</a></li></ol></li><li><a href="#TOC-Representative-AGI-Projects"><strong>3 </strong>Representative AGI Projects</a></li><li><a href="#TOC-AGI-Literatures-and-Resources"><strong>4 </strong>AGI Literatures and Resources</a></li></ol></div></span></p></div>
<h2><a name="TOC-From-AI-to-AGI"></a>From AI to AGI</h2>
<h3><a name="TOC-AI:-in-different-directions-and-through-seasonal-cycles"></a>AI: in different directions, and through seasonal cycles</h3><p>
    Artificial Intelligence (AI) started with "thinking machine" or
    "human-comparable intelligence" as the ultimate goal, as documented by
    the following literature:
    
</p><ul>
<li><a href="http://cogprints.org/499/1/turing.html" rel="nofollow">Computing
          machinery and intelligence</a>, 1950</li>
<li><a href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html" rel="nofollow">Proposal of the Dartmouth Meeting</a>, 1956</li>
<li><a href="https://mitpress.mit.edu/books/computers-and-thought-1" rel="nofollow">Computers and Thought</a>, 1963</li>
</ul><p>
    In the past, there were some ambitious projects aiming at this goal,
    though they all failed. The best-known examples include the
    following ones:
</p><ul>
<li><a href="https://en.wikipedia.org/wiki/General_Problem_Solver" rel="nofollow">General Problem Solver</a> </li>
<li><a href="http://en.wikipedia.org/wiki/Fifth_generation_computer" rel="nofollow">Fifth
          Generation Computer Systems</a> </li>
<li><a href="https://en.wikipedia.org/wiki/Strategic_Computing_Initiative" rel="nofollow">DARPA's Strategic Computing Initiative</a></li>
</ul><p>
    Partly due to the recognized difficulty of the problem, in the
    1970s-1980s mainstream AI gradually moved away from general-purpose
    intelligent systems, and turned to domain-specific problems and
    special-purpose solutions, though there are opposite attitudes
    toward this change:
</p><ul>
<li>"<a href="https://www.americanscientist.org/article/the-manifest-destiny-of-artificial-intelligence" rel="nofollow">AI adopts
          the scientific method (1987-present): ... It is now more
        common to build on existing theories than to propose brand new
        ones, to base claims on rigorous theorems or hard experimental
        evidence rather than on intuition, and to show relevance to
        real-world applications rather than toy examples.</a>"</li>
<li>"<a href="https://www.wired.com/2003/08/why-a-i-is-brain-dead/" rel="nofollow">Only a small community has concentrated on general intelligence ... AI has been brain-dead since the 1970s.</a>" </li>
</ul><p>
    Consequently, the field currently called "AI" consists of many
    loosely related subfields without a common foundation or framework,
    and suffers from an identity crisis:
</p><ul>
<li><a href="http://en.wikipedia.org/wiki/AI_effect" rel="nofollow">External
          recognition</a>: As soon as a problem is solved, it is no
        longer considered as requiring "intelligence" anymore, so the AI community rarely gets credit. </li>
<li><a href="http://www.aaai.org/Library/President/Brachman.pdf" rel="nofollow">Internal
          fragmentation</a>: The subfields of AI become less and less
        associated to one another, even though their problems are closely
        related. </li>
</ul>
<h3><a name="TOC-A-new-spring"></a>A new spring</h3><p>
    Roughly in the period of 2004 to 2007, calls for research on
    general-purpose systems returned, both inside and outside mainstream
    AI.
    
</p><p> Anniversaries are good time to review the big picture of the
      field. In the following collections and events, many
      well-established AI researchers raised the topic of
      general-purpose and human-level intelligence: </p>
<ul>
<li><a href="http://www.aaai.org/ojs/index.php/aimagazine/issue/view/161/showToc" rel="nofollow">AI
          Magazine 26(4), Winter 2005</a>: for the 25th Anniversary of
        AAAI and AI Magazine </li>
<li><a href="http://www.aaai.org/ojs/index.php/aimagazine/issue/view/165/showToc" rel="nofollow">AI
          Magazine 27(4), Winter 2006</a>: for the 50th Anniversary of
        AI </li>
<li><a href="https://en.wikipedia.org/wiki/AI@50" rel="nofollow">AI@50</a>:
        2006 Dartmouth Artificial Intelligence Conference: The Next
        Fifty Years </li>
</ul><p>
    More or less coincidentally, from outside mainstream AI, there were several books with bold titles and novel technical approaches to produce
    intelligence as a whole in computers:
</p><ul>
<li>Eric Baum, <a href="http://www.whatisthought.com/" rel="nofollow">What is
          Thought?</a>, 2004 </li>
<li>Jeff Hawkins, <a href="https://numenta.com/resources/papers-videos-and-more/on-intelligence/" rel="nofollow">On Intelligence</a>, 2004 </li>
<li>Marcus Hutter, <a href="http://www.hutter1.net/ai/uaibook.htm" rel="nofollow">Universal
          Artificial Intelligence</a>, 2005 </li>
<li>Pei Wang, <a href="http://www.springer.com/west/home/computer/artificial?SGWID=4-147-22-173659733-0" rel="nofollow">Rigid
Flexibility:
          The Logic of Intelligence</a>, 2006 [The manuscript was finished in 2003.]</li>
<li>Ben Goertzel &amp; Cassio Pennachin (Editors), <a href="http://www.springer.com/sgw/cda/frontpage/0,11855,4-147-22-43950079-0,00.html" rel="nofollow">Artificial General Intelligence</a>, 2007 [The manuscript was finished in 2003.] </li>
</ul><p>
    There were also several less technical but more influential books,
    with the same optimism on the possibility of building
    general-purpose AI:
    
</p><ul>
<li>Ray Kurzweil, <a href="http://www.singularity.com/aboutthebook.html" rel="nofollow">The
          Singularity Is Near: When Humans Transcend Biology</a>, 2005 </li>
<li>Marvin Minsky, <a href="http://en.wikipedia.org/wiki/The_Emotion_Machine" rel="nofollow">The
          Emotion Machine: Commonsense Thinking, Artificial
          Intelligence, and the Future of the Human Mind</a>, 2006 </li>
<li>Ben Goertzel, <a href="http://www.brownwalker.com/book.php?method=ISBN&amp;book=1581129890" rel="nofollow">The
          Hidden Pattern: A Patternist Philosophy of Mind</a>, 2006 </li>
<li>J. Storrs Hall, <a href="https://www.google.com/books/edition/Beyond_AI/j6ofAQAAIAAJ?hl=en" rel="nofollow">Beyond AI: Creating the Conscience of the Machine</a>, 2007 </li>
</ul><p>
    So after several decades, "general-purpose system", "integrated AI",
    and "human-level AI" become less taboo (though still far from popular)
    topics, as shown by several related meetings:
    
</p><ul>
<li><a href="http://www.aaai.org/Library/Symposia/Fall/fs04-01.php" rel="nofollow">Achieving Human-Level Intelligence through Integrated Systems and Research, AAAI Fall Symposium (2004)</a>
</li>
<li><a href="http://www-cs.stanford.edu/groups/nips05-AI-Workshop/" rel="nofollow">Towards Human-Level AI?, NIPS Workshop (2005)</a>
</li>
<li><a href="http://www.aaai.org/Conferences/AAAI/2006/aaai06iictrack.php" rel="nofollow">AAAI conferences special track on Integrated Intelligent
        Capabilities (2006)</a>
</li>
<li><a href="http://www.iospress.nl/book/advances-in-artificial-general-intelligence-concepts-architectures-and-algorithms/" rel="nofollow">Artificial General Intelligence Workshop (2006)</a></li>
</ul>
<h3><a name="TOC-It-s-summer-again"></a>It's summer again</h3><p>

Since 2008, several research communities have emerged, with similar focuses and overlapping participants:
</p><ul>
<li>Artificial General Intelligence: <a href="http://www.agi-conf.org/" rel="nofollow">conferences</a>, <a href="https://sciendo.com/journal/JAGI" rel="nofollow">journal</a>, <a href="http://www.agi-society.org/" rel="nofollow">society</a> </li>
<li>Biologically Inspired Cognitive Architectures: <a href="https://bica.ai/" rel="nofollow">conferences</a>, <a href="http://www.sciencedirect.com/science/journal/2212683X" rel="nofollow">journal</a>,
        <a href="http://www.bicasociety.org/" rel="nofollow">society</a> </li>
<li>Advances in Cognitive Systems: <a href="http://www.cogsys.org/journal" rel="nofollow">journal</a>, <a href="http://www.cogsys.org/" rel="nofollow">conferences</a></li>
<li>IEEE Task Force on Towards Human-like Intelligence: <a href="http://www.mini.pw.edu.pl/%7Emandziuk/cis_tf_thli/" rel="nofollow">website</a>, <a href="http://www.mini.pw.edu.pl/~mandziuk/cis_tf_thli/?page=activities" rel="nofollow">conferences</a></li>
</ul><p>
More research books have been published:
</p><ul>
<li>Joscha Bach, <a href="https://global.oup.com/academic/product/principles-of-synthetic-intelligence-psi-an-architecture-of-motivated-cognition-9780195370676" rel="nofollow">Principles of Synthetic Intelligence PSI: An Architecture of Motivated Cognition</a>, 2009</li>
<li>John Laird, <a href="http://mitpress.mit.edu/books/soar-cognitive-architecture" rel="nofollow">The Soar Cognitive Architecture</a>, 2012</li>
<li>Pei Wang and Ben Goertzel (Editors), <a href="http://www.springer.com/computer/ai/book/978-94-91216-61-9" rel="nofollow">Theoretical
          Foundations of Artificial General Intelligence</a>, 2012</li>
<li>Pei Wang, <a href="http://www.worldscientific.com/worldscibooks/10.1142/8665" rel="nofollow">Non-Axiomatic
Logic: A Model of Intelligent Reasoning</a>, 2013</li>
<li>Ben Goertzel <i>et al.</i>, Engineering General Intelligence, <a href="http://www.springer.com/computer/ai/book/978-94-6239-026-3" rel="nofollow">Part 1</a> and <a href="http://www.springer.com/computer/ai/book/978-94-6239-029-4" rel="nofollow">Part 2</a>, 2014</li>
</ul>
<p>In mainstream AI, <a href="https://en.wikipedia.org/wiki/Deep_learning" rel="nofollow">deep learning</a> has made impressive progress in recent years, which raises many people's hope on "human-level" AI once again. The claim <a href="https://www.telegraph.co.uk/technology/news/10884839/Computer-passes-Turing-Test-for-the-first-time-after-convincing-users-it-is-human.html" rel="nofollow">"The Turing Test has been passed"</a> and the success of <a href="https://en.wikipedia.org/wiki/AlphaGo" rel="nofollow">AlphaGo</a> in the board game Go renewed the discussion on what "artificial intelligence" is really about, and how to reach it. There is still no consensus, and the <a href="https://content.sciendo.com/view/journals/jagi/11/2/article-p1.xml" rel="nofollow">opinions</a> are not even converging. Several large companies have labeled their results as "steps towards AGI", and their approaches are either extensions of deep learning or integrations of the existing AI techniques. This approach is exemplified by <a href="https://openai.com/research/gpt-4">GPT-4</a>, which is claimed by its creator as "a significant step towards AGI".
</p>
<p>
Partly triggered by the recent progresses, more and more people consider AGI, or whatever it is called, as really possible. As a consequence, the risk and safety of it becomes a hot topic:
</p><ul>
<li><a href="https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies" rel="nofollow">Superintelligence: Paths, Dangers, Strategies</a> by Nick Bostrom, 2014</li>
<li><a href="hhttps://futureoflife.org/open-letter/pause-giant-ai-experiments/" rel="nofollow">Pause Giant AI Experiments: An Open Letter</a> from the Future of Life Institute, 2023</li>
</ul>

<h2><a name="TOC-AGI-Basics"></a>AGI Basics</h2>
<div><p>The most general questions every AGI researcher needs to answer include:
  </p><ol><li>What is AGI, accurately specified?</li>
<li>Is it possible to build the AGI as specified?</li>
<li>If AGI is possible, what is the most plausible way to achieve it?</li>
<li>Even if we know how to achieve AGI, should we really do it?</li>
</ol><p>
[My own answers to these questions are <a href="http://www.iiim.is/2010/05/questions-about-artificial-intelligence/" rel="nofollow">here</a>.]</p></div>
<p>In the following the major answers in the field of AGI are summarized.</p>
<h3><a name="TOC-What-is-AGI"></a>What is AGI</h3><p>
Roughly speaking, Artificial General Intelligence (AGI) research has the following features:
</p><ul>
<li>Stressing on the <i>general-purpose</i> nature of intelligence,</li>
<li>Taking a <i>holistic or integrative</i> viewpoint on intelligence,</li>
<li>Believing the time has come to build an AI that is comparable to human intelligence.</li></ul><p>
Therefore, "AGI" is closer to the original meaning "AI", while very different from the current mainstream "AI research", which focuses on domain-specific and problem-specific methods. "AGI" is similar or related to notions like "<a href="http://en.wikipedia.org/wiki/Strong_AI" rel="nofollow">strong AI</a>", "<a href="http://www-formal.stanford.edu/jmc/human/human.html" rel="nofollow">human-level AI</a>", "<a href="http://en.wikipedia.org/wiki/AI-complete" rel="nofollow">complete AI</a>", "<a href="http://cogprints.org/499/1/turing.html" rel="nofollow">thinking machine</a>", "<a href="http://en.wikipedia.org/wiki/Cognitive_computing" rel="nofollow">cognitive computing</a>", and some others. <a href="https://goertzel.org/who-coined-the-term-agi/">Here</a> is an explanation about the selection of the term "AGI".
</p><p>
Even though there is a vague consensus on the objective of reproducing "intelligence" as a whole in computers, the current AGI projects are not aimed at exactly the same goal. Though every AGI approach gets its inspiration from the same source, that is, human intelligence, here "intelligence" is understood in several senses. Consequently, AGI projects attempt to duplicate human intelligence at different levels of abstraction:
</p><ul>
<li><b>Structure</b><br>
            Rationale: Intelligence is produced by the human brain. Therefore, to build an intelligent computer means to simulate the brain structure as faithfully as possible.<br>
            Background: Neuroscience, biology, etc.<br>
            Examples:&nbsp; <a href="http://en.wikipedia.org/wiki/Hierarchical_Temporal_Memory" rel="nofollow">HTM</a>,&nbsp;<a href="https://www.vicarious.com/" rel="nofollow">Vicarious</a><br>
            Challenge: There may be biological details that are neither
            possible nor necessary to be reproduced in AI systems.
      </li>
<li><b>Behavior</b><br>
            Rationale: Intelligence is displayed in how the human beings
            behave. Therefore, the goal should be to make a computer to behave exactly like a human.<br>
            Background: Psychology, linguistics, etc.<br>
            Examples: <a href="http://en.wikipedia.org/wiki/Turing_test" rel="nofollow">Turing
              Test</a>, <a href="https://openai.com/blog/chatgpt/" rel="nofollow">ChatGPT</a><br>
            Challenge: There may be psychological or social factors that are
            neither possible nor necessary to be reproduced in AI
            systems.
      </li>
<li><b>Capability</b><br>
            Rationale: Intelligence is evaluated by problem-solving capability. Therefore, an intelligent system should be able to solve certain practical problem that is currently solvable by humans only.<br>
            Background: Computer application guided by domain knowledge<br>
            Examples: <a href="https://en.wikipedia.org/wiki/IBM_Watson" rel="nofollow">IBM Watson</a>, <a href="https://en.wikipedia.org/wiki/AlphaGo" rel="nofollow">AlphaGo</a><br>
            Challenge: There is no defining problems of intelligence, and the
            special-purpose solutions lack generality and flexibility.
      </li>
<li><b>Function</b><br>
            Rationale: Intelligence is associated to a collection of cognitive
            functionality, such as perceiving, reasoning, learning, acting, communicating, problem solving, etc. Therefore the goal is to reproduce these functions in computers.<br>
            Background: Computer science<br>
            Examples: <a href="http://aima.cs.berkeley.edu/chapters.html" rel="nofollow">Mainstream
              AI textbooks</a>, <a href="http://soar.eecs.umich.edu/" rel="nofollow">Soar</a><br>
            Challenge: The AI techniques developed so far are highly
            fragmented and rigid, and it is hard for them to work together.
      </li>
<li><b>Principle</b><br>
            Rationale: Intelligence is a form of rationality or
            optimality. Therefore, an intelligent system should always "do the right thing" according to certain general principles.<br>
            Background: Logic, mathematics, etc.<br>
            Examples: <a href="http://www.hutter1.net/ai/uaibook.htm" rel="nofollow">AIXI</a>, <a href="https://cis.temple.edu/~pwang/NARS-Intro.html">NARS</a>
<br>
            Challenge: There are too many aspects in intelligence and cognition to be explained and reproduced by a
            simple theory.</li></ul>
<p>
From top to bottom, they correspond to descriptions of human intelligence in more and more general level, and to reproduce that description in computer systems. Since different descriptions have different granularity and scope, the above objectives are related, but still very different, and do not subsume each other. The best way to achieve one is usually not a good choice for the others. [A more detailed discussion of this issue can be found <a href="https://content.sciendo.com/view/journals/jagi/10/2/article-p1.xml" rel="nofollow">here</a>.]
</p><p>
The "general purpose" nature of AGI has also obtained different interpretations over the years, as meaning
</p>
<p><i><ol>
<li>Can solve all problems,</li>
<li>Can solve all human-solvable problems,</li>
<li>Can solve all computable problems,</li>
<li>Can try to solve all representable problems.</li>
</ol></i></p><p>
Because of this diversity in research goal, in AGI currently there is no commonly accepted evaluation criteria (such as milestones and benchmarks).

</p>
<h3><a name="TOC-Limitations-and-objections"></a>Limitations and objections</h3><p>

Since the idea of AI or "thinking machine" appeared, there have been various objections against its possibility. Some people claimed that they have proved that AGI, or whatever it is called, is theoretically impossible, due to certain fundamental limitations of computers.
</p><p>
Many researchers have argued against these objections. Classical arguments can be found in the following works:
</p>
<ul>
<li><a href="http://cogprints.org/499/1/turing.html" rel="nofollow">Computing machinery and
    intelligence</a>, Alan M. Turing</li>
<li><a href="http://en.wikipedia.org/wiki/G%C3%B6del%2C_Escher%2C_Bach" rel="nofollow">G<span color="#6a6a6a" face="Arial">ö</span>del, Escher, Bach: An Eternal Golden Braid</a>, Douglas R. Hofstadter</li>
</ul><p>
Obviously, all AGI researchers believe that AGI can be achieved (though they have different interpretations to the term). In the <a href="http://www.cis.temple.edu/~pwang/Publication/AGI_Aspects.pdf" rel="nofollow">introductory chapter of the AGI 2006 Workshop Proceedings</a>, I and Ben Goertzel responded to the following common doubts and objections of this research:
</p><ul><i>
<li>AGI is impossible.</li>
<li>There is no such a thing as general intelligence.</li>
<li>General-purpose systems are not as good as special-purpose ones.</li>
<li>AGI is already included in the current AI.</li>
<li>It is too early to work on AGI.</li>
<li>AGI is nothing but hype.</li>
<li>AGI research is not fruitful.</li>
<li>AGI is dangerous.</li>
</i></ul>
<p>Some of the doubts about the possibility of AGI come from misconceptions on what AGI attempts to achieve or what computers can do. The previous subsection has clarified the former issue, while an analysis of the latter issue can be found <a href="http://www.cis.temple.edu/~pwang/Publication/AI_Misconceptions.pdf" rel="nofollow">here</a>.</p>
<h3><a name="TOC-Strategies-and-techniques"></a>Strategies and techniques</h3><p>

On one hand, the ultimate goal of AGI is to reproduce intelligence as a whole, while on the other hand, engineering practice must be step-by-step. To resolve this dilemma, three overall strategies have been proposed:
    
</p><ul>
<li><b>Hybrid</b><br>
            Approach: To develop individual functions first (using
            different theories and techniques), then to connect them
            together.<br>
            Argument: <a href="http://www.aaai.org/Library/President/Brachman.pdf" rel="nofollow">(AA)AI:
              More than the Sum of Its Parts</a>, Ronald Brachman<br>
            Difficulty: Compatibility of the theories and techniques
      </li>
<li><b>Integrated</b><br>
            Approach: To design an architecture first, then to design
            its modules (using various techniques) accordingly.<br>
            Argument: <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.233.1596" rel="nofollow">Cognitive
              Synergy: A Universal Principle for Feasible General
              Intelligence?</a>, Ben Goertzel<br>
            Difficulty: Isolation, specification, and coordination of
            the functions
      </li>
<li><b>Unified</b><br>
            Approach: Using a single technique to start from a core
            system, then to extend and augment it incrementally.<br>
            Argument: <a href="http://www.cis.temple.edu/%7Epwang/Publication/unifiedAI.pdf" rel="nofollow">Toward
              a Unified Artificial Intelligence</a>, Pei Wang<br>
            Difficulty: Versatility and extensibility of the core technique
      </li>
</ul><p>
Obviously, the selection of development strategy partially depends on the selection of the research objective.
</p>
<div><p>At the current time, the major techniques used in AGI projects include, though are not limited to:
</p><ul><li>logic</li>
<li>probability theory</li>
<li>production system</li>
<li>graph theory</li>
<li>knowledge base</li>
<li>learning algorithm</li>
<li>neural network</li>
<li>evolutionary computation</li>
<li>robotics</li>
<li>multi-agent system</li></ul><p>
Though each of these techniques is also explored in mainstream AI, to use it in a general-purpose system leads to very different design decisions in technical details.</p><h3><a name="TOC-The-ethics-of-AGI"></a>The ethics of AGI</h3>
<p>Even if we have found out how to achieve AGI, it does not necessarily mean we really want to do it. Like all major scientific discoveries and technical breakthroughs, AGI has the potential to revolutionize our life and even the fate of the human species, either in a desired way or an undesired way — or, as things usually go, a mixture of the two.
</p>
<p>AGI researchers are aware of their responsibility on this topic, though most of them think that, according to the currently available evidence, progress in AGI research will benefit the human species, rather than to destroy it. Discussions on how to make AGI "safe" have existed in AGI meetings since the very beginning. Sample discussions include</p>
<ul>
<li><a href="http://agi-conf.org/2008/" rel="nofollow">AGI-08</a> had a workshop on <a href="http://agi-conf.org/2008/workshop/" rel="nofollow">The Sociocultural, Ethical and Futurological Implications of Artificial General Intelligence</a></li>
<li><a href="http://agi-conf.org/2012/" rel="nofollow">AGI-12</a> was jointly sponsored by Oxford's <a href="https://www.fhi.ox.ac.uk/" rel="nofollow">Future of Humanity Institute</a>. In this conference, many papers address ethical and moral issues</li>
</ul>
<p>Of course, many crucial problems remain open, but to find their solutions, the research of AGI should be speed up, rather than slowed down. Once again, some wide-spreading concerns and fears about AGI are based on misconceptions about the nature of AGI.</p>
	
<h2><a name="TOC-Representative-AGI-Projects"></a>Representative AGI Projects</h2><p>

The following projects are selected to represent the current AGI research, as for each of them, it can be said that</p></div>
<div>
<ol><li>It is clearly oriented to AGI (that is why IBM's Watson and DeepMind's AlphaGo are not included)</li>
<li>It is still very active (that is why Pollock's OSCAR and Brooks' Cog are no longer included)</li>
<li>It has ample publications on technical details (that is why many recent AGI projects are not included yet, except GPT-4 that is used to represent various deep learning projects toward AGI)</li>
</ol>
<p>The projects are listed in alphabetical order. Each project name is linked to the project website, where the following quotations are extracted. The focus of the quotations is on the research goal (the 1st question) and technical path (the 3rd question). Two publications on the project are selected, usually one brief introduction and one detailed description.</p>
<blockquote><i>
</i></blockquote>
<p><b><a href="http://act-r.psy.cmu.edu/" rel="nofollow">ACT-R</a></b>
[<a href="http://act-r.psy.cmu.edu/wordpress/wp-content/uploads/2012/12/526FSQUERY.pdf" rel="nofollow">An Integrated Theory of the Mind</a>; <a href="http://act-r.psy.cmu.edu/book/" rel="nofollow">The Atomic Components of Thought</a>]
    <i>
<blockquote>
    ACT-R is a cognitive architecture: a theory for simulating and
          understanding human cognition. Researchers working on ACT-R
          strive to understand how people organize knowledge and produce
          intelligent behavior. As the research continues, ACT-R evolves
          ever closer into a system which can perform the full range of
          human cognitive tasks: capturing in great detail the way we
          perceive, think about, and act on the world. 
<p>
On the exterior, ACT-R looks like a programming language;
          however, its constructs reflect assumptions about human
          cognition. These assumptions are based on numerous facts
          derived from psychology experiments. Like a programming
          language, ACT-R is a framework: for different tasks (e.g.,
          Tower of Hanoi, memory for text or for list of words, language
          comprehension, communication, aircraft controlling),
          researchers create models (aka programs) that are written in
          ACT-R and that, beside incorporating the ACT-R's view of
          cognition, add their own assumptions about the particular
          task. These assumptions can be tested by comparing the results
          of the model with the results of people doing the same tasks.
     </p>
<p>
     ACT-R is a hybrid cognitive
          architecture. Its symbolic structure is a production system;
          the subsymbolic structure is represented by a set of massively
          parallel processes that can be summarized by a number of
          mathematical equations. The subsymbolic equations control many
          of the symbolic processes. For instance, if several
          productions match the state of the buffers, a subsymbolic
          utility equation estimates the relative cost and benefit
          associated with each production and decides to select for
          execution the production with the highest utility. Similarly,
          whether (or how fast) a fact can be retrieved from declarative
          memory depends on subsymbolic retrieval equations, which take
          into account the context and the history of usage of that
          fact. Subsymbolic mechanisms are also responsible for most
          learning processes in ACT-R.
        </p>
</blockquote>
</i>
<b><a href="https://openaera.org/" rel="nofollow">AERA</a></b>
[<a href="https://alumni.media.mit.edu/~kris/ftp/AnytimeBoundedRationalityagi15_nivelEtAl.pdf" rel="nofollow">Anytime Bounded Rationality</a>; <a href="https://alumni.media.mit.edu/~kris/ftp/AERA-RUTR-SCS13002.pdf" rel="nofollow">Autocatalytic Endogenous Reflective Architecture</a>]
    <i>
<blockquote>
    AERA is a cognitive architecture - and a blueprint - for constructing agents with high levels of operational autonomy, starting from only a small amount of designer-specified code – a seed. Using a value-driven dynamic priority scheduling to control the parallel execution of a vast number of lines of reasoning, the system accumulates increasingly useful models of its experience, resulting in recursive self-improvement that can be autonomously sustained after the machine leaves the lab, within the boundaries imposed by its designers. 
<p>
AERA demonstrates domain-independent self-supervised cumulative learning of complex tasks. Unlike contemporary AI systems, AERA-based agents excel at handling novelty - situations, information, data, tasks - that their programmers could not anticipate. It is the only implementable / implemented system in existence for achieving bounded recursive self-improvement.
     </p>
<p>
     AERA-based agents learn cumulatively from experience by interacting with the world and generating compositional causal-relational micro-models of its experience. Using non-axiomatic abduction and deduction, it constantly predicts how to achieve its active goals and what the future may hold, generating a flexible opportunistically-interruptable plan for action.
        </p>
</blockquote>
</i>
<b><a href="http://www.hutter1.net/ai/index.htm" rel="nofollow">AIXI</a></b>  [<a href="http://www.hutter1.net/ai/aixigentle.htm" rel="nofollow">Universal Algorithmic Intelligence: A mathematical top-&gt;down approach</a>; <a href="http://www.hutter1.net/ai/uaibook.htm" rel="nofollow">Universal Artificial Intelligence</a><span>]</span><i>
<blockquote>An important observation is that most, if not all known facets of intelligence can be formulated as goal driven or, more precisely, as maximizing some utility function.
<p>Sequential decision theory formally solves the problem of rational agents in uncertain worlds if the true environmental prior probability distribution is known. Solomonoff's theory of universal induction formally solves the problem of sequence prediction for unknown prior distribution. We combine both ideas and get a parameter-free theory of universal Artificial Intelligence. We give strong arguments that the resulting AIXI model is the most intelligent unbiased agent possible.</p>
<p>The major drawback of the AIXI model is that it is uncomputable, ... which makes an implementation impossible. To overcome this problem, we constructed a modified model AIXItl, which is still effectively more intelligent than any other time t and length l bounded algorithm.</p>
</blockquote>
</i>
<b><a href="http://www.cyc.com/" rel="nofollow">Cyc</a></b> [<a href="http://www.csee.umbc.edu/courses/471/papers/cyc95.pdf" rel="nofollow">Cyc: A Large-Scale Investment in Knowledge Infrastructure</a>; <a href="https://www.researchgate.net/publication/220545983_D_B_Lenat_and_R_V_Guha_Building_Large_Knowledge-Based_Systems_Representation_and_Inference_in_the_Cyc_Project" rel="nofollow">Building Large Knowledge-Based Systems</a>]<i>
<blockquote>Vast amounts of commonsense knowledge, representing human consensus reality, would need to be encoded to produce a general AI system. In order to mimic human reasoning, Cyc would require background knowledge regarding science, society and culture, climate and weather, money and financial systems, health care, history, politics, and many other domains of human experience. The Cyc Project team expected to encode at least a million facts spanning these and many other topic areas.
<p>The Cyc knowledge base (KB) is a formalized representation of a vast quantity of fundamental human knowledge: facts, rules of thumb, and heuristics for reasoning about the objects and events of everyday life. The medium of representation is the formal language CycL. The KB consists of terms -- which constitute the vocabulary of CycL -- and assertions which relate those terms. These assertions include both simple ground assertions and rules.</p>
</blockquote>
</i>
<b><a href="https://openai.com/research/gpt-4" rel="nofollow">GPT-4</a></b> [<a href="https://cdn.openai.com/papers/gpt-4.pdf" rel="nofollow">GPT-4 Technical Report</a>; <a href="https://arxiv.org/abs/2303.12712">Sparks of Artificial General Intelligence</a>]<i>
<blockquote>
We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks. <p>
The combination of the generality of GPT-4's capabilities, with numerous abilities spanning a broad swath of domains, and its performance on a wide spectrum of tasks at or beyond human-level, makes us comfortable with saying that GPT-4 is a significant step towards AGI.</p>
</blockquote>
</i>
<b><a href="http://en.wikipedia.org/wiki/Hierarchical_Temporal_Memory" rel="nofollow">HTM</a></b> [<a href="http://numenta.com/assets/pdf/whitepapers/hierarchical-temporal-memory-cortical-learning-algorithm-0.2.1-en.pdf" rel="nofollow">Hierarchical Temporal Memory</a>; <a href="http://www.onintelligence.org/" rel="nofollow">On Intelligence</a>]<i>
<blockquote>At the core of every Grok model is the Cortical Learning Algorithm (CLA), a detailed and realistic model of a layer of cells in the neocortex. Contrary to popular belief, the neocortex is not a computing system, it is a memory system. When you are born, the neocortex has structure but virtually no knowledge. You learn about the world by building models of the world from streams of sensory input. From these models, we make predictions, detect anomalies, and take actions.
<p>In other words, the brain can best be described as a predictive modeling system that turns predictions into actions. Three key operating principles of the neocortex are described below: sparse distributed representations, sequence memory, and on-line learning.</p>
</blockquote>
</i><b><a href="http://ccrg.cs.memphis.edu/projects.html" rel="nofollow">LIDA</a></b>
[<a href="http://ccrg.cs.memphis.edu/assets/papers/zo-1010-lida-060403.pdf" rel="nofollow">The LIDA Architecture</a>;
<a href="http://ccrg.cs.memphis.edu/tutorial/tutorial.html" rel="nofollow">LIDA Tutorial</a>]
  <i>
  <blockquote>
Implementing and fleshing out
          a number of psychological and neuroscience theories of
          cognition, the LIDA conceptual model aims at being a cognitive
          "theory of everything." With modules or processes for
          perception, working memory, episodic memories,
          "consciousness," procedural memory, action selection,
          perceptual learning, episodic learning, deliberation,
          volition, and non-routine problem solving, the LIDA model is
          ideally suited to provide a working ontology that would allow
          for the discussion, design, and comparison of AGI systems. The
          LIDA technology is based on the LIDA cognitive cycle, a sort
          of "cognitive atom." The more elementary cognitive modules
          play a role in each cognitive cycle. Higher-level processes
          are performed over multiple cycles.
    
<p>
     The LIDA architecture
          represents perceptual entities, objects, categories,
          relations, etc., using nodes and links .... These serve as
          perceptual symbols acting as the common currency for
          information throughout the various modules of the LIDA
          architecture.</p>
</blockquote>
</i><b><a href="http://cognitive-ai.com/" rel="nofollow">MicroPsi</a></b><span>  [</span><a href="http://cognitive-ai.com/publications/assets/MicroPsiArchitectureICCM03.pdf" rel="nofollow">The MicroPsi Agent Architecture</a><span>;  </span><a href="https://global.oup.com/academic/product/principles-of-synthetic-intelligence-psi-an-architecture-of-motivated-cognition-9780195370676?cc=us&amp;lang=en&amp;" rel="nofollow">Principles of Synthetic Intelligence</a><span>]</span><i>
<blockquote>The MicroPsi agent architecture describes the interaction of emotion, 
motivation and cognition of situated agents, mainly based on the Psi 
theory of Dietrich Dorner. 
The Psi theory addresses emotion, perception, representation and bounded
 rationality, but being formulated within psychology, has had relatively
 little impact on the discussion of agents within computer science. 
MicroPsi is a formulation of the original theory in a more abstract and 
formal way, at the same time enhancing it with additional concepts for 
memory, building of ontological categories and attention.
<p>The agent framework uses semantic networks, called node nets, that are a
 unified representation for control structures, plans, sensory and 
action schemas, Bayesian networks and neural nets. Thus it is possible 
to set up different kinds of agents on the same framework.</p>
</blockquote>
</i><b><a href="http://opennars.org/">NARS</a></b><span>  [</span><a href="https://proceedings.mlr.press/v192/wang22a/wang22a.pdf">Intelligence: From Definition to Design</a><span>;  </span><a href="http://www.springer.com/west/home/computer/artificial?SGWID=4-147-22-173659733-0" rel="nofollow">Rigid Flexibility: The Logic of Intelligence</a><span>]</span><i>
<blockquote>What makes NARS different from conventional reasoning systems is its ability to learn from its experience and to work with insufficient knowledge and resources. NARS attempts to uniformly explain and reproduce many cognitive facilities, including reasoning, learning, planning, etc, so as to provide a unified theory, model, and system for AI as a whole. The ultimate goal of this research is to build a thinking machine.
<p>The development of NARS takes an incremental approach consisting four major stages. At each stage, the logic is extended to give the system a more expressive language, a richer semantics, and a larger set of inference rules; the memory and control mechanism are then adjusted accordingly to support the new logic.</p>
<p>In NARS the notion of "reasoning" is extended to represent a system's ability to predict the future according to the past, and to satisfy the unlimited resources demands using the limited resources supply, by flexibly combining justifiable micro steps into macro behaviors in a domain-independent manner.</p>
</blockquote>
</i><b><a href="http://opencog.org/" rel="nofollow">OpenCog</a> </b><span>[</span><a href="https://arxiv.org/abs/2103.15100v3" rel="nofollow">The General Theory of General Intelligence: A Pragmatic Patternist Perspective</a><span>; Engineering General Intelligence, </span><a href="http://www.springer.com/computer/ai/book/978-94-6239-026-3" rel="nofollow">Part 1</a><span> and </span><a href="http://www.springer.com/computer/ai/book/978-94-6239-029-4" rel="nofollow">Part 2</a><span>]</span><i>
<blockquote>OpenCog, as a software framework, aims to provide research scientists and software developers with a common platform to build and share artificial intelligence programs. The long-term goal of OpenCog is acceleration of the development of beneficial AGI.
<p>OpenCogPrime is a specific AGI design being constructed within the OpenCog framework. It comes with a fairly detailed, comprehensive design covering all aspects of intelligence. The hypothesis is that if this design is fully implemented and tested on a reasonably-sized distributed network, the result will be an AGI system with general intelligence at the human level and ultimately beyond.</p>
<p>While an OpenCogPrime based AGI system could do a lot of things, we are initially focusing on using OpenCogPrime to control simple virtual agents in virtual worlds. We are also experimenting with using it to control a Nao humanoid robot. See http://novamente.net/example for some illustrative videos.</p>
</blockquote>
</i><b><a href="http://cogarch.ict.usc.edu/" rel="nofollow">Sigma</a></b><span> [</span><a href="https://www.dropbox.com/s/bsfsyot89xl28zo/SM%20Symp%20Sigma%202017%20Revised%20D.pdf" rel="nofollow">Lessons from Mapping Sigma onto the Standard Model of the Mind</a><span>; </span><a href="https://sciendo.com/article/10.1515/jagi-2016-0001" rel="nofollow">The Sigma Cognitive Architecture and System</a><span>]</span><i>
<blockquote>The goal of this effort is to develop a sufficiently efficient, 
functionally elegant, generically cognitive, grand unified, cognitive 
architecture in support of virtual humans (and hopefully intelligent 
agents/robots – and even a new form of unified theory of human cognition
 – as well).<p>

Our focus is on the development of the <em>Sigma</em> (∑) architecture, which explores the <em>graphical architecture hypothesis</em>
 that progress at this point depends on blending what has been learned 
from over three decades worth of independent development of cognitive 
architectures and <em>graphical models</em>, a broadly applicable state-of-the-art formalism for constructing intelligent mechanisms.  The result is a <em>hybrid</em> (discrete+continuous) <em>mixed</em>
 (symbolic+probabilistic) approach that has yielded initial results 
across memory and learning, problem solving and decision making, mental 
imagery and perception, speech and natural language, and emotion and 
attention.</p></blockquote>
</i><b><a href="http://www.cse.buffalo.edu/sneps/" rel="nofollow">SNePS</a></b>
[<a href="http://www.cse.buffalo.edu/%7Eshapiro/Papers/shabon09a.pdf" rel="nofollow">The
GLAIR Cognitive Architecture</a>; <a href="http://www.cse.buffalo.edu/sneps/Tutorial/" rel="nofollow">SNePS Tutorial</a>]
<i>
<blockquote>
The long term goal of the SNePS Research Group is to understand the
          nature of intelligent cognitive processes by developing and
          experimenting with computational cognitive agents that are
          able to use and understand natural language, reason, act, and
          solve problems in a wide variety of domains.
          
<p>
          The SNePS knowledge representation, reasoning, and
          acting system has several features that facilitate
          metacognition in SNePS-based agents. The most prominent is the
          fact that propositions are represented in SNePS as terms
          rather than as logical sentences. The effect is that
          propositions can occur as arguments of propositions, acts, and
          policies without limit, and without leaving first-order logic.</p>
</blockquote>
</i></p><p><b><a href="http://soar.eecs.umich.edu/" rel="nofollow">Soar</a></b> [<a href="http://www.cse.msu.edu/~cse841/papers/Soar.pdf" rel="nofollow">A Gentle Introduction to Soar</a>; <a href="http://mitpress.mit.edu/books/soar-cognitive-architecture" rel="nofollow">The Soar Cognitive Architecture</a>]</p>
<blockquote><i>The ultimate in intelligence would be complete rationality which would imply the ability to use all available knowledge for every task that the system encounters. Unfortunately, the complexity of retrieving relevant knowledge puts this goal out of reach as the body of knowledge increases, the tasks are made more diverse, and the requirements in system response time more stringent. The best that can be obtained currently is an approximation of complete rationality. The design of Soar can be seen as an investigation of one such approximation.
<p>For many years, a secondary principle has been that the number of distinct architectural mechanisms should be minimized. Through Soar 8, there has been a single framework for all tasks and subtasks (problem spaces), a single representation of permanent knowledge (productions), a single representation of temporary knowledge (objects with attributes and values), a single mechanism for generating goals (automatic subgoaling), and a single learning mechanism (chunking). We have revisited this assumption as we attempt to ensure that all available knowledge can be captured at runtime without disrupting task performance. This is leading to multiple learning mechanisms (chunking, reinforcement learning, episodic learning, and semantic learning), and multiple representations of long-term knowledge (productions for procedural knowledge, semantic memory, and episodic memory).</p>
<p>Two additional principles that guide the design of Soar are functionality and performance. Functionality involves ensuring that Soar has all of the primitive capabilities necessary to realize the complete suite of cognitive capabilities used by humans, including, but not limited to reactive decision making, situational awareness, deliberate reasoning and comprehension, planning, and all forms of learning. Performance involves ensuring that there are computationally efficient algorithms for performing the primitive operations in Soar, from retrieving knowledge from long-term memories, to making decisions, to acquiring and storing new knowledge.</p>
</i></blockquote>
<p><b>A rough classification</b></p><p>
The above AGI projects are roughly classified in the following
        table, according to the type of their answers to the previously
        listed 1st question (on research goal) and 3rd question (on
        technical path).
</p>

<center>
<table>
<tbody>
<tr>
<td><i>goal  \  path</i></td>
<td><b>hybrid</b></td>
<td><b>integrated</b></td>
<td><b>unified</b></td>
</tr>
<tr>
<td><b>principle</b></td>
<td> </td>
<td><br>
</td>
<td>AERA, AIXI, NARS</td>
</tr>
<tr>
<td><b>function</b></td>
<td><br>
</td>
<td>OpenCog, Sigma, Soar</td>
<td>SNePS</td>
</tr>
<tr>
<td><b>capability</b></td>
<td><br>
</td>
<td><br>
</td>
<td>Cyc</td>
</tr>
<tr>
<td><b>behavior</b></td>
<td><br>
</td>
<td>ACT-R, LIDA, MicroPsi</td>
<td>GPT-4</td>
</tr>
<tr>
<td><b>structure</b></td>
<td><br>
</td>
<td><br>
</td>
<td>HTM</td>
</tr>
</tbody>
</table>
</center>
<p>
Since this classification is made at a high level, projects in the same entry of the table are still quite different in the details of their research goals and technical paths.
 </p>
<p>
In summary, the current AGI projects are based on very different theories and techniques.</p>
<h2><a name="TOC-AGI-Literatures-and-Resources"></a>AGI Literatures and Resources</h2>
<p>AGI collections:</p>
<div>
<ul><li>The earliest collection of AGI works is <a href="https://link.springer.com/book/10.1007/978-3-540-68677-4" rel="nofollow">Artificial General Intelligence</a>. Though this book was published in 2007, 
the manuscript was finished in 2003.</li>
<li><a href="https://www.iospress.com/catalog/books/advances-in-artificial-general-intelligence-concepts-architectures-and-algorithms" rel="nofollow">Advances in Artificial General Intelligence: Concepts, Architectures and Algorithms</a> is a post-conference proceedings of the 2006 AGI Workshop. The introductory chapter "<a href="https://cis.temple.edu/~pwang/Publication/AGI_Aspects.pdf" rel="nofollow">Aspects of Artificial General Intelligence</a>" clarified the notion of AGI and summarized the other chapters.</li>
<li><a href="http://www.springer.com/computer/ai/book/978-94-91216-61-9" rel="nofollow">Theoretical Foundations of Artificial General Intelligence</a> is a collection co-authored by active AGI researchers. Each chapter address a theoretical topic in AGI, and is written in a non-technical style, so as to provide information for readers who are not AGI researchers.</li>
<li><a href="https://www.amazon.com/Between-Ape-Artilect-Conversations-Transformative/dp/1496138171" rel="nofollow">Between Ape and Artilect: Conversations with Pioneers of Artificial General Intelligence and Other Transformative Technologies</a> contains some interviews of AGI researchers.</li></ul>
<p>
The <a href="http://agi-conf.org/" rel="nofollow">annual AGI international conference series</a> was started in 2008. The conference websites link to all accepted papers, plus additional materials like presentation files and video records.
</p>
<p>
<a href="https://sciendo.com/journal/JAGI" rel="nofollow">Journal of Artificial General Intelligence</a> (JAGI) is a peer-reviewed journal with open access, started in 2009.</p>
<p>The AGI conference and journal are managed by the <a href="http://www.agi-society.org/" rel="nofollow">Artificial General Intelligence Society</a> (AGIS). Everyone interested in AGI can become a member.
</p><p>
Communication venues and social media dedicated to AGI or related research:
</p><ul>
<li>AGI groups in Facebook: <a href="https://www.facebook.com/groups/propBitDev/" rel="nofollow">Artificial General Intelligence (AGI)</a>, <a href="https://www.facebook.com/groups/RealAGI/" rel="nofollow">Real AGI</a>,
<a href="https://www.facebook.com/groups/396475193810786/" rel="nofollow">Artificial General Intelligence</a>, <a href="https://www.facebook.com/groups/722892624534381/" rel="nofollow">Artificial Cognition</a></li>
<li><a href="https://www.linkedin.com/groups/1084997" rel="nofollow">AGI group</a> in LinkedIn</li>
<li><a href="http://groups.google.com/group/artificial-general-intelligence">AGI group</a> in Google Group</li>
<li><a href="https://agi.topicbox.com/" rel="nofollow">AGI mailing list</a> in Listbox</li>
</ul>
<p>Educational materials for students:</p>
<ul>
<li><a href="https://cis.temple.edu/~pwang/AGI-Curriculum.html">
Suggested Education for Future AGI Researchers</a>, by Pei Wang</li>
<li><a href="http://goertzel.org/agi-curriculum/" rel="nofollow">Sketch of an AGI Curriculum</a>, by Ben Goertzel</li>
<li><a href="http://www.hutter1.net/ai/introref.htm" rel="nofollow">AI Recommendations</a>, by Marcus Hutter</li>
<li><a href="http://www.agi-society.org/resources/" rel="nofollow">Videos of the past AGI Summer School lectures</a></li>
</ul>
<p>Other AGI resources:</p>
<div>
<ul><li>AGIS <a href="http://www.agi-society.org/resources/" rel="nofollow">resources page</a></li>
<li><a href="http://en.wikipedia.org/wiki/Artificial_General_Intelligence" rel="nofollow">Artificial general intelligence page</a> in Wikipedia</li>
<li><a href="http://www.scholarpedia.org/article/Artificial_General_Intelligence" rel="nofollow">Artificial general intelligence page</a> in Scholarpedia</li></ul>
</div>
</div>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Bipolar Lisp Programmer (2007) (142 pts)]]></title>
            <link>https://www.marktarver.com/bipolar.html</link>
            <guid>37086301</guid>
            <pubDate>Fri, 11 Aug 2023 08:13:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marktarver.com/bipolar.html">https://www.marktarver.com/bipolar.html</a>, See on <a href="https://news.ycombinator.com/item?id=37086301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <td><span color="#FFFFFF" size="4" face="Nyala"><br>
        &nbsp;</span><div>
			<p>
			<span color="#000000" size="4" face="Nyala">Any lecturer who serves 
			his time will probably graduate hundreds, if not thousands of 
			students. &nbsp;Mostly they merge into a blur; like those paintings of 
			crowd scenes where the leading faces are clearly picked out and the 
			rest just have iconic representations. &nbsp; This anonymity can be 
			embarrassing when some past student hails you by name and you really 
			haven't got the foggiest idea of who he or she is. &nbsp;It's both nice 
			to be remembered and also toe curlingly embarrassing to admit that 
			you cannot recognise who you are talking to.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But some faces you do 
			remember; students who did a project under you. &nbsp;Also two other 
			categories - the very good and the very bad. &nbsp; Brilliance and abject 
			failure both stick in the mind. And one of the oddest things, and 
			really why I'm writing this short essay, is that there are some 
			students who actually fall into both camps. &nbsp;Here's another 
			confession. &nbsp;I've always liked these students and had a strong 
			sympathy for them.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now abject failure is 
			nothing new in life. &nbsp;Quite often I've had students who have failed 
			miserably for no other reason than they had very little ability. &nbsp; 
			&nbsp;This is nothing new. What is new is that in the UK, we now graduate 
			a lot of students like that. &nbsp;But, hey, that's a different story and 
			I'm not going down that route.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">No I want to look at the 
			brilliant failures. &nbsp; Because brilliance amd failure are so often 
			mixed together and our initial reaction is it shouldn't be. &nbsp; But it 
			happens and it happens a lot. &nbsp;Why?</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Well, to understand 
			that, we have to go back before university. Let's go back to high 
			school and look at a brilliant failure in the making. &nbsp;Those of you 
			who have seen the film "Donnie Darko" will know exactly the kind of 
			student I'm talking about. &nbsp;But if you haven't, don't worry, because 
			you'll soon recognise the kind of person I'm talking about. &nbsp;Almost 
			every high school has one every other year or so.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Generally what we're 
			talking about here is a student of outstanding brilliance. &nbsp;Someone 
			who is used to acing most of his assignments; of doing things at the 
			last minute but still doing pretty well at them. &nbsp; &nbsp;At some level he 
			doesn't take the whole shebang all that seriously; because, when you 
			get down to it, a lot of the rules at school are pretty damned 
			stupid. &nbsp;In fact a lot of the things in our world don't make a lot 
			of sense, if you really look at them with a fresh mind. &nbsp;</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">So we have two aspects 
			to this guy; intellectual acuteness and not taking things seriously. 
			&nbsp;The not taking things seriously goes with finding it all pretty 
			easy and a bit dull. &nbsp;But also it goes with realising that a lot of 
			human activity is really pretty pointless, and when you realise that 
			and internalise it then you become cynical and also a bit sad - 
			because you yourself are caught up in this machine and you have to 
			play along if you want to get on. &nbsp;Teenagers are really good at 
			spotting this kind of phony nonsense. &nbsp;Its also the seed of an 
			illness; a melancholia that can deepen in later life into full blown 
			depression.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Another feature about 
			this guy is his low threshold of boredom. He'll pick up on a task 
			and work frantically at it, accomplishing wonders in a short time 
			and then get bored and drop it before its properly finished. &nbsp;He'll 
			do nothing but strum his guitar and lie around in bed for several 
			days after. That's also part of the pattern too; periods of frenetic 
			activity followed by periods of melancholia, withdrawal and 
			inactivity. &nbsp; This is a bipolar personality.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Alright so far? &nbsp;OK, 
			well lets graduate this guy and see him go to university. &nbsp;What 
			happens to him then?</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Here we have two 
			stories; a light story and a dark one.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">The light story is that 
			he's really turned on by what he chooses and he goes on to graduate&nbsp;<em>summa 
			cum laude</em>, vindicating his natural brilliance.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But that's not the story 
			I want to look at. &nbsp;I want to look at the dark story. &nbsp;The one where 
			brilliance and failure get mixed together.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">This is where this 
			student begins by recognising that university, like school, is also 
			fairly phony in many ways. What saves university is generally the 
			beauty of the subject as built by great minds. &nbsp;But if you just look 
			at the professors and don't see past their narrow obsession with 
			their pointless and largely unread (and unreadable) publications to 
			the great invisible university of the mind, you will probably 
			conclude its as phony as anything else. &nbsp;Which it is.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But lets stick to this 
			guy's story.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now the big difference 
			between school and university for the fresher is FREEDOM. &nbsp;Freedom 
			from mom and dad, freedom to do your own thing. &nbsp; Freedom in fact to 
			screw up in a major way. &nbsp; So our hero begins a new life and finds 
			he can do all he wants. &nbsp;Get drunk, stumble in at 3.00 AM. So he 
			goes to town and he relies on his natural brilliance to carry him 
			through because, hey, it worked at school. &nbsp;And it does work for a 
			time.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But brilliance is not 
			enough. &nbsp;You need application too, because the material is harder at 
			university. &nbsp; So pretty soon our man is getting B+, then Bs and then 
			Cs for his assignments. &nbsp; He experiences alternating feelings of 
			failure cutting through his usual self assurance. &nbsp;He can still stay 
			up to 5.00AM and hand in his assignment before the 9.00AM deadline, 
			but what he hands in is not so great. &nbsp;Or perhaps he doesn't get 
			into beer, but into some mental digression from his official studies 
			that takes him too far away from the main syllabus.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">This sort of student 
			used to pass my way every now and then, riding on the bottom of the 
			class. &nbsp; One of them had&nbsp;<strong>Bored&gt;</strong>&nbsp;as his UNIX prompt. 
			If I spotted one I used to connect well with them. &nbsp;(In fact I 
			rescued one and now he's a professor and miserable because he's 
			surrounded by phonies - but hey, what can you do?). &nbsp; Generally he 
			would come alive in the final year project when he could do his own 
			thing and hand in something really really good. &nbsp; Something that 
			would show (shock, horror) originality. &nbsp;And a lot of professors 
			wouldn't give it a fair mark for that very reason - and because the 
			student was known to be scraping along the bottom.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Often this kind of 
			student never makes it to the end. &nbsp;He flunks himself by dropping 
			out. &nbsp; He ends on a soda fountain or doing yard work, but all the 
			time reading and studying because a good mind is always hungry.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now one of the things 
			about Lisp, and I've seen it before, is that Lisp is a real magnet 
			for this kind of mind. &nbsp; Once you understand that, and see that it 
			is this kind of mind that has contributed a lot to the culture of 
			Lisp, you begin to see why Lisp is, like many of its proponents, a 
			brilliant failure. &nbsp;It shares the peculiar strengths and weaknesses 
			of the brilliant bipolar mind (BBM).</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Why is this? &nbsp;Well, its 
			partly to do with vision. &nbsp; The 'vision thing' as George Bush Snr. 
			once described it, is really one of the strengths of the BBM. &nbsp;He 
			can see far; further than in fact his strength allows him to travel. 
			&nbsp;He conceives of brilliant ambitious projects requiring great 
			resources, and he embarks on them only to run out of steam. &nbsp;It's 
			not that he's lazy; its just that his resources are insufficient.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And this is where Lisp 
			comes in. &nbsp;Because Lisp, as a tool, is to the mind as the lever is 
			to the arm. &nbsp;It amplifies your power and enables you to embark on 
			projects beyond the scope of lesser languages like C. &nbsp; Writing in C 
			is like building a mosaic out of lentils using a tweezer and glue. &nbsp; 
			Lisp is like wielding an air gun with power and precision. &nbsp; It 
			opens out whole kingdoms shut to other programmers.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">So BBMs love Lisp. &nbsp;And 
			the stunning originality of Lisp is reflective of the creativity of 
			the BBM; so we have a long list of ideas that originated with 
			Lispers - garbage collection, list handling, personal computing, 
			windowing and areas in which Lisp people were amongst the earliest 
			pioneers. &nbsp;So we would think, off the cuff, that Lisp should be well 
			established, the premiere programming language because hey - its 
			great and we were the first guys to do this stuff.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">But it isn't and the 
			reasons why not are not in the language, but in the community 
			itself, which contains not just the strengths but also the 
			weaknesses of the BBM.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">One of these is the 
			inability to finish things off properly. &nbsp;The phrase 'throw-away 
			design' is absolutely made for the BBM and it comes from the Lisp 
			community. &nbsp; Lisp allows you to just chuck things off so easily, and 
			it is easy to take this for granted. &nbsp;I saw this 10 years ago when 
			looking for a GUI to my Lisp (Garnet had just gone West then). &nbsp;No 
			problem, there were 9 different offerings. &nbsp;The trouble was that 
			none of the 9 were properly documented and none were bug free. 
			Basically each person had implemented his own solution and it worked 
			for him so that was fine. &nbsp; This is a BBM attitude; it works for me 
			and I understand it. &nbsp; It is also the product of not needing or 
			wanting anybody else's help to do something.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now in contrast, the 
			C/C++ approach is quite different. &nbsp;It's so damn hard to do anything 
			with tweezers and glue that anything significant you do will be a 
			real achievement. &nbsp;You want to document it. &nbsp;Also you're liable to 
			need help in any C project of significant size; so you're liable to 
			be social and work with others. &nbsp; You need to, just to get 
			somewhere.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And all that, from the 
			point of view of an employer, is attractive. Ten people who 
			communicate, document things properly and work together are 
			preferable to one BBM hacking Lisp who can only be replaced by 
			another BBM (if you can find one) in the not unlikely event that he 
			will, at some time, go down without being rebootable.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Now the other aspect of 
			the BBM that I remarked on is his sensitivity to artifice. &nbsp;To put 
			it in plain American, he knows bullshit when he smells it. &nbsp; Most of 
			us do. &nbsp;However the BBM has much lower tolerance of it than others. 
			&nbsp;He can often see the absurdity of the way things are, and has the 
			intelligence to see how they should be. &nbsp;And he is, unlike the rank 
			and file, unprepared to compromise. &nbsp;And this leads to many things.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">The Lisp machines were a 
			product of this kind of vision. It was, as Gabriel once said, the 
			Right Thing. &nbsp;Except of course it wasn't. &nbsp;Here the refusal to 
			compromise with the market, and to use the platforms that the C 
			bashers were using proved in the long run to be a fatal mistake.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And this brings me to 
			the last feature of the BBM. &nbsp;The flip side of all that energy and 
			intelligence - the sadness, melancholia and loss of self during a 
			down phase. &nbsp; &nbsp;If you read many posts discussing Lisp (including one 
			in comp.lang.lisp called&nbsp;<strong>Common Lisp Sucks</strong>) you see 
			it writ large. &nbsp; Veteran programmers of many years with obvious 
			ability and talent go down with a fit of the blues. &nbsp;The 
			intelligence is directed inwards in mournful contemplation of the 
			inadequacies of their favourite programming language. &nbsp; The problems 
			are soluble (Qi is a proof of that for God's sake), but when you're 
			down everything seems insoluble. &nbsp;Lisp is doomed and we're all going 
			to hell.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">Actually one paper that 
			exemplifies that more than any other is the classic&nbsp;<strong>Lisp: 
			Good News, Bad News, How to Win Big</strong>. If you read that 
			paper, you feel and see nature of the BBM. &nbsp;Its unique because 
			Gabriel actually displays both aspects at the same time. &nbsp; The 
			positive side, the intellectual pride and belief in Lisp is there. 
			&nbsp;But also in there is the depressive 'but its all going to go to 
			hell' aspect is there too. &nbsp;This is contained in the message that 
			Worse is Better.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">So what's the message in 
			all of this? Basically, that there are two problems. The problem 
			with the Lisp mindset and the problem with Lisp. The problem of the 
			Lisp mindset is the problem of the mindset characteristic of the BBM.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">And the problem with 
			Lisp? &nbsp;The answer is tailor made for the minds who program it. It is 
			the koan of Lisp.</span></p>
			<p>
			<span color="#000000" size="4" face="Nyala">The answer is that there 
			is no problem with Lisp, because Lisp is, like life, what you make 
			of it.&nbsp;</span></p></div>
		</td>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Browsers barely care what HTTP status code your web pages are served with (131 pts)]]></title>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/BrowsersAndHTTPStatusCodes</link>
            <guid>37085449</guid>
            <pubDate>Fri, 11 Aug 2023 05:37:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://utcc.utoronto.ca/~cks/space/blog/web/BrowsersAndHTTPStatusCodes">https://utcc.utoronto.ca/~cks/space/blog/web/BrowsersAndHTTPStatusCodes</a>, See on <a href="https://news.ycombinator.com/item?id=37085449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Browsers barely care what HTTP status code your web pages are served with</h2>

	<p><small>August 10, 2023</small></p>
</div><div><p>Back when I wrote an entry on <a href="https://utcc.utoronto.ca/~cks/space/blog/web/WebServerDefaultNotThere">issues around the HTTP status code
for a web server's default front page</a>,
I said in passing that <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">the HTTP status code</a> mostly
doesn't matter to browsers. More exactly, the status code for a web
page mostly doesn't matter to people looking at web pages in a
browser (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/PragmaticHTTPErrorCodes">this has come up before</a>). This
is well known in some circles and probably surprising in others.</p>

<p>Certain HTTP status codes cause web browsers to do specific things;
there are the HTTP 3xx redirections, <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401">HTTP 401 Unauthorized</a>, and
some others. However, in general if you respond to a request for a
web page with a HTTP 200, 4xx, or 5xx code outside of these specific
ones and some HTML, almost all browsers will display the HTML to
the user and not expose the actual HTTP status code to them in any
obvious way. If the HTML says 'HTTP 500 internal failure', they'll
assume one thing; if the HTML says 'welcome to the default server
page', they'll assume another thing.</p>

<p>(I'm not sure there's any way to find the HTTP status code in a
modern Firefox environment short of using web developer tools.
It's not in places like 'Page Info' as far as I can see.)</p>

<p>This is not so true in other browser contexts. If a web page is
trying to fetch CSS, JavaScript, or images as sub-resources, I
believe that browsers will react very differently to <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200">a HTTP 200</a>
response than to the exact same content with the exact same
Content-Type but with a HTTP 4xx or 5xx status code; only the
successful HTTP 200 response will work. Similarly if there's
JavaScript running to fetch HTML chunks and stuff them into the
page, it's likely to care (and not work) if you return the same
HTML with a HTTP 404 instead of a HTTP 200.</p>

<p>It's a convention (and a useful one) that the HTML served for a web
server's error pages will include the HTTP status code in the text
(and often the &lt;title&gt; as well). But it's only a convention and it
can be violated, both accidentally and deliberately (both in omitting
the status code and listing the wrong one). If it is violated, you
probably won't notice for a while (if ever).</p>

<p>PS: It turns out that <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">our Django based web application</a> doesn't actually list
the HTTP status codes on its various custom error pages, although
it does have appropriate text that says you've hit a nonexistent
page or an internal error. I probably should at least add a footer
saying '(This is a HTTP status 404 error)' (with the correct code
for the specific error page).</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox desktop extensions coming soon for the upcoming Android release (747 pts)]]></title>
            <link>https://blog.mozilla.org/addons/2023/08/10/prepare-your-firefox-desktop-extension-for-the-upcoming-android-release/</link>
            <guid>37084677</guid>
            <pubDate>Fri, 11 Aug 2023 03:09:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/addons/2023/08/10/prepare-your-firefox-desktop-extension-for-the-upcoming-android-release/">https://blog.mozilla.org/addons/2023/08/10/prepare-your-firefox-desktop-extension-for-the-upcoming-android-release/</a>, See on <a href="https://news.ycombinator.com/item?id=37084677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">

    
      <article id="post-9099">
  <!-- .entry-header -->

  <div>
    <p><img width="160" height="160" src="https://blog.mozilla.org/addons/files/2019/10/Fx-Browser-icon-fullColor-160x160.png" alt="" decoding="async" title="" srcset="https://blog.mozilla.org/addons/files/2019/10/Fx-Browser-icon-fullColor-160x160.png 160w, https://blog.mozilla.org/addons/files/2019/10/Fx-Browser-icon-fullColor-252x252.png 252w, https://blog.mozilla.org/addons/files/2019/10/Fx-Browser-icon-fullColor-768x768.png 768w, https://blog.mozilla.org/addons/files/2019/10/Fx-Browser-icon-fullColor-600x600.png 600w, https://blog.mozilla.org/addons/files/2019/10/Fx-Browser-icon-fullColor.png 2048w" sizes="(max-width: 160px) 100vw, 160px"></p><p>In the coming months Mozilla will launch support for an open ecosystem of extensions on Firefox for Android on <i>addons.mozilla.org</i> (AMO). We’ll announce a definite launch date in early September, but it’s safe to expect a roll-out before the year’s end. Here’s everything developers need to know to get their Firefox desktop extensions ready for Android usage and discoverability on AMO…</p>
<h2>Firefox will become the only major Android browser to support an open extension ecosystem</h2>
<p>For the past few years Firefox for Android officially supported a small subset of extensions while we focused our efforts on strengthening core Firefox for Android functionality and understanding the unique needs of mobile browser users. Today, Mozilla has built the infrastructure necessary to support an open extension ecosystem on Firefox for Android. We anticipate considerable user demand for more extensions on Firefox for Android, so why not start optimizing your desktop extension for mobile-use right away?</p>
<blockquote><p><b>“There is so much creative potential to unlock within the mobile browser space. Mozilla wants to provide developers with the best support we can so they’re equipped and empowered to build modern mobile WebExtensions.”<i> — Giorgio Natili, Firefox Director of Engineering<br>
</i></b></p></blockquote>
<p>To support our ecosystem of extension developers, we will create additional guides, resources and host community events to support your transition to a managed multi-process environment like Android.</p>
<h2>Transition background scripts to non-persistent event pages</h2>
<p>We recently introduced support for multi-process in Firefox for Android Nightly. This means extensions are no longer hosted in the main process as Firefox’s user interface. This is a key consideration since Android is prone to shutting down resource-intensive processes, such as extensions. To mitigate the risk of unexpected extension termination, we’ve introduced event page architecture to be non-persistent and more resilient to process termination. Thus we strongly encourage developers to <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Background_scripts#convert_to_non-persistent">transition from persistent backgrounds to non-persistent Event pages</a> to improve their extension’s stability. In summary, this means:</p>
<ul>
<li>Update your manifest.json background key and add “persistent”: false.</li>
<li aria-level="1">Ensure listeners are registered synchronously at the top-level.</li>
<li aria-level="1">Record global state in the storage API, for example storage.session.</li>
<li aria-level="1">Change timers to alarms.</li>
<li aria-level="1">Switch from using<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/extension/getBackgroundPage"> extension.getBackgroundPage</a> for calling a function from the background page, to extension messaging or<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/runtime/getBackgroundPage"> runtime.getBackgroundPage</a>.</li>
</ul>
<p>Once you’re ready to test the mobile version of your extension, <a href="https://support.mozilla.org/en-US/kb/how-use-collections-addonsmozillaorg?utm_source=blog.mozilla.org&amp;utm_medium=post&amp;utm_content=expanded-extension-support-in-firefox-for-android-nightly#">create a collection</a> on AMO and test it on <a href="https://play.google.com/store/apps/details?id=org.mozilla.fenix">Firefox for Android Nightly</a>. If you’d prefer to polish your extension before publishing it on AMO, you can also <a href="https://extensionworkshop.com/documentation/develop/developing-extensions-for-firefox-for-android/#install-and-run-your-extension-in-firefox-for-android">debug and run the extension with web-ext</a>.</p>
<p>This is an exciting time for developers seeking to expand the reach of their desktop extensions into the mobile Android space. For community support and input, you’re welcome to join the conversation on <a href="https://discourse.mozilla.org/c/add-ons/35">Firefox Add-ons Discourse</a>.</p>
      </div><!-- .entry-content -->

  <!-- .entry-meta -->
</article><!-- #post -->

      



    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Git-appraise – Distributed Code Review for Git (236 pts)]]></title>
            <link>https://github.com/google/git-appraise</link>
            <guid>37084575</guid>
            <pubDate>Fri, 11 Aug 2023 02:52:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google/git-appraise">https://github.com/google/git-appraise</a>, See on <a href="https://news.ycombinator.com/item?id=37084575">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Distributed Code Review For Git</h2>
<p dir="auto"><a href="https://travis-ci.org/google/git-appraise" rel="nofollow"><img src="https://camo.githubusercontent.com/aab84ff1822ea5220228493cad4a8d4b0174a0e7ab5404ddc125fe27f47bb3ca/68747470733a2f2f7472617669732d63692e6f72672f676f6f676c652f6769742d61707072616973652e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/google/git-appraise.svg?branch=master"></a></p>
<p dir="auto">This repo contains a command line tool for performing code reviews on git
repositories.</p>
<h2 tabindex="-1" dir="auto">Overview</h2>
<p dir="auto">This tool is a <em>distributed</em> code review system for git repos.</p>
<p dir="auto">By "distributed", we mean that code reviews are stored inside of the repository
as git objects. Every developer on your team has their own copy of the review
history that they can push or pull. When pulling, updates from the remote
repo are automatically merged by the tool.</p>
<p dir="auto">This design removes the need for any sort of server-side setup. As a result,
this tool can work with any git hosting provider, and the only setup required
is installing the client on your workstation.</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">Assuming you have the <a href="https://golang.org/doc/install" rel="nofollow">Go tools installed</a>, run
the following command:</p>
<div data-snippet-clipboard-copy-content="go get github.com/google/git-appraise/git-appraise"><pre><code>go get github.com/google/git-appraise/git-appraise
</code></pre></div>
<p dir="auto">Then, either make sure that <code>${GOPATH}/bin</code> is in your PATH, or explicitly add the
"appraise" git alias by running the following command.</p>
<div data-snippet-clipboard-copy-content="git config --global alias.appraise '!'&quot;${GOPATH}/bin/git-appraise&quot;"><pre><code>git config --global alias.appraise '!'"${GOPATH}/bin/git-appraise"
</code></pre></div>
<h4 tabindex="-1" dir="auto">Windows:</h4>
<div data-snippet-clipboard-copy-content="git config --global alias.appraise &quot;!%GOPATH%/bin/git-appraise.exe&quot;"><pre><code>git config --global alias.appraise "!%GOPATH%/bin/git-appraise.exe"
</code></pre></div>
<h2 tabindex="-1" dir="auto">Requirements</h2>
<p dir="auto">This tool expects to run in an environment with the following attributes:</p>
<ol dir="auto">
<li>The git command line tool is installed, and included in the PATH.</li>
<li>The tool is run from within a git repo.</li>
<li>The git command line tool is configured with the credentials it needs to
push to and pull from the remote repos.</li>
</ol>
<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto">Requesting a code review:</p>

<p dir="auto">Pushing code reviews to a remote:</p>
<div data-snippet-clipboard-copy-content="git appraise push [<remote>]"><pre><code>git appraise push [&lt;remote&gt;]
</code></pre></div>
<p dir="auto">Pulling code reviews from a remote:</p>
<div data-snippet-clipboard-copy-content="git appraise pull [<remote>]"><pre><code>git appraise pull [&lt;remote&gt;]
</code></pre></div>
<p dir="auto">Listing open code reviews:</p>

<p dir="auto">Showing the status of the current review, including comments:</p>

<p dir="auto">Showing the diff of a review:</p>
<div data-snippet-clipboard-copy-content="git appraise show --diff [--diff-opts &quot;<diff-options>&quot;] [<review-hash>]"><pre><code>git appraise show --diff [--diff-opts "&lt;diff-options&gt;"] [&lt;review-hash&gt;]
</code></pre></div>
<p dir="auto">Commenting on a review:</p>
<div data-snippet-clipboard-copy-content="git appraise comment -m &quot;<message>&quot; [-f <file> [-l <line>]] [<review-hash>]"><pre><code>git appraise comment -m "&lt;message&gt;" [-f &lt;file&gt; [-l &lt;line&gt;]] [&lt;review-hash&gt;]
</code></pre></div>
<p dir="auto">Accepting the changes in a review:</p>
<div data-snippet-clipboard-copy-content="git appraise accept [-m &quot;<message>&quot;] [<review-hash>]"><pre><code>git appraise accept [-m "&lt;message&gt;"] [&lt;review-hash&gt;]
</code></pre></div>
<p dir="auto">Submitting the current review:</p>
<div data-snippet-clipboard-copy-content="git appraise submit [--merge | --rebase]"><pre><code>git appraise submit [--merge | --rebase]
</code></pre></div>
<p dir="auto">A more detailed getting started doc is available <a href="https://github.com/google/git-appraise/blob/master/docs/tutorial.md">here</a>.</p>
<h2 tabindex="-1" dir="auto">Metadata</h2>
<p dir="auto">The code review data is stored in <a href="https://git-scm.com/docs/git-notes" rel="nofollow">git-notes</a>,
using the formats described below. Each item stored is written as a single
line of JSON, and is written with at most one such item per line. This allows
the git notes to be automatically merged using the "cat_sort_uniq" strategy.</p>
<p dir="auto">Since these notes are not in a human-friendly form, all of the refs used to
track them start with the prefix "refs/notes/devtools". This helps make it
clear that these are meant to be read and written by automated tools.</p>
<p dir="auto">When a field named "v" appears in one of these notes, it is used to denote
the version of the metadata format being used. If that field is missing, then
it defaults to the value 0, which corresponds to this initial version of the
formats.</p>
<h3 tabindex="-1" dir="auto">Code Review Requests</h3>
<p dir="auto">Code review requests are stored in the "refs/notes/devtools/reviews" ref, and
annotate the first revision in a review. They must conform to the
<a href="https://github.com/google/git-appraise/blob/master/schema/request.json">request schema</a>.</p>
<p dir="auto">If there are multiple requests for a single commit, then they are sorted by
timestamp and the final request is treated as the current one. This sorting
should be done in a stable manner, so that if there are multiple requests
with the same timestamp, then the last such request in the note is treated
as the current one.</p>
<p dir="auto">This design allows a user to update a review request by re-running the
<code>git appraise request</code> command.</p>
<h3 tabindex="-1" dir="auto">Continuous Integration Status</h3>
<p dir="auto">Continuous integration build and test results are stored in the
"refs/notes/devtools/ci" ref, and annotate the revision that was built and
tested. They must conform to the <a href="https://github.com/google/git-appraise/blob/master/schema/ci.json">ci schema</a>.</p>
<h3 tabindex="-1" dir="auto">Robot Comments</h3>
<p dir="auto">Robot comments are comments generated by static analysis tools. These are
stored in the "refs/notes/devtools/analyses" ref, and annotate the revision.
They must conform to the <a href="https://github.com/google/git-appraise/blob/master/schema/analysis.json">analysis schema</a>.</p>
<h3 tabindex="-1" dir="auto">Review Comments</h3>
<p dir="auto">Review comments are comments that were written by a person rather than by a
machine. These are stored in the "refs/notes/devtools/discuss" ref, and
annotate the first revision in the review. They must conform to the
<a href="https://github.com/google/git-appraise/blob/master/schema/comment.json">comment schema</a>.</p>
<h2 tabindex="-1" dir="auto">Integrations</h2>
<h3 tabindex="-1" dir="auto">Libraries</h3>
<ul dir="auto">
<li><a href="https://github.com/google/git-appraise/blob/master/review/review.go">Go (use git-appraise itself)</a></li>
<li><a href="https://github.com/Nemo157/git-appraise-rs">Rust</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Graphical User Interfaces</h3>
<ul dir="auto">
<li><a href="https://github.com/google/git-appraise-web">Git-Appraise-Web</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Plugins</h3>
<ul dir="auto">
<li><a href="https://github.com/google/git-appraise-eclipse">Eclipse</a></li>
<li><a href="https://github.com/jenkinsci/google-git-notes-publisher-plugin">Jenkins</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Mirrors to other systems</h3>
<ul dir="auto">
<li><a href="https://github.com/google/git-pull-request-mirror">GitHub Pull Requests</a></li>
<li><a href="https://github.com/google/git-phabricator-mirror">Phabricator Revisions</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">Please see <a href="https://github.com/google/git-appraise/blob/master/CONTRIBUTING.md">the CONTRIBUTING file</a> for information on contributing to Git Appraise.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I fixed a bug the other day (146 pts)]]></title>
            <link>https://www.javiergonzalez.io/blog/i-fixed-a-bug/</link>
            <guid>37084262</guid>
            <pubDate>Fri, 11 Aug 2023 02:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.javiergonzalez.io/blog/i-fixed-a-bug/">https://www.javiergonzalez.io/blog/i-fixed-a-bug/</a>, See on <a href="https://news.ycombinator.com/item?id=37084262">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>I fixed a bug that was in production for 2 years the other day. My boss said thank you, the UX researcher that called it out two years ago and was told it was not possible to do on our end said thank you. The product manager that had tried to tackle the issue a few times but gotten nowhere with their devs said thank you. It turns out that it was one of the biggest customer complaints and for some reason it had been neglected? ignored? idk. The change was about 20 lines of code, as they usually are, but had an outsized impact on customer satisfaction ratings. Why?</p><div><h3>The Issue</h3>
<p>I work in supermarket systems. Think e-commerce on steroids. We do weekly ads (which are called circulars) and these have discounts, the app also handles enough work to employ hundreds of developers working on loyalty programs, personalized recommendations, organizing pick up, delivery, managing availability for orders that are fulfilled in a physical location (which is most orders) shopping lists, a custom cms..., you get the picture. The issue was that our system for weekly ad was having an issue where the ads needed to 'clip' a coupon (read hit an api) for the discounted price to reach our cart calculations. However, the api that we used for managing the weekly ads was managed by an external vendor, and often when we queried their endpoint, the coupon field was returning empty when it shouldn't. To the customer, this meant that they would click on a tile that says a discounted price in their description, but would hit their cart as full price. Really frustrating and a cause of many loud customer complaints.</p>
<h3>Why was it hard to fix</h3>
<p>It wasn't. It was, however an issue that was difficult to replicate in our lower test environments, as the data simply wasn't there. It was also an issue that had to do how the external provider formatted the data that they were passing to us. Because this data was missing a field, it required manual data entry to update it. However, this data changed in real time, so it was OFTEN out of date. Whenever this issue came up to developers, the reaction was always to blame the vendor. This is natural, as it technically was the vendor's fault. However, what became apparent is that people were not going below the surface level to get to the heart of what could be done.</p>
<p>It became clear that this was an issue in <strong>process</strong> not in <strong>execution</strong>. The inertia in the company was to find why it would be hard to do, or impossible to do, why the fault lay elsewhere. We had spikes, and backlogs with this issue, but no action. I had never looked at this code, but was told to take a look, given that we seemed to have the data coming back in one of our API calls. Here's a diagram of the flow of info that we already had on our site:
<img src="https://www.javiergonzalez.io/assets/i-fixed-a-bug-graphic.a273ed83.png"></p>
<p>That's right, for any developer, the answer here is simple: use the coupons that we are ALREADY receiving on the frontend to populate the fields that users expect so they can get their discounts. Products already had the associated coupons, but we were simply ignoring that. Not only where we ignoring that, we said it was not possible to do. This reminds me of <a href="https://badsoftwareadvice.substack.com/p/how-to-debug-software">this article</a> I read on how to report a bug:</p>
<ul>
<li>Deny that there is a problem.</li>
<li>Deny that it is your problem.</li>
<li>Ask for more information.</li>
<li>Complain.</li>
</ul>
<p>The real difficulty was in reproducing the data, so I completely hacked it, and replaced the api call service with a dumb function that returned hardcoded data copied from a production. As our principal engineer said to me when I told him about the hack to get the data in my local environment: "<strong>All data in lower environments is mock data</strong>".</p>
<h3>The Solution</h3>
<p>There is very little that is exciting about the bugfix. It was easy, a few array methods to ensure we were not searching for duplicates, and it even required one less API call than before. It worked nicely and the customer satisfaction scores went up as expected. What I did is come in as an outsider to the issue and this particular business concern, let my naivety guide my investigation and provided a solution within a few days. Why wasn't this done before is the more interesting question, and it seems to be related to a few things that are above my paygrade but are quite interesting to me.</p>
<h3>Closing Thoughts</h3>
<p>I like my company, and my direct managers, and several other people that I interact with in a regular basis. However, this was a case where the inertia of the status quo got the better of the organization at the expense of customer experience. I want to understand how this came to be, rather than to shift blame around, and to do there are a few things that I am paying attention to. The incentives and the feedback loops.</p>
<p>A company that is not a startup has strange incentives opposed to some of the original ones when it is getting started. Here's the cycle described by <a href="https://thenetworkstate.com/left-is-the-new-right-is-the-new-left#the-libertarian-cycle">Balaji Srinivasan</a>:</p>
<blockquote>
<p>First, a libertarian(ish) founder leaves the stifling bureaucracy of a big company to start their own. Most immediately fail, but through pure maneuver warfare and relentless execution, that founder might be able to make enough money to hire someone. In the early days the most important quantity is the burn rate. Every single person must be indispensable.</p>
<p>Eventually, if successful, the company starts building up some structure. Conservativism takes over. With the business growing consistently, the founder adds structure, career tracks, and a stable hierarchy. Now the most important quantity becomes the bus number, the number of people who can get hit by a bus such that the company is still functional. Suddenly every single person must now be&nbsp;<strong>dispensable</strong>.</p>
</blockquote>
<p><a href="https://medium.com/tech-tajawal/the-bus-factor-6ea1a3ede6bd">The bus factor</a> creates redundancy, and people being dispensable makes a strange feedback loop. When everyone is dispensable, as a good company should make their employees, there is a tension between owning your work and standing out, vs just doing the minimum. Where that line sits is not clear at all.</p>
<p>This pressure and quite frankly this contradiction is an extremely difficult one to solve. Harvard and others have written about it <a href="https://hbr.org/2012/09/why-big-companies-cant-innovate">Why Big Companies Can't Innovate</a>. I am interested in this, because I am interested in doing work, at scale, within a company that has a culture of solving problems, not of being a behemoth with enough inertia to not need to correct when there is a need. Luckily, my team within the larger org values this nimble attitude of getting sh(stuff)t done, and was able to in some sense circumvent this inertia and this extreme risk aversion.</p>
<p>I've also been thinking quite a bit of a company as a cybernetic system. You have a product, and that product has a shape which is shaped by the organizational structure (in Software Development, we call it <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway's Law</a>). The product reflects the org, and the org reflects the product. This separation gets reinforced, and we were reinforcing invisible (and nonexistent to the customer) boundaries within ourselves and the vendors for no good reason. I want to investigate this notion of cybernetic systems and how to direct them in the context of a software company, so I'll be writing more about that.</p>
<p>In the end, this issue revealed a flaw in process more than a flaw in the technical execution of our product. Of course a <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/">leaky abstraction</a> showed to the customer, but it was a matter of understanding it and patching it rather than allowing that distinction to continue and reinforce itself. As I progress in software, I am very interested in thinking of steering the cybernetic system of a corporation in order to get self reinforcing outcomes in an intentional direction. I will be writing on that more soon.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tetris, but the blocks are ARM instructions that execute in the browser (315 pts)]]></title>
            <link>https://ofrak.com/tetris/</link>
            <guid>37083309</guid>
            <pubDate>Thu, 10 Aug 2023 23:56:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ofrak.com/tetris/">https://ofrak.com/tetris/</a>, See on <a href="https://news.ycombinator.com/item?id=37083309">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="nowasm">
      
      <p>
        This game is Tetris, but the blocks are assembly instructions that run
        on a full, in-browser CPU emulator.
      </p>
      <p>This game requires WebAssembly to run.</p>
      <p>
        The game includes a WebAssembly-based emulator to execute CPU
        instructions. Please enable WebAssembly, or use a browser that supports
        it to play.
      </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite Functions for Working with JSON (175 pts)]]></title>
            <link>https://www.sqlite.org/json1.html</link>
            <guid>37082941</guid>
            <pubDate>Thu, 10 Aug 2023 23:14:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sqlite.org/json1.html">https://www.sqlite.org/json1.html</a>, See on <a href="https://news.ycombinator.com/item?id=37082941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p>
JSON Functions And Operators
</p>


</div>





<h2 id="overview"><span>1. </span>Overview</h2>
<p>
By default, SQLite supports sixteen functions and two operators for
dealing with JSON values.  There are also two <a href="https://www.sqlite.org/vtab.html#tabfunc2">table-valued functions</a>
that can be used to decompose a JSON string.

</p><p>
There are 15 scalar functions and operators:

</p><ol>
<li value="1">
<a href="#jmini">json</a>(<i>json</i>)
</li>

<li value="2">
<a href="#jarray">json_array</a>(<i>value1</i>,<i>value2</i>,...)
</li>

<li value="3">
<a href="#jarraylen">json_array_length</a>(<i>json</i>)<br><a href="#jarraylen">json_array_length</a>(<i>json</i>,<i>path</i>)
</li>

<li value="4">
<a href="#jerr">json_error_position</a>(<i>json</i>)
</li>

<li value="5">
<a href="#jex">json_extract</a>(<i>json</i>,<i>path</i>,...)
</li>

<li value="6">
<i>json</i> <a href="#jptr">-&gt;</a> <i>path</i>
</li>

<li value="7">
<i>json</i> <a href="#jptr">-&gt;&gt;</a> <i>path</i>
</li>

<li value="8">
<a href="#jins">json_insert</a>(<i>json</i>,<i>path</i>,<i>value</i>,...)
</li>

<li value="9">
<a href="#jobj">json_object</a>(<i>label1</i>,<i>value1</i>,...)
</li>

<li value="10">
<a href="#jpatch">json_patch</a>(<i>json</i>1,json2)
</li>

<li value="11">
<a href="#jrm">json_remove</a>(<i>json</i>,<i>path</i>,...)
</li>

<li value="12">
<a href="#jrepl">json_replace</a>(<i>json</i>,<i>path</i>,<i>value</i>,...)
</li>

<li value="13">
<a href="#jset">json_set</a>(<i>json</i>,<i>path</i>,<i>value</i>,...)
</li>

<li value="14">
<a href="#jtype">json_type</a>(<i>json</i>)<br><a href="#jtype">json_type</a>(<i>json</i>,<i>path</i>)
</li>

<li value="15">
<a href="#jvalid">json_valid</a>(<i>json</i>)
</li>

<li value="16">
<a href="#jquote">json_quote</a>(<i>value</i>)
</li>


</ol>

<p>There are two aggregate SQL functions:

</p><ol>
<li value="17">
<a href="#jgrouparray">json_group_array</a>(<i>value</i>)
</li>

<li value="18">
<a href="#jgroupobject">json_group_object</a>(name,<i>value</i>)
</li>


</ol>

<p>The two <a href="https://www.sqlite.org/vtab.html#tabfunc2">table-valued functions</a> are:

</p><ol>
<li value="19">
<a href="#jeach">json_each</a>(<i>json</i>)<br><a href="#jeach">json_each</a>(<i>json</i>,<i>path</i>)
</li>

<li value="20">
<a href="#jtree">json_tree</a>(<i>json</i>)<br><a href="#jtree">json_tree</a>(<i>json</i>,<i>path</i>)
</li>


</ol>






<h2 id="compiling_in_json_support"><span>2. </span>Compiling in JSON Support</h2>

<p>
The JSON functions and operators are built into SQLite by default,
as of SQLite version 3.38.0 (2022-02-22).  They can be omitted
by adding the -DSQLITE_OMIT_JSON compile-time option.  Prior to
version 3.38.0, the JSON functions were an extension that would only
be included in builds if the -DSQLITE_ENABLE_JSON1 compile-time option
was included.  In other words, the JSON functions went from being
opt-in with SQLite version 3.37.2 and earlier to opt-out with
SQLite version 3.38.0 and later.

</p><h2 id="interface_overview"><span>3. </span>Interface Overview</h2>

<p>
SQLite stores JSON as ordinary text.
Backwards compatibility constraints mean that SQLite is only able to
store values that are NULL, integers, floating-point numbers, text,
and BLOBs.  It is not possible to add a sixth "JSON" type.

</p><p>
SQLite does not (currently) support a binary encoding
of JSON.  Experiments have been unable to find a binary encoding
that is smaller or faster than a plain text encoding.
(The present implementation parses JSON text at over 250 MB/s.)
All JSON functions currently throw an error if any of their
arguments are BLOBs because BLOBs are reserved
for a future enhancement in which BLOBs will store the binary encoding
for JSON.

</p><h2 id="json_arguments"><span>3.1. </span>JSON arguments</h2>

<p>
For functions that accept JSON as their first argument, that argument
can be a JSON object, array, number, string, or null.  SQLite numeric
values and NULL values are interpreted as JSON numbers and nulls, respectively.
SQLite text values can be understood as JSON objects, arrays, or strings.
If an SQLite text value that is not a well-formed JSON object, array, or
string is passed into JSON function, that function will usually throw
an error.  (Exceptions to this rule are <a href="https://www.sqlite.org/json1.html#jvalid">json_valid()</a>,
<a href="https://www.sqlite.org/json1.html#jquote">json_quote()</a>, and <a href="https://www.sqlite.org/json1.html#jerr">json_error_position()</a>.)

</p><p>
These routines understand all
<a href="https://www.rfc-editor.org/rfc/rfc7159.txt">rfc-7159 JSON syntax</a>
and also <a href="https://spec.json5.org/">JSON5 extensions</a>.  JSON text
generated by these routines always strictly conforms to the
<a href="https://json.org/">canonical JSON definition</a> and does not contain any JSON5
or other extensions.  The ability to read and understand JSON5 was added in
version 3.42.0 (2023-05-16).
Prior versions of SQLite would only read canonical JSON.


<a name="jsonpath"></a>

</p><h2 id="path_arguments"><span>3.2. </span>PATH arguments</h2>

<p>
For functions that accept PATH arguments, that PATH must be well-formed or
else the function will throw an error.
A well-formed PATH is a text value that begins with exactly one
'$' character followed by zero or more instances
of ".<i>objectlabel</i>" or "[<i>arrayindex</i>]".

</p><p>
The <i>arrayindex</i> is usually a non-negative integer <i>N</i>.  In
that case, the array element selected is the <i>N</i>-th element
of the array, starting with zero on the left.
The <i>arrayindex</i> can also be of the form "<b>#-</b><i>N</i>"
in which case the element selected is the <i>N</i>-th from the
right.  The last element of the array is "<b>#-1</b>".  Think of
the "#" characters as the "number of elements in the array".  Then
the expression "#-1" evaluates to the integer that corresponds to 
the last entry in the array.  It is sometimes useful for the array
index to be just the <b>#</b> character, for example when appending
a value to an existing JSON array:

</p><ul>
<li><span>json_set('[0,1,2]','$[#]','new')</span>
<span>→ '[0,1,2,"new"]'</span></li>

</ul>


<h2 id="value_arguments"><span>3.3. </span>VALUE arguments</h2>

<p>
For functions that accept "<i>value</i>" arguments (also shown as
"<i>value1</i>" and "<i>value2</i>"),
those arguments are usually understood
to be literal strings that are quoted and become JSON string values
in the result.  Even if the input <i>value</i> strings look like 
well-formed JSON, they are still interpreted as literal strings in the
result.

</p><p>
However, if a <i>value</i> argument comes directly from the result of another
JSON function or from <a href="https://www.sqlite.org/json1.html#jptr">the -&gt; operator</a> (but not <a href="https://www.sqlite.org/json1.html#jptr">the -&gt;&gt; operator</a>),
then the argument is understood to be actual JSON and
the complete JSON is inserted rather than a quoted string.

</p><p>
For example, in the following call to json_object(), the <i>value</i>
argument looks like a well-formed JSON array.  However, because it is just
ordinary SQL text, it is interpreted as a literal string and added to the
result as a quoted string:

</p><ul>
<li><span>json_object('ex','[52,3.14159]')</span>
<span>→ '{"ex":"[52,3.14159]"}'</span></li>

<li><span>json_object('ex',('52,3.14159]'-&gt;&gt;'$'))</span>
<span>→ '{"ex":"[52,3.14159]"}'</span></li>

</ul>


<p>
But if the <i>value</i> argument in the outer json_object() call is the
result of another JSON function like <a href="https://www.sqlite.org/json1.html#jmini">json()</a> or <a href="https://www.sqlite.org/json1.html#jarray">json_array()</a>, then
the value is understood to be actual JSON and is inserted as such:

</p><ul>
<li><span>json_object('ex',json('[52,3.14159]'))</span>
<span>→ '{"ex":[52,3.14159]}'</span></li>

<li><span>json_object('ex',json_array(52,3.14159))</span>
<span>→ '{"ex":[52,3.14159]}'</span></li>

<li><span>json_object('ex','[52,3.14159]'-&gt;'$')</span>
<span>→ '{"ex":[52,3.14159]}'</span></li>

</ul>


<p>
To be clear: "<i>json</i>" arguments are always interpreted as JSON
regardless of where the value for that argument comes from.  But
"<i>value</i>" arguments are only interpreted as JSON if those arguments
come directly from another JSON function or <a href="https://www.sqlite.org/json1.html#jptr">the -&gt; operator</a>.

</p><p>
Within JSON value arguments interpreted as JSON strings, Unicode escape
sequences are not treated as equivalent to the characters or escaped
control characters represented by the expressed Unicode code point.
Such escape sequences are not translated or specially treated; they
are treated as plain text by SQLite's JSON functions.

</p><h2 id="compatibility"><span>3.4. </span>Compatibility</h2>

<p>
The current implementation of this JSON library uses a recursive descent
parser.  In order to avoid using excess stack space, any JSON input that has
more than 1000 levels of nesting is considered invalid.   Limits on nesting
depth are allowed for compatible implementations of JSON by
<a href="https://tools.ietf.org/html/rfc7159#section-9">RFC-7159 section 9</a>.

<a name="json5"></a>

</p><h2 id="json5_extensions"><span>3.5. </span>JSON5 Extensions</h2>

<p>
Beginning in version 3.42.0 (2023-05-16), these routines will
read and interpret input JSON text that includes
<a href="https://spec.json5.org/">JSON5</a> extensions.  However, JSON text generated
by these routines will always be strictly conforming to the 
<a href="https://json.org/">canonical definition of JSON</a>.

</p><p>
Here is a synopsis of JSON5 extensions (adapted from the
<a href="https://spec.json5.org/#introduction">JSON5 specification</a>):

</p><ul>
<li> Object keys may be unquoted identifiers.
</li><li> Objects may have a single trailing comma.
</li><li> Arrays may have a single trailing comma.
</li><li> Strings may be single quoted.
</li><li> Strings may span multiple lines by escaping new line characters.
</li><li> Strings may include new character escapes.
</li><li> Numbers may be hexadecimal.
</li><li> Numbers may have a leading or trailing decimal point.
</li><li> Numbers may be "Infinity", "-Infinity", and "NaN".
</li><li> Numbers may begin with an explicit plus sign.
</li><li> Single (//...) and multi-line (/*...*/) comments are allowed.
</li><li> Additional white space characters are allowed.
</li></ul>

<p>
To convert string X from JSON5 into canonical JSON, invoke
"<a href="https://www.sqlite.org/json1.html#jmini">json(X)</a>".  The output of the "<a href="https://www.sqlite.org/json1.html#jmini">json()</a>" function will be canonical
JSON regardless of any JSON5 extensions that are present in the input.
For backwards compatibility, the <a href="https://www.sqlite.org/json1.html#jvalid">json_valid(X)</a> function continues
to report false for inputs that are not canonical JSON, even if the
input is JSON5 that the function is able to understand.  To determine
whether or not an input string is valid JSON5,
use the expression: "<a href="https://www.sqlite.org/json1.html#jerr">json_error_position(X)</a>==0".

</p><p>
These routines understand all of JSON5, plus a little more.
SQLite extends the JSON5 syntax in these two ways:

</p><ol>
<li><p>
Strict JSON5 requires that
unquoted object keys must be ECMAScript 5.1 IdentifierNames.  But large
unicode tables and lots of code is required in order to determine whether or
not a key is an ECMAScript 5.1 IdentifierName.  For this reason,
SQLite allows object keys to include any unicode characters
greater than U+007f that are not whitespace characters.  This relaxed
definition of "identifier" greatly simplifies the implementation and allows
the JSON parser to be smaller and run faster.

</p></li><li><p>
JSON5 allows floating-point infinities to be expressed as
"<tt>Infinity</tt>", "<tt>-Infinity</tt>", or "<tt>+Infinity</tt>"
in exactly that case - the initial "I" is capitalized and all other
characters are lower case.  SQLite also allows the abbreviation "<tt>Inf</tt>"
to be used in place of "<tt>Infinity</tt>" and it allows both keywords
to appear in any combination of upper and lower case letters.
Similarly,
JSON5 allows "NaN" for not-a-number.  SQLite extends this to also allow
"QNaN" and "SNaN" in any combination of upper and lower case letters.
Note that SQLite interprets NaN, QNaN, and SNaN as just an alternative
spellings for "null".
This extension has been added because (we are told) there exists a lot
of JSON in the wild that includes these non-standard representations
for infinity and not-a-number.
</p></li></ol>

<h2 id="function_details"><span>4. </span>Function Details</h2>

<p>The following sections provide additional detail on the operation of
the various JSON functions and operators:

<a name="jmini"></a>

</p><h2 id="the_json_function"><span>4.1. </span>The json() function</h2>

<p>The json(X) function verifies that its argument X is a valid
JSON string and returns a minified version of that JSON string
(with all unnecessary whitespace removed).  If X is not a well-formed
JSON string, then this routine throws an error.

</p><p>In other words, this function converts raw text that looks like
JSON into actual JSON so that it may be passed into the <a href="https://www.sqlite.org/json1.html#varg">value argument</a>
of some other json function and will be interpreted as JSON rather than
a string.  This function is not appropriate for testing whether or not
a particular string is well-formed JSON - use the <a href="https://www.sqlite.org/json1.html#jvalid">json_valid()</a> and/or
<a href="https://www.sqlite.org/json1.html#jerr">json_error_position()</a> routines below for that task.

</p><p>If the argument X to json(X) contains JSON objects with duplicate
labels, then it is undefined whether or not the duplicates are
preserved.  The current implementation preserves duplicates.
However, future enhancements
to this routine may choose to silently remove duplicates.

</p><p>
Example:

</p><ul>
<li><span>json(' { "this" : "is", "a": [ "test" ] } ')</span>
<span>→ '{"this":"is","a":["test"]}'</span></li>

</ul>


<h2 id="the_json_array_function"><span>4.2. </span>The json_array() function</h2>

<p>The json_array() SQL function accepts zero or more arguments and
returns a well-formed JSON array that is composed from those arguments.
If any argument to json_array() is a BLOB then an error is thrown.

</p><p>An argument with SQL type TEXT is normally converted into a quoted 
JSON string.  However, if the argument is the output from another json1
function, then it is stored as JSON.  This allows calls to json_array()
and <a href="https://www.sqlite.org/json1.html#jobj">json_object()</a> to be nested.  The <a href="https://www.sqlite.org/json1.html#jmini">json()</a> function can also
be used to force strings to be recognized as JSON.

</p><p>Examples:

</p><ul>
<li><span>json_array(1,2,'3',4)</span>
<span>→ '[1,2,"3",4]'</span></li>

<li><span>json_array('[1,2]')</span>
<span>→ '["[1,2]"]'</span></li>

<li><span>json_array(json_array(1,2))</span>
<span>→ '[[1,2]]'</span></li>

<li><span>json_array(1,null,'3','[4,5]','{"six":7.7}')</span>
<span>→ '[1,null,"3","[4,5]","{\"six\":7.7}"]'</span></li>

<li><span>json_array(1,null,'3',json('[4,5]'),json('{"six":7.7}'))</span>
<span>→ '[1,null,"3",[4,5],{"six":7.7}]'</span></li>

</ul>



<h2 id="the_json_array_length_function"><span>4.3. </span>The json_array_length() function</h2>

<p>The json_array_length(X) function returns the number of elements
in the JSON array X, or 0 if X is some kind of JSON value other
than an array.  The json_array_length(X,P) locates the array at path P
within X and returns the length of that array, or 0 if path P locates
an element in X that is not a JSON array, and NULL if path P does not
locate any element of X.  Errors are thrown if either X is not 
well-formed JSON or if P is not a well-formed path.

</p><p>Examples:

</p><ul>
<li><span>json_array_length('[1,2,3,4]')</span>
<span>→ 4</span></li>

<li><span>json_array_length('[1,2,3,4]', '$')</span>
<span>→ 4</span></li>

<li><span>json_array_length('[1,2,3,4]', '$[2]')</span>
<span>→ 0</span></li>

<li><span>json_array_length('{"one":[1,2,3]}')</span>
<span>→ 0</span></li>

<li><span>json_array_length('{"one":[1,2,3]}', '$.one')</span>
<span>→ 3</span></li>

<li><span>json_array_length('{"one":[1,2,3]}', '$.two')</span>
<span>→ NULL</span></li>

</ul>



<h2 id="the_json_error_position_function"><span>4.4. </span>The json_error_position() function</h2>

<p>The json_error_positionf(X) function returns 0 if the input X is a
well-formed JSON or JSON5 string.  If the input X contains one or more
syntax errors, then this function returns the character position of the
first syntax error.  The left-most character is position 1.

</p><p>This routine is useful for at least two purposes:

</p><ol>
<li>
<p> To determine is a text string X is valid JSON or JSON5 as understood
    by SQLite, run "<tt>json_error_position(X)==0</tt>".  This is similar
    to <a href="https://www.sqlite.org/json1.html#jvalid">json_valid()</a> except that json_valid(X) requires X to be strictly
    conforming canonical JSON whereas json_error_position() allows the
    input to contains <a href="https://www.sqlite.org/json1.html#json5">JSON5 extensions</a>.
</p></li><li>
<p> Use this routine to find the location of a syntax error in a large
    JSON string during interactive debugging, or to generate a better
    error messages for human users.
</p></li></ol>

<p>
The json_error_position() function was added with
SQLite version 3.42.0 (2023-05-16).


<a name="jex"></a>

</p>

<p>The json_extract(X,P1,P2,...) extracts and returns one or more 
values from the
well-formed JSON at X.  If only a single path P1 is provided, then the
SQL datatype of the result is NULL for a JSON null, INTEGER or REAL
for a JSON numeric value, an INTEGER zero for a JSON false value,
an INTEGER one for a JSON true value, the dequoted text for a 
JSON string value, and a text representation for JSON object and array values.
If there are multiple path arguments (P1, P2, and so forth) then this
routine returns SQLite text which is a well-formed JSON array holding
the various values.

</p><p>Examples:

</p><ul>
<li><span>json_extract('{"a":2,"c":[4,5,{"f":7}]}', '$')</span>
<span>→ '{"a":2,"c":[4,5,{"f":7}]}'</span></li>

<li><span>json_extract('{"a":2,"c":[4,5,{"f":7}]}', '$.c')</span>
<span>→ '[4,5,{"f":7}]'</span></li>

<li><span>json_extract('{"a":2,"c":[4,5,{"f":7}]}', '$.c[2]')</span>
<span>→ '{"f":7}'</span></li>

<li><span>json_extract('{"a":2,"c":[4,5,{"f":7}]}', '$.c[2].f')</span>
<span>→ 7</span></li>

<li><span>json_extract('{"a":2,"c":[4,5],"f":7}','$.c','$.a')</span>
<span>→ '[[4,5],2]'</span></li>

<li><span>json_extract('{"a":2,"c":[4,5],"f":7}','$.c[#-1]')</span>
<span>→ 5</span></li>

<li><span>json_extract('{"a":2,"c":[4,5,{"f":7}]}', '$.x')</span>
<span>→ NULL</span></li>

<li><span>json_extract('{"a":2,"c":[4,5,{"f":7}]}', '$.x', '$.a')</span>
<span>→ '[null,2]'</span></li>

<li><span>json_extract('{"a":"xyz"}', '$.a')</span>
<span>→ 'xyz'</span></li>

<li><span>json_extract('{"a":null}', '$.a')</span>
<span>→ NULL</span></li>

</ul>


<p>There is a subtle incompatibility between the json_extract() function
in SQLite and the json_extract() function in MySQL.  The MySQL version
of json_extract() always returns JSON.  The SQLite version of
json_extract() only returns JSON if there are two or more PATH arguments
(because the result is then a JSON array) or if the single PATH argument
references an array or object.  In SQLite, if json_extract() has only
a single PATH argument and that PATH references a JSON null or a string
or a numeric value, then json_extract() returns the corresponding SQL
NULL, TEXT, INTEGER, or REAL value.

</p><p>The difference between MySQL json_extract() and SQLite json_extract()
really only stands out when accessing individual values within the JSON
that are strings or NULLs.  The following table demonstrates the difference:

</p><center>
<table>
<tbody><tr><th>Operation</th><th>SQLite Result</th><th>MySQL Result
</th></tr><tr><td>json_extract('{"a":null,"b":"xyz"}','$.a')</td><td>NULL</td><td>'null'
</td></tr><tr><td>json_extract('{"a":null,"b":"xyz"}','$.b')</td><td>'xyz'</td><td>'"xyz"'
</td></tr></tbody></table></center>

<h2 id="the_and_operators"><span>4.6. </span>The -&gt; and -&gt;&gt; operators</h2>

<p>Beginning with SQLite version 3.38.0 (2022-02-22), the -&gt;
and -&gt;&gt; operators are available for extracting subcomponents of JSON.
The SQLite implementation of -&gt; and -&gt;&gt; strives to be
compatible with both MySQL and PostgreSQL.
The -&gt; and -&gt;&gt; operators take a JSON string
as their left operand and a PATH expression or object field
label or array index as their right operand.  The -&gt; operator
returns a JSON representation of the selected subcomponent or NULL if that
subcomponent does not exist.  The -&gt;&gt; operator returns an SQL TEXT,
INTEGER, REAL, or NULL value that represents the selected subcomponent,
or NULL if the subcomponent does not exist.

</p><p>Both the -&gt; and -&gt;&gt; operators select the same subcomponent
of the JSON to their left.  The difference is that -&gt; always returns a
JSON representation of that subcomponent and the -&gt;&gt; operator always
returns an SQL representation of that subcomponent.  Thus, these operators
are subtly different from a two-argument <a href="https://www.sqlite.org/json1.html#jex">json_extract()</a> function call.
A call to json_extract() with two arguments will return a JSON representation
of the subcomponent if and only if the subcomponent is a JSON array or
object, and will return an SQL representation of the subcomponent if the
subcomponent is a JSON null, string, or numeric value.

</p><p>The right-hand operand to the -&gt; and -&gt;&gt; operators can
be a well-formed JSON path expression.  This is the form used by MySQL.
For compatibility with PostgreSQL,
the -&gt; and -&gt;&gt; operators also accept a text label or
integer as their right-hand operand.  If the right operand is a text
label X, then it is interpreted as the JSON path '$.X'.  If the right
operand is an integer value N, then it is interpreted as the JSON path '$[N]'.

</p><p>Examples:

</p><ul>
<li><span>'{"a":2,"c":[4,5,{"f":7}]}' -&gt; '$'</span>
<span>→ '{"a":2,"c":[4,5,{"f":7}]}'</span></li>

<li><span>'{"a":2,"c":[4,5,{"f":7}]}' -&gt; '$.c'</span>
<span>→ '[4,5,{"f":7}]'</span></li>

<li><span>'{"a":2,"c":[4,5,{"f":7}]}' -&gt; 'c'</span>
<span>→ '[4,5,{"f":7}]'</span></li>

<li><span>'{"a":2,"c":[4,5,{"f":7}]}' -&gt; '$.c[2]'</span>
<span>→ '{"f":7}'</span></li>

<li><span>'{"a":2,"c":[4,5,{"f":7}]}' -&gt; '$.c[2].f'</span>
<span>→ '7'</span></li>

<li><span>'{"a":2,"c":[4,5],"f":7}' -&gt; '$.c[#-1]'</span>
<span>→ '5'</span></li>

<li><span>'{"a":2,"c":[4,5,{"f":7}]}' -&gt; '$.x'</span>
<span>→ NULL</span></li>

<li><span>'[11,22,33,44]' -&gt; 3</span>
<span>→ '44'</span></li>

<li><span>'[11,22,33,44]' -&gt;&gt; 3</span>
<span>→ 44</span></li>

<li><span>'{"a":"xyz"}' -&gt; '$.a'</span>
<span>→ '"xyz"'</span></li>

<li><span>'{"a":"xyz"}' -&gt;&gt; '$.a'</span>
<span>→ 'xyz'</span></li>

<li><span>'{"a":null}' -&gt; '$.a'</span>
<span>→ 'null'</span></li>

<li><span>'{"a":null}' -&gt;&gt; '$.a'</span>
<span>→ NULL</span></li>

</ul>


<h2 id="the_json_insert_json_replace_and_json_set_functions"><span>4.7. </span>The json_insert(), json_replace, and json_set() functions</h2>

<p>The json_insert(), json_replace, and json_set() functions all take
a single JSON value as their first argument followed by zero or more
pairs of path and value arguments, and return a new JSON string formed
by updating the input JSON by the path/value pairs.  The functions
differ only in how they deal with creating new values and overwriting
preexisting values.

</p><center>
<table>
<tbody><tr>
<th>Function</th><th>Overwrite if already exists?</th><th>Create if does not exist?
</th></tr><tr>
<td>json_insert()</td><td>No</td><td>Yes
</td></tr><tr>
<td>json_replace()</td><td>Yes</td><td>No
</td></tr><tr>
<td>json_set()</td><td>Yes</td><td>Yes
</td></tr></tbody></table></center>

<p>The json_insert(), json_replace(), and json_set() functions always
take an odd number of arguments.  The first argument is always the original
JSON to be edited.  Subsequent arguments occur in pairs with the first
element of each pair being a path and the second element being the value
to insert or replace or set on that path.

</p><p>Edits occur sequentially from left to right.  Changes caused by
prior edits can affect the path search for subsequent edits.

</p><p>If the value of a path/value pair is an SQLite TEXT value, then it
is normally inserted as a quoted JSON string, even if the string looks
like valid JSON.  However, if the value is the result of another
json function (such as <a href="https://www.sqlite.org/json1.html#jmini">json()</a> or <a href="https://www.sqlite.org/json1.html#jarray">json_array()</a> or <a href="https://www.sqlite.org/json1.html#jobj">json_object()</a>)
or if it is the result of <a href="https://www.sqlite.org/json1.html#jptr">the -&gt; operator</a>,
then it is interpreted as JSON and is inserted as JSON retaining all
of its substructure.  Values that are the result of <a href="https://www.sqlite.org/json1.html#jptr">the -&gt;&gt; operator</a>
are always interpreted as TEXT and are inserted as a JSON string even
if they look like valid JSON.

</p><p>These routines throw an error if the first JSON argument is not
well-formed or if any PATH argument is not well-formed or if any
argument is a BLOB.

</p><p>To append an element onto the end of an array, using json_insert()
with an array index of "#".  Examples:

</p><ul>
<li><span>json_insert('[1,2,3,4]','$[#]',99)</span>
<span>→ '[1,2,3,4,99]'</span></li>

<li><span>json_insert('[1,[2,3],4]','$[1][#]',99)</span>
<span>→ '[1,[2,3,99],4]'</span></li>

</ul>


<p>Other examples:

</p><ul>
<li><span>json_insert('{"a":2,"c":4}', '$.a', 99)</span>
<span>→ '{"a":2,"c":4}'</span></li>

<li><span>json_insert('{"a":2,"c":4}', '$.e', 99)</span>
<span>→ '{"a":2,"c":4,"e":99}'</span></li>

<li><span>json_replace('{"a":2,"c":4}', '$.a', 99)</span>
<span>→ '{"a":99,"c":4}'</span></li>

<li><span>json_replace('{"a":2,"c":4}', '$.e', 99)</span>
<span>→ '{"a":2,"c":4}'</span></li>

<li><span>json_set('{"a":2,"c":4}', '$.a', 99)</span>
<span>→ '{"a":99,"c":4}'</span></li>

<li><span>json_set('{"a":2,"c":4}', '$.e', 99)</span>
<span>→ '{"a":2,"c":4,"e":99}'</span></li>

<li><span>json_set('{"a":2,"c":4}', '$.c', '[97,96]')</span>
<span>→ '{"a":2,"c":"[97,96]"}'</span></li>

<li><span>json_set('{"a":2,"c":4}', '$.c', json('[97,96]'))</span>
<span>→ '{"a":2,"c":[97,96]}'</span></li>

<li><span>json_set('{"a":2,"c":4}', '$.c', json_array(97,96))</span>
<span>→ '{"a":2,"c":[97,96]}'</span></li>

</ul>


<h2 id="the_json_object_function"><span>4.8. </span>The json_object() function</h2>

<p>The json_object() SQL function accepts zero or more pairs of arguments
and returns a well-formed JSON object that is composed from those arguments.
The first argument of each pair is the label and the second argument of
each pair is the value.
If any argument to json_object() is a BLOB then an error is thrown.

</p><p>The json_object() function currently allows duplicate labels without
complaint, though this might change in a future enhancement.

</p><p>An argument with SQL type TEXT it is normally converted into a quoted 
JSON string even if the input text is well-formed JSON.  
However, if the argument is the direct result from another JSON
function or <a href="https://www.sqlite.org/json1.html#jptr">the -&gt; operator</a> (but not <a href="https://www.sqlite.org/json1.html#jptr">the -&gt;&gt; operator</a>), 
then it is treated as JSON and all of its JSON type information
and substructure is preserved.  This allows calls to json_object()
and <a href="https://www.sqlite.org/json1.html#jarray">json_array()</a> to be nested.  The <a href="https://www.sqlite.org/json1.html#jmini">json()</a> function can also
be used to force strings to be recognized as JSON.

</p><p>Examples:

</p><ul>
<li><span>json_object('a',2,'c',4)</span>
<span>→ '{"a":2,"c":4}'</span></li>

<li><span>json_object('a',2,'c','{e:5}')</span>
<span>→ '{"a":2,"c":"{e:5}"}'</span></li>

<li><span>json_object('a',2,'c',json_object('e',5))</span>
<span>→ '{"a":2,"c":{"e":5}}'</span></li>

</ul>


<h2 id="the_json_patch_function"><span>4.9. </span>The json_patch() function</h2>

<p>The json_patch(T,P) SQL function runs the
<a href="https://tools.ietf.org/html/rfc7396">RFC-7396</a> MergePatch algorithm
to apply patch P against input T.  The patched copy of T is returned.

</p><p>MergePatch can add, modify, or delete elements of a JSON Object,
and so for JSON Objects, the json_patch() routine is a generalized
replacement for <a href="https://www.sqlite.org/json1.html#jset">json_set()</a> and <a href="https://www.sqlite.org/json1.html#jrm">json_remove()</a>.  However, MergePatch
treats JSON Array objects as atomic.  MergePatch cannot append to an
Array nor modify individual elements of an Array.  It can only insert,
replace, or delete the whole Array as a single unit.  Hence, json_patch()
is not as useful when dealing with JSON that includes Arrays,
especially Arrays with lots of substructure.

</p><p>Examples:

</p><ul>
<li><span>json_patch('{"a":1,"b":2}','{"c":3,"d":4}')</span>
<span>→ '{"a":1,"b":2,"c":3,"d":4}'</span></li>

<li><span>json_patch('{"a":[1,2],"b":2}','{"a":9}')</span>
<span>→ '{"a":9,"b":2}'</span></li>

<li><span>json_patch('{"a":[1,2],"b":2}','{"a":null}')</span>
<span>→ '{"b":2}'</span></li>

<li><span>json_patch('{"a":1,"b":2}','{"a":9,"b":null,"c":8}')</span>
<span>→ '{"a":9,"c":8}'</span></li>

<li><span>json_patch('{"a":{"x":1,"y":2},"b":3}','{"a":{"y":9},"c":8}')</span>
<span>→ '{"a":{"x":1,"y":9},"b":3,"c":8}'</span></li>

</ul>


<h2 id="the_json_remove_function"><span>4.10. </span>The json_remove() function</h2>

<p>The json_remove(X,P,...) function takes a single JSON value as its
first argument followed by zero or more path arguments.
The json_remove(X,P,...) function returns
a copy of the X parameter with all the elements 
identified by path arguments removed.  Paths that select elements
not found in X are silently ignored.

</p><p>Removals occurs sequentially from left to right.  Changes caused by
prior removals can affect the path search for subsequent arguments.

</p><p>If the json_remove(X) function is called with no path arguments,
then it returns the input X reformatted, with excess whitespace
removed.

</p><p>The json_remove() function throws an error if the first argument
is not well-formed JSON or if any later argument is not a well-formed
path, or if any argument is a BLOB.

</p><p>Examples:

</p><ul>
<li><span>json_remove('[0,1,2,3,4]','$[2]')</span>
<span>→ '[0,1,3,4]'</span></li>

<li><span>json_remove('[0,1,2,3,4]','$[2]','$[0]')</span>
<span>→ '[1,3,4]'</span></li>

<li><span>json_remove('[0,1,2,3,4]','$[0]','$[2]')</span>
<span>→ '[1,2,4]'</span></li>

<li><span>json_remove('[0,1,2,3,4]','$[#-1]','$[0]')</span>
<span>→ '[1,2,3]'</span></li>

<li><span>json_remove('{"x":25,"y":42}')</span>
<span>→ '{"x":25,"y":42}'</span></li>

<li><span>json_remove('{"x":25,"y":42}','$.z')</span>
<span>→ '{"x":25,"y":42}'</span></li>

<li><span>json_remove('{"x":25,"y":42}','$.y')</span>
<span>→ '{"x":25}'</span></li>

<li><span>json_remove('{"x":25,"y":42}','$')</span>
<span>→ NULL</span></li>

</ul>


<h2 id="the_json_type_function"><span>4.11. </span>The json_type() function</h2>

<p>The json_type(X) function returns the "type" of the outermost element
of X.  The json_type(X,P) function returns the "type" of the element
in X that is selected by path P.  The "type" returned by json_type() is
one of the following SQL text values:
'null', 'true', 'false', 'integer', 'real', 'text', 'array', or 'object'.
If the path P in json_type(X,P) selects an element that does not exist
in X, then this function returns NULL.

</p><p>The json_type() function throws an error if any of its arguments is
not well-formed or is a BLOB.

</p><p>Examples:

</p><ul>
<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}')</span>
<span>→ 'object'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$')</span>
<span>→ 'object'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a')</span>
<span>→ 'array'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[0]')</span>
<span>→ 'integer'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[1]')</span>
<span>→ 'real'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[2]')</span>
<span>→ 'true'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[3]')</span>
<span>→ 'false'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[4]')</span>
<span>→ 'null'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[5]')</span>
<span>→ 'text'</span></li>

<li><span>json_type('{"a":[2,3.5,true,false,null,"x"]}','$.a[6]')</span>
<span>→ NULL</span></li>

</ul>


<h2 id="the_json_valid_function"><span>4.12. </span>The json_valid() function</h2>

<p>The json_valid(X) function return 1 if the argument X is well-formed
canonical RFC-7159 JSON without any extensions, or return 0 if the
argument X is not well-formed JSON or is JSON that includes
<a href="https://www.sqlite.org/json1.html#json5">JSON5 extensions</a>.

</p><p>Examples:

</p><ul>
<li><span>json_valid('{"x":35}')</span>
<span>→ 1</span></li>

<li><span>json_valid('{"x":35')</span>
<span>→ 0</span></li>

</ul>


<p>Use the expression "<a href="https://www.sqlite.org/json1.html#jerr">json_error_position(X)</a>==0" to determine if
a string is well-formed JSON5.  Use the "<a href="https://www.sqlite.org/json1.html#jmini">json(X)</a>" routine to convert
JSON5 into canonical JSON.

<a name="jquote"></a>

</p><h2 id="the_json_quote_function"><span>4.13. </span>The json_quote() function</h2>

<p>The json_quote(X) function converts the SQL value X (a number or a
string) into its corresponding JSON representation.  If X is a JSON value
returned by another JSON function, then this function is a no-op.

</p><p>Examples:

</p><ul>
<li><span>json_quote(3.14159)</span>
<span>→ 3.14159</span></li>

<li><span>json_quote('verdant')</span>
<span>→ '"verdant"'</span></li>

<li><span>json_quote('[1]')</span>
<span>→ '"[1]"'</span></li>

<li><span>json_quote(json('[1]'))</span>
<span>→ '[1]'</span></li>

<li><span>json_quote('[1,')</span>
<span>→ '"[1,"'</span></li>

</ul>


<h2 id="the_json_group_array_and_json_group_object_aggregate_sql_functions"><span>4.14. </span>The json_group_array() and json_group_object()
aggregate SQL functions</h2>

<p>The json_group_array(X) function is an
<a href="https://www.sqlite.org/lang_aggfunc.html">aggregate SQL function</a> that returns a JSON array
comprised of all X values in the aggregation.
Similarly, the json_group_object(NAME,VALUE) function returns a JSON object
comprised of all NAME/VALUE pairs in the aggregation.


<a name="jeach"></a>

<a name="jtree"></a>

</p><h2 id="the_json_each_and_json_tree_table_valued_functions"><span>4.15. </span>The json_each() and json_tree() table-valued functions</h2>

<p>The json_each(X) and json_tree(X) <a href="https://www.sqlite.org/vtab.html#tabfunc2">table-valued functions</a> walk the
JSON value provided as their first argument and return one row for each
element.  The json_each(X) function only walks the immediate children
of the top-level array or object,
or just the top-level element itself if the top-level
element is a primitive value.
The json_tree(X) function recursively walks through the
JSON substructure starting with the top-level element.  

</p><p>The json_each(X,P) and json_tree(X,P) functions work just like
their one-argument counterparts except that they treat the element
identified by path P as the top-level element.

</p><p>The schema for the table returned by json_each() and json_tree() is
as follows:

</p><blockquote><pre>CREATE TABLE json_tree(
    key ANY,             -- key for current element relative to its parent
    value ANY,           -- value for the current element
    type TEXT,           -- 'object','array','string','integer', etc.
    atom ANY,            -- value for primitive types, null for array &amp; object
    id INTEGER,          -- integer ID for this element
    parent INTEGER,      -- integer ID for the parent of this element
    fullkey TEXT,        -- full path describing the current element
    path TEXT,           -- path to the container of the current row
    json JSON HIDDEN,    -- 1st input parameter: the raw JSON
    root TEXT HIDDEN     -- 2nd input parameter: the PATH at which to start
);
</pre></blockquote>

<p>
The "key" column is the integer array index for elements of a JSON array 
and the text label for elements of a JSON object.  The key column is
NULL in all other cases.

</p><p>
The "atom" column is the SQL value corresponding to primitive elements - 
elements other than JSON arrays and objects.  The "atom" column is NULL
for a JSON array or object.  The "value" column is the same as the
"atom" column for primitive JSON elements but takes on the text JSON value
for arrays and objects.

</p><p>
The "type" column is an SQL text value taken from ('null', 'true', 'false',
'integer', 'real', 'text', 'array', 'object') according to the type of
the current JSON element.

</p><p>
The "id" column is an integer that identifies a specific JSON element
within the complete JSON string.  The "id" integer is an internal housekeeping
number, the computation of which might change in future releases.  The
only guarantee is that the "id" column will be different for every row.

</p><p>
The "parent" column is always NULL for json_each().
For json_tree(),
the "parent" column is the "id" integer for the parent of the current
element, or NULL for the top-level JSON element or the element identified
by the root path in the second argument.

</p><p>
The "fullkey" column is a text path that uniquely identifies the current
row element within the original JSON string.  The complete key to the
true top-level element is returned even if an alternative starting point
is provided by the "root" argument.

</p><p>
The "path" column is the path to the array or object container that holds 
the current row, or the path to the current row in the case where the 
iteration starts on a primitive type and thus only provides a single
row of output.

</p><h3 id="examples_using_json_each_and_json_tree_"><span>4.15.1. </span>Examples using json_each() and json_tree()</h3>

<p>Suppose the table "CREATE TABLE user(name,phone)" stores zero or
more phone numbers as a JSON array object in the user.phone field.
To find all users who have any phone number with a 704 area code:

</p><blockquote><pre>SELECT DISTINCT user.name
  FROM user, json_each(user.phone)
 WHERE json_each.value LIKE '704-%';
</pre></blockquote>

<p>Now suppose the user.phone field contains plain text if the user
has only a single phone number and a JSON array if the user has multiple
phone numbers.  The same question is posed: "Which users have a phone number
in the 704 area code?"  But now the json_each() function can only be called
for those users that have two or more phone numbers since json_each()
requires well-formed JSON as its first argument:

</p><blockquote><pre>SELECT name FROM user WHERE phone LIKE '704-%'
UNION
SELECT user.name
  FROM user, json_each(user.phone)
 WHERE json_valid(user.phone)
   AND json_each.value LIKE '704-%';
</pre></blockquote>

<p>Consider a different database with "CREATE TABLE big(json JSON)".
To see a complete line-by-line decomposition of the data:

</p><blockquote><pre>SELECT big.rowid, fullkey, value
  FROM big, json_tree(big.json)
 WHERE json_tree.type NOT IN ('object','array');
</pre></blockquote>

<p>In the previous, the "type NOT IN ('object','array')" term of the
WHERE clause suppresses containers and only lets through leaf elements.
The same effect could be achieved this way:

</p><blockquote><pre>SELECT big.rowid, fullkey, atom
  FROM big, json_tree(big.json)
 WHERE atom IS NOT NULL;
</pre></blockquote>

<p>Suppose each entry in the BIG table is a JSON object 
with a '$.id' field that is a unique identifier
and a '$.partlist' field that can be a deeply nested object.
You want to find the id of every entry that contains one
or more references to uuid '6fa5181e-5721-11e5-a04e-57f3d7b32808' anywhere
in its '$.partlist'.

</p><blockquote><pre>SELECT DISTINCT json_extract(big.json,'$.id')
  FROM big, json_tree(big.json, '$.partlist')
 WHERE json_tree.key='uuid'
   AND json_tree.value='6fa5181e-5721-11e5-a04e-57f3d7b32808';
</pre></blockquote>
<p><small><i>This page last modified on  <a href="https://sqlite.org/docsrc/honeypot" id="mtimelink" data-href="https://sqlite.org/docsrc/finfo/pages/json1.in?m=f2d9d092d1">2023-08-01 17:34:32</a> UTC </i></small></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Source code for Quake 2 rerelease (538 pts)]]></title>
            <link>https://github.com/id-Software/quake2-rerelease-dll</link>
            <guid>37082771</guid>
            <pubDate>Thu, 10 Aug 2023 22:57:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/id-Software/quake2-rerelease-dll">https://github.com/id-Software/quake2-rerelease-dll</a>, See on <a href="https://news.ycombinator.com/item?id=37082771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Quake II Rerelease Game Source</h2>
<p dir="auto">This repository contains the game code for the 2023 rerelease of Quake II, for users who wish to mod the game, along with the original game code that was use for reference. Mods can be loaded into the rerelease the same way as the original game: launch the game with <code>+set game mymod</code> or type <code>game mymod</code> into the console while the game is running. We recommend installing mods into your <code>%USERPROFILE%\Saved Games\Nightdive Studios\Quake II</code> directory to ensure the original game files do not get modified.</p>
<p dir="auto">id Software is unable to provide support for this release, however we urge you to take advantage of the depth of community-driven resources already available.</p>
<p dir="auto">The rerelease of Quake II uses a new version of the API to communicate between the server &amp; the game module. It also introduces a very thin "client game" module, akin to Quake III Arena's cgame module, to allow for extended modding opportunities that change previously hardcoded client behavior. It also has a new network protocol, version 2023.</p>
<p dir="auto">This codebase is a combination of the separate game modules that were part of the original game: baseq2, ctf, rogue, and xatrix. It requires a C++17 compiler. In cases of conflicting spawnflags, maps were modified in order to resolve issues, so original expansion pack maps may not load correctly with this DLL. The combined FGD as used for development is also available for users wishing to make new maps. A modified TrenchBroom Quake II <code>gameconfig.cfg</code> is included as there are modified textureflags.</p>
<p dir="auto">Because the game export interface has changed, existing mods may be able to be moved over to support the API changes. However, in order to support all expansion packs under one codebase and new features in the rerelease, there have been some major changes to structure and layout, so old mods wishing to use the new codebase may need to be rewritten.</p>
<p dir="auto">The API changes discussed here are written from the perspective of the game DLL.</p>
<h2 tabindex="-1" dir="auto">Compiling</h2>
<p dir="auto">The game DLL has only been tested with Clang, VS2019 and VS2022.</p>
<p dir="auto">The code can compile under both C++17 and C++20. Using C++20 allows you to skip <code>fmtlib</code> as a dependency.</p>
<h3 tabindex="-1" dir="auto">Required preprocessor definitions</h3>
<ul dir="auto">
<li><code>GAME_INCLUDE</code> must be defined, tells <code>game.h</code> that this is the game DLL compiling it.</li>
<li><code>KEX_Q2GAME_EXPORTS</code> must be defined, tells <code>game.h</code> that we are exporting the <code>GetGameAPI</code> function.</li>
<li><code>KEX_Q2GAME_DYNAMIC</code> must be defined. The game DLL supports static linking on console platforms, but is always dynamic on PC.</li>
<li><code>NO_FMT_SOURCE</code>: this is only here because of a limitation in the internal build system. It must be defined.</li>
</ul>
<h3 tabindex="-1" dir="auto">Optional preprocessor definitions</h3>
<ul dir="auto">
<li><code>KEX_Q2_GAME</code>: must be defined if compiling for Kex. This changes the behavior of the <code>say</code> command to go through the lobby.</li>
<li><code>KEX_Q2GAME_IMPORTS</code>: only used by engine, tells <code>game.h</code> that we are importing <code>GetGameAPI</code>.</li>
<li><code>USE_CPP20_FORMAT</code>: if explicitly defined, C++20's <code>&lt;format&gt;</code> library will be used instead of <code>fmtlib</code>; otherwise <code>fmtlib</code> usage will be autodetected.</li>
</ul>
<h3 tabindex="-1" dir="auto">Dependencies</h3>
<ul dir="auto">
<li><a href="https://github.com/fmtlib/fmt">fmtlib</a>: If <code>USE_CPP20_FORMAT</code> is not set, the library needs to be available in the <code>fmt</code> subdirectory.</li>
<li><a href="https://github.com/open-source-parsers/jsoncpp">jsoncpp</a>: Must be placed inside <code>json</code> subdirectory.</li>
</ul>
<p dir="auto">Both of these can also be installed via vcpkg: <code>vcpkg install jsoncpp:x64-windows fmt:x64-windows</code></p>
<h3 tabindex="-1" dir="auto">Windows (Visual Studio 2019 / 2022):</h3>
<ul dir="auto">
<li>We recommend placing the source in a subfolder within a mod directory. For example, alongside <code>baseq2</code>, make a folder called <code>mymod</code>, enter that folder, make a folder called <code>src</code>, and copying the contents of the <code>rerelease</code> directory into the newly-created <code>src</code> subfolder.</li>
<li>Open <code>game.sln</code></li>
<li>Build solution</li>
</ul>
<p dir="auto">Debugging the DLL is possible when attaching to the engine EXE. Note that if you are using VS2022 Hot Reload, due to an internal Hot Reload issue, current edits will be lost when disconnecting from the server, or changing levels using the <code>map</code> command.</p>
<h2 tabindex="-1" dir="auto">40hz Tickrate Support</h2>
<p dir="auto">As part of this release, all internal logic in the game DLL has been adjusted to run at 40hz compared to the original 10hz of the original engine. This provides a better gameplay experience, and allows maps and game logic to run at more precise steps than the original 100ms. 40hz was chosen as it is a multiple of the original 10hz, operates at an integral 25ms step, and was the best balance between bandwidth and CPU concerns around the original tech.</p>
<h2 tabindex="-1" dir="auto">Print Adjustments</h2>
<p dir="auto">As part of the API cleanup, the game DLL no longer uses varargs in any of its functions. Varargs are compiler-specific and not very portable, so instead, the onus is on the caller to handle formatting. As a bonus, this allows the game DLL to more easily hook in modern formatting providers; the game DLL uses <code>fmt</code> almost exclusively. Several built-in types, like <code>edict_t</code> and <code>vec3_t</code>, can be formatted directly.</p>
<h2 tabindex="-1" dir="auto">Math Changes</h2>
<p dir="auto">Since C++ is now used in the game DLL, math functions were made constexpr where appropriate, and operator overloads are used to make math easier to work with and closer to QuakeC. For instance, <code>VectorMA(a, s, b, c)</code> can now be written as <code>c = a + (b * s)</code>, which expresses the operation better.</p>
<h2 tabindex="-1" dir="auto">Type Changes</h2>
<p dir="auto"><code>qboolean</code>, which was aliased to <code>int32_t</code>, is now instead aliased to <code>bool</code>. This type should be equivalent to C's <code>_Bool</code>.</p>
<h2 tabindex="-1" dir="auto">Info Keys</h2>
<p dir="auto">In the original Quake II, all infokey values are purely ASCII with upper bits stripped. Kex and the Quake II rerelease engine supports UTF-8 for things like player names, which necessated a change to the way info keys work. Instead of implementing a whole UTF-8 system in the game DLL, these functions are now imports, so the engine is in control of the parsing and string management.</p>
<p dir="auto">Userinfo variables are now suffixed with a number for split screen support. For instance, <code>name</code> and <code>skin</code> have become <code>name_0</code> and <code>skin_0</code> for the first player, <code>name_1</code> and <code>skin_1</code> for the second player, and so on.</p>
<h2 tabindex="-1" dir="auto">Extensions</h2>
<p dir="auto">In an attempt to remain compatible with future community engines, all engine interfaces contain stubbed functions for GetExtension. This is currently unused and will only return nullptr, however other engines may wish to support returning named structs containing extra function pointers based on string parameters. This is similar to <code>getextension</code> that has become standard in many QuakeC environments.</p>
<p dir="auto">Conforming engines should return nullptr if an extension is not supported, otherwise they should return a non null pointer value that is relevant to the requested feature. Supporting engines should use namespaces for features to prevent name collisions around common and possibly incompatible implementations.</p>
<h2 tabindex="-1" dir="auto">Player Movement</h2>
<p dir="auto">Player movement ("pmove") is now handled as an export in both <code>game_export_t</code> <em>and</em> <code>cgame_export_t</code>. This allows a game module to modify physics while still working with client prediction. Pmove also received several upgrades, such as more bits for flags and full float positioning.</p>
<p dir="auto">Because a lot of movement quirks in Quake II were indirectly caused by the compression, these behaviors were retained. Trick jumping is now an explicit movement type, to allow for things like the Mega Health box jumps to still work. Some fixes were made, like jumping higher below the 0 z point of the map.</p>
<h2 tabindex="-1" dir="auto">Frame visibility</h2>
<p dir="auto">As part of network improvements, some changes were made to the "entity is visible to client in frame" methods:</p>
<ul dir="auto">
<li>Split-screen support since all clients share a frame.</li>
<li>Entities with shadows will be visible if their shadows may be visible to a player.</li>
<li>Sound attenuation culling is now calculated formulaically to match the sound system, and takes loop_attenuation into account.</li>
</ul>
<h2 tabindex="-1" dir="auto">Entity linkage</h2>
<p dir="auto">To fix a legacy bug where lasers only relied on one position for culling, RF_BEAM entities now set their <code>absmin</code> &amp; <code>absmax</code> properly. This can cause them to be a bit inflated if they are angled, but should not cause any issues otherwise.</p>
<p dir="auto">In a similar vein, <code>gi.linkentity</code> no longer automatically sets <code>old_origin</code> for beams. This is to make it a bit easier to work with beams, as otherwise you'd be forced to link twice to get it linked into the world correctly. This <em>might</em> break old mods that depends on this behavior.</p>
<h2 tabindex="-1" dir="auto">Audio positioning</h2>
<p dir="auto">Entity spatialization underwent an overhaul (<code>CL_GetEntitySoundOrigin</code> mainly).</p>
<ul dir="auto">
<li>Brush models will use the closest point on the bmodel's absmin/absmax to the listener's origin. This allows moving brush models with sounds to make consistent sounds, and be full volume if you are inside of them.</li>
<li>Beams now support <code>s.sound</code>, and plays their sound on the nearest point between the two beam origins.</li>
</ul>
<p dir="auto">As a secondary fix to the above, <code>S_StartSound</code> has slightly different logic now surrounding what origin to pick when playing a sound:</p>
<div dir="auto" data-snippet-clipboard-copy-content="if (entnum < MAX_EDICTS &amp;&amp; (origin || fixed_origin))
{
	// [Paril-KEX] if we can currently see the entity in question
	// and it's a bmodel or beam, don't use a fixed origin so it sounds correct
	if (!fixed_origin &amp;&amp; entnum > 1 &amp;&amp; (cl_entities[entnum].serverframe == cl.frame.serverframe || 
		(cl_entities[entnum].current.solid == PACKED_SOLID_BSP || (cl_entities[entnum].current.renderfx &amp; RF_BEAM))))
	{
		ps->fixed_origin = false;
	}
	else
	{
		VectorCopy (origin, ps->origin);
		ps->fixed_origin = true;
	}
}
else
	ps->fixed_origin = false;"><pre><span>if</span> (entnum &lt; MAX_EDICTS &amp;&amp; (origin || fixed_origin))
{
	<span><span>//</span> [Paril-KEX] if we can currently see the entity in question</span>
	<span><span>//</span> and it's a bmodel or beam, don't use a fixed origin so it sounds correct</span>
	<span>if</span> (!fixed_origin &amp;&amp; entnum &gt; <span>1</span> &amp;&amp; (cl_entities[entnum].<span>serverframe</span> == cl.<span>frame</span>.<span>serverframe</span> || 
		(cl_entities[entnum].<span>current</span>.<span>solid</span> == PACKED_SOLID_BSP || (cl_entities[entnum].<span>current</span>.<span>renderfx</span> &amp; RF_BEAM))))
	{
		ps-&gt;<span>fixed_origin</span> = <span>false</span>;
	}
	<span>else</span>
	{
		<span>VectorCopy</span> (origin, ps-&gt;<span>origin</span>);
		ps-&gt;<span>fixed_origin</span> = <span>true</span>;
	}
}
<span>else</span>
	ps-&gt;fixed_origin = <span>false</span>;</pre></div>
<p dir="auto"><code>fixed_origin</code> is set to <code>flags &amp; SND_EXPLICIT_POS</code> for svc_sound packets, and is <code>false</code> otherwise. If the playsounds' <code>fixed_origin</code> field is set, then the <code>ps-&gt;origin</code> value will <em>always</em> be used over automatically trying to determine its position.</p>
<h2 tabindex="-1" dir="auto">Client entity adjustments</h2>
<ul dir="auto">
<li>Beam origin points are interpolated if they exist between frames.</li>
<li><code>TE_ELECTRIC_SPARKS</code> and <code>TE_SCREEN_SPARKS</code>/<code>TE_SHIELD_SPARKS</code> will only play sounds once on any given frame.</li>
<li>Entities will never play the same footstep sound twice in a row.</li>
<li>Beams now squash the ends of their beams so they don't intersect walls or end early.</li>
<li>Alpha and transparency settings now get copied over to all sub-modelindices.</li>
<li>Lightramps are now interpolated, which looks nicer and helps with epilepsy.</li>
<li><code>delta_angles</code> are interpolated now, although this is never used at all in the game.</li>
<li><code>screen_blend</code> and <code>damage_blend</code> are interpolated now, but only if the frame prior didn't have a clear color.</li>
</ul>
<h2 tabindex="-1" dir="auto">Configstrings</h2>
<p dir="auto">Configstrings have been overhauled. There is now a theoretical maximum of <code>32767</code> entries, although you are still bound by the game APIs value of <code>MAX_CONFIGSTRINGS</code>.</p>
<p dir="auto">The maximum length of a configstring has increased from <code>64</code> to <code>96</code>.</p>
<p dir="auto">The API now canonizes that certain spans (<code>CS_STATUSBAR</code> and <code>CS_GENERAL</code>) can span multiple lines. A <code>CS_SIZE</code> function is provided to calculate the total size (in bytes) that can be written to for a given configstring ID.</p>
<p dir="auto">A convenience function, <code>CS_REMAP</code>, is provided to help remap old configstring IDs to new ones. This is used in our engine to provide old demo support.</p>
<p dir="auto"><code>MAX_MODELS</code>, <code>MAX_SOUNDS</code> and <code>MAX_IMAGES</code> have been increased from 256 to 8192, 2048, and 512, respectively.</p>
<h3 tabindex="-1" dir="auto">CS_STATUSBAR</h3>
<p dir="auto">This entry now spans entries 5 to 58 instead of 5 to 28, giving you an effective size of 5184 bytes (minus one for the null terminator) for the statusbar strings, up from 1536 bytes.</p>
<h3 tabindex="-1" dir="auto">CS_SHADOWLIGHTS</h3>
<p dir="auto">This new span each consists of a shadow light entry. Its format is semicolon-separated numerical values, in the following type &amp; order:</p>
<ul dir="auto">
<li>int entity_order</li>
<li>int type (0 = point, 1 = cone)</li>
<li>float radius</li>
<li>int resolution</li>
<li>float intensity</li>
<li>float fade_start</li>
<li>float fade_end</li>
<li>int lightstyle</li>
<li>float coneangle</li>
<li>float direction_x</li>
<li>float direction_y</li>
<li>float direction_z</li>
</ul>
<h3 tabindex="-1" dir="auto">CS_WHEEL_WEAPONS</h3>
<p dir="auto">This new span consists of entries for the weapon wheel. It consists of pipe-separated integral values, in the following order:</p>
<ul dir="auto">
<li>CS_ITEMS item index</li>
<li>CS_IMAGES image index</li>
<li>CS_WHEEL_AMMO ammo index (or -1 for no ammo)</li>
<li>minimum ammo to use weapon</li>
<li>whether the weapon is on the powerup wheel or the weapon wheel</li>
<li>additional sort integer</li>
<li>quantity to warn on low ammo on</li>
<li>whether this weapon is droppable or not</li>
</ul>
<h3 tabindex="-1" dir="auto">CS_WHEEL_AMMO</h3>
<p dir="auto">This new span consists of entries for the weapon wheel ammo types. It consists of pipe-separated integral values, in the following order:</p>
<ul dir="auto">
<li>CS_ITEMS item index</li>
<li>CS_IMAGES image index</li>
</ul>
<h3 tabindex="-1" dir="auto">CS_WHEEL_POWERUPS</h3>
<p dir="auto">This new span consists of entries for the powerup wheel. It consists of pipe-separated integral values, in the following order:</p>
<ul dir="auto">
<li>CS_ITEMS image index</li>
<li>CS_IMAGES image index</li>
<li>if 1, it is a togglable powerup instead of having a count</li>
<li>additional sort integer</li>
<li>whether we can drop this powerup or not</li>
<li>CS_WHEEL_AMMO ammo index, if applicable (-1 for no ammo)</li>
</ul>
<h3 tabindex="-1" dir="auto">CS_CD_LOOP_COUNT</h3>
<p dir="auto">Integer which determines how many times to loop the music before switching to the ambient track. Leave blank to use the clients' preferred value, otherwise it is forced to this value (a value of zero means never switch to ambient track).</p>
<h3 tabindex="-1" dir="auto">CS_GAME_STYLE</h3>
<p dir="auto">Inform the client about the type of game being played.</p>
<h2 tabindex="-1" dir="auto">Structures</h2>
<p dir="auto">Quake II has two main shared structures: <code>gclient_t</code> and <code>edict_t</code>. These split off into various other shared structures that have to be the same between the game &amp; server.</p>
<p dir="auto">Like the original release, the "shared" aspects of these structs must be identical, and are stored in <code>game.h</code> as <code>edict_shared_t</code> and <code>gclient_shared_t</code> respectively.</p>
<p dir="auto">The structure changes will be listed from the bottom-up. Full listings of the structures can be found in the source.</p>
<h2 tabindex="-1" dir="auto">cvar_flags_t</h2>
<h3 tabindex="-1" dir="auto">CVAR_USER_PROFILE (bit 5)</h3>
<p dir="auto">This is a new flag that is solely for the client; it indicates that a cvar is treated like userinfo for the purposes of storage, but is not sent to the server like userinfo usually is. For example, this flag is applied to <code>cl_run_N</code>, which controls the individual Always Run flags for each split screen player.</p>
<h2 tabindex="-1" dir="auto">contents_t</h2>
<h3 tabindex="-1" dir="auto">CONTENTS_PROJECTILECLIP (bit 14)</h3>
<p dir="auto">This new content flag will be collided against by <code>CONTENTS_PROJECTILE</code> entities.</p>
<h3 tabindex="-1" dir="auto">CONTENTS_PLAYER (bit 30)</h3>
<p dir="auto">This special content type flag is set only on player entities, and allows tracing to exclude/include them.</p>
<h3 tabindex="-1" dir="auto">CONTENTS_PROJECTILE (bit 31)</h3>
<p dir="auto">This special content type flag is set only on projectiles, and allows tracing to exclude/include them.</p>
<h2 tabindex="-1" dir="auto">surfflags_t</h2>
<h3 tabindex="-1" dir="auto">SURF_ALPHATEST (bit 25)</h3>
<p dir="auto">This bit is widely supported by other engines and is supported in the rerelease.</p>
<h3 tabindex="-1" dir="auto">SURF_N64_UV (bit 28)</h3>
<p dir="auto">This flag is specific to N64, and halves texture sizes.</p>
<h3 tabindex="-1" dir="auto">SURF_N64_SCROLL_X (bit 29)</h3>
<p dir="auto">This flag is specific to N64, and causes textures to scroll in the X axis.</p>
<h3 tabindex="-1" dir="auto">SURF_N64_SCROLL_Y (bit 30)</h3>
<p dir="auto">This flag is specific to N64, and causes textures to scroll in the Y axis.</p>
<h3 tabindex="-1" dir="auto">SURF_N64_SCROLL_FLIP (bit 31)</h3>
<p dir="auto">This flag is specific to N64, and flips the scroll axis.</p>
<h2 tabindex="-1" dir="auto">csurface_t</h2>
<p dir="auto">This structure has undergone canonization of the 3.2x changes by Zoid.</p>
<h3 tabindex="-1" dir="auto">char[32] name</h3>
<p dir="auto">Uses the proper name length now.</p>
<h3 tabindex="-1" dir="auto">uint32_t id</h3>
<p dir="auto">This value must represent a unique ID that corresponds to its texinfo. The same ID must always reference the same texinfo, but they don't necessarily have to be sequential. Zero must always mean "no texinfo".</p>
<p dir="auto">This is used by the client for indexing footstep sounds.</p>
<h3 tabindex="-1" dir="auto">char[16] material</h3>
<p dir="auto">The material ID for this texinfo, from the corresponding <code>.mat</code> file.</p>
<h2 tabindex="-1" dir="auto">trace_t</h2>
<h3 tabindex="-1" dir="auto">csurface_t *surface</h3>
<p dir="auto">The only change is a contractual one: this value must never be null.</p>
<h3 tabindex="-1" dir="auto">cplane_t plane2 / csurface_t *surface2</h3>
<p dir="auto">When a trace impacts multiple planes at the destination, the collision system will now report both of them. The "second best" plane and surface are stored here. <code>surface2</code> <em>must</em> be null if a second surface was not hit.</p>
<p dir="auto">This is used to solve some epsilon issues with the player movement system.</p>
<h2 tabindex="-1" dir="auto">cvar_t</h2>
<h3 tabindex="-1" dir="auto">int32_t modified_count</h3>
<p dir="auto">The old <code>qboolean modified;</code> has been changed into an integral value. This value is increased when the cvar has been changed, but is <strong>never</strong> zero. The reason for this is so that "is cvar modified" checks always succeed on the first check, assuming you initialize the last modified value to 0.</p>
<p dir="auto">The function <code>Cvar_WasModified</code> is provided as a convenience function to perform this task for you.</p>
<h3 tabindex="-1" dir="auto">int32_t integer</h3>
<p dir="auto">A common extension to Quake II, the integral value is stored at the end of the struct for you to use.</p>
<h2 tabindex="-1" dir="auto">player_state_t</h2>
<h3 tabindex="-1" dir="auto">int32_t gunskin</h3>
<p dir="auto">This is a new value which sets the skin number used on the weapon.</p>
<h3 tabindex="-1" dir="auto">int32_t gunrate</h3>
<p dir="auto">This value sets the frame rate (in hz) of the players' weapon. For backwards compatibility, a value of 0 is equivalent to a value of 10. This ia mainly used for the Haste powerup, but in theory it could be used for future mods to have higher tickrate weapons in general.</p>
<h3 tabindex="-1" dir="auto">float[4] screen_blend / damage_blend</h3>
<p dir="auto">The full-screen <code>blend</code> value was split into two values: <code>screen_blend</code> and <code>damage_blend</code>.</p>
<p dir="auto"><code>screen_blend</code> is the same as the original one, and is a full-screen color change. It is mainly used now for full-screen fades. To reduce the amount of screen flashing, the base game avoids flashing the screen whenever possible.</p>
<p dir="auto"><code>damage_blend</code> is a new type of blend that occurs around the edge of the screen; this is used to replace many events that previously would flash the full screen.</p>
<h3 tabindex="-1" dir="auto">refdef_flags_t rdflags</h3>
<p dir="auto">The only adjustment to <code>rdflags</code> was the addition of a new flag: <code>RDF_NO_WEAPON_LERP</code>. This occupies bit 4, and can be used to temporarily disable interpolation on weapons.</p>
<h3 tabindex="-1" dir="auto">short[64] stats</h3>
<p dir="auto"><code>MAX_STATS</code> was increased from 32 to 64. Note that because stats are now handled by the game &amp; cgame modules, you are not limited to a short for the purposes of packing down data/</p>
<h3 tabindex="-1" dir="auto">uint8_t team_id</h3>
<p dir="auto">For teamplay-oriented games, the player's team is sent in player state. While the client could derive this from entity state in theory, in practice that's a bit ugly since the players' entity may not even be visible (for instance if you've been gibbed), so this was the cleaner approach.</p>
<h2 tabindex="-1" dir="auto">usercmd_t</h2>
<p dir="auto">The fields <code>upmove</code>, <code>impulse</code> and <code>lightlevel</code> have been removed.</p>
<h3 tabindex="-1" dir="auto">button_t buttons</h3>
<h4 tabindex="-1" dir="auto">BUTTON_HOLSTER (bit 2)</h4>
<p dir="auto">This button corresponds to the new <code>+holster</code> command, which will keep the weapon holstered until depressed. It is used by the weapon wheel to allow the player to start switching weapons before the weapon wheel is dismissed.</p>
<h4 tabindex="-1" dir="auto">BUTTON_JUMP (bit 3)</h4>
<h4 tabindex="-1" dir="auto">BUTTON_CROUCH (bit 4)</h4>
<p dir="auto">These two new bits replace <code>usercmd_t::upmove</code>, and determine the players' jumping and crouch states.</p>
<h3 tabindex="-1" dir="auto">vec3_t angles</h3>
<p dir="auto">These are now full float precision, allowing for players to aim more precisely.</p>
<h3 tabindex="-1" dir="auto">float forwardmove / sidemove</h3>
<p dir="auto">These are now full float, to allow controller inputs to be more precise.</p>
<h3 tabindex="-1" dir="auto">uint32_t server_frame</h3>
<p dir="auto">New entry sent along with every usercmd, which tells the server which server frame that the input was depressed on. This is used for integrity checks, as well as for anti-lag hitscan.</p>
<h2 tabindex="-1" dir="auto">pmove_state_t</h2>
<h3 tabindex="-1" dir="auto">pmtype_t pm_type</h3>
<p dir="auto">Two new pmove types have been added before <code>PM_SPECTATOR</code>, offsetting it and its subsequent entries by 2.</p>
<h4 tabindex="-1" dir="auto">PM_GRAPPLE (1)</h4>
<p dir="auto">Used for the grappling hook; it informs client prediction that you should be pulled towards <code>velocity</code> and are not affected by gravity.</p>
<h4 tabindex="-1" dir="auto">PM_NOCLIP (2)</h4>
<p dir="auto">This is what <code>PM_SPECTATOR</code> used to be, and prevents all clipping.</p>
<h4 tabindex="-1" dir="auto">PM_SPECTATOR (3)</h4>
<p dir="auto">This value now represents spectator mode; you cannot enter walls, but can go through brush entities.</p>
<h3 tabindex="-1" dir="auto">vec3_t origin / vec3_t velocity / vec3_t delta_angles</h3>
<p dir="auto">These fields now have full float precision versus the original release. See <a href="#pmove">Pmove</a> for more details.</p>
<h3 tabindex="-1" dir="auto">pmflags_t pm_flags</h3>
<p dir="auto">This type has had its capacity increased to <code>int16</code>. The following flags are new or adjusted:</p>
<h4 tabindex="-1" dir="auto">PMF_NO_POSITIONAL_PREDICTION</h4>
<p dir="auto">This flag was originally called <code>PMF_NO_PREDICTION</code>; it now only disables prediction on origin, allowing angles to be predicted. <strong>This is a backwards-incompatible change</strong>, but should have very minimal impact on running old mods. This improves the feeling of the grappling hook.</p>
<h4 tabindex="-1" dir="auto">PMF_ON_LADDER</h4>
<p dir="auto">This bit is used to signal back to the game that we are currently attached to a ladder.</p>
<h4 tabindex="-1" dir="auto">PMF_NO_ANGULAR_PREDICTION</h4>
<p dir="auto">The angular equivalent of <code>PMF_NO_POSITIONAL_PREDICTION</code>.</p>
<h4 tabindex="-1" dir="auto">PMF_IGNORE_PLAYER_COLLISION</h4>
<p dir="auto">This flag is input only, and tells Pmove to ignore <code>CONTENTS_PLAYER</code> contents.</p>
<h4 tabindex="-1" dir="auto">PMF_TIME_TRICK</h4>
<p dir="auto">If set, then <code>pm_time</code> is the time remaining to start a trick jump.</p>
<h3 tabindex="-1" dir="auto">uint16_t pm_time</h3>
<p dir="auto"><code>pm_time</code> is now expressed in milliseconds instead of 8 * ms; since the code clamped subtractions on this to 1, it meant that high framerate players experienced slightly different physics, and in the case of trick jumps, had a smaller time gap to perform them.</p>
<h3 tabindex="-1" dir="auto">int8_t viewheight</h3>
<p dir="auto">A new field describing the viewheight output; this is for crouch prediction.</p>
<h2 tabindex="-1" dir="auto">pmove_t</h2>
<p dir="auto">The field <code>viewheight</code> has been removed, since it is now part of <code>pmove_state_t</code>.</p>
<h3 tabindex="-1" dir="auto">touch_list_t touch</h3>
<p dir="auto">The list of touched entities has been replaced with a list of traces, allowing the game to react better to touches.</p>
<h3 tabindex="-1" dir="auto">cplane_t groundplane</h3>
<p dir="auto">The plane that you're standing on is now returned by pmove.</p>
<h3 tabindex="-1" dir="auto">edict_t *player</h3>
<p dir="auto">An opaque handle to the player object, passed back to <code>trace</code>.</p>
<h3 tabindex="-1" dir="auto">trace / clip</h3>
<p dir="auto"><code>trace</code> is now sent the <code>passent</code> and <code>contentmask</code>, so it can perform more complex tracing routines.</p>
<p dir="auto"><code>clip</code> is also now available to pmove, should you need it. It is currently only used in spectator movement, to clip solely against the world and nothing else.</p>
<h3 tabindex="-1" dir="auto">vec3_t viewoffset</h3>
<p dir="auto">The player's viewoffset is now passed in, to allow for accurate blending. Pmove is now semi-responsible for screen blends.</p>
<h3 tabindex="-1" dir="auto">vec3_t screen_blend</h3>
<p dir="auto">An output variable containing full-screen blends to apply to the view.</p>
<h3 tabindex="-1" dir="auto">refdef_flags_t rdflags</h3>
<p dir="auto">An output variable containing flags that should be merged with the server's representation.</p>
<h3 tabindex="-1" dir="auto">bool jump_sound</h3>
<p dir="auto">An output variable to tell the game to play a jumping sound.</p>
<h3 tabindex="-1" dir="auto">float impact_delta</h3>
<p dir="auto">When new ground is achieved, the impact is stored here for fall damage checks.</p>
<h2 tabindex="-1" dir="auto">edict_shared_t</h2>
<p dir="auto">NOTE: the following members of the old <code>edict_t</code> struct have been removed, and were moved server-side:</p>
<ul dir="auto">
<li><code>link_t area</code></li>
<li><code>int num_clusters</code></li>
<li><code>int clusternums[]</code></li>
<li><code>int headnode</code></li>
</ul>
<h3 tabindex="-1" dir="auto">sv_entity_t sv</h3>
<p dir="auto">Most of the meat of the bot system is contained in the server code, and doesn't have direct access to the games' representation of the state of the game.</p>
<p dir="auto">Bots use this thin interpretation of the game state data about entities to understand how to use entities to its advantage - similar to how the client receives a thin portion of entities to understand how to render them.</p>
<h3 tabindex="-1" dir="auto">bool linked</h3>
<p dir="auto">This boolean indicates whether the entity is currently linked into the world or not. It is the replacement of checking for <code>area.prev</code> being non-null.</p>
<h3 tabindex="-1" dir="auto">svflags_t svflags</h3>
<p dir="auto">For new functionality, some new flags were added to <code>svflags</code>. <strong>This may cause backwards-incompatibility in older mods that have modified this enum!</strong> This enum is server-specific, so it is always incorrect for mods to modify this.</p>
<h4 tabindex="-1" dir="auto">SVF_PLAYER</h4>
<p dir="auto">This flag causes the object to be treated as <code>CONTENTS_PLAYER</code> for collision. All players have this flag.</p>
<h4 tabindex="-1" dir="auto">SVF_BOT</h4>
<p dir="auto">This flag marks the entity as a bot.</p>
<h4 tabindex="-1" dir="auto">SVF_NOBOTS</h4>
<p dir="auto">This flag tells the bot subsystem to ignore this entity.</p>
<h4 tabindex="-1" dir="auto">SVF_RESPAWNING</h4>
<p dir="auto">This flag is a hint to the bot subsystem to inform it about how items respawn.</p>
<h4 tabindex="-1" dir="auto">SVF_PROJECTILE</h4>
<p dir="auto">This flag treats the entity as <code>CONTENTS_PROJECTILE</code> for collision.</p>
<h4 tabindex="-1" dir="auto">SVF_INSTANCED</h4>
<p dir="auto">This flag marks the entity as being instanced - it may be invisible or hidden for certain players.</p>
<h4 tabindex="-1" dir="auto">SVF_DOOR</h4>
<p dir="auto">This flag is for the bot subsystem, and informs it that this entity is a door.</p>
<h4 tabindex="-1" dir="auto">SVF_NOCULL</h4>
<p dir="auto">This flag overrides the client frame building culling routines, causing an entity to always be sent regardless of where it is (ignoring PVS/PHS, essentially). Its only use in our code is to keep no-attenuation looping speakers in frame always.</p>
<h4 tabindex="-1" dir="auto">SVF_HULL</h4>
<p dir="auto">This flag adjusts the servers' method of clipping movement to entities. Normally, only <code>SOLID_BSP</code> entities will use their proper clipping bounds for collision, but if this is set on a <code>SOLID_TRIGGER</code> brush entity, traces will have to collide with the actual BSP tree of the trigger instead of solely touching its bounding box.</p>
<p dir="auto">This is used in our game DLL to allow for certain triggers (like <code>trigger_gravity</code> or <code>trigger_flashlight</code>) to be activated when you are actually touching their brushes, allowing for angled triggers to finally exist.</p>
<h2 tabindex="-1" dir="auto">entity_state_t</h2>
<h3 tabindex="-1" dir="auto">uint32_t number</h3>
<p dir="auto">Number was changed to <code>uint32_t</code> (from <code>int32_t</code>) to better represent its use and to only have to catch out of bounds in one direction.</p>
<h3 tabindex="-1" dir="auto">int32_t skinnum</h3>
<p dir="auto">Skinnum now packs a bit more data into it.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// [Paril-KEX] player s.skinnum's encode additional data
union player_skinnum_t
{
    int32_t         skinnum;
    struct {
        uint8_t     client_num; // client index
        uint8_t     vwep_index; // vwep index
        int8_t      viewheight; // viewheight
        uint8_t     team_index : 4; // team #; note that teams are 1-indexed here, with 0 meaning no team
                                    // (spectators in CTF would be 0, for instance)
        uint8_t     poi_icon : 4;   // poi icon; 0 default friendly, 1 dead, others unused
    };
};"><pre><span><span>//</span> [Paril-KEX] player s.skinnum's encode additional data</span>
<span>union</span> <span>player_skinnum_t</span>
{
    <span>int32_t</span>         skinnum;
    <span>struct</span> {
        <span>uint8_t</span>     client_num; <span><span>//</span> client index</span>
        <span>uint8_t</span>     vwep_index; <span><span>//</span> vwep index</span>
        <span>int8_t</span>      viewheight; <span><span>//</span> viewheight</span>
        <span>uint8_t</span>     team_index : <span>4</span>; <span><span>//</span> team #; note that teams are 1-indexed here, with 0 meaning no team</span>
                                    <span><span>//</span> (spectators in CTF would be 0, for instance)</span>
        <span>uint8_t</span>     poi_icon : <span>4</span>;   <span><span>//</span> poi icon; 0 default friendly, 1 dead, others unused</span>
    };
};</pre></div>
<h3 tabindex="-1" dir="auto">effects_t effects</h3>
<p dir="auto">The type <code>effects_t</code> was changed from <code>uint32_t</code> to <code>uint64_t</code> since we have way more effects to express.</p>
<h4 tabindex="-1" dir="auto">EF_BOB (bit 4)</h4>
<p dir="auto">Bit was unused in Quake II. This was repurposed into a weapon bobbing effect, similar to Quake III.</p>
<h4 tabindex="-1" dir="auto">EF_POWERSCREEN (bit 9)</h4>
<p dir="auto">This effect uses a different model that is scaled to the monster's size now.</p>
<h4 tabindex="-1" dir="auto">EF_DUALFIRE (bit 32)</h4>
<p dir="auto">This bit is used for a special effect, similar to <code>EF_QUAD</code>, but for Dualfire Damage.</p>
<h4 tabindex="-1" dir="auto">EF_HOLOGRAM (bit 33)</h4>
<p dir="auto">This bit is used for the N64 hologram effect; it adds a spinning ball of green particles around the object.</p>
<h4 tabindex="-1" dir="auto">EF_FLASHLIGHT (bit 34)</h4>
<p dir="auto">This bit marks a player entity as having a flashlight enabled. The effect itself is rendered separately by the client.</p>
<h4 tabindex="-1" dir="auto">EF_BARREL_EXPLODING (bit 35)</h4>
<p dir="auto">This effect is used before an explobox explodes; it emits steam particles from the barrel, as if it is experiencing a decompression event.</p>
<h4 tabindex="-1" dir="auto">EF_TELEPORTER2 (bit 36)</h4>
<p dir="auto">This effect is used for the teleporter FX in the N64.</p>
<h4 tabindex="-1" dir="auto">EF_GRENADE_LIGHT (bit 37)</h4>
<p dir="auto">This effect creates a small light on monster grenades, to make them slightly easier to track visually.</p>
<h3 tabindex="-1" dir="auto">EF_FIREBALL (EF_ROCKET | EF_GIB)</h3>
<p dir="auto">This mutually-exclusive bit combo did nothing in the original game, since these special trails could only render one or the other. In the rerelease, it will render a fireball trail that begins yellow and large, tapering off into an orange trail, to mimick the effect on N64.</p>
<h3 tabindex="-1" dir="auto">renderfx_t renderfx</h3>
<h4 tabindex="-1" dir="auto">RF_NO_ORIGIN_LERP (bit 6)</h4>
<p dir="auto">This effect had a confusing name originally. Its name now reflects what it does: it disables origin interpolation.</p>
<h4 tabindex="-1" dir="auto">RF_BEAM (bit 7)</h4>
<p dir="auto">You can now create custom segmented beams by setting a non-one modelindex on beams.</p>
<h4 tabindex="-1" dir="auto">RF_CUSTOMSKIN (bit 8)</h4>
<p dir="auto">This effect was unused originally. It is now implemented and works as intended: specifying a <code>skinnum</code> will change the skin on the model to the skin specified in <code>CS_IMAGES + skinnum</code>. For <code>RF_FLARE</code>, <code>frame</code> must be used instead however, as <code>skinnum</code> is used for color data.</p>
<h4 tabindex="-1" dir="auto">RF_NOSHADOW (bit 13)</h4>
<p dir="auto">This effect was client-only originally.</p>
<h4 tabindex="-1" dir="auto">RF_CASTSHADOW (bit 14)</h4>
<p dir="auto">This effect marks an entity that casts light in the world; it is only used by <code>dynamic_light</code> (or dynamic <code>light</code> entities), and should not be used otherwise.</p>
<h4 tabindex="-1" dir="auto">RF_SHELL_LITE_GREEN (bit 19)</h4>
<p dir="auto">This is the equivalent shell color for <code>EF_DUALFIRE</code>.</p>
<h4 tabindex="-1" dir="auto">RF_CUSTOM_LIGHT (bit 20)</h4>
<p dir="auto">This flag creates a custom dynamic light at the position of the object. Its used in the N64 campaign, as it has custom light entities (<code>target_light</code>). <code>s.frame</code> is the light's radius, and <code>s.skinnum</code> is the light's current color (packed RGB).</p>
<h4 tabindex="-1" dir="auto">RF_FLARE (bit 21)</h4>
<p dir="auto">This flag marks an entity as being rendered with a flare instead of the usual entity rendering. Flares overload some fields:</p>
<ul dir="auto">
<li><code>s.renderfx &amp; RF_SHELL_RED</code> causes the flare to have an outer red rim.</li>
<li><code>s.renderfx &amp; RF_SHELL_GREEN</code> causes the flare to have an outer green rim.</li>
<li><code>s.renderfx &amp; RF_SHELL_BLUE</code> causes the flare to have an outer blue rim.</li>
<li><code>s.renderfx &amp; RF_FLARE_LOCK_ANGLE</code> causes the flare to not rotate towards the viewer.</li>
<li><code>s.renderfx &amp; RF_CUSTOMSKIN</code> causes the flare to use the custom image index in <code>s.frame</code>.</li>
<li><code>s.modelindex2</code> is the start distance of fading the flare out.</li>
<li><code>s.modelindex3</code> is the end distance of fading the flare out.</li>
<li><code>s.skinnum</code> is the RGBA of the flare.</li>
</ul>
<h4 tabindex="-1" dir="auto">RF_OLD_FRAME_LERP (bit 22)</h4>
<p dir="auto">This flag signals that <code>s.old_frame</code> should be used for the next frame and respected by the client. This can be used for custom frame interpolation; its use in this engine is specific to fixing interpolation bugs on certain monster animations.</p>
<h4 tabindex="-1" dir="auto">RF_DOT_SHADOW (bit 23)</h4>
<p dir="auto">Draw a blob shadow underneath the entity.</p>
<h4 tabindex="-1" dir="auto">RF_LOW_PRIORITY (bit 24)</h4>
<p dir="auto">This flag marks an entity as low priority; if the renderer runs out of entity slots, these entities will be eligible for replacement. For instance, a monster is more important than a gib, so gibs are marked low priority so they can be replaced by a monster if the limit is reached.</p>
<h4 tabindex="-1" dir="auto">RF_NO_LOD (bit 25)</h4>
<p dir="auto">The original MD2 models will be used for LOD. Setting this bit prevents this behavior.</p>
<h4 tabindex="-1" dir="auto">RF_NO_STEREO (bit 2)</h4>
<p dir="auto">This is an overloaded flag that only applies to non-rendered entities that contain sounds. If set, stereo panning is disabled on this entity.</p>
<h4 tabindex="-1" dir="auto">RF_STAIR_STEP (bit 26)</h4>
<p dir="auto">The tick rate increase caused a bit of a visual bug with monsters and players: they now stepped up steps within 0.025 seconds instead of 0.1, causing jarring hitching. To fix this, entities set this flag when they detect they have stepped up a stair, and the client will interpolate their height difference over 0.1 seconds.</p>
<h4 tabindex="-1" dir="auto">RF_BEAM_LIGHTNING (RF_BEAM | RF_GLOW)</h4>
<p dir="auto">This mutually-exclusive bit combo causes a laser to become a lightning bolt, for N64 support.</p>
<h3 tabindex="-1" dir="auto">uint32_t solid</h3>
<p dir="auto">This was changed from <code>int32_t</code> to <code>uint32_t</code>, and now packs more data into it to better represent bounding boxes to clients.</p>
<p dir="auto">For backwards compatibility, 31 is still the magic value used for BSP entities. The actual packed data, however, is now as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="union solid_packed_t
{
    struct {
        uint8_t x;
        uint8_t y;
        uint8_t zd; // always negative
        uint8_t zu; // encoded as + 32
    } p;

    uint32_t u;
};

// packing:

packed.p.x = ent->maxs[0];
packed.p.y = ent->maxs[1];
packed.p.zd = -ent->mins[2];
packed.p.zu = ent->maxs[2] + 32;

// unpacking:
packed.u = state->solid;
ent->mins[0] = -packed.p.x;  ent->maxs[0] = packed.p.x;
ent->mins[1] = -packed.p.y;  ent->maxs[1] = packed.p.y;
ent->mins[2] = -packed.p.zd; ent->maxs[2] = packed.p.zu - 32;"><pre><span>union</span> <span>solid_packed_t</span>
{
    <span>struct</span> {
        <span>uint8_t</span> x;
        <span>uint8_t</span> y;
        <span>uint8_t</span> zd; <span><span>//</span> always negative</span>
        <span>uint8_t</span> zu; <span><span>//</span> encoded as + 32</span>
    } p;

    <span>uint32_t</span> u;
};

<span><span>//</span> packing:</span>

packed.p.x = ent-&gt;maxs[<span>0</span>];
packed.p.y = ent-&gt;maxs[<span>1</span>];
packed.p.zd = -ent-&gt;mins[<span>2</span>];
packed.p.zu = ent-&gt;maxs[<span>2</span>] + <span>32</span>;

<span><span>//</span> unpacking:</span>
packed.u = state-&gt;solid;
ent-&gt;mins[<span>0</span>] = -packed.p.x;  ent-&gt;maxs[<span>0</span>] = packed.p.x;
ent-&gt;mins[<span>1</span>] = -packed.p.y;  ent-&gt;maxs[<span>1</span>] = packed.p.y;
ent-&gt;mins[<span>2</span>] = -packed.p.zd; ent-&gt;maxs[<span>2</span>] = packed.p.zu - <span>32</span>;</pre></div>
<p dir="auto">This is similar to Quake III Arena, and essentially allows any integral bbox to make it to the clients unchanged.</p>
<h3 tabindex="-1" dir="auto">entity_event_t event</h3>
<p dir="auto">Two new events were added:</p>
<h4 tabindex="-1" dir="auto">EV_OTHER_FOOTSTEP (8)</h4>
<p dir="auto">Allows non-players to send footsteps. They have idle attenuation, whereas regular footsteps have normal attenuation.</p>
<h4 tabindex="-1" dir="auto">EV_LADDER_STEP (9)</h4>
<p dir="auto">Ladder climbing 'footstep' event.</p>
<h3 tabindex="-1" dir="auto">float alpha</h3>
<p dir="auto">This value allows you to specify exact transparency values for entities. For backwards compatibility, setting it to zero should be equivalent to an unchanged value, but any non-zero value should be respected as changed.</p>
<h3 tabindex="-1" dir="auto">float scale</h3>
<p dir="auto">This value allows you to scale an entity by the given amount. For backwards compatibility, setting it to zero should be equivalent to an unchanged value, but any non-zero value should be respected as changed.</p>
<h3 tabindex="-1" dir="auto">uint8_t instance_bits</h3>
<p dir="auto">This value is not meant to be set directly by the game code, but will have non-zero bits set for split-screen players that cannot see this entity.</p>
<h3 tabindex="-1" dir="auto">float loop_volume / loop_attenuation</h3>
<p dir="auto">Looping noises can now have volume and attenuation explicitly specified. For both, a value of zero indicates default/unchanged, for backwards compatibility. For <code>loop_attenuation</code>, a value of <code>-1</code> indicates full level audio (like <code>ATTN_NONE</code>).</p>
<h3 tabindex="-1" dir="auto">int32_t owner</h3>
<p dir="auto">An entity's owner is now networked, allowing for it to ignore collision properly.</p>
<h3 tabindex="-1" dir="auto">int32_t old_frame</h3>
<p dir="auto">Only sent when <code>renderfx &amp; RF_OLD_FRAME_LERP</code> - indicates that this frame is the frame to lerp from.</p>
<h2 tabindex="-1" dir="auto">Import/Exports</h2>
<h2 tabindex="-1" dir="auto">Game Import</h2>
<h3 tabindex="-1" dir="auto">(read-only) tick_rate / frame_time_s / frame_time_ms</h3>
<p dir="auto">This holds the server's tick variables. They will be set at the start of the server, before <a href="#preinit">PreInit</a>.
<code>tick_rate</code> stores the tick rate, in hz.
<code>frame_time_s</code> is the time a game frame will take in seconds.
<code>frame_time_ms</code> is the time a game frame will take in ms.</p>
<p dir="auto">These are provided pre-calculated for convenience.</p>
<h3 tabindex="-1" dir="auto">Broadcast_Print</h3>
<p dir="auto">This function writes <code>message</code> with the print type of <code>printlevel</code> to all players. See <a href="#print-adjustments">Print Adjustments</a>. This is kept for compatibility purposes, <a href="#loc_print">Loc_Print</a> replaces it.</p>
<h3 tabindex="-1" dir="auto">Com_Print</h3>
<p dir="auto">This function writes <code>message</code> to the server. See <a href="#print-adjustments">Print Adjustments</a>.</p>
<h3 tabindex="-1" dir="auto">Client_Print</h3>
<p dir="auto">This function writes out <code>message</code> with the print type of <code>printlevel</code> to the specified <code>ent</code> player. See <a href="#print-adjustments">Print Adjustments</a>. This is kept for compatibility purposes, <a href="#loc_print">Loc_Print</a> replaces it.</p>
<h3 tabindex="-1" dir="auto">Center_Print</h3>
<p dir="auto">This function writes <code>message</code> to the specified <code>ent</code> player in the center of their screen. See <a href="#print-adjustments">Print Adjustments</a>. This is kept for compatibility purposes, <a href="#loc_print">Loc_Print</a> replaces it.</p>
<h3 tabindex="-1" dir="auto">sound / positioned_sound</h3>
<p dir="auto">The <code>channel</code> enum has a single new flag:</p>
<h4 tabindex="-1" dir="auto">CHAN_FORCE_POS (bit 5)</h4>
<p dir="auto">If set (and an origin is <strong>not</strong> supplied), the entity's origin will be forced to be used as the origin point of the sound even if there is a better position available.</p>
<h3 tabindex="-1" dir="auto">local_sound</h3>
<p dir="auto">This function was introduced to deal with some split-screen issues that popped up. It's designed to mimick <code>localsound</code> of QuakeC; it will directly send a sound packet to the specified player, using a <code>dupe_key</code> if supplied (see <a href="#unicast">unicast</a>).</p>
<p dir="auto">See <a href="#sound--positioned_sound">sound</a> for info about the channels.</p>
<h3 tabindex="-1" dir="auto">get_configstring</h3>
<p dir="auto">This function fetches a configstring from the servers' current configstring data.</p>
<h3 tabindex="-1" dir="auto">Com_Error</h3>
<p dir="auto">See <a href="#print-adjustments">Print Adjustments</a>.</p>
<h3 tabindex="-1" dir="auto">clip</h3>
<p dir="auto">This is a new function designed to fit a specific purpose: it will test if the box specified by <code>mins</code> &amp; <code>maxs</code>, moved from <code>start</code> to <code>end</code>, will clip against the specified <code>entity</code> with the given <code>contentmask</code>. As an example, you could use this to detect if an entity is actually intersecting a brush in a trigger instead of just being within its bounding box.</p>
<h3 tabindex="-1" dir="auto">inPVS / inPHS</h3>
<p dir="auto">This function now accepts a boolean, <code>portals</code>, which changes whether or not it should ignore areaportals.</p>
<h3 tabindex="-1" dir="auto">BoxEdicts</h3>
<p dir="auto">This function was modified with a simple filtering callback, greatly extending its purpose and removing some limitations that would occur with previous uses. The filter callback is called for every entity discovered, and you can choose to include or skip entities that it finds, or even completely abort the search. In addition, you can now call the function with a 0 <code>maxcount</code>, and the function will still continue to filter and find entities, reporting the final count. To match the old behavior, if a non-zero <code>maxcount</code> is supplied, the return count will cap out at <code>maxcount</code>.</p>
<p dir="auto">Note that it is disallowed to modify world links (linkentity/unlinkentity, etc) in a filter callback, it can only be used for filtering.</p>
<h3 tabindex="-1" dir="auto">unicast</h3>
<p dir="auto">The <code>dupe_key</code> parameter is new, and is to solve a very peculiar issue with split screen players. When unicast is used to spawn effects or sounds, it may not be desirable to replay the same effect on multiple split screens, since split screen players are all the same client and share views. For example, if you do a unicast for a <code>TE_BLASTER</code> somewhere in the world for every player, for a split screen client with 4 players, that effect will play 4 times - even though all four players are viewing the same world. The game DLL also has no knowledge or understanding of split screen, so there's no way for the game to work around it.</p>
<p dir="auto">Instead of having the game need to know this kind of implementation detail and prevent double-sending, for effects that are going to potentially be sent to multiple players that <em>may</em> be on a split screen, you can specify a dupe key value. This value, when non-zero, will be marked as "already sent" for that client, and won't be sent again for the next packet if it was already tripped. The game DLL provides the <code>GetUnicastKey</code> global which will give you a rolling value to directly pass into unicast or local_sound.</p>
<h3 tabindex="-1" dir="auto">WriteFloat</h3>
<p dir="auto">Implemented; this was stubbed out of the old code.</p>
<h3 tabindex="-1" dir="auto">WritePosition</h3>
<p dir="auto">Now sends full float positions.</p>
<h3 tabindex="-1" dir="auto">WriteDir / WriteAngle</h3>
<p dir="auto">Unchanged - WriteAngle is for compressed angles, when high precision is not necessary.</p>
<h3 tabindex="-1" dir="auto">WriteEntity</h3>
<p dir="auto">New function to write an entity, to make it easier to write them without needing to WriteShort directly.</p>
<h3 tabindex="-1" dir="auto">GetExtension</h3>
<p dir="auto">See <a href="#extensions">Extensions</a>.</p>
<h3 tabindex="-1" dir="auto">Bot_RegisterEdict</h3>
<p dir="auto">Informs the bot subsystem that an entity needs to be registered.</p>
<h3 tabindex="-1" dir="auto">Bot_UnRegisterEdict</h3>
<p dir="auto">Informs the bot subsystem that an entity needs to be unregistered.</p>
<h3 tabindex="-1" dir="auto">Bot_MoveToPoint</h3>
<p dir="auto">Forces a bot to move to the specified point.</p>
<h3 tabindex="-1" dir="auto">Bot_FollowActor</h3>
<p dir="auto">Forces a bot to follow the specified actor.</p>
<h3 tabindex="-1" dir="auto">GetPathToGoal</h3>
<p dir="auto">The main pathfinding function; with the given pathfinding <code>request</code>, you'll be given <code>info</code> about the operation, the path, etc.</p>
<h3 tabindex="-1" dir="auto">Loc_Print</h3>
<p dir="auto">The new primary entry point for printing. This function replaces all of the others (except Com_Print).
For basic usage, it can be called on an entity (or nullptr for broadcasting) with the correct <code>level</code>, with the message to send in <code>base</code>, and nullptr <code>args</code> along with 0 <code>num_args</code>. For actual localized messages, however, you can send additional arguments via the <code>args</code>/<code>num_args</code> parameters which are sent to the client for further processing.</p>
<p dir="auto">In addition to localization, <code>level</code> now has new values and bit flags.</p>
<h4 tabindex="-1" dir="auto">PRINT_TYPEWRITER (4)</h4>
<p dir="auto">Causes the message to be printed out one at a time, like a typewriter. Used for objectives, similar to the N64 version.</p>
<h4 tabindex="-1" dir="auto">PRINT_CENTER (5)</h4>
<p dir="auto">An instant centerprint, like the legacy centerprints.</p>
<h4 tabindex="-1" dir="auto">PRINT_TTS (6)</h4>
<p dir="auto">Identical to <code>PRINT_HIGH</code> in importance, but additionally causes text to speech narration to activate if enabled on the client.</p>
<h4 tabindex="-1" dir="auto">PRINT_BROADCAST (bit 3)</h4>
<p dir="auto">Message will be sent to all players.</p>
<h4 tabindex="-1" dir="auto">PRINT_NO_NOTIFY (bit 4)</h4>
<p dir="auto">Message will not be sent to the notify system.</p>
<h3 tabindex="-1" dir="auto">Draw_Line / Draw_Point / Draw_Circle / Draw_Bounds / Draw_Sphere / Draw_OrientedWorldText / Draw_StaticWorldText / Draw_Cylinder / Draw_Ray</h3>
<p dir="auto">These functions are debugging aids that only render on the server.</p>
<h3 tabindex="-1" dir="auto">ReportMatchDetails_Multicast</h3>
<p dir="auto">This function is solely for platforms that need match result data.</p>
<h3 tabindex="-1" dir="auto">ServerFrame</h3>
<p dir="auto">Returns the server's frame number.</p>
<h3 tabindex="-1" dir="auto">SendToClipBoard</h3>
<p dir="auto">Copy data to the server's clipboard, useful for debugging.</p>
<h3 tabindex="-1" dir="auto">Info_ValueForKey / Info_RemoveKey / Info_SetValueForKey</h3>
<p dir="auto">See <a href="#info-keys">Info Keys</a>.</p>
<h2 tabindex="-1" dir="auto">Save Games</h2>
<p dir="auto">One of the major changes to this release of Quake II is the save system. Instead of storing pointer offsets and copies of memory, the level &amp; game data is written to UTF-8 JSON. This makes save data much easier to navigate for a human &amp; developer that wants to look into a bug, while also being quick and efficient for storage.</p>
<p dir="auto">The save system, as a result, no longer interfaces with the filesystem at all. Other mods are not required to use JSON, any text format will work as the server and client do not interact with the data.</p>
<h2 tabindex="-1" dir="auto">Game Export</h2>
<h3 tabindex="-1" dir="auto">(read-only) apiversion</h3>
<p dir="auto">The version # reported by the server.</p>
<h3 tabindex="-1" dir="auto">PreInit</h3>
<p dir="auto">This function is called before InitGame, and should be where you initialize your mod's latched cvars. This can be used to fix any conflicting latched cvars, which will be "locked in" after this is called.</p>
<h3 tabindex="-1" dir="auto">SpawnEntities</h3>
<p dir="auto">All three parameters are now properly marked const.</p>
<h3 tabindex="-1" dir="auto">WriteGameJson</h3>
<p dir="auto">See <a href="#save-games">Save Games</a>.</p>
<h3 tabindex="-1" dir="auto">ReadGameJson</h3>
<p dir="auto">See <a href="#save-games">Save Games</a>.</p>
<h3 tabindex="-1" dir="auto">WriteLevelJson</h3>
<p dir="auto">This function is now informed whether the level write is from a level transition or a manual save.
See <a href="#save-games">Save Games</a>.</p>
<h3 tabindex="-1" dir="auto">ReadLevelJson</h3>
<p dir="auto">See <a href="#save-games">Save Games</a>.</p>
<h3 tabindex="-1" dir="auto">CanSave</h3>
<p dir="auto">This new export now dictates whether the game is saveable or not.</p>
<h3 tabindex="-1" dir="auto">ClientChooseSlot</h3>
<p dir="auto">ClientChooseSlot is intended to take in a bunch of information about the client that is connecting, and choose which <code>edict_t</code> entity this player should occupy. It is used in the rerelease to reorder players consistently throughout coop games, and ensure that everybody always gets the correct slot.</p>
<p dir="auto">Callers are given the player's <code>userinfo</code> and <code>social_id</code> (the social ID is a unique value per player on certain platforms), which you can use to find the correct slot from the current saved client data. You're also told whether the client <code>isBot</code>, which should always use non-saved available slots first. The <code>ignore</code> field will give you a list of slots up to <code>num_ignore</code> entities that are already occupied or were reported as such, so they can be safely skipped over. Finally, the <code>cinematic</code> parameters will tell you whether the loaded map is a video, which in most cases reordering will not be necessary.</p>
<h3 tabindex="-1" dir="auto">ClientConnect</h3>
<p dir="auto">The function is now given the <code>social_id</code> and <code>isBot</code> state of the connecting client.</p>
<h3 tabindex="-1" dir="auto">RunFrame</h3>
<p dir="auto">This function now receives a boolean to tell whether the call is from the main game loop, or from some other source (the game is settling, or running frames to advance level transitions). If the latter is occurring, you can use this boolean to speed up level transitions by skipping logic that is not necessary but is CPU-intensive, such as enemies searching for players to attack.</p>
<h3 tabindex="-1" dir="auto">PrepFrame</h3>
<p dir="auto">This function used to be in the server, but is now controlled by the game DLL. It's ran after the game has execute a frame &amp; has sent the packet data over to all players. Things like hit markers and one-shot events are cleared in here.</p>
<h3 tabindex="-1" dir="auto">edict_size / num_edicts / max_edicts</h3>
<p dir="auto">These were changed to size_t and uint32_t/uint32_t respectively, to better represent their use.</p>
<h3 tabindex="-1" dir="auto">server_flags</h3>
<p dir="auto">This is an integer shared between server and game, which stores bits for special states that the server cares about.</p>
<h3 tabindex="-1" dir="auto">Pmove</h3>
<p dir="auto">See <a href="#pmove">Pmove</a>.</p>
<h3 tabindex="-1" dir="auto">GetExtension</h3>
<p dir="auto">See <a href="#extensions">Extensions</a>.</p>
<h3 tabindex="-1" dir="auto">Bot_SetWeapon</h3>
<p dir="auto">Called by the bot subsystem to switch weapons.</p>
<h3 tabindex="-1" dir="auto">Bot_TriggerEdict</h3>
<p dir="auto">Called by the bot subsystem to trigger an entity.</p>
<h3 tabindex="-1" dir="auto">Bot_UseItem</h3>
<p dir="auto">Called by the bot subsystem to use an item.</p>
<h3 tabindex="-1" dir="auto">Bot_GetItemID</h3>
<p dir="auto">Fetch an item ID by a classname; for the bot subsystem.</p>
<h3 tabindex="-1" dir="auto">Entity_IsVisibleToPlayer</h3>
<p dir="auto">This function is for item instancing; the rerelease of Quake II supports instanced items, which will display only for the players who haven't picked it up yet. For online players, this simply removes the item if you've gotten it, but for split screen players it will show a ghost where the entity was on players that have already picked it up.</p>
<h3 tabindex="-1" dir="auto">GetShadowLightData</h3>
<p dir="auto">This function fetches data for the given shadow light for building client frames.</p>
<h2 tabindex="-1" dir="auto">Player State</h2>
<p dir="auto">In the original client, player state was often accessed directly to perform various tasks or render things. Much of this has been moved into the cgame module to allow increased customization.</p>
<h2 tabindex="-1" dir="auto">Client Game Import</h2>
<h3 tabindex="-1" dir="auto">(read-only) tick_rate</h3>
<h3 tabindex="-1" dir="auto">(read-only) frame_time_s</h3>
<h3 tabindex="-1" dir="auto">(read-only) frame_time_ms</h3>
<p dir="auto">This holds the server's tick variables. They will be set at the start of the client, before Init.
<code>tick_rate</code> stores the tick rate, in hz.
<code>frame_time_s</code> is the time a game frame will take in seconds.
<code>frame_time_ms</code> is the time a game frame will take in ms.</p>
<p dir="auto">These are provided pre-calculated for convenience.</p>
<h3 tabindex="-1" dir="auto">Com_Print</h3>
<p dir="auto">Print a debug message to the client.</p>
<h3 tabindex="-1" dir="auto">get_configstring</h3>
<p dir="auto">Fetch the given configstring data from the client.</p>
<h3 tabindex="-1" dir="auto">Com_Error</h3>
<p dir="auto">Abort error for client.</p>
<h3 tabindex="-1" dir="auto">TagMalloc / TagFree / FreeTags</h3>
<p dir="auto">Same as server.</p>
<h3 tabindex="-1" dir="auto">cvar / cvar_set / cvar_forceset</h3>
<p dir="auto">Same as server.</p>
<h3 tabindex="-1" dir="auto">AddCommandString</h3>
<p dir="auto">Push command(s) into the command buffer on the client side.</p>
<h3 tabindex="-1" dir="auto">GetExtension</h3>
<p dir="auto">See <a href="#extensions">Extensions</a>.</p>
<h3 tabindex="-1" dir="auto">CL_FrameValid</h3>
<p dir="auto">Returns true if the current frame being rendered is valid.</p>
<h3 tabindex="-1" dir="auto">CL_FrameTime</h3>
<p dir="auto">Returns the current frame time delta.</p>
<h3 tabindex="-1" dir="auto">CL_ClientTime</h3>
<p dir="auto">Returns the client's current time (server-bound).</p>
<h3 tabindex="-1" dir="auto">CL_ClientRealTime</h3>
<p dir="auto">Returns the client's current real, unbound time.</p>
<h3 tabindex="-1" dir="auto">CL_ServerFrame</h3>
<p dir="auto">Returns the client's server frame.</p>
<h3 tabindex="-1" dir="auto">CL_ServerProtocol</h3>
<p dir="auto">Returns the client's connected server protocol.</p>
<h3 tabindex="-1" dir="auto">CL_GetClientName</h3>
<p dir="auto">Returns a UTF-8 string containing the givern player's name.</p>
<h3 tabindex="-1" dir="auto">CL_GetClientPic</h3>
<p dir="auto">Returns a string containing the given player's icon.</p>
<h3 tabindex="-1" dir="auto">CL_GetClientDogtag</h3>
<p dir="auto">Returns a string containing the given player's dogtag.</p>
<h3 tabindex="-1" dir="auto">CL_GetKeyBinding</h3>
<p dir="auto">Returns a key binding for the given key. Returns an empty string if the key is unbound.</p>
<h3 tabindex="-1" dir="auto">Draw_RegisterPic</h3>
<p dir="auto">Precache the given image.</p>
<h3 tabindex="-1" dir="auto">Draw_GetPicSize</h3>
<p dir="auto">Returns the size of the given image.</p>
<h3 tabindex="-1" dir="auto">SCR_DrawChar</h3>
<p dir="auto">Draw the given conchars char at the specified position. A <code>shadow</code> parameter has been added to draw a drop shadow.</p>
<h3 tabindex="-1" dir="auto">SCR_DrawPic</h3>
<p dir="auto">Draw the given pic at the specified position.</p>
<h3 tabindex="-1" dir="auto">SCR_DrawColorPic</h3>
<p dir="auto">Draw the given pic at the specified location, with the specified color.</p>
<h3 tabindex="-1" dir="auto">SCR_SetAltTypeface</h3>
<p dir="auto">Change whether the alternate (accessibility) typeface is in use or not.</p>
<h3 tabindex="-1" dir="auto">SCR_DrawFontString</h3>
<p dir="auto">Draw a string to the screen, using the Kex KFONT which includes non-latin characters.</p>
<h3 tabindex="-1" dir="auto">SCR_MeasureFontString</h3>
<p dir="auto">Measure the size of the string as it would be rendered.</p>
<h3 tabindex="-1" dir="auto">SCR_FontLineHeight</h3>
<p dir="auto">Returns the line height of the font.</p>
<h3 tabindex="-1" dir="auto">CL_GetTextInput</h3>
<p dir="auto">Returns a pointer to the current text input, and whether this input is for team say or not.</p>
<h3 tabindex="-1" dir="auto">CL_GetWarnAmmoCount</h3>
<p dir="auto">For the given weapon ID, get the amount that is considered to be low ammo.</p>
<h3 tabindex="-1" dir="auto">Localize</h3>
<p dir="auto">Localize the given string and arguments to an output buffer.</p>
<h3 tabindex="-1" dir="auto">SCR_DrawBind</h3>
<p dir="auto">Draw a user bind to the screen, returns the Y offset from rendering.</p>
<h3 tabindex="-1" dir="auto">CL_InAutoDemoLoop</h3>
<p dir="auto">Returns true if the engine is running the attract demo loop.</p>
<h2 tabindex="-1" dir="auto">Client Game Export</h2>
<h3 tabindex="-1" dir="auto">(read-only) apiversion</h3>
<p dir="auto">API version.</p>
<h3 tabindex="-1" dir="auto">Init / Shutdown</h3>
<p dir="auto">Lifecycle functions for the client game. Note that the cgame does not control UI, so the cgame only exists when you are connected and in-game.</p>
<h3 tabindex="-1" dir="auto">DrawHUD</h3>
<p dir="auto">This function is called by the client when their HUD needs to be rendered.</p>
<ul dir="auto">
<li><code>isplit</code> contains the split screen index of the player.</li>
<li><code>data</code> contains a pointer to some transient information from the server. This includes currently active layout, and the player's active inventory when the inventory is open.</li>
<li><code>hud_vrect</code> contains the unpadded rectangle of the HUD being rendered.</li>
<li><code>hud_safe</code> contains the size of the safe area. Only x and y are set, w and h are unused.</li>
<li><code>scale</code> is the integral scale of the HUD being rendered.</li>
<li><code>playernum</code> is the player's client index.</li>
<li><code>ps</code> is a pointer to the player's current player state.</li>
</ul>
<h3 tabindex="-1" dir="auto">TouchPics</h3>
<p dir="auto">Function called for precaching images used by the HUD.</p>
<h3 tabindex="-1" dir="auto">LayoutFlags</h3>
<p dir="auto">For the given player state, return the <code>layout_flags_t</code> that would match it.</p>
<h3 tabindex="-1" dir="auto">GetActiveWeaponWheelWeapon / GetOwnedWeaponWheelWeapons / GetWeaponWheelAmmoCount / GetPowerupWheelCount</h3>
<p dir="auto">The weapon wheel is in the client, but uses these callbacks to fetch data from <code>player_state_t</code>.</p>
<h3 tabindex="-1" dir="auto">GetHitMarkerDamage</h3>
<p dir="auto">Returns how much damage was done for this player.</p>
<h3 tabindex="-1" dir="auto">Pmove</h3>
<p dir="auto">See <a href="#pmove">Pmove</a>.</p>
<h3 tabindex="-1" dir="auto">ParseConfigString</h3>
<p dir="auto">When a configstring is received, the cgame is also notified of changes. The cgame module can react to configstring updates here.</p>
<h3 tabindex="-1" dir="auto">ParseCenterPrint</h3>
<p dir="auto">When a centerprint-like message is received by the client, it is sent to the cgame via this function.</p>
<ul dir="auto">
<li><code>isplit</code> is the split screen player it was sent to.</li>
<li><code>instant</code> is true if the message is a centerprint that is drawn without the typewriter effect.</li>
</ul>
<h3 tabindex="-1" dir="auto">ClearNotify</h3>
<p dir="auto">The client will call this when the notification area should be cleared.</p>
<h3 tabindex="-1" dir="auto">ClearCenterprint</h3>
<p dir="auto">The client will call this when centerprints should be cleared.</p>
<h3 tabindex="-1" dir="auto">NotifyMessage</h3>
<p dir="auto">When a notify message is received, the client will send it to this function.</p>
<ul dir="auto">
<li><code>isplit</code> is the split screen player it was sent to.</li>
<li><code>is_chat</code> is true if it was a chat-like message.</li>
</ul>
<h3 tabindex="-1" dir="auto">GetMonsterFlashOffset</h3>
<p dir="auto">To simplify the server to client muzzleflash communication, the cgame now exports muzzleflash origins via this function.</p>
<h3 tabindex="-1" dir="auto">GetExtension</h3>
<p dir="auto">See <a href="#extensions">Extensions</a>.</p>
<h2 tabindex="-1" dir="auto">Quake II server protocol - version 2023</h2>
<p dir="auto">The Quake II rerelease features an updated server protocol. Most of the messages are backwards compatible, but some needed adjustments to work with new or changed features, or raised limits.</p>
<p dir="auto">This document will only outline the changes since the original release, rather than the whole protocol.</p>
<h2 tabindex="-1" dir="auto">(out of band, client &lt;-&gt; server) challenges</h2>
<p dir="auto">The out of band challenges have been removed.</p>
<h2 tabindex="-1" dir="auto">(out of band, client -&gt; server) connect</h2>
<p dir="auto">The <code>connect</code> message is similar to the original, but has redundant information removed. Port and challenge are handled at a lower level, so that information is not included. The <code>connect</code> message is in the following format:</p>
<p dir="auto"><code>connect {protocol} {num split} {socials...} {userinfo...}</code></p>
<ul dir="auto">
<li><code>protocol</code> is 2023</li>
<li><code>num split</code> is the number of split screen players</li>
<li><code>socials</code> is <code>num split</code> number of arguments containing each players' social identifiers</li>
<li><code>userinfo</code> is the clients' userinfo string, split up by groups of 510 characters each (since command arguments have a maximum length). This can often span 2 or more arguments, since each userinfo var has a value per player. See <a href="#info-keys">Info Keys</a>.</li>
</ul>
<h2 tabindex="-1" dir="auto">(out of band, server -&gt; client) client_connect</h2>
<p dir="auto">This message is sent when the server accepts the connection. It is in the following format:</p>
<p dir="auto"><code>client_connect {protocol}</code></p>
<ul dir="auto">
<li><code>protocol</code> is 2023</li>
</ul>
<p dir="auto">The protocol version is sent mainly for backward compatibility with demos.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_muzzleflash (1)</h2>
<p dir="auto">The following enum values are now accepted.</p>
<h3 tabindex="-1" dir="auto">MZ_BFG2 (19)</h3>
<p dir="auto">Secondary muzzleflash for the BFG, sent when the BFG actually fires.</p>
<h3 tabindex="-1" dir="auto">MZ_PHALANX2 (20)</h3>
<p dir="auto">Secondary muzzleflash for the Phalanx, sent for the second projectile.</p>
<h3 tabindex="-1" dir="auto">MZ_PROX (31)</h3>
<p dir="auto">Sent when the Prox Launcher is fired.</p>
<h3 tabindex="-1" dir="auto">MZ_ETF_RIFLE_2 (32)</h3>
<p dir="auto">Sent when the other barrel of the ETF Rifle is fired.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_muzzleflash2 (2)</h2>
<h3 tabindex="-1" dir="auto">MZ2_BOSS2_MACHINEGUN_L2 / MZ2_BOSS2_MACHINEGUN_R2 (74 / 134)</h3>
<p dir="auto">These two values were just copies of L1/R1, but were repurposed to make Hyperblaster-specific sounds for the new Hornet.</p>
<p dir="auto">The following enum values are now accepted.</p>
<h3 tabindex="-1" dir="auto">MZ2_SOLDIER_RIPPER_1 - MZ2_SOLDIER_HYPERGUN_8 (211 - 226)</h3>
<p dir="auto">Muzzleflashes for the ripper &amp; blue hyperblaster guards.</p>
<h3 tabindex="-1" dir="auto">MZ2_GUARDIAN_BLASTER - MZ2_ARACHNID_RAIL_UP2 (227 - 231)</h3>
<p dir="auto">Muzzleflashes for the PSX monsters.</p>
<h3 tabindex="-1" dir="auto">MZ2_INFANTRY_MACHINEGUN_14 - MZ2_INFANTRY_MACHINEGUN_21 (232 - 239)</h3>
<p dir="auto">Muzzleflashes for the Infantry's run-attack animation.</p>
<h3 tabindex="-1" dir="auto">MZ2_GUNCMDR_CHAINGUN_1 - MZ2_GUNCMDR_GRENADE_CROUCH_3 (240 - 250)</h3>
<p dir="auto">Muzzleflashes for the Gunner Commander.</p>
<h3 tabindex="-1" dir="auto">MZ2_SOLDIER_BLASTER_9 - MZ2_SOLDIER_HYPERGUN_9 (251 - 255)</h3>
<p dir="auto">Muzzleflashes for the guards' new prone-firing animation.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_muzzleflash3 (32)</h2>
<p dir="auto">This packet was necessitated from running out of bits in svc_muzzleflash2. The only difference is the byte for <code>id</code> is a ushort.</p>
<h3 tabindex="-1" dir="auto">MZ2_GUNNER_GRENADE2_1 - MZ2_GUNNER_GRENADE2_4 (256 - 259)</h3>
<p dir="auto">Alternate firing animation for the Gunner's grenade launcher.</p>
<h3 tabindex="-1" dir="auto">MZ2_INFANTRY_MACHINEGUN_22 (260)</h3>
<p dir="auto">Alternate firing animation for the Infantry.</p>
<h3 tabindex="-1" dir="auto">MZ2_SUPERTANK_GRENADE_1 (261 - 262)</h3>
<p dir="auto">Supertank's grenade launcher.</p>
<h3 tabindex="-1" dir="auto">MZ2_HOVER_BLASTER_2 / MZ2_DAEDALUS_BLASTER_2 (263 / 264)</h3>
<p dir="auto">The Icarus and Daedalus' opposite side blaster.</p>
<h3 tabindex="-1" dir="auto">MZ2_MEDIC_HYPERBLASTER1_1 - MZ2_MEDIC_HYPERBLASTER1_12 / MZ2_MEDIC_HYPERBLASTER2_1 - MZ2_MEDIC_HYPERBLASTER2_12 (265 - 276 / 277 - 288)</h3>
<p dir="auto">The Medic and Medic Commander's Hyperblaster firing animation sweep.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_temp_entity (3)</h2>
<p dir="auto">As documented in <a href="#writeposition">WritePosition</a>, WritePos now writes full float precision, so ReadPos has to read full float.</p>
<h3 tabindex="-1" dir="auto">TE_SPLASH (10)</h3>
<p dir="auto">The "color/splash" enumeration accepts a new value:</p>
<h4 tabindex="-1" dir="auto">SPLASH_ELECTRIC (7)</h4>
<p dir="auto">A spark used exclusively in N64, which spawns blue/white particles and makes sparking noises.</p>
<p dir="auto">The following new enum values are accepted:</p>
<h3 tabindex="-1" dir="auto">TE_RAILTRAIL2 (31)</h3>
<p dir="auto">This effect was unused in Quake II, and was retooled to a lighter railgun effect used for Instagib mode.</p>
<h3 tabindex="-1" dir="auto">TE_BLUEHYPERBLASTER (56)</h3>
<p dir="auto">"Correct" version of the old buggy <code>TE_BLUEHYPERBLASTER</code>, which is now <code>TE_BLUEHYPERBLASTER_DUMMY</code>.</p>
<ul dir="auto">
<li>ReadPos</li>
<li>ReadDir</li>
</ul>
<h3 tabindex="-1" dir="auto">TE_BFG_ZAP (57)</h3>
<p dir="auto">Laser when an entity has been zapped by a BFG explosion.</p>
<ul dir="auto">
<li>ReadPos (start)</li>
<li>ReadPos (end)</li>
</ul>
<h3 tabindex="-1" dir="auto">TE_BERSERK_SLAM (58)</h3>
<p dir="auto">Large blue flash &amp; particles at impact point towards a direction.</p>
<ul dir="auto">
<li>ReadPos</li>
<li>ReadDir</li>
</ul>
<h3 tabindex="-1" dir="auto">TE_GRAPPLE_CABLE_2 (59)</h3>
<p dir="auto">The grappling hook in Quake II 3.20 used a larger message that didn't allow the cable to render like other player-derived beams.</p>
<ul dir="auto">
<li>ReadEntity</li>
<li>ReadPos (start)</li>
<li>ReadPos (end)</li>
</ul>
<h3 tabindex="-1" dir="auto">TE_POWER_SPLASH (60)</h3>
<p dir="auto">Effect sent when a power shield evaporates.</p>
<ul dir="auto">
<li>ReadEntity</li>
<li>ReadByte (1 for screen, 0 for armor)</li>
</ul>
<h3 tabindex="-1" dir="auto">TE_LIGHTNING_BEAM (61)</h3>
<p dir="auto">A lightning bolt that originates from the player, like the heat beam. Unused.</p>
<ul dir="auto">
<li>ReadEntity</li>
<li>ReadPos (start)</li>
<li>ReadPos (end)</li>
</ul>
<h3 tabindex="-1" dir="auto">TE_EXPLOSION1_NL / TE_EXPLOSION2_NL (62 / 63)</h3>
<p dir="auto">Variants of explosion that don't include any dynamic light.</p>
<ul dir="auto">
<li>ReadPos</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_sound (9)</h2>
<p dir="auto">Since <code>MAX_EDICTS</code> is now 8192, this packet required changes to support higher entity numbers. <code>MAX_SOUNDS</code> being increased to 1024 also necessitated the sound index changing from byte to ushort.</p>
<ul dir="auto">
<li>ReadByte (flags)</li>
<li>ReadShort (soundindex)</li>
<li>[if flags &amp; SND_VOLUME] ReadByte (volume)</li>
<li>[if flags &amp; SND_ATTENUATION] ReadByte (attenuation)</li>
<li>[if flags &amp; SND_OFFSET] ReadByte (offset)</li>
<li>[if flags &amp; SND_ENT]
<ul dir="auto">
<li>[if flags &amp; SND_LARGE_ENT] ReadLong (entchan)</li>
<li>[if !(flags &amp; SND_LARGE_ENT)] ReadShort (entchan)</li>
</ul>
</li>
<li>[if flags &amp; SND_POS] ReadPos (origin)</li>
</ul>
<p dir="auto"><code>entchan</code> is encoded as such:</p>
<div data-snippet-clipboard-copy-content="struct sndchan_t
{
	uint8_t		channel : 3;
	uint32_t	entity : 29;
}"><pre><code>struct sndchan_t
{
	uint8_t		channel : 3;
	uint32_t	entity : 29;
}
</code></pre></div>
<p dir="auto"><code>flags</code> contains the following bits:</p>
<ul dir="auto">
<li>SND_VOLUME (bit 0)</li>
<li>SND_ATTENUATION (bit 1)</li>
<li>SND_POS (bit 2)</li>
<li>SND_ENT (bit 3)</li>
<li>SND_OFFSET (bit 4)</li>
<li>SND_EXPLICIT_POS (bit 5)</li>
<li>SND_LARGE_ENT (bit 6)</li>
</ul>
<p dir="auto">Note that <code>SND_POS</code> is <strong>always</strong> set. This is to fix a legacy bug where sounds played on entities outside of your PVS will play at the origin instead of their real location. The client should pick the real position if the entity is in their frame, but otherwise fall back to the sound packets' position.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_print (10)</h2>
<p dir="auto">This packet now supports <code>PRINT_TYPEWRITER</code> and <code>PRINT_CENTER</code> values. See <a href="#loc_print">Loc_Print</a>.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_stufftext (11)</h2>
<p dir="auto">For security reasons, this packet will only allow commands things to be executed.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_serverdata (12)</h2>
<ul dir="auto">
<li>ReadLong (protocol)</li>
<li>ReadLong (spawncount)</li>
<li>ReadByte (0 = game, 1 = demo, 2 = server demo)</li>
<li>ReadByte (tickrate)</li>
<li>ReadString (gamedir)</li>
<li>ReadShort[N] (playernums; see below)</li>
<li>ReadString (level name)</li>
</ul>
<p dir="auto">To parse <code>playernums</code>, read the first short and check its value. If it is -2, then read an additional short, which is the number of split screen entities to follow. Read that number of shorts to get each entity number for each split screen player. Otherwise, the value returned by the initial ReadShort is the playernum of the client.</p>
<p dir="auto">The special value -1 will be used in cinematics, to indicate that the player has no entity.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_frame (20)</h2>
<ul dir="auto">
<li>ReadLong (serverframe)</li>
<li>ReadLong (deltaframe)</li>
<li>ReadByte (surpressCount)</li>
</ul>
<p dir="auto">For each player in this client's <code>numSplit</code> the following data is parsed:</p>
<ul dir="auto">
<li>ReadByte (areabits length)</li>
<li>ReadData (using above byte)</li>
<li>ReadByte (value will be <code>svc_playerinfo</code>)</li>
<li>ParsePlayerState (see <a href="#svc_playerinfo-17">svc_playerinfo</a>)</li>
</ul>
<p dir="auto">Then, back to <code>svc_frame</code> data:</p>
<ul dir="auto">
<li>client entity <code>event</code>s should all be cleared back to <code>EV_NONE</code></li>
<li>ReadByte (value will be <code>svc_packetentities</code>)</li>
<li>ParsePacketEntities (see <a href="#svc_packetentities-18">svc_packetentities</a>)</li>
</ul>
<h3 tabindex="-1" dir="auto">svc_playerinfo (17)</h3>
<h4 tabindex="-1" dir="auto">Bits</h4>
<div dir="auto" data-snippet-clipboard-copy-content="#define PS_M_TYPE           (1<<0)
#define PS_M_ORIGIN         (1<<1)
#define PS_M_VELOCITY       (1<<2)
#define PS_M_TIME           (1<<3)
#define PS_M_FLAGS          (1<<4)
#define PS_M_GRAVITY        (1<<5)
#define PS_M_DELTA_ANGLES   (1<<6)

#define PS_VIEWOFFSET       (1<<7)
#define PS_VIEWANGLES       (1<<8)
#define PS_KICKANGLES       (1<<9)
#define PS_BLEND            (1<<10)
#define PS_FOV              (1<<11)
#define PS_WEAPONINDEX      (1<<12)
#define PS_WEAPONFRAME      (1<<13)
#define PS_RDFLAGS          (1<<14)

#define PS_MOREBITS         (1<<15)

// [Paril-KEX]
#define PS_DAMAGE_BLEND     (1<<16)
#define PS_TEAM_ID          (1<<17)"><pre><span>#define</span> <span>PS_M_TYPE</span>           (1&lt;&lt;0)
<span>#define</span> <span>PS_M_ORIGIN</span>         (1&lt;&lt;1)
<span>#define</span> <span>PS_M_VELOCITY</span>       (1&lt;&lt;2)
<span>#define</span> <span>PS_M_TIME</span>           (1&lt;&lt;3)
<span>#define</span> <span>PS_M_FLAGS</span>          (1&lt;&lt;4)
<span>#define</span> <span>PS_M_GRAVITY</span>        (1&lt;&lt;5)
<span>#define</span> <span>PS_M_DELTA_ANGLES</span>   (1&lt;&lt;6)

<span>#define</span> <span>PS_VIEWOFFSET</span>       (1&lt;&lt;7)
<span>#define</span> <span>PS_VIEWANGLES</span>       (1&lt;&lt;8)
<span>#define</span> <span>PS_KICKANGLES</span>       (1&lt;&lt;9)
<span>#define</span> <span>PS_BLEND</span>            (1&lt;&lt;10)
<span>#define</span> <span>PS_FOV</span>              (1&lt;&lt;11)
<span>#define</span> <span>PS_WEAPONINDEX</span>      (1&lt;&lt;12)
<span>#define</span> <span>PS_WEAPONFRAME</span>      (1&lt;&lt;13)
<span>#define</span> <span>PS_RDFLAGS</span>          (1&lt;&lt;14)

<span>#define</span> <span>PS_MOREBITS</span>         (1&lt;&lt;15)

<span>// [Paril-KEX]</span>
<span>#define</span> <span>PS_DAMAGE_BLEND</span>     (1&lt;&lt;16)
<span>#define</span> <span>PS_TEAM_ID</span>          (1&lt;&lt;17)</pre></div>
<h4 tabindex="-1" dir="auto">Data</h4>
<ul dir="auto">
<li>ReadUShort (flags)</li>
<li>[if flags &amp; PS_MOREBITS] flags |= ReadUShort &lt;&lt; 16</li>
<li>[if flags &amp; PS_M_TYPE] ReadByte (pm_type)</li>
<li>[if flags &amp; PS_M_ORIGIN] ReadPos (pm_origin)</li>
<li>[if flags &amp; PS_M_VELOCITY] ReadPos (pm_velocity)</li>
<li>[if flags &amp; PS_M_TIME] ReadUShort (pm_time)</li>
<li>[if flags &amp; PS_M_FLAGS] ReadUShort (pm_flags)</li>
<li>[if flags &amp; PS_M_GRAVITY] ReadShort (pm_gravity)</li>
<li>[if flags &amp; PS_M_DELTA_ANGLES] ReadPos (pm_delta_angles)</li>
<li>[if flags &amp; PS_VIEWOFFSET]:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="	viewoffset_x = ReadShort() * (1.f / 16.f)
	viewoffset_y = ReadShort() * (1.f / 16.f)
	viewoffset_z = ReadShort() * (1.f / 16.f)
	viewheight = ReadChar() // note: not in protocol 2022"><pre>	viewoffset_x = ReadShort() * (<span>1</span>.f / <span>16</span>.f)
	viewoffset_y = ReadShort() * (<span>1</span>.f / <span>16</span>.f)
	viewoffset_z = ReadShort() * (<span>1</span>.f / <span>16</span>.f)
	viewheight = ReadChar() <span><span>//</span> note: not in protocol 2022</span></pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_VIEWANGLES] ReadPos (viewangles)</li>
<li>[if flags &amp; PS_KICKANGLES]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="kick_angles_x = ReadShort() / 1024.f
kick_angles_y = ReadShort() / 1024.f
kick_angles_z = ReadShort() / 1024.f"><pre>kick_angles_x = ReadShort() / <span>1024</span>.f
kick_angles_y = ReadShort() / <span>1024</span>.f
kick_angles_z = ReadShort() / <span>1024</span>.f</pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_WEAPONINDEX]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="gunindex_temp = ReadUShort()
gunskin = (gunindex_temp &amp; 0xE000) >> 13
gunindex = gunindex_temp &amp; ~0xE000"><pre>gunindex_temp = ReadUShort()
gunskin = (gunindex_temp &amp; <span>0xE000</span>) &gt;&gt; <span>13</span>
gunindex = gunindex_temp &amp; ~<span>0xE000</span></pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_WEAPONFRAME]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="#define GUNBIT_OFFSET_X (1<<0)
#define GUNBIT_OFFSET_Y (1<<1)
#define GUNBIT_OFFSET_Z (1<<2)
#define GUNBIT_ANGLES_X (1<<3)
#define GUNBIT_ANGLES_Y (1<<4)
#define GUNBIT_ANGLES_Z (1<<5)
#define GUNBIT_GUNRATE (1<<6)"><pre>#<span>define</span> <span>GUNBIT_OFFSET_X</span> (<span>1</span>&lt;&lt;<span>0</span>)
#<span>define</span> <span>GUNBIT_OFFSET_Y</span> (<span>1</span>&lt;&lt;<span>1</span>)
#<span>define</span> <span>GUNBIT_OFFSET_Z</span> (<span>1</span>&lt;&lt;<span>2</span>)
#<span>define</span> <span>GUNBIT_ANGLES_X</span> (<span>1</span>&lt;&lt;<span>3</span>)
#<span>define</span> <span>GUNBIT_ANGLES_Y</span> (<span>1</span>&lt;&lt;<span>4</span>)
#<span>define</span> <span>GUNBIT_ANGLES_Z</span> (<span>1</span>&lt;&lt;<span>5</span>)
#<span>define</span> <span>GUNBIT_GUNRATE</span> (<span>1</span>&lt;&lt;<span>6</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="gunframe_temp = ReadUShort()
gun_bits = (gunframe_temp &amp; 0xFE00) >> 9
gunframe = (gunframe_temp &amp; ~0xFE00)

[if gun_bits &amp; GUNBIT_OFFSET_X] gunoffset_x = ReadFloat()
[if gun_bits &amp; GUNBIT_OFFSET_Y] gunoffset_y = ReadFloat()
[if gun_bits &amp; GUNBIT_OFFSET_Z] gunoffset_z = ReadFloat()
[if gun_bits &amp; GUNBIT_ANGLES_X] gunangles_x = ReadFloat()
[if gun_bits &amp; GUNBIT_ANGLES_Y] gunangles_y = ReadFloat()
[if gun_bits &amp; GUNBIT_ANGLES_Z] gunangles_z = ReadFloat()
[if gun_bits &amp; GUNBIT_GUNRATE] gunrate = ReadByte()"><pre>gunframe_temp = ReadUShort()
gun_bits = (gunframe_temp &amp; <span>0xFE00</span>) &gt;&gt; <span>9</span>
gunframe = (gunframe_temp &amp; ~<span>0xFE00</span>)

[<span>if</span> gun_bits &amp; GUNBIT_OFFSET_X] gunoffset_x = ReadFloat()
[<span>if</span> gun_bits &amp; GUNBIT_OFFSET_Y] gunoffset_y = ReadFloat()
[<span>if</span> gun_bits &amp; GUNBIT_OFFSET_Z] gunoffset_z = ReadFloat()
[<span>if</span> gun_bits &amp; GUNBIT_ANGLES_X] gunangles_x = ReadFloat()
[<span>if</span> gun_bits &amp; GUNBIT_ANGLES_Y] gunangles_y = ReadFloat()
[<span>if</span> gun_bits &amp; GUNBIT_ANGLES_Z] gunangles_z = ReadFloat()
[<span>if</span> gun_bits &amp; GUNBIT_GUNRATE] gunrate = ReadByte()</pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_BLEND]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="screen_blend_r = ReadByte() / 255.f
screen_blend_g = ReadByte() / 255.f
screen_blend_b = ReadByte() / 255.f
screen_blend_a = ReadByte() / 255.f"><pre>screen_blend_r = ReadByte() / <span>255</span>.f
screen_blend_g = ReadByte() / <span>255</span>.f
screen_blend_b = ReadByte() / <span>255</span>.f
screen_blend_a = ReadByte() / <span>255</span>.f</pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_FOV] ReadByte(fov)</li>
<li>[if flags &amp; PS_RDFLAGS] ReadByte(rdflags)</li>
<li>ReadLong(statbits)</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="for (i = 0; i < 32; i++)
	if (statbits &amp; (1 << i))
		ReadShort(stats[i])"><pre><span>for</span> (i = <span>0</span>; i &lt; <span>32</span>; i++)
	<span>if</span> (statbits &amp; (<span>1</span> &lt;&lt; i))
		<span>ReadShort</span>(stats[i])</pre></div>
<ul dir="auto">
<li>ReadLong(morestatbits)</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="for (i = 32; i < 64; i++)
	if (morestatbits &amp; (1 << (i - 32)))
		ReadShort(stats[i])"><pre><span>for</span> (i = <span>32</span>; i &lt; <span>64</span>; i++)
	<span>if</span> (morestatbits &amp; (<span>1</span> &lt;&lt; (i - <span>32</span>)))
		<span>ReadShort</span>(stats[i])</pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_DAMAGE_BLEND]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="damage_blend_r = ReadByte() / 255.f
damage_blend_g = ReadByte() / 255.f
damage_blend_b = ReadByte() / 255.f
damage_blend_a = ReadByte() / 255.f"><pre>damage_blend_r = ReadByte() / <span>255</span>.f
damage_blend_g = ReadByte() / <span>255</span>.f
damage_blend_b = ReadByte() / <span>255</span>.f
damage_blend_a = ReadByte() / <span>255</span>.f</pre></div>
<ul dir="auto">
<li>[if flags &amp; PS_TEAM_ID]</li>
</ul>

<h3 tabindex="-1" dir="auto">svc_packetentities (18)</h3>
<h4 tabindex="-1" dir="auto">Bits</h4>
<div dir="auto" data-snippet-clipboard-copy-content="
// try to pack the common update flags into the first byte
#define U_ORIGIN1   (1<<0)
#define U_ORIGIN2   (1<<1)
#define U_ANGLE2    (1<<2)
#define U_ANGLE3    (1<<3)
#define U_FRAME8    (1<<4)      // frame is a byte
#define U_EVENT     (1<<5)
#define U_REMOVE    (1<<6)      // REMOVE this entity, don't add it
#define U_MOREBITS1 (1<<7)      // read one additional byte

// second byte
#define U_NUMBER16  (1<<8)      // NUMBER8 is implicit if not set
#define U_ORIGIN3   (1<<9)
#define U_ANGLE1    (1<<10)
#define U_MODEL     (1<<11)
#define U_RENDERFX8 (1<<12)     // fullbright, etc
#define U_EFFECTS8  (1<<14)     // autorotate, trails, etc
#define U_MOREBITS2 (1<<15)     // read one additional byte

// third byte
#define U_SKIN8     (1<<16)
#define U_FRAME16   (1<<17)     // frame is a short
#define U_RENDERFX16 (1<<18)    // 8 + 16 = 32
#define U_EFFECTS16 (1<<19)     // 8 + 16 = 32
#define U_MODEL2    (1<<20)     // weapons, flags, etc
#define U_MODEL3    (1<<21)
#define U_MODEL4    (1<<22)
#define U_MOREBITS3 (1<<23)     // read one additional byte

// fourth byte
#define U_OLDORIGIN (1<<24)     // FIXME: get rid of this
#define U_SKIN16    (1<<25)
#define U_SOUND     (1<<26)
#define U_SOLID     (1<<27)
#define U_MODEL16   (1<<28)
#define U_EFFECTS64 (1<<29) // [Edward-KEX]
#define U_ALPHA     (1<<30) // [Paril-KEX]
#define U_MOREBITS4 (1<<31) // [Paril-KEX] read one additional byte
#define U_SCALE     (1ull<<32ull) // [Paril-KEX]
#define U_INSTANCE  (1ull<<33ull) // [Paril-KEX]
#define U_OWNER     (1ull<<34ull) // [Paril-KEX]
#define U_OLDFRAME  (1ull<<35ull) // [Paril-KEX]"><pre><span>// try to pack the common update flags into the first byte</span>
<span>#define</span> <span>U_ORIGIN1</span>   (1&lt;&lt;0)
<span>#define</span> <span>U_ORIGIN2</span>   (1&lt;&lt;1)
<span>#define</span> <span>U_ANGLE2</span>    (1&lt;&lt;2)
<span>#define</span> <span>U_ANGLE3</span>    (1&lt;&lt;3)
<span>#define</span> <span>U_FRAME8</span>    (1&lt;&lt;4)      // frame is a byte
<span>#define</span> <span>U_EVENT</span>     (1&lt;&lt;5)
<span>#define</span> <span>U_REMOVE</span>    (1&lt;&lt;6)      // REMOVE this entity, don't add it
<span>#define</span> <span>U_MOREBITS1</span> (1&lt;&lt;7)      // read one additional byte

<span>// second byte</span>
<span>#define</span> <span>U_NUMBER16</span>  (1&lt;&lt;8)      // NUMBER8 is implicit if not set
<span>#define</span> <span>U_ORIGIN3</span>   (1&lt;&lt;9)
<span>#define</span> <span>U_ANGLE1</span>    (1&lt;&lt;10)
<span>#define</span> <span>U_MODEL</span>     (1&lt;&lt;11)
<span>#define</span> <span>U_RENDERFX8</span> (1&lt;&lt;12)     // fullbright, etc
<span>#define</span> <span>U_EFFECTS8</span>  (1&lt;&lt;14)     // autorotate, trails, etc
<span>#define</span> <span>U_MOREBITS2</span> (1&lt;&lt;15)     // read one additional byte

<span>// third byte</span>
<span>#define</span> <span>U_SKIN8</span>     (1&lt;&lt;16)
<span>#define</span> <span>U_FRAME16</span>   (1&lt;&lt;17)     // frame is a short
<span>#define</span> <span>U_RENDERFX16</span> (1&lt;&lt;18)    // 8 + 16 = 32
<span>#define</span> <span>U_EFFECTS16</span> (1&lt;&lt;19)     // 8 + 16 = 32
<span>#define</span> <span>U_MODEL2</span>    (1&lt;&lt;20)     // weapons, flags, etc
<span>#define</span> <span>U_MODEL3</span>    (1&lt;&lt;21)
<span>#define</span> <span>U_MODEL4</span>    (1&lt;&lt;22)
<span>#define</span> <span>U_MOREBITS3</span> (1&lt;&lt;23)     // read one additional byte

<span>// fourth byte</span>
<span>#define</span> <span>U_OLDORIGIN</span> (1&lt;&lt;24)     // FIXME: get rid of this
<span>#define</span> <span>U_SKIN16</span>    (1&lt;&lt;25)
<span>#define</span> <span>U_SOUND</span>     (1&lt;&lt;26)
<span>#define</span> <span>U_SOLID</span>     (1&lt;&lt;27)
<span>#define</span> <span>U_MODEL16</span>   (1&lt;&lt;28)
<span>#define</span> <span>U_EFFECTS64</span> (1&lt;&lt;29) // [Edward-KEX]
<span>#define</span> <span>U_ALPHA</span>     (1&lt;&lt;30) // [Paril-KEX]
<span>#define</span> <span>U_MOREBITS4</span> (1&lt;&lt;31) // [Paril-KEX] read one additional byte
<span>#define</span> <span>U_SCALE</span>     (1ull&lt;&lt;32ull) // [Paril-KEX]
<span>#define</span> <span>U_INSTANCE</span>  (1ull&lt;&lt;33ull) // [Paril-KEX]
<span>#define</span> <span>U_OWNER</span>     (1ull&lt;&lt;34ull) // [Paril-KEX]
<span>#define</span> <span>U_OLDFRAME</span>  (1ull&lt;&lt;35ull) // [Paril-KEX]</pre></div>
<h4 tabindex="-1" dir="auto">Data</h4>
<p dir="auto">The regular process for deltaing entities has not changed, but the data bits have.</p>
<p dir="auto">ParseEntityBits:</p>
<ul dir="auto">
<li>ReadByte(bits)</li>
<li>[if bits &amp; U_MOREBITS1] bits |= ReadByte() &lt;&lt; 8</li>
<li>[if bits &amp; U_MOREBITS2] bits |= ReadByte() &lt;&lt; 16</li>
<li>[if bits &amp; U_MOREBITS3] bits |= ReadByte() &lt;&lt; 24</li>
<li>[if bits &amp; U_MOREBITS4] bits |= ReadByte() &lt;&lt; 32</li>
<li>[if bits &amp; U_NUMBER16] ReadShort(number) [else] ReadByte(number)</li>
</ul>
<p dir="auto">ParseDelta:</p>
<ul dir="auto">
<li>[if bits &amp; U_MODEL16]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="ReadShort(modelindex)
ReadShort(modelindex2)
ReadShort(modelindex3)
ReadShort(modelindex4)"><pre><span>ReadShort</span>(modelindex)
ReadShort(modelindex2)
ReadShort(modelindex3)
ReadShort(modelindex4)</pre></div>
<ul dir="auto">
<li>[else]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="ReadByte(modelindex)
ReadByte(modelindex2)
ReadByte(modelindex3)
ReadByte(modelindex4)"><pre><span>ReadByte</span>(modelindex)
ReadByte(modelindex2)
ReadByte(modelindex3)
ReadByte(modelindex4)</pre></div>
<ul dir="auto">
<li>[if bits &amp; U_FRAME8] ReadByte(frame)</li>
<li>[if bits &amp; U_FRAME16] ReadShort(frame)</li>
<li>[if bits &amp; (U_SKIN8 | U_SKIN16) == (U_SKIN8 | U_SKIN16)] ReadLong(skinnum)</li>
<li>[elseif bits &amp; U_SKIN8] ReadByte(skinnum)</li>
<li>[elseif bits &amp; U_SKIN16] ReadUShort(skinnum)</li>
<li>[if bits &amp; (U_EFFECTS8 | U_EFFECTS16 | U_EFFECTS64)]</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="// if 64-bit effects are sent, the low bits are sent first
// and the high bits come after.
[if bits &amp; U_EFFECTS64] ReadULong(loeffects)

[if bits &amp; (U_EFFECTS8 | U_EFFECTS16) == (U_EFFECTS8 | U_EFFECTS16)] ReadULong(effects)
[elseif bits &amp; U_EFFECTS16] ReadUShort(effects)
[else] ReadByte(effects)

[if bits &amp; U_EFFECTS64] effects = (effects << 32) | loeffects "><pre><span><span>//</span> if 64-bit effects are sent, the low bits are sent first</span>
<span><span>//</span> and the high bits come after.</span>
[<span>if</span> bits &amp; U_EFFECTS64] ReadULong(loeffects)

[<span>if</span> bits &amp; (U_EFFECTS8 | U_EFFECTS16) == (U_EFFECTS8 | U_EFFECTS16)] ReadULong(effects)
[elseif bits &amp; U_EFFECTS16] ReadUShort(effects)
[<span>else</span>] ReadByte(effects)

[<span>if</span> bits &amp; U_EFFECTS64] effects = (effects &lt;&lt; <span>32</span>) | loeffects </pre></div>
<ul dir="auto">
<li>[if bits &amp; (U_RENDERFX8 | U_RENDERFX16) == (U_RENDERFX8 | U_RENDERFX16)] ReadLong(effects)</li>
<li>[elseif bits &amp; renderfx] ReadByte(renderfx)</li>
<li>[elseif bits &amp; U_RENDERFX16] ReadShort(renderfx)</li>
<li>[if bits &amp; U_SOLID] ReadULong(solid)</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="// note: for the protocol in the demos (2022), if `solid` is zero,
// then the following reads are lower precision, using ReadShort() * (1.f / 8.f)
[if bits &amp; U_ORIGIN1] ReadFloat(origin_x)
[if bits &amp; U_ORIGIN2] ReadFloat(origin_y)
[if bits &amp; U_ORIGIN3] ReadFloat(origin_z)
[if bits &amp; U_OLDORIGIN] ReadPos(oldorigin)"><pre><span><span>//</span> note: for the protocol in the demos (2022), if `solid` is zero,</span>
<span><span>//</span> then the following reads are lower precision, using ReadShort() * (1.f / 8.f)</span>
[<span>if</span> bits &amp; U_ORIGIN1] ReadFloat(origin_x)
[<span>if</span> bits &amp; U_ORIGIN2] ReadFloat(origin_y)
[<span>if</span> bits &amp; U_ORIGIN3] ReadFloat(origin_z)
[<span>if</span> bits &amp; U_OLDORIGIN] ReadPos(oldorigin)</pre></div>
<ul dir="auto">
<li>[if bits &amp; U_ANGLE1] ReadFloat(angle_x)</li>
<li>[if bits &amp; U_ANGLE2] ReadFloat(angle_y)</li>
<li>[if bits &amp; U_ANGLE3] ReadFloat(angle_z)</li>
<li>[if bits &amp; U_SOUND] ReadUShort(temp_sound)</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="bool has_volume = temp_sound &amp; 0x4000
bool has_attenuation = temp_sound &amp; 0x8000;

// the sound index takes up 14 bits
sound = temp_sound &amp; ~(0x4000 | 0x8000)

[if has_volume] loop_volume = ReadByte() / 255.f
[else] loop_volume = 1.f

[if has_attn] loop_attenuation = ReadByte()
[else] loop_attenuation = ATTN_STATIC"><pre><span>bool</span> has_volume = temp_sound &amp; <span>0x4000</span>
<span>bool</span> has_attenuation = temp_sound &amp; <span>0x8000</span>;

<span><span>//</span> the sound index takes up 14 bits</span>
sound = temp_sound &amp; ~(<span>0x4000</span> | <span>0x8000</span>)

[<span>if</span> has_volume] loop_volume = ReadByte() / <span>255</span>.f
[<span>else</span>] loop_volume = <span>1</span>.f

[<span>if</span> has_attn] loop_attenuation = ReadByte()
[<span>else</span>] loop_attenuation = ATTN_STATIC</pre></div>
<ul dir="auto">
<li>[if bits &amp; U_EVENT] ReadByte(event) [else] event = 0</li>
<li>[if bits &amp; U_ALPHA] alpha = ReadByte() / 255.f</li>
<li>[if bits &amp; U_SCALE] scale = ReadByte() / 16.f</li>
<li>[if bits &amp; U_INSTANCE] ReadByte(instance_bits)</li>
<li>[if bits &amp; U_OWNER] ReadShort(owner)</li>
<li>[if bits &amp; U_OLDFRAME] ReadUShort(old_frame)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_splitclient (21)</h2>
<p dir="auto">This packet indicates to the client which split screen player the next messages are directed towards, for unicast messages.</p>
<ul dir="auto">
<li>ReadByte (isplit)</li>
</ul>
<p dir="auto">Note that <code>isplit</code> will be offset by 1 (that is to say, a value of 1 indicates split screen client 0).</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_configblast (22)</h2>
<p dir="auto">Compressed configstring data. This is to make connection faster by sending fewer packets.</p>
<ul dir="auto">
<li>ReadShort (compressed size)</li>
<li>ReadShort (uncompressed size)</li>
<li>ReadByte[compressed size] (buffer)</li>
</ul>
<p dir="auto">The received <code>buffer</code> is directly passed through to zlib's <code>uncompress</code>. After decompression, until the buffer is exhausted, the following data repeats:</p>
<ul dir="auto">
<li>ReadUShort (index)</li>
<li>ReadString (str)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_spawnbaselineblast (23)</h2>
<p dir="auto">Compressed baseline data. This is to make connection faster by sending fewer packets.</p>
<ul dir="auto">
<li>ReadShort (compressed size)</li>
<li>ReadShort (uncompressed size)</li>
<li>ReadByte[compressed size] (buffer)</li>
</ul>
<p dir="auto">The received <code>buffer</code> is directly passed through to zlib's <code>uncompress</code>. After decompression, until the buffer is exhausted, read in the data contained in a <code>svc_spawnbaseline</code> packet.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_level_restart (24)</h2>
<p dir="auto">Sent when the server executes a <code>restart_level</code> command. The client should be prepared to do a "soft wipe" of their state, but might want to defer it until the full frame is read since effects might come in after this command is executed.</p>
<p dir="auto">This message's data contains configstrings that were changed by restarting the level. The following should be repeated until an exit condition is met:</p>
<ul dir="auto">
<li>ReadShort (id)</li>
<li>[if id is -1, exit]</li>
<li>ReadString (str)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_damage (25)</h2>
<p dir="auto">This message is sent after accumulating damage on a player. It gives the player a rough idea of the damage they're receiving and from where.</p>
<ul dir="auto">
<li>ReadByte (count)</li>
</ul>
<p dir="auto">For <code>count</code> number of loops, read the following:</p>
<ul dir="auto">
<li>ReadByte (encoded)</li>
<li>ReadDir</li>
</ul>
<p dir="auto"><code>encoded</code> is in the following format:</p>
<div data-snippet-clipboard-copy-content="struct packed_damage_t
{
	uint8_t damage : 5;
	uint8_t health : 1;
	uint8_t armor : 1;
	uint8_t shield : 1;
}"><pre><code>struct packed_damage_t
{
	uint8_t damage : 5;
	uint8_t health : 1;
	uint8_t armor : 1;
	uint8_t shield : 1;
}
</code></pre></div>
<p dir="auto"><code>health</code> provides a <code>1,0,0</code> addition to color.
<code>armor</code> provides a <code>1,1,1</code> addition to color.
<code>shield</code> provides a <code>0,1,0</code> addition to color.</p>
<p dir="auto">The <code>damage</code> value is also divided by 3, so multiplying it by 3 will get you an approximation of the real damage amount.</p>
<p dir="auto">The color is then normalized.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_locprint (26)</h2>
<p dir="auto">This packet is the new entry point for prints.</p>
<ul dir="auto">
<li>ReadByte (flags)</li>
<li>ReadString (base)</li>
<li>ReadByte (num args)</li>
<li>ReadString[num args] (args)</li>
</ul>
<p dir="auto">The <code>base</code> string is a <code>fmtlib</code> formatted string.</p>
<p dir="auto">The information in <a href="#print-adjustments">Print Adjustments</a> and <a href="#loc_print">Loc_Print</a> explains how formatting works.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_fog (27)</h2>
<div dir="auto" data-snippet-clipboard-copy-content="enum bits_t : uint16_t
{
	// global fog
	BIT_DENSITY     = bit_v<0>,
	BIT_R           = bit_v<1>,
	BIT_G           = bit_v<2>,
	BIT_B           = bit_v<3>,
	BIT_TIME        = bit_v<4>, // if set, the transition takes place over N milliseconds

	// height fog
	BIT_HEIGHTFOG_FALLOFF   = bit_v<5>,
	BIT_HEIGHTFOG_DENSITY   = bit_v<6>,
	BIT_MORE_BITS           = bit_v<7>, // read additional bit
	BIT_HEIGHTFOG_START_R   = bit_v<8>,
	BIT_HEIGHTFOG_START_G   = bit_v<9>,
	BIT_HEIGHTFOG_START_B   = bit_v<10>,
	BIT_HEIGHTFOG_START_DIST= bit_v<11>,
	BIT_HEIGHTFOG_END_R     = bit_v<12>,
	BIT_HEIGHTFOG_END_G     = bit_v<13>,
	BIT_HEIGHTFOG_END_B     = bit_v<14>,
	BIT_HEIGHTFOG_END_DIST  = bit_v<15>
};"><pre><span>enum</span> <span>bits_t</span> : <span>uint16_t</span>
{
	<span><span>//</span> global fog</span>
	BIT_DENSITY     = bit_v&lt;<span>0</span>&gt;,
	BIT_R           = bit_v&lt;<span>1</span>&gt;,
	BIT_G           = bit_v&lt;<span>2</span>&gt;,
	BIT_B           = bit_v&lt;<span>3</span>&gt;,
	BIT_TIME        = bit_v&lt;<span>4</span>&gt;, <span><span>//</span> if set, the transition takes place over N milliseconds</span>

	<span><span>//</span> height fog</span>
	BIT_HEIGHTFOG_FALLOFF   = bit_v&lt;<span>5</span>&gt;,
	BIT_HEIGHTFOG_DENSITY   = bit_v&lt;<span>6</span>&gt;,
	BIT_MORE_BITS           = bit_v&lt;<span>7</span>&gt;, <span><span>//</span> read additional bit</span>
	BIT_HEIGHTFOG_START_R   = bit_v&lt;<span>8</span>&gt;,
	BIT_HEIGHTFOG_START_G   = bit_v&lt;<span>9</span>&gt;,
	BIT_HEIGHTFOG_START_B   = bit_v&lt;<span>10</span>&gt;,
	BIT_HEIGHTFOG_START_DIST= bit_v&lt;<span>11</span>&gt;,
	BIT_HEIGHTFOG_END_R     = bit_v&lt;<span>12</span>&gt;,
	BIT_HEIGHTFOG_END_G     = bit_v&lt;<span>13</span>&gt;,
	BIT_HEIGHTFOG_END_B     = bit_v&lt;<span>14</span>&gt;,
	BIT_HEIGHTFOG_END_DIST  = bit_v&lt;<span>15</span>&gt;
};</pre></div>
<ul dir="auto">
<li>ReadByte (bits)</li>
<li>[if bits &amp; BIT_MORE_BITS] ReadByte (morebits), bits |= (morebits &lt;&lt; 8)</li>
<li>[if bits &amp; BIT_DENSITY] ReadFloat (density)</li>
<li>[if bits &amp; BIT_DENSITY] ReadByte (skyfactor)</li>
<li>[if bits &amp; BIT_R] ReadByte (red)</li>
<li>[if bits &amp; BIT_G] ReadByte (green)</li>
<li>[if bits &amp; BIT_B] ReadByte (blue)</li>
<li>[if bits &amp; BIT_TIME] ReadUShort (time)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_FALLOFF] ReadFloat (heightfog falloff)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_DENSITY] ReadFloat (heightfog density)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_START_R] ReadByte (heightfog start red)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_START_G] ReadByte (heightfog start green)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_START_B] ReadByte (heightfog start blue)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_START_DIST] ReadLong (heightfog start distance)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_END_R] ReadByte (heightfog end red)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_END_G] ReadByte (heightfog end green)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_END_B] ReadByte (heightfog end blue)</li>
<li>[if bits &amp; BIT_HEIGHTFOG_END_DIST] ReadLong (heightfog end distance)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_waitingforplayers (28)</h2>
<p dir="auto">Sent when there are players waiting to join before the game can start (or zero if all players are in).</p>
<ul dir="auto">
<li>ReadByte (count)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_bot_chat (29)</h2>
<p dir="auto">Bots talking to players.</p>
<ul dir="auto">
<li>ReadString (bot name)</li>
<li>ReadShort (client index, or 256 if no particular player)</li>
<li>ReadString (loc string)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_poi (30)</h2>
<p dir="auto">Spawn a POI.</p>
<div dir="auto" data-snippet-clipboard-copy-content="enum svc_poi_flags
{
    POI_FLAG_NONE = 0,
    POI_FLAG_HIDE_ON_AIM = 1, // hide the POI if we get close to it with our aim
};"><pre><span>enum</span> svc_poi_flags
{
    POI_FLAG_NONE = <span>0</span>,
    POI_FLAG_HIDE_ON_AIM = <span>1</span>, <span><span>//</span> hide the POI if we get close to it with our aim</span>
};</pre></div>
<ul dir="auto">
<li>ReadUShort (key)</li>
<li>ReadUShort (time)</li>
<li>ReadPos (pos)</li>
<li>ReadUShort (image index)</li>
<li>ReadByte (palette index)</li>
<li>ReadByte (flags)</li>
</ul>
<p dir="auto">If a non-zero <code>key</code> is specified, only one of that POI key can exist at any given time. If <code>time</code> is 0xFFFF, the POI that matches the key will be removed.</p>
<p dir="auto">If <code>time</code> is zero, the POI will last forever, <code>key</code> should be set in order to allow the POI to be cleaned up later.</p>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_help_path (31)</h2>
<p dir="auto">Spawns the Compass help path effect at the given location.</p>
<ul dir="auto">
<li>ReadByte (start)</li>
<li>ReadPos (pos)</li>
<li>ReadDir (dir)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, server -&gt; client) svc_achievement (32)</h2>
<ul dir="auto">
<li>ReadString (id)</li>
</ul>
<h2 tabindex="-1" dir="auto">(packet, client -&gt; server) clc_stringcmd (4)</h2>
<ul dir="auto">
<li>ReadByte (isplit)</li>
<li>ReadString (s)</li>
</ul>
<p dir="auto">Note that <code>isplit</code> is offset by 1, so <code>1</code> is the first split screen client.</p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>