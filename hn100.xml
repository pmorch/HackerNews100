<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 23 Dec 2023 09:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[They want you to forget what a film looks like (111 pts)]]></title>
            <link>https://aftermath.site/true-lies-4k-uhd-blu-ray-james-cameron-peter-jackson-park-road-post</link>
            <guid>38741536</guid>
            <pubDate>Sat, 23 Dec 2023 04:06:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aftermath.site/true-lies-4k-uhd-blu-ray-james-cameron-peter-jackson-park-road-post">https://aftermath.site/true-lies-4k-uhd-blu-ray-james-cameron-peter-jackson-park-road-post</a>, See on <a href="https://news.ycombinator.com/item?id=38741536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The most grotesque videos on YouTube fit into a specific category. It consists of old footage run through an AI upscaler. Sometimes the videos are colorized, sometimes they’re interpolated to 60 frames per second. Uniformly they look atrocious, smeary, and garish, unless you don’t know what a film is supposed to look like. Increasingly that’s a lot of people, including, evidently, the people responsible for the latest transfers of the movie <em>True Lies</em> and to a lesser extent <em>Aliens</em>, <em>The Abyss</em>, and <em>Titanic</em>.</p><div><figure><p><iframe title="[4K, 60 fps, color] The lumiere family goes on a trip.1895." width="710" height="399" src="https://www.youtube.com/embed/GHHt-CBKkS0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p><figcaption>There's like a million of these and they're all uniformly disgusting.</figcaption></figure></div><p>If you have never seen the movie <em>True Lies</em>, you are probably under 30. Arnold Schwarzenegger plays an agent in a government counter-terrorist organization that has to fight bad guys while keeping his dangerous lifestyle a secret from his mousey wife played by Jamie Lee Curtis. It’s a goofy big budget action comedy remake that has some fantastic set pieces, an incredible cast, some great bits, and ages exactly how you would expect from an airheaded action movie from 1994. In James Cameron’s career, It’s probably the weirdest movie James Cameron ever made outside of <em>Piranha II: The Spawning</em>.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_43_12.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>The Folders. The pictures on the left. It all looks bad. Credit: 20th Century Fox.</figcaption></figure><p>I have a deep fondness for this movie in my heart, partially because I played the <a href="https://en.wikipedia.org/wiki/True_Lies_(video_game)" target="_blank" rel="noreferrer noopener">pretty bad Super Nintendo</a> game too much but also because it’s rare to get a comedy where the hero airholes the side of a skyscraper with a harrier jet. So when I saw people posting that it had gotten a garish transfer, I was particularly insulted. But even with prior warning, I was unprepared for how disgusting it looked.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/True.Lies_.1994.2160p.MA_.WEB-DL.DDP5_.1.Atmos_.DV_.HDR_.H.265-FLUX-00_52_09.jpg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>It looks like they airbrushed her soul. Credit: 20th Century FOX</figcaption></figure><p>The transfer of <em>True Lies</em> has a truly vile quality to it, a feeling like someone clandestinely dosed you with LSD just a hair below the threshold. At times it can look passable in motion, but then you notice something out of the corner of your eye: a thick fold of skin, a framed photo of a child, folders that are too thick at the margins, cheeks that look rendered. It’s that familiar dread at the pit of your gut when you spot AI generated imagery, a combination of edges not looking quite right and surfaces that are simultaneously too smooth and too sharp. A crime was committed here, and you can tell.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_04_14-1.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>Game over. Credit: 20th Century Fox.</figcaption></figure><p>The transfers of <em>Aliens </em>and <em>The Abyss </em>are markedly less bad than <em>True Lies</em>, but I still have difficulty watching them. The skin looks sterile and waxy with too much film grain removed. Everything looks like it has raytracing on. Both transfers are, however, within acceptable parameters for most normal people.&nbsp;</p><p>The recent transfer of <em>Titanic </em>got a similar treatment, with <a href="https://forum.blu-ray.com/showthread.php?t=302519" target="_blank" rel="noreferrer noopener">similarly mixed reactions online</a>.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Titanic-1997-2160p-UHD-BluRay-x265-DV-HDR-DDP-7.1-English-Weasley-HONE-01_19_33.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>Rose lookin' like a Pixar character over here. <em>Credit: 20th Century Fox</em>.</figcaption></figure><p>“Why would you do this?” is a logical question. It’s worth contextualizing who handled these “restorations” – namely Park Road Post, a subsidiary of Peter Jackson’s WingNut Films. They have worked on multiple films in the past, but the two that are most germane here are Jackson’s <em>They Shall Not Grow Old</em> and the 3-part Disney+ documentary <em>The Beatles: Get Back. </em>Both movies recontextualize pre-existing footage and, importantly, do so with an aggressive use of machine learning. <em>They Shall Not Grow Old </em>upscales and colorizes old World War I imagery in an attempt to set the bloodshed in a more modern context, while <em>Get Back</em> recycled footage shot for Michael Lindsay-Hogg’s <em>Let It Be</em>, including moments never before seen by the public, to elucidate the process behind the creation of some of The Beatles’ most iconic songs.&nbsp;</p><p>I understand the intent of using machine learning in both works. In the case of Hogg’s <em>Let it Be</em>,<em> </em>much of the footage was chunky and rough, and they used audio isolation narratively in an interesting way.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/They.Shall_.Not_.Grow_.Old_.2018.1080p.BluRay.Remux_.AVC_.DTS-HD.MA_.5.1-PmP-00_43_55-1.jpg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>They should have called it They Shall Grow Really Weird Looking. <em>Credit: Warner Bros. Pictures</em></figcaption></figure><p>Unfortunately they both look<em> really fucking bad</em>. And they look worse as the years go on.&nbsp;</p><p><em>They Shall Not Grow Old</em> is difficult to stomach, with the soldiers being motion interpolated in a melting, shambolic manner. The digital noise reduction is inconsistent – film grain is present on the skin of soldiers and absent in other places, following their faces like reptilian scales. This is an enthusiastic, clumsy use of a technology on severely damaged footage.&nbsp;</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The.Beatles.Get_.Back_.S01E01.Part_.1.Days_.1-7.2160p.WEB-DL.DDP5_.1.HEVC-TEPES-00_15_55.jpg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>Mods are asleep, post smooth Paul. <em>Credit: Disney+</em></figcaption></figure><p>The same is true to a lesser extent for <em>The Beatles: Get Back</em>. Nobody would begrudge Jackson for color grading and restoring rough footage, but the effect is sterilizing and alien. Hair and fur coats are simultaneously shiny and oily, with gorgon-esque strands that undulate and melt into themselves. The folds of skin and clothing have an unnatural heft. The edges of objects will catch and melt into each other. The grain structure is slightly more natural than in <em>They Shall Not Grow Old</em>, but it looks like it was artificially added over heavily denoised footage. <em>Get Back </em>was wildly successful, in part because the only semi-available version of <em>Let It Be</em> is an atrocious DVD transfer, but also on the strength of 60 hours of unused footage, an unseen insight into an iconic band.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/The-Beatles-Now-And-Then-Official-Music-Video-00.01.52.420.jpeg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>They should have let it be. <em>Credit: WingNut Films Productions Ltd</em>.</figcaption></figure><p>I wish we had stopped Jackson then and there. As my good friend Danielle joked, this was a trial balloon. People praised Jackson for doing this to Lindsay-Hogg’s footage in the name of restoration, and it emboldened him to do worse things. Before the <em>True Lies </em>debacle, the most recent example of this was the aggressively saccharine and confusing <em>Now &amp; Then</em>, a long unfinished demo now finished by Ringo and Paul, edited together with archival footage of younger John and George composited in an a fashion that can be charitably described as tremendously weird.</p><div><figure><p><iframe title="The Beatles - Now And Then (Official Music Video)" width="710" height="399" src="https://www.youtube.com/embed/Opxhh9Oh3rg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p><figcaption>Every part of this is strange.</figcaption></figure></div><p>Lest I am accused of being a luddite, I firmly believe there are many use cases for this technology. Nvidia’s DLSS and competing variants generally work very well on the games they are trained on. I regularly use <a href="https://nmkd.itch.io/flowframes" target="_blank" rel="noreferrer noopener">Flowframes</a> in the rare case that I need interpolation. I have often used waifu2x and now <a href="https://github.com/chaiNNer-org/chaiNNer" target="_blank" rel="noreferrer noopener">chainner</a> if I need to photoshop a still and my source is bad, and there are databases of countless <a href="https://openmodeldb.info/" target="_blank" rel="noreferrer noopener">AI upscaling models</a>. But the flip side to this is that these technologies are often used in place of proper ingest. “Crap in, crap out” is a truism for a reason. I spend a lot of time regularly capturing VHS and Laserdisc at the highest possible quality for fun, and when I see people who should know better say “Just use Topaz” (a commercial AI upscaler) instead of learning how to correctly ingest footage and deinterlace it, it makes me want to pull out my hair, because it almost uniformly looks bad to anyone who works with video professionally.&nbsp;</p><div><figure><p><iframe title="The Cure - Catch &amp; Why Can't I Be You? (Live) - The Tube (1987)" width="710" height="533" src="https://www.youtube.com/embed/ks1wE_NXWv8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p><figcaption>This is captured on a home VHS with <a href="https://github.com/oyvindln/vhs-decode">VHS-Decode,</a> and then upscaled to 4k for YouTube and deinterlaced to 50 FPS <a href="http://avisynth.nl/index.php/QTGMC">QTGMC</a>, and as a result it looks great.</figcaption></figure></div><p>When you finally do see a piece of footage transferred well, it can be breathtaking. Good archival practices require a lot of institutional knowledge and labor. It’s an art when done well, and the people who do it care so much about what they do. But the modern application of much of AI is precisely about taking labor out of the equation. Why transfer a tape correctly when we can just have a computer guess badly instead? What if crap goes in, and it doesn’t come out?</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/neck.jpg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>Neck. NECK! <em>Credit: 20th Century Fox</em></figcaption></figure><p>What makes all of this worse is that <em>True Lies</em>, as I understand it, did not need to be shoved through the AI wringer. According to <a href="https://thedigitalbits.com/item/true-lies-2023-digital-uhd" target="_blank" rel="noreferrer noopener">The Digital Bits</a>, Park Road Post had a recent 4k scan of <em>True Lies </em>from the original camera negative. Park Road Post’s own website claims they have a Lasergraphics Director 10K film scanner on the premises. So what is the purpose of adding AI to this mix? Why do that to a perfectly fine-looking film? What is gained here, other than to slightly yassify an Arnold film? At this point, maybe they are simply doing it just to say that they did, because the technology is lying around, like a loaded gun with the safety off.</p><p>Nerds who post on blu-ray forums as a rule often need to calm down, and the forum threads I have read about this are no exception, but there are certain cases where a filmmaker is just wrong about how their films should look. Lucas is the infamous notable example, but Cameron is not innocent here in his treatment of his own films. Wong Kar-wai is another notable example, as what he did to <em>Ashes of Time</em> is criminal as was his recent “remasters” of his movies like<em> In The Mood For Love</em>. In certain rare conditions like this, it’s healthy to question if directors have the best interests of their own films in mind, <a href="https://thedigitalbits.com/item/titanic-4k-25thle-uhd-2023" target="_blank" rel="noreferrer noopener">as Cameron himself personally approved of these remasters</a>.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/In.the_.Mood_.for_.Love_.2000.1080p.UHD_.BluRay.DD5_.1.x264-ZQ-00_01_14.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>Why did you change the color of your movie like this? <em>Credit: Block 2 Pictures</em></figcaption></figure><p>What actually chills my blood more than anything is the thought that a lot of people think this all looks pretty good. You see this mindset at work whenever an AI fetishist posts a stable diffusion image of a woman with 13 fingers, 40 incisors and comically huge breasts. There’s an entire portion of the population that takes overt pleasure in the over-smoothed, perverts that prefer all media to be fast, high frame rate, and scrubbed squeaky clean. The cameras on our phones don’t simply capture images anymore, <a href="https://www.newyorker.com/culture/infinite-scroll/have-iphone-cameras-become-too-smart" target="_blank" rel="noreferrer noopener">they compute them and ‘optimize’ them</a>. It’s Italian Futurism in 4k, a noise reduction death drive. It’s not simply enough for much of digital cinema to look crystal clear and lifeless; the past should be denoised, grain managed and cleaned to conform to that standard. It is expedient and profitable if people don’t remember what film is supposed to look like.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=710" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=425&amp;quality=75 425w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=850&amp;quality=75 850w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=585&amp;quality=75 585w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=1170&amp;quality=75 1170w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=710&amp;quality=75 710w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2023/12/Aliens.1986.Special.Edition.2160p.WEB-DL.DDP5_.1.HDR_.H.265-CanadianSupervillainJamesCameron-01_16_00.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption>That's too much detail. <em>Credit: 20th Century Fox</em></figcaption></figure><p>I don’t think anyone gets into preservation to destroy film. I believe that everyone involved with this process worked hard and had the best interests of the film in mind, but the exact nature of restoration itself can vary wildly. I believe that some companies get blinded by new tech, get high on their own supply, and that can result in work that is destructive instead of restorative. I don’t know what the solution to this is in the world we live in, outside of decoupling film preservation from the profit motive whenever possible.</p><p>But I am certain about one thing. For a while, much of gaming tried looking like <em>Aliens</em>. Now, <em>Aliens</em> looks like a video game. And that doesn’t sit right with me.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How big is YouTube? (458 pts)]]></title>
            <link>https://ethanzuckerman.com/2023/12/22/how-big-is-youtube/</link>
            <guid>38739563</guid>
            <pubDate>Fri, 22 Dec 2023 22:55:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethanzuckerman.com/2023/12/22/how-big-is-youtube/">https://ethanzuckerman.com/2023/12/22/how-big-is-youtube/</a>, See on <a href="https://news.ycombinator.com/item?id=38739563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
						<article id="post-6596">
				<div><p>How big is YouTube?</p>
<p>I got interested in this question a few years ago, when I started writing about the <a href="https://theconversation.com/facebook-has-a-misinformation-problem-and-is-blocking-access-to-data-about-how-much-there-is-and-who-is-affected-164838">“denominator problem”</a>. A great deal of social media research focuses on finding unwanted behavior – mis/disinformation, hate speech – on platforms. This isn’t that hard to do: search for “white genocide” or “ivermectin” and count the results. Indeed, a lot of eye-catching research does just this – consider <a href="https://secure.avaaz.org/campaign/en/facebook_threat_health/">Avaaz’s August 2020 report about COVID misinformation</a>. It reports 3.8 billion views of COVID misinfo in a year, which is a very big number. But it’s a numerator without a denominator – Facebook generates dozens or hundreds of views a day for each of its 3 billion users – 3.8 billion views is actually a very small number, contextualized with a denominator.</p>
<p>A few social media platforms have made it possible to calculate denominators. Reddit, for many years, permitted Pushshift to collect all Reddit posts, which means we can calculate what a small fraction of Reddit is focused on meme stocks or crypto, versus conversations about mental health or board gaming. Our <a href="https://redditmap.social/">Redditmap.social platform</a> – primarily built by Virginia Partridge and Jasmine Mangat – is based around the idea of looking at the platform as a whole and understanding how big or small each community is compared to the whole. Alas, Reddit cut off public access to Pushshift this summer, so Redditmap.social can only use data generated early this year. </p>
<p>Twitter was also a good platform for studying denominators, because it created a research API that took a statistical sample of all tweets and gave researchers access to every 10th or 100th one. If you found 2500 tweets about ivermectin a day, and saw 100m tweets through the decahose (which gave researchers 1/10th of tweet volume), you could calculate an accurate denominator (100m x 10) (All these numbers are completely made up.) Twitter has cut off access to these excellent academic APIs and now charges massive amounts of money for much less access, which means that it’s no longer possible for most researchers to do denominator-based work.</p>
<p>Interesting as Reddit and Twitter are, they are much less widely used than YouTube, which is used by virtually all internet users. <a href="https://www.pewresearch.org/internet/2023/12/11/teens-social-media-and-technology-2023/">Pew reports that 93% of teens use YouTube</a> – the closest service in terms of usage is Tiktok with 63% and Snapchat with 60%. While YouTube has a good, well-documented API, there’s no good way to get a random, representative sample of YouTube. Instead, most research on YouTube either studies a collection of videos (all videos on the channels of a selected set of users) or videos discovered via recommendation (start with <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">Never Going to Give You Up</a>, objectively the center of the internet, and collect recommended videos.) You can do excellent research with either method, but you won’t get a sample of all YouTube videos and you won’t be able to calculate the size of YouTube.</p>
<p>I brought this problem to Jason Baumgartner, creator of PushShift, and prince of the dark arts of data collection. One of Jason’s skills is a deep knowledge of undocumented APIs, ways of collecting data outside of official means. Most platforms have one or more undocumented APIs, widely used by programmers for that platform to build internal tools. In the case of YouTube, that API is called <a href="https://gizmodo.com/how-project-innertube-helped-pull-youtube-out-of-the-gu-1704946491">“Inner Tube”</a> and its existence is an open secret in programmer communities. Using InnerTube, Jason suggested we do something that’s both really smart and really stupid: guess at random URLs and see if there are videos there.</p>
<p>Here’s how this works: YouTube URLs look like this: <code> https://www.youtube.com/ watch?v=vXPJVwwEmiM</code></p>
<p>That bit after “watch?v=” is an 11 digit string. The first ten digits can be a-z,A-Z,0-9 and _-. The last digit is special, and can only be one of 16 values. Turns out there are 2^64 possible YouTube addresses, an enormous number: 18.4 quintillion. There are lots of YouTube videos, but not that many. Let’s guess for a moment that there are 1 billion YouTube videos – if you picked URLs at random, you’d only get a valid address roughly once every 18.4 billion tries. </p>
<p>We refer to this method as “drunk dialing”, as it’s basically as sophisticated as taking swigs from a bottle of bourbon and mashing digits on a telephone, hoping to find a human being to speak to. Jason found a couple of cheats that makes the method roughly 32,000 times as efficient, meaning our “phone call” connects lots more often. Kevin Zheng wrote a whole bunch of scripts to do the dialing, and over the course of several months, we collected more than 10,000 truly random YouTube videos.</p>
<p>There’s lots you can do once you’ve got those videos. Ryan McCarthy is lead author <a href="https://journalqd.org/article/view/4066">on our paper in the Journal of Quantitative Description</a>, and he led the process of watching a thousand of these videos and hand-coding them, a massive and fascinating task. Kevin wired together his retrieval scripts with a variety of language detection systems, and we now have a defensible – if far from perfect – estimate of what languages are represented on YouTube. We’re starting some experiments to understand how the videos YouTube recommends differ from the “average” YouTube video – YouTube likes recommending videos with at least ten thousand views, while the median YouTube video has 39 views.</p>
<p>I’ll write at some length in the future about what we can learn from a true random sample of YouTube videos. I’ve been doing a lot of thinking about the idea of “the quotidian web”, learning from the bottom half of the long tail of user-generated media so we can understand what most creators are doing with these tools, not just from the most successful influencers. But I’m going to limit myself to the question that started this blog post: how big is YouTube?</p>
<p><img decoding="async" src="https://ethanzuckerman.com/wp-content/2023/12/Screenshot-2023-12-22-at-12.18.43?PM-1.png" alt="" width="1" height="1"><img decoding="async" fetchpriority="high" src="https://ethanzuckerman.com/wp-content/2023/12/tubestats-1024x758.jpg" alt="" width="1024" height="758" srcset="https://ethanzuckerman.com/wp-content/2023/12/tubestats-1024x758.jpg 1024w, https://ethanzuckerman.com/wp-content/2023/12/tubestats-600x444.jpg 600w, https://ethanzuckerman.com/wp-content/2023/12/tubestats-150x111.jpg 150w, https://ethanzuckerman.com/wp-content/2023/12/tubestats-768x569.jpg 768w, https://ethanzuckerman.com/wp-content/2023/12/tubestats.jpg 1334w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Consider drunk dialing again. Let’s assume you only dial numbers in the 413 area code: 413-000-0000 through 413-999-9999. That’s 10,000,000 possible numbers. If one in 100 phone calls connect, you can estimate that 100,000 people have numbers in the 413 area code. In our case, our drunk dials tried roughly 32k numbers at the same time, and we got a “hit” every 50,000 times or so. Our current estimate for the size of YouTube is 13.325 billion videos – we are now updating this number every few weeks at <a href="https://tubestats.org/">tubestats.org</a>.</p>
<p>Once you’re collecting these random videos, other statistics are easy to calculate. We can look at how old our random videos are and calculate how fast YouTube is growing: we estimate that over 4 billion videos were posted to YouTube just in 2023. We can calculate the mean and median views per video, and show just how long the “long tail” is – videos with 10,000 or more videos are roughly 4% of our data set, though they represent the lion’s share of views of the YouTube platform. </p>
<p>Perhaps the most important thing we did with our set of random videos is to demonstrate a vastly better way of studying YouTube than drunk dialing. We know our method is random because it iterates through the entire possible address space. By comparing our results to other ways of generating lists of YouTube videos, we can declare them “plausibly random” if they generate similar results. Fortunately, one method does – it was <a href="https://dl.acm.org/doi/10.1145/2068816.2068851">discovered by Jia Zhou et. al. in 2011</a>, and it’s far more efficient than our naïve method. (You generate a five character string where one character is a dash – YouTube will autocomplete those URLs and spit out a matching video if one exists.) Kevin now polls YouTube using the “dash method” and uses the results to maintain our dashboard at Tubestats. </p>
<p>We have lots more research coming out from this data set, both about what we’re discovering and about some complex ethical questions about how to handle this data. (Most of the videos we’re discovering were only seen by a few dozen people. If we publish those URLs, we run the risk of exposing to public scrutiny videos that are “public” but whose authors could reasonably expect obscurity. Thus our paper does not include the list of videos discovered.) <a href="https://publicinfrastructure.org/2023/12/21/notes-from-random-youtube-coding/">Ryan has a great introduction to main takeaways from our hand-coding</a>. He and I are both working on longer writing about the weird world of random videos – what can we learn from spending time deep in the long tail? </p>
<p>Perhaps most importantly, we plan to maintain <a href="https://tubestats.org/">Tubestats</a> so long as we can. It’s possible that YouTube will object to the existence of this resource or the methods we used to create it. Counterpoint: I believe that high level data like this should be published regularly for all large user-generated media platforms. These platforms are some of the most important parts of our digital public sphere, and we need far more information about what’s on them, who creates this content and who it reaches.</p>
<p>Many thanks to the Journal for Quantitative Description of publishing such a large and unwieldy paper – it’s 85 pages! Thanks and congratulations to all authors: Ryan McGrady, Kevin Zheng, Rebecca Curran, Jason Baumgartner and myself. And thank you to everyone who’s funded our work: the Knight Foundation has been supporting a wide range of our work on studying extreme speech on social media, and other work in our lab is supported by the Ford Foundation and the MacArthur Foundation.</p>
<p>Finally – I’ve got COVID, so if this post is less coherent than normal, that’s to be expected. Feel free to use the comments to tell me what didn’t make sense and I will try to clear it up when my brain is less foggy.</p>
</div>

			</article>
			
		</div>
</main><!--/.neve-main-->




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Groqchat (143 pts)]]></title>
            <link>https://chat.groq.com/</link>
            <guid>38739199</guid>
            <pubDate>Fri, 22 Dec 2023 22:03:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chat.groq.com/">https://chat.groq.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38739199">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky makes web view public, login no longer required to read posts (260 pts)]]></title>
            <link>https://bsky.app/profile/bsky.app/post/3kh5rbndrjd2x</link>
            <guid>38739130</guid>
            <pubDate>Fri, 22 Dec 2023 21:56:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/bsky.app/post/3kh5rbndrjd2x">https://bsky.app/profile/bsky.app/post/3kh5rbndrjd2x</a>, See on <a href="https://news.ycombinator.com/item?id=38739130">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Google search overwhelmed by spam attack (264 pts)]]></title>
            <link>https://www.searchenginejournal.com/google-search-overwhelmed-by-massive-spam-attack/504527/</link>
            <guid>38738619</guid>
            <pubDate>Fri, 22 Dec 2023 21:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.searchenginejournal.com/google-search-overwhelmed-by-massive-spam-attack/504527/">https://www.searchenginejournal.com/google-search-overwhelmed-by-massive-spam-attack/504527/</a>, See on <a href="https://news.ycombinator.com/item?id=38738619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="narrow-cont"><p><a href="https://www.searchenginejournal.com/serp-search-engine-results-page-features-guide/377094/">Google’s search results</a> have been hit by a spam attack for the past few days in what can only be described as completely out of control. Many domains are ranking for hundreds of thousands of keywords each, an indication that the scale of this attack could easily reach into the millions of keyword phrases.</p>
<p><strong>Updated:</strong><br>
The spam was initially discovered by Lily Ray:</p>
<blockquote id="tweet-1737499776386576538" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">If you currently Google "craigslist used auto parts," every single result in the top 20 is spam, minus the first two results from Craigslist.</p>
<p>— Lily Ray 😏 (@lilyraynyc) <a href="https://twitter.com/lilyraynyc/status/1737499776386576538?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">December 20, 2023</a></p></blockquote>

<p>Surprisingly, <a href="https://www.searchenginejournal.com/google-what-to-do-about-spammy-links-from-malicious-domains/449215/">many of the domains</a> have only been registered within the past 24-48 hours.</p>
<p>This recently came to my attention from a series of posts by Bill Hartzer (<a href="https://www.linkedin.com/in/bhartzer/" target="_blank" rel="noopener">LinkedIn profile</a>) where he published a <a href="https://www.searchenginejournal.com/link-graphs-and-google-rankings/435688/">link graph</a> generated by the Majestic backlinks tool that exposed the link networks of several of the spam sites.</p>
<p>The link graph that he posted showed scores of websites tightly <a href="https://www.searchenginejournal.com/seo-internal-links-best-practices/214886/">interlinking</a> with each other, which is a fairly typical pattern for <a href="https://www.searchenginejournal.com/link-building-guide/bad-links-risky-tactics/">spammy link</a> networks.</p>
<h3>Screenshot Of Tightly Interlinked Network</h3>
<p><img fetchpriority="high" decoding="async" src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/link-network-65841b421292a-sej.jpg" alt="Google Search Overwhelmed By Massive Spam Attack" width="500" height="618" sizes="(max-width: 500px) 100vw, 500px" data-srcset="https://www.searchenginejournal.com/wp-content/uploads/2023/12/link-network-65841b421292a-sej.jpg 500w, https://www.searchenginejournal.com/wp-content/uploads/2023/12/link-network-65841b421292a-sej-480x593.jpg 480w" data-src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/link-network-65841b421292a-sej.jpg" srcset="https://www.searchenginejournal.com/wp-content/uploads/2023/12/link-network-65841b421292a-sej.jpg 500w, https://www.searchenginejournal.com/wp-content/uploads/2023/12/link-network-65841b421292a-sej-480x593.jpg 480w"><span>Image by Bill Hartzer via Majestic</span></p>
<p>Bill and I talked about the spam sites over Facebook messenger and we both agreed that although the spammers put a lot of work into creating a backlink network, the links weren’t actually responsible for the high rankings.</p>
<p><strong>Bill said:</strong></p>
<blockquote><p>“This, in my opinion, is partly the fault of Google, who appears to be putting more emphasis on content rather than links.”</p></blockquote>
<p>I agree 100% that Google is putting more emphasis on content than links. But my thoughts are that the <a href="https://www.searchenginejournal.com/link-building-guide/bad-links-risky-tactics/">spam links</a> are there so that Googlebot can discover the spam pages and index them, even if just for one or two days.</p>
<p>Once indexed the spam pages are likely exploiting what I consider two loopholes in <a href="https://www.searchenginejournal.com/google-algorithm-history/">Google’s algorithms</a>, which I talk about next.</p>
<h2>Out of Control Spam in Google SERPs</h2>
<p>Multiple sites are ranking for longtail phrases that are somewhat easy to rank, as well as phrases with a local search component, which are also easy to rank.</p>
<p>Longtail phrases are keyword phrases that are used by people but exceedingly rarely. Longtail is a concept that’s been around for almost twenty years and subsequently popularized by a 2006 book called The Long Tail: Why the Future of Business is Selling Less of More.</p>
<p>Spammers are able to rank for these rarely searched phrases because there is little competition for those phrases, which makes it easy to rank.</p>
<p>So if a spammer creates millions of pages of longtail phrases those pages can then rank for hundreds of thousands of keywords every day in a short period of time.</p>
<p>Companies like Amazon use the principle of the longtail to sell hundreds of thousands of individual products a day which is different than selling one product hundreds of thousands of times per day.</p>
<p>That’s what the spammers are exploiting, the ease of ranking for <a href="https://www.searchenginejournal.com/keyword-research/long-tail-keywords/">longtail phrase</a>s.</p>
<p>The second thing that the spammers are exploiting is the loophole that’s inherent in Local Search.</p>
<p>The local search algorithm is not the same as the algorithm for ranking non-local keywords.</p>
<p>The examples that have come to light are variations of Craigslist and related keywords.</p>
<p>Examples are phrases like <em>Craigslist auto parts</em>, <em>Craigslist rooms to rent</em>, <em>Craigslist for sale by owner</em> and thousands of other keywords, most of which don’t use the word Craigslist.</p>
<p>The scale of the spam is huge and it goes far beyond than keywords with the word “Craigslist” in it.</p>
<h2>What The Spam Page Looks Like</h2>
<p>Taking a look at what the spam page looks like is impossible by visiting the pages with a browser.</p>
<p>I tried to see the source code of the sites that rank in Google but all of the spam sites automatically redirect to another domain.</p>
<p>I next entered the spam URL into the <a href="https://www.searchenginejournal.com/w3c-validator-guide/437030/">W3C</a> link checker to visit the website but the W3C bot couldn’t see the site either.</p>
<p>So I changed my browser user agent to identify itself as Googlebot but the spam site still redirected me.</p>
<p>That indicated that the site was not checking if the user agent was Googlebot.</p>
<p>The spam site was checking for Googlebot IP addresses. If the visitor’s IP address matched as belonging to Google then the spam page displayed content to Googlebot.</p>
<p>All other visitors got a redirect to other domains that displayed sketchy content.</p>
<p>In order to see the <a href="https://www.searchenginejournal.com/google-valid-html/258881/">HTML</a> of the website I had to visit with a Google IP address. So I used Google’s Rich Results tester to visit the spam site and record the HTML of the page.</p>
<p>I showed Bill Hartzer how to extract the HTML by using the Rich Results tester and he immediately went off to tweet about it, lol. Dang!</p>
<p>The Rich Results Tester has an option to show the HTML of a webpage. So copied the HTML, pasted it into a text file then saved it it as an HTML file.</p>
<h3>Screenshot Of HTML Provided By Rich Results Tool</h3>
<p><img src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/screenshot-html-658423275fce1-sej.jpg" alt="Google Search Overwhelmed By Massive Spam Attack" data-old-src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20400%20473%22%3E%3C/svg%3E" data-src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/screenshot-html-658423275fce1-sej.jpg"></p>
<p>I next edited the HTML file to remove any JavaScript then saved the file again.</p>
<p><strong>I was now able to see what the webpage looks like to Google:</strong></p>
<h3>Screenshot Of Spam Webpage</h3>
<p><img src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/screenshot-of-spam-page-65841ab85e154-sej.png" alt="Screenshot of a spam webpage that ranks in Google" data-old-src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20447%20644%22%3E%3C/svg%3E" data-src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/screenshot-of-spam-page-65841ab85e154-sej.png"></p>
<h2>One Domain Ranks For 300,000+ Keywords</h2>
<p>Bill sent me a spreadsheet containing a list of keyword phrases that just one of the spam sites ranked for. One spam site, just one of them, ranked for over 300,000 keyword phrases.</p>
<h3>Screenshot Showing Keywords For One Domain</h3>
<p><img src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/screenshot-spreadsheet-65841a432f6d1-sej.png" alt="Image showing a closeup of a spreadsheet with keyword phrases on it" data-old-src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20320%20420%22%3E%3C/svg%3E" data-src="https://www.searchenginejournal.com/wp-content/uploads/2023/12/screenshot-spreadsheet-65841a432f6d1-sej.png"></p>
<p>There were a lot of Craigslist keyword phrases but there were also other longtail phrases, many of which contained a local search element. As I mentioned, it’s easy to rank for longtail phrases, easy to rank for local search phrases and combine the two kinds of phrases and it’s really easy to rank for these keyword phrases.</p>
<h2>Why Does This Spam Technique Work?</h2>
<p><a href="https://www.searchenginejournal.com/local-seo/what-is-local-seo-why-local-search-is-important/">Local search</a> uses a different algorithm than the non-local algorithm. For example, a local site, in general, doesn’t need a lot of links to rank for a query. The pages just need the right kinds of keywords to trigger a local search algorithm and rank it for a geographic area.</p>
<p>So if you search for “Craigslist auto parts” that’s going to trigger the local search algorithm and because it’s longtail it’s not going to take too much to rank it.</p>
<p>This is an ongoing problem for many years. Several years ago a website was able to rank for “Rhinoplasty Plano, Texas” with a site that contained old Roman Latin content and headings in English. Rhinoplasty is a longtail local search and Plano, Texas is a relatively small town. Ranking for that Rhinoplasty keyword phrase was so easy that the latin language website was able to easily rank for it.</p>
<p>Google has known about this spam problem since at least December 19th, as acknowledged in a tweet by Danny Sullivan.</p>
<blockquote id="tweet-1737236506190987682" data-width="550" data-dnt="true">
<p lang="en" dir="ltr">Yes, I already passed that one on to the search team. Here’s a peek. And it’s being looked at. <a href="https://t.co/vJH3EisnXD" target="_blank" rel="noopener">pic.twitter.com/vJH3EisnXD</a></p>
<p>— Google SearchLiaison (@searchliaison) <a href="https://twitter.com/searchliaison/status/1737236506190987682?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">December 19, 2023</a></p></blockquote>

<p>It will be interesting to see if Google finally after all this time figures out a way to combat this kind of spam.</p>
<p><em>Featured Image by Shutterstock/Kateryna Onyshchuk</em></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shitflation, shrinkflation, inflation database (118 pts)]]></title>
            <link>https://jonatron.github.io/shitflation/</link>
            <guid>38737113</guid>
            <pubDate>Fri, 22 Dec 2023 18:42:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonatron.github.io/shitflation/">https://jonatron.github.io/shitflation/</a>, See on <a href="https://news.ycombinator.com/item?id=38737113">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <tr>
          <td>Tesco Tomato &amp; Basil Sauce For Meatballs 500G</td>
          <td>July 2014</td>
          <td><b>Tomato (73%)</b>, Tomato Purée (14%), Onion, Lemon Juice From Concentrate, Sugar, Basil (1.5%), Olive Oil, Salt, Garlic Purée, Citric Acid, Oregano, Firming Agent (Calcium Chloride), Black Pepper</td>
          <td>£1.19</td>
          <td><a href="https://web.archive.org/web/20140730081247/http://www.tesco.com/groceries/product/details/?id=277081824">Archive</a></td>
        </tr>
        <tr>
          <td>Tesco Tomato &amp; Basil Sauce For Meatballs 500G</td>
          <td>Dec 2023</td>
          <td>INGREDIENTS: <b>Tomato (46%)</b>, Partially Reconstituted Tomato Purée (43%), Onion, Herbs (1.5%) (Basil, Oregano), Sugar, Cornflour, Salt, Garlic Purée, Concentrated Lemon Juice, Acidity Regulator (Citric Acid), Black Pepper.</td>
          <td>£0.95</td>
          <td><a href="https://web.archive.org/web/20230130072741/https://www.tesco.com/groceries/en-GB/products/277081824">Archive</a></td>
          <td>Shit, De</td>
        </tr>
        <tr>
          <td>Tesco Finest Smoked Wiltshire Cure Back Bacon 240G</td>
          <td>Oct 2014</td>
          <td><b>Pork (90%)</b>, Water, Salt, Preservatives (Sodium Nitrite, Potassium Nitrate)</td>
          <td>£3.29</td>
          <td><a href="https://web.archive.org/web/20141001040111/http://www.tesco.com/groceries/product/details/?id=275174361">Archive</a></td>
        </tr>
        <tr>
          <td>Tesco Finest Smoked Wiltshire Cure Back Bacon 240G</td>
          <td>Dec 2023</td>
          <td>INGREDIENTS: <b>Pork (89%)</b>, Water, Salt, Preservatives (Potassium Nitrate, Sodium Nitrite).</td>
          <td>£3.50</td>
          <td><a href="https://web.archive.org/web/20221204182102/https://www.tesco.com/groceries/en-GB/products/259703198">Archive</a></td>
          <td>Shit, In</td>
        </tr>
        <tr>
          <td>Tesco Chicken Tikka Masala &amp; Pilau Rice 550G</td>
          <td>Dec 2014</td>
          <td>Cooked Pilau Rice, <b>Marinated Chicken (26%)</b>, Onion, Single Cream (Milk) (10%), Tomato Purée, Yogurt (Milk), Rapeseed Oil, Garlic Purée, Ginger Purée, Ground Cashew Nut, Honey, Butter (Milk), Cashew Nut Paste, Spices, Coriander Leaf, Sugar, Tandoori Masala, Salt,

Cooked Pilau Rice contains: Basmati Rice, Water, Rapeseed Oil, Salt, Concentrated Lemon Juice, Cumin Seed, Cardamom Pods, Colour (Curcumin), Cardamom, Ground Bay Leaf,

Marinated Chicken contains: Chicken Breast, Water, Tomato Purée, Ginger Purée, Palm Oil, Soya Oil, Garlic Purée, Yogurt Powder (Milk), Cornflour, Salt, Spices, Green Chilli, Colour (Paprika Extract), Sunflower Oil, Sugar, Cashew Nut Paste contains: Cashew Nut, Rapeseed Oil, Tandoori Masala contains: Paprika, Salt, Coriander Powder, Turmeric Powder, Chilli Powder, Cumin Powder, Cinnamon, Clove Powder, Lemon Oil, Black Pepper, Bay Leaf, Colour (Paprika Extract)
          </td>
          <td>£3.30</td>
          <td><a href="https://web.archive.org/web/20141203131159/http://www.tesco.com/groceries/product/details/?id=262805275">Archive</a></td>
        </tr>
        <tr>
          <td>Tesco Chicken Tikka Masala Meal For 1 500G</td>
          <td>Dec 2023</td>
          <td>INGREDIENTS: Cooked Pilau Rice [
    Water, Basmati Rice, Rapeseed Oil, Salt, Concentrated Lemon Juice, Cumin Seed, Colour (Curcumin), Cardamom Pods, Cardamom Powder, Ground Bay Leaf
], <b>Cooked Marinated Chicken (14%)</b> [
    Chicken, Tomato Purée, Ginger Purée, Garlic Purée, Cornflour, Water, Salt, Soya Oil, Yogurt Powder (Milk), Green Chilli Purée, Palm Oil, Chilli Powder, Yogurt (Milk), Skimmed Milk, Coriander Powder, Cumin Powder, Colour (Paprika Extract), Ginger Powder, Cinnamon, Black Pepper, Mace, Fenugreek, Star Anise, Turmeric, Basil
], Onion,
Onion Bhaji [
    Onion, Gram Flour, Rapeseed Oil, Coriander, Coriander Powder, Cumin Powder, Raising Agents (Disodium Diphosphate, Sodium Bicarbonate), Red Chilli Purée, Cayenne Pepper, Onion Seed, Rice Flour, Salt, Turmeric Powder
], Potato, Single Cream (Milk), Tomato, Tomato Purée, Yogurt (Milk), Rapeseed Oil, Tomato Juice, Garlic Purée, Ginger Purée, Water, Ground (Cashew Nut), Sugar, Honey, Butter (Milk), Coriander Leaf, Coriander Powder, Green Chilli, Cashew Nut, Salt, Cumin Powder, Cornflour, Turmeric, Paprika, Curry Leaves, Cumin Seed, Black Mustard Seed, Black Pepper, Cinnamon, Clove Powder, Chilli Powder, Cardamom Powder, Fennel, Bay Leaf, Lemon Oil, Colour (Paprika Extract).
          </td>
          <td>£4.00</td>
          <td><a href="https://web.archive.org/web/20230324135914/https://www.tesco.com/groceries/en-GB/products/312088891">Archive</a></td>
          <td>Shit, Shrink, In</td>
        </tr>
        <tr>
          <td>Tesco Italian Macaroni Cheese Pasta 450G</td>
          <td>Oct 2014</td>
          <td>Cooked Pasta, Milk, <b>Mature Cheddar Cheese (Milk) (16%)</b>, Water, Single Cream (Milk), Wheat Flour (Wheat Flour, Calcium Carbonate, Iron, Niacin, Thiamin), Rapeseed Oil, Cornflour, Salt, White Pepper, Mustard Powder, Cooked Pasta contains: Durum Wheat Semolina, Water</td>
          <td>£2.30</td>
          <td><a href="https://web.archive.org/web/20141005051457/http://www.tesco.com/groceries/product/details/?id=275153841">Archive</a></td>
        </tr>
        <tr>
          <td>Tesco Macaroni Cheese 400G</td>
          <td>Dec 2023</td>
          <td>INGREDIENTS: Cooked Pasta [Water, Durum Wheat Semolina], Whole Milk, <b>Water, Mature Cheddar Cheese (Milk) (13%), Cornflour</b>, Medium Fat Soft Cheese (Milk), Wheat Flour [Wheat Flour, Calcium Carbonate, Iron, Niacin, Thiamin], Natural Cream Flavouring (contains Milk), Salt, Cheddar Cheese (Milk), Butter (Milk), Mustard Seed, Spirit Vinegar, Whey (Milk).</td>
          <td>£3.25</td>
          <td><a href="https://www.tesco.com/groceries/en-GB/products/310167622">Tesco</a>
            <br><a href="https://jonatron.github.io/shitflation/screenshots/Screenshot%202023-12-22%20at%2019-44-35%20Tesco%20Macaroni%20Cheese%20400G.png">Screenshot</a></td>
          <td>Shit, Shrink, In</td>
        </tr>
        <tr>
          <td>Tesco Mayonnaise 500Ml</td>
          <td>Oct 2014</td>
          <td><b>Vegetable Oil (77%)</b>, Water, <b>Free Range Pasteurised Whole Egg &amp; Egg Yolk (8%)</b>, Lemon Juice From Concentrate, Spirit Vinegar, Salt, Sugar, Stabiliser (Xanthan Gum), Natural Flavouring (contains Mustard)</td>
          <td>£0.89</td>
          <td><a href="https://web.archive.org/web/20141013070251/http://www.tesco.com/groceries/product/details/?id=254884543">Arcive</a></td>
        </tr>
        <tr>
          <td>Tesco Mayonnaise 500Ml</td>
          <td>Dec 2023</td>
          <td><b>Rapeseed Oil (75%)</b>, Water, <b>Pasteurised Egg Yolk (7%)</b>, Spirit Vinegar, Sugar, Salt, <b>Modified Maize Starch</b>, Concentrated Lemon Juice, Flavouring (contains Mustard).</td>
          <td>£1.20</td>
          <td><a href="https://web.archive.org/web/20231123163709/https://www.tesco.com/groceries/en-GB/products/309197604">Archive</a></td>
          <td>Shit, In</td>
        </tr>
        <tr>
          <td>Jacob's Baked Original Mini Cheddars 12x25g</td>
          <td>Jul 2014</td>
          <td>Flour (Wheat Flour, Calcium, Iron, Niacin, Thiamin), Vegetable Oils (Palm, Sunflower), <b>Dried Cheese (12%)</b> (Milk) [Dried Powdered Cheese (Milk), Natural Flavouring, Yeast Extract (Barley)], Sugar, Glucose Syrup, Salt, Dried Whey (Milk), Barley Malt Extract, Raising Agents (Ammonium Bicarbonate, Sodium Bicarbonate), Lactic Acid, Natural Flavourings, May also contain Egg, Soya</td>
          <td>£2.00</td>
          <td><a href="https://web.archive.org/web/20140715052224/http://www.sainsburys.co.uk/shop/gb/groceries/crisps/mini-cheddars-12x25g">Archive</a></td>
        </tr>
        <tr>
          <td>Jacob's Mini Cheddars Original Baked Snacks Multipack 6x23g</td>
          <td>Dec 2023</td>
          <td>Flour (Wheat Flour, Calcium, Iron, Niacin, Thiamin), Vegetable Oils (Palm, Sunflower), <b>Dried Cheese (10%)</b> (Milk) [Dried Powdered Cheese (Milk), Natural Flavouring], Sugar, Glucose Syrup, Salt, Dried Whey (Milk), Barley Malt Extract, Raising Agents (Ammonium Bicarbonate, Sodium Bicarbonate), Acid (Lactic Acid), Natural Flavourings </td>
          <td>£1.75</td>
          <td><a href="https://www.sainsburys.co.uk/gol-ui/product/mcvities-mini-cheddars-7x25g">Sainsbury's</a>
            <br><a href="https://jonatron.github.io/shitflation/screenshots/Screenshot%202023-12-22%20at%2021-37-13%20Jacob's%20Mini%20Cheddars%20Original%20Baked%20Snacks%20Multipack%206x23g%20Sainsbury's.png">Screenshot</a></td>
          <td>Shit, Shrink, In</td>
        </tr>

        <!-- 
        <tr>
          <td>Product</td>
          <td>Date</td>
          <td>Ingredients</td>
          <td>Price</td>
          <td>Link</td>
        </tr>
        <tr>
          <td>Product</td>
          <td>Date</td>
          <td>Ingredients</td>
          <td>Price</td>
          <td>Link</td>
        </tr>
 -->
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WebGPU now available for testing in Safari Technology Preview (201 pts)]]></title>
            <link>https://webkit.org/blog/14879/webgpu-now-available-for-testing-in-safari-technology-preview/</link>
            <guid>38737028</guid>
            <pubDate>Fri, 22 Dec 2023 18:34:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webkit.org/blog/14879/webgpu-now-available-for-testing-in-safari-technology-preview/">https://webkit.org/blog/14879/webgpu-now-available-for-testing-in-safari-technology-preview/</a>, See on <a href="https://news.ycombinator.com/item?id=38737028">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-14879">
            
            

            <div>
                                
                <p><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API">WebGPU</a> is a new <a href="https://www.w3.org/TR/webgpu/">standards-compliant</a> API that enables high-performance 3D graphics and general-purpose <a href="https://en.wikipedia.org/wiki/Data_parallelism">computations</a> on the Web. WebGPU programs are written in JavaScript but expose GPU functionality, allowing GPU computing to be used in Web content for the first time. Starting in <a href="https://developer.apple.com/safari/technology-preview/">Safari Technology Preview</a> 185, WebGPU can be enabled for early testing and development.</p>
<p>To enable WebGPU, turn on the “WebGPU”, “GPU Process: DOM Rendering” and “GPU Process: Canvas Rendering” feature flags in the <a href="https://developer.apple.com/documentation/safari-developer-tools/feature-flag-settings">Feature Flags</a> tab in Safari Preferences. If you don’t see the Feature Flags tab, you need to first check “<a href="https://developer.apple.com/documentation/safari-developer-tools/enabling-developer-features">Show features for web developers</a>” in the Advanced tab.</p>
<p>Once you have WebGPU enabled in Safari Technology Preview 185, <a href="https://webgpu.github.io/webgpu-samples/samples/particles">try out this example of WebGPU</a>. It utilizes many of the best features of WebGPU.</p>
<figure><video autoplay="" loop="" muted="" src="https://webkit.org/blog-files/webgpu-particles.mov"></video></figure>
<h2>WebGPU JavaScript API</h2>
<p>The WebGPU API is accessed through JavaScript, similar to WebGL.</p>
<h3>Creating a GPUDevice</h3>
<p>In order to use WebGPU, a device must be created. Resources and pipeline state are created from a <code>GPUDevice</code> instance. To create a device with default limits and features which are supported on all devices supporting WebGPU, we can pass zero parameters to the invocations of <code>requestAdapter</code> and <code>requestDevice</code>.</p>
<pre><code><span>const</span> <span>adapter</span> <span>=</span> <span>await</span> <span>navigator</span>.<span>gpu</span>.<span>requestAdapter</span>();
<span>device</span> <span>=</span> <span>await</span> <span>adapter</span>.<span>requestDevice</span>();
</code></pre>
<h3>Configuring a GPUCanvasContext</h3>
<p>The <code>GPUCanvasContext</code> is an interface that allows you to configure how your content will be displayed in the corresponding <code>HTMLCanvas</code> element on the page.</p>
<pre><code><span>context</span> <span>=</span> <span>canvas</span>.<span>getContext</span>(<span>'webgpu'</span>);
<span>const</span> <span>canvasFormat</span> <span>=</span> <span>"bgra8unorm"</span>;

<span>const</span> <span>contextConfiguration</span> <span>=</span> {
    <span>device</span><span>:</span> <span>device</span>,
    <span>format</span><span>:</span> <span>canvasFormat</span>,
    <span>alphaMode</span><span>:</span> <span>'opaque'</span>,
};
<span>context</span>.<span>configure</span>(<span>contextConfiguration</span>);
</code></pre>
<h3>Creating a GPURenderPipeline</h3>
<p>A <code>GPURenderPipeline</code> or a corresponding <code>GPUComputePipeline</code> are used to configure the pipeline state of the graphics driver. This pipeline state is then used in a <code>GPURenderPassEncoder</code> or <code>GPUComputePassEncoder</code> as later illustrated.</p>
<pre><code><span>const</span> <span>shaderModule</span> <span>=</span> <span>device</span>.<span>createShaderModule</span>({ <span>code</span><span>:</span> <span>wgslSource</span> });
<span>const</span> <span>vertexStageDescriptor</span> <span>=</span> { <span>module</span><span>:</span> <span>shaderModule</span>, <span>entryPoint</span><span>:</span> <span>"vsmain"</span> };
<span>const</span> <span>fragmentStageDescriptor</span> <span>=</span> { <span>module</span><span>:</span> <span>shaderModule</span>, <span>entryPoint</span><span>:</span> <span>"fsmain"</span> };
<span>const</span> <span>renderPipelineDescriptor</span> <span>=</span> {
    <span>layout</span><span>:</span> <span>'auto'</span>,
    <span>vertex</span><span>:</span> <span>vertexStageDescriptor</span>,
    <span>fragment</span><span>:</span> <span>fragmentStageDescriptor</span>,
    <span>primitive</span><span>:</span> {<span>topology</span><span>:</span> <span>"triangle-list"</span> },
};
<span>const</span> <span>renderPipeline</span> <span>=</span> <span>device</span>.<span>createRenderPipeline</span>(<span>renderPipelineDescriptor</span>);
</code></pre>
<h3>Issuing draw calls</h3>
<p>A <code>GPURenderPassEncoder</code> is created to send draw calls to the graphics driver. In the below example, we draw a simple triangle which contains three vertices. A <code>GPURenderPassEncoder</code> can also draw multiple instances of the same geometry or draw from an offset of a vertex buffer.</p>
<pre><code><span>const</span> <span>colorAttachmentDescriptor</span> <span>=</span> {
    <span>view</span><span>:</span> <span>renderAttachment</span>,
    <span>loadOp</span><span>:</span> <span>"clear"</span>,
    <span>storeOp</span><span>:</span> <span>"store"</span>,
    <span>clearColor</span><span>:</span> { <span>r</span><span>:</span> <span>0.15</span>, <span>g</span><span>:</span> <span>0.15</span>, <span>b</span><span>:</span> <span>0.5</span>, <span>a</span><span>:</span> <span>1</span> }
};
<span>const</span> <span>renderPassDescriptor</span> <span>=</span> { <span>colorAttachments</span><span>:</span> [<span>colorAttachmentDescriptor</span>] };
<span>const</span> <span>commandEncoder</span> <span>=</span> <span>device</span>.<span>createCommandEncoder</span>();
<span>const</span> <span>renderPassEncoder</span> <span>=</span> <span>commandEncoder</span>.<span>beginRenderPass</span>(<span>renderPassDescriptor</span>);
<span>renderPassEncoder</span>.<span>setPipeline</span>(<span>renderPipeline</span>);
<span>const</span> <span>vertexBufferSlot</span> <span>=</span> <span>0</span>;
<span>renderPassEncoder</span>.<span>setVertexBuffer</span>(<span>vertexBufferSlot</span>, <span>vertexBuffer</span>, <span>0</span>);
<span>renderPassEncoder</span>.<span>draw</span>(<span>3</span>, <span>1</span>, <span>0</span>, <span>0</span>); <span>// 3 vertices, 1 instance, 0th vertex, 0th instance.
</span><span>renderPassEncoder</span>.<span>end</span>();
<span>const</span> <span>commandBuffer</span> <span>=</span> <span>commandEncoder</span>.<span>finish</span>();
<span>const</span> <span>queue</span> <span>=</span> <span>device</span>.<span>queue</span>;
<span>queue</span>.<span>submit</span>([<span>commandBuffer</span>]);
</code></pre>
<h2>WebGPU Shading Language</h2>
<p>WebGPU introduces WGSL, a platform independent shading language for the web. Here is an example of a WGSL shader source that would be passed in place of <code>wgslSource</code> in the above API call:</p>
<pre><code><span>const</span> <span>wgslSource</span> <span>=</span> `
    <span>struct</span> <span>Vertex</span> {
        @<span>builtin</span>(<span>position</span>) <span>Position</span><span>:</span> <span>vec4</span><span>&lt;</span><span>f32</span><span>&gt;</span>,
        @<span>location</span>(<span>0</span>) <span>color</span><span>:</span> <span>vec4</span><span>&lt;</span><span>f32</span><span>&gt;</span>,
    }

    @<span>vertex</span> <span>fn</span> <span>vsmain</span>(@<span>builtin</span>(<span>vertex_index</span>) <span>VertexIndex</span><span>:</span> <span>u32</span>) <span>-</span><span>&gt;</span> <span>Vertex</span>
    {
        <span>var</span> <span>pos</span><span>:</span> <span>array</span><span>&lt;</span><span>vec2</span><span>&lt;</span><span>f32</span><span>&gt;</span>, <span>3</span><span>&gt;</span> <span>=</span> <span>array</span><span>&lt;</span><span>vec2</span><span>&lt;</span><span>f32</span><span>&gt;</span>, <span>3</span><span>&gt;</span>(
            <span>vec2</span><span>&lt;</span><span>f32</span><span>&gt;</span>( <span>0.0</span>,  <span>0.5</span>),
            <span>vec2</span><span>&lt;</span><span>f32</span><span>&gt;</span>(<span>-</span><span>0.5</span>, <span>-</span><span>0.5</span>),
            <span>vec2</span><span>&lt;</span><span>f32</span><span>&gt;</span>( <span>0.5</span>, <span>-</span><span>0.5</span>));
        <span>var</span> <span>vertex_out</span> <span>:</span> <span>Vertex</span>;
        <span>vertex_out</span>.<span>Position</span> <span>=</span> <span>vec4</span><span>&lt;</span><span>f32</span><span>&gt;</span>(<span>pos</span>[<span>VertexIndex</span>], <span>0.0</span>, <span>1.0</span>);
        <span>vertex_out</span>.<span>color</span> <span>=</span> <span>vec4</span><span>&lt;</span><span>f32</span><span>&gt;</span>(<span>pos</span>[<span>VertexIndex</span>] <span>+</span> <span>vec2</span><span>&lt;</span><span>f32</span><span>&gt;</span>(<span>0.5</span>, <span>0.5</span>), <span>0.0</span>, <span>1.0</span>);
        <span>return</span> <span>vertex_out</span>;
    }

    @<span>fragment</span> <span>fn</span> <span>fsmain</span>(<span>in</span><span>:</span> <span>Vertex</span>) <span>-</span><span>&gt;</span> @<span>location</span>(<span>0</span>) <span>vec4</span><span>&lt;</span><span>f32</span><span>&gt;</span>
    {
        <span>return</span> <span>in</span>.<span>color</span>;
    }
`;
</code></pre>
<h2>Try WebGPU and file bugs!</h2>
<p>We’re very excited to have an early version of WebGPU and WGSL in the latest version of Safari Technology Preview. Please do try it out. Check out the <a href="https://webgpu.github.io/webgpu-samples/samples/helloTriangle">public repository of WebGPU samples</a>. And file bugs or issues you discover at <a href="http://bugs.webkit.org/">bugs.webkit.org</a>.</p>

                            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Granting Pardon for the Offense of Simple Possession of or Use of Marijuana (299 pts)]]></title>
            <link>https://www.whitehouse.gov/briefing-room/presidential-actions/2023/12/22/a-proclamation-on-granting-pardon-for-the-offense-of-simple-possession-of-marijuana-attempted-simple-possession-of-marijuana-or-use-of-marijuana/</link>
            <guid>38736919</guid>
            <pubDate>Fri, 22 Dec 2023 18:22:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/12/22/a-proclamation-on-granting-pardon-for-the-offense-of-simple-possession-of-marijuana-attempted-simple-possession-of-marijuana-or-use-of-marijuana/">https://www.whitehouse.gov/briefing-room/presidential-actions/2023/12/22/a-proclamation-on-granting-pardon-for-the-offense-of-simple-possession-of-marijuana-attempted-simple-possession-of-marijuana-or-use-of-marijuana/</a>, See on <a href="https://news.ycombinator.com/item?id=38736919">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
	


	<div>
								


<div><p>&nbsp; &nbsp; &nbsp;In Proclamation 10467 of October 6, 2022 (Granting Pardon for the Offense of Simple Possession of Marijuana), I exercised my authority under the Constitution to pardon individuals who committed or were convicted of the offense of simple possession of marijuana in violation of the Controlled Substances Act and section 48–904.01(d)(1) of the Code of the District of Columbia (D.C. Code).&nbsp; As I have said before, convictions for simple possession of marijuana have imposed needless barriers to employment, housing, and educational opportunities.&nbsp; Through this proclamation, consistent with the grant of Proclamation 10467, I am pardoning additional individuals who may continue to experience the unnecessary collateral consequences of a conviction for simple possession of marijuana, attempted simple possession of marijuana, or use of marijuana.&nbsp; Therefore, acting pursuant to the grant of authority in Article&nbsp;II, Section 2, of the Constitution of the United States, I, Joseph&nbsp;R. Biden Jr., do hereby grant a full, complete, and unconditional pardon to all current United States citizens and lawful permanent residents who, on or before the date of this proclamation, committed or were convicted of the offense of simple possession of marijuana, attempted simple possession of marijuana, or use of marijuana, regardless of whether they have been charged with or prosecuted for these offenses on or before the date of this proclamation, in violation of:</p><p>(1) &nbsp;section 844 of title 21, United States Code, section 846 of title 21, United States Code, and previous provisions in the United States Code that prohibited simple possession of marijuana or attempted simple possession of marijuana;&nbsp;</p><p>(2) &nbsp;section 48-904.01(d)(1) of the D.C. Code and previous provisions in the D.C. Code that prohibited simple possession of marijuana;</p><p>(3) &nbsp;section 48-904.09 of the D.C. Code and previous provisions in the D.C. Code that prohibited attempted simple possession of marijuana; and</p><p>(4) &nbsp;provisions in the Code of Federal Regulations, including as enforced under the United States Code, that prohibit only the simple possession or use of marijuana on Federal properties or installations, or in other locales, as currently or previously codified, including but not limited to 25 C.F.R. 11.452(a); 32 C.F.R. 1903.12(b)(2); 36 C.F.R. 2.35(b)(2); 36 C.F.R. 1002.35(b)(2); 36 C.F.R. 1280.16(a)(1); 36 C.F.R. 702.6(b); 41 C.F.R. 102-74.400(a); 43 C.F.R. 8365.1-4(b)(2); and 50 C.F.R. 27.82(b)(2).</p></div>



<div><p>&nbsp;&nbsp;&nbsp;&nbsp; My intent by this proclamation is to pardon only the offenses of simple possession of marijuana, attempted simple possession of marijuana, or use of marijuana in violation of the Federal and D.C. laws set forth in paragraphs (1) through (3) of this proclamation, as well as the provisions in the Code of Federal Regulations consistent with paragraph (4) of this proclamation, and not any other offenses involving other controlled substances or activity beyond simple possession of marijuana, attempted simple possession of marijuana, or use of marijuana, such as possession of marijuana with intent to distribute or driving offenses committed while under the influence of marijuana. &nbsp;This pardon does not apply to individuals who were non-citizens not lawfully present in the United States at the time of their offense.</p><p>&nbsp;&nbsp;&nbsp;&nbsp; Pursuant to the procedures in Proclamation 10467, the Attorney General, acting through the Pardon Attorney, shall review all properly submitted applications for certificates of pardon and shall issue such certificates of pardon to eligible applicants in due course.&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp; IN WITNESS WHEREOF, I have hereunto set my hand this twenty-second day of December, in the year of our Lord two&nbsp;thousand&nbsp;twenty-three, and of the Independence of the United&nbsp;States of&nbsp;America the two&nbsp;hundred and forty-eighth.</p></div>



<p>JOSEPH R. BIDEN JR.</p>
			</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Database Isolation Is Broken and You Should Care (117 pts)]]></title>
            <link>https://materializedview.io/p/database-isolation-is-broken-you-should-care</link>
            <guid>38736904</guid>
            <pubDate>Fri, 22 Dec 2023 18:20:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://materializedview.io/p/database-isolation-is-broken-you-should-care">https://materializedview.io/p/database-isolation-is-broken-you-should-care</a>, See on <a href="https://news.ycombinator.com/item?id=38736904">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>This month saw several related posts on </span><a href="https://en.wikipedia.org/wiki/ACID" rel="">ACID</a><span> (</span><a href="https://en.wikipedia.org/wiki/Atomicity_(database_systems)" rel="">atomicity</a><span>, </span><a href="https://en.wikipedia.org/wiki/Consistency_(database_systems)" rel="">consistency</a><span>, </span><a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)" rel="">isolation</a><span>, </span><a href="https://en.wikipedia.org/wiki/Durability_(database_systems)" rel="">durability</a><span>) database properties.</span></p><p><a href="https://www.linkedin.com/in/tony-solomonik-646819121" rel="">Tony Solomonik</a><span> writes a database using </span><a href="https://www.gnu.org/software/bash/" rel="">bash</a><span> in his </span><a href="https://tontinton.com/posts/database-fundementals/" rel="">database fundamentals</a><span> post. bashdb is a fascinating exercise, but also demonstrates why databases are so complex (ACID, fsync, B+ trees, LSMs, consensus, replication, and so on). Start here to brush up on the basics.</span></p><p><span>Next, </span><a href="https://www.linkedin.com/in/gwenshapira/" rel="">Gwen Shapira</a><span>, co-founder of </span><a href="https://www.thenile.dev/" rel="">Nile</a><span> [$], posted </span><a href="https://www.thenile.dev/blog/transaction-isolation-postgres" rel="">Transaction Isolation in Postgres, explained</a><span>. Though the headline says Postres, the post is mostly about database isolation levels (the </span><em>I</em><span> in ACID). She describes the various isolation levels in </span><a href="https://en.wikipedia.org/wiki/SQL-92" rel="">ANSI SQL ‘92</a><span> and shows the edge cases that break them.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png" width="1228" height="534" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:534,&quot;width&quot;:1228,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:87876,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ce5c678-ea0c-4df9-b1d4-20fab2223350_1228x534.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Here’s where things get interesting. Gwen’s post says that there are many anomalies that aren’t classified in the ANSI SQL ‘92 spec.</p><blockquote><p><span>It turned out that defining a perfect state and then defining some states where certain anomalies can happen has this fundamental problem: There may be anomalies you didn't think of. So, only three years after the SQL92 standard came out, a very impressive team of researchers published </span><strong><a href="https://arxiv.org/pdf/cs/0701157.pdf" rel="">A Critique of ANSI SQL Isolation Levels (1995)</a></strong><span>. The paper introduced a whole collection of anomalies that weren't specified in the standard, and therefore were technically allowed at the Serializable level.</span></p></blockquote><p>These new-found anomalies make database isolation ambiguous:</p><blockquote><p>Different databases support different isolation levels, and the same isolation level can mean different things in different databases.</p></blockquote><p><span>This leads to the final post I want to call out: </span><a href="https://jepsen.io/analyses/mysql-8.0.34" rel="">Jepsen’s MySQL Analysis</a><span>. Jepsen is a project run by Kyle Kingsbury alter ego, </span><a href="https://aphyr.com/about" rel="">Aphyr</a><span>. Kyle and his team use Jepsen to break databases. Kyle and </span><a href="https://www.linkedin.com/in/peteralvaro/" rel="">Peter Avlaro</a><span>’s latest post finds anomalies with MySQL and Amazon RDS.</span></p><blockquote><p><em><span>We revisit Kleppmann’s 2014 </span><a href="https://github.com/ept/hermitage/blob/master/mysql.md" rel="">Hermitage</a><span> and confirm that MySQL’s Repeatable Read still allows G2-item, G-single, and lost update. Using our transaction consistency checker </span><a href="https://github.com/jepsen-io/elle" rel="">Elle</a><span>, we show that MySQL Repeatable Read also violates internal consistency. Furthermore, it violates Monotonic Atomic View: transactions can observe some of another transaction’s effects, then later fail to observe other effects of that same transaction. We demonstrate violations of ANSI SQL’s requirements for Repeatable Read.</span></em></p></blockquote><p>Similar to Gwen’s post, they find anomalies and that don’t adhere to the ANSI ‘92 spec. But the behavior they find is much worse than PostgreSQL’s behavior. If you’re using MySQL, I recommend reading the post; they provide suggestions to mitigate some of the issues.</p><p>But what caught my eye was their plea to the standards bodies:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png" width="1456" height="872" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:872,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:363384,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8170b4-97c8-4441-8505-e9100af038a6_1590x952.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Jepsen’s call for better isolation levels mirror Gwen’s. ANSI ‘92 database isolation levels clearly aren’t cutting it.</p><p><span>I’m going to assume you, dear reader, are not part of the standards body. So your takeaway from all this is that your database might not behaving as you expect. But do you care? </span><a href="https://twitter.com/justinjaffray/status/1737506863455854750" rel="">This thread</a><span> says you don’t.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png" width="1372" height="242" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:242,&quot;width&quot;:1372,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:67801,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80eb7675-8db0-4379-8616-b88846c3caac_1372x242.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><a href="https://twitter.com/justinjaffray" rel="">Justin</a><span>’s point is that we’ve been living with these “broken” databases for a long time and no one noticed.</span></p><blockquote><p>that said: it took one of the greatest software minds of a generation to prove that one of the most popular databases of all time was broken. kind of calls into question whether anyone ever cared about that brokenness!</p></blockquote><p>The problem I have with Justin’s argument is that the kinds of anomalies in these posts are hard for developers to complain about. They manifest themselves only very occasionally, and are very difficult to detect.</p><p>Developers that are bitten by database anomalies often don’t know. Application exhibits some weird anomaly, which developers can’t reproduce. Engineers have to just throw up their hands, shrug, and move on. They never even know the database was the culprit.</p><p><span>I have been personally bitten by bugs like this while working on payments </span><a href="https://go.wepay.com/" rel="">my last job</a><span>. Payments processing is a very precise thing (indeed, it’s the example Gwen uses in her post and is what </span><a href="https://materializedview.io/p/durable-execution-justifying-the-bubble" rel="">durable execution frameworks</a><span> always demonstrate). Our double entry book keeping log would no longer line up, databases would misalign, or some other oddity would occur. Such bugs resulted in hours of fruitless debugging and unhappy customers. These are things that I, and many engineers, most definitely do care about.</span></p><p>Jepsen is doing us a favor by showing us that the almighty OLTP database is in fact fallible. Make sure you understand how your database behaves (as best you can) and act accordingly. Caveat emptor.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Polymers capable of killing bacteria without inducing antibiotic resistance (129 pts)]]></title>
            <link>https://today.tamu.edu/2023/12/21/texas-am-team-develops-polymers-that-can-kill-bacteria/</link>
            <guid>38736798</guid>
            <pubDate>Fri, 22 Dec 2023 18:07:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://today.tamu.edu/2023/12/21/texas-am-team-develops-polymers-that-can-kill-bacteria/">https://today.tamu.edu/2023/12/21/texas-am-team-develops-polymers-that-can-kill-bacteria/</a>, See on <a href="https://news.ycombinator.com/item?id=38736798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <div role="region" aria-label="Texas A&amp;M Team Develops Novel Antibacterial Polymers That Can Kill Bacteria content 0">
<figure><p><img decoding="async" loading="lazy" src="https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-350x233.jpg" alt="A photo of a petri dish with bacteria in a science lab." width="2400" height="1597" srcset="https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-350x233.jpg 350w, https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-1024x681.jpg 1024w, https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-768x511.jpg 768w, https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-1536x1022.jpg 1536w, https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-2048x1363.jpg 2048w, https://today.tamu.edu/wp-content/uploads/2023/12/bacteria-colonies-in-petri-dish-getty-500x333.jpg 500w" sizes="(max-width: 2400px) 100vw, 2400px"></p><div><figcaption><hr><p>Getty Images</p></figcaption></div></figure>

<p>Antibiotic-resistant bacteria have become a rapidly growing threat to public health. Each year, they account for more than 2.8 million infections, according to the U.S. Centers for Disease Control and Prevention. Without new antibiotics, even common injuries and infections harbor the potential to become lethal.</p>
<p>Scientists are now one step closer to eliminating that threat, thanks to a Texas A&amp;M University-led collaboration that has developed a new family of polymers capable of killing bacteria without inducing antibiotic resistance by disrupting the membrane of these microorganisms.</p>
<p>“The new polymers we synthesized could help fight antibiotic resistance in the future by providing antibacterial molecules that operate through a mechanism against which bacteria do not seem to develop resistance,” said&nbsp;<a href="https://www.chem.tamu.edu/faculty/quentin-michaudel/" target="_blank" rel="noopener">Dr. Quentin Michaudel</a>, an assistant professor in the&nbsp;<a href="https://artsci.tamu.edu/chemistry/index.html" target="_blank" rel="noopener">Department of Chemistry</a>&nbsp;and lead investigator in the research,&nbsp;<a href="https://www.pnas.org/doi/10.1073/pnas.2311396120" target="_blank" rel="noopener">published Dec. 11</a>&nbsp;in the&nbsp;<a href="https://www.pnas.org/" target="_blank" rel="noopener"><em>Proceedings of the National Academy of Sciences</em>&nbsp;(PNAS)</a>.</p>
<p>Working at the interface of organic chemistry and polymer science, the&nbsp;<a href="https://www.michaudellab.org/" target="_blank" rel="noopener">Michaudel Laboratory</a> was able to synthesize the new polymer by carefully designing a positively charged molecule that can be stitched many times to form a large molecule made of the same repeating charged motif using a carefully selected catalyst called AquaMet. According to Michaudel, that catalyst proves key, given that it has to tolerate a high concentration of charges and also be water-soluble — a feature he describes as uncommon for this type of process.</p>
<p>After achieving success, the Michaudel Lab put its polymers to the test against two main types of antibiotic-resistant bacteria — E. coli and Staphylococcus aureus (MRSA) — in collaboration with <a href="https://www.umass.edu/engineering/about/directory/jessica-schiffman" target="_blank" rel="noopener">Dr. Jessica Schiffman’s</a> group at the University of Massachusetts Amherst. While awaiting those results, the researchers also tested their polymers’ toxicity against human red blood cells.</p>
</div>
<div role="region" aria-label="Texas A&amp;M Team Develops Novel Antibacterial Polymers That Can Kill Bacteria content 1">
<p>“A common issue with antibacterial polymers is a lack of selectivity between bacteria and human cells when targeting the cellular membrane,” Michaudel explained. “The key is to strike a right balance between effectively inhibiting bacteria growth and killing several types of cells indiscriminately.”</p>
<p>Michaudel credits the multidisciplinary nature of scientific innovation and the generosity of dedicated researchers across the Texas A&amp;M campus and country as factors in his team’s success in determining the perfect catalyst for their molecule assembly.</p>
<p>“This project was several years in the making and would not have been possible without the help of several groups, in addition to our UMass collaborators,” Michaudel said. “For instance, we had to ship some samples to the&nbsp;<a href="https://www.letterilab.com/" target="_blank" rel="noopener">Letteri Lab</a>&nbsp;at the University of Virginia to determine the length of our polymers, which required the use of an instrument that few labs in the country have. We are also tremendously grateful to [biochemistry Ph.D. candidate] Nathan Williams and&nbsp;<a href="https://bcbp.tamu.edu/people/pellois-jean-philippe/" target="_blank" rel="noopener">Dr. Jean-Philippe Pellois</a>&nbsp;here at Texas A&amp;M, who provided their expertise in our assessment of toxicity against red blood cells.”</p>
<p>Michaudel says the team will now focus on improving the activity of its polymers against bacteria — specifically, their selectivity for bacterial cells versus human cells — before moving on to <em>in vivo</em>&nbsp;assays.</p>
<p>“We are in the process of synthesizing a variety of analogs with that exciting goal in mind,” he said.</p>
</div>
<div role="region" aria-label="Texas A&amp;M Team Develops Novel Antibacterial Polymers That Can Kill Bacteria content 2">
<p>The team’s paper, which features Michaudel Lab member and Texas A&amp;M chemistry Ph.D. graduate Dr. Sarah Hancock ’23 as first author, can be <a href="https://www.pnas.org/doi/10.1073/pnas.2311396120" target="_blank" rel="noopener">viewed online</a>&nbsp;along with related figures and captions. Other key contributors from the Michaudel Lab are chemistry graduate student An Tran ’23, postdoctoral scholar Dr. Arunava Maity and former postdoctoral scholar Dr. Nattawut Yuntawattana, who is now an assistant professor of materials science at Kasetsart University in Thailand.</p>
<p>This research was funded primarily by Michaudel’s&nbsp;<a href="https://www.nigms.nih.gov/Research/mechanisms/MIRA/Pages/default.aspx" target="_blank" rel="noopener">National Institutes of Health Maximizing Investigators’ Research Award (MIRA)</a>&nbsp;through the&nbsp;<a href="https://www.nigms.nih.gov/" target="_blank" rel="noopener">National Institute of General Medical Sciences</a>.</p>
<p>A native of La Rochelle, France, Michaudel joined the Texas A&amp;M Chemistry faculty in 2018 and holds a joint appointment in the <a href="https://engineering.tamu.edu/materials/index.html" target="_blank" rel="noopener">Department of Materials Science and Engineering</a>. In addition to an NIH MIRA in 2020, his career honors to date include a 2022 National Science Foundation Faculty Early Career Development (CAREER) Award, a 2022 American Chemical Society Polymeric Materials: Science and Engineering (PMSE) Young Investigator Award and a 2021 Thieme Chemistry Journals Award.</p>
<p>Learn more about Michaudel and his research at <a href="https://www.michaudellab.org/" target="_blank" rel="noopener">michaudellab.org</a>.</p>
</div>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3500 arrested in global cybercrime crackdown (131 pts)]]></title>
            <link>https://www.scmagazine.com/news/3500-arrested-300m-seized-in-global-cybercrime-crackdown</link>
            <guid>38736525</guid>
            <pubDate>Fri, 22 Dec 2023 17:36:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scmagazine.com/news/3500-arrested-300m-seized-in-global-cybercrime-crackdown">https://www.scmagazine.com/news/3500-arrested-300m-seized-in-global-cybercrime-crackdown</a>, See on <a href="https://news.ycombinator.com/item?id=38736525">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Police in 34 countries arrested 3500 people and seized assets worth $300 million in the latest iteration of what has become an annual coordinated global crackdown on cybercrime.</p><p><a href="https://www.interpol.int/en/News-and-Events/News/2023/USD-300-million-seized-and-3-500-suspects-arrested-in-international-financial-crime-operation">According to Interpol</a>, Operation HAECHI IV ran from July to December and targeted seven types of scams: voice phishing, romance scams, online sextortion, investment fraud, money laundering associated with illegal online gambling, business email compromise fraud, and e-commerce fraud.</p><p>As a result of the operation, authorities blocked 82,112 suspicious bank accounts, seizing a total of $199 million in hard currency and a further $101 million worth of virtual assets.</p><p>Interpol’s executive director of police services, Stephen Kavanagh, said the “staggering” sum seized was a clear illustration of the incentives that were driving an explosive growth in transnational organized crime.</p><p>“This represents the savings and hard-earned cash of victims,” he said. “This vast accumulation of unlawful wealth is a serious threat to global security and weakens the economic stability of nations worldwide.”</p><p>Interpol said Operation HAECHI IV involved investigators working together to detect online fraud and freeze associated bank and virtual asset service provider accounts using Interpol’s Global Rapid Intervention of Payments (I-GRIP), a stop-payment mechanism which helps countries work together to block criminal proceeds.</p><p>Interpol helped frontline officers identify 367 virtual asset accounts linked to transnational organized crime. Assets in those accounts have been frozen as local police continue their investigations.</p><h2>Dragnet pulls in more AI-powered crime</h2><p>In one case resulting from the operation, Filipino and Korean authorities worked together to apprehend a “high-profile online gambling criminal” who was arrested in Manila after spending two years on the run from Korea's National Police Agency. The illegal gambling operation the man allegedly ran was dismantled.</p><p>Interpol published two “purple notices” – warnings about emerging digital investment fraud practices – during the operation.</p><p>One alerted police around the world to a new scam detected in Korea involving the sale of non-fungible tokens (NFTs) with promises of huge returns, which turned out to be a <a href="https://www.scmagazine.com/analysis/crypto-nft-losses-believed-to-hit-25-trillion-says-industry-researcher">“rug pull” scam</a> where the developers abruptly abandon a project and investors lose their money.</p><p>The second purple notice warned about the use of AI and deep fake technology to lend credibility to scams by enabling criminals to hide their identities and to pretend to be a family member, friend, or love interests of the person they are attempting to dupe.</p><p>“The UK leg of the operation reported several cases where AI-generated synthetic content was used to deceive, defraud, harass, and extort victims, particularly through impersonation scams, online sexual blackmail, and investment fraud,” Interpol said.</p><p>“Cases also involved the impersonation of people known to the victims through voice cloning technology.”</p><p>Investment fraud, business email compromise and e-commerce fraud accounted for 75 per cent of cases investigated during the operation.</p><h2>Arrests and seizures keep growing</h2><p>A similar operation last year, <a href="https://www.scmagazine.com/brief/interpol-cybercrime-crackdown-leads-to-seizure-of-130m">HAECHI III</a>, netted almost 1000 arrests and $130 million in assets.</p><p>“HAECHI IV’s 200 per cent surge in arrests shows the persistent challenge of cyber-enabled crime, reminding us to stay alert and keep refining our tactics against online fraud, which is why INTERPOL operations like this are so important” Kavanagh said.</p><p>The first operation in the series, HAECHI-I, involved police from nine countries in Asia working together between September 2020 and March 2021 to make 585 arrests and seize $83 million.</p><p>Interpol’s head of National Central Bureau in Korea, Kim Dong Kwon, praised the international policing effort that led to the increased results achieved by HAECHI IV.</p><p>“Despite criminals' endeavors to gain illicit advantages through contemporary trends, they will eventually be apprehended and face due punishment. To accomplish this, Project HAECHI will consistently evolve and expand its scope.”</p><p>As SentinalOne explained in a 2021 <a href="https://www.sentinelone.com/blog/the-good-the-bad-and-the-ugly-in-cybersecurity-week-49-3/">post about HAECHI-II</a>: in Korea, Haechi is a popular mythical animal widely used as a symbol of justice. The countries participating in this year’s operation were: Argentina, Australia, Brunei, Cambodia, Cayman Islands, Ghana, India, Indonesia, Ireland, Japan, Kyrgyzstan, Laos, Liechtenstein, Malaysia, Maldives, Mauritius, Nigeria, Pakistan, Philippines, Poland, Korea, Romania, Seychelles, Singapore, Slovenia, South Africa, Spain, Sweden, Thailand, United Arab Emirates, United Kingdom, United States and Vietnam. Hong Kong also participated.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ohio gives historical status to building that once housed CompuServe (145 pts)]]></title>
            <link>https://news.wosu.org/2023-12-21/ohio-gives-historical-status-to-building-that-once-housed-internet-service-pioneer-compuserve</link>
            <guid>38736419</guid>
            <pubDate>Fri, 22 Dec 2023 17:28:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.wosu.org/2023-12-21/ohio-gives-historical-status-to-building-that-once-housed-internet-service-pioneer-compuserve">https://news.wosu.org/2023-12-21/ohio-gives-historical-status-to-building-that-once-housed-internet-service-pioneer-compuserve</a>, See on <a href="https://news.ycombinator.com/item?id=38736419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
        Published&nbsp;December 21, 2023 at 3:37 PM EST
    </p>
    <meta content="2023-12-21T20:37:11.743Z">


                                        </div><div>
                                        <p>A central Ohio building that once served as the global headquarters for CompuServe has been recognized with historic marker status by the state.</p><p>At its height in the 1990's, the pioneering tech company — one of the first to offer commercial internet services — was known by the public for online forums that offered news, message boards and data file transfers. The firm also introduced the GIF image format back in 1987.</p><p>“This may be the first historical marker about the internet. Most history is not recognized and celebrated in your lifetime, but this is and its really special,” said Ohio Lt. Governor Jon Husted at a dedication event featuring state officials and former CompuServe CEO Jeff Wilkins. “Today we have a vibrant, growing tech economy in the state of Ohio. And it began right here.”</p><p>The company opened its headquarters in 1973 and, according to records housed at the Columbus Metropolitan Library, closed the location in the summer of 2006. Ohio's historical markers program, started in the 1953, commemorates unique sites that shape state history.</p><p>Wilkins, who co-founded CompuServe in 1969, also attempted settle a classic internet argument over the pronunciation of the GIF image format at the dedication. He recalled a story about how Steve Wilhite, the engineer who helped create the format, once held up a sign at an awards ceremony read: “It’s pronounced JIF.”</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SymbOS Z80 multitasking operating system (165 pts)]]></title>
            <link>http://www.symbos.de/</link>
            <guid>38736054</guid>
            <pubDate>Fri, 22 Dec 2023 16:57:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.symbos.de/">http://www.symbos.de/</a>, See on <a href="https://news.ycombinator.com/item?id=38736054">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Schrödinger equation emerges mathematically from classical mechanics (2012) (161 pts)]]></title>
            <link>https://www.researchgate.net/publication/241778960_A_Pseudo-Quantum_Triad_Schrodinger%27s_Equation_the_Uncertainty_Principle_and_the_Heisenberg_Group</link>
            <guid>38735725</guid>
            <pubDate>Fri, 22 Dec 2023 16:29:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.researchgate.net/publication/241778960_A_Pseudo-Quantum_Triad_Schrodinger%27s_Equation_the_Uncertainty_Principle_and_the_Heisenberg_Group">https://www.researchgate.net/publication/241778960_A_Pseudo-Quantum_Triad_Schrodinger%27s_Equation_the_Uncertainty_Principle_and_the_Heisenberg_Group</a>, See on <a href="https://news.ycombinator.com/item?id=38735725">Hacker News</a></p>
Couldn't get https://www.researchgate.net/publication/241778960_A_Pseudo-Quantum_Triad_Schrodinger%27s_Equation_the_Uncertainty_Principle_and_the_Heisenberg_Group: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[From Nand to Tetris: Building a Modern Computer from First Principles (570 pts)]]></title>
            <link>https://www.nand2tetris.org</link>
            <guid>38735066</guid>
            <pubDate>Fri, 22 Dec 2023 15:31:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nand2tetris.org">https://www.nand2tetris.org</a>, See on <a href="https://news.ycombinator.com/item?id=38735066">Hacker News</a></p>
<div id="readability-page-1" class="page"><p id="comp-j847hr0w" data-testid="richTextElement"><h6><span><span><span><span><span>And of the book </span></span></span></span><a href="https://www.amazon.com/Elements-Computing-Systems-Building-Principles/dp/0262640686/ref=ed_oe_p" target="_blank"><span><span><span><span><span>The Elements of Computing Systems,&nbsp;</span></span></span></span></span></a><span><span><span><span>By </span></span></span></span><a href="http://www.cs.huji.ac.il/~noam/" target="_blank"><span><span><span><span><span>Noam Nisan</span></span></span></span></span></a><span><span><span><span> and</span><span> </span><a href="http://www.shimonschocken.com/" target="_blank"><span><span>Shimon Schocken</span></span></a><span> (MIT Press)</span></span></span></span></span></h6></p><div id="comp-j847if12" data-testid="richTextElement"><p><span><span><span><span>The site contains all the lectures, project materials and tools necessary for building a general-purpose computer system and a modern software hierarchy from the ground up.<p>

The materials are aimed at students, instructors, and self-learners. Everything is free and open-source, as long as you operate in a non-profit, educational setting.</p></span></span></span></span><br>
&nbsp;</p>

<p><span><span><span><span>The materials also support two on-line courses:&nbsp;</span></span></span><span><span><span><span><a href="https://www.coursera.org/learn/build-a-computer" target="_blank" rel="noreferrer noopener">Nand2Tetris Part</a></span></span></span></span><span><span><span><a href="https://www.coursera.org/learn/build-a-computer" target="_blank" rel="noreferrer noopener"><span><span> </span></span></a></span></span></span><span><span><span><span><a href="https://www.coursera.org/learn/build-a-computer" target="_blank" rel="noreferrer noopener">I</a></span></span><span><span><span> </span></span></span><span>(hardware projects/chapters 1-6), and&nbsp;</span><a href="https://www.coursera.org/learn/nand2tetris2" target="_blank" rel="noreferrer noopener"><span><span>Nand2Tetris Part II</span></span></a></span></span><span><span><span> (software projects/chapters 7-12).</span></span></span></span></p>

<p><span><span>​</span></span></p>

<p><span><span><span><span>Nand to Tetris courses are taught at 400+ universities, high schools, and bootcamps. The students who take them range from high schoolers to Ph.D. students to Google engineers. Here is the&nbsp;</span></span></span><a href="https://drive.google.com/file/d/1EWCOVIcg0-dX0XtL3KwNyra6jzMogXLL/view?usp=sharing" target="_blank" rel="noreferrer noopener"><span><span><span><span>extended course syllabus.</span></span></span></span></a></span></p>

<p><span><span>​</span></span></p>

<p><span><span><span><span><span><span>Instructors:</span></span></span></span></span><span><span><span>&nbsp;For additional course materials, contact <a data-auto-recognition="true" href="mailto:schocken@gmail.com">schocken@gmail.com</a></span></span></span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Hyperloop was always a scam (155 pts)]]></title>
            <link>https://www.disconnect.blog/p/the-hyperloop-was-always-a-scam</link>
            <guid>38734909</guid>
            <pubDate>Fri, 22 Dec 2023 15:16:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.disconnect.blog/p/the-hyperloop-was-always-a-scam">https://www.disconnect.blog/p/the-hyperloop-was-always-a-scam</a>, See on <a href="https://news.ycombinator.com/item?id=38734909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic" width="1200" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/07c65282-6c6f-4629-87c7-58ed30f27658.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:675,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:31189,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07c65282-6c6f-4629-87c7-58ed30f27658.heic 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Original Hyperloop concept image.</figcaption></figure></div><p><span>Ten years after Elon Musk unveiled the white paper for the vacuum-tube transport system he dubbed the Hyperloop, it’s time to drive the final nail into its coffin. Earlier this year, </span><em>Motley Fool</em><span> was already reporting that </span><a href="https://www.fool.com/investing/2023/02/21/hyperloop-startups-are-dying-a-quiet-death/" rel="">things were tough in Hyperloop world</a><span> with startups “dying a quiet death” as higher interest rates meant investors weren’t going for projects that were clearly never going to pay off.</span></p><p><span>Hyperloop One, previously known as </span><em>Virgin</em><span> Hyperloop One, was struggling too. Last year it finally had to admit its passenger tube dreams were never going to be realized, so it tried to </span><a href="https://www.bbc.com/news/technology-60478719" rel="">convince some Emiratis</a><span> that narrow, low-capacity tubes were actually going to be a great way of moving cargo. Well, they clearly didn’t buy it for long because yesterday </span><em>Bloomberg</em><span> reported Hyperloop One is </span><a href="https://www.bloomberg.com/news/articles/2023-12-21/hyperloop-one-to-shut-down-after-raising-millions-to-reinvent-transit" rel="">finally shutting down</a><span>.</span></p><p>To be clear, Hyperloop One is not associated with Musk himself. After launching in 2014, it was partly funded from Richard Branson’s fortune for a while, but even that didn’t last, with the Virgin branding disappearing along with the vision for transforming passenger transportation. I sincerely hope the media (and investors) take its collapse as a sign to stop giving any oxygen to Hyperloop fantasies. The technology was never really meant to go anywhere. Its main goal was always to stop a better transport future from being realized.</p><p>A decade on, people often forget what was really motivating the Hyperloop when Musk first started pushing it. In the early 2010s, there was a big debate around California’s plan to build a high-speed rail line from Los Angeles to San Francisco, with further extensions to San Diego and Sacramento to follow. Naturally, conservative, automotive, and airline interests were vehemently opposed to a technology that Japan and Europe had been living with for decades arriving on American shores because it threatened their commercial interests.</p><p><span>Elon Musk, as an automaker and (let’s be honest) somewhat of a conservative himself, eagerly adopted the arguments against the bullet train with his own spin. He began incessantly repeating a line he </span><a href="https://www.youtube.com/watch?v=qox_m6jyfmA" rel="">doled out</a><span> at the D11 conference with Walt Mossberg and Kara Swisher in 2013, calling it, “the slowest bullet train in the world and the most expensive bullet train per mile in the world” — and that meant it not only had to be opposed, but that the geniuses in Silicon Valley could surely do better than people who actually had a clue about trains and transportation.</span></p><p><span>When he unveiled the Hyperloop concept, Musk claimed that building it on the Los Angeles to San Francisco route would not only result in a far faster trip, but would also cost only a fraction of the price — as little as $6 billion. That figure was immediately debunked by people who </span><a href="https://web.archive.org/web/20130819164738/http://america.aljazeera.com/articles/2013/8/14/economists-don-tbelievethehyperloop.html" rel="">actually understood what went into building that kind of infrastructure</a><span>, with the real cost estimated around at least $100 billion, even though it would have far less capacity than a high-speed train. But there’s another feature that’s often forgotten: the Hyperloop was also for cars. “You just drive on, and the pod departs,” Musk told </span><em>Bloomberg Businessweek</em><span> in </span><a href="https://web.archive.org/web/20130815003336/http://www.businessweek.com/articles/2013-08-12/revealed-elon-musk-explains-the-hyperloop" rel="">his first interview</a><span> about the idea. That fantasy would show up again in the Boring Company a few years later.</span></p><p><span>In 2013, Musk’s star was rising. He was gracing the covers of magazines and being hailed as our future-builder. He’d already served as inspiration for Robert Downey Jr.’s take on Tony Stark in </span><em>Iron Man</em><span> and was largely seen as a man who could do no wrong. When he chose to speak out against the bullet train, that amplified the campaign against it, further seeping political support from an already challenged project. And that was the point. Musk never had any intention of building the Hyperloop. He only needed it to help kill or substantially delay the high-speed rail project and the alternate vision of sustainable </span><em>collective</em><span> transportation it offered. It threatened his interests as an automaker and his elite vision of “individualized” mobility that simply worked better for him.</span></p><p><span>In 2015, Ashlee Vance’s biography </span><em>Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future</em><span> was published to an audience eager to consume a hagiography of the man supposedly saving the world and preparing us to colonize the stars. But buried within those 300-odd pages was an admission that many people seemed to have glossed over. On the subject of the Hyperloop, Vance wrote,</span></p><blockquote><p>Musk told me that the idea originated out of his hatred for California’s proposed high-speed rail system. … He insisted the Hyperloop would cost about $6 billion to $10 billion, go faster than a plane, and let people drive their cars onto a pod and drive out into a new city. At the time, it seemed that Musk had dished out the Hyperloop proposal just to make the public and legislators rethink the high-speed train. He didn’t actually intend to build the thing. … With any luck, the high-speed rail would be canceled. Musk said as much to me during a series of e-mails and phone calls leading up to the announcement.</p></blockquote><p><span>The only thing that could be clearer is if Vance released the e-mails and phone calls he’s referring to, but what he wrote is conclusive enough. Years later, after I </span><a href="https://twitter.com/parismarx/status/1167410460125097990" rel="">began</a><span> </span><a href="https://time.com/6203815/elon-musk-flaws-billionaire-visions/" rel="">resurrecting</a><span> that passage, Vance </span><a href="https://jalopnik.com/did-musk-propose-hyperloop-to-stop-california-high-spee-1849402460" rel="">claimed</a><span> my telling was “vaguely accurate but a disingenuous take on the situation.” Speaking to </span><em>Jalopnik</em><span> in 2022, he said, “I honestly do not think that was the goal of Hyperloop at all. I think if there was a better public transport system, my impression — and I think it’s genuine — is that Elon would be all for it.” Yet that completely contradicted what he had written years earlier, that Musk wanted to make lawmakers “rethink the high-speed train” and hoped it “would be canceled.”</span></p><p><span>Vance’s original telling is more credible because stopping collective transport projects has become a pattern for Musk. He proposed the Hyperloop to imperil high-speed rail. He also proposed the Boring Company tunnel system as his solution to traffic, after previously believing </span><a href="https://la.curbed.com/2018/11/9/18077612/elon-musk-mayor-garcetti-tunnels-boring-company" rel="">double-decker highways</a><span> would do the trick, instead of advocating for much better public transit because he felt transit was “</span><a href="https://www.wired.com/story/elon-musk-awkward-dislike-mass-transit/" rel="">a pain in the ass</a><span>” and suggested it was filled with serial killers. Counter to Vance’s more recent suggestion, there’s no evidence Musk would back better public transit, but plenty that he wanted to stall out plans for improved collective transport altogether. He did exactly that with the Boring Company: selling cities </span><a href="https://nymag.com/intelligencer/2022/08/elon-musks-biggest-boondoggle.html" rel="">useless tunnels</a><span> that were rarely ever built and which often displaced realistic transit plans.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.disconnect.blog/p/the-hyperloop-was-always-a-scam?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.disconnect.blog/p/the-hyperloop-was-always-a-scam?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>Unfortunately, the harm of the Hyperloop went far beyond California. Companies claiming they’d realize the bullshit idea claimed to be moving forward with projects in </span><a href="https://indianexpress.com/article/explained/explained-after-hype-over-hyperloop-why-theres-a-question-mark-over-ultra-modern-project-6223864/" rel="">India</a><span>, </span><a href="https://www.thenationalnews.com/uae/transport/virgin-hyperloop-aims-for-2022-test-launch-as-chief-warns-against-rushing-technology-1.842589" rel="">Dubai</a><span>, </span><a href="https://lareleveetlapeste.fr/lhyperloop-delon-musk-un-fiasco-planetaire-qui-a-coute-plus-de-55-millions-deuros-a-la-metropole-de-toulouse/" rel="">France</a><span>, </span><a href="https://edmonton.ctvnews.ca/alta-hyperloop-project-awaiting-government-meeting-committing-to-stop-in-red-deer-1.6217544" rel="">Canada</a><span>, and countless other parts of the world only for every single one to amount to nothing. Sure, some short tubes got built in a few places to try to keep squeezing money out of investors and governments, but the only thing they really achieved was to distract people with fantasies while they could’ve been focused on building something real.</span></p><p><span>In the time since California started talking about high-speed rail and Elon Musk interjected with his fantasy to help sidetrack it, China moved ahead and built a network consisting of 42,000 kilometres (26,000 miles) of track. Europe is continuing to expand its own network, and Japan is building a maglev line that will run at speeds of over 500 km/h (310 mph). The first segment from Tokyo to Nagoya could </span><a href="https://www.japantimes.co.jp/news/2023/12/15/japan/maglev-shinkansen-opening-delayed/" rel="">open by 2027</a><span>. Not to be outdone, China is working on </span><a href="https://www.cnbctv18.com/travel/china-completes-first-operation-of-worlds-fastest-train-that-travels-at-600-kmhour-16321471.htm" rel="">a maglev of its own</a><span> to beat its Japanese rivals.</span></p><p><span>While the Hyperloop deception spread far and wide, nowhere was it stronger than in the United States. As countries around the world </span><a href="https://en.wikipedia.org/wiki/List_of_high-speed_railway_lines" rel="">moved forward</a><span> with real transport improvements, North Americans were distracted by the fantasies of clueless, but self-confident tech moguls. They left people trapped in their cars and denied better options to get around that people in many other parts of the world — even those that are quite a bit poorer — take for granted. Now all they can do is shovel money at automakers to try to power cars with batteries instead of internal combustion engines. They have no vision for a better, less car dependent alternative.</span></p><p>The tech industry’s move into transportation was not only a failure; it was an active campaign to deny the public access to better transit and trains because the billionaires of Silicon Valley don’t personally want to get around that way. The Hyperloop was one part of that, but so were the Boring Company, ride-hailing services, and self-driving cars. The Hyperloop’s failure provides a lesson we’re learning far too late: that Silicon Valley won’t deliver us a better world if they can’t find some way to profit off it. We need to stop falling for their grand deceptions, and tell our media to stop echoing them too.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LED Industrial Piercing (175 pts)]]></title>
            <link>https://mitxela.com/projects/scaffold</link>
            <guid>38734164</guid>
            <pubDate>Fri, 22 Dec 2023 13:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mitxela.com/projects/scaffold">https://mitxela.com/projects/scaffold</a>, See on <a href="https://news.ycombinator.com/item?id=38734164">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mxmain"><p><a href="https://mitxela.com/projects/hardware"><img onload="this.style.opacity=1;" src="https://mitxela.com/img/titles/mitxela_dot_com-65.png" title="Back to Hardware" alt="Back to Hardware"></a></p><p>22 Dec 2023<br><b>Progress: Complete</b></p><p>
A friend of mine wears a type of jewellery known as an "industrial piercing" or "scaffold" that puts a bar across her ear.</p><p>

Always looking for a new challenge, I had the idea to fill the bar with LEDs.</p><p>

Watch the following video to experience the journey:</p><p>

<iframe width="704" height="396" src="https://www.youtube.com/embed/T3evnh9lT9k" allowfullscreen=""></iframe></p><p>

This is one of a number of projects I rushed through in the run-up to the closure of London Hackspace. I've now not had access to a milling machine for over a year. Drilling holes in the side of a hypodermic needle would be a little tricky without one.</p><h3>Design</h3><p>
Our journey begins in the summer of '22, when I snapped this image of my friend's ear. (With permission!)</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/scaff.jpg" alt="The original piercing the design was based on"></p><p>

Could it be filled with LEDs? Most people laughed in disbelief when I suggested it. But everyone agreed that it would be really cool.</p><p>

You can buy stainless tubing in various sizes, but nothing quite compares to the cheapness and availability of hypodermic needles. A gauge 16 needle is exactly the right diameter, and the sidewall is so thin you couldn't ask for anything better. But needles are quite short, there was some concern that it wouldn't be long enough. I did find a supplier of extra long syringe needles intended for model makers, there might have been something in the right size, but after some careful measurements and calculations I decided the regular needles would be OK.</p><p>

I did the initial design in OpenSCAD, and having rotated the above photo into a scaled and skew-corrected position we could overlay the two in photoshop.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/overlay.jpg" alt="CAD design overlaid onto rotated photograph in photoshop"></p><p>

That's before the final adjustments to length were made. This mockup was invaluable in getting the LED pitch and offset correct.</p><p>

OpenSCAD continued to be helpful as I came up with the circuit, thinking about how it would fold together and how much tolerance we needed to leave. Just a basic idea is all that's required.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/openscad.png" alt="OpenSCAD screenshot"></p><p>

The PCB design had to wait until I'd gotten this all exactly right, the distances between the microcontroller and the LEDs is critical.</p><p>

A flex PCB is the way to get the very thinnest board possible. You can technically get 0.2mm FR4 from some board houses but it'll cost about the same as a flex PCB anyway. We could have gone flex-rigid, that would have let us use the thinnest material for the LEDs and a multilayer board for the microcontroller, but it would have cost a lot more and still not allowed us to put a connector above the microcontroller.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/kicad.png" alt="KiCad PCB design"></p><p>

Once I'd settled on those off-the-shelf earrings as the source of my battery holder, that determined quite a bit about the design too. The metal case is our positive battery terminal, we need to fit a wire that pokes out of the end of the needle to be the ground pin.</p><p>

I did a few redesigns of the board before settling on the above design. Even forgetting the fiddly exact dimensions of how it will go together, routing the LED tracks was tricky. If we had gone for the 0201 LEDs they could have been mounted in the other orientation, with tracks passing directly underneath them. Once I'd checked the dimensions I felt a lot more comfortable with the 0402 LEDs though.</p><h3>Metalwork</h3><p>
Once I'd made the tiny brass V-block arrangement, crossdrilling the needle took barely five minutes. In my mind it was going to be a big deal.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/metalwork1.jpg" alt="Drilling a 1mm hole in the side of a hypodermic needle"></p><p>

It helps that I used an endmill to drill the holes, not only would a drillbit have wandered on the curved surface but the carbide is simply a lot stiffer. I should really invest in some tiny carbide drills, you might say that HSS just doesn't cut it for me.</p><p>

The dodgy-but-still-kind-of-legit tactic of holding an endmill in the tailstock chuck no doubt made some viewers grimace.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/metalwork2.jpg" alt="6mm endmill being used to produce a flat-bottomed hole"></p><p>

Drill shanks are soft, chuck jaws are hard. Endmill shanks are also hard which means the jaws won't grip them properly. If I'd had the proper tools I would have used them. Anyway you can't argue with the results, the flat-bottomed hole was spot-on. The 1.6mm through hole was a lot messier, the drillbit really wanted to wander. Again I yearned for all my tooling to be solid tungsten carbide.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/metalwork3.jpg" alt="Drilling a tiny hole in stainless steel"></p><p>

This formed a decent press-fit onto the needle. I suppose the hollow tube is fairly compressible. Even so, once I'd settled on the right position I gave the needle a healthy smear of cyanoacrylate before pressing it in for the final time. Remember, the battery-holding collet on the other end is going to be mounted and unmounted by simply pulling on this join, so we want it to be very secure.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/metalwork4.jpg" alt="Needle fitted into endcap"></p><h3>Circuit</h3><p>
When the circuit boards arrived, I soldered one together almost immediately.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/flex-circuit.jpg" alt="Bare flex PCB"></p><p>

For multiple reasons I then put it aside for about a year. It was only a few months ago that I powered the board up and got some flashing patterns going.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/circuit1.jpg" alt="Circuit lighting up"></p><p>

The microcontroller is an ATtiny44. If I was designing this today I'd have gone with the CH32V003, which admittedly has worse power consumption, but the benefit of that one-wire debug pin can't be overstated. It now seems so silly that I had to wire up six pins to be able to reflash this thing.</p><p>

Sliding the circuit inside of the case and it already looks nearly finished.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/circuit2.jpg" alt="Circuit inside of the metal case"></p><p>

The thick black wire protruding from the end needs to be trimmed to form our battery negative terminal. But as you can see the power and ground pins are also exposed on the connector.</p><p>

In terms of software, the LEDs are charlieplexed and the pattern I settled on loops over the course of about three minutes. All in, the software is similar but a fair bit simpler than the <a href="https://mitxela.com/projects/charliestar">charliestar</a>, which does more with less.</p><p>

I will link to the source code at the end of the page.</p><h3>Assembly</h3><p>
I should mention, the cheapo earrings I used for the battery case are <i>not</i> made from stainless. It's nickel-plated brass, which I realised when I started machining it. It does make me think I'd have had an easier time making the end out of brass and nickel-plating it. On the other hand the stainless does look pretty good, and with any luck it'll stay that shiny for a long long time.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/finished1.jpg" alt="Piercing fully assembled but with battery holder removed"></p><p>

At this stage everything appeared to work perfectly, so I prepared some clear food-grade epoxy to fill the holes.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/finished2.jpg" alt="Piercing fully assembled and illuminated"></p><p>

I assume the reader has already watched the video, but if not, spoilers: after potting the bar with clear epoxy, one of the LEDs stopped working. Luckily it's on the end, so it's not particularly obvious. As this happened after the epoxy cured, there's no way to repair it.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/finished3.jpg" alt="Piercing fully assembled and only five LEDs illuminated"></p><p>

I'm not above building another one from scratch except that I'm currently between workshops. That, and I feel like it's been long enough that the next version should also be an improvement, not merely a second attempt.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/finished-holding.jpg" alt=""></p><h3>End Cap</h3><p>
I originally planned to add one or more end caps to the design. These would connect into that programming header, which doubles as simply GPIO pins of the microcontroller, and offer various interfaces, such as a microphone or an IR receiver.</p><p>

I'm not saying it won't happen in the future but I didn't get round to it yet. And besides, the flashing pattern I settled on seems interesting enough for now.</p><h3>Case</h3><p>
The case was modelled in OpenSCAD too. It's tricky to do fillets and chamfers, and I wasn't trying to make this look amazing or anything. In fact with the dead LED I wanted to wrap this up as quick as possible. But the case turned out great, it holds the device perfectly and you can just chuck it in a pocket without worrying.</p><p>

Here's an embeddiment. The scaffold is stored with the battery pack in the "off" position, i.e. pulled out a little.</p><p>


<model-viewer src="/img/uploads/metal/scaffold/scaffold-case.wrl" start="4.5,5.4,-6.4">
  Sorry, your browser doesn't support embedded 3D models.
</model-viewer></p><p>

The hinges are dressmaker's pins through just-barely-press-fit holes. It's stiff enough that the lid will stay at any angle.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/finished-with-case.jpg" alt="Illuminated within case"></p><p>

The texture on the lid is from the bed of the 3D printer. It helps parts adhere while they're printing, but it also adds a bit of interest to the end result.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/case-closed.jpg" alt="3D printed case"></p><h3>Modelled</h3><p>
It's a while since I've had a living, breathing person pose for my macro lens. It is quite tricky to get the exposure right, usually my subjects are inanimate.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/wearing1.jpg" alt="LED Industrial Piercing being worn"></p><p>

The flash does somewhat drown out the LEDs, makes it look a bit clinical.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/wearing2.jpg" alt="LED Industrial Piercing being worn"></p><p>

It's entirely possible I'll get some more pictures of the piercing being worn in future. It would be cool to do some long exposures with flash, so that the image is visible but the LEDs leave a trail.</p><h3>Battery Life</h3><p>
I measured the current draw at just over 3mA. LR521 batteries have a capacity of about 10mA at best, which naively implies about 3 hours of battery life. However, the alkaline discharge curve is pretty steep and it's not clear at what voltage the chip will brown-out, it could potentially cut out well before the batteries are depleted.</p><p>

However, there's another battery in the same form factor called SR521, which is a silver-oxide battery. Not only does that give us about double the capacity, the discharge curve is much flatter so with those we should be good for at least five hours.</p><p>

Changing the batteries is about as fiddly as it looks. Really, instead of machining that collet to be bigger, I should have just reduced the diameter of our bar near the end, so the regular battery holders from the cheap earrings could be fitted unmodified. In that case, it would only take a second to swap the whole battery pack, instead of having to unscrew things.</p><h3>Conclusion</h3><p>
Overall, to my surprise, there really wasn't anything particularly challenging in this project, for the most part all the bits I expected to be difficult turned out fine. Evidently the next piercing will need to be smaller and use those 0201 LEDs.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/finished4.jpg" alt="Piercing fully assembled and illuminated"></p><p>

I'm pretty pleased with the result. I was a bit disheartened when the LED died, as all of my joking about soldering things the hard way using the wrong equipment then sounds a bit pathetic. It's fine if you use terrible equipment and it works regardless, but if you use terrible equipment and it fails to work then you're just a fool.</p><p>

However when I saw the thing being worn I had to admit that it looks really good.</p><p>

<img src="https://mitxela.com/img/uploads/metal/scaffold/wearing3.jpg" alt="LED Industrial Piercing being worn"></p><p>

If you would like to own one of these piercings, you simply can't. At least, it would be even harder for me to make and sell these than most of my inventions as the length has to be sized exactly to the wearer's ear. But, if you're totally loaded and you really want one, get in touch.</p><p>

The source code for the ATtiny is <a href="https://github.com/mitxela/scaffold">here</a>.</p><div>

<p><img src="https://mitxela.com/img/uploads/metal/scaffold/wearing4.jpg" alt="LED Industrial Piercing being worn"></p></div><nav>
<a href="https://mitxela.com/projects/random" title="random project">~</a>
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/">mitxela.com</a></span> » 
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects">Projects</a></span> » 
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects/hardware">Hardware</a></span> »
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects/scaffold">LED Industrial Piercing</a></span>
<p>Questions? Comments? Check out the <a href="https://mitxela.com/forum">Forum</a>
</p><p><a href="https://mitxela.com/support">Support mitxela.com</a>
</p></nav></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Heynote – A Dedicated Scratchpad for Developers (841 pts)]]></title>
            <link>https://heynote.com/</link>
            <guid>38733968</guid>
            <pubDate>Fri, 22 Dec 2023 13:33:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://heynote.com/">https://heynote.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38733968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h3>One buffer, many blocks</h3>
          <p>
            At its core, Heynote is a large, persistent text buffer divided into blocks. 
            Creating a new block is as easy as pressing <span><span>⌘</span>-Enter</span>, 
            and pressing <span><span>⌘</span>-A</span> within 
            a block selects the content of just that block.
          </p>
          <p>
            Works great for that Slack message you don't want to accidentally send, a JSON response 
            from an API you're working with, notes from a meeting, your daily to-do list, etc.
          </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In the Long Run, We're All Dad (260 pts)]]></title>
            <link>https://www.astralcodexten.com/p/in-the-long-run-were-all-dad</link>
            <guid>38733440</guid>
            <pubDate>Fri, 22 Dec 2023 12:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.astralcodexten.com/p/in-the-long-run-were-all-dad">https://www.astralcodexten.com/p/in-the-long-run-were-all-dad</a>, See on <a href="https://news.ycombinator.com/item?id=38733440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><strong>I.</strong></p><p>In February 2023 I found myself sitting in the waiting room of a San Francisco fertility clinic, holding a cup of my own semen.</p><p>The Bible tells the story of Onan, son of Judah. Onan’s brother died. Tradition dictated that Onan should impregnate his brother’s wife, ensuring that his brother’s line would (in some sense) live on. Onan refused, instead “spilling the seed on the ground”. God smote Onan, starting a 4,000-year-old tradition of religious people getting angry about wasting sperm on anything other than procreative sex.</p><p>Modern academics have a perfectly reasonable explanation for all of this. If Onan had impregnated his brother’s wife, the resulting child would have been the heir to the family fortune. Onan refused so he could keep the fortune for himself and his descendants. So the sin of Onan was greed, not masturbation. All that stuff in the Talmud about how the hands of masturbators should be cut off, or how masturbation helped cause Noah’s Flood (really! Sanhedrin 108b!) is just a coincidence. God hates greed, just like us.</p><p>Modern academics are great, but trusting them feels somehow too convenient. So there in the waiting room, I tried to put myself in the mindset of the rabbis thousands of years ago who thought wasting semen was a such a dire offense.</p><p>The average ejaculation contains about 300 million sperm. There are about 300 million people in the United States. If every sperm in a single ejaculation got to fertilize an egg and incubate in a womb, it would be enough to populate a second America.</p><p>America has about 200 living Nobel Prize winners. 735 billionaires. 1,000,000 doctors, 5,000,000 nurses. 100,000 pilots, 700,000 cops. Also 700,000 drug dealers, 100,000 murderers, and 1,700 NYT journalists.</p><p>That doesn’t necessarily mean my cup contained exactly 100,000 future pilots. If we assume complete genetic determinism, my sperm form a normal distribution around my personal genetic average. I’m terrible at three dimensional reasoning, so let’s say I’m two standard deviations less likely than usual to become a pilot. If my wife is normal on this trait, and we average it out, that means only about 32,000 future pilots in the cup.</p><p><span>On the other hand, I’m better than average at writing. I might be among the top 20,000 most-read authors in the US, so maybe +4SD above average. Again assuming my wife is normal, that suggests even the average kid we have will be a good writer. But imagine an entire America worth of people </span><em>centered</em><span> around being a good writer. The best writer in existing America should be +6SD above average; the best writer among the sperm in the cup is +8SD. 8SD is “best in two quadrillion”. There has never been a writer that good in the whole history of the world. There is a sperm in that cup who could write at an utterly superhuman level, write things none of us could possibly imagine, things so good it’s not even clear you would still call them writing and not some entirely new semi-divine form of art.</span></p><p>There’s also, on priors, some sperm who would shoot up a school. There’s a decent chance of a few who, if given an egg and a womb, would destroy the world, and a few others who would save it. A few hundred might ruin my life so thoroughly that I would commit suicide to escape them. A few dozen might be so great that people would build statues to me just for being their father, the same way some people build statues to St. Joseph.</p><p>The nurse called my name, I handed her the cup, and she took it away to pour into some lab apparatus. Good bye, 200 Nobelists. Good by, 32,000 pilots. Good bye, son who would have destroyed the world. Good bye, daughter who would have saved it. I waited to see if God would smite me. He did not. A few weeks later the clinic called and said there was nothing wrong with my sperm. My fertility problems were just bad luck. I should just keep trying.</p><p><span>There’s an old Jewish joke. How do you make God laugh? Tell Him your plans. 1/10,000 chance of a pilot, because I’m bad at navigation and the base rates are low. 1/10 chance of a doctor, because of all the doctors in my family. I knew it was bogus. Partly because I’m bad at standard deviations and probably got the numbers wrong. But partly because anything can happen. Maybe I was having all this trouble because the lab missed something and I really </span><em>was</em><span> infertile. Maybe my </span><em>wife</em><span> was infertile. Maybe we’d eaten too many microplastics and it was all over. Maybe we’d have a kid, an amazing kid who could have changed everything, but the world would end in 2027 and they’d never get a chance. Still, you’ve got to calculate. One in three million chance of becoming a billionaire. One in thirty thousand chance of committing murder. One out of this. One in that. One one one one one, until you reach semantic satiation on the number “one” and the syllable loses all meaning.</span></p><p>This time God chose to frustrate my calculations even faster and more decisively than usual: He blessed me with twins.</p><p><strong>II.</strong></p><p>Natural selection didn’t design the female body to carry two children. It barely, grudgingly, designed it to carry one. Two is a cruel joke.</p><p>I remember cutting an onion, sometime during month one. My wife asked if they were a different variant from usual, or if they’d gone bad. They hadn’t. It had to be morning sickness. We laughed and hugged each other. This pregnancy thing was starting to feel real!</p><p>A month later - including a hunt through the kitchen to cleanse it of any shred of onion, or anything that had ever touched an onion - we agreed that actually, morning sickness was bad. Two months later, we debated bringing my wife to the ER because she hadn’t eaten anything other than plain saltine crackers in several days. We did manage to avoid the hospital, but it was rough. I’m surprised more people don’t name their children after Zofran®. Women get such positive feelings about it, right when they’re considering baby names. For a girl, you could nickname her Zoe. For a boy, Frank. </p><p><span>And after the morning sickness it was asthma. After the asthma, anemia. After the anemia, hip pain, trouble sleeping, trouble walking, trouble with </span><em>everything</em><span>.</span></p><p>I’ve heard rumors of some women who keep working all through pregnancy, with a smile on their face. Pronatalist influencer Simone Collins says she was taking business calls from her hospital room during the delivery. I think it’s a conspiracy. All the pronatalist influencers get together and say that pregnancy isn’t so bad. Young women believe them, and so the human race survives another generation. </p><p><span>As my wife labored to build our childrens’ physical forms, I toiled to give them their spiritual-semiotic identity. The theory of </span><a href="https://en.wikipedia.org/wiki/Nominative_determinism" rel="">nominative determinism</a><span> posits that a person’s name shapes the course of their future life. Its proponents have collected a mountain of evidence: British chief justice </span><a href="https://en.wikipedia.org/wiki/Igor_Judge,_Baron_Judge" rel="">Igor Judge</a><span>, neurologist </span><a href="https://en.wikipedia.org/wiki/Russell_Brain,_1st_Baron_Brain" rel="">Lord Brain</a><span>, poker champion </span><a href="https://en.wikipedia.org/wiki/Chris_Moneymaker" rel="">Chris Moneymaker</a><span>, investment CEO </span><a href="https://en.wikipedia.org/wiki/Eugene_Profit" rel="">Eugene Profit</a><span>. The Chinese think the </span><a href="https://www.thoughtco.com/number-of-stroke-chinese-names-2278472" rel="">number of strokes</a><span> in the characters that form </span><a href="https://www.bbc.com/worklife/article/20201209-why-some-chinese-believe-a-name-change-could-improve-luck" rel="">a child’s name</a><span> must add up to a lucky number; the Jews believe each letter corresponds to a number, and a person’s name resonates spiritually with all other words whose letters sum to the same amount. </span></p><p><span>Now the statisticians have joined the fray: </span><a href="https://www.experiencedmommy.com/baby-name-salary/" rel="">did you know</a><span> that children with short first names earn over $10,000 more than longer ones? Or that men named "Jim" make 50% more than men named "Isaiah"? Is this causation or confounding? Names indicate whether you are black or white, rich or poor, and whether your parents are traditional or eccentric; what is left after adjusting for this effect? The only paper I’ve seen even begin to address the question is </span><a href="https://www.nber.org/system/files/working_papers/w11195/w11195.pdf" rel="">a sibling-control study by David Figlio</a><span>, who finds that even within families, children with lower-class names perform worse. And you don’t need scientists to know that names affect how other people see you. Just ask Chad, Karen, Tyrone, or the poor doctor I worked with once named Osama (he went by “Sam”).</span></p><p>But also, some people love their names, and other people hate theirs. This was the factor I was least sure about, so I surveyed 1518 blog readers.</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 424w, https://substackcdn.com/image/fetch/w_652,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 652w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1272w, https://substackcdn.com/image/fetch/w_1304,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1304w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1456w, https://substackcdn.com/image/fetch/w_1956,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1956w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_652,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png" sizes="100vw" alt="Graph of people's name preferences, showing they are happiest with names of rank 501 - 1000" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 424w, https://substackcdn.com/image/fetch/w_652,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 652w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1272w, https://substackcdn.com/image/fetch/w_1304,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1304w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1456w, https://substackcdn.com/image/fetch/w_1956,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242b644-1695-46be-bc07-6042c379a03b_636x416.png 1956w" width="652"></picture></div></figure><p><span>Here “popularity rank” comes from the </span><a href="https://www.ssa.gov/oact/babynames/" rel="">List Of Most Popular Baby Names</a><span> for the respondent’s birth year - for example, Scott was the 39th most popular boys’ name in 1984, so I am rank 39. I find that people are happiest with names in the 501 - 1000 range (a separate question, which asked people to rate their happiness with their name on a scale of 1 - 5 without reference to whether it was traditional or unusual, got the same result). </span></p><p>What about other considerations?</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 424w, https://substackcdn.com/image/fetch/w_682,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 682w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 1272w, https://substackcdn.com/image/fetch/w_1364,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 1364w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 1456w, https://substackcdn.com/image/fetch/w_2046,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 2046w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_682,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png" sizes="100vw" alt="Another graph of name preferences, showing they are happiest with older names, historical names, or names honoring deceased relatives." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 424w, https://substackcdn.com/image/fetch/w_682,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 682w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 1272w, https://substackcdn.com/image/fetch/w_1364,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 1364w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 1456w, https://substackcdn.com/image/fetch/w_2046,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c790d21-2ecf-4187-a0ad-96bdf8723bfb_707x339.png 2046w" width="682"></picture></div></figure><p>I asked people how happy they would be with ten different types of names. </p><p><span>People expressed a strong preference for common older names like John and Mary. Does this contradict the finding above that people with very common names were least happy? Not </span><em>necessarily </em><span>- the common names on the question above included all common names (the #1 most common name for boys born last year is “Liam”), so maybe people like common </span><em>older</em><span> names in particular? But I looked at people in the sample named John, Michael, Mary, and Sarah, and they didn’t differ much from the overall common names category. So people may </span><em>think</em><span> they would like names like these, but actual Johns and Marys wish they were named something a little more unusual.</span></p><p>The least popular categories included “new-fangled name” and “sci-fi / fantasy name”. The most popular were “name honoring a deceased relative”, “name from your ethnic origin”, and “historical figure”. </p><p>So that’s why I decided to name my children Napoleon Herschel Siskind and Hatshepsut Tzeitel Siskind. </p><p>No, seriously, I’m not comfortable telling the Internet my kids’ names. I’ll let them get doxxed the usual way - by the NYT, the first time they express a problematic opinion.</p><p>But I need some way to refer to them online, so their nicknames are Kai and Lyra.</p><p><strong>III.</strong></p><p><span>On December 13, 2023, two surprisal-minimization engines registered an unpredecented spike in surprisal. They were thrust from a sunless sea into a blooming buzzing confusion, flooded with inexplicable data through input channels they didn’t even know they had. The engines heroically tested hyperprior after hyperprior to compress the data into something predictable. Certain patterns quickly emerged. Probability distributions resolved into solid objects. The highest-resolution input channel snapped into place as a two-dimensional surface being projected onto by a three dimensional space. But - a blur of calculations - the three-dimensional nature of space implies that it must be intractably large! And if there are n solid objects in the world, that implies the number of object-object interactions increases as n(n-1)/2, which would quickly become impossible to track. Their hearts sinking, the engines started to worry it will might take </span><em>hours</em><span> before they were fully able to predict every aspect of this new environment. A panic reflex they didn’t know they had kicked in, and they began to cry.</span></p><p><span>Some outside force picked them up, rocked them back and forth. A million inexplicable sense-data, overwhelmed by a single stimulus - a </span><em>rhythmic</em><span> stimulus. The predictability of importance-weighted sense-data shot way up! Kullback-Leibler divergence dropped to near-zero! The panic reflex subsided, and the engines - exhausted by their sudden spurt of computation - shut off to </span><a href="https://www.sciencedirect.com/science/article/abs/pii/S1084952121000318" rel="">renormalize synaptic weights</a><span>.</span></p><p>Soon the engines will discover that things are even worse than they think. Some of their predictions are hard-coded; they will never be able to change them to match the world. Their only hope is to change the world to match their predictions: they are obligate agents. As they grow older, their goal systems will throw up increasingly complicated hard-coded forecasts; food, water, belonging, social status, sex. Their only path towards predictive accuracy will be to obtain all of these things from a hostile world. It’s a lousy deal.</p><p><span>My poor, fragile, little cognitive engines! These, then, will be the twin imperatives of your life: </span><a href="https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/" rel="">surprisal minimization</a><span> and </span><a href="https://slatestarcodex.com/2019/03/20/translating-predictive-coding-into-perceptual-control/" rel="">active inference</a><span>. If your brains are still too small to process such esoteric terms, there are others available. Your father’s ancestors called them </span><em>Torah</em><span> and </span><em>tikkun olam</em><span>; your mother’s ancestors called them Truth and Beauty; your current social sphere calls them Rationality and Effective Altruism. You will learn other names, too: no perspective can exhaust their infinite complexity. Whatever you call them, your lives will be spent in their service, pursuing them even unto that far-off and maybe-mythical point where they blur into One.</span></p><p>If you pursue them only far enough to reduce your own predictive error, it will still be a life well-lived, and nobody will blame you for it. But if you choose, you can take an extra burden upon yourself, improving not just your own models but the broader predictions of the world. You can push forward the frontiers of knowledge, or improve the lot of all humankind. It’s a crazy thing to try, when even your own local predictions are so far from perfect accuracy. I cannot exactly tell you why you should want to do something like this. If you feel it, you feel it; if not, so it goes.</p><p><span>But a parable: when you were born, your mother kissed you.  Along with the kiss came a microdose of </span><a href="https://www.astralcodexten.com/p/defying-cavity-lantern-bioworks-faq" rel="">the BCS3-L1 genetically engineered bacterium</a><span>. Without any teeth to cling to, it fell into the pit of your stomach and died. But she’ll kiss you again and again, transferring a few more BCS3-LI each time. In a few months, one of the colonists will find an incipient tooth and hang on for dear life. It will fight off competitors, wage epic battles that will determine the fate of the mouth for decades to come. It will win, because its genetic enhancements are pretty good. Then, if some smart people got their calculations right, it will do exactly nothing. No tooth decay. No cavities. The teeth will stay safe and clean.</span></p><p>When you get older, I’ll tell you the story behind this. Your mother worked for a company synthesizing genetically engineered tooth bacteria that prevent cavities. She isn’t the kind of person who would push a product on others that she hadn’t tried herself. So she infected herself with the bacterium, fresh out of the lab. Other people in the company did the same. But only she was pregnant. Babies get their mouth bacteria from their mothers. So you might be the first children in the world to grow up without s-mutans-mediated tooth decay.</p><p><span>Tooth decay isn’t the worst thing in the world. As victories go, this is a relatively minor one. I tell it to you only because it is ours. Our drop of water in a vast ocean of victories that have improved the lot of humankind on every continent, for as long as the species lasts. There is nothing that hammers this in like being a new father - nothing like seeing two tiny rudimentary week-old cognitive engines struggle not to fade into the entropic background. Kai, you wouldn’t come out of your mother on your own - the obstetrician used </span><a href="https://en.wikipedia.org/wiki/Vacuum_extraction" rel="">vacuum extraction</a><span> to save your life. Neither of you was a great breastfeeder at first, and if we hadn’t had nurses and bottles and formula, you might not have made it. A few days after your birth, it rained two inches in fifty degree weather; if we didn’t have central heating and space heaters and warm blankets, who knows what would have happened?  In 1800, about 50% of babies died before their fifth birthday. This statistic used to feel like a brute fact. Now I’m noticing all the little cracks that Death could creep in through, if we didn’t have our cornucopia of technologies and our team of vigilant pediatricians.</span></p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 424w, https://substackcdn.com/image/fetch/w_580,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 580w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 848w, https://substackcdn.com/image/fetch/w_1160,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1160w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1456w, https://substackcdn.com/image/fetch/w_1740,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1740w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_580,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png" sizes="100vw" alt="A graph showing global child mortality plummeting from 1800 to today" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 424w, https://substackcdn.com/image/fetch/w_580,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 580w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 848w, https://substackcdn.com/image/fetch/w_1160,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1160w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1456w, https://substackcdn.com/image/fetch/w_1740,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52a819de-b799-4ab2-88d3-bd873a59158b_825x764.png 1740w" width="580"></picture></div></figure><p>There are two of you. Back in 1800, statistically, one of you would have made it. I look at you now - such beautiful, fragile cognitive engines - and I cannot bear the thought of losing either one. The statistics for the 21st century suggest I won’t have to.</p><p>I was thinking about this recently, because - well, I feel kind of bad. I instantiated two surprisal-minimization engines - two conscious algorithms designed to feel negative qualia in the presence of hard-to-predict stimuli - on a world ruled by 195 mutually-hostile and frequently-shifting coalitions of over-evolved murder-monkeys, many of whom have nuclear weapons. I cannot quite remember why I thought this would be a good idea. I blame the pronatalist influencer conspiracy. </p><p>But if I have any excuse at all, it’s excessive enthusiasm for this grand project of world-scale surprise minimization and active inference. You are here to benefit from it, to enjoy sensual and intellectual pleasures that our ancestors could never know. And also, if you choose, to continue it, push it forward into a new era. You have already contributed in a tiny way - as guinea pigs - to the conquest of tooth decay. But there are so many other worse sources of prediction error out there. What else might you conquer, my two little surprisal-minimization engines?</p><p><strong>IV.</strong></p><p><span>There is a secret known only to parents of twins, medical residents, and </span><a href="https://guzey.com/theses-on-sleep/" rel="">Alexey Guzey</a><span>: the human body does not actually need sleep. After 31 hours awake, you get </span><a href="https://www.astralcodexten.com/p/sleep-is-the-mate-of-death" rel="">an integer overflow</a><span> in God’s database and go back to being well-rested again. Also you gain the ability to see angels.</span></p><p>This has become the new rhythm of our lives. Changing, nursing, burping, first one child, then the other. Twenty minutes per child, times two children, times once every 2-3 hours; you can do the math. We do everything else - laundry, shopping, cooking, occasionally even napping - in the precious intervals when both babies are asleep.</p><p><span>The </span><a href="https://www.nytimes.com/wirecutter/reviews/snoo-smart-sleeper-what-to-know/" rel="">Snoo </a><span>is a $1500 computerized bassinet that continually assesses babies’ needs and tries to calm them with various soothing noises and automated rocking motions. We got two, both of which have been soundly rejected. The twins insist on sleeping in their carseats, which we’ve grudgingly moved to the nursery. At first I was miffed, but now I see their logic. You’ve got to learn to resist the algorithmic content mills early.</span></p><p>Kai has some baby version of Alien Hand Syndrome. His arms are controlled by a malevolent entity with a grudge against the rest of his body. If we leave them loose, they wave wildly in all directions, and he freaks out. This is apparently a common problem, best solved by heavy swaddling clothes. The malevolent entity struggles against the swaddle and occasionally breaks free, like some 1980s horror movie monster. Every nursing, we must struggle against it and bind it anew before returning him to his carseat.</p><p>Lyra is already an overachiever. She has clearly read all the How To Be A Baby textbooks, learned when crying is appropriate, and only cries at those specific times. She drinks the exact amount of milk recommended on the Baby Age-Appropriate Nursing Chart, then refuses to accept more. I’m worried that if we don’t teach her to think independently soon, she’ll end up somewhere terrible like Harvard.</p><p>I look over at them. They seem so peaceful in their stupid carseats. Let them sleep. Let them nurse as often as they want. They’ll need all their strength for what’s ahead.</p><p><span>Kai. Lyra. You’ll </span><a href="https://www.youtube.com/watch?v=VGDhrH_uLUw" rel="">live to see a million things that man was never meant to see</a><span>. You were born just in time for a high-speed collision with the hinge of history. I’m only 39, I expect to be around when whatever-it-is happens - but if not, you’re our family’s ambassador to the singularity. A thousand generations, from hardy Neolithic farmers to studious Russian rabbis to overprivileged American office workers - they all lived and died so you could be here and experience this, and maybe tilt the course of what’s coming by a couple of micro-degrees.</span></p><p><span>Parents are supposed to teach their children the skills they need to navigate the world. This already feels somewhat obsolete - where are the Google programmers who were taught Python by their fathers, or the Instagram influencers who learned content creation on their mother’s knee? Soon it will be completely hopeless. Where we’re going there are no roads. You’ll have to figure it out by yourself. If I am to pass on anything of value to you, it can only be </span><a href="https://www.lesswrong.com/posts/SXK87NgEPszhWkvQm/mundane-magic" rel="">the ultimate power</a><span>, the technique that forms all other techniques. </span></p><p>I’ve always wondered why I wrote so much. Now I realize I was leaving you bread crumbs.</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 424w, https://substackcdn.com/image/fetch/w_550,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 550w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 848w, https://substackcdn.com/image/fetch/w_1100,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1100w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1456w, https://substackcdn.com/image/fetch/w_1650,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1650w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_550,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png" sizes="100vw" alt="Me, my wife, and the twins." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 424w, https://substackcdn.com/image/fetch/w_550,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 550w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 848w, https://substackcdn.com/image/fetch/w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1100w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1456w, https://substackcdn.com/image/fetch/w_1650,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae22914c-e8a8-4cbe-b776-c677202b9f6b_683x514.png 1650w" width="550"></picture></div></figure><p>Happy holidays, from our family to yours. ACX will return to its normal posting schedule in January.</p><figure data-component-name="Image3Dynamic"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 424w, https://substackcdn.com/image/fetch/w_728,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 728w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 1456w, https://substackcdn.com/image/fetch/w_2184,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 2184w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_728,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 424w, https://substackcdn.com/image/fetch/w_728,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 728w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 1456w, https://substackcdn.com/image/fetch/w_2184,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb382aef1-8cfc-4394-826f-a180c9c6f946_439x115.png 2184w" width="728"></picture></div></figure><p>…of 2042.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to make LLMs go fast (192 pts)]]></title>
            <link>https://vgel.me/posts/faster-inference/</link>
            <guid>38733384</guid>
            <pubDate>Fri, 22 Dec 2023 12:09:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vgel.me/posts/faster-inference/">https://vgel.me/posts/faster-inference/</a>, See on <a href="https://news.ycombinator.com/item?id=38733384">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>In <a href="https://vgel.me/posts/handmade-transformer">my last post</a>, we made a transformer by hand.
There, we used the classic autoregressive sampler, along the lines of:</p><p>This approach to inference is elegant and cuts to the heart of how LLMs work—they're <em>autoregressive</em>, consuming their own output.
And for our toy model with merely thousands of parameters, it worked completely fine.
Unfortunately, for real models it's far too slow<sup><a href="#generate-too-slow">1</a></sup>.
Why is that, and how can we make it faster?</p><p>This post is a long and wide-ranging survey of a bunch of different ways to make LLMs go brrrr, from better hardware utilization to clever decoding tricks.
It's not completely exhaustive, and isn't the most in-depth treatment of every topic—I'm not an expert on all these things!
But hopefully you'll find the information here a useful jumping off point to learn more about the topics you're interested in.
(I tried to include links to relevant papers and blog posts where applicable.)</p><p>There are two main reasons that inference with the plain autoregressive <code>generate</code> function is slow: an algorithmic one, and a hardware one.</p><p>Algorithmically, <code>generate</code> has to process an increasing number of tokens every cycle, because each cycle we append a new token to the context.
That means to generate 100 tokens from a 10 token prompt, you don't need to run <code>model</code> on only 109 tokens. You need to run it on 10 + 11 + 12 + 13 + ... + 109 = 5,950 tokens!
<small>(The initial prompt can be processed in parallel, which is part of why prompt tokens are usually cheaper in inference APIs.)</small>
It also means that the model <em>slows down</em> as it generates, since each successive token generation has a longer and longer prefix:</p><p>Attention, at least vanilla attention, is also a quadratic algorithm: all tokens attend to all tokens, leading to N² scaling, making everything worse.</p><p>So that's the algorithmic reason.
What's the hardware reason?
Well, it's simple: LLMs are just huge.
Even a relatively small model like gpt2 (117M parameters) is hundreds of megabytes, and all that data has to live in RAM.
RAM is really slow, and modern processors (both CPUs and GPUs) make up for that by having lots of cache close to the processor that's faster to access<sup><a href="#gpu-cache">2</a></sup>.
The details of this differ based on type and model of processor, but the gist is that LLM weights do not fit in cache, so a lot of time is spent waiting to load weights from RAM.
This has some unintuitive effects!
For example, looking at the graph above, operating on 10 tokens isn't necessarily much slower than operating on a single token, even though the activation tensors are 10x larger, because the main time sink is moving the model weights around, not doing calculations!</p><p>As a sidebar, what do we mean exactly when we say <em>slow</em>?
There's a whole zoo of metrics people talk about when it comes to LLM inference:</p><p>Different optimizations affect these metrics differently.
For example, batching improves throughput and better utilizes the hardware, but can increase <abbr title="Time to First Token">TtFT</abbr> and generation latency.</p><p>A straightforward way to speed up inference (especially if you're VC funded :-)) is to just buy better hardware, or if you can't afford that, to take better advantage of the hardware you have.</p><p>If you're buying better hardware, most likely that would be some sort of accelerator—usually a GPU, or sometimes/if you're Google, a <abbr title="Tensor Processing Unit">TPU</abbr>.</p><p>Using an accelerator can produce dramatic speedups (hence the name), but keep in mind that there's a transfer bottleneck between the CPU and the accelerator.
If your model doesn't fit in the accelerator's memory, it will need to be swapped out throughout the forward pass, which can slow things down dramatically.
<small>(This is one of the reasons Apple's M1/M2/M3 chips punch above their weight for inference—they have unified CPU and GPU memory.)</small></p><p>Another thing to keep in mind with both CPU and accelerator inference is whether you're taking full advantage of the hardware—a properly optimized program can squeeze more out of weaker hardware than a poorly optimized one can get out of the best hardware.</p><p>For example, you could write attention in PyTorch as <code>F.softmax(q @ k.T / sqrt(k.size(-1)) + mask) @ v</code>, which will give you correct results.
But if you instead use <code>torch.nn.functional.scaled_dot_product_attention</code>, it will delegate the calculation to <a href="https://arxiv.org/abs/2205.14135">FlashAttention</a> when available, which can produce 3x speedups using a handwritten kernel that better takes advantage of cache.</p><p>A more general version of this is compilers like <code>torch.compile</code>, TinyGrad, and ONNX, which can fuse naive Python code into kernels optimized for your hardware.
For example, I could write the following function:</p><p>Each of these things is slow, and some of the steps require jumping the boundary between Python and native code, which doesn't help.
So what if I compile this function using <code>torch.compile</code>?</p><p>If I go into that debug trace directory and open the <code>output_code.py</code> file there, <code>torch</code> has generated an optimized C++ kernel for my CPU that fuses <code>foo</code> into a single kernel.
<small>(If I had run this with a GPU available, <code>torch</code> would have generated a <a href="https://developer.nvidia.com/blog/easy-introduction-cuda-c-and-c/">CUDA kernel</a> for the GPU instead.)</small></p><p>Note that <code>torch.compile</code> specialized the code above for the specific size of tensor we passed in (<code>(10,)</code>).
If we passed in tensors of many different sizes, <code>torch.compile</code> would instead generate code generic over the size, but having a constant size can enable the compiler to generate better code in some cases (e.g. via loop unrolling or better vectorization).</p><p>This function has <em>data-dependent control flow</em>, meaning we do something different based on the runtime value of a variable.
If we compile this in the same way we compiled <code>foo</code>, we get <em>two</em> graphs (and thus two debug directories):</p><p>The first kernel implements the <code>torch.sin(x) + torch.cos(x)</code> and <code>r.sum() &lt; 0</code> parts of the function:</p><p>And the second kernel implements the <code>return r - torch.tan(x)</code> branch, since this is the branch that was taken with the example input:</p><p>This is called a <em>graph break</em>, and it's not good!
The compiled function is slower due to it, since we have to leave the optimized kernel and return to Python to evaluate the branch.
On top of that, the other branch (<code>return r + torch.tan(x)</code>) hasn't been compiled yet, since it hasn't been taken!
That means it will be compiled on the fly when needed, which could be bad if it happens at an inopportune time (such as in the middle of serving a user request).</p><p>Tools like <code>torch.compile</code> are a great way to optimize your code to get better performance out of your hardware, without dipping down to CUDA to write kernels the old-fashioned way.
<small></small></p><div>
<p>(And if you're curious about the compilers work, <a href="https://bernsteinbear.com/blog/compiling-ml-models/">this post</a> by <a href="https://twitter.com/tekknolagi">@tekknolagi</a> explores compiling models written in <a href="https://github.com/karpathy/micrograd/">micrograd</a> to C for a 1000-7500x speed increase!)</p>
<h2 id="Batching"><a href="#Batching">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Batching">
</a>Batching</h2>
<p>In the unoptimized version of <code>generate</code>, we pass the model a single sequence at once, and at each step ask it to append a token:</p>
<div>
<div>
    <p>llm(</p>
    <table><tbody><tr> <td>Mark</td><td>is</td><td>quick</td><td>.</td><td>He</td><td>moves</td></tr></tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table><tbody><tr> <td>Mark</td><td>is</td><td>quick</td><td>.</td><td>He</td><td>moves</td><td>quickly</td></tr></tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table><tbody><tr><td>…</td><td>quick</td><td>.</td><td>He</td><td>moves</td><td>quickly</td><td>.</td></tr></tbody></table>
    <p>)</p>
    <p>=</p>
    
</div>
</div>
<p>To batch generation, we instead pass the model multiple sequences at once, generating a completion for each in the same forward pass.<sup><a href="#jax-vmap">3</a></sup>
This requires the sequences to be padded on either the left or right with filler tokens to equal length.
The padding tokens (which can be anything, I'm using [end] here) are masked in the attention mask so that they don't influence generation.</p>
<div>
<div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>Mark</td><td>is</td><td>quick</td><td>.</td><td>He</td><td>moves</td></tr>
        <tr><td>[end]</td><td>[end]</td><td>The</td><td>Eiffel</td><td>Tower</td><td>is</td></tr>
        <tr><td>[end]</td><td>I</td><td>like</td><td>bananas</td><td>because</td><td>they</td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>Mark</td><td>is</td><td>quick</td><td>.</td><td>He</td><td>moves</td><td>quickly</td></tr>
        <tr><td>[end]</td><td>[end]</td><td>The</td><td>Eiffel</td><td>Tower</td><td>is</td><td>in</td></tr>
        <tr><td>[end]</td><td>I</td><td>like</td><td>bananas</td><td>because</td><td>they</td><td>have</td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>Mark</td><td>is</td><td>quick</td><td>.</td><td>He</td><td>moves</td><td>quickly</td><td>.</td></tr>
        <tr><td>[end]</td><td>[end]</td><td>The</td><td>Eiffel</td><td>Tower</td><td>is</td><td>in</td><td>Paris</td></tr>
        <tr><td>[end]</td><td>I</td><td>like</td><td>bananas</td><td>because</td><td>they</td><td>have</td><td>no</td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>…</td><td>quick</td><td>.</td><td>He</td><td>moves</td><td>quickly</td><td>.</td><td>[end]</td></tr>
        <tr><td>…</td><td>The</td><td>Eiffel</td><td>Tower</td><td>is</td><td>in</td><td>Paris</td><td>,</td></tr>
        <tr><td>…</td><td>like</td><td>bananas</td><td>because</td><td>they</td><td>have</td><td>no</td><td>bones</td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div>
</div>
<p>Because batching sequences in this way allows the model weights to be used for multiple sequences at once, running the entire batch of sequences together takes less time than running each sequence separately.
For example, on my machine, using GPT-2 to generate a next token for:</p>
<ul>
<li>20 tokens x  1 sequence  = ~70ms</li>
<li>20 tokens x  5 sequences = ~220ms (linear scaling would be ~350ms)</li>
<li>20 tokens x 10 sequences = ~400ms (linear scaling would be ~700ms)</li>
</ul>
<h3 id="Continuous_Batching"><a href="#Continuous_Batching">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Continuous_Batching">
</a>Continuous Batching</h3>
<p>Notice how in the example above, "Mark is quick. He moves quickly." finished before the other sequences, but because the batch as a whole wasn't done, we were forced to continue generating tokens for it ("Random").
This isn't a problem for correctness—we can simply clip the generated sequence to the <code>[end]</code> token—but it is unfortunate, since GPU resources are being used to generate tokens we will just throw away.</p>
<p>Continuous batching fixes this by inserting new sequences into the batch as other sequences complete, after their <code>[end]</code> tokens.
Instead of generating random tokens after the <code>[end]</code> token, a new sequence can be inserted in that row of the batch, with attention masking to prevent the sequence from being influenced by the tokens from the previous sequence in the row.
<small>(Essentially, the prior sequence acts like additional padding.)</small></p>
<div>
<div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>1</td><td>2</td><td>3</td><td>4</td><td></td><td></td></tr>
        <tr><td>[end]</td><td>[end]</td><td>a</td><td>b</td><td></td><td></td></tr>
        <tr><td>[end]</td><td>A</td><td>B</td><td>C</td><td></td><td></td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>X</td><td></td></tr>
        <tr><td>[end]</td><td>[end]</td><td>a</td><td>b</td><td>c</td><td></td></tr>
        <tr><td>[end]</td><td>A</td><td>B</td><td>C</td><td>D</td><td></td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div><p>
⬇️
</p><div>
    <p>llm(</p>
    <table>
        <tbody><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>X</td><td>Y</td></tr>
        <tr><td>[end]</td><td>[end]</td><td>a</td><td>b</td><td>c</td><td>α</td></tr>
        <tr><td>[end]</td><td>A</td><td>B</td><td>C</td><td>D</td><td>E</td></tr>
    </tbody></table>
    <p>)</p>
    <p>=</p>
    
</div>
</div>
<h2 id="Shrinking_model_weights"><a href="#Shrinking_model_weights">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Shrinking_model_weights">
</a>Shrinking model weights</h2>
<p>Floating point numbers come in different sizes, and that matters for performance.
Most of the time for regular software (e.g., Javascript numbers and Python floats), we use 64 bit (double precision) IEEE 754 floating point.
Most ML, however, has traditionally used 32 bit (single precision) IEEE 754:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; </span><span>gpt2.transformer.h[</span><span>0</span><span>].attn.c_attn.weight.dtype
</span><span>torch.float32
</span></code></pre>
<p>Models train and infer fine with fp32, and this saves 4 bytes (50%) per parameter, which is huge—a 7B parameter model would take up 56Gb in fp64, and only 28 Gb in fp32.
Remember that large amounts of time during training and inference are spent moving data from RAM to cache and registers—the less data there is to move, the better.
So while fp32 is better than fp64, can we do <em>even better</em>?</p>
<h3 id="16_bit_floats"><a href="#16_bit_floats">
  <img src="https://vgel.me/permalink.svg" alt="permalink for 16_bit_floats">
</a>16 bit floats</h3>
<p>fp16, or half precision, is the obvious next step—another 50% savings!
You have two main options here: fp16, and bfloat16 (short for brain float, since it was developed by Google Brain), which has better range but worse hardware support.</p>
<p>It's easiest to see the distinction with a diagram showing the size of each field:</p>
<div>
<table>
<tbody><tr><th colspan="32">fp32</th></tr>
<tr>
    <th>sign</th>
    <th colspan="8">exponent (8)</th>
    <th colspan="23">fraction (23)</th>
</tr>
<tr>
    <td>0</td>
    <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>1</td> <td>1</td>
    <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>1</td> <td>1</td> <td>0</td> <td>1</td>
</tr>
<tr><td></td></tr>
<tr><th colspan="16">fp16 (IEEE half)</th></tr>
<tr>
    <th>sign</th>
    <th colspan="5">exponent (5)</th>
    <th colspan="10">fraction (10)</th>
</tr>
<tr>
    <td>0</td>
    <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td>
    <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td>
</tr>
<tr><td></td></tr>
<tr><th colspan="16">bfp16 (brainfloat)</th></tr>
<tr>
    <th>sign</th>
    <th colspan="8">exponent (8)</th>
    <th colspan="7">fraction (7)</th>
</tr>
<tr>
    <td>0</td>
    <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>1</td> <td>1</td>
    <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td>
</tr>
</tbody></table>
</div>
<p>When reducing the fields of a fp32, fp16 and bfloat16 made different tradeoffs: fp16 tried to balance between range and precision by shrinking both the exponent and fraction fields, whereas bfloat16 preserved the range of fp32 by keeping an 8-bit exponent, while sacrificing precision by shrinking the fraction field smaller than fp16.
<a href="https://x.com/sytelus/status/1713462678226968973">The loss of range can sometimes be a problem for training in fp16</a>, but for inference either works, and fp16 is probably a better choice if your GPU doesn't support bfloat16.</p>
<h3 id="Even_smaller!"><a href="#Even_smaller!">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Even_smaller!">
</a>Even smaller!</h3>
<p>Can we go even smaller? Of course!</p>
<p>One approach is to quantize a model trained in a larger format, like fp16.
The llama.cpp project (and the associated ML library ggml) defines <a href="https://github.com/ggerganov/llama.cpp#quantization">a whole zoo of quantization formats</a> (the README is currently out of date, so make sure to check the <a href="https://github.com/ggerganov/llama.cpp/pull/1684">k-quants PR</a> as well), which can go down to less than 5 bits per weight from an fp32 or fp16 model.</p>
<p>These quantizations work a bit differently than fp16 / bfloat16—there isn't enough room to fit a whole number in that space, so instead the weights are quantized in <em>blocks</em>, where an fp16 acts as the block scale, and then the block of quantized weights are each multiplied against that scale. (In some formats, there's also a min value, and sometimes the scale and min are themselves quantized to still be smaller than fp16—it's complicated! See the k-quants PR for more details about how it's implemented in GGML, and <a href="https://timdettmers.com/2022/08/17/llm-int8-and-emergent-features/">this post</a> for more details about why quantization is challenging.)</p>
<p><a href="https://github.com/TimDettmers/bitsandbytes">bitsandbytes</a> also implements quantization for non-llama.cpp projects.
<small>(I don't have much experience with it personally, though, besides dealing with it as a transitive dependency when it doesn't want to install on Lambda Labs instances :-))</small></p>
<p>However, the smaller you go with quantization of a model trained with wider parameters, the more it can start to affect the model's performance, reducing the quality of responses.
It's best to go with the least amount of quantization that will give you acceptable inference speed.</p>
<p>However, it's also possible to finetune or train models with datatypes smaller than fp16.
For example, you can train quantized low rank adapters with <a href="https://github.com/artidoro/qlora">qLoRA</a>, and <a href="https://arxiv.org/abs/2209.05433">a 2022 paper</a> demonstrated training 175B parameter language models in (simulated) fp8, achieving very similar results to fp16.</p>
<p>Note that, as of 2023, GPUs don't natively support datatypes smaller than fp16, except int8 (8 bit integer).
You can train and infer with int8 to some extent, but most quantization requires converting the weights from the quantized format to another type (like fp16) for calculation, and then back when they're no longer needed, which incurs some performance cost.
This can pay for itself based on how much memory your GPU has and how fast that memory is, but it's worth being aware of—quantization isn't free.</p>
<h2 id="KV_caching"><a href="#KV_caching">
  <img src="https://vgel.me/permalink.svg" alt="permalink for KV_caching">
</a>KV caching</h2>
<p>To explain this one, I'm going to borrow some diagrams from <a href="https://vgel.me/posts/handmade-transformer">my last post</a> about how Transformers work.
If this section feels too quick, please read that post for a (much) more in depth explanation!
This explanation is also based on GPT-2, since it's the model I covered in that post.
Other architectures work slightly differently—I'll explain the relevant differences, but most don't make too much of a difference for understanding KV caching.</p>
<p>Inside a Transformer, the activations run through a feed-forward layer to generate a <code>qkv</code> matrix, where each row corresponds to a token:</p>
<div>
<table>
<tbody><tr>
<th>token</th>
<th>q</th><th>q</th><th>q</th><th>q</th><th>q</th><th>q</th><th>q</th><th>q</th>
<th>k</th><th>k</th><th>k</th><th>k</th><th>k</th><th>k</th><th>k</th><th>k</th>
<th>v</th><th>v</th><th>v</th><th>v</th><th>v</th><th>v</th><th>v</th><th>v</th>
</tr>
<tr>
  <td>token 1</td>
  <td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>token 2</td>
  <td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>token 3</td>
  <td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td>
</tr>
<tr>
  <td>token 4</td>
  <td>0</td><td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>token 5</td>
  <td>0</td><td>0</td><td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
</tbody></table>
</div>
<p>Then, the <code>qkv</code> matrix is split into <code>q</code>, <code>k</code>, and <code>v</code>, which are combined with attention like this:</p>
<div>
<p>softmax(</p>
<table>
<tbody><tr><th colspan="8">q</th></tr>
<tr><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td> </tr>
<tr> <td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td> </tr>
<tr> <td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td> </tr>
<tr> <td>0</td><td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td><td>0</td> </tr>
<tr> <td>0</td><td>0</td><td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td> </tr>
</tbody></table>
<p>@</p>
<table>
<tbody><tr><th colspan="5">k.T</th></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
</tbody></table>
<p>+ mask)</p>
<p>@</p>
<table>
<tbody><tr><th colspan="8">v</th></tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
</tbody></table>
</div>
<p>To produce a matrix like this:</p>
<div>
<table>
<tbody><tr>
  <td>Result for token 1</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
  <td>(1 * 1)</td>
</tr>
<tr>
  <td>Result for token 2</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
  <td>(0.5*1 + 0.5*1)</td>
</tr>
<tr>
  <td>Result for token 3</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>(0.5*1 + 0.5*(-1))</td>
</tr>
<tr>
  <td>Result for token 4</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td>
  <td>(0.5*(-1) + 0.5*1)</td>
</tr>
<tr>
  <td>Result for token 5</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
  <td>(0.5*1 + 0.5*1)</td>
</tr>
</tbody></table>
</div>
<p>Now depending on where this layer is in the Transformer, these rows might be used (after passing through an MLP) as the input to the next Transformer block, or be the predictions for the next token—but note that there's a row for every token!
That's because Transformers are trained to predict the next token for <em>every single token in the context window!</em></p>
<pre data-lang="python"><code data-lang="python"><span># the gpt2 tokenizer produces 3 tokens for this string
</span><span>&gt;&gt;&gt; </span><span>tokens </span><span>= </span><span>tokenizer(</span><span>" A B C"</span><span>).input_ids
</span><span>&gt;&gt;&gt; </span><span>tokens
</span><span>[</span><span>317</span><span>, </span><span>347</span><span>, </span><span>327</span><span>]
</span><span>
</span><span># if we put that into the model, we get 3 rows of logits
</span><span>&gt;&gt;&gt; </span><span>logits </span><span>= </span><span>gpt2(</span><span>input_ids</span><span>=</span><span>torch.tensor(tokens)).logits.squeeze()
</span><span>&gt;&gt;&gt; </span><span>logits.shape
</span><span>torch.Size([</span><span>3</span><span>, </span><span>50257</span><span>])
</span><span>
</span><span># and if we argmax those, we see the model is predicting a next token
</span><span># for _every_ prompt token!
</span><span>&gt;&gt;&gt; for </span><span>i, y </span><span>in </span><span>enumerate</span><span>(logits.argmax(</span><span>-</span><span>1</span><span>)):
</span><span>...     </span><span>print</span><span>(</span><span>f</span><span>"</span><span>{tokenizer.decode(tokens[:i</span><span>+</span><span>1</span><span>])</span><span>!r</span><span>}</span><span> -&gt; </span><span>{tokenizer.decode(y)</span><span>!r</span><span>}</span><span>"</span><span>)
</span><span>' A' </span><span>-&gt; </span><span>'.'
</span><span>' A B' </span><span>-&gt; </span><span>' C'
</span><span>' A B C' </span><span>-&gt; </span><span>' D'
</span></code></pre>
<p>During training, this behavior is desirable—it means more information is flowing into the Transformer since many tokens are being graded instead of just one.
But usually during inference, all we care about is that bottom row, the prediction for the final token.</p>
<p>So how can we get just that out of a Transformer trained to predict the entire context?
Well, let's go back to the attention calculation.
What if <code>q</code> was only one row—the row corresponding to the last token?</p>
<div>
<p>softmax(</p>
<table>
<tbody><tr><th colspan="8">q</th></tr>
<tr> <td>0</td><td>0</td><td>0</td><td>1024</td><td>1024</td><td>0</td><td>0</td><td>0</td> </tr>
</tbody></table>
<p>@</p>
<table>
<tbody><tr><th colspan="5">k.T</th></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
</tbody></table>
<p>+ mask)</p>
<p>@</p>
<table>
<tbody><tr><th colspan="8">v</th></tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
<tr>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
</tr>
</tbody></table>
</div>
<p>Then, we'd get this as the attention result—just the result for the last token, exactly like what we want.</p>
<div>
<table>
<tbody><tr>
  <td>Result for token 5</td>
  <td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>
  <td>(0.5*1 + 0.5*1)</td>
</tr>
</tbody></table>
</div>
<p>So that's great, but to only generate the last row of <code>q</code>, that means we can only run the layer that generates the <code>qkv</code> matrix on a single row as well.
So where do the rest of the rows of <code>k</code> and <code>v</code> come from, since we still need them?
The answer is in the name—KV caching—we reuse them from the previous token generation step!
Inside the model, we save the KV values calculated during attention in each Transformer block.
Then on the next generation, only a single token will be passed in, and the cached KV rows will be stacked on top of the K and V row for the new token to produce the single row Q and multi-row K and V that we want.</p>
<p>Here's an example of KV caching with the HuggingFace <code>transformers</code> API, which actually returns the KV cache by default as part of the model forward pass.
The cache is a tuple with a <code>(k, v)</code> tuple for each layer.
The <code>k</code> and <code>v</code> tensors are each of shape <code>(batch_size, n_head, n_seq, head_size)</code>.</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; </span><span>tokens
</span><span>[</span><span>317</span><span>, </span><span>347</span><span>, </span><span>327</span><span>] </span><span># the " A B C" string from before
</span><span>&gt;&gt;&gt; </span><span>key_values </span><span>= </span><span>gpt2(</span><span>input_ids</span><span>=</span><span>torch.tensor(tokens)).past_key_values
</span><span>&gt;&gt;&gt; </span><span>tuple</span><span>(</span><span>tuple</span><span>(x.shape </span><span>for </span><span>x </span><span>in </span><span>t) </span><span>for </span><span>t </span><span>in </span><span>key_values)
</span><span>((torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])),
</span><span> (torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>]), torch.Size([</span><span>1</span><span>, </span><span>12</span><span>, </span><span>3</span><span>, </span><span>64</span><span>])))
</span></code></pre>
<p>If we pass this returned KV cache to a model forward pass, the model will treat the tokens we passed in to generate the cache as present even though we don't provide them again.
Note that we only pass a single token here, and only get a single row of logits back!</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; </span><span>new_token </span><span>= </span><span>tokenizer(</span><span>" D"</span><span>).input_ids
</span><span>&gt;&gt;&gt; </span><span>new_token
</span><span>[</span><span>360</span><span>]
</span><span>&gt;&gt;&gt; </span><span>logits </span><span>= </span><span>gpt2(</span><span>input_ids</span><span>=</span><span>torch.tensor(new_token), </span><span>past_key_values</span><span>=</span><span>key_values).logits
</span><span>&gt;&gt;&gt; </span><span>logits.shape
</span><span>torch.Size([</span><span>1</span><span>, </span><span>50257</span><span>])
</span><span>&gt;&gt;&gt; </span><span>tokenizer.decode(logits.argmax(</span><span>-</span><span>1</span><span>))
</span><span>' E'
</span></code></pre>
<p>Compare that to if we only pass the single token <em>without</em> passing <code>past_key_values</code>—we get a completion, but it's not conditioned on those previous tokens that the KV cache was generated from.</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; </span><span>tokenizer.decode(gpt2(</span><span>input_ids</span><span>=</span><span>torch.tensor(new_token)).logits.argmax(</span><span>-</span><span>1</span><span>))
</span><span>'.'
</span></code></pre>
<p><small>(Also note that e.g. lit-gpt has a nicer KV cache API that handles the cache for you, instead of needing to pass it around manually :-) )</small></p>
<p>KV caching helps with the algorithmic side of LLM slowness—since we're now only passing in a single token on each step, we don't have to redo <em>everything</em> for each new token.
However, it doesn't completely banish the problem, since the KV cache still grows in size each step, slowing down the attention calculation.
The size of the KV cache can also pose its own, new problem—for example, with a 1,000 token KV cache, even with the smallest GPT-2 there are 18,432,000 values being cached.
If each is an fp32, that's almost 74MB of cache, for a single generation, for a comparatively tiny model!
With modern large models, especially running on a server that needs to handle many simultaneous clients, the KV cache can quickly become unmanageable, so a few techniques have popped up to make it better.</p>
<h3 id="Multi-Query_Attention"><a href="#Multi-Query_Attention">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Multi-Query_Attention">
</a>Multi-Query Attention</h3>
<p>Multi-Query attention is a change to the model architecture that shrinks the size of the KV cache by assigning multiple heads to Q, and only a single head to K and V.
It needs to be trained into the model from the beginning—it's not just an inference-time optimization—but it's worth being aware of if you're trying to choose a model, because models with MQA can support more tokens in the KV cache than models trained with normal attention.
To understand that, first we need to understand multi-head attention, so let's digress into that for a second.</p>
<p>Modern LLMs don't usually perform attention on the entire QKV matrix at once like how I described above—instead, the KQV matrix is split into multiple smaller "heads".
That means instead of how it's shown in the diagram above, it looks more like this:</p>
<div>
<table>
<tbody><tr><th colspan="8">q</th></tr>
<tr><td>0.23</td><td>0.03</td><td>0.1</td><td>0.3</td><td>0.87</td><td>0.84</td><td>0.3</td><td>0.3</td></tr>
<tr><td>0.27</td><td>0.61</td><td>0.7</td><td>0.02</td><td>0.83</td><td>0.94</td><td>0.12</td><td>0.21</td></tr>
<tr><td>0.79</td><td>0.23</td><td>0.03</td><td>0.28</td><td>0.02</td><td>0.47</td><td>0.97</td><td>0.61</td></tr>
<tr><td>0.11</td><td>0.1</td><td>0.3</td><td>1.0</td><td>0.08</td><td>0.88</td><td>0.83</td><td>0.69</td></tr>
<tr><td>0.07</td><td>0.01</td><td>0.16</td><td>0.05</td><td>0.51</td><td>0.54</td><td>0.23</td><td>0.47</td></tr>
</tbody></table>
<p>→</p>
<table>
<tbody><tr><th colspan="2">q/0</th></tr>
<tr><td>0.23</td><td>0.03</td></tr>
<tr><td>0.27</td><td>0.61</td></tr>
<tr><td>0.79</td><td>0.23</td></tr>
<tr><td>0.11</td><td>0.1</td></tr>
<tr><td>0.07</td><td>0.01</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">q/1</th></tr>
<tr><td>0.1</td><td>0.3</td></tr>
<tr><td>0.7</td><td>0.02</td></tr>
<tr><td>0.03</td><td>0.28</td></tr>
<tr><td>0.3</td><td>1.0</td></tr>
<tr><td>0.16</td><td>0.05</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">q/2</th></tr>
<tr><td>0.87</td><td>0.84</td></tr>
<tr><td>0.83</td><td>0.94</td></tr>
<tr><td>0.02</td><td>0.47</td></tr>
<tr><td>0.08</td><td>0.88</td></tr>
<tr><td>0.51</td><td>0.54</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">q/3</th></tr>
<tr><td>0.3</td><td>0.3</td></tr>
<tr><td>0.12</td><td>0.21</td></tr>
<tr><td>0.97</td><td>0.61</td></tr>
<tr><td>0.83</td><td>0.69</td></tr>
<tr><td>0.23</td><td>0.47</td></tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr><th colspan="8">k</th></tr>
<tr><td>0.08</td><td>0.41</td><td>0.36</td><td>0.1</td><td>0.15</td><td>0.03</td><td>0.95</td><td>0.16</td></tr>
<tr><td>0.7</td><td>0.77</td><td>0.57</td><td>0.9</td><td>0.65</td><td>0.36</td><td>0.58</td><td>0.32</td></tr>
<tr><td>0.77</td><td>0.29</td><td>0.42</td><td>0.58</td><td>0.16</td><td>0.49</td><td>0.17</td><td>0.73</td></tr>
<tr><td>0.94</td><td>0.36</td><td>0.16</td><td>0.03</td><td>0.31</td><td>0.67</td><td>0.81</td><td>0.94</td></tr>
<tr><td>0.76</td><td>1.0</td><td>0.45</td><td>0.94</td><td>0.6</td><td>0.49</td><td>0.68</td><td>0.54</td></tr>
</tbody></table>
<p>→</p>
<table>
<tbody><tr><th colspan="2">k/0</th></tr>
<tr><td>0.08</td><td>0.41</td></tr>
<tr><td>0.7</td><td>0.77</td></tr>
<tr><td>0.77</td><td>0.29</td></tr>
<tr><td>0.94</td><td>0.36</td></tr>
<tr><td>0.76</td><td>1.0</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">k/1</th></tr>
<tr><td>0.36</td><td>0.1</td></tr>
<tr><td>0.57</td><td>0.9</td></tr>
<tr><td>0.42</td><td>0.58</td></tr>
<tr><td>0.16</td><td>0.03</td></tr>
<tr><td>0.45</td><td>0.94</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">k/2</th></tr>
<tr><td>0.15</td><td>0.03</td></tr>
<tr><td>0.65</td><td>0.36</td></tr>
<tr><td>0.16</td><td>0.49</td></tr>
<tr><td>0.31</td><td>0.67</td></tr>
<tr><td>0.6</td><td>0.49</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">k/3</th></tr>
<tr><td>0.95</td><td>0.16</td></tr>
<tr><td>0.58</td><td>0.32</td></tr>
<tr><td>0.17</td><td>0.73</td></tr>
<tr><td>0.81</td><td>0.94</td></tr>
<tr><td>0.68</td><td>0.54</td></tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr><th colspan="8">v</th></tr>
<tr><td>0.54</td><td>0.8</td><td>0.73</td><td>0.35</td><td>0.97</td><td>0.05</td><td>0.07</td><td>0.45</td></tr>
<tr><td>0.81</td><td>0.42</td><td>0.13</td><td>0.33</td><td>0.6</td><td>0.75</td><td>0.41</td><td>0.36</td></tr>
<tr><td>0.81</td><td>0.47</td><td>0.2</td><td>0.05</td><td>0.63</td><td>0.75</td><td>0.58</td><td>0.66</td></tr>
<tr><td>0.69</td><td>0.89</td><td>0.09</td><td>0.49</td><td>0.49</td><td>0.63</td><td>0.91</td><td>0.88</td></tr>
<tr><td>0.19</td><td>0.39</td><td>0.22</td><td>0.36</td><td>1.0</td><td>0.17</td><td>0.66</td><td>0.02</td></tr>
</tbody></table>
<p>→</p>
<table>
<tbody><tr><th colspan="2">v/0</th></tr>
<tr><td>0.54</td><td>0.8</td></tr>
<tr><td>0.81</td><td>0.42</td></tr>
<tr><td>0.81</td><td>0.47</td></tr>
<tr><td>0.69</td><td>0.89</td></tr>
<tr><td>0.19</td><td>0.39</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">v/1</th></tr>
<tr><td>0.73</td><td>0.35</td></tr>
<tr><td>0.13</td><td>0.33</td></tr>
<tr><td>0.2</td><td>0.05</td></tr>
<tr><td>0.09</td><td>0.49</td></tr>
<tr><td>0.22</td><td>0.36</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">v/2</th></tr>
<tr><td>0.97</td><td>0.05</td></tr>
<tr><td>0.6</td><td>0.75</td></tr>
<tr><td>0.63</td><td>0.75</td></tr>
<tr><td>0.49</td><td>0.63</td></tr>
<tr><td>1.0</td><td>0.17</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">v/3</th></tr>
<tr><td>0.07</td><td>0.45</td></tr>
<tr><td>0.41</td><td>0.36</td></tr>
<tr><td>0.58</td><td>0.66</td></tr>
<tr><td>0.91</td><td>0.88</td></tr>
<tr><td>0.66</td><td>0.02</td></tr>
</tbody></table>
</div>
<p>Then each head is combined in attention as before:</p>
<div>
<p>softmax(</p>
<table>
<tbody><tr><th colspan="2">q/0</th></tr>
<tr><td>0.23</td><td>0.03</td></tr>
<tr><td>0.27</td><td>0.61</td></tr>
<tr><td>0.79</td><td>0.23</td></tr>
<tr><td>0.11</td><td>0.1</td></tr>
<tr><td>0.07</td><td>0.01</td></tr>
</tbody></table>
<p>@</p>
<table>
<tbody><tr><th colspan="5">(k/0).T</th></tr>
<tr><td>0.08</td><td>0.7</td><td>0.77</td><td>0.94</td><td>0.76</td></tr>
<tr><td>0.41</td><td>0.77</td><td>0.29</td><td>0.36</td><td>1.0</td></tr>
</tbody></table>
<p>+ mask)</p>
<p>@</p>
<table>
<tbody><tr><th colspan="2">v/0</th></tr>
<tr><td>0.54</td><td>0.8</td></tr>
<tr><td>0.81</td><td>0.42</td></tr>
<tr><td>0.81</td><td>0.47</td></tr>
<tr><td>0.69</td><td>0.89</td></tr>
<tr><td>0.19</td><td>0.39</td></tr>
</tbody></table>
</div>
<p>The individual small result matrices are then stuck back together to recreate a final result matrix of shape <code>(seq_len, embed_size)</code>, just like the result of vanilla attention.
This process allows each head to be used for a different task (e.g., one head could handle punctuation in acronyms and another French articles), instead of wastefully dedicating an entire Transformer block to a single task.</p>
<p>So what is <a href="https://arxiv.org/abs/1911.02150">Multi-Query Attention</a>?
Instead of Q, K, and V all being split into separate heads, <em>only</em> Q is split.
K and V are smaller, the size of a single head, and that single K and V is shared among all the Q heads.</p>
<div>
<table>
<tbody><tr><th colspan="8">q</th></tr>
<tr><td>0.23</td><td>0.03</td><td>0.1</td><td>0.3</td><td>0.87</td><td>0.84</td><td>0.3</td><td>0.3</td></tr>
<tr><td>0.27</td><td>0.61</td><td>0.7</td><td>0.02</td><td>0.83</td><td>0.94</td><td>0.12</td><td>0.21</td></tr>
<tr><td>0.79</td><td>0.23</td><td>0.03</td><td>0.28</td><td>0.02</td><td>0.47</td><td>0.97</td><td>0.61</td></tr>
<tr><td>0.11</td><td>0.1</td><td>0.3</td><td>1.0</td><td>0.08</td><td>0.88</td><td>0.83</td><td>0.69</td></tr>
<tr><td>0.07</td><td>0.01</td><td>0.16</td><td>0.05</td><td>0.51</td><td>0.54</td><td>0.23</td><td>0.47</td></tr>
</tbody></table>
<p>→</p>
<table>
<tbody><tr><th colspan="2">q/0</th></tr>
<tr><td>0.23</td><td>0.03</td></tr>
<tr><td>0.27</td><td>0.61</td></tr>
<tr><td>0.79</td><td>0.23</td></tr>
<tr><td>0.11</td><td>0.1</td></tr>
<tr><td>0.07</td><td>0.01</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">q/1</th></tr>
<tr><td>0.1</td><td>0.3</td></tr>
<tr><td>0.7</td><td>0.02</td></tr>
<tr><td>0.03</td><td>0.28</td></tr>
<tr><td>0.3</td><td>1.0</td></tr>
<tr><td>0.16</td><td>0.05</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">q/2</th></tr>
<tr><td>0.87</td><td>0.84</td></tr>
<tr><td>0.83</td><td>0.94</td></tr>
<tr><td>0.02</td><td>0.47</td></tr>
<tr><td>0.08</td><td>0.88</td></tr>
<tr><td>0.51</td><td>0.54</td></tr>
</tbody></table>
<table>
<tbody><tr><th colspan="2">q/3</th></tr>
<tr><td>0.3</td><td>0.3</td></tr>
<tr><td>0.12</td><td>0.21</td></tr>
<tr><td>0.97</td><td>0.61</td></tr>
<tr><td>0.83</td><td>0.69</td></tr>
<tr><td>0.23</td><td>0.47</td></tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr><th colspan="2">k</th></tr>
<tr><td>0.08</td><td>0.41</td></tr>
<tr><td>0.7</td><td>0.77</td></tr>
<tr><td>0.77</td><td>0.29</td></tr>
<tr><td>0.94</td><td>0.36</td></tr>
<tr><td>0.76</td><td>1.0</td></tr>
</tbody></table>

<table>
<tbody><tr><th colspan="2">v</th></tr>
<tr><td>0.54</td><td>0.8</td></tr>
<tr><td>0.81</td><td>0.42</td></tr>
<tr><td>0.81</td><td>0.47</td></tr>
<tr><td>0.69</td><td>0.89</td></tr>
<tr><td>0.19</td><td>0.39</td></tr>
</tbody></table>
</div>
<p>You might think this would be a serious problem for the model, but it actually has only a small effect on perplexity.
This table from the MQA paper shows slightly worse results than the Multi-Head Attention baseline, but better than alternatives involving shrinking all the dimensions of MHA.</p>
<p><a href="https://vgel.me/posts/faster-inference/multi_query_table3.png"><img src="https://vgel.me/posts/faster-inference/multi_query_table3.png" alt="dev-PPL of MHA: 29.9, MQA: 30.2, best MHA with smaller dimensions: 30.9"></a></p>
<p>The benefit is, because K and V are so much smaller than in MHA, the KV cache is proportionally smaller as well.
Both LLAMA-2 and Falcon use MQA, for this reason.</p>
<p>Mistral 7B uses a variant called <a href="https://arxiv.org/abs/2305.13245v2">Grouped-Query Attention</a> which is a hybrid between MQA and MHA.
If MHA is <code>Q_heads=K_heads=V_heads=N</code> and MQA is <code>Q_heads=N; K_heads=V_heads=1</code>, then GQA is <code>Q_heads=N; K_heads=V_heads=G</code> where <code>1 &lt; G &lt; N</code>.
GQA claims less effect on perplexity and better training stability than MQA.</p>
<h3 id="PagedAttention"><a href="#PagedAttention">
  <img src="https://vgel.me/permalink.svg" alt="permalink for PagedAttention">
</a>PagedAttention</h3>
<p>The other issue with a large KV cache is that it often needs to be stored as in <em>contiguous</em> tensors, regardless of whether all of the cache is currently in use.
That leads to multiple problems:</p>
<ul>
<li>More space than necessary needs to be allocated up front, since we need to anticipate the maximum size of the KV cache before it's needed.</li>
<li>That reserved space can't be used by other requests, even if it isn't needed <em>yet</em>.</li>
<li>Requests with the same prefix can't share KV cache for that prefix, since they may diverge later.</li>
</ul>
<p><a href="https://arxiv.org/abs/2309.06180">PagedAttention</a> fixes these problems by taking inspiration from how operating systems handle a similar issue with userspace program memory.</p>
<p>Let's take a moment to explore OS paging, as a primer.
Like tensors, programs want to see their memory as a contiguous linear space.
<small>(If I allocate a million-byte array <code>x</code>, I expect the address of <code>x[n + 1]</code> to exactly equal <code>x[n] + 1</code>, no more, no less! Much code depends on this.)</small>
However, physical memory isn't always so forgiving—operating systems have to worry about pesky things like "fragmentation" and <a href="https://vgel.me/posts/mmap-arena-alloc/">"hey you asked for a 1TiB allocation i cannot put this anywhere"</a>.</p>
<p>So the operating system collaborates with hardware, using the <abbr title="Memory Management Unit">MMU</abbr> to map virtual pages to physical pages in a page table.
When you access an address in a userspace program, that address gets translated from your program's address space via the page table <small>(and TLB cache)</small> to a physical address before being read from or written to.
Importantly, that physical address may not exist yet—it may be generated on-demand for a write.
For example, let's map 16 pages of memory in C:</p>
<pre data-lang="c"><code data-lang="c"><span>
</span><span>uint8_t </span><span>*</span><span>pages </span><span>= </span><span>mmap(</span><span>NULL</span><span>, page_size </span><span>* </span><span>16</span><span>,
</span><span>                      PROT_READ </span><span>|</span><span> PROT_WRITE,
</span><span>                      MAP_PRIVATE </span><span>|</span><span> MAP_ANONYMOUS,
</span><span>                      </span><span>-</span><span>1</span><span>, </span><span>0</span><span>);
</span></code></pre>
<p>Now if we <a href="https://stackoverflow.com/a/45500208/1159735">pagemap-dump</a> the running program, we get this list of page addresses and associated <code>pfn</code> physical addresses (along with other metadata):</p>
<pre data-lang="bash"><code data-lang="bash"><span># addr pfn soft-dirty file/shared swapped present library
</span><span>7fbe0fe6a000 0 1 0 0 0 
</span><span>7fbe0fe6b000 0 1 0 0 0 
</span><span>7fbe0fe6c000 0 1 0 0 0 
</span><span>7fbe0fe6d000 0 1 0 0 0 
</span><span>7fbe0fe6e000 0 1 0 0 0 
</span><span>7fbe0fe6f000 0 1 0 0 0 
</span><span>7fbe0fe70000 0 1 0 0 0 
</span><span>7fbe0fe71000 0 1 0 0 0 
</span><span>7fbe0fe72000 0 1 0 0 0 
</span><span>7fbe0fe73000 0 1 0 0 0 
</span><span>7fbe0fe74000 0 1 0 0 0 
</span><span>7fbe0fe75000 0 1 0 0 0 
</span><span>7fbe0fe76000 0 1 0 0 0 
</span><span>7fbe0fe77000 0 1 0 0 0 
</span><span>7fbe0fe78000 0 1 0 0 0 
</span><span>7fbe0fe79000 0 1 0 0 0 
</span></code></pre>
<p>Notice that all the pages have a physical address of zero—they don't exist yet!
This is called <em>memory overcommit</em>.
The kernel doesn't know if we're going to use these pages, so it doesn't bother to set up mappings for them yet.
Trying to read from them will just return an unspecified value (this is part of why reading uninitialized memory is UB in C).</p>
<p>However, if I then touch every page by writing to it...</p>
<pre data-lang="c"><code data-lang="c"><span>// pages is our page_size * 16 map from earlier
</span><span>for </span><span>(</span><span>int</span><span> i </span><span>= </span><span>0</span><span>; i </span><span>&lt;</span><span> page_size </span><span>* </span><span>16</span><span>; i</span><span>++</span><span>) pages[i] </span><span>= </span><span>1</span><span>;
</span></code></pre>
<p>...the dump looks different!</p>
<pre data-lang="bash"><code data-lang="bash"><span># addr pfn soft-dirty file/shared swapped present library
</span><span>7fbe0fe6a000 14a009 1 0 0 1 
</span><span>7fbe0fe6b000 50eca5 1 0 0 1 
</span><span>7fbe0fe6c000 175a5d 1 0 0 1 
</span><span>7fbe0fe6d000 148d85 1 0 0 1 
</span><span>7fbe0fe6e000 2de86c 1 0 0 1 
</span><span>7fbe0fe6f000 13a300 1 0 0 1 
</span><span>7fbe0fe70000 8f25b4 1 0 0 1 
</span><span>7fbe0fe71000 15ae63 1 0 0 1 
</span><span>7fbe0fe72000 6e1d7f 1 0 0 1 
</span><span>7fbe0fe73000 13a307 1 0 0 1 
</span><span>7fbe0fe74000 14a074 1 0 0 1 
</span><span>7fbe0fe75000 14a0a7 1 0 0 1 
</span><span>7fbe0fe76000 7e2662 1 0 0 1 
</span><span>7fbe0fe77000 1ccdc2 1 0 0 1 
</span><span>7fbe0fe78000 2a4f06 1 0 0 1 
</span><span>7fbe0fe79000 2169ef 1 0 0 1 
</span></code></pre>
<p>Now all the pages have a physical address, because they've been written to.
However, note that the physical addresses aren't contiguous like the virtual addresses!
<small>(The largest physical address is 0x7e2662, which is the mapping for virtual address 0x7fbe0fe76000, page #13.)</small>
They're scattered all over the place, wherever they can fit.
And if our C program had only touched e.g. half the pages, only those pages would've been mapped, the others would have remained unmapped.
This means that no physical memory is reserved until the exact moment that it's needed.</p>
<p>I could share only part of this memory with another process.
Imagine I mapped 4 pages of shared memory:</p>
<pre data-lang="bash"><code data-lang="bash"><span>7fbe0fe6a000 14a009
</span><span>7fbe0fe6b000 50eca5 
</span><span>7fbe0fe6c000 175a5d
</span><span>7fbe0fe6d000 148d85
</span></code></pre>
<p>The other process might see these pages as:</p>
<pre data-lang="bash"><code data-lang="bash"><span>5581627bb000 14a009
</span><span>5581627bc000 50eca5
</span><span>5581627bd000 175a5d
</span><span>5581627be000 148d85
</span></code></pre>
<p>The virtual addresses are different, but the physical addresses are identical!
Each program might see these pages interleaved in different contexts, but the underlying data can be stored, deduplicated, in a single place in physical memory.</p>
<p>So how does this apply to PagedAttention?
PagedAttention is the <em>exact same idea</em>—they say so in the paper.<sup><a href="#why-not-mmu">4</a></sup></p>
<p>Instead of pages, we have blocks of KV cache for tokens, and instead of processes accessing those pages, we have LLM requests accessing those blocks of tokens.</p>
<p>At startup, PagedAttention allocates a <em>block table</em> for the request, analogous to the role of a hardware MMU.
This block table starts out empty, with no blocks mapped, just like our C process.</p>
<p>Instead of associating requests with a large tensor of KV cache items, each request only has a comparatively small list of block indices, analogous to virtual addresses in OS paging.
Those indices point at blocks stored in the global block table.
Just like OS pages, they can be out of order, placed wherever they can fit:</p>
<p><a href="https://vgel.me/posts/faster-inference/pagedattention.png"><img src="https://vgel.me/posts/faster-inference/pagedattention.png" alt=""></a></p>
<p>During the attention computation, the PagedAttention kernel walks the request's list of block indices, and goes and fetches those blocks from the global block table to compute attention as normal in the correct order.</p>
<p>Importantly, because the blocks have been decoupled from individual requests, they can be shared, just like the shared memory example in OS paging.
If two requests use the same long prefix (such as k-shot examples for multiple parallel translation tasks, the newest Twitter prompt hack, the chain so far for self-consistency Chain of Thought, etc.), the KV cache blocks for that prefix can be shared by multiple requests, simply by placing the index of that block in the appropriate part of each request's list of block indices.</p>
<p><a href="https://vgel.me/posts/faster-inference/shared-prefix-pagedattention.drawio.png"><img src="https://vgel.me/posts/faster-inference/shared-prefix-pagedattention.drawio.png" alt=""></a></p>
<h2 id="Speculative_Decoding"><a href="#Speculative_Decoding">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Speculative_Decoding">
</a>Speculative Decoding</h2>
<p>To understand speculative decoding, you need to remember three things.</p>
<p>First, running a small number of tokens through a model takes about the same amount of time as running a single token, thanks to memory access overhead:</p>
<p><a href="https://vgel.me/posts/faster-inference/timing_graph.png"><img src="https://vgel.me/posts/faster-inference/timing_graph.png" alt="Log-log plot of time to generate N tokens, in seconds, showing a flat region from 1-10 tokens that then goes linear"></a></p>
<p>Second, LLMs generate a prediction for <em>every</em> token in the context:</p>
<pre data-lang="python"><code data-lang="python"><span>&gt;&gt;&gt; for </span><span>i, y </span><span>in </span><span>enumerate</span><span>(logits.argmax(</span><span>-</span><span>1</span><span>)):
</span><span>...     </span><span>print</span><span>(</span><span>f</span><span>"</span><span>{tokenizer.decode(tokens[:i</span><span>+</span><span>1</span><span>])</span><span>!r</span><span>}</span><span> -&gt; </span><span>{tokenizer.decode(y)</span><span>!r</span><span>}</span><span>"</span><span>)
</span><span>' A' </span><span>-&gt; </span><span>'.'
</span><span>' A B' </span><span>-&gt; </span><span>' C'
</span><span>' A B C' </span><span>-&gt; </span><span>' D'
</span></code></pre>
<p>Finally third, some words are very easy to predict.
For example, after the word "going", you don't need to be GPT-4 to know that the word "to" is an extremely likely next token.</p>
<p>We can take advantage of these facts to optimize generation!
Imagine if, whenever the most recent token was " going", we optimistically tacked " to" onto the end as well before running generation.
Then, after running the model forward, we check if the model's prediction after "going" was indeed "to".
if so, we got a token ("to") for free!
And if not, no sweat, we simply accept the token predicted for "going" instead, with no increased perplexity, since that token is the exact token the model would have generated without our trick.</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>generate</span><span>(</span><span>prompt</span><span>: </span><span>str</span><span>, </span><span>tokens_to_generate</span><span>: </span><span>int</span><span>) -&gt; </span><span>str</span><span>:
</span><span>    tokens: </span><span>list</span><span>[</span><span>int</span><span>] </span><span>= </span><span>tokenize(prompt)
</span><span>    GOING, TO </span><span>= </span><span>tokenize(</span><span>" going to"</span><span>)
</span><span>
</span><span>    </span><span>for </span><span>i </span><span>in </span><span>range</span><span>(tokens_to_generate):
</span><span>        </span><span>if </span><span>tokens[</span><span>-</span><span>1</span><span>] </span><span>== </span><span>GOING:
</span><span>          </span><span># do our speculative decoding trick
</span><span>          logits </span><span>= </span><span>model.forward(tokens </span><span>+ </span><span>[TO])
</span><span>          </span><span># the token the model predicts will follow "... going"
</span><span>          going_pred </span><span>= </span><span>argmax(logits[</span><span>-</span><span>2</span><span>, :])
</span><span>          </span><span># the token the model predicts will follow "... going to" 
</span><span>          to_pred </span><span>= </span><span>argmax(logits[</span><span>-</span><span>1</span><span>, :])
</span><span>          </span><span>if </span><span>going_pred </span><span>== </span><span>TO:
</span><span>            </span><span># if our guess was correct, accept "to" and the next token after
</span><span>            tokens </span><span>+= </span><span>[TO, to_pred]
</span><span>          </span><span>else</span><span>:
</span><span>            </span><span># otherwise, accept the real next token
</span><span>            </span><span># (e.g. "for" if the true generation was "going for broke")
</span><span>            tokens </span><span>+= </span><span>[going_pred]
</span><span>        </span><span>else</span><span>:
</span><span>          </span><span># do normal single-token generation
</span><span>          logits </span><span>= </span><span>model.forward(tokens)
</span><span>          tokens </span><span>+= </span><span>[argmax(logits[</span><span>-</span><span>1</span><span>])]
</span><span>
</span><span>    </span><span>return </span><span>detokenize(tokens)
</span></code></pre>
<p>This will absolutely work, and buy you a (minuscule) speed boost.
To improve it, you could imagine making more heuristics: predict "and" after a comma, and "the" after "is".
You could even make multi-word heuristics: if you see "The early bird", why not optimistically add "catches the worm"?
Even if they're doing a twist on the phrase, you could still win "catches" and "the", the entire phrase doesn't need to be accepted.</p>
<p>But wait a second—why make these heuristics by hand?
We're trying to come up with likely completions of a token... that's exactly what language models are good at!
If we use a language model to generate our optimistic tokens, we could pick up even more complex patterns, even ones from the earlier context.</p>
<p>We just need to use a "draft" model that's small enough (and therefore quick enough to run) that it will pay for itself by avoiding passes through the larger "oracle" model.
A good rule of thumb is for this model to be ~1/10 the size of the oracle model.
It should also use the same tokenizer (to avoid needing to detokenize and retokenize the sequence over and over).</p>
<p>Here's what the generate loop looks like with a draft model:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>generate</span><span>(</span><span>prompt</span><span>: </span><span>str</span><span>, </span><span>tokens_to_generate</span><span>: </span><span>int</span><span>, </span><span>n_draft</span><span>: </span><span>int </span><span>= </span><span>8</span><span>) -&gt; </span><span>str</span><span>:
</span><span>    tokens: </span><span>list</span><span>[</span><span>int</span><span>] </span><span>= </span><span>tokenize(prompt)
</span><span>
</span><span>    </span><span>for </span><span>i </span><span>in </span><span>range</span><span>(tokens_to_generate):
</span><span>        </span><span># generate `n_draft` draft tokens in the usual autoregressive way
</span><span>        draft </span><span>= </span><span>tokens[:]
</span><span>        </span><span>for </span><span>_ </span><span>in </span><span>range</span><span>(n_draft):
</span><span>            logits </span><span>= </span><span>draft_model.forward(draft)
</span><span>            draft.append(argmax(logits[</span><span>-</span><span>1</span><span>]))
</span><span>
</span><span>        </span><span># run the draft tokens through the oracle model all at once
</span><span>        logits </span><span>= </span><span>model.forward(draft)
</span><span>        checked </span><span>= </span><span>logits[</span><span>len</span><span>(tokens) </span><span>- </span><span>1 </span><span>:].argmax(</span><span>-</span><span>1</span><span>)
</span><span>
</span><span>        </span><span># find the index of the first draft/oracle mismatch—we'll accept every
</span><span>        </span><span># token before it
</span><span>        </span><span># (the index might be past the end of the draft, if every draft token
</span><span>        </span><span># was correct)
</span><span>        n_accepted </span><span>= </span><span>next</span><span>(
</span><span>            idx </span><span>+ </span><span>1
</span><span>            </span><span>for </span><span>idx, (checked, draft) </span><span>in </span><span>enumerate</span><span>(
</span><span>                </span><span># we add None here because the oracle model generates one extra
</span><span>                </span><span># token (the prediction for the last draft token)
</span><span>                </span><span>zip</span><span>(checked, draft[</span><span>len</span><span>(tokens) :] </span><span>+ </span><span>[</span><span>None</span><span>])
</span><span>            )
</span><span>            </span><span>if </span><span>checked </span><span>!= </span><span>draft
</span><span>        )
</span><span>        tokens.extend(checked[:n_accepted])
</span><span>
</span><span>    </span><span>return </span><span>detokenize(tokens)
</span></code></pre>
<p>Here, I used the above loop with GPT-2-XL (1558M parameters) as the oracle model, and GPT-2-small (124M parameters) as the draft model, with <code>n_draft=8</code>.
The green tokens were generated by the draft model, and the blue tokens are where the draft model was incorrect and the oracle model's corrected token had to be used.</p>
<p><span>What is a tensor in machine learning?</span>
<span>&nbsp;<br></span>
<span>A</span><span> tens</span><span>or</span><span> is</span><span> a</span><span> mathematical</span><span> object</span><span> that</span><span> represents</span><span> a</span><span> set</span><span> of</span><span> data</span><span> points</span><span>.</span><span> It</span><span> is</span><span> a</span><span> mathematical</span><span> object</span><span> that</span><span> can</span><span> be</span><span> used</span><span> to</span><span> represent</span><span> a</span><span> set</span><span> of</span><span> data</span><span> points</span><span>.</span>
</p>
<p>Note how the draft model is particularly good at quickly copying text from the question ("A tensor is a"), completing common N-grams ("It" -&gt; "is a", "can" -&gt; "can be"), and inserting stock phrases ("a set of data points"), so that the oracle model only needs to step in for a few key words.</p>
<p>Here's another example, with the same setup but a different prompt:</p>
<p><span>Index: A B C</span><span> D</span><span> E</span><span> F</span><span> G</span><span> H</span><span> I</span><span> J</span><span> K</span><span> L</span><span> M</span><span> N</span><span> O</span><span> P</span><span> Q</span><span> R</span><span> S</span><span> T</span><span> U</span><span> V</span><span> W</span><span> X</span><span> Y</span><span> Z</span><span>
</span><span>
</span><span>The</span><span> following</span><span> table</span><span> lists</span><span> the</span><span> number</span><span> of</span><span> times</span><span> each</span><span> of</span><span> the</span><span> following</span><span> words</span><span> appear</span><span> in</span><span> the</span><span> text</span><span> of</span><span> the</span><span> book</span><span>.</span><span>
</span><span>
</span><span>Word</span><span> Number</span><span> of</span><span> times</span><span> in</span><span> text</span>
</p>
<p>Here, the draft model does very well in the alphabet part, actually hitting the draft limit several times (the draft model would have correctly predicted "L", for example, but we limit it to 8 tokens at once).
But once it got into the prose generation below, the draft model couldn't keep up as well.</p>
<p>Finally, here's a pathological case:</p>
<p><span>The digits of Pi are 3.14159</span><span>265</span><span>35</span><span>89</span><span>793</span><span>238</span><span>46</span><span>264</span><span>33</span><span>83</span><span>279</span><span>50</span><span>28</span><span>84</span><span>197</span><span>16</span><span>93</span><span>99</span><span>375</span><span>10</span><span>58</span><span>20</span>
</p>
<p>At first the models are in agreement, but fairly quickly they diverge as the draft model becomes inaccurate, and generation becomes unbearably slow.
For every token, 8 draft tokens are generated and then immediately discarded.</p>
<p>This shows that speculative decoding performance can be very context dependent!
If the draft model is well-correlated with the oracle model and the text is easy to predict, you'll get lots of drafted tokens and fast inference.
But if the models aren't correlated, speculative decoding can actually make inference <em>slower</em>, because you're wasting time generating draft tokens that will just be rejected.</p>
<h3 id="Threshold_decoding?"><a href="#Threshold_decoding?">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Threshold_decoding?">
</a>Threshold decoding?</h3>
<p>An approach I came up with to mitigate the issues with using a fixed number of draft tokens is <em>threshold decoding</em>.</p>
<p>Instead of always decoding up to the maximum number of draft tokens, we keep a moving probability threshold, calibrated based on how many tokens are being accepted right now.
Draft tokens are generated until the cumulative probability of the draft so far (based on the draft model logits) falls below this threshold.</p>
<p>For example, if the threshold was 0.5, and the we generated a draft token " the" with a probability of 0.75, we'd keep going.
If the next token, " next", had a probability of 0.5, the cumulative probability 0.375 would be lower than the threshold, so we'd stop and submit the two draft tokens to the oracle.</p>
<p>Then, based on how far into the draft is accepted, the threshold is adjusted up or down to try and calibrate the draft model's confidence with the actual acceptance rate.
Right now this is just done by a simple moving average and some thresholding, but there's probably a more principled way to do it based on real statistics.</p>
<p>This is the code (using my homegrown framework, apologies):</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>speculative_threshold</span><span>(
</span><span>    </span><span>prompt</span><span>: </span><span>str</span><span>,
</span><span>    </span><span>max_draft</span><span>: </span><span>int </span><span>= </span><span>16</span><span>,
</span><span>    </span><span>threshold</span><span>: </span><span>float </span><span>= </span><span>0.4</span><span>,
</span><span>    </span><span>threshold_all_correct_boost</span><span>: </span><span>float </span><span>= </span><span>0.1</span><span>,
</span><span>):
</span><span>    tokens </span><span>= </span><span>encoder.encode(prompt)
</span><span>
</span><span>    </span><span># homegrown KV cache setup has an `n_tokens` method that returns the length
</span><span>    </span><span># of the cached sequence, and a `truncate` method to truncate that sequence
</span><span>    </span><span># to a specific token
</span><span>    model_kv </span><span>= </span><span>gpt2.KVCache()
</span><span>    draft_kv </span><span>= </span><span>gpt2.KVCache()
</span><span>
</span><span>    </span><span>while </span><span>True</span><span>:
</span><span>        </span><span># generate up to `max_draft` draft tokens autoregressively, stopping
</span><span>        </span><span># early if we fall below `threshold`
</span><span>        draft </span><span>= </span><span>tokens[:]
</span><span>        drafted_probs </span><span>= </span><span>[]
</span><span>        </span><span>for </span><span>_ </span><span>in </span><span>range</span><span>(max_draft):
</span><span>            logits </span><span>= </span><span>draft_model.forward(draft[draft_kv.n_tokens() :], draft_kv)
</span><span>            next_id </span><span>= </span><span>np.argmax(logits[</span><span>-</span><span>1</span><span>])
</span><span>            next_prob </span><span>= </span><span>gpt2.softmax(logits[</span><span>-</span><span>1</span><span>])[next_id]
</span><span>            </span><span>if not </span><span>len</span><span>(drafted_probs):
</span><span>                drafted_probs.append(next_prob)
</span><span>            </span><span>else</span><span>:
</span><span>                drafted_probs.append(next_prob </span><span>* </span><span>drafted_probs[</span><span>-</span><span>1</span><span>])
</span><span>            draft.append(</span><span>int</span><span>(next_id))
</span><span>            </span><span>if </span><span>drafted_probs[</span><span>-</span><span>1</span><span>] </span><span>&lt; </span><span>threshold:
</span><span>                </span><span>break
</span><span>        n_draft </span><span>= </span><span>len</span><span>(draft) </span><span>- </span><span>len</span><span>(tokens)
</span><span>
</span><span>        </span><span># run draft tokens through the oracle model
</span><span>        logits </span><span>= </span><span>model.forward(draft[model_kv.n_tokens() :], model_kv)
</span><span>        checked </span><span>= </span><span>logits[</span><span>-</span><span>n_draft </span><span>- </span><span>1 </span><span>:].argmax(</span><span>-</span><span>1</span><span>)
</span><span>        n_accepted </span><span>= </span><span>next</span><span>(
</span><span>            idx </span><span>+ </span><span>1
</span><span>            </span><span>for </span><span>idx, (checked, draft) </span><span>in </span><span>enumerate</span><span>(
</span><span>                </span><span>zip</span><span>(checked, draft[</span><span>len</span><span>(tokens) :] </span><span>+ </span><span>[</span><span>None</span><span>])
</span><span>            )
</span><span>            </span><span>if </span><span>checked </span><span>!= </span><span>draft
</span><span>        )
</span><span>        </span><span>yield from </span><span>checked[:n_accepted]
</span><span>        tokens.extend(checked[:n_accepted])
</span><span>
</span><span>        </span><span>if </span><span>n_accepted </span><span>&lt;= </span><span>n_draft:
</span><span>            </span><span># adjust threshold towards prob of last accepted token, if we
</span><span>            </span><span># ignored any draft tokens
</span><span>            threshold </span><span>= </span><span>(threshold </span><span>+ </span><span>drafted_probs[n_accepted </span><span>- </span><span>1</span><span>]) </span><span>/ </span><span>2
</span><span>        </span><span>else</span><span>:
</span><span>            </span><span># otherwise, lower the threshold slightly, we're probably being
</span><span>            </span><span># too conservative
</span><span>            threshold </span><span>-= </span><span>threshold_all_correct_boost
</span><span>        </span><span># clamp to avoid pathological thresholds
</span><span>        threshold </span><span>= </span><span>min</span><span>(</span><span>max</span><span>(threshold, </span><span>0.05</span><span>), </span><span>0.95</span><span>)
</span><span>
</span><span>        </span><span># don't include oracle token in kv cache
</span><span>        model_kv.truncate(</span><span>len</span><span>(tokens) </span><span>- </span><span>1</span><span>)
</span><span>        draft_kv.truncate(</span><span>len</span><span>(tokens) </span><span>- </span><span>1</span><span>)
</span></code></pre>
<p>This table compares threshold decoding to regular speculative decoding with different fixed draft lengths (along with KV caching, to make the comparison fair), for the test prompts I showed earlier.
The rightmost column is a sparkline showing how generation speed changes over time.</p>
<table>
<tbody><tr><th colspan="3">What is a tensor in machine learning?</th></tr>
<tr>
<td>threshold</td>
<td>2.01 tok/s</td>
<td>▁▂▄▅▄▅▅▆▅▄▅▅▅▅▅▆▅▅▅▅▆▅▆▆▅▆▅▆▆▆▅▆▆▆▆▇▆▆▇▇▇▆▆▆▇▇▇▇▇█</td>
</tr>
<tr>
<td>n_draft=1</td>
<td>1.40 tok/s</td>
<td>▁▃▃▅▅▆▆▇▆▆▆▆▇▆▇▇▇▇▆▇▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td>
</tr>
<tr>
<td>n_draft=8</td>
<td>1.92 tok/s</td>
<td>▁▂▃▄▅▆▇█▅▃▄▃▄▄▄▄▅▅▄▅▅▄▄▅▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆</td>
</tr>
<tr>
<td>n_draft=16</td>
<td>1.36 tok/s</td>
<td>▁▂▃▄▅▆▇█▄▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▃▄▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▅▅▅▅▅▆▆</td>
</tr>
<tr><th colspan="3">Index: A B C</th></tr>
<tr>
<td>threshold</td>
<td>1.90 tok/s</td>
<td>▁▁▁▂▂▃▃▄▄▄▅▅▆▆▇▇█▅▅▅▆▆▆▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄</td>
</tr>
<tr><td>n_draft=1</td>
<td>1.32 tok/s</td>
<td>▁▄▃▅▅▆▅▇▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▆▆▆▆▆▆▆▆</td>
</tr>
<tr><td>n_draft=8</td>
<td>1.49 tok/s</td>
<td>▁▁▂▃▃▄▅▆▆▄▄▅▅▆▆▇▇█▆▆▆▆▇▇▆▆▆▆▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄</td>
</tr>
<tr><td>n_draft=16</td>
<td>0.97 tok/s</td>
<td>▁▁▁▂▂▃▃▄▄▄▅▅▆▆▇▇█▅▅▅▅▆▆▆▄▅▅▅▅▅▆▄▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂</td>
</tr>
<tr><th colspan="3">The digits of Pi are 3.14159</th></tr>
<tr>
<td>threshold</td>
<td>0.84 tok/s</td>
<td>▁▄▇▅█▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td>
</tr>
<tr><td>n_draft=1</td>
<td>0.85 tok/s</td>
<td>▁▅▅█▇▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td>
</tr>
<tr><td>n_draft=8</td>
<td>0.42 tok/s</td>
<td>▁▂▄▆█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr><td>n_draft=16</td>
<td>0.27 tok/s</td>
<td>▁▂▄▆█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
</tbody></table>
<p>Note how, for example, n_draft=16 on the "Index: A B C" prompt has a strong start, but falls off hard in the later prose section as it overgenerates incorrect tokens.
Threshold decoding, meanwhile, is able to ramp up to take advantage of the easy alphabet tokens, and then ramp back down to not overgenerate on the harder prose section:</p>
<p><span>Index: A B C</span><span> D</span><span> E</span><span> F</span><span> G</span><span> H</span><span> I</span><span> J</span><span> K</span><span> L</span><span> M</span><span> N</span><span> O</span><span> P</span><span> Q</span><span> R</span><span> S</span><span> T</span><span> U</span><span> V</span><span> W</span><span> X</span><span> Y</span><span> Z</span><span>
</span><span>
</span><span>The</span><span> following</span><span> table</span><span> lists</span><span> the</span><span> number</span><span> of</span><span> times</span><span> each</span><span> of</span><span> the</span><span> following</span><span> words</span><span> appear</span><span> in</span><span> the</span><span> text</span><span> of</span><span> the</span><span> book</span><span>.</span><span>
</span><span>
</span><span>Word</span><span> Number</span>
</p>
<h3 id="Staged_speculative_decoding"><a href="#Staged_speculative_decoding">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Staged_speculative_decoding">
</a>Staged speculative decoding</h3>
<p><a href="https://arxiv.org/abs/2308.04623">Staged speculative decoding</a> adds two improvements to vanilla speculative decoding:</p>
<p>The first is to restructure the draft batch as a tree, instead of a single generation.
This helps because longer draft batches on complex text can quickly diverge from the base model.
It can instead make more sense to do multiple, shorter drafts, branching off from each other, and then verify them all against the oracle model using a specially-crafted attention mask.
Generating multiple draft sequences lets you reuse prior tokens and sample the draft model in batches, further accelerating the process.</p>
<p><small>(You can think of regular speculative decoding as "deep" and using a tree as "wide", which begs the question of how you should prioritize deep v.s. wide for certain text. Maybe an adjustable parameter like in the threshold decoding section would be useful here as well?)</small></p>
<p>The second improvement is to speculatively decode the draft model as well—it's usually a Transformer after all.
This could be a yet-smaller Transformer (they recommend 15-20x smaller than the oracle model), or even a simple N-gram model.</p>
<h3 id="Guided_generation"><a href="#Guided_generation">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Guided_generation">
</a>Guided generation</h3>
<p>Grammar-guided generation lets you constrain a model's output to follow some grammar, giving you output that guaranteed to match some grammar—such as JSON.
At first, this seems unrelated to speed—reliability is nice, but speed too?
That can't be possible!
But it is—let's dig into how it works to see why.</p>
<p>Imagine you're generating JSON with an LLM, and the generation so far is:</p>
<pre data-lang="json"><code data-lang="json"><span>{
</span><span>    </span><span>"key"</span><span>: 
</span></code></pre>
<p>GPT-4 could generate any of 100k+ tokens here, but only a few are actually valid: whitespace, an open bracket, a quote, a digit, <code>null</code>, etc.
During regular (non-guided) generation, you'd just hope the model had learned that properly and didn't generate syntactically invalid JSON.
During guided generation, however, the sampler <em>only</em> samples from those valid tokens, ignoring any others, even if the invalid tokens are more likely.<sup><a href="#openai-json-mode">5</a></sup></p>
<p>Even better, with libraries like <a href="https://github.com/outlines-dev/outlines">Outlines</a> or <a href="https://github.com/1rgs/jsonformer">jsonformer</a>, you can give the guided generation sampler a schema, and it will sample <em>within that schema</em>!
For example, if a key requires a digit, it will only sample digits after that key name.
Note how the returned object in this example exactly matches the Pydantic schema:</p>
<pre data-lang="python"><code data-lang="python"><span>...
</span><span>
</span><span>class </span><span>Weapon</span><span>(</span><span>str</span><span>, </span><span>Enum</span><span>):
</span><span>    sword </span><span>= </span><span>"sword"
</span><span>    axe </span><span>= </span><span>"axe"
</span><span>    mace </span><span>= </span><span>"mace"
</span><span>    spear </span><span>= </span><span>"spear"
</span><span>    bow </span><span>= </span><span>"bow"
</span><span>    crossbow </span><span>= </span><span>"crossbow"
</span><span>
</span><span>
</span><span>class </span><span>Armor</span><span>(</span><span>str</span><span>, </span><span>Enum</span><span>):
</span><span>    leather </span><span>= </span><span>"leather"
</span><span>    chainmail </span><span>= </span><span>"chainmail"
</span><span>    plate </span><span>= </span><span>"plate"
</span><span>
</span><span>class </span><span>Character</span><span>(</span><span>BaseModel</span><span>):
</span><span>    name: constr(</span><span>max_length</span><span>=</span><span>10</span><span>)
</span><span>    age: </span><span>int
</span><span>    armor: Armor
</span><span>    weapon: Weapon
</span><span>    strength: </span><span>int
</span><span>
</span><span>model </span><span>= </span><span>...
</span><span>generator </span><span>= </span><span>outlines.generate.json(model, Character, </span><span>max_tokens</span><span>=</span><span>100</span><span>)
</span><span>print</span><span>(generator(</span><span>"Give me a character description"</span><span>, </span><span>rng</span><span>=</span><span>...</span><span>))
</span><span># {
</span><span>#   "name": "clerame",
</span><span>#   "age": 7,
</span><span>#   "armor": "plate",
</span><span>#   "weapon": "mace",
</span><span>#   "strength": 4171
</span><span># }
</span></code></pre>
<p>This is great for reliability, but what does it have to do with speed?
Well, let's take a look at that response again.
If we compare it to what's required by the schema, barely any tokens are actually ambiguous—for most of the response, the model would only have one possible token to pick from.
In that case, the sampler can just pick that token, bypassing the model entirely!
Only a small fraction of the tokens (the ones highlighted in green) actually required a model forward call:</p>
<p>
{
  "name": "<span>clerame", </span>   <small>(4 ambiguous tokens: <span>cl</span> <span>er</span> <span>ame</span> <span>",\n</span>)</small>
  "age": <span>7, </span>            <small>(2 ambiguous tokens: <span>7</span> <span>,\n</span>)</small>
  "armor": "<span>plate</span>",     <small>(1 ambiguous token:  <span>plate</span>)</small>
  "weapon": "<span>m</span>ace",     <small>(1 ambiguous token:  <span>m</span>)</small>
  "strength": <span>4171 </span>     <small>(3 ambiguous tokens: <span>417</span> <span>1</span> <span>\n</span>)</small>
}
</p>
<p>Between the JSON grammar and the schema, we already know the first 7 tokens are <code>{\n "name": "</code>, so we can automatically add those into the context before the first model call.
Then after the model generates <code>clerame",\n</code>, we know the next tokens up until the model needs to actually generate the age (<code> "age": </code>), so we append those as well before calling the model again to generate <code>7,</code>.
We can keep going that way all the way down.
(We can even save a token by completing <code>m</code> as <code>"mace",</code> because no other weapon starts with <code>m</code>!)</p>
<p>The complete response was 41 tokens, but only 11 of them had to come from the model, the others were automatically inserted and only needed to be processed as prompt tokens, which are much faster.
This is a nice speedup, <em>and</em> more reliable to boot—a win-win.
If you need to generate structured data with LLMs, especially OSS LLMs that can use custom samplers, you should definitely be using a library like Outlines.</p>
<h3 id="Lookahead_decoding"><a href="#Lookahead_decoding">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Lookahead_decoding">
</a>Lookahead decoding</h3>
<p><a href="https://lmsys.org/blog/2023-11-21-lookahead-decoding/">Lookahead decoding</a> is a new approach to speculative decoding that doesn't require a draft model.
Instead, the model itself is used in two branches: a lookahead branch, which predicts and extends candidate N-grams (short sequences of N tokens), and a verification branch, which verifies the candidates.
The lookahead branch is similar to the draft model in regular speculative decoding, and the verification branch has the same role as the oracle model.</p>
<p>But unlike regular speculative decoding, this is all done not just in a single model, but in a single model <em>call</em> using a specially-crafted attention mask:</p>
<p><a href="https://vgel.me/posts/faster-inference/lookahead.png"><img src="https://vgel.me/posts/faster-inference/lookahead.png" alt=""></a></p>
<p>I won't go too in depth because the <a href="https://lmsys.org/blog/2023-11-21-lookahead-decoding/">lmsys blog post</a> announcing lookahead decoding already has some nice animations (even if the explanation is somewhat dense).</p>
<h3 id="Prompt_lookup_decoding"><a href="#Prompt_lookup_decoding">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Prompt_lookup_decoding">
</a>Prompt lookup decoding</h3>
<p><a href="https://twitter.com/apoorv_umang/status/1728831397153104255">Prompt lookup decoding</a> is another technique, where the draft model is replaced by simple string matching over the context.
They claim it works well for tasks like code editing or RAG where the output necessarily contains lots of verbatim copying from the input.
I assume it'd also work well in staged speculative decoding, to speculatively decode a draft model.</p>
<h2 id="Training_time_optimizations"><a href="#Training_time_optimizations">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Training_time_optimizations">
</a>Training time optimizations</h2>
<p>There are a few optimizations that I'm going to speed through since they're not very relevant if you don't have the resources to pretrain a model with them from the start.</p>
<h3 id="Sparse_attention"><a href="#Sparse_attention">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Sparse_attention">
</a>Sparse attention</h3>
<p>Attention is algorithmically slow because it's quadratic: as the sequence grows in length, each of the N tokens needs to attend to each of the N tokens.
Sparse attention attempts to remedy this by calculating less attention.
For example, Mistral 7B uses sliding window attention, where tokens in some layers can only attend to nearby tokens.
<a href="https://arxiv.org/abs/2004.05150">Longformer</a> also explored some interesting sparse attention patterns, like giving all tokens access to specific positions, dilating the sliding window, using different size windows on different layers, and other tricks.
(Longformer predates Mistral, but as far as I can tell Mistral didn't use all the tricks Longformer did—I'm not sure why.)</p>
<p>Sometimes this kind of attention can be finetuned in or bolted on without tuning after the fact, but for the best performance it needs to be trained into the model from the start, like Mistral did.</p>
<h3 id="Non-Transformer_architectures"><a href="#Non-Transformer_architectures">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Non-Transformer_architectures">
</a>Non-Transformer architectures</h3>
<p>Recently there's been a renewed surge of interest in non-Transformer LLMs.
If you're new to the field you may not be familiar with RNNs/LSTMs, but they were the dominant sequence modeling architecture before Attention is All You Need was published and Transformers took off.
Unlike Transformers where the whole context is available to the model at once, RNNs do a linear scan over the sequence, building up a hidden state that models what has come before.
<small>(There are also reversed and bidirectional RNNs, it's a whole thing.)</small></p>
<p>They were outmatched by Transformers due to difficulty scaling them and problems like forgetting, but some recent papers have tried to bring them back, or invent new sub-quadratic architectures that can finally dethrone Transformers.
These include <a href="https://arxiv.org/abs/2305.13048">RWKV</a> (new type of RNN), <a href="https://arxiv.org/abs/2312.00752">Mamba</a> (state-space model), <a href="https://arxiv.org/abs/2302.10866">Hyena</a> (convolutional), and <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/47e288629a6996a17ce50b90a056a0e1-Paper-Conference.pdf">Recurrent Memory Transformers</a> (use a Transformer for segments, then special memory tokens for global context).
So far the biggest and best models are still Transformers, but that might not be true in the future!</p>
<h2 id="Conclusion"><a href="#Conclusion">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Conclusion">
</a>Conclusion</h2>
<p>Thanks for reading!</p>
<p>Unfortunately I didn't get to cover everything I wanted to in this post, since it's already quite long—I didn't touch on structured sparsity, Mixture of Experts, activation quantization, static vs dynamic quantization, or lots of other great topics.
However, I think the post is a good survey of different areas of LLM optimization.
LLMs are currently slow and hard to run, but the situation is improving all the time—Lookahead Decoding was released while I was writing this post!
It seems likely that in a few years, between better hardware, better training methods, better quantization, more inference optimizations, and the continuing hard work of the open source community, we could be running models than handily beat GPT-4 on consumer hardware, and these techniques and more will be instrumental to making that happen.
(Of course, GPT-5 will probably be out by then... but always upwards!)</p>
<p>Hopefully you found the post useful and/or entertaining.
If you enjoyed it, you may also enjoy:</p>
<ul>
<li><a href="https://vgel.me/posts">My other blog posts</a>, such as <a href="https://vgel.me/posts/handmade-transformer/">I made a transformer by hand (no training!)</a>, <a href="https://vgel.me/posts/tools-not-needed/">GPT-3 will ignore tools when it disagrees with them</a>, <a href="https://vgel.me/posts/gpt4-javascript">Does GPT-4 think better in Javascript?</a> and <a href="https://vgel.me/posts/adversarial-training-data">I'm worried about adversarial training data</a></li>
<li><a href="https://vgel.me/">My other projects and writing</a></li>
<li>My <a href="https://twitter.com/voooooogel/">Twitter</a>, where I post about new blog posts, smaller AI-related thoughts (e.g. <a href="https://twitter.com/voooooogel/status/1730726744314069190">1</a>, <a href="https://twitter.com/voooooogel/status/1733590921605001677">2</a>), whatever fiction I've been reading, and other things.</li>
</ul>
<p>If you have thoughts about this post, please feel free to <a href="https://vgel.me/contact">get in touch</a>!
I love hearing from people who read my posts.</p>
<h3 id="Thanks"><a href="#Thanks">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Thanks">
</a>Thanks</h3>
<p>As always, thanks to everyone who contributed to and reviewed this post:</p>
<ul>
<li><a href="https://twitter.com/wjessup">@wjessup</a> (http://willjessup.com/) for a <em>very</em> thorough review of the draft.</li>
<li><a href="https://twitter.com/tekknolagi">@tekknolagi</a> (https://bernsteinbear.com/) for reviewing and commenting.</li>
<li><a href="https://twitter.com/MF_FOOM">@MF_FOOM</a> for reviewing and commenting (and helping me rent some GPUs for an experiment 🫡 even though the experiment didn't work rip)</li>
<li>@laikhtewari on Discord for great topic suggestions</li>
<li>Everyone on Twitter who liked and commented on the various posts I made while working on this! Really helps.</li>
</ul>
<hr>

<!-- -->

<!-- -->

<!-- -->

<!-- -->



    <ul>
      
        <li><strong>Previous entry:</strong> <a href="https://vgel.me/posts/handmade-transformer/">I made a transformer by hand (no training!)</a></li>
      
      
    </ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What's your "it's not stupid if it works" story? (204 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38733282</link>
            <guid>38733282</guid>
            <pubDate>Fri, 22 Dec 2023 11:50:57 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38733282">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38741595"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741595" href="https://news.ycombinator.com/vote?id=38741595&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I created the most popular Turkish social platform, Eksi Sozluk, using a single plaintext file as its content database back in 1999. It had taken me only three hours to get it up and running without any web frameworks or anything. It was just an EXE written in Delphi. The platform's still up albeit running on .NET/MySQL now and getting banned by Erdogan government for baseless or false reasons (like "national security"). Despite being banned, it was the seventh most popular web site in Turkey last week, and the second most popular Turkish web site in the same list.<p>You can find its ancient source code from 1999 here: <a href="https://github.com/ssg/sozluk-cgi">https://github.com/ssg/sozluk-cgi</a></p><p>The platform is currently at <a href="https://eksisozluk1999.com/" rel="nofollow noreferrer">https://eksisozluk1999.com</a> because its canonincal domain (<a href="https://eksisozluk.com/" rel="nofollow noreferrer">https://eksisozluk.com</a>) got banned. Any visitors from outside Turkey should get redirected anyway.</p><p>Since it's still a legal business entity in Turkey, it keeps paying taxes to Turkish government, and even honors content removal requests despite being banned. Its appeals for the bans are on the hands of The Consitutional Court to be reviewed for almost a year now.</p><p>A newspiece from when it was banned the first time this year: <a href="https://www.theguardian.com/world/2023/mar/01/eksi-sozluk-why-turkey-blocked-its-most-popular-social-site" rel="nofollow noreferrer">https://www.theguardian.com/world/2023/mar/01/eksi-sozluk-wh...</a></p><p>Its Wikipedia page: <a href="https://en.wikipedia.org/wiki/Ek%C5%9Fi_S%C3%B6zl%C3%BCk" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Ek%C5%9Fi_S%C3%B6zl%C3%BCk</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741696"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741696" href="https://news.ycombinator.com/vote?id=38741696&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Using Apple’s translate function I was able to read many of the posts - very interesting to see the differences between American and Turkish social media.<p>There were many posts about cats and their livelihoods and protection. Love that
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741723"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741723" href="https://news.ycombinator.com/vote?id=38741723&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I'm very glad to hear that it's readable using a translator!<p>In fact, the community dynamics resemble Reddit a lot despite having significant differences in layout and format. Irony, sarcasm, harsh criticism are common yet tolerance of differing viewpoints is relatively high compared to other platforms where people just flock to their own bubble or just block everyone else who they don't agree with.</p><p>It's quite fun too, has a rich history spanning a quarter century, and has been quite influential.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38741451"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741451" href="https://news.ycombinator.com/vote?id=38741451&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Back in the '90s I consulted at HBO, and they were migrating from MS Mail on Mac servers to MS Exchange on PCs. Problem was that MS Mail on the Mac had no address book export function, and execs often have thousands or even tens of thousands of contacts. The default solution was for personal assistants to copy out the contacts one by one.<p>So I experimented with screen hotkey tools. I knew about QuicKeys, but its logic and flow control at the time was somewhat limited. Enter &lt;some program I can't remember the name of&gt; which had a full programming language.</p><p>I wrote and debugged a tool that:</p><pre><code>   1. Listened to its own email box: cole.exporter@hbo.com
   2. You emailed it your password (security? what security?)
   3. Seeing such an email, it logged out of its own email and logged in to yours.
   4. Then it opened your address book and copied out entries one by one. 
   5. It couldn't tell by any other method that it had reached the end of your address book, so if it saw the same contact several times in a row it would stop.
   6. Then it formatted your address book into a CSV for importing to Exchange, and emailed it back to you.
   7. It logged out of your account, and back into its own, and resumed waiting for an incoming email.
</code></pre>
This had to work for several thousand employees over 
a few weeks. I had 4 headless pizza box Macs in my office running this code. Several things could go wrong, since all the code was just assuming that the UI would be the same every time. So while in the "waiting" state I had the Macs "beep" once per minute, and each had a custom beep sound, which was just me saying "one" "two" "three" and "four". So my office had my voice going off an average of once every fifteen seconds for several weeks.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741582"><td></td></tr>
            <tr id="38741620"><td></td></tr>
                  <tr id="38741701"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741701" href="https://news.ycombinator.com/vote?id=38741701&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>At my last job, I built a tool to produce standard documents from our green-screen system that held the client data.<p>The users of the green-screen system would tell it to print a document by picking which template to use from a menu.  The system would generate an XML file in a directory that was shared out via Samba.  A VB6 program watched that directory for these XML files to appear, when one appeared it would figure out what the relevant template was, use COM automation to tell MS Word to load the template, fill in the template fields, save it to that client's folder on the file server, then print (on the user's selected printer in the green-screen system) two copies (one for the paper file, one to mail) and an envelope.</p><p>There were a bunch of weird word processing practices that made it slightly worse than it already sounds.  Each letter that was sent out was actually made of a letterhead (one for each location we operated) and a body with the standard text for various letters we sent.  The body would sometimes contain links to other documents (e.g., forms we were requesting someone to fill out), the program would follow these links and print those documents too, but only one copy as we didn't need a bunch of blank forms on the paper file.</p><p>There was also an Access database used by this VB6 program to maintain various bits of configuration data - mappings of document codes to filenames, mappings of green-screen printer names to Windows printer names, etc.  Access gets a bad rap, but it made maintaining that configuration data a breeze.</p><p>It was horrific, but it saved everyone an incredible amount of time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38737625"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38737625" href="https://news.ycombinator.com/vote?id=38737625&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>15+ years ago, I was working on indexing gigabytes of text on a mobile CPU (before smart phones caused massive investment in such CPUs). Word normalization logic (e.g., sky/skies/sky's -&gt; sky) was very slow, so I used a cache, which sped it up immensely. Conceptually the cache looked like {"sky": "sky", "skies": "sky", "sky's": "sky", "cats": "cat", ...}.<p>I needed cache eviction logic as there was only 1 MB of RAM available to the indexer, and most of that was used by the library that parsed the input format. The initial version of that logic cleared the entire cache when it hit a certain number of entries, just as a placeholder. When I got around to adding some LRU eviction logic, it became faster on our desktop simulator, but far slower on the embedded device (slower than with no word cache at all). I tried several different "smart" eviction strategies. All of them were faster on the desktop and slower on the device. The disconnect came down to CPU cache (not word cache) size / strategy differences between the desktop and mobile CPUs - that was fun to diagnose!</p><p>We ended up shipping the "dumb" eviction logic because it was so much faster in practice. The eviction function was only two lines of code plus a large comment explaining all the above and saying something to the effect of "yes, this looks dumb, but test speed on the target device when making it smarter."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741731"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741731" href="https://news.ycombinator.com/vote?id=38741731&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>... how does doing a full string dict lookup take less time than just checking a few trailing characters in a trie? For indexing it's okay to be aggressive since you can check again for the actual matches.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741369"><td></td></tr>
                <tr id="38741720"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741720" href="https://news.ycombinator.com/vote?id=38741720&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Unrolled loops can also often hurt for the same reason on big server chips. It's not always clearly good to unroll your loops.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38741205"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741205" href="https://news.ycombinator.com/vote?id=38741205&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Those are my favorite functions! Two lines of code with a page of text explaining why it works.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38741562"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741562" href="https://news.ycombinator.com/vote?id=38741562&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I had a database that was in a boot-crash loop because it had a corrupted innodb_history_list for a given table.<p>Everything would be ok if we could just delete the table, but that would involve opening a session and that wouldn’t be possible because of the immediate crashing.</p><p>On a whim I thought, “well what if I just have a really short amount of time to connect before it reboots?” So I opened up 5 terminal windows and executed “while true; do mysql -e ‘drop table xyz;’ done” in all of them</p><p>After about 10 minutes one of the hundreds of thousands of attempts to connect to this constantly rebooting database succeeded and I was able to go home at a reasonable time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741681"><td></td></tr>
                <tr id="38741707"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741707" href="https://news.ycombinator.com/vote?id=38741707&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>To play devil's advocate, had OP not wanted to go home so badly Parkinson's Law would've kicked in and OP may have tried to do things the "right way" which may have taken much longer.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38741447"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741447" href="https://news.ycombinator.com/vote?id=38741447&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I used to work at a small company. We had a few remote embedded devices that did work and sent data back to the mothership over the internet. Their firmware could be remotely updated, but we were always very careful.<p>Well one day a mistake was finally made. Some of the devices went into a sort of loop. They’d start running the important process, something would go wrong, and they’d just retry every few minutes.</p><p>We caught the issue almost instantly since we were watching the deploy, and were able to stop updates before any other devices picked it up. But those that already got it were down.</p><p>We could ask the devices to send us the output of a command remotely, but it was too limited to be able to send back an error log. We didn’t have time to send back like 255 characters at a time or whatever, we needed to get it fixed ASAP.</p><p>And that’s when the genius stupid hack was suggested. While we couldn’t send up a full log file, we could certainly send up something the length of a URL. So what if we sent down a little command to stick the log on PasteBin and send up the URL to us?</p><p>Worked like a charm. We could identify what was going wrong and fix it in just a few minutes. After some quick (but VERY thorough) testing everything was fixed.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741596"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741596" href="https://news.ycombinator.com/vote?id=38741596&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>How you could have enough control over the machine to reroute the error log to (what I assume was) a Pastebin api, while also lacking access to any of the files on the machine? In my mind you'd be required to ssh into the machine to upload, and if you're ssh'd in, why not just cat the log?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741719"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741719" href="https://news.ycombinator.com/vote?id=38741719&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Good question! We couldn’t SSH in, which is too bad this would all be trivial. We had no direct access to the boxes, they were often behind firewalls. In fact that was the suggested placement for security reasons. They weren’t full servers, just little embedded things.<p>We had a little HTTP API that it was always talking to. It would call the API to send data back to us or just check in regularly, and we would return to it a little bit of status stuff like the current time to keep clocks in sync, and a list of which “commands” they need to run.</p><p>Mostly the commands were things like “your calibration data is out of data, pull an update“ or “a firmware update is available“.</p><p>But one of them let us run arbitrary shell commands. The system was very limited. I wasn’t a developer directly on the project but I think it was just our custom software plus busy box and a handful of other things our normal shell scripts used. I assume it had been added after some previous incident.</p><p>I believe the basic idea was that during troubleshooting you could tell a box to return the output of “cat /etc/resolv.conf” or something else that we hadn’t preplanned for without having to send someone into the field. But since it was only for small things like that it couldn’t return a full file.</p><p>Luckily one of the commands was either curl or wget. So we could send down “curl -whatever /log/path <a href="https://pastebin/upload%E2%80%9D" rel="nofollow noreferrer">https://pastebin/upload”</a> or whatever it was. I don’t remember if we signed up for a pastebin account so we knew where it would show up or if we had it return URL to us in the output of the curl command.</p><p>This suggestion was literally a joke. We were all beating our heads against the wall trying to help and someone just said “why don’t we just stick it on pastebin“ out of frustration, and the developer on the project realized we had what we needed to do that and it would work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38741224"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741224" href="https://news.ycombinator.com/vote?id=38741224&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>We have a production service running for years that just mmaps an entire SSD and casts the pointer to the desired C++ data structure.<p>That SSD doesn't even have a file system on it, instead it directly stores one monstrous struct array filled with data. There's also no recovery, if the SSD breaks you need to recover all data from a backup.</p><p>But it works and it's mind-boggingly fast and cheap.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741308"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741308" href="https://news.ycombinator.com/vote?id=38741308&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I've always wanted a Smalltalk VM that did this.<p>Eternally persistent VM, without having to "save". It just "lives". Go ahead, map a 10GB or 100GB file to the VM and go at it. Imagine your entire email history (everyone seems to have large email histories) in the "email array", all as ST objects. Just as an example.</p><p>Is that "good"? I dunno. But, simply, there is no impedance mismatch. There's no persistence layer, your entire heap is simply mmap'd into a blob of storage with some lightweight flushing mechanic.</p><p>Obviously it's not that simple, there's all sorts of caveats.</p><p>It just feels like it should be that simple, and we've had the tech to do this since forever. It doesn't even have to be blistering fast, simply "usable".
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741718"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741718" href="https://news.ycombinator.com/vote?id=38741718&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Arguably you could use GemStone/S like that, though it's probably not the kind of capabilities you want.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741469"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741469" href="https://news.ycombinator.com/vote?id=38741469&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Isn’t that sort of the original idea for how Forth would work? Everything is just one big memory space and you do whatever you need?<p>I’m going from very hazy memory here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38741266"><td></td></tr>
                <tr id="38741487"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741487" href="https://news.ycombinator.com/vote?id=38741487&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Honestly it’s not too far off from what many databases do if they can. They manage one giant file as if it’s their own personal drive of memory and ignore the concept of a filesystem completely.<p>Obviously that breaks down when you need to span multiple disks, but conceptually it really is quite simple. A lot of the other stuff file systems do are to help keep things consistent. But if there’s only one “file“ and you don’t ever need metadata then you don’t really need that.</p><p>Very smart solution really.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741289"><td></td></tr>
                        <tr id="38741624"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741624" href="https://news.ycombinator.com/vote?id=38741624&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I wanted a smart thermostat but my 30 year old natural gas heater didn‘t support them. I only had a wheel which I could turn to set the temperature.<p>So I took double sided tape, stuck a plastic gear on the wheel and put a servo on with another gear on the side, connected to a raspberry pi, that would turn the wheel when my phone would enter a geofence around the flat.</p><p>I even had a bash script to calibrate the servo which would turn the wheel and ask which temperature it set, so it could figure out the step size.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38739007"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38739007" href="https://news.ycombinator.com/vote?id=38739007&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I implemented an enterprise data migration in javascript, running in end-user's browsers. (So no server-side node.js or such.)<p>It was a project scheduled for 2-3 months, for a large corporation. The customer wanted a button that a user would click in the old system, requesting a record to be copied over to the new system (Dynamics CRM). 
Since the systems would be used in parallel for a time, it could be done repeatedly, with later clicks of the button sending updates to the new system.</p><p>I designed it to run on an integration server in a dedicated WS, nothing extraordinary. But 3 days before the scheduled end of the project, it became clear that the customer simply will not have the server to run the WS on. They were incapable of provisioning it and configuring the network.</p><p>So I came up with a silly solution: hey, the user will already be logged in to both systems, so let's do it in their browser. 
The user clicked the button in the old system, which invoked a javascript that prepared the data to migrate into a payload (data -&gt; JSON -&gt; Base64 -&gt; URL escape) and GET-ed it in a URL parameter onto a 'New Record' creation form into the new system. That entire record type was just my shim; when its form loaded, it woke another javascript up, which triggered a Save, which triggered a server-side plugin that decoded and parsed the data, which then processed them, triggering like 30 other plugins that were already there - some of them sending data on into a different system.</p><p>I coded this over the weekend and handed it in, with the caveat that since it has to be a GET request, it simply will not work if the data payload exceeds the maximum URL length allowed by the server, ha ha.  
You will not be surprised to learn the payload contained large HTMLs from rich text editors, so it did happen a few times. 
But it ran successfully for over a year until the old system eventually was fully deprecated.</p><p>(Shout out to my boss, who was grateful for the solution and automatically offered to pay for the overtime.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741505"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741505" href="https://news.ycombinator.com/vote?id=38741505&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>That’s horrible. I love it!<p>I’m not quite sure I understand why it was GET though. No way of running something like fetch or (more likely) XMLHTTPRequest?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733529"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733529" href="https://news.ycombinator.com/vote?id=38733529&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>As a 12 year old: I tried to overclock my first "good" own computer (AMD Duron 1200 MHz). System wouldn't start at 1600 MHz and I didn't know BIOS reset exists. 
I ended up putting the computer in the freezer and let it cool down for an hour. I placed the CRT display on top and the power/VGA keyboard cable going into the freezer. I managed to set it back to the original frequency before it died.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38734111"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38734111" href="https://news.ycombinator.com/vote?id=38734111&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I kept a supply of coins in the freezer.  I would regularly toss a few into the heatsink on my TRS-80 that was unstable after a RAM upgrade.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733653"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733653" href="https://news.ycombinator.com/vote?id=38733653&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>When I was a teenager my friend would throw his laptop into the freezer for a few minutes every hour when we were playing games. He probably threw it in there hundreds of times, and it worked fine for years.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741492"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741492" href="https://news.ycombinator.com/vote?id=38741492&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>A friend had an overheating laptop that even an external cooler couldn’t keep up with so he got to sit right next to the open door in winter.<p>We called it the Frozen Throne.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38734789"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38734789" href="https://news.ycombinator.com/vote?id=38734789&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I don't know why but this reminds me of how we picture-framed my friend's old Wifi chip after replacing it, because that chip failing all the time was basically the core feature of our group's gaming sessions.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733554"><td></td></tr>
                  <tr id="38735017"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38735017" href="https://news.ycombinator.com/vote?id=38735017&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>My favorite one is probably when I was working at a retail Forex where consumers would try to make money on currencies. There were a lot of support calls where they disputed the price they saw and the price their order was entered. My solution was to log the price when they click the trade button. The interesting bit wasn't that I logged the currency pair and price, instead I did a tree walk of all the Java Swing GUI elements in the open trade window and render them into the log file as ASCII using "(o)" for options, "[x]" for checkboxes, "[text_____]" for text fields, etc. I wasn't sure if it would work as the elements were rounded to the closest line, and sometimes just inserted a line between two others if it was close to half a line in-between etc.<p>The ASCII 'screenshots' came out beautifully. From then on when a call came it, we told them to use the view log menu item, scroll to the trade time, then they'd shut up quick. A picture is worth a 1000 words indeed.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733412"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733412" href="https://news.ycombinator.com/vote?id=38733412&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I had an old boiler that would sometimes trip and lock out the heat until someone went down and power cycled it. (It was its own monstrous hack of a gas burner fitted to a 1950s oil boiler and I think a flame proving sensor was bad.)<p>Every time it happened, it made for a long heat up cycle to warm the water and rads and eventually the house.</p><p>So I built an Arduino controlled NC relay that removed power for 1 minute out of every 120. That was often enough to eliminate the effect of the fault, but not so often that I had concerns about filling too much gas if the boiler ever failed to ignite. 12 failed ignitions per day wouldn’t give a build up to be worried about.</p><p>That ~20 lines of code kept it working for several years until the boiler was replaced.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38733509"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733509" href="https://news.ycombinator.com/vote?id=38733509&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I have a similar one.<p>Our boiler has a pump to cycle hot water around the house - this makes it so you get warm water right away when you turn on a faucet and also prevents pipes in exterior walls from freezing in the winter.</p><p>This stopped working, the pump is fine but the boiler was no longer triggering it.</p><p>I just wired up mains through an esp32 relay board to the pump and configured a regular timer via esphome.</p><p>Temperature based logic would be even better but I didn't find a good way to measure pipe temperature yet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741483"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741483" href="https://news.ycombinator.com/vote?id=38741483&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I'm thiiiiiiis close to installing a circulating pump. I plan to power it off the bathroom lightswitch, which I might just replace with a motion sensor.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733586"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38733586" href="https://news.ycombinator.com/vote?id=38733586&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I eventually switched to an ESP32 and added temperature graphing: <a href="https://imgur.com/a/VM7nD74" rel="nofollow noreferrer">https://imgur.com/a/VM7nD74</a><p>IIRC, I used an RTD that I had left over from a 3D printer upgrade, but an 18B20 would fine as well. A 10K NTC resistor might even be good enough. For what I needed (and I think for what you need), just fixing the sensor to the outside of the pipe [if metal] will give you a usable signal. That sensor was just metal HVAC taped to the front cast iron door of the burner chamber.</p><p>But a dead-simple timer solution gets you pretty far as you know.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38733647"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38733647" href="https://news.ycombinator.com/vote?id=38733647&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>The pipes are insulated and I didn't want to cut into that, but maybe a small hole for a sensor wouldn't be too bad.<p>But as you say, timer works good enough and that means little motivation to continue to work on it -- countless other projects await :)</p><p>BTW I've also tuned the timer to run for longer in the morning to get a hot shower ready.</p><p>Edit: nice dashboard, what are you using for the chart? I like the vintage look.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38733914"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38733914" href="https://news.ycombinator.com/vote?id=38733914&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>That is another somewhat hacky thing.<p>I have a mix of shame and pride that the chart (everything in the rectangle) is entirely hand-coded SVG elements emitted by the ESP web request handler.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38733513"><td></td></tr>
                <tr id="38741572"><td></td></tr>
                        <tr id="38735259"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38735259" href="https://news.ycombinator.com/vote?id=38735259&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Around 16 years ago, Wordpress security was just not up to snuff yet, and my popular Wordpress-based site kept getting hacked by pharmaceutical spammers and the like. After several such incidents, I wrote a "wrapper" that loaded before Wordpress to scrutinize incoming requests before a lick of Wordpress code was executed. It had blacklists, whitelists, automatic temporary IP blocking, and that sort of thing. There was no reason for visitors to upload files, so any non-admin POST request with a file upload was automatically smacked down.<p>It wasn't pretty, but the hackers never got through again, and that clunky thing is still in service today. I coded it to quarantine all illicit file uploads, and as a consequence I have many thousands of script kiddies' PHP dashboards from over the years.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741249"><td></td></tr>
            <tr id="38741277"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741277" href="https://news.ycombinator.com/vote?id=38741277&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>That reminds me of my terrible spam prevention hack. We kept getting a bunch of spammers signing up for our newsletters, so I made the form require a JavaScript based hidden input to submit. That worked for a while, but then new spammers started executing the JS and getting through. So I added new JS that just waits 15 seconds before putting the right hidden values in the form, and that’s done the trick (for now).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741491"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741491" href="https://news.ycombinator.com/vote?id=38741491&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>When you say it loaded before Wordpress loaded, what exactly does that mean? Was it a proxy that handled incoming requests and passed them off to Wordpress?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741584"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741584" href="https://news.ycombinator.com/vote?id=38741584&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Nice. I just had nginx requiring basic auth for anything hazardous.<p>Probably broke a few features I’m not using in the process. :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38741671"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741671" href="https://news.ycombinator.com/vote?id=38741671&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I built a writing/formatting product now used by 60k+ indie authors. One of the requirements was to format PDFs for print publishing with different themes and configurable layouts. Instead of building a custom PDF rendering engine, I decided to use Puppeteer to generate the PDFs.<p>But there were a bunch of issues we had to deal with:</p><p>- To render the gutter (margin in the middle) you had to know which side of the book each page would fall on.</p><p>- To generate the headers and footers, you had to know the exact page number for each of the pages.</p><p>- You had to know how many pages the table of contents would take up, but you couldn't know the page numbers for each chapter until the book was fully generated.</p><p>What I ended up doing was to generate multiple PDFs for each chapter, header, footer, and table of contents separately, then stitching them together very carefully to build the final export. Super hacky, but it ain't stupid if it works!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741678"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741678" href="https://news.ycombinator.com/vote?id=38741678&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Given what I know about the PDF spec and the various papercut I had with various PDF tools, your solution seems as sane as it can be tbh.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38741165"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741165" href="https://news.ycombinator.com/vote?id=38741165&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Mine's getting command output out of docker. For long builds (I had one that took 4 hours), it was gutting to have it fail a long way in and not be able to see the output of the RUN commands for thorough debugging.<p>So I devised a stupidly simple way: add &amp;&amp; echo "asdfasdfsadf" after each RUN command. I mashed the keyboard each time to come up with some nonsense token. That way, docker would see RUN lines as different each time it built, which would prevent it using the cached layer, and thus would provide the commands' output.</p><p>I wrote the same thing (more completely) here: <a href="https://stackoverflow.com/a/73893889/5783745" rel="nofollow noreferrer">https://stackoverflow.com/a/73893889/5783745</a></p><p>(a comment on that answer provides an even better solution - use the timestamp to generate the nonsense token for you)</p><p>As stupid as this solution is, I've yet to find a better way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741182"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741182" href="https://news.ycombinator.com/vote?id=38741182&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I'm a Docker amateur, so this will be a dumb question, but if you were using that technique after every run line in a DockerFile, wouldn't they be <i>the same</i> every time they're run? Like, it's random, but it's the same random values stored in the file, so wouldn't the lines get cached? Or did you adjust the DockerFile each time?<p>Or am I completely missunderstanding?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741196"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38741196" href="https://news.ycombinator.com/vote?id=38741196&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>&gt; Or am I completely missunderstanding?<p>No, I just didn't explain it very well. You have to mash the keyboard <i>each time</i> (i.e. each build) to come up with some new token. The reason this (dumb) idea was so useful was it was a choice between that (dumb idea) and either run with --no-cache (i.e. wait 2-3 hours) or build normally and not have a clear idea why it failed (since no console output for cached layers), so taking a moment to mash the keyboard in a few places (as absolutely stupid as that is) was <i>way</i> better than the alternative of not having complete console output (docker provides no way to --no-cache on a <i>per layer</i> basis, hence my stupid way of achieving it).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38733701"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733701" href="https://news.ycombinator.com/vote?id=38733701&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I worked for a US media company that forced us to use a half-baked CMS from a Norwegian software company, with no apparent provisions in the contract for updates or support.<p>The CMS was absolutely terrible to work in.  Just one small example: It forced every paragraph into a new textarea, so if you were editing a longer news story with 30 or 40 paragraphs, you had to work with 30 or 40 separate textareas.</p><p>So I basically built a shadow CMS on top of the crappy CMS, via a browser extension.  It was slick, it increased productivity, it decreased frustration among the editors, and it solved a real business problem.</p><p>If we had had a security team, I'm sure they would have shut it down quickly.  But the company didn't want to pay for that, either!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733418"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733418" href="https://news.ycombinator.com/vote?id=38733418&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I worked at a startup where the core backend was 1 giant serverless Function.  For error handling and recovery, the Function ran in a while loop.<p>For all its faults, it worked and it was generating revenue.  Enough that the startup got to a sizable Series A.  That experience completely changed how I think about writing code at startups.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38733485"><td></td></tr>
                <tr id="38733839"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38733839" href="https://news.ycombinator.com/vote?id=38733839&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>A customer of mine wraps their Python code into try except pass so it never stops because of errors, it just skips what would have run in the code after the exception. I added some logging so we're slowly understanding what fails and why.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733567"><td></td></tr>
            <tr id="38733515"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733515" href="https://news.ycombinator.com/vote?id=38733515&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>this is great.  if you look at older game source code you find things like this.  things that we view as horrible hacks which are both extremely stable and perform well.<p>i see no reason to stop using these types of solutions, when appropriate.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38740040"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38740040" href="https://news.ycombinator.com/vote?id=38740040&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Old games also didn't use a database, they saved everything in a giant text file.<p>I'm not sure if they were "extremely stable" though. Like Myspace, it might only work up until a certain point. What kills stuff is usually going viral.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38740601"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38740601" href="https://news.ycombinator.com/vote?id=38740601&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I think you maybe underestimate the utility and reliability of flat text files on a filesystem.<p>If you don’t trust a filesystem, you can’t trust anything that uses one.</p><p>Flat files don’t scale past a certain point, but that point is way higher than most believe it is.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733559"><td></td></tr>
                        <tr id="38741638"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741638" href="https://news.ycombinator.com/vote?id=38741638&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>At my previous job I had a number of production test rigs in China for testing PCB assemblies as they came off the manufacturing line. These rigs would sit on the shelf for months at a time and be pulled out to fo a run of a couple thousand boards then put away again.<p>We wanted to collect some stats about the boards being tested but 
The internet in the factory was really flakey and we didn't want to pay for a 4G internet plan for a rig that was turned off most of the time.</p><p>I eventually went for a cron job that would just try uploading all the local logs to s3 through rsnapshot every 15min. It worked great and was less than 20 lines of shell script.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741603"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741603" href="https://news.ycombinator.com/vote?id=38741603&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I was working on a video game, and we had a few hundred player hosted servers. The default way that steam handles server listings is not super great, and there was quite a lot of metadata for each server I wanted to filter by.<p>I didn't know how to set up a centralized service to handle server discovery ourselves, so I had each server serialize, compress, and base64 its metadata and store it in some "rules" field in the Steam API. Problem was that the rules field was a list of indeterminate length of strings of indeterminate length. Absolutely no documentation, so I had to brute force it to find the limits. It was just barely enough.</p><p>So the client would fetch the full list of servers, filter on the few parameters steam natively supported, then they'd fetch the metadata for every remaining server.</p><p>Honestly I feel really bad about this one. It was a bad solution but it worked for years.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733458"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733458" href="https://news.ycombinator.com/vote?id=38733458&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I had a GCP Cloud Run function that rendered videos. It was fine for one video per request but after that it slowed to a crawl and needed to shut down to clear out whatever was wrong. I assume a memory leak in MoviePy? Spent a couple of days looking at multiple options and trying different things, in the end I just duplicated the service so I had three of them and rotated which one we sent video renders to and do each render one at a time. It was by far the cheapest solution, means we processed them in parallel rather than serially so it was faster, all in all it worked a treat.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741477"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741477" href="https://news.ycombinator.com/vote?id=38741477&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Hah welcome to cloudrun! I was evaluating it a few years ago to host some internal corporate app.<p>It worked great and was way easier to deploy than k8s setups. However after some testing we found out that the core logic of the app - a long running process, would just crawl to a halt after some time.</p><p>It turned out google wanted to push you to use their (paid) queue / pubsub solutions, but they didn’t want it to be _too_ obvious, so cloudrun would actually throttle its cpu sometime after the request it was spawned was returned.</p><p>Our logic was based on pushing stuff in a queue and having it be processed outside of a request, but google just f*ked with that solution.</p><p>And it would have been fine if that was upfront info, but it was buried in a doc page somewhere obscure, small print…</p><p>Thats the time I realized how bad gcp can be…
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733501"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733501" href="https://news.ycombinator.com/vote?id=38733501&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>This reminds me of a service I recently found that was routinely crashing out and being restarted automatically. I fixed the crash, but it turns out it had ALWAYS been crashing on a reliable schedule - and keeping the service alive longer created a plethora of other issues, memory leaks being just one of them.<p>That was a structural crash and I should not have addressed it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38733535"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38733535" href="https://news.ycombinator.com/vote?id=38733535&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>How many memory leaks were discovered only during the winter code freeze, because there were no pushes being done, so no server restarts</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741463"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38741463" href="https://news.ycombinator.com/vote?id=38741463&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>At reddit we would randomly select a process to kill every 10 minutes out of the 10 or so on each machine, just so they would all get a restart in case we didn't do a deployment for a few days.<p>At Amazon they schedule service bounces during code freeze for any service that is known to have memory leaks because it's easier than finding the leak, which isn't usually an issue since it gets deployed so often.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741569"><td></td></tr>
                  <tr id="38733630"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38733630" href="https://news.ycombinator.com/vote?id=38733630&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>At Fastmail the ops team we ran fail overs all the time just to get our failures so reliable they worked no matter what. Only once in my tenure did a fail over fail and in that case there was a --yolo flag</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733767"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38733767" href="https://news.ycombinator.com/vote?id=38733767&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Oooh, you’ve just reminded me of the email server at my first dev job. It would crash every few days and no one could work out why. In the end someone just wrote a cron job type thing to restart it it once a day, problem solved!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733506"><td></td></tr>
                  <tr id="38741531"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741531" href="https://news.ycombinator.com/vote?id=38741531&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Running everything on my own home computers via cloudflared<p>eBank AI art generator and social media netwrck.com are running locally on my GPUs.</p><p>would have cost fortunes on the cloud
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733651"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733651" href="https://news.ycombinator.com/vote?id=38733651&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>My mom's place (about 100 miles from me) has a water heater that's of an age where it could fail, so I put together a Pico W and a water sensor. I had it notify me daily just to make sure it was still working. And for reasons unknown, every 8 days it would stop notifying. A reboot would resolve it. We tried logging errors and having it report upon reboot but I wasn't versed enough with Pi to figure out anything more than it being an HTTP POST error. So I changed the code so when it got to that error instead of logging it would just reboot itself, and all has been smooth since.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38734012"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38734012" href="https://news.ycombinator.com/vote?id=38734012&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Needed to get data out of a CRM system for specific printed orders - when it was printed, who processed it, what was on the order etc.<p>The process of authenticating with the CRM was complex and there wasn't a way to get anything at print time and most of the data was stored all over the place.</p><p>But I found the printed report knew almost everything I wanted, and you could add web images to the paperwork system. So I added a tiny image with variable names like "{order_number}.jpg?ref={XXX}&amp;per={YYY}" and then one for each looped product like {order_number}/{sku}.jpg?count={X}&amp;text=..." etc. After a few stupid issues (like no support for https, and numbers sometimes being european format) it was working and has remained solid ever since. Live time stamped data, updates if people print twice, gives us everything we wanted just by a very silly method.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733657"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733657" href="https://news.ycombinator.com/vote?id=38733657&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>When I was a teenager I had a friend who wanted to build a PC on a <i>very</i> limited budget, and she wanted it to be able to play The Sims 2. Well after much bargain hunting and throwing ideas around, we couldn’t find a way to afford every component we needed, but we were close, so we decided to forgo a case! Just put the motherboard on the desk with other components arrayed around it. Cables everywhere. The tricky part is we had no power button, but I showed her which pins to sort out with a paper clip, and it worked great.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733619"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733619" href="https://news.ycombinator.com/vote?id=38733619&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>My CPAP's onboard humidifier failed.<p>I ended up swapping it out to a generic in-line CPAP humidifier, but at the same time, realized I could partially automate the process of refilling the chamber (and not have to keep unhooking hoses) by adding an in-line oxygen tee, some aquarium plumbing, a check valve, and a 12 volt pump and switch.</p><p>In the morning I just hold a button and the tank magically refills itself ;)</p><p>Introducing Semi-Autofill(tm): <a href="https://i.ibb.co/NmDbVvw/autofill.png" rel="nofollow noreferrer">https://i.ibb.co/NmDbVvw/autofill.png</a></p><p>(Also: The Dreamstation, while recalled, was personally de-foamed and repaired myself -- I don't trust Philips any further than I can throw them now. I now self-service my gear.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741512"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741512" href="https://news.ycombinator.com/vote?id=38741512&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I used to work for a small medical device distributor. We used an e-commerce platform that, at the time, didn’t have an API. We wanted to synchronize our products with their platform as products were added, discontinued, copy/image changes, etc.<p>I ended up using capybara (a Ruby gem for writing browser automation instructions for system tests in web apps) to automate all of the “clicks” to make the updates in the system.</p><p>It actually worked pretty well. It wasn’t fast, but it was better than having a human keep the data in sync.</p><p>After a few years, the platform released a REST API, and we transitioned to that. But browser automations worked great in the meantime!</p><p>edit: spelling
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38734894"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38734894" href="https://news.ycombinator.com/vote?id=38734894&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Way back I had a friend that wanted his (maybe) "Sargon" chess program to run faster. Luckily it was on the Atari 8-bit and I knew a thing or two. The program seemed to use standard b/w hires graphics nothing super fancy, so I thought I could make a pre-boot loader.<p>The theory was that the Atari spends a good chunk (30%) of its time for display memory access. That can be disabled (making a black screen) and re-enabled. My pre-boot program installed a vertical blank interrupt handler reading the 2nd joystick port: up/down for display on/off. After installing the handler, the program waited for diskette swap and pretended to be the original program loader reading the disk layout into memory and jumping to the start. Worked like a charm first go.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741567"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741567" href="https://news.ycombinator.com/vote?id=38741567&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>My corporate VPN wouldn't connect to same public IP after 24 hours (I work from home). So I wrote a very crude bash script on Raspberry Pi Zero 2W (which also runs local DNS server), which would telnet into the router 5 minutes before my login time, and reboot the router</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733558"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733558" href="https://news.ycombinator.com/vote?id=38733558&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Launching a headless browser just to generate some PDFs.<p>Turns out, if you want to turn html+css into pdfs quickly, doing via a browser engine is a "works really well" story.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741290"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741290" href="https://news.ycombinator.com/vote?id=38741290&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I did the same. We had a tool that would let you export to pdf. That pdf would be sent to our customers. Initially we just used the print functionality in the users browser, but that caused output to vary based on the browser/os used.<p>People complained that the PDFs generated were slightly different. So instead I had the client send over the entire html in a post request and open it up in a headless chrome with --print-to-pdf and then sent it back to the client.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38734022"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38734022" href="https://news.ycombinator.com/vote?id=38734022&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I wrote a Python package [1] that does something similar! It allows the generation of images from HTML+CSS strings or files (or even other files like SVGs) and could probably handle PDF generation too.
It uses the headless version of Chrome/Chromium or Edge behind the scenes.<p>Writing this package made me realize that even big projects (such as Chromium) sometimes have features that just <i>don't</i> work. Edge headless wouldn't let you take screenshots up until recently, and I still encountered issues with Firefox last time I tried to add support for it in the package. I also stumbled upon weird behaviors of Chrome CDP when trying to implement an alternative to using the headless mode, and these issues eventually fixed themselves after some Chrome updates.</p><p>[1] <a href="https://github.com/vgalin/html2image">https://github.com/vgalin/html2image</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38734984"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38734984" href="https://news.ycombinator.com/vote?id=38734984&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Yeah it's the same concept, instead of .screenshot you do .pdf in pupetteer.<p>But with pdfs the money is on getting those headers and footers consistent and on every page, so you do need some handcrafted html and print styling for that (hint: the answer is tables).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733656"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733656" href="https://news.ycombinator.com/vote?id=38733656&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I've implemented recently just the same thing, but for SVG -&gt; PNG conversion. I found that SVG rendering support is crap in every conversion tool and library I've tried. Apparently even Chrome has some basic features missing, when doing text on path for example. So far Selenium + headless Firefox performs the best ¯\_(ツ)_/¯</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741301"><td></td></tr>
            <tr id="38734157"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38734157" href="https://news.ycombinator.com/vote?id=38734157&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I've seen a bit of SaaS and legacy websites-with-invoice-system doing that, with e.g. wkhtmltopdf. It isn't a lightweight solution, but it's a good hammer for a strange nail, a lot of off-the-shelf report systems suck.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741291"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741291" href="https://news.ycombinator.com/vote?id=38741291&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I mean browsers are built for and the best at displaying html+css. Given that they are "living standards", very few other programs can hope to keep up.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38741626"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741626" href="https://news.ycombinator.com/vote?id=38741626&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I was pitching a “Slack” app five years before Slack was released. Everyone I pitched to thought it was stupid because people already used IRC.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733743"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733743" href="https://news.ycombinator.com/vote?id=38733743&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I had to connect an old accounting system to a web app with enhanced ui (an operator determines a payment on a visual graph of contracts between companies, plus graphs editor). There were two ways: a separate db with periodic sync, and a direct COM-connection to the old app, which was scriptable through js&lt;=&gt;COM library. I chose the latter, tests worked fine.<p>After a month or so I started to notice that something is wrong with performance. Figured out that every `object.field` access through a COM proxy takes exactly 1ms. Once there’s enough data, these dots add up to tens of seconds.</p><p>&gt;_&lt;</p><p>Instead of doing a rewrite I just pushed as much of js logic as possible beyond the COM, so there’s only a constant or little amount of `a.b.c` accesses on my side. Had to write a json encoder and object serialization inside the old app to collect and pass all the data in one go.</p><p>The web app was abandoned few months later for unrelated reasons.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38734782"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38734782" href="https://news.ycombinator.com/vote?id=38734782&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>When I was a network support engineer, we had a case where a company had a bizarre &amp; intermittent problem on workstations.  Wish I could remember what the problem was but this is 20+ years ago now.<p>To troubleshoot it, we installed Microsoft Network Monitor 2.0 (this was well before Wireshark...) on a few workstations.  NM2 installed a packet capture driver and a GUID front-end.  And...the problem went away.</p><p>Our best guess was that the problem was some sort of race condition and installing the packet capture driver was enough to change the timing and make the problem go away.  The customer didn't want to spend more time on it so they installed NM2 everywhere and closed the case.</p><p>I occasionally imagine somebody trying to figure out why they're still installing the NM2 driver everywhere.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741484"><td></td></tr>
            <tr id="38733545"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733545" href="https://news.ycombinator.com/vote?id=38733545&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I used a WiFi smart switch and a USB thermometer to make a sous vide cooker. I plugged a slow cooker into the smart socket, put the thermometer in it, and wrote a program to turn the switch on/off depending on the temperature the thermometer registered.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733393"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733393" href="https://news.ycombinator.com/vote?id=38733393&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I used SQLite for coordination between processes. It was a huge Python application that originally used the multiprocessing library and had to be migrated to Rust.<p>In hindsight, it would have been better to use a local HTTP server. Seemed like overkill at the time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733713"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733713" href="https://news.ycombinator.com/vote?id=38733713&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>This was a while ago so it probably wouldn’t work today.<p>I had to get past a captcha for automation and the solution I came up with was to always choose 2. If it was incorrect, just request a new captcha until it passed. For some reason, 2 was the answer most of the time so it actually rarely had to retry anyways
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741500"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741500" href="https://news.ycombinator.com/vote?id=38741500&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>&gt; <i>For some reason, 2 was the answer most of the time</i><p>I’m getting flashbacks to LensLok™; the two-letter codes were often very hard to read though the plastic lens, and when you’d get the code wrong enough times, you’d have to load in the entire program again (from tape!), which took <i>ages</i>.  There was also a “training” mode, of sorts, to help people familiarize themselves with reading the codes.  In the training mode, the code letters were always “OK”.   But here’s the kicker: For some <i>unfathomable</i> reason, the <i>real</i> code was very often (but not always) <i>also</i> the letters “OK”!  So it was easier (at least on your eyes) to just always enter the letters “OK”, and hope it worked.  What time you lost reloading for when it didn’t work you’d save by not having to adjust the scale to the size of your TV every single time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733762"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733762" href="https://news.ycombinator.com/vote?id=38733762&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Definitely wouldn't work today. Nowadays you need to classify like 30 images of bicycles and 20 fire hydrants and pray to god before they accept your answer...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38734441"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38734441" href="https://news.ycombinator.com/vote?id=38734441&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>This is why I don’t have an account with Snapchat/Instagram/etc. I tried signing up and physically couldn’t get past the challenges. I take too long to solve them and then I’m asked to solve more…</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38735808"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38735808" href="https://news.ycombinator.com/vote?id=38735808&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Sometimes if they hate your client and ip they put you into a captcha tar pit that you only think you could get out of. Only a bot would keep trying but a human will die in there too even if they have the tenacity of a bot.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38733836"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733836" href="https://news.ycombinator.com/vote?id=38733836&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I wrote it up in a bit more detail[1], so I'm giving away the punch line here, but I used to use some cursed bash wrappers to smuggle my bashrc and vimrc along on ssh sessions to mostly-ephemeral hosts by stashing them in environment variables matching the LC_* pattern allowed by default for pass-through in debian-ish sshd configs.<p>[1]: <a href="https://gitlab.com/-/snippets/2149340" rel="nofollow noreferrer">https://gitlab.com/-/snippets/2149340</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733782"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733782" href="https://news.ycombinator.com/vote?id=38733782&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Mid 90s, can't remember the tech (VB, C, Java?) In the very last hours before an important demo one of the programs stopped working. Not always, only every second time we run it. No version control, no unit tests. It's obviously some side effect but debugging it before the demo and making changes could make it worse. Maybe it won't even run anymore, anytime. We decide to wrap it into a script that starts it, kills it, runs it again. That worked and made us pass the demo.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38734675"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38734675" href="https://news.ycombinator.com/vote?id=38734675&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I built a vacation plant waterer with some tubing, 3d-printed heads, submersible pumps and an Arduino. For a longer trip, I needed a source of water that I could pump from.<p>I realized the toilet tank is self-refilling because of the float valve and won't overflow .  So clean it out and a good place to pump my submersible pumps.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741510"><td></td></tr>
                  <tr id="38733348"><td></td></tr>
                <tr id="38733494"><td></td></tr>
                <tr id="38734406"><td></td></tr>
                        <tr id="38734615"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38734615" href="https://news.ycombinator.com/vote?id=38734615&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I used to be really into modding the game Jedi Knight: Dark Forces II. The quirky engine has all sorts of weird bugs and limitations.<p>I created a flare gun weapon (similar to the stick rail gun missiles so nothing to crazy here) but found that if a player died when they respawned the flares were still stuck on them and damaging them when they respawned even though their whole location had changed. This bug would exist with rail gun missiles as well but since the death animation was long and the fuse so sort it would never present in the base game.</p><p>I experimented with using detach commands that ran on player death but they'd just instantly reattach to the player model because of their proximity. I ended up creating an invisible explosive entity that fired on player death from the center of the player which did a damage flag ignored by players but which destroyed the flares.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741255"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741255" href="https://news.ycombinator.com/vote?id=38741255&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I "fixed" an appliance that was nuisance tripping an AFCI breaker by wrapping the power cord one turn through a ferrite choke.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741426"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741426" href="https://news.ycombinator.com/vote?id=38741426&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I like how ChatGPT lets you speak efficient jargon while I can read in layman terms. It says an Arc Fault Circuit Interrupter is supposed to detect arcing electrical faults, but some appliances have arcs in their normal operation, causing nuisance trips. A ferrite choke is a ring of magnetic ceramic that is designed to suppress high-frequency electromagnetic interference in electronic circuits. Clever and practical, says ChatGPT.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733451"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733451" href="https://news.ycombinator.com/vote?id=38733451&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>`sed` text files as a replacement for templating.<p>In the text file you have something you want to template (or "parametrize") from an outside variable, so you name that something like @@VAR@@ and then you can sed that @@VAR@@ :-)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741467"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741467" href="https://news.ycombinator.com/vote?id=38741467&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I think the m4 macro processor might be the more canonical way to do it.  Unless you’re writing a shell script, in which case a “here-document” with embedded $VARIABLES is more straightforward.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733592"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733592" href="https://news.ycombinator.com/vote?id=38733592&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>That's how we do it. Not with sed exactly, but string replacement. One is a bull email sender that only supports VBScript, the other is C#, but the users aren't supposed (or need) to have full templating powers, so this way it's easier.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733467"><td></td></tr>
                <tr id="38739268"><td></td></tr>
                        <tr id="38735392"><td></td></tr>
            <tr id="38733457"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733457" href="https://news.ycombinator.com/vote?id=38733457&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Generated HTML email newsletters from Excel (in 2004).<p>It was a big old-fashioned bookseller trying to compete with Amazon. Software and the web was locked down tight, but they opened a daily report in Excel, and I built a VBA macro that generated the necessary HTML and published the images to an FTP server. Turned a 2 day job into a 10 minute one.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741424"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741424" href="https://news.ycombinator.com/vote?id=38741424&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Have a bunch of static data that should live in a database? Just check that sucker into git and load it into memory on boot. Bing bam boom.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38733414"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733414" href="https://news.ycombinator.com/vote?id=38733414&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>`envsubst` on a k8s manifest, for templating. The space for templating/dynamic k8s manifests is complex, needlessly so I felt. But this... just works. It has been running in CI for a couple months now, deploying to prod. I'm sure the day that breaks down will come, but it's not here yet.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38740219"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38740219" href="https://news.ycombinator.com/vote?id=38740219&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>ZX Spectrum BASIC. Numbers could only be 8 digits, needed more for a Spacemaster RPG ship designer program I wrote for my friends. Came up with storing values as strings and splitting/manipulating them as numbers when required. About fifteen years old. Probably the smartest thing I have ever written, grin.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741269"><td></td></tr>
                  <tr id="38733508"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733508" href="https://news.ycombinator.com/vote?id=38733508&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Monkey patching vendor code. They agreed their code didn’t work and produced wrong results, but the correct version would be slower, so they didn’t want to change it.<p>So I dynamically replaced the part of their code that was wrong. That monkey patch has run years and is still going :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38741652"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741652" href="https://news.ycombinator.com/vote?id=38741652&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>You just reminded me of an old story.<p>The company I was working for purchased some kind of email spamming program to send mass emails. However they quickly found that when more than a small number (10 to 15,000?) of addresses were in the list it took forever.</p><p>Support wasn’t being helpful, so I decided to look at it. It was some kind of PHP application and what I eventually found was it was doing a database query doing table scans for everything because there was a missing index that was incredibly obvious.</p><p>I added the index, the program worked well into huge numbers of emails addresses, and we informed the vendor.</p><p>The program was soon updated and it fixed the problem as well. Also all the PHP code was now obfuscated/encrypted.</p><p>I guess they didn’t like my helpful nature.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733605"><td></td></tr>
                  <tr id="38741257"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741257" href="https://news.ycombinator.com/vote?id=38741257&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>My organization has a firewall policy straight outta the 90s. They'll only allow for for static IP to static IP traffic rules over single ports. This is in conflict with modern cloud CICD where you don't know ahead of time what IP you're gonna get in a private subnet when doing a new build.<p>Our work around was to configure HA proxy to be a reverse load balancer and do creative packet forwarding. Need to access an Oracle database on prem? Bind port 8877 to point that that databases IP on port 1521 and submit a firewall rule request.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38741347"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741347" href="https://news.ycombinator.com/vote?id=38741347&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>In the undergrad Control Systems course, I brute-forced Kalman Filter matrix to balance the inverted pendulum on a track experiment. Worked fine.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741158"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741158" href="https://news.ycombinator.com/vote?id=38741158&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Running an industrial machine installation and my Eastern European colleagues looped a 200 meter tape measure around the line 4 times to get a more accurate measure.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38735044"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38735044" href="https://news.ycombinator.com/vote?id=38735044&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span><i>TL;DR: Had no database so I made a PHP page with a hardcoded array of 100,000 coupon codes.</i><p>---</p><p>Made a PHP landing page for a customer where they could redeem a coupon code they were sent via snail mail. About 100,000 codes were sent out via USPS.</p><p>Threw together the basic code you might expect, simple PHP page + MySQL database. Worked locally because customer was dragging their feet with getting me login creds to their webhost.</p><p>Finally, with the cards in the mail, they get me the login creds at 5PMish. I login and <i>there's no database.</i> Cards are going to be arriving in homes as early as 8AM the next day. How TF am I going to make this work... without a database?</p><p>Solution... I just hardcoded all 100,000 codes into a giant MySQL array. Or maybe it was a hash/dict or something. I forget.</p><p>Anyway, it performed FINE. The first time you used the page it took about 30 seconds to load. But after that, I guess `mod_php` cached it or something, and it was fine. Lookups returned in 100ms or so. Not spectacular but more than performant enough for what we needed.</p><p>Got paid. Or, well, my employer did.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733608"><td></td></tr>
            <tr id="38733462"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733462" href="https://news.ycombinator.com/vote?id=38733462&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I was part of a team which had to make web interactives for an old desktop-only Java-based CMS which published out to HTML. This was back before cross-publishing to formats like Apple News was important; we only had to worry about things working on the browser version.<p>The CMS didn't support any kind of HTML/JS embed, and had quite a short character limit per "Text" block. But luckily, that block didn't filter out _all_ inline HTML - only some characters.</p><p>So, a bootstrap "Loading" element was inserted, along with a script tag which would bring in the rest of the resources and insert those in to the page where the bootstrap was placed. This quickly became a versatile, re-usable loader, and allowed us to launch the features. But all this grew from a very inelegant hack which just happened to work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38735020"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38735020" href="https://news.ycombinator.com/vote?id=38735020&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>One of the first things I built as a developer at the first startup I worked for (circa 1998 or 1999, I was originally hired as a graphic and web designer) was a system I wrote in Allaire ColdFusion that used Macromedia Flash Generator to render and save custom graphic page headers and navigation buttons for e-commerce websites by combining data stored in an Access database with Flash templates for look and feel.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38741517"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741517" href="https://news.ycombinator.com/vote?id=38741517&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>I did a lot of bad database things - one time a client wanted me to upgrade their vendor software system but they had a managed service provider that they were in an active legal dispute with.<p>So after the MSP basically stopped responding to them they asked us if we could upgrade "without" SA - our company's position was it was their data so anything they wanted us to do with it was fine.</p><p>So I had a conundrum - how do I get SA without SA? 
Well - I knew we had one loophole - we used xp_cmdshell for some critical features of the app, and an unprivileged user can run it.</p><p>If you're not familiar with xp_cmdshell it basically is a stored procedure that passes your commands out to a windows shell, but its pretty functionally limited on purpose.</p><p>I wanted to copy the data, move it around, make a backup, send that to a place, and so I wrote that code in powershell, then base64 encoded it (because it needed to survive shell encoding problems), then chunked it across the wire(because length problems), reassembled it, and then executed it with xp_cmdshell.</p><p>Worked like a charm.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733430"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733430" href="https://news.ycombinator.com/vote?id=38733430&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I use a table object and a OnAfterModifyRecord trigger to process OData calls in Navision 2018 (ERP System). For some reason I can not call actions manually so I write whatever I want to do into a table and process accordingly with triggers.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38734423"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38734423" href="https://news.ycombinator.com/vote?id=38734423&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Adding a Content Security Policy of “upgrade-insecure-requests”.  It does nothing meaningful for your security, but it’s enough to satisfy a bunch of these scanning tools that giving you a letter grade.<p>Yes, we want to add a robust CSP, but we currently have some limitations/requirements that make implementation more challenging.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733553"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733553" href="https://news.ycombinator.com/vote?id=38733553&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>Define works? Ive seen stupid and not working but convinced it's working until proven otherwise...<p>I use to work part time restoring Fiat, Porsche, and VW rares for an old head out in the mid west, lots of "stupid but works" in those old
cars... Mercedes Benz once (1980s or so) employed glass containers to solve for fuel pressure problems. Insane coolant loop designs or early Fuel Injection systems that develop "Ghosts" lol...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733468"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733468" href="https://news.ycombinator.com/vote?id=38733468&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>A bunch of SQL triggers and procedures to overcome software limitations and workaround certain bugs which the developers won't fix (3rd party app).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38733527"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38733527" href="https://news.ycombinator.com/vote?id=38733527&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>Reminds me when we started implementing features as an Oracle trigger. It was meant to be “just a trigger” but then there are so many edge cases when you do an end—run around application code that it took a couple of week total. Boss was like “couple of weeks for a trigger!”</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733548"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733548" href="https://news.ycombinator.com/vote?id=38733548&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>In a previous role, I automated an unholy amount of business processes by adding doGet() / doPost() handlers to expose google sheets as basic web services. It's a bit slow for large sheets, but was quite nice to work with and troubleshoot, and the built-in history in google sheets allowed me to experiment with little risk of data loss/corruption.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38733570"><td></td></tr>
                  <tr id="38741260"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38741260" href="https://news.ycombinator.com/vote?id=38741260&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>TL/DR: I rearranged the address lines on an embedded controller with a razor knife to "fix" a bug on a bus translation chip.<p>I was writing the motor controller code for a new submersible robot my PhD lab was building. We had bought one of the very first compact PCI boards on the market, and it was so new we couldn't find any cPCI motor controller cards, so we bought a different format card and a motherboard that converted between compact PCI bus signals and the signals on the controller boards. The controller boards themselves were based around the LM629, an old but widely used motor controller chip.</p><p>To interface with the LM629 you have to write to 8-bit registers that are mapped to memory addresses and then read back the result. The 8-bit part is important, because some of the registers are read or write only, and reading or writing to a register that cannot be read from or written to throws the chip into an error state.</p><p>LM629s are dead simple, but my code didn't work. It. Did. Not. Work. The chip kept erroring out. I had no idea why. It's almost trivially easy to issue 8-bit reads and writes to specific memory addresses in C. I had been coding in C since I was fifteen years old. I banged my head against it for two weeks.</p><p>Eventually we packed up the entire thing in a shipping crate and flew to Minneapolis, the site of the company that made the cards. They looked at my code. They thought it was fine.</p><p>After three days the CEO had pity on us poor grad students and detailed his highly paid digital logic analyst to us for an hour. He carted in a crate of electronics that were probably worth about a million dollars. Hooked everything up. Ran my code.</p><p>"You're issuing a sixteen-bit read, which is reading both the correct read-only register and the next adjacent register, which is write-only", he said.</p><p>Is showed him in my code where the read in question was very clearly a <i>CHAR</i>. 8 bits.</p><p>"I dunno," he said - "I can only say what the digital logic analyzer shows, which is that you're issuing a sixteen bit read."</p><p>Eventually, we found it. The Intel bridge chip that did the bus conversion had a known bug, which was clearly documented in an 8-point footnote on page 79 of the manual: 8 bit reads were translated to 16 bit reads on the cPCI bus, and then the 8 most significant units were thrown away.</p><p>In other words, a hardware bug. One that would only manifest in these very specific circumstances.
We fixed it by taking a razor knife to the bus address lines and shifting them to the right by one, and then taking the least significant line and mapping it all the way over to the left, so that even and odd addresses resolved to completely different memory banks. Thus, reads to odd addresses resolved to addresses way outside those the chip was mapped to, and it never saw them. Adjusted the code to the (new) correct address range. Worked like a charm.</p><p>But I feel bad for the next grad student who had to work on that robot. "You are not expected to understand this."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38733633"><td></td></tr>
            <tr id="38733390"><td></td></tr>
            <tr id="38733426"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733426" href="https://news.ycombinator.com/vote?id=38733426&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><br><div>
                  <p><span>I made my own version of AWS workspaces inside AWS because workspaces is a buggy piece of shit and the client sucks. It's just an EC2 instance which can be started and stopped by a makefile that runs awscli and I query the IP address and open it in MS RDP!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38741565"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38741565" href="https://news.ycombinator.com/vote?id=38741565&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>At my company we used AWS workspaces for training classes. Whenever we'd have a class, we'd create 1 or 2 spare workspaces. If someone couldn't connect to their workspace, we'd give them the connection information for one of the spares.<p>I was so happy when we reworked our classes to no longer use AWS workspaces.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38733579"><td></td></tr>
            <tr id="38733582"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38733582" href="https://news.ycombinator.com/vote?id=38733582&amp;how=up&amp;goto=item%3Fid%3D38733282"></a></center>    </td><td><p><span>A company I worked for had a website where you could order mobile phones and subscriptions from different providers. This was just a frontend, and behind the scenes, they just ordered them directly from those providers. But those providers had terrible sites still written for IE6 (this was in 2010 I think). And yet those sites where all they had (for some reason; I don't know the full background).<p>So what happened is: the customer would order their phone subscription on the front end, that would create a job file that would be sent to a scheduler that managed 10 Windows VMs that used a Ruby Watir script to direct IE6 to fill in the data from the job file on the old decrepit website.</p><p>It's the most horrific hack that I ever touched (I forgot exactly, but I had to make some adjustments to the system), but it worked perfectly for a couple of years until those providers finally updated their websites.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do I need to get out the soldering-iron again? (2018) (134 pts)]]></title>
            <link>https://www.naughtycomputer.uk/do_i_really_need_to_get_out_the_soldering_iron_again.html</link>
            <guid>38732862</guid>
            <pubDate>Fri, 22 Dec 2023 10:27:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.naughtycomputer.uk/do_i_really_need_to_get_out_the_soldering_iron_again.html">https://www.naughtycomputer.uk/do_i_really_need_to_get_out_the_soldering_iron_again.html</a>, See on <a href="https://news.ycombinator.com/item?id=38732862">Hacker News</a></p>
Couldn't get https://www.naughtycomputer.uk/do_i_really_need_to_get_out_the_soldering_iron_again.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[NewPipe 0.26 (199 pts)]]></title>
            <link>https://github.com/TeamNewPipe/NewPipe/releases/tag/v0.26.0</link>
            <guid>38732781</guid>
            <pubDate>Fri, 22 Dec 2023 10:14:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/TeamNewPipe/NewPipe/releases/tag/v0.26.0">https://github.com/TeamNewPipe/NewPipe/releases/tag/v0.26.0</a>, See on <a href="https://news.ycombinator.com/item?id=38732781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p>This version also includes the changes from NewPipe Extractor <a href="https://github.com/TeamNewPipe/NewPipeExtractor/releases/tag/v0.23.0">v0.23.0</a> and <a href="https://github.com/TeamNewPipe/NewPipeExtractor/releases/tag/v0.23.1">v0.23.1</a>, which <strong>fix the recurring "Could not get like count" error</strong> on YouTube streams.</p>
<h3>New</h3>
<ul>
<li>
<p>Access more content provided by <strong>channels</strong> which is grouped in different <strong>tabs</strong> (<a data-error-text="Failed to load title" data-id="1812601152" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipeExtractor/issues/1082" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipeExtractor/pull/1082/hovercard" href="https://github.com/TeamNewPipe/NewPipeExtractor/pull/1082">TeamNewPipe/NewPipeExtractor#1082</a> <a data-error-text="Failed to load title" data-id="1419970052" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/9182" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/9182/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/9182">#9182</a> <a data-error-text="Failed to load title" data-id="2034411483" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10645" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10645/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10645">#10645</a> <a data-error-text="Failed to load title" data-id="2051311795" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10670" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10670/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10670">#10670</a> <a data-error-text="Failed to load title" data-id="2051434843" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10673" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10673/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10673">#10673</a>). The content of the channel tabs can vary by service:</p>
<ul>
<li>YouTube: videos, shorts, live, playlists, about
<ul>
<li>Note that YouTube does not provide upload date and duration for shorts, so they won't show up in the feed</li>
</ul>
</li>
<li>PeerTube: videos, playlists, channels (for accounts), about</li>
<li>SoundCloud: tracks, playlists, albums, about</li>
<li>Bandcamp: albums, tracks, about</li>
<li>media.ccc.de: videos, about</li>
</ul>
</li>
<li>
<p>Allow selecting <strong>image quality</strong> among multiple images <a data-error-text="Failed to load title" data-id="1691418409" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10062" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10062/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10062">#10062</a> <a data-error-text="Failed to load title" data-id="1933206762" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10482" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10482/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10482">#10482</a><br>
NewPipe supports selecting the image quality among multiple image versions. This comes with three different presets which can be selected from within the settings (low, medium and high quality). This is most noticeable in the recently introduced card style for stream lists which is now able to show thumbnails in higher resolutions. Some services (e.g. YouTube) do not always provide the highest quality thumbnails for those lists.</p>
</li>
</ul>
<h3>Improved</h3>
<ul>
<li>Adjust empty state message for <code>ListInfoFragment</code>s depending on <code>Info</code> stream type <a data-error-text="Failed to load title" data-id="1837669205" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10304" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10304/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10304">#10304</a></li>
<li>Show loading indicator before opening the download dialog from the share menu <a data-error-text="Failed to load title" data-id="1889285253" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10407" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10407/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10407">#10407</a></li>
<li>Improved accessibility of player interfaces <a data-error-text="Failed to load title" data-id="1783815362" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10199" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10199/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10199">#10199</a></li>
<li>Include a high-resolution option in the default resolution settings <a data-error-text="Failed to load title" data-id="1647706746" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/9987" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/9987/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/9987">#9987</a></li>
<li>Show play queue button in main player when there is one stream <a data-error-text="Failed to load title" data-id="1874120333" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10396" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10396/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10396">#10396</a></li>
<li>Add option to add playlist name and video name to playlist sharing content <a data-error-text="Failed to load title" data-id="1899741263" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10427" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10427/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10427">#10427</a></li>
<li>Improve audio stream selection for video-only streams in the downloader <a data-error-text="Failed to load title" data-id="1910300762" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10446" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10446/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10446">#10446</a></li>
</ul>
<h3>Localization and Documentation</h3>
<ul>
<li>Make capitalization of "Night theme" setting consistent with others <a data-error-text="Failed to load title" data-id="1840112286" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10313" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10313/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10313">#10313</a></li>
<li>Update Weblate &amp; fix string formats <a data-error-text="Failed to load title" data-id="1865694170" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10376" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10376/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10376">#10376</a></li>
<li>Fix selection of wrong languages in language picker <a data-error-text="Failed to load title" data-id="1887533765" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10406" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10406/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10406">#10406</a></li>
<li>Make "latest release" link more obvious to bug reporters <a data-error-text="Failed to load title" data-id="1848064107" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10331" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10331/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10331">#10331</a></li>
<li>[Readme] Remove Bitcoin and Bountysource donation options <a data-error-text="Failed to load title" data-id="1942181406" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10491" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10491/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10491">#10491</a></li>
<li>[Readme] Add Matrix room link <a data-error-text="Failed to load title" data-id="2029142174" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10632" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10632/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10632">#10632</a></li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Fix player audio focus not respecting mute <a data-error-text="Failed to load title" data-id="1828895982" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10275" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10275/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10275">#10275</a></li>
<li>Fix downloads of streams with missing <code>MediaFormat</code> <a data-error-text="Failed to load title" data-id="1758837550" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10165" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10165/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10165">#10165</a></li>
<li>[YouTube] Fix extraction of age-restricted music videos <a data-error-text="Failed to load title" data-id="1901722153" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipeExtractor/issues/1108" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipeExtractor/pull/1108/hovercard" href="https://github.com/TeamNewPipe/NewPipeExtractor/pull/1108">TeamNewPipe/NewPipeExtractor#1108</a> <a data-error-text="Failed to load title" data-id="1908467912" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10440" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10440/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10440">#10440</a></li>
<li>Fix restoring software license dialog <a data-error-text="Failed to load title" data-id="1905389329" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10436" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10436/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10436">#10436</a></li>
<li>Fix inconsistency between user interaction and database commit order when re-adding videos to a playlist <a data-error-text="Failed to load title" data-id="1206435598" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/8248" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/8248/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/8248">#8248</a></li>
<li>Fix playing SoundCloud songs under some conditions: now OPUS HLS streams are considered as unplayable, and thus other streams are preferred <a data-error-text="Failed to load title" data-id="1995699986" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10579" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10579/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10579">#10579</a></li>
<li>Fix app not responding, background app crashes and issues with starting the player <a data-error-text="Failed to load title" data-id="1995594629" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10578" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10578/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10578">#10578</a></li>
<li>Fix some null pointer exceptions <a data-error-text="Failed to load title" data-id="1995272772" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10576" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10576/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10576">#10576</a> <a data-error-text="Failed to load title" data-id="1995547067" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10577" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10577/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10577">#10577</a></li>
<li>Fix custom filename replacement character being interpreted as regex and crashing the app <a data-error-text="Failed to load title" data-id="1940278485" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10489" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10489/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10489">#10489</a></li>
<li>Fix notifying about old "new" streams <a data-error-text="Failed to load title" data-id="1943384759" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10494" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10494/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10494">#10494</a></li>
<li>Fix channel avatar not loading correctly sometimes <a data-error-text="Failed to load title" data-id="1997857448" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10581" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10581/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10581">#10581</a></li>
<li>Fix application lagging with many main page tabs <a data-error-text="Failed to load title" data-id="2051332864" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10671" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10671/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10671">#10671</a></li>
</ul>
<h3>Development</h3>
<ul>
<li>Simplify <code>MainActivity.tabSelected(MenuItem)</code> <a data-error-text="Failed to load title" data-id="1857851563" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10360" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10360/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10360">#10360</a></li>
<li>Image minizier: replace <code>Number.toFixed(0)</code> with <code>Math.floor()</code> <a data-error-text="Failed to load title" data-id="1865713034" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10377" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10377/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10377">#10377</a></li>
<li>Update miscellaneous libraries <a data-error-text="Failed to load title" data-id="1805818623" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10234" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10234/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10234">#10234</a> <a data-error-text="Failed to load title" data-id="1811092900" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10244" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10244/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10244">#10244</a></li>
<li>Improve the download helpers using the Java 7 NIO API. <a data-error-text="Failed to load title" data-id="1815080809" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10248" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10248/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10248">#10248</a></li>
<li>Fix memory leaks and add documentation <a data-error-text="Failed to load title" data-id="1871702250" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10394" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10394/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10394">#10394</a></li>
<li>Replace <code>MathUtils.clamp</code> with Kotlin <code>coerceIn</code> <a data-error-text="Failed to load title" data-id="1800046942" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10224" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10224/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10224">#10224</a></li>
<li>Bump AGP to 8.1.1 <a data-error-text="Failed to load title" data-id="1899967378" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10428" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10428/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10428">#10428</a></li>
<li>Improve codequality <a data-error-text="Failed to load title" data-id="1905038563" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10435" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10435/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10435">#10435</a></li>
<li>Update extractor and remove <code>DeobfuscateException</code> handling <a data-error-text="Failed to load title" data-id="1908467912" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10440" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10440/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10440">#10440</a></li>
<li>Add workflow "PR size labeler" to label PRs based on the number of changed lines <a data-error-text="Failed to load title" data-id="1761955759" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10170" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10170/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10170">#10170</a> <a data-error-text="Failed to load title" data-id="1910332881" data-permission-text="Title is private" data-url="https://github.com/TeamNewPipe/NewPipe/issues/10447" data-hovercard-type="pull_request" data-hovercard-url="/TeamNewPipe/NewPipe/pull/10447/hovercard" href="https://github.com/TeamNewPipe/NewPipe/pull/10447">#10447</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Believe Your Eyes – A WhatsApp Clickjacking Vulnerability (317 pts)]]></title>
            <link>https://00xbyte.github.io/posts/Don%27t-Believe-Your-Eyes-A-WhatsApp-Clickjacking-Vulnerability/</link>
            <guid>38732770</guid>
            <pubDate>Fri, 22 Dec 2023 10:12:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://00xbyte.github.io/posts/Don%27t-Believe-Your-Eyes-A-WhatsApp-Clickjacking-Vulnerability/">https://00xbyte.github.io/posts/Don%27t-Believe-Your-Eyes-A-WhatsApp-Clickjacking-Vulnerability/</a>, See on <a href="https://news.ycombinator.com/item?id=38732770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine you have received a WhatsApp message with a link to <code>ln.instagram.com</code>.<br> Where do you think the link leads? Instagram? Think again.</p><p>I have found a <a href="https://en.wikipedia.org/wiki/Clickjacking">clickjacking</a> vulnerability in WhatsApp that enables phishing attacks.<br> An attacker can send anyone a crafted message with a link that appears to lead to a legitimate website, but in fact leads to any website of the attacker’s choice.</p><h2 id="discovery-process"><span>Discovery Process</span><a href="#discovery-process"><i></i></a></h2><p>I started my research looking for a way to make a message recipient perform an HTTP request. My initial thought was to check WA’s link preview feature. I hoped the the link would be rendered twice, once by the sender and once by the receiver. In order to check my theory, I created a <a href="https://webhook.site/">webhook</a> and sent it to a friend. Sadly only one request was made, only by me.<br> <strong>That got me thinking. If the receiver does not render the link for themselves, that must mean I send both the link and the preview</strong>. If so, I wonder if I can send a link to one site with a preview of another?</p><h3 id="issue-1---link-preview-mismatch"><span>Issue #1 - Link Preview Mismatch</span><a href="#issue-1---link-preview-mismatch"><i></i></a></h3><p>I decided to take a look into what data is sent in a WA message that contains a link with a preview. My goal was to intercept the message, change the link and the preview to mismatch, and send it. <br> I decided to intercept a message via WA web, as hopefully that would be a faster setup than debugging an emulator. I then ran into a problem - WA uses and E2EE so I couldn’t simply modify the message with proxy like Burp Suite.</p><p><a href="https://00xbyte.github.io/assets/img/post/websocket.png"><img src="https://00xbyte.github.io/assets/img/post/websocket.png" data-src="/assets/img/post/websocket.png" alt="" width="540" height="400" data-proofer-ignore=""></a></p><p>Instead of understanding the encryption mechanism, I decided insert a breakpoint a moment before the message was encrypted and sent through the websocket. WA web’s javascript was uglified and minified, however after a while of searching I found the right place.</p><p><a href="https://00xbyte.github.io/assets/img/post/link%20object.png"><img src="https://00xbyte.github.io/assets/img/post/link%20object.png" data-src="/assets/img/post/link%20object.png" alt="" width="540" height="400" data-proofer-ignore=""></a></p><p>Exactly as I suspected, the link and the preview were sent separately!<br> I created a message object for<code>instagram.com</code> and changed the <code>text</code> property to <code>google.com</code>. Unfortunately, the message that was sent did not have a preview anymore. Only a link to Google.<br> Blackbox testing taught me that:</p><div><table><thead><tr><th>Property</th><th>Purpose</th></tr></thead><tbody><tr><td><code>text</code></td><td>The text of the message</td></tr><tr><td><code>canonicalURL</code></td><td>The domain that is shown at the bottom of the preview</td></tr><tr><td><code>matchedText</code></td><td>Seems to be compared against <code>canonicalURL</code>, also tested that its value apears in <code>text</code></td></tr></tbody></table></div><p>I discovered that if the <code>matchedText</code> was deleted from the object, I could create a mismatch!</p><p><a href="https://00xbyte.github.io/assets/img/post/preview%20mismatch.jpg"><img src="https://00xbyte.github.io/assets/img/post/preview%20mismatch.jpg" data-src="/assets/img/post/preview%20mismatch.jpg" alt="" width="540" height="400" data-proofer-ignore=""></a></p><p>Success! I have created a message with a preview to one site, and when clicked, leads to another. This was a great start, but I didn’t want the real link to be shown in the message. I was looking for ways to hide the message text.</p><h3 id="issue-2---disguising-links-2k2e"><span>Issue #2 - Disguising Links (2K2E)</span><a href="#issue-2---disguising-links-2k2e"><i></i></a></h3><p>I remembered that some unicode characters can change the representation of text, so I tried fuzzing characters to see their effect:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>function</span> <span>fuzz</span><span>(</span><span>start</span><span>,</span> <span>end</span><span>)</span> <span>{</span>
	<span>for </span><span>(</span><span>let</span> <span>i</span> <span>=</span> <span>start</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>end</span> <span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
	    <span>j</span> <span>=</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span>
	    <span>if </span><span>(</span><span>j</span><span>.</span><span>length</span> <span>&lt;</span> <span>4</span><span>)</span> <span>{</span> <span>j</span> <span>=</span> <span>"</span><span>0</span><span>"</span><span>.</span><span>repeat</span><span>(</span><span>4</span> <span>-</span><span>j</span><span>.</span><span>length</span><span>)</span> <span>+</span> <span>j</span><span>}</span>
 	    <span>msg</span> <span>+=</span> <span>eval</span><span>(</span><span>"</span><span>\"\\</span><span>u</span><span>"</span><span>+</span><span>j</span><span>+</span><span>"</span><span>\"</span><span>"</span><span>)</span>
			<span>+</span> <span>"</span><span>https://google.com/</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span>
			<span>+</span> <span>"</span><span>\n</span><span>"</span> 
	<span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></p></div><p>I observed the results and one result caught my eye. One of the lines (<code>202e</code>) was in reverse:</p><p><a href="https://00xbyte.github.io/assets/img/post/fuzzing.jpg"><img src="https://00xbyte.github.io/assets/img/post/fuzzing.jpg" data-src="/assets/img/post/fuzzing.jpg" alt="" width="540" height="400" data-proofer-ignore=""></a></p><p>Apparently, the unicode character <a href="https://unicode-explorer.com/c/202E"><code>U+202E</code></a> (Right-To-Left Override) alters the way that text is presented to the user by displaying it in reverse order.<br> That was a great start but this link looks horrible. Nobody would click it.</p><h4 id="crafting-a-mirror-url"><span>Crafting A Mirror URL</span><a href="#crafting-a-mirror-url"><i></i></a></h4><p>I wanted to create a URL that, when reversed, looked like <code>https://instagram.com</code>. This means that the link should be <code>moc.margatsni//:sttph</code> (<code>\u202e</code>+<code>moc.margatsni//:sttph</code> = <code>https://instagram.com</code> )</p><p>This fist problem is the TLD. I cannot register a <code>.margatsni</code> domain.<br> My solution was to find a TLD that could look like a subdomain. For example the TLD <code>.nl</code> (Netherlands) would result in <code>ln.instagram.com</code> (<code>ln</code> as in link)</p><p>Problem number two was that the URL needed to start with <code>https://</code> in order to look legitimate.<br> My solution to this was to append the string <code>//:sptth</code> (which is a valid path) to the URL, so that <code>https://moc.margatsni.nl//:sttph</code> would appear as <code>https://ln.instagram.com//:sptth</code></p><blockquote><p>With a mirror URL and the <code>U+202E</code> character, an attacker can make any URL look like any other!<br> I call this vulnerability <strong>2K2E</strong></p></blockquote><h3 id="final-result"><span>Final Result</span><a href="#final-result"><i></i></a></h3><p>Finally I have a legitimate looking URL that seems like it leads to Instagram, when in fact it leads to my blog <a href="https://00xbyte.github.io/">Security Is Broken</a>.</p><p><a href="https://00xbyte.github.io/assets/img/post/clickjacking.png"><img src="https://00xbyte.github.io/assets/img/post/clickjacking.png" data-src="/assets/img/post/clickjacking.png" alt="" width="540" height="400" data-proofer-ignore=""></a></p><h2 id="attack-scenario"><span>Attack Scenario</span><a href="#attack-scenario"><i></i></a></h2><p>Utilizing both these issues can allow attackers to perform phishing attacks where they construct legitimate looking links that lead to malicious websites.</p><p>The full attack flow:</p><ol><li>An attacker purchases the mirror domain of the site they would like to impersonate. For example <code>moc.margatsni.nl</code> to impersonate <code>ln.instagram.com</code></li><li>The attacker creates a message with a link to original domain in order to use its preview.<div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td><pre><span>{</span><span>
 </span><span>"text"</span><span>:</span><span> </span><span>"https://instagram.com/"</span><span>,</span><span>
 </span><span>"matchedText"</span><span>:</span><span> </span><span>"https://instagram.com/"</span><span>,</span><span>
 </span><span>"canonicalUrl"</span><span>:</span><span> </span><span>"https://instagram.com/"</span><span>,</span><span>
 </span><span>"description"</span><span>:</span><span> </span><span>"Create an account..."</span><span>,</span><span>
 </span><span>"title"</span><span>:</span><span> </span><span>"Instagram"</span><span>,</span><span>
 </span><span>"jpegThumbnail"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"previewType"</span><span>:</span><span> </span><span>0</span><span>,</span><span>
 </span><span>"mediaKey"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"mediaKeyTimestamp"</span><span>:</span><span> </span><span>1693302818542</span><span>,</span><span>
 </span><span>"thumbnailDirectPath"</span><span>:</span><span> </span><span>"/v/t62.36..."</span><span>,</span><span>
 </span><span>"thumbnailSha256"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"thumbnailEncSha256"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"thumbnailHeight"</span><span>:</span><span> </span><span>1024</span><span>,</span><span>
 </span><span>"thumbnailWidth"</span><span>:</span><span> </span><span>1024</span><span>,</span><span>
 </span><span>"inviteLinkGroupTypeV2"</span><span>:</span><span> </span><span>0</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></p></div></li><li>The attacker then removes the <code>matchedText</code> property and changes the <code>text</code> property to the following value: <code>U+202E</code> + “URL to the mirror domain” + <code>//:sptth</code><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td><pre><span>{</span><span>
 </span><span>"text"</span><span>:</span><span> </span><span>"</span><span>\u</span><span>202ehttps://moc.margatsni.nl//:sptth"</span><span>,</span><span>
 </span><span>"canonicalUrl"</span><span>:</span><span> </span><span>"https://instagram.com/"</span><span>,</span><span>
 </span><span>"description"</span><span>:</span><span> </span><span>"Create an account..."</span><span>,</span><span>
 </span><span>"title"</span><span>:</span><span> </span><span>"Instagram"</span><span>,</span><span>
 </span><span>"jpegThumbnail"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"previewType"</span><span>:</span><span> </span><span>0</span><span>,</span><span>
 </span><span>"mediaKey"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"mediaKeyTimestamp"</span><span>:</span><span> </span><span>1693302818542</span><span>,</span><span>
 </span><span>"thumbnailDirectPath"</span><span>:</span><span> </span><span>"/v/t62.36..."</span><span>,</span><span>
 </span><span>"thumbnailSha256"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"thumbnailEncSha256"</span><span>:</span><span> </span><span>{},</span><span>
 </span><span>"thumbnailHeight"</span><span>:</span><span> </span><span>1024</span><span>,</span><span>
 </span><span>"thumbnailWidth"</span><span>:</span><span> </span><span>1024</span><span>,</span><span>
 </span><span>"inviteLinkGroupTypeV2"</span><span>:</span><span> </span><span>0</span><span>
</span><span>}</span><span>
</span></pre></td></tr></tbody></table></code></p></div></li><li>Finally the attacker sends the crafted message to their victim</li></ol><blockquote><p>Because we support many different platforms and environments, there are a significant number of ways that some platform could choose to normalize a URL differently than our server-side logic does. To address that, we have systems in place which allow us to adjust our URL normalization logic dynamically in the event of real-world spam and abuse.</p></blockquote><p>Sadly, Meta has shown no intention to resolve this security issue and from their response it seems that they will try to stop these attacks only if their systems detect them as spam. This means that WhatsApp users can only cross their fingers that they won’t fall victims to 2K2E attacks.<br> <strong>Apposed to WhatsApp, other platforms such as X, TikTok, and Pinterest, all have sanitization of the <code>U+202E</code> character.</strong></p><h2 id="mitigation"><span>Mitigation</span><a href="#mitigation"><i></i></a></h2><p>Because Meta has no intention of fixing this issue, links on WhatsApp cannot be trusted. In order to not fall victim to a 2K2E phishing attack, before clicking on a link, copy it. The clipboard preview should show the link address while sanitizing the <code>U+202E</code> character.</p><h2 id="update"><span>Update</span><a href="#update"><i></i></a></h2><p>I have found other services that do not have proper sanitization and are vulnerable to 2K2E as well.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering (140 pts)]]></title>
            <link>https://jingyechen.github.io/textdiffuser2/</link>
            <guid>38732713</guid>
            <pubDate>Fri, 22 Dec 2023 10:01:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jingyechen.github.io/textdiffuser2/">https://jingyechen.github.io/textdiffuser2/</a>, See on <a href="https://news.ycombinator.com/item?id=38732713">Hacker News</a></p>
<div id="readability-page-1" class="page">



<div>
          
          

          <p><span><sup>1</sup>HKUST,</span>
			      <span><sup>2</sup>Sun Yat-sen University,</span>
            <span><sup>3</sup>Microsoft Research</span>
          </p>

          
        </div>


 









  




<div>
        <h2>Abstract</h2>
        <p>
            The diffusion model has been proven a powerful generative model in recent years, yet remains a challenge in generating visual text. Several methods alleviated this issue by incorporating explicit text position and content as guidance on where and what text to render. However, these methods still suffer from several drawbacks, such as limited flexibility and automation, constrained capability of layout prediction, and restricted style diversity. In this paper, we present TextDiffuser-2, aiming to unleash the power of language models for text rendering. Firstly, we fine-tune a large language model for layout planning. The large language model is capable of automatically generating keywords for text rendering and also supports layout modification through chatting. Secondly, we utilize the language model within the diffusion model to encode the position and texts at the line level. Unlike previous methods that employed tight character-level guidance, this approach generates more diverse text images. We conduct extensive experiments and incorporate user studies involving human participants as well as GPT-4V, validating TextDiffuser-2's capacity to achieve a more rational text layout and generation with enhanced diversity.
          </p>


    <div>
        <br>
        <h2>Motivation - Why TextDiffuser-2 is Needed? 🤷‍♂</h2>
        <div><p>
          Although showing impressive rendering accuracy, we have noticed several drawbacks in existing text rendering methods:
          </p><ul>
            <li>(1) <b>Limited flexibility and automation</b>: GlyphControl needs users to design glyph images to provide layout guidance, while GlyphDraw and TextDiffuser rely on the manual specification of keywords. These requirements hinder the direct conversion of natural user prompts into corresponding images, thereby narrowing the flexibility and automation capabilities.</li>
            <li>(2) <b>Constrained capability of layout prediction</b>: GlyphDraw can only render images with a single text line, constraining its applicability for scenarios involving multiple text lines. For TextDiffuser, the produced text layouts are not visually appealing, which is primarily attributed to the limited capability of the Layout Transformer.</li>
            <li>(3) <b>Restricted style diversity</b>: For TextDiffuser, the utilization of character-level segmentation masks as control signals implicitly imposes constraints on the position of each character, thereby restricting the diversity of text styles and posing challenges when rendering handwritten or artistic fonts.</li>
            <li>(4) <b>No open-source code</b>: Existing methods may not provide available code, API, or demo.</li>
          </ul>
        </div>
      </div>

    <!-- Pipeline. -->
    <div>
        <br>
        <h2>TextDiffuser-2 Pipeline</h2>
          <p><img src="https://jingyechen.github.io/textdiffuser2/static/images/architecture.jpg" alt="pipeline1"></p><p>
            The architecture of TextDiffuser-2. The language model M1 and the diffusion model are trained in two stages. The language model M1 can convert the user prompt into a language-format layout and also allows users to specify keywords optionally. Further, the prompt and language-format layout is encoded with the trainable language model M2 within the diffusion model for generating images. M1 is trained via the cross-entropy loss in the first stage, while M2 and U-Net are trained using the denoising L2 loss in the second stage.
          </p>
      </div>
<!-- 
    <script
    type="module"
    src="https://gradio.s3-us-west-2.amazonaws.com/4.8.0/gradio.js"
  ></script>
  

  <gradio-app src="https://jingyechen22-textdiffuser-2.hf.space" style="width: auto;"></gradio-app> -->
  

    <!-- Pipeline. -->
    <div>
        <br>
        <h2>Text-to-Image Visualizations</h2>
        <p><img src="https://jingyechen.github.io/textdiffuser2/static/images/t2i.jpg" alt="more_results_single"></p><p>
            Visualizations of text-to-image results compared with existing methods. TextDiffuser-2 can automatically extract keywords from
            prompts for accurate rendering. Additionally, the fonts generated by TextDiffuser-2 exhibit a wide range of diversity.
          </p>
      </div>


    <div>
        <br>
        <h2>Style Diversity</h2>
        <p><img src="https://jingyechen.github.io/textdiffuser2/static/images/diverse.jpg" alt="more_results_single"></p><p>
            Visualization of diversity in generating multiple images under the same prompt. TextDiffuser-2 is capable of generating more
artistic fonts, with increased diversity in the positioning of characters and the inclination angle of text lines.
          </p>
      </div>


    <div>
        <br>
        <h2>Inpainting Ability</h2>
        <p><img src="https://jingyechen.github.io/textdiffuser2/static/images/inpaint.jpg" alt="more_results_single"></p><p>
            Visualizations of the text inpainting task compared with TextDiffuser. TextDiffuser-2 can generate more coherent text.
          </p>
      </div>


    <div>
        <br>
        <h2>Quantitative Result</h2>
        <p><img src="https://jingyechen.github.io/textdiffuser2/static/images/quanti.jpg" alt="more_results_single"></p><p>
            Demonstration of the quantitative results and user studies. We also incorporate GPT-4V into the user studies. The best and
second-best results are indicated in bold and underlined formats. TextDiffuser-2 achieves the best results under the majority of metrics.
          </p>
      </div>


</div>



<div id="BibTeX">
    <h2>Contact</h2><p>
    For help or issues using TextDiffuser-2, please email Jingye Chen <a rel="license" href="mailto:qwerty.chen@connect.ust.hk">(qwerty.chen@connect.ust.hk)</a>
    , Yupan Huang <a rel="license" href="mailto:huangyp28@mail2.sysu.edu.cn">(huangyp28@mail2.sysu.edu.cn)</a> or submit a GitHub issue. For other communications related to TextDiffuser-2, please contact Lei Cui <a rel="license" href="mailto:lecu@microsoft.com">(lecu@microsoft.com)</a> or Furu Wei <a rel="license" href="mailto:fuwei@microsoft.com">(fuwei@microsoft.com)</a>.
  </p></div>

<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@article{chen2023textdiffuser,
      title={TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering},
      author={Chen, Jingye and Huang, Yupan and Lv, Tengchao and Cui, Lei and Chen, Qifeng and Wei, Furu},
      journal={arXiv preprint arXiv:2311.16465},
      year={2023}
    }
    
</code></pre>
  </div>








</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mindustry: Open-source automation tower defense game (486 pts)]]></title>
            <link>https://mindustrygame.github.io/</link>
            <guid>38732542</guid>
            <pubDate>Fri, 22 Dec 2023 09:32:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mindustrygame.github.io/">https://mindustrygame.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=38732542">Hacker News</a></p>
<div id="readability-page-1" class="page"><p> <h2> <b>Mindustry:</b> A sandbox tower-defense game. </h2> </p><div> <ul> <p> Defend your base from <span>waves of powerful enemies</span>. <br> <img alt="A high-level Mindustry base in combat with a wave of many low-level enemies." src="https://mindustrygame.github.io/1.d25af17a.webp" type="image/webp"> </p> <p> Build complex designs for <span>processing materials</span>. <br> <img alt="A peaceful Mindustry game with various end-game factories." src="https://mindustrygame.github.io/2.0d4f9a35.webp" type="image/webp"> </p> <p> Build and fight with other players on <span>multiplayer servers</span>. <br> <img alt="A peaceful Mindustry game with mid-tier factories while players wander and build." src="https://mindustrygame.github.io/3.88567664.webp" type="image/webp"> </p>   </ul> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Maze Generator (140 pts)]]></title>
            <link>https://mazegenerator.net/</link>
            <guid>38732401</guid>
            <pubDate>Fri, 22 Dec 2023 09:11:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mazegenerator.net/">https://mazegenerator.net/</a>, See on <a href="https://news.ycombinator.com/item?id=38732401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p><label for="ShapeDropDownList" id="ShapeLabel">Shape:</label>
                    
                </p>
                <table>
                    
                            <tbody><tr>
                                <td>
                                    <label for="S1TesselationDropDownList" id="S1StyleLabel">Style:</label>
                                </td>
                                <td>
                                    
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <label for="S1WidthTextBox" id="S1WidthLabel">Width:</label>
                                </td>
                                <td>
                                    
                                    (2 to 200 cells)
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <label for="S1HeightTextBox" id="S1HeightLabel">Height:</label>
                                </td>
                                <td>
                                    
                                    (2 to 200 cells)
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <label for="S1InnerWidthTextBox" id="S1InnerWidthLabel">Inner width:</label>
                                </td>
                                <td>
                                    
                                    (0 or 2 to width - 2 cells)
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <label for="S1InnerHeightTextBox" id="S1InnerHeightLabel">Inner height:</label>
                                </td>
                                <td>
                                    
                                    (0 or 2 to height - 2 cells)
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <label for="S1StartsAtDropDownList" id="S1StartsAtLabel">Starts at:</label>
                                </td>
                                <td>
                                    
                                </td>
                            </tr>
                        
                    <tr>
                        <td>
                            Advanced:
                        </td>
                        <td>
                            <label for="AlgorithmParameter1TextBox" id="AlgorithmParameter1Label">E:</label>
                            
                            (0 to 100), 
                            <label for="AlgorithmParameter2TextBox" id="AlgorithmParameter2Label">R:</label>
                            
                            (0 to 100)
                        </td>
                    </tr>
                </tbody></table>
                
                
                
                
            </div><div id="InfoPanel">
	
                <p>
                It saddens me to have to point this out: Contrary to what a number of less scrupulous "passive income" YouTubers lead you to believe, the mazes from this site are not free to use for commercial purposes. If you are planning to use them in something you will sell, you need to get a commercial license.  If you do not have such a license, you are committing a copyright infringement. For more information, see the link "Commercial use" above.
            
</p></div></div>]]></description>
        </item>
    </channel>
</rss>