(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 28 Apr 2025 05:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: I made a web-based, free alternative to Screen Studio (102 pts)]]></title>
            <link>https://www.screenrecorder.me</link>
            <guid>43816419</guid>
            <pubDate>Mon, 28 Apr 2025 00:38:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.screenrecorder.me">https://www.screenrecorder.me</a>, See on <a href="https://news.ycombinator.com/item?id=43816419">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[AI helps unravel a cause of Alzheimer’s and identify a therapeutic candidate (129 pts)]]></title>
            <link>https://today.ucsd.edu/story/ai-helps-unravel-a-cause-of-alzheimers-disease-and-identify-a-therapeutic-candidate</link>
            <guid>43815591</guid>
            <pubDate>Sun, 27 Apr 2025 22:19:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://today.ucsd.edu/story/ai-helps-unravel-a-cause-of-alzheimers-disease-and-identify-a-therapeutic-candidate">https://today.ucsd.edu/story/ai-helps-unravel-a-cause-of-alzheimers-disease-and-identify-a-therapeutic-candidate</a>, See on <a href="https://news.ycombinator.com/item?id=43815591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">



		
	
		


	<div id="feature-detail-hero">
					<figure data-slideshow-item="" data-slideshow-image-src="https://today.ucsd.edu/news_uploads/PHGDH-brain-20250424.jpg" data-slideshow-image-alt="illustration of a human brain with apparent damage" data-slideshow-image-caption="About one in nine people aged 65 and older has Alzheimer’s disease, which causes cognitive decline and increased anxiety in patients. Image credit: Jolygon/iStock
">
						<p><img data-src="https://today.ucsd.edu/news_uploads/_social/PHGDH-brain-20250424.jpg" alt="illustration of a human brain with apparent damage" width="1200" height="628" src="https://today.ucsd.edu/news_uploads/_social/PHGDH-brain-20250424.jpg">
						</p>
						
					   <figcaption>
					     About one in nine people aged 65 and older has Alzheimer’s disease, which causes cognitive decline and increased anxiety in patients. Image credit: Jolygon/iStock

					   </figcaption>
					   
					</figure>
				</div>
	
		<section id="wysiwyg">
    
  
  
    
	 <!-- START DATE STORIES IN NEW FORMAT -->
	 
	 <!-- START OF AUTHORS-BLOCK FOR MOBILE  -->
	 
	 <!-- END OF AUTHORS-BLOCK FOR MOBILE -->
	 
	 

		  <!-- START NEW CONTENT BLOCK -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
							
							
							
						   <p>A new study found that a gene recently recognized as a biomarker for Alzheimer’s disease is actually a cause of it, due to its previously unknown secondary function. Researchers at the University of California San Diego used artificial intelligence to help both unravel this mystery of Alzheimer’s disease and discover a potential treatment that obstructs the gene’s moonlighting role.</p>

<p>The research team published their results on April 23 in the journal <a href="https://doi.org/10.1016/j.cell.2025.03.045">Cell</a>.</p>

<p>About one in nine people aged 65 and older has Alzheimer’s disease, the most common cause of dementia. While some particular genes, when mutated, can lead to Alzheimer’s, that connection only accounts for a small percentage of all Alzheimer’s patients. The vast majority of patients do not have a mutation in a known disease-causing gene; instead, they have “spontaneous” Alzheimer’s, and the causes for that are unclear.</p>

<p>Discovering those causes could ultimately improve medical care.</p>

<p>“Unfortunately, treatment options for Alzheimer’s disease are very limited. And treatment responses are not outstanding at this moment,” said study senior author Sheng Zhong, a professor in the Shu Chien-Gene Lay Department of Bioengineering at the UC San Diego Jacobs School of Engineering.</p>

<p>So Zhong and his team took a closer look at phosphoglycerate dehydrogenase (PHGDH), which they had previously <a href="https://today.ucsd.edu/story/discovery-of-new-biomarker-in-blood-could-lead-to-early-test-for-alzheimers-disease">discovered as a potential blood biomarker</a> for early detection of Alzheimer’s disease. In a follow-up study, they later found that <a href="https://today.ucsd.edu/story/study-of-promising-alzheimers-marker-in-blood-prompts-warning-about-brain-boosting-supplements">expression levels of the PHGDH gene directly correlated</a> with changes in the brain in Alzheimer’s disease; in other words, the higher the levels of protein and RNA produced by the PHGDH gene, the more advanced the disease. That correlation has since been verified in multiple cohorts from different medical centers, according to Zhong.</p>

<p>Intrigued by this reproducible correlation, the research team decided to investigate in this latest study whether there was a causal effect. Using mice and human brain organoids, the researchers found that altering the amounts of PHGDH expression had consequential effects on Alzheimer’s disease: lower levels corresponded to less disease progression, whereas increasing the levels led to more disease advancement. Thus, the researchers established that PHGDH is indeed a causal gene to spontaneous Alzheimer’s disease.</p>

<p>In further support of that finding, the researchers determined—with the help of AI—that PHGDH plays a previously undiscovered role: it triggers a pathway that disrupts how cells in the brain turn genes on and off. And such a disturbance can cause issues, like the development of Alzheimer’s disease.</p>

<h3>Moonlighting role</h3>

<p>PHGDH creates an enzyme key for the production of serine, an essential amino acid and a neurotransmitter. Because PHGDH’s enzymatic activity was its only known role, the researchers hypothesized that its metabolic function must be connected to an Alzheimer’s outcome. However, all their experiments designed to prove so failed.</p>
								
		
			
		
	
	<!-- Begin Climate Change -->
	
	<!-- End Climate Change -->
	<!-- Begin Artificial Intelligence -->
	
		
			
		
	
	<!-- End Artificial Intelligence -->
	
		
			
		
	

<!-- Begin Giving Bug -->

						</div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
										<!-- 
  This figure is meant to be part of a Article/Feature Detail page. It provides 
  data attributes for the slideshow carousel script to target the image and
  caption for dynamically pulling into the slideshow modal
  - Supported variables
  -- image-src
  -- image-alt
  -- image-caption
  -- image-size
-->

	<figure data-slideshow-item="" data-slideshow-image-src="https://today.ucsd.edu/news_uploads/PHGDH-graphic-20250424.jpg" data-slideshow-image-alt="graphic showing how Alzheimer's severity increases with PHGDH expression" data-slideshow-image-caption="<p>{/exp:typographee}</p><div>Illustration depicts the relationship between PHGDH expression and Alzheimer’s disease severity. A small molecule inhibitor targeting PHGDH’s moonlighting role can reduce symptoms of Alzheimer’s disease. Image credit: Zhong lab</div>">
	  <img data-src="https://today.ucsd.edu/news_uploads/PHGDH-graphic-20250424.jpg" alt="graphic showing how Alzheimer's severity increases with PHGDH expression" width="705" height="470" src="https://today.ucsd.edu/news_uploads/PHGDH-graphic-20250424.jpg">
	  
	  <figcaption>
	    <p>Illustration depicts the relationship between PHGDH expression and Alzheimer’s disease severity. A small molecule inhibitor targeting PHGDH’s moonlighting role can reduce symptoms of Alzheimer’s disease. Image credit: Zhong lab</p>
	  </figcaption>
	  
	</figure>
	
										<p>“At that time, our study hit a wall, and we didn’t have a clue of what mechanism it is,” said Zhong.</p>

<p>But <a href="https://today.ucsd.edu/story/music-map-reveals-some-brain-cells-age-faster-and-are-more-prevalent-in-alzheimers">another Alzheimer’s project</a> in his lab, which did not focus on PHGDH, changed all this. A year ago, that project revealed a hallmark of Alzheimer’s disease: a widespread imbalance in the brain in the process where cells control which genes are turned on and off to carry out their specific roles.</p>

<p>The researchers were curious if PHGDH had an unknown regulatory role in that process, and they turned to modern AI for help.</p>

<p>With AI, they could visualize the three-dimensional structure of the PHGDH protein. Within that structure, they discovered that the protein has a substructure that is very similar to a known DNA-binding domain in a class of known transcription factors. The similarity is solely in the structure and not in the protein sequence.&gt;</p>

<p>Zhong said, “It really demanded modern AI to formulate the three-dimensional structure very precisely to make this discovery.”</p>

<p>After discovering the substructure, the team then demonstrated that with it, the protein can activate two critical target genes. That throws off the delicate balance, leading to several problems and eventually the early stages of Alzheimer’s disease. In other words, PHGDH has a previously unknown role, independent of its enzymatic function, that through a novel pathway leads to spontaneous Alzheimer’s disease.</p>

<p>That ties back to the team’s earlier studies: the PHGDH gene produced more proteins in the brains of Alzheimer’s patients compared to the control brains, and those increased amounts of the protein in the brain triggered the imbalance. While everyone has the PHGDH gene, the difference comes down to the expression level of the gene, or how many proteins are made by it.</p>

<h3>Treatment option</h3>

<p>Now that the researchers uncovered the mechanism, they wanted to figure out how to intervene and thus possibly identify a therapeutic candidate, which could help target the disease.</p>

<p>While many current treatments focus on treating the abnormal buildup of the sticky protein called beta-amyloid in the brain, some studies suggest that treating those plaques may be ineffective: essentially by that stage of accumulation, treatment is too late. But the critical pathway discovered in this study is upstream, so preventing this pathway can reduce amyloid plaque formation in the first place.</p>
											
		
			
		
	
	<!-- Begin Climate Change -->
	
	<!-- End Climate Change -->
	<!-- Begin Artificial Intelligence -->
	
		
			
		
	
	<!-- End Artificial Intelligence -->
	
		
			
		
	

<!-- Begin Giving Bug -->

								 	</div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		  
		    <!-- START IF COPY -->
		   
		      <div>
			        
		          
		          <!-- START If block also has image, video, quote, or related stories -->
						 
						 <!-- START OF OPTIONAL VIDEO -->
						 
						 <!-- END OF OPTIONAL VIDEO -->
						 
						 <!-- START OF OPTIONAL SLIDESHOW -->
						  
						  <!-- END OF OPTIONAL SLIDESHOW -->
						
						 <!-- START OF OPTIONAL QUOTE -->
						 
						 <!-- END OF OPTIONAL QUOTE -->
						
						 <!-- START OF OPTIONAL RELATED-STORIES -->
						 
						 <!-- END OF OPTIONAL REATED-STORIES -->
						
						 <!-- START OF OPTIONAL IMAGE -->
						 
							
								
							 		<div>
										<p>Given that PHGDH is such an important enzyme, there are past studies on its possible inhibitors. One small molecule, known as NCT-503, stood out to the researchers because it is not quite effective at impeding PHGDH’s enzymatic activity (the production of serine), which they did not want to change. NCT-503 is also able to penetrate the blood-brain-barrier, which is a desirable characteristic.</p>

<p><span><span>They turned to AI again for three-dimensional visualization and modeling. They found that NCT-503 can access that DNA-binding substructure of PHGDH, thanks to a binding pocket. With more testing, they saw that NCT-503 does indeed inhibit PHGDH’s regulatory role.</span></span><they access="" again="" ai="" and="" can="" dna-binding="" for="" found="" modeling.="" nct-503="" of="" phgdh="" substructure="" that="" they="" three-dimensional="" to="" turned="" visualization=""> </they></p>

<p>When the researchers tested NCT-503 in two mouse models of Alzheimer’s disease, they saw that it significantly alleviated Alzheimer’s progression. The treated mice demonstrated substantial improvement in their memory and anxiety tests. These tests were chosen because Alzheimer’s patients suffer from cognitive decline and increased anxiety.</p>

<p>The researchers do acknowledge limitations of their study. One being that there is no perfect animal model for spontaneous Alzheimer’s disease. They could test NCT-503 only in the mouse models that are available, which are those with mutations in those known disease-causing genes.</p>

<p>Still, the results are promising, according to Zhong.</p>

<p>“Now there is a therapeutic candidate with demonstrated efficacy that has the potential of being further developed into clinical tests,” said Zhong. “There may be entirely new classes of small molecules that can potentially be leveraged for development into future therapeutics.”</p>

<p>An advantage of small molecules is that they could even be administered orally, he added, unlike the current treatments that require infusions.</p>

<p>The next steps will be to optimize the compound and subject it to FDA IND-enabling studies.</p>

<p>Paper: “<a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00397-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867425003976%3Fshowall%3Dtrue">Transcriptional regulation by PHGDH drives amyloid pathology in Alzheimer’s disease</a>.” Co-authors include Junchen Chen*, Fatemeh Hadi*, Xingzhao Wen, Wenxin Zhao, Ming Xu, Shuanghong Xue, Pei Lin, Riccardo Calandrelli, John Lalith Charles Richard, Zhixuan Song, Jessica Li, Alborz Amani, Yang Liu and Xu Chen, all of UC San Diego.</p>

<p>*These authors contributed equally</p>

<p>This work is partially funded by the National Institutes of Health (grants R01GM138852, DP1DK126138, UH3CA256960, R01HD107206, R01AG074273 and R01AG078185).</p>

<p>Disclosure: Sheng Zhong is a founder and shareholder of Genemo, Inc. and Neurospan, LLC. The remaining authors declare no competing interests.</p>
											
		
			
				<p>Learn more about research and education at UC San Diego in:
			
		
	
	<!-- Begin Climate Change -->
	
	<!-- End Climate Change -->
	<!-- Begin Artificial Intelligence -->
	
		
			
				<a href="https://ucsd.edu/research-innovation/artificial-intelligence.html">Artificial Intelligence</a>
			
		
	
	<!-- End Artificial Intelligence -->
	
		
			</p>
			
		
	

<!-- Begin Giving Bug -->

									</div>
									
									<div>
										<!-- 
  This figure is meant to be part of a Article/Feature Detail page. It provides 
  data attributes for the slideshow carousel script to target the image and
  caption for dynamically pulling into the slideshow modal
  - Supported variables
  -- image-src
  -- image-alt
  -- image-caption
  -- image-size
-->

	<figure data-slideshow-item="" data-slideshow-image-src="https://today.ucsd.edu/news_uploads/PHGDH-lab-20250424.jpg" data-slideshow-image-alt="group photo of coauthors, all dressed in lab coats" data-slideshow-image-caption="<p>{/exp:typographee}</p><div><p>&nbsp;</p><p><span><span>The study co-authors (from left to right) Sheng Zhong, Junchen Chen, Wenxin Zhao, Ming Xu, Shuanghong Xue, Zhixuan Song and Fatemeh Hadi uncovered that the PHGDH gene can trigger a pathway that disrupts how cells in the brain turn genes on and off, which can cause diseases like Alzheimer’s to develop.&nbsp;</span></span><span><span>Photo credit: Zhong lab</span></span></p>
</div>">
	  <img data-src="https://today.ucsd.edu/news_uploads/PHGDH-lab-20250424.jpg" alt="group photo of coauthors, all dressed in lab coats" width="705" height="470" src="https://today.ucsd.edu/news_uploads/PHGDH-lab-20250424.jpg">
	  
	  <figcaption>
	    <p><span><span>The study co-authors (from left to right) Sheng Zhong, Junchen Chen, Wenxin Zhao, Ming Xu, Shuanghong Xue, Zhixuan Song and Fatemeh Hadi uncovered that the PHGDH gene can trigger a pathway that disrupts how cells in the brain turn genes on and off, which can cause diseases like Alzheimer’s to develop.&nbsp;</span></span><span><span>Photo credit: Zhong lab</span></span></p>
	  </figcaption>
	  
	</figure>
	
								 	</div>							 	
								
						 	
						 
						 <!-- END OF OPTIONAL IMAGE -->
						 
						 <!-- START OF OPTIONAL SOCIAL MEDIA EMBEDS -->
						 
						 <!-- END OF OPTIONAL VIDEO -->
						 				 
		          <!-- END If block also has image, video, quote, or related stories -->	
		        </div>
		      
		    <!-- END IF COPY -->
		    
		    <!-- START OPTIONAL STAND ALONE IMAGE -->
		    
		    <!-- END OPTIONAL STAND ALONE IMAGE -->
		    
		  <!-- END CONTENT BLOCK -->
		  
	
	  
      
  

  <!-- START TOPICS & SHARE MOBILE  -->
  
  <!-- END TOPICS & SHARE MOIBILE -->
</section>

	

	<div>
    <h2>
      You May Also Like
    </h2>
    
  </div>
	<div id="subscribe">
    <div>
        <h2>Stay in the Know</h2>
        <p>Keep up with all the latest from UC San Diego. Subscribe
          to the newsletter today.
        </p>
      </div>
    <div>
        <form novalidate="" data-subscribe-form="" action="subscribe.html" method="post" data-form_type="newsletter_signup">
          <div>
            <p><label for="subscriber-email">
              Email
            </label>
            </p><div data-validation-message="email">
              <p>Please provide a valid email address.</p></div>
          </div>
          
        </form>
      </div>
  </div>
<!-- START Subscribe Modal -->

<!-- STOP Subscribe Modal -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I just want to code (2023) (120 pts)]]></title>
            <link>https://www.zachbellay.com/daily/i-just-want-to-code/</link>
            <guid>43814708</guid>
            <pubDate>Sun, 27 Apr 2025 20:08:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zachbellay.com/daily/i-just-want-to-code/">https://www.zachbellay.com/daily/i-just-want-to-code/</a>, See on <a href="https://news.ycombinator.com/item?id=43814708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>I have an angel and a devil sitting atop each shoulder. The angel says, "Just code for fun! What you make can be just for your enjoyment and that's --" the devil interjects, "not enough to get ahead, loser. If you're not coding your next startup then how're you gunna get rich? Coding for fun? Pfft, sounds like the fast lane to being poor."</p>
<p>Since I was a kid I've always gravitated toward computers. First sucked in via computer games, then Lego NXT Robots, then turtles, then high school Java, and finally a college degree. It always starts off as some form of play, and before I know it I've learned something new. At 8 years old, I played Age of Empires III only to get suckered into learning how to fix the install on Windows. In 6th grade I built a Lego machine gun using the Lego NXT robotics and learned how to program using blocks. In 8th grade I used turtles to make cool designs. </p>
<p>But I also grew up consuming hustle porn. I loved reading Wired and Entreprenuer magazine and dreamed of being on the cover. For 2 years in highschool I so desperately wanted to attend Babson College to enroll in their entreprenuership program. I watched an Amazon Prime knockoff of Silicon Valley called <em>Betas</em> and unironically wanted to be like the "visionary" social media startup founder who was founding yet another doomed social media platform. Now I'm on Twitter/X &amp; Hacker News, which of course mainline these capitalist ideals straight to my brain.</p>
<p>So I've cultivated the angel, and the devil. The angel motivated by curiosity, a sincere desire to learn and improve, and most of all have fun. The devil motivated by power, money, status.</p>
<p>I constantly find the devil on my shoulder trying to convince me to start a new side hustle. Starting a new monetizable side project is like a latent addiction. Giving in feels like relapsing. The angel says don't worry about some side hustle, just do well in your day job and code for fun as a hobby. But the devil keeps telling me that you can "be your own boss" and "earn what you're worth". </p>
<p>In a perfect world, I could listen to the angel and solely get by having fun and working on things I enjoy. But if I didn't listen to the devil from time to time, I wouldn't stay up to date with the latest technologies, and as a result I wouldn't be able to pay my bills.</p>
<p>Typically, the devil is associated with worldly material things, whereas angels are associated with high ideals, such as curiosity, enlightenment, and purity. Unfortunately, we don't live in a perfect world, so the devil on my shoulder will never be vanquished. Which means that instead, this will always be a story of managing the devil, and learning when and when not to listen to him. </p>
<p>I've learned now, that I can no longer force myself to work on things that I don't like forever, since I will burn out. As I mature, I am better honing perception for when and when not to give in to the devil's call to build something for profit. </p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Business co-founders in tech startups are less valuable than they think (205 pts)]]></title>
            <link>https://verdikapuku.com/posts/business-founders-are-less-valuable-than-they-think/</link>
            <guid>43814497</guid>
            <pubDate>Sun, 27 Apr 2025 19:35:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://verdikapuku.com/posts/business-founders-are-less-valuable-than-they-think/">https://verdikapuku.com/posts/business-founders-are-less-valuable-than-they-think/</a>, See on <a href="https://news.ycombinator.com/item?id=43814497">Hacker News</a></p>
Couldn't get https://verdikapuku.com/posts/business-founders-are-less-valuable-than-they-think/: Error: getaddrinfo ENOTFOUND verdikapuku.com]]></description>
        </item>
        <item>
            <title><![CDATA[Internet in a Box (361 pts)]]></title>
            <link>https://internet-in-a-box.org/</link>
            <guid>43814433</guid>
            <pubDate>Sun, 27 Apr 2025 19:26:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://internet-in-a-box.org/">https://internet-in-a-box.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43814433">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <h2>Quality Content</h2>
              <p>
                Internet-in-a-Box shows you the latest Content Packs
                installable in the languages your community needs (from online
                libraries like
                <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kiwix#Available_content">Kiwix</a>,
                <a target="_blank" rel="noopener" href="https://rachel.worldpossible.org/content">OER2Go</a>,
                <a target="_blank" rel="noopener" href="https://archive.org/">Archive.org</a>)
                then takes care of all the downloading details for you!
              </p>

              <p>
                Which eye-opening
                <a href="https://limnology.co/" rel="noopener" target="_blank">                
                  YouTube and Vimeo learning videos</a>
                do your kids truly need?  You choose!
                <a href="https://github.com/iiab/calibre-web/wiki#calibre-web" rel="noopener" target="_blank">
                  Pick channels</a>
                with mind-altering
                <a href="https://www.favoree.io/search?category=all_Documentary%20and%20Essay" rel="noopener" target="_blank">                
                  documentaries</a>
                and unforgettable radio episodes, created by <i>the</i> very
                best teachers worldwide.
              </p>

              <p>
                Schools can also choose among
                <a target="_blank" rel="noopener" href="https://wiki.iiab.io/go/FAQ#What_services_%28IIAB_apps%29_are_suggested_during_installation%3F">
                  almost 40 powerful apps</a>
                for teachers and students — optionally with a complete LMS
                (learning management system) like Kolibri, Moodle, Nextcloud,
                Sugarizer or WordPress.
              </p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a single line of code could brick your iPhone (231 pts)]]></title>
            <link>https://rambo.codes/posts/2025-04-24-how-a-single-line-of-code-could-brick-your-iphone</link>
            <guid>43814360</guid>
            <pubDate>Sun, 27 Apr 2025 19:12:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rambo.codes/posts/2025-04-24-how-a-single-line-of-code-could-brick-your-iphone">https://rambo.codes/posts/2025-04-24-how-a-single-line-of-code-could-brick-your-iphone</a>, See on <a href="https://news.ycombinator.com/item?id=43814360">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>This is the story of how I found one of my favorite iOS vulnerabilities so far. It’s one of my favorites because of how simple it was to implement an exploit for it. There’s also the fact that it uses a legacy public API that’s still relied upon by many components of Apple’s operating systems, and that many developers have never heard of.</p><h2>Darwin Notifications</h2><p>Most iOS developers are likely used to <a href="https://developer.apple.com/documentation/foundation/notificationcenter?language=objc">NSNotificationCenter</a>, and most Mac developers are also likely used to <a href="https://developer.apple.com/documentation/foundation/distributednotificationcenter?language=objc">NSDistributedNotificationCenter</a>. The former only works within a single process, the latter allows simple notifications to be exchanged between processes, with the option to include a string with additional data to be transmitted alongside the notification.</p><p><a href="https://developer.apple.com/documentation/darwinnotify/darwin-notification-api">Darwin notifications</a> are even simpler, as they’re a part of the CoreOS layer. They provide a low-level mechanism for simple message exchange between processes on Apple’s operating systems. Instead of objects or strings, each notification may have a <code>state</code> associated with it, which is a <code>UInt64</code>, and typically is only used to indicate a boolean <code>true</code> or <code>false</code> by specifying <code>0</code> or <code>1</code>.</p><p>A simple use case for the API would be for a process that just wants to notify other processes about a given event, in which case it can call the <code>notify_post</code> function, which takes a string that’s usually a reverse DNS value like <code>com.apple.springboard.toggleLockScreen</code>.</p><p>Processes interested in receiving such a notification can register by using the <code>notify_register_dispatch</code> function, which will invoke a block on a given queue any time another process posts the notification with the specified name.</p><p>A process that’s interested in posting a Darwin notification with a state has to first register a handle for it, which can be done by calling the <code>notify_register_check</code> function, which takes the name of the notification and the pointer to an <code>Int32</code>, which is where the function returns a token that can be used to call <code>notify_set_state</code>, which also takes a <code>UInt64</code> value for the state.</p><p>Via the same <code>notify_register_check</code> mechanism, a process that wants to get the state of a notification can call <code>notify_get_state</code> to get its current state. This allows Darwin notifications to be used for certain types of events, but also hold some state that any process on the system can query at any given time.</p><h2>The Vulnerability</h2><p>Any process on Apple’s operating systems — including iOS — can register to be notified about any Darwin notification, from within its sandbox, without the need for special entitlements. This makes sense given that some system frameworks used by third-party apps rely on Darwin notifications for important functionality.</p><p>Given that the amount of data transferred through them is very limited, Darwin notifications are not a significant risk for sensitive data leaks, even though the API is public, and sandboxed apps can register for notifications.</p><p>However, just as any process on the system can register to <strong>receive</strong> Darwin notifications, the same is true for <strong>sending</strong> them.</p><p>To summarize, Darwin notifications:</p><ul><li>Require no special privileges for receiving</li><li>Require no special privileges for <strong>sending</strong></li><li>Are available as public API</li><li>Have no mechanism for <strong>verifying the sender</strong></li></ul><p>Considering these properties, I began to wonder if there were places on iOS using Darwin notifications for powerful operations that could potentially be exploited as a denial-of-service attack from within a sandboxed app.</p><p>You’re reading this blog post, so I’ve already spoiled it: the answer was “yes”.</p><h2>Proof of Concept: EvilNotify</h2><p>With that question in mind, I grabbed a fresh copy of the iOS root filesystem — one of the early iOS 18 betas at the time, I think — and began looking for processes that used <code>notify_register_dispatch</code> and <code>notify_check</code>.</p><p>I quickly found a bunch of them, and made a test app called “EvilNotify” that I could use for testing.</p><p>Unfortunately, I no longer have a vulnerable device I could use to record a proper on-device video, but the iOS Simulator demo above shows most of what the proof of concept was able to do. Some of them don’t work in the Simulator, so I couldn’t demo them in the video.</p><p>You can see a hint at the end of the video of what the ultimate denial of service was, but let me mention all the other things it was capable of doing. Keep in mind, all of them would affect the entire system, even if the user force-quit the app.</p><ul><li>Cause the “liquid detection” icon to show up in the status bar</li><li>Trigger the Display Port connection status to show up in the Dynamic Island</li><li>Block system-wide gestures for pulling down Control Center, Notification Center, and Lock Screen</li><li>Force the system to disregard Wi-Fi and use the cellular connection instead</li><li>Lock the screen</li><li>Trigger a “data transfer in progress” UI that prevented the device from being used until the user cancelled it</li><li>Simulate the device entering and leaving Find My’s “Lost Mode”, triggering an Apple ID password dialog prompt to re-enable Apple Pay</li><li>Trigger device entering a “restore in progress” mode</li></ul><h2>“Restore in Progress”</h2><p>Since I was looking for a denial-of-service attack, this last one seemed to be the most promising, as there was no way out of it other than by tapping the “Restart” button, which would always cause the device to reboot.</p><p>It was also quite neat, since it consisted of a single line of code:</p><pre><code><span>notify_post</span>(<span>"com.apple.MobileSync.BackupAgent.RestoreStarted"</span>)
</code></pre><p>That’s it! That single line of code was enough to make the device enter “Restore in Progress”. The operation would inevitably fail after a timeout since the device was not actually being restored, for which the only remedy was tapping the “Restart” button, which would then reboot the device.</p><p>Looking into the binaries, SpringBoard was observing that notification to trigger the UI. The notification is triggered when the device is being restored from a local backup via a connected computer, but as established before, any process could send the notification and trick the system into entering that mode.</p><h2>Denial of Service: VeryEvilNotify</h2><p>Now that I had a Darwin notification with the potential of becoming a denial of service, I just had to figure out a way to trigger it repeatedly across device reboots.</p><p>At first, this sounded quite tricky, since apps on iOS have very limited opportunities for background processing, and quite a few APIs with side effects are prevented from working when an app is not in the foreground. The latter I found out would not be a problem, as I could verify that <code>notify_post</code> worked even when the app was not in the foreground.</p><p>As for being able to post the notification again and again as the device rebooted multiple times, I wasn’t so sure, but I had a hunch that an app extension would be the most likely to succeed.</p><p>Some types of third-party app extensions may run before first unlock on iOS devices, so I decided to try a type of app extension I’m quite familiar with, and created a widget extension, in a new app that I called “VeryEvilNotify”.</p><p>Widget extensions are periodically woken up in the background by iOS. They have a limited amount of time for generating snapshots and timelines, which the system then displays in various places, including the Lock Screen, Home Screen, Notification Center, and Control Center.</p><p>Because of how widespread the use of widgets is on the system, when a new app that includes a widget extension is installed and launched, the system is very eager to execute its widget extension. That gets an app’s widgets ready for the user to pick and add to the various supported placements.</p><p>A widget extension is ultimately just a process that can run code, so I added the aforementioned line of code to my widget extension. I had configured the extension to include every possible type of widget, just to make it as likely as possible that iOS would execute it as quickly as possible.</p><p>There’s a problem though: widget extensions produce placeholders, snapshots, and timelines, which are then cached by the system in order to preserve resources. These extensions are not running in the background all the time, and even if the extension requests very frequent updates, the system will enforce a time budget and delay updates if the extension attempts to request them too frequently.</p><p>To circumvent that, I decided to try making my widget extension always crash shortly after running the <code>notify_post</code> function, which I did by calling Swift’s <code>fatalError()</code> function in every extension point method of its <code>TimelineProvider</code>.</p><p>The call to <code>notify_post</code> was made as part of the entry point of the extension, before handing off execution to the extension runtime:</p><pre><code><span>import</span> WidgetKit
<span>import</span> SwiftUI
<span>import</span> notify

<span>struct</span> VeryEvilWidgetBundle: <span>WidgetBundle</span> {
    <span>var</span> body: <span>some</span> <span>Widget</span> {
        <span>VeryEvilWidget</span>()
        <span>if #available</span>(iOS <span>18</span>, *) {
            <span>VeryEvilWidgetControl</span>()
        }
    }
}

<span>/// Override extension entry point to ensure the exploit code is always run whenever
/// our extension gets woken up by the system.</span>
<span>@main
struct</span> VeryEvilWidgetEntryPoint {
    <span>static func</span> main() {
        <span>notify_post</span>(<span>"com.apple.MobileSync.BackupAgent.RestoreStarted"</span>)

        <span>VeryEvilWidgetBundle</span>.<span>main</span>()
    }
}
</code></pre><p>With that widget extension in place, as soon as I installed the VeryEvilNotify app on my security research device, the “Restore in Progress” UI was shown, then failed with a prompt to restart the system.</p><p>After restarting, as soon as SpringBoard was initialized, the extension would be woken up by the system, since it had failed to produce any widget entries before, which would then start the process all over again.</p><p>The result is a device that’s soft-bricked, requiring a device erase and restore from backup. I suspect that if the app ended up in the backup and the device was restored from it, the bug would eventually be triggered again, making it even more effective as a denial of service.</p><p>My theory was that iOS would have some sort of retry mechanism when a widget extension crashes, which would obviously have some sort of throttling mechanism. I still think that’s true, but something about the timing of the extension crashing and the restore starting then failing probably prevented such a mechanism from working.</p><p>Satisfied with my proof of concept, I reported the issue to Apple.</p><h2>Timeline</h2><p>Below is a summarized timeline of events for this vulnerability report. There were additional status updates via automated messages from Apple’s security reports system that I have not included for brevity.</p><ul><li>June 26, 2024: initial report sent to Apple</li><li>September 27, 2024: got a message from Apple informing me that mitigation was in progress</li><li>January 28, 2025: issue flagged as resolved and bounty eligibility confirmed</li><li>March 11, 2025: bug assigned CVE-2025-24091, <a href="https://support.apple.com/122066">addressed in iOS/iPadOS 18.3</a></li><li>Bug bounty amount: US$17,500</li></ul><p>Even though the CVE has already been assigned and Apple has provided a link where the advisory and credit are supposed to be published, that hasn’t happened yet. I’ve been informed that it will be published soon, but you can read the advisory below in case it hasn’t been published yet by the time this post goes out.</p><figure>
    <picture>
        <source srcset="https://rambo.codes/assets/img/CVE-2025-24091/CVE-2025-24091-box-dark.png" media="(prefers-color-scheme: dark)">
        <img src="https://rambo.codes/assets/img/CVE-2025-24091/CVE-2025-24091-box.png" alt="Apple has assigned CVE-2025-24091 to this issue. CVEs are unique IDs used to uniquely identify vulnerabilites. The following describes the impact and description of this issue. Impact - An app may be able to cause a denial-of-service. Description - An app could impersonate system notifications. Sensitive notifications now require restricted entitlements.">
    </picture>
</figure><p>Notice how the advisory mentions that “sensitive notifications now require restricted entitlements”, hinting at what the mitigation was. You can read more about that in the following section.</p><h2>Mitigation</h2><p>As mentioned by Apple in the advisory, sending sensitive Darwin notifications now requires the sending process to possess restricted entitlements. It’s not a single entitlement that just allows posting any sensitive notification, but a prefix entitlement in the form of <code>com.apple.private.darwin-notification.restrict-post.&lt;notification&gt;</code>.</p><p>From what I could gather from a brief look into the disassembly, what causes a notification to be “restricted” is the prefix <code>com.apple.private.restrict-post.</code> in the name of the notification.</p><p>For example, the <code>com.apple.MobileBackup.BackupAgent.RestoreStarted</code> notification is now posted as <code>com.apple.private.restrict-post.MobileBackup.BackupAgent.RestoreStarted</code>, which causes <code>notifyd</code> to verify that the posting process has the <code>com.apple.private.darwin-notification.restrict-post.MobileBackup.BackupAgent.RestoreStarted</code> entitlement before it allows the notification to be posted.</p><p>Processes observing the notification will also be using its new name with the <code>com.apple.private.restrict-post</code> prefix, thus preventing any random unentitled app or process from posting a notification that can have serious side effects on the system.</p><p>I didn’t have the opportunity to bisect numerous older iOS releases to find the exact version where this mechanism was introduced, but thanks to <a href="https://github.com/blacktop/ipsw-diffs">ipsw-diffs</a>, it appears that the entitlement first showed up in <a href="https://github.com/blacktop/ipsw-diffs/blob/fee5b3c8c18e4639e74677dd3cc1fa80203e64f6/18_2_22C5109p__vs_18_2_22C5125e/Entitlements.md?plain=1#L2336">iOS 18.2 build 22C5125e</a>, AKA iOS 18.2 beta 2.</p><p>The first adopters were <code>backupd</code>, <code>BackupAgent2</code>, and <code>UserEventAgent</code>, all gaining entitlements related to notifying the system about device restores, mitigating the most egregious exploit presented in my proof of concept.</p><p>Throughout the various iOS 18 betas and releases, more and more processes began adopting the new entitlement for restricted notifications, and with the release of iOS 18.3, all issues demonstrated in my PoC were addressed.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD 7.7 Released (124 pts)]]></title>
            <link>https://www.openbsd.org/77.html</link>
            <guid>43814058</guid>
            <pubDate>Sun, 27 Apr 2025 18:29:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openbsd.org/77.html">https://www.openbsd.org/77.html</a>, See on <a href="https://news.ycombinator.com/item?id=43814058">Hacker News</a></p>
<div id="readability-page-1" class="page">


<table>
<tbody><tr>
<td>
<a href="https://www.openbsd.org/images/LifeOfAFish.png">
<img width="200" height="300" src="https://www.openbsd.org/images/LifeOfAFish-s.gif" alt="Life Of A Fish"></a>
</td><td>
Released Apr 28, 2025. (58th OpenBSD release)<br>
Copyright 1997-2025, Theo de Raadt.<p>

Artwork by <a href="https://analognowhere.com/wiki/">Tomáš Rodr</a>.
</p><ul>
<li>See the information on <a href="https://www.openbsd.org/ftp.html">the FTP page</a> for
    a list of mirror machines.
</li><li>Go to the <code>pub/OpenBSD/7.7/</code> directory on
    one of the mirror sites.
</li><li>Have a look at <a href="https://www.openbsd.org/errata77.html">the 7.7 errata page</a> for a list
    of bugs and workarounds.
</li><li>See a <a href="https://www.openbsd.org/plus77.html">detailed log of changes</a> between the
    7.6 and 7.7 releases.
</li><li><a href="https://man.openbsd.org/signify.1">signify(1)</a>
    pubkeys for this release:<table>
<tbody><tr><td>
openbsd-77-base.pub:
</td><td>
<a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/openbsd-77-base.pub">
RWSbCCUoGpcxVRmNb/XFYBbthxWMK7G6fNbJhb993Ohuh29WFaT9vhe2
</a></td></tr><tr><td>
openbsd-77-fw.pub:
</td><td>
RWSJsKh8CzZG93aXHWDPCNM04iMwt7wRzfWzs1nL/2K6OsUvmAEfQavY
</td></tr><tr><td>
openbsd-77-pkg.pub:
</td><td>
RWQ0omJ8AdcUd41n7fqEccjc/VyLhJLKVJo7oFUg7epg6lUHRtgMgT52
</td></tr><tr><td>
openbsd-77-syspatch.pub:
</td><td>
RWRtcHFMyeKCcG4TkoK/TbEvDd1vch0tq8VgRR5UBpvAQkUcgja3jtV9
</td></tr></tbody></table>
</li></ul>
<p>
All applicable copyrights and credits are in the src.tar.gz,
sys.tar.gz, xenocara.tar.gz, ports.tar.gz files, or in the
files fetched via <code>ports.tar.gz</code>.
</p></td></tr></tbody></table>

<hr>

<section id="new">
<h3>What's New</h3>
<p>
This is a partial list of new features and systems included in OpenBSD 7.7.
For a comprehensive list, see the <a href="https://www.openbsd.org/plus77.html">changelog</a> leading to 7.7.
</p><ul>

<li>Platforms specific improvements:
  <ul>
  <li><a href="https://www.openbsd.org/arm64.html">arm64</a>:
    <ul>
    <li>Set AP power state, fixing the SMC initialization on the M1 MacBook with the latest system firmware.
    </li><li>Implemented a new pmap_populate() interface on arm64 and riscv64
	to help <a href="https://man.openbsd.org/pmap_enter.9">pmap_enter(9)</a> succeed
	when there's enough free physical memory but we can't allocate KVA to
	map that memory.
    </li><li>Optimized pmap teardown by skipping TLB flushes, giving ~5%
	performance boost for kernel build.
    </li><li>Enabled PAC on hardware that uses the new QARMA3 cipher.
    </li><li>Implemented support for SVE (Scalable Vector Extension).

    </li></ul>
  </li><li><a href="https://www.openbsd.org/amd64.html">amd64</a>:
    <ul>
    <li>Added the ability for <a href="https://man.openbsd.org/bus_dmamem_alloc.9">bus_dmamem_alloc(9)</a>
	to recognize the BUS_DMA_64BIT flag and allocate memory for DMA
	without any 4GB restrictions on amd64.
    </li><li>Allowed boot loader to run as AMD SEV guest on QEMU with EFI.
    </li><li>Allowed kernel boot on QEMU with AMD SEV.
    </li><li>Allowed use of MSI with the QEMU default pc-i440fx machine.
    </li><li>Stopped amd64 leak of kernel stack guard pages.
    </li><li>Implemented the AMD SEV <a href="https://man.openbsd.org/psp.4">psp(4)</a> download firmware
	command to load new firmware onto the chip and made the AMD SEV
	automatically load psp(4) firmware during <a href="https://man.openbsd.org/vmd.8">vmd(8)</a> startup.
    </li></ul>
  </li><li>Other <a href="https://www.openbsd.org/plat.html">architectures</a>:
    <ul>
    <li>Fixed <a href="https://www.openbsd.org/riscv64.html">riscv64</a> sigcode copying and put riscv64 sigcode in the .rodata memory section.
    </li><li>Implemented an interrupt depth counter on <a href="https://www.openbsd.org/sparc64.html">sparc64</a>.
    </li><li>Moved the <a href="https://www.openbsd.org/hppa.html">hppa</a> stack 1GB higher.
    </li><li>On <a href="https://www.openbsd.org/i386.html">i386</a>, improved the stability in low-memory situations, especially for MP.
    </li><li>Fixed a <a href="https://www.openbsd.org/powerpc64.html">powerpc64</a> bug where a pte could be put into an incorrect pteg, leading to a crash.
    </li><li>Changed <a href="https://www.openbsd.org/luna88k.html">luna88k</a> disklabel labeloffset to 0.
    </li></ul>

  </li><li>More platform specific changes can be found in the <a href="#hardware_support">hardware support</a> section below.
  </li></ul>

</li><li>Various kernel improvements:
  <ul>
  <li>Improved responsiveness in OOM situations and made free target checks coherent.

  </li><li>Removed the ability to specify a root, dump or swap device on <a href="https://man.openbsd.org/st.4">st(4)</a>.

  </li><li>In uvm, prevent a race where a mapped object is being truncated
	while we are spinning to unwire it.
  </li><li>Optimized page daemon active and inactive list traversals when
	looking only for low pages.
  </li><li>Added a helper to check if memory has been freed for a given
	request to improve speed of the page daemon loop.
  </li><li>Started accounting for in-flight pages being written to disk when
	the page daemon is computing page shortage.

  </li><li>Adjusted the ptrace interface to properly support
	single-threaded continue and make it possible to use breakpoints in
	multi-threaded processes in gdb.
  </li><li>Add <a href="https://man.openbsd.org/ptrace.2">ptrace(2)</a>
	commands used to read/write the XSAVE area of a traced process.
  </li><li>Correctly honored the count optional argument of the <a href="https://man.openbsd.org/ddb.4">ddb(4)</a> break command,
	ensuring execution does not stop until the breakpoint is hit at least
	that many times.
  </li><li>Taught <a href="https://man.openbsd.org/ddb.4">ddb(4)</a> how to
	disassemble endbr64.
  </li><li>Moved <a href="https://man.openbsd.org/dt.4">dt(4)</a> to using
	a ringbuffer per CPU.
  </li><li>Added 'socket' refcnt type to <a href="https://man.openbsd.org/dt.4">dt(4)</a>.
  </li><li>Made <a href="https://man.openbsd.org/btrace.8">btrace(8)</a>
	support additional interval/profile units (hz, us, ms, s).
  </li><li>Added multi-line strings support to the <a href="https://man.openbsd.org/bt.5">bt(5)</a> script parser.

  </li><li>Added kern.audio.kbdcontrol <a href="https://man.openbsd.org/sysctl.2">sysctl(2)</a> variable,
	allowing the volume keys on multimedia keyboards to be handled as
	regular keys if set to 0.
  </li><li>Implement <a href="https://man.openbsd.org/bus_dma.9">bus_dma(9)</a> bounce buffering
	for raw memory.
  </li><li>Started ignoring sub-nodes of non-functional nodes in the ACPI
	tree walk to fix double and triple attachments of the same PCIe root
	bridges.

  </li><li>Suspend/Hibernate Support
  <ul>
  <li>Ensured all
    <a href="https://man.openbsd.org/apm.8">hibernate</a>
    data is written inside the allocated chunk of swap.
  </li><li>Removed unneeded zeroing of free pages during
    <a href="https://man.openbsd.org/apm.8">hibernate</a>.
  </li><li>Corrected
    <a href="https://man.openbsd.org/apm.8">hibernate</a>
    error detection during RLE writes.
  </li><li>Ensured
    <a href="https://man.openbsd.org/apm.8">hibernate</a>
    fails when I/O or memory allocation errors occur.
  </li></ul>

  </li><li>Bugfixes
  <ul>
  <li>Fixed a (mostly) hypothetical race in <a href="https://man.openbsd.org/pinsyscalls.2">pinsyscalls(2)</a> by
	making it return an error if called in a multi-threaded process.
  </li><li>Fixed CPU idle percentage in <a href="https://man.openbsd.org/top.1">top(1)</a> on <a href="https://www.openbsd.org/macppc.html">macppc</a>.
  </li><li>Reworked how processes are stopped because of a signal. Now
	multithreaded processes can be reliably stopped and continued. This
	should fix problems seen in golang, mpv and in our regress tests.
  </li><li>Fix possible races of changes to the per-process unveil
	data structures by either pledge() [removing all path promises] or
	unveil() [adding new paths], against namei() inspecting in other
	thread system calls.
  </li></ul>
  </li></ul>

</li><li id="SMP_Improvements">SMP Improvements
  <ul>
  <li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">kern.timeout_stats</a>.
  </li><li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">kern.allowkmem</a>.
  </li><li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">kern.video.record</a>.
  </li><li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">net.inet.gre.allow</a> and
	net.inet.gre.wccp.
  </li><li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">kern.global_ptrace</a>.
  </li><li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">kern.wxabort</a>.
  </li><li>Unlocked sysctl <a href="https://man.openbsd.org/sysctl.2">kern.malloc.kmemstat</a>.
  </li><li>Reduced kernel lock contention when tearing down file-backed regions.
  </li><li>Unlocked ptsignal, psignal and prsignal by using the ps_mtx <a href="https://man.openbsd.org/mutex.9">mutex(9)</a>.
  </li><li>Used a mutex to make <a href="https://man.openbsd.org/psp.4">psp(4)</a> MP safe.
  </li><li>Locked send socket buffer for <a href="https://man.openbsd.org/fstat.2">fstat(2)</a> syscall.
  </li><li>Made lock changes to reduce lock contention in __thrsleep and
	__thrwakeup syscalls. go performance particularly benefits from this.
  </li><li>Unlocked <a href="https://man.openbsd.org/virtio.4">virtio(4)</a>.
  </li><li>Made `video_filtops' MP-safe.
  </li><li>Run TCP output and TCP timers in parallel.
    <ul>
    <li>TCP <a href="https://man.openbsd.org/send.2">send(2)</a>
	and <a href="https://man.openbsd.org/recv.2">recv(2)</a>
	system calls use shared netlock.
	Multiple userland threads can work on different sockets in
	parallel.
    </li><li>TCP output no longer blocks IP processing.
    </li><li>TCP timer also use locks that are specific to the socket they
	are working on, other network traffic can be processed by
	different CPUs.
    </li><li>Socket splicing is MP-safe for TCP.
    </li><li>Some of the sysctl syscalls affecting TCP no longer block
	network operations on other CPUs.
    </li><li>Only TCP input still uses exclusive netlock and prevents
	other parts of the network stack from running in parallel.
    </li></ul>
  </li><li>Unlocked <a href="https://man.openbsd.org/accept.2">accept(2)</a> for TCP sockets.
  </li><li>Started using shared net lock when calling <a href="https://man.openbsd.org/shutdown.2">shutdown(2)</a> on internet
	socket.
  </li><li>Reworked rwlocks to reduce pressure on the scheduler and SCHED_LOCK.
  </li><li>Pushed the KERNEL_LOCK() down to <a href="https://man.openbsd.org/namei.9">namei(9)</a> in <a href="https://man.openbsd.org/stat.2">stat(2)</a>, lstat(2) &amp;
	fstatat(2) and Unlocked <a href="https://man.openbsd.org/fstat.2">fstat(2)</a>.
  </li><li>Unlocked <a href="https://man.openbsd.org/wskbd.4">wskbd(4)</a>
	kqueue filterops.
  </li><li>Used `ws_mtx' <a href="https://man.openbsd.org/mutex.9">mutex(9)</a> to make <a href="https://man.openbsd.org/wsmux.4">wsmux(4)</a> filterops MP-safe.
  </li><li>Unlocked <a href="https://man.openbsd.org/open.2">open(2)</a>
	and <a href="https://man.openbsd.org/openat.2">openat(2)</a>.
  </li><li>Made <a href="https://man.openbsd.org/wsmouse.4">wsmouse(4)</a>
	and wstpad filterops MP-safe.
  </li><li>Pushed KERNEL_LOCK() inside __realpath(2).
  </li><li>Made wakeup of parent process in dowait6 reliable even without kernel lock.
  </li><li>Used ps_mtx <a href="https://man.openbsd.org/mutex.9">mutex(9)</a> to lock the child
	process that is being checked by dowait6.
  </li></ul>

</li><li>Direct Rendering Manager and graphics drivers
  <ul>
  <li>Updated <a href="https://man.openbsd.org/drm.4">drm(4)</a>
      to Linux 6.12.21.
  </li><li><a href="https://man.openbsd.org/drm.4">amdgpu(4)</a>: Added kernel
      support for Ryzen AI 300 (Strix Point, Strix Halo, Krackan Point),
      Radeon RX 9070 (Navi 48).
  </li><li><a href="https://man.openbsd.org/inteldrm.4">inteldrm(4)</a>: Added
      support for Arrow Lake.
  </li></ul>

</li><li>VMM/VMD improvements
  <ul>
  <li>Added an IPI for executing INVEPT to flush EPT on remote CPUs, a
	first step toward allowing guest memory not to be wired by UVM.
  </li><li>Implemented <a href="https://man.openbsd.org/psp.4">psp(4)</a>
	shutdown command and <a href="https://man.openbsd.org/ioctl.2">ioctl(2)</a> PSP_IOC_SHUTDOWN,
	which will be used by <a href="https://man.openbsd.org/vmd.8">vmd(8)</a> to reset <a href="https://man.openbsd.org/psp.4">psp(4)</a> on startup.
  </li><li>Started using <a href="https://man.openbsd.org/acpipci.4">acpipci(4)</a> on
	hypervisors. If the hypervisor cpuid bit is set, use acpipci to attach
	PCI busses. As virtualization is not that old, we can assume that in
	VMs we don't need the quirk for old, broken ACPI.  This solves
	problems with PCI BAR access and recent SeaBIOS versions on QEMU.
  </li></ul>

</li><li>Various new userland features:
  <ul>
  <li>Numerous changes to make the
	<a href="https://man.openbsd.org/imsg_init.3">imsg</a> API
	stricter and better, which were followed
	by adapting all applications across the tree.
  </li><li>Allow the user to provide an alternative perfpolicy when on
	battery, extending the semantics of hw.perfpolicy to provide two
	buttons to specify desired behavior. This gives users more flexibility
	in setting the performance when AC-powered vs. battery powered.
  </li><li>Made <a href="https://man.openbsd.org/calendar.1">calendar(1)</a> use the
	environment variable RECIPIENT_EMAIL for sending mails to.
  </li><li>Made <a href="https://man.openbsd.org/security.8">security(8)</a>
	use GMT rather than the local timezone when checking for changes in
	device nodes and setuid files. Avoids false positives when changing
	timezones.
  </li><li>Added a new variable PASSWDSKIP that can be set in
	/etc/daily.local to prevent <a href="https://man.openbsd.org/security.8">security(8)</a> from
	complaining about specific accounts that have no password. This is
	typically used for services like anoncvs and gotd.
  </li><li>Added [-f file] to <a href="https://man.openbsd.org/sysctl.8">sysctl(8)</a> to apply
	<a href="https://man.openbsd.org/sysctl.conf.5">sysctl.conf(5)</a>
	in one go, and started using it in <a href="https://man.openbsd.org/rc.8">rc(8)</a> instead of a parser implemented in ksh.
  </li><li>Added support for read/write of xmm/ymm registers to
        <a href="https://man.openbsd.org/lldb.1">lldb(1)</a>.
  </li></ul>

</li><li>Various bugfixes and tweaks in userland:
  <ul>
  <li>Added <a href="https://man.openbsd.org/wsconscfg.8">wsconscfg(8)</a> -g option
	to get the index of the current virtual terminal.
  </li><li>Made <a href="https://man.openbsd.org/getgrouplist.3">getgrouplist(3)</a>
	always return the total number of groups found.
  </li><li>Ignore extra groups that don't fit in the buffer passed to <a href="https://man.openbsd.org/getgrouplist.3">getgrouplist(3)</a>,
	providing only the kernel maximum of sixteen groups.
  </li><li>Prevent <a href="https://man.openbsd.org/newsyslog.8">newsyslog(8)</a> from running
	through time checks when an entry needs to be rotated based on size.
  </li><li>Changed <a href="https://man.openbsd.org/ps.1">ps(1)</a> to print
	the session id (PID of the session leader) instead of a pointer with
	display argument 'sess'.
  </li><li>In <a href="https://man.openbsd.org/cu.1">cu(1)</a>, map ucom
	unit number to cuaU number using the same scheme MAKEDEV uses, fixing
	problems with ucom units &gt; 10.
  </li><li>Made CPU frequencies human-readable with <a href="https://man.openbsd.org/systat.1">systat(1)</a> sensors -h.
  </li><li>Fixed a bug where <a href="https://man.openbsd.org/getty.8">getty(8)</a> dx flag was
	supposed to set decctlq, but was setting ixany instead.
  </li><li>Made <a href="https://man.openbsd.org/pkg_add.1">pkg_add(1)</a> run <a href="https://man.openbsd.org/ldconfig.8">ldconfig(8)</a> after each
	updateset if the list of shared libraries was changed.
  </li><li>Corrected behavior of <a href="https://man.openbsd.org/sed.1">sed(1)</a> c command to match
	POSIX.
  </li><li>Make <a href="https://man.openbsd.org/clang.1">clang(1)</a>
	-fzero-call-used-regs aware of the register used by
	retguard. QEMU is using -fzero-call-used-regs, causing a crash.
  </li><li>Disk partition information is now saved by
	  <a href="https://man.openbsd.org/security.8">security(8).</a>
  </li><li>Made <a href="https://man.openbsd.org/security.8">security(8)</a>
	ignore <a href="https://man.openbsd.org/quota.1">quota(1)</a> files
	and all subdirectories of /var/mail when checking the ownership and
	mode of mailboxes.
  </li><li>Added <a href="https://man.openbsd.org/pkg-config.1">pkg-config(1)</a> support
	for relocatable .pc files.
  </li><li>Made <a href="https://man.openbsd.org/mandoc.1">mandoc(1)</a> "-T html"
	and "-T markdown" output translate ".%R RFC &lt;number&gt;" to a
	hyperlink to rfc-editor.org.
  </li><li>Support decimal fractions like "0.25i" in
	<a href="https://man.openbsd.org/roff.7">roff(7)</a> scaled widths
	and arithmetic operations in
	<a href="https://man.openbsd.org/tbl.7">tbl(7)</a> column widths,
	as needed for some manual pages written with DocBook.
  </li><li>When <a href="https://man.openbsd.org/syslogd.8">syslogd(8)</a>
	acting as logserver with TLS (-S) and
	client-certificates are used for authentication (-K), use the CN from
	the client's certificate as hostname.
  </li><li>Adjusted the alignment when
	<a href="https://man.openbsd.org/df.1">df(1)</a> prints inode columns.
	This makes
	'df -hi' on systems with large partitions easier on the eyes.
  </li><li>Made <a href="https://man.openbsd.org/test.1">test(1)</a> use
	timespeccmp() and st_mtim instead of comparing st_mtime to fix
	comparison of files with modification times that differ by less than a
	second.
  </li><li>Made <a href="https://man.openbsd.org/ksh.1">ksh(1)</a> use
	timespeccmp() and st_mtim instead of comparing st_mtime to fix
	comparison of files with modification times that differ by less than a
	second.
  </li><li>In <a href="https://man.openbsd.org/ps.1">ps(1)</a> added a
	digit to vsz and rss to accommodate processes using more memory.
  </li><li>Updated <a href="https://man.openbsd.org/tzfile.5">tzfile(5)</a>
	to 2025bgtz from https://github.com/JodaOrg/global-tz.
  </li><li>Updated libc/locale support including
	e.g. <a href="https://man.openbsd.org/wcwidth.3">wcwidth(3)</a>
	and the <a href="https://man.openbsd.org/iswalnum.3">iswalnum(3)</a>
        family of functions to Unicode Version 15.0.0.
  </li></ul>

</li><li id="hardware_support">Improved hardware support and driver bugfixes, including:
  <ul>
  <li>Increased <a href="https://man.openbsd.org/psp.4">psp(4)</a> timeouts, allowing the EPYC 9124 time to attach.
  </li><li>Added PercentLoad sensor to <a href="https://man.openbsd.org/upd.4">upd(4)</a>, reporting the % of the available UPS power drawn by output outlets.
  </li><li>Fixed RunTimeToEmpty on some EATON models in <a href="https://man.openbsd.org/upd.4">upd(4)</a>.
  </li><li>Improved the heuristic for detecting I2C devices (making type-A ports on the Vivobook work in ACPI mode).
  </li><li>Added support for CSI b control sequence (repeat last printed character) to the <a href="https://man.openbsd.org/wscons.4">wscons(4)</a> vt100 emulation.
  </li><li>Fixed <a href="https://man.openbsd.org/simplefb.4">simplefb(4)</a> colours for BPP16 and BPP24.
  </li><li>Added support for BPP16 16-bit color EFI framebuffer format as offered by U-Boot.
  </li><li>Implemented CSI s and CSI u to save and restore cursor position in <a href="https://man.openbsd.org/wscons.4">wscons(4)</a>.
  </li><li>Made scaling available for normal <a href="https://man.openbsd.org/wsmouse.4">wsmouse.4</a> mice, not just touchpads.
  </li><li>Added <a href="https://man.openbsd.org/scmi.4">scmi(4)</a> mailbox transport and perf protocol for CPU frequency management on Snapdragon X Elite.
  </li><li>Moved to send only a single reset during attach for <a href="https://man.openbsd.org/ihidev.4">ihidev(4)</a> devices, preventing issues with some devices like the built-in keyboard on the ThinkPad T14s Gen 6.
  </li><li>Changed the <a href="https://man.openbsd.org/sdhc.4">sdhc(4)</a> bus power behavior to no longer perform a power-off voltage switch request when the card is already operating at the requested voltage.
  </li><li>Implemented <a href="https://man.openbsd.org/aplsmc.4">aplsmc(4)</a> support for the new CHLS key used to control the battery charge level in newer SMC firmware.
  </li><li>Added <a href="https://man.openbsd.org/pinctrl.4">pinctrl(4)</a> support to the <a href="https://man.openbsd.org/qciic.4">qciic(4)</a> driver for Qualcomm Snapdragon SoCs.
  </li><li>Made <a href="https://man.openbsd.org/qcpas.4">qcpas(4)</a> send APM_POWER_CHANGE events on AC/battery life changes, allowing upowerd to react.
  </li><li>Added <a href="https://man.openbsd.org/qccpucp.4">qccpucp(4)</a>, a driver for the Qualcomm CPUSS Control Processor (CPUCP) mailbox controller.
  </li><li>Made <a href="https://man.openbsd.org/qcpon.4">qcpon(4)</a> query hardware for the button state to detect release even if the press event is missed, and to signal wakeup when the button is pressed.
  </li><li>Made qcscm(4) attach at acpi(4). This lets Qualcomm machines which use qcscm(4) access EFI variables in ACPI mode. Some arm64 machines, like the Samsung Galaxy Book4 Edge can be successfully installed with this change.
  </li><li>Fixed support for AMD 600 series <a href="https://man.openbsd.org/ahci.4">ahci(4)</a> controller.
  </li><li>Introduce a pckbc@acpi driver attachment that is use instead of pckbc@isa when an interrupt configuration is incompatible with legacy ISA. This unbreaks, among other things, the keyboards in various Chromebooks.
  </li><li>Implemented <a href="https://man.openbsd.org/rkpmic.4">rkpmic(4)</a> power down if the PMIC is marked as the system power controller in the device tree.
  </li><li>Added RK3399 support to <a href="https://man.openbsd.org/rkusbphy.4">rkusbphy(4)</a>.
  </li><li>Added <a href="https://man.openbsd.org/dwmmc.4">dwmmc(4)</a> support for the "post-power-on-delay-ms" in the MMC power sequencing.
  </li><li>Implemented regulator-based signal voltage switch support in <a href="https://man.openbsd.org/dwmmc.4">dwmmc(4)</a>, fixing bootup on the MNT Reform2 with the RK3588 module.
  </li><li>Added <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> support for Jabra PanaCast 20.
  </li><li>Ensure <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> fills v4l2_capability correctly (allowing some V4L consumers to use bus_info to identify the desired webcam when attempting to switch devices).
  </li><li>Added <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> support for devices which report bulk and isochronous endpoints.
  </li><li>Made <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> bypass unknown pixelformat to consumer rather than rejecting unknown driver formats.
  </li><li>Support colorformat from <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> device.
  </li><li>Fixed a <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> crash on close of isochronous endpoint's webcam.
  </li><li>Ensure <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a> forwards frames with error bit to V4L consumers, which adds support of the integrated camera on ThinkPad T14 Gen 5, ThinkPad X1 Nano Gen 2, ThinkPad X13 and many other devices.
  </li><li>Forced 32-bit accesses when reading 8-bit or 16-bit registers, allowing use of <a href="https://man.openbsd.org/xhci.4">xhci(4)</a> on a Cadence xHCI controller as seen on the Radxa Orion O6.
  </li><li>Added USB 3.0 speed support to <a href="https://man.openbsd.org/xhci.4">xhci(4)</a> and <a href="https://man.openbsd.org/uvideo.4">uvideo(4)</a>.
  </li><li>Fixed <a href="https://man.openbsd.org/uaudio.4">uaudio(4)</a> devices that don't support sample rate changes.
  </li><li>Added LED support for <a href="https://man.openbsd.org/ikbd.4">ikbd(4)</a> keyboards.
  </li><li>Added <a href="https://man.openbsd.org/mtintc.4">mtintc(4)</a> a driver supporting interrupt controllers found on MediaTek SoCs.
  </li><li>Added <a href="https://man.openbsd.org/mtrng.4">mtrng(4)</a>, a driver supporting the 32-bit random number generator on MediaTek SoCs.
  </li><li>Added <a href="https://man.openbsd.org/mtxhci.4">mtxhci(4)</a>, a driver for the xHCI USB controller found on MediaTek SoCs, and enable it on armv7 and arm64.
  </li></ul>

</li><li>New or improved network hardware support:
  <ul>
  <li>Added <a href="https://man.openbsd.org/ice.4">ice(4)</a>, a driver for Intel E810 Ethernet (1Gb/10Gb/25Gb/50Gb/100Gb) devices.
  </li><li>Increased receive mbuf size with LRO in <a href="https://man.openbsd.org/vio.4">vio(4)</a>, helping TCP splice performance.
  </li><li>Fixed <a href="https://man.openbsd.org/xbf.4">xbf(4)</a> and <a href="https://man.openbsd.org/xnf.4">xnf(4)</a> not attaching on XCP-ng 8.3/Xen 4.17.
  </li><li>Added printing of number of queues and interrupt and Ethernet address details to <a href="https://man.openbsd.org/mcx.4">mcx(4)</a>.
  </li><li>Fixed the <a href="https://man.openbsd.org/bnxt.4">bnxt(4)</a> receive refill timeout to only refill rings that are currently empty, preventing possible corruption and crashes.
  </li><li>Added support for AX88772D to <a href="https://man.openbsd.org/axen.4">axen(4)</a>.
  </li><li>Added <a href="https://man.openbsd.org/ixv.4">ixv(4)</a>, a driver for virtual functions of Intel 82598EB, 82559 and X540.
  </li><li>Enabled rx/tx checksum offloading on <a href="https://man.openbsd.org/iavf.4">iavf(4)</a>.
  </li><li>Added RSS/multiqueue support for AQC11x models ("aq2") in <a href="https://man.openbsd.org/aq.4">aq(4)</a>.
  </li><li>Added support for reading EEPROM pages for <a href="https://man.openbsd.org/aq.4">aq(4)</a> cards with SFP slots.
  </li><li>Started clearing the OACTIVE flag on transmit queues when <a href="https://man.openbsd.org/ixl.4">ixl(4)</a> is reset.
  </li></ul>

</li><li>Added or improved wireless network drivers:
  <ul>
  <li>Added support for MA devices to <a href="https://man.openbsd.org/iwx.4">iwx(4)</a>.
  </li><li>Restricted scanned channels appropriately when <a href="https://man.openbsd.org/qwx.4">qwx(4)</a> runs in a fixed PHY mode.
  </li><li>Add support for QCA2066 to <a href="https://man.openbsd.org/qwx.4">qwx(4)</a>.
  </li><li>Changed <a href="https://man.openbsd.org/mtw.4">mtw(4)</a> to only open bulk <a href="https://man.openbsd.org/usb.4">usb(4)</a> pipes once for the lifetime of the device.
  </li></ul>

</li><li>Installer, upgrade and bootloader improvements:
  <ul>
  <li>On the <a href="https://www.openbsd.org/macppc.html">macppc</a>
	architecture, make ofwboot sync instruction cache before entering
	kernel, preventing a potential boot failure.
<!-- installboot -->
  </li><li>Made <a href="https://man.openbsd.org/installboot.8">installboot(8)</a>
	install a copy of the UEFI bootloader in /efi/openbsd on the EFI
	system partition, allowing creation of boot options for the firmware
	boot manager other OSes will leave alone.
  </li><li>Only install a second copy of the bootloader if the EFI
	System Partition is at least 1MB to avoid filling up the tiny ESPs we
	used to create a few releases ago.
  </li><li>Made <a href="https://man.openbsd.org/installboot.8">installboot(8)</a> only
	set BootOrder if our boot option isn't already part of it. This means
	sysupgrade (or reinstalls) will no longer set OpenBSD as the default
	OS if users change the boot order by some other means.  Fresh installs
	will still make OpenBSD the default OS.
  </li><li>Added a -c option <a href="https://man.openbsd.org/installboot.8">installboot(8)</a> that
	sets up the machine to boot from the specified disk, used on arm64 and
	amd64 with UEFI and GPT.
<!-- sysupgrade -->
  </li><li>Added <a href="https://man.openbsd.org/sysupgrade.8">sysupgrade(8)</a> -R #.#
	to try to use a specific release version rather than the immediate
	+0.1.
  </li><li>Provided a mechanism for getting required keys to <a href="https://man.openbsd.org/sysupgrade.8">sysupgrade(8)</a> older
	machines, providing a new set of keybundles signed by older keys to
	allow sysupgrade to securely and automatically download the required
	key.
  </li><li>Added firmware keys to the signify key bundles. <a href="https://man.openbsd.org/sysupgrade.8">sysupgrade(8)</a> will now
	extract the firmware key also, allowing fw_update fetch the most
	up-to-date firmware before upgrading.
  </li><li>Added support to <a href="https://man.openbsd.org/sysupgrade.8">sysupgrade(8)</a> to
	perform a sysupgrade from a fileset stored on a filesystem. This is
	convenient for offline machines.
<!-- fw_update -->
  </li><li>Made <a href="https://man.openbsd.org/fw_update.8">fw_update(8)</a> -a mean
	all when downloading or installing, not just deleting.
  </li><li>Allowed <a href="https://man.openbsd.org/fw_update.8">fw_update(8)</a> to
	download firmware without root.
  </li><li>Added <a href="https://man.openbsd.org/fw_update.8">fw_update(8)</a> -l flag to
	list drivers or files.
  </li><li>Added -D option to <a href="https://man.openbsd.org/fw_update.8">fw_update(8)</a> for using
	a different dmesg for driver detection.
<!-- installer proper -->
  </li><li>Reworked the "Default IPv6 router?" question in the installer to
	behave like the other questions.
  </li><li>On amd64 with ACPI &gt;= 5, assume that the installer booted in
	UEFI mode and default to using a GUID Partition Table (GPT).
  </li><li>Make IPv6 link-local scope identifiers in "HTTP Server?" answers work in the installer.
<!-- updates/sysmerge -->
  </li><li>On updates using <a href="https://man.openbsd.org/sysmerge.8">sysmerge(8)</a>, added
	options to interactive <a href="https://man.openbsd.org/sdiff.1">sdiff(1)</a> merge for choosing
	both sides of a diff.
  </li></ul>

</li><li>Security improvements:
  <ul>
  <li>Added sshd-auth to the binaries that relink at boot.
  </li><li>Split the user authentication code from the sshd-session binary
	into a separate sshd-auth binary. This will be executed by
	sshd-session to complete the user authentication phase of the protocol
	only.  Splitting this code into a separate binary ensures that the
	crucial pre-authentication attack surface has an entirely disjoint
	address space from the code used for the rest of the connection.
  </li><li>Unveiled <a href="https://man.openbsd.org/mountd.8">mountd(8)</a>
	privileged child's write to/create of
	mountdtab file, and drop exec permission.
  </li></ul>

</li><li>New features in the network stack:
  <ul>
  <li>Added an AF_FRAME socket domain and an IFT_ETHER protocol family
	under it, allowing userland to use sockets to send and receive
	Ethernet frames.
  </li><li>Added tunneldf support to <a href="https://man.openbsd.org/sec.4">sec(4)</a>.
  </li><li>Added use of Toeplitz hash for UDP and IPv6 TCP output, giving an
	improvement in traffic distribution over the queues and 20%
	performance increase with UDP send on v4/v6 and TCP send on v6 without
	pf.
  </li><li>Implemented <a href="https://man.openbsd.org/tun.4">tun(4)</a>
	network offloads between the kernel and userland and introduced a new
	TUNSCAP ioctl .
  </li><li>Implement a per-thread route cache by implementing a thread
	local memory (struct netstack) that gets passed down the network
	stack. For consecutive packets it can reuse the route to the same
	destination.
  </li></ul>

  </li><li>Further changes and bugfixes in the network stack:
  <ul>
  <li>Replaced rwlock with iterator in UDP input multicast loop, preventing a potential kernel crash.
  </li><li>Ensure that the correct address family is used in ip_deliver()
	for enqueuing a packet, fixing a problem with tunneling of different
	address families.
  </li><li>Let LLDP packets fall through to being handled on the port
	interfaces for <a href="https://man.openbsd.org/aggr.4">aggr(4)</a> as mandated by the standard.
  </li><li>Enabled multiqueue for <a href="https://man.openbsd.org/vio.4">vio(4)</a>.
  </li><li>Let <a href="https://man.openbsd.org/pppoe.4">pppoe(4)</a> data
	packets go through if_vinput instead of the pppoeinq, improving
	throughput and possibly reducing packet loss.
  </li><li>Fixed out-of-band data in <a href="https://man.openbsd.org/somove.9">somove(9)</a> socket splicing.
  </li><li>Added <a href="https://man.openbsd.org/wg.4">wg(4)</a> logging of IP addresses of remote endpoints.
  </li><li>Limited receive queue of loopback interfaces with 8192 packets,
	preventing unlimited queues from reaching mbuf limits and making
	network unusable on some architectures.
  </li><li>Fixed TCP checksum for IPv6 packets with extension headers.
  </li><li>Fixed incorrect ICMP error translation in af-to NAT, making
	traceroute6 behind af-to to provide meaningful information.
  </li><li>Fixed a 24-year old bug where various checks for broadcast
	packets were mistakenly skipped, allowing one to send broadcast
	packets without the SO_BROADCAST option.
  </li><li>Prevented installation of path MTU routes for IPsec transport mode SAs.
  </li></ul>

</li><li>The following changes were made to the <a href="https://man.openbsd.org/pf.4">pf(4)</a> firewall:
  <ul>
  <li>Allowed <a href="https://man.openbsd.org/pfctl.8">pfctl(8)</a>
	specification of interface and queue bandwidths greater than ~4Gbit.
  </li><li>Fixed inpcb leak in <a href="https://man.openbsd.org/divert.4">divert(4)</a> attach.
  </li></ul>

</li><li>Routing daemons and other userland network programs saw the following improvements:
<ul>
  <li>Added <a href="https://man.openbsd.org/iked.8">iked(8)</a>
	"natt" option that forces negotiation of nat-t (and udpencap).
  </li><li>Made <a href="https://man.openbsd.org/radiusd.8">radiusd(8)</a> log the username when rejecting by ipcp.
  </li><li>Added <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a> vxlan
	"[-]endpoint" command, to remove a tunnel endpoint of a MAC address.
  </li><li>Made <a href="https://man.openbsd.org/ifconfig.8">ifconfig(8)</a> scan display
	wpa3.
  </li><li>Made <a href="https://man.openbsd.org/tcpdump.8">tcpdump(8)</a> print PPPoE tags as hex dumps.
  </li><li>Improved lldp output of <a href="https://man.openbsd.org/tcpdump.8">tcpdump(8)</a>.
  </li><li>Added support for client certificates to <a href="https://man.openbsd.org/relayd.8">relayd(8)</a>.
  </li><li>Made <a href="https://man.openbsd.org/acme-client.1">acme-client(1)</a> -v show the account URI from the Location header sent by the server in response to the newAccount API call.
  </li><li>Made <a href="https://man.openbsd.org/acme-client.1">acme-client(1)</a> always print account URI on first creation of an account key.
  </li><li>Added TLS support to <a href="https://man.openbsd.org/tcpbench.1">tcpbench(1)</a>.
  </li><li>Started taking into account how long the <a href="https://man.openbsd.org/ntpd.8">ntpd(8)</a> DNS probe takes
	before deciding to punt.
  </li><li>Added <a href="https://man.openbsd.org/unwind.8">unwind(8)</a>
	block list wildcard support using block list entries starting with '.'.
  </li><li>Implemented zoneversion EDNS option (RFC 9660) in <a href="https://man.openbsd.org/dig.1">dig(1)</a>.
  </li><li>Adjusted rDNS lifetime to RFC 8106 default (minimum) value in <a href="https://man.openbsd.org/rad.8">rad(8)</a>.
  </li><li>Made <a href="https://man.openbsd.org/nfsd.8">nfsd(8)</a> default to UDP when using only -n.
  </li><li>Implemented <a href="https://man.openbsd.org/iscsid.8">iscsid(8)</a> handling of
	HeaderDigest and DataDigest params.
  </li><li>Made iscsid send out all the values for session and connection
	params for each login stage, keeping control of what is selected,
	making it possible to connect to a lio target.
  </li><li>Respect checksum offloading in <a href="https://man.openbsd.org/dhcrelay.8">dhcrelay(8)</a> and <a href="https://man.openbsd.org/dhcrelay6.8">dhcrelay6(8)</a>.
  </li><li>Respect checksum offloading for incoming UDP in <a href="https://man.openbsd.org/dhcpd.8">dhcpd(8)</a>.

  </li><li>In <a href="https://man.openbsd.org/smtpd.8">smtpd(8)</a>,
  <ul>
	<li>Fixed few imprecisions in
	    <a href="https://man.openbsd.org/forward.5">forward(5)</a>
	    with regard to where and when <code>|</code> and
	    <code>:include:</code> are disallowed.
	</li><li>Fixed the connect filter request documentation in
	    <a href="https://man.openbsd.org/smtpd-filters.7">smtpd-filters(7)</a>.
	</li><li>Proper handling of permanent failures in
	    <a href="https://man.openbsd.org/mail.lmtp.8">mail.lmtp(8)</a>,
	    previously all failures were considered temporary and so delivery
	    was attempted again.
  </li></ul>
  </li><li>In <a href="https://man.openbsd.org/bgpd.8">bgpd(8)</a>,
  <ul>
  <li>Cache the Adj-RIB-Out for sessions that have not been down for
      more than 1h. This significantly improves synchronisation time
      of peers that flap.
  </li><li>Implement RFC 8538: Notification Message Support for
      BGP Graceful Restart.
  </li><li>Add support for RFC 8654, extended messages.
  </li><li>In bgplgd add additional endpoints to query the Adj-RIB-In and
      Adj-RIB-Out.
  </li><li>Bump internal message size limit to 128k and handle up to 10 000
      ASPA SPAS entries as suggested in draft-ietf-sidrops-aspa-profile.
  </li><li>Various improvements to the ibuf API including a new reader API
      which is used to make all message parsing in bgpd memory safe.
  </li><li>Added support for IPsec and TCP MD5 to RTR sessions.
  </li><li>Improve default multiproto capability announcement selection.
      The default MP capability is only set if no other capability is
      configured on the neighbor.
  </li><li>The `reject as-set` configuration option now defaults to yes.
      Route announcements with AS_SET segments in the AS_PATH Attribute
      will be rejected. See draft-ietf-idr-deprecate-as-set-confed-set
      for more information.
  </li><li>The RFC 8654 Extended Message configuration changed from
      "announce extended (yes|no|enforce)" to
      "announce extended message (yes|no|enforce)"
  </li><li>RFC 8950 - Extended nexthop encoding support in the RIB.
  </li><li>Preliminary support for EVPN in the RIB.
  </li><li>When "transparent-as yes" is set, well-known BGP communities are
      passed on according to RFC 7947. This means that IX Route Servers
      transparently pass through NO_EXPORT, NO_ADVERTISE, etc.
  </li><li>Make the example bgpd.conf work out of the box with 4byte ASN.
  </li></ul>

  </li><li>In <a href="https://man.openbsd.org/rpki-client.8">rpki-client(8)</a>,
  <ul>
  <li>The generated BIRD config file was reworked. BIRD versions 1.x are no
  longer supported and the -T option to customize the ROA table name was
  removed. The config file now includes the ASPA-set by default and is
  therefore only compatible with BIRD 2.16 and later. If compatibility
  with older BIRD versions is required, the ASPA-set can be excluded
  with the -A flag. Operators should delete any remaining bird1v4 and
  bird1v6 output files.
  </li><li>Validated ROA payloads from AS0 TALs are by default excluded from the
  output files as they are not recommended for automatic filtering of
  BGP routes. This precaution can be overridden with the new -0 flag.
  </li><li>Various improvements to the ibuf API, including a new reader API
  which is used to make all message parsing in rpki-client memory safe.
  </li><li>Warn about gaps in manifest issuance. Such gaps can appear for example
  if rpki-client isn't run frequently enough, if there are issues with
  an RFC 8181 publication server or if there is an operational error on
  the side of the CA.
  </li><li>Work around a backward compatibility break accidentally introduced
  in OpenSSL 3.4.0, which resulted in all RPKI signed objects being
  rejected. Earlier and later versions of OpenSSL are not affected.
  </li><li>Improved validity period checking in file mode. The product's lifetime
  and the expiration time of the signature path are now taken into
  account.
  </li><li>Better cleanup in case of a fallback from RRDP to RSYNC. In rare
  circumstances, files were moved to the wrong place in the cache.
  </li><li>rpki-client now includes arin.tal which is no longer
  <a href="https://www.arin.net/announcements/20250116-tal/">legally encumbered</a>.
  </li><li>rpki-client reports Certification Authorities that do not meaningfully
  participate in the RPKI as non-functional CAs. By definition, a CA is
  non-functional if there is no currently valid Manifest. The number of
  such CAs is printed at the end of each run and more detailed information
  is available in the JSON (-j) and ometrics (-m) output.
  </li><li>Fix a problem where incorrect internal RRDP state handling in
  rpki-client could lead to a denial of service.
  </li><li>Termination of rsync child processes with SIGTERM is no longer treated as
  an error if rpki-client has sent this signal. This only affects openrsync.
  </li><li>Do not exit filemode with an error if a .gbr or a .tak object contains
  control characters in its UTF-8 strings. Instead, only warn and emit a
  sanitized version in JSON output.
  </li></ul>
</li></ul><!-- Routing daemons and other userland network improvements -->

</li><li><a href="https://man.openbsd.org/tmux.1">tmux(1)</a> improvements and bug fixes:
  <ul>
  <li>Fixed grey color in <a href="https://man.openbsd.org/tmux.1">tmux(1)</a>.
  </li><li>Added a way to make the preview larger in <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> tree mode.
  </li><li>Fixed <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> problems with pasted text being interpreted as extended keys.
  </li><li>Made <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> only use default-shell for popups, returning to /bin/sh for run-shell, if-shell and #().
  </li><li>Added MSYSTEM to <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> default update-environment.
  </li><li>Added copy-mode-position-format to configure the <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> position indicator.
  </li><li>Added -y flag to disable <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> confirmation prompts in modes.
  </li><li>Reworked <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> copy mode commands ("send-keys -X") to parse the arguments so that flags may be detected properly rather than just looking for strings ("-O" and so on). Also added -C and -P flags to the copy commands. -C prevents the commands from sending the text to the clipboard and -P prevents them from adding the text as a paste buffer.
  </li><li>Added <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> prompt-cursor-colour and prompt-cursor-style to set the style of the cursor in the command prompt and remove the emulated cursor.
  </li><li>Added <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> initial-repeat-time option to allow the first repeat time to be increased and later reduced.
  </li><li>Added a <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> sixel_support format variable which is 1 if SIXEL is supported (always 0 on OpenBSD).
  </li><li>Allow control characters prefixed with C-v to be entered at the tmux.1 command prompt.
  </li><li>Added <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> support for a scrollbar at the side of each pane using new options pane-scrollbars, pane-scrollbars-positions and pane-scrollbars-styles.
  </li><li>Added <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> option to control the input buffer size.
  </li><li>Added <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> scrollbar mouse support.
  </li><li>Added a <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> no-detach-on-destroy client option, useful for control mode clients.
  </li><li>Added <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> scrollbar style parameters width and pad.
  </li><li>Added copy-mode-position-style and copy-mode-selection-style options to <a href="https://man.openbsd.org/tmux.1">tmux(1)</a>.
  </li><li>Added a <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> option allowing users to override the width of individual Unicode codepoints.
  </li><li>Fixed mouse_hyperlink format in <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> copy mode.
  </li><li>Added S-Up and S-Down to move windows in <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> tree mode.
  </li><li>Made <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> correctly skip wide characters in hyperlinks.
  </li><li>Made <a href="https://man.openbsd.org/tmux.1">tmux(1)</a> only align panes and windows, not sessions.
</li></ul>

</li><li>LibreSSL version 4.1.0
  <ul>
  <li>Portable changes
    <ul>
    <li>Added initial experimental support for loongarch64.
    </li><li>Fixed compilation for mips32 and reenable CI.
    </li><li>Fixed CMake builds on FreeBSD.
    </li><li>Fixed the --prefix option for cmake --install.
    </li><li>Fixed tests for MinGW due to missing sh(1).
    </li></ul>
  </li><li>Internal improvements
    <ul>
    <li>Cleaned up the error implementation.
    </li><li>Many bug fixes and simplifications in the EC ASN.1 code.
    </li><li>Corrected DER encoding for EC keys and parameters.
    </li><li>Polished
      <a href="https://man.openbsd.org/EC_POINT_oct2point.3">EC_POINT_{oct2point,point2oct}(3)</a> internals.
    </li><li>Rewrote the wNAF code for fast ECDSA verification.
    </li><li>Improved the code setting compressed coordinates for EC points.
    </li><li>Reworked CPU capabilities detection for amd64 and aarch64.
    </li><li>New SHA-1, SHA-256 and SHA-512 assembly implementations for amd64.
      These make use of the SHA-NI instruction if it is available and
      replace the perl-generated assembly optimized for museum pieces.
      These are not yet enabled in libressl-portable.
    </li><li>New SHA-256 and SHA-512 assembly implementations for aarch64
      making use of the ARM Cryptographic Extension (CE). Not yet
      enabled in libressl-portable.
    </li><li>New simplified, readable MD5 implementation for amd64.
    </li><li>Rewrote
      <a href="https://man.openbsd.org/BN_bn2binpad.3">BN_bn2binpad(3)</a>
      and its lebin siblings.
    </li><li>The BIGNUMs in EC_GROUP and EC_POINT are now heap allocated.
    </li><li>Rewrote TS_ASN1_INTEGER_print_bio().
    </li><li>Improved bit counter handling in MD5.
    </li><li>Simplified and cleaned up the BN_RECP_CTX internals.
    </li><li>Improved SM4 to match other symmetric ciphers more closely.
    </li><li>Rewrote <a href="https://man.openbsd.org/X509_NAME_oneline.3">X509_NAME_oneline(3)</a> and X509_NAME_print() using CBS/CBB.
    </li><li>CRLs are now cached in the issuer cache like certificates.
    </li><li>Replaced combinations of
      <a href="https://man.openbsd.org/BN_MONT_CTX_new.3">BN_MONT_CTX_new(3)</a>/set with an internal BN_MONT_CTX_create().
    </li><li>Replaced <a href="https://man.openbsd.org/BN_bn2hex.3">BN_bn2hex(3)</a>
      reimplementation in
      <a href="https://man.openbsd.org/openssl.1#ca">openssl(1) ca</a> with
      a proper API call.
    </li><li>Fixed integer overflows due to signed shift in obj_dat.c.
    </li><li>Improved some X509_VERIFY_PARAM internals and avoid an out of
      bounds read from public API.
    </li><li>Imported ML-KEM 768 and 1024 from BoringSSL (not yet public API).
    </li></ul>
  </li><li>Compatibility changes
    <ul>
    <li>Added an OPENSSL_INIT_NO_ATEXIT flag for
      <a href="https://man.openbsd.org/OPENSSL_init_crypto.3">OPENSSL_init_crypto(3)</a>.
      It has no effect since LibreSSL doesn't call
      <a href="https://man.openbsd.org/atexit.3">atexit(3)</a>.
    </li><li>Elliptic curve parameters are only accepted if they encode a
      built-in curve.
    </li><li>EC_METHOD is no longer public and the API exposing it has been
      removed.  This includes
      <a href="https://man.openbsd.org/OpenBSD-7.6/EC_GROUP_new.3">EC_GROUP_new(3)</a>,
      <a href="https://man.openbsd.org/OpenBSD-7.6/EC_GFp_mont_method.3">EC_GFp_mont_method(3)</a>,
      <a href="https://man.openbsd.org/OpenBSD-7.6/EC_GROUP_method_of.3">EC_GROUP_method_of(3)</a>, and EC_METHOD_get_field_type().
    </li><li>The precomputation stubs for EC_GROUP were removed.
    </li><li>The API setting Jacobian projective coordinates for a point was
      removed as were
      <a href="https://man.openbsd.org/OpenBSD-7.6/EC_POINTs_mul.3">EC_POINTs_{mul,make_affine}(3)</a>.
    </li><li>All elliptic curves over fields with less than 224 bits and a
      few more were removed from the built-in curves. This includes
      all WTLS curves and P-192.
    </li><li>It is no longer necessary to set RSA_FLAG_SIGN_VER to use the
      sign and verify handlers set with
      <a href="https://man.openbsd.org/RSA_meth_set_sign.3">RSA_meth_set_{sign,verify}</a>.
    </li><li>Removed the -C option to generate "C code" from the
      <a href="https://man.openbsd.org/openssl.1">openssl(1)</a>
      dh, dhparam, dsaparam, ecparam, and x509 subcommands.
    </li><li>Removed #error in headers when OPENSSL_NO_* is defined.
    </li><li><a href="https://man.openbsd.org/CRYPTO_set_mem_functions.3">CRYPTO_set_mem_functions(3)</a> now matches OpenSSL 1.1 and
      CRYPTO_set_mem_ex_functions() was removed.
    </li><li>The tls_session_secret_cb_fn type now matches OpenSSL 1.1.
    </li><li>Unexport
      <a href="https://man.openbsd.org/OpenBSD-7.6/X509_NAME_print.3">X509_NAME_print(3)</a> and
      <a href="https://man.openbsd.org/OpenBSD-7.6/X509_OBJECT_up_ref_count.3">X509_OBJECT_up_ref_count(3)</a>.
    </li><li>const corrected
      <a href="https://man.openbsd.org/UI_OpenSSL.3">UI_OpenSSL(3)</a> and
      <a href="https://man.openbsd.org/BN_MONT_CTX_copy.3">BN_MONT_CTX_copy(3)</a>.
    </li><li>Support OPENSSL_NO_FILENAMES.
    </li><li>Support SSL_OP_NO_RENEGOTIATION and SSL_OP_ALLOW_CLIENT_RENEGOTIATION.
    </li><li>Export PKCS12_key_gen_uni() again.
    </li></ul>
  </li><li>New features
    <ul>
    <li>libtls has a new
      <a href="https://man.openbsd.org/tls_peer_cert_common_name.3">tls_peer_cert_common_name(3)</a> API call to retrieve
      the peer's common name without having to inspect the PEM.
    </li></ul>
  </li><li>Bug fixes
    <ul>
    <li>Plugged a leak in eckey_compute_pubkey().
    </li><li>Again allow the magic values -1, -2 and -3 for the salt length
      of an RSA-PSS key in the
      <a href="https://man.openbsd.org/EVP_PKEY_CTX_ctrl_str.3">EVP_PKEY_CTX_ctrl_str(3)</a> interface.
    </li><li>Fixed a few memory leaks in legacy code.
    </li></ul>
  </li><li>Documentation
    <ul>
    <li>The remaining undocumented public
      <a href="https://man.openbsd.org/evp.3">EVP</a> API is now documented.
    </li><li>Reorganization of existing documentation for clarity and accuracy.
    </li></ul>
  </li><li>Testing and proactive security
    <ul>
    <li>Improved regress coverage of the EC code.
    </li></ul>
  </li></ul>

</li><li>OpenSSH 10.0
  <ul>
  <li>Security fixes
    <ul>

      <li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
      fix the DisableForwarding directive, which was failing
      to disable X11 forwarding and agent forwarding as documented.
      X11 forwarding is disabled by default in the server and agent
      forwarding is off by default in the client.
    </li></ul>
  </li><li>Potentially incompatible changes
    <ul>
    <li>This release removes support for the weak DSA signature
    algorithm, completing the deprecation process that began in
    2015 (when DSA was disabled by default) and repeatedly warned
    over the last 12 months.

    </li><li><a href="https://man.openbsd.org/scp.1">scp(1)</a>, <a href="https://man.openbsd.org/sftp.1">sftp(1)</a>: pass "ControlMaster
    no" to ssh when invoked by scp &amp; sftp. This disables implicit
    session creation by these tools when ControlMaster was set to yes/auto
    by configuration, which some users found surprising. This change will
    not prevent scp/sftp from using an existing multiplexing session if
    one had already been created.

    </li><li>This release has the version number 10.0 and announces itself as
    "SSH-2.0-OpenSSH_10.0". Software that naively matches versions using
    patterns like "OpenSSH_1*" may be confused by this.

     </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: this
     release removes the code responsible for the user authentication
     phase of the protocol from the per- connection sshd-session binary to
     a new sshd-auth binary.  Splitting this code into a separate binary
     ensures that the crucial pre-authentication attack surface has an
     entirely disjoint address space from the code used for the rest
     of the connection. It also yields a small runtime memory saving as
     the authentication code will be unloaded after the authentication
     phase completes. This change should be largely invisible to users,
     though some log messages may now come from "sshd-auth" instead of
     "sshd-session". Downstream distributors of OpenSSH will need to
     package the sshd-auth binary.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: this
      release disables finite field (a.k.a modp) Diffie-Hellman key
      exchange in sshd by default. Specifically, this removes the
      "diffie-hellman-group*" and "diffie-hellman-group-exchange-*"
      methods from the default KEXAlgorithms list. The client is unchanged
      and continues to support these methods by default. Finite field
      Diffie Hellman is slow and computationally expensive for the same
      security level as Elliptic Curve DH or PQ key agreement while
      offering no redeeming advantages. ECDH has been specified for
      the SSH protocol for 15 years and some form of ECDH has been the
      default key exchange in OpenSSH for the last 14 years.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: this
      release removes the implicit fallback to compiled- in groups for
      Diffie-Hellman Group Exchange KEX when the moduli file exists
      but does not contain moduli within the client- requested range.
      The fallback behaviour remains for the case where the moduli file
      does not exist at all. This allows administrators more explicit
      control over which DH groups will be selected, but can lead to
      connection failures if the moduli file is edited incorrectly.

    </li></ul>

  </li><li>New features
    <ul>

     <li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: the hybrid
     post-quantum algorithm mlkem768x25519-sha256
     is now used by default for key agreement. This algorithm is considered
     to be safe against attack by quantum computers, is guaranteed to
     be no less strong than the popular curve25519-sha256 algorithm,
     has been standardised by NIST and is considerably faster than the
     previous default.

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: prefer AES-GCM
     to AES-CTR mode when selecting a cipher for the connection. The
     default cipher preference list is now ChaCha20/Poly1305, AES-GCM
     (128/256) followed by AES-CTR (128/192/256).

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: add %-token
     and environment variable expansion to the ssh_config SetEnv directive.

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: allow %-token
     and environment variable expansion in the ssh_config User directive,
     with the exception of %r and %C which would be self-referential.

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: add "Match version"
     support to ssh_config and sshd_config. Allows matching on the local
     version of OpenSSH, e.g. "Match version OpenSSH_10.*".

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: add support
     for "Match sessiontype" to ssh_config.  Allows matching on the type of
     session initially requested, either "shell" for interactive sessions,
     "exec" for command execution sessions, "subsystem" for subsystem
     requests, such as sftp, or "none" for transport/forwarding-only
     sessions.

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: add support
     for "Match command ..." support to ssh_config, allowing matching on
     the remote command as specified on the command-line.

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: allow 'Match
     tagged ""' and 'Match command ""' to match empty tag and command
     values respectively.

     </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: allow
     glob(3) patterns to be used in sshd_config AuthorizedKeysFile and
     AuthorizedPrincipalsFile directives.

     </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: support the
     VersionAddendum in the client, mirroring the option of the same name
     in the server.

     </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>: the
     agent will now delete all loaded keys when signaled with SIGUSR1. This
     allows deletion of keys without having access to $SSH_AUTH_SOCK.

     </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
     support FIDO tokens that return no attestation data, e.g. recent
     WinHello.

     </li><li><a href="https://man.openbsd.org/ssh-agent.1">ssh-agent(1)</a>: add
     a "-Owebsafe-allow=..." option to allow the default FIDO application
     ID allow-list to be overridden.

     </li><li>Add a work-in-progress tool to verify FIDO attestation blobs
     that ssh-keygen can optionally write when enrolling FIDO keys.
     This tool is available under regress/misc/ssh-verify-attestation
     for experimentation but is not installed by "make install".

     </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
     allow "-" as output file for moduli screening.

    </li></ul>
  </li><li>Bugfixes
    <ul>
      <li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: remove
      assumption that the sshd_config and any configs
      it includes can fit in a (possibly enlarged) socket buffer.  Previously
      it was possible to create a sufficiently large configuration
      that could cause sshd to fail to accept any connection. <a href="https://man.openbsd.org/sshd.8">sshd(8)</a> will now actively
      manage sending its config to the sshd-session sub-process.

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: don't start
      the ObscureKeystrokeTiming mitigations if there has been traffic
      on a X11 forwarding channel recently.  Should fix X11 forwarding
      performance problems when this setting is enabled.

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: prohibit the
      comma character in hostnames accepted, but allow an underscore as
      the first character in a hostname.

      </li><li><a href="https://man.openbsd.org/sftp.1">sftp(1)</a>: set
      high-water when resuming a "put". Prevents bogus "server reordered
      acks" debug message.

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: fix regression in
      openssh-9.8, which would fail to accept "Match criteria=argument" as
      well as the documented "Match criteria argument" syntax in ssh_config
      and sshd_config.

      </li><li><a href="https://man.openbsd.org/sftp.1">sftp(1)</a>, <a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: fix a number possible
      NULL dereference bugs, including Coverity CIDs 405019 and 477813.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: fix
      PerSourcePenalty incorrectly using "crash" penalty when LoginGraceTime
      was exceeded.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: fix "Match
      invalid-user" from incorrectly being activated in initial configuration
      pass when no other predicates were present on the match line

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: fix debug
      logging of user specific delay.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: improve
      debug logging across sub-process boundaries.
      Previously some log messages were lost early in the sshd-auth and
      sshd-session processes' life.

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: require
      control-escape character sequences passed via the '-e ^x' command-line
      to be exactly two characters long. Avoids one byte out-of-bounds read
      if ssh is invoked as "ssh -e^ ..."

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>, <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: prevent integer
      overflow in X11 port handling.  These are theoretically possible if
      the admin misconfigured X11DisplayOffset or the user misconfigures
      their own $DISPLAY, but don't happen in normal operation.

      </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
      don't mess up ssh-keygen -l output when the file contains CR
      characters.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>:
      add rate limits to logging of connections dropped by
      PerSourcePenalties. Previously these could be noisy in logs.

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>: fix argument
      of "Compression" directive in ssh -G config dump, which regressed
      in openssh-9.8.

      </li><li><a href="https://man.openbsd.org/sshd.8">sshd(8)</a>: fix a
      corner-case triggered by UpdateHostKeys when sshd refuses to accept
      the signature returned by an agent holding host keys during the hostkey
      rotation sub-protocol. This situation could occur in situations where
      a PKCS#11 smartcard that lacked support for particular signature
      algorithms was used to store host keys.

      </li><li><a href="https://man.openbsd.org/ssh-keygen.1">ssh-keygen(1)</a>:
      when using RSA keys to sign messages with "ssh-keygen -Y", select
      the signature algorithm based on the requested hash algorithm
      ("-Ohashalg=xxx"). This allows using something other than the default
      of rsa-sha2-512, which may not be supported on all signing backends,
      e.g. some smartcards only support SHA256.

      </li><li><a href="https://man.openbsd.org/ssh.1">ssh(1)</a>,
      <a href="https://man.openbsd.org/sshd.8">sshd(8)</a>, <a href="https://man.openbsd.org/ssh-keyscan.1">ssh-keyscan(1)</a>:
      fix ML-KEM768x25519 KEX on big-endian systems.

      </li><li>Many regression and interop test improvements.
    </li></ul>
  </li></ul>

</li><li>Ports and packages:
  <p>Many pre-built packages for each architecture:
  <!-- number of FTP packages minus SHA256, SHA256.sig, index.txt -->
  </p><ul>
    <li>aarch64:    12446
    </li><li>amd64:      12593
    </li><li>arm:        xxx
    </li><li>i386:       10429
    </li><li>mips64:     8635
    </li><li>powerpc:    xxx
    </li><li>powerpc64:  7501
    </li><li>riscv64:    10585
    </li><li>sparc64:    9080
  </li></ul>

  <p>Some highlights:
  </p><ul><!-- checked 2025-04-12 -->
    <li>Asterisk 16.30.1, 18.26.1, 20.13.0 and 22.3.0
    </li><li>Audacity 3.7.3
    </li><li>CMake 3.31.6
    </li><li>Chromium 135.0.7049.52
    </li><li>Emacs 30.1
    </li><li>FFmpeg 6.1.2
    </li><li>GCC 8.4.0 and 11.2.0
    </li><li>GHC 9.8.3
    </li><li>GNOME 47
    </li><li>Go 1.24.1
    </li><li>JDK 8u442, 11.0.26, 17.0.14 and 21.0.6
    </li><li>KDE Applications 24.12.3
    </li><li>KDE Frameworks 6.12.0
    </li><li>KDE Plasma 6.3.3
    </li><li>Krita 5.2.9
    </li><li>LLVM/Clang 13.0.0, 16.0.6, 18.1.8 and 19.1.7
    </li><li>LibreOffice 25.2.1.2
    </li><li>Lua 5.1.5, 5.2.4, 5.3.6 and 5.4.7
    </li><li>MariaDB 11.4.5
    </li><li>Mono 6.12.0.199
    </li><li>Mozilla Firefox 137.0 and ESR 128.9.0
    </li><li>Mozilla Thunderbird 128.9.0
    </li><li>Mutt 2.2.14 and NeoMutt 20250113
    </li><li>Node.js 22.14.0
    </li><li>OCaml 4.14.2
    </li><li>OpenLDAP 2.6.9
    </li><li>PHP 8.2.28, 8.3.19 and 8.4.5
    </li><li>Postfix 3.10.1
    </li><li>PostgreSQL 17.4
    </li><li>Python 2.7.18 and 3.12.9
    </li><li>Qt 5.15.16 (+ kde patches) and 6.8.2
    </li><li>R 4.4.2
    </li><li>Ruby 3.2.8, 3.3.7 and 3.4.2
    </li><li>Rust 1.86.0
    </li><li>SQLite 3.49.1
    </li><li>Shotcut 25.01.25
    </li><li>Sudo 1.9.16p1
    </li><li>Suricata 7.0.7
    </li><li>Tcl/Tk 8.5.19 and 8.6.16
    </li><li>TeX Live 2024
    </li><li>Vim 9.1.1265 and Neovim 0.10.4
    </li><li>Xfce 4.20.0
  </li></ul>
  </li><li>As usual, steady improvements in manual pages and other documentation.

</li><li>The system includes the following major components from outside suppliers:
  <ul><!-- updated 2025-04-12 -->
    <li>Xenocara (based on X.Org 7.7 with xserver 21.1.16 + patches,
        freetype 2.13.3, fontconfig 2.15.0, Mesa 23.3.6, xterm 395,
        xkeyboard-config 2.20, fonttosfnt 1.2.4 and more)
    </li><li>LLVM/Clang 16.0.6 (+ patches)
    </li><li>GCC 4.2.1 (+ patches) and 3.3.6 (+ patches)
    </li><li>Perl 5.40.1 (+ patches)
    </li><li>NSD 4.9.1
    </li><li>Unbound 1.22.0
    </li><li>Ncurses 6.4
    </li><li>Binutils 2.17 (+ patches)
    </li><li>Gdb 6.3 (+ patches)
    </li><li>Awk 20250116
    </li><li>Expat 2.7.1
    </li><li>zlib 1.3.1 (+ patches)
  </li></ul>
</li></ul>
</section>

<hr>

<section id="install">
<h3>How to install</h3>
<p>
Please refer to the following files on the mirror site for
extensive details on how to install OpenBSD 7.7 on your machine:

</p><ul>
<li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/alpha/INSTALL.alpha">
	.../OpenBSD/7.7/alpha/INSTALL.alpha</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/amd64/INSTALL.amd64">
	.../OpenBSD/7.7/amd64/INSTALL.amd64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/arm64/INSTALL.arm64">
	.../OpenBSD/7.7/arm64/INSTALL.arm64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/armv7/INSTALL.armv7">
	.../OpenBSD/7.7/armv7/INSTALL.armv7</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/hppa/INSTALL.hppa">
	.../OpenBSD/7.7/hppa/INSTALL.hppa</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/i386/INSTALL.i386">
	.../OpenBSD/7.7/i386/INSTALL.i386</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/landisk/INSTALL.landisk">
	.../OpenBSD/7.7/landisk/INSTALL.landisk</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/loongson/INSTALL.loongson">
	.../OpenBSD/7.7/loongson/INSTALL.loongson</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/luna88k/INSTALL.luna88k">
	.../OpenBSD/7.7/luna88k/INSTALL.luna88k</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/macppc/INSTALL.macppc">
	.../OpenBSD/7.7/macppc/INSTALL.macppc</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/octeon/INSTALL.octeon">
	.../OpenBSD/7.7/octeon/INSTALL.octeon</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/powerpc64/INSTALL.powerpc64">
	.../OpenBSD/7.7/powerpc64/INSTALL.powerpc64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/riscv64/INSTALL.riscv64">
	.../OpenBSD/7.7/riscv64/INSTALL.riscv64</a>
</li><li><a href="https://ftp.openbsd.org/pub/OpenBSD/7.7/sparc64/INSTALL.sparc64">
	.../OpenBSD/7.7/sparc64/INSTALL.sparc64</a>
</li></ul>
</section>

<hr>

<section id="quickinstall">
<p>
Quick installer information for people familiar with OpenBSD, and the use of
the "<a href="https://man.openbsd.org/disklabel.8">disklabel</a> -E" command.
If you are at all confused when installing OpenBSD, read the relevant
INSTALL.* file as listed above!

</p><h3>OpenBSD/alpha:</h3>

<p>
If your machine can boot from CD, you can write <i>install77.iso</i> or
<i>cd77.iso</i> to a CD and boot from it.
Refer to INSTALL.alpha for more details.

</p><h3>OpenBSD/amd64:</h3>

<p>
If your machine can boot from CD, you can write <i>install77.iso</i> or
<i>cd77.iso</i> to a CD and boot from it.
You may need to adjust your BIOS options first.

</p><p>
If your machine can boot from USB, you can write <i>install77.img</i> or
<i>miniroot77.img</i> to a USB stick and boot from it.

</p><p>
If you can't boot from a CD, floppy disk, or USB,
you can install across the network using PXE as described in the included
INSTALL.amd64 document.

</p><p>
If you are planning to dual boot OpenBSD with another OS, you will need to
read INSTALL.amd64.

</p><h3>OpenBSD/arm64:</h3>

<p>
If your machine can boot from CD, you can write <i>install77.iso</i> or
<i>cd77.iso</i> to a CD and boot from it.

</p><p>
To boot from disk, write <i>install77.img</i> or <i>miniroot77.img</i> to a
disk and boot from it after connecting to the serial console.  Refer to
INSTALL.arm64 for more details.

</p><h3>OpenBSD/armv7:</h3>

<p>
Write a system specific miniroot to an SD card and boot from it after connecting
to the serial console.  Refer to INSTALL.armv7 for more details.

</p><h3>OpenBSD/hppa:</h3>

<p>
Boot over the network by following the instructions in INSTALL.hppa or the
<a href="https://www.openbsd.org/hppa.html#install">hppa platform page</a>.

</p><h3>OpenBSD/i386:</h3>

<p>
If your machine can boot from CD, you can write <i>install77.iso</i> or
<i>cd77.iso</i> to a CD and boot from it.
You may need to adjust your BIOS options first.

</p><p>
If your machine can boot from USB, you can write <i>install77.img</i> or
<i>miniroot77.img</i> to a USB stick and boot from it.

</p><p>
If you can't boot from a CD, floppy disk, or USB,
you can install across the network using PXE as described in
the included INSTALL.i386 document.

</p><p>
If you are planning on dual booting OpenBSD with another OS, you will need to
read INSTALL.i386.

</p><h3>OpenBSD/landisk:</h3>

<p>
Write <i>miniroot77.img</i> to the start of the CF
or disk, and boot normally.

</p><h3>OpenBSD/loongson:</h3>

<p>
Write <i>miniroot77.img</i> to a USB stick and boot bsd.rd from it
or boot bsd.rd via tftp.
Refer to the instructions in INSTALL.loongson for more details.

</p><h3>OpenBSD/luna88k:</h3>

<p>
Copy 'boot' and 'bsd.rd' to a Mach or UniOS partition, and boot the bootloader
from the PROM, and then bsd.rd from the bootloader.
Refer to the instructions in INSTALL.luna88k for more details.

</p><h3>OpenBSD/macppc:</h3>

<p>
Burn the image from a mirror site to a CDROM, and power on your machine
while holding down the <i>C</i> key until the display turns on and
shows <i>OpenBSD/macppc boot</i>.

</p><p>
Alternatively, at the Open Firmware prompt, enter <i>boot cd:,ofwboot
/7.7/macppc/bsd.rd</i>

</p><h3>OpenBSD/octeon:</h3>

<p>
After connecting a serial port, boot bsd.rd over the network via DHCP/tftp.
Refer to the instructions in INSTALL.octeon for more details.

</p><h3>OpenBSD/powerpc64:</h3>

<p>
To install, write <i>install77.img</i> or <i>miniroot77.img</i> to a
USB stick, plug it into the machine and choose the <i>OpenBSD
install</i> menu item in Petitboot.
Refer to the instructions in INSTALL.powerpc64 for more details.

</p><h3>OpenBSD/riscv64:</h3>

<p>
To install, write <i>install77.img</i> or <i>miniroot77.img</i> to a
USB stick, and boot with that drive plugged in.
Make sure you also have the microSD card plugged in that shipped with the
HiFive Unmatched board.
Refer to the instructions in INSTALL.riscv64 for more details.

</p><h3>OpenBSD/sparc64:</h3>

<p>
Burn the image from a mirror site to a CDROM, boot from it, and type
<i>boot cdrom</i>.

</p><p>
If this doesn't work, or if you don't have a CDROM drive, you can write
<i>floppy77.img</i> or <i>floppyB77.img</i>
(depending on your machine) to a floppy and boot it with <i>boot
floppy</i>. Refer to INSTALL.sparc64 for details.

</p><p>
Make sure you use a properly formatted floppy with NO BAD BLOCKS or your install
will most likely fail.

</p><p>
You can also write <i>miniroot77.img</i> to the swap partition on
the disk and boot with <i>boot disk:b</i>.

</p><p>
If nothing works, you can boot over the network as described in INSTALL.sparc64.
</p></section>

<hr>

<section id="upgrade">
<h3>How to upgrade</h3>
<p>
If you already have an OpenBSD 7.6 system, and do not want to reinstall,
upgrade instructions and advice can be found in the
<a href="https://www.openbsd.org/faq/upgrade77.html">Upgrade Guide</a>.
</p></section>

<hr>

<section id="sourcecode">
<h3>Notes about the source code</h3>
<p>
<code>src.tar.gz</code> contains a source archive starting at <code>/usr/src</code>.
This file contains everything you need except for the kernel sources,
which are in a separate archive.
To extract:
</p><blockquote><pre># <kbd>mkdir -p /usr/src</kbd>
# <kbd>cd /usr/src</kbd>
# <kbd>tar xvfz /tmp/src.tar.gz</kbd>
</pre></blockquote>
<p>
<code>sys.tar.gz</code> contains a source archive starting at <code>/usr/src/sys</code>.
This file contains all the kernel sources you need to rebuild kernels.
To extract:
</p><blockquote><pre># <kbd>mkdir -p /usr/src/sys</kbd>
# <kbd>cd /usr/src</kbd>
# <kbd>tar xvfz /tmp/sys.tar.gz</kbd>
</pre></blockquote>
<p>
Both of these trees are a regular CVS checkout.  Using these trees it
is possible to get a head-start on using the anoncvs servers as
described <a href="https://www.openbsd.org/anoncvs.html">here</a>.
Using these files
results in a much faster initial CVS update than you could expect from
a fresh checkout of the full OpenBSD source tree.
</p></section>

<hr>

<section id="ports">
<h3>Ports Tree</h3>
<p>
A ports tree archive is also provided.  To extract:
</p><blockquote><pre># <kbd>cd /usr</kbd>
# <kbd>tar xvfz /tmp/ports.tar.gz</kbd>
</pre></blockquote>
<p>
Go read the <a href="https://www.openbsd.org/faq/ports/index.html">ports</a> page
if you know nothing about ports
at this point.  This text is not a manual of how to use ports.
Rather, it is a set of notes meant to kickstart the user on the
OpenBSD ports system.
</p><p>
The <i>ports/</i> directory represents a CVS checkout of our ports.
As with our complete source tree, our ports tree is available via
<a href="https://www.openbsd.org/anoncvs.html">AnonCVS</a>.
So, in order to keep up to date with the -stable branch, you must make
the <i>ports/</i> tree available on a read-write medium and update the tree
with a command like:
</p><blockquote><pre># <kbd>cd /usr/ports</kbd>
# <kbd>cvs -d anoncvs@server.openbsd.org:/cvs update -Pd -rOPENBSD_7_7</kbd>
</pre></blockquote>
<p>
[Of course, you must replace the server name here with a nearby anoncvs
server.]
</p><p>
Note that most ports are available as packages on our mirrors. Updated
ports for the 7.7 release will be made available if problems arise.
</p><p>
If you're interested in seeing a port added, would like to help out, or just
would like to know more, the mailing list
<a href="https://www.openbsd.org/mail.html">ports@openbsd.org</a> is a good place to know.
</p></section>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Read the Obits (207 pts)]]></title>
            <link>https://thereader.mitpress.mit.edu/the-creativity-hack-no-one-told-you-about-read-the-obits/</link>
            <guid>43813175</guid>
            <pubDate>Sun, 27 Apr 2025 16:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thereader.mitpress.mit.edu/the-creativity-hack-no-one-told-you-about-read-the-obits/">https://thereader.mitpress.mit.edu/the-creativity-hack-no-one-told-you-about-read-the-obits/</a>, See on <a href="https://news.ycombinator.com/item?id=43813175">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Reading obituaries can boost creativity by exposing you to distant ideas, fueling the associations that lead to unexpected breakthroughs.</p><figure><img width="700" height="420" src="https://thereader.mitpress.mit.edu/wp-content/uploads/2025/04/Obituaries-700x420.jpg" alt="" decoding="async" fetchpriority="high"><figcaption>The obituary section of the April 6, 2025, issue of The New York Times, with the author's highlights.</figcaption></figure><p>I’ve been reading the obituaries for as long as I can remember. At first glance, they might seem like little more than a collection of dates and accomplishments. But for me, they’ve become a wellspring of creativity — each one a glimpse into a life I never would’ve imagined. And as decades of creativity research suggest, the most original ideas often come from the most unlikely sources.</p><p>That’s why one popular piece of advice for boosting creativity is to learn something new every day. But here’s the catch: This only works if that new information is <em>very different</em> from what’s already in your head. This is where most of our modern habits fall short. Internet searches, for instance, give you information that’s related to what you already know, or information that you’re already interested in. So, how do you escape that loop and stumble upon something unexpected, something you didn’t even know to look for? The obituaries, obviously — but I’ll come back to that.</p><p>In February, I <a href="https://sawyerpodcast.com/yoed-kenett-the-associations-of-the-creative-mind" target="_blank" rel="nofollow">interviewed Yoed Kenett</a>, who studies high-level cognition and creativity, for my podcast “The Science of Creativity.” His research shows that creativity thrives on making connections between very different concepts. The core idea is simple: Our ability to create relies on prior knowledge, and our creative potential increases when that knowledge is organized into conceptual networks that help us search for, connect, and generate new ideas — what Kenett calls a “Google of the mind.”</p><figure><blockquote><p>The greater the distance between two ideas, the more original and surprising their combination tends to be.</p></blockquote></figure><p>This research goes back to the 1960s, when psychologist Sarnoff Mednick was studying patterns of thought in people diagnosed with schizophrenia. He was exploring the idea that highly creative individuals might share certain associative patterns with those diagnosed with schizophrenia, namely, the tendency to make connections between seemingly unrelated ideas. In <a href="https://psycnet.apa.org/record/1963-06161-001" target="_blank" rel="nofollow">a classic 1962 experiment</a>, Mednick asked participants to say the first word that came to mind when they heard a prompt like <em>table</em>. Less creative participants tended to respond with obvious associations like <em>chair</em> or <em>leg</em>. The more creative participants gave those answers, too, but they also came up with more surprising ones, like <em>food</em> or even <em>mouse</em>.</p><p>Mednick’s observations led him to propose that highly creative people have a different kind of memory structure — one that holds a wider range of ideas and forges more unexpected connections between them. He called his theory <em>the associative theory of creativity</em>. His research showed that creative ideas are more likely to emerge from combinations of concepts that are further apart in the mind’s conceptual network. The greater the distance between two ideas, the more original and surprising their combination tends to be. <a href="https://pubmed.ncbi.nlm.nih.gov/30667235/" target="_blank" rel="nofollow">More recent research</a>, by Kenett and others, confirms these observations.</p><p>Some of the best-known stories of invention come from unexpected associations. Velcro, for example, <a href="https://invention.si.edu/invention-stories/george-de-mestral-velcror-inventor" target="_blank" rel="nofollow">was invented</a> when George de Mestral was walking his hairy sheepdog through a field of burr-covered plants. It’s notoriously difficult to remove burrs from an animal’s hair, which means the animal is going to carry seeds a far distance, allowing the plant to spread more successfully. De Mestral took out a magnifying glass and saw very tiny hooks that clung to the dog’s hair. Then he made the distant connection: The burr’s mechanism, designed by nature to spread seeds, could be used to make a clothing fastener. There’s no shortage of other surprising inventions that began with distant connections: <a href="https://www.invent.org/blog/trends-stem/who-invented-post-it-notes" target="_blank" rel="nofollow">Post-It notes</a>, the <a href="https://www.sciencealert.com/these-eighteen-accidental-scientific-discoveries-changed-the-world" target="_blank" rel="nofollow">X-ray</a>, <a href="https://thereader.mitpress.mit.edu/is-discovery-inevitable-or-serendipitous/">shatterproof glass</a>, <a href="https://www.scienceabc.com/social-science/how-some-inventions-had-the-funniest-origin-stories.html" target="_blank" rel="nofollow">the microwave oven</a>, <a href="https://www.museumofplay.org/toys/silly-putty/" target="_blank" rel="nofollow">silly putty</a>, <a href="https://www.mddionline.com/cardiovascular/the-surprising-history-behind-an-extremely-common-cardiovascular-medical-device" target="_blank" rel="nofollow">heart stents</a>.</p><p>The psychologist Dedre Gentner <a href="https://groups.psych.northwestern.edu/gentner/papers/wisniewski%26Gentner_1991.pdf" target="_blank" rel="nofollow">also found</a> that the more conceptually distant two ideas are, the more creative their combination tends to be. For instance, she found that if you ask 100 people to imagine a chair combined with a table — two closely related items — most of them will picture something like a school desk. It’s an obvious match within the category of furniture. But if you asked 100 people to imagine a chair combined with a pony — very distant concepts — the results are far more varied and surprising: A chair you sit on while grooming a pony, one that a pony sits in, one shaped like a pony’s head, or one covered in fur.</p><p>Gentner calls this <em>property mapping</em> — when people borrow attributes like texture or shape from one concept and apply them to another. It’s a kind of remote association, and clearly more creative than imagining a standard school desk. But Gentner identified something even more powerful: <em>structure mapping</em>. This happens when you transfer the <em>relational structure</em> of one concept to another. Say you combine “pony” and “chair” and picture a chair shaped like a pony — that’s still property mapping, just more elaborate. But if you imagine a <em>small</em> chair, you’ve made a bigger leap. That’s structure mapping: drawing on the idea that a pony is smaller than a horse, and applying that relationship to redefine the size of a chair. These kinds of mappings — especially when the underlying relations are abstract or non-obvious — tend to produce the most original and surprising combinations.</p><p>You can strengthen your ability to make remote associations by exposing yourself to a wider variety of information, especially from conceptually different domains. Most of us stick to what we know. We don’t normally encounter distant concepts in everyday life, so stretching our minds into unfamiliar territory takes some effort.</p><hr><p>Which brings me back to obituaries. I’m not talking about the half-page write-ups of celebrities or politicians. I mean the small-print obituaries in the <em>New York Times</em> Sunday edition — the ones squeezed into eight columns on a single page, paid for by friends and family. These people aren’t famous. But their lives, described lovingly and vividly by those who knew them best, are often more surprising than any headline obituary. And they’re an ideal way to boost your creativity.</p><p>It’s important to read all of the obituaries on Sunday. If you filter your reading by only choosing people who are like you, then you won’t be absorbing the most different, surprising new information.</p><p>Here are two that I read one Sunday morning recently:</p><p><strong>Berta Escurra</strong> was born in 1924 in San Pedro de Lloc, Peru. She was a follower of British writer and spiritual thinker Rodney Collin when he moved to Mexico City in 1948. In 1963, she moved to New York City and founded the Spanish International Network (SIN) with Rene Anselmo. SIN was the first TV network in the U.S. to broadcast entirely in Spanish. Anselmo later went on to found PanAmSat, the world’s first private international satellite system.</p><p><strong>Norton Garfinkle</strong> died on March 20, 2025 at the age of 94. Garfinkle was a professor at Amherst College and a serial entrepreneur. He founded a company that detected land mines for the U.S. and foreign governments. He invented a news database search algorithm and sold it to Reuters. He developed PLAX, the first pre-brushing dental rinse. He started Electronic Retailing Systems, which provided self-checkout systems to supermarkets. He started a company that published <em>Lamaze Parent Magazine</em>.</p><p>See what I mean about being interesting? You’ve probably never heard of either of them. (I hadn’t.) But reading their stories introduces you to a mix of fields — broadcasting, aerospace, esotericism, oral hygiene, database design, prenatal publishing — that you’d rarely, if ever, encounter all in one place. It’s exactly the kind of conceptually distant material that helps fuel creative thinking.</p><figure><blockquote><p>Start by reading the obituaries slowly, without searching for a big idea.</p></blockquote></figure><p>Here’s how you can use the obituaries to enhance your creative cognition.</p><p>First, start by reading them slowly, without searching for a big idea. Let the details wash over you — the places lived, the professions practiced, the odd hobbies pursued. Notice what sticks.</p><p>It’s not just about learning new facts, of course — it’s about asking questions. Why was a British mystic in Mexico City? How did Spanish-language television evolve in the U.S.? What led someone to invent PLAX or build search tools for financial news decades before Google? Even if you don’t find all the answers, just posing the questions helps you flex the creative muscle that thrives on curiosity and connection.</p><p>Will any of the life stories you read cause you to have a surprising, creative insight? No one can say. But<strong> </strong>research shows that <em>distant analogies</em> often lead to creative breakthroughs, often in unexpected ways. What you’re doing is filling up your brain with a range of very different cognitive material.</p><p>In every person’s life story, there’s always a narrative, always a deeper principle at work. How did a woman from Peru get to Scotland, Mexico City, and then New York? How does a professor at Amherst College found so many different companies, with so many different technologies and within so many industries? Seek that deeper principle, ask “Why?”, and look for distant connections with your own life. Creativity is a daily practice available to anyone.</p><hr><p><strong><em>Keith Sawyer</em></strong><em> is one of the world’s leading creativity researchers. He has published 20 books, including “<a href="http://www.groupgenius.net/" target="_blank" rel="nofollow">Group Genius</a>,” “<a href="http://www.zigzagcreate.com/" target="_blank" rel="nofollow">Zig Zag</a>,” and, most recently, “<a href="https://mitpress.mit.edu/9780262551649/learning-to-see/" target="_blank">Learning to See</a>.” Sawyer is the Morgan Distinguished Professor in Educational Innovations at the University of North Carolina at Chapel Hill.</em></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Did 5G Kill the IMSI Catcher? (178 pts)]]></title>
            <link>https://zetier.com/5g-imsi-catcher/</link>
            <guid>43813083</guid>
            <pubDate>Sun, 27 Apr 2025 16:27:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zetier.com/5g-imsi-catcher/">https://zetier.com/5g-imsi-catcher/</a>, See on <a href="https://news.ycombinator.com/item?id=43813083">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p><img src="https://zetier.com/wp-content/uploads/2025/04/Zetier-IMSI-Catcher-Featured-Image.png" alt="/nl_img1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://zetier.com/wp-content/uploads/2025/04/Zetier-IMSI-Catcher-Featured-Image.png">
			</p>
						
			
<p>You dial into your Zoom meeting while sitting on a moving train. Your mobile device (i.e., User Equipment, UE) must seamlessly switch towers as you go in and out of range. This concept, called <strong>mobility,</strong> remains a central requirement for mobile networks, but it’s also a central security vulnerability.</p>



<p>You see, you may have just been hacked while leisurely zooming on said train – and you’d never know it.</p>



<p>The GSM (better known as 2G) protocol has <strong>a security vulnerability that exposes a user’s personal identifier (IMSI) in the clear, allowing for attribution and geolocation.</strong> This vulnerability is also in the UMTS (a.k.a. 3G) spec, and in the LTE (4G) spec. While the vulnerability was finally addressed in NR (5G), it’s imperfect and remains an exploitable 5G network vulnerability… and my favorite cybersecurity topic.</p>



<p>In this article, I’ll introduce this long-standing security exploit, known as an IMSI catcher, discuss some high-level technical aspects regarding 2G–4G IMSI catchers, then finish with 5G security improvements and the possibility of 5G IMSI catchers.</p>











<h2 id="h-what-is-an-imsi">What is an IMSI?</h2>



<p>Every account on a cellular network has a unique identifier to connect a SIM card to a credit card, and that identifier is called the International Mobile Subscriber Identity (IMSI, pronounced “IM-zee”). This number contains 3 pieces of information: the Mobile Country Code (MCC) of the issuing network operator, the Mobile Network Code (MNC) of the issuing network operator, and a unique number that only exists for that SIM card. The IMSI is ultimately used to make sure you paid your bill and that you’re allowed to register onto a network.</p>











<h2 id="h-what-is-an-imsi-catcher">What is an IMSI catcher?</h2>



<p>An IMSI catcher is a tool that collects cellular signals and decodes packets to access and save off the IMSI. There are two types of IMSI catchers: <strong>active and passive.</strong></p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="750" height="428" data-attachment-id="4960" data-permalink="https://zetier.com/zetier-active-imsi-catcher/" data-orig-file="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?fit=1792%2C1024&amp;ssl=1" data-orig-size="1792,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zetier-Active-IMSI-Catcher" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?fit=750%2C428&amp;ssl=1" src="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=750%2C428&amp;ssl=1" alt="Diagram showing a person with a cell phone that's interacting with an IMSI catcher because it has a stronger signal than a nearby 5G cell tower. So, the IMSI catcher is directly catching the phone's IMSI. This illustrates Active IMSI Catching." srcset="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=1024%2C585&amp;ssl=1 1024w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=150%2C86&amp;ssl=1 150w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=768%2C439&amp;ssl=1 768w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=1536%2C878&amp;ssl=1 1536w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=1568%2C896&amp;ssl=1 1568w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?w=1792&amp;ssl=1 1792w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20428'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=1024%2C585&amp;ssl=1 1024w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=150%2C86&amp;ssl=1 150w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=768%2C439&amp;ssl=1 768w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=1536%2C878&amp;ssl=1 1536w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=1568%2C896&amp;ssl=1 1568w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?w=1792&amp;ssl=1 1792w" data-lazy-src="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Active-IMSI-Catcher.png?resize=750%2C428&amp;ssl=1"></figure>



<h3 id="h-active-imsi-catcher">Active IMSI Catcher</h3>



<p>Also known as a cell station simulator or rogue base station, an active IMSI catcher is the more effective of the two. The downside is that it requires RF transmission, which violates FCC laws (and international equivalents) and is detectable.</p>











<figure><img data-recalc-dims="1" decoding="async" width="750" height="428" data-attachment-id="4962" data-permalink="https://zetier.com/zetier-passive-imsi-catcher/" data-orig-file="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?fit=1792%2C1024&amp;ssl=1" data-orig-size="1792,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zetier-Passive-IMSI-Catcher" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?fit=750%2C428&amp;ssl=1" src="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=750%2C428&amp;ssl=1" alt="Diagram showing a person with a cell phone that's interacting with a 5G tower, and the IMSI catcher is listening in, and thus catching the phone's IMSI. This illustrates Passive IMSI Catching." srcset="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=1024%2C585&amp;ssl=1 1024w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=150%2C86&amp;ssl=1 150w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=768%2C439&amp;ssl=1 768w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=1536%2C878&amp;ssl=1 1536w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=1568%2C896&amp;ssl=1 1568w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?w=1792&amp;ssl=1 1792w" sizes="(max-width: 750px) 100vw, 750px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20428'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=1024%2C585&amp;ssl=1 1024w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=150%2C86&amp;ssl=1 150w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=768%2C439&amp;ssl=1 768w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=1536%2C878&amp;ssl=1 1536w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=1568%2C896&amp;ssl=1 1568w, https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?w=1792&amp;ssl=1 1792w" data-lazy-src="https://i0.wp.com/zetier.com/wp-content/uploads/2025/04/Zetier-Passive-IMSI-Catcher.png?resize=750%2C428&amp;ssl=1"></figure>



<h3 id="h-passive-imsi-catcher">Passive IMSI Catcher</h3>



<p>This type requires a lot more planning and may not yield as many IMSIs. However, it’s undetectable (from an RF perspective) and reflects a true account of the network without interference.</p>



<p>To use an analogy, <strong>active</strong> IMSI catchers are like standing outside of the grocery store with an official-looking outfit and asking for people’s licenses to write down the number; it may work until someone with a badge shows up. </p>



<p>On the other hand, <strong>passive</strong> IMSI catchers are like sitting behind the one-way glass by the checkout counter and taking a photo of everyone’s licenses when they open their wallets – difficult to detect and not illegal because it’s in plain sight (probably… I’m not a lawyer and this isn’t legal advice).</p>











<h2 id="h-how-does-an-imsi-catcher-work">How does an IMSI catcher work?</h2>



<p><em>(NB: The remainder of this article refers exclusively to passive IMSI catchers.) </em></p>



<p>A UE (User Equipment, like your smartphone) is constantly performing selection, reselection, and registration procedures to maintain mobility and access to the cellular network. These processes are extremely complicated at the technical level, yet conceptually they’re very simple.</p>



<ol>
<li>After selecting a cell tower, based on measurements and control information, the UE sends a request to attach to a cell tower.</li>



<li>If the UE is allowed to attach, the cell tower and UE go back and forth a few times to negotiate some parameters, finalizing with the UE sending its IMSI.</li>



<li>The cell tower starts a new back-and-forth with the network to establish whether or not the IMSI is valid, active, and paid.</li>



<li>If the UE is allowed on the network, the cell tower initiates the authentication process, and everything from here on out is encrypted.</li>
</ol>



<p>This would be the end of the story, were it not for mobility. Again, mobility is a feature, as well as a network vulnerability. Every time the UE switches to another tower, it must repeat the registration process. (Ok, not EVERY time, but every time that the UE is in IDLE mode, which is most of the time. Handover is a whole other discussion.)</p>



<p>To minimize the number of times a UE registers using an unencrypted IMSI, the network issues a Temporary Mobile Subscriber Identity (TMSI, pronounced “TIM-zee”). The TMSI is issued over an encrypted connection and associated with the IMSI on the network side. For the sake of this article, we’ll consider the TMSI to be an unexploitable solution (…it’s not).</p>



<p>There are 3 ways to catch an IMSI: </p>



<p>LOCATION, LOCATION, LOCATION! </p>



<p>As mentioned earlier, the technical aspects of developing a passive IMSI catcher are complicated. (If you’re interested in this topic, send an email to <a href="mailto:hello@zetier.com" target="_blank" rel="noreferrer noopener">hello@zetier.com</a>.) The simplified explanation is this: sometimes phones send IMSIs in cleartext, and if you’re collecting at the right place and right time, you’ll catch them. Conversely, even if you have the perfect IMSI catcher, but you’re in the wrong location, you’ll never catch an IMSI.</p>











<h2 id="h-so-where-do-you-catch-an-imsi">So, where do you catch an IMSI?</h2>



<p>In the 2G and 3G protocols, IMSIs are sent in the clear under 3 conditions:</p>



<ol>
<li>Initial attach</li>



<li>Crossing a Location Area Code (LAC) boundary <em>(NB: Depending on the system configuration, TMSIs can be shared between LACs)</em></li>



<li>Location Update Request (LUR)</li>
</ol>



<p>In addition, these protocols utilize spectrum around the downlink center frequency for Radio Resource Control (RRC), meaning a radio only needs to tune to a single frequency to get the downlink and uplink for these particular messages – which is very convenient. However, my favorite thing about the ever-dwindling 2G/3G towers is that the initial attach procedure includes inter-RAT (<a href="https://en.wikipedia.org/wiki/Radio_access_technology" target="_blank" rel="noreferrer noopener">Radio Access Technology</a>) reselection. This means you can grab an IMSI in any LTE dead zone where a UE falls back to 2G or 3G.</p>



<p>4G is much less convenient: the uplink and downlink channels are necessary, and they must be partially synchronized. This is ultimately a technical issue that can be overcome with computing power. Furthermore, the initial attach is really the only viable option for reliably grabbing IMSIs, yet it’s extremely unreliable. 4G IMSIs can be found on PLMN borders (e.g., country borders, airports, roaming boundaries) and older RAT borders (e.g., reselection boundaries from 2G or 3G towers). If 4G/LTE piques your curiosity, you may want to explore the <a href="https://www.usenix.org/conference/usenixsecurity22/presentation/kotuliak" target="_blank" rel="noreferrer noopener">IMSI extractor.</a></p>



<p><strong>5G has finally addressed the cleartext IMSI network vulnerability.</strong> The IMSI is now called the Subscription Permanent Identifier (SUPI, pronounced “SOUP-ee”), and the unique identifier portion is encrypted using public key cryptography to create the Subscription Concealed Identifier (SUCI, pronounced “SU-shi”). </p>



<p>Together, the 5G SUPI and SUCI sufficiently solve the 5G network vulnerability: the SUCI is transmitted in the clear (instead of the 5G SUPI), yet the SUCI isn’t useful for identification or geolocation.</p>











<h2 id="h-so-that-s-it-imsi-catchers-are-dead">So that’s it? IMSI catchers are dead?</h2>



<p>From a purely academic stance, perhaps IMSI catchers have become impractical on fully patched, full-featured, network-wide 5G deployments. But such <strong>perfection remains extremely unlikely, and I expect to see several opportunities:</strong></p>



<ol>
<li>5G is a multi-stage rollout, and any 5G Non-Standalone (NSA) deployments have all of the same vulnerabilities as 4G!</li>



<li>Downgrading from 5G to 4G supports handover (i.e., the TMSI is passed between RATs), but I’ve seen so many misconfigured towers over the years that I’d assume a downgrade to be vulnerable.</li>



<li>Mobile carriers may also not use the SUCI at all. I’m not sure how prevalent this vulnerability is in the wild, but I believe it’s non-zero.</li>
</ol>











<h2 id="h-how-to-block-an-imsi-catcher">How to block an IMSI catcher</h2>



<p>There’s no way to block an IMSI catcher. The only simple thing you can do, that can have an effect, is to set your network priority to 5G-SA – but most phones don’t support this feature. </p>



<p>If you’re really paranoid, stay in airplane mode until you’re in a very dense coverage area. While this is far from a guarantee, IMSI catchers are more likely to be sitting in areas with compromised signal quality. </p>



<p>Finally, you can keep your phone in a Faraday bag, which can provide up to 100 dB of signal attenuation.</p>











<h2 id="h-there-s-always-something">There’s always something</h2>



<p>Cellular mobility will always have intrinsic vulnerabilities. The 3GPP 5G-NR spec has been a huge improvement against attribution attacks, which is definitely good for users. As for CNE developers, it has shifted the problem from technical to geographical. Active IMSI catchers and active jamming remain viable options, but they come with the same risks as always. On the bright side, there’s still work to be done – and it’s very fun work!</p>



<p>If you’re interested in this space, feel free to <a href="mailto:hello@zetier.com" target="_blank" rel="noreferrer noopener">reach out</a> – or explore our OSS in the cellular space: <a href="https://zetier.com/android-testing-with-bungeegum/" target="_blank" rel="noreferrer noopener">Bungeegum</a>, our free Android testing tool for simulating real-world conditions, and <a href="https://zetier.com/android-testing-with-lariat/" target="_blank" rel="noreferrer noopener">Lariat</a>, another open-source testing tool for wrangling the wide range of Android devices – both developed in-house at Zetier.</p>







<p><em>Illustrations by Rebecca DeField.</em></p>







<h3 id="h-thought-this-was-an-intriguing-read">Thought this was an intriguing read?</h3>



<p><strong><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fzetier.com%2F5g-imsi-catcher%2F&amp;t=Did%205G%20kill%20the%20IMSI%20catcher%3F%20A%20primer%20on%20one%20of%20the%20oldest%20cellular%20vulnerabilities" target="_blank" rel="noreferrer noopener">Share on HackerNews →</a></strong></p>




					
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Libogc (Wii homebrew library) discovered to contain code stolen from RTEMS (161 pts)]]></title>
            <link>https://github.com/fail0verflow/hbc/blob/80a80251f83f1993c272c58e471d040f3eb1dee9/README.md</link>
            <guid>43812995</guid>
            <pubDate>Sun, 27 Apr 2025 16:18:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/fail0verflow/hbc/blob/80a80251f83f1993c272c58e471d040f3eb1dee9/README.md">https://github.com/fail0verflow/hbc/blob/80a80251f83f1993c272c58e471d040f3eb1dee9/README.md</a>, See on <a href="https://news.ycombinator.com/item?id=43812995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ARCHIVED</h2><a id="user-content-archived" aria-label="Permalink: ARCHIVED" href="#archived"></a></p>
<p dir="auto">This repository is archived and will not accept any further contributions.</p>
<p dir="auto">Like most Wii homebrew software, this software depends on <a href="https://github.com/devkitPro/libogc">libogc</a>.
After development of The Homebrew Channel had already started, we discovered that large portions of libogc
were stolen directly from the Nintendo SDK or games using the Nintendo SDK (decompiled and cleaned up).
We thought that at least significant parts of libogc, such as its threading implementation, were original,
and reluctantly continued to use the project while distancing ourselves from it.</p>
<p dir="auto">It has recently been revealed that the threading/OS implementation in libogc is, in fact,
<a href="https://github.com/derek57/libogc">stolen from RTEMS</a>. The authors of libogc didn't just steal proprietary
Nintendo code, but also saw it fit to steal an <em>open source</em> RTOS and remove all attribution and copyright
information. This goes far beyond ignorance about the copyright implications of reverse engineering Nintendo
binaries, and goes straight into outright deliberate, malicious code theft and copyright infringement.</p>
<p dir="auto">The current developers of libogc are <a href="https://github.com/devkitPro/libogc/issues/201">not interested</a> in
tracking this issue, finding a solution, nor informing the community of the problematic copyright status of
the project. When we filed an issue about it, they immediately closed it, replied with verbal abuse, and then
completely deleted it from public view.</p>
<p dir="auto">For this reason, we consider it impossible to legally and legitimately compile this software at this point,
and cannot encourage any further development.</p>
<p dir="auto">The Wii homebrew community was all built on top of a pile of lies and copyright infringement, and it's all
thanks to shagkur (who did the stealing) and the rest of the team (who enabled it and did nothing when it was discovered). Together, the developers deceived everyone into believing their work was original.</p>
<p dir="auto">Please demand that the leaders and major contributors to console or other proprietary device SDKs and
toolkits that you use and work with do things legally, and do not tolerate this kind of behavior.</p>
<p dir="auto">If you wish to check for yourself, for example, you can compare
<a href="https://github.com/devkitPro/libogc/blob/52c525a13fd1762c10395c78875e3260f94368b5/libogc/lwp_threads.c#L580">this</a>
function in libogc to
<a href="https://github.com/atgreen/RTEMS/blob/2f200c7e642c214accb7cc6bd7f0f1784deec833/c/src/exec/score/src/thread.c#L385">this</a>
function in a really old version of RTEMS. While the code has been simplified and many identifiers renamed, it
is clear that the libogc version is a direct descendant of the RTEMS version. It is not possible for two code
implementations to end up this similar purely by chance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Homebrew Channel</h2><a id="user-content-the-homebrew-channel" aria-label="Permalink: The Homebrew Channel" href="#the-homebrew-channel"></a></p>
<p dir="auto">This repository contains the public release of the source code for
The Homebrew Channel.</p>
<p dir="auto">Included portions:</p>
<ul dir="auto">
<li>The Homebrew Channel</li>
<li>Reload stub</li>
<li>Banner</li>
<li>PyWii (includes Alameda for banner creation)</li>
<li>WiiPAX (LZMA executable packer)</li>
</ul>
<p dir="auto">Not included:</p>
<ul dir="auto">
<li>Installer</li>
</ul>
<p dir="auto">Note that the code in this repository differs from the source code used to build
the official version of The Homebrew Channel, which includes additional
protection features (i.e. we had to add reverse-DRM to stop scammers from
selling it).</p>
<p dir="auto">This code is released with no warranty, and hasn't even been tested on a real
Wii, only under Dolphin (yes, this release runs under Dolphin).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build instructions</h2><a id="user-content-build-instructions" aria-label="Permalink: Build instructions" href="#build-instructions"></a></p>
<p dir="auto">You need devkitPPC and libogc installed, and the DEVKITPRO/DEVKITPPC environment
variables correctly set. Use the latest available versions. Make sure you have
libogc/libfat, and also install the following 3rd party libraries:</p>
<ul dir="auto">
<li>zlib</li>
<li>libpng</li>
<li>mxml</li>
<li>freetype</li>
</ul>
<p dir="auto">You can obtain binaries of those with
<a href="https://devkitpro.org/wiki/devkitPro_pacman" rel="nofollow">devkitPro pacman</a>. Simply use</p>
<div data-snippet-clipboard-copy-content="sudo (dkp-)pacman -S ppc-zlib ppc-libpng ppc-mxml ppc-freetype"><pre><code>sudo (dkp-)pacman -S ppc-zlib ppc-libpng ppc-mxml ppc-freetype
</code></pre></div>
<p dir="auto">Additionally, you'll need the following packages on your host machine:</p>
<ul dir="auto">
<li>pycryptodomex (for PyWii)</li>
<li>libpng headers (libpng-dev)</li>
<li>gettext</li>
<li>sox</li>
</ul>
<p dir="auto">The build process has only been tested on Linux. You're on your own if you
want to try building this on OSX or Windows.</p>
<p dir="auto">You'll need the Wii common key installed as ~/.wii/common-key.</p>
<p dir="auto">First run 'make' in wiipax, then 'make' in channel. You'll find a .wad file
that you can install or directly run with Dolphin under
channel/title/channel_retail.wad. You'll also find executable binaries under
channel/channelapp, but be advised that the NAND save file / theme storage
features won't work properly if HBC isn't launched as a channel with its
correct title identity/permissions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Unless otherwise noted in an individual file header, all source code in this
repository is released under the terms of the GNU General Public License,
version 2 or later. The full text of the license can be found in the COPYING
file.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Virginia passes law to enforce maximum vehicle speeds for repeat speeders (128 pts)]]></title>
            <link>https://www.fastcompany.com/91323835/virginia-will-use-technology-to-slow-chronic-speeders-cars-and-other-states-are-rushing-to-join-in</link>
            <guid>43812856</guid>
            <pubDate>Sun, 27 Apr 2025 16:02:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastcompany.com/91323835/virginia-will-use-technology-to-slow-chronic-speeders-cars-and-other-states-are-rushing-to-join-in">https://www.fastcompany.com/91323835/virginia-will-use-technology-to-slow-chronic-speeders-cars-and-other-states-are-rushing-to-join-in</a>, See on <a href="https://news.ycombinator.com/item?id=43812856">Hacker News</a></p>
Couldn't get https://www.fastcompany.com/91323835/virginia-will-use-technology-to-slow-chronic-speeders-cars-and-other-states-are-rushing-to-join-in: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[TmuxAI: AI-Powered, Non-Intrusive Terminal Assistant (132 pts)]]></title>
            <link>https://tmuxai.dev/</link>
            <guid>43812646</guid>
            <pubDate>Sun, 27 Apr 2025 15:35:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tmuxai.dev/">https://tmuxai.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=43812646">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-f73bbfd7="" id="__nuxt"><header data-v-f73bbfd7="" data-v-93af87f7=""></header><div data-v-f73bbfd7=""><div data-v-f73bbfd7=""><p> BORING DYSTOPIA DEVELOPMENT </p><p data-v-f73bbfd7=""> TmuxAI is a non-intrusive terminal assistant that works alongside you in a tmux window. TmuxAI's design philosophy mirrors the way humans collaborate at the terminal. Just as a colleague sitting next to you, TmuxAI observes your screen, understand context from what's visible, and helps accordingly. </p><div data-v-f73bbfd7=""><p data-v-f73bbfd7=""><span data-v-f73bbfd7="">curl</span><span data-v-f73bbfd7=""> -fsSL </span><span data-v-f73bbfd7="">https://get.tmuxai.dev</span><span data-v-f73bbfd7=""> | </span><span data-v-f73bbfd7="">bash</span></p></div></div><div data-v-f73bbfd7=""><p><span data-v-f73bbfd7="">$</span><span data-v-f73bbfd7="">tmuxai find large files and cleanup some space</span></p><p><span data-v-f73bbfd7="">TmuxAI</span> <span data-v-f73bbfd7="">»</span> I'll help you find large files taking up space in this directory. </p><p><span data-v-f73bbfd7="">TmuxAI</span> <span data-v-f73bbfd7="">»</span> <span data-v-f73bbfd7="">find . -type f -size +100M -exec du -h {} \; | sort -rh | head -5</span></p><p><span data-v-f73bbfd7="">Do you want to execute this command? </span><span data-v-f73bbfd7="">[Y]es/No/Edit:</span></p><p><span data-v-f73bbfd7="">TmuxAI</span> <span data-v-f73bbfd7="">»</span> Found several large files in node_modules and logs directories. </p><p><span data-v-f73bbfd7="">TmuxAI</span> <span data-v-f73bbfd7="">»</span> <span data-v-f73bbfd7="">rm -i ./logs/debug-*.log</span></p><p><span data-v-f73bbfd7="">Do you want to execute this command? </span><span data-v-f73bbfd7="">[Y]es/No/Edit: </span><span data-v-f73bbfd7="">_</span></p></div></div><div data-v-f73bbfd7="" id="features"><h3 data-v-f73bbfd7=""><span data-v-f73bbfd7="">01</span> FEATURES <span data-v-f73bbfd7=""></span></h3><div data-v-f73bbfd7=""><div data-v-f73bbfd7=""><div data-v-f73bbfd7=""><p>CONTEXT-AWARE TERMINAL ASSISTANCE</p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" data-v-f73bbfd7=""><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" color="currentColor" data-v-f73bbfd7=""><path d="m7.5 14.5l1.842-5.526a.694.694 0 0 1 1.316 0L12.5 14.5m3-6v6m-7-2h3" data-v-f73bbfd7=""></path><path d="M21.011 14.097c.522-.141.783-.212.886-.346c.103-.135.103-.351.103-.784v-1.934c0-.433 0-.65-.103-.784s-.364-.205-.886-.345c-1.95-.526-3.171-2.565-2.668-4.503c.139-.533.208-.8.142-.956s-.256-.264-.635-.479l-1.725-.98c-.372-.21-.558-.316-.725-.294s-.356.21-.733.587c-1.459 1.455-3.873 1.455-5.333 0c-.377-.376-.565-.564-.732-.587c-.167-.022-.353.083-.725.295l-1.725.979c-.38.215-.57.323-.635.48c-.066.155.003.422.141.955c.503 1.938-.718 3.977-2.669 4.503c-.522.14-.783.21-.886.345S2 10.6 2 11.033v1.934c0 .433 0 .65.103.784s.364.205.886.346c1.95.526 3.171 2.565 2.668 4.502c-.139.533-.208.8-.142.956s.256.264.635.48l1.725.978c.372.212.558.317.725.295s.356-.21.733-.587c1.46-1.457 3.876-1.457 5.336 0c.377.376.565.564.732.587c.167.022.353-.083.726-.295l1.724-.979c.38-.215.57-.323.635-.48s-.003-.422-.141-.955c-.504-1.937.716-3.976 2.666-4.502" data-v-f73bbfd7=""></path></g></svg></div><p data-v-f73bbfd7=""> TmuxAI reads and understands what's displayed across all your terminal panes in real-time, providing intelligent help based on what you're actually working on. </p></div><div data-v-f73bbfd7=""><p data-v-f73bbfd7=""> Works instantly with your existing tmux setup without requiring special shells, wrappers, or terminal emulators. Just install and run. </p></div><div data-v-f73bbfd7=""><div data-v-f73bbfd7=""><p>UNIVERSAL TERMINAL COMPATIBILITY</p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 14" data-v-f73bbfd7=""><path fill="currentColor" fill-rule="evenodd" d="M9.721.657c.186-.846 1.39-.851 1.582-.007l.01.04l.018.08a2.48 2.48 0 0 0 1.992 1.879c.881.153.881 1.42 0 1.573a2.48 2.48 0 0 0-1.996 1.894l-.024.105c-.192.844-1.396.839-1.582-.007l-.02-.09c-.214-.98-1-1.732-1.987-1.904c-.88-.153-.88-1.417 0-1.57A2.47 2.47 0 0 0 9.7.757l.015-.066zM1.766 2.48h4.39c-.57 1.05-.115 2.6 1.364 2.857c.486.085.882.43 1.036.893h-7.04v6c0 .138.112.25.25.25h9a.25.25 0 0 0 .25-.25V7.923c.644-.163 1.21-.646 1.394-1.45l.024-.106a1.4 1.4 0 0 1 .082-.247v6.11a1.75 1.75 0 0 1-1.75 1.75h-9a1.75 1.75 0 0 1-1.75-1.75v-8c0-.967.784-1.75 1.75-1.75m.963 4.836a.625.625 0 0 1 .884 0l1.5 1.5a.625.625 0 0 1 0 .884l-1.5 1.5a.625.625 0 1 1-.884-.884L3.787 9.26L2.73 8.201a.625.625 0 0 1 0-.884Zm2.817 3.442c0-.345.28-.625.625-.625h1.5a.625.625 0 1 1 0 1.25h-1.5a.625.625 0 0 1-.625-.625" clip-rule="evenodd" data-v-f73bbfd7=""></path></svg></div><p data-v-f73bbfd7=""> Works with nested shells, SSH connections, database CLIs, network equipment shells (Cisco IOS, Juniper, etc), and any other text-based terminal interface. </p></div><div data-v-f73bbfd7=""><p data-v-f73bbfd7=""> Enhances command tracking with custom shell prompts that provide exact command completion detection and exit code awareness for more accurate assistance. </p></div><div data-v-f73bbfd7=""><p data-v-f73bbfd7=""> Transforms TmuxAI into a proactive assistant that monitors your terminal activity and offers improvements or explanations based on your specified goals. </p></div><div data-v-f73bbfd7=""><p data-v-f73bbfd7=""> Available as open source software. Use TmuxAI for free and adapt it to your workflow. </p></div></div></div><div data-v-b19bab3b="" id="getting-started" data-v-f73bbfd7=""><h3 data-v-b19bab3b=""><span data-v-b19bab3b="">02</span> DEMO <span data-v-b19bab3b=""></span></h3><div data-v-b19bab3b=""><div data-v-b19bab3b=""><p>CHAT PANE </p><div data-v-b19bab3b=""><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span><span data-v-b19bab3b="">start docker container mysql and then connect to mysql shell.</span></p><p> First I'll start the container: </p><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span><span data-v-b19bab3b="">docker run --name mysql_container -e MYSQL_ROOT_PASSWORD=password -d mysql:latest</span></p><p> Do you want to execute this command? <span data-v-b19bab3b="">[Y]es/No/Edit:</span></p><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span> Now I will connect to the mysql shell. </p><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span><span data-v-b19bab3b="">docker exec -it mysql_container mysql -u root -p</span></p><p> Do you want to execute this command? <span data-v-b19bab3b="">[Y]es/No/Edit:</span></p><div data-v-b19bab3b=""><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span> I'll now send the password to the mysql shell. </p><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span><span data-v-b19bab3b="">Sending keys: password</span></p><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span><span data-v-b19bab3b="">Sending keys: Enter</span></p></div><p><span data-v-b19bab3b="">TmuxAI</span><span data-v-b19bab3b="">»</span> I've successfully connected to the MySQL shell. </p></div></div><div data-v-b19bab3b=""><p>EXEC PANE </p><div data-v-b19bab3b=""><p> $ docker run --name mysql_container -e MYSQL_ROOT_PASSWORD=password -d mysql:latest </p><p> 6d76ba47b7f </p><p> $ docker exec -it mysql_container mysql -u root -p </p><p> Enter password: </p><p> Welcome to the MySQL monitor. Commands end with ; or \g. </p><p> Your MySQL connection id is 9 </p><p> Server version: 8.2.0 MySQL Community Server - GPL </p><p> Copyright (c) 2000, 2023, Oracle and/or its affiliates. </p><p> Oracle is a registered trademark of Oracle Corporation and/or its </p><p> affiliates. Other names may be trademarks of their respective </p><p> owners. </p><p> Type 'help;' or '\h' for help. Type '\c' to clear the current input statement. </p><p> mysql&gt; </p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The coming knowledge-work supply-chain crisis (150 pts)]]></title>
            <link>https://worksonmymachine.substack.com/p/the-coming-knowledge-work-supply</link>
            <guid>43812459</guid>
            <pubDate>Sun, 27 Apr 2025 15:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worksonmymachine.substack.com/p/the-coming-knowledge-work-supply">https://worksonmymachine.substack.com/p/the-coming-knowledge-work-supply</a>, See on <a href="https://news.ycombinator.com/item?id=43812459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png" width="1456" height="813" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:813,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6023513,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://worksonmymachine.substack.com/i/162257174?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd433d925-82af-4d6a-9b3b-847069a0adf6_2752x1536.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Remember the first time an autocomplete suggestion nailed exactly what you meant to type? Multiply that by a thousand and aim it at every task you once called “work.” AI is scaling the creation side of knowledge work at an exponential rate, but our decision-making tools and rituals remain stuck in the past. The imbalance creates bottlenecks in everything from code reviews to roadmapping and everything in between. Before we drown in our own todo queues, we need to rethink the entire production-to-judgment pipeline.</p><p>Over the past few months, I’ve shared various experiments where AI dramatically accelerates production tasks:</p><ul><li><p><a href="https://worksonmymachine.substack.com/p/a-vibe-code-to-user-stories-pipeline" rel="">Generating user stories from prototypes</a></p></li><li><p><a href="https://worksonmymachine.substack.com/p/automating-test-generation-with-gemini" rel="">Creating integration tests from user stories</a></p></li><li><p><a href="https://worksonmymachine.substack.com/p/fanoutparallelizereduce-refactoring" rel="">Breaking down a big refactoring into bite-sized tasks for an AI to do</a></p></li><li><p><a href="https://worksonmymachine.substack.com/p/ai-programs-while-i-sleep-using-github" rel="">Autonomously developing new features overnight</a></p></li><li><p><a href="https://worksonmymachine.substack.com/p/wasting-inferences-with-aider" rel="">Implementing complete features and tests directly from user stories</a></p></li></ul><p>There’s one common theme here: AI excels at production but always ends up with humans as a critical bottleneck dealing with a mountain of tasks to evaluate, approve, or modify what it creates.</p><p><span>This pile of tasks is how I understand what Vaughn Tan refers to as </span><a href="https://uncertaintymindset.substack.com/p/ai-meaningmaking" rel="">Meaningmaking</a><span>: the uniquely human ability to make subjective decisions about the relative value of things. He argues this type of value judgement is something AI fundamentally cannot do, as it can only pattern match against existing decisions, not create new frameworks for assigning worth.</span></p><p>When an AI generates 10 pull requests overnight, a human needs to decide which ones are worth merging, which need modification, and which should be rejected entirely. This isn’t just about checking if the code works (which you still need to do!), it’s also about making judgement calls on whether the changes align with the project’s goals, whether they solve the right problems, and whether they will be maintainable long-term. </p><p>Ok, calling this a “crisis” may be a bit hyperbolic, but we can already see at least two problems emerging. </p><p><span>First, Rohit Krishnan points out in </span><a href="https://www.strangeloopcanon.com/p/when-we-become-cogs" rel="">When We Become Cogs</a><span> that working with AI effectively leads to less job satisfaction. An MIT study found materials scientists experienced a 44% drop in job satisfaction when AI automated 57% of their “idea-generation” tasks — precisely the creative work they most enjoyed.  This is similar to the direction that software development is going - as AI gets better at generating code, more and more of the work of a software engineer will turn into PR review and less of the aspects of creative problem-solving that drew many of them to the field.</span></p><p><span>Second, you may have realized while watching some of my demos that our tools aren’t designed for the volume of work AI can generate. In </span><a href="https://worksonmymachine.substack.com/p/ai-programs-while-i-sleep-using-github" rel="">AI Programs While I Sleep,</a><span> you can see that I am already underwater with hundreds of AI-generated PRs to review. Our code review tools are designed for reviewing at most 5-10 PRs a day, not 50. You can also see a similar pattern emerge in the other videos having to do with managing user stories, doing product acceptance, and test case validation. Our tools are designed for orders of magnitude less work. </span></p><p>These two problems compound each other. Just as the tools knowledge workers use for evaluation and judgment (the “meaningmaking” work) start to break under the weight of more tasks than they are designed for, the tasks themselves are becoming much less rewarding. The result? Work piles up in review queues, decisions get rushed or postponed, and we’re no better off than before adding AI tools into our process.</p><p>This raises some big questions:</p><ul><li><p>How might we design tools to enhance decision-making velocity?</p></li><li><p>What would code review look like if optimized for 50 PRs daily instead of 5?</p></li><li><p>Which skills become premium when humans focus on judgement rather than production?</p></li><li><p>Can we find job satisfaction in a majorly reviewer or “decider” role?</p></li></ul><p>Our current evaluation tools were designed for an era of scarcity - when human effort was the limiting factor in production. In an era of AI-driven abundance, we need systems built around human cognitive limitations. </p><p>The meta-challenge here is that we’re using tools optimized for the constraint of yesterday (production capacity) while facing a completely different constraint today (judgement capacity). The organizations that thrive will be those that recognize this fundamental shift and redesign their workflows accordingly.</p><p>For those familiar with John Boyd’s OODA loop (Observe, Orient, Decide, Act), there’s a parallel. AI is increasingly handling the “Orient” and “Act” phases — the creative synthesis and execution that many knowledge workers found most satisfying. What remains are the “Observe” and “Decide” phases - the evaluation and judgment work that our tools and processes aren’t optimized for.</p><p>We must reimagine knowledge work as a high-velocity decision-making operation rather than a creative production process. Without new tools and frameworks, humans will become overwheLLMed judges in a court where AI generates more cases than could ever be heard.</p><p>Ultimately, I don’t see AI completely replacing knowledge workers any time soon. What I see happening is us not being prepared for how AI transforms the nature of knowledge work and us having a very painful and slow transition into this new era.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We're building a dystopia just to make people click on ads [video] (272 pts)]]></title>
            <link>https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads</link>
            <guid>43812379</guid>
            <pubDate>Sun, 27 Apr 2025 14:56:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads">https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads</a>, See on <a href="https://news.ycombinator.com/item?id=43812379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Newsletters</p><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_1694_78433)"><path fill-rule="evenodd" clip-rule="evenodd" d="M4 4.75C3.31421 4.75 2.75 5.31421 2.75 6V18C2.75 18.6858 3.31421 19.25 4 19.25H20C20.6858 19.25 21.25 18.6858 21.25 18V6C21.25 5.31421 20.6858 4.75 20 4.75H4ZM1.25 6C1.25 4.48579 2.48579 3.25 4 3.25H20C21.5142 3.25 22.75 4.48579 22.75 6V18C22.75 19.5142 21.5142 20.75 20 20.75H4C2.48579 20.75 1.25 19.5142 1.25 18V6Z" fill="#B5B5B5"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.38564 5.56991C1.62318 5.23057 2.09082 5.14804 2.43016 5.38558L12.0001 12.0845L21.57 5.38558C21.9093 5.14804 22.377 5.23057 22.6145 5.56991C22.852 5.90924 22.7695 6.37689 22.4302 6.61443L12.4302 13.6144C12.1719 13.7952 11.8282 13.7952 11.57 13.6144L1.56997 6.61443C1.23063 6.37689 1.1481 5.90924 1.38564 5.56991Z" fill="#B5B5B5"></path></g><defs><clipPath id="clip0_1694_78433"><rect width="24" height="24" fill="white"></rect></clipPath></defs></svg><p>Get the latest talks</p></div><p>Get a daily email featuring the latest talk, plus a quick mix of trending content.</p><form></form><div><p>By subscribing, you understand and agree that we will store, process and manage your personal information according to our</p><!-- --> <p><a href="https://www.ted.com/about/our-organization/our-policies-terms/privacy-policy">Privacy Policy</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse Geocoding Is Hard (196 pts)]]></title>
            <link>https://shkspr.mobi/blog/2025/04/reverse-geocoding-is-hard/</link>
            <guid>43812323</guid>
            <pubDate>Sun, 27 Apr 2025 14:45:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shkspr.mobi/blog/2025/04/reverse-geocoding-is-hard/">https://shkspr.mobi/blog/2025/04/reverse-geocoding-is-hard/</a>, See on <a href="https://news.ycombinator.com/item?id=43812323">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Wikipedia: Database Download (192 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Wikipedia:Database_download</link>
            <guid>43811732</guid>
            <pubDate>Sun, 27 Apr 2025 13:21:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Wikipedia:Database_download">https://en.wikipedia.org/wiki/Wikipedia:Database_download</a>, See on <a href="https://news.ycombinator.com/item?id=43811732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en" dir="ltr" id="mw-content-text">


<p>Not to be confused with <a href="https://en.wikipedia.org/wiki/Wikipedia:DDD" title="Wikipedia:DDD">WP:DDD</a>.</p>


<p>Wikipedia offers free copies of all available content to interested users. These databases can be used for <a href="https://en.wikipedia.org/wiki/Wikipedia:Mirrors_and_forks" title="Wikipedia:Mirrors and forks">mirroring</a>, personal use, informal backups, offline use or database queries (such as for <a href="https://en.wikipedia.org/wiki/Wikipedia:Maintenance" title="Wikipedia:Maintenance">Wikipedia:Maintenance</a>). All text content is licensed under the <a href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License" title="Wikipedia:Text of the Creative Commons Attribution-ShareAlike 4.0 International License">Creative Commons Attribution-ShareAlike 4.0 License</a> (CC-BY-SA), and most is additionally licensed under the <a href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a> (GFDL).<sup id="cite_ref-1"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup> Images and other files are available under <a href="https://en.wikipedia.org/wiki/Wikipedia:Image_copyright_tags" title="Wikipedia:Image copyright tags">different terms</a>, as detailed on their description pages. For our advice about complying with these licenses, see <a href="https://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Wikipedia:Copyrights</a>.
</p>
<meta property="mw:PageProp/toc">
<p><h2 id="Offline_Wikipedia_readers" data-mw-thread-id="h-Offline_Wikipedia_readers"><span data-mw-comment-start="" id="h-Offline_Wikipedia_readers"></span>Offline Wikipedia readers<span data-mw-comment-end="h-Offline_Wikipedia_readers"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Offline_Wikipedia_readers","replies":[]}}--></p>
<p>Some of the many ways to read Wikipedia while offline:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Kiwix" title="Kiwix">Kiwix</a>: (<a href="#Kiwix">§&nbsp;Kiwix</a>)&nbsp;– <a rel="nofollow" href="https://library.kiwix.org/#lang=eng">index of images</a> (2024)</li>
<li><a href="https://en.wikipedia.org/wiki/XOWA" title="XOWA">XOWA</a>: (<a href="#XOWA">§&nbsp;XOWA</a>)&nbsp;– <a rel="nofollow" href="http://xowa.org/home/wiki/Dashboard/Image_databases.html">index of images</a> (2015)</li>
<li>WikiTaxi: <a href="#WikiTaxi_(for_Windows)">§&nbsp;WikiTaxi (for Windows)</a></li>
<li>aarddict: <a href="#Aard_Dictionary_/_Aard_2">§&nbsp;Aard Dictionary / Aard 2</a></li>
<li>BzReader: <a href="#BzReader_and_MzReader_(for_Windows)">§&nbsp;BzReader and MzReader (for Windows)</a></li>
<li>WikiFilter: <a href="#WikiFilter">§&nbsp;WikiFilter</a></li>
<li>Wikipedia on rockbox: <a href="#Wikiviewer_for_Rockbox">§&nbsp;Wikiviewer for Rockbox</a></li>
<li>Selected Wikipedia articles as a printed document: <a href="https://en.wikipedia.org/wiki/Help:Printing" title="Help:Printing">Help:Printing</a></li></ul>
<p>Some of them are mobile applications&nbsp;– see "<a href="https://en.wikipedia.org/wiki/List_of_Wikipedia_mobile_applications" title="List of Wikipedia mobile applications">List of Wikipedia mobile applications</a>".
</p>
<p><h2 id="Where_do_I_get_the_dumps?" data-mw-thread-id="h-Where_do_I_get_the_dumps?"><span id="Where_do_I_get_the_dumps.3F"></span><span data-mw-comment-start="" id="h-Where_do_I_get_the_dumps?"></span>Where do I get the dumps?<span data-mw-comment-end="h-Where_do_I_get_the_dumps?"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Where_do_I_get_the_dumps?","replies":["h-English-language_Wikipedia-Where_do_I_get_the_dumps?","h-Other_Wikipedia_editions-Where_do_I_get_the_dumps?"]}}--></p>
<p><h3 id="English-language_Wikipedia" data-mw-thread-id="h-English-language_Wikipedia-Where_do_I_get_the_dumps?"><span data-mw-comment-start="" id="h-English-language_Wikipedia-Where_do_I_get_the_dumps?"></span>English-language Wikipedia<span data-mw-comment-end="h-English-language_Wikipedia-Where_do_I_get_the_dumps?"></span></h3></p>
<ul><li>Dumps from any Wikimedia Foundation project: <span><a href="https://dumps.wikimedia.org/">dumps<wbr>.wikimedia<wbr>.org</a></span> and the <a href="https://archive.org/details/wikimediadownloads" title="iarchive:wikimediadownloads">Internet Archive</a></li>
<li>English Wikipedia dumps in SQL and XML: <span><a href="https://dumps.wikimedia.org/enwiki/">dumps<wbr>.wikimedia<wbr>.org<wbr>/enwiki<wbr>/</a></span> and the <a rel="nofollow" href="https://archive.org/search.php?query=subject%3A%22enwiki%22%20AND%20subject%3A%22data%20dumps%22%20AND%20collection%3A%22wikimediadownloads%22">Internet Archive</a>
<ul><li><a href="https://meta.wikimedia.org/wiki/Data_dump_torrents#English_Wikipedia">Download</a> the data dump using a BitTorrent client (torrenting has many benefits and reduces server load, saving bandwidth costs).</li>
<li>pages-articles-multistream.xml.bz2 – Current revisions only, no talk or user pages; this is probably what you want, and is over 19 GB compressed (expands to over 86 GB when decompressed).</li>
<li>pages-meta-current.xml.bz2 – Current revisions only, all pages (including talk)</li>
<li>abstract.xml.gz – page abstracts</li>
<li>all-titles-in-ns0.gz – Article titles only (with redirects)</li>
<li>SQL files for the pages and links are also available</li>
<li>All revisions, all pages: <b>These files expand to multiple <a href="https://en.wikipedia.org/wiki/Terabyte" title="Terabyte">terabytes</a> of text. Please only download these if you know you can cope with this quantity of data.</b> Go to <a href="https://dumps.wikimedia.org/enwiki/latest/">Latest Dumps</a> and look out for all the files that have 'pages-meta-history' in their name.</li></ul></li>
<li>To download a subset of the database in XML format, such as a specific category or a list of articles see: <a href="https://en.wikipedia.org/wiki/Special:Export" title="Special:Export">Special:Export</a>, usage of which is described at <a href="https://en.wikipedia.org/wiki/Help:Export" title="Help:Export">Help:Export</a>.</li>
<li>Wiki front-end software: <a href="https://en.wikipedia.org/wiki/MediaWiki" title="MediaWiki">MediaWiki</a> <a href="https://www.mediawiki.org/">[1]</a>.</li>
<li>Database backend software: <a href="https://en.wikipedia.org/wiki/MySQL" title="MySQL">MySQL</a>.</li>
<li>Image dumps: See below.</li></ul>
<p><h3 id="Other_Wikipedia_editions" data-mw-thread-id="h-Other_Wikipedia_editions-Where_do_I_get_the_dumps?"><span data-mw-comment-start="" id="h-Other_Wikipedia_editions-Where_do_I_get_the_dumps?"></span>Other Wikipedia editions<span data-mw-comment-end="h-Other_Wikipedia_editions-Where_do_I_get_the_dumps?"></span></h3></p>
<ul><li>Wikipedia dumps in SQL and XML: <span><a href="https://dumps.wikimedia.org/">dumps<wbr>.wikimedia<wbr>.org</a></span></li></ul>
<p><h2 id="Should_I_get_multistream?" data-mw-thread-id="h-Should_I_get_multistream?"><span id="Should_I_get_multistream.3F"></span><span data-mw-comment-start="" id="h-Should_I_get_multistream?"></span>Should I get multistream?<span data-mw-comment-end="h-Should_I_get_multistream?"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Should_I_get_multistream?","replies":["h-How_to_use_multistream?-Should_I_get_multistream?","h-Other_languages-Should_I_get_multistream?"]}}--></p>
<p>:
<b>GET THE MULTISTREAM VERSION!</b> (and the corresponding index file, <i>pages-articles-multistream-index.txt.bz2</i>)
</p><p><i>pages-articles.xml.bz2</i> and <i>pages-articles-multistream.xml.bz2</i> both contain the same <i>xml</i> contents. So if you unpack either, you get the same data. But with multistream, it is possible to get an article from the archive without unpacking the whole thing. Your reader should handle this for you; if your reader doesn't support it, it will work anyway since multistream and non-multistream contain the same <i>xml</i>. The only downside to multistream is that it is marginally larger. You might be tempted to get the smaller non-multistream archive, but this will be useless if you don't unpack it. And it will unpack to ~5–10 times its original size. Penny wise, pound foolish. Get multistream.
</p><p>NOTE THAT the multistream dump file contains multiple bz2 'streams' (bz2 header, body, footer) concatenated together into one file, in contrast to the vanilla file which contains one stream. Each separate 'stream' (or really, file) in the multistream dump contains 100 pages, except possibly the last one. 
</p>
<p><h3 id="How_to_use_multistream?" data-mw-thread-id="h-How_to_use_multistream?-Should_I_get_multistream?"><span id="How_to_use_multistream.3F"></span><span data-mw-comment-start="" id="h-How_to_use_multistream?-Should_I_get_multistream?"></span>How to use multistream?<span data-mw-comment-end="h-How_to_use_multistream?-Should_I_get_multistream?"></span></h3></p>
<p>For multistream, you can get an index file, <i>pages-articles-multistream-index.txt.bz2</i>. The first field of this index is the number of bytes to seek into the compressed archive <i>pages-articles-multistream.xml.bz2</i>, the second is the article ID, the third the article title. 
</p><p>Cut a small part out of the archive with dd using the byte offset as found in the index. You could then either bzip2 decompress it or use bzip2recover, and search the first file for the article ID.
</p><p>See <a rel="nofollow" href="https://docs.python.org/3/library/bz2.html#bz2.BZ2Decompressor">https://docs.python.org/3/library/bz2.html#bz2.BZ2Decompressor</a> for info about such multistream files and about how to decompress them with python; see also <a href="https://gerrit.wikimedia.org/r/plugins/gitiles/operations/dumps/+/ariel/toys/bz2multistream/README.txt">https://gerrit.wikimedia.org/r/plugins/gitiles/operations/dumps/+/ariel/toys/bz2multistream/README.txt</a> and related files for an old working toy.
</p>
<p><h3 id="Other_languages" data-mw-thread-id="h-Other_languages-Should_I_get_multistream?"><span data-mw-comment-start="" id="h-Other_languages-Should_I_get_multistream?"></span>Other languages<span data-mw-comment-end="h-Other_languages-Should_I_get_multistream?"></span></h3></p>
<p>In the <span><a href="https://dumps.wikimedia.org/">dumps<wbr>.wikimedia<wbr>.org</a></span> directory you will find the latest SQL and XML dumps for the projects, not just English. The sub-directories are named for the <a href="https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes" title="List of ISO 639-1 codes">language code</a> and the appropriate project. Some other directories (e.g. simple, nostalgia) exist, with the same structure. These dumps are also available from the <a href="https://archive.org/details/wikimediadownloads" title="iarchive:wikimediadownloads">Internet Archive</a>.
</p>
<p><h2 id="Where_are_the_uploaded_files_(image,_audio,_video,_etc.)?" data-mw-thread-id="h-Where_are_the_uploaded_files_(image,_audio,_video,_etc.)?"><span id="Where_are_the_uploaded_files_.28image.2C_audio.2C_video.2C_etc..29.3F"></span><span data-mw-comment-start="" id="h-Where_are_the_uploaded_files_(image,_audio,_video,_etc.)?"></span>Where are the uploaded files (image, audio, video, etc.)?<span data-mw-comment-end="h-Where_are_the_uploaded_files_(image,_audio,_video,_etc.)?"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Where_are_the_uploaded_files_(image,_audio,_video,_etc.)?","replies":[]}}--></p>
<p>Images and other uploaded media are available from mirrors in addition to being served directly from Wikimedia servers. Bulk download is (as of September 2013) available from mirrors but not offered directly from Wikimedia servers. See the <a href="https://meta.wikimedia.org/wiki/Mirroring_Wikimedia_project_XML_dumps#Media" title="m:Mirroring Wikimedia project XML dumps">list of current mirrors</a>. You should <a href="https://en.wikipedia.org/wiki/Rsync" title="Rsync">rsync</a> from the mirror, then fill in the missing images from <a href="https://upload.wikimedia.org/">upload.wikimedia.org</a>; when downloading from <code>upload.wikimedia.org</code> you should throttle yourself to 1 cache miss per second (you can check headers on a response to see if was a hit or miss and then back off when you get a miss) and you shouldn't use more than one or two simultaneous HTTP connections. In any case, make sure you have an accurate <a href="https://en.wikipedia.org/wiki/User_agent" title="User agent">user agent</a> string with contact info (email address) so ops can contact you if there's an issue. You should be getting checksums from the mediawiki API and verifying them. The <a href="https://www.mediawiki.org/wiki/API:Etiquette" title="mw:API:Etiquette">API Etiquette</a> page contains some guidelines, although not all of them apply (for example, because upload.wikimedia.org isn't MediaWiki, there is no <code>maxlag</code> parameter).
</p><p>Unlike most article text, images are not necessarily licensed under the GFDL &amp; CC-BY-SA-4.0. They may be under one of many <a href="https://en.wikipedia.org/wiki/Wikipedia:File_copyright_tags/Free_licenses" title="Wikipedia:File copyright tags/Free licenses">free licenses</a>, in the <a href="https://en.wikipedia.org/wiki/Wikipedia:File_copyright_tags/Public_domain" title="Wikipedia:File copyright tags/Public domain">public domain</a>, believed to be <a href="https://en.wikipedia.org/wiki/Wikipedia:File_copyright_tags/Non-free" title="Wikipedia:File copyright tags/Non-free">fair use</a>, or even copyright infringements (which should be <a href="https://en.wikipedia.org/wiki/Wikipedia:IFD" title="Wikipedia:IFD">deleted</a>). In particular, use of fair use images outside the context of Wikipedia or similar works may be illegal. Images under most licenses require a credit, and possibly other attached copyright information. This information is included in image description pages, which are part of the text dumps available from <a href="https://dumps.wikimedia.org/">dumps.wikimedia.org</a>. In conclusion, download these images at your own risk (<a href="https://dumps.wikimedia.org/legal.html">Legal</a>).
</p>
<p><h2 id="Dealing_with_compressed_files" data-mw-thread-id="h-Dealing_with_compressed_files"><span data-mw-comment-start="" id="h-Dealing_with_compressed_files"></span>Dealing with compressed files<span data-mw-comment-end="h-Dealing_with_compressed_files"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Dealing_with_compressed_files","replies":[]}}--></p>
<p>Compressed dump files are significantly compressed, thus after being decompressed will take up <b>large</b> amounts of drive space.  A large list of decompression programs are described in <a href="https://en.wikipedia.org/wiki/Comparison_of_file_archivers" title="Comparison of file archivers">comparison of file archivers</a>. The following  programs in particular can be used to decompress bzip2, <a href="https://en.wikipedia.org/wiki/.bz2" title=".bz2">.bz2</a>, <a href="https://en.wikipedia.org/wiki/.zip" title=".zip">.zip</a>, and <a href="https://en.wikipedia.org/wiki/.7z" title=".7z">.7z</a> files.
</p>
<dl><dt><a href="https://en.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a></dt></dl>
<p>Beginning with <a href="https://en.wikipedia.org/wiki/Windows_XP" title="Windows XP">Windows XP</a>, a basic decompression program enables decompression of zip files.<sup id="cite_ref-2"><a href="#cite_note-2"><span>[</span>2<span>]</span></a></sup><sup id="cite_ref-3"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup> Among others, the following can be used to decompress bzip2 files.
</p>
<ul><li><a rel="nofollow" href="https://sourceware.org/pub/bzip2/v102/bzip2-102-x86-win32.exe">bzip2 (command-line)</a> (from <a rel="nofollow" href="https://www.sourceware.org/bzip2/">here</a>) is available for free under a BSD license.</li>
<li><a href="https://en.wikipedia.org/wiki/7-Zip" title="7-Zip">7-Zip</a> is available for free under an <a href="https://en.wikipedia.org/wiki/GNU_Lesser_General_Public_License" title="GNU Lesser General Public License">LGPL</a> license.</li>
<li><a href="https://en.wikipedia.org/wiki/WinRAR" title="WinRAR">WinRAR</a></li>
<li><a href="https://en.wikipedia.org/wiki/WinZip" title="WinZip">WinZip</a></li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/Macintosh" title="Macintosh">Macintosh</a> (Mac)</dt></dl>
<ul><li><a href="https://en.wikipedia.org/wiki/MacOS" title="MacOS">macOS</a> ships with the command-line bzip2 tool.</li></ul>
<dl><dt>GNU/<a href="https://en.wikipedia.org/wiki/Linux" title="Linux">Linux</a></dt></dl>
<ul><li>Most GNU/Linux distributions ship with the command-line bzip2 tool.</li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution" title="Berkeley Software Distribution">Berkeley Software Distribution</a> (BSD)</dt></dl>
<ul><li>Some BSD systems ship with the command-line bzip2 tool as part of the operating system. Others, such as <a href="https://en.wikipedia.org/wiki/OpenBSD" title="OpenBSD">OpenBSD</a>, provide it as a package which must first be installed.</li></ul>
<dl><dt>Notes</dt></dl>
<ol><li>Some older versions of bzip2 may not be able to handle files larger than 2 GB, so make sure you have the latest version if you experience any problems.</li>
<li>Some older archives are compressed with gzip, which is compatible with PKZIP (the most common Windows format).</li></ol>
<p><h2 id="Dealing_with_large_files" data-mw-thread-id="h-Dealing_with_large_files"><span data-mw-comment-start="" id="h-Dealing_with_large_files"></span>Dealing with large files<span data-mw-comment-end="h-Dealing_with_large_files"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Dealing_with_large_files","replies":["h-File_system_limits-Dealing_with_large_files","h-Operating_system_limits-Dealing_with_large_files","h-Tips-Dealing_with_large_files"]}}--></p>
<p>As files grow in size, so does the likelihood they will exceed some limit of a computing device. Each operating system, file system, hard storage device, and software (application) has a maximum file size limit. Each one of these will likely have a different maximum, and the lowest limit of all of them will become the file size limit for a storage device.
</p><p>The older the software in a computing device, the more likely it will have a 2 GB file limit somewhere in the system. This is due to older software using 32-bit integers for file indexing, which limits file sizes to 2^31 bytes (2 GB) (for signed integers), or 2^32 (4 GB) (for unsigned integers). Older <a href="https://en.wikipedia.org/wiki/C_(programming_language)" title="C (programming language)">C</a> <a href="https://en.wikipedia.org/wiki/Library_(computing)" title="Library (computing)">programming libraries</a> have this 2 or 4 GB limit, but the newer file libraries have been converted to 64-bit integers thus supporting file sizes up to 2^63 or 2^64 bytes (8 or 16 <a href="https://en.wikipedia.org/wiki/Exabyte" title="Exabyte">EB</a>).
</p><p>Before starting a download of a large file, check the storage device to ensure its file system can support files of such a large size, check the amount of free space to ensure that it can hold the downloaded file, and make sure the device(s) you'll use the storage with are able to read your chosen file system.
</p>
<p><h3 id="File_system_limits" data-mw-thread-id="h-File_system_limits-Dealing_with_large_files"><span data-mw-comment-start="" id="h-File_system_limits-Dealing_with_large_files"></span>File system limits<span data-mw-comment-end="h-File_system_limits-Dealing_with_large_files"></span></h3></p>
<p>There are two limits for a file system: the file system size limit, and the file system limit. In general, since the file size limit is less than the file system limit, the larger file system limits are a moot point. A large percentage of users assume they can create files up to the size of their storage device, but are wrong in their assumption. For example, a 16 GB storage device formatted as FAT32 file system has a file limit of 4 GB for any single file. The following is a list of the most common file systems, and see <a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems#Limits" title="Comparison of file systems">Comparison of file systems</a> for additional detailed information.
</p>
<dl><dt><a href="https://en.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a></dt></dl>
<ul><li><a href="https://en.wikipedia.org/wiki/File_Allocation_Table" title="File Allocation Table">FAT16</a> supports files up to 4 <a href="https://en.wikipedia.org/wiki/Gigabyte" title="Gigabyte">GB</a>. FAT16 is the factory format of smaller <a href="https://en.wikipedia.org/wiki/USB" title="USB">USB</a> drives and all <a href="https://en.wikipedia.org/wiki/SD_card" title="SD card">SD cards</a> that are 2 GB or smaller.</li>
<li><a href="https://en.wikipedia.org/wiki/File_Allocation_Table" title="File Allocation Table">FAT32</a> supports files up to 4 GB. FAT32 is the factory format of larger <a href="https://en.wikipedia.org/wiki/USB" title="USB">USB</a> drives and all <a href="https://en.wikipedia.org/wiki/SD_card" title="SD card">SDHC</a> cards that are 4 GB or larger.</li>
<li><a href="https://en.wikipedia.org/wiki/ExFAT" title="ExFAT">exFAT</a> supports files up to 127 <a href="https://en.wikipedia.org/wiki/Petabyte" title="Petabyte">PB</a>. exFAT is the factory format of all <a href="https://en.wikipedia.org/wiki/SD_card" title="SD card">SDXC</a> cards, but is incompatible with most flavors of UNIX due to licensing problems.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources.">citation needed</span></a></i>]</sup></li>
<li><a href="https://en.wikipedia.org/wiki/NTFS" title="NTFS">NTFS</a> supports files up to 16 <a href="https://en.wikipedia.org/wiki/Terabyte" title="Terabyte">TB</a>. NTFS is the default file system for modern <a href="https://en.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a> computers, including Windows 2000, Windows XP, and all their successors to date. Versions after Windows 8 can support larger files if the file system is formatted with a larger cluster size.</li>
<li><a href="https://en.wikipedia.org/wiki/ReFS" title="ReFS">ReFS</a> supports files up to 16 <a href="https://en.wikipedia.org/wiki/Exabyte" title="Exabyte">EB</a>.</li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/Macintosh" title="Macintosh">Macintosh</a> (Mac)</dt></dl>
<ul><li><a href="https://en.wikipedia.org/wiki/HFS_Plus" title="HFS Plus">HFS Plus</a> (HFS+) (Also known as Mac OS Extended) supports files up to 8 EiB (8 exbibytes) (2^63 bytes).<sup id="cite_ref-AppleVolumecomparison_4-0"><a href="#cite_note-AppleVolumecomparison-4"><span>[</span>4<span>]</span></a></sup> An exbibyte is similar to an <a href="https://en.wikipedia.org/wiki/Exabyte" title="Exabyte">exabyte</a>. HFS Plus is supported on <a href="https://en.wikipedia.org/wiki/MacOS" title="MacOS">macOS</a> 10.2+ and <a href="https://en.wikipedia.org/wiki/IOS" title="IOS">iOS</a>. It was the default file system for <a href="https://en.wikipedia.org/wiki/MacOS" title="MacOS">macOS</a> computers prior to the release of <a href="https://en.wikipedia.org/wiki/MacOS_High_Sierra" title="MacOS High Sierra">macOS High Sierra</a> in 2017 when it was replaced as default with <a href="https://en.wikipedia.org/wiki/Apple_File_System" title="Apple File System">Apple File System</a>, <a href="https://en.wikipedia.org/wiki/APFS" title="APFS">APFS</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/APFS" title="APFS">APFS</a> supports files up to 8 exbibytes (2^63 bytes).<sup id="cite_ref-AppleVolumecomparison_4-1"><a href="#cite_note-AppleVolumecomparison-4"><span>[</span>4<span>]</span></a></sup></li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/Linux" title="Linux">Linux</a></dt></dl>
<ul><li><a href="https://en.wikipedia.org/wiki/Ext2" title="Ext2">ext2</a> and <a href="https://en.wikipedia.org/wiki/Ext3" title="Ext3">ext3</a> supports files up to 16 GB, but up to 2 TB with larger block sizes. See <a rel="nofollow" href="https://users.suse.com/~aj/linux_lfs.html">https://users.suse.com/~aj/linux_lfs.html</a> for more information.</li>
<li><a href="https://en.wikipedia.org/wiki/Ext4" title="Ext4">ext4</a> supports files up to 16 TB, using 4 KB block size. (<a rel="nofollow" href="https://fedoraproject.org/wiki/Features/F17Ext4Above16T">limit removed in e2fsprogs-1.42 (2012)</a>)</li>
<li><a href="https://en.wikipedia.org/wiki/XFS" title="XFS">XFS</a> supports files up to 8 EB.</li>
<li><a href="https://en.wikipedia.org/wiki/ReiserFS" title="ReiserFS">ReiserFS</a> supports files up to 1 EB, 8 TB on 32-bit systems.</li>
<li><a href="https://en.wikipedia.org/wiki/JFS_(file_system)" title="JFS (file system)">JFS</a> supports files up to 4 PB.</li>
<li><a href="https://en.wikipedia.org/wiki/Btrfs" title="Btrfs">Btrfs</a> supports files up to 16 EB.</li>
<li><a href="https://en.wikipedia.org/wiki/NILFS" title="NILFS">NILFS</a> supports files up to 8 EB.</li>
<li><a href="https://en.wikipedia.org/wiki/YAFFS" title="YAFFS">YAFFS</a>2 supports files up to 2 GB</li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/FreeBSD" title="FreeBSD">FreeBSD</a></dt></dl>
<ul><li><a href="https://en.wikipedia.org/wiki/ZFS" title="ZFS">ZFS</a> supports files up to 16 EB.</li></ul>
<dl><dt>FreeBSD and other BSDs</dt></dl>
<ul><li><a href="https://en.wikipedia.org/wiki/Unix_File_System" title="Unix File System">Unix File System</a> (UFS) supports files up to 8 ZiB.</li></ul>
<p><h3 id="Operating_system_limits" data-mw-thread-id="h-Operating_system_limits-Dealing_with_large_files"><span data-mw-comment-start="" id="h-Operating_system_limits-Dealing_with_large_files"></span>Operating system limits<span data-mw-comment-end="h-Operating_system_limits-Dealing_with_large_files"></span></h3></p>
<p>Each operating system has internal file system limits for file size and drive size, which is independent of the file system or physical media. If the operating system has any limits lower than the file system or physical media, then the OS limits will be the real limit.
</p>
<dl><dt><a href="https://en.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a></dt></dl>
<ul><li>Windows 95, 98, ME have a 4 GB limit for all file sizes.</li>
<li>Windows XP has a 16 TB limit for all file sizes.</li>
<li>Windows 7 has a 16 TB limit for all file sizes.</li>
<li>Windows 8, 10, and Server 2012 have a 256 TB limit for all file sizes.</li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/Linux" title="Linux">Linux</a></dt></dl>
<ul><li>32-bit kernel 2.4.x systems have a 2 TB limit for all file systems.</li>
<li>64-bit kernel 2.4.x systems have an 8 EB limit for all file systems.</li>
<li>32-bit kernel 2.6.x systems without option CONFIG_LBD have a 2 TB limit for all file systems.</li>
<li>32-bit kernel 2.6.x systems with option CONFIG_LBD and all 64-bit kernel 2.6.x systems have an 8 ZB limit for all file systems.<sup id="cite_ref-5"><a href="#cite_note-5"><span>[</span>5<span>]</span></a></sup></li></ul>
<p><a href="https://en.wikipedia.org/wiki/Android_(operating_system)" title="Android (operating system)">Android</a>:
Android is based on Linux, which determines its base limits.
</p>
<ul><li>Internal storage:
<ul><li><a href="https://en.wikipedia.org/wiki/Android_(operating_system)" title="Android (operating system)">Android</a> 2.3 and later uses the <a href="https://en.wikipedia.org/wiki/Ext4" title="Ext4">ext4</a> file system.<sup id="cite_ref-6"><a href="#cite_note-6"><span>[</span>6<span>]</span></a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Android_(operating_system)" title="Android (operating system)">Android</a> 2.2 and earlier uses the <a href="https://en.wikipedia.org/wiki/YAFFS" title="YAFFS">YAFFS</a>2 file system.</li></ul></li>
<li>External storage slots:
<ul><li>All Android devices should support FAT16, FAT32, ext2 file systems.</li>
<li>Android 2.3 and later supports ext4 file system.</li></ul></li></ul>
<dl><dt><a href="https://en.wikipedia.org/wiki/Apple_Inc." title="Apple Inc.">Apple</a> <a href="https://en.wikipedia.org/wiki/IOS" title="IOS">iOS</a> (see <a href="https://en.wikipedia.org/wiki/List_of_iPhone_models" title="List of iPhone models">List of iPhone models</a>)</dt>
<dd></dd></dl>
<ul><li>All devices support <a href="https://en.wikipedia.org/wiki/HFS_Plus" title="HFS Plus">HFS Plus</a> (HFS+) for internal storage. No devices have external storage slots. Devices on 10.3 or later run <a href="https://en.wikipedia.org/wiki/Apple_File_System" title="Apple File System">Apple File System</a> supporting a max file size of 8 EB.</li></ul>
<p><h3 id="Tips" data-mw-thread-id="h-Tips-Dealing_with_large_files"><span data-mw-comment-start="" id="h-Tips-Dealing_with_large_files"></span>Tips<span data-mw-comment-end="h-Tips-Dealing_with_large_files"></span></h3></p>
<p><h4 id="Detect_corrupted_files" data-mw-thread-id="h-Detect_corrupted_files-Tips"><span data-mw-comment-start="" id="h-Detect_corrupted_files-Tips"></span>Detect corrupted files<span data-mw-comment-end="h-Detect_corrupted_files-Tips"></span></h4></p>
<p>It is useful to check the <a href="https://en.wikipedia.org/wiki/MD5" title="MD5">MD5</a> sums (provided in a file in the download directory) to make sure the download was complete and accurate. This can be checked by running the "md5sum" command on the files downloaded. Given their sizes, this may take some time to calculate. Due to the technical details of how files are stored, <i>file sizes</i> may be reported differently on different filesystems, and so are not necessarily reliable. Also, corruption may have occurred during the download, though this is unlikely.
</p>
<p><h4 id="Linux_and_Unix" data-mw-thread-id="h-Linux_and_Unix-Tips"><span data-mw-comment-start="" id="h-Linux_and_Unix-Tips"></span>Linux and Unix<span data-mw-comment-end="h-Linux_and_Unix-Tips"></span></h4></p>
<p>If you seem to be hitting the 2 GB limit, try using <a href="https://en.wikipedia.org/wiki/Wget" title="Wget">wget</a> version 1.10 or greater, <a href="https://en.wikipedia.org/wiki/CURL" title="CURL">cURL</a> version 7.11.1-1 or greater, or a recent version of <a href="https://en.wikipedia.org/wiki/Lynx_(web_browser)" title="Lynx (web browser)">lynx</a> (using -dump). Also, you can resume downloads (for example wget -c).
</p>
<p><h2 id="Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?" data-mw-thread-id="h-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"><span id="Why_not_just_retrieve_data_from_wikipedia.org_at_runtime.3F"></span><span data-mw-comment-start="" id="h-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"></span>Why not just retrieve data from <a href="https://en.wikipedia.org/wiki/Main_Page" title="Main Page">wikipedia.org</a> at runtime?<span data-mw-comment-end="h-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?","replies":["h-Please_do_not_use_a_web_crawler-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?","h-Doing_SQL_queries_on_the_current_database_dump-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"]}}--></p>
<p>Suppose you are building a piece of software that at certain points displays information that came from Wikipedia. If you want your program to display the information in a different way than can be seen in the live version, you'll probably need the wikicode that is used to enter it, instead of the finished HTML.
</p><p>Also, if you want to get all the data, you'll probably want to transfer it in the most efficient way that's possible. The wikipedia.org servers need to do quite a bit of work to convert the wikicode into HTML. That's time consuming both for you and for the wikipedia.org servers, so simply spidering all pages is not the way to go.
</p><p>To access any article in XML, one at a time, access <a href="https://en.wikipedia.org/wiki/Special:Export/Title_of_the_article" title="Special:Export/Title of the article">Special:Export/Title of the article</a>.
</p><p>Read more about this at <a href="https://en.wikipedia.org/wiki/Special:Export" title="Special:Export">Special:Export</a>.
</p><p>Please be aware that live mirrors of Wikipedia that are dynamically loaded from the Wikimedia servers are prohibited. Please see <a href="https://en.wikipedia.org/wiki/Wikipedia:Mirrors_and_forks" title="Wikipedia:Mirrors and forks">Wikipedia:Mirrors and forks</a>.
</p>
<p><h3 id="Please_do_not_use_a_web_crawler" data-mw-thread-id="h-Please_do_not_use_a_web_crawler-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"><span data-mw-comment-start="" id="h-Please_do_not_use_a_web_crawler-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"></span>Please do not use a web crawler<span data-mw-comment-end="h-Please_do_not_use_a_web_crawler-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"></span></h3></p>
<p>Please do not use a <a href="https://en.wikipedia.org/wiki/Web_crawler" title="Web crawler">web crawler</a> to download large numbers of articles. Aggressive crawling of the server can cause a dramatic slow-down of Wikipedia.
</p>
<p><h4 id="Sample_blocked_crawler_email" data-mw-thread-id="h-Sample_blocked_crawler_email-Please_do_not_use_a_web_crawler"><span data-mw-comment-start="" id="h-Sample_blocked_crawler_email-Please_do_not_use_a_web_crawler"></span>Sample blocked crawler email<span data-mw-comment-end="h-Sample_blocked_crawler_email-Please_do_not_use_a_web_crawler"></span></h4></p>
<dl><dd>IP address <i><b>nnn.nnn.nnn.nnn</b></i> was retrieving up to 50 pages per second from wikipedia.org addresses. Something like at least a second delay between requests is reasonable. Please respect that setting. If you must exceed it a little, do so only during the least busy times shown in our site load graphs at <b><span><a href="https://stats.wikimedia.org/#/all-wikipedia-projects">stats<wbr>.wikimedia<wbr>.org<wbr>#<wbr>/all-wikipedia-projects</a></span></b>. It's worth noting that to crawl the whole site at one hit per second will take several weeks. The originating IP is now blocked or will be shortly. Please contact us if you want it unblocked. Please don't try to circumvent it&nbsp;– we'll just block your whole IP range.</dd></dl>
<dl><dd>If you want information on how to get our content more efficiently, we offer a variety of methods, including weekly database dumps which you can load into MySQL and crawl locally at any rate you find convenient. Tools are also available which will do that for you as often as you like once you have the infrastructure in place.</dd></dl>
<dl><dd>Instead of an email reply you may prefer to visit <span>#mediawiki</span> <sup><a rel="nofollow" href="https://web.libera.chat/?channel=#mediawiki"><span>connect</span></a></sup> at irc.libera.chat to discuss your options with our team.</dd></dl>
<p><h3 id="Doing_SQL_queries_on_the_current_database_dump" data-mw-thread-id="h-Doing_SQL_queries_on_the_current_database_dump-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"><span data-mw-comment-start="" id="h-Doing_SQL_queries_on_the_current_database_dump-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"></span>Doing SQL queries on the current database dump<span data-mw-comment-end="h-Doing_SQL_queries_on_the_current_database_dump-Why_not_just_retrieve_data_from_wikipedia.org_at_runtime?"></span></h3></p>
<p>You can do SQL queries on the current database dump using <a rel="nofollow" href="https://quarry.wmflabs.org/">Quarry</a> (as a replacement for the disabled <a href="https://en.wikipedia.org/wiki/Special:Asksql" title="Special:Asksql (page does not exist)">Special:Asksql</a> page).
</p>
<p><h2 id="Database_schema" data-mw-thread-id="h-Database_schema"><span data-mw-comment-start="" id="h-Database_schema"></span>Database schema<span data-mw-comment-end="h-Database_schema"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Database_schema","replies":["h-SQL_schema-Database_schema","h-XML_schema-Database_schema"]}}--></p>
<p><h3 id="SQL_schema" data-mw-thread-id="h-SQL_schema-Database_schema"><span data-mw-comment-start="" id="h-SQL_schema-Database_schema"></span>SQL schema<span data-mw-comment-end="h-SQL_schema-Database_schema"></span></h3></p>
<p><i>See also: <a href="https://www.mediawiki.org/wiki/Manual:Database_layout" title="mw:Manual:Database layout">mw:Manual:Database layout</a></i>
</p><p>The sql file used to initialize a MediaWiki database can be found <a href="https://phabricator.wikimedia.org/source/mediawiki/browse/master/sql/mysql/tables-generated.sql">here</a>.
</p>
<p><h3 id="XML_schema" data-mw-thread-id="h-XML_schema-Database_schema"><span data-mw-comment-start="" id="h-XML_schema-Database_schema"></span>XML schema<span data-mw-comment-end="h-XML_schema-Database_schema"></span></h3></p>
<p>The XML schema for each dump is defined at the top of the file and described in the <a href="https://www.mediawiki.org/wiki/Help:Export#Export_format" title="mw:Help:Export">MediaWiki export help page</a>.
</p>
<p><h2 id="Help_to_parse_dumps_for_use_in_scripts" data-mw-thread-id="h-Help_to_parse_dumps_for_use_in_scripts"><span data-mw-comment-start="" id="h-Help_to_parse_dumps_for_use_in_scripts"></span>Help to parse dumps for use in scripts<span data-mw-comment-end="h-Help_to_parse_dumps_for_use_in_scripts"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Help_to_parse_dumps_for_use_in_scripts","replies":["h-Doing_Hadoop_MapReduce_on_the_Wikipedia_current_database_dump-Help_to_parse_dumps_for_use_in_scripts"]}}--></p>
<ul><li><a href="https://en.wikipedia.org/wiki/Wikipedia:Computer_help_desk/ParseMediaWikiDump" title="Wikipedia:Computer help desk/ParseMediaWikiDump">Wikipedia:Computer help desk/ParseMediaWikiDump</a> describes the <a href="https://en.wikipedia.org/wiki/Perl" title="Perl">Perl</a> Parse::MediaWikiDump library, which can parse XML dumps.</li>
<li><a rel="nofollow" href="https://web.archive.org/web/20070907074625/http://www.cs.technion.ac.il/~gabr/resources/code/wikiprep">Wikipedia preprocessor (wikiprep.pl)</a> is a <a href="https://en.wikipedia.org/wiki/Perl" title="Perl">Perl</a> script that preprocesses raw XML dumps and builds link tables, category hierarchies, collects anchor text for each article etc.</li>
<li><a rel="nofollow" href="https://github.com/svick/Wikipedia-SQl-dump-parser">Wikipedia SQL dump parser</a> is a .NET library to read MySQL dumps without the need to use MySQL database</li>
<li><a rel="nofollow" href="https://github.com/MartinRichards23/WikiDumpParser">WikiDumpParser</a> – a .NET Core library to parse the database dumps.</li>
<li><a rel="nofollow" href="https://github.com/newca12/dictionary-builder">Dictionary Builder</a> is a Rust program that can parse XML dumps and extract entries in files</li>
<li><a rel="nofollow" href="https://github.com/napsternxg/WikiUtils">Scripts for parsing Wikipedia dumps</a> ­– Python based scripts for parsing sql.gz files from wikipedia dumps.</li>
<li><a rel="nofollow" href="https://crates.io/crates/parse-mediawiki-sql/">parse-mediawiki-sql</a> – a Rust library for quickly parsing the SQL dump files with minimal memory allocation</li>
<li><a rel="nofollow" href="https://gitlab.com/tozd/go/mediawiki">gitlab.com/tozd/go/mediawiki</a> – a Go package providing utilities for processing Wikipedia and Wikidata dumps.</li></ul>
<p><h3 id="Doing_Hadoop_MapReduce_on_the_Wikipedia_current_database_dump" data-mw-thread-id="h-Doing_Hadoop_MapReduce_on_the_Wikipedia_current_database_dump-Help_to_parse_dumps_for_use_in_scripts"><span data-mw-comment-start="" id="h-Doing_Hadoop_MapReduce_on_the_Wikipedia_current_database_dump-Help_to_parse_dumps_for_use_in_scripts"></span>Doing Hadoop MapReduce on the Wikipedia current database dump<span data-mw-comment-end="h-Doing_Hadoop_MapReduce_on_the_Wikipedia_current_database_dump-Help_to_parse_dumps_for_use_in_scripts"></span></h3></p>
<p>You can do Hadoop MapReduce queries on the current database dump, but you will need an extension to the InputRecordFormat to
have each &lt;page&gt; &lt;/page&gt; be a single mapper input. A working set of java methods (jobControl, mapper, reducer, and XmlInputRecordFormat) is available at <a rel="nofollow" href="https://tpmoyer-gallery.appspot.com/hadoopWikipedia">Hadoop on the Wikipedia</a>
</p>
<p><h2 id="Help_to_import_dumps_into_MySQL" data-mw-thread-id="h-Help_to_import_dumps_into_MySQL"><span data-mw-comment-start="" id="h-Help_to_import_dumps_into_MySQL"></span>Help to import dumps into MySQL<span data-mw-comment-end="h-Help_to_import_dumps_into_MySQL"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Help_to_import_dumps_into_MySQL","replies":[]}}--></p>
<p>See:
</p>
<ul><li><a href="https://www.mediawiki.org/wiki/Manual:Importing_XML_dumps" title="mw:Manual:Importing XML dumps">mw:Manual:Importing XML dumps</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Data_dumps" title="m:Data dumps">m:Data dumps</a></li></ul>

<p>Access to recent article update dumps (Snapshot API) or individual article retrieval (On-demand API) are available via <i><a href="https://enterprise.wikimedia.com/">Wikimedia Enterprise</a></i> with a free account (<a href="https://meta.wikimedia.org/wiki/Wikimedia_Enterprise" title="m:Wikimedia Enterprise">documentation on Meta wiki</a>). Alternatively, use your developer account to access APIs within Wikimedia Cloud Services.
</p>
<p><h2 id="Static_HTML_tree_dumps_for_mirroring_or_CD_distribution" data-mw-thread-id="h-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"><span data-mw-comment-start="" id="h-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span>Static HTML tree dumps for mirroring or CD distribution<span data-mw-comment-end="h-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution","replies":["h-Kiwix-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution","h-Aard_Dictionary_\/_Aard_2-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution","h-Wikiviewer_for_Rockbox-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution","h-Old_dumps-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"]}}--></p>
<p>MediaWiki 1.5 includes routines to dump a wiki to HTML, rendering the HTML with the same parser used on a live wiki. As the following page states, putting one of these dumps on the web unmodified will constitute a trademark violation. They are intended for private viewing in an intranet or desktop installation.
</p>
<ul><li>If you want to draft a traditional website in Mediawiki and dump it to HTML format, you might want to try <a rel="nofollow" href="https://barnesc.blogspot.com/2005/10/mw2html-export-mediawiki-to-static.html">mw2html</a> by <a href="https://en.wikipedia.org/wiki/User:Connelly" title="User:Connelly">User:Connelly</a>.</li>
<li>If you'd like to help develop dump-to-static HTML tools, please drop us a note on <a href="https://en.wikipedia.org/wiki/Wikipedia:Mailing_lists" title="Wikipedia:Mailing lists">the developers' mailing list</a>.</li>
<li>Static HTML dumps as of 2008 are available <a href="https://dumps.wikimedia.org/other/static_html_dumps/">here</a>.</li></ul>
<p><b>See also:</b>
</p>
<ul><li><a href="https://www.mediawiki.org/wiki/Alternative_parsers" title="mw:Alternative parsers">mw:Alternative parsers</a> lists some other not working options for getting static HTML dumps</li>
<li><a href="https://en.wikipedia.org/wiki/Wikipedia:Snapshots" title="Wikipedia:Snapshots">Wikipedia:Snapshots</a></li>
<li><a href="https://en.wikipedia.org/wiki/Wikipedia:TomeRaider_database" title="Wikipedia:TomeRaider database">Wikipedia:TomeRaider database</a></li></ul>
<p><h3 id="Kiwix" data-mw-thread-id="h-Kiwix-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"><span data-mw-comment-start="" id="h-Kiwix-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span>Kiwix<span data-mw-comment-end="h-Kiwix-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span></h3></p>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Kiwix_on_Android.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Kiwix_on_Android.jpg/250px-Kiwix_on_Android.jpg" decoding="async" width="250" height="141" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Kiwix_on_Android.jpg/500px-Kiwix_on_Android.jpg 1.5x" data-file-width="4608" data-file-height="2592"></a><figcaption>Kiwix on an Android tablet</figcaption></figure>
<p><a href="https://en.wikipedia.org/wiki/Kiwix" title="Kiwix">Kiwix</a> is by far the largest offline distribution of <a href="https://en.wikipedia.org/wiki/Wikipedia" title="Wikipedia">Wikipedia</a> to date. As an offline reader, Kiwix works with a library of contents that are zim files: you can pick &amp; choose whichever <a href="https://en.wikipedia.org/wiki/Wikimedia_Foundation#Wikimedia_projects" title="Wikimedia Foundation">Wikimedia project</a> (Wikipedia in any language, <a href="https://en.wikipedia.org/wiki/Wiktionary" title="Wiktionary">Wiktionary</a>, <a href="https://en.wikipedia.org/wiki/Wikisource" title="Wikisource">Wikisource</a>, etc.), as well as <a href="https://en.wikipedia.org/wiki/TED_Talks" title="TED Talks">TED Talks</a>, <a href="https://en.wikipedia.org/wiki/PhET_Interactive_Simulations" title="PhET Interactive Simulations">PhET Interactive Maths &amp; Physics simulations</a>, <a href="https://en.wikipedia.org/wiki/Project_Gutenberg" title="Project Gutenberg">Project Gutenberg</a>, etc.
</p><p>It is free and open source, and currently available for download on: 
</p>
<ul><li><a rel="nofollow" href="https://play.google.com/store/apps/details?id=org.kiwix.kiwixmobile">Android</a></li>
<li><a rel="nofollow" href="https://itunes.apple.com/us/app/kiwix/id997079563?mt=8">iOS</a></li>
<li><a rel="nofollow" href="https://apps.apple.com/us/app/kiwix-desktop/id1275066656">macOS</a></li>
<li><a rel="nofollow" href="https://download.kiwix.org/release/kiwix-desktop/kiwix-desktop_windows_x64.zip">Windows</a> &amp; <a rel="nofollow" href="https://www.microsoft.com/store/apps/9P8SLZ4J979J">Windows 10 (UWP)</a></li>
<li><a rel="nofollow" href="https://flathub.org/apps/details/org.kiwix.desktop">GNU/Linux</a></li></ul>
<p>... as well as extensions for <a rel="nofollow" href="https://chrome.google.com/webstore/detail/kiwix/donaljnlmapmngakoipdmehbfcioahhk">Chrome</a> &amp; <a rel="nofollow" href="https://addons.mozilla.org/fr/firefox/addon/kiwix-offline/">Firefox</a> browsers, server solutions, etc. See <a rel="nofollow" href="https://www.kiwix.org/en/">official Website</a> for the complete Kiwix portfolio.
</p>
<p><h3 id="Aard_Dictionary_/_Aard_2" data-mw-thread-id="h-Aard_Dictionary_/_Aard_2-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"><span id="Aard_Dictionary_.2F_Aard_2"></span><span data-mw-comment-start="" id="h-Aard_Dictionary_/_Aard_2-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span>Aard Dictionary / Aard 2<span data-mw-comment-end="h-Aard_Dictionary_/_Aard_2-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span></h3></p>
<p><a rel="nofollow" href="https://github.com/aarddict">Aard Dictionary</a> is an offline Wikipedia reader. No images. Cross-platform for Windows, Mac, Linux, Android, Maemo. Runs on rooted Nook and Sony PRS-T1 eBooks readers.
</p><p>It also has a successor <a rel="nofollow" href="http://aarddict.org/">Aard 2</a>.
</p>
<p><h3 id="Wikiviewer_for_Rockbox" data-mw-thread-id="h-Wikiviewer_for_Rockbox-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"><span data-mw-comment-start="" id="h-Wikiviewer_for_Rockbox-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span>Wikiviewer for <a href="https://en.wikipedia.org/wiki/Rockbox" title="Rockbox">Rockbox</a><span data-mw-comment-end="h-Wikiviewer_for_Rockbox-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span></h3></p>
<p>The wikiviewer plugin for rockbox permits viewing converted Wikipedia dumps on many <a href="https://en.wikipedia.org/wiki/Rockbox" title="Rockbox">Rockbox</a> devices.
It needs a custom build and conversion of the wiki dumps using the instructions available at <a rel="nofollow" href="http://www.rockbox.org/tracker/4755">http://www.rockbox.org/tracker/4755</a> . The conversion recompresses the file and splits it into 1 <a href="https://en.wikipedia.org/wiki/Gigabyte" title="Gigabyte">GB</a> files and an index file which all need to be in the same folder on the device or micro sd card.
</p>
<p><h3 id="Old_dumps" data-mw-thread-id="h-Old_dumps-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"><span data-mw-comment-start="" id="h-Old_dumps-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span>Old dumps<span data-mw-comment-end="h-Old_dumps-Static_HTML_tree_dumps_for_mirroring_or_CD_distribution"></span></h3></p>
<ul><li>The static version of Wikipedia created by Wikimedia: <a href="https://static.wikipedia.org/">http://static.wikipedia.org/</a> Feb. 11, 2013&nbsp;– This is apparently offline now. There was no content.</li>
<li><a rel="nofollow" href="http://www.tommasoconforti.com/">Wiki2static</a> (site down as of October&nbsp;2005) <b>was</b> an experimental program set up by <a href="https://en.wikipedia.org/wiki/User:Alfio" title="User:Alfio">User:Alfio</a> to generate html dumps, inclusive of images, search function and alphabetical index. At the linked site experimental dumps and the script itself can be downloaded. As an example it was used to generate these copies of <a rel="nofollow" href="http://fixedreference.org/en/20040424/wikipedia/Main_Page">English WikiPedia 24 April 04</a>, <a rel="nofollow" href="https://web.archive.org/web/20040618150011/http://fixedreference.org/simple/20040501/wikipedia/Main_Page">Simple WikiPedia 1 May 04</a>(old database) format and <a rel="nofollow" href="http://july.fixedreference.org/en/20040724/wikipedia/Main_Page">English WikiPedia 24 July 04</a><a rel="nofollow" href="http://july.fixedreference.org/simple/20040724/wikipedia/Main_Page">Simple WikiPedia 24 July 04</a>, <a rel="nofollow" href="http://july.fixedreference.org/fr/20040727/wikipedia/Accueil">WikiPedia Francais 27 Juillet 2004</a> (new format). <a href="https://en.wikipedia.org/wiki/User:BozMo" title="User:BozMo">BozMo</a> uses a version to generate periodic static copies at <a rel="nofollow" href="http://fixedreference.org/">fixed reference</a> (site down as of October 2017).</li></ul>
<p><h2 id="Dynamic_HTML_generation_from_a_local_XML_database_dump" data-mw-thread-id="h-Dynamic_HTML_generation_from_a_local_XML_database_dump"><span data-mw-comment-start="" id="h-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span>Dynamic HTML generation from a local XML database dump<span data-mw-comment-end="h-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Dynamic_HTML_generation_from_a_local_XML_database_dump","replies":["h-XOWA-Dynamic_HTML_generation_from_a_local_XML_database_dump","h-WikiFilter-Dynamic_HTML_generation_from_a_local_XML_database_dump","h-WikiTaxi_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump","h-BzReader_and_MzReader_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump","h-EPWING-Dynamic_HTML_generation_from_a_local_XML_database_dump"]}}--></p>
<p>Instead of converting a database dump file to many pieces of static HTML, one can also use a dynamic HTML generator. Browsing a wiki page is just like browsing a Wiki site, but the content is fetched and converted from a local dump file on request from the browser.
</p>
<p><h3 id="XOWA" data-mw-thread-id="h-XOWA-Dynamic_HTML_generation_from_a_local_XML_database_dump"><span data-mw-comment-start="" id="h-XOWA-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span>XOWA<span data-mw-comment-end="h-XOWA-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span></h3></p>
<p><a href="https://en.wikipedia.org/wiki/XOWA" title="XOWA">XOWA</a> is a free, open-source application that helps download Wikipedia to a computer. Access all of Wikipedia offline, without an internet connection!
It is currently in the beta stage of development, but is functional. It is available for download <a rel="nofollow" href="http://xowa.org/home/wiki/Help/Download_XOWA.html">here</a>.
</p>
<p><h4 id="Features" data-mw-thread-id="h-Features-XOWA"><span data-mw-comment-start="" id="h-Features-XOWA"></span>Features<span data-mw-comment-end="h-Features-XOWA"></span></h4></p>
<ul><li>Displays all articles from Wikipedia without an internet connection.</li>
<li>Download a complete, recent copy of English Wikipedia.</li>
<li>Display 5.2+ million articles in full HTML formatting.</li>
<li>Show images within an article. Access 3.7+ million images using the offline image databases.</li>
<li>Works with any Wikimedia wiki, including Wikipedia, Wiktionary, Wikisource, Wikiquote, Wikivoyage (also some non-wmf dumps)</li>
<li>Works with any non-English language wiki such as French Wikipedia, German Wikisource, Dutch Wikivoyage, etc.</li>
<li>Works with other specialized wikis such as Wikidata, Wikimedia Commons, Wikispecies, or any other MediaWiki generated dump</li>
<li>Set up over 660+ other wikis including:
<ul><li>English Wiktionary</li>
<li>English Wikisource</li>
<li>English Wikiquote</li>
<li>English Wikivoyage</li>
<li>Non-English wikis, such as French Wiktionary, German Wikisource, Dutch Wikivoyage</li>
<li>Wikidata</li>
<li>Wikimedia Commons</li>
<li>Wikispecies</li>
<li>... and many more!</li></ul></li>
<li>Update your wiki whenever you want, using Wikimedia's database backups.</li>
<li>Navigate between offline wikis. Click on "Look up this word in Wiktionary" and instantly view the page in Wiktionary.</li>
<li>Edit articles to remove vandalism or errors.</li>
<li>Install to a flash memory card for portability to other machines.</li>
<li>Run on Windows, Linux and Mac OS X.</li>
<li>View the HTML for any wiki page.</li>
<li>Search for any page by title using a Wikipedia-like Search box.</li>
<li>Browse pages by alphabetical order using Special:AllPages.</li>
<li>Find a word on a page.</li>
<li>Access a history of viewed pages.</li>
<li>Bookmark your favorite pages.</li>
<li>Downloads images and other files on demand (when connected to the internet)</li>
<li>Sets up Simple Wikipedia in less than 5 minutes</li>
<li>Can be customized at many levels: from keyboard shortcuts to HTML layouts to internal options</li></ul>
<p><h4 id="Main_features" data-mw-thread-id="h-Main_features-XOWA"><span data-mw-comment-start="" id="h-Main_features-XOWA"></span>Main features<span data-mw-comment-end="h-Main_features-XOWA"></span></h4></p>
<ol><li>Very fast searching</li>
<li>Keyword (actually, title words) based searching</li>
<li>Search produces multiple possible articles: you can choose amongst them</li>
<li>LaTeX based rendering for mathematical formulae</li>
<li>Minimal space requirements: the original .bz2 file plus the index</li>
<li>Very fast installation (a matter of hours) compared to loading the dump into MySQL</li></ol>
<p><h3 id="WikiFilter" data-mw-thread-id="h-WikiFilter-Dynamic_HTML_generation_from_a_local_XML_database_dump"><span data-mw-comment-start="" id="h-WikiFilter-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span>WikiFilter<span data-mw-comment-end="h-WikiFilter-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span></h3></p>
<p><a rel="nofollow" href="http://wikifilter.sourceforge.net/">WikiFilter</a> is a program which allows you to browse over 100 dump files without visiting a Wiki site.
</p>
<p><h4 id="WikiFilter_system_requirements" data-mw-thread-id="h-WikiFilter_system_requirements-WikiFilter"><span data-mw-comment-start="" id="h-WikiFilter_system_requirements-WikiFilter"></span>WikiFilter system requirements<span data-mw-comment-end="h-WikiFilter_system_requirements-WikiFilter"></span></h4></p>
<ul><li>A recent Windows version (Windows XP is fine; Windows 98 and ME won't work because they don't have NTFS support)</li>
<li>A fair bit of hard drive space (to install you will need about 12–15 Gigabytes; afterwards you will only need about 10 Gigabytes)</li></ul>
<p><h4 id="How_to_set_up_WikiFilter" data-mw-thread-id="h-How_to_set_up_WikiFilter-WikiFilter"><span data-mw-comment-start="" id="h-How_to_set_up_WikiFilter-WikiFilter"></span>How to set up WikiFilter<span data-mw-comment-end="h-How_to_set_up_WikiFilter-WikiFilter"></span></h4></p>
<ol><li>Start downloading a Wikipedia database dump file such as an <a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2">English Wikipedia dump</a>. It is best to use a download manager such as <a href="https://en.wikipedia.org/wiki/GetRight" title="GetRight">GetRight</a> so you can resume downloading the file even if your computer crashes or is shut down during the download.</li>
<li>Download XAMPPLITE from <a rel="nofollow" href="http://sourceforge.net/project/showfiles.php?group_id=61776&amp;package_id=89552">[2]</a> (you must get the 1.5.0 version for it to work). Make sure to pick the file whose filename ends with .exe</li>
<li>Install/extract it to C:\XAMPPLITE.</li>
<li>Download WikiFilter 2.3 from this site: <a rel="nofollow" href="http://sourceforge.net/projects/wikifilter">http://sourceforge.net/projects/wikifilter</a>. You will have a choice of files to download, so make sure that you pick the 2.3 version. Extract it to C:\WIKIFILTER.</li>
<li>Copy the WikiFilter.so into your C:\XAMPPLITE\apache\modules folder.</li>
<li>Edit your C:\xampplite\apache\conf\httpd.conf file, and add the following line:
<ul><li>LoadModule WikiFilter_module "C:/XAMPPLITE/apache/modules/WikiFilter.so"</li></ul></li>
<li>When your Wikipedia file has finished downloading, uncompress it into your C:\WIKIFILTER folder. (I used WinRAR <a rel="nofollow" href="https://www.rarlab.com/">http://www.rarlab.com/</a> demo version&nbsp;– BitZipper <a rel="nofollow" href="http://www.bitzipper.com/winrar.html">http://www.bitzipper.com/winrar.html</a> works well too.)</li>
<li>Run WikiFilter (WikiIndex.exe), and go to your C:\WIKIFILTER folder, and drag and drop the XML file into the window, click Load, then Start.</li>
<li>After it finishes, exit the window, and go to your C:\XAMPPLITE folder. Run the setup_xampp.bat file to configure xampp.</li>
<li>When you finish with that, run the Xampp-Control.exe file, and start Apache.</li>
<li>Browse to <a rel="nofollow" href="http://localhost/wiki">http://localhost/wiki</a> and see if it works
<ul><li>If it doesn't work, see the <a rel="nofollow" href="http://sourceforge.net/forum/forum.php?forum_id=495411">forums</a>.</li></ul></li></ol>
<p><h3 id="WikiTaxi_(for_Windows)" data-mw-thread-id="h-WikiTaxi_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump"><span id="WikiTaxi_.28for_Windows.29"></span><span data-mw-comment-start="" id="h-WikiTaxi_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span>WikiTaxi (for Windows)<span data-mw-comment-end="h-WikiTaxi_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span></h3></p>
<p><a rel="nofollow" href="https://www.yunqa.de/delphi/apps/wikitaxi/index">WikiTaxi</a> is an offline-reader for wikis in MediaWiki format. It enables users to search and browse popular wikis like Wikipedia, Wikiquote, or WikiNews, without being connected to the Internet. WikiTaxi works well with different languages like English, German, Turkish, and others but has a problem with right-to-left language scripts. WikiTaxi does not display images.
</p>
<p><h4 id="WikiTaxi_system_requirements" data-mw-thread-id="h-WikiTaxi_system_requirements-WikiTaxi_(for_Windows)"><span data-mw-comment-start="" id="h-WikiTaxi_system_requirements-WikiTaxi_(for_Windows)"></span>WikiTaxi system requirements<span data-mw-comment-end="h-WikiTaxi_system_requirements-WikiTaxi_(for_Windows)"></span></h4></p>
<ul><li>Any Windows version starting from Windows 95 or later. Large File support (greater than 4 GB which requires an exFAT filesystem) for the huge wikis (English only at the time of this writing).</li>
<li>It also works on Linux with <a href="https://en.wikipedia.org/wiki/Wine_(software)" title="Wine (software)">Wine</a>.</li>
<li>16 MB RAM minimum for the WikiTaxi reader, 128 MB recommended for the importer (more for speed).</li>
<li>Storage space for the WikiTaxi database. This requires about 11.7 GiB for the English Wikipedia (as of 5 April 2011), 2 GB for German, less for other Wikis. These figures are likely to grow in the future.</li></ul>
<p><h4 id="WikiTaxi_usage" data-mw-thread-id="h-WikiTaxi_usage-WikiTaxi_(for_Windows)"><span data-mw-comment-start="" id="h-WikiTaxi_usage-WikiTaxi_(for_Windows)"></span>WikiTaxi usage<span data-mw-comment-end="h-WikiTaxi_usage-WikiTaxi_(for_Windows)"></span></h4></p>
<ol><li>Download WikiTaxi and extract to an empty folder. No installation is otherwise required.</li>
<li>Download the XML database dump (*.xml.bz2) of your favorite wiki.</li>
<li>Run WikiTaxi_Importer.exe to import the database dump into a WikiTaxi database. The importer takes care to uncompress the dump as it imports, so make sure to save your drive space and do not uncompress beforehand.</li>
<li>When the import is finished, start up WikiTaxi.exe and open the generated database file. You can start searching, browsing, and reading immediately.</li>
<li>After a successful import, the XML dump file is no longer needed and can be deleted to reclaim disk space.</li>
<li>To update an offline Wiki for WikiTaxi, download and import a more recent database dump.</li></ol>
<p>For WikiTaxi reading, only two files are required: WikiTaxi.exe and the .taxi database. Copy them to any storage device (memory stick or memory card) or burn them to a CD or DVD and take your Wikipedia with you wherever you go!
</p>
<p><h3 id="BzReader_and_MzReader_(for_Windows)" data-mw-thread-id="h-BzReader_and_MzReader_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump"><span id="BzReader_and_MzReader_.28for_Windows.29"></span><span data-mw-comment-start="" id="h-BzReader_and_MzReader_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span>BzReader and MzReader (for Windows)<span data-mw-comment-end="h-BzReader_and_MzReader_(for_Windows)-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span></h3></p>
<p><a rel="nofollow" href="https://code.google.com/archive/p/bzreader/">BzReader</a> is an offline Wikipedia reader with fast search capabilities. It renders the Wiki text into HTML and doesn't need to decompress the database. Requires Microsoft .NET framework 2.0.
</p><p><a rel="nofollow" href="http://homepage.ntlworld.com/bharat.vadera/MzReader/">MzReader</a> by <a href="https://en.wikipedia.org/wiki/User_talk:Mun206" title="User talk:Mun206">Mun206</a> works with (though is not affiliated with) BzReader, and allows further rendering of wikicode into better HTML, including an interpretation of the monobook skin. It aims to make pages more readable. Requires Microsoft Visual Basic 6.0 Runtime, which is not supplied with the download. Also requires Inet Control and Internet Controls (Internet Explorer 6 ActiveX), which are packaged with the download.
</p>
<p><h3 id="EPWING" data-mw-thread-id="h-EPWING-Dynamic_HTML_generation_from_a_local_XML_database_dump"><span data-mw-comment-start="" id="h-EPWING-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span>EPWING<span data-mw-comment-end="h-EPWING-Dynamic_HTML_generation_from_a_local_XML_database_dump"></span></h3></p>
<p>Offline Wikipedia database in EPWING dictionary format, which is common and an out-dated <a href="https://en.wikipedia.org/wiki/Japanese_Industrial_Standards" title="Japanese Industrial Standards">Japanese Industrial Standards</a> (JIS) in Japan, can be read including thumbnail images and tables with some rendering limits, on any systems where a reader is available (<a rel="nofollow" href="https://sites.google.com/site/boookends">Boookends</a>). There are many free and commercial readers for Windows (including Mobile), Mac OS X, iOS (iPhone, iPad), Android, Unix-Linux-BSD, DOS, and Java-based browser applications (<a rel="nofollow" href="http://maximilk.web.fc2.com/viewers.htm">EPWING Viewers</a>).
</p>
<p><h2 id="Mirror_building" data-mw-thread-id="h-Mirror_building"><span data-mw-comment-start="" id="h-Mirror_building"></span>Mirror building<span data-mw-comment-end="h-Mirror_building"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-Mirror_building","replies":["h-WP-MIRROR-Mirror_building"]}}--></p>
<p><h3 id="WP-MIRROR" data-mw-thread-id="h-WP-MIRROR-Mirror_building"><span data-mw-comment-start="" id="h-WP-MIRROR-Mirror_building"></span>WP-MIRROR<span data-mw-comment-end="h-WP-MIRROR-Mirror_building"></span></h3></p>
<dl><dd><i><b>Important:</b></i> <i>WP-mirror hasn't been supported since 2014, and community verification is needed that it actually works. <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:Database_download#Does_WP-mirror_work?" title="Wikipedia talk:Database download">See talk page</a>.</i></dd></dl>
<p><a href="https://www.mediawiki.org/wiki/Wp-mirror" title="mw:Wp-mirror">WP-MIRROR</a> is a free utility for mirroring any desired set of WMF wikis. That is, it builds a wiki farm that the user can browse locally. WP-MIRROR builds a complete mirror with original size media files. WP-MIRROR is available for <a rel="nofollow" href="http://www.nongnu.org/wp-mirror/">download</a>.
</p>
<p><h2 id="See_also" data-mw-thread-id="h-See_also"><span data-mw-comment-start="" id="h-See_also"></span>See also<span data-mw-comment-end="h-See_also"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-See_also","replies":[]}}--></p>
<ul><li><a href="https://en.wikipedia.org/wiki/DBpedia" title="DBpedia">DBpedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/WikiReader" title="WikiReader">WikiReader</a></li>
<li><a href="https://www.mediawiki.org/wiki/Help:Export" title="mw:Help:Export">mw:Help:Export</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Help:Downloading_pages" title="m:Help:Downloading pages">m:Help:Downloading pages</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Help:Import" title="m:Help:Import">m:Help:Import</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Data_dumps/Other_tools" title="meta:Data dumps/Other tools">Meta:Data dumps/Other tools</a>, for related tools, e.g. extractors and "dump readers"</li>
<li><a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_CD_Selection" title="Wikipedia:Wikipedia CD Selection">Wikipedia:Wikipedia CD Selection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia" title="Wikipedia:Size of Wikipedia">Wikipedia:Size of Wikipedia</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Mirroring_Wikimedia_project_XML_dumps" title="meta:Mirroring Wikimedia project XML dumps">meta:Mirroring Wikimedia project XML dumps</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Static_version_tools" title="meta:Static version tools">meta:Static version tools</a></li>
<li><a href="https://meta.wikimedia.org/wiki/Offline_Projects">Wikimedia offline projects</a></li></ul>
<p><h2 id="References" data-mw-thread-id="h-References"><span data-mw-comment-start="" id="h-References"></span>References<span data-mw-comment-end="h-References"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-References","replies":[]}}--></p>
<div><ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span>See <a href="https://en.wikipedia.org/wiki/Wikipedia:Reusing_Wikipedia_content#Re-use_of_text_under_the_GNU_Free_Documentation_License" title="Wikipedia:Reusing Wikipedia content">Wikipedia:Reusing Wikipedia content §&nbsp;Re-use of text under the GNU Free Documentation License</a> for more information on compatibility with the GFDL.</span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.howtogeek.com/200698/benchmarked-whats-the-best-file-compression-format/">"Benchmarked: What's the Best File Compression Format?"</a>. <i>How To Geek</i>. How-To Geek, LLC<span>. Retrieved <span>18 January</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=How+To+Geek&amp;rft.atitle=Benchmarked%3A+What%27s+the+Best+File+Compression+Format%3F&amp;rft_id=http%3A%2F%2Fwww.howtogeek.com%2F200698%2Fbenchmarked-whats-the-best-file-compression-format%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AWikipedia%3ADatabase+download"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite><a rel="nofollow" href="https://support.microsoft.com/en-us/help/14200/windows-compress-uncompress-zip-files">"Zip and unzip files"</a>. <i>Microsoft</i>. Microsoft<span>. Retrieved <span>18 January</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Microsoft&amp;rft.atitle=Zip+and+unzip+files&amp;rft_id=https%3A%2F%2Fsupport.microsoft.com%2Fen-us%2Fhelp%2F14200%2Fwindows-compress-uncompress-zip-files&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AWikipedia%3ADatabase+download"></span></span>
</li>
<li id="cite_note-AppleVolumecomparison-4"><span>^ <a href="#cite_ref-AppleVolumecomparison_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-AppleVolumecomparison_4-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/APFS_Guide/VolumeFormatComparison/VolumeFormatComparison.html">"Volume Format Comparison"</a>. <i>developer.apple.com</i><span>. Retrieved <span>2023-11-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=developer.apple.com&amp;rft.atitle=Volume+Format+Comparison&amp;rft_id=https%3A%2F%2Fdeveloper.apple.com%2Flibrary%2Farchive%2Fdocumentation%2FFileManagement%2FConceptual%2FAPFS_Guide%2FVolumeFormatComparison%2FVolumeFormatComparison.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AWikipedia%3ADatabase+download"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span> <a rel="nofollow" href="http://www.suse.com/~aj/linux_lfs.html">Large File Support in Linux</a></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><a rel="nofollow" href="http://www.h-online.com/open/news/item/Android-2-3-Gingerbread-to-use-Ext4-file-system-1152775.html">Android 2.2 and before used YAFFS file system; December 14, 2010.</a></span>
</li>
</ol></div>
<p><h2 id="External_links" data-mw-thread-id="h-External_links"><span data-mw-comment-start="" id="h-External_links"></span>External links<span data-mw-comment-end="h-External_links"></span></h2><!--__DTELLIPSISBUTTON__{"threadItem":{"headingLevel":2,"name":"h-","type":"heading","level":0,"id":"h-External_links","replies":[]}}--></p>
<ul><li><a href="https://dumps.wikimedia.org/">Wikimedia downloads</a>.</li>
<li><a rel="nofollow" href="http://dammit.lt/wikistats/">Domas visits logs</a> (<a rel="nofollow" href="http://infodisiac.com/blog/2010/07/wikimedia-page-views-some-good-and-bad-news/">read this!</a>). Also, <a rel="nofollow" href="https://archive.org/details/wikipedia_visitor_stats_200712">old data</a> in <a href="https://en.wikipedia.org/wiki/Internet_Archive" title="Internet Archive">the Internet Archive</a>.</li>
<li><a href="https://meta.wikimedia.org/wiki/Mailing_lists/Overview" title="meta:Mailing lists/Overview">Wikimedia mailing lists</a> archives.</li>
<li><a href="https://en.wikipedia.org/wiki/User:Emijrp/Wikipedia_Archive" title="User:Emijrp/Wikipedia Archive">User:Emijrp/Wikipedia Archive</a>. An effort to find all the Wiki[mp]edia available data, and to encourage people to download it and save it around the globe.</li>
<li><a rel="nofollow" href="https://github.com/WikiTeam/wikiteam/blob/master/wikipediadownloader.py">Script to download all Wikipedia 7z dumps</a>.</li></ul>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐d68c94cb‐z7kwv
Cached time: 20250419113528
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
DiscussionTools time usage: 0.042 seconds
CPU time usage: 0.462 seconds
Real time usage: 0.624 seconds
Preprocessor visited node count: 1674/1000000
Post‐expand include size: 25045/2097152 bytes
Template argument size: 933/2097152 bytes
Highest expansion depth: 14/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 27959/5000000 bytes
Lua time usage: 0.218/10.000 seconds
Lua memory usage: 4618696/52428800 bytes
Number of Wikibase entities loaded: 0/500
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  470.816      1 -total
 23.33%  109.826      3 Template:Cite_web
 21.64%  101.876      1 Template:Reader_help
 20.66%   97.248      1 Template:Sidebar
 18.05%   84.996      1 Template:Wikipedia_how-to
 14.93%   70.306      1 Template:Ombox
  8.50%   40.040      1 Template:Short_description
  7.85%   36.970      1 Template:Shortcut
  6.46%   30.403      1 Template:Cn
  5.90%   27.792      1 Template:Startflatlist
-->

<!-- Saved in parser cache with key enwiki:pcache:68321:|#|:idhash:canonical and timestamp 20250419113528 and revision id 1284893687. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shardines: SQLite3 Database-per-Tenant with ActiveRecord (229 pts)]]></title>
            <link>https://blog.julik.nl/2025/04/a-can-of-shardines</link>
            <guid>43811400</guid>
            <pubDate>Sun, 27 Apr 2025 12:16:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.julik.nl/2025/04/a-can-of-shardines">https://blog.julik.nl/2025/04/a-can-of-shardines</a>, See on <a href="https://news.ycombinator.com/item?id=43811400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

	<article>

    
		

<small>
  
    
  &nbsp;·&nbsp;<time datetime="2025-04-25T00:00:00+00:00">25 Apr 2025</time>
</small>

    <p>There is a pattern I am very fond of - “one database per tenant” in web applications with multiple, isolated users. Recently, I needed to fix an application I had for a long time where this database-per-tenant multitenancy utterly broke down, because I was doing connection management wrong. Which begat the question: how do you even approach doing it right?</p>

<p>And it turns out I was not alone in this. The most popular gem for multitenancy - Apartment - which I have even used in my failed startup back in the day -
<a href="https://github.com/rails-on-services/apartment/issues/304#issuecomment-2648202324">has the issue too.</a></p>

<p>The culprit of <q>does not handle multithreading very well</q> is actually deeper. Way deeper. Doing runtime-defined multiple databases with Rails has only recently become less haphazard, and there are no tools either via gems or built-in that facilitate these flows. It has also accrued a ton of complexity, and also changes with every major Rails revision.</p>

<p><strong>TL;DR</strong> If you need to do database-per-tenant multitenancy with Rails or ActiveRecord <em>right now</em> - grab the middleware from <a href="https://gist.github.com/julik/69066f5a819ac3b38480d42c1351f8ef">this gist</a> and move on.</p>

<p>If you are curious about the genesis of this solution, strap in - we are going on a tour of a sizeable problem, and of an API of stature - the ActiveRecord connection management. 
Read on and join me on the ride! Many thanks to <a href="https://kirshatrov.com/">Kir Shatrov</a> and <a href="https://fractaledmind.com/">Stephen Margheim</a> for their help in this.</p>

<!--more-->

<h2 id="the-advantages-of-the-database-per-tenant">The advantages of the “database per tenant”</h2>

<p>If you have a tenanted application (your “tenant” is a subgraph of your data model that can function independently, and mostly references other entities from within itself), you have a number of ways to approach an architecture like that. Imagine we have a system where the tenant is a <code>Site</code>. That system is some kind of end-user-serviceable CMS, and users own multiple <code>Sites</code> and can manage pages, media and other items within a <code>Site</code>. The data model will be as follows:</p>

<div><pre><code><span>class</span> <span>Site</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
<span>end</span>

<span>class</span> <span>Page</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
  <span>belongs_to</span> <span>:site</span>
  <span>has_many</span> <span>:media_blocks</span>
  <span>has_many</span> <span>:pages</span><span>,</span> <span>through: :media_blocks</span>
<span>end</span>

<span>class</span> <span>MediaBlock</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
  <span>belongs_to</span> <span>:media_item</span>
  <span>belongs_to</span> <span>:page</span>
<span>end</span>

<span>class</span> <span>Comment</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
  <span>belongs_to</span> <span>:page</span> <span># and thus to a Site, "through"</span>
<span>end</span>

<span>class</span> <span>MediaItem</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
  <span>has_many</span> <span>:media_items</span>
  <span>has_many</span> <span>:pages</span><span>,</span> <span>through: :media_items</span>
  <span>has_one_</span> <span>:site</span><span>,</span> <span>through: :pages</span> <span># since it can be reused across multiple pages</span>
<span>end</span>
</code></pre></div>

<p>Sites very rarely get merged together, and 99% of the data that gets created within a <code>Site</code> stays inside that <code>Site</code>, forever. Either because your system has outgrown hosting a single <code>Site</code>, or because you want to have robust isolation (you don’t want Jane to post to her <code>Site</code> only for the article to end up on Blake’s <code>Site</code> by mistake), or because your system is wildly successful and profitable, you may want to apply the following strategies:</p>

<ul>
  <li>Just like our initial model - the <code>Site</code> has an <code>id</code>, some models link to it directly, some - through others</li>
  <li>Every model gets a <code>site_id</code>. Every <code>INSERT</code>, <code>UPDATE</code> or <code>DELETE</code> then knows which <code>Site</code> a particular model makes part of - and a deletion can address the database where the site is stored. Databases will then be <em>shards</em> and store multiple <code>Sites</code>. If you decide to become a host for Slashdot, and get millions of <code>Page</code> records and bullions of <code>Comment</code> records, they will likely be extracted into a separate DB. There will be a mapping table of sorts, that will record that <code>slashdot.org</code> gets mapped to <code>db_slashdot_tenant</code> explicitly.</li>
  <li>Just like our initial model - but there is only <em>one</em> <code>Site</code> record in the entire database. All records belonging to a <code>Site</code> are stored inside that database.</li>
</ul>

<p>There are other tricks for doing sharding/multitenancy well - for example, using generated primary keys which contain the tenant ID within them - so that shards can be merged, etc.</p>

<p>But what interests us here, specifically, is the last approach - having one database per tenant. For my smaller sites, using SQLite as the database has become part and parcel. Having a DB server that you can configure easily is very good. Having a database server that you do not have to configure at all - exceptional, though. Same for backups: centralised backup is great and useful. But nothing beats an <code>rsync</code> if that’s all you need to do a backup. And the schema becomes smaller too - we can move the <code>Site</code> out of the database outright, and the rest of the models no longer needs the associations to <code>site</code>:</p>

<pre><code>class Page &lt; ActiveRecord::Base
  has_many :media_blocks
  has_many :pages, through: :media_blocks
end

class MediaBlock &lt; ActiveRecord::Base
  belongs_to :media_item
  belongs_to :page
end

class Comment &lt; ActiveRecord::Base
  belongs_to :page # and thus to a Site, "through"
end

class MediaItem &lt; ActiveRecord::Base
  has_many :media_blocks
end
</code></pre>

<p>Development-wise those setups are a breeze too - if you need to debug something inside a particular <code>Site</code>, all you need to do is download this site’s data. With just one <code>scp</code> command, usually. And there are elephants in the room too:</p>

<ul>
  <li>Doing schema migrations where a migration runs on one tenant, but fails on another</li>
  <li>Accessing the same DB from multiple servers</li>
  <li>Doing backups is somewhat unorthodox - there are many ways to do it</li>
</ul>

<p>But remember: using this approach has one jarring advantage. It firmly pushes you out of the “big data” territory, and even out of “medium data” - it is “tiny data”.</p>

<blockquote>
  <p>“Data which, when stored on immediately-accessible random-read storage media of reasonable speed, does not fit under your desk” is my formal definition for “big data”, if that helps.</p>
</blockquote>

<p>Some joints were exceptionally successful doing this. <a href="https://use.expensify.com/blog/scaling-sqlite-to-4m-qps-on-a-single-server">Expensify,</a> for one, is notorious for pushing and pulling SQLite well beyond the boundaries most folks would call comfortable. I know that Autodesk’s own ShotGrid - back when it used to be Shotgun and was an independent software product - used SQLite3 pretty extensively. Along with the obligatory <code>SQLite3::BusyException</code> every now and then 😉</p>

<h2 id="why-this-is-challenging-with-rails">Why this is challenging with Rails</h2>

<p>When using SQLite3 “bare”, handling a database “open” and “close” is absolutely trivial:</p>

<div><pre><code><span>SQLite3</span><span>::</span><span>Database</span><span>.</span><span>open</span><span>(</span><span>"site_1.sqlite3"</span><span>)</span> <span>do</span> <span>|</span><span>db</span><span>|</span>
  <span>site_title</span> <span>=</span> <span>db</span><span>.</span><span>get_first_value</span><span>(</span><span>"SELECT title FROM sites LIMIT 1"</span><span>)</span>
  <span>pages</span> <span>=</span> <span>db</span><span>.</span><span>execute</span><span>(</span><span>"SELECT * FROM pages "</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>If we use Rack, we just wrap this in a middleware:</p>

<div><pre><code><span>def</span> <span>call</span><span>(</span><span>env</span><span>)</span>
  <span>SQLite3</span><span>::</span><span>Database</span><span>.</span><span>open</span><span>(</span><span>"site_1.sqlite3"</span><span>)</span> <span>do</span> <span>|</span><span>db</span><span>|</span>
    <span>@app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>.</span><span>merge</span><span>(</span><span>"site_db"</span> <span>=&gt;</span> <span>db</span><span>))</span>
  <span>end</span>
<span>end</span>  
</code></pre></div>

<p>But for this to work, the <code>db</code> variable - the handle to the database - has to be explicitly used for every query! ActiveRecord, however, manages the connections not through a variable you give it, but through it’s own “recollection” of what database a particular ActiveRecord <a href="https://stackoverflow.com/questions/141201/how-to-best-handle-per-model-database-connections-with-activerecord">superclass connects to:</a></p>

<div><pre><code>class Page &lt; ActiveRecord::Base
  establish_connection database: "site_1.sqlite3"
end
</code></pre></div>

<p>Needless to say, this code runs just once (and you don’t know exactly “when” - to which the answer is <em>at first query</em>), and is not at all designed for disconnecting and reconnecting all the time. Now, if there was a way to do this:</p>

<div><pre><code><span>class</span> <span>Page</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
  <span>obtain_connection_from</span> <span>{</span> <span>tenancy_system</span><span>.</span><span>database_config</span> <span>}</span>
<span>end</span>
</code></pre></div>

<p>it would have been easier, but alas. And with the addition of connection pooling, query cache, schema cache - you are looking at a sizeable contraption of <a href="https://www.youtube.com/watch?v=LFrdqQZ8FFc">things which are put on top of other things.</a> Which is what makes this exercise so frustrating: you know something utterly trivial with a “bare” API is infuriatingly complicated when doing it through ActiveRecord. Moreover - this is one of the headliner use-cases for SQLite3, and ActiveRecord seems to make it nigh-impossible to execute.</p>

<p>How come?</p>

<h2 id="churn-inevitable">Churn, inevitable</h2>

<p>The reason for difficulties with multiple databases in Rails comes down to the history of that feature and the needs of the <em>hyperscalers</em> - the Githubs, the Shopifys and the Zendesks of the ecosystem.</p>

<p>Since I have been using Rails - and this ActiveRecord - for quite a long while - here is a brief history recap:</p>

<ul>
  <li>Rails 1 already had database assignment per <code>ActiveRecord::Base</code> subclass</li>
  <li>Rails 3 added connection pooling</li>
  <li>Rails 4 added <code>connection_handling</code> (albeit - hidden)</li>
  <li>Rails 6 added <code>connected_to</code></li>
  <li>Rails 7 expanded on <code>connected_to</code> with the addition of shards (so now you have both roles and shards)</li>
</ul>

<p>The interesting part of it all is that while ActiveRecord <a href="https://github.com/rails/rails/blob/main/activerecord/examples/simple.rb">example code</a> includes snippets like this:</p>

<div><pre><code><span>class</span> <span>Person</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Base</span>
  <span>establish_connection</span> <span>adapter: </span><span>"sqlite3"</span><span>,</span> <span>database: </span><span>"foobar.db"</span>
  <span>connection</span><span>.</span><span>create_table</span> <span>table_name</span><span>,</span> <span>force: </span><span>true</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
    <span>t</span><span>.</span><span>string</span> <span>:name</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>the changes in how Rails handles multiple databases have led to the fact that this example code is useful only in a very small number of cases. For example: with a snippet like this, how do we <code>close_connection</code>? Or, how do we tell <code>Person</code> to connect to a different database after having done a query or two?</p>

<p>If you start looking into this, an entire world opens befor your eyes. And this world has its own taxonomy - and it is sizeable. <code>ConnectionHandling</code>, <code>DatabaseConfig</code>, <code>DatabaseConfigurations</code> (yes, plural), <code>Resolver</code>, <code>PoolConfig</code>, <code>PoolManager</code>… and all these things interact, live and breathe in a carefully managed dance. Spoiler: they can do everything we need, but we have to conduct them like a little orchestra - <em>just like so.</em></p>

<h2 id="divergent-api-design">Divergent API design</h2>

<p>The way ActiveRecord is designed - having model classes with no explicit way to tell them “through which connection” they should work for this query - means that there will always be some hidden state. It can be a global, or a class variable (which is… a glorified global) - or a thread-local, but somewhere there <em>is</em> a connection, and until recently (Rails 6, to be exact) there was no official way to tell ActiveRecord which connection to use.</p>

<p>In theory, an API like this could be realised:</p>

<p><code>Page.with_connection(tenant_db_conn).first</code></p>

<p>However, this database connection argument would then need to be provided to every call to ActiveRecord - and the API is truly vast.</p>

<p>An extra complication is that a lot of the design of AR assumes that a connection to the database (and that it is going to be <em>the</em> database) will be opened early, and then kept intact. The schema cache (letting ActiveRecord subclasses know which columns are in the tables, for example) gets loaded once. The query cache gets initialised once. Migrations get run once - and, again, they run on <em>the</em> database,</p>

<h2 id="divergent-configuration-lifecycle">Divergent configuration lifecycle</h2>

<p>If you want to build a multitenant system of small tenants using SQLite3, with a single database being allocated per tenant, your needs are not exactly in alignment with a hypothetical Shopify: they want to have <code>cluster_a</code>, <code>cluster_b</code>, <code>cluster_eu</code> and <code>cluster_us</code>, each tens of terabytes in size. You, instead, want to have <code>site_1</code>, <code>site_2</code> and so on - with some being just a few KB in size.</p>

<p>This would mean that for them, the configuration of those big clusters can be output into <code>database.yml</code> programmatically. It can be source-controlled, and follow strict and specific semantics regarding</p>

<ul>
  <li>When the file gets read</li>
  <li>Whether (and when) templating is done in it, for example - to inject credentials</li>
  <li>That all internal datastructures - such as connection pools - get initialised ahead of time</li>
  <li>Preconfigured, large clusters where data is usually sharded - using things like <code>shop_id</code> - but not segregated.</li>
</ul>

<p>None of the “big guys” from the mentioned three have true, single-database-per-tenant setups – or at least I never heard they do.</p>

<p>Most of the modern ActiveRecord infrastructure is built around those assumptions, not because the makers of the feature want to work against what “we” want - they just made different tradeoffs.</p>

<h2 id="divergent-db-engine-tradeoffs">Divergent DB engine tradeoffs</h2>

<p>Another important item is database performance. “Big” database servers are designed with some assumptions. For example, if you have a database, the engine would be interested in holding file descriptors open for that database or <code>mmap()</code>ed files from it. If the tablespaces are large - they will be cached in memory, and cached fairly aggressively. If there are indices - the engine will try to cache them in memory as well, and keep access to the files containing the index data close at hand.</p>

<p>The end result is that, at least when I was working on an Apartment-based system with MySQL 5.7, after a certain number of databases created you would start hitting file descriptor limits. Those are set low on MacOS, but it was still noticeable - and it was clear that it was a question of time (and scale) - which we haven’t hit though - before that would become an actual problem.</p>

<p>On balance, thus, a database server is optimised for <em>few large databases</em> – not for thousands of small ones. This is another reason why the approach with a static <code>database.yml</code> seemed so appealing.</p>

<p>Just check <a href="https://kirshatrov.com/posts/fast-skip-locked">this article</a> out:</p>

<blockquote>
  <p>By implementing these optimizations, I’ve seen remarkable performance improvements: single MySQL server handling 2M+ ticket reservation transactions per minute while the average latency of SELECT … FOR UPDATE SKIP LOCKED query staying under 400μS.</p>
</blockquote>

<p>This is the kind of perf those “big engines” optimise for. Not “quickly handling 120 pages within this site, which is one of 2 thousands”.</p>

<p>With SQLite3, the story is completely different. SQLite3 <em>thrives</em> with multiple small databases. Since a SQLite3 database is just a file (well, 3 files sometimes, but you get the point), it makes perfect sense to have a single database per tenant in the system. Since the system is multitenanted, a request for tenant <code>A</code> is guaranteed not to need data from tenant <code>B</code>. Moreover - when we are handling a request for tenant <code>A</code>, we don’t need any resources from <code>B</code> - so we don’t even need a connection (file handle).</p>

<p>Having smaller SQLite3 databases has more affordances - for example, it’s much faster - and more granular - to do backups on a per-tenant basis. Debugging becomes much easier - instead of doing a sophisticated sequence of <code>SELECT</code>s to extract the “slice” of data for a particular tenant, you just copy the tenant’s DB wholesale. Same for granular restore. Same for deletions - removing a tenant, even a large one, is just an <code>unlink</code> away.</p>

<p>So one of the reasons why the modern multi-DB features in Rails do not support dynamic tenant management with automatically allocated databases - in large numbers - is because, at least on the surface, only SQLite3 currently makes this pattern viable.</p>

<p>And it’s not only viable – it is <em>glorious.</em> Did you know that the way iCloud works, for example, is literally millions of isolated SQLite databases, stored <em>inside</em> of larger Cassandra databases?</p>

<h2 id="back-to-the-original-problem">Back to the original problem</h2>

<p>So, I had an app. It has been running for more than a decade now. It was initially built with static HTML with some templating getting pre-processed before server upload using <code>rsync</code> - it was a glorified static site generator, essentially. Then came the “admin” features, and the app acquired databases. From the get go, the app - which is a mini-CMS of sorts - provided every website owner a UI to edit the content of their website. Every website also has its own database. Requests between them never cross - and no <code>site_id</code> is involved anywhere in the process.</p>

<p>Initially it was based on raw ERB and some glue code. Then it got rewritten into Camping, and the database switching looked roughly like the <code>establish_connection</code> example above. This was pre-Rails-3, so no Rack middleware, no frills, no nothing.</p>

<p>With the ActiveRecord 3 upgrade came the dance of splitting code into something more appropriate, along with a changeover to Sinatra. And the connection management - which got moved into a Rack middleware - took the following shape:</p>

<div><pre><code><span>def</span> <span>call</span><span>(</span><span>env</span><span>)</span>
  <span>begin</span>
    <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>establish_connection</span><span>(</span><span>adapter: </span><span>'sqlite3'</span><span>,</span> 
      <span>database: </span><span>env</span><span>.</span><span>fetch</span><span>(</span><span>'site_db_path'</span><span>),</span>
      <span>timeout: </span><span>BUSY_TIMEOUT</span><span>)</span>

    <span>s</span><span>,</span> <span>h</span><span>,</span> <span>b</span> <span>=</span> <span>app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>.</span><span>merge</span><span>(</span><span>'database'</span> <span>=&gt;</span> <span>self</span><span>))</span>
    <span>connection_closing_body</span> <span>=</span> <span>::</span><span>Rack</span><span>::</span><span>BodyProxy</span><span>.</span><span>new</span><span>(</span><span>b</span><span>)</span> <span>do</span>
      <span>::</span><span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>clear_active_connections!</span>
    <span>end</span>
    <span>[</span><span>s</span><span>,</span> <span>h</span><span>,</span> <span>connection_closing_body</span><span>]</span>
  <span>rescue</span> <span>Exception</span>
    <span>::</span><span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>clear_active_connections!</span>
    <span>raise</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>And this worked… mostly. Around the same time I have installed Sentry, but I didn’t take the habit of looking at it regularly - don’t remember the exact reasons. But, after a few years of painless operation, the app started throwing odd errors. The error that caught my eye was <code>ActiveRecord::ConnectionNotEstablished</code>, and it became more frequent the more load on the site there was. More visits - more frequent errors. Fast-forward a few years, and the error became quite frequent.</p>

<p>My assumption was that to figure out what is going on, I can better upgrade to at least ActiveRecord 6. This version is the oldest Rails version which, by virtue of Ruby version compatibilities, was already able to run on Apple Silicon - <a href="https://blog.julik.nl/2025/03/a-little-adventure-in-modern-frontend">which I am a proud owner of now.</a></p>

<p>Some hours later and a multitude of CoffeeScript files converted (and even more Ruby files edited) the update was complete. I tested it locally, verified everything was in good working order, and deployed the app.</p>

<p>And just 30 minutes in - <code>ConnectionNotEstablished</code>. And not only that, but 10x as frequently as before. The update hasn’t fixed the problem – in fact, it made it worse. Some experiments I did:</p>

<ul>
  <li>Allocating a separate connection pool per tenant and managing it myself</li>
  <li>Doing a connection checkout from a pool and checking it back into the pool</li>
  <li>Juju and voodoo magic</li>
</ul>

<p>Nothing worked. With a helpful hint from <a href="https://kirshatrov.com/posts">Kir</a> – who is responsible for exactly the managing of database sharding at one of the “big boys” – I got the idea that it should be possible to use the new <code>roles:</code> parameter - and a fake database configuration - to achieve this functionality.</p>

<p>My mistake was that I was trying to manage pools and connections myself, manually - while the new Rails functionality is actually geared towards Rails maging the pools and connections <em>for you.</em> So in this instance there was also… a divergent understanding of the API.</p>

<p>I was still in the paradigm that you use <code>establish_connection</code> - like in the olden days - to manage that infrastructure. But the “blessed” approach is actually to furnish Rails the connection configurations and let it handle them automatically.</p>

<h2 id="the-solution">The solution</h2>

<p><code>ActiveRecord::Base</code> now has a class method called <code>connected_to</code>. It allows you to do exactly the thing you need for a database-per-tenant setup - hop into a block with something being your “main” database. Previously, it accepted <code>database:</code> with a whole DB configuration, but now it only accepts <code>role:</code> (and - with Rails 7 and above - <code>shard:</code>). This is how you use it:</p>

<div><pre><code><span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connected_to</span><span>(</span><span>shard: </span><span>"sites_1"</span><span>)</span> <span>do</span>
  <span>site</span> <span>=</span> <span>Site</span><span>.</span><span>find</span><span>(</span><span>site_id</span><span>)</span> <span># Which lives on this shard, "sites_1"</span>
  <span>posts</span> <span>=</span> <span>site</span><span>.</span><span>pages</span><span>.</span><span>order</span><span>(</span><span>created_at: :desc</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>The challenge is where the <code>sites_1</code> gets configured. Normally it would be in your <code>database.yml</code>, as per the <a href="https://guides.rubyonrails.org/active_record_multiple_databases.html">official doc:</a></p>

<div><pre><code><span>production</span><span>:</span>
  <span>primary</span><span>:</span>
    <span>database</span><span>:</span> <span>my_primary_database</span>
    <span>adapter</span><span>:</span> <span>mysql2</span>
  <span>primary_replica</span><span>:</span>
    <span>database</span><span>:</span> <span>my_primary_database</span>
    <span>adapter</span><span>:</span> <span>mysql2</span>
    <span>replica</span><span>:</span> <span>true</span>
  <span>primary_shard_one</span><span>:</span>
    <span>database</span><span>:</span> <span>my_primary_shard_one</span>
    <span>adapter</span><span>:</span> <span>mysql2</span>
    <span>migrations_paths</span><span>:</span> <span>db/migrate_shards</span>
</code></pre></div>

<p>But if you want to switch between tenants live - and tenants get created (and deleted!) at runtime - having this static config with cross-referencing keys is not going to fly at all. Moreover - even if you can change that “God config” – how do you force ActiveRecord to reload it? How can you tell ActiveRecord that a shard/tenant no longer exists? And how do you do it in a thread-safe manner? Does it lead to a reinitialisation of all the connection pools, or just addition-deletion?</p>

<p>The solution then becomes focused in one area: taking over from ActiveRecord in managing those connection pools and naming the <code>roles</code> and <code>shards</code> automatically. This is where the bulk of the work was, in the end. We want to convert our tenant database name/filename into a string to devise the <code>role</code> name that we can furnish to AR. For me, I only went to update to Rails 6, so I didn’t go into shards yet. If I did (and I might, eventually) - the tenant name would be the <code>shard</code>, and the <code>reading</code> and <code>writing</code> roles could be used for hosting a <code>readonly: true</code> DB connection and a writable one. However, a method I ended up using does <em>not</em> support shards even on Rails 8, so read on.</p>

<h2 id="so-how-do-we-create-those-pools">So how do we create those pools?</h2>

<p>The way to do it is to <em>query</em> ActiveRecord for whether a particular connection pool is already setup or not. If it is not - there is going to be a <code>NoConnectionPool</code> exception if you try to switch to the role/shard that doesn’t exist. But doing this via rescues is not great – the control flow becomes a bit intricate. What we can do instead is check whether there is a connection pool set up for a particular role/shard, and then connect if there are none. Note that since this manages pools - it needs to be protected by a mutex:</p>

<div><pre><code><span>MUX</span><span>.</span><span>synchronize</span> <span>do</span>
  <span>if</span> <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>connection_pool_list</span><span>(</span><span>role_name</span><span>).</span><span>none?</span>
    <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>establish_connection</span><span>(</span><span>database_config_hash</span><span>,</span> <span>role: </span><span>role_name</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>After that we can use <code>connected_to</code> - which is going to be thread-safe, fast and pretty neat:</p>

<div><pre><code><span>MUX</span><span>.</span><span>synchronize</span> <span>do</span>
  <span>if</span> <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>connection_pool_list</span><span>(</span><span>role_name</span><span>).</span><span>none?</span>
    <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>establish_connection</span><span>(</span><span>database_config_hash</span><span>,</span> <span>role: </span><span>role_name</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connected_to</span><span>(</span><span>role: </span><span>role_name</span><span>)</span> <span>do</span>
  <span>pages</span> <span>=</span> <span>Page</span><span>.</span><span>order</span><span>(</span><span>created_at: :desc</span><span>).</span><span>limit</span><span>(</span><span>10</span><span>)</span> <span># Only selects from that site/tenant</span>
<span>end</span>
</code></pre></div>

<h2 id="dont-forget-about-streaming-rack-bodies">Don’t forget about streaming Rack bodies</h2>

<p>There is a small additional element we need to take care of, though: doing it correctly in Rack. To have something similar to <a href="https://github.com/rails-on-services/apartment/blob/development/lib/apartment/elevators/generic.rb">Apartment::Elevator</a> we need to do something that - again - <code>apartment</code> doesn’t do correctly. If we assume all the renders of our app are buffered, we can do this:</p>

<div><pre><code><span>def</span> <span>call</span><span>(</span><span>env</span><span>)</span>
  <span>site_name</span> <span>=</span> <span>env</span><span>[</span><span>"SERVER_NAME"</span><span>]</span>
  <span>connection_config_hash</span> <span>=</span> <span>{</span><span>adapter: </span><span>"sqlite3"</span><span>,</span> <span>database: </span><span>"sites/</span><span>#{</span><span>site_name</span><span>}</span><span>.sqlite3"</span><span>}</span>
  <span>role_name</span> <span>=</span> <span>"site_</span><span>#{</span><span>site_name</span><span>}</span><span>"</span>

  <span># Create a connection pool for that tenant if it doesn't exist</span>
  <span>MUX</span><span>.</span><span>synchronize</span> <span>do</span>
    <span>if</span> <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>connection_pool_list</span><span>(</span><span>role_name</span><span>).</span><span>none?</span>
      <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>establish_connection</span><span>(</span><span>connection_config_hash</span><span>,</span> <span>role: </span><span>role_name</span><span>)</span>
    <span>end</span>
  <span>end</span>
  <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connected_to</span><span>(</span><span>role: </span><span>role_name</span><span>)</span> <span>do</span>
    <span>@app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>)</span> <span># returns [status, header, body]</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>But we are aware, of course, that Rack bodies are <em>callable</em> and <em>iterable</em> - and Rack response bodies may also just be doing SQL queries. Code that lives in the Rack response body and serves streaming data is not any less useful than the one living in the app <code>call()</code> method, even though much fewer people use it. I even worked on a <a href="https://github.com/appsignal/appsignal-ruby/pull/1037">big patch to Appsignal, my favorite APM</a> that made it report what happens inside a Rack streaming body the same way it would for the app’s <code>call</code>. The way it usually works for resource release with those bodies is this:</p>

<div><pre><code><span>f</span> <span>=</span> <span>File</span><span>.</span><span>open</span><span>(</span><span>path</span><span>,</span> <span>"rb"</span><span>)</span>
<span>status</span><span>,</span> <span>headers</span><span>,</span> <span>body</span> <span>=</span> <span>@app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>)</span>
<span>body_with_close</span> <span>=</span> <span>Rack</span><span>::</span><span>BodyProxy</span><span>.</span><span>new</span><span>(</span><span>body</span><span>)</span> <span>{</span> <span>f</span><span>.</span><span>close</span> <span>}</span>
<span>[</span><span>status</span><span>,</span> <span>headers</span><span>,</span> <span>body_with_close</span><span>]</span>
</code></pre></div>

<p>This attaches a callback to the <code>#close</code> method of the Rack body we return, which - according to the Rack [SPEChttps://github.com/rack/rack/blob/main/SPEC.rdoc] - <em>must</em> be called by the webserver <em>or</em> by the calling middleware.</p>

<p>Reasonably enough, the ActiveRecord API for <code>connected_to</code> only works with a block. That’s a good idea from the point of encouraging the correct (and safe) usage of a rather blunt tool. However, specifically in this case, it gets in the way. Luckily, this problem can be bypassed with judicious <a href="https://blog.appsignal.com/2018/11/27/ruby-magic-fibers-and-enumerators-in-ruby.html">application of a Fiber:</a></p>

<div><pre><code><span>connected_to_context_fiber</span> <span>=</span> <span>Fiber</span><span>.</span><span>new</span> <span>do</span>
  <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connected_to</span><span>(</span><span>role: </span><span>role_name</span><span>)</span> <span>do</span>
    <span>Fiber</span><span>.</span><span>yield</span>
  <span>end</span>
<span>end</span>
<span>connected_to_context_fiber</span><span>.</span><span>resume</span>

<span>status</span><span>,</span> <span>headers</span><span>,</span> <span>body</span> <span>=</span> <span>@app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>)</span>
<span>body_with_close</span> <span>=</span> <span>Rack</span><span>::</span><span>BodyProxy</span><span>.</span><span>new</span><span>(</span><span>body</span><span>)</span> <span>{</span> <span>connected_to_context_fiber_</span><span>.</span><span>resume</span> <span>}</span>

<span>[</span><span>status</span><span>,</span> <span>headers</span><span>,</span> <span>body_with_close</span><span>]</span>
</code></pre></div>

<p>And thus, our “tenant switching middleware” for ActiveRecord connection management with one database per tenant becomes:</p>

<div><pre><code><span>class</span> <span>Shardine</span>
  <span>MUX</span> <span>=</span> <span>Mutex</span><span>.</span><span>new</span>

  <span>def</span> <span>initialize</span><span>(</span><span>connection_config</span><span>)</span>
    <span>@config</span> <span>=</span> <span>connection_config</span>
    <span>@role_name</span> <span>=</span> <span>connection_config</span><span>.</span><span>fetch</span><span>(</span><span>:database</span><span>).</span><span>to_s</span>
  <span>end</span>

  <span>def</span> <span>with</span><span>(</span><span>&amp;</span><span>blk</span><span>)</span>
    <span># Create a connection pool for that tenant if it doesn't exist</span>
    <span>MUX</span><span>.</span><span>synchronize</span> <span>do</span>
      <span>if</span> <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>connection_pool_list</span><span>(</span><span>@role_name</span><span>).</span><span>none?</span>
        <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connection_handler</span><span>.</span><span>establish_connection</span><span>(</span><span>@config</span><span>,</span> <span>role: </span><span>@role_name</span><span>)</span>
      <span>end</span>
    <span>end</span>
    <span>ActiveRecord</span><span>::</span><span>Base</span><span>.</span><span>connected_to</span><span>(</span><span>role: </span><span>@role_name</span><span>,</span> <span>&amp;</span><span>blk</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>enter!</span>
    <span>@fiber</span> <span>=</span> <span>Fiber</span><span>.</span><span>new</span> <span>do</span>
      <span>with</span><span>(</span><span>conn</span><span>)</span> <span>{</span> <span>Fiber</span><span>.</span><span>yield</span> <span>}</span>
    <span>end</span>
    <span>@fiber</span><span>.</span><span>resume</span>
    <span>true</span>
  <span>end</span>

  <span>def</span> <span>leave!</span>
    <span># Probably there is something in ConnectionHandling</span>
    <span># that can be used here, but I was too lazy to look</span>
    <span>to_resume</span><span>,</span> <span>@fiber</span> <span>=</span> <span>@fiber</span><span>,</span> <span>nil</span>
    <span>to_resume</span><span>&amp;</span><span>.</span><span>resume</span>
  <span>end</span>

  <span>class</span> <span>Middleware</span>
    <span>def</span> <span>initialize</span><span>(</span><span>app</span><span>,</span> <span>&amp;</span><span>database_config_lookup</span><span>)</span>
      <span>@app</span> <span>=</span> <span>app</span>
      <span>@lookup</span> <span>=</span> <span>database_config_lookup</span>
    <span>end</span>

    <span>def</span> <span>call</span><span>(</span><span>env</span><span>)</span>
      <span>connection_config</span> <span>=</span> <span>@lookup</span><span>.</span><span>call</span><span>(</span><span>env</span><span>)</span>
      <span>switcher</span> <span>=</span> <span>TenantDatabaseSwitcher</span><span>.</span><span>new</span><span>(</span><span>connection_config</span><span>)</span>
      <span>did_enter</span> <span>=</span> <span>switcher</span><span>.</span><span>enter!</span>
      <span>status</span><span>,</span> <span>headers</span><span>,</span> <span>body</span> <span>=</span> <span>@app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>)</span>
      <span>body_with_close</span> <span>=</span> <span>Rack</span><span>::</span><span>BodyProxy</span><span>.</span><span>new</span><span>(</span><span>body</span><span>)</span> <span>{</span> <span>switcher</span><span>.</span><span>leave!</span> <span>}</span>
      <span>[</span><span>status</span><span>,</span> <span>headers</span><span>,</span> <span>body_with_close</span><span>]</span>
    <span>rescue</span>
      <span>switcher</span><span>.</span><span>leave!</span> <span>if</span> <span>did_enter</span>
      <span>raise</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>which we then configure in <code>config.ru</code> (or in Rails similarly) like so:</p>

<div><pre><code><span>use</span> <span>Shardine</span><span>::</span><span>Middleware</span> <span>do</span> <span>|</span><span>env</span><span>|</span>
  <span>site_name</span> <span>=</span> <span>env</span><span>[</span><span>"SERVER_NAME"</span><span>]</span>
  <span>{</span><span>adapter: </span><span>"sqlite3"</span><span>,</span> <span>database: </span><span>"sites/</span><span>#{</span><span>site_name</span><span>}</span><span>.sqlite3"</span><span>}</span>
<span>end</span>
</code></pre></div>

<p>And there you go - a safe and performant database-per-tenant switcher.</p>

<h2 id="an-additional-hurdle">An additional hurdle</h2>

<p>Since I was upgrading to Rails 6 - which seemed the lowest “modern” version I really had to go to - there was an extra snag.</p>

<p>By default, when you use ActiveRecord without Rails, it gets configured “conservatively” - or, rather, not configured at all. Rails 6 has the concept of <code>legacy_connection_handling</code>. Without going into too much detail, to make this solution work that parameter must be turned off explicitly. In Rails 7 and above this parameter no longer exists.</p>

<h2 id="some-remaining-work">Some remaining work</h2>

<p>Since I initially migrated my app to ActiveRecord 6 I don’t have <code>shard</code> support yet. It would actually make perfect sense to have your “reading replica” be a <code>readonly: true</code> SQLite3 database, <a href="https://fractaledmind.github.io/2024/04/11/sqlite-on-rails-isolated-connection-pools/">as Stephen has written.</a></p>

<p>Another aspect is that there’s currently no API to remove a connection pool if a tenant gets removed from the system, which I just don’t need (my tenants don’t change as frequently).</p>

<p>Handling other contexts when you need to “step into” a Tenant can be handled similarly, either using <code>connected_to</code> or using the fiber approach.</p>

<p>And, of course, the “database per tenant” workflow is just starting and it’s only in the recent years, with product from the ONCE family specifically, where SQLite3 began to shine again - as an engine of “small data, in big numbers”.</p>

<p>May we live to see this pattern come into the spotlight, finally.</p>


  </article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mesmerizing Interlocking Geometric Patterns Produced with Japanese Woodworking (108 pts)]]></title>
            <link>https://www.smithsonianmag.com/smithsonian-institution/see-the-mesmerizing-interlocking-geometric-patterns-produced-with-this-ancient-japanese-woodworking-technique-180986494/</link>
            <guid>43810724</guid>
            <pubDate>Sun, 27 Apr 2025 10:01:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smithsonian-institution/see-the-mesmerizing-interlocking-geometric-patterns-produced-with-this-ancient-japanese-woodworking-technique-180986494/">https://www.smithsonianmag.com/smithsonian-institution/see-the-mesmerizing-interlocking-geometric-patterns-produced-with-this-ancient-japanese-woodworking-technique-180986494/</a>, See on <a href="https://news.ycombinator.com/item?id=43810724">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smithsonian-institution/see-the-mesmerizing-interlocking-geometric-patterns-produced-with-this-ancient-japanese-woodworking-technique-180986494/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[ZFS: Apple's New Filesystem that wasn't (2016) (156 pts)]]></title>
            <link>https://ahl.dtrace.org/2016/06/15/apple_and_zfs/</link>
            <guid>43810566</guid>
            <pubDate>Sun, 27 Apr 2025 09:25:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/">https://ahl.dtrace.org/2016/06/15/apple_and_zfs/</a>, See on <a href="https://news.ycombinator.com/item?id=43810566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="skip">
			<heading-anchors>
				


<ul>
	<li><time datetime="2016-06-15">15 June 2016</time></li>
	<li><a href="https://ahl.dtrace.org/tags/apple/">apple</a>, </li>
	<li><a href="https://ahl.dtrace.org/tags/mac-os-x/">mac-os-x</a></li>
</ul>

<h4 id="prologue-2006">Prologue (2006)</h4>
<picture><source type="image/avif" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/6l51fI_CaR-200.avif 200w"><source type="image/webp" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/6l51fI_CaR-200.webp 200w"><img loading="lazy" decoding="async" src="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/6l51fI_CaR-200.jpeg" alt="Description" width="200" height="150"></picture>
<p>I attended my first WWDC in 2006 to participate in Apple's&nbsp;<a href="http://dtrace.org/blogs/ahl/2006/08/07/dtrace_on_mac_os_x/">launch of their DTrace port</a> to the next version of Mac OS X (Leopard). Apple completed all but the fiddliest finishing touches without help from the DTrace team. Even when they did meet with us we had no idea that they were mere weeks away from the finished product being announced to the world. It was a testament both to Apple’s engineering acumen as well as their storied secrecy.</p>
<p>At that same WWDC Apple announced Time Machine, a product that would record file system versions through time for backup and recovery. How were they doing this? We were energized by the idea that there might be another piece of adopted Solaris technology. When we launched Solaris 10, DTrace shared the marquee with ZFS, a new filesystem that was to become the standard against which other filesystems are compared. Key among the many features of ZFS were snapshots that made it simple to capture the state of a filesystem, send the changes around, recover data, etc. Time Machine looked for all the world like a GUI on ZFS (indeed the GUI that we had imagined but knew to be well beyond the capabilities of Sun).</p>
<p>Of course Time Machine had nothing to do with ZFS. After the keynote we rushed to an Apple engineer we knew. With shame in his voice he admitted that it was really just a bunch of <a href="http://arstechnica.com/staff/2006/08/4995/">hard links to directories</a>. For those who don’t know a symlink from a symtab this is the moral equivalent of using newspaper as insulation: it’s fine until the completely anticipated calamity destroys everything you hold dear.</p>
<p>So there was no ZFS in Mac OS X, at least not yet.</p>
<h4 id="not-so-fast-2007">Not So Fast (2007)</h4>
<picture><source type="image/avif" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/_Pcr91YZCB-200.avif 200w"><source type="image/webp" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/_Pcr91YZCB-200.webp 200w"><img loading="lazy" decoding="async" src="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/_Pcr91YZCB-200.jpeg" alt="Description" width="200" height="134"></picture>
<p>A few weeks before WWDC 2007 nerds like me started to lose their minds: Apple really <strong>was</strong> going to port ZFS to Mac OS X. It was actually going to happen! Beyond the snapshots that would make backing up a cinch, ZFS would dramatically advance the state of data storage for Apple users. HFS was introduced in System 2.1 (“System” being what we called “Mac OS” in the days before operating systems gained their broad and ubiquitous sex appeal). HFS improved upon the Macintosh File System by adding—wait for it—hierarchy! No longer would files accumulate in a single pile; you could organize them in folders. Not that there were many to organize on those 400K floppies, but progress is progress. And that filesystem has limped along for more than 30 years, nudged forward, rewritten to avoid in-kernel Pascal code (though retaining Pascal-style, length-prefixed strings), but never reimagined or reinvented. Even in its most modern form, HFS lacks the most basic functionality around data integrity. Bugs, power failures, and expected and inevitable media failures all mean that data is silently altered. Pray that your old photos are still intact. When’s the last time you backed up your Mac? I’m backing up right now just like I do every time I think about the neglectful stewardship of HFS.</p>
<p>ZFS was to bring to Mac OS X data integrity, compression, checksums, redundancy, snapshots, etc, etc etc. But while energizing Mac/ZFS fans, Sun CEO, Jonathan Schwartz, had clumsily disrupted the momentum that ZFS had been gathering in Apple’s walled garden. Apple <strong>had</strong> been working on a port of ZFS to Mac OS X. They <strong>were</strong>&nbsp;planning on mentioning it at the upcoming WWDC. Jonathan, brought into the loop either out of courtesy or legal necessity, violated the cardinal rule of the Steve Jobs-era Apple. Only one person at Steve Job’s company announces new products: Steve Jobs. <a href="http://www.theregister.co.uk/2007/06/07/apple_using_zfs_in_leopard/">"In fact, this week you'll see that Apple is announcing at their Worldwide Developer Conference that ZFS has become the file system in Mac OS 10,”</a> mused Jonathan at a press event, apparently to bolster Sun’s own credibility.</p>
<p>Less than a week later, Apple spoke about ZFS only when it became clear that a port was indeed present in a developer version of Leopard albeit in a nascent form. <a href="http://www.informationweek.com/apple-clarifies-status-of-zfs-file-system-in-mac-os/d/d-id/1056096?">Yes, ZFS would be there, sort of, but it would be read-only and no one should get their hopes up.</a></p>
<h4 id="ray-of-hope-2008">Ray of Hope (2008)</h4>
<picture><source type="image/avif" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/gjVx4g4uTA-200.avif 200w"><source type="image/webp" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/gjVx4g4uTA-200.webp 200w"><img loading="lazy" decoding="async" src="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/gjVx4g4uTA-200.jpeg" alt="Description" width="200" height="135"></picture>
<p>By the next WWDC it seemed that <a href="http://www.zdnet.com/article/apple-announces-zfs-on-snow-leopard/">Sun had been forgiven</a>. ZFS was featured in the keynotes, it was on the developer disc handed out to attendees, and it was even mentioned on the <a href="http://web.archive.org/web/20080721031014/http://www.apple.com/server/macosx/snowleopard/">Mac OS X Server website</a>. Apple had been working on their port since 2006 and <a href="http://appleinsider.com/articles/08/06/23/five_undisclosed_features_of_apples_mac_os_x_snow_leopard">now it was functional enough to be put on full display</a>. I took it for a spin myself; it was really real. The feature that everyone wanted (but most couldn’t say why) was coming!</p>
<h4 id="the-little-engine-that-couldnt-2009">The Little Engine That Couldn't (2009)</h4>
<p>By the time Snow Leopard shipped only a careful examination of the Apple web site would turn up the <a href="https://web.archive.org/web/20090627034320/http://www.apple.com/xserve/specs.html">odd reference to ZFS left unscrubbed</a>. Whatever momentum ZFS had enjoyed within the Mac OS X product team was gone. I’ve heard a couple of theories and anecdotes from people familiar with the situation; first some relevant background.</p>
<picture><source type="image/avif" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/FUXSn_It80-200.avif 200w"><source type="image/webp" srcset="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/FUXSn_It80-200.webp 200w"><img loading="lazy" decoding="async" src="https://ahl.dtrace.org/2016/06/15/apple_and_zfs/FUXSn_It80-200.png" alt="Description" width="200" height="125"></picture>
<p><a href="https://en.wikipedia.org/wiki/Sun_acquisition_by_Oracle">Sun was dying.</a> After failed love affairs with IBM and HP (the latter formed, according to former Sun CEO, Scott McNealy, by two garbage trucks colliding), Oracle scooped up the aging dame with dim prospects. The nearly yearlong process of closing the acquisition was particularly hard on Sun, creating uncertainty around its future and damaging its bottom line. Despite the well-documented personal friendship between Steve Jobs and Oracle CEO, Larry Ellison (more on this later), I’m sure this uncertainty had some impact on the decision to continue with ZFS.</p>
<p>In the meantime Sun and NetApp had been locked in a lawsuit over ZFS and other storage technologies since mid-2007. <a href="https://web.archive.org/web/20080625023043/http://blogs.sun.com/jonathan/entry/harvesting_from_a_troll">While Jonathan Schwartz had blogged about protecting Apple and its users</a> (as well as Sun customers of course), this likely lead to further uncertainly. On top of that, filesystem transitions are far from simple. When Apple included DTrace in Mac OS X a point in favor was that it could be yanked out should any sort of legal issue arise. Once user data hit ZFS it would take years to fully reverse the decision. While the NetApp lawsuit never seemed to have merit (ZFS uses unique and from-scratch mechanisms for snapshots), it indisputably represented risk for Apple.</p>
<p>Finally, and perhaps most significantly, personal egos and NIH (not invented here) syndrome certainly played a part. I’m told by folks in Apple at the time that certain leads and managers preferred to build their own rather adopting external technology—even technology that was best of breed. They pitched their own project, an Apple project, that would bring modern filesystem technologies to Mac OS X. The design center for ZFS was servers, not laptops—and certainly not phones, tablets, and watches—his argument was likely that it would be better to start from scratch than adapt ZFS. Combined with the uncertainty above and, I’m told, no shortage of political savvy their arguments carried the day. Licensing FUD was thrown into the mix; even today folks at Apple see the ZFS license as nefarious and toxic in some way whereas the DTrace license works just fine for them. Note that both use the same license with the same grants and same restrictions. Maybe the technical arguments really were overwhelming (note however that ZFS was working internally on the iPhone), and maybe the risks really were insurmountable. I obviously have my own opinions, and think this was a great missed opportunity for the industry, but I never had the burden of weighing the totality of the facts and deciding. Nevertheless Apple put an end to its ZFS work; Apple’s from-scratch filesystem efforts were underway.</p>
<h4 id="the-little-engine-that-still-couldn-t-2010">The Little Engine That Still Couldn’t (2010)</h4>
<p>Amazingly that wasn’t quite the end for ZFS at Apple. <a href="https://www.linkedin.com/in/donjbrady/">The architect for ZFS at Apple had left</a>, the project had been shelved, but there were high-level conversations between Sun and Apple about reviving the port. Apple would get indemnification and support for their use of ZFS. Sun would get access to the Apple File Protocol (AFP—which, ironically, seems to have been collateral damage with the new APFS), and, more critically, Sun’s new ZFS-based storage appliance (which I helped develop) would be a natural server and backup agent for millions of Apple devices. It seemed to make some sort of sense.</p>
<p>The excruciatingly debilitatingly slow acquisition of Sun finally closed. The Apple-ZFS deal was brought for Larry Ellison’s approval, the first born child of the conquered land brought to be blessed by the new king. “I’ll tell you about doing business with my best friend Steve Jobs,” he apparently said, “I don’t do business with my best friend Steve Jobs.”</p>
<p>(Amusingly the version of the story told quietly at WWDC 2016 had the friends reversed with Steve saying that he wouldn’t do business with Larry. Still another version I’ve heard calls into question the veracity of their purported friendship, and has Steve instead suggesting that Larry go f*ck himself. Normally the iconoclast, that would, if true, represent Steve’s most mainstream opinion.)</p>
<p>And that was the end.</p>
<h4 id="epilogue-2016">Epilogue (2016)</h4>
<p>In the 7 years since ZFS development halted at Apple, they’ve worked on a variety of improvements in HFS and Core Storage, and hacked at at least two replacements for HFS that didn’t make it out the door. This week Apple announced their new filesystem, APFS, after 2 years in development. It’s not done; some features are still in development, and they’ve announced the ambitious goal of rolling it out to laptop, phone, watch, and tv within the next 18 months. At Sun we started ZFS in 2001. It shipped in 2005 and that was really the starting line, not the finish line. Since then I've shipped the ZFS Storage Appliance in 2008 and Delphix in 2010 and each has required investment in ZFS / OpenZFS to make them ready for prime time. A broadly featured, highly functional filesystem takes a long time.</p>
<p>APFS has merits (more in my next post), but it will always disappoint me that Apple didn’t adopt ZFS irrespective of how and why that decision was made. Dedicated members of the OpenZFS community have built and maintain <a href="https://openzfsonosx.org/">a port</a>. It’s not quite the same as having Apple as a member of that community, embracing and extending ZFS rather than building their own incipient alternative.</p>

<ul><li>← Previous<br> <a href="https://ahl.dtrace.org/2016/05/13/shv/">Finding What's Next</a></li><li>Next →<br><a href="https://ahl.dtrace.org/2016/06/19/apfs-part1/">APFS in Detail: Overview</a></li>
</ul>

			</heading-anchors>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. autism data project sparks uproar over ethics, privacy and intent (195 pts)]]></title>
            <link>https://www.washingtonpost.com/health/2025/04/25/autism-registry-privacy-rfk-research/</link>
            <guid>43810561</guid>
            <pubDate>Sun, 27 Apr 2025 09:23:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/health/2025/04/25/autism-registry-privacy-rfk-research/">https://www.washingtonpost.com/health/2025/04/25/autism-registry-privacy-rfk-research/</a>, See on <a href="https://news.ycombinator.com/item?id=43810561">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/health/2025/04/25/autism-registry-privacy-rfk-research/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Chongqing, the Largest City – In Pictures (205 pts)]]></title>
            <link>https://www.theguardian.com/world/gallery/2025/apr/27/chongqing-the-worlds-largest-city-in-pictures</link>
            <guid>43809915</guid>
            <pubDate>Sun, 27 Apr 2025 06:42:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/gallery/2025/apr/27/chongqing-the-worlds-largest-city-in-pictures">https://www.theguardian.com/world/gallery/2025/apr/27/chongqing-the-worlds-largest-city-in-pictures</a>, See on <a href="https://news.ycombinator.com/item?id=43809915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-link-name="standfirst" data-component="standfirst">
    

        
            <meta itemprop="description" content="The largest city in the world is as big as Austria, but few people have ever heard of it. The megacity of 34 million people in central of China is the emblem of the fastest urban revolution on the planet. The Communist party decided 30 years ago to unify and populate vast rural areas, an experiment that has become a symbol of the Chinese ability to reshape the world">
        
    
    
        
            <p>The largest city in the world is as big as Austria, but few people have ever heard of it. The megacity of 34 million people in central of China is the emblem of the fastest urban revolution on the planet. The Communist party decided 30 years ago to unify and populate vast rural areas, an experiment that has become a symbol of the Chinese ability to reshape the world</p>
        
    
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Remote-Controlled IKEA Deathstar Lamp (264 pts)]]></title>
            <link>https://gitlab.com/sephalon/deathstar_lamp</link>
            <guid>43809841</guid>
            <pubDate>Sun, 27 Apr 2025 06:25:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlab.com/sephalon/deathstar_lamp">https://gitlab.com/sephalon/deathstar_lamp</a>, See on <a href="https://news.ycombinator.com/item?id=43809841">Hacker News</a></p>
<div id="readability-page-1" class="page">





<header data-testid="navbar">
<a href="#content-body">Skip to content</a>
<div>
<nav aria-label="Explore GitLab">
<div>
<span>GitLab</span>
<a title="Homepage" id="logo" aria-label="Homepage" data-track-label="main_navigation" data-track-action="click_gitlab_logo_link" data-track-property="navigation_top" href="https://gitlab.com/"><svg aria-hidden="true" role="img" width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="m24.507 9.5-.034-.09L21.082.562a.896.896 0 0 0-1.694.091l-2.29 7.01H7.825L5.535.653a.898.898 0 0 0-1.694-.09L.451 9.411.416 9.5a6.297 6.297 0 0 0 2.09 7.278l.012.01.03.022 5.16 3.867 2.56 1.935 1.554 1.176a1.051 1.051 0 0 0 1.268 0l1.555-1.176 2.56-1.935 5.197-3.89.014-.01A6.297 6.297 0 0 0 24.507 9.5Z" fill="#E24329"></path>
  <path d="m24.507 9.5-.034-.09a11.44 11.44 0 0 0-4.56 2.051l-7.447 5.632 4.742 3.584 5.197-3.89.014-.01A6.297 6.297 0 0 0 24.507 9.5Z" fill="#FC6D26"></path>
  <path d="m7.707 20.677 2.56 1.935 1.555 1.176a1.051 1.051 0 0 0 1.268 0l1.555-1.176 2.56-1.935-4.743-3.584-4.755 3.584Z" fill="#FCA326"></path>
  <path d="M5.01 11.461a11.43 11.43 0 0 0-4.56-2.05L.416 9.5a6.297 6.297 0 0 0 2.09 7.278l.012.01.03.022 5.16 3.867 4.745-3.584-7.444-5.632Z" fill="#FC6D26"></path>
</svg>

</a></div>
<ul>
<li>

<div>
<ul>
<li>
<a href="https://about.gitlab.com/why-gitlab">Why GitLab
</a></li>
<li>
<a href="https://about.gitlab.com/pricing">Pricing
</a></li>
<li>
<a href="https://about.gitlab.com/sales">Contact Sales
</a></li>
<li>
<a href="https://gitlab.com/explore">Explore</a>
</li>
</ul>
</div>
</li>
<li>
<a href="https://about.gitlab.com/why-gitlab">Why GitLab
</a></li>
<li>
<a href="https://about.gitlab.com/pricing">Pricing
</a></li>
<li>
<a href="https://about.gitlab.com/sales">Contact Sales
</a></li>
<li>
<a href="https://gitlab.com/explore">Explore</a>
</li>
</ul>
<ul>
<li>
<a href="https://gitlab.com/users/sign_in?redirect_to_referer=yes">Sign in</a>
</li>
<li>
<a href="https://gitlab.com/users/sign_up"><span>
Get free trial

</span>

</a></li>
</ul>
</nav>
</div>
</header>

<div>


<div data-testid="top-bar">
<div data-testid="breadcrumb-links" id="js-vue-page-breadcrumbs-wrapper">


</div>
<div>





</div>
</div>

<div>
<main id="content-body" itemscope="" itemtype="http://schema.org/SoftwareSourceCode">











<header>
<div>
<div>
<div alt="deathstar_lamp" itemprop="image">
D
</div>

<h2 data-testid="project-name-content" itemprop="name">
deathstar_lamp


</h2>
</div>

</div>

</header>


<div>

<div data-blame-per-page="1000" id="tree-holder">

<div role="status" data-history-link="/sephalon/deathstar_lamp/-/commits/master" data-ref-type="heads" id="js-last-commit"><span aria-hidden=""></span><span>Loading</span>
</div>

</div>
</div>

</main>
</div>


</div>








</div>]]></description>
        </item>
    </channel>
</rss>