<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 26 Oct 2023 02:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Was Rust Worth It? (165 pts)]]></title>
            <link>https://jsoverson.medium.com/was-rust-worth-it-f43d171fb1b3</link>
            <guid>38019231</guid>
            <pubDate>Wed, 25 Oct 2023 22:37:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jsoverson.medium.com/was-rust-worth-it-f43d171fb1b3">https://jsoverson.medium.com/was-rust-worth-it-f43d171fb1b3</a>, See on <a href="https://news.ycombinator.com/item?id=38019231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><figcaption>An unsure crab</figcaption></figure><div><h2 id="ade7">From JavaScript to Rust, three years in.</h2><div><a rel="noopener follow" href="https://jsoverson.medium.com/?source=post_page-----f43d171fb1b3--------------------------------"><div aria-hidden="false"><p><img alt="Jarrod Overson" src="https://miro.medium.com/v2/resize:fill:88:88/1*DUjBSZ8vCnqtthWwHubL9A.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><p id="b39c">A few years ago, I dropped everything to focus 100% on WebAssembly. At the time, Rust had the best support for compiling into WebAssembly, and the most full-featured WebAssembly runtimes were Rust-based. Rust was the best option on the menu. I jumped in, eager to see what all the hype was about.</p><p id="b755">Since then, I (along with some other awesome people) built <a href="https://github.com/candlecorp/wick" rel="noopener ugc nofollow" target="_blank">Wick</a>, an application framework and runtime that uses WebAssembly as its core module system.</p><figure><figcaption>Wick was the primary target of our Rust experimentation</figcaption></figure><p id="6fee">After three years, multiple production deployments, an <a href="https://github.com/jsoverson/node-to-rust" rel="noopener ugc nofollow" target="_blank">ebook</a>, and ~100 packages deployed on <a href="https://crates.io/me/crates" rel="noopener ugc nofollow" target="_blank">crates.io</a>, I feel it’s time to share some thoughts on Rust.</p><h2 id="7ba4">The Good</h2><h2 id="0854">You can maintain more with less</h2><p id="9c68">I am a massive proponent of test-driven development. I got used to testing in languages like Java and JavaScript. I started writing tests in Rust as I would in any other language but found that I was writing tests that <em>couldn’t fail</em>. Once you get to the point where your tests can run – that is, where your Rust code compiles – Rust has accounted for so many errors that many common test cases become irrelevant. If you avoid <code>unsafe {}</code> blocks and panic-prone methods like <code>.unwrap()</code>, you start with a foundation that sidesteps many problems by default.</p><p id="468a">The aggressiveness of Rust’s borrow checker, the richness of Rust’s type system, the functional patterns and libraries, and the lack of “null” values all lead to maintaining more with less effort spent in places like testing. I’ve maintained the 70,000+ lines of code in the Wick project with far fewer tests than I would need in other languages.</p><p id="cde4">When you need to write tests, adding them on the fly is easy without thinking about it. Rust’s integrated test harness lets you add tests right next to code with barely a second thought.</p><h2 id="29a1">I code better in other languages now</h2><p id="7b0c">Programming in Rust is like being in an emotionally abusive relationship. Rust screams at you all day, every day, often about things that you would have considered perfectly normal in another life. Eventually, you get used to the tantrums. They become routine. You learn to walk the tightrope to avoid triggering the compiler’s temper. And just like in real life, those behavior changes stick with you forever.</p><p id="d05f">Emotional abuse is not generally considered a <em>healthy</em> way to encourage change, but it does effect change nonetheless.</p><p id="c7a0">I can’t write code in other languages without feeling uncomfortable when lines are out of order or when return values are unchecked. I also now get irrationally upset when I experience a runtime error.</p><figure><figcaption><em>What do you mean “</em><code><em>done"</em></code><em> is not a function? Why didn’t you let me know "</em><code><em>done”</em></code><em> might not be a function??</em></figcaption></figure><h2 id="133d">Clippy is great!</h2><p id="f0cc"><a href="https://github.com/rust-lang/rust-clippy" rel="noopener ugc nofollow" target="_blank">Clippy</a> is Rust’s linter, but calling it a linter is a disservice. In a language where the compiler can make you cry, Clippy is more of a gentle friend than a linter.</p><p id="aed8">The Rust standard library is <em>enormous.</em> It’s hard to find functions you know probably exist when so much functionality is spread across myriad granular types, traits, macros, and functions. Many Clippy rules (e.g., <code><a href="https://rust-lang.github.io/rust-clippy/master/index.html#/manual_is_ascii_check" rel="noopener ugc nofollow" target="_blank">manual_is_ascii_check</a></code>) look for common patterns that stdlib methods or types would better replace.</p><p id="b1cb">Clippy has <a href="https://rust-lang.github.io/rust-clippy/master/index.html" rel="noopener ugc nofollow" target="_blank">hundreds of rules</a> that tackle performance, readability, and unnecessary indirection. It will frequently give you the replacement code when possible.</p><p id="fd27">It also looks like (soon) you’ll <a href="https://github.com/rust-lang/cargo/issues/12115" rel="noopener ugc nofollow" target="_blank">finally</a> be able to configure global lints for a project. Until now, you had to hack your solution to keep lints consistent for projects. In Wick, we use a script to automatically update <a href="https://github.com/candlecorp/wick/blob/main/src/main.rs#L8-L84" rel="noopener ugc nofollow" target="_blank">inline lint configurations</a> for a few dozen crates. It took <a href="https://github.com/rust-lang/cargo/issues/5034" rel="noopener ugc nofollow" target="_blank"><em>years</em></a> for the Rust community to land on a solution for this, which brings us to…</p><h2 id="9fdb">The Bad</h2><h2 id="8a7c">There are gaps that you’ll have to live with</h2><p id="764a">I questioned my sanity every time I circled back around to the Clippy issue above. Surely, I was wrong. There must be a configuration I missed. I couldn’t believe it. I still can’t. Surely there must be a way to configure lints globally. I <a href="https://github.com/rust-lang/cargo/issues/5034" rel="noopener ugc nofollow" target="_blank">quadruple</a>-<a href="https://github.com/rust-lang/rust/issues/45832" rel="noopener ugc nofollow" target="_blank">checked</a> <a href="https://github.com/rust-lang/rust-clippy/issues/1313" rel="noopener ugc nofollow" target="_blank">when</a> I <a href="https://github.com/rust-lang/rust-clippy/issues/6625" rel="noopener ugc nofollow" target="_blank">wrote</a> <a href="https://www.appsloveworld.com/rust/4/how-can-i-have-a-shared-clippy-configuration-for-all-the-crates-in-a-workspace" rel="noopener ugc nofollow" target="_blank">this</a> <a href="https://github.com/EmbarkStudios/rust-ecosystem/issues/22" rel="noopener ugc nofollow" target="_blank">to</a> make sure I wasn’t delusional. Those issues are closed now, but they had been open for years.</p><p id="a078">Clippy’s awesome, but this use case is one example of many around the Rust world. I frequently come across libraries or tools where my use cases aren’t covered. That’s not uncommon in newer languages or projects. Software takes time (usage) to mature. But Rust isn’t <em>that</em> new. There’s something about Rust that feels different.</p><p id="8970">In open source, edge cases are frequently addressed by early adopters and new users. They’re the ones with the edge cases. Their PRs refine projects so they’re better for the next user. <a href="https://github.blog/2023-08-30-why-rust-is-the-most-admired-language-among-developers/" rel="noopener ugc nofollow" target="_blank">Rust has been awarded the “most loved language” for the better part of a decade</a>. It’s got no problem attracting new users, but it’s not resulting in dramatically improved libraries or tools. It’s resulting in one-off forks that handle specific use cases. I’m guilty of that, too, but not for lack of trying to land PRs.</p><p id="79b6">I don’t know why. Maybe the pressure to maintain stable APIs, along with Rust’s granular type system, makes it difficult for library owners to iterate. It’s hard to accept a minor change if it would result in a major version bump.</p><p id="674c">Or maybe it’s because writing Rust code that does everything for everyone is exceedingly difficult, and people don’t want to deal with it.</p><h2 id="e6f5">Cargo, crates.io, and how to structure projects</h2><p id="d7d1">I modeled the Wick repository structure around some other popular projects I saw. It looked reasonable and worked fine until it didn’t.</p><p id="e84b">You can build, test, and use what feels like a module-sized crate easily with Cargo. Deploying it to crates.io, though? That’s a whole different story.</p><p id="4893">You can’t publish packages to crates.io unless <strong>every</strong> referenced crate is also published individually. That makes some sense. You don’t want to depend on a crate that depends on packages that only exist on the author’s local filesystem.</p><p id="2591">However, many developers break large projects down into smaller modules naturally, and you can’t publish a parent crate that has sub-crates that <em>only exist within itself. </em>You can’t even publish a crate that has local dev dependencies. You must choose between publishing random utility crates or restructuring your project to avoid this problem. This limitation feels arbitrary and unnecessary. You can clearly build projects structured like this, you just can’t publish them.</p><p id="b0d9">Cargo does have excellent workspace support, though! Cargo’s workspaces offer a better experience managing large projects than most languages. But they don’t solve the deployment problem. Turns out, you can set workspaces up in any of a dozen ways, <em>none</em> of which make it easy to deploy.</p><p id="5bd0">You can see the problem manifest in the sheer number of <a href="https://crates.io/search?q=cargo+workspace+publish" rel="noopener ugc nofollow" target="_blank">utility crates</a> designed to simplify publishing workspaces. Each works with a subset of configurations, and the “one true way” of setting workspaces up still eludes me. When I publish Wick, it’s frequently an hour+ of effort combining manual, repetitive tasks with tools that only partially work.</p><h2 id="8ab7">Async</h2><p id="b1a0">Rust added async-iness to the language after its inception. It feels like an afterthought, acts like an afterthought, and frequently gets in your way with errors that are hard to understand and resolve. When you search for solutions, you have to filter based on the various runtimes and their async flavors. Want to use an async library? There’s a chance you can’t use it outside of a specific async runtime.</p><p id="ba1a">After two decades of JavaScript and decent experience with Go, this is the <em>most significant </em>source of frustration and friction with Rust. It’s not an insurmountable problem, but you must always be ready to deal with the async monster when it rears its head. In other languages, async is almost invisible.</p><h2 id="14b4">The Ugly</h2><h2 id="c70d">Refactoring can be a slog</h2><p id="64a2">Rust’s rich type system is a blessing and a curse. Thinking in Rust types is a dream. Managing Rust’s types can be a nightmare. Your data and function signatures can have generic types, generic lifetimes, and trait constraints. Those constraints can have their own generic types and lifetimes. <a href="https://github.com/rxRust/rxRust/blob/master/src/observable.rs#L1134-L1142" rel="noopener ugc nofollow" target="_blank">Sometimes, you’ll have more type constraints than actual code</a>.</p><figure><figcaption>Constraints that outweigh logic</figcaption></figure><p id="79ea">You also need to define all your generics on <a href="https://github.com/bytecodealliance/wasmtime/blob/038ddfeb6699591b5d82546c9b2d5076097bc9ce/cranelift/entity/src/iter.rs#L29-L58" rel="noopener ugc nofollow" target="_blank">every </a><code><a href="https://github.com/bytecodealliance/wasmtime/blob/038ddfeb6699591b5d82546c9b2d5076097bc9ce/cranelift/entity/src/iter.rs#L29-L58" rel="noopener ugc nofollow" target="_blank">impl</a></code>. It’s tedious when writing it the first time. When refactoring though, it can turn a minor change into a cascading mess.</p><figure><figcaption>Simple generic IDs are duplicated over and over again.</figcaption></figure><p id="c24a">It’s hard to make rapid progress when you need to tweak 14 different definitions before you can take a single step forward.</p><h2 id="32dd">The Verdict</h2><p id="be53">I love Rust. I love what it can do and how versatile it is. I can write system-level code in the same language as CLI apps, web servers, <em>and</em> web clients. With WebAssembly, I can use the same exact binary to run an LLM <a href="https://wasm.candle.dev/llama2" rel="noopener ugc nofollow" target="_blank">in the browser</a> as on the command line. That still blows my mind.</p><p id="715e">I love how rock-solid Rust programs can be. It’s hard to return to other languages after you learn to appreciate what Rust protects you from. I went back to Go for a brief period. I quickly became intoxicated with the speed of development again. Then I hit the runtime panics, and the glass shattered.</p><p id="9526">But Rust has its warts. It’s hard to hire for, slow to learn, and too rigid to iterate quickly. It’s hard to troubleshoot memory and performance issues, especially with async code. Not all libraries are as good about safe code as others, and dev tooling leaves much to be desired. You start behind and have a lot working against you. If you can get past the hurdles, you’ll leave everyone in the dust. That’s a big if.</p><p id="39d7">Was Rust worth it for us? It’s too early to tell. We’ve done amazing things with a small team but also had immense roadblocks. We also had technical reasons that made Rust more viable.</p><p id="75ff">Will it be worth it for you? If you need to iterate rapidly, probably not. If you have a known scope, or can absorb more upfront cost? Definitely consider it. You’ll end up with bulletproof software. With the WebAssembly angle becoming stronger every month, the prospect of writing perfect software <em>once</em> and reusing it <em>everywhere</em> is becoming a reality sooner rather than later.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Helix 23.10 Highlights (126 pts)]]></title>
            <link>https://helix-editor.com/news/release-23-10-highlights/</link>
            <guid>38017541</guid>
            <pubDate>Wed, 25 Oct 2023 20:02:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://helix-editor.com/news/release-23-10-highlights/">https://helix-editor.com/news/release-23-10-highlights/</a>, See on <a href="https://news.ycombinator.com/item?id=38017541">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        

 <h2>Release 23.10 Highlights</h2>
 <time>25 October 2023</time>

<p>The Helix 23.10 release is finally here! 23.10 introduces some very large
internal changes that enable some powerful features. A very big <em>thank you</em> to
everyone who made this release possible.</p>
<p>New to Helix?
Helix is a modal text editor with built-in support for multiple selections,
Language Server Protocol (LSP), tree-sitter, and experimental support for Debug
Adapter Protocol (DAP).</p>
<p>Let's check out this release's highlights.</p>
<h2 id="multiple-language-servers">Multiple language servers</h2>
<p>23.10 brings a big change to the way we handle language servers.
Previously each language could only support one language server at a time but
now you can configure multiple to work in tandem. For example you might use
the TypeScript language server for JavaScript/TypeScript development and also
configure <a href="https://github.com/mattn/efm-langserver">efm-langserver</a> for
Prettier formatting and ESLint diagnostics. With the new support for multiple
language servers, you can specify which features to use from each language
server.</p>
<p>This brings a big change to the way language servers are configured in your
language configuration (<code>languages.toml</code>). All language servers are now
specified separately from languages and then each language selects which
language server(s) to use. From the example above, you might configure efm-
langserver and typescript-language-server like so:</p>
<pre data-lang="toml"><code data-lang="toml"><span>[language-server.efm]
</span><span>command </span><span>= "</span><span>efm-langserver</span><span>"
</span><span>config</span><span>.</span><span>documentFormatting </span><span>= </span><span>true
</span><span>
</span><span>[language-server.typescript-language-server]
</span><span>command </span><span>= "</span><span>typescript-language-server</span><span>"
</span><span>args </span><span>= ["</span><span>--stdio</span><span>"]
</span><span>config</span><span>.</span><span>hostInfo </span><span>= "</span><span>helix</span><span>"
</span><span>
</span><span>[[language]]
</span><span>name </span><span>= "</span><span>typescript</span><span>"
</span><span>auto-format </span><span>= </span><span>true
</span><span>language-servers </span><span>= [
</span><span>  { </span><span>name </span><span>= "</span><span>efm</span><span>", </span><span>only-features </span><span>= ["</span><span>format</span><span>", "</span><span>diagnostics</span><span>"] },
</span><span>  { </span><span>name </span><span>= "</span><span>typescript-language-server</span><span>", </span><span>except-features </span><span>= ["</span><span>format</span><span>", "</span><span>diagnostics</span><span>"] },
</span><span>]
</span></code></pre>
<p>See more details in the <a href="https://docs.helix-editor.com/languages.html">language configuration docs</a>.</p>
<h2 id="fuzzy-matching-with-nucleo">Fuzzy matching with Nucleo</h2>
<asciinema-player src="/nucleo-nix-store.cast" cols="94" rows="25"></asciinema-player>
<p>Helix uses "fuzzy" matching to filter as-you-type in components like the file
picker. Previously we used the popular <code>skim</code>/<code>fuzzy-matcher</code> crates but in the
23.10 release we've switched to the new
<a href="https://github.com/helix-editor/helix"><code>nucleo</code></a> crate. Nucleo is
significantly faster than skim and fzf, handles Unicode correctly, and uses a
bonus system that feels more intuitive.</p>
<p>Nucleo also enables us to lazily stream in new items, which is a big boost for
the user experience for pickers. In the asciicast above I'm scanning through
my computer's <code>/nix/store</code>, a huge directory containing more than twenty
million files. The file picker now works gradually as we scan through the
directory and matches files as we find them.</p>
<p>Nucleo also paves the way for future picker upgrades. Stay tuned to the
upcoming release notes to see where we'll take the picker.</p>
<h2 id="smart-tab">Smart tab</h2>
<p>Smart tab is a new feature bound to the tab key in the default keymap. When
you press tab and the line to the left of the cursor isn't all whitespace,
the cursor will jump to the end of the syntax tree's parent node. For example:</p>
<pre data-lang="nix"><code data-lang="nix"><span>{
</span><span>  </span><span>key </span><span>= "</span><span>value</span><span>";
</span><span>  </span><span>nested </span><span>= {
</span><span>    </span><span>key2 </span><span>= "</span><span>value2</span><span>"; </span><span># When the cursor is at the end of the line here, &lt;tab&gt;
</span><span>                     </span><span># jumps right after the closing brace on the next line.
</span><span>  };
</span><span>}
</span></code></pre>
<p>This is useful in languages like Nix for adding semicolons at the end of an
attribute set or jumping to the end of a block in a C-like language:</p>
<asciinema-player src="/smart-tab.cast" cols="94" rows="25"></asciinema-player>
<h2 id="expanded-support-for-registers">Expanded support for registers</h2>
<asciinema-player src="/special-registers.cast" cols="94" rows="25"></asciinema-player>
<p>Registers allow you to save and paste values. For example you might select
a paragraph, use <code>"ay</code> to yank it into the <code>a</code> register, and later use <code>"ap</code>
to paste that paragraph. Some registers have special effects when read or
written to though like the <code>_</code> "blackhole" register: any values written are
discarded and nothing can be read. Special registers have been expanded to
include some useful ones from Kakoune and clipboard registers:</p>
<ul>
<li><code>%</code>: the current buffer name</li>
<li><code>#</code>: the number of each selection, 1-indexed</li>
<li><code>.</code>: the contents of each selection</li>
<li><code>*</code> and <code>+</code>: system and primary clipboards</li>
</ul>
<p>Also check out the new register statusline element. It appears when you select
a register with <code>"</code>. Notice the <code>reg=#</code> in the bottom-right corner of the
statusline in the asciicast when we select the <code>#</code> register and how it goes
away when we paste that register (<code>p</code>) or increment the selections (<code>C-a</code>).</p>
<h2 id="initial-support-for-lsp-didchangewatchedfiles">Initial support for LSP DidChangeWatchedFiles</h2>
<asciinema-player src="/initial-lsp-didchangewatchedfiles.cast" cols="94" rows="25"></asciinema-player>
<p>Some language servers use the DidChangeWatchedFiles notification to discover
changes to related files in other languages. For example, <code>rust-analyzer</code> will
fetch and index new dependencies when you add them to your <code>Cargo.toml</code>.
Helix will now send file change notifications when the file is changed by
Helix itself. Full support for DidChangeWatchedFiles will require a file
watcher but for now we're able to support the most common use-case for
DidChangeWatchedFiles.</p>
<h2 id="syntax-highlight-regex-prompts">Syntax highlight regex prompts</h2>
<img src="https://helix-editor.com/regex-prompt-highlighting.png">
<p>Regex prompts like those created with <code>s</code>, <code>S</code> or <code>|</code> are now syntax highlighted
via tree-sitter-regex. The highlighting makes special characters more obvious
and can catch syntax errors like trailing backslashes.</p>
<h2 id="wrapping-up">Wrapping up</h2>
<p>As always, this is just the tip of the iceberg for the 23.10 release. Check out
the <a href="https://github.com/helix-editor/helix/blob/master/CHANGELOG.md#2310-2023-10-24">changelog</a> for the full details.</p>
<p>Come chat about usage and development questions in the <a href="https://matrix.to/#/#helix-community:matrix.org">Matrix space</a>
and follow along with Helix's development in the <a href="https://github.com/helix-editor/helix/">GitHub repository</a>.</p>






    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The cost of cloud, a trillion dollar paradox (2021) (129 pts)]]></title>
            <link>https://a16z.com/the-cost-of-cloud-a-trillion-dollar-paradox/</link>
            <guid>38017239</guid>
            <pubDate>Wed, 25 Oct 2023 19:37:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://a16z.com/the-cost-of-cloud-a-trillion-dollar-paradox/">https://a16z.com/the-cost-of-cloud-a-trillion-dollar-paradox/</a>, See on <a href="https://news.ycombinator.com/item?id=38017239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                            <p>There is no doubt that the cloud is one of the most significant platform shifts in the history of computing. Not only has cloud already impacted hundreds of billions of dollars of IT spend, it’s still in early innings and growing rapidly on a base of over $<a href="https://www.gartner.com/en/newsroom/press-releases/2020-07-23-gartner-forecasts-worldwide-public-cloud-revenue-to-grow-6point3-percent-in-2020#:~:text=The%20worldwide%20public%20cloud%20services,%2C%20according%20to%20Gartner%2C%20Inc" target="_blank" rel="noopener">100B</a> of annual public cloud spend. This shift is driven by an incredibly powerful value proposition—infrastructure available immediately, at exactly the scale needed by the business—driving efficiencies both in operations and economics. The cloud also helps cultivate innovation as company resources are freed up to focus on new products and growth.</p>

<p>However, as industry experience with the cloud matures—and we see a more complete picture of cloud lifecycle on a company’s economics—it’s becoming evident that while cloud clearly delivers on its promise<em> early</em> on in a company’s journey, the pressure it puts on margins can start to outweigh the benefits, as a company scales and growth slows. Because this shift happens<em> later</em> in a company’s life, it is difficult to reverse as it’s a result of years of development focused on new features, and not infrastructure optimization. Hence a rewrite or the significant restructuring needed to dramatically improve efficiency can take years, and is often considered a non-starter.</p>
<p>Now, there is a growing awareness of the long-term cost implications of cloud. As the cost of cloud starts to contribute significantly to the total cost of revenue (COR) or cost of goods sold (COGS), some companies have taken the dramatic step of “repatriating” the majority of workloads (as in the example of Dropbox) or in other cases adopting a hybrid approach (as with CrowdStrike and Zscaler). Those who have done this have reported significant cost savings: In 2017, Dropbox detailed in its <a href="https://www.sec.gov/Archives/edgar/data/1467623/000119312518055809/d451946ds1.htm" target="_blank" rel="noopener">S-1</a> a whopping $75M in cumulative savings over the two years prior to IPO due to their infrastructure optimization overhaul, the majority of which entailed repatriating workloads from public cloud.</p>
<p>Yet most companies find it hard to justify moving workloads off the cloud given the sheer magnitude of such efforts, and quite frankly the dominant, somewhat singular, industry narrative that “cloud is great”. (It is, but we need to consider the broader impact, too.) Because when evaluated relative to the scale of potentially lost market capitalization—which we present in this post—the calculus changes. As growth (often) slows with scale, near term efficiency becomes an increasingly key determinant of value in public markets. The excess cost of cloud weighs heavily on market cap by driving lower profit margins.</p>
<p>The point of this post isn’t to argue for repatriation, though; that’s an incredibly complex decision with broad implications that vary company by company. Rather, we take an initial step in understanding just how much market cap is being suppressed by the cloud, so we can help inform the decision-making framework on managing infrastructure as companies scale.</p>
<p>To frame the discussion: We estimate the recaptured savings in the extreme case of full repatriation, and use public data to pencil out the impact on share price. We show (using relatively conservative assumptions!) that <em>across 50 of the top public software companies</em> currently utilizing cloud infrastructure, an estimated $100B of market value is being lost among them due to cloud impact on margins— relative to running the infrastructure themselves. And while we focus on software companies in our analysis, the impact of the cloud is by no means limited to software. Extending this analysis to the broader universe of scale public companies that stands to benefit from related savings, we estimate that the total impact is potentially greater than $500B.</p>
<p>Our analysis highlights how much value can be gained through cloud optimization—whether through system design and implementation, re-architecture, third-party cloud efficiency solutions, or moving workloads to special purpose hardware. This is a very counterintuitive assumption in the industry given prevailing narratives around cloud vs. on-prem. However, it’s clear that when you factor in the impact to market cap in addition to near term savings, <em>scaling companies can justify nearly any level of work that will help keep cloud costs low.</em></p>
<h3><strong>Unit economics of cloud repatriation: The case of Dropbox, and beyond</strong></h3>
<p>To dimensionalize the cost of cloud, and understand the magnitude of potential savings from optimization, let’s start with a more extreme case of large scale cloud repatriation: Dropbox. When the company embarked on its infrastructure optimization initiative in 2016, they saved nearly $75M over two years by shifting the majority of their workloads from public cloud to “lower cost, custom-built infrastructure in co-location facilities” directly leased and operated by Dropbox. Dropbox gross margins increased from 33% to 67%&nbsp; from 2015 to 2017, which they <a href="https://www.sec.gov/Archives/edgar/data/1467623/000119312518055809/d451946ds1.htm" target="_blank" rel="noopener">noted</a> was “primarily due to our Infrastructure Optimization and an… increase in our revenue during the period.”</p>

<p>But that’s just Dropbox. So to help generalize the potential savings from cloud repatriation to a broader set of companies, Thomas Dullien, former Google engineer and co-founder of cloud computing optimization company Optimyze, estimates that repatriating $100M of annual public cloud spend can translate to roughly <em>less than half </em>that amount in all-in annual total cost of ownership (TCO)—from server racks, real estate, and cooling to network and engineering costs.</p>
<p>The exact savings obviously varies company, but several experts we spoke to converged on this “formula”: <em>Repatriation results in one-third to one-half the cost of running equivalent workloads in the cloud</em>. Furthermore, a director of engineering at a large consumer internet company found that public cloud list prices can be 10 to 12x the cost of running one’s own data centers. Discounts driven by use-commitments and volume are common in the industry, and can bring this multiple down to single digits, since cloud compute typically drops by ~30-50% with committed use. But AWS still operates at a roughly 30% blended operating margin net of these discounts and an aggressive R&amp;D budget—implying that potential company savings due to repatriation are larger. The performance lift from managing one’s own hardware may drive even further gains.</p>
<p>Across all our conversations with diverse practitioners, the pattern has been remarkably consistent:<em> If you’re operating at scale, the cost of cloud can at least double your infrastructure bill. </em></p>
<h3><strong>The true cost of cloud</strong></h3>
<p>When you consider the sheer magnitude of cloud spend as a percentage of the total cost of revenue (COR), 50% savings from cloud repatriation is particularly meaningful. Based on benchmarking public software companies (those that disclose their committed cloud infrastructure spend), we found that contractually committed spend averaged 50% of COR.</p>
<p>Actual spend as a percentage of COR is typically even higher than committed spend: A billion dollar private software company told us that their public cloud spend amounted to 81% of COR, and that “cloud spend ranging from 75 to 80% of cost of revenue was common among software companies”. Dullien observed (from his time at both industry leader Google and now Optimyze) that companies are often conservative when sizing cloud commit size, due to fears of being overcommitted on spend, so they commit to only their baseline loads. So, as a rule of thumb, committed spend is often typically ~20% lower than actual spend… elasticity cuts both ways. Some companies we spoke with reported that they exceeded their committed cloud spend forecast by at least 2X.</p>
<p>If we extrapolate these benchmarks across the broader universe of software companies that utilize some public cloud for infrastructure, our back-of-the-envelope estimate is that the cloud bill reaches $8B in aggregate for 50 of the top publicly traded software companies (that reveal some degree of cloud spend in their annual filings). While some of these companies take a hybrid approach—public cloud <em>and</em> on-premise (which means cloud spend may be a lower percentage of COR relative to our benchmarks)—our analysis balances this, by assuming that committed spend equals actual spend across the board. Drawing from our conversations with experts, we assume that cloud repatriation drives a 50% reduction in cloud spend, resulting in total savings of $4B in recovered profit. For the broader universe of scale public software and consumer internet companies utilizing cloud infrastructure, this number is likely much higher.</p>
<div id="attachment_306515"><p><a href="https://a16z.com/wp-content/uploads/2021/05/cloud-spend-as_percent_of_COR_a16z-scaled.jpg"><img aria-describedby="caption-attachment-306515" decoding="async" src="https://a16z.com/wp-content/uploads/2023/04/cloud-spend-as_percent_of_COR_a16z-1024x491.jpg" alt="" width="1024" height="491"></a></p><p id="caption-attachment-306515"><em>source: company S-1 and 10K filings; a16z analysis</em></p></div>
<p>While $4B of estimated net savings is staggering on its own, this number becomes even more eye-opening when translated to <em>unlocked market capitalization</em>. Since all companies are conceptually valued as the present value of their future cash flows, realizing these aggregate annual net savings results in market capitalization creation well over that $4B.</p>
<p>How much more? One rough proxy is to look at how the public markets value additional gross profit dollars: High-growth software companies that are still burning cash are often valued on gross profit multiples, which reflects assumptions about the company’s long term growth and profitable margin structure. (Commonly referenced revenue multiples also reflect a company’s long term profit margin, which is why they tend to increase for higher gross margin businesses even on a growth rate-adjusted basis). Both capitalization multiples, however, serve as a heuristic for estimating the market discounting of a company’s future cash flows.</p>
<p>Among the set of 50 public software companies we analyzed, the average total enterprise value to 2021E gross profit multiple (based on CapIQ at time of publishing) is 24-25X. In other words: For every dollar of gross profit saved, market caps rise on average 24-25X the net cost savings from cloud repatriation. (Assumes savings are expressed net of depreciation costs incurred from incremental CapEx if relevant).</p>
<p>This means an additional $4B of gross profit can be estimated to yield an additional $100B of market capitalization among these 50 companies alone. Moreover, since using a gross profit multiple (vs. a free cash flow multiple) assumes that incremental gross profit dollars are also associated with certain incremental operating expenditures, this approach may underestimate the impact to market capitalization from the $4B of annual net savings.</p>
<p>For a given company, the impact may be even higher depending on its specific valuation. To illustrate this phenomenon [please note this is not investment advice, see full disclosures below and at <a href="https://a16z.com/disclosures/">https://a16z.com/disclosures/</a>], take the example of <span>infrastructure monitoring as a service company </span>Datadog. The company traded at close to 40X 2021 estimated gross profit at time of publishing, and disclosed an aggregate $225M 3-year commitment to AWS in their S-1. If we annualize committed spend to $75M of annual AWS costs—and assume 50% or $37.5M of this may be recovered via cloud repatriation—this translates to roughly $1.5B of market capitalization for the company on committed spend reductions alone!</p>
<p>While back-of-the-envelope analyses like these are never perfect, the directional findings are clear: market capitalizations of scale public software companies are weighed down by cloud costs, and <em>by hundreds of billions of dollars</em>. If we expand to the broader universe of enterprise software and consumer internet companies, this number is likely over $500B—assuming 50% of overall cloud spend is consumed by scale technology companies that stand to benefit from cloud repatriation.</p>
<p>For business leaders, industry analysts, and builders, it’s simply too expensive to ignore the impact on market cap when making both long-term <em>and</em> even near-term infrastructure decisions.</p>
<div id="attachment_306516"><p><a href="https://a16z.com/wp-content/uploads/2021/05/gross-margin-v-growth-adjusted-revenue-multiples_a16z-scaled.jpg"><img aria-describedby="caption-attachment-306516" decoding="async" loading="lazy" src="https://a16z.com/wp-content/uploads/2023/04/gross-margin-v-growth-adjusted-revenue-multiples_a16z-1024x710.jpg" alt="" width="1024" height="710"></a></p><p id="caption-attachment-306516"><em>source: CapIQ as of May 2021; note: charts herein are for informational purposes only and should not be relied upon when making any investment decision</em></p></div>
<h3><strong>The paradox of cloud</strong></h3>
<p>Where do we go from here? On one hand, it is a major decision to start moving workloads off of the cloud. For those who have not planned in advance, the necessary rewriting seems SO impractical as to be impossible; any such undertaking requires a strong infrastructure team that may not be in place. And all of this requires building expertise beyond one’s core, which is not only distracting, but can itself detract from growth. Even at scale, the cloud retains many of its benefits—such as on-demand capacity, and hordes of existing services to support new projects and new geographies.</p>
<p>But on the other hand, we have the phenomenon we’ve outlined in this post, where the cost of cloud “takes over” at some point, locking up hundreds of billions of market cap that are now stuck in this paradox: <em>You’re crazy if you don’t start in the cloud; you’re crazy if you stay on it.</em></p>
<p>So what can companies do to free themselves from this paradox? As mentioned, we’re not making a case for repatriation one way or the other; rather, we’re pointing out that <em>infrastructure spend should be a first-class metric</em>. What do we mean by this? That companies need to optimize early, often, and, sometimes, also outside the cloud. When you’re building a company at scale, there’s little room for religious dogma.</p>
<p>While there’s much more to say on the mindset shifts and best practices here—especially as the full picture has only more recently emerged—here are a few considerations that may help companies grapple with the ballooning cost of cloud.</p>
<p><strong>Cloud spend as a KPI. </strong>Part of making infrastructure a first-class metric is making sure it is a key performance indicator for the business. Take for example Spotify’s Cost Insights, a homegrown <a href="https://redmonk.com/jgovernor/2021/04/28/shifting-cost-optimisation-left-spotify-backstage-cost-insights/" target="_blank" rel="noopener">tool that tracks</a> cloud spend. By tracking cloud spend, the company enables engineers, and not just finance teams, to take ownership of cloud spend. Ben Schaechter, formerly at Digital Ocean, now co-founder and CEO of Vantage, observed that not only have they been seeing companies across the industry look at cloud cost metrics alongside core performance and reliability metrics earlier in the lifecycle of their business, but also that “Developers who have been burned by surprise cloud bills are becoming more savvy and expect more rigor with their team’s approach to cloud spend.”</p>
<p><strong>Incentivize the right behaviors.</strong> Empowering engineers with data from first-class KPIs for infrastructure takes care of awareness, but doesn’t take care of incentives to change the way things are done. A prominent industry CTO told us that at one of his companies, they put in short-term incentives like those used in sales (SPIFFs), so that any engineer who saved a certain amount of cloud spend by optimizing or shutting down workloads received a spot bonus (which still had a high company ROI since the savings were recurring). He added that this approach—basically, “tie the pain directly to the folks who can fix the problem”—actually cost them less, because it paid off 10% of the entire organization, and brought down overall spend by $3M in just six months. Notably, the company CFO was key to endorsing this non-traditional model.</p>
<p><strong>Optimization, optimization, optimization. </strong>When evaluating the value of any business, one of the most important factors is the cost of goods sold or COGS—and for every dollar that a business makes, how many dollars does it cost to deliver? Customer data platform company Segment <a href="https://segment.com/blog/the-10m-engineering-problem/" target="_blank" rel="noopener">recently shared</a> how they reduced infrastructure costs by 30% (while simultaneously increasing traffic volume by 25% over the same period) through incremental optimization of their infrastructure decisions. There are a number of third-party optimization tools that can provide quick gains to existing systems, ranging anywhere from 10-40% in our experience observing this space.</p>
<p><strong>Think about repatriation up front. </strong>Just because the cloud paradox exists—where cloud is cheaper and better early on and more costly later in a company’s evolution—exists, doesn’t mean a company has to passively accept it without planning for it. Make sure your system architects are aware of the potential for repatriation early on, because by the time cloud costs start to catch up to or even outpace revenue growth, it’s too late. Even modest or more modular architectural investment early on—including architecting to be able to move workloads to the optimal location and not get locked in—reduces the work needed to repatriate workloads in the future. The popularity of Kubernetes and the <a href="https://a16z.com/containers/" target="_blank" rel="noopener">containerization</a> of software, which makes workloads more portable, was in part a reaction to companies not wanting to be locked into a specific cloud.</p>
<p><strong>Incrementally repatriate.</strong> There’s also no reason that repatriation (if that’s indeed the right move for your business), can’t be done incrementally, and in a hybrid fashion. We need more nuance here beyond either/or discussions: for example, repatriation likely only makes sense for a subset of the most resource-intensive workloads. It doesn’t have to be all or nothing! In fact, of the many companies we spoke with, even the most aggressive take-back-their-workloads ones still retained 10 to 30% or more in the cloud.</p>
<p>While these recommendations are focused on SaaS companies, there are also other things one can do; for instance, if you’re an infrastructure vendor, you may want to consider options for passing through costs—like using the customer’s cloud credits—so that the cost stays off your books. The entire ecosystem needs to be thinking about the cost of cloud.</p>
<p><strong>*&nbsp; &nbsp; &nbsp;*&nbsp; &nbsp; &nbsp;*</strong></p>
<p>How the industry got here is easy to understand: The cloud is the perfect platform to optimize for innovation, agility, and growth. And in an industry fueled by private capital, margins are often a secondary concern. That’s why new projects tend to start in the cloud, as companies prioritize velocity of feature development over efficiency.</p>
<p>But now, we know. The long term implications have been less well understood—which is ironic given that over 60% of companies <a href="https://datometry.com/blog/moving-to-the-cloud-survey-analysis/" target="_blank" rel="noopener">cite</a> <em>cost savings</em> as the very reason to move to the cloud in the first place! For a new startup or a new project, the cloud is the obvious choice. And it is certainly worth paying even a moderate “flexibility tax” for the nimbleness the cloud provides.</p>
<p>The problem is, for large companies—including startups as they reach scale—that tax equates to hundreds of billions of dollars of equity value in many cases… and is levied well after the companies have already, deeply committed themselves to the cloud (and are often too entrenched to extricate themselves). Interestingly, one of the most commonly cited reasons to move the cloud early on—a large up-front capital outlay (CapEx)—is no longer required for repatriation. Over the last few years, alternatives to public cloud infrastructures have evolved significantly and can be built, deployed, and managed entirely via operating expenses (OpEx) instead of capital expenditures.</p>
<p>Note too that as large as some of the numbers we shared here seem, we were actually conservative in our assumptions. Actual spend is often higher than committed, and we didn’t account for overages-based elastic pricing. The actual drag on industry-wide market caps is likely far higher than penciled.</p>
<p>Will the 30% margins currently enjoyed by cloud providers eventually winnow through competition and change the magnitude of the problem? Unlikely, given that the majority of cloud spend is currently directed toward an oligopoly of three companies. And here’s a bit of dramatic irony: Part of the reason Amazon, Google, and Microsoft—representing a combined ~5 trillion dollar market cap—are all buffeted from the competition, is that they have high profit margins driven in part by running their own infrastructure, enabling ever greater reinvestment into product and talent while buoying their own share prices.</p>
<p>And so, with hundreds of billions of dollars in the balance, this paradox will likely resolve one way or the other: either the public clouds will start to give up margin, or, they’ll start to give up workloads. Whatever the scenario, perhaps the largest opportunity in infrastructure right now is sitting somewhere between cloud hardware and the unoptimized code running on it.</p>
<p><em>Acknowledgements: We’d like to thank everyone who spoke with us for this article (including those named above), sharing their insights from the frontlines.&nbsp;</em></p>
<div id="attachment_306518"><p><a href="https://a16z.com/wp-content/uploads/2021/05/cloud-paradox-companies-appendix_a16z-scaled.jpg"><img aria-describedby="caption-attachment-306518" decoding="async" loading="lazy" src="https://a16z.com/wp-content/uploads/2023/04/cloud-paradox-companies-appendix_a16z-1024x677.jpg" alt="" width="1024" height="677"></a></p><p id="caption-attachment-306518"><em>Companies selected denoted some degree of public cloud infrastructure utilization in 10Ks</em></p></div>
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI 'breakthrough': neural net has human-like ability to generalize language (112 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-03272-3</link>
            <guid>38017146</guid>
            <pubDate>Wed, 25 Oct 2023 19:28:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-03272-3">https://www.nature.com/articles/d41586-023-03272-3</a>, See on <a href="https://news.ycombinator.com/item?id=38017146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03272-3/d41586-023-03272-3_26220188.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03272-3/d41586-023-03272-3_26220188.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="An chalkboard illustration of two figures communicating and understanding each other." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03272-3/d41586-023-03272-3_26220188.jpg">
  <figcaption>
   <p><span>A version of the human ability to apply new vocabulary in flexible ways has been achieved by a neural network.</span><span>Credit: marrio31/Getty</span></p>
  </figcaption>
 </picture>
</figure><p>Scientists have created a neural network with the human-like ability to make generalizations about language<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>. The artificial intelligence (AI) system performs about as well as humans at folding newly learned words into an existing vocabulary and using them in fresh contexts, which is a key aspect of human cognition known as systematic generalization.</p><p>The researchers gave the same task to the AI model that underlies the chatbot <a href="https://www.nature.com/articles/d41586-023-00340-6" data-track="click" data-label="https://www.nature.com/articles/d41586-023-00340-6" data-track-category="body text link">ChatGPT</a>, and found that it performs much worse on such a test than either the new neural net or people, despite the chatbot’s <a href="https://www.nature.com/articles/d41586-023-00758-y" data-track="click" data-label="https://www.nature.com/articles/d41586-023-00758-y" data-track-category="body text link">uncanny ability to converse</a> in a human-like manner.</p><p>The work, published on 25 October in <i>Nature</i>, could lead to machines that interact with people more naturally than do even the best AI systems today. Although systems based on large language models, such as ChatGPT, are adept at conversation in many contexts, <a href="https://www.nature.com/articles/d41586-023-02361-7" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02361-7" data-track-category="body text link">they display glaring gaps and inconsistencies in others</a>.</p><p>The neural network’s human-like performance suggests there has been a “breakthrough in the ability to train networks to be systematic”, says Paul Smolensky, a cognitive scientist who specializes in language at Johns Hopkins University in Baltimore, Maryland.</p><h2>Language lessons</h2><p>Systematic generalization is demonstrated by people’s ability to effortlessly use newly acquired words in new settings. For example, once someone has grasped the meaning of the word ‘photobomb’, they will be able to use it in a variety of situations, such as ‘photobomb twice’ or ‘photobomb during a Zoom call’. Similarly, someone who understands the sentence ‘the cat chases the dog’ will also understand ‘the dog chases the cat’ without much extra thought.</p><p>But this ability does not come innately to neural networks, a method of emulating human cognition that has dominated artificial-intelligence research, says Brenden Lake, a cognitive computational scientist at New York University and co-author of the study. Unlike people, neural nets struggle to use a new word until they have been trained on many sample texts that use that word. Artificial-intelligence researchers have sparred for nearly 40 years as to whether neural networks could ever be a plausible model of human cognition if they cannot demonstrate this type of systematicity.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-022-01921-7" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03272-3/d41586-023-03272-3_26213144.jpg"><p>Title not specified</p></a>
 </article><p>To attempt to settle this debate, the authors first tested 25 people on how well they deploy newly learnt words to different situations. The researchers ensured the participants would be learning the words for the first time by testing them on a pseudo-language consisting of two categories of nonsense words. ‘Primitive’ words such as ‘dax,’ ‘wif’ and ‘lug’ represented basic, concrete actions such as ‘skip’ and ‘jump’. More abstract ‘function’ words such as ‘blicket’, ‘kiki’ and ’fep’ specified rules for using and combining the primitives, resulting in sequences such as ‘jump three times’ or ‘skip backwards’.</p><p>Participants were trained to link each primitive word with a circle of a particular colour, so a red circle represents ‘dax’, and a blue circle represents ‘lug’. The researchers then showed the participants combinations of primitive and function words alongside the patterns of circles that would result when the functions were applied to the primitives. For example, the phrase ‘dax fep’ was shown with three red circles, and ‘lug fep’ with three blue circles, indicating that fep denotes an abstract rule to repeat a primitive three times.</p><p>Finally, the researchers tested participants’ ability to apply these abstract rules by giving them complex combinations of primitives and functions. They then had to select the correct colour and number of circles and place them in the appropriate order.</p><h2>Cognitive benchmark</h2><p>As predicted, people excelled at this task; they chose the correct combination of coloured circles about 80% of the time, on average. When they did make errors, the researchers noticed that these followed a pattern that reflected known human biases.</p><p>Next, the researchers trained a neural network to do a task similar to the one presented to participants, by programming it to learn from its mistakes. This approach allowed the AI to learn as it completed each task rather than using a static data set, which is the standard approach to training neural nets. To make the neural net human-like, the authors trained it to reproduce the patterns of errors they observed in humans’ test results. When the neural net was then tested on fresh puzzles, its answers corresponded almost exactly to those of the human volunteers, and in some cases exceeded their performance.</p><article data-label="Related">
  <a href="https://www.nature.com/immersive/d41586-023-02822-z/index.html" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03272-3/d41586-023-03272-3_26213232.jpg"><p>A test of artificial intelligence</p></a>
 </article><p>By contrast, GPT-4 struggled with the same task, failing, on average, between 42 and 86% of the time, depending on how the researchers presented the task. “It’s not magic, it’s practice,” Lake says. “Much like a child also gets practice when learning their native language, the models improve their compositional skills through a series of compositional learning tasks.”</p><p>Melanie Mitchell, a computer and cognitive scientist at the Santa Fe Institute in New Mexico, says this study is an interesting proof of principle, but it remains to be seen if this training method can scale up to generalize across a much larger data set or even to images. Lake hopes to tackle this problem by studying how people develop a knack for systematic generalization from a young age, and incorporating those findings to build a more robust neural net.</p><p>Elia Bruni, a specialist in natural language processing at the University of Osnabrück in Germany, says this research could make neural networks more-efficient learners. This would reduce the gargantuan amount of data necessary to train systems such as ChatGPT and would minimize ‘hallucination’, which occurs when AI perceives patterns that are non-existent and creates inaccurate outputs. “Infusing systematicity into neural networks is a big deal,” Bruni says. “It could tackle both these issues at the same time.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I think GCP is better than AWS (2020) (113 pts)]]></title>
            <link>https://nandovillalba.medium.com/why-i-think-gcp-is-better-than-aws-ea78f9975bda</link>
            <guid>38016849</guid>
            <pubDate>Wed, 25 Oct 2023 19:01:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nandovillalba.medium.com/why-i-think-gcp-is-better-than-aws-ea78f9975bda">https://nandovillalba.medium.com/why-i-think-gcp-is-better-than-aws-ea78f9975bda</a>, See on <a href="https://news.ycombinator.com/item?id=38016849">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="36c3">AWS is the best platform to showcase how great GCP is…</h2><div><a rel="noopener follow" href="https://nandovillalba.medium.com/"><div aria-hidden="false"><p><img alt="Fernando Villalba" src="https://miro.medium.com/v2/resize:fill:88:88/2*xEX2cPxo4eaKN9uOXHVDrA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><figure></figure><blockquote><p id="822e">I originally posted this on <a href="https://www.reddit.com/r/devops/comments/ge79zy/let_me_tell_you_why_i_think_gcp_is_better_than/?sort=top" rel="noopener ugc nofollow" target="_blank">Reddit</a> so I could get a good sample of opinions from other engineers to see how they compared to mine before posting and expanding here. This is my opinion based on my experience with both platforms (two years in each). My bias towards GCP is mostly based on the superior experience I have gotten with it and I am in no way affiliated with Google. AWS is still my second choice as an enterprise option for cloud platform and it would be nice for them to do better. I welcome your comments and corrections, especially if they are informed and constructive, I am happy to learn from you.</p></blockquote><h2 id="2cb0">Ikea for Cars</h2><p id="c587">If AWS (Amazon Web Services) and GCP (Google Cloud Platform) were both car companies and you wanted to purchase a car, AWS would give you the wheel, a chunky verbose manual and the keys and then tell you to go to twenty different shops they also own to get the rest of the components to put them together yourself the best you can. Sure, maybe you can hire a service and get tools to automate this part, but it still falls on you to assemble these components together and maintain the automation.</p><p id="82ea">The experience of GCP on the other hand is more like collecting the car keys and driving off from the parking lot, with the option of dismantling and customising the car if you wish, but the default is a fully built functioning car with cohesive parts so you can quickly achieve your objectives, which is driving around, not assemble the car.</p><p id="5136">My first experience working with AWS, before I had much to compare it to, was brief and I didn’t like it; I felt the interface and the way tools and settings were organised was counter-intuitive and weird.</p><p id="def2">For example assigning a static ip to a server was just bizarre, I kept looking for ways to assign the static ip without knowing that it was meant to be called elastic ip and hidden away in a separate set of menus. These elastic ips were part of a different pool of ips than the ones that were assigned dynamically, so I had to stop a production server to change the ip and also change the DNS pointing to that new ip, this was because my predecessor hadn’t assigned an static ip to the server, my bet is that he probably gave up after ten minutes trying to figure out that it was called an elastic ip.</p><p id="f03c">My second experience working with AWS was after a year and a half working with GCP, and now by comparison I really couldn’t stand AWS, it took me a few months to get accustomed back to use it and I remember that in my first few weeks I actually considered quitting and just accepting GCP roles.</p><p id="cda8">It’s not that AWS is harder to use than GCP, it’s that it is needlessly hard; a disjointed, sprawl of infrastructure primitives with poor cohesion between them. A challenge is nice, a confusing mess is not, and the problem with AWS is that a large part of your working hours will be spent untangling their documentation and weeding through features and products to find what you want, rather than focusing on cool interesting challenges.</p><p id="0d4f">Let’s just go over a few of the things that make AWS such a pain to use and how it compares with GCP.</p><h2 id="fa1e">Accounts vs Projects</h2><p id="c31d">One of the first differences that strikes you when going from GCP to AWS is accounts vs projects. In GCP you have one master account/project that you can use to manage the rest of your projects, you log in with your company google account and then you can set permissions to any project however you want. So you can have a dev project, a production project, etc. All of this works out of the box and there is absolutely nothing additional for you to do.</p><p id="2dac">In AWS you have accounts, and each account has a separate set of users. There are ways to connect these accounts so your user has permissions on other accounts. One way of doing this is creating a master users account and then adding roles that can be assumed in all other accounts by this master account.</p><p id="c341">This is not only a pain to set up, it’s very painful to use as well. For example when using terraform scripts you need to coordinate multiple roles across several modules if you need to work across multiple accounts.</p><p id="ac3d"><strong>Command Line Interface Tools (CLI tools)</strong></p><p id="67bb">Let’s just compare what you have to do in order to use GCP cli compared to AWS provided we are using 2FA and a couple of different projects/accounts.</p><p id="40e3">In GCP after you <a href="https://cloud.google.com/sdk/docs/quickstart-linux" rel="noopener ugc nofollow" target="_blank">install the Google SDK</a>, all you need to do is run gcloud init, which redirects you in the browser to a Google login page. Here you can login with your 2FA (which if you have an android phone is as easy as unlocking the phone and pressing okay) and you are done. Your login session is attached to your Google session so when you kill this session you are logged out— very simple.</p><p id="2fce">In AWS you need to create a token that you can use to login with your CLI, simple enough, right? But now we want to use 2FA, and this is where the fun begins.</p><p id="afc8">After you login with your token you then need to <a href="https://github.com/asagage/aws-mfa-script" rel="noopener ugc nofollow" target="_blank">create a script</a> to give you a 12 hour session, and you need to do this every day, because there is no way to extend this.</p><p id="b05e">Okay, but that’s not a big deal, you say, after all it’s just a code that you need to input once a day and you can get on with your day after that.</p><p id="6f39">But wait, there is more! If you need to assume roles in another account, you need to create yet <a href="https://github.com/Integralist/Shell-Scripts/blob/master/aws-cli-assumerole.sh" rel="noopener ugc nofollow" target="_blank">another script</a> that creates another profile for you to use.</p><p id="fd75">That’s one step plus two scripts, plus many steps in between. And sure, you can automate much of this or use someone else’s tools you find online (that you most likely will need to tweak), but why? Why do we have to do so much work to use AWS? Why can’t AWS abstract away this pain away from you in the way that Google has done?</p><h2 id="77a8">Web User Interface</h2><p id="6750">If using the CLI is too painful for you, you can always log in to the portal and use their user interface, although I don’t recommend you do this for everything, in fact I recommend you use it the least possible and only for reference and to check status of your services, always do infrastructure as code as much as you can</p><p id="c0c4">The AWS interface looks like it was designed by a lonesome alien living in an asteroid who once saw a documentary about humans clicking with a mouse. It is confusing, counterintuitive, messy and extremely overcrowded.</p><p id="fc51">I can’t even count the times I’ve gotten lost or stumped in the AWS console, sometimes over the most stupid details, like missing that there was a next button hidden on a weird corner. Or trying to use search bars that can only search prefixes (WTF?)</p><p id="2b02">But the biggest frustration I have from the AWS console is how you are always overwhelmed with scores of settings and options you need to fill in before actually provisioning anything.</p><p id="4833">One example that comes to mind is when someone at work said we should use codebuild/codedeploy to replace Jenkins for ECS deployments. The first engineer tried, he got stuck, the second engineer tried, he got stuck, I tried for hours and I got stuck… in the end I just gave up for lack of wanting to spend any more time on a tool that doesn’t seem to be that popular for CI/CD that I thought was meant to make life easier.</p><p id="7155">Amazon seems to be particularly terrible at interfaces in almost all of their products though. For example in my Smart TV the Netflix app works flawlessly and is intuitive to use whereas the Amazon Prime app is an abomination, you are constantly accidentally pressing the wrong button or getting lost or the subtitles are often out of sync.</p><p id="e1ba">In a rant that a Google engineer who had worked at Amazon <a href="https://gist.github.com/chitchcock/1281611" rel="noopener ugc nofollow" target="_blank">wrote a while back</a> he explained the issue with Amazon and Bezos not understanding interfaces (or is it human interaction?) like this:</p><blockquote><p id="a3f1">Jeff Bezos is an infamous micro-manager. He micro-manages every single pixel of Amazon’s retail site. He hired Larry Tesler, Apple’s Chief Scientist and probably the very most famous and respected human-computer interaction expert in the entire world, and then ignored every goddamn thing Larry said for three years until Larry finally — wisely — left the company. Larry would do these big usability studies and demonstrate beyond any shred of doubt that nobody can understand that frigging website, but Bezos just couldn’t let go of those pixels, all those millions of semantics-packed pixels on the landing page. They were like millions of his own precious children. So they’re all still there, and Larry is not.</p></blockquote><p id="21e7">GCP’s user interface is on the other hand very intuitive to use and whenever you want to provision anything you are given <a href="https://en.wikipedia.org/wiki/Convention_over_configuration" rel="noopener ugc nofollow" target="_blank">sane defaults</a> so you can deploy anything in a couple of clicks, I have never gotten lost using GCP or needed to consult a million pages of documentation to find out what I needed to do.</p><p id="854e">This however does not mean that GCP is taking away from you the power to configure things to an intricate detail, it just means they are giving you an example of a working configuration that you can then tweak to your purposes.</p><p id="2dfe">There are also other things you can do from the UI in GCP that either work really badly in AWS or are non-existent. For example you can easily open a terminal and ssh into any instance you have spun (provided you set permissions for it) and it works really well.</p><p id="f5a1">Another feature you have in GCP that I absolutely LOVE is the ability to view the CLI command that would do whatever settings you have in the console. That makes learning the cli so much easier, it’s far better than scouring the net for examples on how to do anything or trying to make sense of AWS’s gorgeous documentation…</p><h2 id="c506">Documentation</h2><figure></figure><p id="b52b">You can forgive the documentation in AWS being a nightmare to navigate for being a mere reflection of the confusing mess that is trying to describe. Whenever you are trying to solve a simple problem far too often you end up drowning in reference pages, the experience is like asking for a glass of water and being hosed down with a fire hydrant.</p><p id="3905">Great documentation is contextual, not referential. If you wanted to learn how to cook a dish, you don’t want someone to point you to a list of ingredients, you want a recipe describing how to use them, and this is where AWS documentation too often fails; it exhaustively describes everything that they have (which is not bad), but they don’t always do a good job at putting the documentation into context.</p><p id="9b26">To be perfectly fair to whoever is tasked to document anything in AWS, it is a lot harder to document something that’s confusing and messy than something that’s simple to use. Extensive and overly verbose documentation is often a sign of complicated and over convoluted software or processes, so in this sense Google Cloud already has an advantage to begin with.</p><p id="23fa">The big problem here is not that AWS doesn’t document enough, in fact it may even document more than GCP, the problem is that documentation is not a substitute for automation. Take <a href="https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html" rel="noopener ugc nofollow" target="_blank">this example</a> of long document (that leads to many other documents) telling you how to deploy the alb controller in EKS. All of this incredibly long and tedious process should have been automated by AWS so when you run EKS you can opt whether to have this controller installed or not with a tick box or a cli parameter or an extra option in terraform, as it’s the case in GCP. Instead AWS forces you to go through this lengthy documentation and put this together yourself, which can easily take you a day or more if you want to test and understand everything thoroughly.</p><p id="db60">The documentation in GCP is generally more clear and concise because they don’t need to teach you how to build everything from scratch like the above example, and while it may not always be perfect I generally found it useful and to the point. If you want other good examples of great documentation look at DigitalOcean — they are great.</p><h2 id="0612">GKE vs EKS</h2><p id="7481">If your intent is to use Kubernetes, don’t even bother with AWS, their implementation is so bad I can’t even comprehend how they have the gall to call it managed, especially when compared with GCP</p><p id="7647">In GCP if you want to spin a cluster, no problem, just a couple of clicks and you are there. The defaults are easy and sane and the entire product feels very cohesive with all the ugly, tedious bits abstracted away from your experience.</p><p id="903c">With GKE you don’t need to join the nodes, you don’t need to plan or automate for an upgrade of these nodes either, or go through <a href="https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html" rel="noopener ugc nofollow" target="_blank">this abomination</a> to use ingress, it’s done automatically or with a couple of easy clicks, and this does not mean you are sacrificing complexity. You can customise a lot, but when presented with sane, simple defaults, it’s a lot easier to understand a product that when being overwhelmed with a barrage of options and trying to figure out how everything fits together as it’s the case with EKS.</p><p id="fbf4">̶S̶p̶i̶n̶n̶i̶n̶g̶ ̶a̶n̶ ̶E̶K̶S̶ ̶c̶l̶u̶s̶t̶e̶r̶ ̶g̶i̶v̶e̶s̶ ̶y̶o̶u̶ ̶e̶s̶s̶e̶n̶t̶i̶a̶l̶l̶y̶ ̶a̶ ̶b̶r̶i̶c̶k̶.̶ ̶Y̶o̶u̶ ̶h̶a̶v̶e̶ ̶t̶o̶ ̶s̶p̶i̶n̶ ̶y̶o̶u̶r̶ ̶o̶w̶n̶ ̶n̶o̶d̶e̶s̶ ̶o̶n̶ ̶t̶h̶e̶ ̶s̶i̶d̶e̶ ̶a̶n̶d̶ ̶m̶a̶k̶e̶ ̶s̶u̶r̶e̶ ̶t̶h̶e̶y̶ ̶c̶o̶n̶n̶e̶c̶t̶ ̶w̶i̶t̶h̶ ̶t̶h̶e̶ ̶m̶a̶s̶t̶e̶r̶,̶ ̶w̶h̶i̶c̶h̶ ̶a̶ ̶l̶o̶t̶ ̶o̶f̶ ̶w̶o̶r̶k̶ ̶f̶o̶r̶ ̶y̶o̶u̶ ̶t̶o̶ ̶d̶o̶ ̶o̶n̶ ̶t̶o̶p̶ ̶o̶f̶ ̶t̶h̶e̶ ̶p̶r̶o̶m̶i̶s̶e̶ ̶o̶f̶ ̶“̶m̶a̶n̶a̶g̶e̶d̶”̶</p><blockquote><p id="2254"><strong>EDIT</strong>: From the time I worked with EKS to the time I wrote this article, AWS added managed node groups. However when going through the console creating EKS resources you still have to go through a lot of options and screens. Also managed nodes need to be created after provisioning the cluster going through yet another set of options and screens. While this is definitely a welcomed improvement, the underlining design ethos that applies to most of AWS is still in EKS, which is what I am ranting about here. Thank you to the EKS team for bringing this to my attention and please don’t take this as a personal attack, I have every confidence of your competence and you are not to blame for the <a href="https://en.wikipedia.org/wiki/Conway%27s_law" rel="noopener ugc nofollow" target="_blank">organisational structures</a> that may compel you build products this way.</p></blockquote><p id="bd08">And yes, I know that there are official terraform modules that take care of most of this work for you and make the job a lot easier and there is also a tool called <a href="https://github.com/weaveworks/eksctl" rel="noopener ugc nofollow" target="_blank">eksctl</a> developed by Weaveworks which is great, but these aim to simplify a complex solution that should have been abstracted away by AWS by design, not rely on others to make sense of the mess with complex scripts and tools.</p><p id="7ce7">Even if you use those tools to create your automation on top of AWS, the fact remains that there are a lot of moving parts underneath that you will always be responsible to orchestrate and make sure that are working and up to date. eksctl for example uses cloudformation templates in the background.</p><h2 id="96d8">Product Overload</h2><p id="372d">At the time of writing this, there are 169 AWS products compared to 90 in GCP. AWS has been around for longer and therefore they have more offering, and in good Amazon spirits, they constantly and aggressively are expanding this offering to give you more of what you may need (and a lot of what you don’t need) at breakneck speed.</p><p id="7497">This sounds like a good thing, until you start seeing the amount of half cooked products or <a href="https://www.forbes.com/sites/janakirammsv/2018/01/08/aws-service-sprawl-starts-to-hurt-the-cloud-ecosystem/#20aee5455c1f" rel="noopener ugc nofollow" target="_blank">near duplicates they have</a>. One good example is Parameter Store and Secret Manager, which are different, but from a practical point of view they can look very similar with Secret Manager mostly just adding rotation of secrets.</p><p id="d771">Another case of insane product overload is queues, explained well in <a href="https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/" rel="noopener ugc nofollow" target="_blank">this article by deps</a>:</p><blockquote><p id="fb24">GCP has done well integrating their different services together. GCP provides a smaller set of core primitives that are global and work well for lots of use cases. <a href="https://cloud.google.com/pubsub/" rel="noopener ugc nofollow" target="_blank">Pub/Sub</a> is probably the best example I have for this. In AWS you have SQS, SNS, Amazon MQ, Kinesis Data Streams, Kinesis Data Firehose, DynamoDB Streams, and maybe another queueing service by the time you read this post. 2019 Update: Amazon has now released another streaming service: <a href="https://aws.amazon.com/msk/" rel="noopener ugc nofollow" target="_blank">Amazon Managed Streaming Kafka</a>. GCP has Pub/Sub. Pub/Sub seems flexible enough to replace most (all?) of AWS’ various queues.</p></blockquote><p id="077e">AWS product naming and packaging is also very confusing. For example AWS Control Tower, Landing Zone and AWS Organisations seem like they should be consolidated into one product, and it seems they name these products in parallel, without talking to each other; apparently Control Tower creates landing zones, but they are not the “Landing Zone”. I watched a couple of talks on this and I still don’t fully understand it, like this one, notice the speaker struggling to try to make sense of this mess in <a href="https://youtu.be/nNy5UjzejNc?list=PLuI6lMS0-kCj8H5PBF0XQypIVhbYgSgQ3&amp;t=47" rel="noopener ugc nofollow" target="_blank">three</a> <a href="https://youtu.be/nNy5UjzejNc?list=PLuI6lMS0-kCj8H5PBF0XQypIVhbYgSgQ3&amp;t=90" rel="noopener ugc nofollow" target="_blank">different</a> <a href="https://youtu.be/nNy5UjzejNc?list=PLuI6lMS0-kCj8H5PBF0XQypIVhbYgSgQ3&amp;t=206" rel="noopener ugc nofollow" target="_blank">points</a>. And then in <a href="https://youtu.be/fxo67UeeN1A?t=522" rel="noopener ugc nofollow" target="_blank">another talk</a> about AWS Organisations, a different speaker explaining what the difference is between Control Tower and AWS Organisations…</p><figure></figure><p id="a3d0">GCP on the other hand has fewer products but the ones they have (at least in my experience) feel more complete and well integrated with the rest of the ecosystem, and choosing one product over other doesn’t become an agonising choice that requires extensive research (okay, you still need to research, but not nearly as much)</p><p id="70b9">I used to mock Apple in the past for how limiting they were and how very few features they had compared to Windows and Linux Distros until I started using a Macbook, it was then that it became so clear to me that having an opinionated approach on a few products and tighter integration of the various components often yields a far superior and more stable experience which is similar to the experience that I am having with GCP vs AWS. GCP gives you less and is slower delivering, but what it gives you is far better integrated, simple to use and often works better than its AWS counterpart.</p><h2 id="3919">AWS is a lot more Expensive</h2><p id="3d88">AWS charges <a href="https://thehftguy.com/2016/11/18/google-cloud-is-50-cheaper-than-aws/" rel="noopener ugc nofollow" target="_blank">substantially more</a> for their services than GCP does, but most people ignore the real high cost of using AWS, which is; expertise, time and manpower.</p><p id="57f5">With GCP, a relatively inexperienced engineer in platforming tools can pick it up and get his work done in a relatively short time because most of the tedious tasks of piecing all the parts together have been done by Google already.</p><p id="03bd">A task that may take you a day or less to do in GCP, you may spend a week to do the same thing in AWS. One example I can give here is <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html" rel="noopener ugc nofollow" target="_blank">VPC Endpoints</a>. I was working with a terraform cluster installation and I wanted to restrict outbound traffic to the internet. The problem is that if you do this then you are also cutting off traffic to AWS, in order to address this problem you need to set up endpoints. Endpoints essentially allow you to connect to AWS via the AWS intranet as opposed to the internet (Don’t ask me why cloud providers don’t do this by default, it makes no sense to me).</p><p id="ff01">So simple enough, I just add these endpoints and then my job is done. Problem is that I was working with a cluster provisioner in terraform with a lot of moving parts and using multiple AWS services and you cannot set up an endpoint that applies to all AWS services, you can only do one endpoint per service and I had to do a lot of digging trying to figure out exactly all the services that the provisioner was using and add endpoints for each one of them, every time I added an endpoint, I found out I had to add another endpoint, I ended up adding about five of them and then I found out that a couple of the services that I was using didn’t have endpoints for them, so in the end I just had to allow outgoing traffic via a NAT.</p><p id="3b71">Out of curiosity I investigated how to do this in Google Cloud because I had never done it before, just to see how difficult it would be in comparison to AWS and I wasn’t surprised to find out that you can accomplish the same thing just by <a href="https://cloud.google.com/vpc/docs/configure-private-google-access" rel="noopener ugc nofollow" target="_blank">clicking on a checkbox</a> or activating a setting, and it applies to all services. Also, doing this in GCP is free whereas in AWS you have to <a href="https://aws.amazon.com/privatelink/pricing/" rel="noopener ugc nofollow" target="_blank">pay for each endpoint</a></p><p id="3c78">The above is just one example, but I have found that generally <strong>any task that I want to do in AWS requires far more energy and effort to do than GCP</strong>, meaning you are probably going to need to hire far more engineers and need more time and more money on human resources if you are using AWS than if you are using GCP.</p><p id="0936"><strong>The Cost of interrupted Flow</strong></p><p id="dd14">Another significant cost to your organisation if you decide to use AWS is the continuous interrupted flow. <a href="https://en.wikipedia.org/wiki/Flow_(psychology)" rel="noopener ugc nofollow" target="_blank">Flow</a> is the state where you ideally want your engineers to be a good portion of their time at your company, not only they will be much happier, they will also be a lot more productive.</p><p id="a7ea">The problem with using AWS is that because everything is so confusing and complicated to use you will have to spend a lot of time reading documentation and testing to figure out how things work, and the irritating thing is that it won’t be fun experimentation, it will be tedious and trivial issues that should not exist, like the endpoint issue I described above.</p><p id="7b7e">Even after you are seasoned in the use of AWS you still spend an inordinate amount of time doing tedious things that you never have to do in GCP. Like inputting your 2FA code every 12 hours, or assuming roles, or just going over pieces and services and putting them together. The more tedious obstacles between you and the task you want to achieve, the harder it is to achieve flow.</p><h2 id="4690">Performance</h2><p id="a756">I am not going to do extensive testing in both platforms and post benchmarks for this article since it’s a lot more work than I want to spend on this but I’ll just say that in my experience I felt that performance was almost always better in GCP, for example copying from instances to buckets in GCP is INSANELY fast, I remember being shocked by this because in a previous job I had to do a lot of hourly backups to buckets of large chunks of data in AWS and I always felt the copying was very slow, but this was not the case at all for GCP.</p><p id="37b0">One good example I experienced recently is how slow it is to spin clusters up with EKS. In GKE you can have a fully functional cluster in less than<a href="https://kubedex.com/google-gke-vs-azure-aks-automation-and-reliability/" rel="noopener ugc nofollow" target="_blank"> 4 minutes</a>. In EKS it takes about 16 minutes to create just the control plane (and even then it’s <a href="https://github.com/aws/containers-roadmap/issues/654" rel="noopener ugc nofollow" target="_blank">not ready!!</a>) and then you have to add another 3 minutes or longer to spin the nodes, although sometimes I had to wait much longer than this for the workers. This may not matter that much to some, but when I am creating new infrastructure I tear it down and recreate it a lot to test that everything is working correctly and to save the company money on weekends and evenings so for me this matters a lot.</p><p id="2255">There are some latency tests in <a href="https://kinsta.com/blog/google-cloud-vs-aws/#google-compute-engine-cloudharmony-latency-test" rel="noopener ugc nofollow" target="_blank">this article</a> that clearly show that GCP does better across almost all areas when it comes to Network performance.</p><p id="c6af"><a href="https://thehftguy.com/2016/06/15/gce-vs-aws-in-2016-why-you-should-never-use-amazon/" rel="noopener ugc nofollow" target="_blank">This article</a> also compares some services between AWS and GCP.</p><h2 id="b2bb">Security</h2><p id="4a44">Both AWS and GCP are very secure and you will be okay as long as are not careless in your design. However GCP for me has an edge in the sense that everything is encrypted by default. For example their buckets and their logs are encrypted in transit and at rest. For some bizarre reason AWS does not encrypt buckets or logs by default, you have to enable this. Who the hell would NOT want their data encrypted on AWS servers?</p><p id="e048">GCP is also continuously publishing its internal models for security like <a rel="noopener" href="https://nandovillalba.medium.com/beyondcorp-vs-beyondprod-781565bc4b91">BeyondCorp and BeyondProd</a>, and designing GCP so it’s easier to integrate them for other companies. These security models are generally way ahead of the curve; for example BeyondCorp’s model has just been recently <a href="https://www.ncsc.gov.uk/blog-post/zero-trust-1-0" rel="noopener ugc nofollow" target="_blank">adopted</a> by the National Cyber Security Center, and Google has published this<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43231.pdf" rel="noopener ugc nofollow" target="_blank"> six years ago</a> while providing tools to implement it for quite some time. I am not saying that it is impossible to do the same with AWS, but it wasn’t designed with this intent in mind and it is a lot more difficult to implement. AWS on the other hand seems to have opted for supporting more <a href="https://aws.amazon.com/blogs/networking-and-content-delivery/introducing-aws-client-vpn-to-securely-access-aws-and-on-premises-resources/" rel="noopener ugc nofollow" target="_blank">traditional models of security</a>.</p><p id="f76d">This is a good talk if you are interested in hearing more about GCP security:</p><figure></figure><p id="46b1">And here is an <a href="https://youtu.be/kd33UVZhnAA" rel="noopener ugc nofollow" target="_blank">interesting tour</a> of GCP’s datacenter security.</p><h2 id="9ffd">Google is a world leader of Scalable Infrastructure.</h2><p id="da3f">I would argue that there isn’t any other company on the planet that does scalability and global infrastructure better than Google (although CloudFlare definitely gives it a run for its money in <a href="https://medium.com/@nykolas.z/dns-resolvers-performance-compared-cloudflare-x-google-x-quad9-x-opendns-149e803734e5" rel="noopener">some areas</a>).</p><p id="937c">Just to get a grasp of how incredible Google’s infrastructure is, In 2013 Google went down for 5 minutes and the <a href="https://www.cnet.com/news/google-goes-down-for-5-minutes-internet-traffic-drops-40/" rel="noopener ugc nofollow" target="_blank">internet traffic of the entire world went down by 40%</a> because people assumed their Internet was broken when Google wouldn’t open.</p><p id="776a">People trust google a lot more than they do their own internet connections because Google rarely ever goes down, and yet their combined services serve the <a href="https://youtu.be/2Uj1A9AguFs" rel="noopener ugc nofollow" target="_blank">most amount of traffic in the world</a>.</p><p id="9866">Google is constantly on the edge developing new technologies that can scale, and once these technologies have been tried and tested enough, they often open source them and put them as part of their cloud offering. These technologies include kubernetes, Golang, Hadoop, and <a href="https://opensource.google/projects/list/cloud?page=2" rel="noopener ugc nofollow" target="_blank">many more</a></p><h2 id="83bc">So what’s better about AWS? There has to be something!</h2><p id="45a0">As I mentioned I think that AWS certainly offers a lot more features, configuration options and products than GCP does, and you may benefit from some of them. Also AWS releases products at a much faster speed.</p><p id="70f5">You can certainly do more with AWS, there is no contest here. If for example you <a href="https://aws.amazon.com/snowmobile/faqs/" rel="noopener ugc nofollow" target="_blank">need a truck with a server inside</a>, then AWS is for you. AWS also has more flexibility in terms of location of your data centres. Other than that… I would chose GCP any day, and I think GCP will cover the vast majority of your cases.</p><h2 id="949f">Typical Objections to using GCP</h2><p id="6ebe">These are some of the objections I heard from people who pick AWS and are weary of choosing GCP as their provider.</p><h2 id="6b3a">But wait, there are lots of third party tools to automate AWS so it’s not a problem</h2><p id="ef55">Yes, like the aforementioned <a href="https://github.com/weaveworks/eksctl" rel="noopener ugc nofollow" target="_blank">eksctl</a>, some of them do an amazing job at this but they are still third party tools. I firmly believe AWS needs to work a lot on their abstraction of needless complexity so there is no need to have so many tools on top of it.</p><h2 id="9e9b">So if GCP is so much better, why so many more people use AWS?</h2><p id="c714">I want to cover some of the reasons that hold back GCP from overtaking AWS, some of them are reasonable, other are pure myths or misperceptions.</p><p id="7aa3"><strong>They were the first</strong></p><p id="99f4">The principal reason why more people use AWS more than any other platform is that it has been around substantially longer than others. But that alone is not enough to make it king. Even though AWS is over-convoluted and mired with all the problems I just described, it is still a very decent product with excellent uptime and performance so if you are using it, you may not be compelled enough to move another platform, no matter how much better that other platform is.</p><p id="73f3"><strong>Aggressive expansion of product line</strong></p><p id="5dca">AWS is much quicker at releasing new products than GCP, although as I mentioned previously, this can be good and bad, in my opinion is mostly bad.</p><p id="7f0e"><strong>Following the Crowd</strong></p><p id="ef76">Whenever you start working in a DevOps field you are bombarded with the idea that you must study and know how to use AWS in order to fail proof your career. AWS certifications for example are a very popular topic and every other engineer has at least one.</p><p id="e5c3">And so it happens that most engineers made a commitment to AWS right from the beginning, spending years of their lives learning this platform and ignoring or glossing over others.</p><p id="50f2">Imagine if you are an engineer with 5 years of experience in AWS with lots of money and effort spent on AWS certifications and you are tasked to do infrastructure at greenfield project, what are you going to chose? Probably not GCP.</p><h2 id="3c2d"><strong>Fear that you won’t be able to get another job if you chose GCP</strong></h2><p id="a139">It’s true that there are a lot more jobs that use AWS, but there are also very, very few engineers with extensive experience in GCP compared to AWS. Taking a GCP job or getting a GCP certification will not make you disposable any time soon. Also, many employers are smart enough to recognise that a tool alone is not enough to define the quality of an engineer. I made a transition into another AWS role after having more experience with GCP fine, and even if some employers won’t like this, many others won’t mind.</p><p id="06b8">If you are still doubting that learning and dedicating yourself to GCP is a bad idea, <a href="https://www.forbes.com/sites/louiscolumbus/2020/02/10/15-top-paying-it-certifications-in-2020/#3fdede95358e" rel="noopener ugc nofollow" target="_blank">maybe this will change your mind</a>:</p><figure><figcaption><a href="https://www.forbes.com/sites/louiscolumbus/2020/02/10/15-top-paying-it-certifications-in-2020/#1aa35449358e" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h2 id="d594"><strong>Fear that GCP may be abandoned by Google</strong></h2><p id="0441">Google will very often release products to see how the market reacts to them and if they don’t work well, they will abandon them. This is deliberate and a strategy that revolves around trying new things as a source of innovation and also not wasting resources on products that don’t work, which makes sense. Now that the company has started to release paid products like Stadia or GCP there is a perception that they will soon be abandoned.</p><p id="93a4">I highly doubt this will apply to GCP for three reasons:</p><p id="dc93">First, GCP is not just one product, but many products, all of which have involved a monumental amount of engineering effort and time invested.</p><p id="c363">Second, it would be a PR disaster if Google were to leave out in the cold all the companies that rely on them, especially the big ones like Evernote, Coca Cola, Apple, Spotify, etc. It just won’t happen.</p><p id="495d">Finally and most importantly, there is absolutely <a href="https://kinsta.com/google-cloud-market-share/" rel="noopener ugc nofollow" target="_blank">no sign</a> of GCP’s business slowing down, which would make it even more unlikely for them to abandon the platform. Why would you throw out a part of your business that’s generating <a href="https://techcrunch.com/2020/02/03/alphabet-earnings-show-google-cloud-on-10b-run-rate/" rel="noopener ugc nofollow" target="_blank">2.6 billion as of 2020 </a>and growing each year?</p><h2 id="8940"><strong>Google doesn’t “eat their own dog food” with GCP</strong></h2><blockquote><p id="bd4e">This point doesn’t prove anything in my opinion, but I am just bringing it up here because it seems to be where AWS enthusiasts lean heavily on when promoting the platform, as if it was irrefutable proof that AWS is superior.</p></blockquote><p id="6d76">There is a perception that because Google doesn’t use GCP for all their products and projects internally, they are not good enough for the public to use. Alternatively there is a perception that Amazon uses AWS for everything so that automatically makes them the most reliable choice — neither of them is accurate.</p><p id="6136">Google does use GCP for a lot of things internally, including YouTube and Gmail as explained in <a href="https://cloud.google.com/docs/compare/aws/#why" rel="noopener ugc nofollow" target="_blank">this page</a>:</p><blockquote><p id="8c83">Internally, Google uses this infrastructure for several high-traffic and global-scale services, including <a href="https://mail.google.com/" rel="noopener ugc nofollow" target="_blank">Gmail</a>, <a href="https://www.google.com/maps" rel="noopener ugc nofollow" target="_blank">Maps</a>, <a href="https://www.youtube.com/" rel="noopener ugc nofollow" target="_blank">YouTube</a>, and <a href="https://www.google.com/" rel="noopener ugc nofollow" target="_blank">Search</a>. Because of the size and scale of these services, Google has put a lot of work into optimizing its infrastructure and creating a suite of tools and services to manage it effectively. Google Cloud puts this infrastructure and these management resources at your fingertips.</p></blockquote><p id="b679">Amazon also uses AWS to power itself internally but this is <a href="https://www.networkworld.com/article/2956631/amazon-isnt-eating-all-of-its-own-cloud-dog-food.html" rel="noopener ugc nofollow" target="_blank">not always the case</a>.</p><p id="59aa">It’s true that Google does not use GCP internally for everything but there is a good reason for it. Google is always on the edge trying and testing new innovative technologies, these are extensively tested until they work great and later open sourced and made part of their cloud offering. This is not a bad thing, because as a customer you will rarely get a half cooked product with teething issues.</p><p id="844d">AWS on the other hand will release a lot more products faster, and as a consequence products will not be as complete as their GCP counterparts which can also be good in the sense they may release some tool that meets your needs and works acceptably well at a faster speed than Google would.</p><p id="8dcc">I don’t think neither approach is wrong, but I would prefer to use something that works more reliably than being a guinea pig, especially if I am paying good money for it, which is why I favour Google’s approach in this case.</p><p id="b96f">Another thing I will point out here is that Google contributes <a href="https://opensource.google/projects/list/cloud?page=2" rel="noopener ugc nofollow" target="_blank">way more</a> to the Open Source community and industry overall than Amazon does, which happens thanks to the experimentation going on inside Google.</p><h2 id="254d"><strong>“You can’t get fired for choosing AWS”</strong></h2><p id="1540">Meaning that AWS is such a safe bet as a platform provider that you could not get fired as a result of choosing it. This is what some people say in the industry to justify picking AWS as the default.</p><p id="0565">All I can say here is that if your employer fires you for choosing GCP, he is probably not a very good employer to begin with and you deserve a better job, which I am sure you can easily get giving the demand for your skills.</p><p id="9531">Jokes aside though, if the engineering talent in your company is good, they will make it work both in AWS and GCP, so I wouldn’t worry too much about your choices. Chose the platform that you feel suits your needs best, and yes, GCP is also a very safe bet.</p><h2 id="c483"><strong>Disdain for Google</strong></h2><p id="7b52">For some reason, some people really seem to hate Google. I can completely understand that Google sometimes will do things that are objectionable (and occasionally toying with the <a href="https://www.bbc.co.uk/news/technology-49015516" rel="noopener ugc nofollow" target="_blank">very objectionable</a>), but I would argue that Google is not the worst of the lot by a long shot, they are in many ways more ethical than Microsoft, Amazon and Facebook. Some people may disagree with me, but I would argue that Google has not abused its monopoly nearly as much as Microsoft did back in the day (like for example <a href="http://www.ecis.eu/documents/Finalversion_Consumerchoicepaper.pdf" rel="noopener ugc nofollow" target="_blank">hustling PC vendors</a> to only accept MS Office Suite or withdraw Windows from their machines), and their monopoly has been earned by genuinely being the very best at what they do, which is architecture of scale and search, rather than by locking you down in their ecosystem.</p><p id="04cd">Some of this disdain comes from Google’s attitude towards users and that’s something I can agree that Google can do better, but I wouldn’t say that by choosing AWS you are being more ethical than by choosing Google at all.</p><p id="5d9b">Google’s approach is to create products that are so well engineered that they don’t need as much support, and in many ways I prefer this approach to having a nice sales rep buddy who is friendly but I need to contact all the time with issues.</p><h2 id="ad9b">But this AWS complexity is creating so many jobs for us!</h2><p id="4bf4">Yes, and it does sound like I am shooting myself on the foot by posting this because this is my job. AWS definitely creates a lot more jobs for DevOps, SRE, Sysadmin, Platform Engineers etc. than GCP due to this extra complexity and the lack of desire for the developers themselves wanting to tackle this complexity.</p><p id="4966">But personally I am not afraid of learning new things, I embrace it and I enjoy it, especially if those new technologies are well designed and simple. So I am okay making this transition.</p><h2 id="3079">So will GCP ever catchup to AWS on market share?</h2><p id="1526">It’s hard to tell. One thing that AWS has going for it is that it churns out products like churros, and while I don’t think this is necessarily that great of a thing, it does meet the needs of most businesses, even if fragmented and tedious to work with. Also migrating from one platform to another is such an onerous task that many companies will never bother to do so. That being said, the increasing market share and profits coming from GCP look promising and this ex-googler author of this <a href="https://blog.usejournal.com/im-leaving-google-and-here-s-the-real-deal-behind-google-cloud-1b86513be01b" rel="noopener ugc nofollow" target="_blank">article</a>, seem very confident that GCP will eventually reign:</p><blockquote><p id="007c">My friends ask me if I think Google Cloud will catch up to its rivals. Not only do I think so — I’m positive five years down the road it will surpass them. Because today, <strong>Cloud is about helping other companies build software like Google does</strong>. All those great things about working at Google? Making them available to other companies — that’s the product market fit.</p></blockquote><p id="4b73">While I am not so sure if I am as confident as he is that it will just take five years to get there. I believe that down the road people who chose to specialise in GCP today won’t regret it.</p><h2 id="4d1a">Conclusion</h2><figure></figure><h2 id="771f">So I should always pick GCP then?</h2><p id="57f4">No, you should pick whatever fits your needs. If you are a very small company or an independent developer you may even want to give these two a miss and go with DigitalOcean or Linode or some of the smaller companies which are even easier to use and will cover your most basic needs for less money.</p><p id="e87b"><strong>AWS is still my second choice as an enterprise cloud provider after GCP</strong>. I know there is also Azure, but being a little harsh here, I have a little PTSD from using and supporting Microsoft products in the past, my memories from growing up using windows are daily blue screens and continuous Outlook issues. I just feel that Microsoft has historically been very much focused on the sale, not the quality of the product, they have the capacity to do great things, but they only do them when competition pushes them to do it, and/or have someone to copy from and they stop putting an effort once they reach monopoly. This is a stark contrast from Google or Apple who are very driven by engineering finesse and product design first respectively, not purely sales.</p><p id="5676">Of course, there are exceptions to this (I love VSCode) and some people swear that Microsoft has gotten much better over the years, but I still feel that this is only a consequence of pressure from the fierce and much better qualified competition, not because of a cultural pivot.</p><p id="0220">Based on that, if I can help it, I will avoid using Azure, but I can also respect that some people may love it, so I’ll leave it up to them to write their thoughts on it.</p><h2 id="6172">Okay then, GCP is perfect, let’s go for it!</h2><p id="6d31">Nothing is perfect. You will surely come across things in GCP that you will hate, as I have in the past, but for most people the amount of headaches will be fewer and farther in between than with AWS, and that alone is a good reason to pick it.</p><h2 id="075c">Additional Resources</h2><p id="9f0d"><a href="https://kinsta.com/google-cloud-market-share/" rel="noopener ugc nofollow" target="_blank">https://kinsta.com/google-cloud-market-share/</a></p><p id="de88"><a href="https://sada.com/blog/google-cloud/gcp-vs-aws-why-gcp-better-option-2019/" rel="noopener ugc nofollow" target="_blank">https://sada.com/blog/google-cloud/gcp-vs-aws-why-gcp-better-option-2019/</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iLeakage: Browser-Based Timerless Speculative Execution Attacks on Apple Devices (399 pts)]]></title>
            <link>https://ileakage.com/</link>
            <guid>38015277</guid>
            <pubDate>Wed, 25 Oct 2023 17:15:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ileakage.com/">https://ileakage.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38015277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<section id="abstract">
				<h4><i></i>Overview of the <span>iLeakage Attack.</span></h4>
				<div>
					<p>
						<!-- After first sentence, emphasize how Spectre is still alive and kicking nearly 6 years after release -->
						We present iLeakage, a transient execution side channel targeting the <a href="https://www.apple.com/safari/">Safari web browser</a> present on Macs, iPads and
						iPhones. iLeakage shows that the <a href="https://spectreattack.com/">Spectre</a> attack is still
						relevant and exploitable, even after nearly 6 years of effort to mitigate it since its discovery.
						We show how an attacker can induce Safari to render an arbitrary webpage, subsequently
						recovering sensitive information present within it using speculative execution. In particular,
						we demonstrate how Safari allows a malicious webpage to recover secrets from popular high-value
						targets, such as Gmail inbox content. Finally, we demonstrate the recovery of passwords, in case
						these are autofilled by credential managers.
					</p>

					

					
				</div>
			</section>

			<section id="demos">
				<h4><i></i>Demo <span>Videos.</span></h4>
				<div>
						<div>
							<h5>Recovering Instagram Credentials</h5>
							<p>
								We show a scenario where the target uses an autofilling credential manager
								(LastPass in this demo) to sign into Instagram with Safari on macOS.
							</p>
							<p>
								<iframe src="https://www.youtube-nocookie.com/embed/Z2RtpN77H8o" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope" allowfullscreen=""></iframe>
							</p>
						</div>
						<div>
							<h5>Recovering Gmail Inbox Content</h5>
							<p>
								Assuming the target is signed into Google on Safari for iOS, we recover the subject
								lines of the Gmail account's most recent messages on an iPad.
							</p>
							<p>
								<iframe src="https://www.youtube-nocookie.com/embed/2uH9slLKTjw" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope" allowfullscreen=""></iframe>
							</p>
						</div>
						<div>
							<h5>Recovering YouTube Watch History</h5>
							<p>
								We recover YouTube watch history from the Chrome browser for iOS, which is a shell on
								top of Safari's browsing engine due to Apple's App Store policy.
							</p>
							<p>
								<iframe src="https://www.youtube-nocookie.com/embed/sNdyrCtajP4" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope" allowfullscreen=""></iframe>
							</p>
						</div>
					</div>
			</section>

			<section id="people">
				<h4><i></i>The People
					<span>Behind iLeakage.</span>
				</h4>
				<div>
							<ul>
								<li><a href="https://jasonkim.page/">Jason Kim </a><span><a href="https://www.gatech.edu/">Georgia Institute of
											Technology</a></span></li>
								<li><a href="https://www.synkhronix.com/about/">Stephan van Schaik</a> <span><a href="https://umich.edu/">University of Michigan</a></span></li>
								<li><a href="https://www.cc.gatech.edu/~genkin/">Daniel Genkin</a> <span><a href="https://www.gatech.edu/">Georgia Institute of Technology</a></span>
								</li>
								<li><a href="https://yuval.yarom.org/">Yuval Yarom</a> <span><a href="https://www.ruhr-uni-bochum.de/">Ruhr University
											Bochum</a></span></li>
							</ul>
						</div>
			</section>

			<section id="qa">
				<h4><i></i>Frequently Asked <span>Questions.</span></h4>

				<p>
					<h5>The Basics</h5>
				</p>
				<div id="impact-and-potential-concerns">
					<div id="panelsStayOpen-collapseAffected" aria-labelledby="panelsStayOpen-headingAffected">
							<p>
								Yes (with a very high chance), if you have a device running macOS or iOS with Apple's
								A-series or M-series CPUs. This includes all recent iPhones and iPads, as well as
								Apple's laptops and desktops from 2020 and onwards.
							</p>
						</div>
					<div id="panelsStayOpen-collapseImpact" aria-labelledby="panelsStayOpen-headingImpact">
							<p>
								Code running in one web browser tab should be isolated and not be able to infer anything
								about other tabs that a user has open. However, with iLeakage, malicious JavaScript and
								WebAssembly can read the content of a target webpage when a target visits and clicks on
								an attacker's webpage. This content includes personal information, passwords, or credit
								card information.
							</p>
						</div>
					<div id="panelsStayOpen-collapseMitigation" aria-labelledby="panelsStayOpen-headingMitigation">
								<p>
									At the time of public release, Apple has implemented a mitigation for iLeakage
									in Safari. However, this mitigation is not enabled by default, and enabling it
									is possible only on macOS. Furthermore, it is marked as unstable.
									We will keep this FAQ updated as Apple pushes more iOS and macOS updates.
									If you wish to enable the mitigation on your Mac now, below are the steps:
								</p>
								<p>
									<b>If you have updated to macOS Sonoma:</b>
								</p>
								<ol>
									<li>Open the Terminal app. You can find this in the Launchpad, or through Spotlight
										search.</li>
									<li>Copy and paste the following command (in magenta), and press the Return key to
										run it:
										<br><code>defaults write com.apple.Safari IncludeInternalDebugMenu 1</code>.
									</li>
								</ol>
								<p>
									<b>If you are on an earlier macOS version (macOS Ventura and earlier):</b>
								</p>
								<ol>
									<li>We recommend enabling automatic updates and updating to macOS Sonoma. However,
										if you wish to enable the mitigation on older macOS versions, follow these
										steps:</li>
									<li>First, download the version of Safari Technology Preview tht matches your macOS
										version from Apple's <a href="https://developer.apple.com/safari/resources/">download page.</a></li>
									<li>Double-click the downloaded installer with the <code>.pkg</code> file extension,
										and follow its directions until Safari Technology Preview is installed.</li>
									<li>Open the Terminal app. You can find this in the Launchpad, or through Spotlight
										search.</li>
									<li>Copy and paste the following command (in magenta), and press the Return key to
										run it:
										<br><code>defaults write com.apple.SafariTechnologyPreview IncludeInternalDebugMenu 1</code>.
									</li>
								</ol>
								<p>
									<b>This enables Safari's hidden debugging menu. Then, follow these steps:</b>
								</p>
								<ol>
									<li>Open Safari (or Safari Technology Preview). On the menu bar, you should see a
										new entry named <b>Debug</b>. <br><img src="https://ileakage.com/img/debug-menu.png" alt="Hidden debug menu"></li>
									<li>Click the Debug menu. This opens a long dropdown. Click on <b>WebKit Internal
											Features</b>. <br><img src="https://ileakage.com/img/webkit-internal.png" alt="WebKit internal features"></li>
									<li>This opens another long dropdown to the side. Scroll down to the bottom of this
										new dropdown, where you'll find an entry called <b>Swap Processes on Cross-Site
											Window Open</b>. <br><img src="https://ileakage.com/img/pson.png" alt="Swap processes on cross-site window.open">
									</li>
									<li>Click this entry. A checkmark should appear to the left of it, like the
										screenshot below. <br><img src="https://ileakage.com/img/pson-enabled.png" alt="Mitigation enabled"></li>
								</ol>
								<p>
									Afterwards, you're all set! To disable the mitigation, repeat steps 1-4 from above,
									and the checkmark will disappear.
									To disable the hidden debugging menu, open the Terminal app, copy and paste the
									following command (depending on your OS version), and press the Return key to run.
									The changes will apply the next time you start Safari (or Safari Technology
									Preview).
								</p>
								<ul>
									<li>For Safari (macOS Sonoma):
										<br><code>defaults write com.apple.Safari IncludeInternalDebugMenu 0</code></li>
									<li>For Safari Technology Preview (macOS Ventura and earlier):
										<br><code>defaults write com.apple.SafariTechnologyPreview IncludeInternalDebugMenu 0</code>
									</li>
								</ul>
							</div>
					<div id="panelsStayOpen-collapseDetect" aria-labelledby="panelsStayOpen-headingDetect">
							<p>
								iLeakage is highly unlikely to be detected, since the attack runs in Safari and does not
								leave traces in the system's log files. However, traces of an attacker webpage hosting
								iLeakage may be present in the browser's cache of pages it has recently visited.
							</p>
						</div>
					<div id="panelsStayOpen-collapseAbuse" aria-labelledby="panelsStayOpen-headingAbuse">
							<p>
								So far, we do not have evidence that iLeakage has been or not been abused. However, we
								note that iLeakage is a significantly difficult attack to orchestrate end-to-end, and
								requires advanced knowledge of browser-based side-channel attacks and Safari's
								implementation.
							</p>
						</div>
					<div id="panelsStayOpen-collapseStopPassword" aria-labelledby="panelsStayOpen-headingStopPassword">
							<p>
								Not for the most part. In fact, we encourage using credential managers as opposed to
								trying to remember all of your passwords. In general, this is a better approach
								than reusing passwords or storing them insecurely. While iLeakage can recover
								credentials that are autofilled into a webpage, we note that many platforms require user
								interaction for autofill to occur.
							</p>
						</div>
					<div id="panelsStayOpen-collapseNotify" aria-labelledby="panelsStayOpen-headingNotify">
							<p>
								We disclosed our results to Apple on September 12, 2022 (408 days before public release).
							</p>
						</div>
				</div>

				<p>
					<h5>For Tech-Savvy Readers</h5>
				</p>
				<div id="technical-details">
					<div id="panelsStayOpen-collapseJS" aria-labelledby="panelsStayOpen-headingJS">
							<p>
								JavaScript and WebAssembly are two programming languages that make up the backbone of
								interactive webpages, such as online games and video streaming services. JavaScript can
								update the content of the website directly, while WebAssembly is used for
								high-performance web applications. Ultimately, WebAssembly interfaces with JavaScript to
								deliver dynamic content to users. Since both are sandboxed in a browser environment,
								side-channel attacks are notably more difficult to implement in these languages.
								However, the impact is drastically greater, as browsers execute both types of code
								automatically and do not require the user to download the malicious program.
							</p>
						</div>
					<div id="panelsStayOpen-collapseSidechannel" aria-labelledby="panelsStayOpen-headingSidechannel">
								<p>
									Most computer bugs arise from mistakes in programming, such as missing bounds checks
									or use-after-frees. However, a side-channel attack exploits the implementation of a
									computer system to attack it, even if the program it runs is a secure algorithm.
									Systems can leak sensitive data through sound, electromagnetic radiation, or thermal
									throttling, just for a few examples.
								</p>
								<p>
									Many side channels, including ones we use for iLeakage, comes from the CPU's
									microarchitecture.
									Whenever an attacker and target run on the same CPU, they share the CPU's internal
									resources such as cores, caches, and internal buffers.
									Sharing resources leads to contention, and contention can be measured indirectly
									through several variables like timing or power consumption.
									These measurements leave fingerprints on the target's behavior on the CPU.
									Accordingly, an attacker can abuse this to make inferences about the target's
									secrets even if they are isolated at the process level or the hypervisor level.
								</p>
							</div>
					<div id="panelsStayOpen-collapseSpectre" aria-labelledby="panelsStayOpen-headingSpectre">
								<p>
									Virtually all modern CPUs use a performance optimization where they predict if a
									branch instruction will be taken or not, should the outcome not be readily
									available. Once a prediction is made, the CPU will execute instructions along the
									prediction, a process called speculative execution. If the CPU realizes it had
									mispredicted, it must revert all changes in the state it performed after the
									prediction. Both desktop and mobile CPUs exhibit this behavior, regardless of
									manufacturer (such as Apple, AMD, or Intel).
								</p>
								<p>
									<a href="https://spectreattack.com/">Spectre</a> is a hardware vulnerability in
									virtually all modern CPUs that occurs when speculative execution backfires. While
									the CPU should ideally revert all changes in state, speculative execution leaves
									traces in the CPU's microarchitectural state and especially the cache. A Spectre
									attack coerces the CPU into speculatively executing the wrong flow of instructions.
									If this wrong flow has instructions depending on sensitive data, their value can be
									inferred through a side channel even after the CPU realizes the mistake and reverts
									its changes. An adversary can abuse this behavior to read data that they cannot
									normally access through program semantics. Because speculative execution is an
									important part of CPU performance that is infeasible to simply remove as a
									countermeasure, Spectre continues to be dangerous to software even years after its
									discovery.
								</p>
							</div>
					<div id="panelsStayOpen-collapseDifference" aria-labelledby="panelsStayOpen-headingDifference">
								<p>
									Since the original <a href="https://spectreattack.com/">Spectre</a> exploit, browser
									vendors had significantly hardened browsers against attacks based on speculative and
									transient execution. For the case of Safari, this includes 35-bit addressing and the
									value poisoning, one process per tab isolation policy, as well as a low resolution
									timer.
								</p>
								<p>
									Nonetheless, iLeakage is the first demonstration of a speculative execution attack
									against <a href="https://en.wikipedia.org/wiki/Apple_silicon">Apple Silicon</a> CPUs
									and the Safari browser.
									In particular, we show that speculative execution attacks are possible on Apple's
									latest A-series and M-series architectures, despite Apple's side channel hardening.
									More specifically, we first devise an empirical method to recover the cache
									organization of Apple CPUs, since it is not publicly documented. We then use this
									information to develop a gadget that can distinguish cache hits from misses even in
									the absence of a cycle-accurate timer, which is the case for both native and browser
									environments for Apple devices. We use this gadget as both a test to generate cache
									eviction sets and as a covert channel. Finally, we migrate these techniques to the
									Safari browser, where we make Safari run code designed for one datatype on our
									maliciously crafted object of the wrong type while the CPU is performing speculative
									execution. Ultimately, we achieve a out-of-bounds read anywhere in the address space
									of Safari's rendering process.
								</p>
							</div>
					<div id="panelsStayOpen-collapseWorks" aria-labelledby="panelsStayOpen-headingWorks">
							<p>
									In order to construct iLeakage, we first reverse engineer the cache topology on <a href="https://en.wikipedia.org/wiki/Apple_silicon">Apple Silicon</a> CPUs.
									We then overcome Apple's timer limitations using a new speculation-based gadget, which allows us
									to distinguish individual cache hits from cache misses, despite having access to only low
									resolution timers. We also demonstrate a variant of this gadget that uses no timers, leveraging
									race conditions instead.
									After using our speculation-based gadget to construct eviction sets, we
									proceded to analyze Safari's side channel resilience. Here, we bypass Safari's 35-bit addressing
									and the value poisoning countermeasures, creating a primitive that can speculatively read and
									leak any 64-bit pointer within Safari's rendering process. Combining this with a new method for
									consolidating websites from different domains into the same address space, we are able to mount
									a speculative type confusion attack that leaks sensitive information.
								</p>
						</div>
					<div id="panelsStayOpen-collapsePaper" aria-labelledby="panelsStayOpen-headingPaper">
							<p>
									The download button at the top of this website links to an academic paper, also
									available through this <a href="https://ileakage.com/files/ileakage.pdf">link.</a>
									Our paper will appear at the 2023 ACM Conference on Computer and Communications
									Security (CCS).
								</p>
						</div>
				</div>

				<p>
					<h5>Miscellaneous</h5>
				</p>
				<div id="miscellaneous">
					<div id="panelsStayOpen-collapseOther" aria-labelledby="panelsStayOpen-headingOther">
								<p>
									On macOS, other popular browsers such as Chrome, Firefox and Microsoft Edge use
									different JavaScript engines. Since iLeakage exploits idiosyncrasies in Safari's
									JavaScript engine, these nuances suffice to deter iLeakage from working on them.
								</p>
								<p>
									However, iOS has a different situation. Due to Apple's App Store and sandboxing
									policies, other browser apps are forced to use Safari's JavaScript engine. That is,
									Chrome, Firefox and Edge on iOS are simply wrappers on top of Safari that provide
									auxiliary features such as synchronizing bookmarks and settings. Consequently,
									nearly every browser application listed on the App Store is vulnerable to iLeakage.
								</p>
							</div>
					<div id="panelsStayOpen-collapseLogo" aria-labelledby="panelsStayOpen-headingLogo">
							<p>
									Yes, we have <a href="https://ileakage.com/img/ileakage.svg">SVG</a> and <a href="https://ileakage.com/img/ileakage.png">PNG</a> versions of the iLeakage logo. While the logo
									contains a modified version of the Safari logo, we note the Safari logo is in the
									public domain at <a href="https://commons.wikimedia.org/wiki/File:Safari_browser_logo.svg">Wikimedia
										Commons</a>. Furthermore, it is not on Apple's list of <a href="https://www.apple.com/legal/intellectual-property/trademark/appletmlist.html">trademarks.</a>
								</p>
						</div>
				</div>

			</section>
			<section id="acknowledgments">
				<h4><i></i>Acknowledgments</h4>
				<div><p>
						This research was supported by
						the Air Force Office of Scientific Research (AFOSR) under award number FA9550-20-1-0425;
						an ARC Discovery Project number DP210102670;
						the Defense Advanced Research Projects Agency (DARPA) under contract HR00112390029 and
						W912CG-23-C-0022;
						the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence
						Strategy - EXC 2092 CASA - 390781972;
						the National Science Foundation under grant CNS-1954712;
						and gifts by Cisco and Qualcomm.
						</p><p>
						
						The views and conclusions contained in this website are those of the authors and
						should not be interpreted as representing the official policies,
						either expressed or implied, of the U.S. Government.
						</p><p>
						
						Parts of this work were undertaken while Yuval Yarom was affiliated with the University of
						Adelaide.
					</p></div>
			</section>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Adding crushed rock to farmland pulls carbon out of the air (201 pts)]]></title>
            <link>https://www.ucdavis.edu/climate/news/adding-crushed-rock-farmland-pulls-carbon-out-air</link>
            <guid>38015169</guid>
            <pubDate>Wed, 25 Oct 2023 17:08:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ucdavis.edu/climate/news/adding-crushed-rock-farmland-pulls-carbon-out-air">https://www.ucdavis.edu/climate/news/adding-crushed-rock-farmland-pulls-carbon-out-air</a>, See on <a href="https://news.ycombinator.com/item?id=38015169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span>Adding crushed volcanic rock to cropland could play a key role in removing carbon from the air. In a field study, scientists at the University of California, Davis, and Cornell University found the technology stored carbon in the soil even during an extreme drought in California. The <a href="https://iopscience.iop.org/article/10.1088/2515-7620/acfd89/meta">study</a> was published in the journal Environmental Research Communications.</span></span></p>

<p><span><span>Rain captures carbon dioxide from the air as it falls and reacts with volcanic rock to lock up carbon. The process, called rock weathering, can take millions of years — too slow to offset global warming. But by crushing the rock into a fine dust, rock weathering speeds up. Previous <a href="https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023EF003698">studies</a> have estimated this “enhanced” rock weathering could store 215 billion tons of carbon dioxide over the next 75 years if spread across croplands globally.</span></span></p>

<p><span><span>But until now the technology hasn’t been field-tested in dry climates. </span></span></p>

<p><span><span>“These reactions require water,” said lead author Iris Holzer, a doctoral candidate in soils and biogeochemistry in the Department of Land, Air and Water Resources at UC Davis. “Since we’re interested in the global carbon storage potential of enhanced weathering, we need to understand if it can work in these drier climates and if different measurement approaches are effective. We were excited to observe carbon removal in this environment.”</span></span></p>

<h2><span><span><strong>California as a test case for storing carbon</strong></span></span></h2>

<p><span><span>Researchers applied crushed rock, both metabasalt and olivine, on 5 acres of a fallowed cornfield in the Sacramento Valley. They collected measurements during the winter months of 2020-2021. California was experiencing extreme drought at the time, with rainfall at 41% of its historical average. </span></span></p>

<layout-columns columns="1" cwidth="overflow"><div slot="column1">
	<figure role="group"><p><img loading="lazy" src="https://www.ucdavis.edu/sites/default/files/media/images/DSC_8875_edited.jpg" width="2000" height="1125" alt="A spreader unloads crushed metabasalt rock on a fallowed corn field in the Central Valley. (Amy Quinton/ UC Davis)" typeof="foaf:Image"></p>
<figcaption>A spreader unloads crushed metabasalt rock on a fallowed corn field in the Central Valley. (Amy Quinton/ UC Davis)</figcaption></figure></div>

	

	

	
</layout-columns><p><span><span>The study found the plots with crushed rock stored 0.15 tons of carbon dioxide per hectare (2.47 acres) during the study compared to plots without crushed rock. Though researchers expect different weathering rates in different environments, if this amount of carbon was removed across all California cropland, it would be equivalent to taking 350,000 cars off the road every year.</span></span></p>

<p><span><span>“We’re definitely seeing evidence of weathering processes taking place on short time scales,” said Holzer. “Even the infrequent heavy rains we get in the West might be enough to drive enhanced rock weathering and remove carbon dioxide.”</span></span></p>

<p><span><span>Holzer said measuring and verifying that carbon storage at larger scales and following it over time is the next challenge. </span></span></p>

<p><span><span>Forty-one percent of Earth’s land surface is covered by drylands that are expanding due to climate change. Researchers said this makes investigating enhanced rock weathering in drylands increasingly important.</span></span></p>

<p><span><span>“When it comes to bending the global carbon curve, we are in a race against time,” said senior author Benjamin Z. Houlton, Ronald P. Lynch Dean of the Cornell University College of Agriculture and Life Sciences. “Our study demonstrates a new way to verify carbon dioxide removal via enhanced weathering, which is a critical leap forward for scaling this technology in croplands worldwide.”</span></span></p>

<p><span><span>Other authors include Mallika Nocco, in the Department of Land, Air and Water Resources at UC Davis. </span></span></p>

<p><span><span>The research, part of the Working Lands Innovation Center, was funded by the California Strategic Growth Council and the Grantham Foundation, Roger Sant and Doris Matsui. Aggregates and mining company, SGI, a Standard Industries company, donated the crushed metabasalt rock from its site in Ione, California. </span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nile: Serverless Postgres for modern SaaS (158 pts)]]></title>
            <link>https://www.thenile.dev/blog/introducing-nile</link>
            <guid>38014812</guid>
            <pubDate>Wed, 25 Oct 2023 16:45:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thenile.dev/blog/introducing-nile">https://www.thenile.dev/blog/introducing-nile</a>, See on <a href="https://news.ycombinator.com/item?id=38014812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I am thrilled to announce Nile, a serverless Postgres database designed for modern SaaS applications. Modern SaaS applications are multi-tenant. We’re the first database that virtualizes tenants into the database. This enables seamless tenant isolation, per-tenant backups, and placement on multi-tenant or dedicated infrastructure, anywhere on the planet. You can do all this with the experience of a single Postgres! You don’t have to manage multiple databases, build complex permissions for isolation, or write buggy scripts to read specific tenant data from backups. On top of the tenant model, we provide opt-in user management capabilities, customer-specific vector embeddings, and instant tenant admin dashboards. You can do all of this with very little code. Moreover, Nile's Postgres is built for the cloud, enabling effortless scaling and a true serverless experience. You can <a href="https://www.thenile.dev/">sign up for our waitlist</a> today to try it out.</p>
<p>Before Nile, I spent six years at Confluent, helping transform the company from primarily on-premise to a successful global SaaS company. Through this journey, I learned the challenges of launching and scaling a SaaS product to thousands of customers and tens of thousands of users. We spent significant time managing and isolating tenants, supporting different tenant deployment models, dealing with long downtimes to restore tenant data from backups, and optimizing per-tenant performance. We also had to build the organization and user management capabilities, store and move data to different parts of the company, track usage, bill individual customers, and handle many other SaaS problems. When we spoke to many other companies from different verticals, the problems were similar. All these problems in building SaaS were around data, but the database had little to offer.</p>
<p>We started thinking about what an ideal database for SaaS will look like. What foundational elements would it require? How can we create a fully integrated solution that simplifies the development and scaling of SaaS while also offering the flexibility for developers to integrate with their preferred tools? We picked Postgres as our foundational database. We built tenant virtualization into it, allowing many virtual tenant databases to be placed on physical Postgres databases. We built a single database experience to interact with all these virtual tenant DBs. This was a powerful primitive that provided world-class developer experience and helped solve all the tenant management problems. These virtual tenant DBs are isolated, have their own backups, can be placed on multi-tenant or dedicated infrastructure, and can be deployed to any location worldwide.</p>
<p>On top of this basic foundation of tenants, we also built the concept of users and their relationship with the tenants. The authentication and authorization semantics execute on top of this, providing an impregnable level of security for tenants and users. Storing and querying vector embeddings per tenant becomes trivial. They can now be placed closer to the tenant and scale indefinitely when the index size becomes large and resource-consuming. Finally, the database gives out-of-the-box customer admin dashboards to understand and debug issues with tenant and user growth, insights into per-tenant performance, and management controls to perform administrative operations on tenants and users. Finally, the database is built to be serverless and leverage cloud-native solutions. This database, built from first principles, significantly simplifies the development and scaling of SaaS.</p>
<p>We will go deeper to understand what SaaS is, what it means to say they are modern, the current challenges in building them, and finally, what choices and tradeoffs we made in building the database for modern SaaS.</p>
<h2 id="what-makes-saas-modern-and-why-is-it-hard-to-build">What makes SaaS modern, and why is it hard to build?</h2>
<p>SaaS is a pretty overloaded term at this point, and it would be useful to specify how we define it. We define SaaS as any application that’s multi-tenant. A tenant can be a company, an organization, or a workspace in your product that contains a group of users. Here are a few examples of SaaS products and how tenants and users map to them:</p>
<ol>
<li>GitHub helps a group of developers manage and deploy their code. Each Github organization is a tenant, and the developers within those organizations are users.</li>
<li>Salesforce or Hubspot helps sales reps manage their leads. Each company is a tenant, and the users are the sales reps.</li>
<li>Ring is a home security company that provides alarm services to different households. Each household is a tenant, and people living in a house using their service are users.</li>
<li>Toast is a platform to help build software for restaurants. The restaurants are tenants, and the employees of the restaurants are the users.</li>
</ol>
<p>It is clear from these examples that SaaS is a delivery mechanism and will be leveraged by every vertical, including technology, hardware, manufacturing, industrial, legal, etc. Our insight is that 95% of companies fall into this category, and there’s a massive opportunity to simplify the life of developers building these products.</p>
<p>We've spent years building and talking to SaaS companies identifying the core principles of modern SaaS. They're tenant-centric, secure, globally deployed and scalable, fast and responsive, and provide AI-native experiences. Secondary values like data-centricity, real-time, collaboration and offline mode, and monetization are increasingly important. Let's examine them in more detail based on our experience.</p>
<h3 id="customer-or-tenant-centric">Customer or tenant-centric</h3>
<p>A SaaS application provides services to multiple tenants or organizations. Users can create new organizations and get invited to existing ones. They can access the organization irrespective of where they are in the world. One organization's data is perfectly isolated from the other. In addition, you want the performance of one tenant not to affect the other tenants.</p>
<p>There are many other considerations:</p>
<ul>
<li>Where is the tenant’s data located?</li>
<li>What happens when a tenant's data is deleted?</li>
<li>How long will you keep data backups for each tenant?</li>
<li>How can you restore a specific tenant’s data?</li>
<li>How many tenants can you support?</li>
<li>What are the compliance needs for each customer, etc?</li>
</ul>
<p><img src="https://www.thenile.dev/blog/github_organization.png" alt="“Github Organization”"></p>
<p><strong>Everything about tenant management is hard.</strong> You typically start with a single database and place all the tenants on it. You tackle data isolation between tenants by implementing brittle permission logic at the application level or complex, hard-to-debug, row-level security policies in databases like Postgres. You turn on daily backups but have little idea how to restore data for specific tenants when customers lose data. You end up writing some hacky scripts that are slow and buggy to parse through the backups and extract the tenant data. Once the application has users, you run into your first performance issue. Some tenants are pushing more load, and others have large datasets causing queries to take more resources. This impacts other customers as well. You need help determining which customer is causing the impact and which ones are being impacted. To solve this, you migrate some tenants to dedicated databases, which requires building metadata and sharding logic at the application layer to manage all this. Schema changes, rollouts, monitoring, and developer experience become more complex. This was our story and every other SaaS company's story.</p>
<h3 id="secure-at-every-step">Secure at every step</h3>
<p>Modern SaaS is all about being secure by default. The data that belongs to one tenant cannot be exposed to another tenant under any circumstances. This is commonly referred to as tenant data isolation. Users should only be able to see the data of tenants to whom they have access. Most applications need to provide modern authentication support, such as social logins and enterprise logins. There has to be support for a fine-grained permission model for users within a tenant. The same user can have different permission policies across different tenants.</p>
<p><strong>These security needs seem simple but are complex to get right for a multi-tenant application in practice.</strong> Most authentication solutions focus on only users and leave developers to think about tenants and the interaction between users and tenants. Organization management is an entire suite of problems that needs deep coordination with the tenant's data in the database. One other critical decision that needs to be made is where the user data resides. Ideally, the primary database should be the source of truth for user data. If not, you must figure out how to sync the data between a third-party service and your primary database. This is a hard problem in distributed systems. Synchronizing user data from a third-party service requires a reliable way to copy it to the primary database, even when failures happen. This cannot be accomplished by stateless event services like webhooks, where you can lose data. You need a reliable replayable event stream to synchronize it. Even with that, you have to deal with eventual consistency in your application. Another option is a two-phase commit between the database and the external service, which is impractical. The cleanest approach is to build auth on top of your source of truth database.</p>
<h2 id="globally-available"><strong>Globally available</strong></h2>
<p>All SaaS companies want to be global from day one. At the same time, customers expect great performance and want their compliance needs to be satisfied.</p>
<p><strong>Providing low latency globally is hard because you need more than optimizing the database performance alone.</strong> The last mile of receiving the response from the server to the client constitutes a significant part of the latency. For example, the network latency between Sydney, Australia, and New York, USA, is around 200 ms on average. This is probably 10x more than the server-side latency of the database. The only solution is to place the data closer to the tenant.
<img src="https://www.thenile.dev/blog/latency_graph.png" alt="“Latency Graph&quot;">
<strong>Achieving compliance requirements in different countries is equally hard, and it also needs data to be stored locally in the country where the application is accessed.</strong> This, again, requires managing multiple databases distributed across the globe. Most companies lose critical business because they cannot provide this capability.</p>
<p>Creating and managing multiple databases across different parts of the globe poses many challenges. This is hard as it creates challenges with schema migrations, is expensive to operate, and requires complex sharding and client-side routing. Developers should be abstracted from these problems and spend their time on the core business logic.</p>
<h2 id="ai-native-experience">AI-native experience</h2>
<p>With the rise of GPT and other open-source large language models, AI-native applications have gained massive traction. Instead of AI being a separate vertical, AI will become more immersive in interacting with SaaS applications. For example, GitHub Copilot provides a seamless experience for developers to use as a coding assistant. Notion provides an AI assistant that helps to write documents, rephrase existing writeups, and summarize long articles (like this one). Hubspot provides a personal chatbot for salespeople to have conversations about their leads and pipelines. It is obvious from these examples where this is heading. New product designs will have AI built in from the start.</p>
<p><strong>The difficulty of building the AI infrastructure for SaaS is that you cannot use the large language models directly.</strong> They are trained on public data and will typically provide incorrect results. They need tenant-specific data to give relevant results. In addition, there are compliance and security issues with sharing all the private data of tenants to a large language model. This requires building architectures like RAG (more about this later) that require creating tenant-specific vector embeddings, storing them, and augmenting the LLM prompt with the tenant context. This will help with avoiding the hallucination problem and also keep the data secure. The latency of querying these embeddings is another challenge, and network latency from the user to the database will further exacerbate it. Finally, vector indexes like HNSW take significant resources and need horizontal scaling if the embeddings grow fast.</p>
<h2 id="highly-available-and-scalable">Highly available and scalable</h2>
<p>Everyone wants their application to be highly available. SaaS applications used to have weekend maintenance schedules to upgrade the database. Some applications still do! This is no longer acceptable for most users. The expectation is to have 99.99 percentile availability. Also, as the application scales, users want things to work as they used to. They don’t want any interruption in service or any performance degradation.</p>
<p><strong>Building a fully automated technology to manage tenant health proactively is not trivial.</strong> You have a service impact if you cannot do zero downtime upgrades. Similarly, you would have customer impact when it takes too long to restore specific tenant data from backups, or developers are manually trying to add more capacity due to a sudden spike in workload or lack of isolation.</p>
<p>In addition to these five principles, modern SaaS also has a few other considerations that are quickly becoming standard.</p>
<p><strong>Data-centric</strong></p>
<p>SaaS applications can be enhanced by providing valuable data insights to the users through the application. Building these data-centric experiences is still a challenge for front-end engineers.</p>
<p><strong>Real-time</strong></p>
<p>This falls into two categories: pushing data as they happen to the application and executing complex business workflows as events happen. Building these flows and connecting all these systems require multiple moving parts today.</p>
<p><strong>Collaborative and offline mode</strong></p>
<p>Applications like Figma and Notion have a collaborative experience built into the product. In addition, you can work offline and sync your data later if you don’t have an internet connection. Techniques like CRDTs needed to solve this are not easy to use.</p>
<p><strong>Monetizable</strong></p>
<p>There is a big shift towards usage-based billing from just charging for the number of seats, especially in these market conditions. The complexity of collecting usage and billing on it is not easy.</p>
<h2 id="designing-a-database-from-first-principles-for-modern-saas">Designing a database from first principles for modern SaaS</h2>
<p>We had a few key criteria that we wanted to take into consideration when we designed the database. We had to pick a good relational database that was highly performant, and extensible with growing popularity. We wanted to consider supporting multiple tenants and how the experience can still be like a single database. The ability to place tenants anywhere on the planet while not losing any of the benefits of a single database in one location was critical. On top of the tenant model, we wanted to design a foundational user model to help support all the user management capabilities. We also had to think about how we will enable vector embedding per tenant and how to support scaling them. Finally, the ability to scale instantaneously and reduce the cost of storage was key factors.</p>
<h3 id="postgres">Postgres</h3>
<p>We needed to pick a database we would build our tooling around, and the obvious choice was Postgres. Postgres is a world-class database that is winning in the OLTP space. This trend will continue, and making Postgres easy for building SaaS is the best way for us to have the maximum impact. In my opinion, one of the biggest reasons for Postgres's success is its wide suite of features and extension flexibility. This is a great foundation to build the right tooling around it, making it world-class for SaaS. A solution with Postgres should provide a fully integrated experience while preserving the complete flexibility and extensibility of Postgres. It should also work well with Postgres’s vast tooling ecosystem.
<img src="https://www.thenile.dev/blog/database_growth.png" alt="“Postgres Growth”"></p>
<h3 id="built-in-tenant-virtualization">Built-in tenant virtualization</h3>
<p>The most foundational element in SaaS is a tenant. It makes a lot of sense to build this core concept into the database. Imagine having a lot of virtual tenant databases that can be co-located on one physical Postgres (multi-tenant) for better cost, and some of them can be placed on a dedicated database for better isolation. The virtual tenant DBs can be located anywhere on the planet for low latency or compliance. The client can route to the right tenant seamlessly without routing logic in the application.</p>
<p>Isolating tenants into their own virtual DBs is great, but you will also want to be able to share data across tenants where it makes sense. Backups should be available for each tenant, and it should be possible to restore them instantaneously. Schema changes should be applied seamlessly across all the tenant DBs, and it should also be possible to do staged rollouts for different tenant tiers. While supporting all this, all the standard SQL capabilities should work across the tenants for admin operations. All the standard Postgres tooling should work. You want the experience of a single Postgres! This sounds like magic, and we can make this magic a reality.</p>
<p>The experience would be something as follows:</p>
<p><strong>Creating a new virtual tenant DB is as simple as a standard insert into the tenant's table</strong>. By default, the tenant will get created on a multi-tenant Postgres in the default region. You should be able to specify any location in the world or the infrastructure type if you want a dedicated Postgres for a tenant (more on this in the next section).</p>
<pre><code><span>-- create a record for the first customer</span>
<span>insert</span> <span>into</span> tenants (name) <span>VALUES</span> (<span>'customer1'</span>);
</code></pre>
<p><strong>Creating a new table for each tenant should be like standard table creation</strong>, and the database should ensure all the virtual tenant DBs get the schema changes applied to them. Let us call them tenant-aware tables.</p>
<pre><code><span>-- creating an employee table that is tenant aware</span>
<span>create</span> <span>table</span> employees (
  tenant_id uuid,
  id <span>integer</span>,
  name text,
  age <span>integer</span>,
  address text,
  start_date <span>timestamp</span>,
  title text,
  <span>CONSTRAINT</span> FK_tenants <span>FOREIGN</span> KEY(tenant_id) <span>REFERENCES</span> tenants(id),
  <span>CONSTRAINT</span> PK_employee <span>PRIMARY</span> KEY(tenant_id,id));
</code></pre>
<p>With the table in place, you can add rows for a specific tenant. Let us say tenant “customer 1” has a few employees that must be added to the system.</p>
<pre><code><span>-- adding employees for customer 1</span>
<span>insert</span> <span>into</span> employees (tenant_id, id, name, age, address, start_date, title)
<span>values</span>
  (<span>'018ac98e-b37a-731b-b03a-6617e8fd5266'</span>,<span>1345</span>,<span>'Jason'</span>,<span>30</span>,<span>'Sunnyvale,California'</span>,<span>'2016-12-22 19:10:25-07'</span>,<span>'software engineer'</span>),
  (<span>'018ac98e-b37a-731b-b03a-6617e8fd5266'</span>,<span>2423</span>,<span>'Minnie'</span>,<span>24</span>,<span>'Seattle,Washingtom'</span>,<span>'2018-11-11 12:09:22-06'</span>,<span>'sales engineer'</span>),
  (<span>'018ac98e-b37a-731b-b03a-6617e8fd5266'</span>,<span>4532</span>,<span>'Shiva'</span>,<span>32</span>,<span>'Fremont, California'</span>,<span>'2019-09-05 04:03:12-05'</span>,<span>'product manager'</span>);
</code></pre>
<p>Now, let us assume a second tenant, “customer 2” needs to be added to the system, and a few employees are added to this new tenant. This would again create another virtual tenant DB. The inserts will route to the right virtual tenant DB, but the experience will be like simply inserting into the employee's table.</p>
<pre><code><span>-- create the second customer</span>
<span>insert</span> <span>into</span> tenants (name) <span>VALUES</span> (<span>'customer2'</span>);

<span>-- insert employees for the second customer</span>
<span>insert</span> <span>into</span> employees (tenant_id, id, name, age, address, start_date, title)
<span>values</span>
  (<span>'018aca35-b8c4-7674-882c-30ae56d7b479'</span>,<span>5643</span>,<span>'John'</span>,<span>36</span>,<span>'London,UK'</span>,<span>'2017-12-12 19:10:25-07'</span>,<span>'senior software engineer'</span>),
  (<span>'018aca35-b8c4-7674-882c-30ae56d7b479'</span>,<span>1532</span>,<span>'Mark'</span>,<span>27</span>,<span>'Manchester,UK'</span>,<span>'2022-10-10 12:09:22-06'</span>,<span>'support engineer'</span>),
  (<span>'018aca35-b8c4-7674-882c-30ae56d7b479'</span>,<span>8645</span>,<span>'Sam'</span>,<span>42</span>,<span>'Liverpool,UK'</span>,<span>'2015-08-04 04:03:12-05'</span>,<span>'product manager'</span>);
</code></pre>
<p><strong>Directing queries to a specific tenant DB and getting full data isolation should be as easy as specifying the tenant ID in the session context</strong> . The client library can even abstract this by invoking this for you, depending on what tenant_id is trying to access data. This should all work out of the box without struggling with complex permissions, managing multiple databases, or dealing with error-prone row-level security policies.</p>
<pre><code><span>-- set the session context to a specific tenant</span>
<span>-- who needs to be isolated.</span>
<span>set</span> nile.tenant_id <span>=</span> <span>'018ac98e-b37a-731b-b03a-6617e8fd5266'</span>;

<span>select</span> <span>*</span> <span>from</span> employees
</code></pre>

<p><strong>The best part is you should still be able to query across the tenant DBs like a
standard table if you don’t specify any context.</strong></p>
<pre><code><span>select</span> <span>*</span> <span>from</span> employees
</code></pre>

<p>While there’s a need for virtual tenant DBs that isolate data, there’s also a need
to <a href="https://www.thenile.dev/docs/tenant-sharing">share data across tenants</a>. It should
be easy to create shared tables that can be accessed by/[across] all tenants and
are globally available. All standard queries should work seamlessly both on tenant-aware
and shared tables</p>
<pre><code>
<span>-- list of flights that a corporate travel booking site can use to share across all the tenants.</span>
<span>-- employees in different tenants can view these flight data to book tickets</span>
<span>create</span> <span>table</span> flights (
  id <span>integer</span> <span>PRIMARY</span> KEY,
  name text,
  from_location text,
  to_location text,
  departure_time <span>TIMESTAMP</span>,
  arrival_time <span>TIMESTAMP</span>
);

</code></pre>
<h3 id="global-and-flexible-tenant-placement">Global and flexible tenant placement</h3>
<p>When building a modern SaaS application, the critical factors that need to be considered are latency, performance isolation, compliance, and cost. The capability of a database to place tenants has a significant impact on achieving this balance.</p>
<p>Placement can be of two types:</p>
<p><strong>Regional placement</strong></p>
<p>You want to place individual tenants (customers) in different regions worldwide for compliance or latency reasons. You should be able to create the tenant database in any available location without worrying about the number of databases or the operational complexity.</p>
<pre><code><span>insert</span> <span>into</span> tenants (name, region)
<span>values</span> (<span>'customer 1'</span>, <span>'aws-us-east1'</span>);

<span>insert</span> <span>into</span> tenants (name, region)
<span>values</span> (<span>'customer 2'</span>, <span>'aws-eu-west1'</span>);
</code></pre>
<p><strong>Infrastructure placement</strong></p>
<p>You will want to place tenants in a multi-tenant or dedicated physical database. The decision for this will depend on the customer's needs, cost, and level of isolation needed. Typically, you would start to place all your customers in a multi-tenant database and then have the need to place some tenants on dedicated physical databases.</p>
<pre><code><span>insert</span> <span>into</span> tenants (name, region, deployment_mode)
<span>values</span> (<span>'customer 2'</span>, <span>'aws-us-east1'</span>, <span>'dedicated'</span>);
</code></pre>
<p>The client should be able to route to the right tenant without any work from the user. Also, while providing all the placement flexibility, the magic lies in providing the ability to manage all these tenants in different locations and placements like a single Postgres instance. Here are a couple of examples where this will be useful:</p>
<p>Make schema changes once, and the database should apply the change across all the virtual tenant DBs</p>
<pre><code><span>-- the bookings table where each row represents a single booking</span>
<span>-- for a specific employee within a customer/tenant</span>
<span>create</span> <span>table</span> bookings (
  tenant_id uuid,
  booking_id <span>integer</span>,
  employee_id text,
  flight_id <span>integer</span>,
  total_price <span>float</span>,
  <span>PRIMARY</span> KEY(tenant_id,booking_id));
</code></pre>
<p>Query across tenants for insights like a single database</p>
<pre><code><span>-- Calculates the total no of candidates per tenant that have</span>
<span>-- applied for a job for a recruiting product. Can be used to define</span>
<span>-- active tenants</span>
<span>select</span> t1.id <span>as</span> customer_id,t1.name <span>as</span> customer_name,
<span>count</span>(c1.id) <span>as</span> no_of_candidates <span>from</span> candidates c1
<span>right</span> <span>join</span> tenants t1 <span>on</span> c1.tenant_id<span>=</span>t1.id <span>group</span> <span>by</span> t1.id,t1.name;
</code></pre>
<h3 id="first-class-support-for-users">First-class support for users</h3>
<p>The first basic primitive of a database built for SaaS is tenants. The second is users. Managing users in the context of tenants is complex, and having built-in support will make application development significantly faster. In addition, it will help to store user data in the database with strong consistency and correctness. Authentication should provide a suite of tools that makes it easy to drop in a form to get end-to-end authentication supported for tenants and users in minutes. This should support the entire lifecycle of tenant or organization management, including inviting users to an organization, deleting an organization that soft deletes the tenants in the underlying database, and providing overrides for each tenant to configure custom authentications.
<img src="https://www.thenile.dev/blog/authcode.png" alt="“Auth Code&quot;"></p>
<p>For permissions, basic enforcement of what data users get access to should be easier than it is today. When a user belongs to a specific tenant, access should automatically be restricted to other tenants. You don’t need application logic or complex SQL policies to enforce and maintain this. In addition, permissions should have a flexible language to help define fine-grained column-level resource permissions. The best part is that no instrumentations are required in code, which is often buggy due to the different paths that need to be secured. Instead, permission at source is the strongest security guarantee you can get.</p>
<p>While the database should provide a fantastic solution out of the box, it should also be flexible for users to bring their own auth. This includes building your own authentication or integrating another third-party auth with the database. Great developer platforms can provide flexibility and let developers have finer control over how they want to build out their applications.</p>
<h3 id="domain-and-tenant-aware-ai-native-architecture">Domain and tenant-aware AI-native architecture</h3>
<p>Every SaaS application will be an AI-native application like every software application was a SaaS-native application when SaaS happened. SaaS revolutionized how software was delivered. AI will revolutionize how software is experienced.</p>
<p>AI for SaaS needs to be specific to the domain and tenant. For example,</p>
<ol>
<li>A corporate wiki (e.g., Confluence, Notion) where the employees can perform a semantic search on their company data</li>
<li>A chatbot for a CRM (e.g., Salesforce, Hubspot) that sales reps can use to ask questions about past and future customer deals and can have a back-and-forth conversation</li>
<li>An autopilot for developers in their code repository (Github, Gitlab) to improve productivity. The autopilot should run on the company's code as well, apart from learning from public repositories.</li>
</ol>
<p>A powerful architecture to achieve this is Retrieval augmented generation(RAG). The idea is to prevent large language models from hallucinating by augmenting the prompt with relevant context. This is usually done by converting the tenant's data set and the query to a common format called embeddings. The prompt issued by the user belonging to a specific tenant will be augmented with more context from that tenant's embeddings. This helps LLMs to be more contextual and also more secure.</p>
<p>A database for SaaS should have native support for storing vector embeddings per tenant. It should also help store the metadata relevant to each tenant and the embeddings. Given Postgres is our choice, the pgvector extension combined with tenant virtualization would be powerful.</p>
<pre><code><span>create</span> <span>table</span> wiki_documents(tenant_id uuid, id <span>integer</span>, embedding vector(<span>3</span>));

<span>insert</span> <span>into</span> wiki_documents(tenant_id, id, embedding)
<span>values</span> (<span>'018ade1a-7843-7e60-9686-714bab650998'</span>, <span>1</span>, <span>'[1,2,3]'</span>);

<span>select</span> embedding <span>&lt;</span><span>-</span><span>&gt;</span> <span>'[3,1,2]'</span> <span>as</span> distance <span>from</span> wiki_documents;
</code></pre>
<p>You get the following benefits with such a system:</p>
<ol>
<li>Embeddings and metadata computed and stored per tenant</li>
<li>Embeddings and metadata are stored near the customer to speed up the first-byte response to a query</li>
<li>HNSW and IVFLAT index support from pg_vector</li>
<li>Unlimited scaling of embeddings since tenants can be distributed and sharded. HNSW is a pretty resource-intensive</li>
<li>Purpose-built SDKs that integrate with LLM hosts such as OpenAI and Huggingface and vector embeddings.</li>
</ol>
<h3 id="serverless-and-cloud-native">Serverless and cloud-native</h3>
<p>Serverless is how developers will adopt databases in the next decade. Before anyone jumps to say, “There is no such thing as serverless. There are only other people's servers”, the intent of using serverless is to define the experience developers get. It does not mean that the database is implemented without any servers! A database for SaaS should allow developers to focus on their queries, use cases, and core application logic. Developers don’t have to worry about managing capacity, the server configurations, or paying for capacity they don’t use. This gets even more complex if you want to manage multiple databases for each tenant. A database should let you have any number of virtual tenant databases but give you all the goodness of serverless. It should enforce price limits and ensure developers don’t get a sticker shock. The goal of serverless is to care about developers, which is exactly what it should do.</p>
<p>The second thing is that the database needs to be built for the cloud. This means leveraging the native cloud infrastructure to build a highly scalable and elastic system. It makes sense to decouple storage and compute and push storage to cloud storage like S3. This helps to keep the compute stateless and makes it easier to scale them quickly. You still want to shard the tenants across databases and regions to provide placement flexibility (regional and infrastructure placement) and scale the storage as needed.</p>
<h3 id="tenant-level-insights-and-administration">Tenant-level insights and administration</h3>
<p>A huge part of building and running a SaaS application is to understand the growth and performance of each tenant and optimize it. This has been traditionally hard for SaaS. Most want a simple way to look up their active customers, users, and product usage to understand better how the different queries are performing for each customer.</p>
<p>The database should have native support for this. Given it understands tenant boundaries, users within those tenants, and all the queries executed in that context, it would be trivial to show relevant insights to the developers. Developers should be able to understand the growth of the product, how the query performs for each tenant, and past trends. All the performance metrics, usage metrics, and even logs can be understood for each tenant. Postgres tools such as pg_stats, EXPLAIN, and ANALYZE should work and provide insights by tenant.
<img src="https://www.thenile.dev/blog/nile_dashboard.png" alt="“Nile Dashboard”"></p>
<h3 id="world-class-developer-experience">World-class developer experience</h3>
<p>Databases still need to be made easier to use. While Postgres does a great job, there is still a lot of friction in the end-to-end developer journey to build SaaS applications with a cloud-native database. Developers should be able to test locally with the DB for a rapid feedback loop on their laptop, create test databases to apply schema changes, and then migrate to production. This whole experience should be integrated well with a change management system like GitHub. Lastly, ensuring a thriving developer community around the database is key to helping each other and learning quickly.</p>
<h3 id="and-some-more">And some more</h3>
<p>There are many more things I chose not to talk about now. Things like propagating real-time changes per tenant to the front end, supporting analytics to build data-centric applications, and leveraging usage data per tenant for monetization are all critical topics in building SaaS. The tenant virtualization is the basic building block. Many SaaS tooling and integrations can be built on this foundation to make it easy to build and scale the product. We would love to hear your feedback and thoughts about this on our <a href="https://github.com/niledatabase/niledatabase/discussions">GitHub discussion forum</a> or <a href="https://discord.gg/8UuBB84tTy">Discord community</a>.</p>
<h2 id="nile---a-company-to-accelerate-modern-saas">Nile - a company to accelerate modern SaaS</h2>
<p>Nile is a company that was started to make the database that I explained a reality. The mission of Nile is to enable developers to accelerate the next billion modern SaaS applications. What we will build at Nile will help accomplish this and truly change the future of SaaS. Nile will deliver on this promise. If you are building SaaS, we would love to talk to you. If you are an amazing engineer, we would love to have you join us in this mission.</p>
<p>You can try out Nile by <a href="https://www.thenile.dev/">signing up for our waitlist</a> today. We are onboarding new users every day. You can get started with one of our quickstarts. We also have <a href="https://www.thenile.dev/templates">templates and demos</a> that will make it easy to get started. We would love to have you try out Nile, give us feedback, and help us build something truly world-class. If you need help, you can reach us on our <a href="https://github.com/niledatabase/niledatabase/discussions">GitHub discussion forum</a> or our <a href="https://discord.gg/8UuBB84tTy">Discord community</a>. Follow us on <a href="https://twitter.com/niledatabase">Twitter</a> or <a href="https://www.linkedin.com/company/niledatabase/">Linkedin</a> to get regular updates.</p>
<p>We are building something truly wonderful and are excited about this journey!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare API, dashboard, tunnels down (134 pts)]]></title>
            <link>https://www.cloudflarestatus.com/incidents/s1hkh315y9s9</link>
            <guid>38014582</guid>
            <pubDate>Wed, 25 Oct 2023 16:31:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cloudflarestatus.com/incidents/s1hkh315y9s9">https://www.cloudflarestatus.com/incidents/s1hkh315y9s9</a>, See on <a href="https://news.ycombinator.com/item?id=38014582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <div>
      <p>Cloudflare Dashboard and Cloudflare API service issues</p>
      
    </div>

    <div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <p>
            Monitoring
          </p>
          <div>
            <p><span>A fix has been implemented and we are monitoring the results.<p>Customers using IPsec tunnels who are still impacted should try bouncing their IKE sessions to force rekeying.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698256294000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">17:51</var> UTC
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p><span>We have fixed the issue impacting Alerts, Dashboard functionality, Zero Trust, WARP Waiting Room, Gateway, Stream, API Shield,  Workers. We are monitoring the results for these products.<p>However, we are still working on a fix for resolving the issue on Cloudflare Pages, Cloudflare Tunnels, and Magic WAN</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698255326000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">17:35</var> UTC
            </p>
          </div>
        </div>
        <div>
          <p>
            Identified
          </p>
          <div>
            <p><span>The issue has been identified and a fix is being implemented.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698252494000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">16:48</var> UTC
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p><span>We are continuing to investigate this issue.<p>This issue is impacting all services that rely on our API infrastructure including Alerts, Dashboard functionality, Zero Trust, WARP, Cloudflared, Waiting Room, Gateway, Stream, Magic WAN, API Shield, Pages, Workers.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698249346000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">15:55</var> UTC
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p><span>We are continuing to investigate this issue.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698249005000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">15:50</var> UTC
            </p>
          </div>
        </div>
        <div>
          <p>
            Update
          </p>
          <div>
            <p><span>We are continuing to investigate this issue.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698247958000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">15:32</var> UTC
            </p>
          </div>
        </div>
        <div>
          <p>
            Investigating
          </p>
          <div>
            <p><span>Cloudflare is investigating issues with Cloudflare Dashboard and related APIs.<p>This issue is impacting all services that rely on our API infrastructure including Alerts, Dashboard functionality, Zero Trust, WARP, Cloudflared, Waiting Room, Gateway, Stream, Magic WAN, API Shield, Pages, Workers. <br>Customers using the Dashboard / Cloudflare APIs are impacted as requests might fail and/or errors may be displayed.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1698247051000"></span>Oct <var data-var="date">25</var>, <var data-var="year">2023</var> - <var data-var="time">15:17</var> UTC
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affects: Cloudflare Sites and Services (API, Dashboard, Magic Transit, Magic WAN, Notifications, Pages, Tunnel, Workers, Zero Trust).
        </p>
    </div>

    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft now thirstily injects a poll when you download Google Chrome (142 pts)]]></title>
            <link>https://www.theverge.com/23930960/microsoft-edge-google-chrome-poll-why-try-another-browser</link>
            <guid>38014168</guid>
            <pubDate>Wed, 25 Oct 2023 16:00:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/23930960/microsoft-edge-google-chrome-poll-why-try-another-browser">https://www.theverge.com/23930960/microsoft-edge-google-chrome-poll-why-try-another-browser</a>, See on <a href="https://news.ycombinator.com/item?id=38014168">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="content"><div><div><div><h2>Microsoft now thirstily injects a poll when you download Google Chrome</h2><p><span><span> / </span><h2>“Can you please take a minute to tell us why you are trying another browser?”</h2></span></p></div><div><p><span>By</span> <span><span></span> <span><a href="https://www.theverge.com/authors/sean-hollister">Sean Hollister</a></span><span>, <span>a senior editor and founding member of The Verge who covers gadgets, games, and toys. He spent 15 years editing the likes of CNET, Gizmodo, and Engadget.</span></span></span></p><p><time datetime="2023-10-25T00:12:18.788Z"> <!-- -->Oct 25, 2023, 12:12 AM UTC</time><span>|</span></p><div><h2>Share this story</h2></div></div></div><div><figure><span><span></span><img alt="Microsoft Edge now pops up a poll after you press the “Download Chrome” button." sizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/16x11/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 16w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/32x21/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 32w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/48x32/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 48w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/64x43/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 64w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/96x64/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 96w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/128x85/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 128w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/256x171/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/376x251/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/384x256/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/415x277/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/480x320/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/540x360/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/640x427/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/750x500/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/828x552/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/1080x720/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/1200x800/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/1440x960/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/1920x1280/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/2048x1365/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/2400x1600/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1174x788/2400x1600/filters:focal(587x394:588x395):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029208/NVIDIA_Share_wDQfiR22KU.jpg" decoding="async" data-nimg="responsive"></span><div><figcaption><em>Microsoft Edge now pops up a poll after you press the “Download Chrome” button.</em></figcaption> <p><cite>Screenshot by Sean Hollister / The Verge</cite></p></div></figure></div></div><div><div><p><a href="https://youtu.be/O6rHeD5x2tI?si=IxGULBEJ0VqCGcFo&amp;t=35">How many licks</a> does it take to get to the center of a Google Chrome download in Microsoft’s Edge web browser? How many times will the company try to steer me away?</p><p>Let’s check! </p><p><h3>One:</h3></p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="“There’s no need to download a new web browser,” reads the top of a search for “Chrome download” in Microsoft Edge." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/376x188/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/384x192/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/415x207/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/480x239/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/540x269/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/640x319/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/750x374/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/828x413/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/1080x539/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/1200x599/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/1440x718/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/1920x958/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/2048x1022/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/2400x1197/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:880x439/2400x1197/filters:focal(440x220:441x221):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029225/msedge_yoCVyeYDEW.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>“There’s no need to download a new web browser,” reads the top of a search for “Chrome download” in Microsoft Edge.</em></figcaption> <p><cite>Screenshot by Sean Hollister / The Verge</cite></p></div></div><p><h3>Two:</h3></p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="“Microsoft edge runs on the same technology as Chrome, with the added trust of Microsoft,” reads a pop-up that appears after you land on Google’s site." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/376x221/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/384x225/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/415x244/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/480x282/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/540x317/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/640x376/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/750x440/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/828x486/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/1080x634/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/1200x704/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/1440x845/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/1920x1127/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/2048x1202/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/2400x1409/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:603x354/2400x1409/filters:focal(302x177:303x178):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029229/msedge_6Xy4AsRXYT.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>“Microsoft edge runs on the same technology as Chrome, with the added trust of Microsoft,” reads a pop-up that appears after you land on Google’s site.</em></figcaption> <p><cite>Screenshot by Sean Hollister / The Verge</cite></p></div></div><p><h3>Three:</h3></p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="“We love having you! Can you please take a minute to tell us why you are trying another browser?” reads a new pop-up poll. " loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/376x565/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/384x577/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/415x624/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/480x722/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/540x812/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/640x962/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/750x1128/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/828x1245/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/1080x1624/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/1200x1805/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/1440x2166/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/1920x2887/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/2048x3080/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/2400x3609/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:385x579/2400x3609/filters:focal(193x290:194x291):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029231/msedge_gzOf0nzwpc.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>“We love having you! Can you please take a minute to tell us why you are trying another browser?” reads a new pop-up poll. </em></figcaption> <p><cite>Screenshot by Sean Hollister / The Verge</cite></p></div></div><p><h3>Four:</h3></p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="“Microsoft Edge runs on the same technology as Chrome, with the added trust of Microsoft,” reads an injected ad that appeared after my download." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/376x210/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/384x215/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/415x232/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/480x268/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/540x302/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/640x358/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/750x420/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/828x463/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/1080x604/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/1200x671/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/1440x805/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/1920x1074/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/2048x1146/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/2400x1342/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1112x622/2400x1342/filters:focal(556x311:557x312):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029232/msedge_He5soYyzls.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>“Microsoft Edge runs on the same technology as Chrome, with the added trust of Microsoft,” reads an injected ad that appeared after my download.</em></figcaption> <p><cite>Screenshot by Sean Hollister / The Verge</cite></p></div></div><p><h3>Four. </h3></p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="To be fair, it did appear after the download was finished." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/376x80/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/384x82/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/415x89/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/480x102/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/540x115/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/640x137/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/750x160/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/828x177/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/1080x231/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/1200x256/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/1440x307/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/1920x410/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/2048x437/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/2400x512/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:670x143/2400x512/filters:focal(335x72:336x73):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25029236/msedge_He5soYyzls_2.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>To be fair, it did appear after the download was finished.</em></figcaption> <p><cite>Screenshot by Sean Hollister / The Verge</cite></p></div></div><div><p>The pop-ups are <a href="https://www.theverge.com/2021/12/2/22813733/microsoft-windows-edge-download-chrome-prompts">nearly two years old</a>, and the injected ads are from <a href="https://www.neowin.net/news/microsoft-is-now-injecting-full-size-ads-on-chrome-website-to-make-you-stay-on-edge/">earlier this year</a>. The poll seems to be new, though — <a href="https://www.neowin.net/news/microsoft-now-wants-you-to-take-a-poll-before-installing-google-chrome/"><em>Neowin</em> reports</a> it first saw the poll last weekend.</p></div><p>But hey, <em><strong>it could be worse:</strong></em></p><div><p>I cannot believe how many stories we’ve written about the shit Microsoft has pulled to steer you away from Chrome. Even today, the company <em>still</em> won’t always respect <a href="https://www.theverge.com/22714629/windows-11-microsoft-browser-edge-chrome-firefox">your choice of default browser</a>, though that <a href="https://www.theverge.com/2023/9/5/23859537/microsoft-windows-11-default-browser-links-eu-eea-changes">may finally be changing in the EU</a>.</p></div><p>Sadly the poll doesn’t include an “I’m boycotting Edge because you don’t respect me as a user” option. </p></div><div><p>Most Popular</p><ol><li><a href="https://www.theverge.com/2023/10/24/23930478/microsoft-ceo-satya-nadella-mobile-windows-phone"><h2>Microsoft CEO Satya Nadella admits giving up on Windows Phone and mobile was a mistake</h2></a><hr></li><li><a href="https://www.theverge.com/2023/10/24/23930407/apple-scary-fast-halloween-imac-event-macbook-pro-rumors"><h2>Apple plans ‘Scary Fast’ product event just before Halloween</h2></a><hr></li><li><a href="https://www.theverge.com/23930058/forecast-clean-renewable-unstoppable-international-energy-agency"><h2>Clean&nbsp;energy&nbsp;is officially ‘unstoppable’ now</h2></a><hr></li><li><a href="https://www.theverge.com/2023/10/24/23929990/amazon-prime-video-crunchyroll-channel-now-available"><h2>Amazon will now let you access Crunchyroll’s anime library right from Prime Video</h2></a><hr></li><li><a href="https://www.theverge.com/2023/10/24/23930669/humane-ai-pin-trust-light-camera"><h2>The Humane AI Pin apparently runs GPT-4 and flashes a ‘Trust Light’ when it’s recording</h2></a><hr></li></ol></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wait, what's a bookmarklet? (200 pts)]]></title>
            <link>https://thehistoryoftheweb.com/postscript/wait-whats-a-bookmarklet/</link>
            <guid>38014069</guid>
            <pubDate>Wed, 25 Oct 2023 15:50:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehistoryoftheweb.com/postscript/wait-whats-a-bookmarklet/">https://thehistoryoftheweb.com/postscript/wait-whats-a-bookmarklet/</a>, See on <a href="https://news.ycombinator.com/item?id=38014069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


		


		<p>Written by <span>Jay Hoffmann</span> on <span>October 25, 2023</span>.<br>

					It takes place somewhere between <span>1995</span> and <span>2008</span>.

		</p></div><div>

	<article>

					<p>How this one small browser quirk turned into a tool used by countless people for decades.</p>
			<hr>
				
<p>In 1995, Brendan Eich demoed what would eventually become JavaScript to a room full of engineers at Netscape. It was met with instant enthusiasm. For his demo, Eich opened up his version of the browser and typed a command right into the address bar, which opened up a console and allowed him to demonstrate an alert box. Six months later, the first version of JavaScript shipped with Netscape Navigator 2.</p>



<p>JavaScript in the address bar, as a protocol for a URL, was possible virtually from day one of the language, effectively creating JavaScript URLs. And even in the first version, “visiting” a JavaScript URL triggered a change on the current page, rather than opening up an entirely new one.&nbsp;<a href="https://web.archive.org/web/20111127233722/http://www.sitepoint.com/bookmarklets/" target="_blank" rel="noreferrer noopener">Eich even added the&nbsp;<code>void</code>&nbsp;operator</a>&nbsp;to an early version of JavaScript to make it possible to create arbitrary functions with values right in that URL.</p>



<p>To introduce new developers to JavaScript, Netscape released a comprehensive guide on how to use it. And in that guide, they&nbsp;<a href="https://web.archive.org/web/20030609224912/http://devedge.netscape.com/library/manuals/2000/javascript/1.3/guide/advtopic.html#1004952" target="_blank" rel="noreferrer noopener">included a short snippet about these JavaScript URLs</a>:</p>



<blockquote>
<p>You are probably familiar with the standard types of URLs: http:, ftp:, file:, and so on. With Navigator, you can also use URLs of type javascript: to execute JavaScript statements instead of loading a document. You simply use a string beginning with javascript: as the value for the HREF attribute of anchor tags.</p>



<p><code>&lt;A HREF="javascript:history.go(0)"&gt;Reload Now&lt;/A&gt;</code></p>



<p>In general, you can put any statements or function calls after the&nbsp;<code>javascript:</code>&nbsp;URL prefix.</p>
</blockquote>



<p>So you ended up with this JavaScript quirk where it was possible to create unique URLs that ran a bit of JavaScript on whatever page you happened to be looking at. It could even make changes to that page. Move things around. Replace words. Open links. And pretty early on, people realized that these JavaScript URLs were also bookmarkable, just like any other URL.</p>



<p>And, crucially, easily shareable as links.</p>



<p>As rapid iteration spread through the early web, one corner of that world began experimenting with these bookmarkable, shareable JavaScript URLs to manipulate and transform web pages. Some early examples were used to quickly&nbsp;<a href="http://web.archive.org/web/20010503103754/http://www.squarefree.com/bookmarklets/pagelinks.html" target="_blank" rel="noreferrer noopener">open all the links on a page</a>, for instance, or&nbsp;<a href="http://tantek.com/favelets/" target="_blank" rel="noreferrer noopener">run the current page through a validator</a>. But there were also plenty of unique utilities as well, like interacting with online services,&nbsp;<a href="https://www.sitepoint.com/bookmarklets-2/" target="_blank" rel="noreferrer noopener">manipulating images on a page</a>, or even&nbsp;<a href="http://web.archive.org/web/20010505005613/http://www.squarefree.com/bookmarklets/tipping.html" target="_blank" rel="noreferrer noopener">tipping the website owner</a>.</p>



<p>Early versions of the browser also featured something which has faded away in recent years. The bookmarks bar (or sometimes, the favorites bar). Up at the top of the browser window, below the URL, was a list of bookmarks. The easiest way to share a JavaScript URL was to drag one into your bookmarks bar, and then use it as you were surfing around.</p>



<p><img decoding="async" fetchpriority="high" src="https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/10/what-is-a-bookmarklet-internet-explorer-300x194.jpg" alt="An example of a bookmarklet in action" width="300" height="194" srcset="https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/10/what-is-a-bookmarklet-internet-explorer-300x194.jpg 300w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/10/what-is-a-bookmarklet-internet-explorer.jpg 346w" sizes="(max-width: 300px) 100vw, 300px"></p>



<p>It is difficult to trace the exact moment that all of this began, but there did come a time when the concept—a shareable JavaScript URL that acted as some sort of personal utility—needed a name. In December of 1998, Steve Kangas did just that, when he launched Bookmarklets.com. And the bookmarklet (or Favlet,&nbsp;<a href="http://tantek.com/favelets/" target="_blank" rel="noreferrer noopener">as it was called by Tantek Çelik</a>) started spreading.</p>



<p>Even in the first few months, Kangas had a list of over a hundred bookmarklets to share, that he had compiled and created. Some could be used to search a page for specific links or text. Others could alter the appearance of a page, removing images, changing the color or making things more readable. Some were fun (<a href="https://web.archive.org/web/20150603003341/http://www.bookmarklets.com/tools/misc/index.phtml" target="_blank" rel="noreferrer noopener">a bookmarklet that could make a Valentine’s Day heart dance across the page</a>) and some were unadorned and simple (<a href="https://web.archive.org/web/20110128083629/http://www.bookmarklets.com/tools/data/index.phtml" target="_blank" rel="noreferrer noopener">turn text underlines on or off</a>).</p>



<figure><img decoding="async" width="800" height="364" src="https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.55.48-AM-800x364.png" alt="The category section of Bookmarklets.com" srcset="https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.55.48-AM-800x364.png 800w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.55.48-AM-300x137.png 300w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.55.48-AM-768x350.png 768w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.55.48-AM-1536x699.png 1536w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.55.48-AM-2048x932.png 2048w" sizes="(max-width: 800px) 100vw, 800px"></figure>



<p>Bookmarklets are interesting. They are generally limited by browsers to a certain number of characters, which means they require efficient code that make use of the quirks of the language. They can’t be too complex or verbose. They usually have to be minified, which is a process of taking human readable JavaScript code and removing as many complicated variable names and whitespace as is needed. A Bookmarklet generally wasn’t able to do ten things at once. Each one did one thing, and did it well. That directness and focus made it all the more easy to share them around and instantly understand their utility. And bookmarklets became very popular.</p>



<p>Browsers have also typically featured another way to change and manipulate a page. They’ve been called add-ons, plugins, and extensions, but they are an officially supported way of interacting with a browser and extending its functionality. For a long time, however, they were difficult to manage and install. You had to find what you were looking for, download it, and find the right place to put it on your computer. They were useful cases, but not necessarily a viable alternative to Bookmarklets, which were easily shareable and dead simple.</p>



<p>In 2007, Moziilla Firefox released its Add-ons Gallery, a much simpler way to discover and install official Firefox add-ons. It was a searchable and categorized index of add-ons that any developer could add to. Add-ons were officially supported, were reviewed for security, and could be installed with one click. In 2009, Chrome added an extension gallery with similar features.</p>



<figure><img decoding="async" width="800" height="522" src="https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.39.51-AM-800x522.png" alt="A first version of Firefox's Add-on Gallery" srcset="https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.39.51-AM-800x522.png 800w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.39.51-AM-300x196.png 300w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.39.51-AM-768x501.png 768w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.39.51-AM-1536x1002.png 1536w, https://ik.imagekit.io/aoi3fgebjgr/wp-content/uploads/2023/06/Screenshot-2023-06-29-at-6.39.51-AM-2048x1336.png 2048w" sizes="(max-width: 800px) 100vw, 800px"></figure>



<p>As those browsers rose in market share, extensions began to overtake bookmarklets in popularity. The Bookmarks bar faded to the background more. Bookmarklets are still in use, and still quite useful, but they are ….</p>
	



		
	</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX Starship Super Heavy Project at the Boca Chica Launch Site (128 pts)]]></title>
            <link>https://www.faa.gov/space/stakeholder_engagement/spacex_starship</link>
            <guid>38013955</guid>
            <pubDate>Wed, 25 Oct 2023 15:39:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.faa.gov/space/stakeholder_engagement/spacex_starship">https://www.faa.gov/space/stakeholder_engagement/spacex_starship</a>, See on <a href="https://news.ycombinator.com/item?id=38013955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <p>SpaceX proposes to conduct Starship/Super Heavy launch operations from the Boca Chica Launch Site in Cameron County, Texas. SpaceX must apply for and obtain an experimental permit(s) and/or a vehicle operator license from the <abbr>FAA</abbr> Office of Commercial Space Transportation to operate the Starship/Super Heavy launch vehicle. The <abbr>FAA</abbr>'s evaluation of a permit or license application includes a review of 1) public safety issues (such as overflight of populated areas and payload contents); 2) national security or foreign policy concerns; 3) insurance requirements for the launch operator; and 4) potential environmental impact. Read more about the <a href="https://www.faa.gov/space/stakeholder_engagement/spacex_starship/history">history of the Boca Chica launch site</a> and <a href="https://www.faa.gov/space/stakeholder_engagement/spacex_starship/operations">the location of the launch site</a>.</p>

<h2><abbr>FAA</abbr></h2>

<p>The Commercial Space Launch Act of 1984, as amended and codified at 51 <abbr>U.S.C.</abbr> §§ 50901-50923, authorizes the Secretary of Transportation to oversee, license, and regulate commercial launch and reentry activities, and the operation of launch and reentry sites within the United States or as carried out by <abbr>U.S.</abbr> citizens. Section 50905 directs the Secretary to exercise this responsibility consistent with public health and safety, safety of property, and the national security and foreign policy interests of the United States. In addition, Section 50903 requires the Secretary to encourage, facilitate, and promote commercial space launches and reentries by the private sector. As codified at 49 <abbr>CFR</abbr> § 1.83(b), the Secretary has delegated authority to carry out these functions to the <abbr>FAA</abbr> Administrator.</p>

<p>For more information, read more about the <a href="https://www.faa.gov/space/stakeholder_engagement/spacex_starship/license_review_process">License Review Process</a> and the <a href="https://www.faa.gov/space/stakeholder_engagement/spacex_starship/environmental_review">Environmental Review Process</a>.</p>

<h2>SpaceX</h2>

<p>Founded in 2002, SpaceX is a commercial space transportation company headquartered in Hawthorne, California. SpaceX designs, manufactures, and launches advanced rockets and spacecraft. SpaceX developed the Falcon 1 (no longer operational), Falcon 9, and Falcon Heavy vertical orbital launch vehicles, all of which were built with the goal of becoming reusable launch vehicles. SpaceX launches commercial and government payloads, including the Dragon spacecraft, which was recently used to send <abbr>NASA</abbr> astronauts to the International Space Station and bring them back to Earth. SpaceX is currently developing a new rocket, Starship/Super Heavy, with the goal of traveling to Mars. For additional information on SpaceX, please visit <a href="https://www.spacex.com/">spacex.com</a>.</p>

<h2>Project Updates</h2>

<h3>In Process: Written Re-Evaluation</h3>

<p>SpaceX must obtain a modified license from the FAA before it is authorized to conduct a second Starship/Super Heavy launch. The modification must address all safety, environmental, and other regulatory requirements. As part of that license application determination process, the FAA will review new environmental information, including changes related to the launch pad, as well as other proposed vehicle and flight modifications.&nbsp;</p>

<p>The FAA will complete a Written Reevaluation (WR) to the 2022 Programmatic Environmental Assessment (PEA) evaluating the new environmental information, including Endangered Species Act consultation with the U.S. Fish and Wildlife Service. If the FAA determines through the WR process that the contents of the PEA do not remain valid in light of the changes proposed for Flight 2, additional environmental review will be required. The FAA will post the completed WR on this site.<br>
&nbsp;</p>

<h3>April 2023 Written Re-Evaluation</h3>

<div><p>Since the 2022 Programmatic Environmental Assessment, SpaceX provided the FAA with additional information regarding Starship’s planned landing, Super Heavy’s planned soft water landing, and the Launch Pad Detonation Suppression System. The FAA has published a Written Re-Evaluation which evaluates, based on this new information, whether supplemental environmental analysis is needed to support the FAA Office of Commercial Space Transportation decision to issue a vehicle operator license to SpaceX for the operation of the Starship/Super Heavy launch vehicle at its existing Boca Chica Launch Site in Cameron County, Texas.&nbsp;</p><p>
In the Written Re-Evaluation, the FAA concluded that the issuance of a vehicle operator license for Starship/Super Heavy operations conforms to the prior environmental documentation, that the data contained in the 2022 Programmatic Environmental Assessment remains substantially valid, that there are no significant environmental changes, and all pertinent conditions and requirements of the prior approval have been met or will be met in the current action. Therefore, the preparation of a supplemental or new environmental document is not necessary to support the Proposed Action.</p><p>
An electronic version of the document was uploaded on Friday, April 14, 2023 and is available at the following link:</p><p>
•&nbsp; &nbsp;&nbsp;<a href="https://www.faa.gov/media/27271" hreflang="en">Written Re-Evaluation for SpaceX Starship Super Heavy Reentry</a></p><p>
For media inquiries, please contact the FAA press office at <a href="mailto:pressoffice@faa.gov">pressoffice@faa.gov</a>.</p></div>

<h3>Programmatic Environmental Assessment</h3>

<p>The FAA published the Final Programmatic Environmental Assessment (Final PEA) and Mitigated Finding of No Significant Impact/Record of Decision (Mitigated FONSI/ROD) for the SpaceX Starship/Super Heavy Launch Vehicle Program at the SpaceX Boca Chica Launch Site in Cameron County, Texas (PEA) on June 13, 2022. The documentation is available for download below.&nbsp;</p>

<p><strong>Spanish</strong></p>

<ul><li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/hallazgo-mitigado-de-impacto-no-significativoregistro-de">Hallazgo Mitigado de Impacto No Significativo/Registro de Decisión</a> – Spanish (PDF) 1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/resumen-ejecutivo">Resumen Ejecutivo</a> – Spanish&nbsp;(PDF) 1MB</li>
</ul><p><strong>English</strong></p>

<ul><li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/final-programmatic-environmental-assessment-pea-executive">Executive Summary of the Final PEA</a>&nbsp;– English&nbsp;(PDF) 2MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/spacex-starship-super-heavy-boca-chica-fonsi-rod">Mitigated FONSI/ROD</a>&nbsp;– English (PDF) 1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/assessment-spacex-starshipsuper-heavy-launch-vehicle-program">Final PEA for SpaceX Starship Super Heavy at Boca Chica</a> (PDF) 12MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-references">Appendix A. References</a> (PDF) &lt;1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-b-starship-rocket-noise-assessment-boca-chica-launch">Appendix B. Noise Assessment</a>&nbsp;(PDF) 8MB</li>
	<li><a href="https://www.faa.gov/spacexstarship/starshipsuperheavy/appendix-c-national-historic-preservation-act-section-106">Appendix C. National Historic Preservation Act Section 106 Consultation</a>&nbsp; (PDF) 3MB</li>
	<li><a href="https://www.faa.gov/spacexstarship/starshipsuperheavy/appendix-d-biological-resources">Appendix D. Endangered Species Act Section 7 Consultation</a>&nbsp;(PDF) 25MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-e-department-transportation-act-section-4f-spacex">Appendix E. Department of Transportation Act Section 4(f) Consultation</a>&nbsp;(PDF) 7MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-f-visual-assessment">Appendix F. Viewshed Supporting Images</a>&nbsp;(PDF) 3MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-g-exhaust-plume-calculations">Appendix G. Exhaust Plume Calculations</a>&nbsp;(PDF) &lt;1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-h-jurisdictional-wetland-determination">Appendix H. Jurisdictional Wetland Determination</a>&nbsp;(PDF) &lt;1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-i-responses-public-comments">Appendix I. Comment Response</a> (PDF) &lt;1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-j-tglo-correspondence-redacted">Appendix J. TGLO Correspondence</a>&nbsp;(PDF) &lt;1MB</li>
	<li><a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-k-moa-between-spacex-and-tpwd">Appendix K. MOA Between Texas Parks and Wildlife Department and SpaceX</a>&nbsp;(PDF) &lt;1MB</li>
</ul><h3>Mitigated Finding of No Significant Impact/Record of Decision</h3>

<p>The FAA determined that the Proposed Action would not result in significant environmental consequences and has issued a Mitigated Finding of No Significant Impact/Record of Decision (FONSI/ROD). The Mitigated FONSI/ROD is available above. Required mitigation measures are listed throughout Chapter 3 of the <a href="https://www.faa.gov/stakeholderengagement/spacexstarship/assessment-spacex-starshipsuper-heavy-launch-vehicle-program">final PEA</a>. Should any future license or permit be issued to SpaceX to perform any aspect of the Proposed Action, the FAA will ensure that SpaceX implements these mitigation measures as conditions for licensure.&nbsp;</p>

<h3>Biological Opinion</h3>

<p>As part of the Endangered Species Act Section 7 consultation process, the U.S. Fish and Wildlife Service (USFWS) issued a Biological Opinion (BO), which concludes the Proposed Action is not likely to jeopardize the continued existence of any federally listed species or adversely modify designated critical habitat. The BO is included in PEA Appendix D and available <a href="https://www.faa.gov/spacexstarship/starshipsuperheavy/appendix-d-biological-resources">here</a>&nbsp;(PDF).</p>

<h3>Programmatic Agreement&nbsp;</h3>

<p>As part of the National Historic Preservation Act Section 106 consultation process, the FAA, Texas State Historic Preservation Officer, National Park Service, Advisory Council on Historic Preservation, SpaceX, USFWS, and Texas Parks and Wildlife Department executed a Programmatic Agreement (PA). The PA outlines the measures to resolve adverse effects of the Proposed Action on historic properties. The PA is included in PEA Appendix C and available <a href="https://www.faa.gov/spacexstarship/starshipsuperheavy/appendix-c-national-historic-preservation-act-section-106">here</a> (PDF).</p>

<h3>Background</h3>

<p>The FAA published the draft PEA on September 17, 2021. The original comment period was from September 17, 2021 through October 18, 2021. In response to public requests, the FAA extended the comment period to November 1, 2021. The FAA held two virtual public hearings to solicit comments from the public concerning the scope and content of the draft PEA. The hearings were held October 18 and October 20, 2021. The comments can be found on this <a href="https://www.faa.gov/spacexstarship/starshipsuperheavy/comments-draft-programmatic-environmental-assessment-pea-spacex">page</a>. The PEA was revised based on public comments, and the final PEA includes responses to comments (see <a href="https://www.faa.gov/stakeholderengagement/spacexstarship/appendix-i-responses-public-comments">final PEA Appendix I</a>).</p>

<h2>Stay Informed</h2>

<p><a href="mailto:spacexbocachica@icf.com">Subscribe to our mailing list</a> to receive updates on this project.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sergey Brin's airship gets FAA clearance (143 pts)]]></title>
            <link>https://spectrum.ieee.org/lta-airship-faa-clearance</link>
            <guid>38013919</guid>
            <pubDate>Wed, 25 Oct 2023 15:36:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/lta-airship-faa-clearance">https://spectrum.ieee.org/lta-airship-faa-clearance</a>, See on <a href="https://news.ycombinator.com/item?id=38013919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elid="2666055530" data-post-url="https://spectrum.ieee.org/lta-airship-faa-clearance" data-authors="Mark Harris" data-headline="EXCLUSIVE: Google Founder’s Airship Gets FAA Clearance" data-page-title="EXCLUSIVE: Google Founder’s Airship Gets FAA Clearance - IEEE Spectrum"><p>Expect traffic on the 101 highway in Mountain View, California, to be even worse in the days or weeks ahead, as motorists slow down to watch <a href="https://spectrum.ieee.org/tag/google">Google</a> co-founder Sergey Brin’s 124-meter long airship <a href="https://www.ltaresearch.com/technology" rel="noopener noreferrer" target="_blank">Pathfinder 1</a> launch into the air for the first time.</p><p><em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em> has learned that <a href="https://www.ltaresearch.com/" target="_blank">LTA Research</a>, the company that Brin founded in 2015 to develop airships for humanitarian and cargo transport, received a special airworthiness certificate for the helium-filled airship in early September.</p><p>That piece of paper allows the largest aircraft since the ill-fated Hindenburg to begin flight tests at <a href="https://en.wikipedia.org/wiki/Moffett_Federal_Airfield" target="_blank">Moffett Field</a>, a joint civil-military airport in Silicon Valley, with immediate effect.</p><p>The certificate permits LTA to fly Pathfinder 1 within the boundaries of Moffett Field and neighboring Palo Alto airport’s airspaces, at a height of up to 460 meters (1500 feet). That will let it venture out over the south San Francisco Bay, without interfering with planes flying into or out of San Jose and San Francisco International commercial airports. </p><p>In a letter supporting its application for the certificate, LTA wrote: “Pathfinder 1’s experimental flight test program is to demonstrate and establish the flight envelope for the airship…. LTA’s test plan is tailored to include substantial indoor and outdoor ground testing, using a build-up approach to gradually increase the flight envelope.”</p><p>The huge airship will initially be attached to a mobile mast for outdoor ground testing, before conducting about 25 low-level flights, for a total of 50 hours’ flight time. </p><p>Although its rigid design hearkens back to the gargantuan airships of the early 20th century, Pathfinder 1 is almost completely different from any large airship that has flown before. Crucially, its <a href="https://www.ltaresearch.com/technology" target="_blank">reported</a> 96 welded titanium hubs and 288 carbon fiber reinforced polymer tubes are light enough that it can use non-flammable helium instead of explosive hydrogen as a lifting gas. </p><p><img alt="Interior view of the airship's foundation during construction." data-rm-shortcode-id="38da14c974a020e52bfaaa29d4a6e3f4" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/interior-view-of-the-airship-s-foundation-during-construction.jpg?id=50295607&amp;width=980" height="1693" id="e5a30" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/interior-view-of-the-airship-s-foundation-during-construction.jpg?id=50295607&amp;width=980" width="3300"><small data-gramm="false" data-lt-tmp-id="lt-504252" placeholder="Add Photo Caption..." spellcheck="false">LTA’s airship frames are made of lightweight titanium and carbon-fiber.  </small><small placeholder="Add Photo Credit...">LTA Research and Exploration</small></p><p>Twelve electric motors distributed on the sides and tail of the airship, and four fin rudders, allow for vertical takeoff and landing (VTOL) and <a href="https://spectrum.ieee.org/airship" target="_self">speeds of up to about 120 kilometers per hour</a>. A tough layer of <a href="https://www.dupont.com/brands/tedlar.html" target="_blank">laminated Tedlar material</a> contains 13 helium bags of ripstop nylon, which contain lidar systems to track the gas levels within. </p><p>Pathfinder 1 has a hybrid propulsion system, with two 150 kilowatt diesel generators working alongside 24 batteries to provide power for the electric motors, according to a <a href="https://aviationweek.com/aerospace/advanced-air-mobility/ltas-large-rigid-airship-gets-airborne" rel="noopener noreferrer" target="_blank">recent presentation</a> by LTA’s CEO, Alan Weston. He said that LTA has plans to use hydrogen in later versions of the airship, perhaps as fuel for future fuel cells or turbogenerators, and possibly even as a lifting gas. </p><p>LTA confirmed the airworthiness certificate had been granted but not provide any further details.</p><p>Although the Pathfinder 1 is designed for single pilot operation, it has dual controls and, according to LTA’s letter to the FAA, will have a second pilot on board “for initial flight testing until pilot workload can be assessed.” The gondola that LTA is using for the airship was designed by the famous Zeppelin company in Germany and can <a href="https://spectrum.ieee.org/sergey-brins-revolutionary-20-airship" target="_self">accommodate up to 14 people</a>, although no superfluous passengers will be allowed during testing. </p><p>After extensive flight testing in California, the Pathfinder 1 will transit to the former <a href="https://en.wikipedia.org/wiki/Goodyear_Airdock" target="_blank">Goodyear Airdock</a> airship hangar in Akron, Ohio, which the company has acquired as its future manufacturing location. There, an even larger 180-meter long airship, the Pathfinder 3, is already under development. </p><p>Ultimately, LTA intends its aircraft to be used for humanitarian missions, deploying cargo and personnel to areas that are inaccessible by road. Brin runs a separate non-profit, called <a href="https://gsd.ngo/en" rel="noopener noreferrer" target="_blank">Global Support and Development</a>, that has already carried out such missions by sea, in the Caribbean, Latin American and the South Pacific. It originally used Brin’s own superyacht to ferry medical personnel to the scene of hurricanes and other disasters, and recently launched a purpose built vessel capable of transporting dozens of medical staff and full-size shipping containers. The <a href="https://gsd.ngo/en/what-we-do/humanitarian-vessel" rel="noopener noreferrer" target="_blank">MV Dawn</a> also carries its own watercraft and vehicles, and is capable of producing and off-loading bulk supplies of fresh water, and could be a model for future humanitarian airships. </p><p>Pathfinder 1’s airworthiness certificate is valid for a full year although LTA told the FAA in its application letter that it expects the test program to be complete within 180 days. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Artifact Museum (176 pts)]]></title>
            <link>https://neal.fun/internet-artifacts/</link>
            <guid>38013477</guid>
            <pubDate>Wed, 25 Oct 2023 14:54:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neal.fun/internet-artifacts/">https://neal.fun/internet-artifacts/</a>, See on <a href="https://news.ycombinator.com/item?id=38013477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-3a470780=""><div data-date="1977" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1977</p> <p>Map of ARPANET</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
A map of ARPANET, the precursor to the internet, showing the 111
computer terminals connected to the network in 1977.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
ARPANET was created by the Department of Defense to allow
researchers to share information and resources. The network was
initially limited to universities and research institutions.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
By 1983, ARPANET had over 4,000 connected computers and a
growing number of e-mail users. The ARPANET completion report
concluded that "the full impact of the technical changes set in
motion by this project may not be understood for many years."
</p></div> <p>
A complete map of the ARPANET as it existed in 1977.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1977" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1977</p> <p>First SPAM Email</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The first spam email was sent by Gary Thuerk, a marketing
manager for the Digital Equipment Corporation. Thuerk sent the
email to 320 recipients on ARPANET, advertising a product
presentation of the new DECSYSTEM-20 mainframe computers.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The reaction to the email was overwhelmingly negative: one user
claimed it broke his computer system, and the US Defense
Communications Agency called his company to complain. Thuerk
claims he sold $13 to $14 million worth of mainframe computers
through the campaign.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The term "spam" would not be used until years later, after being
inspired by a Monty Python sketch.
</p></div> <p>
The first spam email was sent by Gary Thuerk to 397 recipients on
ARPANET to promote a new computer system.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1982" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1982</p> <p>First Smiley</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The first recorded use of a smiley on the internet came in 1982,
when computer scientist Scott Fahlman proposed the use of :-)
and :-( to distinguish between jokes and serious posts online.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The proposal came in response to a post on the Carnegie Mellon
University bulletin board, where a student joked that there was
a mercury spill in the physics department’s elevator. Other
students missed context for the joke and thought a spill
actually occurred.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The smileys were slowly adopted throughout Carnegie Mellon and
later to the broader internet.
</p></div> <p>
The first recorded use of a smiley on the internet was posted by
computer scientist Scott Fahlman to help distinguish between jokes
and serious posts online.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1983" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1983</p> <p>The Hacker's Dictionary</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780=""><i data-v-200d9b1b="" data-v-3a470780="">The Hacker's Dictionary</i>—also known as
<i data-v-200d9b1b="" data-v-3a470780="">The Jargon File</i>—was a collection of hacker terminology,
jokes, and folklore from the early internet. It became an
essential reference for hackers and computer scientists, and
helped shape early online culture.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
First created in 1975 by Raphael Finkel at Stanford's AI lab,
the dictionary quickly spread to MIT and eventually to the
broader internet community. It became a collaborative effort as
hackers and computer scientists crowdsourced new editions of the
dictionary to reflect the ever-changing culture.
</p></div> <p>
The Hacker's Dictionary was a collection of hacker terminology,
jokes, and folklore from the early internet.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1985" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1985</p> <p>Usenet Newsgroups</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Developed by Tom Truscott and Jim Ellis, Usenet was dubbed the
"poor man’s ARPANET" because it was more accessible to the
average person. The network allowed users to post messages and
articles in different topic-specific newsgroups.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Usenet had no central authority, instead news servers exchanged
articles with each other at set intervals. The platform quickly
evolved beyond its initial focus on technical topics, expanding
to host newsgroups ranging from music to philosophy.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
By 1985, around 375 articles were posted a day on Usenet to over
100 active newsgroups. The network helped shape early Internet
culture, popularizing terms like FAQ, flame wars, and spam.
</p></div> <p>
Usenet was a more accessible alternative to ARPANET, allowing
user's to share articles in topic-specific newsgroups.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1987" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1987</p> <p>First MP3</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The first ever MP3 was the a cappella version of "Tom's Diner"
by Suzanne Vega. Karlheinz Brandenburg, who worked on the MP3
format, used the song as a benchmark to see how the compression
algorithm would handle the human voice.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Instrumental music had been easier to compress, but Vega's voice
sounded distorted and unnatural in early versions of the format.
Brandenburg would end up making hundreds of tweaks to the MP3
compression algorithm to make Vega's voice clearer. He would
later even get to meet Suzanne Vega and hear the song performed
live.
</p></div> <p>
The first ever MP3 was of "Tom's Diner", the song was used to
benchmark and test the MP3 format.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1988" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1988</p> <p>Morris Worm</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
On November 2nd, 1988, a computer worm was released onto the
internet. Created by Robert Tappan Morris, a 23-year-old Cornell
University graduate student, it was designed as an experiment to
measure the internet's size, but a programming error caused it
to propagate wildly. Within 24 hours, close to 10% of the 88,000
computers on the internet were disabled.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
After learning that his experiment had gone awry, Morris asked a
friend to anonymously relay an apology and instructions for
removing the worm to internet users, but ironically those most
impacted didn’t get his message because of the damage the worm
did to the network. Morris became the first person convicted
under the Computer Fraud and Abuse Act.
</p></div> <p>
The Morris Worm was one of the first computer worms to spread on
the internet.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1988" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1988</p> <p>Dave Rhodes Chain Letter</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
One of the earliest chain letters to spread on the internet was
titled "Make Money Fast." It promised readers that they would
receive $50,000 in cash after sixty days if they followed the
given instructions.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The letter worked like a pyramid scheme, where each person had
to pay those before them. It quickly spread through email and
Usenet groups after being posted by an unknown creator in 1988.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Many variations of the letter also spread with titles like "Make
Beer Fast", making it an early internet meme.
</p></div> <p>
One of the earliest chain letters to spread on the internet,
created by an unknown author in 1988.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1988" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1988</p> <p>Internet Relay Chat</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created by Jarkko Oikarinen as a side-project while working at
the University of Oulu in Finland, IRC, or Internet Relay Chat,
is a text-based communication protocol that lets users chat in
real-time group conversations, known as channels.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The initial IRC server consisted mostly of Jarkko's friends, but
the protocol slowly spread when others started hosting their own
servers. Other schools, like Oregon State University also
started using the protocol. By mid-1989, around 40 servers
existed worldwide, and IRC was adopted by early internet
communities as a chat alternative to message boards.
</p></div> <p>
An early chat protocol that allowed users and online communities
chat in real-time.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1989" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1989</p> <p>Earliest LOL</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The acronym "LOL" made its first documented appearance on the
internet in a FidoNet newsletter. FidoNet was a network of BBSs
- or bulletin board systems. Messages were transferred over
phone calls during off-peak hours to minimize toll costs.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
This edition of the FidoNet newsletter attempts to catalog the
increasing number of emoticons and acronyms that were spreading
on the network at the time. It also contained conventions that
never really caught on - like ODM for "On De Move".
</p></div> <p>
The acronym "LOL" made its first recorded appearance on the
internet in a FidoNet newsletter.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1991" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1991</p> <p>AOL Dial Up</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
America Online debuted in 1991 and quickly became the largest
dial-up service provider. The start screen and iconic dial-up
sound became many people's first introduction to the Internet.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Dial-up internet worked by using the existing telephone
infrastructure. Modems connected in a way similar to phone
conversations, with the dial-up sound serving as a handshake
between machines. The dial-up sound was a choreographed dance of
beeps and boops that exchanged all the information needed to
connect to the network.
</p></div> <p>
America Online debuted in 1991 and quickly became the largest
dial-up service provider.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1991" desc="<p>The first ever website describes the world wide web in detail.</p>
        <p>The first website at CERN - and in the world - was dedicated to the World Wide Web project itself and was hosted on Berners-Lee's NeXT computer. In 2013, CERN launched a project to restore this first ever website: info.cern.ch.</p>" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1991</p> <p>First Website</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In March 1989, Tim Berners-Lee wrote the initial proposal for
the World Wide Web, envisioning it as a "universal linked
information system" to help researchers share information.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
In December 1990, he launched the world’s first website,
info.cern.ch. The site featured details about the WWW project,
including an explanation of hypertext and instructions for
setting up a web server.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Tim Berners-Lee created the first web browser, called
WorldWideWeb, to display the site. He hosted the first website
on a NeXT computer, attaching a handwritten note to the
computer: "This machine is a server. DO NOT POWER IT DOWN!!"
</p></div> <p>
Created by Tim Berners-Lee, the creator of the World Wide Web, the
first ever website describes the web in detail.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1992" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1992</p> <p>Early Web Photo</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
One of the very first photos uploaded to the World Wide Web was
of
<i data-v-200d9b1b="" data-v-3a470780="">Les Horribles Cernettes</i>, an all-female band founded by
employees at CERN. The band—whose name pays homage to the
world’s largest particle accelerator—sang parody pop songs with
lyrics like "You never spend your nights with me… you only love
your collider."
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The band was based out of the same lab where the Web was
invented, and Tim Berners-Lee was such a fan that he uploaded
this photo to the first website. The band later said the picture
"was one of those that changed the web, from a platform for
physics documentation to a media for our lives."
</p></div> <p>
One of the very first photos uploaded to the World Wide Web was of
<i data-v-200d9b1b="" data-v-3a470780="">Les Horribles Cernettes</i>, an all-female band founded by
employees at CERN.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1993" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1993</p> <p>First Webcam</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The first webcam was set up in the Trojan Room of the Computer
Laboratory at the University of Cambridge, its lens focused on a
coffee pot. Researchers created the feed so they could check the
coffee pot's status without leaving their desks.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Initially, a program called XCoffee had to be downloaded to
watch the stream, but in 1993, the black and white feed – which
only had a frame rate of 3 frames per minute – was made
available on the web. Millions of people ended up watching the
coffee maker online throughout the 1990s.
</p></div> <p>
The first ever webcam monitored a coffee pot at the University of
Cambridge, so researchers could see whether there was a fresh pot
of coffee brewing.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1993" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1993</p> <p>Severe Tire Damage</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
On June 24, 1993, Severe Tire Damage became the first band to
livestream a concert on the internet. The little-known rock band
performed on the patio at Xerox PARC in Palo Alto, California,
using the Mbone (Internet Multicast Backbone) to broadcast video
that was watched live as far away as Australia.&nbsp;As one viewer
remarked, "To quote all the people who said of Woodstock, ‘I was
there’ (remotely)."
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The band subsequently began live streaming every Wednesday
night. Viewers of the weekly streams could change the camera
angle, adjust the audio mix, and even control a fog machine in
the band’s basement.
</p></div> <p>
The first band to livestream a concert on the internet.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>What is internet, anyway?</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In 1994, on the TODAY Show, anchors Katie Couric, Bryant Gumbel
and Elizabeth Vargas pondered the nature of the Internet,
debating the meaning of the @ symbol and asking, "What is
internet, anyway?"
</p> <p data-v-200d9b1b="" data-v-3a470780="">
At the time only 20 million people worldwide were using the
internet, with less than half of that having an email account.
Just 10 years after this news segment aired, the number of
internet users would reach more than a billion.
</p></div> <p>
TODAY Show anchors discuss what the internet is in 1994.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>PizzaNet</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Launched by PizzaHut in 1994, PizzaNet was the first online
pizza delivery website and was only available to those in the
Santa Cruz area. It was responsible for one of the first online
web purchases - A large pepperoni and mushroom pizza, with extra
cheese.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Despite making a cameo in the 1995 Sandra Bullock movie
<i data-v-200d9b1b="" data-v-3a470780="">The Net</i>, PizzaNet grew slowly. After customers ordered
food and drinks on the site, the nearest Pizza Hut would still
confirm each one by phone, leading the LA Times to dub the idea
as "half baked."
</p></div> <p>
The first pizza delivery website, launched by PizzaHut in 1994.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>Justin's Links from the Underground</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created by 19-year-old Justin Hall, Justin's Links from the
Underground was one of the earliest blogs. Initially started to
post cool links he found online, Justin began sharing intimate
details of his life, including stories about his childhood, drug
experiences and love life.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Within a year, the blog had 27,000 daily readers—more than the
publication HotWired, where he was an intern. He became an early
internet celebrity and blogged about the struggles of internet
fame.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Justin also became an early advocate for blogging - creating
free tutorials on HTML so others could make their own blogs.
</p></div> <p>
One of the first blogs on the web, created by 19-year-old Justin
Hall.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>Yahoo!</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Yahoo! was created by Jerry Yang and David Filo, two Stanford
graduate students. Initially just lists of interesting links
called <i data-v-200d9b1b="" data-v-3a470780="">"Jerry's Guide to the World Wide Web"</i>, it took
off when they created a program to combine them.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Once the guide started getting 50,000 daily hits, they realized
it needed a better name and rebranded to Yahoo! (an acronym for
Yet Another Hierarchically Organized Oracle).
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Initially the two programmers manually added links, but as the
web grew they hired full-time "surfers" to browse and categorize
the internet. Eventually 1,000 sites were being added a day.
They later pitched the site to investors as a "TV Guide for the
internet."
</p></div> <p>
The original Yahoo! website, created by two Stanford graduates.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" site="white-house" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>White house page</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In 1994, the Clinton administration launched the first-ever
White House homepage. The pioneering site featured a guest book,
an option to email the President, and virtual tours of the White
House.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The rollout was successful, although initially delayed to find
images and audio of Socks the Cat, the First Family's pet.
Although only 1 in 10 Americans had access to the Internet at
the time, the number of visitors to the White House website more
than tripled annually throughout Clinton's tenure.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
A mock-up of the White House homepage was allegedly handed out
by Clinton himself to put pressure on agencies lagging behind in
the digital space.
</p></div> <p>
The first White House homepage, launched by the Clinton
administration in 1994.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>Geocities</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Launched in 1994, Geocities was a website hosting service with a
unique twist. Instead of just hosting websites, the site
consisted of virtual "neighborhoods" that let users decide where
to setup their page. There was the "Hollywood" neighborhood for
fan and celeb sites and "Area51" for science fiction and
fantasy. Geocities had an interactive 2D map, allowing users to
navigate through these virtual spaces.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
For new internet users, this virtual representation of the real
world helped make the complexities of the internet more
understable and fun. It created an easy way to discover new
content and people, and gave many their first virtual "home" on
the internet.
</p></div> <p>
Geocities was a web hosting service that allowed users to create
their own sites in virtual "neighborhoods".
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1994" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1994</p> <p>Fogcam</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created by two graduate students at San Francisco State
University, FogCam is celebrated as the longest-running webcam.
Originally set up as an experiment to provide slice-of-life
views of the campus, it quickly became a beloved fixture of the
early internet. At one point, the webcam even had a chat room
where users could discuss the weather.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The webcam was almost shut down in 2019, but a public outcry
kept it alive. It has now been streaming for 29 years.
</p></div> <p>
The longest-running webcam, created in 1994 by two graduate
students at San Francisco State University.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1995" desc="The first uploaded image to the world wide web. Uploaded by Tim Berners Lee." data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1995</p> <p>First Amazon Order</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
On April 3rd, 1995, John Wainwright ordered the first item from
Amazon.com—Douglas Hofstadter’s book
<i data-v-200d9b1b="" data-v-3a470780="">Fluid Concepts and Creative Analogies</i>. A friend of his,
the first Amazon employee, had invited him to a beta launch of
Amazon.com. Wainwright thought the items would be free and was
surprised when "they took my credit card and charged it!"
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Amazon would later name a building after Wainwright on their
corporate campus to commemorate the sale; he still has the
packing slip.
</p></div> <p>
The first ever item ordered on Amazon.com was the book
<i data-v-200d9b1b="" data-v-3a470780="">Fluid Concepts and Creative Analogies</i>.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1995" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1995</p> <p>Ebay AuctionWeb</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created by 28-year old Pierre Omidyar, AuctionWeb was an early
e-commerce platform that let people list items for sale to the
highest bidder. Omidyar wanted to create a platform that allowed
people to be producers as well as consumers. The very first item
sold was a broken laser pointer, which sold for $14.83.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
AuctionWeb was soon generating $10,000 a month, but the site’s
large traffic also prompted an increase in web hosting fees,
leading Omidyar to leave his day job and begin taking a
percentage of each transaction to fund the site that became
Ebay.
</p></div> <p>
The first version of Ebay, then called AuctionWeb.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>Space Jam</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The website used to promote the 1996 movie Space Jam included
games, coloring books, quizzes, and even a 360-degree tour of
the "Jordan Dome".
</p> <p data-v-200d9b1b="" data-v-3a470780="">
A rag-tag group of five New York City-based designers and
producers were charged with creating the movie's website. Most
executives at Warner headquarters in California didn't
understand or particularly care about the Internet, giving the
team free rein to experiment with little oversight.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The five-person team initially didn't know HTML and had
purchased the book
<i data-v-200d9b1b="" data-v-3a470780="">Teach Yourself Web Publishing with HTML in 14 Days</i> to get
started.
</p></div> <p>
The website used to promote the 1996 movie Space Jam.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>Dancing Baby</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
One of the biggest early internet memes, the
<i data-v-200d9b1b="" data-v-3a470780="">Dancing Baby</i> was the unintentional result of a plugin
demo for 3D Studio Max that could animate two-legged creatures.
Created by applying the plugin's <i data-v-200d9b1b="" data-v-3a470780="">Cha-Cha dance</i> animation
to the 3D model of a baby, the resulting animation was first
discarded for being too "disturbing."
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The animation found a second life when it was recreated from the
same files and posted as a GIF to a CompuServe forum. It found
its way into company-wide emails and exploded in popularity
after being set to the song <i data-v-200d9b1b="" data-v-3a470780="">"Hooked on a Feeling"</i>. It
became endlessly remixed, and even appeared as an hallucination
on the show Ally McBeal.
</p></div> <p>
One of the first internet memes, the Dancing Baby spread through
emails and forums.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>McDonald's Page</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The first McDonald's homepage featured a McTrivia Quiz, jingles
and an interactive world tour.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
McDonalds.com was originally purchased by Joshua Quittner, a
writer for WIRED, who was researching a story on domain
squatting when he realized McDonalds.com was available. He
reached out to McDonald's media relations to ask why they
hadn't bought it, only to discover that nobody at McDonald's
seemed to understand the internet. He told the company they
could reach him at <a href="https://neal.fun/cdn-cgi/l/email-protection" data-cfemail="d0a2bfbeb1bcb490bdb3b4bfbeb1bcb4a3feb3bfbd">[email&nbsp;protected]</a> if they ever wanted the
domain - which they eventually did.
</p></div> <p>
The first McDonald's homepage launched in 1996.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>Apple Homepage</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
The earliest surviving copy of Apple's homepage is from 1996,
during its most turbulent time. Apple was grappling with an
all-time low financially, resulting in widespread layoffs and a
loss of faith among shareholders and customers alike.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Later that year, Apple decided to acquire the company NeXT and
its operating system for $429 million, bringing Steve Jobs back
into Apple for the first time since 1985.
</p></div> <p>
The 1996 Apple website before the return of Steve Jobs. <span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>Beanie Babies</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Beanie Babies were an early internet sensation. Created by Ty
Warner in 1993, the plush animals were priced between $5 and $7
and slightly understuffed with plastic pellets. The plushies
were only sold in specialty shops, and different characters were
frequently retired, making them highly collectible.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The website URL was placed on the hangtags of the beanie babies,
an unusual move at the time but one that paid off. The mania
began when a group of suburban moms near Chicago started calling
stores nationwide to track down the rarest characters. By May
1997, Beanie Babies accounted for 6% of eBay's total annual
sales ($500 million), before the bubble finally burst at the
turn of the millennium.
</p></div> <p>
One of the earliest internet fads, Beanie Babies were a line of
plushies created by Ty Inc.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>Heaven's Gate</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Heaven’s Gate was a UFO-centric cult that believed salvation lay
in departing the planet aboard a spaceship. Comprised mainly of
computer programmers, the group operated a cutting-edge web
design firm called "Higher Source" that offered a wide range of
services.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
On March 26, 1997, the 39 members ended their lives, convinced
that the passing Hale-Bopp comet concealed a spaceship. Since
then, their space-themed website has remained frozen in time,
featuring a star-dotted background and a final message
proclaiming that "our 22 years of classroom here on planet Earth
is finally coming to conclusion."
</p></div> <p>
Heaven's Gate was a UFO religious cult that funded itself by
offering web design services.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1996" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1996</p> <p>Pepsi World</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In 1996, Pepsi launched its first website, "Pepsi World,"
featuring web design that was cutting-edge for its time. The
site explained that it aimed to "rev up the nerve center of your
imagination to a degree never before experienced".
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The chaotic site featured a series of Flash mini-games in a
section titled "Lab Rats". It also, for some reason, hosted a
section devoted entirely to astrology and dedicated an entire
page to promoting Shaquille O’Neal’s new album,
<i data-v-200d9b1b="" data-v-3a470780="">"You Can’t Stop The Reign."</i></p></div> <p>
The 1996 Pepsi website was a chaotic blend of flash games and bold
web-design. <span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1997" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1997</p> <p>First Emoji Set</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Japanese companies took the first steps in the late 1990s to
develop emojis for mobile devices. The first set of 90 emojis
was released by J-Phone (now SoftBank Mobile) on the SkyWalker
DP-211SW phone in November 1997.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The phone did not sell well, and emojis could only be shared
between users of that specific model, limiting their spread.
Despite the sluggish start, a later version of SoftBank's
emoji set became the foundation for Apple's emojis that
appeared with the release of iOS 2 in 2008 and that led to the
their standardization by Unicode in 2010.
</p></div> <p>
The first known set of emojis was released by J-Moblie on the
SkyWalker DP-211SW phone in 1997.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1997" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1997</p> <p>Year 2000 Bug</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Early computer programs only stored the last two digits of the
year to save on expensive storage space. With the year 2000
approaching, there was a frenzied effort to fix programs that
would break when the new millennium started.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Alarmists predicted failing banks, plummeting airplanes, and
nuclear plant disasters. Some people stockpiled gas masks and
food. To cushion against a potential financial crisis, the
Federal Reserve pumped an extra $50 billion into circulation.
But when the new year rolled around, the world breathed a
collective sigh of relief as the proactive work of programmers
had paid off, averting widespread catastrophes.
</p></div> <p>
A computer bug that was predicted to cause widespread problems
when the new millennium began.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1997" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1997</p> <p>Ask Jeeves</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Appearing in 1997, Ask Jeeves revolutionized search by allowing
users to make queries with natural language. Co-founded by
Garrett Gruener and David Warthen, the duo started with $250,000
and named the site after P.G. Wodehouse’s all-knowing butler.
The search engine rapidly gained traction, handling over a
million queries daily within two years of launching.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Unlike traditional search engines, Ask Jeeves used semantic
analysis to sort questions into one of about 10,000 basic
templates. A team of human reviewers curated and verified the
responses, ensuring the database remained up-to-date.
</p></div> <p>
Ask Jeeves was a search engine that allowed users to ask questions
with natural language.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1998" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1998</p> <p>The Hampster Dance</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created by Deidre LaCarte, a 37-year-old art student and martial
arts instructor from British Columbia, the Geocities webpage was
a tribute to her pet hamster, affectionately dubbed "Hampton the
Hampster". The page was created as part of a competition to see
whose website could garner the most views between her friends
and sister.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
By the end of 1999, an estimated 17 million people had visited
the page. The site's popularity spawned a wave of imitators,
including websites featuring dancing cows, fish, and amoebas. An
official Hampster Dance song was released in 2000 and reached #1
on the Canadian charts.
</p></div> <p>
An early internet meme created by Deidre LaCarte in 1998 for her
pet hamster.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1998" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1998</p> <p>Google Homepage</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Originally called BackRub, Google began as a research project by
Stanford PhD students Larry Page and Sergey Brin aimed at
crawling the 10 million websites on the web at the time. In
March 1996, they pointed their crawler at a Stanford webpage and
let it crawl the internet outward from there.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Their main breakthrough was the PageRank algorithm, which
measured the quantity and quality of links to and from a site.
The duo quickly realized that their search results outperformed
existing engines like AltaVista and Excite. Working initially
from their dorm rooms, they continually expanded the service, at
one point consuming nearly half of Stanford’s network bandwidth.
</p></div> <p>
The beta version of the Google homepage, launched in 1998.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1999" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1999</p> <p>Napster</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Founded by 19-year-old Shawn Fanning, Napster was a
revolutionary peer-to-peer service that allowed users to share
MP3s. Fanning conceived the idea in his dorm room at
Northeastern University after hearing his roommate complain
about dead MP3 links. By 2000, Napster had grown to more than 20
million users, with about 14,000 songs downloaded every minute.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Napster's rapid rise terrified the music industry. The RIAA, or
Record Industry Association of America, started sueing
individuals for downloading songs from Napster. Metallica was
the first individual band to sue, with Dr. Dre following soon
after. The legal onslaught led to Napster ceasing operations in
2001.
</p></div> <p>
Napster was a peer-to-peer file sharing service that allowed users
to share MP3 files.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1999" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1999</p> <p>Netflix Homepage</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
With fewer than half a million DVD players sold worldwide,
Netflix launched in 1998 with an initial library of more than
900 movies. They were able to target early adopters of DVDs
since most video stores didn't stock them yet.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The idea for Netflix came while co-founders Reed Hastings and
Marc Randolph were carpooling. They initially thought of letting
people rent VHS tapes online, but VHS was too expensive and
delicate to ship. A few months later, they read about a new
format called DVD and dusted off the idea. They mailed a used CD
to Hastings’s home and realized idea could work when it arrived
intact.
</p></div> <p>
The first version of the Netflix homepage, launched in 1999 with
over 900 movies.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="1999" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>1999</p> <p>Zombo.com</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Zombo.com is a website where you can do anything. The only limit
is yourself. Welcome.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Created by Josh Levine in late 1999, the site was a parody of
the flashy and pointless introductions in web design during that
era. When visitors land on Zombo.com, they are greeted by a
simple blinking pinwheel and a deep voice that lavishes them
with promises of limitless possibilities. The Guardian labeled
it as the "least useful website" on the Internet.
</p></div> <p>
Zombo.com is a website where you can do anything. The only limit
is yourself.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2000" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2000</p> <p>Ishkur's Guide to Electronic Music</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created by Kenneth Taylor, also known as Ishkur,
<i data-v-200d9b1b="" data-v-3a470780="">Ishkur's Guide to Electronic Music</i>
was an interactive flash-based guide to electronic music from
the 90s. "I told a friend I could categorize any electronic
music genre within an 8- bar radius. He dared me to prove it, so
I did." Ishkur would later say.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Launched on October 21, 2000, Ishkur built the site in just two
weeks, with the majority of his time spent looking through his
vast collection of mp3s for the perfect samples. New versions of
the guide were created over time, with new subgenres and tracks
being added with each release.
</p></div> <p>
An interactive guide to electronic music from the 90s.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2000" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2000</p> <p>Homestar Runner</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
An iconic flash-animated series, Homestar Runner took the
Internet by storm in the early 2000s, charming viewers with its
unique humor and memorable characters. Created by Mike and Matt
Chapman (also known as The Brothers Chaps), the series
originally started as a parody of a children’s book.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The website’s popularity soared with the introduction of the
"Strong Bad Email" series, a feature where the character Strong
Bad responds to emails from fans. The interactive element
captured the potential of the Internet at the time, and the
segments grew so popular that they were eventually released on
DVD.
</p></div> <p>
An iconic flash-animated series, Homestar Runner took the Internet
by storm in the early 2000s.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2001" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2001</p> <p>Wikipedia</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In 2000, founder Jimmy Wales enlisted graduate student Larry
Sanger to develop Nupedia, an online encyclopedia reliant on
scholarly contributions and a stringent seven-step review
process. After a year, the platform had only produced 21
articles.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Understanding the need to pivot, in 2001 they launched
Wikipedia, a collaborative and open wiki. Within a month,
Wikipedia had 600 articles—and 20,000 a year later. Contributors
started calling themselves "Wikipedians", and a community of
mostly anonymous users coalesced with the goal of creating a
free online encyclopedia. One of the most radical ideas of
Wikipedia was that everyone could contribute equally, "I don’t
care if they’re a high-school kid or a Harvard professor" Jimmy
Wales said.
</p></div> <p>
Launched by Jimmy Wales in 2001 as a collaborative and open wiki.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2002" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2002</p> <p>Helicopter game</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Designed by David McCandless and released in 2002, the
Helicopter Game was an early addiciting flash game. Using just a
single mouse button to ascend, you guide a helicopter through a
tunnel, dodging obstacles along the way.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
It was originally created for Seethru.co.uk, a website that
existed within the fictional universe of the BBC TV series
<i data-v-200d9b1b="" data-v-3a470780="">Attachments</i>. The site was a fictional blog about the
fictional startup <i data-v-200d9b1b="" data-v-3a470780="">"See Thru"</i>. The show and its
corresponding website served as early examples of "in-universe"
interactive media.
</p></div> <p>
The Helicopter Game was an addicting early flash game with simple
controls.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2003" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2003</p> <p>Friendster</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Launched by Jonathan Abrams in 2003, Friendster became an early
social media sensation, quickly amassing three million users.
Its rise came after several failed attempts in social networking
during the late ’90s, like Six Degrees. Serving as a blueprint
for future platforms, Friendster attracted notable early users
like Matthew McConaughey and even Mark Zuckerberg.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
However, as it grew in popularity, the platform faced
significant technical challenges, like unbearable load times.
Only a few months after Friendster launched, MySpace came out
with many of the same features, taking away Friendster's
momentum.
</p></div> <p>
Friendster was an early social media sensation, quickly amassing
three million users.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2003" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2003</p> <p>MySpace Tom</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In the spring of 2003, Tom Anderson saw the rise of platforms
like Friendster and felt that it was a missed opportunity to
create a more creative platform. He conceived of MySpace as a
place where users could express themselves, even allowing custom
HTML and CSS on users' profiles.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The platform first gained traction in the Los Angeles music
scene, where bands used the site to promote their songs. As the
site grew, it started launching the careers of bands, like
Panic! at the Disco. Tom became a celebrity himself, since he
was everyone's default first friend on MySpace. By October, the
platform was adding 10,000 new users a day.
</p></div> <p>
A social media platform that focused on self-expression and music.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2004" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2004</p> <p>The Facebook</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
After the Harvard administration shut down Facemash, a "Hot or
Not"-style website to rate students, Mark Zuckerberg launched
TheFacebook.com. Unlike MySpace, the site was based on
real-world connections, requiring users to have a Harvard e-mail
and to use their real name. It was the first time many students
used their real names on social media.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The platform was an instant hit, with two-thirds of the Harvard
student body signing up within a few weeks. A simple directory
at its core, most mainly used it to check relationship statuses
and see who shared classes. The site quickly expanded to other
colleges, and by the end of 2004, it had over one million users.
</p></div> <p>
Launched by Mark Zuckerberg, TheFacebook.com focused on real-world
connections on campus.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2004" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2004</p> <p>Club Penguin</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Club Penguin was created as a safe, fun space for kids to play
and hang out online. From the town square to the dance club, the
game featured meticulously designed virtual rooms where kids
could chat and play mini-games like Puffle Roundup and Cart
Surfer. Players were given their own personal igloo that could
be decorated with items purchased in the game.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The site hosted much beloved monthly virtual parties along with
annual Halloween celebrations that changed the entire map. By
2006, Club Penguin had over 2.6 million users in the U.S. and
Canada. For many young users, it was their first introduction to
social media.
</p></div> <p>
Club Penguin was created as as a safe, fun space for kids to play
and hang-out online.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2004" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2004</p> <p>You Wouldn't Steal a Car</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In 2004, the Motion Picture Association of America and the
Federation Against Copyright Theft launched the
<i data-v-200d9b1b="" data-v-3a470780="">"You Wouldn’t Steal a Car"</i> campaign, an anti-piracy
public service announcement displayed before movies on DVDs.
Aimed at deterring online movie piracy, the initiative coincided
with Hollywood’s first-ever lawsuits against individuals
suspected of sharing movies online.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Despite its serious intent, the ad became the subject of
widespread mockery through memes and parodies. It was also later
found out that, ironically, the ad’s music was used without the
creator’s permission.
</p></div> <p>
An anti-piracy public service announcement displayed before movies
on DVDs.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2004" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2004</p> <p>Numa Numa</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In December 2004, 19-year-old Gary Brolsma uploaded a webcam
video titled "Numa Numa," featuring himself lip-syncing to the
Romanian song <i data-v-200d9b1b="" data-v-3a470780="">"Dragostea Din Tei"</i> by O-Zone. Hosted
initially on Newgrounds.com, Brolsma created the video after
watching a cartoon about Japanese cats.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Even before the existence of YouTube, his video exploded one
night after Newgrounds featured it on their front page. A couple
days later, Brolsma woke up to find news vans from all the major
networks parked outside his house, forcing him to explain his
sudden Internet fame to his surprised mother.
</p></div> <p>
An early viral webcam video featuring Gary Brolsma lip-syncing to
a Romanian song.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2005" toppadding="150" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2005</p> <p>Million Dollar Homepage</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In 2005, 21-year-old Alex Tew from Wiltshire, England, devised a
unique way to pay for college: The Million Dollar Homepage. Tew
sold 1,000,000 pixels on the page for $1 each or $100 for a
10-by-10 pixel block, turning them into tiny digital billboards
for advertisers.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The ads ranged from mainstream outlets like The Times of London
to more niche sites, like online casinos. The site received
200,000 unique visitors daily within the first month. The last
1,000 pixels were auctioned off for $38,100, earning Tew a total
of $1,037,100 from the stunt. Tew ended up dropping out after
his first semester, saying school wasn't for him.
</p></div> <p>
Created by Alex Tew as a clever way to pay for college.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2005" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2005</p> <p>Me at the Zoo</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
YouTube co-founder Jawed Karim uploaded the first YouTube video,
<i data-v-200d9b1b="" data-v-3a470780="">"Me at the Zoo,"</i> on April 23, 2005. The 19-second clip
features Karim discussing the long trunks of two elephants at
the San Diego Zoo. Though not groundbreaking in content, the
video set the tone for a new era of user-created videos.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Initially conceived as a dating site, YouTube pivoted to online
entertainment just as conditions became ripe for widespread
video sharing, like the emergence of widespread broadband
access. By its official launch on December 15, 2005, YouTube was
already serving over two million video views per day.
</p></div> <p>
The first YouTube video, uploaded by co-founder Jawed Karim.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2005" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2005</p> <p>Reddit Homepage</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
In the summer of 2005, two college students joined the first
cohort of Y Combinator with $12,000 of seed money. They pivoted
from their original idea of a phone-based food ordering system
to create Reddit, envisioned as the "front page of the
Internet." The site consisted of a simple list of links that
users could vote on, making it a collaborative popularity
contest.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The founders initially created fake posts under fake profiles to
make the platform appear livelier. At first, there were no
subreddits and all posts were mixed together. They eventually
created the first subreddit to separate NSFW content from the
main page.
</p></div> <p>
Envisioned as the "front page of the Internet," Reddit launched in
2005.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2006" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2006</p> <p>The Ultimate Showdown of Ultimate Destiny</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Released on December 22, 2005, The Ultimate Showdown of Ultimate
Destiny is a parody song and video that took the Internet by
storm. Created by Neil Cicierega under the pseudonym "Lemon
Demon", with Flash animation by Shawn Vulliez, the animation
showcases a fantastical, century-long battle in Tokyo.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Featuring an eclectic mix of both real and fictional pop-culture
icons from Shaquille O’Neal to Batman, the video was viewed over
13 million times on Newgrounds.
</p></div> <p>
A parody song and animation that took the Internet by storm.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2006" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2006</p> <p>First Tweet</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Co-founder Jack Dorsey sent the first-ever tweet—"just setting
up my twttr" on March 21st, 2006. Twitter was initially designed
as an SMS-based platform for friends to share status updates. It
was called "twttr," since it was cool at the time remove vowels
from company names.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
In its early days, amidst a world dominated by flip phones,
Twitter took time to gain traction. Its significant breakthrough
came during the South by Southwest Interactive conference in
March 2007, where the platform saw a massive surge in usage.
</p></div> <p>
Jack Dorsey, co-founder of Twitter, posted the first-ever tweet.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2006" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2006</p> <p>Line Rider</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
Created over four months and released in September 2006 by
Slovenian university student Boštjan Cadež, the online game Line
Rider quickly gained a cult following, becoming one of the most
popular flash games of all time and even appearing in a 2008
McDonald’s Snack Wrap commercial.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
Initially introduced on the deviantART site, the interactive
"toy" allows users to draw ramps, hills, and slopes, sending a
virtual sledder with a red scarf on a physics-based joyride.
Fans started syncing their elaborate levels to music, uploading
over 11,000 track videos to YouTube by 2007.
</p></div> <p>
Created by Boštjan Cadež, the online game Line Rider became one of
the most popular flash games of all time.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2007" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2007</p> <p>The Impossible Quiz</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
A 2007 Flash game created by deviantART user Splapp-me-do, the
Impossible Quiz gained notoriety for its absurd questions and
humor. Featuring 110 bewildering, riddle-like questions, the
game frustrated players with its warped logic, making it one of
the earliest viral rage games.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
The game became a classroom sensation, with students competing
and collaborating to memorize the game’s nonsensical answers
during free time in computer labs.
</p></div> <p>
A Flash game created by deviantART user Splapp-me-do, the
Impossible Quiz gained fame for its absurd humor.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div> <div data-date="2007" data-v-200d9b1b="" data-v-3a470780=""><div data-v-200d9b1b=""> <p><img src="https://neal.fun/internet-artifacts/column-shadow.png" data-v-200d9b1b=""> <img src="https://neal.fun/internet-artifacts/column.webp" data-v-200d9b1b=""></p></div> <div data-v-200d9b1b=""><p>2007</p> <p>an internet communicator</p>  <div data-v-200d9b1b=""><div data-v-200d9b1b=""><p data-v-200d9b1b="" data-v-3a470780="">
On January 9, 2007, Steve Jobs introduced the iPhone as a
"widescreen iPod," a "revolutionary phone," and a "breakthrough
Internet communicator". Although the crowd didn't seem as
excited about the internet communicator part, it ended up
becoming by far the most revolutionary feature—the device would
re-shape the internet.
</p> <p data-v-200d9b1b="" data-v-3a470780="">
It forced a redesign of web interfaces to become responsive and
minimalistic. Flash began a slow death as it wasn't supported.
Social media went mobile-first, and became all-encompassing. An
era of the internet had ended, and a new one began.
</p></div> <p>
The launch of the iPhone in 2007 started a new era of the
internet.
<span data-v-200d9b1b="">More...</span></p></div></div>  </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Confessions of a Middle-Class Founder (101 pts)]]></title>
            <link>https://nymag.com/intelligencer/article/venture-capital-backed-startup-founder-confessions.html</link>
            <guid>38013157</guid>
            <pubDate>Wed, 25 Oct 2023 14:24:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nymag.com/intelligencer/article/venture-capital-backed-startup-founder-confessions.html">https://nymag.com/intelligencer/article/venture-capital-backed-startup-founder-confessions.html</a>, See on <a href="https://news.ycombinator.com/item?id=38013157">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="nymag.com/intelligencer/_components/article/instances/clo4s1e31000k0if6k8oyj5i2@published" data-content-channel="Technology" data-crosspost="" data-type="Enterprise, First-Person Essay" data-syndication="original" data-headline="Confessions of a Middle-Class Founder" data-authors="Anonymous" data-publish-date="2023-10-25" data-tags="technology, venture capital, the money game" data-issue-date="" data-components-count="41">
    


  
  
  
  <header>
    <div>
          
            <h2 data-editable="displayTeaser">During the boom times, I launched a start-up so I could become rich. Years later, I’m still looking for my exit.</h2>
            

            
        </div>
      <div data-editable="lede">
          <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.2x.rhorizontal.w1100.jpg" width="1100" height="733"> <img src="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.rhorizontal.w1100.jpg" data-content-img="" width="1100" height="733" fetchpriority="high"> </picture>
          </div>
        <p><span>Illustration: Tim Bouckley</span>
        </p>
  </header>
  <section>
    <div data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.2x.rhorizontal.w1100.jpg 2x" width="1100" height="733"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.rhorizontal.w1100.jpg" width="1100" height="733"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.2x.rhorizontal.w1100.jpg" width="1100" height="733"> <img src="https://pyxis.nymag.com/v1/imgs/5ca/78b/658a54fbe9077c51f1b84cb31b628439d9-anonymous-tech-founder.rhorizontal.w1100.jpg" data-content-img="" width="1100" height="733" fetchpriority="high"> </picture>
          </div>
            <div>
              <p><span>Illustration: Tim Bouckley</span>
              </p>
            </div>
              </div>
            <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1e31000j0if63ylhwav4@published" data-word-count="59">Sometime in the second half of the past decade, I decided to found a start-up. I was in my 20s and working at a mid-size tech company, and I didn’t yet have an idea, or even a general sense of where I wanted to focus. But I was convinced becoming a founder was the right thing to do next.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1k59000y3b7gknyuqhyi@published" data-word-count="186">In college, I<strong> </strong>had majored in a discipline within the liberal arts. I would have liked to become a philosopher or a writer but lacked the intestinal fortitude to risk being poor, a perpetual worry in spite of — or because of — having enjoyed a solid upper-middle-class upbringing. My desire to be a capitalist may have crystallized<strong> </strong>a few years after graduation,<strong> </strong>when I attended a reading by a former professor, a lecturer from my alma mater, on tour for his new book. Seeing me in the audience, he invited me to a sumptuous dinner with several eminent literary types:<strong> </strong>an award-winning author, the proprietor of a cherished bookstore, a leading critic. We spent a great evening gossiping about famous writers, but when the check arrived, no one moved. Instead, we all made a furtive scan of the table — me, young with a tech job; them, decades older but sheltered from being first to reach for the bill by their commitment to art — realizing after an extended pause that no obviously rich person was around to pick up the tab. (We split it.)</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1k77000z3b7gcqxd17v7@published" data-word-count="64">I had always envied the gentry of the Enlightenment, who produced intellectual and artistic<strong> </strong>breakthroughs because they were smart but also because few others had the leisure to think. I also envied their modern equivalents, people with family money. What if I could make<strong> </strong>my own family money? That way, I could consummate my intellectual ambitions without sacrificing a reasonably bougie standard of living.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1k8000103b7gm1rqemlk@published" data-word-count="106">I began lurking in Reddit<strong> </strong>forums with names like “<a href="http://reddit.com/r/fatfire">FATFire</a>,” filled with people who obsessed over their “number”: the amount of money they wanted to sock away before they could pursue their whims forever. I remember hunching over a spreadsheet in a coffee shop one sunny weekend while my friends were at the beach, adding up the present value of my projected lifetime expenditures to estimate my own number. Of course, I had to factor in a safe withdrawal rate from my nest egg, private school for my hypothetical kids, and allowances like the occasional Michelin dinner. <em>Around $6 million,</em> I thought, <em>ought to do it.&nbsp;</em></p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1ka700113b7g2ppo1w10@published" data-word-count="140">A strategy consists of matching means to an end; if my end was rapid financial independence, my means were youth, pedigree, lack of student debt, a prodigious capacity for work, and a lack of a faculty for combinatorics, which rendered me unsuitable for quantitative finance. It helped that I genuinely liked technology, had devoured science fiction and messed around with computers since I was little. The smart move was probably working for one of the FAANGs, which grew so reliably that you could chill and make a few hundred thousand dollars a year. But I didn’t want to do that. This was the mid-2010s. Though peak mania had yet to arrive, venture capitalists were showering people the same age as me with capital. Someone in my graduating class had just flipped a two year old start-up for a life-changing sum.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kcp00123b7gfjvu45hx@published" data-word-count="116">After several false starts, I was introduced to my co-founder by a mutual friend. He was affably bright in a way that balanced my neurotic tendencies, and I liked him right away. We had been exploring similar markets and started tinkering together on a promising idea: an outwardly boring but vast corner of a broader sector that was hot at the time. We fleshed out the idea over a series of whiteboard sessions at a WeWork, each followed by a trip to a dive bar where we’d get drunk and talk about our goals, speedrunning the process of becoming friends. We both agreed that we wanted money but not a lot. “What’s your number?” I asked.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kdz00133b7g7cuv5y0q@published" data-word-count="13">“If we each made a few million,” he said, “that would be enough.”</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kg000143b7g5gk7ycxu@published" data-word-count="65">Every founder tells themselves a story<strong>&nbsp;</strong>about why they’re heading to the gold rush, but the executive coach I would eventually hire says there are really only two.&nbsp;Do you want to be rich, generating wealth in service of some further end? Or do you want to be king, with money a mere byproduct of trying to make the world the way you feel it should be?</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kh900153b7grmi7qzyu@published" data-word-count="99">At the time, I told myself I wanted the freedom of being rich. I thought I’d be able to recognize a winning hand fast or fold.<strong> </strong>Now, several years later, I’m still waiting for the river card that determines my fate. You could call me a middle-class founder: proprietor of a business you may or may not have<strong> </strong>heard of, tenuously wealthy on paper, by no means a failure but not yet a success, chugging along in the twilight of an era that minted more giants and more waste than any other in history with no exit in sight.</p>

  

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1klj00173b7ghr1kq5iq@published" data-word-count="157">Fans of <a href="http://www.paulgraham.com/articles.html">Paul Graham</a> — founder of Y Combinator, the leading start-up incubator in the land and one of the patron saints of the modern start-up era — would probably say my original sin was being a mercenary. For about a decade, starting when the first tech bubble popped in the early 2000s and ending with Facebook’s IPO in 2012, founding a start-up just to make money was both crass and unwise. If a founder wanted to raise money or hire the best people, the dogma went,<strong> </strong>it was important they lay claim to changing the world. Organize the world’s information (Google), bring the world closer together (Facebook), belong anywhere (Airbnb): The ideal founder was the protagonist of a Zen koan, or Harry Potter facing the desire mirror in <em>The Sorcerer’s Stone.</em> Seek money, find nothing — but <em>seek the</em> <em>voice of the customer,</em> and find the riches you never wanted but are darn glad to have.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kmo00183b7gu8bmrrwp@published" data-word-count="154">The extent to which founders really followed this precept is debatable. But in the early 2010s, three things happened to make start-ups more attractive to mercenaries looking for a lucrative exit. Finance became less cool and generally less profitable after 2008. Several start-ups of the past decade, led by Facebook, grew into robust and outrageously profitable behemoths. And interest rates came down to zero, creating a glut of money seeking returns and increasing the spreadsheet value of profits generated far in the future (which happen to be the only profits most start-ups generate). This potent combination spawned an avalanche of capital earmarked for start-ups and doled out by venture capitalists. Over the coming years, a portion of these venture dollars wound their way to genuinely innovative companies. Some of it landed in money pits like WeWork. Far too much was airdropped into the Ponzi-ridden wasteland of crypto. And a tiny sliver landed with me.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1knx00193b7gb3blj7cv@published" data-word-count="43">Before I met my co-founder, I spent a year trying to identify business opportunities that were both personally compelling and commercially viable. When I pitched my VC friends these ideas — for example, a niche media company — they were kind but unimpressed.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kri001a3b7gk16mlf1p@published" data-word-count="61">“What about addressable market?” my friend T asked over dinner. <em>Translation: If you succeed, how much money could this make us? </em>He was delighted I was pitching him so we could charge our meal to his firm, a prominent bank that had entered the VC game but retained its relatively stingy expense policy. “This could be a big business!” I said.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1ku8001b3b7gabfg4t3v@published" data-word-count="108">“My guy, I think we have different definitions of <em>big,</em>” he responded. Venture capitalists, I’d soon learn, don’t get out of bed unless a start-up has the potential to generate roughly a hundred million dollars of revenue per year. This implies the company is worth some multiple of that number, which in turn enables the average investor to “return the fund,” or generate a sum of returns equivalent to the whole pot of money they have to invest, if the company is bought or goes public. I had been introduced to the tyranny of the power law: the need for winners to win big because most start-ups fail.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1kwd001c3b7gbjsi205i@published" data-word-count="137">I could have tried roughing it without venture funding, what the industry calls “bootstrapping.” The venture world has a condescending label for bootstrapped companies without scale potential: a “lifestyle” business, which roughly translates to: <em>Good for you, now back to the sandbox until you’re ready to play with the big boys</em>. Given my professed aim, this could have made sense. But there was so much funding for the taking, and part of me figured that if I was swinging, I may as well swing big. Why not make more than $6 million? So I narrowed my focus to the beam of a management consultant, scanning for hallmarks of a “venture-scale”<em> </em>business: addressable market, gross margins, incumbent NPS, lifetime value. You can Google these terms if you’d like, but taken in aggregate, all they mean is dollar signs.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1l0g001e3b7g0zg1jkz8@published" data-word-count="142">As I talked through our idea with my co-founder, I ran through the VC-ratified checklist in my head: <em>Large market — check. Fragmented landscape with dissatisfied customers — check. </em>Most businesses are interesting if you look at them closely enough, but the perception of boringness — workflow automation, human-resource information systems — is good because competition is death; the cooler you sound at parties, the harder it is to succeed. The idea was far from perfect, but I was impatient, and after a rapid courtship, we decided to try raising a round of funding. If we could pull together enough to get started — a sum I estimated in the mid-six figures — we’d quit our jobs and found the company. I made a PowerPoint, following a handy <a href="https://www.ycombinator.com/library/2u-how-to-build-your-seed-round-pitch-deck">template</a> produced by Y Combinator: problem, solution, how you find customers, all vagaries eliminated.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1l1t001f3b7gcporb0jr@published" data-word-count="89">We received plenty of rejections. These surprised us, though a state of the world enabling two people who barely know each other to obtain hundreds of thousands of dollars with nothing but a few dozen prettily formatted words should have been far more astonishing. Some part of me was relieved by the rejections, which might have built slowly toward permission to throw in the towel, until we got our first yes — on the basis of a single phone call with an investor about the same age as me.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1l33001g3b7g00ntvv7q@published" data-word-count="6">“What could go wrong?” he asked.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1l5m001h3b7gvm8zv3ps@published" data-word-count="49">“Well, a lot,” I said, and I laid out the ways our thesis might be flawed, along with a theoretical solution to each snag. I treated this as a game, like switching to the affirmative after arguing the negative in a high-school debate, but he seemed convinced of something.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1l9f001i3b7gc5lh6yv1@published" data-word-count="5">“Have you incorporated?” he asked.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lbe001j3b7g8ntlvfg3@published" data-word-count="80">When he emailed to say he was inclined to invest, I wondered what he had learned over the course of a half-hour to make him write this check. It was an astounding hourly rate. Later, I learned that he was rich and wrote many checks and that this check, in the grand scheme of this world, was small. After the first year, I never heard from him again. He’s still on our cap table today, making money while he sleeps.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lix001k3b7gdgmu9bf4@published" data-word-count="129">We used the momentum from his “yes” to secure others, then incorporated our business using a tool created by a<strong> </strong>company called Stripe to make it easier for entrepreneurs to form corporations. As I typed our company name into the web form, I recalled that when my father started a small company decades ago, he had to write a physical letter to a legal agent in Delaware. I wondered briefly if there should be more friction in making a decision to start a company. To some extent, reducing friction is what the whole start-up game is about: Calling a cab when you want it, summoning food when you want it, an infinite radio that plays whatever you want on command. I clicked the button, submitted the form, and incorporated.</p>

  

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lmi001m3b7gg6zm1alb@published" data-word-count="122">We hired a small team. Because we couldn’t afford to pay top dollar, we looked beyond the world of Ivy League, Big Tech, and management-consulting alumni to find moneyball hires mispriced by the market. The best of them were searching for a chance to prove their worth, and we gave it to them. The first year or so was a constant swing between the radiant high of making customers happy and the comedown of watching our jerry-rigged product disappoint them. I learned most customers are indifferent as long as the job gets done, about 20 percent are discerning but reasonable, and 3 percent will drive you nuts (no amount of support will satisfy them because the product they really need is therapy).</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lnw001n3b7gdnx8atvc@published" data-word-count="99">Buried in my master plan was an assumption that I could stay above the emotional fray of building a company. In hindsight, this was dumb. Start-ups are like sharks: They need movement to survive. But movement implies change, change implies volatility, and volatility implies fluctuations between good and bad. To succeed, you need to average more good days than bad, but bad days are impossible to avoid. And more than any other trait, good founders are defined by an obsession with doing things right; it was inevitable that my self-worth would become entangled with the performance of the business.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lpe001o3b7gibiq7ck7@published" data-word-count="59">This felt great during the good times. Over the coming years, the company grew. At parties, where I had assiduously avoided the “What do you do?” question for years and responded when asked with a self-effacing bit on the mundanity of our market, people I didn’t know started to recognize our start-up. Some even used and liked the product.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lql001p3b7gs8z5vwkg@published" data-word-count="109">But it didn’t feel as good when I looked around. In 2021, COVID and its aftermath marked<a href="https://nymag.com/intelligencer/2021/04/nft-future-of-money.html"> peak froth </a>for tech. The phenomenon of <a href="https://nymag.com/intelligencer/2021/09/the-big-spac-crackdown.html">SPACs</a> gave questionable but sexy companies a shortcut to going public. Crypto had reached full sail. Other founders I knew were raising absurd amounts of money for concepts that made a napkin business plan look fleshed out, spurred by a new class of leviathan VCs that had raised mind-bogglingly large funds. Founders could sell their own stock to these investors, sometimes pocketing more millions personally than their companies had earned in lifetime revenue. I still hadn’t made a cent beyond the salary I paid myself.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lrs001q3b7gvufhkvdu@published" data-word-count="122">I’d like to say we never considered taking this money, but we did try pitching a megafund partner during our last round of fundraising in the latter days of this madness. We told the story of our business, and he cut us off after 20 minutes with a curt, “You can clearly execute, but this won’t get big enough for us.” Market sentiment had turned against our particular vertical; it felt like we were sprinting to stay in place<strong>. </strong>Meanwhile<strong>, </strong>start-ups that had staked a claim on vast frontiers of innovation — <em>immutable money, infinite frontier, and eternal life</em>, as the Twitter bio of a prominent crypto evangelist proclaimed — were speeding on a moving walkway toward giant valuations and general adulation.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lte001r3b7ggtqzuq0u@published" data-word-count="137">The mood inside our company all-hands during this time was confusing. We were growing sustainably, making even our pickiest customers happy, but it was a euphoric time in the world outside our Zoom screens; you might be having fun sober at the party, but it’s hard not to watch your friends on drugs and wonder what it’s like. The irony that selling fiction to investors was making these founders richer than selling a bona fide product to paying customers wasn’t lost on me. But it wasn’t just the money: After years of work, I had the temerity to be proud of the culture and product we had built. I had started to believe we could actually make a difference. In the market of 2021, our mission felt quaint; we may as well have been a lifestyle business.</p>

  

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1lza001t3b7gexfsc7xg@published" data-word-count="65">At the tippy-top of the market, a party. I met another founder, a few years older than me, who had unequivocally made it, with a liquid net worth of multiples of my number. I was tipsy enough to ask all kinds of direct questions about what it was like. He was tipsy enough to answer unequivocally: Yes, having a fuck ton of money is great.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1m1e001u3b7g2dbe2wsi@published" data-word-count="95">This is the difference between equity and cash: Partying in prime time in Aspen and Cannes; a gorgeous apartment in one of the best neighborhoods in our city, which I saw when he brought the after-party there; other apartments around the country and in a premier European capital where he lived a month or two out of the year. Meetings with anyone you want, whenever you want. Respect among both the tech cognoscenti and normal people who figured out what he had made. I knew this because of the deferential way I behaved around him.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1m35001v3b7gaewbrxmo@published" data-word-count="5">“What gets worse?” I asked.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1m6w001w3b7gx0rhsrm3@published" data-word-count="28">“You can probably guess,” he said. It was what you expect: People treat you less like a human and more like a mythical being or a human bank.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1m8i001x3b7gbo5wpj97@published" data-word-count="6">“Do you want more?” I asked.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1ma4001y3b7gdb531urt@published" data-word-count="135">I don’t remember his answer; things were hazy by this point. I staggered out of the fifth bar we visited that night, more intoxicated by the conversation than the drinks, just sober enough to be perturbed by my own fascination. Financially, my best-case outcome was a fraction of what this guy had already. No one needed the amount of money he had: an amount of wealth impossible to justify by any rational calculation of needs I could run on a spreadsheet (which explains why he was spending it on frivolous things). But now my number seemed too low. That night, I dreamt about market size, which in my subconscious manifested as a visual resembling the spirals of light that appear when you press directly on your eyeballs, rippling wider and wider. I woke up stressed.</p>

  

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1md400203b7g11des0ec@published" data-word-count="83">Today, the market has turned for everyone. We’re growing slower than I want, but other start-ups, even the hot companies that dominated fundraising in past years, are showing far more signs of strain. Some have already flamed out spectacularly, and for those that survive, the gobs of money raised from megafunds come with a catch: It needs to be paid back first, which means that employees and early investors who expected millions won’t make any money unless they deliver on their tall tales.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1meh00213b7g1ehrck43@published" data-word-count="90">The culprit is technically rising interest rates, but you could argue it began when founders and investors started to see the downside of swinging for the power law. The first venture funds formed as a way for savvy investors to help innovators create fundamental technologies like transistors, which required huge outlays of time and treasure before they could produce value. But in the past few years, causality inverted: Start-ups and entire markets were manufactured from whole cloth to meet the demand of overcapitalized venture funds searching for a home run.</p>

  <p data-editable="text" data-uri="nymag.com/intelligencer/_components/clay-paragraph/instances/clo4s1mfx00223b7gm469dyzo@published" data-word-count="145">Exit markets have dried up. I have yet to hit my number, though I’d guess my odds of getting there in the next couple years are decent. I would be disappointed if it didn’t happen, but I’m not sure it would change what I do next. At work, there’s some sense that we’ve missed the windfall, the easy IPO, the fairy godmother of acquisition that taps some lucky people and makes them rich. You’d think that would suck for morale. But from what I can tell, our team seems happy. What venture capitalists are now telling startups to do — <em>forget “growth at all costs”, be profitable </em>— is what we, partly by accident, have been doing all along. With the exception of the new wave of AI companies, the skies are full of Icaruses crashing to earth, but we’ve been here the whole time.</p>

    </div>

    


          



      <span>Confessions of a Middle-Class Founder</span>



  </section>

  
  
</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Components Will Outlive Your JavaScript Framework (263 pts)]]></title>
            <link>https://jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/</link>
            <guid>38012662</guid>
            <pubDate>Wed, 25 Oct 2023 13:40:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/">https://jakelazaroff.com/words/web-components-will-outlive-your-javascript-framework/</a>, See on <a href="https://news.ycombinator.com/item?id=38012662">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-content="" data-astro-cid-rnrqlda2="">
<p>If you’re anything like me, when you’re starting a project, there’s a paralyzing period of indecision while you try to figure out how to build it. In the JavaScript world, that usually boils down to picking a framework. Do you go with Ol’ Reliable, a.k.a. React? Something slimmer and trendier, like Svelte or Solid? How about kicking it old school with a server-side framework and HTMX?</p>
<p>When I was writing my <a href="https://jakelazaroff.com/words/an-interactive-intro-to-crdts/" data-astro-cid-bi7aps5f="">CRDT blog post series</a><a data-tooltip="" href="https://jakelazaroff.com/words/an-interactive-intro-to-crdts/" data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/og/an-interactive-intro-to-crdts.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">An Interactive Intro to CRDTs | jakelazaroff.com</span><span data-astro-cid-bi7aps5f="">CRDTs don't have to be all academic papers and math jargon. Learn what CRDTs are and how they work through interactive visualizations and code samples.</span><span data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jakelazaroff.com/words/an-interactive-intro-to-crdts/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, I knew I wanted to include interactive demos to illustrate the concepts. Here’s an example: a toy collaborative pixel art editor.</p>
<pixelart-demo></pixelart-demo>

<p>Even though I’ve written before — and still believe — that <a href="https://jakelazaroff.com/words/no-one-ever-got-fired-for-choosing-react/" data-astro-cid-bi7aps5f="">React is a good default option</a><a data-tooltip="" href="https://jakelazaroff.com/words/no-one-ever-got-fired-for-choosing-react/" data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/og/no-one-ever-got-fired-for-choosing-react.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">No One Ever Got Fired for Choosing React | jakelazaroff.com</span><span data-astro-cid-bi7aps5f="">If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a project without a framework.</span><span data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jakelazaroff.com/words/no-one-ever-got-fired-for-choosing-react/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, the constraints of a project should determine the technology decisions. In this case, I chose to use vanilla JS web components. I want to talk about why.</p>
<p>There was one guiding principle for this project: although they happened to be built with HTML, CSS and JS, these examples were <strong>content, not code</strong>. In other words, they’d be handled more or less the same as any image or video I would include in my blog posts. They should be portable to any place in which I can render HTML.</p>
<p>As of 2023, this blog is built with Astro. Before that, it was built with <a href="https://jake.museum/jakelazaroff-v5/" data-astro-cid-bi7aps5f="">my own static site generator</a><a data-tooltip="" href="https://jake.museum/jakelazaroff-v5/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/jakelazaroff-v5-GAPUBCDN.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jakelazaroff.com v5 | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/jakelazaroff-v5/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>. Before that, <a href="https://jake.museum/jakenyc-v3/" data-astro-cid-bi7aps5f="">Hugo</a><a data-tooltip="" href="https://jake.museum/jakenyc-v3/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/jakenyc-v3-EAU7OKHC.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.nyc v3 | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/jakenyc-v3/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>; before that, <a href="https://jake.museum/jakelazaroff-blog/" data-astro-cid-bi7aps5f="">a custom CMS written in PHP</a><a data-tooltip="" href="https://jake.museum/jakelazaroff-blog/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/jakelazaroff-blog-R46W4ETF.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">blog.jakelazaroff.com | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/jakelazaroff-blog/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>; before that, <a href="https://jake.museum/hexnut-v5/" data-astro-cid-bi7aps5f="">Tumblr</a><a data-tooltip="" href="https://jake.museum/hexnut-v5/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/hexnut-v5-NJJNLALO.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Hexnut v5 | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/hexnut-v5/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, <a href="https://jake.museum/hexnut-v4/" data-astro-cid-bi7aps5f="">Movable Type</a><a data-tooltip="" href="https://jake.museum/hexnut-v4/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/hexnut-v4-XX7XCL43.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Hexnut v4 | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/hexnut-v4/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> and <a href="https://jake.museum/mlingojones/" data-astro-cid-bi7aps5f="">WordPress</a><a data-tooltip="" href="https://jake.museum/mlingojones/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/mlingojones-PNOBBKOA.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">mlingojones | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/mlingojones/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> — and I’m sure I’m missing some in between. I really like Astro, but it’s reasonable to assume that this website won’t run on it forever.</p>
<p>One thing that has made these migrations easier in recent years is keeping all my content in plain text files written in Markdown. Rather than dealing with the invariably convoluted process of moving my content between systems — exporting it from one, importing it into another, fixing any incompatibilities, maybe removing some things that I can’t find a way to port over — I drop my Markdown files into the new website and it mostly Just Works.</p>
<p>Most website generators have a way to include more complex markup within your content, and Astro is no different. The MDX integration allows you to render Astro components within your Markdown files. Those components have access to all the niceties of the Astro build system: you can write HTML, CSS and JS within one file, and Astro will automagically extract and optimize everything for you. It will scope CSS selectors and compile TypeScript and let you conditionally render markup and do all sorts of other fancy stuff.</p>
<p>The drawback, of course, is that it all only works inside Astro. In order to switch to a different site generator, I’d have to rewrite those components. I might need to split up the HTML, CSS and JS, or configure a new build system, or find a new way to scope styles. So Astro-specific features were off limits — no matter how convenient.</p>
<p>But Markdown has a secret weapon: <a href="https://daringfireball.net/projects/markdown/syntax#html" data-astro-cid-bi7aps5f="">you can write HTML inside of it</a><a data-tooltip="" href="https://daringfireball.net/projects/markdown/syntax#html" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Daring Fireball: Markdown Syntax Documentation</span><span data-astro-cid-bi7aps5f=""><img src="https://daringfireball.net/graphics/favicon.ico#html" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">daringfireball.net/projects/markdown/syntax#html</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>! That means any fancy interactive diagrams I wanted to add would be just as portable as my the rest of my Markdown as long as I could express them as plain HTML tags.</p>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Components" data-astro-cid-bi7aps5f="">Web components</a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Components" data-astro-cid-bi7aps5f=""><img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Web Components - Web APIs | MDN</span><span data-astro-cid-bi7aps5f="">Web Components is a suite of different technologies allowing you to create reusable custom elements — with their functionality encapsulated away from the rest of your code — and utilize them in your web apps.</span><span data-astro-cid-bi7aps5f=""><img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/API/Web_Components</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> hit that nail square on the head. They’re a set of W3C standards for building reusable HTML elements. You use them by writing a class for a custom element, registering a tag name and using it in your markup. Here’s how I embedded that pixel art editor before:</p>
<pre><code><span><span><span>&lt;</span>pixelart-demo</span><span>&gt;</span></span><span><span><span>&lt;/</span>pixelart-demo</span><span>&gt;</span></span></code></pre>
<p>That’s the honest-to-goodness HTML I have in the Markdown for this post. That’s it! There’s no special setup; I don’t have to remember to put specific elements on the page before calling a function or load a bunch of extra resources.<sup><a href="#user-content-fn-cheating" id="user-content-fnref-cheating" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">1</a></sup> Of course, I do need to keep the JS files around and link to them with a <code>&lt;script&gt;</code> tag. But that goes for any media: there needs to be <strong>some</strong> way to reference it from within textual content. With web components, once the script is loaded, the tag name gets registered and works anywhere on the page — even if the markup is present before the JavaScript runs.</p>
<p>Web components encapsulate all their HTML, CSS and JS within a single file, with no build system necessary. Having all the code for a component in one place significantly reduces my mental overhead, and I continue to be a huge fan of single-file components for their developer experience. While web components aren’t <strong>quite</strong> as nice to write as their Astro or Svelte counterparts, they’re still super convenient.<sup><a href="#user-content-fn-frameworks" id="user-content-fnref-frameworks" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">2</a></sup></p>
<p>In case you’re not familiar with web components, here’s the code for that <code>&lt;pixelart-demo&gt;</code> component above:<sup><a href="#user-content-fn-abridged" id="user-content-fnref-abridged" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">3</a></sup></p>
<pre><code><span>import</span> PixelEditor <span>from</span> <span>"./PixelEditor.js"</span><span>;</span>

<span>class</span> <span>PixelArtDemo</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>constructor</span><span>(</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>)</span><span>;</span>

    <span>this</span><span>.</span>shadow <span>=</span> <span>this</span><span>.</span><span>attachShadow</span><span>(</span><span>{</span> <span>mode</span><span>:</span> <span>"closed"</span> <span>}</span><span>)</span><span>;</span>
    <span>this</span><span>.</span><span>render</span><span>(</span><span>)</span><span>;</span>

    <span>const</span> resolution <span>=</span> <span>Number</span><span>(</span><span>this</span><span>.</span><span>getAttribute</span><span>(</span><span>"resolution"</span><span>)</span><span>)</span> <span>||</span> <span>100</span><span>;</span>
    <span>const</span> size <span>=</span> <span>{</span> <span>w</span><span>:</span> resolution<span>,</span> <span>h</span><span>:</span> resolution <span>}</span><span>;</span>

    <span>const</span> alice <span>=</span> <span>new</span> <span>PixelEditor</span><span>(</span><span>this</span><span>.</span>shadow<span>.</span><span>querySelector</span><span>(</span><span>"#alice"</span><span>)</span><span>,</span> size<span>)</span><span>;</span>
    <span>const</span> bob <span>=</span> <span>new</span> <span>PixelEditor</span><span>(</span><span>this</span><span>.</span>shadow<span>.</span><span>querySelector</span><span>(</span><span>"#bob"</span><span>)</span><span>,</span> size<span>)</span><span>;</span>

    alice<span>.</span>debug <span>=</span> bob<span>.</span>debug <span>=</span> <span>this</span><span>.</span><span>hasAttribute</span><span>(</span><span>"debug"</span><span>)</span><span>;</span>
  <span>}</span>

  <span>render</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>shadow<span>.</span>innerHTML <span>=</span> <span><span>`</span><span>
      &lt;div class="wrapper"&gt;
        &lt;canvas class="canvas" id="alice"&gt;&lt;/canvas&gt;
        &lt;canvas class="canvas" id="bob"&gt;&lt;/canvas&gt;
        &lt;input class="color" type="color" value="#000000" /&gt;
      &lt;/div&gt;

      &lt;style&gt;
        .wrapper {
          display: grid;
          grid-template-columns: 1fr 1fr;
          grid-template-rows: 1fr auto;
          gap: 1rem;
          margin: 2rem 0 3rem;
        }

        .canvas {
          grid-row: 1;
          width: 100%;
          aspect-ratio: 1 / 1;
          border: 0.25rem solid #eeeeee;
          border-radius: 0.25rem;
          cursor: crosshair;
        }

        .color {
          grid-column: 1 / span 2;
        }
      &lt;/style&gt;
    </span><span>`</span></span><span>;</span>
  <span>}</span>
<span>}</span>

customElements<span>.</span><span>define</span><span>(</span><span>"pixelart-demo"</span><span>,</span> PixelArtDemo<span>)</span><span>;</span></code></pre>
<p>Everything is nicely contained within this one file. There is that one import at the top, but it’s an <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules" data-astro-cid-bi7aps5f="">ES module import</a><a data-tooltip="" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules" data-astro-cid-bi7aps5f=""><img src="https://developer.mozilla.org/mdn-social-share.cd6c4a5a.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">JavaScript modules - JavaScript | MDN</span><span data-astro-cid-bi7aps5f="">This guide gives you all you need to get started with JavaScript module syntax.</span><span data-astro-cid-bi7aps5f=""><img src="https://developer.mozilla.org/favicon-48x48.cbbd161b.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> — it doesn’t rely on any sort of build system. As long as I keep all the files together, the browser will sort everything out.</p>
<p>Another nice thing about Web components is shadow DOM, which isolates the component from the surrounding page. I think shadow DOM is often awkward when you want to share styles between your components and the rest of your app, but it’s perfect when you do truly want everything to be isolated. Just like images and videos, these components will look and act the same no matter where they’re used.</p>
<p>Sorry — they’re not <strong>just</strong> like images and videos. Web components can expose attributes that allow you to configure them from the outside. You can think of them as native props. Voilà:</p>


<p>Two input ranges with different accent colors. In this case, I’m just setting a CSS variable, which is one of the few things allowed into the shadow DOM:</p>
<pre><code><span><span><span>&lt;</span>range-slider</span> <span><span>style</span><span><span>=</span><span>"</span><span><span>--accent</span><span>:</span> #0085F2</span><span>"</span></span></span><span>&gt;</span></span><span><span><span>&lt;/</span>range-slider</span><span>&gt;</span></span></code></pre>
<p>Here’s a more complex example:</p>
<pixelart-demo debug="true" resolution="20"></pixelart-demo>

<p>And here’s the markup. It uses attributes to alter the component’s behavior, setting the resolution to 20 and showing debug information on every pixel:</p>
<pre><code><span><span><span>&lt;</span>pixelart-demo</span> <span>debug</span> <span>resolution</span><span><span>=</span><span>"</span>20<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>pixelart-demo</span><span>&gt;</span></span></code></pre>
<p>If you were wondering what those calls to <code>getAttribute</code> and <code>hasAttribute</code> were doing in the web component class, now you know. This was particularly useful when reusing the same component for different stages of a tutorial, allowing me to enable certain features as the tutorial progressed.</p>
<p>The other part of the equation was using vanilla JS. There are frameworks that compile to web components — most notably Lit (although I’d call it more of a library) but also Stencil, Svelte, and probably others. I’m sure they’re all wonderful tools that would have made my life easier in a lot of ways. But frameworks are dependencies, and dependencies have a bunch of tradeoffs. In this case, the tradeoff I’m most worried about is maintenance.<sup><a href="#user-content-fn-vendoring" id="user-content-fnref-vendoring" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">4</a></sup></p>
<p>That goes for TypeScript, too. By my count, the last 15 versions of TypeScript have had breaking changes — many of them new features that I was happy to have, even though I had to change my code to accommodate them. But as much as I love TypeScript, it’s not a native substrate of the web. It’s still a dependency.</p>
<p>There’s a cost to using dependencies. New versions are released, APIs change, and it takes time and effort to make sure your own code remains compatible with them. And the cost accumulates over time. It would be one thing if I planned to continually work on this code; it’s usually simple enough to migrate from one version of a depenency to the next. But I’m not planning to ever really touch this code again unless I absolutely need to. And if I <strong>do</strong> ever need to touch this code, I <strong>really</strong> don’t want to go through multiple years’ worth of updates all at once.</p>
<p>I <a href="https://jakelazaroff.com/words/preserving-the-web/" data-astro-cid-bi7aps5f="">learned that lesson the hard way</a><a data-tooltip="" href="https://jakelazaroff.com/words/preserving-the-web/" data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/og/preserving-the-web.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Preserving the Web | jakelazaroff.com</span><span data-astro-cid-bi7aps5f="">jake.museum: an online collection of my web design and development work, from 2007 to the present day. But finding the source code was just the beginning. A lot has changed since 2007, and getting these old sites up and running again is not as simple as plopping the files on a server.</span><span data-astro-cid-bi7aps5f=""><img src="https://jakelazaroff.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jakelazaroff.com/words/preserving-the-web/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> when I built my online museum, wiping the cobwebs off of code saved on laptops that hadn’t been turned on in a full decade. The more dependencies a website had, the more difficult it was to restore.</p>
<p>I’ve been building on the web for almost 20 years. That’s long enough to witness the birth, rise and fall of jQuery. Node.js was created, forked into io.js and merged back into Node. Backbone burst onto the scene and was quickly replaced with AngularJS, which was replaced with React, which has been around for only half that time and has <strong>still</strong> gone through like five different ways to write components.</p>
<p>But as the ecosystem around it swirled, the web platform itself remained remarkably stable — largely because the stewards of the standards painstakingly ensured that no new change would break existing websites.<sup><a href="#user-content-fn-smooshgate" id="user-content-fnref-smooshgate" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">5</a></sup> The <a href="https://www.spacejam.com/1996/" data-astro-cid-bi7aps5f="">original Space Jam website</a><a data-tooltip="" href="https://www.spacejam.com/1996/" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Space Jam</span><span data-astro-cid-bi7aps5f=""><img src="https://www.spacejam.com/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">www.spacejam.com/1996/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> from 1996 is famously still up, and renders perfectly in modern browsers. So does the <a href="https://jake.museum/jakelazaroff-v1/" data-astro-cid-bi7aps5f="">first version of the website you’re reading now</a><a data-tooltip="" href="https://jake.museum/jakelazaroff-v1/" data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/jakelazaroff-v1-J5BRU2JR.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jakelazaroff.com v1 | JAKE.MUSEUM</span><span data-astro-cid-bi7aps5f="">A collection of visual and hypertext media.</span><span data-astro-cid-bi7aps5f=""><img src="https://jake.museum/public/favicon-6MX7OTNZ.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">jake.museum/jakelazaroff-v1/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, made when I was a freshman in college 15 years ago. Hell, the <a href="http://info.cern.ch/hypertext/WWW/TheProject.html" data-astro-cid-bi7aps5f="">first website ever created</a><a data-tooltip="" href="http://info.cern.ch/hypertext/WWW/TheProject.html" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">The World Wide Web project</span><span data-astro-cid-bi7aps5f=""><img src="http://info.cern.ch/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">info.cern.ch/hypertext/WWW/TheProject.html</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> — built closer to the formation of the Beatles <sup><a href="#user-content-fn-moonlanding" id="user-content-fnref-moonlanding" data-footnote-ref="" aria-describedby="footnote-label" data-astro-cid-bi7aps5f="">6</a></sup> than to today! — still works, in all its barebones hypertext glory.</p>
<p>If we want that sort of longevity, we need to avoid dependencies that we don’t control and stick to standards that we know won’t break. If we want our work to be accessible in five or ten or even 20 years, we need to use the web with no layers in between. For all its warts, the web has become the most resilient, portable, future-proof computing platform we’ve ever created — at least, if we build with that in mind.</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-cheating">
<p>I did cheat a little here. At the top of each post’s Markdown, I import and render an Astro component with a <code>&lt;script&gt;</code> tag that loads that post’s JS files. I could have put the <code>&lt;script&gt;</code> tag directly in the Markdown, but I would have had to store the JS files far away in Astro’s public directory. By permitting this small bit of framework-specific behavior, I was able to colocate the Markdown and JS files for each post. <a href="#user-content-fnref-cheating" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-frameworks">
<p>They might actually be just as nice if I’d used a library like <a href="https://lit.dev/" data-astro-cid-bi7aps5f="">Lit</a><a data-tooltip="" href="https://lit.dev/" data-astro-cid-bi7aps5f=""><img src="https://lit.dev/images/logo-whitebg-padded-1600x800.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f=""> Lit</span><span data-astro-cid-bi7aps5f="">Simple. Fast. Web Components.</span><span data-astro-cid-bi7aps5f=""><img src="https://lit.dev/images/flame-favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">lit.dev</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>. More on that in a minute! <a href="#user-content-fnref-frameworks" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-abridged">
<p>I omitted a bit, like the color input events and the network controls at the top. I wanted to be concise, while keeping enough to give you the gist of what’s going on. <a href="#user-content-fnref-abridged" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-vendoring">
<p>I briefly tried vendoring <a href="https://lit.dev/docs/libraries/standalone-templates/" data-astro-cid-bi7aps5f="">lit-html</a><a data-tooltip="" href="https://lit.dev/docs/libraries/standalone-templates/" data-astro-cid-bi7aps5f=""><img src="https://lit.dev/images/logo-whitebg-padded-1600x800.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">Using lit-html standalone – Lit</span><span data-astro-cid-bi7aps5f="">Simple. Fast. Web Components.</span><span data-astro-cid-bi7aps5f=""><img src="https://lit.dev/images/flame-favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">lit.dev/docs/libraries/standalone-templates/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>, the templating part of Lit — as in, copying the source code directly into my project. It worked, but conveniences like binding event handlers with <code>@click</code> felt a little too magical. That would have been fine if I were leaning into the library rather than trying to minimize the number of moving parts. Instead, I cobbled together a crude DOM diffing function based on work by <a href="https://gomakethings.com/dom-diffing-with-vanilla-js/" data-astro-cid-bi7aps5f="">Chris Ferdinandi</a><a data-tooltip="" href="https://gomakethings.com/dom-diffing-with-vanilla-js/" data-astro-cid-bi7aps5f=""><img src="https://gomakethings.com/img/og.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">DOM diffing with vanilla JS</span><span data-astro-cid-bi7aps5f="">A couple of weeks ago, we looked at how to build reactive, state-based components with vanilla JS.
 How to create a state-based UI component How to add reactivity to a state-based UI component with Proxies How to batch UI rendering for better performance  Today, we’re going to learn how to add DOM diffing to our component.
If you haven’t yet, go back and read the first three articles, or today’s won’t make a whole lot of sense.</span><span data-astro-cid-bi7aps5f=""><img src="https://gomakethings.com/img/favicon.ico" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">gomakethings.com/dom-diffing-with-vanilla-js/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a> and <a href="https://github.com/bigskysoftware/idiomorph" data-astro-cid-bi7aps5f="">Big Sky Software</a><a data-tooltip="" href="https://github.com/bigskysoftware/idiomorph" data-astro-cid-bi7aps5f=""><img src="https://opengraph.githubassets.com/a838a2cefe0467775a4de5231e12ee6dc6d86efe8be0b83723242ee4c7540a36/bigskysoftware/idiomorph" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">GitHub - bigskysoftware/idiomorph: A DOM-merging algorithm</span><span data-astro-cid-bi7aps5f="">A DOM-merging algorithm. Contribute to bigskysoftware/idiomorph development by creating an account on GitHub.</span><span data-astro-cid-bi7aps5f=""><img src="https://github.githubassets.com/favicons/favicon.svg" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">github.com/bigskysoftware/idiomorph</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>. <a href="#user-content-fnref-vendoring" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-smooshgate">
<p>Remember <a href="https://developer.chrome.com/blog/smooshgate/" data-astro-cid-bi7aps5f="">smooshgate</a><a data-tooltip="" href="https://developer.chrome.com/blog/smooshgate/" data-astro-cid-bi7aps5f=""><img src="https://wd.imgix.net/image/fuiz5I8Iv7bV8YbrK2PKiY3Vask2/iGPiWTtoy7iF932Xday1.png?auto=format&amp;w=1521" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">SmooshGate FAQ - Chrome for Developers</span><span data-astro-cid-bi7aps5f="">What can SmooshGate teach us about standards development and the Web Platform? This write-up gives an overview.
</span><span data-astro-cid-bi7aps5f=""><img src="https://developer.chrome.com/images/meta/favicon-32x32.png" alt="" onerror="this.remove()" data-astro-cid-bi7aps5f=""><span data-astro-cid-bi7aps5f="">developer.chrome.com/blog/smooshgate/</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"><use href="/icons.svg#share"></use></svg></span></a>? <a href="#user-content-fnref-smooshgate" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
<li id="user-content-fn-moonlanding">
<p>I was originally going to use the first Moon landing as a point of comparison, but that’s not even close. Neil Armstrong set foot on the Moon in 1969, 22 years before <code>info.cern.ch</code> was created in August 1991 — a date that is, as of today, over 32 years in the past! <a href="#user-content-fnref-moonlanding" data-footnote-backref="" aria-label="Back to content" data-astro-cid-bi7aps5f="">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The human body has 1.8T cells dedicated to defending it (132 pts)]]></title>
            <link>https://english.elpais.com/science-tech/2023-10-25/the-human-body-has-18-trillion-cells-dedicated-to-defending-it.html</link>
            <guid>38012380</guid>
            <pubDate>Wed, 25 Oct 2023 13:07:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/science-tech/2023-10-25/the-human-body-has-18-trillion-cells-dedicated-to-defending-it.html">https://english.elpais.com/science-tech/2023-10-25/the-human-body-has-18-trillion-cells-dedicated-to-defending-it.html</a>, See on <a href="https://news.ycombinator.com/item?id=38012380">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>To adequately defend ourselves against any pathogen that may enter our body, the cells of the <a href="https://english.elpais.com/usa/2022-01-04/how-our-immune-systems-killer-t-cells-may-be-protecting-us-from-severe-covid-19.html" target="_blank">immune system</a> must be in continuous movement, so that they <a href="https://english.elpais.com/science-tech/2023-05-18/chronic-inflammation-how-to-prevent-the-body-from-living-on-constant-alert.html" target="_blank">carry out surveillance</a> even in the remotest parts of our body. Non-specific immune cells (granulocytes, macrophages, dendritic cells, NK cells and mast cells, among others) are dispersed, but the specific cells involved are largely found in the secondary immune organs. This is where the presentation of the antigen and the stimulation of lymphocytes capable of recognition takes place.</p><p>The dispersed nature of the immune system raises three interesting questions that are very difficult to answer. How many immune cells are there in the human body? How many do we have in each organ? And what is their total weight?</p><p>A <a href="https://www.pnas.org/doi/10.1073/pnas.2308511120" target="_blank">recently published study</a> tries to answer these questions. Since it is impossible to count the cells one by one, the researchers opted for a three-pronged strategy.</p><p>Firstly, they carried out an extensive bibliographic review, collecting all available data regarding the presence of <a href="https://english.elpais.com/science-tech/2023-06-14/why-do-some-people-get-sick-less-than-others.html" target="_blank">immune cells in tissues</a>. Specifically, they tried to collect the different cell densities, that is, the number of cells per gram of tissue, in addition to histological data.</p><figure><span><img alt="Distribution of immune cells in the human body. Estimates of immune cell populations by cell type and tissue grouped by primary tissues and systems. GI stands for gastrointestinal tract." decoding="auto" height="395" srcset="https://images.english.elpais.com/resizer/rpIlT9bXqgKFO9yYejULG38umoE=/414x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/UM5UUUWVRNFD7CT6ZCKZNJWHUI.jpg 414w,https://images.english.elpais.com/resizer/6C8ZJF2X7DAJyRXGmTW2IG9_dVA=/828x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/UM5UUUWVRNFD7CT6ZCKZNJWHUI.jpg 640w,https://images.english.elpais.com/resizer/4_9ClubNIFMCAZq2VIW95xw6mng=/980x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/UM5UUUWVRNFD7CT6ZCKZNJWHUI.jpg 1000w,https://images.english.elpais.com/resizer/yWhAPahNxlC9hr-8fd0zVB5nvbI=/1960x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/UM5UUUWVRNFD7CT6ZCKZNJWHUI.jpg 1960w" width="414" loading="lazy" src="https://images.english.elpais.com/resizer/rpIlT9bXqgKFO9yYejULG38umoE=/414x0/cloudfront-eu-central-1.images.arcpublishing.com/prisa/UM5UUUWVRNFD7CT6ZCKZNJWHUI.jpg" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw"><svg viewBox="0 0 40 40"><use xlink:href="#svg-ampliar"></use></svg></span><figcaption><span>Distribution of immune cells in the human body. Estimates of immune cell populations by cell type and tissue grouped by primary tissues and systems. GI stands for gastrointestinal tract.</span><span>PNAS, CC BY-NC-ND</span></figcaption></figure><p>Second, they used multichannel cell imaging, a new technology that allows many biomarkers to be identified simultaneously. This allows complex tissues and cellular phenotypes to be recognized.</p><p>And, thirdly, they used deconvolution based on methylation patterns. Cellular deconvolution consists of estimating — using computational techniques — the proportion of cells that exist in a specific tissue. As each cell has a characteristic methylation pattern, the combination of both techniques allows researchers to identify the different cell subpopulations present in a sample.</p><h3>Billions of cells</h3><p>The use and cross-validation of these three techniques has allowed the authors to reach the conclusion that a prototypical person — historically characterized as a 20-30 year old male, weighing 73 kilos and standing 176 centimeters tall — has a total of 1.8x10¹² cells. That is, almost two billion (1.8 billion) cells. That’s a lot, especially if we take into account that muscle and adipose tissues constitute 75% of total body mass, but that, being very large cells, only represent 0.2% of all the cells in our body.</p><p>Most immune cells are located in two places: bone marrow and lymphatic tissue. Bone marrow contains 40% of that astronomical number of cells — with neutrophil accounting for 80%. A total of 39% of immune cells are located in the<a href="https://english.elpais.com/science-tech/2022-10-21/who-was-the-woman-who-discovered-a-virus-that-exists-in-95-of-humans.html" target="_blank"> lymphatic tissue</a>, with a significant predominance of lymphocytes. The skin, lungs and gastrointestinal tract each contain a modest 3% of the total.</p><p>Macrophages, which are poorly represented in many tissues, gather in the liver, where they represent 70% of the immune cells in this organ. Thirty percent of all NK cells also reside in the organ. Based on this, it is deduced that the liver plays an<a href="https://english.elpais.com/science-tech/2022-07-07/liver-experts-abstain-from-alcohol-at-least-three-days-in-a-row-every-week.html" target="_blank"> important role in the body’s immune response</a>, especially with regard to eliminating antigens that have entered through the digestive tract.</p><h3>More than a kilo</h3><p>The study also offers some surprising discoveries. For example, if the immune system were a solid organ, it would weigh 1.2 kilos. Or, in other words, it would have almost the same weight as the <a href="https://english.elpais.com/science-tech/2023-08-10/pere-gines-hepatologist-there-will-be-an-increase-in-cirrhosis-and-liver-cancer-cases-because-alcohol-consumption-has-not-been-curbed-and-neither-has-obesity.html" target="_blank">liver</a>, which is considered the largest and heaviest organ.</p><p>Of those 1.2 kilos, macrophages — which represent just 15% of the total immune cells — would weigh 600 grams. And the even scarcer dendritic cells would weigh another 100 grams. This is due to the large size of these two types of cells. In contrast, lymphocytes would weigh less than 200 grams, despite their high percentage, because of their small size. The mass of immune cells contained in the bone marrow and lymphatic tissue is the largest of all (30% and 27% of the total, respectively).</p><p>However, the biggest surprise concerns the gastrointestinal tract. Contrary to what was thought, only 3% of the total immune cells are located there, much less than expected. And it is also surprising that around 70% of the total plasma cells, which produce antibodies, are found in the digestive tract.</p><h3>Looking towards the future</h3><p>This study is significant because it combines multiple approaches to solve problems that cannot be approached directly, and that could be of interest to determine the number of cells belonging to other lineages.</p><p>More importantly, by giving us a global distribution of the cells of the immune system, we can<a href="https://english.elpais.com/science-tech/2022-05-17/latest-human-cells-atlas-reveals-more-of-the-unknown-world-inside-our-bodies.html" target="_blank"> better understand their global organization</a> and, therefore, how to modulate it to design innovative therapies.</p><p><i><b>Ignacio J. Molina Pineda de las Infantas</b></i><i>, professor of Immunology, Biomedical Research Center, University of Granada.</i></p><p><i>This article was originally published in </i><a href="https://theconversation.com/ya-sabemos-cuantas-celulas-inmunitarias-tenemos-216190" target="_blank"><i>Spanish in The Conversation.</i></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Loyal workers are selectively and ironically targeted for exploitation (394 pts)]]></title>
            <link>https://www.sciencedirect.com/science/article/abs/pii/S0022103122001615</link>
            <guid>38012263</guid>
            <pubDate>Wed, 25 Oct 2023 12:54:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022103122001615">https://www.sciencedirect.com/science/article/abs/pii/S0022103122001615</a>, See on <a href="https://news.ycombinator.com/item?id=38012263">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="preview-section-introduction"><h2>Introduction</h2><section id="s0005"><p id="p0010">Loyalty is a foundational moral principle, or virtue, that people usually value and aspire to embody in their social and business relations (Altman, 2008; Coughlan, 2005; Fiske, 1991, Fiske, 1992; Graham et al., 2011, Graham et al., 2013, Graham et al., 2018; Haidt &amp; Graham, 2007; Haidt &amp; Joseph, 2007; Reichheld, Markey Jr, &amp; Hopton, 2000; Shweder, Much, Mahapatra, &amp; Park, 1997; Souryal &amp; McKay, 1996; Van Kenhove, De Wulf, &amp; Steenhaut, 2003). Those who display loyalty to their countries, families, companies, religious organizations, sports teams, and other groups are publicly venerated (at least among their own group members), and the value placed on loyalty is emphasized in national oaths of allegiance, military and business mottos, anthems, literature, film, awards, and codes of conduct (Coleman, 2009; Connor, 2007; Hildreth, Gino, &amp; Bazerman, 2016; Kruger, 2021; Reichheld &amp; Teal, 2001; Souryal &amp; McKay, 1996). Individuals with reputations for loyalty (relative to those without such reputations) are considered to be better friends (Shaw, DeScioli, Barakzai, &amp; Kurzban, 2017), employees (Hirschman, 1970; McGinley &amp; Shi, 2022), and leaders (Fehr, Yam, &amp; Dang, 2015). Loyalty can also facilitate prosocial behavior by encouraging people to help others in their organizations and communities, and it can foster trust and cooperation among group members to achieve shared goals (Graham et al., 2011; Hirschman, 1970; Powers, 2000; Reichheld &amp; Teal, 2001; Rosanas &amp; Velilla, 2003). Disloyalty, in contrast, tends to elicit disgust, contempt, and moral outrage among observers, often damaging personal and professional reputations (Baumeister &amp; Leary, 1995; Haidt, 2003; McManus, Kleiman-Weiner, &amp; Young, 2020; Rousseau, 2001; Rozin, Lowery, Imada, &amp; Haidt, 1999).</p><p id="p0015">Decades of research across the fields of organizational behavior, psychology, evolutionary biology, and business ethics have identified numerous positive outcomes of loyalty and negative outcomes of disloyalty (Berry, Lewis Jr, &amp; Sowden, 2021; Haidt, 2003; Hirschman, 1970; Kruger, 2021; Powers, 2000; Reichheld &amp; Teal, 2001; Rosanas &amp; Velilla, 2003; Sinn &amp; Hayes, 2017; Van Kenhove et al., 2003). But is loyalty always beneficial? Although people tend to value loyalty as a moral virtue, it is possible that loyal people are disproportionately (and ironically) targeted for potentially harmful and unfair managerial practices in the contemporary workplace. Employing complementary methods and designs, we investigate whether and why loyalty could lead to deleterious consequences for those who are loyal. More specifically, we first investigate whether workers who have reputations for loyalty are perceived to be more exploitable, because loyal individuals are expected to make personal sacrifices for the objects of their loyalty.<sup>1</sup> We then investigate whether those employees who agree to poor treatment boost their reputations for being loyal. If workers are perceived to be more exploitable because of their reputations for loyalty and if agreeing to poor treatment boosts workers' reputations for loyalty, these bidirectional causal relations have the potential to create a vicious circle of suffering for certain workers.</p><section id="s0010"><p id="p0020">Researchers across different fields have examined several constructs related to loyalty that describe different components of interpersonal bonds and social relationships (e.g., feelings of attachment, commitment, identification, liking, love; Abrams &amp; Hogg, 1988; Brewer, 1999; Schrag, 2001; Mowday, Steers, &amp; Porter, 1979; O'Reilly &amp; Chatman, 1986; Mael &amp; Ashforth, 1992; Rubin, 1973; Seligman, Fazio, &amp; Zanna, 1980; Tajfel &amp; Turner, 1979; Scott, 1965; Sternberg, 1986). Much of what makes loyalty unique and distinct from related constructs is its inherent <em>moral</em> nature (Hildreth et al., 2016). That is, loyalty is a <em>moral</em> principle or virtue. The quintessential moral nature of loyalty is important because it creates a strong expectation, or perhaps even an obligation or imperative, to act in an individual's or group's interest, because it is the morally right thing to do (Hildreth et al., 2016).</p><p id="p0025">The inherent moral nature of loyalty is reflected in recent theorizing. For example, Shweder et al. (1997) argue that there are three distinct, cross-cultural “codes of morality” – community, autonomy, and divinity – that drive human action, with loyalty being central to the code of community. Drawing on insights from cultural anthropology, evolutionary psychology, and social psychology, <em>Moral Foundations Theory</em> (MFT) contends that loyalty is one of five innate foundations of morality that emerged to contend with scarce resources and social challenges (Graham, Haidt, &amp; Nosek, 2009; Graham et al., 2013, Graham et al., 2018, Graham et al., 2011; Haidt &amp; Joseph, 2007). Taking a social-relational approach to morality, <em>Relationship Regulation Theory</em> (Rai &amp; Fiske, 2011) posits four fundamental and distinct moral motives or obligations—unity, hierarchy, equality, and proportionality—that drive moral action, with loyalty being central in the motive/obligation for unity (see also, Fiske, 1991, Fiske, 1992). According to each of these theories, people take concerns about loyalty to exist within the purview of morality, and loyalty operates to bind our groups together, making them more cohesive and coordinated in ways that usually facilitate group success.</p><p id="p0030">Loyalty may give rise to an expectation that people should act in ways that favor the objects of their loyalty. Indeed, this expectation for action is built into Hirschman's seminal treatise on Exit, Voice, and Loyalty (Hirschman, 1970; see also, Barry, 1974) and the Attitude-Based Framework of Loyalty (Oliver, 1999). One specific kind of action that might be expected of the loyal is that they make <em>personal sacrifices</em> for the objects of their loyalty. That is, they might be expected to act in accordance with an individual's or group's interests, even when doing so comes at a personal cost. Several operationalizations of loyalty in business ethics explicitly refer to this expectation for self-sacrifice. For example, Elegido (2013) refers to loyalty as a “deliberate commitment to further the best interests of one's employer, even when doing so may demand sacrificing some aspects of one's self-interest beyond what would be required by one's legal and other moral duties” (p. 496). Hart and Thompson (2007) account of loyalty “involve[s] self-sacrifice in the face of alternatives” (p. 300). Schrag (2001) remarks that the loyal are expected to “sacrifice convenience or immediate advantage for the sake of the person or group or organization” (p. 45) (see also, Zdaniuk &amp; Levine, 2001). Due to the inherent moral nature of loyalty, self-sacrifice for the objects of one's loyalty should be considered as the morally right thing to do. This expectation for self-sacrifice may, therefore, take the form of an obligation or imperative. Although operationalizations of loyalty often come with an expectation for self-sacrifice, there is no empirical evidence linking loyalty to an expectation for self-sacrifice. We empirically investigate whether lay people expect the loyal to self-sacrifice for the objects of their loyalty.</p><p id="p0035">Over the past few decades, many different definitions of loyalty have proliferated both within and between fields. But a necessary precondition of any definition of loyalty is that at least two objects (e.g., individuals, groups, organizations) exist, with at least one being the object of loyalty. Most definitions of loyalty also involve <em>partiality</em> (i.e., favorable bias) toward an object (Brewer &amp; Brown, 1998; Hildreth et al., 2016; Hirschman, 1970; Oliver, 1999). Accounting for the inherent moral nature of loyalty, we broadly define loyalty as the moral principle of partiality toward an object, which gives rise to expectations (or perhaps obligations or imperatives) for action on behalf of the object of loyalty (e.g., self-sacrifice). See Hildreth et al. (2016) for a similar definition of loyalty.</p></section><section id="s0015"><p id="p0040">What exactly constitutes a case of exploitation? Many (now) illegal practices are clearly exploitative (e.g., sex trafficking) to the point of being self-evident. But in other cases, what counts as exploitative might be less clear, and people often disagree over whether specific cases of worker treatment are exploitative or not (Kim, Campbell, Shepherd, &amp; Kay, 2020; Mayer, 2007; Shelby, 2002). Much of the business ethics literature adopts a fairness-based account of exploitation, according to which exploitation occurs when an agent or entity <em>takes unfair advantage of</em> another agent or entity (Snyder, 2010; Wertheimer, 1996; Zwolinski, 2012). The (un)fairness of a transaction between agents/entities is typically measured by how the <em>benefits</em> resulting from the transaction are distributed (Wertheimer, 1996). Applied to an organizational context, it would be exploitative for management, representing the organization's goals and interests, to have some workers work excessively or engage in tasks unrelated to their job duties without extra pay or tangible reward (Kim et al., 2020). In such cases, workers are not rewarded for their behavior, and management receives all the benefits. In other words, management benefits at the expense of the workers.<sup>2</sup></p><p id="p0045">One might argue that it is not truly exploitative for managers to merely ask, but not require, certain workers to work excessively or to do tasks unrelated to their job duties without extra pay or tangible rewards. If workers are only asked, and not required, to work excessively or do tasks unrelated to their job duties without extra pay or tangible reward, then employees could still freely choose whether to acquiesce. In line with Kim et al. (2020), however, we argue that when there is a significant power difference between agents/entities in a transaction, agents/entities with less power may not feel free to decline the more powerful agent/entity's request. Applied to an organizational context, management controls outcomes necessary and vital to workers (e.g., promotion, job security, health insurance (at least in the U.S.), bonuses, etc.), so workers are put in a particularly vulnerable position when asked to do extra work or do tasks unrelated to their job duties without extra pay or tangible rewards. They may feel as though they can't decline such requests from management, or else they could be harmed.</p><p id="p0050">For our series of studies, we adapted materials from Kim et al. (2020) to ensure that we capture unfair transactions between management and their workers where management reaps the benefits at the expense of the workers. We make it clear that workers who work excessively or perform uncomfortable tasks unrelated to their job duties do not receive any extra pay or tangible reward. In our cases, management benefits at the expense of workers. The cases of exploitation used in our series of studies also count as exploitation under other theoretical accounts (e.g., vulnerability-instrumentalization views; Goodin, 1985, Wood, 1995).<sup>3</sup> But, more importantly, we also pre-test the cases of exploitation used in our studies to ensure that people tend to agree, on average, that they are exploitative. What matters most for addressing our hypotheses is that lay people tend to believe these cases of poor worker treatment are exploitative – not whether some particular normative, philosophical account is right.</p></section><section id="s0020"><p id="p0055">We have now characterized the central constructs under investigation – loyalty and exploitation. But what exactly is the relationship between loyalty and exploitation? We hypothesize bidirectional causal links between loyalty and exploitation that could create a vicious circle of suffering for contemporary workers. In one direction, we hypothesize that workers with reputations for loyalty (relative to other workers without such reputations) will be perceived as more exploitable in the workplace, because of the lay assumption that loyal people are readily willing to make personal sacrifices for the objects of their loyalty. Consider a manager who wants some additional work done. The manager intends to ask a worker to stay late to do extra work and to work on some of their upcoming vacation days, but the manager isn't offering extra compensation or any other reward for that matter. The manager intends to take unfair advantage of a worker, benefitting at the expense of the worker. On our account, the manager should presume that loyal workers would be particularly likely to do this extra work and work on their vacation days, because loyalty comes with an expectation for self-sacrifice to management (or to the organization as a whole). Staying late to do extra work and working on vacation days without compensation or any other rewards are, definitionally and quintessentially, self-sacrificing behaviors. In contrast, the manager shouldn't expect disloyal workers to self-sacrifice for the manager or for the organization as a whole; it seems improbable that they would agree to engage in potentially harmful and unfair practices that predominantly benefit management and the larger organization.</p><p id="p0060">We expect to find evidence corroborating the hypothesis that workers with reputations for loyalty (relative to other workers without such reputations) will be perceived as more exploitable, because of the assumption that loyal individuals are readily willing to make personal sacrifices for the objects of their loyalty. However, there is a case to be made for the competing hypothesis: that managers would attempt to protect or reward employees for their loyalty by <em>not</em> targeting them for exploitative practices. Hiring and retaining loyal employees is highly desirable to organizations (Hirschman, 1970; McGinley &amp; Shi, 2022), as loyal employees offer numerous benefits to management and the larger organization (Hirschman, 1970; Powers, 2000; Reichheld &amp; Teal, 2001; Rosanas &amp; Velilla, 2003). If managers are interested in retaining and motivating more desirable employees, they should presumably refrain from taking unfair advantage of them in ways that could cause them to suffer. They shouldn't treat loyal employees poorly by asking them to, for example, work on their scheduled days off or work late without reward. Our studies were designed to impartially adjudicate between these competing hypotheses.</p><p id="p0065">We not only expect to find evidence for a causal link from loyalty reputation to exploitation; we also expect that workers who agree to be exploited by management (relative to workers who refuse) will obtain stronger reputations for loyalty, due to the very act of agreeing to submit to exploitative practices. When a person acts in ways indicative of them possessing some trait, then that person should gain a reputation for possessing that trait (assuming others were exposed to the person's actions; Emler, 1990). So, when a person acts in ways that are indicative of loyalty toward some object and when other people see those actions, that person should acquire a reputation for being loyal. Consider a worker who has agreed to poor treatment in several ways over time: they have agreed to work late on several occasions and on many of their vacation days for no rewards. These are actions that are indicative of loyalty to management; they show partiality toward management at personal cost. The worker should, therefore, gain a reputation for loyalty.</p><p id="p0070">Despite the now considerable literature detailing positive outcomes of loyalty and negative outcomes of disloyalty (Haidt, 2003; Hirschman, 1970; Kruger, 2021; Powers, 2000; Reichheld &amp; Teal, 2001; Rosanas &amp; Velilla, 2003), evidence in favor of our hypotheses would suggest that those who seem loyal are more likely to suffer potentially harmful and unfair treatment in the workplace. Such evidence would call into question the value of loyalty, at least for certain individuals in certain contexts.</p></section><section id="s0025"><p id="p0075">Across four studies, we investigate whether loyal employees are selectively and ironically targeted by managers for exploitation in hypothetical scenarios, whether this targeting of loyal workers for exploitation is mediated by the expectation that loyal individuals are readily willing to make personal sacrifices for the objects of their loyalty, and whether those who agree (versus refuse) to be exploited in the workplace acquire stronger reputations for loyalty. To start, in Study 1, participants were presented with a worker who had acquired a reputation for loyalty, disloyalty, or neither loyalty nor disloyalty. We test whether managers express greater willingness to ask workers with a reputation for loyalty to be exploited than workers without such a reputation. Study 1 also probes mechanism, testing whether managers are more willing to ask loyal employees to be exploited because of the assumption that loyal people are readily willing to make personal sacrifices for the objects of their loyalty.</p><p id="p0080">Study 2 then tests for specificity of process. We do not expect a reputation for possessing just any moral virtue to encourage targeting for exploitation. Instead, we expect loyalty to be unique among moral virtues insofar as a reputation for loyalty (as opposed to other moral virtues) is what encourages managers to target workers for exploitation. To offer some evidence that loyalty is unique, we compare loyalty to two other common moral virtues that people usually value and aspire to exemplify – fairness and honesty. Loyalty, fairness, and honesty are all closely related moral virtues. Based on evidence coalesced across 20 countries, loyalty, fairness, and honesty all appear in Schwartz (1992) universal psychological structure of human values, with loyalty and honesty in the same value cluster of Benevolence and with fairness in the closely related neighboring cluster of Universalism. In addition, research and theory on moral identity and the self-concept consider virtues like loyalty, fairness, and honesty to be closely interconnected (Hildreth et al., 2016; Kihlstrom &amp; Klein, 1994) and central in people's constructed self-concepts (Aquino &amp; Reed II, 2002; Stanley &amp; De Brigard, 2019).</p><p id="p0085">Studies 3 and 4 reverse the causal pathway from loyalty reputation to exploitation, testing whether workers who agree (versus refuse) to be exploited are seen as more loyal in the eyes of managers. Assessing bidirectional causal links between loyal reputation and exploitation is important because evidence in favor of bidirectional causal links could be indicative of a vicious circle of harm and suffering for workers. Study 4 also tests whether the certainty with which managers believe that a case of poor worker treatment is exploitative predicts their judgments about the loyalty of employees who agree to be treated poorly. We expect that the more certain managers are that a practice is exploitative, the more loyal they will judge employees who agree to this poor treatment.</p></section><section id="s0030"><p id="p0090">For all studies, we report all exclusion criteria, all materials and conditions included, and all independent and dependent measures. We ensured ample power across studies by seeking at least 100 participants per condition after expected exclusions. In each study, the sample size was determined before any data analysis. To best address our hypotheses, we recruited samples of managers with at least one year of experience. These managers were not permitted to access more than one study. Studies 1, 2, and 4 were all formally pre-registered, and we did not deviate from these pre-registrations. De-identified data for all studies are publicly available (<a href="https://osf.io/ze9a2/?view_only=256ed8597c2446fcb52a67172a33ddbc" target="_blank" rel="noreferrer noopener"><span>https://osf.io/ze9a2/?view_only=256ed8597c2446fcb52a67172a33ddbc</span><svg focusable="false" viewBox="0 0 8 8" aria-label="Opens in new window" width="8px" height="8px"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a>).</p></section></section></div><div id="preview-section-snippets"><h2>Section snippets</h2><section id="s0035"><h2>Study 1</h2><p id="p0095">In Study 1, managers were randomly assigned to see a profile of a worker with a reputation for loyalty, disloyalty, or neither loyalty nor disloyalty (between-subjects manipulation). Managers then reported their willingness to ask the worker to work late several evenings for no reward and do uncomfortable tasks unrelated to their job duties for no reward. These are two common forms of contemporary workplace exploitation (Kim et al., 2020). We test whether managers are more willing to ask the</p></section><section id="s0075"><h2>Study 2</h2><p id="p0200">The results of Study 1 indicate that loyal employees are more likely to be targets of exploitative managerial practices in hypothetical scenarios (relative to employees with reputations for disloyalty and baseline controls), and that this targeting of loyal workers for exploitation is mediated by the expectation that loyal people are readily willing to make personal sacrifices for the objects of their loyalty. Study 2 extends Study 1 by assessing specificity of process. We expect loyalty</p></section><section id="s0100"><h2>Study 3</h2><p id="p0265">The previous studies offer consistent evidence that loyal employees are selectively targeted for exploitative managerial practices in hypothetical scenarios. That is, the previous studies offer causal evidence from loyalty reputation to exploitation. In Study 3, we experimentally investigate the reverse-direction of this process, testing whether workers who agree (versus refuse) to be exploited in the workplace subsequently acquire stronger reputations for loyalty. Study 3 was pre-registered (<a href="https://osf.io/dw65k/?view_only=8b2042b08ca644eeb39be03be9c5139a" target="_blank" rel="noreferrer noopener"><span>//osf.io/dw65k/?view_only=8b2042b08ca644eeb39be03be9c5139a</span><svg focusable="false" viewBox="0 0 8 8" aria-label="Opens in new window" width="8px" height="8px"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a></p></section><section id="s0125"><h2>Study 4</h2><p id="p0310">Study 4 has two aims. First, we attempt to conceptually replicate the central finding from Study 3 that workers who agree (versus refuse) to be exploited in the workplace subsequently acquire stronger reputations for loyalty. Second, we test whether the certainty with which managers believe that a case of poor worker treatment is exploitative predicts their judgments about the loyalty of those who agree to be treated poorly. We expect that the more certain managers are that a practice is</p></section><section id="s0150"><h2>General discussion</h2><p id="p0355">Across four studies, we found consistent support for our hypotheses. First, we found that loyal employees are selectively targeted by managers for exploitation in hypothetical scenarios (Studies 1–2), and that the targeting of these loyal workers is mediated by the expectation that loyal people are readily willing to make personal sacrifices for the objects of their loyalty (Study 1). These effects were specific to targets with reputations for loyalty (Study 2). We then found evidence for the</p></section><section id="s0160"><h2>Conclusions</h2><p id="p0400">Society has made some positive strides in formally outlawing egregious kinds of exploitation (Crane, 2013; Quirk, 2006; Wertheimer, 1996), but more subtle types of exploitation remain all too common (Kim et al., 2020). Insofar as exploitative managerial practices persist, certain workers will be targeted for exploitation. Although loyalty is typically touted as a moral virtue worth exemplifying, our research indicates that loyal workers are perceived to be more exploitable than other employees, </p></section><section id="s0165"><h2>Authorship statement</h2><p id="p0405">The submitted work is original and is the authors' own work. This manuscript is not under review at any other journal.</p></section><section id="coi0005"><h2 id="st0190">Declaration of Competing Interest</h2><p id="p0435">The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.</p></section></div><p><span>© 2022 Elsevier Inc. All rights reserved.</span></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: OpenAPI DevTools – Chrome ext. that generates an API spec as you browse (673 pts)]]></title>
            <link>https://github.com/AndrewWalsh/openapi-devtools</link>
            <guid>38012032</guid>
            <pubDate>Wed, 25 Oct 2023 12:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/AndrewWalsh/openapi-devtools">https://github.com/AndrewWalsh/openapi-devtools</a>, See on <a href="https://news.ycombinator.com/item?id=38012032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto"><a href="https://github.com/AndrewWalsh/openapi-devtools/blob/main/LICENSE.txt"><img src="https://camo.githubusercontent.com/111148992d0253f8d5e36b62087d48a9eabb1d7244b2b7316214f47d5c9a8781/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6f74686e65696c647265772f426573742d524541444d452d54656d706c6174652e7376673f7374796c653d666f722d7468652d6261646765" alt="MIT License" data-canonical-src="https://img.shields.io/github/license/othneildrew/Best-README-Template.svg?style=for-the-badge"></a></p>

<br>
<div dir="auto">
  <p><a href="https://github.com/AndrewWalsh/openapi-devtools">
    <img src="https://github.com/AndrewWalsh/openapi-devtools/raw/main/resources/logo.svg" alt="Open API dev tools" width="300" height="250">
  </a></p><div dir="auto"><p>
    Effortlessly discover API behaviour with a Chrome extension that automatically generates OpenAPI specifications in real time for any app or website.
    </p><p>
    
    <a href="https://github.com/AndrewWalsh/openapi-devtools/issues">Report Bug</a>
    ·
    <a href="https://github.com/AndrewWalsh/openapi-devtools/issues">Request Feature</a></p></div>
</div>
<h2 tabindex="-1" id="user-content-about-the-project" dir="auto"><a href="#about-the-project">About The Project</a></h2>
<p width="100%" dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AndrewWalsh/openapi-devtools/blob/main/resources/demo.gif"><img width="80%" src="https://github.com/AndrewWalsh/openapi-devtools/raw/main/resources/demo.gif" data-animated-image=""></a>
</p>
<p dir="auto">OpenAPI DevTools is a Chrome extension that generates OpenAPI specifications in real time from network requests. Once installed it adds a new tab to Chrome DevTools called <code>OpenAPI</code>. While the tool is open it automatically converts network requests into a specification.</p>
<p dir="auto"><em>Features</em>:</p>
<ul dir="auto">
<li>Instantly generate an OpenAPI 3.1 specification for any website or application just by using it</li>
<li>Automatically merges new request &amp; response headers, bodies, and query parameters per endpoint</li>
<li>Click on a <a href="https://www.abstractapi.com/api-glossary/path-parameters" rel="nofollow">path parameter</a> and the app will automatically merge existing and future matching requests</li>
<li>View the specification inside the tool using <a href="https://www.npmjs.com/package/redoc" rel="nofollow">Redocly</a> and download with a click</li>
</ul>
<p dir="auto">(<a href="#readme-top">back to top</a>)</p>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation</a></h2>
<p width="100%" dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AndrewWalsh/openapi-devtools/blob/main/resources/demo-img.png"><img width="80%" src="https://github.com/AndrewWalsh/openapi-devtools/raw/main/resources/demo-img.png"></a>
</p>
<ul dir="auto">
<li><a href="https://github.com/AndrewWalsh/openapi-devtools/raw/main/resources/dist.zip">Download and extract the zip</a></li>
<li>In Chrome, navigate to <code>chrome://extensions</code></li>
<li>In the top right enable the <code>Developer mode</code> toggle</li>
<li>In the top left click <code>Load unpacked</code> and select the extracted <code>dist</code> directory</li>
<li>Open a new tab and then select <code>OpenAPI</code> in the developer tools (open with <code>cmd+i</code> or <code>ctrl+i</code>)</li>
</ul>
<p dir="auto">(<a href="#readme-top">back to top</a>)</p>
<h2 tabindex="-1" id="user-content-usage" dir="auto"><a href="#usage">Usage</a></h2>
<p dir="auto">The specification will automatically populate based on JSON requests that fire as you browse the web. In the settings menu you can filter hosts and parameterise paths in URLs. Once you do so all matching existing and future requests to that endpoint will be merged. This process is irreversible, but you can clear the specification and restart at any time.</p>
<p dir="auto">When the same endpoint responds with different data, such as a value that is sometimes a string and sometimes null, the specification for that value will be <em>either</em> string or null. All information is accounted for in the final specification. If you see something missing from a request, trigger a request that contains the missing information.</p>
<p dir="auto">(<a href="#readme-top">back to top</a>)</p>
<h2 tabindex="-1" id="user-content-contributing" dir="auto"><a href="#contributing">Contributing</a></h2>
<p dir="auto">To develop the project:</p>
<ul dir="auto">
<li><code>npm install</code></li>
<li><code>npm run build</code></li>
<li>Navigate to <code>chrome://extensions</code></li>
<li>In the top right enable the <code>Developer mode</code> toggle</li>
<li>In the top left click <code>Load unpacked</code> and select the extracted <code>dist</code> directory</li>
<li>You should now see the tool in Chrome DevTools. You can interact it with like a regular page, including inspection of the React app.</li>
<li><a href="https://chrome.google.com/webstore/detail/extensions-reloader/fimgfedafeadlieiabdeeaodndnlbhid" rel="nofollow">Extensions Reloader</a> is suggested to update the tool after running <code>npm run build</code> and updating the <code>dist</code> directory</li>
</ul>
<p dir="auto">(<a href="#readme-top">back to top</a>)</p>


</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First malaria vaccine slashes early childhood mortality (334 pts)]]></title>
            <link>https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths</link>
            <guid>38012008</guid>
            <pubDate>Wed, 25 Oct 2023 12:20:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths">https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths</a>, See on <a href="https://news.ycombinator.com/item?id=38012008">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ArtistAssistApp – the web app to paint better with ease (149 pts)]]></title>
            <link>https://artistassistapp.com/</link>
            <guid>38011432</guid>
            <pubDate>Wed, 25 Oct 2023 10:53:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://artistassistapp.com/">https://artistassistapp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38011432">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>🖼️ Unleash your creativity</h2><p>Are you an artist who wants to improve your skills and create stunning artworks?</p><p>ArtistAssistApp is designed for artists of all levels and styles. <br>Whether you are a beginner or a professional, whether you prefer watercolor or oil paint, whether you like realistic or loose painting styles, whether you want to paint landscapes, portraits, still lifes, or anything else, you will find the tools for artists that suit your needs and preferences.</p><p>ArtistAssistApp is easy to use, interactive, and fun, try it today.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A note-keeping system on top of Fossil SCM (102 pts)]]></title>
            <link>https://github.com/rguiscard/fossil-notebook-demo</link>
            <guid>38011421</guid>
            <pubDate>Wed, 25 Oct 2023 10:51:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rguiscard/fossil-notebook-demo">https://github.com/rguiscard/fossil-notebook-demo</a>, See on <a href="https://news.ycombinator.com/item?id=38011421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h3 tabindex="-1" id="user-content-fossil-notebook" dir="auto"><a href="#fossil-notebook">Fossil Notebook</a></h3>
<p dir="auto">This is a note-keeping web app on top of Fossil SCM. It combines several tools and concepts:</p>
<ol dir="auto">
<li><a href="https://fossil-scm.org/" rel="nofollow">Fossil SCM</a>: version control, synchronization, web server with JSON api.</li>
<li><a href="https://johnnydecimal.com/" rel="nofollow">Johnny Decimal</a>: file organization method</li>
<li>Front Matter: for meta information</li>
<li><a href="https://mithril.js.org/" rel="nofollow">Mithril.js</a>: Javascript framework for front end</li>
</ol>
<h4 tabindex="-1" id="user-content-download" dir="auto"><a href="#download">Download</a></h4>
<p dir="auto">Download it from <a href="https://github.com/rguiscard/fossil-notebook-demo/releases/tag/demo">github</a></p>
<h4 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation</a></h4>
<p dir="auto"><a href="https://fossil-scm.org/home/doc/trunk/www/build.wiki" rel="nofollow">Install fossil</a>, better to compile with <code>--with-th1-docs</code>.</p>
<h4 tabindex="-1" id="user-content-run" dir="auto"><a href="#run">Run</a></h4>
<p dir="auto"><code>fossil server notebook-demo.fossil</code> and use browser to connect to &lt;fossil server ip&gt;:8080</p>
<h4 tabindex="-1" id="user-content-login" dir="auto"><a href="#login">Login</a></h4>
<p dir="auto">use demo:demo as user:password. Not necessary for reading.</p>
<h4 tabindex="-1" id="user-content-write-notes" dir="auto"><a href="#write-notes">Write notes</a></h4>
<p dir="auto">Use <code>fossil open</code> to create a local copy of repository. Add notes in markdown format inside local repository. Use <code>fossil addremove</code> if new files are added. <code>fossil commit</code> to commit.</p>
<p dir="auto">Read notes at <code>00-09.System/02.Documentation/</code> for more details.</p>
<h3 tabindex="-1" id="user-content-how-does-it-work" dir="auto"><a href="#how-does-it-work">How does it work</a></h3>
<p dir="auto">Fossil supports <a href="https://www.fossil-scm.org/home/doc/trunk/www/embeddeddoc.wiki" rel="nofollow">project documentation</a>. It basically serves as a web server for static files. A web app can be created as project documentation and served by fossil. Fossil also support <a href="https://www.fossil-scm.org/home/doc/trunk/www/json-api/index.md" rel="nofollow">JSON api</a> to read files inside repository. Therefore, this web app can access content in the fossil repository. The drawback is that web app cannot create files inside repository. But fossil also support wiki which is readable and wriable through its JSON api.</p>
<p dir="auto">In some sense, this can be seen as a highly <a href="https://www.fossil-scm.org/home/doc/trunk/www/customskin.md" rel="nofollow">customized skin</a> of Fossil SCM.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: PG's 'Do Things That Don't Scale' manual examples? (158 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38010992</link>
            <guid>38010992</guid>
            <pubDate>Wed, 25 Oct 2023 09:37:24 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38010992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38016704"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016704" href="https://news.ycombinator.com/vote?id=38016704&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>"Do Thinks That Don't Scale" is probably the <i>absolute heart</i> of my (bootstrapped, two-founder) company. Off the top of my head, we:<pre><code>   * Manually create pre-configured accounts for potential customers, sometimes with up to an hour of entering in their existing data so things look familiar right from first login.
    * Investigate problems and repair live data, usually just by logging in as a user and using the tools in the product. Can they do this themselves? Sure. Do they appreciate our doing it instead? Oh, hell yes.
   * Have screen-sharing calls where we walk customers through the process of linking our product with third parties (e.g. OAuth pairing with Square so they can process payments).
   * Call customers who are want help or advice with _other parts of their business_ that aren't related to our product, but about which we know something. Don't know what you should put in your vendor contracts or what % you should charge for sales commissions? Give us a call; we'll help you out.
</code></pre>
...plus probably dozens more that aren't fresh on my mind. We work flat-out to onboard every single customer, no matter how small, because word-of-mouth is our only growth channel and delivering a surprisingly human onboarding/support experience is the best way I know to generate great referrals. It doesn't scale, but it's also probably our main growth driver.<p>It'll work until it doesn't, I guess, but so far doing things that don't scale is <i>how</i> we scale.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38017119"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017119" href="https://news.ycombinator.com/vote?id=38017119&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>What you’re describing here is _good customer service_, which basically doesn’t scale at all ever (at least in any automated way). You provide more tools to expand the capability of CS, but at some point, you simply just have to hire more and more CS people.<p>This isn’t a knock by the way. Good customer service makes a customer feel like there’s someone just waiting at the company to help them. Kudos to you for providing that experience.</p><p>So while these aren’t great examples of “doing something that doesn’t scale (with the eventual goal of scaling)”, it’s a great example of “doing something that doesn’t scale (to provide a better product)”.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38017423"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017423" href="https://news.ycombinator.com/vote?id=38017423&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Based on every mega-scale consumer tech company, the best way to scale customer service is to make it as useless and frustrating as possible.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38017736"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38017736" href="https://news.ycombinator.com/vote?id=38017736&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Apple would be a notable exception. As would Amazon.<p>I think you’re referring specifically to Google and Facebook, and you’re right. I think the big difference is the amount of profit per customer.</p><p>Google and Facebook make a small amount from a large number of people so it makes sense that they could not profitably scale customer support. In the instances where they make a large amount of money off of a small number of people, mainly ad sales, their support is much better.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018460"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38018460" href="https://news.ycombinator.com/vote?id=38018460&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Apple and Amazon aren't event remotely in the same league.  Amazon chat agents use canned responses (probably due to being required to handle multiple customers at one time.) I've had one tech support/customer service interaction by phone with Apple and it was great - I needed my out of warranty MBP battery replaced. The agent was kind, knowledgeable, focused and took her time working with me to diagnose/confirm the issue and setup the return (they sent me a box &amp; label to send the MBP in for service.) I had my MBP back within 5 business days from the day they picked it up.  Apple is expensive, but they take phone support seriously.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38018398"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38018398" href="https://news.ycombinator.com/vote?id=38018398&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Even amazon seems to do a lot to err on the side of "automatically make the customer happy" rather than "actually have someone look into the problem" (I did a recent round of "order a three-pack, get a singleton labelled as a three pack, return for replacement, the replacement was also a singleton, return for refund" - they were prompt about the replacement, and prompt about the refund, very straightforward - but I actually <i>wanted</i> 6 of the items (and got someone else to not even order them to avoid dealing with this.) This is a pretty straightforward inventory problem, and I'm not convinced amazon even got any "signal" about it from the interaction.  (And after all, the alternate items I ordered... were still from amazon, so <i>they</i> don't have a problem either, really...)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38018465"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38018465" href="https://news.ycombinator.com/vote?id=38018465&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Apple is only good compared to the total garbage fire of MS/Google, and Amazon's support has been horrible for years now. If they don't have an automated answer to your problem you're SOL.I had them ship me the wrong item with the correct item's SKU taped on it and they argued with me for quite awhile before just refunding me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38018004"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38018004" href="https://news.ycombinator.com/vote?id=38018004&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I at least don't expect anything from FB.<p>I must also say Uber's CS is absolute garbage. I just cannot believe how bad they are. 
I have been unable to use uber for weeks and have been reaching out to them non-stop every few days. It is like speaking to a brick wall.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018364"><td></td></tr>
                        <tr id="38017779"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017779" href="https://news.ycombinator.com/vote?id=38017779&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>A more subtle aspect of customer service here is that, as the dev or PM responding to the customer, you have a lot more power to give the customer what they want.<p>A BigCo can hire a lot of CS people but the best they can do sometimes is "we hear you and we'll pass along your feedback".
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018206"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38018206" href="https://news.ycombinator.com/vote?id=38018206&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Alas, you’ve found the reason this won’t scale. Doing customer support as the CTO is a superpower (up to a point!) for both user growth and product design. But there’s going be to come a point where we have to hand some portion of support over to a dedicated support team, and no matter how well we train those folks they’re just not going to be quite as empowered and effective. The longer I can kick that can down the road, though, the better!<p>(At least for the business. My sleep schedule would improve amazingly!)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38017150"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017150" href="https://news.ycombinator.com/vote?id=38017150&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>You can also give the tools directly to the customers, and you can bundle/package the tools into future versions of the product.  A common pattern is to have a public git repo and the customers can git pull to get the latest versions of the support tools.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38018155"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38018155" href="https://news.ycombinator.com/vote?id=38018155&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Shipping tools as a git repository sounds delightful, at least to my engineering-minded heart. So painless! Free versioning! Rollbacks!<p>If we were in the devtools business I would certainly consider that. Sadly, though, owners of small retail businesses tend not to be as comfortable with version control as one might hope…
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38017306"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017306" href="https://news.ycombinator.com/vote?id=38017306&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I disagree: if you're a good product owner, it will aid with the goal of scaling.<p>For example, when you're sitting there walking them through something they could do alone, are you just playing back some script, or are you getting an understanding of where they went "aha!" and making note of how you can embed that aha moment into the product itself?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018121"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38018121" href="https://news.ycombinator.com/vote?id=38018121&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>You’ve found me out! Not only is it excellent customer service, it’s also priceless market research that I would be lost without. Side conversations during calls like that have led to more improvements and features (and in one case an entirely new side product) than I can possibly count.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38017722"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017722" href="https://news.ycombinator.com/vote?id=38017722&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>&gt; Investigate problems and repair live data, usually just by logging in as a user and using the tools in the product. Can they do this themselves? Sure. Do they appreciate our doing it instead? Oh, hell yes.<p>This is definitely one that doesn’t scale as eventually they don’t allow devs to see prod data, so using user accounts is a no go at my org for that reason.</p><p>Makes things infuriating for both clients and customer support.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018259"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018259" href="https://news.ycombinator.com/vote?id=38018259&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Not being allowed to see production data (or even in some cases see production!) was my greatest frustration in my last corporate job. But to be fair, keeping engineers off the live data was…pretty non-negotiable at most customers.<p>Which leads to some pretty boring days onsite, when “onsite” means “in the SCIF”
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018418"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38018418" href="https://news.ycombinator.com/vote?id=38018418&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>&gt; SCIF<p>Though there's a big sliding scale there, between "not allowed to look at prod user data for privacy/etc reasons" and "the giant black hole of nothing-comes-out" in a SCIF.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38018783"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018783" href="https://news.ycombinator.com/vote?id=38018783&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I run BenkoPhone which is the only business mobile number app in Australia that supports voice, txt and picture messages, currently 211 paid users in 50 different companies and $100k ARR.<p>The very first version was an old Android phone sitting on my desk that I connected to Trello for messaging and Bria for voice calls, for a handful of clients.</p><p>We later launched an app, but we didn't build the app ourselves we licensed it from a 3rd party vendor who does white labelling, and we used their demo version to sell the first corporate customer, who's setup costs paid for the white label one-off licensing costs.</p><p>Then we developed a proprietary, scalable hardware platform to manage the connections so we don't have to use Android phones anymore, but we still don't have our own VoIP stack, so when customers express interest in a free trial, we have to firstly contact each one to make sure they're genuine (almost all free trial requests are from scammers). Once they have tried the product, they put their details into DIFFERENT TypeForm, then we have to manually enter those details into our VoIP reseller platform and create the users and devices in the PBX, then we have to email our mobile carrier to provision the numbers because we don't have a direct wholesale connection yet.</p><p>That whole process can be automated once we have a different VoIP platform and have wholesale carrier connections.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018703"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018703" href="https://news.ycombinator.com/vote?id=38018703&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Just remember to automate the manual process at some point.<p>from <a href="https://allenpike.com/2023/dialup-world-isp" rel="nofollow noreferrer">https://allenpike.com/2023/dialup-world-isp</a>:</p><p>"1. When a customer submitted their signup form to Dialup World, they would add a row for that new customer to their 20,000-row Excel spreadsheet.</p><p>2.Then, they would put that signup form in a pile with all the other signup forms of customers who had signed up on that day of the month.</p><p>[billing steps removed]</p><p>5. When a customer called to cancel their service, they would stop that customer from being billed further by simply – I shit you not – finding that customer’s signup form and trashing it. No signup form in the pile, no more bills going out.</p><p>You gotta hand it to these people. The seminal startup essay “Do Things that Don’t Scale” didn’t come out until 2013, and these legends were doing things that didn’t scale way back in the late 90s. They got 20,000 signups billed with the process equivalent of a shoelace and a discarded sauce packet."</p><p>Assuming they distributed the signup forms evenly amongst the 20 working days of a month, that would mean the billing group would have 1,000 bills to handle each day. Slogging day in, day out, forever. Might as well have named the group/department Sisyphus.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38016896"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016896" href="https://news.ycombinator.com/vote?id=38016896&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Some examples:<p>- The Airbnb founders took photographs for listings themselves.</p><p>- ProductHunt started out as a newsletter, with the founders themselves hunting and curating products.</p><p>- Reddit founders submitted links (wrote comments?) everyday using different usernames, to get the community going.</p><p>- Dropbox launched with a video demonstration and an email signup page to gauge viability. The product wouldn't be ready for another year, iirc.</p><p>- Doordash was a single webpage with a phone number (and 5 students?), serving just Palo Alto.</p><p>- Meesho was a WhatsApp group (one of the few teams in the batch that failed to raise money on <i>Demo Day</i>, afaik).</p><p>- Segment was a single javascript file viz. <i>analytics.js</i>.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38017917"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017917" href="https://news.ycombinator.com/vote?id=38017917&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>&gt; - ProductHunt started out as a newsletter, with the founders themselves hunting and curating products.<p>I can't remember if it was product hunt or not, but there was one such site that actually started as a way for the developer to feed attention to their other startup. Turned out producthunt (or whatever one I'm thinking of) became successful instead.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38017013"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017013" href="https://news.ycombinator.com/vote?id=38017013&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Further to your doordash example, I believe many of delivery sites simply took the online order, then called the restaurant themself to order the food. This however lead to some issues where restaurants were getting from complaints from customers they didn't know they had. They also had different pricing from the online companies.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38018817"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018817" href="https://news.ycombinator.com/vote?id=38018817&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Back in the stone age, lastminute.com would fax the customer's details through to the theatre so they could pick up their tickets at the box office.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38017745"><td></td></tr>
                <tr id="38017928"><td></td></tr>
                        <tr id="38018005"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38018005" href="https://news.ycombinator.com/vote?id=38018005&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>This is a great list. I could be wrong but I believe that some early version of Dropbox was usable not too long after the demo.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38017161"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017161" href="https://news.ycombinator.com/vote?id=38017161&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>I manually review the ~3000 or so domains in Marginalia Search's random exploration mode every once in a blue moon.  Takes like a solid afternoon but I'll be damned if it doesn't improve the experience quite a lot.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38017707"><td></td></tr>
                  <tr id="38016642"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016642" href="https://news.ycombinator.com/vote?id=38016642&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>If you're interested in this area, Lean Startup (book or general resources from that area) might be helpful. One example from the [Wikipedia Page](<a href="https://en.wikipedia.org/wiki/Lean_startup" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Lean_startup</a>):<p>&gt; As an example, Ries noted that Zappos founder Nick Swinmurn wanted to test the hypothesis that customers were ready and willing to buy shoes online. Instead of building a website and a large database of footwear, Swinmurn approached local shoe stores, took pictures of their inventory, posted the pictures online, bought the shoes from the stores at full price after he'd made a sale, and then shipped them directly to customers. Swinmurn deduced that customer demand was present, and Zappos would eventually grow into a billion dollar business based on the model of selling shoes online.</p><p>It also is very common for "AI" startups to have the AI just be manual work, though this can be controversial: <a href="https://www.404media.co/kaedim-ai-startup-2d-to-3d-used-cheap-human-labor/" rel="nofollow noreferrer">https://www.404media.co/kaedim-ai-startup-2d-to-3d-used-chea...</a></p><p>We also definitely did it in the early days of my non-profit — we wanted to build a very optimized public records submission platform that handled mail, fax, etc., but in our early days I literally hand delivered records requests, which was super helpful from learning but at $2 per request was a huge money-not-maker.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38017671"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017671" href="https://news.ycombinator.com/vote?id=38017671&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span><i>&gt; We also definitely did it in the early days of my non-profit</i><p>We are in Phase One testing of our NPO flagship.</p><p>It has been designed as a native Swift iOS-only app (but the backend will feed anything).</p><p>It also has a few design "tricks" that probably won't scale to millions, but has been tested with tens of thousands (of fake users). They make it lightning fast, and it will be a sad day, if I have to sideline them, in the future.</p><p>We sign up users manually, one at a time. I'm developing a dashboard, to lubricate that process, but it will still be manual.</p><p>Fortunately (for us, but many for-profits would hate it), I think it will be a long time, before we get to the point where matters of scale become an issue. We Serve a small, demanding, demographic.</p><p>Also, we don't collect PID. Extreme privacy and security are a big part of our model. I deliberately avoid a lot of the dependencies that could introduce issues.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018658"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018658" href="https://news.ycombinator.com/vote?id=38018658&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>&gt; [EDIT] Heh. I find it absolutely fascinating that this post, describing our own small, non-threatening, NPO app, has already earned a ding.<p>There's a barrier to being able to downvote, but the only downvotes I actually see on HN seem like they're given in bad faith.  I'd love an option to turn off displaying downvoting at all since it's never useful to me; from my perspective random comments just fade off a page, usually in the middle of a thread.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018563"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018563" href="https://news.ycombinator.com/vote?id=38018563&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>If I had to guess, you're being dinged because this is your only contribution to the conversation about doing things that don't scale is: "We sign up users manually, one at a time."</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38018792"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38018792" href="https://news.ycombinator.com/vote?id=38018792&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Actually, I suspect because the original version mentioned that the way we do things was not going to be popular with profit-seekers. It was a bit petty, and I removed it.<p>Otherwise, it is absolutely relevant to the topic at hand. I described:</p><p>1) Native iOS-only (not something that will necessarily scale. A large part of our demographic uses Android, and I am regretful that we don't Serve them, but I don't write Android, and don't want to use a hybrid system or PWA)</p><p>2) Uses "tricks" to improve performance (I mention these may not scale into the millions. An example is loading a fast list of minimal info on all the users on the system, so we don't have to do realtime searches)</p><p>3) We do sign up users manually (BTW: <i>lots</i> of other posts, here, say pretty much exactly the same thing).</p><p>But it may be because I mention that we don't collect PID, and that I eschew dependencies. These postures don't play so well, in today's tech industry.</p><p>But our app will be great. It absolutely Serves its users well, and we're already getting a great deal of positive feedback (We've only been testing since Monday). My main concern is that we may have to scale sooner than I expected.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38018890"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018890" href="https://news.ycombinator.com/vote?id=38018890&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>I once sent a snail mail letter from my little company to one of our subscribers in another country who was having trouble and emailed us about it several times but was apparently not receiving our email replies. It worked. :-)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38016706"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016706" href="https://news.ycombinator.com/vote?id=38016706&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I'm building a new product for farm monitoring (IoT device that monitors soil moisture and other enviro/climate conditions). I spent a whole lot of time in the past few weeks hand-soldering circuit boards using prototype boards (one step up from breadboards), then drove ~10 hours to a remote town to install them on farms and stayed around for a few days to get/keep them working.<p>By doing that I not only ensured they were up and running in good shape, but I learned what it's like to be the person installing and maintaining them. We have an installer in town who made the into to that customer, but for this new product it was a big learning experience to be there, doing it myself.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38016870"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38016870" href="https://news.ycombinator.com/vote?id=38016870&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I'm genuinely curious if you could elaborate a little bit more, thanks.<p>I always thought about a product like that in my area but the "features" you mentioned (soil/climate conditions monitoring) are pretty simple, so I wonder if you're still able of finding a market (fit) for products like that, that "anyone" could build. Are you able to find customers, which I assume is B2B?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018639"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018639" href="https://news.ycombinator.com/vote?id=38018639&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Markets exist for just about anything. The hard part is finding them.<p>For example: one of the simplest things I've built this year is a device that reads an input and then turns on an LED and sends a message to a connected app (I didn't write the app) when the input changes state.</p><p>After I shipped the first one, the customer came back and asked for 10 more and they expect that over time they may need about 100 or so. I can do stuff like this all day long: it's technologically trivial, but world-altering to the people who need it.</p><p>My main problem is getting people who need these little machines to know how to find me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38018587"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38018587" href="https://news.ycombinator.com/vote?id=38018587&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>&gt; We have an installer in town who made the into to that customer<p>Excuse me? Could you please rewrite that one?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38017262"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017262" href="https://news.ycombinator.com/vote?id=38017262&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>If it doesnt work for B2B then you should make one for plants at home (i've been looking for a bluetooth-like "this plant needs watering" thingy for a while and haven't found a good choice).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38018708"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018708" href="https://news.ycombinator.com/vote?id=38018708&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>The "problem" with that is that typically an item that a business will happily pay $200 for can only be sold to a home customer for $10. Selling consumer items is a good example of things that <i>require</i> scale.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38017828"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017828" href="https://news.ycombinator.com/vote?id=38017828&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I've been happy with our "North Flower Care" BLE plant monitor. Monitors light (which is not useful IMO for an indoor plant), moisture, temperature, and soil fertility. There's a companion app that can record the data and correlate it with what the plant you've configured finds ideal.<p>I paid $11 for it, which is a lot more reasonable than the current $30, but if it helps a plant you like grow... I don't actively monitor it with an automation, but I recall poking at it with one of the NRF apps and seem to recall that the data format was open enough that you could monitor it outside the official app.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018310"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018310" href="https://news.ycombinator.com/vote?id=38018310&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Xiami Flora should be good enough and widely supported (Home Assistant and similar). Sends simple BLE packets.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38017345"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017345" href="https://news.ycombinator.com/vote?id=38017345&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Ecowitt sensors are well done in my experience and they have a soil sensor product.  Works with HomeAssistant too.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38018190"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018190" href="https://news.ycombinator.com/vote?id=38018190&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I had a product to help political campaigns canvas neighborhoods door to door.  In the early days there was a "smart walk sheet" feature, which would magically pick the optimal doors to knock given how much time you had (e.g. 2 hours after work).<p>While I was building out this feature, I'd stay up late in the night manually selecting clusters of houses and setting them for the customer, so the next morning they'd be greeted with what looked like our backend systems auto-magically picking the perfect cluster of houses.</p><p>The bonus of doing it manually for a while is that I found a lot of edge cases I would have missed otherwise.  The initial release of the finished feature was rock solid thanks to what I learned.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018711"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018711" href="https://news.ycombinator.com/vote?id=38018711&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>I violate DRY all the time in terraform. My process is roughly to write something that resembles a module, and when I need it again, I copy all the code and just change relevant variable values and see how it behaves. if I need to copy again a 3rd or 4th time, usually by that point I will have learned things that allow me to make a much better module/library than if I had relentlessly and mindlessly followed DRY.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38016667"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016667" href="https://news.ycombinator.com/vote?id=38016667&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>I build synthetic DNA. In the beginning (and still) I do a ton of steps by hand that I’ve slowly been moving to robots. Hours and hours at a bench picking colonies, designing sequences by-hand for customers instead of using software, writing robotic scripts for one particular customer’s needs, that kinda of thing</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38016639"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016639" href="https://news.ycombinator.com/vote?id=38016639&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I'm in a pretty low tech industry but that mindset basically describes every system I've built.<p>The original sin of Software Engineering is building a really well architected system that solves the wrong problem.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38016893"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016893" href="https://news.ycombinator.com/vote?id=38016893&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>For a time, I emailed every B2C customer who signed up. I welcomed them, asked where they heard about BeeLine, and told them if they ever had any questions they could email me directly.<p>Most people didn't engage, but some did. I was able to nip some onboarding issues in the bud, and develop some evangelists as well.</p><p>Some bigger companies automate this, but I always found it feels weird coming from a big company. I was always careful to put "founder" in my email signature, so the recipient knew it was coming from me. And I never sent the email right after they signed up, which might make it seem automated — even though it wasn't.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38016702"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016702" href="https://news.ycombinator.com/vote?id=38016702&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I have a small side project where I scrape a Finnish news site and generate high quality flashcards from its content for fellow language learners in the form of a daily email. I sell bulk access to the back catalogue for more serious learners.<p>I don't want to pay any cloud costs, so all the scraping, flashcard creation, etc are just shell scripts on cronjobs that runs every hour or so on my personal laptop. The back catalogue is persisted to my other devices via Syncthing, instead of living in S3. I give the deck a manual review every day before I send it off, which I guess also counts as dogfooding.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38017966"><td></td></tr>
            <tr id="38018759"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018759" href="https://news.ycombinator.com/vote?id=38018759&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>In ETL work I often come across a nightly job that is harder to implement than most for some snowflakey reason, and I just start my day doing it manually, which might just take a minute. At some point I will get so annoyed that I will take the time to figure it out properly.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38016909"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016909" href="https://news.ycombinator.com/vote?id=38016909&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>When reddit first started, all merch was hand packed by Alexis with a note in it.  At one point he sent us a stack of 1000 postcards and made all of us sign them, and then used those to pack the merch.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38017696"><td></td></tr>
                <tr id="38018540"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38018540" href="https://news.ycombinator.com/vote?id=38018540&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I'm unclear what you are asking.  What does "it" refer to here?<p>The postcards went in with the merch and that package was sent to the person who bought the merch.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38017955"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38017955" href="https://news.ycombinator.com/vote?id=38017955&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>I got a snoo car sticker back in like '08 or '09 in a regular envelope type thingy, IIRC.  I think I just asked for one?  Maybe it was a form, IDK.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38017185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017185" href="https://news.ycombinator.com/vote?id=38017185&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>When looking for early users for a new product, it’s usually better to reach out directly to people one at a time or post in small communities like niche subreddits rather than trying to do a big launch on HN or ProductHunt with the hope of getting a lot of users all at once.<p>Ditto for more “scalable” marketing like ads or PR. It’s (usually) best to save those until after you have a core group of happy engaged users that you cultivated by hand.</p><p>There are exceptions where people do the big launch or large-scale marketing right away and it works, but the risk of failure with that strategy is high.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018282"><td></td></tr>
            <tr id="38016707"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016707" href="https://news.ycombinator.com/vote?id=38016707&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I was an early hire at a computational reproducibility startup for scientists  [0]; the platform was basically an online frontend wrapped around a Docker container hosted on AWS, and the idea was that you'd put your code and data on the platform and have it be online-executable indefinitely, so you wouldn't have to worry about package updates, functions breaking, etc., because it was containerized.<p>The long-term goal was that scientists would describe their native software environments at a high level, and then the machine would build a Docker container that matched. In practice, your typical academic has no experience with containers/Linux/system-level dependencies. To prevent their walking away, I basically set up their software environments for them on an individualized basis when they reached out to us through intercom.</p><p>As PG says elsewhere, one of the main advantages of an early-stage startup is they can devote an insane level of attention to early users.</p><p>[0] <a href="https://codeocean.com/" rel="nofollow noreferrer">https://codeocean.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018737"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018737" href="https://news.ycombinator.com/vote?id=38018737&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Someone may have said it, but the DoorDash guys acted as their first drivers until they couldn't anymore</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38017061"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017061" href="https://news.ycombinator.com/vote?id=38017061&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>My first employer is now a decently well known B2B SaaS and we didn't build user interfaces to manage various settings for a very long time. For example, we supported custom fonts, but we would have to jack into production to upload them and manually configure the database to make them available to a given customer. That ability didn't become customer-facing for a decade, simply because it was easier to file a ticket and make an SRE do it.<p>This is a little tangential but another good piece of advice is to avoid over optimization of the engineering stack. A giant monolith running on the largest RDS instance AWS provides a lot more runway than people realize.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018157"><td></td></tr>
            <tr id="38017257"><td></td></tr>
            <tr id="38018452"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018452" href="https://news.ycombinator.com/vote?id=38018452&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>TL;DR: my co-founder and I hosted hundreds of 1-hour co-working sessions ourselves.<p>In the early days of what is now Flow Club, my co-founder and I had built several apps to try to help us stay in touch with busy 30+-year-old friends. It was tough to get any friends to even install the apps we made on Testflight, much less use them. They were busy with work or family (and the apps just weren't compelling enough).</p><p>We started asking friends to come work together on Zoom (during the pandemic) like we used to do at coffee shops. We wanted to add some structure to these, so we made them 1-hour co-working sprints with a screen-shared pomodoro clock and agenda (5 minutes to share goals, 50 minutes of working, 5 minutes to check in), sent out the Zoom links to friends, and then started pre-committing to times at the beginning of each week and sending that out to an email list. Within a month, we had hosted a couple hundred of these sessions between the two of us and couldn't keep up with the demand or requests for more times of day as it spread to friends of friends. When an early user who we didn't know IRL and then my partner each separately asked if they could also host sessions, we were blown away. We didn't think anyone else would want to volunteer to host. Then when we realized both of them were actually better "hosts" than we were, a lightbulb came on for us that we could stop doing the unscalable thing we had been doing and build for hosts.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38018013"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38018013" href="https://news.ycombinator.com/vote?id=38018013&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>If you read the other essays he also says you do things manually as the founder first to learn the specifics that matter but then you scale it (typically by hiring someone, or via code) when you have learned very well how it should scale.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38017249"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017249" href="https://news.ycombinator.com/vote?id=38017249&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>When I founded my bootstrapped startup, I would go as far as opening PR's within the customer's codebase to integrate our dev tool on their behalf.<p>But most common one is probably pricing. Start out with cheap (or free) pricing to capture early adopters, even if it's not economical long-term. If/when you gain traction and momentum, gradually increase prices until the unit economics make sense.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38017528"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38017528" href="https://news.ycombinator.com/vote?id=38017528&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>One problem with cheap or free is that when you are trying to validate your product, a user paying you good money is far more validation that a free user.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38016673"><td></td></tr>
            <tr id="38017041"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017041" href="https://news.ycombinator.com/vote?id=38017041&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>There was an online car sales startup years ago where they put up the web page and ordering stuff before getting any buying or delivery stuff in place. When they got their first order, the boss said "well, go buy the car!"</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38017516"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017516" href="https://news.ycombinator.com/vote?id=38017516&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>I had understood it more as an abstract lesson than an instruction. ie avoid a mindset of everything must scale or we don’t do it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38016564"><td></td></tr>
                <tr id="38016685"><td></td></tr>
                <tr id="38017187"><td></td></tr>
                <tr id="38017425"><td></td></tr>
                <tr id="38018154"><td></td></tr>
            <tr id="38017532"><td></td></tr>
                        <tr id="38016806"><td></td></tr>
                <tr id="38017060"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38017060" href="https://news.ycombinator.com/vote?id=38017060&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>You're not looking at it right. The JSON document is your DB. Wanna add another client config? Your client manager makes a PR with the changes and your CI deploys it with the server binary. Easy peasy no-code solution.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38017626"><td></td></tr>
                              <tr id="38016626"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38016626" href="https://news.ycombinator.com/vote?id=38016626&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>You should have an internal UI around it. This should take all of a couple minutes... if this takes longer than that then you have other problems and adding any features at all is probably taking forever.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38016943"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38016943" href="https://news.ycombinator.com/vote?id=38016943&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>not having a preferences UI isn't just about the time to build the UI, it's about control, QA, and feedback.  If your customer has to communicate with you to get a feature enabled, it gives you a chance to talk to your customer and get a sense of what they need the feature for, if it will work for their use case or the data they're working with, or if there's better features to offer them instead to solve their problem.  it avoids the issue where customers randomly click buttons to see what happens, and then get disappointed when the thing they imagined might happen isn't what actually happens.  And it makes them feel special because you've turned something on just for them.<p>by all means, build a UI.  but click the checkboxes yourself.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38016982"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38016982" href="https://news.ycombinator.com/vote?id=38016982&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Yes - it should be an internal thing for people on the front line, because you're likely going to be turning on features and stuff.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38016793"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38016793" href="https://news.ycombinator.com/vote?id=38016793&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>A simple graphical DB client is often a perfectly fine UI. Everything depends on the details, of course.<p>If this saves a month of defining and building a bunch of admin preference screens, letting you focus your one developer on things that matter, that can mean everything for a small startup.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38016975"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38016975" href="https://news.ycombinator.com/vote?id=38016975&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>what??? a month??? for an internal preferences/flags UI? See, this is what I mean. You've already failed. You cannot execute.<p>Also now you're gonna make customer support folks edit the DB?</p><p>- With Django, this is generated for you. It's literally free.</p><p>- With DotNet Core, also can be generated.</p><p>- Pretty sure Spring MVC has something similar.</p><p>- With Rails - can also be generated, or built very quickly with Hotwire.</p><p>- With React, this takes a couple minutes. Just have a generic "flags" list you can toggle etc. There are like a million form generation libraries.</p><p>At the end of the day if it takes you a week to get a UI with a list of buttons and checkboxes out, you need to rethink the technologies and process you're using if you're trying to move fast. You should probably do away with the process, too, for this early of an organization.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38018395"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38018395" href="https://news.ycombinator.com/vote?id=38018395&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>For Spring I find <a href="https://bootify.io/" rel="nofollow noreferrer">https://bootify.io</a> does a great job of generating DB, models, CRUD frontend+backend. Not open source but the basic variant is free (and I mean really free to use, no registration, just use it) and the code generated is reasonable for further development.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38018148"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38018148" href="https://news.ycombinator.com/vote?id=38018148&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I like your vibe. Execution &gt; Idea.<p>It's def true for so many startups that they are really really slow in execution.</p><p>You need to find developes that execute and not talk about 2 hours in a retrospective about clean code.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38017279"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38017279" href="https://news.ycombinator.com/vote?id=38017279&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>&gt; Also now you're gonna make customer support folks edit the DB?<p>The founders aren't regular customer support folks.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                    <tr id="38017401"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017401" href="https://news.ycombinator.com/vote?id=38017401&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>basically you can do manually everything that could be automated, and should be automated if high volume.<p>- Manually send user welcome email, trial expiration email, etc...</p><p>- Manually fix some errors although the process could be automated.</p><p>- Manually cleanup logs, db tables, etc...</p><p>- Manually check every service, db, website, etc... is up
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38017420"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38017420" href="https://news.ycombinator.com/vote?id=38017420&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>I honestly feel like this advise was applicable 10 years ago when it was written. Especially int he age of AI, but it's really going to depend on the business you're in, if you're business is automated business intelligence, vs mail order bbq sauce or something.<p>Not to mention the greater number of tools opensource and paid available to automate most of the stuff that would take a dev a little longer to do.</p><p>But also from a technical standpoint, if it's a 1 or 2 time task, and it's quicker to do manually, don't bother automating it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38016970"><td></td></tr>
            <tr id="38016633"><td></td></tr>
                <tr id="38016993"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38016993" href="https://news.ycombinator.com/vote?id=38016993&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>Reminds me of how Notion ran on a single database for a very very long time, and everything started breaking.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38016734"><td></td></tr>
            <tr id="38016646"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38016646" href="https://news.ycombinator.com/vote?id=38016646&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><br><div>
                  <p><span>to me its marketing, sales, and support. things that i avoid learning and doing when thinking that "if i build the product the users will come".</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38018229"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38018229" href="https://news.ycombinator.com/vote?id=38018229&amp;how=up&amp;goto=item%3Fid%3D38010992"></a></center>    </td><td><p><span>Is that not the biggest problems for software developers? 
Believing that users come if they have the right product?<p>You need feedback to create the product and you get feedback by having customers - so go out and sell your product</p><p>(Its prop not right for all cases but in general )
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38017088"><td></td></tr>
            <tr id="38017559"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brisk 22-minute walk could offset harmful effects of sitting, study suggests (207 pts)]]></title>
            <link>https://www.theguardian.com/society/2023/oct/24/brisk-minute-walk-offset-harmful-effects-sitting-study</link>
            <guid>38010391</guid>
            <pubDate>Wed, 25 Oct 2023 08:00:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/2023/oct/24/brisk-minute-walk-offset-harmful-effects-sitting-study">https://www.theguardian.com/society/2023/oct/24/brisk-minute-walk-offset-harmful-effects-sitting-study</a>, See on <a href="https://news.ycombinator.com/item?id=38010391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Going for a brisk walk for just 22 minutes once a day may be enough to offset the negative health effects of sitting too much, research suggests.</p><p>Sedentary lifestyles are among the leading causes of ill health worldwide. Millions of people who sit for long periods, watching TV or working at a computer, for example, are more likely to die earlier.</p><p>But moderate-to-vigorous physical activity can eliminate this increased risk from being sedentary, according to the study, <a href="https://bjsm.bmj.com/lookup/doi/10.1136/bjsports-2022-106568" data-link-name="in body link">published in the British Journal of Sports Medicine</a>.</p><p>Experts examined data for 11,989 people aged over 50, half of whom were women, from Norway, Sweden and the US. People in the study had worn activity trackers that measured their moderate-to-vigorous physical activity (MPVA).</p><p>Examples of moderate activity include very brisk walking (4mph or faster), heavy cleaning such as washing windows or mopping, cycling at 10-12mph or badminton. Vigorous activity includes hiking, jogging at 6mph or faster, shovelling, fast cycling, a football game, basketball or tennis.</p><figure id="be153ddd-9243-444d-a8b9-0a3479c9b7a2" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:5,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/society/2023/aug/09/revealed-walking-just-4000-steps-a-day-can-reduce-risk-of-dying&quot;,&quot;text&quot;:&quot;Walking just 4,000 steps a day can cut risk of dying from any cause, analysis finds&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;be153ddd-9243-444d-a8b9-0a3479c9b7a2&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;}"></gu-island></figure><p>In all, 5,943 people spent less than 10.5 hours sitting every day while 6,042 spent 10.5 or more hours being sedentary. Over a five-year follow-up, 6.7% (805) of the people died.</p><p>The author Edvard Sagelv, of the Arctic University of Norway, said: “In our study, we found that only those people doing more than 12 hours per day sitting had a higher risk of death. We are talking about any sitting behaviour – such as being in the office or watching TV for long periods of time.</p><p>“In our study, every minute higher MVPA showed a lower risk of death, meaning if people were doing less than 22 minutes (such as 10 minutes) there was still a lower risk of death. However, doing 22 minutes eliminated the higher risk of death from sedentary time.</p><p>“This means that if doing 22 minutes or more per day, there was no excess risk from sedentary time. And, if doing more than 22 minutes per day, there was a lower risk of death overall. Basically, the more the better.”</p><p>The findings support the UK chief medical officer’s recommendation that people aim for 150 minutes of MVPA per week – about 21 minutes per day.</p><p>The study concludes: “Efforts to promote physical activity may have substantial health benefits for individuals and small amounts of MVPA may be an effective strategy to ameliorate mortality risk associated with high sedentary time.”</p><p>Regina Giblin, a senior cardiac nurse at the British Heart Foundation, said: “This research supports previous findings that show the negative effects of long periods sitting down and the positive impact of exercise.</p><p>“There are some simple tips that can help to spend less time sitting down. <a href="https://www.theguardian.com/lifeandstyle/walking" data-link-name="in body link" data-component="auto-linked-tag">Walking</a> away from your computer screen at regular intervals, going for a walk or cooking a healthy meal from scratch are ways to incorporate active time into your day.</p><p>“Being active can help you control your weight, reduce your blood pressure and improve your mental health.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flawless – Durable execution engine for Rust (275 pts)]]></title>
            <link>https://flawless.dev/</link>
            <guid>38010267</guid>
            <pubDate>Wed, 25 Oct 2023 07:39:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flawless.dev/">https://flawless.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=38010267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <a href="https://flawless.dev/">
                <img src="https://flawless.dev/img/logo.png" alt="Flawless Logo, a beautiful woman with freckles head illustration.">
                <span>flawless</span><span>.dev</span>
            </a>
        </header>

        

<section>
    <p>
        Flawless is an execution engine for durable computation. It will run your code until completion
        even <span>in the presence of hardware or software failure<span>.
    </span></span></p>
    <p>
        We aspire to allow <b>builders</b> to create amazing experiences for others. And the best user
        experiences require complex UIs holding complex state, but trying to model all the state inside
        your database can be challenging. At the same time, you don't want the user to lose progress by
        accidentally refreshing the page, making continues persistence a
        requirement for modern applications.
    </p>
    <p>
        <span>
            Flawless allows you to model this persistent state with just code and local variables, raising
            the bar when it comes to expressing complex behaviors inside applications.</span>
    </p>
</section>

<section>
    <h2>How does it work?</h2>

    <p>
        Workflows in flawless are written in <b>Rust</b>, in fact they are just regular Rust functions.
        This means that they can contain arbitrary logic. But instead of native code, the functions
        are compiled to WebAssembly and executed in a completely deterministic environment. The only
        nondeterminism is introduced when interacting with the "real world", like performing HTTP requests
        or generating random numbers. WebAssembly requires us to explicitly handle the non-deterministic
        execution.
    </p>
    <p>
        We use that knowledge to persist a log of non-deterministic side effects. This means that if
        the execution of a workflow is ever interrupted, we can just re-run it and catch up to the same
        state without the need to perform the side effects again.
    </p>

    
<div id="animation">
    <p>workflow.rs <span>×</span></p>
    <p><b>restarting ...</b></p>
    <p>side effect log</p>

    <p>&gt;</p>

    
    <p>63</p>
    

    <p>64</p>
    <p><span>let user</span> = <span>"Adele Goldberg"</span>;</p>
    <p>deterministic</p>
    
    

    <p>65</p>
    <p><span>let comic_id</span>: <span>u32</span> =
        <span>flawless::random()</span>;
    </p>
    <p>side effect</p>
    
    

    <p>66</p>
    <p><span>let url</span> = <span>format!(</span><span>"https://xkcd.com/{comic_id}/"</span><span>)</span>;
    </p>
    
    <p>deterministic</p>
    

    <p>67</p>
    <p><span>let content</span> = <span>flawless::http::get(</span><span>url</span><span>)</span>;</p>
    
    <p>side effect</p>
    

    <p>68</p>
    <p><span>let quote</span> = <span>parse_comic(</span><span>content</span><span>)</span>;
    </p>
    
    
    <p>deterministic</p>

    <p>69</p>
    <p><span>let greeting</span> = <span>format!(</span><span>"Hi {user}! //
            '{quote}'"</span><span>)</span></p>
    
    
    <p>deterministic</p>

    <p>70</p>
    
    
    

    <p> Error: Execution Interrupted!<br>Machine unexpectedly rebooted.</p>
    <p>Execution Completed!</p>

    
    
    

    
    <div>
        <p>...</p>
        <p>recv msg {...}</p>
        <p>HTTP request</p>
        <p>send msg {...}</p>
        <p>get clock time</p>
        <p>_</p>
        <p>_</p>
        <p>_</p>
    </div>

    <p>
        &gt;
    </p>
    <p>▓———————————————————————————————————————————————————————————————————————————█</p>
</div>



    <p>
        This makes the amount of data we need to persist minimal, and the rest is just re-calculated
        on-demand in case of failure. A nice side effect of this model is that the whole system is
        observable. We can take any finished or still running workflow and analyze the exact execution
        path it took to get into the current state. With a completely deterministic execution environment,
        impossible to reproduce bugs become a problem of the past.
    </p>
    <p>
        Notice how flawless takes away the burden of persisting the state. You just write business logic
        and can be assured that all the actions are going to run until completion, even if you need to
        occasionally restart the server because of maintenance. Once you start the flawless engine back
        up, <span>the workflows are going to seamlessly continue executing from where
            they stopped</span>.
    </p>
</section>

<section>
    <h2>Want to try it out?</h2>

    <p>
        If you would like to be one of the first developers to get access to flawless as part of our
        private alpha. Join our waitlist.
    </p>

    




    <p>
        If you are a company and would like to work closely with me to shape flawless specifically for
        your needs, email <a href="https://flawless.dev/cdn-cgi/l/email-protection#f2829380869c9780b2949e93859e978181dc969784"><span data-cfemail="3949584b4d575c4b795f55584e555c4a4a175d5c4f">[email&nbsp;protected]</span></a>.
    </p>

    <p>~ Bernard</p>
</section>

<section>
    <h2>Essays</h2>

    <ul>
        
        
        <li>
            <a href="https://flawless.dev/essays/when-letting-it-crash-is-not-enough/">When "letting it crash" is not enough</a>
            <span>24 Oct. 2023</span>
        </li>
        
    </ul>
</section>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tarsnap has given 2^18 dollars to open source (390 pts)]]></title>
            <link>https://www.daemonology.net/blog/2023-10-25-2%5E18-dollars-to-open-source.html</link>
            <guid>38010244</guid>
            <pubDate>Wed, 25 Oct 2023 07:35:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.daemonology.net/blog/2023-10-25-2%5E18-dollars-to-open-source.html">https://www.daemonology.net/blog/2023-10-25-2%5E18-dollars-to-open-source.html</a>, See on <a href="https://news.ycombinator.com/item?id=38010244">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>
Yesterday I read a great article from Sentry entitled
<a href="https://blog.sentry.io/we-just-gave-500-000-dollars-to-open-source-maintainers/">"We
Just Gave $500,000 to Open Source Maintainers"</a>, and it made me wonder
just how much <a href="https://www.tarsnap.com/">Tarsnap</a> had spent
on supporting open source software over the years.  Ever since
<a href="https://www.daemonology.net/blog/2009-12.html">December 2009</a>
Tarsnap has spent 100% of its December operating profits on supporting
open source software — which, since needs for support aren't limited
to December, means that Tarsnap hands out money throughout the year, and
at the end of the year (when I know how much profit Tarsnap made in
December) I send whatever is left in the "budget" to the
<a href="https://freebsdfoundation.org/">FreeBSD Foundation</a>.
Going through 14 years of accounting spreadsheets brought me to a total
of $274,482 — or in binary terms, slightly over 2^18 USD.
</p><p>
The largest recipient of this funding every year has been the FreeBSD
Foundation, and to date they have received $173,920.  It's hard to
overstate the importance of the work the Foundation does; they provide
hardware which keeps the FreeBSD project running, they fund a myriad
of independent projects, and they have full-time developers who get
thrown in to fixing whatever needs to be fixed from time to time.
While FreeBSD is unusual among open source projects in that the FreeBSD
project governance is entirely independent of the FreeBSD Foundation,
the FreeBSD project would be immeasurably worse off without the support
of the FreeBSD Foundation.
</p><p>
The second largest recipient of support from Tarsnap has been the
<a href="https://www.bsdnow.tv/">BSD Now</a> podcast, which has received
$47,500 to date.  Now at their 529th episode, they fill an important
niche in the BSD world, being one of the only places people can hear
what's going on across all the BSD operating systems.  As developers,
we're generally lousy at communication, and while technical journalists
(e.g., Phoronix) sometimes report on things happening in the BSD world,
they generally lack the technical knowledge to be consistently accurate.
BSD Now, being produced by <i>actual developers</i>, bridges the two
solitudes.
</p><p>
Third comes <a href="https://www.bsdcan.org/">BSDCan</a>, which has
received $23,188 to date.  In addition to being in Canada — which,
as a Canadian, I have to admit influences me somewhat — BSDCan is
the largest BSD conference in the world and plays an essential role in
bringing together developers to discuss and learn about each others'
work.  Email and IRC are great, but sometimes face-to-face conversations
make a huge difference.
</p><p>
Next comes the annual FreeBSD developer summits held at BSDCan.  These
"piggy back" on BSDCan in the sense that they can take advantage of the
fact that BSDCan is already getting a lot of people to travel to one
spot — but BSDCan does not pay for the rooms, A/V, coffee, or any
of the other miscellaneous costs associated with running a developer
summit.  Tarsnap has contributed $11,062 to those.
</p><p>
While most of the money Tarsnap contributes to open source software is
focused on the BSD world — that's what Tarsnap uses — it does
provide funding for an
<a href="https://awards-search.sfu.ca/Home/AwardDetail/72006">annual
award</a> at my Alma Mater for students who contribute to open source
software.  To date Tarsnap has contributed $7,839 to this.
</p><p>
Finally there's a bunch of miscellaneous sponsorships — conferences,
developers, travel grants, etc. — adding up to $10,972.  (Or maybe
a bit more; there were a lot of these and I might have missed some while
I was putting together my list.)
</p><p>
Tarsnap's 2^18 USD of financial support for open source software over the
past 14 years is only a drop in the bucket compared to what is needed, and
indeed I wish we could contribute more; Tarsnap would not exist without
all of the open source software if runs on.  On the other hand, maybe it's
not a bad total for a two-person company; there are certainly much larger
companies which contribute far less.
</p><p>
If you're at a startup which relies heavily on open source software, please
take a moment to ask yourself: How much does your company contribute back? 
</p>



<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An aborted experiment with server Swift (139 pts)]]></title>
            <link>https://flak.tedunangst.com/post/an-aborted-experiment-with-server-swift</link>
            <guid>38010021</guid>
            <pubDate>Wed, 25 Oct 2023 07:00:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flak.tedunangst.com/post/an-aborted-experiment-with-server-swift">https://flak.tedunangst.com/post/an-aborted-experiment-with-server-swift</a>, See on <a href="https://news.ycombinator.com/item?id=38010021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I wanted to write a fun little experimental ActivityPub server. I have a solid idea how to handle this in go, or at least I think I do, so that’d be pretty boring. Instead, let’s try a new technology.</p><p>I settled on <a href="https://www.swift.org/server/">swift, a general-purpose programming language built using a modern approach to safety, performance, and software design patterns, to create the best available language for uses ranging from systems programming, to mobile and desktop apps, scaling up to cloud services</a>.</p><p>This worked until it didn’t. Here are some incomplete notes on the experience, and some extrapolated thoughts on how things may have gone.<br></p><h3>intro</h3><p>Swift seems like a nice language to program in. I don’t think many people think of it as their first choice for a project running on linux, but that’s what made it interesting. I do like that it’s compiled, supposedly runs efficiently, and takes a modern approach to modularity.</p><p>ActivityPub requires a web server that parses incoming json requests, and sends out its own requests. There are some libraries available for swift to make all this possible, so I should just plug it all together, and then write some logic for request handling.</p><p>To get started, I used <a href="https://vapor.codes/">vapor, the future of web development</a>.<br></p><h3>first build</h3><p>I’ve got the hello world web app created with <i>vapor new</i>. Time to run <i>swift build</i>. This goes on <i>forever</i>. Then it stops.</p><p>I’ve lost the original error message, but it was because the c++ <code>&lt;memory&gt;</code> header couldn’t be found compiling some BoringSSL code. This was my fault, for installing the g++ package, but not the g++-dev package or whatever, but it raises the bigger question of why are we compiling BoringSSL in the first place?</p><p>Swift was sold to me as a safe language. But I think it would be more accurate to describe it as a thin veneer of safety over a deep pit of peril. The linux version of swift replicates a large number of native mac frameworks using whatever mix of C and C++ gets the job done. (On mac, these frameworks are also written in c++ or obj-c or something, by Apple, who may be slowly rewriting them in swift, but certainly isn’t done.)</p><p>This is troubling because I have no idea what version of BoringSSL is included here, or what its update policy is. I can imagine that vapor also includes a middleware layer that automagically transcodes images using a broken libwebp. I don’t think it does, but it’s the future of web development, so who even knows. Regardless of specifics, there’s a large iceberg of code here, that could be outdated or vulnerable.</p><p>Spot check: <a href="https://github.com/vapor/vapor/pull/3038/commits/ce62ebe8c1ae2843986a70cddef961c045c9e3b4">vapor updated async-http-client</a> on 2023-07-28 from 1.10.0 to 1.18.0. A review of <a href="https://github.com/swift-server/async-http-client/releases">async-http-client releases</a> shows 1.10.0 was released 2022-04-27 and 1.18.0 on 2023-05-22, and there’s a few concerning issues in the intervening releases.</p><p>Back to building hello, I installed the necessary headers, and finish. A complete build takes about five minutes on my laptop. This is not one time, but actually recurs, but we’ll get to that. Incremental builds of small changes are pretty fast, a few seconds.</p><pre><code>real    4m44.354s
user    22m35.414s
sys     0m55.632s</code></pre><h3>package.swift</h3><p>The weirdest thing about swift is it records dependencies in a file called <i>Package.swift</i>. And then <i>swift build</i> interprets this file somehow? Cool, but also janky? I’ve seen people do this with lua (which looks a lot like json), but swift is kinda syntax heavy for this purpose.</p><pre><code>    targets: [
        .executableTarget(
            name: "App",
            dependencies: [
                .product(name: "Leaf", package: "leaf"),
                .product(name: "Vapor", package: "vapor")
            ]
        ),</code></pre><p>Another issue I did not quite sort out, simply due to unfamiliarity, is how this file relates to <i>import</i> statements in my code. Like there’s an equivalence to <span>CFLAGS</span> and <span>LDFLAGS</span>, but it’s not what I expected, and I was quite surprised by a few things.<br></p><h3>sometimes super reliable</h3><p>I’ve got my hello world app built, run it a few times, make some changes to have it say hello tedu, the usual kicking the tires. Seems quite reliable, but I notice that sometimes it’s <i>super</i> reliable. As in, hitting ^C doesn’t kill the process about one time in ten. The server keeps running, keeps serving requests. It’s an immortal web juggernaut. The only way to stop it is kill -9.</p><p>A hard to kill web server sounds like a feature, but sometimes we can have too much of a good thing. During development, I’d actually like the server to be easy to kill and restart.</p><p>The fact that this occurs only one time in ten makes me think it’s a bug, and not by design. (Unless it’s buggy 90% of the time.) I did not investigate further because signal races are not my idea of a good time. Not a good omen, either.<br></p><h3>blast from the past</h3><p>I started with vapor, but the project I had in mind needed some lower level access to http requests, so I went searching for an example server that used <a href="https://github.com/apple/swift-nio">SwiftNIO</a>. Start integrating some code and immediately get compiler errors.</p><pre><code>     .childChannelInitializer { channel in
<span>-        channel.pipeline.configureHTTPServerPipeline().then {</span>
<span>+        channel.pipeline.configureHTTPServerPipeline().flatMap { () in</span>
             channel.pipeline.addHandler(myHandler)
         }
     }</code></pre><p>Why? I think it’s weird that swift programmers consider this an improvement in legibility, and even more that this is such an improvement it’s worth making a breaking change for.</p><p>There are dozens of such little changes required, and I guess if you’ve been following swift from day one, you’re on top of such things, but as somebody new to swift, having to speedrun the whole experience represents an unfriendly learning curve. The NIO library is complicated enough I don’t think I would have figured out how to wire it up based solely on reading the documentation, hence the reliance on found samples.</p><p>Whenever a new language or framework comes out, people rush to try it, and github and stackoverflow and everywhere else is immediately filled with code samples that work with 1.0. But none of that info gets garbage collected when it becomes outdated, and people write fewer examples for new code, and the new samples have less link juice, with the result that the answers you seek are not the answers you find.<br></p><h3>everything everywhere</h3><p>Here’s another example that was pretty simple but taught me another quirk about swift.</p><pre><code>     func handlerAdded(ctx: ChannelHandlerContext) {
         self.buffer = ctx.channel.allocator.buffer(capacity: 128)
<span>-        self.buffer.write(staticString: "it works!")</span>
<span>+        self.buffer.writeStaticString("it works!")</span>
     }</code></pre><p>Yeah, sure, explicit method names are better than one method with many parameters. But now look at the compiler error.</p><pre><code>error: incorrect argument label in call (have 'staticstring:', expected 'http2ErrorCode:')
        self.buffer.write(staticstring: "it works!")
                         ^~~~~~~~~~~~~
                          http2ErrorCode</code></pre><p>http2 what? Nowhere in my code was I doing anything with http/2. Not intentionally.</p><p>Turns out that swift allows adding extension methods to classes in other modules. Okay, cool feature if you ask for it, but confusing if you haven’t. Unlike dynamic languages such as ruby, where monkey patched methods are of course globally visible, swift is statically compiled. The compiler should know which extensions I’ve asked for and which I haven’t. Long ago, I worked on a complicated c++ code base with tons of operator overloads, and you can get some pretty surprising compiler errors if you have operator, in scope. The solution is you put the damn thing in a separate header, and then it doesn’t show up except in the code that asks for it.</p><p>You can see the implementation of this extension in <a href="https://github.com/apple/swift-nio-http2/blob/main/Sources/NIOHTTP2/HTTP2ErrorCode.swift">the source for HTTP2ErrorCode</a>. But it appears in neither <a href="https://swiftpackageindex.com/apple/swift-nio-http2/1.27.0/documentation/niohttp2/http2errorcode">the documentation for HTTP2ErrorCode</a> nor <a href="https://swiftpackageindex.com/apple/swift-nio/main/documentation/niocore/bytebuffer">the documentation for ByteBuffer</a>. I’m not sure how I would discover this method in the event that I <i>did</i> want to use it. I’ve been told the documentation simply needs to be rebuilt with the new version of DocC, but at the time of writing, that has not happened.</p><p>I do find it amusing that the http/1 team felt the need to clean up these <i>write</i> methods, but the http/2 team didn’t get the memo or felt it wasn’t worth the bother. I’m not sure how this scales in a larger project. You use a component, they remove or rename a method, so then you just add it back? And bizarrely, due to the way extensions become globally imported, it may be some invisible dependency you’re using, leaving you unaware you’re using an obsolete method. This seems very likely to lead to chaos.<br></p><h3>builds</h3><p>After building your hello world app, you get a build directory full of artifacts. This is for a web app that prints hello on port 8080.</p><pre><code>176M    .build/repositories
355M    .build/x86_64-unknown-linux-gnu/debug
250M    .build/x86_64-unknown-linux-gnu/release
924M    total</code></pre><p>These are not portable, however. As in, you cannot relocate them. Or copy them. Should you dare to do so, the compiler will vomit.</p><pre><code>error: PCH was compiled with module cache path '/home/tedu/proj/swello/.build/x86_64-unknown-linux-gnu/debug/ModuleCache/2U5BFZYJRSGKH', but the path is currently '/home/tedu/proj/swift/swello/.build/x86_64-unknown-linux-gnu/debug/ModuleCache/2U5BFZYJRSGKH'</code></pre><p>I am a bad developer who likes to hold things wrong, so the way I develop features is usually to create proj-feature1 and proj-feature2 directories. This is easier for my tiny brain to reason about than smashing all the features into branches in a single directory. And in the situation where I’m developing a server that talks to other servers, it even lets me see what happens when new code talks to old code. But this requires a full rebuild, which takes long enough rebuilding all that BoringSSL code that it would be a big help to also copy the build directory. Alas, that is forbidden.</p><p>I once heard a rumor that there is a secret flag to let swift share build directories, but I was unable to find existence of such, so it may just be an urban legend.<br></p><h3>illegal instruction</h3><p>You know what else is illegal? The instructions generated by the swift compiler.</p><p>I made a fairly small change, to change a get route to a post route, and upon hitting that route with curl was greeted with a special treat.</p><pre><code>Illegal instruction (core dumped)</code></pre><p>This is where my swift journey ends. I’m not debugging this. I’m not working around it. I’m giving up.</p><p>I cannot rule out the possibility that this is somehow my fault, since I don’t know swift that well, or at all really, so maybe this is just what happens when you forget to call <i>await</i> or something like that. But if that’s the case, this is an unfriendly failure mode for a supposedly modern safe language.<br></p><h3>language</h3><p>Anachronistic ecosystem aside, working with swift was fairly pleasant. I wrote some code in a fairly obvious way, the compiler compiled it, and then it ran as expected (usually). Once I figured out the correct names of the methods I wanted, the compiler was not overly fussy. I think I would have been happy to advance to the level of competent swift developer.</p><p>I got a lot done without spending all my time worrying about error handling, although I have the sinking suspicion that’s because the code doesn’t handle errors, not that the magic error elves are doing it for me. Memory management seemed easy and complete, as advertised. I did not make it far enough to assess how terrifying it is to debug an asynchronous concurrency bug.</p><p>I’m pretty sure one of the swift designers was scarred by working on a huge java swing application in a past life, because the language puts a lot of emphasis on making it very easy to call little anonymous functions. I too remember the dark days of new ActionListener. Mixed thoughts on this. It helps reduce clutter, and I think it’s a great way to add a little bit of logic to constructors, etc. without making them super complicated. Except we have all this async code in the mix. I can’t tell what’s a for loop and what’s a callback, and what’s going to run now and what’s going to run later. In your own code, I’m sure you learn what’s what, but reading a new code base will require a lot of documentation consultation.<br></p><h3>thoughts</h3><p>I certainly can’t recommend swift based on my experience. I don’t know if I can recommend against it based on such a short trial. Several of my frustrations were definitely newb pains, and may not have even been worthy of mention given more time.</p><p>My concern using it for any other project would be the big iceberg of code that’s not swift. That doesn’t appear to be going away anytime soon.</p><p>The combination of the signal handling and illegal instruction is also more than a little problematic. If you wanted to make a serious try at swift, you’d want a plan to deal with that. The vapor website is very pretty, so I’m sure somebody has used swift to do something fun at some point. That somebody just wasn’t me.</p><p>I wonder if <a href="https://danluu.com/everything-is-broken/">Dan Luu</a> has ever tried swift.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EBCDIC Is Incompatible with GDPR (242 pts)]]></title>
            <link>https://shkspr.mobi/blog/2021/10/ebcdic-is-incompatible-with-gdpr/</link>
            <guid>38009963</guid>
            <pubDate>Wed, 25 Oct 2023 06:51:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shkspr.mobi/blog/2021/10/ebcdic-is-incompatible-with-gdpr/">https://shkspr.mobi/blog/2021/10/ebcdic-is-incompatible-with-gdpr/</a>, See on <a href="https://news.ycombinator.com/item?id=38009963">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Not knowing the /proc file system (122 pts)]]></title>
            <link>https://admccartney.mur.at/programming/idkproc/</link>
            <guid>38009372</guid>
            <pubDate>Wed, 25 Oct 2023 05:13:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admccartney.mur.at/programming/idkproc/">https://admccartney.mur.at/programming/idkproc/</a>, See on <a href="https://news.ycombinator.com/item?id=38009372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
      <article role="main">
        <h2 id="overview">Overview</h2>
<p>I’ve been working quite with files and file systems on Linux recently.
Mostly from the vantage point of either a shell or a python script. I
wanted to practice coding against the Linux API, so I cracked open my
copy of <a href="https://man7.org/tlpi/">the Linux Programming Interface</a> to
see if I could find some useful info. As usual, I found myself on an
enjoyable tangent learning about file system and process fundamentals.</p>
<p>I developed a fairly simple goal for a small project over the weekend:
pick some essential aspect of Linux file systems and learn a bit about
it. Specifically, try to use the Linux API directly or at least
understand what parts of the API are being used by whatever script is
being used to get the job done.</p>
<p>The task I eventually settled on is described as a simple exercise in
the book mentioned above. Write a program that prints a list of all
processes running on the system that are associated with a specific
user. Print the pid and name of the program being run. It’s possible to
glean all of this information from the <code>/proc</code> file system. The file
<code>/proc/$pid/status</code> holds the info about uid and program name.</p>
<p>The general plan:</p>
<ol>
<li>Write a quick script in python to do the job</li>
<li>Run the script using strace to see what system calls are being made</li>
<li>Write a program in c to do the same job but use the API directly</li>
<li>Run the program through strace and compare the footprint</li>
<li>Profile both programs</li>
</ol>
<h2 id="python-script">Python script</h2>
<p>The initial script is very straight forward. Is relies on the <code>os</code>
module and the <code>pathlib.Path</code> class to get the uid, list the pids of all
processes being run. It then opens the <code>/proc/$pid/status</code> file for each process
and reads two lines; the first to get the name of the program being run and the
ninth to get the uid.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>#!/usr/bin/python</span>
</span></span><span><span><span>import</span> os
</span></span><span><span><span>from</span> pathlib <span>import</span> Path
</span></span><span><span>
</span></span><span><span>__doc__ <span>=</span><span>"""procuall.py: enumerate all processes run by the user who runs the
</span></span></span><span><span><span>script.
</span></span></span><span><span><span>
</span></span></span><span><span><span>usage: python procuall.py
</span></span></span><span><span><span>"""</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>search_proc</span>():
</span></span><span><span>    <span>"""for each process under /proc
</span></span></span><span><span><span>       parse the status file and try to match uid
</span></span></span><span><span><span>       if there is a match, the process belongs to the user"""</span>
</span></span><span><span>    uid <span>=</span> os<span>.</span>getuid()
</span></span><span><span>    all <span>=</span> Path(<span>"/proc"</span>)
</span></span><span><span>    procs <span>=</span> all<span>.</span>glob(<span>"[0-9]*"</span>)
</span></span><span><span>    processes <span>=</span> [p <span>for</span> p <span>in</span> procs]
</span></span><span><span>    info <span>=</span> {}
</span></span><span><span>    <span>for</span> proc <span>in</span> processes:
</span></span><span><span>        status <span>=</span> proc<span>.</span>joinpath(<span>"status"</span>)
</span></span><span><span>        <span>with</span> open(status) <span>as</span> f:
</span></span><span><span>            lines <span>=</span> f<span>.</span>readlines()
</span></span><span><span>            cmd <span>=</span> lines[<span>0</span>]<span>.</span>split(<span>"</span><span>\t</span><span>"</span>)
</span></span><span><span>            name <span>=</span> cmd[<span>1</span>]<span>.</span>strip(<span>"</span><span>\n</span><span>"</span>)
</span></span><span><span>            uidl <span>=</span> lines[<span>8</span>]<span>.</span>split(<span>"</span><span>\t</span><span>"</span>)
</span></span><span><span>            puid <span>=</span> uidl[<span>1</span>]<span>.</span>strip(<span>"</span><span>\n</span><span>"</span>)
</span></span><span><span>            <span>if</span> int(puid) <span>==</span> uid:
</span></span><span><span>                info<span>.</span>update({name: proc<span>.</span>stem})
</span></span><span><span>    <span>return</span> info
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    <span>"""Get info about running processes
</span></span></span><span><span><span>    output the command being run and the pid"""</span>
</span></span><span><span>    info <span>=</span> search_proc()
</span></span><span><span>    <span>for</span> k, v <span>in</span> info<span>.</span>items():
</span></span><span><span>        print(<span>f</span><span>"cmd: </span><span>{</span>k<span>}</span><span>, pid: </span><span>{</span>v<span>}</span><span>"</span>)
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><p>I found it quite beneficial to sketch out a working program like this. It didn’t
take more than a couple of minutes to get it working and it made it possible to
think of ways to improve the program for the second iteration.</p>
<h2 id="strace-output">Strace output</h2>
<p>The first thing that I went looking for in the strace output was which
system calls get used to list the contents of a directory. In the python
code the <code>Path.glob("*")</code> function is being used to list everything
in the <code>proc</code> directory. The listing happens over the course of three
system calls, lines 912-914 below. Note that these calls are lower level
than anything we would use directly from a C program. The directory is
first opened, then <code>fstatat</code> is called to get the <code>stat</code> structure for
the directory. The call to <code>openat</code> returns the file descriptor for the
directory. This is then passed as the first argument to the 4 following
function calls lines 913-916 below. The hex value is the address of the
directory, this is passed along with the <code>st_size</code> attribute to the
<code>getdents64</code> system call.</p>
<p>One curious part of the system calls generated by the python code is that is
seems to call <code>newfstatat</code> and <code>getents64</code> again with an empty string. I wonder
if this might be some side-effect of the use of the <code>Path.glob</code> function. Which
would imply inclusion of the empty directory?</p>
<p>One moderately thing that occurred to me after writing the initial
python program was that it’s not necessary to read the <code>uid</code> line of the
<code>/proc/$PID/status</code> file. An <code>fstat</code> call using the file descriptor is
enough to glean this info.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># output of strace python procuall.py</span>
</span></span><span><span>...
</span></span><span><span><span>910</span> getuid<span>()</span>                                <span>=</span> <span>1000</span>
</span></span><span><span><span>911</span> newfstatat<span>(</span>AT_FDCWD, <span>"/proc"</span>, <span>{</span>st_mode<span>=</span>S_IFDIR|0555, st_size<span>=</span>0, ...<span>}</span>, 0<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span><span>912</span> openat<span>(</span>AT_FDCWD, <span>"/proc"</span>, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY<span>)</span> <span>=</span> <span>3</span>
</span></span><span><span><span>913</span> newfstatat<span>(</span>3, <span>""</span>, <span>{</span>st_mode<span>=</span>S_IFDIR|0555, st_size<span>=</span>0, ...<span>}</span>, AT_EMPTY_PATH<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span><span>914</span> getdents64<span>(</span>3, 0x560cbd19e900 /* <span>416</span> entries */, 32768<span>)</span> <span>=</span> <span>11232</span>
</span></span><span><span><span>915</span> getdents64<span>(</span>3, 0x560cbd19e900 /* <span>0</span> entries */, 32768<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span><span>916</span> close<span>(</span>3<span>)</span>                                <span>=</span> <span>0</span>
</span></span><span><span>...
</span></span></code></pre></div><p>It was quite clear from the strace output that the overhead of the interpreter
costs practically the same as running the program itself. Strace generated over
3000 lines of output. The C version used about half the number of system calls.
The really major difference is the absence of the virtual machine.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># output of strace ./procuall adam</span>
</span></span><span><span>...
</span></span><span><span><span>97</span> openat<span>(</span>AT_FDCWD, <span>"/proc"</span>, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY<span>)</span> <span>=</span> <span>3</span>
</span></span><span><span><span>98</span> newfstatat<span>(</span>3, <span>""</span>, <span>{</span>st_mode<span>=</span>S_IFDIR|0555, st_size<span>=</span>0, ...<span>}</span>, AT_EMPTY_PATH<span>)</span> <span>=</span> <span>0</span>
</span></span><span><span><span>99</span> getdents64<span>(</span>3, 0x7d3db0 /* <span>438</span> entries */, 32768<span>)</span> <span>=</span> <span>12552</span>
</span></span><span><span>...
</span></span></code></pre></div><p>The following is the strace output surrounding the code that generates the data
for the eventual printed line of:</p>
<pre tabindex="0"><code>cmd: nvim, pid: 306559
</code></pre><p>One thing that stands out is the call to <code>ioctl</code> - I have no idea why
this is happening and it also appears to be causing an error. As far as
I understand, the ioctl call signifies that the program is trying to do
a terminal control operation. Dunno.</p>
<pre tabindex="0"><code>3339 openat(AT_FDCWD, "/proc/306559/status", O_RDONLY|O_CLOEXEC) = 3
3340 newfstatat(3, "", {st_mode=S_IFREG|0444, st_size=0, ...}, AT_EMPTY_PATH) = 0
3341 ioctl(3, TCGETS, 0x7ffff4b194b0)        = -1 ENOTTY (Inappropriate ioctl for devi»
3342 lseek(3, 0, SEEK_CUR)                   = 0
3343 read(3, "Name:\tnvim\nUmask:\t0022\nState:\tS "..., 8192) = 1466
3344 read(3, "", 8192)                       = 0
3345 close(3)                                = 0
</code></pre><p>Strace output from the C program for gathering data for the following line.</p>
<pre tabindex="0"><code>Name:   nvim               pid:306559
</code></pre><p>Again, the output looks a bit tidier. One noticeable difference is that
we’re now at a much higher increment of file descriptor. This is because
of the way the program’s loop is running. We’re not closing files after
we’re finishing them, instead we’re just letting this happen implicitly
on program exit. There is also no <code>lseek</code> operation as there way in the
python code. The file pointer is at byte zero on opening the file, so
I don’t really understand why the python version is calling lseek to
reposition it at the beginning of the file.</p>
<pre tabindex="0"><code>1149 openat(AT_FDCWD, "/proc/306559/status", O_RDONLY) = 341
1150 newfstatat(341, "", {st_mode=S_IFREG|0444, st_size=0, ...}, AT_EMPTY_PATH) = 0
1151 newfstatat(341, "", {st_mode=S_IFREG|0444, st_size=0, ...}, AT_EMPTY_PATH) = 0
1152 read(341, "Name:\tnvim\nUmask:\t0022\nState:\tS "..., 1024) = 1024
1153 write(1, "Name:\tnvim               pid:306"..., 60) = 60
</code></pre><h2 id="c-program">C program</h2>
<p>The listing for the C code is included below. I definitely don’t have
as much practice writing C as python. I try to pick up good habits when
I see them. There are some good online resources for this, like <a href="https://nullprogram.com/">Chris
Wellons’</a> website.</p>
<p>The only real overhead to speak of in the C version is linking a few
libraries at the top of the program. I’m using a custom function for
reading lines from a file.</p>
<div><pre tabindex="0"><code data-lang="C"><span><span><span>/* Function to read a line from file */</span>
</span></span><span><span><span>char</span><span>*</span> <span>fgetLine</span>(<span>size_t</span> size, FILE<span>*</span> fd)
</span></span><span><span>{
</span></span><span><span>	<span>char</span><span>*</span> input <span>=</span> NULL;
</span></span><span><span>	<span>char</span><span>*</span> buf;
</span></span><span><span>	buf <span>=</span> <span>malloc</span>(size);  <span>/* allocate the min number of bytes */</span>
</span></span><span><span>	<span>if</span> (buf <span>==</span> NULL) {
</span></span><span><span>		<span>fprintf</span>(stderr, <span>"malloc error</span><span>\n</span><span>"</span>);
</span></span><span><span>		<span>exit</span>(<span>1</span>);
</span></span><span><span>	}
</span></span><span><span>    <span>size_t</span> len <span>=</span> <span>0</span>, newlen <span>=</span> <span>0</span>;
</span></span><span><span>	<span>do</span> {
</span></span><span><span>		<span>/* read at most size bytes */</span>
</span></span><span><span>		<span>if</span>(<span>!</span><span>fgets</span>(buf, size, fd))
</span></span><span><span>		{
</span></span><span><span>			<span>/* read null bytes */</span>
</span></span><span><span>			buf[<span>0</span>] <span>=</span> <span>'\0'</span>;
</span></span><span><span>			<span>return</span> buf;
</span></span><span><span>		}
</span></span><span><span>		newlen <span>=</span> <span>strlen</span>(buf); <span>/* check length of string to be copied */</span>
</span></span><span><span>		<span>if</span> (newlen <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> buf[newlen<span>-</span><span>1</span>] <span>==</span> <span>'\n'</span>) {
</span></span><span><span>			buf[<span>--</span>newlen] <span>=</span> <span>'\0'</span>; <span>/* remove the trailing newline if present */</span>
</span></span><span><span>		}
</span></span><span><span>		<span>if</span> (newlen <span>==</span> size<span>-</span><span>1</span>) { <span>/* we're not finished */</span>
</span></span><span><span>			size <span>*=</span> <span>2</span>;   <span>/* Double the size    */</span>
</span></span><span><span>		} 		
</span></span><span><span>		input <span>=</span> <span>realloc</span>(input, size);
</span></span><span><span>		<span>if</span> (input <span>==</span> NULL) {
</span></span><span><span>			<span>fprintf</span>(stderr, <span>"realloc error</span><span>\n</span><span>"</span>);
</span></span><span><span>			<span>exit</span>(<span>1</span>);
</span></span><span><span>		}
</span></span><span><span>		<span>memcpy</span>(input <span>+</span> len, buf, newlen<span>+</span><span>1</span>); <span>/* begin to write at byte 0, else */</span>
</span></span><span><span>		len <span>+=</span> newlen;
</span></span><span><span>		size <span>+=</span> newlen;
</span></span><span><span>	} <span>while</span> (buf[newlen] <span>&amp;&amp;</span> buf[newlen<span>-</span><span>1</span>]<span>!=</span><span>'\n'</span> <span>&amp;&amp;</span> buf[newlen<span>-</span><span>1</span>]<span>!=</span>EOF);
</span></span><span><span>	<span>return</span> input;
</span></span><span><span>}
</span></span></code></pre></div><p>Other than that I’m making use of a function written by Michael Kerrisk
to translate a name to a uid.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;dirent.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;stdarg.h&gt;</span><span>
</span></span></span><span><span><span>#include</span> <span>&lt;sys/stat.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#include</span> <span>"adio.h"</span><span>
</span></span></span><span><span><span>#include</span> <span>"cscratch_common.h"</span><span>
</span></span></span><span><span><span>#include</span> <span>"ugid_info.h"</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span>
</span></span><span><span><span>/* procuall.c: all process being run by a user 
</span></span></span><span><span><span> *
</span></span></span><span><span><span> * usage: procuall &lt;username&gt;
</span></span></span><span><span><span> * */</span>
</span></span><span><span>
</span></span><span><span><span>#define MAXLINE 512
</span></span></span><span><span><span>#define LPID 5
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> <span>s_isdigit</span>(<span>const</span> <span>char</span><span>*</span> s) {
</span></span><span><span>    <span>int</span> result <span>=</span> <span>0</span>;
</span></span><span><span>    <span>while</span> (<span>*</span>s <span>!=</span> <span>'\0'</span>) {
</span></span><span><span>        <span>if</span> ((<span>'0'</span> <span>&lt;=</span> <span>*</span>s) <span>&amp;&amp;</span> (<span>'9'</span> <span>&gt;=</span> <span>*</span>s)) {
</span></span><span><span>            result <span>=</span> <span>1</span>;
</span></span><span><span>        }
</span></span><span><span>        s<span>++</span>;
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> result;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>char</span><span>*</span>
</span></span><span><span><span>make_filename</span>(<span>const</span> <span>char</span><span>*</span> pid) {
</span></span><span><span>    <span>char</span><span>*</span> fname;
</span></span><span><span>    <span>if</span> (<span>s_isdigit</span>(pid)) {
</span></span><span><span>        <span>sprintf</span>(fname, <span>"/proc/%s/status"</span>, pid);
</span></span><span><span>        <span>return</span> fname;
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> NULL;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span> (<span>int</span> argc, <span>char</span><span>*</span> argv[])
</span></span><span><span>{
</span></span><span><span>    <span>char</span><span>*</span> uname <span>=</span> argv[<span>1</span>];
</span></span><span><span>    <span>uid_t</span> uid <span>=</span> <span>uidFromName</span>(uname);
</span></span><span><span>    <span>printf</span>(<span>"user: %s</span><span>\t</span><span>uid: %d</span><span>\n</span><span>"</span>, uname, uid);
</span></span><span><span>
</span></span><span><span>    DIR<span>*</span> dirp;
</span></span><span><span>    <span>char</span><span>*</span> proc <span>=</span> <span>"/proc"</span>;
</span></span><span><span>    dirp <span>=</span> <span>opendir</span>(proc);
</span></span><span><span>    <span>struct</span> dirent<span>*</span> dp;
</span></span><span><span>    <span>char</span><span>*</span> fname;
</span></span><span><span>    <span>int</span> size <span>=</span> <span>0</span>;
</span></span><span><span>    FILE<span>*</span> fp;
</span></span><span><span>    <span>int</span> fd;
</span></span><span><span>    <span>char</span><span>*</span> lone;
</span></span><span><span>
</span></span><span><span>    <span>struct</span> stat sb;
</span></span><span><span>
</span></span><span><span>    <span>if</span> (dirp) {
</span></span><span><span>        errno <span>=</span> <span>0</span>;
</span></span><span><span>        <span>while</span> ((dp <span>=</span> <span>readdir</span>(dirp)) <span>!=</span> NULL) {
</span></span><span><span>            fname <span>=</span> <span>make_filename</span>(dp<span>-&gt;</span>d_name);
</span></span><span><span>            <span>if</span> (fname) {
</span></span><span><span>                fp <span>=</span> <span>fopen</span>(fname, <span>"r"</span>);
</span></span><span><span>                fd <span>=</span> <span>fileno</span>(fp);
</span></span><span><span>                <span>if</span> (<span>fstat</span>(fd, <span>&amp;</span>sb) <span>==</span> <span>-</span><span>1</span>) {
</span></span><span><span>                    <span>return</span> <span>-</span><span>1</span>; <span>/* just cheese it! */</span>
</span></span><span><span>                }
</span></span><span><span>                <span>if</span> (uid <span>==</span> sb.st_uid) {
</span></span><span><span>                    lone <span>=</span> <span>fgetLine</span>(MAXLINE, fp);
</span></span><span><span>                    <span>printf</span>(<span>"%-24s pid:%-30.30s</span><span>\n</span><span>"</span>, lone, dp<span>-&gt;</span>d_name);
</span></span><span><span>                }
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>        <span>closedir</span>(dirp);
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><h2 id="profiling">Profiling</h2>
<p>Okay, so this section started off as a kind of a joke, I ran both
programs using the <code>time</code> command on Linux. They run so quickly, it’s
a bit hard to determine (but not that hard to guess) which one runs
faster. As mentioned above, there is a huge overhead in running a python
interpreter. As much as I love python the language for it’s simple,
readable syntax and just how accessible that makes it as a programming
language, I do wonder from time to if life would be any different if I
wasn’t lugging a python interpreter everywhere.</p>
<p>The initial output was as follows:</p>
<pre tabindex="0"><code>python3 scripts/procuall.py  0.03s user 0.01s system 97% cpu 0.043 total
</code></pre><pre tabindex="0"><code>./procuall adam  0.00s user 0.01s system 93% cpu 0.009 total
</code></pre><p>I then stumbled across a CLI tool called <a href="https://github.com/sharkdp/hyperfine">hyperfine</a>
that is aimed at benchmarking programs. Using this, and tweaking a few flags, it
was easy to generate some useful information about the two programs.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>proc % hyperfine --warmup<span>=</span><span>100</span> --shell<span>=</span>none <span>"python scripts/procuall.py"</span> <span>"./procuall adam
</span></span></span><span><span><span>Benchmark 1: python scripts/procuall.py
</span></span></span><span><span><span>  Time (mean ± σ):      32.2 ms ±   0.3 ms    [User: 24.3 ms, System: 7.6 ms]
</span></span></span><span><span><span>  Range (min … max):    31.5 ms …  33.2 ms    92 runs
</span></span></span><span><span><span>
</span></span></span><span><span><span>Benchmark 2: ./procuall adam
</span></span></span><span><span><span>  Time (mean ± σ):       2.5 ms ±   0.1 ms    [User: 0.3 ms, System: 2.1 ms]
</span></span></span><span><span><span>  Range (min … max):     2.3 ms …   3.5 ms    989 runs
</span></span></span><span><span><span>
</span></span></span><span><span><span>Summary
</span></span></span><span><span><span>  ./procuall adam ran
</span></span></span><span><span><span>   12.97 ± 0.72 times faster than python scripts/procuall.py
</span></span></span></code></pre></div>

        
          
        

        
            <hr>
            
        

        
          
            
          

          
                  <h4>See also</h4>
                  <ul>
                
                
                    <li><a href="https://admccartney.mur.at/programming/idkoptimization/">Not knowing...python code optimization</a></li>
                
              </ul>

          
        
      </article>

      
        
      


      
        
        
      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things I've learned about building CLI tools in Python (117 pts)]]></title>
            <link>https://simonwillison.net/2023/Sep/30/cli-tools-python/</link>
            <guid>38008987</guid>
            <pubDate>Wed, 25 Oct 2023 03:59:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2023/Sep/30/cli-tools-python/">https://simonwillison.net/2023/Sep/30/cli-tools-python/</a>, See on <a href="https://news.ycombinator.com/item?id=38008987">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p>30th September 2023</p>

<p>I build a lot of command-line tools in Python. It’s become my favorite way of quickly turning a piece of code into something I can use myself and package up for other people to use too.</p>
<p>My biggest CLI  projects are <a href="https://sqlite-utils.datasette.io/">sqlite-utils</a>, <a href="https://llm.datasette.io/">LLM</a>, <a href="https://shot-scraper.datasette.io/en/stable/">shot-scraper</a> and <a href="https://datasette.io/">Datasette</a>—but I have dozens of others and I build new ones at the rate of at least one a month. A fun recent example is <a href="https://github.com/simonw/blip-caption">blip-caption</a>, a tiny CLI wrapper around the Salesforce BLIP model that can generate usable captions for image files.</p>
<p>Here are some notes on what I’ve learned about designing and implementing CLI tools in Python so far.</p>
<h4 id="starting-with-a-template">Starting with a template</h4>
<p>I build enough CLI apps that I developed my own <a href="https://github.com/cookiecutter/cookiecutter">Cookiecutter</a> template for starting new ones.</p>
<p>That template is <a href="https://github.com/simonw/click-app">simonw/click-app</a>. You can create a new application from that template directly on GitHub, too—I wrote more about that in <a href="https://simonwillison.net/2021/Aug/28/dynamic-github-repository-templates/">Dynamic content for GitHub repository templates using cookiecutter and GitHub Actions</a>.</p>
<h4 id="arguments-options-and-conventions">Arguments, options and conventions</h4>
<p>Almost all of my tools are built using the <a href="https://click.palletsprojects.com/">Click</a> Python library. Click encourages a specific way of designing CLI tools which I really like—I find myself annoyed at the various tools from other ecosystems that don’t stick to the conventions that Click encourages.</p>
<p>I’ll try to summarize those conventions here.</p>
<ul>
<li>Commands have arguments and options. Arguments are positional—they are strings that you pass directly to the command, like <code>data.db</code> in <code>datasette data.db</code>. Arguments can be required or optional, and you can have commands which accept an unlimited number of arguments.</li>
<li>Options are, usually, optional. They are things like <code>--port 8000</code>. Options can also have a single character shortened version, such as <code>-p 8000</code>.
<ul>
<li>Very occasionally I’ll create an option that is required, usually because a command has so many positional arguments that forcing an option makes its usage easier to read.</li>
</ul>
</li>
<li>Some options are flags—they don’t take any additional parameters, they just switch something on. <code>shot-scraper --retina</code> is an example of this.</li>
<li>Flags with single character shortcuts can be easily combined—<code>symbex -in fetch_data</code> is short for <code>symbex --imports --no-file fetch_data</code> <a href="https://github.com/simonw/symbex/blob/1.4/README.md#usage">for example</a>.</li>
<li>Some options take multiple parameters. <code>datasette --setting sql_time_limit_ms 10000</code> is an example, taking both the name of the setting and the value it should be set to.</li>
<li>Commands can have sub-commands, each with their own family of commands. <a href="https://llm.datasette.io/en/stable/templates.html">llm templates</a> is an example of this, with <code>llm templates list</code> and <code>llm templates show</code> and <a href="https://llm.datasette.io/en/stable/help.html#llm-templates-help">several more</a>.</li>
<li>Every command should have help text—the more detailed the better. This can be viewed by running <code>llm --help</code>—or for sub-commands, <code>llm templates --help</code>.</li>
</ul>
<p>Click makes it absurdly easy and productive to build CLI tools that follow these conventions.</p>
<h4 id="consistency-is-everything">Consistency is everything</h4>
<p>As CLI utilities get larger, they can end up with a growing number of commands and options.</p>
<p>The most important thing in designing these is <em>consistency</em> with other existing commands and options (<a href="https://github.com/simonw/llm/issues/160#issuecomment-1682995315">example here</a>)—and with related tools that your user may have used before.</p>
<p>I often turn to GPT-4 for help with this: I’ll ask it for examples of existing CLI tools that do something similar to what I’m about to build, and see if there’s anything in their option design that I can emulate.</p>
<p>Since my various projects are designed to complement each other I try to stay consistent between them as well—I’ll often post an issue comment that says “similar to functionality in X”, with a copy of the <code>--help</code> output for the tool I’m about to imitate.</p>
<h4 id="cli-interfaces-are-an-api---version-appropriately">CLI interfaces are an API—version appropriately</h4>
<p>I try to stick to <a href="https://semver.org/">semantic versioning</a> for my projects, bumping the major version number on breaking changes and the minor version number for new features.</p>
<p>The command-line interface to a tool is absolutely part of that documented API. If someone writes a Bash script or a GitHub Actions automation that uses one of my tools, I’m cautious to avoid breaking that without bumping my major version number.</p>
<h4 id="include-usage-examples-in---help">Include usage examples in --help</h4>
<p>A habit I’ve formed more recently is trying to always including a working example of the command in the <code>--help</code> for that command.</p>
<p>I find I use this a lot for tools I’ve developed myself. All of my tools have extensive online documentation, but I like to be able to consult <code>--help</code> without opening a browser for most of their functionality.</p>
<p>Here’s one of my more involved examples—the help for the <a href="https://sqlite-utils.datasette.io/en/stable/cli.html#converting-data-in-columns">sqlite-utils convert</a> command:</p>
<pre><code>Usage: sqlite-utils convert [OPTIONS] DB_PATH TABLE COLUMNS... CODE

  Convert columns using Python code you supply. For example:

      sqlite-utils convert my.db mytable mycolumn \
          '"\n".join(textwrap.wrap(value, 10))' \
          --import=textwrap

  "value" is a variable with the column value to be converted.

  Use "-" for CODE to read Python code from standard input.

  The following common operations are available as recipe functions:

  r.jsonsplit(value, delimiter=',', type=&lt;class 'str'&gt;)

      Convert a string like a,b,c into a JSON array ["a", "b", "c"]

  r.parsedate(value, dayfirst=False, yearfirst=False, errors=None)

      Parse a date and convert it to ISO date format: yyyy-mm-dd
      
      - dayfirst=True: treat xx as the day in xx/yy/zz
      - yearfirst=True: treat xx as the year in xx/yy/zz
      - errors=r.IGNORE to ignore values that cannot be parsed
      - errors=r.SET_NULL to set values that cannot be parsed to null

  r.parsedatetime(value, dayfirst=False, yearfirst=False, errors=None)

      Parse a datetime and convert it to ISO datetime format: yyyy-mm-ddTHH:MM:SS
      
      - dayfirst=True: treat xx as the day in xx/yy/zz
      - yearfirst=True: treat xx as the year in xx/yy/zz
      - errors=r.IGNORE to ignore values that cannot be parsed
      - errors=r.SET_NULL to set values that cannot be parsed to null

  You can use these recipes like so:

      sqlite-utils convert my.db mytable mycolumn \
          'r.jsonsplit(value, delimiter=":")'

Options:
  --import TEXT                   Python modules to import
  --dry-run                       Show results of running this against first
                                  10 rows
  --multi                         Populate columns for keys in returned
                                  dictionary
  --where TEXT                    Optional where clause
  -p, --param &lt;TEXT TEXT&gt;...      Named :parameters for where clause
  --output TEXT                   Optional separate column to populate with
                                  the output
  --output-type [integer|float|blob|text]
                                  Column type to use for the output column
  --drop                          Drop original column afterwards
  --no-skip-false                 Don't skip falsey values
  -s, --silent                    Don't show a progress bar
  --pdb                           Open pdb debugger on first error
  -h, --help                      Show this message and exit.
</code></pre>
<h4 id="including---help-in-the-online-documentation">Including --help in the online documentation</h4>
<p>My larger tools tend to have extensive documentation independently of their help output. I update this documentation at the same time as the implementation and the tests, as described in <a href="https://simonwillison.net/2022/Oct/29/the-perfect-commit/">The Perfect Commit</a>.</p>
<p>I like to include the <code>--help</code> output in my documentation sites as well. This is mainly for my own purposes—having the help visible on a web page makes it much easier to review it and spot anything that needs updating.</p>
<p>Here are some example pages from my documentation that list <code>--help</code> output:</p>
<ul>
<li><a href="https://sqlite-utils.datasette.io/en/stable/cli-reference.html">sqlite-utils CLI reference</a></li>
<li><a href="https://llm.datasette.io/en/stable/help.html">LLM CLI reference</a></li>
<li><a href="https://docs.datasette.io/en/stable/cli-reference.html">Datasette CLI reference</a></li>
<li>
<code>shot-scraper</code> embeds help output on the relevant pages, e.g. <a href="https://shot-scraper.datasette.io/en/stable/screenshots.html#shot-scraper-shot-help">shot-scraper shot --help</a>
</li>
<li><a href="https://s3-credentials.readthedocs.io/en/stable/help.html">s3-credentials command help</a></li>
</ul>
<p>All of these pages are maintained automatically using <a href="https://github.com/nedbat/cog">Cog</a>. I described the pattern I use for this in <a href="https://til.simonwillison.net/python/cog-to-update-help-in-readme">Using cog to update --help in a Markdown README file</a>, or you can <a href="https://github.com/simonw/datasette/blob/1.0a7/docs/cli-reference.rst">view source</a> on the Datasette CLI reference for a more involved example.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MAME 0.260 (149 pts)]]></title>
            <link>https://www.mamedev.org/?p=530</link>
            <guid>38008461</guid>
            <pubDate>Wed, 25 Oct 2023 02:31:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mamedev.org/?p=530">https://www.mamedev.org/?p=530</a>, See on <a href="https://news.ycombinator.com/item?id=38008461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							
							<p>Some long-anticipated updates landed in October, making MAME&nbsp;0.260 a
							very exciting release!  Firstly, there are some general updates to MAME
							itself.  After a few false starts, MAME now supports bgfx video output
							with Wayland on Linux.  As requested by users, you can finally use delta
							CHD files for clone systems and software items.  This allows for major
							disk space savings in some cases when you have multiple versions of a
							system or software item.  There’s also an updated version of PortAudio
							included.</p>
							
							<p>Two very different systems from Casio have been promoted to working
							this month.  The first is the CZ-101 compact keyboard synthesiser.  It
							used Phase Distortion Synthesis, which was Casio’s patent-avoiding
							answer to Yamaha’s DX series.  To help you load patches, MAME can now
							feed SysEx files to emulated MIDI input ports. The other is the Loopy,
							a game console released exclusively in Japan and marketed primarily to
							girls.  While sound output, the sticker printer, and the frame grabber
							accessory are not emulated (yet), you can try out the system’s entire
							library of eleven software titles.</p>
							
							<p>Several Korean arcade games were added this month, including a
							Solitaire card game from F2&nbsp;System that uses a dedicated control panel
							and features some rather disturbing pre-rendered 3D animations.  A few
							Merit games were added as well.  Other improvements include more
							emulated NuBus and PDS cards for Macs, Cumana&nbsp;DFS disk image support for
							the Acorn Electron, and support for an MSX Flash cartridge.</p>
							
							<p>That’s all we’ve got time to highlight here, but of course there’s
							much more.  You can read about everything that was updated this month in
							the <a href="https://www.mamedev.org/releases/whatsnew_0260.txt">whatsnew.txt
							file</a>.  Source code and 64-bit Windows binary packages are available
							from <a href="https://www.mamedev.org/release.html">the download
							page</a>.</p>
							
							<h3>MAME Testers bugs fixed</h3>
							<ul>
							    <li><a href="https://mametesters.org/view.php?id=8597">08597</a>: [Gameplay] a5200: Not possible to start a game in Pitfall&nbsp;2. (AJR)</li>
							    <li><a href="https://mametesters.org/view.php?id=8771">08771</a>: [DIP/Input] (misc/dgpix.cpp) btplay2k: Player controls are incorrect and incomplete. (Windy Fairy)</li>
							    <li><a href="https://mametesters.org/view.php?id=8772">08772</a>: [Gameplay] (misc/gei.cpp) gtsers9: Category ROM in second position is not loaded correctly. (Nightvoice)</li>
							</ul>
							
							<h3>New working systems</h3>
							<ul>
							    <li>Jack Use (Jackpot settings for Interflip slots machines) [Roberto Fresca, Grull Osgo]</li>
							    <li>Solitaire (version&nbsp;2.5) [Recreativas.org, Brito_cat]</li>
							</ul>
							
							<h3>New working clones</h3>
							<ul>
							    <li>Costa Brava (1 jackpot point, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Costa Brava (2 jackpot points, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Costa Brava (4 jackpot points, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Costa Brava (8 jackpot points, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Deluxe Trivia&nbsp;? Whiz (6221-75, U5-0 Edition&nbsp;5 Vertical) [Brian Troha, The&nbsp;Dumping Union]</li>
							    <li>Demon's World&nbsp;/ Horror Story (set&nbsp;6) [Tonitox]</li>
							    <li>Geo Storm (Japan, 026 custom sound&nbsp;CPU) [playero]</li>
							    <li>Gorf (program&nbsp;1, with French Language&nbsp;ROM) [René Balke]</li>
							    <li>Hegener&nbsp;+ Glaser Mephisto Almeria 16&nbsp;Bit (v0.121) [Berger]</li>
							    <li>New&nbsp;HUNTer [Taksangs]</li>
							    <li>New&nbsp;HUNTer (bootleg, set&nbsp;1) [Taksangs]</li>
							    <li>Pack'n Bang Bang [twistedsymphony, hammy, ekorz, rtw]</li>
							    <li>The&nbsp;Pit Boss (2214-07, U5-0) [Brian Troha, The&nbsp;Dumping Union]</li>
							    <li>Sevilla (1 jackpot point, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Sevilla (2 jackpot points, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Sevilla (4 jackpot points, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Sevilla (8 jackpot points, 77%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Tic Tac Trivia (6221-23, U5-0C, 07/07/86) [Brian Troha, The&nbsp;Dumping Union]</li>
							    <li>Trivia&nbsp;? Whiz (6221-05, U5-0C, Edition&nbsp;3) [Brian Troha, The&nbsp;Dumping Union]</li>
							    <li>Trivia&nbsp;? Whiz (6221-10, U5-0A, Edition&nbsp;4) [Brian Troha, The&nbsp;Dumping Union]</li>
							    <li>Toledo (1 jackpot point, 79%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Toledo (2 jackpot points, 83%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Sum-eoitneun Deongdalireul Chat-ara! [Taksangs]</li>
							    <li>Tandy Radio&nbsp;Shack Tandy&nbsp;1000&nbsp;TL [David Viens]</li>
							</ul>
							
							<h3>Systems promoted to working</h3>
							<ul>
							    <li>Baby Fruits (100&nbsp;pts version) [Roberto Fresca, Grull Osgo]</li>
							    <li>Casio CZ-101 [Devin Acker]</li>
							    <li>Casio Loopy [Phil Bennett, Ryan Holtz]</li>
							    <li>Costa Brava (2 jackpot points, 81%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Sevilla (2 jackpot points, 81%) [Roberto Fresca, Grull Osgo]</li>
							    <li>Toledo (2 jackpot points, 87%) [Roberto Fresca, Grull Osgo]</li>
							</ul>
							
							<h3>Clones promoted to working</h3>
							<ul>
							    <li>Mahjong Vegas (Japan) [Sergio Galiano, hammy]</li>
							</ul>
							
							<h3>New systems marked not working</h3>
							<ul>
							    <li>Bingo Parade (main) (MDA-C0008E) [rtw, MetalliC]</li>
							    <li>Gigabyte GA-6LA7 [The&nbsp;Retro Web]</li>
							    <li>Go&nbsp;&amp; Stop [Phil Bennett]</li>
							    <li>Hanguk Pro&nbsp;Yagu&nbsp;98 [WangDrum]</li>
							    <li>Spin Fever [coolmod, The&nbsp;Dumping Union]</li>
							    <li>unknown Yuvo Joy&nbsp;Stand game [hammy]</li>
							</ul>
							
							<h3>New clones marked not working</h3>
							<ul>
							    <li>Bingo Galaxy (main) (MDA-C0039A) [rtw, MetalliC]</li>
							    <li>Match'em Up (6221-51, U5-1) [Brian Troha, The&nbsp;Dumping Union]</li>
							    <li>Multi Game (Italian, Versione&nbsp;3.9.8 - 1.5.7, 01-JUL-98) [The&nbsp;Dumping Union]</li>
							    <li>New&nbsp;HUNTer (bootleg, set&nbsp;2) [Taksangs]</li>
							    <li>Super Magic Card [The&nbsp;Dumping Union]</li>
							    <li>Super Nove (Playmark, Euro currency) [The&nbsp;Dumping Union]</li>
							</ul>
							
							<h3>New working software list items</h3>
							<ul>
							    <li><b>casloopy</b>: Chakra-kun&nbsp;no Omajinai Paradise [Rachel Simone Weil]</li>
							    <li><b>fmtowns_cd</b>:<br>
							      CONFIG-ROM [beanstalk]<br>
							      Auto Demo&nbsp;'93 Fuyu, Heike Monogatari (Gekan), Hyper Planet Shiki Vol.&nbsp;3, Many Colors&nbsp;II,
							      NHK&nbsp;Special&nbsp;- Ginga Uchuu Odyssey Vol.&nbsp;2&nbsp;- Choushinsei Bakuhatsu (FM&nbsp;Towns Marty version), Naomi Komaki for Janis,
							      Wing Commander (alt), Woman's Memory, Z's Staff Pro Towns [redump.org]<br>
							      Drive Simulator&nbsp;- Home&nbsp;Navi&nbsp;V1.0&nbsp;L01 [redump.org, cyo.the.vile]</li>
							    <li><b>msx2_cart</b>:<br>
							      Gogoboom [ESP&nbsp;Soft]<br>
							      Aleste (Woomb), Alien&nbsp;8 Remake, Los&nbsp;Amores de Brunilda (v1.0), Los&nbsp;Amores de Brunilda (v1.01), Arkanoid&nbsp;2 (Korea),
							      AshGuine&nbsp;- Fukushuu&nbsp;no Honoo (Japan, alt&nbsp;2), Bomb Jack, Bomb Jack (alt), DIM&nbsp;X (demo), Daisenryaku&nbsp;MSX2 (Japan, alt),
							      Gekitotsu Pennant&nbsp;Race&nbsp;2 (Japan, sample), Highway Fighter (demo), Hydlide&nbsp;3&nbsp;- The Space Memories (Woomb), Memory (v1.0),
							      Michelangelo&nbsp;II (Japan), No Ren-Sha (v0.13), O'Conner Among the Falling Walls, Operatión Brazil World&nbsp;Cup, Pengo (freeware),
							      Shift, Shift (alt), Street Fighter&nbsp;II, Super Lode Runner (Japan, alt), The&nbsp;Sword of Ianna (v1.0), The&nbsp;Sword of Ianna (v1.1),
							      The&nbsp;Sword of Ianna (v1.2), The&nbsp;Sword of Ianna (v1.2, alt), TestRAM, Who Dares Wins (remake), Word Processor (Arab),
							      Zanac&nbsp;EX (Japan, Woomb), Zevimodoki (v1.00), Zukkoke Yajikita Onmitsu Douchuu (Japan, alt&nbsp;2) [file-hunter]<br>
							      Manbow&nbsp;2, Manbow&nbsp;2 (alt) [file-hunter, AJR]<br>
							      Police Force&nbsp;2 (English), Police Force&nbsp;2 (Spanish) [MRC MEGA-Challenge]<br>
							      Bubble Dream [MRC Tenliner Challenge]<br>
							      Booming Boy (demo) [MSX Area]<br>
							      Barbarian the&nbsp;Duel, Lilly's Saga&nbsp;- The Stones of Evergreen (v1.0), Lilly's Saga&nbsp;- The Stones of Evergreen (v1.1),
							      Lilly's Saga&nbsp;- The Stones of Evergreen (v1.2), Memory (v1.1), Randoom (v1.0), Randoom (v1.1), Safari Kids (v1.0),
							      Safari Kids (v1.1), Shoulder Blade OVERDRIVE, Zevimodoki (v1.10) [MSXdev]<br>
							      The&nbsp;Adventures of Moron van der Slut&nbsp;- Escape from Castro Castro, Inferno, Pointless Fighting [#msxdev Compo]<br>
							      Gold Fan, Penpen Bubble [N.I]<br>
							      CR3 [NabetaJisho]<br>
							      Vectroids [norakomi]<br>
							      La&nbsp;Sorpresa (Spanish), A&nbsp;Surpresa (Portuguese) [Oniric Factor]<br>
							      Pac-Man Collection&nbsp;DX (demo) [Opcode Games]<br>
							      The&nbsp;Bet [Orazio Cacciola]<br>
							      Wild Puzzle, Wild Puzzle (alt), Wild Puzzle (alt&nbsp;2) [Pac]<br>
							      Equivocal (v1.0), Equivocal (v1.5), Jailbreak (alt), Jailbreak (alt&nbsp;2), Jailbreak (v1.02) [Passion MSX2 Contest]<br>
							      Pengo (demo) [Paxanga Soft]<br>
							      Knight Lore Remake [Retroworks]</li>
							</ul>
							
							<h3>New software list items marked not working</h3>
							<ul>
							    <li><b>fmtowns_cd</b>: Fujitsu Habitat&nbsp;V2.1&nbsp;L13A, Hyper Dream [redump.org]</li>
							    <li><b>gamegear</b>: Pro Action Replay (v1.01) [Apocalypse]</li>
							    <li><b>msx2_cart</b>:<br>
							      Ehagaki-yō Wāpuro (Japan), Life on Earth (demo), Super Mario World (advanced prototype), Super Mario World (demo&nbsp;1),
							      Super Mario World (demo&nbsp;2), Super Mario World (early prototype), Super Mario World (v1.0), Super Mario World (v1.1),
							      Super Rambo Special (Korea), The Goonies r Good Enough (Kralizec goodbye present) [file-hunter]<br>
							      Mr. Balloon [#msxdev Compo]</li>
							</ul>
							
							<h3>Translations added or modified</h3>
							<ul>
							    <li>German [Sönke Joppien]</li>
							    <li>Turkish [Kadir Ekşi]</li>
							</ul>
							
							<h3>Merged pull requests</h3>
							<ul>
							    <li><a href="https://github.com/mamedev/mame/pull/11451">11451</a>: render/drawbgfx.cpp: Added initial support for Wayland on Linux. [Belegdol]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11539">11539</a>: 3rdparty/bgfx: Cherry-picked upstream commits needed to support Wayland on Linux. [Belegdol]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11551">11551</a>: seta/seta.cpp: Updated descriptions, machine configuration settings and input labels. [cam900]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11552">11552</a>: seta/simple_st0016.cpp: Added subtitles to descriptions for Koi Koi Shimasho and Renju Kizoku. [cam900]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11553">11553</a>: toaplan/toaplan2.cpp: Corrected DIP switch and jumper settings for bgaregga bootlegs. [cam900]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11570">11570</a>: formats: Reduced compile-time dependencies in filesystem headers. [AJR]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11574">11574</a>: docs: Removed a stray backtick character in examples for debugger <tt>gtime</tt> command. [Tom Cariello]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11575">11575</a>: docs: Fixed many editing errors and spelling errors and an outdated link to the contributing guidelines. [Tom Cariello]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11578">11578</a>: docs: Fixed a number of grammatical errors and editing errors. [Tom Cariello]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11580">11580</a>: handheld/hh_tms1k.cpp: Added clickable keypad to internal artwork for bcheetah. [Golden Child]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11582">11582</a>: sound/ks0164.cpp, cpu/ks0164, misc/dgpix.cpp: Improved KS0164 emulation, and switched to Flash memory device. [Windy Fairy]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11583">11583</a>: amigaocs_flop.xml, megacdj.xml, megadriv.xml, vic10.xml: Replaced unnecessary abbreviations in descriptions. [ArcadeShadow]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11584">11584</a>: nmk/ddealer.cpp, nmk/nmk16.cpp: Emulate microcontrollers, replacing simulation code. [Sergio Galiano, David Haywood, hammy]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11586">11586</a>: docs: Fixed a title underline too short warning. [Firehawke]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11590">11590</a>: seibu/wiz.cpp: Added preliminary protection simulation for kungfuta (avoids crash after bonus rounds). [David Haywood]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11593">11593</a>: cpu/tms57002: Pasted generated content into header to work around GENie’s lack of dependency analysis. [David Haywood]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11594">11594</a>: video/mc6847.cpp: Improved timings and cleaned up code (improves synchronization between CPU, CRTC and screen). [dave-br]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11595">11595</a>: apple/apple2video.cpp: Fixed Apple&nbsp;II double high resolution graphics rendering in color/composite mode. [uraniumgun]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11596">11596</a>: 3rdparty/bgfx: Fixed duplicate import of GL functions on Linux when using OpenGL&nbsp;ES&nbsp;2.0. [Romain Tisserand]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11597">11597</a>: Updated Turkish (Türkçe) UI translation. [Kadir Ekşi]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11599">11599</a>: saturn.xml: Replaced unnecessary abbreviations in descriptions. [ArcadeShadow]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11600">11600</a>: seta/seta.cpp: Added a Korean version of Triple Fun. [Taksangs, ClawGrip]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11602">11602</a>: Updated Turkish (Türkçe) UI translation. [Kadir Ekşi]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11603">11603</a>: subsino/subsino.cpp: Added a Korean version of Treasure Island called New&nbsp;HUNTer. [Taksangs, ClawGrip]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11604">11604</a>: 3rdparty/portaudio: Updated to latest upstream version (resolves issues building with Visual Studio). [invertego]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11605">11605</a>: subsino/subsino.cpp: Added a bootleg of New&nbsp;HUNTer. [Taksangs, ClawGrip]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11606">11606</a>: msx2_cart.xml: Added 52 items (41 working). [Wilbert Pol]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11609">11609</a>: heathkit/tlb.cpp: Re-added TODO comments about 49/50 row mode. [Mark Garlanger]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11610">11610</a>: cpu/sh: Improved SH7021 system-on-a-chip emulation. [Ryan Holtz, Phil Bennett]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11611">11611</a>: fmtowns_cd.xml: Added thirteen items (eleven working), and replaced four items with better dumps. [r09]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11613">11613</a>: casio/cz101.cpp: Added µPD933 phase distortion synthesis and RAM cartridge, and promoted system to working. [Devin Acker]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11614">11614</a>: Corrected grammar of several German UI message translations. [Sönke Joppien]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11621">11621</a>: casio/casloopy.cpp: Emulated most features of the system, besides sound output and the printer. [Phil Bennett, Ryan Holtz]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11623">11623</a>: misc/vamphalf.cpp: Added an arcade Solitaire card game. [Recreativas.org, Brito_cat, clawgrip]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11624">11624</a>: subsino/subsino.cpp: Added another bootleg of New&nbsp;HUNTer (not working). [Taksangs, ClawGrip]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11625">11625</a>: imagedev/midiin.cpp: Added support for MIDI system exclusive message (SysEx) files. [Devin Acker]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11626">11626</a>: casio/ra3.cpp: Fill newly created RAM cartridge files with zeroes (avoids loud noise if empty patch is used). [Devin Acker]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11641">11641</a>: subsino/subsino.cpp: Noted that PROMs were not dumped for the second New&nbsp;HUNTer bootleg. [ClawGrip]</li>
							    <li><a href="https://github.com/mamedev/mame/pull/11642">11642</a>: msx2_cart.xml: Added 31 items (29 working). [Wilbert Pol]</li>
							</ul>
						</div></div>]]></description>
        </item>
    </channel>
</rss>