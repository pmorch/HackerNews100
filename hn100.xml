<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 06 Nov 2025 13:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Oldest woman to finish Ironman World Championship in Kona (104 pts)]]></title>
            <link>https://bigislandnow.com/2025/10/19/80-year-old-grandmother-becomes-oldest-woman-to-finish-ironman-world-championship-in-kona/</link>
            <guid>45833734</guid>
            <pubDate>Thu, 06 Nov 2025 10:47:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bigislandnow.com/2025/10/19/80-year-old-grandmother-becomes-oldest-woman-to-finish-ironman-world-championship-in-kona/">https://bigislandnow.com/2025/10/19/80-year-old-grandmother-becomes-oldest-woman-to-finish-ironman-world-championship-in-kona/</a>, See on <a href="https://news.ycombinator.com/item?id=45833734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <figure><a href="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/unnamed-1.jpg"><img fetchpriority="high" decoding="async" width="1024" height="683" src="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/unnamed-1-1024x683.jpg" alt=""></a><figcaption>Natalie Grabow, 80, of New Jersey, was the oldest finisher and winner of the 80-84 age group in this year’s Ironman World Championship in Kona on Oct. 11, 2025. (Photo courtesy: Ironman)</figcaption></figure>



<p>When Natalie Grabow grew up in the 1940s and 50s in New Jersey, there were not a lot of opportunities for girls to do sports.</p>



<p>“We were cheerleaders,” Grabow said. “I begged my mother to give me gymnastics lessons, but parents at that time didn’t give you any lessons. We just ran around outside and rode bikes.”</p>



<p>But Grabow always has had a competitive spirit, and that shined through last Saturday when Grabow crossed the finish line on Ali’i Drive. </p>



<p>“You are an Ironman” the announcer said as Grabow, at age 80, became the oldest female ever to finish the Ironman World Championship in Kona. </p>



<p>The previous oldest was Cherie Gruenfeld when she finished the championship race at 78 years old in 2022.</p>



<div><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><div><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><p>“I had a good day and I’m just really pleased with myself,” Grabow said Thursday.</p>



<p>The mother of two and grandmother of four said her goal when she entered the water at Kailua Bay a week ago for the swim leg was to complete the grueling 140.6-mile triathlon before the 17-hour cutoff.</p>



<p>She did, with just under 15 minutes to spare, completing the 2.4-mile swim, 112-mile bike ride and the 26.2-mile run in 16 hours, 45 minutes and 26 seconds. </p>



<p>Of the approximately 1,600 females in the championship race, she was the only person in her 80-84 age group.</p>



<p>It was her 11th Ironman race despite not learning to swim until she was 59 and not starting triathlons until she was 60.</p>



<div id="mn_videoad_midarticle"><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><p>“I’m still not comfortable with swimming,” she said. “If you haven’t grown up swimming, it feels like an awkward endeavor.”</p>



<p>During the first leg of the race, Grabow said Kailua Bay was choppy and congested with swimmers. But her only thought was to be out of the water before the cut-off of 2 hours and 20 minute<strong>s </strong>that would have eliminated her from the race.</p>



<figure><p>
<iframe title="Natalie Grabow Ironman World Championship finish" width="422" height="750" src="https://www.youtube.com/embed/CPylVTXbx6g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Grabow said she is familiar with the conditions on Hawai‘i Island.</p>



<p>“It’s hot, humid and windy,” she said. “You really need to watch your nutrition and salt intake so you don’t cramp up.”</p>



<p>Grabow worked as a software engineer. While raising her daughters, she played tennis and did step aerobics.</p>



<div><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><p>Grabow’s daughter, Amy Rousseau, said her mom was her track coach from ages 9 to 13.</p>



<p>“It was amazing that she would put her time into it,” Rousseau said. “Maybe because she didn’t have access to that, she wanted to make sure the next generation did.”</p>



<p>After going back to work full time in her early 40s, Grabow started running to stay active. However, she seemed to never be completely healthy and would get regular knee injuries.</p>



<p>A friend turned her on to the triathlon as a way to stay active and mix things up.</p>



<p>“I like to do something every day,” Grabow said. “If something bothers me in the swim, I can get on the bike.”</p>



<p>Grabow said that had she been able to participate in a sport growing up, she speculated it might have been a sprint-distance runner because she loves to move.</p>



<figure><a href="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/natalie-before-swim.jpg"><img decoding="async" width="675" height="1024" src="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/natalie-before-swim-675x1024.jpg" alt=""></a><figcaption>Natalie Grabow, 80, of New Jersey, getting ready to start the swim during the Ironman World Championship in Kona on Oct. 11, 2025. (Photo courtesy: Amy Rousseau)</figcaption></figure>



<p>“I think girls and young women today don’t realize how lucky they are with the options they have,” Grabow said.</p>



<p>And, participating in triathlons is an “excellent” opportunity, because amateurs like herself can race side-by-side with the pros.</p>



<p>Grabow, who competed in three 70.3 Ironman races this year, said as she’s gotten older, she’s slower, especially as she hit the 80 milestone.</p>



<p>With that in mind, hitting the time cut-off was critical to her. She said she had a slow swim (1:47:41) and bike (7:51:27), but finished strong with a faster run (6:40:11).</p>



<p>“I didn’t have any dark moments,” Grabow said. “I did have some hamstring tightness before the race, but didn’t have time to rest it. I knew I wouldn’t bike as hard, but in the long run, I think it helped. I took more time and took in nutrition and salt.”</p>



<p>Once she started the run, Grabow felt fine. Her coach and daughter, Amy Rousseau, were on the sidelines cheering her on and keeping her on schedule. As she approached the finish line, she tripped.</p>



<p>“That was such a surprise,” Grabow said. “I guess I just didn’t pick up my feet, or the carpet was wrinkled there.”</p>



<p>It didn’t take long for Grabow to pick herself up and cross the finish line, where the announcer declared her an “Ironman.”</p>



<p>“It didn’t bother me, it was just embarrassing,” Grabow said of the fumble.</p>



<p>Rousseau tracked her mother throughout the race, saying she looked strong the entire time. Despite the trip at the end, “she did bounce right back up and kept going and didn’t stay down.”</p>



<figure><a href="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/amy-and-natalie.jpg"><img decoding="async" width="1024" height="959" src="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/amy-and-natalie-1024x959.jpg" alt=""></a><figcaption>Amy Rousseau with her mother, Natalie Grabow, 80, before the Ironman World Championship race in Kona on Oct. 11, 2025. (Photo courtesy: Amy Rousseau)</figcaption></figure>



<p>“For many 80-year-olds, that (fall) would break a hip or collar bone,” Rousseau said.</p>



<p>But not her mom.</p>



<p>“She showed her spirit throughout that part,” Rousseau said. “I’m so proud of her.”</p>



<p>After the race, Rousseau and Grabow were walking around Ali‘i Drive when her mother declared triathlon racing “was what I was meant to do.”</p>



<p>“It’s a great fit for her,” Rousseau, 50, said. “She loves the training. Triathlon has occupied her mind in a good way.”</p>



<p>Rousseau has been to Kona as her mom’s cheerleader about five times, including the first race in 2006.</p>



<p>This year, Rousseau created a system to follow Grabow throughout the course, watching her finish the bike and start her run: “I rode my bike on the shoulder, keeping an eye on her and making sure she was OK. This was just a race against the clock, and she looked strong the whole time.”</p>



<p>In the past, Rousseau said her mom would jog, then walk through the aid stations, but “she ran the whole thing.”</p>



<p>“I don’t know how she does it,” Rousseau said. “What a great role model and example of what working hard and sticking with something and riding out the highs and lows. You just keep going. You never give up. She’s demonstrated that throughout my life.”</p>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mathematical exploration and discovery at scale (102 pts)]]></title>
            <link>https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/</link>
            <guid>45833162</guid>
            <pubDate>Thu, 06 Nov 2025 09:24:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/">https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/</a>, See on <a href="https://news.ycombinator.com/item?id=45833162">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		

<p>
 <a href="https://bogdan-georgiev.com/">Bogdan Georgiev</a>, <a href="https://sites.brown.edu/jgs/">Javier Gómez-Serrano</a>, <a href="https://zawagner22.github.io/">Adam Zsolt Wagner</a>, and I have uploaded to the arXiv our paper “<a href="https://arxiv.org/abs/2511.02864">Mathematical exploration and discovery at scale</a>“. This is a longer report on the experiments we did in collaboration with Google Deepmind with their <a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/">AlphaEvolve tool</a>, which is in the process of being made available for broader use. Some of our experiments were already reported on in a <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf">previous white paper</a>, but the current paper provides more details, as well as a link to a <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems">repository</a> with various relevant data such as the prompts used and the evolution of the tool outputs.
</p><p>
AlphaEvolve is a variant of more traditional optimization tools that are designed to extremize some given score function over a high-dimensional space of possible inputs. A traditional optimization algorithm might evolve one or more trial inputs over time by various methods, such as stochastic gradient descent, that are intended to locate increasingly good solutions while trying to avoid getting stuck at local extrema. By contrast, AlphaEvolve does not evolve the score function inputs directly, but uses an LLM to evolve computer code (often written in a standard language such as Python) which will in turn be run to generate the inputs that one tests the score function on. This reflects the belief that in many cases, the extremizing inputs will not simply be an arbitrary-looking string of numbers, but will often have some structure that can be efficiently described, or at least approximated, by a relatively short piece of code. The tool then works with a population of relatively successful such pieces of code, with the code from one generation of the population being modified and combined by the LLM based on their performance to produce the next generation. The stochastic nature of the LLM can actually work in one’s favor in such an evolutionary environment: many “hallucinations” will simply end up being pruned out of the pool of solutions being evolved due to poor performance, but a small number of such mutations can add enough diversity to the pool that one can break out of local extrema and discover new classes of viable solutions. The LLM can also accept user-supplied “hints” as part of the context of the prompt; in some cases, even just uploading PDFs of relevant literature has led to improved performance by the tool. Since the initial release of AlphaEvolve, similar tools have been developed by others, including <a href="https://github.com/algorithmicsuperintelligence/openevolve">OpenEvolve</a>, <a href="https://github.com/SakanaAI/ShinkaEvolve">ShinkaEvolve</a> and <a href="https://github.com/liugangcode/deepevolve">DeepEvolve</a>.
</p><p>
We tested this tool on a large number (67) of different mathematics problems (both solved and unsolved) in analysis, combinatorics, and geometry that we gathered from the literature, and reported our outcomes (both positive and negative) in this paper. In many cases, AlphaEvolve achieves similar results to what an expert user of a traditional optimization software tool might accomplish, for instance in finding more efficient schemes for packing geometric shapes, or locating better candidate functions for some calculus of variations problem, than what was previously known in the literature. But one advantage this tool seems to offer over such custom tools is that of <em>scale</em>, particularly when when studying variants of a problem that we had already tested this tool on, as many of the prompts and verification tools used for one problem could be adapted to also attack similar problems; several examples of this will be discussed below.
</p><p>
Another advantage of AlphaEvolve was <em>robustness</em>: it was relatively easy to set up AlphaEvolve to work on a broad array of problems, without extensive need to call on domain knowledge of the specific task in order to tune hyperparameters. In some cases, we found that making such hyperparameters part of the data that AlphaEvolve was prompted to output was better than trying to work out their value in advance, although a small amount of such initial theoretical analysis was helpful. For instance, in calculus of variation problems, one is often faced with the need to specify various discretization parameters in order to estimate a continuous integral, which cannot be computed exactly, by a discretized sum (such as a Riemann sum), which can be evaluated by computer to some desired precision. We found that simply asking AlphaEvolve to specify its own discretization parameters worked quite well (provided we designed the score function to be conservative with regards to the possible impact of the discretization error); see for instance <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/classical_inequalities/classical_inequalities.ipynb">this experiment</a> in locating the best constant in functional inequalities such as the <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/14.html">Hausdorff-Young inequality</a>.
</p><p>
A third advantage of AlphaEvolve over traditional optimization methods was the <em>interpretability</em> of many of the solutions provided. For instance, in <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/classical_inequalities/classical_inequalities.ipynb">one of our experiments</a> we sought to find an extremum to a functional inequality such as the <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/16.html">Gagliardo–Nirenberg inequality</a> (a variant of the Sobolev inequality). This is a relatively well-behaved optimization problem, and many standard methods can be deployed to obtain near-optimizers that are presented in some numerical format, such as a vector of values on some discretized mesh of the domain. However, when we applied AlphaEvolve to this problem, the tool was able to discover the exact solution (in this case, a Talenti function), and create code that sampled from that function on a discretized mesh to provide the required input for the scoring function we provided (which only accepted discretized inputs, due to the need to compute the score numerically). This code could be inspected by humans to gain more insight as to the nature of the optimizer. (Though in some cases, AlphaEvolve’s code would contain some brute force search, or a call to some existing optimization subroutine in one of the libraries it was given access to, instead of any more elegant description of its output.)
</p><p>
For problems that were sufficiently well-known to be in the training data of the LLM, the LLM component of AlphaEvolve often came up almost immediately with optimal (or near-optimal) solutions. For instance, for variational problems where the gaussian was known to be the extremizer, AlphaEvolve would frequently guess a gaussian candidate during one of the early evolutions, and we would have to obfuscate the problem significantly to try to conceal the connection to the literature in order for AlphaEvolve to experiment with other candidates. AlphaEvolve would also propose similar guesses for other problems for which the extremizer was not known. For instance, we <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_kakeya_problem/finite_field_kakeya.ipynb">tested this tool</a> on the sum-difference exponents of relevance to the <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/30.html">arithmetic Kakeya conjecture</a>, which can be formulated as a variational entropy inequality concerning certain two-dimensional discrete random variables. AlphaEvolve initially proposed some candidates for such variables based on discrete gaussians, which actually worked rather well even if they were not the exact extremizer, and already generated some slight improvements to previous lower bounds on such exponents in the literature. Inspired by this, I was later able to rigorously obtain some theoretical results on the asymptotic behavior on such exponents in the regime where the number of slopes was fixed, but the “rational complexity” of the slopes went to infinity; this will be reported on in a separate paper.
</p><p>
Perhaps unsurprisingly, AlphaEvolve was extremely good at locating “exploits” in the verification code we provided, for instance using degenerate solutions or overly forgiving scoring of approximate solutions to come up with proposed inputs that technically achieved a high score under our provided code, but were not in the spirit of the actual problem. For instance, when we asked it (link under construction) to find <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/53.html">configurations to extremal geometry problems such as locating polygons with each vertex having four equidistant other vertices</a>, we initially coded the verifier to accept distances that were equal only up to some high numerical precision, at which point AlphaEvolve promptly placed many of the points in virtually the same location so that the distances they determined were indistinguishable. Because of this, a non-trivial amount of human effort needs to go into designing a non-exploitable verifier, for instance by working with exact arithmetic (or interval arithmetic) instead of floating point arithmetic, and taking conservative worst-case bounds in the presence of uncertanties in measurement to determine the score. For instance, in testing AlphaEvolve against the “moving sofa” problem and its variants, we designed a conservative scoring function that only counted those portions of the sofa that we could definitively prove to stay inside the corridor at all times (not merely the discrete set of times provided by AlphaEvolve to describe the sofa trajectory) to prevent it from exploiting “clipping” type artefacts. Once we did so, it performed quite well, for instance <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/the_2d_moving_sofa/the_2d_moving_sofa.ipynb">rediscovering</a> the optimal “Gerver sofa” for the original sofa problem, and also <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/the_3d_moving_sofa/the_3d_moving_sofa.ipynb">discovering new sofa designs</a> for other problem variants, such as a 3D sofa problem.
</p><p>
For well-known open conjectures (e.g., <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/26.html">Sidorenko’s conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/20.html">Sendov’s conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/25.html">Crouzeix’s conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/19.html">the ovals problem</a>, etc.), AlphaEvolve generally was able to locate the previously known candidates for optimizers (that are conjectured to be optimal), but did not locate any stronger counterexamples: thus, we did not disprove any major open conjecture. Of course, one obvious possible explanation for this is that these conjectures are in fact true; outside of a few situations where there is a matching “dual” optimization problem, AlphaEvolve can only provide one-sided bounds on such problems and so cannot definitively determine if the conjectural optimizers are in fact the true optimizers. Another potential explanation is that AlphaEvolve essentially tried all the “obvious” constructions that previous researchers working on these problems had also privately experimented with, but did not report due to the negative findings. However, I think there is at least value in using these tools to systematically record negative results (roughly speaking, that a search for “obvious” counterexamples to a conjecture did not disprove the claim), which currently only exist as “folklore” results at best. This seems analogous to the role LLM Deep Research tools could play by systematically recording the results (both positive and negative) of automated literature searches, as a supplement to human literature review which usually reports positive results only. Furthermore, when we shifted attention to less well studied variants of famous conjectures, we were able to find some modest new observations. For instance, while AlphaEvolve only found the standard conjectural extremizer <img src="https://s0.wp.com/latex.php?latex=%7Bz%5En-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bz%5En-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bz%5En-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{z^n-1}"> to <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/20.html">Sendov’s conjecture</a>, as well as for variants such as <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/22.html">Borcea’s conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/21.html">Schmeisser’s conjecture</a>, or <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/23.html">Smale’s conjecture</a> it did reveal some potential two-parameter extensions to a <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/24.html">conjecture of de Bruin and Sharma</a> that had not previously been stated in the literature. (For this problem, we were not directly optimizing some variational scalar quantity, but rather a two-dimensional range of possible values, which we could adapt the AlphaEvolve framework to treat). In the future, I can imagine such tools being a useful “sanity check” when proposing any new conjecture, in that it will become common practice to run one of these tools against such a conjecture to make sure there are no “obvious” counterexamples (while keeping in mind that this is still far from conclusive evidence in favor of such a conjecture).
</p><p>
AlphaEvolve did not perform equally well across different areas of mathematics. When testing the tool on analytic number theory problems, such as that of <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/27.html">designing sieve weights for elementary approximations to the prime number theorem</a>, it struggled to take advantage of the number theoretic structure in the problem, even when given suitable expert hints (although such hints have proven useful for other problems). This could potentially be a prompting issue on our end, or perhaps the landscape of number-theoretic optimization problems is less amenable to this sort of LLM-based evolutionary approach. On the other hand, AlphaEvolve does seem to do well when the constructions have some algebraic structure, such as with the finite field Kakeya and Nikodym set problems, which we will turn to shortly.
</p><p>
For many of our experiments we worked with fixed-dimensional problems, such as trying to optimally pack <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> shapes in a larger shape for a fixed value of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">. However, we found in some cases that if we asked AlphaEvolve to give code that took parameters such as <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> as input, and tested the output of that code for a suitably sampled set of values of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> of various sizes, then it could sometimes generalize the constructions it found for small values of this parameter to larger ones; for instance, in the infamous <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/65.html">sixth problem of this year’s IMO</a>, it could use this technique to discover the optimal arrangement of tiles, which none of the frontier models could do at the time (although AlphaEvolve has no capability to demonstrate that this arrangement was, in fact, optimal). Another productive use case of this technique was for <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/1.html">finding finite field Kakeya and Nikodym sets</a> of small size in low-dimensional vector spaces over finite fields of various sizes. For Kakeya sets in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbf+F%7D_q%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbf+F%7D_q%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbf+F%7D_q%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{{\mathbf F}_q^d}">, <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_kakeya_problem/finite_field_kakeya.ipynb">it located</a> the known optimal construction based on quadratic residues in two dimensions, and very slightly beat (by an error term of size <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q)}">) the best construction in three dimensions; this was an algebraic construction (still involving quadratic residues) discovered empirically that we could then prove to be correct by first using Gemini’s “Deep Think” tool to locate an informal proof, which we could then convert into a formalized Lean proof by using Google Deepmind’s “AlphaProof” tool. At one point we thought it had found a construction in four dimensions which achieved a more noticeable improvement (of order <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q^3)}">) of what we thought was the best known construction, but we subsequently discovered that essentially the same construction had appeared already in <a href="https://arxiv.org/abs/2108.00074">a paper of Bukh and Chao</a>, although it still led to a more precise calculation of the error term (to accuracy <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%5E%7B3%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%5E%7B3%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%5E%7B3%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q^{3/2})}"> rather than <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q^2)}">, where the error term now involves the Lang-Weil inequality and is unlikely to have a closed form). Perhaps AlphaEvolve had somehow absorbed the Bukh-Chao construction within its training data to accomplish this. However, when we <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_nikodym_problem/finite_field_nikodym.ipynb">tested the tool on Nikodym</a> sets (which are expected to have asymptotic density <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1}">, although this remains unproven), it did find some genuinely new constructions of such sets in three dimensions, based on removing quadratic varieties from the entire space. After using “Deep Think” again to analyze these constructions, we found that they were inferior to a purely random construction (which in retrospect was an obvious thing to try); however, they did inspire a hybrid construction in which one removed random quadratic varieties and performed some additional cleanup, which ends up outperforming both the purely algebraic and purely random constructions. This result (with completely human-generated proofs) will appear in a subsequent paper.
</p>	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What the hell have you built (269 pts)]]></title>
            <link>https://wthhyb.sacha.house/</link>
            <guid>45832803</guid>
            <pubDate>Thu, 06 Nov 2025 08:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wthhyb.sacha.house/">https://wthhyb.sacha.house/</a>, See on <a href="https://news.ycombinator.com/item?id=45832803">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How I am deeply integrating Emacs (117 pts)]]></title>
            <link>https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/</link>
            <guid>45832341</guid>
            <pubDate>Thu, 06 Nov 2025 07:09:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/">https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/</a>, See on <a href="https://news.ycombinator.com/item?id=45832341">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-pagefind-body="true">  <p><img src="https://revere.b-cdn.net/joshblais.com/2025-11-05-133703_grim.png" alt="img"></p>
<p>Emacs has holistically become my daily computing environment.</p>
<p>My efforts have been focused on building emacs into the workflow of essentially everything I do, as long as it doesn’t involve heavy video or media, I try my very best to accomplish it in emacs.
The idea is to achieve deep integration with everything I do on a computer, to the degree my thoughts are immediately able to be acted upon in the buffer.</p>
<p>I use <a href="https://hypr.land/">hyprland</a> as my window manager, and while I have heard of other managers/DEs (I was using GNOME for the better part of 6 months), I keep coming back to hyprland just because it works and is easy to configure. Also, for some reason, I seem not to have laggin in emacs on wayland in hyprland, while I had to previously run emacs in X11 mode in GNOME, go figure.</p>

<h2 id="my-motivation">My Motivation<a tab-index="0" aria-hidden="false" aria-label="Link to My Motivation" data-pagefind-ignore="" href="#my-motivation">#</a></h2>
<p>I have seen what people are capable of doing when their tools get out of the way, and they are free to just <em>create</em>.
This is how world class athletes, musicians, artists, writers, and of course programmers take what is in their mind and translate it into reality.
The idea is that if I can learn this “<a href="https://www.youtube.com/watch?v=VADudzQGvU8&amp;themeRefresh=1">editor of a lifetime</a>” - then the things that I want to create, the programs I want to write, will be achieved in a near frictionless environment, allowing for velocity that is not possible elsewhere.
It is the ultimate sharpening of the axe before chopping the tree.</p>

<h2 id="why-not-exwm">Why not EXWM?<a tab-index="0" aria-hidden="false" aria-label="Link to Why not EXWM?" data-pagefind-ignore="" href="#why-not-exwm">#</a></h2>
<p>I have considered using EXWM as the window manager (quite literally offloading window management to emacs, and “living in emacs” - to more of a degree than I do already), the hesitation I have is that:</p>
<ol>
<li>Emacs is single threaded, therefore if anything in the system hangs, the whole system hangs, and</li>
<li>It is only X11 where most of the development and forward movement in the linux space has been in wayland. While I understand this is not a tremendous issue, wayland does seem to be where the puck is going.</li>
</ol>
<p>So, what I am aiming to do is replicate functionality as best as I can from EXWM to a wayland environment - not wholly possible, but also not wholly impossible, either.</p>

<h2 id="the-emacs-launcher-program">The Emacs Launcher program<a tab-index="0" aria-hidden="false" aria-label="Link to The Emacs Launcher program" data-pagefind-ignore="" href="#the-emacs-launcher-program">#</a></h2>
<p>If you look at <a href="https://github.com/jblais493/nixos-config">my dotfiles</a>, you can see I have a <a href="https://github.com/jblais493/nixos-config/blob/master/dotfiles/hypr/scripts/emacs-launcher.go">script written in Go</a> that allows me to call each and every one of my emacs controls anywhere is my system.
I was previously calling each of these emacs commands in bash and with a sleep command so as to make sure I was targeting the emacs instance. No longer. This Go script has sped up my workflow by 10x.</p>

<h2 id="my-current-setup">My Current setup<a tab-index="0" aria-hidden="false" aria-label="Link to My Current setup" data-pagefind-ignore="" href="#my-current-setup">#</a></h2>

<h3 id="how-i-launch-emacs">How I Launch Emacs<a tab-index="0" aria-hidden="false" aria-label="Link to How I Launch Emacs" data-pagefind-ignore="" href="#how-i-launch-emacs">#</a></h3>
<p><code>bind = $mainMod SHIFT, E, exec, bash -c "emacs"</code></p>
<p>I almost never press this keybind, as emacs is opened from the get-go in my hyprland sessions.  For that rare time I need to re-open it.</p>

<h3 id="opening-vterm-as-my-default-terminal">Opening vterm as my default terminal<a tab-index="0" aria-hidden="false" aria-label="Link to Opening vterm as my default terminal" data-pagefind-ignore="" href="#opening-vterm-as-my-default-terminal">#</a></h3>
<p><code>bind = $mainMod, E, exec, emacsclient -n -e '(my/new-frame-with-vterm)'</code></p>
<p>This permits me to quickly open a vterm window and enter commands etc. If I need anything that is more graphically intense, I fallback to kitty terminal, but this is less and less these days.</p>

<h4 id="opening-vterm-in-my-emacs-session-quickly-for-in-projects-is-done-like-so">Opening vterm in my emacs session quickly for in projects is done like so:<a tab-index="0" aria-hidden="false" aria-label="Link to Opening vterm in my emacs session quickly for in projects is done like so:" data-pagefind-ignore="" href="#opening-vterm-in-my-emacs-session-quickly-for-in-projects-is-done-like-so">#</a></h4>
<p><code>bind = $mainMod, RETURN, exec, ~/.config/hypr/scripts/emacs-launcher '(my-open-vterm-at-point)'</code></p>

<h3 id="universal-launcher"><a href="https://github.com/jblais493/universal-launcher.el">Universal Launcher</a><a tab-index="0" aria-hidden="false" aria-label="Link to Universal Launcher" data-pagefind-ignore="" href="#universal-launcher">#</a></h3>
<p><code>bind = $mainMod, SPACE, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (universal-launcher-popup))'</code></p>
<p>I wanted to replicate a launcher (similar to wofi/rofi) in which I could easily launch apps and switch to them in the environment.</p>
<p>So, my take on this is to replace wofi with this functionality. I was using ssh providers in GNOME, but then brought the functionality into my universal launcher. It has effectively grown to encapsulate:</p>
<ul>
<li>Passwords</li>
<li>SSH</li>
<li>Bookmarking</li>
<li>Commands and program launching</li>
<li>Emojis</li>
<li>TODOS (though org-agenda/calendar also handles this)</li>
<li>File navigation</li>
<li>Web and documentation search</li>
</ul>
<p>While this is a work in progress, I use it every day, hundreds of times a day, and love the flow &amp; speed my launcher allows.</p>

<h3 id="capture-to-org-mode">Capture to org mode<a tab-index="0" aria-hidden="false" aria-label="Link to Capture to org mode" data-pagefind-ignore="" href="#capture-to-org-mode">#</a></h3>
<p><code>bind = CTRL SHIFT, c, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (org-capture))'</code></p>
<p>When I am not “in” emacs (I am always in emacs by extension) I can still capture direct to emacs with a quick keybind.</p>
<p>I capture to my org directory:</p>
<ul>
<li>notes</li>
<li>bookmarks</li>
<li>contacts</li>
<li>inbox (todos)</li>
<li>events/deadlines</li>
</ul>
<p>This is very useful when I am wanting to save a thought, idea, bookmark, quote, what have you, and then integrate it with my <a href="https://www.orgroam.com/">org-roam</a> file structure.</p>

<h3 id="notes">Notes<a tab-index="0" aria-hidden="false" aria-label="Link to Notes" data-pagefind-ignore="" href="#notes">#</a></h3>
<p><code>bind = $mainMod CTRL, N, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (find-file "~/org/notes.org"))'</code></p>
<p>I can navigate to my notes file very quickly to write emails, keep notes on stuff, and then translate those into my org-roam directory, too.</p>

<h3 id="calendarorg-agenda">Calendar/Org Agenda<a tab-index="0" aria-hidden="false" aria-label="Link to Calendar/Org Agenda" data-pagefind-ignore="" href="#calendarorg-agenda">#</a></h3>
<p><code>bind = $mainMod, C, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (=calendar))'</code></p>
<p><code>bind = $mainMod, N, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (my/org-agenda-dashboard))'</code></p>
<p>Quick access to my agenda and calendar from anywhere.</p>

<h3 id="password-manager">Password manager<a tab-index="0" aria-hidden="false" aria-label="Link to Password manager" data-pagefind-ignore="" href="#password-manager">#</a></h3>
<p><code>bind = $mainMod, P, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (pass))'</code></p>
<p>Password-store inside emacs to create, update, grab passwords and insert them on page in browsers.</p>

<h3 id="file-browsing">File Browsing<a tab-index="0" aria-hidden="false" aria-label="Link to File Browsing" data-pagefind-ignore="" href="#file-browsing">#</a></h3>
<p><code>bind = $mainMod, F, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (dirvish))'</code></p>
<p>I use <a href="https://github.com/alexluigit/dirvish">dirvish</a>/<a href="https://www.gnu.org/s/emacs/manual/html_node/emacs/Dired.html">dired</a> for nearly all my file browsing and manipulation. I have some binds that allow me to pull up <a href="https://docs.xfce.org/xfce/thunar/start">thunar</a> for graphical drag-drop operations, but other than that files are dealt with inside emacs.</p>
<p>The killer feature is that you can edit files as you would edit text, nothing else comes close.</p>

<h3 id="bookmarks">Bookmarks<a tab-index="0" aria-hidden="false" aria-label="Link to Bookmarks" data-pagefind-ignore="" href="#bookmarks">#</a></h3>
<p><code>bind = $mainMod, B, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (find-file "~/org/bookmarks.org"))'</code></p>
<p>Bookmarking within emacs allows me to keep all sites top of mind.</p>

<h3 id="email">Email<a tab-index="0" aria-hidden="false" aria-label="Link to Email" data-pagefind-ignore="" href="#email">#</a></h3>
<p><code>bind = $mainMod, M, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (=mu4e))'</code></p>
<p>The greatest email client.</p>

<h3 id="feed-reader">Feed reader<a tab-index="0" aria-hidden="false" aria-label="Link to Feed reader" data-pagefind-ignore="" href="#feed-reader">#</a></h3>
<p><code>bind = $mainMod CTRL, Z, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (elfeed))'</code></p>
<p>Reading any feed from around the web, I follow youtube, blogs, news, etc. here - never going out to the web to read anything.</p>

<h3 id="music-playing">Music playing<a tab-index="0" aria-hidden="false" aria-label="Link to Music playing" data-pagefind-ignore="" href="#music-playing">#</a></h3>
<p><code>bind = $mainMod CONTROL, M, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (emms-playlist-mode-go))'</code></p>
<p>You thought I <em>wouldn’t</em> play music in emacs?</p>

<h3 id="emacs-everywhere-for-editing-text-anywhere">Emacs everywhere for editing text anywhere<a tab-index="0" aria-hidden="false" aria-label="Link to Emacs everywhere for editing text anywhere" data-pagefind-ignore="" href="#emacs-everywhere-for-editing-text-anywhere">#</a></h3>
<p><code>bind = $mainMod CONTROL, E, exec, emacsclient --eval '(thanos/type)'</code></p>
<p>When you are in a text box on any site, you can just edit the text in emacs, press <code>C-c C-c</code> and have it pasted right there for you.</p>

<h2 id="will-i-use-exwm">Will I use EXWM?<a tab-index="0" aria-hidden="false" aria-label="Link to Will I use EXWM?" data-pagefind-ignore="" href="#will-i-use-exwm">#</a></h2>
<p>I think that because I spend so much time inside emacs, I don’t really get the benefits of everything being a buffer. I only use a browser for projects, not as a window I have always open, and I don’t really need emacs to control buffers or give me the keybinds universally. I will never say never though, perhaps one day it will be my window manager of choice.</p>
<p>How are you integrating emacs in your workflow? I would be super interested to see other setups that allow you to use emacs as your one, true, holistic computing environment. Shoot me an email and tell me how it’s done!</p>
<p>As always, God bless, and until next time.</p>
<p>If you enjoyed this post, consider supporting my work by <a href="https://buymeacoffee.com/joshuablais">Buying me a Coffee</a>, <a href="https://mountainthebook.com/">Checking out my book</a>, or sending me an <a href="mailto:josh@joshblais.com">email</a> to tell me what you think.</p>  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I may have found a way to spot U.S. at-sea strikes before they're announced (122 pts)]]></title>
            <link>https://old.reddit.com/r/OSINT/comments/1opjjyv/i_may_have_found_a_way_to_spot_us_atsea_strikes/</link>
            <guid>45831541</guid>
            <pubDate>Thu, 06 Nov 2025 04:37:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/OSINT/comments/1opjjyv/i_may_have_found_a_way_to_spot_us_atsea_strikes/">https://old.reddit.com/r/OSINT/comments/1opjjyv/i_may_have_found_a_way_to_spot_us_atsea_strikes/</a>, See on <a href="https://news.ycombinator.com/item?id=45831541">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Over the last month the U.S. has carried out several interdiction strikes on narco-trafficking boats in the Eastern Pacific and Caribbean. These are usually acknowledged the next day, described vaguely as “in international waters,” with no coordinates. I’ve been experimenting with NASA’s VIIRS thermal anomaly feed (FIRMS) to see if any of these events are visible <em>as they happen</em>.</p>

<p><a href="https://preview.redd.it/xudkavdw0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=15582a6952deb90dcf9d014a4173b0c523ebd987">https://preview.redd.it/xudkavdw0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=15582a6952deb90dcf9d014a4173b0c523ebd987</a></p>

<p>On Oct 27, a single <strong>daytime</strong> VIIRS hotspot appears at <strong>14.0387° N, 106.4606° W</strong>, which is roughly <strong>415 nautical miles southwest of Acapulco</strong>. It’s the only ocean pixel in that sector for the entire week. Mexico’s subsequent statements referenced <strong>search and rescue ~400 nm SW of Acapulco</strong> after that day’s operations. The geometry lines up almost perfectly.  </p>

<p><a href="https://preview.redd.it/z4nk46ox0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=95de0ab7a01b5688f687cf439e52af6be6f26f99">https://preview.redd.it/z4nk46ox0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=95de0ab7a01b5688f687cf439e52af6be6f26f99</a></p>

<p>Why I think this specific detection is the Oct 27 strike: the public footage released by the U.S. shows a <strong>large explosion with an ongoing flame in daylight</strong>—exactly the type of surface combustion a daytime VIIRS pass can catch. The spot is far from known offshore platforms or refinery flare fields, and I filtered out land fires and industrial sources before scanning. I’m <strong>~90% confident</strong> this pixel is the Oct 27 event.  </p>

<p><a href="https://preview.redd.it/hnryod1z0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=d5c97138b50056839cd0689503b9f05920427e54">https://preview.redd.it/hnryod1z0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=d5c97138b50056839cd0689503b9f05920427e54</a></p>

<p>If you want to replicate: set FIRMS to VIIRS 375 m, date 2025-10-27, pan to the Eastern Pacific off Mexico, and you’ll see the detection with its timestamp and FRP. Measure from Acapulco and you’ll get ~415 nm. It does not recur on adjacent days at that exact location, which argues against a persistent industrial source.</p>

<p>None of this claims intent; it’s simply “thermal anomaly consistent with a fire” in the precise place and time later described by authorities. The interesting part is methodological: with FIRMS alone—no paid feeds—you can narrow vague “international waters” language to a concrete lat/lon box in near-real time. That has obvious implications for open-source monitoring and for how quickly journalists and analysts can geolocate future incidents.  </p>

<p>I’m happy to hear counter-arguments—e.g., alternative explanations for a one-off daytime ocean pixel at those coordinates—but based on the match to the reported location, the unique nature of the detection, and the daylight, high-energy fire profile, I think this one’s a hit.</p>

<p><a href="https://preview.redd.it/bsmhlrm11jzf1.png?width=480&amp;format=png&amp;auto=webp&amp;s=c7db45f505fc502a5915041d63973f37e33de191">https://preview.redd.it/bsmhlrm11jzf1.png?width=480&amp;format=png&amp;auto=webp&amp;s=c7db45f505fc502a5915041d63973f37e33de191</a></p>

<p>disclaimer: i run a website that tracks pentagon pizza deliveries and other fun alt-data for geopolitics + OSINT. we just integrated this thermal anomaly data here: <a href="http://pizzint.watch/polyglobe">pizzint.watch/polyglobe</a></p>

<p><a href="https://preview.redd.it/lxnipd731jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=02e50262cae176d30b516e123dfc0df31a204828">https://preview.redd.it/lxnipd731jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=02e50262cae176d30b516e123dfc0df31a204828</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ratatui – App Showcase (465 pts)]]></title>
            <link>https://ratatui.rs/showcase/apps/</link>
            <guid>45830829</guid>
            <pubDate>Thu, 06 Nov 2025 02:50:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ratatui.rs/showcase/apps/">https://ratatui.rs/showcase/apps/</a>, See on <a href="https://news.ycombinator.com/item?id=45830829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 
<p>Atuin replaces your existing shell history with a SQLite database, and records additional context
for your commands.</p>
<p><img src="https://github.com/atuinsh/atuin/blob/main/demo.gif?raw=true" alt="atui demo"></p>
<hr>

<p>This is a CLI utility for displaying current network utilization by process, connection and remote
IP/hostname</p>
<p><img src="https://github.com/imsnif/bandwhich/blob/main/res/demo.gif?raw=true" alt="bandwhich demo"></p>
<hr>

<p>Perform binary analysis in your terminal.</p>
<p><img src="https://github.com/orhun/binsider/blob/main/website/src/content/assets/quickstart.gif?raw=true" alt="binsider demo"></p>
<hr>

<p>A customizable cross-platform graphical process/system monitor for the terminal</p>
<p><img src="https://github.com/ClementTsang/bottom/blob/main/assets/demo.gif?raw=true" alt="bottom demo"></p>
<hr>

<p>Play crossword puzzles in your terminal.</p>
<p><img src="https://github.com/user-attachments/assets/8a2bb53b-f461-4ddd-b60c-9ae5170b501d" alt="crossword demo"></p>
<hr>

<p><code dir="auto">csvlens</code> is A command line CSV file viewer. It is like less but made for CSV.</p>
<!-- This is in the public folder not the app folder as it causes astro to crash during processing
See https://github.com/withastro/astro/issues/8886 -->
<p><img src="https://ratatui.rs/csvlens.gif" alt="csvlens demo"></p>
<hr>

<p><code dir="auto">dua</code> is a disk space analysis tool designed for speed, leveraging parallel processing to quickly
provide detailed disk usage information and allowing for faster deletion of unnecessary data
compared to the standard ‘rm’ command.</p>
<p><a href="https://asciinema.org/a/kDnXUOeqBxZVMoWuFNqzfpeey" target="_blank" rel="noopener noreferrer"><img src="https://asciinema.org/a/kDnXUOeqBxZVMoWuFNqzfpeey.svg" alt="dua demo"></a></p>
<hr>

<p>A command line tool that executes make target using fuzzy finder with preview window</p>
<p><img src="https://raw.githubusercontent.com/kyu08/fzf-make/main/static/demo.gif" alt="fzf-make demo"></p>
<hr>

<p>TUI for git written in rust</p>
<p><img src="https://github.com/extrawurst/gitui/blob/master/demo.gif?raw=true" alt="gitui demo"></p>
<hr>

<p>gpg-tui is a Terminal User Interface for GnuPG.</p>
<p><img src="https://github.com/orhun/gpg-tui/blob/master/demo/gpg-tui-scrolling_rows.gif?raw=true" alt="gpg-tui demo"></p>
<hr>

<p>Ranger-like terminal file manager written in Rust</p>
<p><img src="https://github.com/kamiyaa/joshuto/raw/main/screenshot.png?raw=true" alt="joshuto demo"></p>
<hr>

<p>A material design color palette for the terminal.</p>
<p><img src="https://i.ibb.co/2MDKmh7/Screenshot-2022-08-02-at-16-43-12.png" alt="material demo"></p>
<hr>

<p>A mine sweeping game written in Rust</p>
<p><img src="https://github.com/cpcloud/minesweep-rs/blob/main/demo.gif?raw=true" alt="minesweep-rs demo"></p>
<hr>

<p>Oatmeal is a terminal UI chat application that speaks with LLMs, complete with slash commands and
fancy chat bubbles. It features agnostic backends to allow switching between the powerhouse of
ChatGPT, or keeping things private with Ollama. While Oatmeal works great as a stand alone terminal
application, it works even better paired with an editor like Neovim!</p>
<p><img src="https://github.com/dustinblackman/oatmeal/assets/5246169/9ee5e910-4eff-4deb-8065-aeab8bfe6b00" alt="oatmeal-demo"></p>
<hr>

<p>oha is a tiny program that sends some load to a web application and show realtime tui</p>
<p><img src="https://github.com/hatoo/oha/blob/master/demo.gif?raw=true" alt="oha demo"></p>
<hr>

<p>A simple TUI to view &amp; control docker containers</p>
<p><img src="https://raw.githubusercontent.com/mrjackwills/oxker/main/.github/demo_01.webp?raw=true" alt="oxker demo"></p>
<hr>

<p>Unlock the power of APIs with simplicity and speed, right from your terminal. View OpenAPI
documentations in your terminal.</p>
<p><img src="https://github.com/zaghaghi/openapi-tui/blob/main/static/demo.gif?raw=true" alt="openapi-tui demo"></p>
<hr>

<p>A lightweight and terminal-based tool for interacting with databases.</p>
<p><img src="https://github.com/achristmascarl/rainfrog/raw/main/vhs/demo.gif?raw=true" alt="rainfrog demo"></p>
<hr>

<p>An application to manage markdown notes from your terminal and compile them to HTML</p>
<p><img src="https://github.com/Linus-Mussmaecher/rucola/blob/main/readme-images/readme-image-select.png?raw=true" alt="rucola demo"></p>
<hr>

<p>A simple oscilloscope/vectorscope/spectroscope for your terminal</p>
<p><img src="https://camo.githubusercontent.com/4b11674184b07eebd6bc386c38c9cce1a7a70ae82733b44cd977c8ab85c5a691/68747470733a2f2f63646e2e616c656d692e6465762f73636f70652d7475692d776964652e706e67" alt="scope-tui demo"></p>
<hr>

<p>Terminal HTTP/REST client</p>
<p><img src="https://media.githubusercontent.com/media/LucasPickering/slumber/master/docs/src/images/demo.gif" alt="slumber demo"></p>
<hr>

<p>A CLI-based AI coding agent for local dev, scripts/CI, and automation.</p>
<p><img src="https://raw.githubusercontent.com/brendangraham14/steer/main/.github/images/demo.gif" alt="steer demo"></p>
<hr>

<p>A terminal user interface for taskwarrior</p>
<p><img src="https://user-images.githubusercontent.com/1813121/159858280-3ca31e9a-fc38-4547-a92d-36a7758cf5dc.gif" alt="taskwarrior-tui demo"></p>
<hr>

<p>Television is a fast and versatile fuzzy finder TUI.</p>
<p>It lets you quickly search through any kind of data source (files, git repositories, environment
variables, docker images, you name it) using a fuzzy matching algorithm and is designed to be easily
extensible.</p>
<p><img src="https://github.com/user-attachments/assets/7a967f9c-779e-4915-baa8-160f586f8936" alt="television demo"></p>
<hr>

<p>A network diagnostic tool that combines the functionality of traceroute and ping and is designed to
assist with the analysis of networking issues.</p>
<p><img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/assets/0.12.0/demo.gif?raw=true" alt="trippy demo"></p>
<hr>

<p>A hackable, minimal, fast TUI file explorer</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/QJaEMeVo9Uw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<hr>

<p>Blazing fast terminal file manager written in Rust, based on async I/O</p>
<p><a href="https://yazi-rs.github.io/features" target="_blank" rel="noopener noreferrer">Features</a></p>
<video controls="">
  <source src="https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7" type="video/mp4">
  Your browser does not support the video tag.
</video>
<hr>

<p>Yōzefu is an interactive TUI application for exploring data of a Kafka cluster.</p>
<p>It is an alternative tool to AKHQ, Redpanda Console, or the Kafka plugin for JetBrains IDEs. It
includes a search query language inspired by SQL, providing fine-grained filtering capabilities.</p>
<p><img src="https://vhs.charm.sh/vhs-UpIJD2h92vKkj01XSS0r0.gif" alt="yozefu demo"></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FAA to cut flights by 10% at 40 major airports due to government shutdown (130 pts)]]></title>
            <link>https://www.cnbc.com/2025/11/05/faa-cuts-flight-capacity-shutdown.html</link>
            <guid>45830797</guid>
            <pubDate>Thu, 06 Nov 2025 02:44:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/11/05/faa-cuts-flight-capacity-shutdown.html">https://www.cnbc.com/2025/11/05/faa-cuts-flight-capacity-shutdown.html</a>, See on <a href="https://news.ycombinator.com/item?id=45830797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108222102" data-test="InlineImage"><p>U.S. Transportation Secretary Sean P. Duffy and FAA Administrator Bryan Bedford hold a press conference at the U.S. Department of Transportation Headquarters on Nov. 5, 2025 in Washington, DC. </p><p>Tasos Katopodis | Getty Images</p></div><div><p>Transportation Secretary Sean Duffy announced Wednesday afternoon that he will be reducing flight capacity by 10% at 40 major airports starting on Friday morning, affecting roughly 3,500 to 4,000 flights daily.</p><p>It was not immediately clear which airports would be affected.</p><p>"This is proactive," Duffy said in a news conference.</p><p>Federal Aviation Administration Administrator Bryan Bedford said additional measures could be taken after the initial reduction.</p><p>"As we slice the data more granularly, we are seeing pressures build in a way that we don't feel, if we allow it to go unchecked, will allow us to continue to tell the public that we operate the safest airline system in the world," Bedford said on Wednesday.</p><p>Bedford added that the administration will be meeting with the airline community to decide how to move forward on implementing the reduction, which he said has never happened before during his time in the industry.</p><p>The government shutdown, which entered its 36th full day on Wednesday, is now the longest in U.S. history.</p><p>Duffy said he expects more cancellations as a result of the reduction, which has no set end time. "We thought 10% was the right number based on the pressure we were seeing," Duffy added.</p><p>The move comes as air traffic controllers have <a href="https://www.cnbc.com/2025/10/28/government-shutdown-air-traffic-controllers.html">missed their paychecks</a> due to the government shutdown. Air traffic controllers and Transportation Security Administration screeners are among the essential government employees who are required to work during the shutdown.</p><p>The closure has also raised concerns about already thin staffing among&nbsp;<a href="https://www.cnbc.com/2025/10/10/government-shutdown-airlines-passengers-delays.html">air traffic controllers</a>, the FAA said. Insufficient staffing at some FAA facilities has disrupted some flights since Oct. 1.</p><p>Earlier this week, Duffy told CNBC's "<a href="https://www.cnbc.com/squawk-box-us/">Squawk Box</a>" that he could "shut the whole airspace down" if the shutdown drags on.</p><p>On Wednesday morning, National Air Traffic Controllers Association President Nick Daniels <a href="https://www.cnbc.com/2025/11/05/air-traffic-controllers-government-shutdown.html">told CNBC</a>'s "<a href="https://www.cnbc.com/squawk-box-us/">Squawk Box</a>" that it could take "weeks to recover" from the impacts of the government shutdown on air traffic controllers.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Longtime Mozilla Support Japanese Community Shuts Down over AI Translation Usage (692 pts)]]></title>
            <link>https://support.mozilla.org/en-US/forums/contributors/717446</link>
            <guid>45830770</guid>
            <pubDate>Thu, 06 Nov 2025 02:38:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.mozilla.org/en-US/forums/contributors/717446">https://support.mozilla.org/en-US/forums/contributors/717446</a>, See on <a href="https://news.ycombinator.com/item?id=45830770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      
      <main role="main">
      
      
  <article id="posts">
    <p id="forum-title">SUMO community discussions</p>
    

    
    

    
      <ol>
        
          <li id="post-89603">
            




<div>
  <div>
    <p>Hi, I am a locale leader of SUMO Japanese community. I have contributed to the Support over 20 years, before the beginning of <a href="http://support.mozilla.org/" rel="nofollow">support.mozilla.org</a>.
</p><p>Today, November 4, we decided to end our SUMO Japanese community.
</p><p>In October 22, the sumobot was introduced to Japanese KB articles. I cannot accept its behavior and no words.
</p>
<ul><li> It doesn't follow our translation guidelines.
</li><li> It doesn't respect current localization for Japanese users, so they were lost.
</li><li> It approves its direct English MT immediately for All archived KB articles.
</li><li> It approves only in 72 hours after its updates, so we lost our work to train new contributors.
</li><li> It has been working now without our acceptance, without controls, without communications.
</li><li> Over 300 Knowledge Base articles are overridden by sumobot.
</li></ul>
<p>They are all happened on the product server, not on staging server. I understand that this is mass destruction of our work and explicit violation to the Mozilla mission, allowed officially.
</p><p>Therefore, I (marsf) declare:
</p>
<ul><li> I quit to contribute to <a href="http://support.mozilla.org/" rel="nofollow">support.mozilla.org</a>.
</li><li> I prohibit to use all my translation as learning data for SUMO bot and AIs.
</li><li> I request to remove all my translation from learned data of SUMO AIs.
</li></ul>
<p>However, individual Japanese contributors may want to work in their responsibility. It is their choice, we don't care nor support.
</p><p>Bye.
</p>
  </div>
  <p>Hi, I am a locale leader of SUMO Japanese community. I have contributed to the Support over 20 years, before the beginning of support.mozilla.org.

Today, November 4, we decided to end our SUMO Japanese community.

In October 22, the sumobot was introduced to Japanese KB articles. I cannot accept its behavior and no words.
* It doesn't follow our translation guidelines.
* It doesn't respect current localization for Japanese users, so they were lost.
* It approves its direct English MT immediately for All archived KB articles.
* It approves only in 72 hours after its updates, so we lost our work to train new contributors.
* It has been working now without our acceptance, without controls, without communications.
* Over 300 Knowledge Base articles are overridden by sumobot.

They are all happened on the product server, not on staging server. I understand that this is mass destruction of our work and explicit violation to the Mozilla mission, allowed officially.

Therefore, I (marsf) declare:
* I quit to contribute to support.mozilla.org.
* I prohibit to use all my translation as learning data for SUMO bot and AIs.
* I request to remove all my translation from learned data of SUMO AIs.

However, individual Japanese contributors may want to work in their responsibility. It is their choice, we don't care nor support.

Bye.</p>
  
</div>
          </li>
        
          <li id="post-89606">
            




<div>
  <p>"Gokurosama deshita" (ご苦労様でした)
</p>
  <p>"Gokurosama deshita" (ご苦労様でした)</p>
  
</div>
          </li>
        
          <li id="post-89607">
            




<div>
  <div>
    <p>Hi Marsf, 
</p><p>I'm sorry for how you and the Japanese community feel about the MT workflow that we just recently introduced. Would you be interested to hop on a call with us to talk about this further? We want to make sure we trully understand what you're struggling with. 
</p><p>My timezone is UTC+7, so it should be easier for us to set up time. Let me know how that sound!
</p>
  </div>
  <p>Hi Marsf, 

I'm sorry for how you and the Japanese community feel about the MT workflow that we just recently introduced. Would you be interested to hop on a call with us to talk about this further? We want to make sure we trully understand what you're struggling with. 

My timezone is UTC+7, so it should be easier for us to set up time. Let me know how that sound!</p>
  
</div>
          </li>
        
          <li id="post-89608">
            




<div>
  <div>
    <p>Hi marsf, I'm so sorry to read your message. Even though we haven't seen each other for a while, I still have fond memories of you (we last met at All Hands in Orlando... in 2018). 
I completely understand your frustration after the introduction of SumoBot. We Italians, along with the Spanish, were the first to experiment with automatic translation/updates via SumoBot (<a href="https://support.mozilla.org/en-US/forums/contributors/717387?last=89505" rel="nofollow">https://support.mozilla.org/en-US/forums/contributors/717387?last=89505</a>), and I've already expressed some concerns. I hope that, after talking with Kiki and the staff, you'll change your mind about ceasing your localization contributions.
</p>
<p><em>marsf <a href="#post-89603" rel="nofollow">said</a></em></p><blockquote>• It doesn't follow our translation guidelines.</blockquote><p>
Fortunately, for the Italian localization, our guidelines are being respected.</p><blockquote>• It approves its direct English MT immediately for All archived KB articles.
• It approves only in 72 hours after its updates, so we lost our work to train new contributors.
• It has been working now without our acceptance, without controls, without communications.</blockquote>
<p>These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).
</p><p>I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.
</p><p>Hugs,
Michele
</p>
  </div>
  <p>Hi marsf, I'm so sorry to read your message. Even though we haven't seen each other for a while, I still have fond memories of you (we last met at All Hands in Orlando... in 2018). 
I completely understand your frustration after the introduction of SumoBot. We Italians, along with the Spanish, were the first to experiment with automatic translation/updates via SumoBot (https://support.mozilla.org/en-US/forums/contributors/717387?last=89505), and I've already expressed some concerns. I hope that, after talking with Kiki and the staff, you'll change your mind about ceasing your localization contributions.

''marsf [[#post-89603|said]]''&lt;blockquote&gt;• It doesn't follow our translation guidelines.&lt;/blockquote&gt;
Fortunately, for the Italian localization, our guidelines are being respected.&lt;blockquote&gt;• It approves its direct English MT immediately for All archived KB articles.
• It approves only in 72 hours after its updates, so we lost our work to train new contributors.
• It has been working now without our acceptance, without controls, without communications.&lt;/blockquote&gt;
These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).

I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.

Hugs,
Michele</p>
  
</div>
          </li>
        
          <li id="post-89609">
            




<div>
  <div>
    <p><em>Michele Rodaro <a href="#post-89608" rel="nofollow">said</a></em>
</p>
<blockquote>
Fortunately, for the Italian localization, our guidelines are being respected.
</blockquote>
<p>I wonder if what Marsf referring to was related to the <a href="https://github.com/mozilla/sumo/issues/2605" rel="nofollow">the bug</a> that we recently reported. I have a feeling the bug may have caused the impression that the MT doesn't respect prior translation and guidelines even though it's actually a bug. 
</p>
<blockquote>
These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).</blockquote>
<p>Michele, you and I talked about the struggle of getting new contributors on board. We've been experimenting with training for the Forum Moderators and we've been getting great feedback from the participants so far. Do you think a training or video tutorials would help with this? 
</p>
<blockquote>
I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.
</blockquote><p>Can you tell me more about SUMObot intrusiveness that you've experienced?
  </p></div>
  <p>''Michele Rodaro [[#post-89608|said]]''
&lt;blockquote&gt;
Fortunately, for the Italian localization, our guidelines are being respected.
&lt;/blockquote&gt;
I wonder if what Marsf referring to was related to the [https://github.com/mozilla/sumo/issues/2605 the bug] that we recently reported. I have a feeling the bug may have caused the impression that the MT doesn't respect prior translation and guidelines even though it's actually a bug. 

&lt;blockquote&gt;
These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).&lt;/blockquote&gt;
Michele, you and I talked about the struggle of getting new contributors on board. We've been experimenting with training for the Forum Moderators and we've been getting great feedback from the participants so far. Do you think a training or video tutorials would help with this? 

&lt;blockquote&gt;
I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.
&lt;/blockquote&gt;Can you tell me more about SUMObot intrusiveness that you've experienced?</p>
  
</div>
          </li>
        
      </ol>

      

    

    
    
  </article>

      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI asks U.S. for loan guarantees to fund $1T AI expansion (141 pts)]]></title>
            <link>https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/</link>
            <guid>45830380</guid>
            <pubDate>Thu, 06 Nov 2025 01:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/">https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/</a>, See on <a href="https://news.ycombinator.com/item?id=45830380">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-ref="article-body" data-v-4026719d="" data-v-b25c96a6=""><p data-start="0" data-end="497" data-v-4026719d="">OpenAI is seeking U.S. government support to help finance what could become one of the largest infrastructure buildouts in corporate history — exceeding $1 trillion. Speaking at a Wall Street Journal business conference, Chief Financial Officer Sarah Friar said the company is exploring federal loan guarantees to attract broader funding for its AI computing expansion, describing a potential “ecosystem of banks, private equity, maybe even governmental” participants.</p><p data-start="499" data-end="898" data-v-4026719d="">Friar said government backing would significantly lower borrowing costs and broaden OpenAI’s access to credit markets, since federal guarantees would protect lenders from losses if the company defaulted. The proposal is highly unusual for a Silicon Valley technology firm, effectively positioning OpenAI alongside sectors such as energy and infrastructure that traditionally rely on state support.</p><p data-start="900" data-end="1250" data-v-4026719d="">The company’s request comes amid a wave of capital-intensive commitments, including a $300 billion deal with Oracle and a $500 billion “Stargate” data center venture with Oracle and SoftBank. Despite projecting revenues in the tens of billions this year, OpenAI’s income remains far below the enormous outlays required to sustain its AI operations.</p><p data-start="1252" data-end="1518" data-v-4026719d="">Friar dismissed speculation that OpenAI might soon go public, saying an IPO “is not on the cards right now.” Instead, she emphasized that the company’s focus remains on scaling its capabilities and securing the financing needed to underpin its long-term ambitions.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recursive macros in C, demystified (once the ugly crying stops) (109 pts)]]></title>
            <link>https://h4x0r.org/big-mac-ro-attack/</link>
            <guid>45830223</guid>
            <pubDate>Thu, 06 Nov 2025 01:09:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://h4x0r.org/big-mac-ro-attack/">https://h4x0r.org/big-mac-ro-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=45830223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p><em>In which it becomes clear, the C Preprocessor was designed by <del>a</del> Kafka <del>fan</del></em></p><p>So you have heard rumors whispered between peers, that a rare few people somehow manage to make compile-time recursion work in C? And you want to have some insight into how that might be possible??</p><p>I should warn you, you’re risking your sanity… but I’ll indulge you.</p><p>Wait, did I really just say that? I must be a glutton for punishment, because the macro system is, by far, the thing I like least about C.</p><p>C has many advantages that have led to its longevity (60 years as perhaps the most important language). It has many quirks due to its age, most of which are easy to look past. But despite 30 years writing C, I still bristle at C’s macro system.</p><p>That’s not just because there are many languages (including C++) with more modern takes on compile-time execution. Macros appear simple, but have subtleties that make them poorly suited for anything other than light wrappers.</p><p>Still, being C’s only compile-time execution capability (currently), it is still both critical and important. <em>Critical</em>, in that many venerable critical systems heavily depend on them, and wouldn’t compile without them. <em>Important</em>, in that it’s often the only way to abstract out complexity that would lead to safety or security issues if exposed, such as automatically adding sentinels or static type checks.</p><p>C macros being hard to use does discourage their overuse. It’s easy for too much abstraction to make it too difficult for other people to maintain the code, so in some ways, as painful as they are, I can find some things to appreciate, and do occasionally find reason to use them for something non-trivial.</p><p>But it doesn’t take much for a macro to be non-trivial, because, while C macros can look like functions, they cannot be called recursively (at least, not easily, as we will see).</p><p>I have never been able to find out <em>why</em> recursion is limited in C macros. It could have started off intentional, but compile time execution wasn’t really on people’s minds then; the challenge was abstracting over many platform differences as cheaply as possible.</p><p>I suspect the system evolved as needed in the early days, without really thinking about it as something that perhaps <em>should</em> support recursion. Certainly at some point, the question would get raised; but it’s easy to imagine:</p><ol><li>The organic evolution of the macro system coupled with early success made it brittle, and hard to evolve.</li><li>People were worried about build issues like hanging compile times due to infinite loops, or crashing with no diagnostics, due to infinite recursion.</li></ol><p>Depending on which of these two was more prominent, I could equally imagine the lack of recursion being an accident, or being an intentional choice.</p><p>However it happened, that die was cast in a completely different era—people have definitely woken up to the value of pushing as much into compile time as possible.</p><p>Either way, it all seems archaic and unnecessary now.</p><p>So, let’s roll up our sleeves and learn to cope with the issue!</p><h2 id="motivation">Motivation</h2><p>If you have anything interesting you need done with the preprocessor, you probably need to generalize over multiple items.</p><p>Maybe you want to add automatic sanity checks around parameters, or add automatic type checking. You might want to pre-fill arrays, or generate a list of functions based on some data. Generally, we should be able to do such things at compile time, and in cases like type checking, it is often incredibly challenging to defer the work till runtime. So the lack of a good compile time solution for such things is problematic.</p><p>I tend to reach for macros when they can remove the potential for human error; for example, calling an API wrong. That can indeed be adding automatic casts, enforcing that null terminators get added on variable argument arrays, etc.</p><p>In all of those scenarios, we would need something to move macros toward Turing completeness at compile time. But macros do not advertise support for either of the things we’d be looking for there: <em>iteration</em>, and <em>recursion</em>.</p><p>Thankfully, we can get there. But it’s not going to be easy.</p><p>To frame our discussion, let’s pick a simple, but highly valuable goal. We’re going to build a macro that counts the number of variable arguments in a function-like macro that accepts variable arguments.</p><p>Why that problem? Because from there it’s a short jump to dealing with some common issues, where we can remove large sources of human error:</p><ol><li>Variadic functions (aka varargs) are error prone, because the implementation has to figure out where the arguments stop; the language doesn’t give you a way to know. The caller has to remember to follow your convention (like adding a null terminator). And that convention can often back fire, for example, when a null value is a valid argument . Being able to count the number of variadic arguments allows us to provide a <a href="https://h4x0r.org/vargs/">single, general approach to dealing with this,</a> and to not put the burden on the caller to have to count correctly.</li><li>There are plenty of cases where we’d want to apply a transformation to each argument of a variable argument function, like statically checking that parameters are all the same type, or automatically adding a layer of sanity checking to a third party API, so that the people calling your function can remain blissfully unaware. These don’t directly require counting, but once we can count recursively, it’s a small change to give ourselves a more general purpose <code>map</code> construct to make such transformations.</li></ol><p>You might be surprised that the language doesn’t provide a way to count variable arguments in a macro, especially if you noticed the recent addition of a pre-defined macro called <code>__COUNTER__</code> in the draft C2Y standard. The new <code>__COUNTER__</code> macro is intended to make it easier to provide uniqueness for situations where macros need to generate identifiers and labels; it definitely isn’t for counting variadic macro arguments.</p><h2 id="apparently-math-is-hard">Apparently math is hard?</h2><p>If there’s no primitive to count variadic macro arguments, well, we need to create one, right? And if we have to create one, that means it should be pretty easy, one would hope?</p><h2 id="heading">🦗🦗🦗</h2><p>I see you’re skeptical. But an optimist who wanted to delve into compile-time coding in C for the first time might give it a go. But they will quickly find that the obvious approach below, that feels like it should work, absolutely <em><strong>does not work</strong></em>:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>// The first macro... counts one argument, then we'd like it to recurse.</span>
</span></span><span><span><span>#</span>define <span>_COUNT_ONE</span>(x, ...) <span>+</span> 1 <span>_COUNT_TOP</span>(__VA_ARGS__)
</span></span><span><span><span>#</span>define <span>_COUNT_TOP</span>(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>COUNT</span>(...)        (_COUNT_TOP(__VA_ARGS__) <span>+</span> 0)
</span></span></code></pre></div><p>Try to call this code, and…</p><h2 id="heading-1">🤮</h2><p>Yup, it’ll barf.</p><p>What this doe-eyed attempt is <em>trying</em> to do, is generate an expression (at compile time) of the form <code>(+ 1 + 1 + … + 0)</code>, by iterating over each argument at a call site (via recursion). It doesn’t care what the arguments are, it just wants to generate a <code>+ 1</code> for each valid argument, and a <code>+ 0</code> at the end, both to make it a valid expression and to handle the case where there are no arguments passed.</p><p>If we’re successful, the addition will all happen at compile time, and will be what C calls an <em>integer constant expression</em>. That means, the compiler will, at compile time, fold this into a single static integer. So, even if it feels inefficient, there is no run-time cost involved.</p><p>Why three macros? That seems a bit excessive, right?</p><p>Unfortunately, C currently doesn’t have an easy way to do the equivalent of an <code>if()</code> statement at compile time. It’s possible to create something with macros, but that’s just extra hackery.</p><p>Instead, we split the primary body into its own macro— <code>_COUNT_ONE()</code>, which adds the <code>1 +</code> and then triggers recursion (we wish, anyway; again, the recursion part won’t work this easily).</p><p>The intent the behind <code>_COUNT_TOP()</code> macro is evaluating an exit condition for our recursion. Specifically, we want to stop when we have no more arguments left in the function. The builtin macro <code>__VA_OPT__()</code> allows us to do exactly that— the text inside the parentheses gets expanded only if there are arguments. And when there are no arguments, the text inside the parentheses is discarded.</p><p>This gives us a lightweight way to separate the one argument case from the two argument case, without need for a kind of <code>if</code> statement; the 0-case won’t generate a recursive call. To combine this with <code>_COUNT_ONE()</code>, we’d need a primitive that allowed us to specify a replacement that only expands when there are <em>no</em> arguments, which doesn’t come out of the box.</p><p>The outer <code>COUNT()</code> macro could be factored out trivially; I leave it because it keeps what’s going on a bit clearer. This macro is the actual entry point, adds the ‘0’ a single time the end, and wraps the whole thing in parentheses, which helps avoid running afoul of operator precedence rules.</p><p>If we directly combine it with <code>_COUNT_TOP()</code> in the obvious way, it would compute the right thing, but it would do it by adding the <code>+ 0</code> after EVERY term, and parenthesizing the expression in a way that would come off as odd if you were looking at the resulting C code. For instance, we’d be aiming for a three argument function to generate:</p><p><code>( + 1 ( + 1 ( + 1 ( + 0 ) + 0 ) + 0 ) + 0 )</code>
If we were to generate this code, it’d be ugly, but most people would declare success and move on. But unfortunately, the above code does not work, and will never work, no matter how many iterations of the standard are released between now and the heat death of the universe— changing the behavior would be too likely to impact plenty of real code.</p><p>For example, let’s attempt to use the above implementation like so:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"COUNT() = %d</span><span>\n</span><span>"</span>, <span>COUNT</span>(<span>1</span>, <span>2</span>, <span>3</span>));
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>With <code>clang</code>, I get:</p><div><pre tabindex="0"><code data-lang="yaml"><span><span><span>tmp.c:8:30: error</span>: <span>expected ')'</span>
</span></span><span><span>    <span>8</span> <span>|     printf("COUNT() = %d\n", COUNT(1, 2, 3));</span>
</span></span><span><span>      <span>|                              ^</span>
</span></span><span><span><span>tmp.c:4:28: note</span>: <span>expanded from macro 'COUNT'</span>
</span></span><span><span>    <span>4</span> <span>|</span> <span>#define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)</span>
</span></span><span><span>      <span>|                            ^</span>
</span></span><span><span><span>tmp.c:3:39: note</span>: <span>expanded from macro '_COUNT_TOP'</span>
</span></span><span><span>    <span>3</span> <span>|</span> <span>#define _COUNT_TOP(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))</span>
</span></span><span><span>      <span>|                                       ^</span>
</span></span><span><span><span>tmp.c:2:32: note</span>: <span>expanded from macro '_COUNT_ONE'</span>
</span></span><span><span>    <span>2</span> <span>|</span> <span>#define _COUNT_ONE(x, ...) + 1 _COUNT_TOP(__VA_ARGS__)</span>
</span></span><span><span>      <span>|                                ^</span>
</span></span><span><span><span>tmp.c:39:30: note</span>: <span>to match this '('</span>
</span></span><span><span><span>tmp.c:4:27: note</span>: <span>expanded from macro 'COUNT'</span>
</span></span><span><span>    <span>4</span> <span>|</span> <span>#define COUNT(...)        (_COUNT_TOP(__VA_ARGS__) + 0)</span>
</span></span></code></pre></div><p>Wow, that’s a lot of error messages, saying little that makes sense.</p><p>I’m sure you can already get the feeling that, when you have a problem with your macros, it’s incredibly challenging to translate the resulting errors into what’s actually wrong. Here, it’s complaining about balancing parentheses, and with just a bit more complexity in our macros, it’d be incredibly easy for someone to spend 10 minutes trying to figure out where the parenthesis is missing, when <em>no parenthesis is missing whatsoever</em>.</p><p>Or, we could have taken advantage of the fact that C is perfectly happy to accept <code>+ + 0</code>, and write <code>1 +</code> instead of <code>+ 1</code>.</p><p>Making that microscopic change, merely transposing two tokens, completely changes the error <code>clang</code> produces:</p><div><pre tabindex="0"><code data-lang="c"><span><span>tmp.c:<span>8</span><span>:</span><span>30</span><span>:</span> error: call to undeclared function <span>'</span>_COUNT_TOP<span>'</span>; ISO C99 and later <span>do</span> not support implicit function declarations [<span>-</span>Wimplicit<span>-</span>function<span>-</span>declaration]
</span></span><span><span>   <span>8</span> <span>|</span>     <span>printf</span>(<span>"COUNT() = %d</span><span>\n</span><span>"</span>, <span>COUNT</span>(<span>1</span>, <span>2</span>, <span>3</span>));
</span></span></code></pre></div><p>Hey, at least that message is concise. Never mind that it’s <em>totally different</em>, and also <strong>unrelated to the real issue</strong>.</p><h2 id="not-counting-on-it">Not counting on it</h2><p>The C Preprocessor (which I will usually call CPP) is responsible for macro expansion and processing lines with a leading <code>#</code>. As we’ve said, it does not fully support recursion. As you might expect, that’s the core of the actual problem in our first attempt. Yet, the preprocessor happily thinks it did its job. We’ll see in more detail what’s going on, but the crux of this particular problem is <em>how</em> recursion is disallowed, not that it IS disallowed.</p><p>The problem here is that C macros are their own programming language, being used to generate C code. The macro language doesn’t model most of the interesting parts of the language, and it is quite easy to produce code that the preprocessor finds acceptable, that the compiler cannot understand (as we will see).</p><p>In both these cases, the preprocessor feels like it’s done its job, and passes off its work to the C compiler. The C compiler gets the generated code, and has no idea that macros were used. It calls the error as it sees it.</p><p>This disconnect between the preprocessor and the compiler is one of the things that makes macros in C so unfriendly.</p><p>If a macro expansion (basically the same as an ‘evaluation’) is recursive, the CPP decides “they can’t possibly have wanted recursion here, because that might loop forever, so this must be plain old text I have to substitute”. <em>As a result, the emitted code will still contain the unexpanded macro.</em></p><p>How can we confirm this? If we can’t understand the resulting transformations, we’re going to end up stumbling around in the dark.</p><p>Many developers don’t know how to see what the C preprocessor actually produces. If the preprocessor successfully exits, we <em>can</em> see it’s output by stopping the compiler after the preprocessing phase, generally with the <code>-E</code> flag. If we don’t give a file name (via the <code>-o</code> flag), we should see the results on the terminal. And at least in the case of <code>clang</code>, we will even get output up to the point that we did something so wrong that the preprocessor gives us an error.</p><p>For the code above, running <code>cc -E tmp.c</code> works without errors, and dumps the output of CPP to my terminal.</p><p>That consists of a lot of stuff you might not expect to see. The output contains our code after the preprocessor has <em>fully</em> expanded it. But that full expansion includes the results of it preprocessing all of the header files we pulled in, which in our case was <code>stdio.h</code>, and any cascading dependencies it might have.</p><p>However, our code is easy to find in that noise. The last thing output will be our fully translated <code>main()</code> function, ready to be input into the C compiler. For the case where we add <code>+1</code> at the beginning of the macro, we will see:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"COUNT() = %d</span><span>\n</span><span>"</span>, (<span>+</span><span>1</span> <span>_COUNT_TOP</span>(<span>2</span>, <span>3</span>) <span>+</span> <span>0</span>));
</span></span><span><span>    <span>return</span> <span>0</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>Here, the compiler doesn’t have to try to look up the symbol <code>_COUNT_TOP</code>; it knows that it doesn’t make sense to have a function call after a number with no operator in between.</p><p>When we reverse the <code>+</code> and the <code>1</code>, the line of code is valid, as long as there’s a function C can resolve called <code>_COUNT_TOP</code>. Because there isn’t, the compiler bails.</p><p>That explains why we get two different errors, for such a minor change.</p><p>Because CPP and the compiler itself are oblivious to the execution of the other, and because we have to live with the fact that recursive macros aren’t errors to the CPP (silently passing them through unexpanded), it’s quite a bit of work for any compiler to even try to tell you that your problem here is attempting to use recursion in a macro. It could be done, and maybe it <em>should</em> be done, because otherwise, compilers are effectively trying to gaslight you into believing you have a syntax error of some sort.</p><p>Because the preprocessor is much more permissive than the compiler, without the compiler having any awareness of macros even existing is perhaps the most significant reason why writing non-trivial macros is so hard to do.</p><p>Again, we can hack our way around the recursion problem. The semantics are arcane and intricate enough that, even knowing the rules (and doing macro work with a copy of the standard at the ready), macro development is incredibly challenging the second you have any problem at all. Decades later, I often feel like I’m stumbling around in the dark when a macro I write blows up on me.</p><p>If this is all too intimidating, absolutely we can plagiarize our way to success. Though, personally, I really prefer not to cut-and-paste code from Stack Overflow, especially if it’s code I don’t understand. Similarly, while Claude and I are casual acquaintances, I do not trust his code. It’s my unwillingness to <em>using code I don’t understand</em> in production that keeps me learning and growing.
Instead, I avoid non-trivial macros, unless (as I said above), I make an exception when they will be a huge net positive for helping the developer, usually by removing potential failure modes, or with significant clarity improvements.
Meaning, if you can use them to provide an abstraction that makes the code more robust, and is also not going to be hard to maintain if the need arises, then I’d consider it (even if you have to get Claude to write it).
Here, automating size detection statically feels like a good enough use case for my tastes, because macros will not only make variadic functions easier to write, but also make it far easier to call them correctly.</p><p>So, I’d like to help those interested understand how to navigate through the pain, and shine a light on it, in the hopes that this is another area of the language that the modern standards committee can make massively better.</p><h2 id="that-doesnt-count">That doesn’t count</h2><p>If we want to know how to circumvent the recursion restriction, we probably need to understand the detection mechanism we are attempting to evade.</p><p>It sure would be nice if we could debug by having our compiler give us intermediate expansions, up until the point that it breaks. This is not directly built into any compiler as far as I know. And my experience with macro debuggers has been that they have a hard time matching compiler semantics. I dusted one of them off when working on this article, and it was easy to get it to expand macros as valid that CPP barfed on, and vice versa.
Despite the lack of tooling, I’ll walk through the expansion process in detail so we can all understand.</p><p>The rules for C macro evaluation are hard to explain in a way that’s simultaneously precise and clear. But for function-like macros, the main process of evaluating a macro boils down to:</p><ol><li><strong>Replace the macro text.</strong> <em>Stashing aside the arguments used to call the macro</em>, we replace the full macro with the textual body, within the larger token stream we’re processing.</li><li><strong>Add placeholder tokens.</strong> Instances of ‘arguments’ in the body get replaced with placeholder tokens, to prevent them from being evaluated as macros in any nested argument expansion we might have. This includes <code>__VA_ARGS__</code> and <code>__VA_OPT__()</code> invocations.</li><li><strong>Evaluate preprocessor operators</strong> in the body that take operands , particularly <code>#</code> and <code>##</code>. We don’t make good use of these operators in this article, so we won’t cover in too much depth. Note, however, that <code>__VA_OPT__()</code> is also a preprocessor operator that takes arguments. We inhibited expansion within the replacement text, when we were evaluating operators, but at the end of this phase, we put it back; it can get expanded in the next step.</li><li><strong>Rescanning the body</strong>. The body is then scanned for more macros to expand, starting from our cursor in the token stream. The “input” head moves forward a token at a time, until we mind a macro to expand, or reach the end of the macro we’re evaluating. When we find a macro to expand, we recursively apply the algorithm.</li></ol><p>There are some pretty large subtleties here. As long as a macro invocation starts in the scope of a rescan, the scanning head position can move past the end of the original macro. For example, consider this basic scenario:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#define CONCAT(X, Y)  X ## Y
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> PRINT_INT <span>=</span> <span>100</span>;
</span></span><span><span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"%d</span><span>\n</span><span>"</span>, <span>CONCAT</span>(PRINT_, INT));
</span></span><span><span>}
</span></span></code></pre></div><p>The <code>##</code> operator, seen used in the <code>CONCAT</code> macro, appends two tokens together, turning them into a single preprocessor token.</p><p>When the preprocessor evaluates <code>CONCAT()</code>, it will result in the token <code>PRINT_INT</code>. If <code>PRINT_INT</code> were a macro, the preprocessor would do further expansion. But it is not, so the preprocessor outputs <code>PRINT_INT</code>. The C compiler does not complain, because it sees a variable named <code>PRINT_INT</code>.</p><p>So far, depending on your background, the semantics may or may not being intuitive. But either way, what do you think should happen in this slightly more complex scenario?</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#define CONCAT(X, Y)  X ## Y
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define PRINT_INT(N)  printf("look an integer %d\n", (N));
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> PRINT_INT <span>=</span> <span>100</span>;
</span></span><span><span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"%d</span><span>\n</span><span>"</span>, <span>CONCAT</span>(PRINT_, INT));
</span></span><span><span>    <span>CONCAT</span>(PRINT_,INT)(<span>100</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>It would be reasonable to think there’s an error here, but this code will compile and run. Why? In both cases, the preprocessor will generate the token <code>PRINT_INT</code>. In the first case, everything will happen the same way it did in our first example, and the compiler will see the variable <code>PRINT_INT</code>.</p><p>But, with the second use of <code>CONCAT</code>, the preprocessor will see that there is a parenthesis immediately following the token <code>PRINT_INT</code>. Since it has a function-like macro with that name, it will prefer the macro interpretation.</p><p>That’s true, even though we didn’t directly write <code>PRINT_INT</code> in the code, there. The effective result of the preprocessor’s expansion would look like this:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#define CONCAT(X, Y)  X ## Y
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define PRINT_INT(N)  printf("look an integer %d\n", (N));
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> PRINT_INT <span>=</span> <span>100</span>;
</span></span><span><span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"%d</span><span>\n</span><span>"</span>, <span>100</span>);
</span></span><span><span>    <span>printf</span>(<span>"look an integer %d</span><span>\n</span><span>"</span>, <span>100</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>That’s because C’s macros come in two flavors, with slightly different semantics:</p><ol><li><em><strong>Function-like macros</strong></em>, which take arguments, and syntactically LOOK like functions. As we see here, if the preprocessor sees a token with the same name as a function like macro, but it’s not used like a function like macro, it will pass it through, letting the C compiler resolve the token.</li><li><em><strong>Object-like macros</strong></em>, the definitions of which look like variables, and do not take arguments. If the C preprocessor sees a left parenthesis after an object-like macro, that token will just be passed through directly to the compiler.</li></ol><p>That is why the following code does NOT error. In fact, it runs quite happily:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span>#define OBJECT_LIKE_MACRO printf</span>
</span></span><span><span><span>#include &lt;stdio.h&gt;</span>
</span></span><span><span>int main<span>()</span>
</span></span><span><span><span>{</span>
</span></span><span><span>  OBJECT_LIKE_MACRO<span>(</span><span>"Hello, world!\n"</span><span>)</span>;
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Meaning, if we we have an object-like macro and it looks like we’re trying to call it, the C preprocessor isn’t going to call it. It’s just going to pass the token through, and let the compiler figure it out.</p><p>As you can see, the preprocessor’s philosophy is to do its job, and nothing else.</p><p>Another preprocessor subtlety that’s easy to miss, yet important to understand is:</p><table><tbody><tr><td>ℹ️️</td><td>Arguments to function-like macros are expanded at the call site. For expansions that trigger inside the body where those arguments are used, the contents of the <i>expanded arguments will not be available to be part of any additional expansion.</i></td></tr></tbody></table><p>The preprocessor’s approach of substituting arguments with placeholder tokens during evaluation is pretty effective at stopping a bunch of accidental recursion that would be non-intuitive. Although, it’s not the problem for the recursion we’re trying to solve. The barrier we’re hitting is a subtlety that we haven’t discussed yet, but we’ll get to it soon enough.</p><p>Before that, let’s solidify our understanding by walking through the relevant steps with our invocation of <code>COUNT(1)</code> .</p><table><caption><h2>Big Mac-ro expansion example</h2></caption><tbody><tr><td><asciinema-marker-player src="/asciinema/macro_expansion.cast"></asciinema-marker-player></td></tr></tbody></table><p>We’ve learned that, when <code>COUNT()</code> has an invocation of <code>_COUNT_TOP()</code>, the replacement text cannot lead to recursion. The expansion endures the rescan, and nothing attempts to expand it.</p><p>The rule that’s preventing the expansion is effectively an explicit anti-recursion rule. Formally, when we replace a macro, that macro is marked as currently being replaced. The mark stays, until that replacement is totally finished, including its rescan.</p><p>And, unfortunately, marked macros are ineligible for replacement. Note the rescan ineligibility is IN THE CALLING ENVIRONMENT. That’s going to cause us some grief in a few minutes.</p><p>For whatever reason, the original C89 standards committee referred to a macro marked as ineligible for expansion as <em>painted blue</em>.</p><table><tbody><tr><td>❓</td><td>Why the term <em>painted blue</em>? Perhaps the standards committee at the time realized how miserable it was going to make future C developers?
It’s not a term mentioned in the standard, but is often used when people try to explain the whole process.</td></tr></tbody></table><h2 id="im-blue-because-i-cant-count-on-you">I’m blue, because I can’t count on you</h2><p>We <em>can</em> work around the problem, despite there being no way in C to opt out of your macro getting painted blue. But the work-around is going to be hard fought.</p><p>First, let’s give ourselves a cause to be optimistic: the restriction that’s preventing <code>_COUNT_TOP()</code> from recursively expanding is relaxed when the second <code>_COUNT_TOP()</code> gets replaced. If, instead, the restriction stayed in full force the entire time we’ve evaluating <code>COUNT()</code>, then you would not be able to do the following:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span>#define H4X(x) # x </span><span>// convert to string
</span></span></span><span><span><span></span><span>#define DUPE(token) H4X(token) H4X(token)
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> 
</span></span><span><span><span>main</span>() {
</span></span><span><span>    <span>printf</span>(<span>"%s</span><span>\n</span><span>"</span>, <span>DUPE</span>(h4x0r));
</span></span><span><span>}
</span></span></code></pre></div><p>But that will absolutely work. The preprocessor will output exactly what I intended:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"%s</span><span>\n</span><span>"</span>, <span>"h4x0r"</span> <span>"h4x0r"</span>);
</span></span><span><span>}
</span></span></code></pre></div><p>In C, two string literals next to each other are merged into a single literal at compile time, so this program prints:</p><p>This leads us to believe that the blue paint wears off when the rescan moves past an expanded macro, after we’ve processed its replacement.</p><p>So our hypothesis right now might be that <code>_COUNT_ONE()</code> expanding inside <code>COUNT()</code> is fine, as long as it happens after the processing head moves past the start of where the macro was, after expansion.</p><p>If that’s the case, then all we need to do now is add another layer of indirection, right? Let the calling macro evaluate its recursive call on rescan!</p><p>That would make sense! We’ll rewrite our attempt at recursion to add a proxy layer to call <code>_COUNT_TOP()</code>, knowing it cannot re-expand.</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_ONE</span>(x, ...) <span>+</span> 1 <span>_COUNT_TOP</span>(__VA_ARGS__)
</span></span><span><span><span>#</span>define <span>_COUNT_TOP</span>(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>_COUNT_PROXY</span>(...)  (_COUNT_TOP(__VA_ARGS__) <span>+</span> 0)
</span></span><span><span><span>#</span>define <span>COUNT</span>(...)         _COUNT_PROXY(__VA_ARGS__)
</span></span></code></pre></div><p>We’d now expect the replacement when our evaluation gets back up to <code>COUNT(1, 2, 3)</code> to look like:</p><div><pre tabindex="0"><code data-lang="java"><span><span>(<span>+</span>1 <span>_COUNT_TOP</span>(2, 3) <span>+</span> 0))
</span></span></code></pre></div><p>So now, we’re thinking that escaped the paint, and <code>_COUNT_TOP()</code> will further expand, right? 🦗🦗🦗</p><p>It’s time to shatter our youthful optimism with the bitter pill of experience. Yes, we’ve added an extra indirection, but here’s what it expands to:</p><div><pre tabindex="0"><code data-lang="java"><span><span>(<span>+</span>1 <span>_COUNT_TOP</span>(2, 3) <span>+</span> 0))
</span></span></code></pre></div><h2 id="heading-2">🤯</h2><p>That’s the same as our intermediate expansion, but nothing further was done to the macro! I thought we made our way past the paint?</p><p>Clearly, there are subtleties to the rules somewhere. Clearly, the author is a jerk, and must have intentionally failed to mention it above.</p><p>It’s true I am a jerk, and it’s also true that I failed to mention the restriction that’s biting us right now. That’s because it’s a part of the journey— no tutorial or explanation I’ve ever seen made it clear to me that restrictions on expanded macros can survive past the call site.</p><p>So maybe I’m just obtuse, and torturing others because I once suffered long ago. Let’s go look at the relevant text in the C23 standard, shall we? It’ll either be enlightening… or further torture.</p><table><tbody><tr><td>ℹ️️</td><td><p>After all parameters in the replacement list have been substituted and # and ## processing has taken place, all place-marker preprocessing tokens are removed. The resulting preprocessing token sequence is then rescanned, along with all subsequent preprocessing tokens of the source file, for more macro names to replace.</p><p><strong>If the name of the macro being replaced is found during this scan of the replacement list (not including the rest of the source file’s preprocessing tokens), it is not replaced.</strong> <i>Furthermore, if any nested replacements encounter the name of the macro being replaced, it is not replaced. These non-replaced macro name preprocessing tokens are no longer available for further replacement even if they are later (re)examined in contexts in which that macro name preprocessing token would otherwise have been replaced.</i></p></td></tr></tbody></table><p>The sentence I bolded, I think we clearly understood; I did explain it above. The two sentences afterward, which I put in italics, is where the restriction that’s hurting us is specified.</p><p>For <em>years</em>, I took that to mean, “Even at the top level where the macro was called, no matter how many times subsequent replacement text gets rescanned, the called macro is still ineligible for expansion.”</p><p>What am I doing wrong? Why does the blue paint leave and then come back? This makes no sense. Right? Right?</p><h2 id="heading-3">😭😭</h2><p>(I warned you, there’d be ugly crying. Better me than you though; I clearly deserve it).</p><h2 id="close-n-counter">Close n-counter</h2><p>Perhaps it would be obvious to most readers that I had misinterpreted the standard. Perhaps, but even once I finally realized that my original interpretation couldn’t possibly be right, I still feel the above text from the standard is bit under-specified.</p><p>Specifically, what are the boundaries for “nested replacement”? Clearly it’s not the case that once a macro is called, a parent of the calling macro can never replace it again. So does it mean, “the resulting text can never, in any way be involved in an expansion which produces an expansion ever again?” requiring full taint tracking of the replacement through all future transformations as long as the text could possibly be rescanned, no matter what?</p><p>Or, does it only apply to any text with the name of the function we called, and the second that changes, it could change back?</p><p>Or maybe there are some different semantics?</p><p>Let’s roll up our sleeves, with another little experiment, to help us determine how we should interpret the above test. What we’d like to see, is, can <code>_COUNT_ONE()</code> produce a macro invocation with a different name, that we <em>don’t try to expand</em> until after leaving the context in which it and <code>_COUNT_TOP()</code> are painted, and then somehow replace that macro with <code>_COUNT_TOP()</code>?</p><p>If we can make that happen, then we’ll test to see if we can call the resulting function is callable. Let’s junk our previous experiment, and go back to where we were before:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_ONE</span>(x, ...) <span>+</span> 1 <span>_COUNT_TOP</span>(__VA_ARGS__)
</span></span><span><span><span>#</span>define <span>_COUNT_TOP</span>(...)    __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>COUNT</span>(...)        (_COUNT_TOP(__VA_ARGS__) <span>+</span> 0)
</span></span></code></pre></div><p>Now, we want to try to change the value of <code>_COUNT_TOP</code> to something else to escape detection. It’s got to be a valid macro, but one that we’re NOT going to end up expanding when rescanning <code>_COUNT_ONE()</code> or <code>_COUNT_TOP()</code>. If we call it <code>_COUNT_INDIRECT</code>, we don’t want <code>_COUNT_INDIRECT(2,3)</code> to evaluate until we pop all the way back up into <code>_COUNT()</code>.</p><p>Sounds like a tall order, but there’s are a couple of facts we’ve already learned, that can help us:</p><ol><li>We know that, if we have a function-like macro named <code>X()</code>, the preprocessor does not consider a bare <code>X</code> with no parenthesis next to it to be an invocation of <code>X</code>.</li><li>Rescans start at the replacement site, they don’t back up tokens.</li></ol><p>So perhaps we can separate the function name and the arguments for a while, and somehow bring them together in a way where we could rescan it inside <code>COUNT()</code>.</p><p>Having the function name separate from an argument list will both keep it from running, and will help us avoid a rescan the first time we get the left parenthesis to plop down in the right place.</p><p>We just need a way to add a spacer of some sort that goes away at rescan, to keep apart the name <code>_COUNT_ONE</code> from its argument list. That is, we’d conceptually like to do:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_ONE</span>(x, ...) <span>\</span>
</span></span><span><span>   <span>+</span> 1 <span>__VA_OPT__</span>(_COUNT_ONE <span>&lt;&lt;</span>SPACER<span>&gt;&gt;</span> (__VA_ARGS__))
</span></span></code></pre></div><p>But we’re going to change the name of <code>_COUNT_ONE</code> to <code>_COUNT_INDRECT</code>. If we just do:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define _COUNT_INDIRECT _COUNT_ONE
</span></span></code></pre></div><p>Then we’re going to re-generate <code>_COUNT_ONE</code> on the rescan, which is painted blue.</p><p>So it’s actually <code>_COUNT_INDIRECT</code> where we currently have the dire need to postpone evaluating it.</p><p>Therefore, we need to turn <code>_COUNT_INDIRECT</code> into a function, and keep THAT identifier separated from the parentheses that trigger it, via our to-be-written spacer. So this is the definition we want instead:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_INDIRECT</span>() _COUNT_ONE
</span></span></code></pre></div><p>We’ll also need to add the empty parameter list to invoke it on the other side of our spacer. So here’s what we really need <code>_COUNT_ONE</code> to look like:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_ONE</span>(x, ...) <span>\</span>
</span></span><span><span>   <span>+</span> 1 <span>__VA_OPT__</span>(_COUNT_INDIRECT <span>&lt;&lt;</span>SPACER<span>&gt;&gt;</span> ()(__VA_ARGS__))
</span></span></code></pre></div><p>As we cascade up with replacements, we want the spacer to disappear, leaving:</p><p>Remember, in the contents where we replace the spacer, we will have advanced the input head past <code>_COUNT_INDIRECT</code>. So if the spacer expands to nothing, the rescan will know that <code>()</code> isn’t a replaceable macro, and go on with its day. But it will leave <code>_COUNT_INDIRECT</code> next to the <code>()</code> so it can be called above, to generate the correct name.</p><h2 id="you-can-count-on-me-being-empty-inside">You can count on me being empty inside</h2><p>It’s not hard to get something to expand to the empty string.</p><p>And then, once we get back up to <code>COUNT()</code>, we will evaluate <code>_COUNT_INDIRECT()</code>, which will leave us with <code>_COUNT_ONE(2,3)</code>.</p><p>Once we get that far, will tinker to find if there are any conditions where we can re-invoke <code>_COUNT_ONE()</code>. Because hey, we already know there are, we just might not know WHAT they are.</p><p>It’s not hard to create a spacer. We can define a macro named <code>EMPTY</code> like this:</p><p>And use that as our spacer. If you’ve ever peeked into someone’s recursive macros and been dumbfounded with what you saw, there’s a good chance you saw a macro named <code>EMPTY</code> and at the time were thinking, “what the heck could that possibly do?”</p><p>Now you know. But when you did see it, it was probably defined as a function-like macro instead:</p><p>Using it to postpone evaluation is as easy as:</p><div><pre tabindex="0"><code data-lang="java"><span><span>_COUNT_INDIRECT <span>EMPTY</span>() () (2, 3)
</span></span></code></pre></div><p>Why would we use a function-like macro for our spacer? Doing so makes it easy for us to control how long we want to wait before we’re able to evaluate what we’re separating.</p><p>Specifically, let’s say we nest our recursive call several levels down. Every level, we use the same trick recursively, separating <code>EMPTY()</code> apart… using another <code>EMPTY()</code> invocation.</p><p>For instance, if we need to postpone a total of three layers, we could write:</p><div><pre tabindex="0"><code data-lang="java"><span><span>_COUNT_INDIRECT EMPTY EMPTY <span>EMPTY</span>() () () () (2, 3)
</span></span></code></pre></div><p>Honestly, <code>EMPTY()</code> is a confusing name that detracts from what’s happening. we can encapsulate this into a more readable macro… or macros, one for each level we might want to postpone evaluation:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>POSTPONE1</span>(macro_name, args) macro_name <span>EMPTY</span>() args
</span></span><span><span><span>#</span>define <span>POSTPONE2</span>(macro_name, args) macro_name EMPTY <span>EMPTY</span>()() args
</span></span><span><span><span>#</span>define <span>POSTPONE3</span>(macro_name, args) <span>\</span>
</span></span><span><span>                               macro_name EMPTY EMPTY <span>EMPTY</span>()()() args
</span></span></code></pre></div><p>We’ll only need the first of these by the way; but now you know, if you never have a use case where you have deeper nesting (though if you do, maybe worry your macros are getting too complex to be readable?)</p><p>Our <code>POSTPONE1</code> macro encapsulates the unintuitive <code>EMPTY()</code> madness for us, allowing us to instead write:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_ONE</span>(x, ...) <span>\</span>
</span></span><span><span>                    <span>+</span> 1 <span>__VA_OPT__</span>(POSTPONE1(_COUNT_INDIRECT, ())(__VA_ARGS__))
</span></span></code></pre></div><p>The <code>EMPTY()</code> invocation is hidden inside <code>POSTPONE1()</code> That makes the code we use here, it’s more explicit that we’re going to postpone expanding <code>_COUNT_INDIRECT</code>. We’ve even added the args we want to call it with as a second parameter, to make it more clear what we’re doing, instead of having a bunch of consecutive argument lists detached from their identifier, which many engineers find alien and incomprehensible.</p><p>So far, the rest of what we have is:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_COUNT_TOP</span>(...)   __VA_OPT__(_COUNT_ONE(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>COUNT</span>(...)        (_COUNT_TOP(__VA_ARGS__) <span>+</span> 0)
</span></span><span><span><span>#</span>define <span>_COUNT_INDIRECT</span>() _COUNT_ONE
</span></span></code></pre></div><p>Let’s now see if it is getting the right text up to the top, even though we won’t yet try to get it to expand (and thus, we will get a compiler error). If we invoke as <code>COUNT(1, 2)</code> again, CPP will generate the following expansion:</p><div><pre tabindex="0"><code data-lang="java"><span><span>(<span>+</span>1 <span>_COUNT_INDIRECT</span> ()(2) <span>+</span> 0)
</span></span></code></pre></div><p>That… looks exactly like what we were hoping to see. As we wanted, the pieces came together, and <code>_COUNT_INDIRECT()</code> did NOT get evaluated during the rescan process. If we had made a mistake, and the rescan had happened, it would have been replaced with <code>_COUNT_ONE</code>, which we already know we could <em>not</em> trigger for re-evaluation.</p><p>Okay, let’s now see what happens if we try to force the expansion of the above, to finally get an answer to our question as to the true scope of blue paint.</p><p>Let’s wrap the body of <code>COUNT()</code> with a call to a passthrough macro, which we’ll name <code>EVAL()</code>:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>EVAL</span>(...)  __VA_ARGS__
</span></span><span><span><span>#</span>define <span>COUNT</span>(...) EVAL((_COUNT_TOP(__VA_ARGS__) <span>+</span> 0))
</span></span></code></pre></div><p>Based on our rules above, <code>EVAL()</code> will substitute, and then rescan. So this passthrough macro forces the rescan we want.</p><p>The test case for our macro should be:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"%d</span><span>\n</span><span>"</span>, <span>COUNT</span>(<span>1</span>, <span>2</span>));
</span></span><span><span>}
</span></span></code></pre></div><p>You might notice, <em>this actually compiles</em>. And if you run it, <em>it gives the right answer</em>.</p><h2 id="heading-4">🥹</h2><p>Wow, are we done?</p><h3 id="heading-5">🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣😂🤣</h3><p>While we may be farther than expected, we don’t have something that will fully work. What’s important is that we’ve shown that blue paint FULLY gets removed from a macro when:</p><ol><li>We have finished all rescans of that macro where it was called; and</li><li>EITHER the macro does not appear in the replacement text, or we completely exit the recursive expansion.</li></ol><p>Unfortunately, we still have a problem. If you change your invocation to <code>COUNT(1, 2, 3)</code> then your code will no longer compile. Instead, it will expand to:</p><div><pre tabindex="0"><code data-lang="java"><span><span>(<span>+</span>1 <span>+</span>1 <span>_COUNT_INDIRECT</span> ()(3) <span>+</span> 0))
</span></span></code></pre></div><p>What’s happening should be clear at this point: while we are iterating over arguments, we are stopping after the second iteration.</p><p>Great, that’s easy to fix. We can do so by…</p><p>Passing the output of <code>EVAL()</code> to another call of <code>EVAL()</code>, like so:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>COUNT</span>(...) EVAL(EVAL((_COUNT_TOP(__VA_ARGS__) <span>+</span> 0)))
</span></span></code></pre></div><p>Before we address the obvious complaint, I’d like to point out that the extra <code>EVAL()</code> doesn’t mess up the results if we change our test invocation to <code>COUNT()</code> or <code>COUNT(1)</code>.</p><p><code>EVAL()</code> will expand, but it doesn’t break anything when there are no macros in the text passed to it that are eligible for expansion. Once the last possible expansion happens, it will just keep copying its arguments to the replacement text, per the algorithm above; the associated rescans have nothing to do.</p><p>Given that, it’s common to say, “Nobody needs more than 10 arguments!” and do something like:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_E</span>(...) __VA_ARGS__
</span></span><span><span><span>#</span>define <span>EVAL</span>(...) _E(_E(_E(_E(_E(_E(_E(_E(_E(_E(__VA_ARGS__))))))))))
</span></span></code></pre></div><p>Although, more commonly, you’d probably see people do more expansions, perhaps enough to accommodate 20 or 50 arguments. Even there, I’ve seen some Microsoft APIs that convince me, that’s too low a limit, so I’d suggest at least 100 iterations.</p><p>We can use a much smarter approach that can still fairly compactly get us as many expansions as we think we might ever need.</p><p>I’d guess that, if we saw a function with 1024 arguments, it would be explicitly TRYING to break our macro. So let’s do the base 2 version of the Spinal Tap “one more”, and get to 1025 expansions:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_E1</span>(...)    __VA_ARGS__
</span></span><span><span><span>#</span>define <span>_E8</span>(...)    _E1(_E1(_E1(_E1(_E1(_E1(_E1(_E1(__VA_ARGS__))))))))
</span></span><span><span><span>#</span>define <span>_E64</span>(...)   _E8(_E8(_E8(_E8(_E8(_E8(_E8(_E8(__VA_ARGS__))))))))
</span></span><span><span><span>#</span>define <span>_E256</span>(...)  _E64(_E64(_E64(_E64(__VA_ARGS__))))
</span></span><span><span><span>#</span>define <span>_E1024</span>(...) _E256(_E256(_E256(_E256(__VA_ARGS__))))
</span></span><span><span><span>#</span>define <span>EVAL</span>(...)   _E1024(__VA_ARGS__)
</span></span></code></pre></div><p>The last expansion really is gratuitous; we could name <code>_E1024()</code> to<code>EVAL()</code> and stop on the power of two, but what fun is that?</p><p>Before writing this article, I generally stopped at 256 iterations, but I was curious as to whether the compiler’s CPP was smart enough to skip unnecessary evaluations, given it’s a common idiom. I ramped the number of iterations up to 65,636, and built a minimal program that would trigger 100 different calls to eval. On a Macbook Pro using <code>clang</code>, that many expansions took .13 seconds; when setting EVAL to 256 expansions, compiling took .06 seconds. When using <code>gcc</code>, both times were a bit more than twice as expensive.</p><p>So no, we definitely shouldn’t keep going until we get to 2^64; it’s unlikely to work. But, I’ve never noticed compile time impact due to 256 iterations, even in programs using recursive macros extensively, and can recommend it, but it also seems 2^16 expansions is totally acceptable for cases where you might need it (probably when you’re iterating over something other than call arguments).</p><p>NOW we can declare victory.</p><p>Hang on, I’m going to go cry again, but this time tears of joy. 😭😭</p><h3 id="you-can-count-me-out">You can count me out</h3><p>While the <code>EVAL</code>approach works, you may find it feels kludgy. Why ask the preprocessor to do all that additional work? <em>maybe</em> it can recognize the idiom and short-circuit a bunch of work with an <code>EVAL()</code>? Is there really no better way?
There <em>is</em> a technique that facilitates the kind of compile-time recursion we’re trying to do here, without unnecessary layers of expansion.
The basic idea is related to the concept of <em>continuations</em>; every macro passes a bag of state to the ‘next’ function-like macro that should get called, doing it in a way that allows us to BOTH dodge blue paint, AND terminate without oblivious expansions.
However:</p><ol><li>The approach is MUCH more complicated than what we’ve done so far (and I hope anyone reading should agree what we’ve done today is already much too complicated).</li><li>Having used the continuation approach, I find it too brittle (as implementable in CPP), and significantly harder to debug than more traditional recursion work-arounds.</li><li>The extra evals in the approach we’re using tend to be cheap enough, that the massive amount of extra complexity buys you virtually nothing.</li><li>I suspect the continuation technique cannot be done without relying on undefined behavior (specifically, how the compiler chooses to resolve cases where there are multiple possible ambiguous valid expansions).
But, it’s still really cool, and if you’re interested (and really want to risk your head going 🤯), <a href="https://github.com/camel-cdr/bfcpp/">check out this brainf— interpreter</a> written entirely in C macros.</li></ol><p>I should note, there are still other ways we could avoid such deep compile-time recursion, or even all recursion if we aren’t trying to get close to an arbitrary number of arguments. It’s all far uglier (and way more challenging to understand), and what we’re doing is performant, enough so that added ugliness isn’t merited, IMHO.</p><p>Though, one thing I do recommend you do differently from what we’ve done today, is that you should add a common prefix to all your names, to remove the risk of name collisions — many libraries already define things like <code>EVAL()</code> and <code>EMPTY()</code>for themselves, and you never know what might make its way into your system, and cause chaos.</p><p>You can’t be bothered? Okay, I’m a pushover (and feel strongly about the issue). So I’ve provided a complete version for you at the end of this article.</p><h2 id="count-your-blessings">Count your blessings</h2><p>This journey has taken us further down the macro rabbit hole than anyone should ever have to go, yet we didn’t have to sacrifice ALL of our remaining sanity (it helps that I was already tapped out).
As much as C actively worked to thwart us from our goal, we got there; now we have a good tool for better compile-time checking of C code in a number of cases, such as when we want to support variable argument functions.
And, with incredibly minor changes, we can re-use the code to operate on each argument, to support other things we might want to automate to make our code more robust. For instance, we could add automatic casts or calls to runtime type checkers, or so on.
All you really need to do is, take the text we insert (generating the addition that the compiler can easily fold into a count), and replace it with an invocation of a macro that the caller passes in, passing that macro the current argument.
Yes, the C standard committee has good reason to disallow recursion— removing the restriction would undoubtedly break existing code. Yet, the difficulty of the whole exercise hopefully demonstrates the need for some quality-of-life improvements in C2Y, all of which can be done without significant backward compatibility risk.</p><p>Most of all, I’d love to be able to do far more meaningful work at compile time much more sanely, minimizing my use of macros (as I know many others would too). For that, the language should extend <code>constexpr</code> capabilities, giving us good, full-fledged <code>constexpr</code> functions, with as few limitations as possible. That may be a tall order for C2Y, given the complexity of that change.
But even still, I’d want to improve the macro system too:</p><ol><li>Add a builtin macro, <code>__VA_COUNT__</code>. We need it to avoid null truncation problems for varargs, and shouldn’t have to keep reinventing the wheel (or doling out <code>__VA_ARGS__</code> in our code like it’s Halloween candy).</li><li>Add another builtin macro, <code>__VA_EMPTY__(...)</code>, which would be the inverse of <code>__VA_OPT__(...)</code>; its arguments would only get expanded only when the are NO variadic arguments. This would make it even easier to ensure people have good tools to easily terminate the kind of recursion we did today. Assuming <code>constexpr</code> functions take longer to do well, A <code>__VA_EMPTY__</code> macro can also bridge the gap of not having a good compile-time IF available for complex use cases; it would be much easier to cobble together a reasonably robust one one in macros than it is today by pairing it with <code>__VA_OPT__</code>.</li><li>Add a <code>__VA_EVAL__(...)</code>which simply expands its contents, with two semantic changes to the process that other macro goes through:<ol><li>When an expansion fully finishes, the entire macro gets rescanned again, as many times as necessary, until the full expansion reaches a fix-point (meaning, no more expansions are possible). That would allow us to worry about artificial limits on <code>EVAL()</code> macros; they’d just stop when they should stop.</li><li>Every top-level rescan should remove all blue paint generated during one expansion, before starting the next expansion (alternately, it could forego further painting macros in the first place).</li></ol></li><li>A more general purpose <code>__MAP__(body_macro, state, ...)</code>would be useful (though, to be fair, much less of a problem to build robustly if the rest of the above were present).</li><li>While waiting for <code>constexr</code> functions, it would be valuable to have a preprocessor built-in <code>__SHA256__</code> that… replaces the contents passed to it (after expansion) with the SHA256 hash of those contents. I’ve seen more than a few cases where this would be incredibly useful for saving both startup costs, and ongoing costs. No? Why can’t we have nice things??!! Interestingly, doing a compile-time only implementation of <code>SHA-256</code> using only C macros may seem possible, but I’ve built it (for strings one block in length), and it completely overwhelms both GCC and Clang, even with significantly reduced rounds.</li></ol><p>If the committee were to adopt most of the above, it sure would make one of the ugliest legacies the language has needed to carry forward far more tolerable.</p><p>We mere mortals would be able to get the gist of expansion rules more easily, if we could tell ourselves, “macro recursion is disallowed unless you use <code>__EVAL__()</code>”. That removes a huge source of confusion, but still leaves us with the problem of getting termination conditions right, which are a bit tricky.
Adding <code>__VA_EMPTY__()</code> makes it pretty easy for someone to get the exit condition right in the common case where our recursion is being used to iterate over the arguments passed to function-like macros. <code>__EVAL__()</code> would then essentially be able to function as a “do what I mean” operator, for most of the things people bang their head against when trying to write useful, robust macros to hide C’s unnecessary complexity. With just these two things, you would be able to implement <code>__VA_COUNT__(…)</code><em>fairly</em> simply:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>__REST__</span>(x, ...) __VA_ARGS__
</span></span><span><span><span>#</span>define <span>__VA_COUNT__</span>(...) <span>\</span>
</span></span><span><span>    __VA_EMPTY__(0) <span>\</span>
</span></span><span><span>    __VA_OPT__(1 <span>+</span> __EVAL__(__VA_COUNT__(__REST__(__VA_ARGS__))))
</span></span></code></pre></div><p>Sure, it’s still a little obtuse, but it’s far more sane than our final product.</p><h2 id="does-this-count">Does this count?</h2><p>I said there was no price for my full implementation, and there’s not. But, if you really feel obliged, then spend a minute indulging me.</p><p>I can count the times I’ve written the word “count” more than 100 times in a week on one finger. The entire time I’ve been working on this article, I keep thinking about what might be my favorite dad joke ever, but I spent far more time in “macro hell” than I like. So, before we talk about our final implementation, I’m going to indulge myself. It will only make sense to people who grew up with US kids programming, and does not in any way contribute to this topic:</p><p><em>Person A:</em> “Who’s your favorite vampire?”</p><p><em>Person B:</em> “Without a doubt, the one who lives on Sesame Street.”</p><p><em>Person A:</em> “The puppet? He doesn’t count!”</p><p><em>Person B:</em> “I assure you, he does.”</p><h2 id="ha-ha-ha-">⚡️Ha! Ha! Ha! ⚡️</h2><pre tabindex="0"><code>              oooOOOooo
           oOOOOOOOOOOOOOo
         oOO"           "OO
    ____oOO  ====   ====  OOo____ 
    \   OO'      ! !.---. 'OO   /
     \  OO   &lt;0&gt; ! !!&lt;0&gt;!  OO  /
      \ Oo       ! !'---'  oO /
       \o        \_/        o/
        .' _______________ '.
      ,'   :   V     V   :   '.
    ,'      -_         _-      '.
  ,'          "oOOOOOo"          '.
,'              OOOOO              '.
-----------     "OOO"     -----------
                 "O"             
</code></pre><p>Okay, if you sat through that (or were smart enough to skip it), you’ve earned the full code.</p><p>As I mentioned above, I added a <code>H4X0R_</code> prefix to everything to avoid name collisions. Additionally, internal helpers have a leading underscore. The notion of <code>_</code> indicating an internal variable has a long heritage (it is particularly prominent in Python, for example).</p><p>Our new top-level count macro is named <code>H4X0R_VA_COUNT()</code>; I added the <code>VA</code> to indicate we’re counting variable arguments (but didn’t want to make it too verbose, either).</p><p>But I actually made some other changes from what we did above.</p><p>Specifically, I first built a macro, <code>H4X0R_MAP(macro, ...)</code>. The implementation of this new macro is structured in pretty much the same way as our <code>COUNT()</code> macro above, at least in terms of the recursion. Our major change, besides the names is that, whereas for each argument, <code>COUNT()</code> ignores the argument and replaces it with <code>+1</code>, <code>H4X0R_MAP()</code> takes the argument, and passes it to a macro supplied by the caller. That caller-supplied macro gets passed the value of the parameter currently being visited.</p><p>That makes it trivial to create <code>H4X0R_VA_COUNT()</code>; we just have to call our new macro, and pass in a body macro that simply does <code>+1</code> (ignoring the parameter value).</p><p>This new macro gives us more flexibility, hopefully lessening the need to write future recursive macros.</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>// To keep this compact width-wise (given the prefix), we only do two </span>
</span></span><span><span><span>// expansions per line, and stop at 256 expansions. Extend as desired.</span>
</span></span><span><span>
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL1</span>(...)    __VA_ARGS__
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL2</span>(...)    H4X0R_EVAL1(H4X0R_EVAL1(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL4</span>(...)    H4X0R_EVAL2(H4X0R_EVAL2(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL8</span>(...)    H4X0R_EVAL4(H4X0R_EVAL4(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL16</span>(...)   H4X0R_EVAL8(H4X0R_EVAL8(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL32</span>(...)   H4X0R_EVAL16(H4X0R_EVAL16(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL64</span>(...)   H4X0R_EVAL32(H4X0R_EVAL32(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL128</span>(...)  H4X0R_EVAL64(H4X0R_EVAL64(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>H4X0R_EVAL</span>(...)     H4X0R_EVAL128(H4X0R_EVAL128(__VA_ARGS__))
</span></span><span><span>
</span></span><span><span><span>#</span>define <span>H4X0R_EMPTY</span>()
</span></span><span><span><span>#</span>define <span>H4X0R_POSTPONE1</span>(macro) macro <span>H4X0R_EMPTY</span>()
</span></span><span><span>
</span></span><span><span><span>// MAP(); If you remove the macro parameter, and replace the call</span>
</span></span><span><span><span>// `macro(x)` with `+1`, you'll see this is structurally the same</span>
</span></span><span><span><span>// as COUNT() above.</span>
</span></span><span><span><span>#</span>define <span>H4X0R_MAP</span>(macro, ...) <span>\</span>
</span></span><span><span>    __VA_OPT__(H4X0R_EVAL(_H4X0R_MAP_ONE(macro, __VA_ARGS__)))
</span></span><span><span><span>#</span>define <span>_H4X0R_MAP_ONE</span>(macro, x, ...) macro(x) <span>\</span>
</span></span><span><span>    __VA_OPT__(H4X0R_POSTPONE1(_H4X0R_MAP_INDIRECT)()(macro, __VA_ARGS__))
</span></span><span><span><span>#</span>define <span>_H4X0R_MAP_INDIRECT</span>() _H4X0R_MAP_ONE
</span></span><span><span>
</span></span><span><span><span>// A re-implementation of count on top of H4X0R_MAP()... it's simple now!</span>
</span></span><span><span><span>#</span>define <span>_H4X0R_COUNT_BODY</span>(x) <span>+</span>1
</span></span><span><span><span>#</span>define <span>H4X0R_VA_COUNT</span>(...)  <span>\</span>
</span></span><span><span>                           (H4X0R_MAP(_H4X0R_COUNT_BODY, __VA_ARGS__) <span>+</span> 0)
</span></span></code></pre></div><p>The new <code>H4X0R_MAP()</code> call gives us a more general purpose way to apply transformations to a list of individual arguments. This can help us automate static type checking per-argument, for instance, when we’re implementing variable-argument functions and want to statically ensure all items at the call site have the same time (as done in the <a href="https://codeberg.org/h4x0r/vargs">variadic function arguments</a> implementation I <a href="https://h4x0r.org/vargs/">wrote about last week</a>.</p><p>For a use case like that, we need to add the commas back in from the original call site. But we won’t want to add the comma at the end of last argument, because the C compiler will complain. There are plenty of different ways to handle this problem, including:</p><ul><li>If the output is being passed to a C varargs function where the same arguments we’re iterating over will have a correct <code>count</code> parameter before the values, we can simply add a dummy value (probably 0 since that’ll pass through easily in most contexts). This one is trivial when appropriate, but I don’t love it, as it isn’t always appropriate.</li><li>We can rework our map implementation to call a different callback for the last parameter, or to call a separate callback in between parameters. This is definitely more workable, but requires more recursive macro work, overcomplicating things. And then, the extra parameter can easily be forgotten by callers, which would lead to confusing errors (any time you make a mistake calling a macro, but the error isn’t detected until the compilation step, we should expect it to be confusing).</li><li>We can let the caller handle the first argument separately, and then for any subsequent arguments, add the comma at the beginning, separating it from the previous argument that we know must be present.</li></ul><p>I personally think the third option is the best compromise. Let’s look at a simple little example. While I normally would want to add more static type checking, sometimes the need might arise to convert a bunch of items of different types into <code>void *</code> .</p><p>If we only need to do it for integer types and pointers, it’s not too hard to use a union to statically convert one item at a time to <code>void *</code>.</p><p>We will create a temporary union, with two fields, one being our largest standard unsigned int type (<code>unsigned long long</code>, guaranteed to be at least 64 bits), and a <code>void *</code>. We will use a cast to assign to the first field, allowing us to insert any integer or pointer type into the anonymous union:</p><ul><li>Shorter integers will happily promote to a larger size.</li><li>Pointers will convert, since they are never more than 64 bits in size today.</li><li>The first field being unsigned prevents unwanted sign extension, when we insert signed values that are kept in smaller values.</li></ul><p>We then will take the value out of the anonymous union, using the <code>void *</code> . The compiler is smart enough to not generate a real temporary object for this conversion.</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_H4X0R_CONVERT_ONE</span>(arg)                  <span>\</span>
</span></span><span><span>    ((union { unsigned <span>long</span> <span>long</span> u; <span>void</span> <span>*</span>v; }){ <span>\</span>
</span></span><span><span>         .<span>u</span> <span>=</span> (unsigned <span>long</span> <span>long</span>)arg,           <span>\</span>
</span></span><span><span>     }).<span>v</span>    
</span></span></code></pre></div><p>Next, let’s build a macro to return the first parameter item in a variable list:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>H4X0R_FIRST</span>(...)     __VA_OPT__(_H4X0R_FIRST(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>_H4X0R_FIRST</span>(x, ...) x
</span></span></code></pre></div><p>The reason for two macros here, is that we want to be able to tolerate cases where no arguments are provided.</p><p>We then can do the same thing to get all the rest of the arguments, after carving off the first argument:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>H4X0R_REST</span>(...)     __VA_OPT__(_H4X0R_REST(__VA_ARGS__))
</span></span><span><span><span>#</span>define <span>_H4X0R_REST</span>(x, ...) __VA_ARGS__
</span></span></code></pre></div><p>When we process the first argument, we’ll be able to call <code>_H4X0R_CONVERT_ONE()</code> directly. For the rest of the arguments, we’re going to want to pass a macro to process the argument, which can reuse <code>_H4X0R_CONVERT_ONE()</code>, but does need to add a comma before the argument. So it’s as simple as:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_H4X0R_CONVERT_LATER_ARG</span>(arg) , _H4X0R_CONVERT_ONE(arg)
</span></span></code></pre></div><p>We’ll want to pass that macro to our map implementation. Here’s the call to our map function:</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>_H4X0R_CONVERT_LIST</span>(...) H4X0R_MAP(_H4X0R_CONVERT_LATER_ARG, __VA_ARGS__)
</span></span></code></pre></div><p>To stitch this all together, we just need to peal off the first argument from the rest, and concatenate the two resulting pieces. The only caveat is that we need to be careful to avoid adding a spurious comma or semicolons in between the two bits we need. When in doubt, use <code>cc -E</code> to review what’s getting produced.</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>#</span>define <span>H4X0R_VA_VOID_STAR_CONVERT</span>(...)          <span>\</span>
</span></span><span><span>    _H4X0R_CONVERT_ONE(H4X0R_FIRST(__VA_ARGS__)) <span>\</span>
</span></span><span><span>    _H4X0R_CONVERT_LIST(H4X0R_REST(__VA_ARGS__))
</span></span></code></pre></div><p>A dumb test case to show this working:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span>
</span></span><span><span><span>main</span>()
</span></span><span><span>{
</span></span><span><span>    <span>printf</span>(<span>"%d items: (%p, %p, %p)</span><span>\n</span><span>"</span>,
</span></span><span><span>           <span>H4X0R_VA_COUNT</span>(<span>1</span>, <span>2</span>, <span>3</span>),
</span></span><span><span>           <span>H4X0R_VA_VOID_STAR_CONVERT</span>(<span>1</span>, <span>2</span>, <span>3</span>));
</span></span><span><span>}
</span></span></code></pre></div><p>As you may expect, this prints:</p><p>With our knowledge, and our final <code>H4X0R_MAP()</code> and <code>H4X0R_COUNT()</code> implementations, we can now do some significant transformations easily most people find mind boggling.</p><p>I find it astounding, the level of difficulty required to understand enough about C macros to be able to build a primitive as basic as counting arguments statically at a call site.</p><p>There’s such a high level of complexity involved, that it’s even more amazing to me, that once we got the understanding we needed, we could implement both macros in a mere 18 lines of code, exactly half of that being the rote <code>H4X0R_EVAL()</code>implementation.</p><p>And in my view, by choosing comprehensible names, despite all the hurdles we’ve had to overcome, the final result looks almost trivial. Yet, the code alone does not hint at the knowledge you need to write it.</p><p>I’m confident that nearly anyone who lacks a solid understanding of those basics who tries to gain understanding by trying to rebuild this code, but using it has a guide (perhaps to a slightly different use case), will be inflicting gruesome self-torture on themselves. They might have preferred to code their algorithm in the Brainf— implementation mentioned above!</p><p>Why is this stuff so hard after decades of standardization? Is the committee secretly a cabal of Rust zealots, that built time travel and went back to 1989, to maximize their torture of C developers?? Maybe that was the inspiration for the movie <em>12 Monkeys</em> 🤔&nbsp;Sounds plausible. Or did they just beam that into my head?! Where did I leave my tin foil hat?</p><p><strong>Happy hacking</strong> (but hopefully not on C macros)!</p><p>— L33 T. (with a <code>#</code>-ing headache)</p><h2 id="acknowledgements">Acknowledgements</h2><p>This post started as an out-of-control sidebar in my post on <a href="https://h4x0r.org/vargs/">variable argument functions in C.</a></p><p>I owe a huge debt of gratitude to Robert Seacord; his early feedback gave me the clarity I needed to (hopefully) help other C programmers over what is probably one of the biggest hurdles in the language… people who become C developers eventually master pointers, but to many senior developers, macro recursion has remained a dark art, requiring a magic incantation borrowed from Stack Overflow, Claude or the like.</p><p>Ivan O’Day also was critical here, BUT is responsible for me taking several extra weeks to get the article out once it was in decent shape… because he helped me see that I really needed the step-by-step example of a macro expansion, which I then had to find time to do!</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Basic Laws of Human Stupidity (1987) [pdf] (109 pts)]]></title>
            <link>https://gandalf.fee.urv.cat/professors/AntonioQuesada/Curs1920/Cipolla_laws.pdf</link>
            <guid>45829210</guid>
            <pubDate>Wed, 05 Nov 2025 22:58:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gandalf.fee.urv.cat/professors/AntonioQuesada/Curs1920/Cipolla_laws.pdf">https://gandalf.fee.urv.cat/professors/AntonioQuesada/Curs1920/Cipolla_laws.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45829210">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Solarpunk is already happening in Africa (933 pts)]]></title>
            <link>https://climatedrift.substack.com/p/why-solarpunk-is-already-happening</link>
            <guid>45827190</guid>
            <pubDate>Wed, 05 Nov 2025 20:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://climatedrift.substack.com/p/why-solarpunk-is-already-happening">https://climatedrift.substack.com/p/why-solarpunk-is-already-happening</a>, See on <a href="https://news.ycombinator.com/item?id=45827190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>👋 </span><strong>Welcome to Climate Drift</strong><span>: your cheat-sheet to climate. Each edition breaks down real solutions, hard numbers, and career moves for operators, founders, and investors who want impact. For more: </span><strong><a href="https://www.climatedrift.com/community" rel="">Community</a><span> | </span><a href="https://www.climatedrift.com/accelerator" rel="">Accelerator</a><span> | </span><a href="https://lu.ma/climatedrift" rel="">Open Climate Firesides</a><span> | </span><a href="https://www.climatedrift.com/archive" rel="">Deep Dives</a></strong></em></p><p><span>Hey there! 👋</span><br><span>Skander here.</span></p><p>You know that feeling when you’re waiting for the cable guy, and they said ‘between 8am and 6pm, and you waste your entire day, and they never show up? </p><p>Now imagine that, except the cable guy is ‘electricity,’ the day is ‘50 years,’ and you’re one of 600 million people. At some point, you stop waiting and figure it out yourself.</p><p>What’s happening across Sub-Saharan Africa right now is the most ambitious infrastructure project in human history, except it’s not being built by governments or utilities or World Bank consortiums. It’s being built by startups selling solar panels to farmers on payment plans. And it’s working.</p><p>Over 30 million solar products sold in 2024. 400,000 new solar installations every month across Africa. 50% market share captured by companies that didn’t exist 15 years ago. Carbon credits subsidizing the cost. IoT chips in every device. 90%+ repayment rates on loans to people earning $2/day.</p><p>And if you understand what’s happening in Africa, you understand the template for how infrastructure will get built everywhere else for the next 50 years.</p><p>Today we are looking into:</p><ul><li><p>Why the grid will never come (and why that’s actually good news)</p></li><li><p>How it takes three converging miracles (cheap hardware, zero-cost payments, and pay-as-you-go) </p></li><li><p>2 case studies on how it works on the ground</p></li><li><p>Whether this template works beyond Africa (spoiler: it already is)</p></li></ul><p>🌊 Let’s dive in</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!K76k!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!K76k!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 424w, https://substackcdn.com/image/fetch/$s_!K76k!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 848w, https://substackcdn.com/image/fetch/$s_!K76k!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 1272w, https://substackcdn.com/image/fetch/$s_!K76k!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!K76k!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png" width="800" height="400" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:400,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!K76k!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 424w, https://substackcdn.com/image/fetch/$s_!K76k!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 848w, https://substackcdn.com/image/fetch/$s_!K76k!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 1272w, https://substackcdn.com/image/fetch/$s_!K76k!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f228441-25e5-428e-a8f9-8c46be35788f_800x400.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Here’s a stat that should make you angry: 600 million people in Sub-Saharan Africa lack reliable electricity. Not because the technology doesn’t exist. Not because they don’t want it. But because the unit economics of grid extension to rural areas are completely, utterly, irredeemably fucked.</p><p>The traditional development playbook goes something like this: Chapter 1, build centralized power generation. Chapter 2, string transmission lines across hundreds of kilometers. Chapter 3, distribute to millions of homes. Chapter 4, collect payments. Chapter 5, maintain the whole thing forever.</p><p>This worked great if you were electrifying America in the 1930s, when labor was cheap, materials were subsidized, and the government could strong-arm right-of-way access. It works less great when you’re trying to reach a farmer four hours from the nearest paved road who earns $600 per year.</p><p>Let me show you the math:</p><ul><li><p><span>Cost to connect one rural household to the grid: </span><strong>$266 to $2,000</strong></p></li><li><p><span>Average rural household electricity spending: </span><strong>~$10-20/month</strong></p></li><li><p><span>Payback period: </span><strong>13-200 months</strong><span> (if you can even collect payments)</span></p></li><li><p><span>Collection rate in rural areas: </span><strong>complicated</strong></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!G64f!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!G64f!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 424w, https://substackcdn.com/image/fetch/$s_!G64f!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 848w, https://substackcdn.com/image/fetch/$s_!G64f!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 1272w, https://substackcdn.com/image/fetch/$s_!G64f!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!G64f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png" width="562" height="337.2" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:1000,&quot;resizeWidth&quot;:562,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!G64f!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 424w, https://substackcdn.com/image/fetch/$s_!G64f!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 848w, https://substackcdn.com/image/fetch/$s_!G64f!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 1272w, https://substackcdn.com/image/fetch/$s_!G64f!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5afbe70e-74e1-419d-b177-fc73609a577d_1000x600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So utilities do what any rational actor would do: they stop building where the math stops working. Which is exactly where the people are.</p><p>This has been the development sector’s dirty little secret for 50 years. “We’re working on grid extension!” Translation: we’re not working on grid extension because the economics are impossible, but we need to say we’re working on it so we keep getting donor money.</p><p>Meanwhile, 1.5 billion people spend up to 10% of their income on kerosene, diesel, and other dirty fuels. They walk hours to charge their phones. They can’t refrigerate medicine or food. Their kids can’t study after dark. Women inhale cooking smoke equivalent to two packs of cigarettes daily.</p><p>While everyone was arguing about feed-in tariffs and utility-scale solar, something wild happened to solar costs:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!LMvP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LMvP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 424w, https://substackcdn.com/image/fetch/$s_!LMvP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 848w, https://substackcdn.com/image/fetch/$s_!LMvP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 1272w, https://substackcdn.com/image/fetch/$s_!LMvP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!LMvP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png" width="1168" height="684" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:684,&quot;width&quot;:1168,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!LMvP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 424w, https://substackcdn.com/image/fetch/$s_!LMvP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 848w, https://substackcdn.com/image/fetch/$s_!LMvP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 1272w, https://substackcdn.com/image/fetch/$s_!LMvP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a98e977-e663-485c-8498-c49f1dbba705_1168x684.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Solar Panel Price History:</strong></p><ul><li><p>1980: $40/watt</p></li><li><p>2000: $5/watt</p></li><li><p>2010: $1.50/watt</p></li><li><p>2020: $0.30/wlltt</p></li><li><p><span>2025: </span><strong>$0.20/watt</strong></p></li></ul><p>That’s a 99.5% decline in 45 years. Moore’s Law except for sunshine.</p><blockquote><p>Want to learn how solar got cheap? </p></blockquote><p>But here’s what’s even crazier: the price of complete solar home systems:</p><p><strong>Solar Home System Evolution:</strong></p><ul><li><p>2008: $5,000 (affordable only for wealthy urban Kenyans)</p></li><li><p>2015: $800 (middle-class farmers)</p></li><li><p><span>2025: </span><strong>$120-$1,200</strong><span> (true smallholders)</span></p></li></ul><p>Battery costs also collapsed 90%. Inverters got cheap. LED bulbs got efficient. Manufacturing in China got insanely good. Logistics in Africa got insanely better.</p><p>All of these trends converged around 2018-2020, and suddenly the economics of off-grid solar just... flipped. The hardware became a solved problem.</p><p><span>But there was still a massive, seemingly insurmountable barrier: </span><strong>$120 upfront might as well be $1 million when you earn $2/day.</strong></p><p>This is where the story gets interesting.</p><p>Quick history lesson: In 2007, Safaricom (Kenya’s telco) launched M-PESA, a mobile money platform that let people transfer cash via SMS.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!3CAj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!3CAj!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 424w, https://substackcdn.com/image/fetch/$s_!3CAj!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 848w, https://substackcdn.com/image/fetch/$s_!3CAj!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 1272w, https://substackcdn.com/image/fetch/$s_!3CAj!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!3CAj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png" width="502" height="334.51454545454544" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:733,&quot;width&quot;:1100,&quot;resizeWidth&quot;:502,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!3CAj!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 424w, https://substackcdn.com/image/fetch/$s_!3CAj!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 848w, https://substackcdn.com/image/fetch/$s_!3CAj!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 1272w, https://substackcdn.com/image/fetch/$s_!3CAj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb998a27b-4c29-4220-99b3-2151d973a7fb_1100x733.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Everyone thought it would fail. Why would anyone use their phone to send money?</p><p><span>By 2025: </span><strong>70% of Kenyans use mobile money</strong><span>. Not in addition to banks. Instead of banks. Kenya processes more mobile money transactions per capita than any country on Earth.</span></p><p>It worked because it solved a real problem: Kenyans were already sending money through informal networks. M-PESA just made it cheaper and safer.</p><p>Here’s why this matters: M-PESA created a payment rail with near-zero transaction costs. Which means you can economically collect tiny payments. $0.21 per day payments.</p><p><span>This broke open a financing model that changes everything: </span><strong>Pay-As-You-Go</strong><span>.</span></p><p>This is the unlock. This is the thing that makes everything else possible.</p><p>Here’s the model:</p><ol><li><p>A company (Sun King, SunCulture) installs a solar system in your home</p></li><li><p>You pay ~$100 down</p></li><li><p>Then $40-65/month over 24-30 months</p></li><li><p>The system has a GSM chip that calls home</p></li><li><p>No payment = remotely shut off</p></li><li><p>Keep paying = keep power</p></li><li><p>After 30 months = you own it, free power forever</p></li></ol><p>The magic is this: You’re not buying a $1,200 solar system. You’re replacing $3-5/week kerosene spending with a $0.21/day solar subscription (so with $1.5 per week half the price of kerosene) that’s cheaper AND gives you better light, phone charging, radio, and no respiratory disease.</p><p><span>The default rate? </span><strong>90%+ of customers repay on time.</strong></p><p>Why? Because the asset actually works. It delivers value every single day. The alternative is going back to kerosene lamps in the dark. Nobody wants that.</p><p>This is the “innovation” that everyone missed. The hardware got cheap, but PAYG made it accessible. And mobile money made PAYG economically viable.</p><p>Now let’s talk about what happens when you combine these three things with 2 case studies.</p><p><span>23 million solar products sold in 2023, serving 40 million customers in 42 countries, and targeting 50 million units by 2026.</span><br><span>Their product range spans from handheld solar lamps to multi-room home solar kits and clean LPG stoves</span></p><p><strong>Products:</strong></p><ul><li><p>Handheld solar lamps ($50-120)</p></li><li><p>Multi-room home systems ($200-500)</p></li><li><p>LPG clean cookstoves (acquired PayGo Energy)</p></li><li><p>Phone charging, battery backup, lighting</p></li></ul><blockquote><p>Want to dive deeper? I got a casestudy for you</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!rrWq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rrWq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 424w, https://substackcdn.com/image/fetch/$s_!rrWq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 848w, https://substackcdn.com/image/fetch/$s_!rrWq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 1272w, https://substackcdn.com/image/fetch/$s_!rrWq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!rrWq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png" width="1000" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!rrWq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 424w, https://substackcdn.com/image/fetch/$s_!rrWq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 848w, https://substackcdn.com/image/fetch/$s_!rrWq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 1272w, https://substackcdn.com/image/fetch/$s_!rrWq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1db96105-78ae-462e-aa63-4573b7842df8_1000x600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Each turn of the wheel makes the next turn easier. This is a compounding moat.</p><p><span>And here’s what nobody outside Africa understands: </span><strong>Sun King has 50%+ market share in their category.</strong><span> They’re not scrappy startup. They’re a dominant infrastructure provider.</span></p><p>This would be like if one startup owned 50% of U.S. home solar. Except the impact and the TAM is bigger because there’s no incumbent grid to compete with.</p><p>If Sun King is the lighting/household electrification play, SunCulture is the agriculture productivity play. And the numbers are even more insane.</p><p><strong>The Problem:</strong></p><ul><li><p>95% of Sub-Saharan Africa’s cropland is rain-dependent</p></li><li><p>Farmers spend $2B annually on diesel pumps</p></li></ul><p><strong>The SunCulture Solution:</strong></p><ul><li><p>Solar-powered irrigation pumps</p></li><li><p>IoT-enabled remote monitoring</p></li><li><p>PAYG financing ($100 down, $40-65/month)</p></li><li><p>Free installation, 10-year warranty</p></li><li><p>Drip irrigation included</p></li></ul><p><strong>The Results:</strong></p><ul><li><p>Crop yields increase 3-5×</p></li><li><p>Farmers go from $600/acre to $14,000/acre revenue</p></li><li><p>Zero marginal cost after payoff (no diesel!)</p></li><li><p>Year-round irrigation instead of seasonal</p></li><li><p>17 hours/week saved from manual water hauling</p></li></ul><p><strong>The Scale:</strong></p><ul><li><p>47,000+ systems deployed</p></li><li><p>40,000+ farmers served</p></li><li><p>50%+ market share in smallholder segment</p></li><li><p>6 countries (Kenya, Uganda, Ethiopia, Ivory Coast, Zambia, Togo)</p></li></ul><p>That’s not a charity. That’s a fucking rocketship.</p><p>Okay, this is where it gets really spicy.</p><p>Remember that SunCulture solar pump displacing diesel? That’s 2.9 tons of CO2 avoided per year. Per pump.</p><p><span>Multiply by 47,000 pumps = </span><strong>136,000 tons CO2/year</strong><span>. Over seven years = </span><strong>3+ million tons cumulative</strong><span>.</span></p><blockquote><p>Want to dive deeper? I got another casestudy for you</p></blockquote><p>Now here’s the hack: Someone will pay for that.</p><p>Enter carbon credits. SunCulture is the first African solar irrigation company with Verra-registered carbon credits. Each ton of avoided CO2 can be sold for $15-30 (high-quality agricultural credits, not sketchy forest offsets).</p><div><p><span>Let’s do the flywheel again, but this time turbocharged with carbon credits.</span></p></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2YiT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2YiT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 424w, https://substackcdn.com/image/fetch/$s_!2YiT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 848w, https://substackcdn.com/image/fetch/$s_!2YiT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 1272w, https://substackcdn.com/image/fetch/$s_!2YiT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2YiT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png" width="1000" height="623" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:623,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2YiT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 424w, https://substackcdn.com/image/fetch/$s_!2YiT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 848w, https://substackcdn.com/image/fetch/$s_!2YiT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 1272w, https://substackcdn.com/image/fetch/$s_!2YiT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21d14191-f856-45b7-a8be-ffae0435847a_1000x623.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><ol><li><p>Install solar system</p></li><li><p>System displaces diesel (verified via IoT telemetry)</p></li><li><p>Displacement = carbon credits issued</p></li><li><p>Sell credits to companies needing offsets</p></li><li><p><span>Carbon revenue subsidizes upfront cost by </span><strong>25-40%</strong></p></li><li><p>Lower cost = 4-5× larger addressable market</p></li><li><p>More systems deployed = more carbon credits</p></li><li><p>Repeat</p></li></ol><p><span>It gets even better: there are people who will pay for credits beforehand. </span><br><span>British International Investment (UK’s DFI) pioneered this with SunCulture: they provided $6.6M in “carbon-backed equipment financing.” They bear the carbon price risk, SunCulture gets upfront capital, farmers get 25-40% cheaper pumps.</span></p><p>This is how it should be: The climate impact that was an externality is now a revenue stream. The global North’s carbon problem subsidizes the global South’s energy access.</p><blockquote><p><strong>A quick note on MRV</strong><br><span>Okay, so you might know I have… issues with the carbon credit world, especially MRV(monitoring, reporting, verification). Here monitoring is IoT-based, the MRV costs are near-zero. No expensive field audits. The telemetry data proves the pump is running = proves diesel is displaced = proves carbon is avoided.</span></p></blockquote><p>The carbon credit mechanism turns climate infrastructure into an asset class. Which means you can finance it at scale.</p><blockquote><div><p><strong>Btw this is how the largest forest of the US is now being financed:</strong></p><p><span>Chestnut Carbon buys degraded farmland across the Southeast, replants biodiverse native forests, verifies long-term carbon removal, and signs long-dated offtake deals with blue-chip buyers like Microsoft. The company has acquired more than 35,000 acres, planted over 17 million trees, and aims to restore 100,000+ acres by 2030 with an expected 100 million tons of CO2 removed over 50 years.</span></p><p><span>Learn more here: </span></p></div></blockquote><p>So: what now?</p><p><span>Why is the market concentrated? </span><strong>Because the full-stack is really fucking hard.</strong></p><p>You need:</p><ol><li><p>Hardware manufacturing expertise</p></li><li><p>Supply chain across fragmented markets</p></li><li><p>Last-mile distribution (29,500 agents for Sun King)</p></li><li><p>Mobile money integration</p></li><li><p>Credit scoring models for the unbanked</p></li><li><p>IoT/telemetry systems</p></li><li><p>Customer service in 10+ languages</p></li><li><p>Financing (equity, debt, securitization)</p></li><li><p>Carbon market relationships</p></li><li><p>Regulatory navigation across 40+ countries</p></li></ol><p>Most companies can do 2-3 of these. The winners do all 10.</p><p><span>This creates </span><strong>massive barriers to entry</strong><span> and </span><strong>long-term moats</strong><span>. New entrants can’t just show up with cheaper panels. The moat is the full-stack execution.</span></p><p>​​Let’s do the math on how big this can get.</p><ul><li><p>600M people without reliable power in Sub-Saharan Africa</p></li></ul><ul><li><p>570M smallholder farming households in Africa</p></li></ul><ul><li><p>900M people in Africa use traditional cookstoves</p></li></ul><p>And that’s just Africa. Add Asia (1 billion without electricity) and you’re north of $300B-$500B.</p><p><span>But here’s the thing: </span><strong>this massively understates the opportunity.</strong></p><p>The solar system is the Trojan horse. The real business is the financial relationship with 40 million customers.</p><p>Because what you’re really doing is creating a digital infrastructure layer that enables:</p><ul><li><p>Consumer lending (smartphones, motorcycles, appliances)</p></li><li><p>Livestock/agriculture financing</p></li><li><p>Insurance products</p></li><li><p>Healthcare delivery</p></li><li><p>Education services</p></li><li><p>Payment processing</p></li></ul><p>So the actual TAM? It’s whatever the total consumer spending is for 600M people rising into the middle class.</p><p>Okay, let’s zoom out. What happens when 100M+ people get electrified through this model?</p><ul><li><p>Kids study at night → higher test scores → better jobs</p></li><li><p>Adults work after dark → higher income</p></li><li><p>Farmers irrigate year-round → 3-5x yields → food security</p></li><li><p>Phone charging → mobile money access → financial inclusion</p></li><li><p>Refrigeration → vaccine storage → disease prevention</p></li><li><p>Refrigeration → Keep milk/meat eatable → reduced food waste No kerosene smoke → respiratory disease drops</p></li><li><p>Clean cookstoves → 600,000 fewer deaths/year from indoor pollution</p></li><li><p>Diesel displacement = cleaner air quality</p></li></ul><p>But here’s the meta-point: This is the template for building infrastructure in the 21st century.</p><p>Not government-led. Not centralized. Not requiring 30-year megaprojects.</p><p>Instead: modular, distributed, digitally-metered, remotely-monitored, PAYG-financed, carbon-subsidized infrastructure deployed by private companies in competitive markets.</p><p>The 20th century infrastructure model was:</p><ul><li><p>Centralized generation</p></li><li><p>Government-led</p></li><li><p>Megaproject financing</p></li><li><p>30-year timelines</p></li><li><p>Monopolistic utilities</p></li></ul><p>The 21st century infrastructure model is:</p><ul><li><p>Distributed/modular</p></li><li><p>Private sector-led</p></li><li><p>PAYG financing</p></li><li><p>Deploy in days/weeks</p></li><li><p>Competitive markets</p></li></ul><p>This is how things will get built going forward.</p><p>So what could go wrong?</p><p><span>Let’s start by making clear this is not a one size fits all solution: </span><br><span>PAYG solar works for households and smallholders. Doesn’t work for factories or heavy industry. This isn’t a complete grid replacement.</span></p><p><strong>1. FX Risk</strong><span> Companies raise dollars, buy hardware in dollars, collect revenue in Naira/Shillings. Currency crashes can blow up unit economics overnight.</span></p><p><strong><span>2. Political/Regulatory Risk</span><br></strong><span> Governments could impose lending restrictions, tariffs on solar imports, or subsidize grid/diesel to protect state utilities.</span></p><p><strong>3. Default Risk</strong><span> </span><br><span>10% default rate is good but fragile. Economic shocks, droughts, or political instability could spike defaults.</span></p><p><strong>4. Maintenance Complexity</strong><span> </span><br><span>Panels last 25 years, batteries 5 years, pumps break. Building service networks across rural Africa is expensive.</span></p><p><strong>5. Carbon Price Volatility</strong><span> </span><br><span>Carbon credits crashed from $30/ton to $5/ton in 2024. If 25-40% of affordability comes from carbon revenue, price swings hurt.</span></p><p><strong>6. Competition from Grid</strong><span> </span><br><span>What if governments actually build the grid? (Unlikely given economics, but possible with enough subsidy)</span></p><p><strong>7. Supply Chain Bottlenecks</strong></p><p>Port congestion, customs delays, tariff swings, China export controls, and last-mile logistics can delay installs, raise COGS, and tie up working capital.</p><blockquote><p><em><strong>Fun fact:</strong><span> Sun King is now producing their devices in Africa, cutting</span><a href="https://www.bloomberg.com/news/articles/2025-11-04/sun-king-s-africa-solar-plants-to-cut-300-million-in-imports?embedded-checkout=true" rel=""> $300 Million in imports over the next years.</a></em></p></blockquote><p>Okay, the bear case is important. But let’s talk about the scenarios where this doesn’t just work: it goes 🏒.</p><p><strong>Solar panels dropped 99.5% in 45 years. What if we’re only halfway through?</strong></p><p>Current situation:</p><ul><li><p>China has 600+ GW of solar manufacturing capacity</p></li><li><p>Current global demand: ~400 GW/year</p></li><li><p>Overcapacity = price collapse incoming</p></li></ul><p><strong>What happens next:</strong></p><ul><li><p>Solar: $0.20/watt → $0.10/watt by 2030</p></li><li><p>Batteries: Another 50% drop as sodium-ion scales</p></li><li><p>Complete solar home systems: $120-1,200 → $60-600</p></li></ul><p><span>A $60 entry-level system puts the addressable market at </span><strong>2 billion people</strong><span> instead of 600 million. You’re not just electrifying rural Africa. You’re electrifying rural India, Bangladesh, Pakistan, Southeast Asia, Latin America.</span></p><p>Right now, these companies finance at 12-18% interest rates. What if Development Finance Institutions (DFIs) actually do their job?</p><p><strong>The scenario:</strong></p><ul><li><p>World Bank, IFC, British International Investment create dedicated facilities</p></li><li><p>“De-risk” lending to proven operators like Sun King/SunCulture</p></li><li><p>Cost of capital drops from 15% → 5-7%</p></li></ul><p><strong>What this unlocks:</strong></p><ul><li><p>Monthly payments drop 30-40%</p></li><li><p>Addressable market expands by 200M+ people</p></li><li><p>Payback periods shrink from 30 months → 18-24 months</p></li><li><p>Companies can deploy 3-5x faster with better unit economics</p></li></ul><p>This is literally what happened with microfinance when Grameen Bank proved the model. Billions in cheap capital followed.</p><p><span>Here’s what nobody’s pricing in: </span><strong>social proof at scale.</strong></p><p><strong>The flywheel:</strong></p><ul><li><p>Village A: 3 households get solar</p></li><li><p>Neighbors see: kids studying at night, no kerosene smell, phone always charged</p></li><li><p>Village A: 30 households get solar within 12 months</p></li><li><p>Next village over hears about it → sales agent swamped</p></li><li><p>Company expands distribution network to meet demand</p></li></ul><p><strong>What the data shows:</strong></p><ul><li><p><span>Sun King’s customer acquisition cost has </span><strong>dropped 60%</strong><span> since 2018</span></p></li><li><p>Why? Word of mouth. Referrals. “My cousin has one.”</p></li><li><p><span>In mature markets (Kenya), </span><strong>40%+ of sales come from referrals</strong></p></li></ul><p>When 20-30% of a region has solar, it becomes the default. You’re not an early adopter, you’re behind. This is how mobile phones scaled in Africa. The tipping point creates exponential adoption curves.</p><p><span>The grid that never came turned out to be a blessing</span><strong>.</strong><span> While development experts spent 50 years debating how to extend 20th-century infrastructure to rural Africa, something more interesting happened: Africa built the 21st-century version instead.</span></p><p>Modular. Distributed. Digital. Financed by the people using it, subsidized by the carbon it avoids.</p><p>The solarpunk future isn’t speculative fiction. It’s 23 million solar systems, 40 million people, and a template for how infrastructure gets built when you’re not stuck defending the past.</p><p><span>Thanks to </span><a href="https://www.linkedin.com/in/jarek-dmowski/" rel="">Jarek Dmowski</a><span> for first spotlighting the companies in our monthly</span><a href="https://climatedrift.substack.com/p/follow-the-money-8f9" rel=""> Follow the Money</a><span> and for his perspectives, and to </span><a href="https://www.linkedin.com/in/aaron-m-kruse/" rel="">Aaron Kruse</a><span> for the conversations that shaped this essay.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New gel restores dental enamel and could revolutionise tooth repair (549 pts)]]></title>
            <link>https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair</link>
            <guid>45826995</guid>
            <pubDate>Wed, 05 Nov 2025 19:44:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair">https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair</a>, See on <a href="https://news.ycombinator.com/item?id=45826995">Hacker News</a></p>
Couldn't get https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive's legal fights are over, but its founder mourns what was lost (194 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2025/11/the-internet-archive-survived-major-copyright-losses-whats-next/</link>
            <guid>45826500</guid>
            <pubDate>Wed, 05 Nov 2025 18:59:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2025/11/the-internet-archive-survived-major-copyright-losses-whats-next/">https://arstechnica.com/tech-policy/2025/11/the-internet-archive-survived-major-copyright-losses-whats-next/</a>, See on <a href="https://news.ycombinator.com/item?id=45826500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2124398">
  
  <header>
  <div>
    <div>
      

      

      <p>
        “We survived, but it wiped out the library,” Internet Archive’s founder says.
      </p>

      
    </div>

    <div>
    
    <p>
      Internet Archive founder Brewster Kahle celebrates 1 trillion web pages on stage with staff.

              <span>
          Credit:

          
          via the Internet Archive

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Last month, the Internet Archive’s Wayback Machine archived its trillionth webpage, and the nonprofit invited its more than 1,200 library partners and 800,000 daily users to join a celebration of the moment. To honor “three decades of safeguarding the world’s online heritage,” the city of San Francisco declared October 22 to be “Internet Archive Day.” The Archive was also <a href="https://blog.archive.org/2025/07/24/internet-archive-designated-as-a-federal-depository-library/">recently designated</a> a federal depository library by Sen. Alex Padilla (D-Calif.), who proclaimed the organization a “perfect fit” to expand “access to federal government publications amid an increasingly digital landscape.”</p>
<p>The Internet Archive might sound like a thriving organization, but it only recently emerged from years of bruising copyright battles that threatened to bankrupt the beloved library project. In the end, the fight led to <a href="https://blog.archive.org/2024/06/14/patrons-speak-out-the-impact-of-losing-access-to-more-than-500000-books/">more than 500,000 books being removed</a> from the Archive’s “Open Library.”</p>
<p>“We survived,” Internet Archive founder Brewster Kahle told Ars. “But it wiped out the Library.”</p>
<p>An Internet Archive spokesperson confirmed to Ars that the archive currently faces no major lawsuits and no active threats to its collections. Kahle thinks “the world became stupider” when the Open Library was gutted—but he’s moving forward with new ideas.</p>
<h2>History of the Internet Archive</h2>
<p>Kahle has been striving since 1996 to transform the Internet Archive into a digital <a href="https://en.wikipedia.org/wiki/Library_of_Alexandria">Library of Alexandria</a>—but “with a better fire protection plan,” joked Kyle Courtney, a copyright lawyer and librarian who leads the nonprofit eBook Study Group, which helps states update laws to protect libraries.</p>
<p>When the Wayback Machine was born in 2001 as a way to take snapshots of the web, Kahle <a href="https://www.nytimes.com/2001/10/29/business/new-economy-library-web-pages-that-warms-cockles-wired-heart-beats-library.html">told The New York Times</a> that building free archives was “worth it.” He was also excited that the Wayback Machine had drawn renewed media attention to libraries.</p>
<p>At the time, law professor Lawrence Lessig predicted that the Internet Archive would face copyright battles, but he also believed that the Wayback Machine would change the way the public understood copyright fights.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>”We finally have a clear and tangible example of what’s at stake,” Lessig told the Times. He insisted that Kahle was “defining the public domain” online, which would allow Internet users to see ”how easy and important” the Wayback Machine “would be in keeping us sane and honest about where we’ve been and where we’re going.”</p>
<p>Kahle suggested that IA’s legal battles weren’t with creators or publishers so much as with large media companies that he thinks aren’t “satisfied with the restriction you get from copyright.”</p>
<p>“They want that and more,” Kahle said, pointing to e-book licenses that expire as proof that libraries increasingly aren’t allowed to own their collections. He also suspects that such companies wanted the Wayback Machine dead—but the Wayback Machine has survived and proved itself to be a unique and useful resource.</p>
<p>The Internet Archive also began archiving—and then lending—e-books. For a decade, the Archive had loaned out individual e-books to one user at a time without triggering any lawsuits. That changed when IA decided to temporarily lift the cap on loans from its Open Library project to <a href="https://arstechnica.com/tech-policy/2020/03/internet-archive-offers-thousands-of-copyrighted-books-for-free-online/">create a “National Emergency Library”</a> as libraries across the world shut down during the early days of the COVID-19 pandemic. The project eventually <a href="https://arstechnica.com/tech-policy/2020/03/internet-archive-offers-thousands-of-copyrighted-books-for-free-online/">grew to 1.4 million</a> titles.</p>
<p>But lifting the lending restrictions also brought more scrutiny from copyright holders, who eventually sued the Archive. Litigation went on for years. In 2024, IA lost its final appeal in a lawsuit brought by book publishers over the Archive’s Open Library project, which used a novel e-book lending model to bypass publishers’ licensing fees and checkout limitations. Damages <a href="https://www.wired.com/story/internet-archive-loses-hachette-books-case-appeal/">could have topped $400 million</a>, but publishers ultimately <a href="https://publishers.org/news/publishers-and-internet-archive-submit-negotiated-judgment-with-permanent-injunction-to-district-court-in-hachette-book-group-et-al-v-internet-archive/">announced</a> a “confidential agreement on a monetary payment” that did not bankrupt the Archive.</p>
<p>Litigation has continued, though. More recently, the Archive <a href="https://arstechnica.com/tech-policy/2025/09/internet-archives-big-battle-with-music-publishers-ends-in-settlement/">settled</a> another suit over its Great 78 Project after music publishers sought damages of <a href="https://arstechnica.com/tech-policy/2025/03/music-labels-will-regret-coming-for-the-internet-archive-sound-historian-says/">up to $700 million</a>. A settlement in that case, reached last month, was similarly confidential. In both cases, IA’s experts challenged publishers’ estimates of their losses as massively inflated.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>For Internet Archive fans, a group that includes <a href="https://www.instagram.com/p/DP2Ph5ck5dx/">longtime Internet users</a>, <a href="https://arstechnica.com/tech-policy/2024/06/internet-archive-forced-to-remove-500000-books-after-publishers-court-win/">researchers, students</a>, <a href="https://arstechnica.com/tech-policy/2025/03/music-labels-will-regret-coming-for-the-internet-archive-sound-historian-says/">historians</a>, <a href="https://www.lexisnexis.com/community/insights/legal/b/thought-leadership/posts/internet-archive-wayback-machine-helps-lawyers-go-back-in-time-to-strengthen-cases">lawyers</a>, and <a href="https://blog.archive.org/2025/07/24/internet-archive-designated-as-a-federal-depository-library/">the US government</a>, the end of the lawsuits brought a sigh of relief. The Archive can continue—but it can’t run one of its major programs in the same way.</p>

<h2>What the Internet Archive lost</h2>
<p>To Kahle, the suits have been an immense setback to IA’s mission.</p>
<p>Publishers had argued that the Open Library’s lending harmed the e-book market, but IA says its vision for the project was not to frustrate e-book sales (which it denied its library does) but to make it easier for researchers to reference e-books by allowing Wikipedia to link to book scans. Wikipedia has long been one of the most visited websites in the world, and the Archive wanted to deepen its authority as a research tool.</p>
<p>“One of the real purposes of libraries is not just access to information by borrowing a book that you might buy in a bookstore,” Kahle said. “In fact, that’s actually the minority. Usually, you’re comparing and contrasting things. You’re quoting. You’re checking. You’re standing on the shoulders of giants.”</p>
<p>Meredith Rose, senior policy counsel for Public Knowledge, told Ars that the Internet Archive’s Wikipedia enhancements could have served to surface information that’s often buried in books, giving researchers a streamlined path to source accurate information online.</p>
<p>But Kahle said the lawsuits against IA showed that “massive multibillion-dollar media conglomerates” have their own interests in controlling the flow of information. “That’s what they really succeeded at—to make sure that Wikipedia readers don’t get access to books,” Kahle said.</p>
<p>At the heart of the Open Library lawsuit was publishers’ market for e-book licenses, which libraries complain provide only temporary access for a limited number of patrons and cost substantially more than the acquisition of physical books. <a href="https://www.nytimes.com/2025/07/16/books/libraries-e-books-licensing.html">Some states are crafting laws to restrict e-book licensing</a>, with the aim of preserving library functions.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>“We don’t want libraries to become Hulu or Netflix,” said Courtney of the eBook Study Group, posting warnings to patrons like “last day to check out this book, August 31st, then it goes away forever.”</p>
<p>He, like Kahle, is concerned that libraries will become unable to fulfill their longtime role—preserving culture and providing equal access to knowledge. Remote access, Courtney noted, benefits people who can’t easily get to libraries, like the elderly, people with disabilities, rural communities, and foreign-deployed troops.</p>
<p>Before the Internet Archive cases, libraries had won some important legal fights, according to Brandon Butler, a copyright lawyer and executive director of Re:Create, a coalition of “libraries, civil libertarians, online rights advocates, start-ups, consumers, and technology companies” that is “dedicated to balanced copyright and a free and open Internet.”</p>
<p>But the Internet Archive’s e-book fight didn’t set back libraries, Butler said, because the loss didn’t reverse any prior court wins. Instead, IA had been “exploring another frontier” <a href="https://arstechnica.com/tech-policy/2013/11/google-books-ruled-legal-in-massive-win-for-fair-use/">beyond the Google Books ruling,</a> which deemed Google’s searchable book excerpts a transformative fair use, hoping that linking to books from Wikipedia would also be deemed fair use. But IA “hit the edge” of what courts would allow, Butler said.</p>
<p>IA basically asked, “Could fair use go this much farther?” Butler said. “And the courts said, ‘No, this is as far as you go.'”</p>
<p>To Kahle, the cards feel stacked against the Internet Archive, with courts, lawmakers, and lobbyists backing corporations seeking “hyper levels of control.” He said IA has always served as a research library—an online destination where people can cross-reference texts and verify facts, just like perusing books at a local library.</p>
<p>“We’re just trying to be a library,” Kahle said. “A library in a traditional sense. And it’s getting hard.”</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<h2>Fears of big fines may delay digitization projects</h2>
<p>President Donald Trump’s <a href="https://www.whitehouse.gov/presidential-actions/2025/03/continuing-the-reduction-of-the-federal-bureaucracy/">cuts</a> to the federal Institute of Museum and Library Services have put America’s public libraries at risk, and reduced funding will continue to challenge libraries in the coming years, ALA has <a href="https://www.ala.org/news/2025/04/imls-cuts-put-americas-public-libraries-risk">warned</a>. Butler has also suggested that under-resourced libraries may delay digitization efforts for preservation purposes if they worry that publishers may threaten costly litigation.</p>
<p>He told Ars he thinks courts are getting it right on recent fair use rulings. But he noted that libraries have fewer resources for legal fights because copyright law “has this provision that says, well, if you’re a copyright holder, you really don’t have to prove that you suffered any harm at all.”</p>
<p>“You can just elect [to receive] a massive payout based purely on the fact that you hold a copyright and somebody infringed,” Butler said. “And that’s really unique. Almost no other country in the world has that sort of a system.”</p>
<p>So while companies like AI firms may be able to afford legal fights with rights holders, libraries must be careful, even when they launch projects that seem “completely harmless and innocuous,” Butler said. Consider the Internet Archive’s Great 78 Project, which digitized 400,000 old shellac records, known as 78s, that were originally pressed from 1898 to the 1950s.</p>
<p>“The idea that somebody’s going to stream a 78 of an Elvis song instead of firing it up on their $10-a-month Spotify subscription is silly, right?” Butler said. “It doesn’t pass the laugh test, but given the scale of the project—and multiply that by the statutory damages—and that makes this an extremely dangerous project all of a sudden.”</p>
<p>Butler suggested that statutory damages could disrupt the balance that ensures the public has access to knowledge, creators get paid, and human creativity thrives, as AI advances and libraries’ growth potentially stalls.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>“It sets the risk so high that it may force deals in situations where it would be better if people relied on fair use. Or it may scare people from trying new things because of the stakes of a copyright lawsuit,” Butler said.</p>
<p>Courtney, who co-wrote a <a href="https://dash.harvard.edu/entities/publication/ef052f76-699c-49fb-aa26-e00488cfa318">whitepaper</a> detailing the legal basis for different forms of “controlled digital lending” like the Open Library project uses, suggested that Kahle may be the person who’s best prepared to push the envelope on copyright.</p>
<p>When asked how the Internet Archive managed to avoid financial ruin, Courtney said it survived “only because their leader” is “very smart and capable.” Of all the “flavors” of controlled digital lending (CDL) that his paper outlined, Kahle’s methodology for the Open Library Project was the most “revolutionary,” Courtney said.</p>
<p>Importantly, IA’s loss did not doom other kinds of CDL that other archives use, he noted, nor did it prevent libraries from trying new things.</p>
<p>“Fair use is a case-by-case determination” that will be made as urgent preservation needs arise, Courtney told Ars, and “libraries have a ton of stuff that aren’t going to make the jump to digital unless we digitize them. No one will have access to them.”</p>

<h2>What’s next for the Internet Archive?</h2>
<p>The lawsuits haven’t dampened Kahle’s resolve to expand IA’s digitization efforts, though. Moving forward, the group will be growing a project called Democracy’s Library, which is “a free, open, online compendium of government research and publications from around the world” that will be conveniently linked in Wikipedia articles to help researchers discover them.</p>
<p>The Archive is also collecting as many physical materials as possible to help preserve knowledge, even as “the library system is largely contracting,” Kahle said. He noted that libraries historically tend to grow in societies that prioritize education and decline in societies where power is being concentrated, and he’s worried about where the US is headed. That makes it hard to predict if IA—or any library project—will be supported in the long term.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>With governments globally partnering with the biggest tech companies to try to win the artificial intelligence race, critics have <a href="https://www.techpolicy.press/tech-oligarchy-imperils-democratic-information-flows/">warned</a> of threats to US democracy, while the <a href="https://americanlibrariesmagazine.org/blogs/the-scoop/white-house-attacks-libraries/">White House has escalated its attack on libraries</a>, <a href="https://arstechnica.com/science/2025/04/trump-administrations-attack-on-university-research-accelerates/">universities</a>, and <a href="https://arstechnica.com/tech-policy/2025/03/china-aims-to-recruit-top-us-scientists-as-trump-tries-to-kill-the-chips-act/">science</a> over the past year.</p>
<p>Meanwhile, AI firms face dozens of lawsuits from creators and publishers, which Kahle thinks only the biggest tech companies can likely afford to outlast. The momentum behind AI risks giving corporations even more control over information, Kahle said, and it’s uncertain if archives dedicated to preserving the public memory will survive attacks from multiple fronts.</p>
<p>“Societies that are [growing] are the ones that need to educate people” and therefore promote libraries, Kahle said. But when societies are “going down,” such as in times of war, conflict, and social upheaval, libraries “tend to get destroyed by the powerful. It used to be king and church, and it’s now corporations and governments.” (He recommended <em>The Library: A Fragile History</em> as a must-read to understand the challenges libraries have always faced.)</p>
<p>Kahle told Ars he’s not “black and white” on AI, and he even sees some potential for AI to enhance library services.</p>
<p>He’s more concerned that libraries in the US are losing support and may soon cease to perform classic functions that have always benefited civilizations—like buying books from small publishers and local authors, supporting intellectual endeavors, and partnering with other libraries to expand access to diverse collections.</p>
<p>To prevent these cultural and intellectual losses, he plans to position IA as a refuge for displaced collections, with hopes to digitize as much as possible while defending the early dream that the Internet could equalize access to information and supercharge progress.</p>
<p>“We want everyone [to be] a reader,” Kahle said, and that means “we want lots of publishers, we want lots of vendors, booksellers, lots of libraries.”</p>
<p>But, he asked, “Are we going that way? No.”</p>
<p>To turn things around, Kahle suggested that copyright laws be “re-architected” to ensure “we have a game with many winners”—where authors, publishers, and booksellers get paid, library missions are respected, and progress thrives. Then society can figure out “what do we do with this new set of AI tools” to keep the engine of human creativity humming.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/ashleybelanger/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2022/06/Ashley-Belanger-400x400.jpg" alt="Photo of Ashley Belanger"></a></p>
  </div>

  <div>
    

    <p>
      Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/tech-policy/2025/11/the-internet-archive-survived-major-copyright-losses-whats-next/#comments" title="214 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    214 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/google/2025/11/meet-project-suncatcher-googles-plan-to-put-ai-data-centers-in-space/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Suncatcher_hero-768x432.png" alt="Listing image for first story in Most Read: Meet Project Suncatcher, Google’s plan to put AI data centers in space" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The state of SIMD in Rust in 2025 (213 pts)]]></title>
            <link>https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d</link>
            <guid>45826348</guid>
            <pubDate>Wed, 05 Nov 2025 18:45:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d">https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d</a>, See on <a href="https://news.ycombinator.com/item?id=45826348">Hacker News</a></p>
Couldn't get https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Dillo, a multi-platform graphical web browser (365 pts)]]></title>
            <link>https://github.com/dillo-browser/dillo</link>
            <guid>45826266</guid>
            <pubDate>Wed, 05 Nov 2025 18:40:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dillo-browser/dillo">https://github.com/dillo-browser/dillo</a>, See on <a href="https://news.ycombinator.com/item?id=45826266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Dillo web browser</h2><a id="user-content-dillo-web-browser" aria-label="Permalink: Dillo web browser" href="#dillo-web-browser"></a></p>
<p dir="auto">Dillo is a multi-platform graphical web browser, known for its speed and
small footprint, that is developed with a focus on personal security and
privacy. It is built with the <a href="http://fltk.org/" rel="nofollow">FLTK 1.3 GUI toolkit</a>.</p>
<p dir="auto">Screenshot of the <a href="https://dillo-browser.github.io/" rel="nofollow">Dillo Website</a> rendered in Dillo:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/dillo-browser/dillo/blob/master/doc/dillo.png"><img src="https://github.com/dillo-browser/dillo/raw/master/doc/dillo.png" width="60%"></a></p>
<p dir="auto">To install Dillo follow the <a href="https://github.com/dillo-browser/dillo/blob/master/doc/install.md">installation guide</a>.</p>
<p dir="auto">This repository contains mostly the original code of Dillo with some
minor patches. Additional patches or pull requests are welcome.</p>
<p dir="auto">See also other related forks: <a href="https://github.com/crossbowerbt/dillo-plus">dillo-plus</a>,
<a href="https://github.com/w00fpack/dilloNG">dilloNG</a>, <a href="https://sourceforge.net/projects/dplus-browser/" rel="nofollow">D+ browser</a> and <a href="https://www.toomanyatoms.com/software/mobilized_dillo.html" rel="nofollow">Mobilized
Dillo</a>.</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT terms disallow its use in providing legal and medical advice to others (330 pts)]]></title>
            <link>https://www.ctvnews.ca/sci-tech/article/openai-updates-policies-so-chatgpt-wont-provide-medical-or-legal-advice/</link>
            <guid>45825965</guid>
            <pubDate>Wed, 05 Nov 2025 18:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ctvnews.ca/sci-tech/article/openai-updates-policies-so-chatgpt-wont-provide-medical-or-legal-advice/">https://www.ctvnews.ca/sci-tech/article/openai-updates-policies-so-chatgpt-wont-provide-medical-or-legal-advice/</a>, See on <a href="https://news.ycombinator.com/item?id=45825965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Updated<!-- -->:&nbsp;<time datetime="2025-11-05T21:12:58.371Z">November 05, 2025 at 4:12PM EST</time></p><p>Published<!-- -->:&nbsp;<time datetime="2025-11-05T14:57:46.237Z">November 05, 2025 at 9:57AM EST</time></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why aren't smart people happier? (399 pts)]]></title>
            <link>https://www.theseedsofscience.pub/p/why-arent-smart-people-happier</link>
            <guid>45824864</guid>
            <pubDate>Wed, 05 Nov 2025 16:32:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theseedsofscience.pub/p/why-arent-smart-people-happier">https://www.theseedsofscience.pub/p/why-arent-smart-people-happier</a>, See on <a href="https://news.ycombinator.com/item?id=45824864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>Adam Mastroianni is the author of </span><a href="https://experimentalhistory.substack.com/" rel="">Experimental History</a><span>. He studies how people perceive and misperceive their social worlds. His work has been featured in Science, Nature, and The Tonight Show with Jimmy Fallon. He has a PhD in psychology from Harvard and a certificate of completion from 137 different escape rooms. He’s originally from Monroeville, Ohio (pop. 1,400) and currently lives in New York City. </span></em></p><p><span>Here’s a definition of intelligence that lots of psychologists can </span><a href="http://www.kushima.org/wp-content/uploads/2016/11/1997mainstream.pdf" rel="">get</a><span> </span><a href="https://sci-hub.se/10.1037/a0026699" rel="">behind</a><span>:</span></p><blockquote><p>Intelligence is a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather, it reflects a broader and deeper capability for comprehending our surroundings-“catching on,” “making sense” of things, or “figuring out” what to do […] Intelligence, so defined, can be measured, and intelligence tests measure it well.</p></blockquote><p>Intelligence sounds pretty great. Who doesn’t want to “catch on” and “make sense”? Hell, “figuring out” what to do is pretty much all of life!</p><p>Naturally, people with more of this mental horsepower must live happier lives. When they encounter a problem, they should use their superior problem-solving ability to solve it. Smarter people should do a better job making plans and getting what they want, and they should learn more from their mistakes and subsequently make fewer of them. All of this should add up to a life that makes smart people go “this life rules!”</p><p>So smarter people are happier, right?</p><p><span>Well, this meta-analysis says </span><a href="https://www.researchgate.net/publication/264815376_Does_Intelligence_Boost_Happiness_Smartness_of_All_Pays_More_Than_Being_Smarter_Than_Others" rel="">no</a><span>. Another says </span><a href="https://www.gwern.net/docs/iq/1998-deneve.pdf" rel="">maybe a teeny tiny bit</a><span>. This large, nationally-representative study from the UK </span><a href="https://sci-hub.se/10.1017/s0033291712002139" rel="">finds</a><span> that people who score the lowest on an intelligence test are a little less happy than everyone else, but that’s pretty much it.</span></p><p><span>I also pulled data from the </span><a href="https://gssdataexplorer.norc.org/home" rel="">General Social Survey</a><span>, which includes (a) a short vocabulary test that </span><a href="https://gss.norc.org/Documents/reports/methodological-reports/MR111%20The%20Psychometric%20Properties%20of%20the%20GSS%20Wordsum%20Vocabulary%20Test.pdf" rel="">seems</a><span> to correlate reasonably well with longer intelligence tests (you can try it </span><a href="https://planspace.org/20220101-try_the_gss_wordsum_questions/" rel="">here</a><span>), and (b) a simple measure of happiness: “Taken all together, how would you say things are these days—would you say that you are very happy, pretty happy, or not too happy?” Across 50 years of data and 30,346 people, the folks who scored higher on the vocab test were a tiny bit </span><em>less</em><span> happy (r = -.06, p &lt; .001).</span></p><p><span>Maybe our tests are bad. The psychological study of intelligence has a </span><a href="https://en.wikipedia.org/wiki/Intelligence_quotient#IQ_testing_and_the_eugenics_movement_in_the_United_States" rel="">long, bleak history</a><span> of racism and prejudice against poor people (“</span><a href="https://education.blogs.archives.gov/2017/05/02/buck-v-bell/" rel="">three generations of imbeciles are enough</a><span>”), so we should be skeptical coming in. Psychologists have been </span><a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Ft14354-000" rel="">trying</a><span> to construct bias-free tests for a long time, but </span><a href="https://journals.sagepub.com/doi/pdf/10.1177/014662168100500309?casa_token=S8S8hrFW2KUAAAAA:83m3hcMT0tNAftX9MYadXlVzz8MZ-FB5Z2KQugTwdB1XQmyTgVHv7SlkYWF1HqZCls0lxlim1InXHQ" rel="">it’s</a><span> </span><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1744-6570.1972.tb00828.x?casa_token=hB0TdBnzAPsAAAAA%3A86panrQGOHm7h5yVMGPXruRPJgJUROsXJvlcw40jEBJeYZ68Ni_Rn_pHyCPZUMoNnxqETeGihvjWc8wZ" rel="">hard</a><span>. Plus, people score higher on IQ tests when you </span><a href="https://www.pnas.org/doi/full/10.1073/pnas.1018601108#sec-7" rel="">pay them for performance</a><span>, so what looks like a test of intelligence may in part be a test of how hard you’re willing to try.</span></p><p>But even if intelligence tests only measure something like “ability to succeed in an unfair society” or “willingness to try hard,” it only deepens the mystery. Shouldn’t those people end up with happier lives, however unfair that may be?</p><p><span>And the tests likely </span><em>do</em><span> tap something more than just privilege and effort. There’s plenty of skepticism toward intelligence tests in psychology, but even the biggest skeptics </span><a href="https://www.jstor.org/stable/pdf/23093686.pdf?casa_token=qStwqh4dZUkAAAAA:vpYyUCiGLL8PQ0GgXqBFagHxcv8Pm8yEvDz7LL6-KfNtwjRcsAgWhefEl_US8D2ZXVVaKkUgzdVbhcKabuGzHkcokhvIUWOtR0p7Gvx1M-u-E6CU6zbg" rel="">agree</a><span> that IQ can predict things like how well you do in school and what kind of job you get, even accounting for all the criticisms. So why doesn’t it also predict living a life that you like?</span></p><p><span>I think there’s one guy to blame for this big mystery, and his name is </span><a href="https://en.wikipedia.org/wiki/Charles_Spearman" rel="">Charles Spearman</a><span>.</span></p><p><span>Way back in 1904, Spearman noticed something weird: the same kids who did well in one subject in school </span><a href="http://94.200.75.214/DL/general_intelligence.pdf" rel="">tended to do well</a><span> in other subjects, too. The correlations were never perfect, of course, but they were pretty darn high, even across subjects that seemed pretty different from each other, like French and math. How come?</span></p><p><span>Spearman figured there must be some general mental ability that humans use to solve all kinds of problems. He later </span><a href="https://wellcomecollection.org/works/wpskbvst/items?canvas=17" rel="">wrote</a><span>:</span></p><blockquote><p>This continued tendency to success of the same person throughout all variations of both form and subject-matter—that is to say throughout all conscious aspects of cognition whatever—appears only explicable by some factor lying deeper than the phenomena of consciousness.</p></blockquote><p>Helpfully, he also drew us a picture:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!3M84!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!3M84!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 424w, https://substackcdn.com/image/fetch/$s_!3M84!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 848w, https://substackcdn.com/image/fetch/$s_!3M84!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 1272w, https://substackcdn.com/image/fetch/$s_!3M84!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!3M84!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png" width="343" height="197" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ad737909-3384-473d-b106-671d51de6008_343x197.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:197,&quot;width&quot;:343,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!3M84!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 424w, https://substackcdn.com/image/fetch/$s_!3M84!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 848w, https://substackcdn.com/image/fetch/$s_!3M84!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 1272w, https://substackcdn.com/image/fetch/$s_!3M84!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad737909-3384-473d-b106-671d51de6008_343x197.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Intelligence!</figcaption></figure></div><p><span>This is, I think, exactly where everything went wrong with the study of intelligence for the next 119 years. It’s not that Spearman’s results were inaccurate—in fact, they’ve been replicated over and over. At this point, pretty much every paper on intelligence has to start out like </span><a href="https://www.researchgate.net/profile/Jelte-Wicherts/publication/289963376_A_dynamical_model_of_general_intelligence_The_positive_manifold_of_intelligence_by_mutualism/links/5710ceaf08aefb6cadac0b21/A-dynamical-model-of-general-intelligence-The-positive-manifold-of-intelligence-by-mutualism.pdf" rel="">this review from 2006</a><span>:</span></p><blockquote><p>In the study of intelligence, one empirical phenomenon is well established: Test scores on cognitive tasks show a positive manifold, that is, they are invariably positively intercorrelated, albeit to varying degrees. This implies that people who score well on one cognitive test are likely to score well on other cognitive tests. The positive manifold is a robust phenomenon.</p></blockquote><p><span>Spearman’s stats were sound, but his interpretation was wrong. He did not, as he claimed, observe a “continued tendency to success throughout all variations of both form and subject-matter,” nor has anybody else. It merely </span><em>looks</em><span> as if we’ve varied all the forms and the subject-matters because we have the wrong theory about what makes them different.</span></p><p>We think tests of math, vocabulary, French, music, etc. are all different because some are about words and others are about numbers and others are about sounds. But psychology, like all sciences, is all about discovering the differences between seemingly similar things, and discovering the similarities between seemingly different things. If psychologists ever had to march into battle, a good candidate for our crests may be the famous Müller-Lyer illusion, the two lines that look like they’re different lengths but aren’t:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!I7Ye!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!I7Ye!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 424w, https://substackcdn.com/image/fetch/$s_!I7Ye!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 848w, https://substackcdn.com/image/fetch/$s_!I7Ye!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 1272w, https://substackcdn.com/image/fetch/$s_!I7Ye!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!I7Ye!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png" width="464" height="361" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:361,&quot;width&quot;:464,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!I7Ye!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 424w, https://substackcdn.com/image/fetch/$s_!I7Ye!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 848w, https://substackcdn.com/image/fetch/$s_!I7Ye!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 1272w, https://substackcdn.com/image/fetch/$s_!I7Ye!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9befc0b2-1d37-433f-8f59-1cfc167743bc_464x361.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>It strikes fear into the hearts of the economists!</figcaption></figure></div><p>Just like those lines, I think all of our various tests of intelligence aren’t as different as they seem. They’re all full of problems that have a few important things in common:</p><ul><li><p>There are stable relationships between the variables.</p></li><li><p>There’s no disagreement about whether the problems are problems, or whether they’ve been solved.</p></li><li><p>There have clear boundaries; there is a finite amount of relevant information and possible actions.</p></li><li><p>The problems are repeatable. Although the details may change, the process for solving the problems does not.</p></li></ul><p><span>I think a good name for problems like these is </span><em>well-defined</em><span>. Well-defined problems can be very difficult, but they aren’t mystical. You can write down instructions for solving them. And you can put them on a test. In fact, standardized tests items </span><em>must</em><span> be well-defined problems, because they require indisputable answers. Matching a word to its synonym, finding the area of a trapezoid, putting pictures in the correct order—all common tasks on IQ tests—are well-defined problems.</span></p><p><span>Spearman was right that people differ in their ability to solve well-defined problems. But he was wrong that well-defined problems are the </span><em>only</em><span> kind of problems. “Why can’t I find someone to spend my life with?” “Should I be a dentist or a dancer?” and “How do I get my child to stop crying?” are all important but poorly defined problems. “How can we all get along?” is not a multiple-choice question. Neither is “What do I do when my parents get old?” And getting better at rotating shapes or remembering state capitals is not going to help you solve them.</span></p><p>We all share some blame with Spearman, of course, because everybody talks about smarts as if they’re one thing. Google “smartest people in the world” and most of the results will be physicists, mathematicians, computer scientists, and chess masters. These are all difficult problems, but they are well-defined, and that makes it easy to rank people. The best chess player in the world is the one who can beat everybody else. The best mathematician is the one who can solve the problems that nobody else could solve. That makes it seem like the best chess players and mathematicians are not just the smartest in their fields, but the smartest in the whole world.</p><p><span>There is, unfortunately no good word for “skill at solving poorly defined problems.” Insight, creativity, agency, self-knowledge—they’re all part of it, but not all of it. </span><em>Wisdom</em><span> comes the closest, but it suggests a certain fustiness and grandeur, and poorly defined problems aren’t just dramatic questions like “how do you live a good life”; they’re also everyday questions like “how do you host a good party” and “how do you figure out what to do today.”</span></p><p><span>One way to spot people who are good at solving poorly defined problems is to look for people who feel good about their lives; “how do I live a life I like” is a humdinger of a poorly defined problem. The rules aren’t stable: what makes </span><em>you</em><span> happy may make </span><em>me</em><span> miserable. The boundaries aren’t clear: literally anything I do could make me more happy or less happy. The problems are not repeatable: what made me happy when I was 21 may not make me happy when I’m 31. Nobody else can be completely sure whether I’m happy or not, and sometimes </span><em>I’m</em><span> not even sure. In fact, some people might claim that I’m not </span><em>really</em><span> happy, no matter what I say, unless I accept Jesus into my heart or reach nirvana or fall in love—if I think I’m happy before all that, I’m simply mistaken about what happiness is!</span></p><p>This is why the people who score well on intelligence tests and win lots of chess games are no happier than the people who flunk the tests and lose at chess: well-defined and poorly defined problems require completely different problem-solving skills. Life ain’t chess! Nobody agrees on the rules, the pieces do whatever they want, and the board covers the whole globe, as well as the inside of your head and possibly several metaphysical planes as well.</p><p>Here’s another way of looking at it.</p><p>Say you want to test people’s math ability. You design a test, administer it to a bunch of people, do all your psychometrics, etc. You’re feeling pretty good about your math test. And then you find that some of the people who ace your test later say things like “two plus two is 19” and “88 is the biggest number.” You’d feel pretty embarrassed about your math test because it’s clearly not measuring mathematical ability, if it’s measuring anything at all.</p><p><span>This is exactly the situation we’re in with tests that claim to measure people’s “reasoning” and “problem-solving ability.” </span><a href="https://en.wikipedia.org/wiki/Christopher_Langan" rel="">Christopher Langan</a><span>, a guy who can score eye-popping numbers on IQ tests, </span><a href="https://thebaffler.com/latest/more-smarter-ward" rel="">believes</a><span> that 9/11 was an inside job meant specifically to distract the public from his theories, and he claims that banks won’t give him a loan because he’s white. </span><a href="https://en.wikipedia.org/wiki/John_H._Sununu" rel="">John Sununu</a><span> supposedly has IQ of </span><a href="https://www.washingtonpost.com/archive/local/1988/11/28/is-176-iq-enough-in-white-house/c0535981-650c-4c33-a233-78babc3006e0/" rel="">176</a><span>, but he still had to resign from being George H.W. Bush’s chief of staff because he flew to his dentist appointments using </span><a href="https://en.wikipedia.org/wiki/John_H._Sununu" rel="">military jets</a><span>. Bobby Fischer is one of the greatest chess players of all time, but he also </span><a href="https://web.archive.org/web/20050321201540/http://worldchessnetwork.com/English/chessNews/articles/2-3.php" rel="">claimed</a><span> that Hitler was a good dude, the Holocaust didn’t happen, and “Jews murder Christian children for their blood and they’re doing it even today.” Then there’s the ever-lengthening list of professors at elite universities who have been disciplined or dismissed for doing things like </span><a href="https://en.wikipedia.org/wiki/Jorge_I._Dom%C3%ADnguez" rel="">sexually harassing colleagues and students</a><span> or </span><a href="https://en.wikipedia.org/wiki/Diederik_Stapel" rel="">completely making up data</a><span> or </span><a href="https://en.wikipedia.org/wiki/Martin_Nowak" rel="">hanging out with a known pedophile</a><span>. These are supposed to be some of the smartest people in the world, endowed with exceptional problem-solving abilities. And yet they’re still unable to solve basic but poorly defined problems like “maintain a basic grip on reality” and “be a good person” and “don’t make any life-altering blunders.”</span></p><p><span>And here’s </span><em>another</em><span> way of looking at it.</span></p><p><span>Over the last generation, we have solved tons of well-defined problems. We eradicated smallpox and polio. We landed on the moon. We built better cars, refrigerators, and televisions. We even got </span><a href="https://en.wikipedia.org/wiki/Flynn_effect" rel="">~15 IQ points</a><span> smarter! And how did our incredible success make us feel?</span></p><p>Well:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6AU5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6AU5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 424w, https://substackcdn.com/image/fetch/$s_!6AU5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 848w, https://substackcdn.com/image/fetch/$s_!6AU5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 1272w, https://substackcdn.com/image/fetch/$s_!6AU5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6AU5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png" width="720" height="372" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:372,&quot;width&quot;:720,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!6AU5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 424w, https://substackcdn.com/image/fetch/$s_!6AU5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 848w, https://substackcdn.com/image/fetch/$s_!6AU5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 1272w, https://substackcdn.com/image/fetch/$s_!6AU5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F53c9aad7-e929-47c4-8ee3-76947bdbd613_720x372.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>All that progress didn’t make us a bit happier. I think there’s an important lesson here: if solving a bunch of well-defined problems did not make our predecessors happier, it probably won’t make </span><em>us</em><span> happier, either. The barrier between you and everlasting bliss is probably not the size of your television, nor your ability to solve </span><a href="https://en.wikipedia.org/wiki/Raven%27s_Progressive_Matrices" rel="">Raven’s Progressive Matrices</a><span>.</span></p><p>(To be clear, I still think it’s good we did all this. Polio sucks and going to the moon is awesome.)</p><p><span>I wish we knew more about how to make that bright green line go up, but we just haven’t yet defined the problem of “living a happy life”. We know that if you’re starving, lonely, or in pain, you’ll probably get happier if you get food, friends, and relief. After that, the returns diminish very quickly. You could read all the positive psychology you want, take the online version of </span><a href="https://www.coursera.org/learn/the-science-of-well-being?ranMID=40328&amp;ranEAID=EHFxW6yx8Uo&amp;ranSiteID=EHFxW6yx8Uo-.uLuPn2MieBhuQZx7IMA2Q&amp;siteID=EHFxW6yx8Uo-.uLuPn2MieBhuQZx7IMA2Q&amp;utm_content=10&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=EHFxW6yx8Uo" rel="">The Science of Wellbeing</a><span> (”Yale’s Most Popular Course Ever!”), read my post on </span><a href="https://experimentalhistory.substack.com/p/the-five-tools-of-hedonic-design" rel="">hacking the hedonic treadmill</a><span>, meditate, exercise, and keep a gratitude journal—and after all that, </span><em>maybe</em><span> you’ll be a </span><em>smidge</em><span> happier. Whatever else you think will put a big, permanent smile on your face, </span><a href="https://en.wikipedia.org/wiki/Stumbling_on_Happiness" rel="">you’re probably wrong</a><span>.</span></p><p>So if you’re really looking for a transformative change in your happiness, you might be better off reading something ancient. The great thinkers of the distant past seemed obsessed with figuring out how to live good lives: Socrates, Plato, Aristotle, Epicurus, Buddha, Confucius, Jesus, Marcus Aurelius, St. Augustine, even up through Thoreau and Vivekananda. But at some point, this kind of stuff apparently fell out of fashion.</p><p><span>And hey, maybe that’s because there’s just no more progress to make on the poorly defined problem of “how do we live.” But most well-defined problems were once defined poorly. For example, “how do we land on the moon” was a hopelessly poorly defined problem for most of human history. It only makes sense if you know that the moon is a big rock you can land on and not, say, </span><a href="https://www.smithsonianmag.com/science-nature/ancient-greek-philosopher-was-exiled-claiming-moon-was-rock-not-god-180972447/" rel="">a god floating in the sky</a><span>. We slowly put some definitions around that problem, and then one day we sent an actual dude to the moon and he walked around and was like “I’m on the moon now.” If we can do that, maybe we can also figure out how to live good lives. It certainly seems worth it to keep trying.</span></p><p><span>I’m not the first to propose that “general” intelligence is more than one thing. Pretty much as soon as Spearman started claiming that intelligence is mainly one thing, </span><a href="https://sci-hub.se/10.1080/08957347.2019.1619560" rel="">other people</a><span> started saying that intelligence is actually many things. (That’s science, baby!) Today, the most popular version of this theory claims there’s something like </span><a href="https://en.wikipedia.org/wiki/Theory_of_multiple_intelligences" rel="">eight intelligences</a><span>, ranging from “visual-spatial” to “bodily-kinesthetic.” I’m sympathetic to this take because it tries to account for all the different weird and wonderful things that humans can do. But it’s got two big problems.</span></p><p><span>Problem #1: People very rarely </span><a href="https://www.tandfonline.com/doi/pdf/10.1207/s15326985ep4104_1?casa_token=l5YMckHnhREAAAAA:_fP7IpehLupiMbJnfllvKjaALBENDDNjWXMZaNXtaY-0xnM9PFenP4NNTrb6y7a5gpdH0k4XCo5fgg" rel="">try</a><span> to find any evidence for it. And when they do, they find that the people who score high on one of the many intelligences </span><a href="https://www.sciencedirect.com/science/article/pii/S0160289606000201?casa_token=lTn7yOEg1ksAAAAA:tfFQaX8JhtoqYUhPbeq_Rag-5vkrYLLZdfzCI9m0H1rLSBHXsIsTZ0YI2AV3ZunYlc2X-XVNrqQ" rel="">tend to score high on the others, too</a><span>, just as Spearman would’ve predicted a hundred years ago.</span></p><p>Problem #2: When you label every human activity as its own intelligence, you give up any hope of understanding anything about the structure of problems in the world or how people solve them. We can make up whatever categories we want; they aren’t given by God. The only reason to use some categories and not others is that some categories are useful and others aren’t.</p><p>For instance, we could have created a periodic table that organized the elements alphabetically, or by color, or by how good they taste. Instead we organize them by atomic number, not because it’s their “true” order, but because it’s useful. It helps us realize things like, “Hey, we’ve got a number 62 and a number 64—I wonder if there’s a number 63 out there. We should go looking for it.”</p><p><span>So we should pick the way of categorizing intelligence that gives us the most bang for our buck. “Intelligence is many things” can’t explain why people perform similarly across supposedly different tests, and “intelligence is mostly one thing” can’t answer a basic question like “why smart people aren’t happier?” But we can handle both of those challenges when we split intelligence into skill at solving </span><em>well-defined</em><span> and </span><em>poorly defined</em><span> problems.</span></p><p>And that’s not all we can do.</p><p><span>People think of AI as a big glob of problem-solving ability. If you make the glob bigger, it can solve harder problems. That’s certainly been true so far: gigantic globs of AI can now </span><a href="https://waymo.com/" rel="">drive cars</a><span>, </span><a href="https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov" rel="">defeat our greatest chess players</a><span>, and </span><a href="https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe" rel="">predict how proteins will fold</a><span>.</span></p><p><span>All this has happened very quickly, which may make it seem like we’re careening toward a “general” artificial intelligence that can do all the things humans can. But if you split problems into </span><em>well-defined</em><span> and </span><em>poorly defined</em><span>, you’ll notice that all of AI’s progress has been on </span><em>defined</em><span> problems. That’s what artificial intelligence </span><em>does</em><span>. In order to get AI to solve a problem, we have to give it data to learn from, and picking that data requires defining the problem.</span></p><p>That doesn’t mean the problems AI has solved so far are stupid or trivial. They’re really important and interesting! They’re just all well-defined problems. And we should expect that pattern to continue: for any well-defined problem, AI will eventually outperform humans. But for poorly defined problems, AI is hopeless. To solve those, we need humans running around doing weird human stuff.</p><p><span>“What about </span><a href="https://openai.com/api/" rel="">GPT-3</a><span>—it can write movie scripts! And what about </span><a href="https://openai.com/dall-e-2/" rel="">DALLE-2</a><span>—it can paint pictures!” These AIs perform a clever trick: they make it seem like they’re solving poorly defined problems when, under the hood, they’re really solving well-defined problems. GPT-3 doesn’t actually write movie scripts; it predicts what words should come next. DALLE-2 doesn’t actually paint pictures; it matches words to images. These problems aren’t easy to solve—that’s why you need such a big glob of AI. But they obey clear, unchanging rules, they have bright boundaries, and you know precisely when you’ve solved them. They are well-defined problems. (This is also why </span><a href="https://erikhoel.substack.com/p/ai-art-isnt-art" rel="">AI art isn’t art</a><span>).</span></p><p>If you booted up a super-smart AI in ancient Greece, fed it all human knowledge, and asked it how to land on the moon, it would respond “You can’t land on the moon. The moon is a god floating in the sky.” How would you get it to realize the moon is actually a big rock? That’s a great, poorly defined problem, and I don’t expect AI to solve it anytime soon.</p><p>Here’s one last advantage of dividing intelligence into well-defined problem-solving and poorly defined problem-solving: it reminds us to give some respect where respect is due.</p><p><span>We’ve got no problem fawning over people who are good at solving well-defined problems. They get to be called “professor” and “doctor.” We pay them lots of money to teach us stuff. They get to join exclusive clubs like </span><a href="https://www.mensa.org/" rel="">Mensa</a><span> and the </span><a href="http://prometheussociety.org/wp/" rel="">Prometheus Society</a><span>. (By the way, Mensa’s page </span><a href="https://www.mensa.org/iq/what-iq" rel="">explaining IQ</a><span> doesn’t mention anything about the dark history of using intelligence tests to hurt people, and you might expect a bunch of smarty-pantses to, you know, use their brains to discuss things with a bit more nuance. But what do I know, I’m just a big dummy.)</span></p><p>People who are good at solving poorly defined problems don’t get the same kind of kudos. They don’t get any special titles or clubs. There is no test they can take that will spit out a big, honking number that will make everybody respect them.</p><p><span>And that’s a shame. My grandma does not know how to use the “input” button on her TV’s remote control, but she does know how to raise a family full of good people who love each other, how to carry on through a tragedy, and how to make the perfect pumpkin pie. We sometimes condescendingly refer to this kind of wisdom as “folksy” or “homespun,” as if answering multiple-choice questions is </span><em>real</em><span> intelligence, and living a good, full life is just some down-home, gee-whiz, cutesy thing that little old ladies do.</span></p><p>Excluding this kind of intelligence from our definitions doesn’t just hurt our grandmas—it hurts us too. If you don’t value the ability to solve poorly defined problems, you’ll never get more of it. You won’t seek out people who have that ability and try to learn from them, nor will you listen to them when they have something important to say. You’ll spend your whole life trying to solve problems with cleverness when what you really need is wisdom. And you’ll wonder why it never really seems to work. All of your optimizing, your straining to achieve and advance, your ruthless crusade to eliminate all of the well-defined problems from your life—it doesn’t actually seem make your life any better.</p><p>If you’re stuck trying to solve poorly defined problems with your slick, well-defined problem-solving skills and you’re lucky enough to have a grandma like mine still on this Earth, my god, go see her. Shut up and listen to her for a while. And once you’ve learned something, maybe ask her if she needs help with her TV.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Norway reviews cybersecurity after remote-access feature found in Chinese buses (367 pts)]]></title>
            <link>https://scandasia.com/norway-reviews-cybersecurity-after-hidden-remote-access-feature-found-in-chinese-buses/</link>
            <guid>45824658</guid>
            <pubDate>Wed, 05 Nov 2025 16:18:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scandasia.com/norway-reviews-cybersecurity-after-hidden-remote-access-feature-found-in-chinese-buses/">https://scandasia.com/norway-reviews-cybersecurity-after-hidden-remote-access-feature-found-in-chinese-buses/</a>, See on <a href="https://news.ycombinator.com/item?id=45824658">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1707918">

	
	
	<!-- .entry-header -->

	
	
	<div>
		<figure id="attachment_1707919" aria-describedby="caption-attachment-1707919"><img fetchpriority="high" decoding="async" src="https://scandasia.com/wp-content/uploads/2025/11/qegeqrfqefew-1024x576-1-735x413.webp" alt="" width="735" height="413" srcset="https://scandasia.com/wp-content/uploads/2025/11/qegeqrfqefew-1024x576-1-735x413.webp 735w, https://scandasia.com/wp-content/uploads/2025/11/qegeqrfqefew-1024x576-1-300x169.webp 300w, https://scandasia.com/wp-content/uploads/2025/11/qegeqrfqefew-1024x576-1-768x432.webp 768w, https://scandasia.com/wp-content/uploads/2025/11/qegeqrfqefew-1024x576-1-600x338.webp 600w, https://scandasia.com/wp-content/uploads/2025/11/qegeqrfqefew-1024x576-1.webp 1024w" sizes="(max-width: 735px) 100vw, 735px"><figcaption id="caption-attachment-1707919">A Yutong electric bus in Norway. Authorities are tightening cybersecurity controls after hidden SIM cards were discovered during internal tests.</figcaption></figure>
<p data-start="92" data-end="304">Norway has launched a cybersecurity review after public transport operator Ruter discovered that electric buses supplied by Chinese manufacturer Yutong contained hidden SIM cards enabling potential remote access.</p>
<p data-start="306" data-end="646">According to Ruter, internal tests at a secure facility found Romanian SIM cards inside the buses, theoretically allowing the Chinese supplier to shut down vehicles or interfere via software updates. The transport operator stressed there is no evidence of misuse but said the discovery moves concerns “from suspicion to concrete knowledge”.</p>
<p data-start="648" data-end="827">Ruter has removed the SIM cards and is strengthening procurement rules, internal firewalls, and cloud-security requirements to ensure full local control over transport operations.</p>
<p data-start="829" data-end="1057">Norway’s Minister of Transport Jon-Ivar Nygård told national broadcaster NRK that the government is assessing supplier risks from countries outside Norway’s security alliances, noting the need to protect critical infrastructure.</p>
<p data-start="1059" data-end="1363">Around 1,300 electric buses operate in Norway, including approximately 850 units from Yutong, with 300 running in Oslo and Akershus. Ruter said the likelihood of attempted interference remains low, but the situation underscores the growing cybersecurity challenges linked to foreign technology suppliers.</p>
<p data-start="1365" data-end="1582">The case comes as Chinese electric buses are increasingly adopted across global markets, including Southeast Asia, raising wider questions about digital security and strategic dependencies in public transport systems.</p>
<p data-start="1584" data-end="1714">“It’s unlikely these buses would ever be misused,” Ruter CEO Bernt Reitan Jenssen said, “but we must take the risk seriously.”</p>
<p data-start="1584" data-end="1714">Source: <a href="https://www.carscoops.com/2025/11/norways-public-buses-can-be-shut-down-remotely-from-china/" target="_blank" rel="noopener">Carscoops</a></p>

	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

		
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ruby and Its Neighbors: Smalltalk (205 pts)]]></title>
            <link>https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/</link>
            <guid>45823831</guid>
            <pubDate>Wed, 05 Nov 2025 15:24:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/">https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/</a>, See on <a href="https://news.ycombinator.com/item?id=45823831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    <header>
      <h2>Ruby And Its Neighbors: Smalltalk</h2>
      <p>
        Posted on
        <a href="https://noelrappin.com/blog/2025/11/">November</a>
        4,
        <a href="https://noelrappin.com/blog/2025/">2025</a>

        </p>
      
    </header>
    <br>
    <section>
      <p><a href="https://noelrappin.com/blog/2025/10/ruby-and-its-neighbors-perl/">Last time, we talked about Perl as an influence on Ruby</a>, this time, we’ll talk about the other major influence on Ruby: Smalltalk.</p>
<p>Smalltalk had a different kind of influence, since almost nothing of Smalltalk’s syntax made into Ruby. But many of the details of how objects work are directly inspired by Smalltalk, including the idea that every piece of data is part of the object system.</p>
<p>Also unlike Perl, I spent a good couple of years working in Smalltalk, and it is one of my favorite languages that I’ll never likely use in anger again.</p>
<h2 id="a-personal-history-of-smalltalk">(A Personal) History of Smalltalk</h2>
<p>Smalltalk originated in the same Xerox PARC team that invented the windowed interface, ethernet, and the laser printer, and who knows what else, they may have invented ice cream and rainbows.</p>
<p>There’s a whole story about what project Smalltalk was invented to be a part of, and a whole alternate history of computing and how people interact with computers that we are going to largely ignore. (If you are interested, start by searching for “Alan Kay Dynabook”.)</p>
<p>Smalltalk went through a few different iterations in the 1970s, but the version that we know today is a direct descendent of Smalltalk-80, which was the first version released to the wider world.</p>
<p>For most of the 80s and 90s, Smalltalk was something that doesn’t really exist today – a programming language and environment that companies paid money to use. Lots of money. The major player was ParcPlace, which was a spinoff of Xerox that provided Smalltalk tools. Their commercial product was originally called ObjectWorks, later changed to VisualWorks, and eventually sold off and presumably slowly losing customers after the late 90s.</p>
<p>Smalltalk was pretty big in the industry for a while. Most of the aviation industry ran on it in the 90s, the big payroll project that was the basis for Extreme Programming was a Smalltalk project, there was reasonably high demand for Smalltalk programmers through at least the mid 1990s. I taught an undergrad OO class in Smalltalk in 1997 and 1998 to students that wanted to be learning C++, and I remember telling them that Smalltalk programmers were paid more.</p>
<p>I first encountered Smalltalk as a grad student in about 1993, where Georgia Tech used ObjectWorks to teach Smalltalk and Object-Oriented programming (there’s a whole other sidebar about how Object-Oriented languages came to prominence in the 90s, and the arguments over that but again, another day). ObjectWorks was pricey, and there was also a lower-cost vendor called Digitalk, and eventually I also used a product called Smalltalk Agents, which has apparently totally vanished from the entire internet.</p>
<p>In 1995, a bunch of the original Xerox Smalltalk team was together at Apple, and they decided to release an open-source Smalltalk VM. What they did was very interesting. They wrote a very, very small kernel in very vanilla C, and then 95% of the environment was then built in Smalltalk on top of that. Oh, and even the vanilla C was written in Smalltalk, they wrote a Smalltalk to C compiler. They called their new Smalltalk “Squeak”, which made a lot more sense when they all moved en masse to Disney.</p>
<p>The fact that Squeak was largely written in itself made it fairly easy to port to new systems, and it was quickly available on just about anything with a microchip.</p>
<p>I’m pretty sure that I first saw Squeak at the OOPSLA conference in 1997. (Object-Oriented Programming, Systems, Languages &amp; Applications, since you asked) At this conference I somehow got to do a team-building exercise with Adelde Goldberg from the original Xerox PARC team, which is not relevant to anything but seemed very cool at the time. I was already using Smalltalk in my projects, but Squeak was immediately interesting and my extended research team started doing cool stuff. Like, what I’m pretty sure was the first Wiki tool outside the original C2 Wiki, was written in Squeak. (Apparently at least <a href="https://wiki.squeak.org/squeak">one</a> is still running).</p>
<h2 id="smalltalks-environment">Smalltalk’s Environment</h2>
<p>It’s important to understand that Smalltalk’s development is a different evolutionary tree from nearly every currently popular programming language, in that Smalltalk is in no way, shape, or form influenced by Unix or C. Perl, Ruby, Python, JavaScript, Swift, Kotlin and on and on, all come from a universe where they expect to run Unix libraries, and where C syntax is normal. The Unix philosophy of “small pieces, loosely joined” is not a part of Smalltalk’s DNA at all.</p>
<p>Smalltalk is basically its own operating system, and the syntax is different from C-style languages in ways big and small. For example, the first element of an array is… 1. Which, when you think about how people count, actually makes sense.</p>
<p>It’s hard to separate Smalltalk the language from Smalltalk the environment, although I suppose technically you could have the language without the whole shebang (and I think there was a GNU Smalltalk that tried this), really the environment is part of the appeal.</p>
<p>Your main interfaces to the smalltalk system are a <em>Workspace</em> and a <em>Browser</em>. A workspace is analogous to REPL session, you can type in arbitrary Smalltalk code and have the system “do it” to execute the code, “print it” to execute the code and output the result. There are some other actions like “debug it” or “inspect it”, but that’s the basic idea. Unlike a Unix REPL, there’s no prompt, and you don’t automatically invoke code by hitting return, you have to select code and then invoke the menu item or the keyboard shortcut for the code you want to act on.</p>
<p>The Browser is where you write code. There a a few different versions in most Smalltalks, here’s the main one, this is from a modern Smalltalk called <a href="https://cuis.st/">Cuis</a>.</p>
<p><img src="https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/browser.png" alt="A Smalltalk browser"></p>
<p>At the top, we have four window panes – left to right we have:</p>
<ul>
<li>Categories – groups of classes that are related in some way. Cuis nicely puts each group in a pulldown list. Categories have no particular syntactic meaning, they are just there to make browsing easier.</li>
<li>Classes – one entry for each class in the currently selected category, at the bottom of this pane is a toggle for “class” vs. “instance” which determines what kinds of messages are shown in the next two panes.</li>
<li>Protocols – a protocol is a user-defined group of messages. Smalltalk internally uses “message” rather than “method” because of how Alan Kay thinks about objects. Again, protocols are for the programmer, not the system.</li>
<li>Messages – each messages in the currently selected protocol is listed.</li>
</ul>
<p>The bottom pane is the code editor, and if a message is selected in the code pane, its code is displayed there.</p>
<p>You probably have questions:</p>
<p><strong>Does this mean that you can see the source code for the entire Smalltalk system?</strong></p>
<p>Yes, yes it does.</p>
<p>**Can you modify any code in the system? **</p>
<p>Yes, yes you can.</p>
<p><strong>Even, like, deep system code?</strong></p>
<p>Yes.</p>
<p><strong>Isn’t that dangerous?</strong></p>
<p>As a Ruby developer, you should know that it’s only as dangerous as the developers who use it.</p>
<p><strong>How do you edit a message?</strong></p>
<p>Just display the existing message in the browser, edit the message and select “save”. The Smalltalk system will parse the code, stop if there are syntax errors, but if not, the updated method will be saved to the system. A side effect is you can’t save code that isn’t syntactically parsable, even as a draft.</p>
<p><strong>Okay, but how do you <em>create</em> a message?</strong></p>
<p>The “real” way is to select a protocol but not a message, and Smalltalk will put a template in the edit window. Write your message in the editor and save it. Alternately, you can just change the name of a message in the edit window, and a new method with that name will be created, without deleting the old message.</p>
<p><strong>And how do you create a class?</strong></p>
<p>Similarly.</p>
<p>If you select a category and not a class, you’ll get this in the code editor pane:</p>
<div><pre><code data-lang="smalltalk"><span>Object</span> <span>subclass:</span> <span>#NameOfSubclass</span>
	<span>instanceVariableNames:</span> <span>''</span>
	<span>classVariableNames:</span> <span>''</span>
	<span>poolDictionaries:</span> <span>''</span>
	<span>category:</span> <span>'Kernel-Chronology'</span>
</code></pre></div><p>The thing to note is that this is not actually template, it’s actually code: a message, waiting for you to fill in the arguments, replacing <code>#NameOfSubclass</code> and adding the instance variables and so on. You don’t save this, you “do it”, just like if you were in a workspace. The message call is evaluated, and Smalltalk creates a new class.</p>
<p><strong>But wait, if all the code is in the image and isn’t in text files, how do people work together and share code?</strong></p>
<p>Don’t worry about it.</p>
<p>Seriously, though, worry about it.</p>
<p>This has always been a problem. Smalltalk allows you to share “change sets”, effectively the code differences between one point and another. Classically, one person would export their change set, and other team members would import it. Different Smalltalks have built up more sophisticated tools over time.</p>
<h2 id="smalltalks-syntax">Smalltalk’s Syntax</h2>
<p>Smalltalk’s syntax is very simple, relative to Ruby and Perl.</p>
<p>Wait a sec, I literally wrote this for a chapter in a book about Smalltalk literally 25 years ago, here’s a slight paraphrase:</p>
<p>Every line of Smalltalk is evaluated the same way.</p>
<ul>
<li>
<p>Every variable is an object. There are no basic types that are not objects.</p>
</li>
<li>
<p>Every expression is a message being passed to an object, there is basically no expression syntax that is not a message.</p>
</li>
<li>
<p>All messages return a value. (The return value is specified by <code>^</code>, if the method does not specify a return value, it implicitly returns <code>self</code>, the instance that received the message.)</p>
</li>
<li>
<p>There are three kinds of messages:</p>
<ul>
<li>Unary messages like <code>3 negated</code></li>
<li>Binary messages like <code>a + b</code>, these actually are messages you can define, there is a small set of them, and they are special cases in the parser.</li>
<li>Keyword messages such as <code>anArray at: 3 put: 7</code>. This syntax got used by ObjectiveC and later Swift, so you may be familiar with it. It’s <code>receiver &lt;messagepart&gt;: &lt;argument&gt;</code> where you can have multiple message parts. If you are referring to the message, typically you just say the message parts, so this message would be called <code>at:put:</code></li>
</ul>
</li>
<li>
<p>Smalltalk does not have operator precedence. All code is evaluated strictly from left to right. Unary messages first, binary messages second, keyword messages last. Parenthesis can be used to force order of operations or to make things clearer.</p>
</li>
<li>
<p>The assignment operator is <code>:=</code> (Smalltalk uses <code>=</code> for boolean equality), the right hand side is evaluated and the value is assigned to the result of the left hand side.</p>
</li>
</ul>
<p>And that’s basically it, with a couple of ways to create literals like strings, arrays, dictionaries, local variables, and blocks.</p>
<p>So, for 10 points and control of the board, what does this do?</p>
<p><code>hypotenuse := 3 squared + 4 squared sqrt</code></p>
<p>The unary messages are evaluated first:</p>
<p><code>hypotenuse := 9 + 16 sqrt</code></p>
<p>There’s still a unary message</p>
<p><code>hypotenuse := 9 + 4</code></p>
<p>Now we can do the binary message:</p>
<p><code>hypotenuse = 13</code></p>
<p>Oops.</p>
<p>To get what you actually want, you need parentheses:</p>
<p><code>hypotenuse := (3 squared + 4 squared) sqrt</code></p>
<p>Smalltalk does not have special syntax for loops, all loop behavior is defined by methods on <code>Array</code> and the like, very similar to Ruby’s <code>Enumerable</code>.</p>
<p>Smalltalk does not have special syntax to create messages or classes. Message creation is managed by the editor (which internally calls a message that adds the new code), class creation is just another method – in Squeak, that method is <code>Object#subclass:instanceVariableNames:classVariableNames:poolDictionaries:category:</code>.</p>
<p>Smalltalk does not have special syntax for boolean logic, all logic behavior is defined by the classes <code>True</code> and <code>False</code>. Ruby sort of does this, but Ruby does have <code>if</code> as special syntax. Smalltalk does not, you’d write a Smalltalk conditional as just another message:</p>
<pre><code>(x &gt; 10) ifTrue: [ x squared ] ifFalse: [ x sqrt ]
</code></pre><p>The square brackets are blocks, and behave very similar to Ruby blocks, except that you can treat them as just normal variables and normal arguments. You can even, as in this case, have multiple arguments that take blocks.</p>
<p>The implementation if the method <code>ifTrue:ifFalse</code> is simple. For the <code>True</code> class, it just takes the true block and executes it by passing it the message <code>value</code>.</p>
<pre><code>ifTrue: trueAlternativeBlock ifFalse: falseAlternativeBlock
	^trueAlternativeBlock value
</code></pre><p>And for the false class, the exact opposite:</p>
<pre><code>ifTrue: trueAlternativeBlock ifFalse: falseAlternativeBlock
	^falseAlternativeBlock value
</code></pre><p>Smalltalk doesn’t have a <code>case</code> or <code>switch</code> statement, typically if you want behavior like that you’d define a dictionary of keys to blocks or you would use the object system and polymorphism and double dispatch.</p>
<h2 id="smalltalks-object-model">Smalltalk’s Object Model</h2>
<p>There’s a lot about Smalltalk’s object model that sound familiar to a Ruby developer:</p>
<ul>
<li>There’s a base class called <code>Object</code> that everything inherits from.</li>
<li>Instance variables are private. Getters and setters default to having the same name as the instance variable.</li>
<li>Method lookup happens at the point of the method call.</li>
<li>Classes are instances of the class <code>Class</code> (sort of).</li>
<li>There’s a thing called a “Metaclass”</li>
<li>There’s a method that’s the method of last resort – in Ruby, it’s <code>method_missing</code>, but in Smalltalk it’s called <code>doesNotUnderstand</code></li>
</ul>
<p>There are a couple of differences as well</p>
<ul>
<li>Smalltalk’s meta classes are structured differently, I <a href="https://noelrappin.com/blog/2025/01/better-know-a-ruby-thing-singleton-classes/">explained this once</a> and I’m not sure I ever want to explain it again.</li>
<li>Smalltalk doesn’t have multiple inheritance or mixins or modules or anything like that. Although there have been some attempts to add these features, the traditional Smalltalk way to do this is through delegation.</li>
</ul>
<p>But overall, Smalltalk and Ruby are similar enough that a huge amount of Kent Beck’s <em>Smalltalk Best Practice Patterns</em> is applicable to Ruby as long as you translate the syntax.</p>
<h2 id="what-happened">What Happened?</h2>
<p>Unlike Perl, I actually did use Smallalk to build a few real applications that had real users. I miss it a lot.</p>
<p>I find that when I try to explain Smalltalk to people, it’s easy to explain the syntax and the object model. What’s hard to explain is how it is to work in a Smalltalk environment.</p>
<p>You’ve likely used powerful coding editors and terminals. Smalltalk is just different. You are in the running environment.</p>
<ul>
<li>Tests start instantly, and in general run very fast. There’s a dedicated test runner window. Some smalltalk integrate tests with the regular browser, so you can see test status from the code browsers.</li>
<li>Debugging is amazing, you can investigate the state of any object in the system, you can change that state, you can easily execute arbitrary code. You can have a test halt on exception, update the code and re-run from the point failure. It’s hard to describe how fluid it is, especially since I’m no longer expert enough to do it fluently.</li>
<li>While the editor doesn’t have all the niceties of the IDE’s you are used to, it’s very powerful in its own way. If you save code with a message name that does not appear in the image at all, Smalltalk will typically ask you if you want to define it right there. A lot of the things we ask a Language Server to do, Smalltalk just kind of does, because the image has access to everything.</li>
</ul>
<p>But the all-encompassing nature of the environment was also Smalltalk’s downfall. As more and more of the general computing environment became Unix and the “small pieces loosely joined” philosophy, Smalltalk got harder and harder to integrate. Smalltalk isn’t a scripting language, it was late to develop connectivity to external databases, its model of team interaction is fundamentally different from Unix source control. The image-based system has some drawbacks – you do get amazing access to the system, but it can be hard to tell where your code ends and the system begins. Code could depend on the state of the image in ways that were hard to replicate in deploys.</p>
<h2 id="what-did-ruby-take-from-smalltalk">What Did Ruby Take From Smalltalk?</h2>
<p>Smalltalk’s legacy in Ruby is primarily the object model – the idea that everything is an object and everything is manageable via method calls, and that message calls are evaluated at the point of call, as late as possible. Ruby takes that idea and translates it into a syntax that is more familiar to programmers used to C/Perl/Java.</p>
<p>I’m not sure this is exactly on point as far as Smalltalk’s influence on Ruby, but my Ruby style has always been very aggressive about creating new classes and objects. I’m quite confident that a reason for that style is that I came from Smalltalk first and not Java, Smalltalk style is much more amenable to small classes.</p>
<p>On my first largish Smalltalk project, users were simulating a chemical plant’s pipe system by placing tiles with pipes in them, and I frequently needed to do logic based on relative directions. I clearly remember creating a <code>Direction</code> class with basically four live instances, <code>up</code>, <code>down</code>, <code>left</code>, <code>right</code>, and just enough logic inside to say that <code>up.turn_left</code> equals <code>left</code>, but <code>down.turn_left</code> equals <code>right</code>. It was useful enough that I remember how much fun it was to build it even  now, nearly thirty years later.</p>
<p>Of all the other programming languages I’ve used, Ruby is the one that most clearly encourages that style of coding.</p>

    </section>

    <hr>
    

    <hr>


  </article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: My family business runs on a 1993-era text-based-UI (TUI). Anybody else? (279 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=45823234</link>
            <guid>45823234</guid>
            <pubDate>Wed, 05 Nov 2025 14:29:49 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=45823234">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="45826136"><td></td></tr><tr id="45826128"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45826128" href="https://news.ycombinator.com/vote?id=45826128&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I worked as a sales consultant for AT&amp;T wireless, back during the smartphone boom, at their retail stores. During onboarding everyone was taught how to use the GUI for everything (OPUS, I believe it was called): creating accounts, upgrading accounts, etc. But I noticed a few of the senior reps lived in the TUI (Telegence) and wondered why. When asked they claimed they were just used to it, but I quickly learned how much faster it was by observing them. They were able to process customers so much more quickly, a comparative advantage in commissioned-based sales.</p><p>My buddy and I requested access and learned how to use it. Not only did it streamline our process, it allowed us to do everything, where the GUI often omitted certain tasks forcing us reps to call customer service (for example, providing customers with credits after fixing their accounts).</p><p>So we lived with both the GUI up for when management walked by and relied on the TUI when we needed/wanted to work quickly.</p><p>I bet the system hasn't changed a bit. But I still live in the terminal quite a bit these days.</p></div></td></tr></tbody></table></td></tr><tr id="45824268"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824268" href="https://news.ycombinator.com/vote?id=45824268&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Many (most?) older retail businesses still use TUIs. They're reliable, consistent, and <i>orders of magnitude</i> faster than GUI systems.</p><p>When I worked ar Sherwin Williams, I got good enough with the TUI that customers could rattle off their orders while I punch it into the computer in real time.</p><p>It's absolutely crazy that a well designed TUI is <i>so</i> much faster. It turns out that if you <i>never</i> change the UI and <i>every</i> menu item <i>always</i> has the same hotkey, navigating the software becomes muscle memory and your speed is only limited by how fast you can physically push the buttons.</p><p>The program had many menu options added and removed over the decades, but the crucial part is that the hotkeys and menu indexes <i>never, ever</i> changed. Once you learn that you can pop into a quick order menu with this specific sequence of five keys, you just automatically open the right menu the moment a customer walks up. No thought, just pure reflex.</p><p>UX absolutely peaked with TUIs several decades ago. No graphical interface I've ever seen comes even close to the raw utility and speed of these finely tuned TUIs. There is a very, <i>very</i> good reason that the oldest and wealthiest retail businesses still use this ancient software. It works, and it's staggeringly effective, and any conceivable replacement will only be worse. There simply is no effective way to improve it.</p><p>Edit: I will say that these systems take time and effort to learn. You have to commit these UI paths to memory, which isn't too hard, but in order to be maximally effective, you also have to memorize a lot of product metadata. But the key is that it really doesn't take longer than your ordinary training period to become minimally effective. After that, you just pick up the muscle memory as you go. It's pretty analogous to learning touch typing without trying. Your hands just learn where the keys are and after enough time your brain translates words into keystrokes without active thought.</p><p>It's a beautiful way to design maximally effective software. We've really lost something very important with the shift to GUI and the shunning of text mode.</p></div></td></tr></tbody></table></td></tr><tr id="45825197"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825197" href="https://news.ycombinator.com/vote?id=45825197&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; I will say that these systems take time and effort to learn. You have to commit these UI paths to memory, which isn't too hard, but in order to be maximally effective, you also have to memorize a lot of product metadata.</p><p>One thing that often gets lost in the discussion of TUIs vs GUIs is that this is also true of GUIs. You have to know which icon to click, and it's not always in the same place, and not always labeled. Increasingly, functionality is hidden behind a hamburger menu, and not laid out in logical sections like File, Edit, View, etc menus.</p></div></td></tr></tbody></table></td></tr><tr id="45825561"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825561" href="https://news.ycombinator.com/vote?id=45825561&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>The cool thing about TUIs is that everything has an explicit label because it <i>has</i> to be this way.</p><p>On the system I use, every menu item was prefixed with a number. You punch in that number on the keyboard and you're in that menu. Just absolutely beautiful functionality</p></div></td></tr></tbody></table></td></tr><tr id="45825955"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825955" href="https://news.ycombinator.com/vote?id=45825955&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>You're right to point out the speed, but it is just not true that GUIs can't be fast. You can have screens that load quickly and shortcut keys etc.</p><p>You just have to make fast navigation and data entry a high priority. The assumptions and approaches people make today mean that generally isn't the case. With a TUI there is a hard limit on the amount of data you can load and that helps as a starting point.</p><p>- Often it's hitting a server is that is far away rather in the same building.</p><pre><code>  - you can put the web server in the same building
</code></pre><p>
- Each page is very heavy with lots of JavaScript etc. loading</p><pre><code>  - you can build lightweight web pages if you priority small script size, minimal dependencies,
    and do profiling to keep things in check
</code></pre><p>
- Data loading delays rendering</p><pre><code>  - limit the amount of data loaded and displayed at one time
</code></pre><p>
- Data is slow to load</p><pre><code>  - an older system has limited capacity meaning it's not an option to keep inactive data around
  - this means data is more likely to be indexed
  - new systems have very large storage capacities, leading to a larger and larger growing db
  - eventually default configuration for the database does not allow for everything active to be indexed
  - solution is to keep inactive data out of active tables being queried for normal operations
</code></pre><p>
- Slow to navigate with mouse</p><pre><code>  - you can create a keyboard navigation system
  - you can build keyboard shortcuts into every screen
  - you can create autocomplete shortcut commands to jump to screens</code></pre></div></td></tr></tbody></table></td></tr><tr id="45826122"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45826122" href="https://news.ycombinator.com/vote?id=45826122&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>At work we recently moved from Jira to Linear. It it fully keyboard navigatable and has shortcuts for pretty much everything. It's great! For me the only downside is that al that keyboard greatness clashes with my Vimium browser extension. Oh well...</p></div></td></tr></tbody></table></td></tr><tr id="45825821"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825821" href="https://news.ycombinator.com/vote?id=45825821&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Similar story.</p><p>I worked for a medium sized company who did work with Toro. We supplied many of their lubricants and they had TUI they still used on one of their machines to enter the orders from our company. It was the last of their legacy products, but worked incredibly well. 
We had very little issues ever with the system. Our Oracle ERP Net Suite? Had three people dedicated to making sure it ran smoothly. I still remember some of the guys I used to talk to at Toro were "lifers" who were always talking about how easier things were before all the SAAS and ERP software came on the scene.</p><p>The stories they had were pretty entertaining.</p></div></td></tr></tbody></table></td></tr><tr id="45824556"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824556" href="https://news.ycombinator.com/vote?id=45824556&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I remember training a new hire on her first day and, about an hour in, she said she needed a coffee break. I never saw her again lol.</p><p>Typically the first two weeks of training revolved around new hires asking why in the world we used this system before their spirits broke and they reluctantly plunged into the deep end...kind of like being released into the matrix.</p></div></td></tr></tbody></table></td></tr><tr id="45824713"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824713" href="https://news.ycombinator.com/vote?id=45824713&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Heh, I can relate. We employ a lot of Linux and Windows admins, for them it's usually not a big problem.</p><p>We also have a small finance team (typically around 2 employees), and finding somebody with a finance/billing background who is willing to work with TUI on Linux... that was a challenge :-)</p></div></td></tr></tbody></table></td></tr><tr id="45825317"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825317" href="https://news.ycombinator.com/vote?id=45825317&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; We've really lost something very important with the shift to GUI and the shunning of text mode.</p><p>GUIs can have keyboard shortcuts too. I'm an artist and I work two-handed: right hand moves the stylus around the screen, left hand floats around the keyboard and changes tools, summons control panels, etc. Whenever I try a different program than the one I'm used to, and have to poke at icons with my right hand because I don't know its shortcuts, I feel like half my brain's idling.</p></div></td></tr></tbody></table></td></tr><tr id="45825951"><td></td></tr><tr id="45825592"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825592" href="https://news.ycombinator.com/vote?id=45825592&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>This is about keyboard navigation rather than TUI vs GUI, there is no reason you have to render your app with plain text to support efficient keyboard nav.</p></div></td></tr></tbody></table></td></tr><tr id="45824633"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824633" href="https://news.ycombinator.com/vote?id=45824633&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I agree with basically everything you've said, but I'd add that I sometimes wish we had a way to sometimes pop up a GUI for very specific tasks.</p><p>For example, enabling a fast multi-select of rows in a longish table (or even worse, a tree) is one of the tasks that TUIs don't really excel at. Popping up a PDF or image viewer would also be great.</p><p>The TUI I'm working with runs on a pair of Linux VMs, and is accessed from Windows, Linux and Mac, so asking all our users to enable X forwarding doesn't really work.</p></div></td></tr></tbody></table></td></tr><tr id="45824854"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824854" href="https://news.ycombinator.com/vote?id=45824854&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Yeah, everything that couldn't be done through the TUI was a shitty web app, or worse, an iPad app. Fortunately those tasks were far less common and mostly dealt with the meta processes like searching national inventory, special corporate account data, things like that. All the day to day was in the TUI</p></div></td></tr></tbody></table></td></tr><tr id="45824358"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824358" href="https://news.ycombinator.com/vote?id=45824358&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Just the fact that you can use the keyboard is brilliant. I teach high school and most of my computing tasks are in lowest-bidder web GUI messes (lousy UX, no hotkeys) and take <i>so much longer</i> than a keyboard interface would. Even taking roll takes a minute or two longer than it used to.</p></div></td></tr></tbody></table></td></tr><tr id="45824980"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824980" href="https://news.ycombinator.com/vote?id=45824980&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I teach at a summer camp once that had custom web app for roll such that it displayed one name at a time to call out and to mark it as present you had to type their given name in a box, otherwise click next with empty input for absent</p></div></td></tr></tbody></table></td></tr><tr id="45825956"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45825956" href="https://news.ycombinator.com/vote?id=45825956&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Somebody needs to be fired for that sort of UI...</p><p>I've probably made that sort of UI without realizing it...</p></div></td></tr></tbody></table></td></tr><tr id="45825123"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825123" href="https://news.ycombinator.com/vote?id=45825123&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>No, but I learned yesterday that a carpenter and renovation person I know uses a GUI software from 1996 called "FloorPlan Plus 3D 3.01" [1] to design furniture before he builds it. He has a dusty old laptop running Windows XP on which the only thing that works is this software and the connection to the printer.</p><p>He showed me his workflow in detail. It's a beautiful software that does everything he needs.</p><p>And notice it's only 3.8 MB - smaller than many SaaS software webpages that offer lesser functionality.</p><p>[1] <a href="https://vetusware.com/download/FloorPlan%20Plus%203D%203.01/?id=9262" rel="nofollow">https://vetusware.com/download/FloorPlan%20Plus%203D%203.01/...</a></p></div></td></tr></tbody></table></td></tr><tr id="45825324"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825324" href="https://news.ycombinator.com/vote?id=45825324&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I wonder if there is a reddit thread with people showing off their surviving Windows XP setups.  Mine is a dell tower laying on its side because I harvested a power supply unit from another dell, but it doesn't fit in the case.</p></div></td></tr></tbody></table></td></tr><tr id="45825236"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825236" href="https://news.ycombinator.com/vote?id=45825236&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Loads of woodworking is done on SketchUp version whatever that's pre-cloud licensing, dating from 2008 I believe. (Cloud <i>aversion</i>, if you will.)</p><p>Picasa &amp; Earth era desktop Google software.</p></div></td></tr></tbody></table></td></tr><tr id="45825344"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825344" href="https://news.ycombinator.com/vote?id=45825344&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I remember using those pre-cloud versions. I loved them. Sketchup was so intuitive (as a 3D modelling noob) it was ridiculous. My tool of choice for making 3D levels for my various OpenGL projects.</p><p>I tried to do some rudimentary modelling with modern day Blender and failed. It‘s quite the juggernaut to learn.</p><p>What software today do people recommend as an alternative to Sketchup? Is the cloud version any good?</p></div></td></tr></tbody></table></td></tr><tr id="45825529"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45825529" href="https://news.ycombinator.com/vote?id=45825529&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; What software today do people recommend as an alternative to Sketchup?</p><p>onshape (web; free to use unless you want to protect your designs) and fusion (autodesk; free license available) are both really popular right now. they work differently than sketchup. i never really made friends with sketchup but the parametric modeling system used in fusion and onshape clicked with me and i really enjoy using them.</p></div></td></tr></tbody></table></td></tr><tr id="45826002"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45826002" href="https://news.ycombinator.com/vote?id=45826002&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Loved using Google Sketchup back in the day! My high school engineering teacher would show off his 3D modeling of cars during class. It was so cool seeing what you could do with that software!</p></div></td></tr></tbody></table></td></tr><tr id="45825947"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825947" href="https://news.ycombinator.com/vote?id=45825947&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>IIRC that version made it really easy to design things with dimensional lumber. 2x4”s, 2x6”s etc. I have vague recollections of designing a dog house that way from that time period.</p><p>I’m not sure how I’d do the same thing now. If I tried to do that now with Fusion, I’d probably have to build out my own primitive set of lumber sizes, right?</p></div></td></tr></tbody></table></td></tr><tr id="45825633"><td></td></tr><tr id="45825369"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825369" href="https://news.ycombinator.com/vote?id=45825369&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>A bit of searching turns up lots of references to SketchUp Make 2017. Could this be what you mean?</p></div></td></tr></tbody></table></td></tr><tr id="45825944"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825944" href="https://news.ycombinator.com/vote?id=45825944&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I worked with a steel warehouse about 10 years ago who were using software written in a Data General Business BASIC offshoot dialect, which ran on a proprietary Windows runtime that was essentially emulating the original minicomputer which ran the software when it was originally written in the late 1970s. Thankfully, the emulator at least ran on Windows so we were able to move it to a hosted environment with backups and away from a random tower in a metal warehouse, which is no place for a computer.</p><p>We were also tasked with adding new process automation and tooling. Instead of rewriting the system, we reverse engineered the database format and wrote additional tools and utilities around the core tooling, using more modern frameworks. I think this was the right choice and everyone was happy: they didn't have to relearn years of muscle-memory and business process built around the BASIC system, but we could iterate in a modern programming environment.</p><p>It wouldn't be surprising if the system was still in use, there was nothing wrong with it and it worked great.</p></div></td></tr></tbody></table></td></tr><tr id="45824226"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824226" href="https://news.ycombinator.com/vote?id=45824226&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I remember using a TUI for a Bank in the UK, and them switching to a web-based javascript system. Because the TUI forced keyboard interaction everyone was quick, and we could all fly through the screens finding what we wanted. One benefit was each screen was a fixed size and there was no scroll, so when you pressed the right incantation the answer you wanted appeared in the same portion of the screen every time. You didn't have to hunt for the right place to look. You pressed the keys, which were buffered, looked to the appropriate part of the screen and more often than not the information you required appeared as you looked.</p><p>Moving to a web based system meant we all had to use mice and spend our days moving them to the correct button on the page all the time. It added hours and hours to the processing.</p><p>Bring back the TUI!</p></div></td></tr></tbody></table></td></tr><tr id="45824520"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824520" href="https://news.ycombinator.com/vote?id=45824520&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>A GUI can be as effective as a TUI if it's designed to be 100% usable from a keyboard - the problem is very few applications take the time to do that design.</p></div></td></tr></tbody></table></td></tr><tr id="45824673"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824673" href="https://news.ycombinator.com/vote?id=45824673&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Maybe in some cases. But largely, no, it really is not comparable. These TUI interfaces literally had 0 latency for any action. You could paste in text (from clipboard), with \t characters, and it would advance the input focus and could fill out an entire form with once paste action. There's a ton of real world cases where the browser is just too heavy to keep up with fast paced data entry.</p><p>I've never once seen an experienced user equal or gain efficiency when switching. It's always a loss even after months of acclimation.</p></div></td></tr></tbody></table></td></tr><tr id="45824842"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45824842" href="https://news.ycombinator.com/vote?id=45824842&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>It's totally possible to get this done with a web based SPA. Just get rid of all the fancy design, images, gradients, animations, and so on, and just focus on usability.</p><p>The management needs to pick the right concept though, not the one with pretty and playful screenshots, but the one that focuses on the right KPIs (the 20 most common user flows need to take less than x seconds for an average user).</p></div></td></tr></tbody></table></td></tr><tr id="45824945"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_45824945" href="https://news.ycombinator.com/vote?id=45824945&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I was just giving some examples, it being theoretically possible in SPA isn't really helpful given that nobody will implement it that way. You're basically living in theory.</p><p>I've literally done the before and after on this a handful of times and it's always worse off. Management will never do that, it's always design by committee, the KPIs won't be defined or will never really have teeth, it will turn into someone's vanity project, they won't even pay someone to optimize the code - quite the opposite, they'll choose to build it on something like Salesforce or some other very non-performant enterprise-y platform, etc, etc. All the TUI get these performance gains out of the box without much additional effort. The constraints of the UI are it's strength as it prevents people from adding all this bloat in the first place. When you leave it up to people, especially business users or UX folks, it will get spoiled. It's almost a law.</p></div></td></tr></tbody></table></td></tr><tr id="45825087"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_45825087" href="https://news.ycombinator.com/vote?id=45825087&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; nobody will implement it that way</p><p>This is not true. Smart companies do it exactly that way. It saves them a lot of money.</p></div></td></tr></tbody></table></td></tr><tr id="45825421"><td></td></tr><tr id="45825461"><td><table><tbody><tr><td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td><center><a id="up_45825461" href="https://news.ycombinator.com/vote?id=45825461&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I have a hard time believing this. The medium impacts interaction.</p><p>Do you have concrete examples in mind that we can review?</p></div></td></tr></tbody></table></td></tr><tr id="45825697"><td><table><tbody><tr><td indent="7"><img src="https://news.ycombinator.com/s.gif" height="1" width="280"></td><td><center><a id="up_45825697" href="https://news.ycombinator.com/vote?id=45825697&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>The things I've worked on were custom tools for internal use. Built on top of existing systems, to improve productivity for specific workflows.</p></div></td></tr></tbody></table></td></tr><tr id="45824926"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_45824926" href="https://news.ycombinator.com/vote?id=45824926&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Possible yes but there are properties of a TUI vs a GUI where the TUI encourages faster keyboard navigation because when they were common there was <i>only</i> keyboard navigation whereas a GUI comes with it's own upsides (discoverability been the big one).</p><p>When I was in college (many years ago) the company I worked for used a TUI for its inventory/back office systems (terminal emulator talking to an AS/400) and once you understood the hierarchical structure and how it worked you could <i>fly</i> through that system because it was <i>all</i> keyboard nav.</p><p>Few GUI's have ever been that fast for me even the ones that go out of their way to make everything accessible via the <i>GUI</i> bindable.</p></div></td></tr></tbody></table></td></tr><tr id="45824994"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_45824994" href="https://news.ycombinator.com/vote?id=45824994&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>The real issue is, that modern UX design is often too focused on pretty looks, instead of productivity. It's still possible to make a highly productive UI look pretty, but the priority is often completely wrong.</p><p>They shouldn't start from a few pretty figma sketches and then try to make them more usable. They should start from user flows, solve how the users can do certain things with maximum productivity, easy navigation, showing the right data together on the same screen, and so on. Only in the end make it pretty.</p></div></td></tr></tbody></table></td></tr><tr id="45825409"><td><table><tbody><tr><td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td><center><a id="up_45825409" href="https://news.ycombinator.com/vote?id=45825409&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; The real issue is, that modern UX design is often too focused on pretty looks,</p><p>It may be pretty but it makes me puke.</p><p>The "modern UX design" is based on layers upon layers of abstraction and "cheap" interfaces. Which one is the button ? Where is the scrollbar ?</p></div></td></tr></tbody></table></td></tr><tr id="45825521"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_45825521" href="https://news.ycombinator.com/vote?id=45825521&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; It's totally possible to get this done with a web based SPA.</p><p>Yeah, I guess I could say that before I tried rebinding ctrl-w and some of the Fx keys (like F12).</p></div></td></tr></tbody></table></td></tr><tr id="45825724"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_45825724" href="https://news.ycombinator.com/vote?id=45825724&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Sure, in a browser you can't use all the shortcuts, but still a lot. If you really need it, just wrap it in Electron, Tauri, or any other customizable browser.</p></div></td></tr></tbody></table></td></tr><tr id="45825370"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_45825370" href="https://news.ycombinator.com/vote?id=45825370&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; It's totally possible to get this done with a web based SPA.</p><p>Sending http response, waiting for reply. Http 200 ok</p><p>and so on and so forth. 
Web sucks. Of course, you can have something like Jira, bur still sucks.</p></div></td></tr></tbody></table></td></tr><tr id="45825081"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45825081" href="https://news.ycombinator.com/vote?id=45825081&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>My experience has always been that TUIs and Terminal emulators these days have massive snags with how they handle control codes and inputs. Pasting into a terminal is a crapshoot of “what on earth is it going to spew back at me”.</p><p>It’s perfectly possible to handle large amounts of data by copy and paste on a web browser, you just have to actually support it.</p></div></td></tr></tbody></table></td></tr><tr id="45824651"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824651" href="https://news.ycombinator.com/vote?id=45824651&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>The other thing that a TUI generally does that a GUI doesn't is that it lets you type ahead, you can drive it without looking at the screen.</p><p>Most GUI's make you wait for the form to appear before you can type into it.   That totally destroys the flow of operators.</p><p>There are GUI's that are properly designed to be keyboard driven and to allow type-ahead.   Those can be truly best-of-both-worlds.   Too bad they're so rare.</p></div></td></tr></tbody></table></td></tr><tr id="45826100"><td></td></tr><tr id="45825494"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825494" href="https://news.ycombinator.com/vote?id=45825494&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Acquiring the skill to fly through such interfaces is equivalent to learning to play a musical instrument, where the desired attention (taking cues) and action (body/finger movement) becomes second nature. Such skill and interfaces are, unfortunately, not viewed as similarly valued as playing a musical instrument, and such visual presentation of the TUI is thought to be "difficult" to use, and they do take learning and effort to achieve that level of mastery. Meanwhile, the interface to traditional musical instruments, while there's been some changes and improvements, have stood the test of time and remain attractive to a lot people who want to make music. Many of the claimed "improvements" that GUI interfaces have over TUIs look in some cases, to me, like busy box toys created for toddlers (this is how I feel about the Windows Ribbon menu widgets). Once something becomes second nature, it's not "I'm putting my fingers in this position" it is "I want to play an A after this series of other notes".</p></div></td></tr></tbody></table></td></tr><tr id="45825660"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825660" href="https://news.ycombinator.com/vote?id=45825660&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I experienced the same thing. The big Brokerage firm I worked for in the 90s had amazing TUIs. You could fly through the screens. They even had DMs and group chats. Pretty amazing. The next company I worked for was rolling-out a GUI replacement for their TUI interface and I watched people's productivity plummet as they went from keyboard, to mouse for every text box... Those old mainframe TUIs were amazing, probably the result of decades of time and motion studies.</p></div></td></tr></tbody></table></td></tr><tr id="45824608"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824608" href="https://news.ycombinator.com/vote?id=45824608&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I was making this argument in early 2000s, how the "upgrade" would kill efficiency - and it largely did for data entry. I did this swap in medical industry and finance industry and it landed on deaf ears all the time in the name of modernization. Actually, feels like I'm reliving it right now with AI.</p></div></td></tr></tbody></table></td></tr><tr id="45824627"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824627" href="https://news.ycombinator.com/vote?id=45824627&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Sounds like the UX designers for the new applications didn't understand the requirements. I worked on two web app projects that required to be usable fast and with keyboards only. It's not that hard, if you define the requirements right.</p><p>Also no scrolling was a requirement. This was done by defining a min and max screen resolution, and designing everything exactly for that. The app was supposed to be used exclusively full screen, so no need for responsive design.</p><p>The result was a bit like a video game, very few loading delays and instant responses to user input.</p></div></td></tr></tbody></table></td></tr><tr id="45825066"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825066" href="https://news.ycombinator.com/vote?id=45825066&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Devil's advocate: There is one thing GUIs do better than TUIs: international text. Try to present on the same terminal screen text in Arabic and Japanese.</p></div></td></tr></tbody></table></td></tr><tr id="45825105"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825105" href="https://news.ycombinator.com/vote?id=45825105&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Yes, I'm quite sure that's true in most cases.</p><p>FWIW, dBASE IV version 1.5 does support Japanese for date format. It's one of the options for 'SET DATE' command.</p></div></td></tr></tbody></table></td></tr><tr id="45825234"><td></td></tr><tr id="45825309"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_45825309" href="https://news.ycombinator.com/vote?id=45825309&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Yes! I was just pointing it out to show that they had at least thought of Japanese users (in some small way).</p></div></td></tr></tbody></table></td></tr><tr id="45824849"><td></td></tr><tr id="45826068"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45826068" href="https://news.ycombinator.com/vote?id=45826068&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I’ve worked at many bars and restaurants. The best ordering interface I ever used was at Pizza Hut circa 1999. It was a monochrome TUI (orange). It was ancient-looking even then.</p><p>The speed was incredible once you got proficient. Once you got the muscle memory down you could punch in any single pizza order in less than a second. Even something complicated like different toppings on the halves was NBD. Pizza Hut was always coming up with these ridiculous gimmicks and the system could accommodate them seamlessly. Just incredible.</p><p>This system probably quietly saved the company millions in its time.</p></div></td></tr></tbody></table></td></tr><tr id="45824909"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824909" href="https://news.ycombinator.com/vote?id=45824909&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Yeah I actually help out a friend's family business a lot and we recently had to fix the program for something. It's a foxpro application rewritten in '89 from an original dBase port from earlier in the 80s. I legit had to bust out radare2 and hexdump(analysis)/hex fiend(editing) in order to get the changes done because the original programmer passed away (RIP). Was quite the learning experience but I'm glad that things were simple enough back then to make it something like an easy introduction into the world of reverse engineering for money.</p><p>I've seen even older in use. There's an auto parts store in the capital city of Costa Rica which was still running dBase III for its inventory system on a green phosphor screen IBM PC. Not sure if that store is around post-pandemic but it certainly was running around 4 or 5 years ago. Wish I got a video but it's in a particularly sketchy area that I don't really have any reason to return to.</p><p>Also, if anyone else ever has to dump an old database to CSV or whatever, I found perl to be the best tool for the job as it handles old encodings just fine. You can go from ancient database to spreadsheet really easy this way. Here's the ticket:</p><p><a href="https://www.burtonsys.com/download/dbf2csv.php" rel="nofollow">https://www.burtonsys.com/download/dbf2csv.php</a></p></div></td></tr></tbody></table></td></tr><tr id="45825723"><td></td></tr><tr id="45825336"><td></td></tr><tr id="45826089"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45826089" href="https://news.ycombinator.com/vote?id=45826089&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>When I worked at State Street everything was done in IBM/370 terminal emulators and a COM component which made is easy to scrape information into Excel. I wasn't really supposed to know about that but found enough code examples which weren't password protected that I could figure it out.</p></div></td></tr></tbody></table></td></tr><tr id="45826073"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45826073" href="https://news.ycombinator.com/vote?id=45826073&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I watched Alien: Earth recently and was admiring the TUIs everywhere.  The show takes place in 2120 and they kept up the aesthetics of the original movies.  A future full of synthetic humanoids and interstellar ships kept the TUI.  I do not remember tablets being in the series, however even those seem to use a similar TUI.</p><p>I look forward to my great grandchildren rediscovering the TUI.</p></div></td></tr></tbody></table></td></tr><tr id="45824705"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824705" href="https://news.ycombinator.com/vote?id=45824705&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Most, if not all, Asian take-out / restaurants in NL still use a TUI for registering your order. Several motorcyle retailers in NL use a TUI for parts management, invoicing, repair tracking. In both cases, people operating these systems develop muscle memory for their everyday usage. I'm not sure if it's still in use, but for at least a decade since 2005 or so, the local university's student canteen used an in-house developed TUI for selling snacks and drinks.</p><p>And if you stretch the definition of TUI a bit, the Bloomberg terminal is a fascinating example.</p></div></td></tr></tbody></table></td></tr><tr id="45825841"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825841" href="https://news.ycombinator.com/vote?id=45825841&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I think the Bloomberg terminal counts as a TUI.  It's also probably the most complex and heavily used TUI in existence.</p></div></td></tr></tbody></table></td></tr><tr id="45824405"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824405" href="https://news.ycombinator.com/vote?id=45824405&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Yes, we still have a TUI to our core CMDB and billing. With 500+ employees, not everybody is happy with it, so we also built an API and a web app to access and manipulate the most central data.</p><p>But, we also have some power users who absolutely swear by it, and we offer some  power user features for them :-)</p><p>* full readline integration, so there's a command history, Ctrl-R reverse search in the command history etc.</p><p>* tab completion for many prompts</p><p>* a generic system where outputs can be redirected to a pager, a physical printer, "wc" (word count), into a file etc.</p><p>* tabular data also has an alternative CSV representation</p><p>* generic fast-jump into menus. This works by supplying commands on the command line, and transitioning to interactive mode when the command list has run out</p><p>This is all built in-house; the first git commit is from 1997 but that was "import from CVS" and already 20k LoC, so the actual origins go back further.</p><p>It's written in Perl with no framework, just libraries.</p></div></td></tr></tbody></table></td></tr><tr id="45825627"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825627" href="https://news.ycombinator.com/vote?id=45825627&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I think you are about a decade off  on your first git commit, unless you meant they went cvs -&gt; svn or something and then ended up on git later.</p></div></td></tr></tbody></table></td></tr><tr id="45824674"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824674" href="https://news.ycombinator.com/vote?id=45824674&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>An interesting theme here in the comments (that I am sympathetic to) is "TUIs have steep learning curves but are fast/efficient for people with proficiency". I wonder if a small part of the modern preference for GUIs is related to a lack of employee retention. If companies aren't necessarily interested in working hard to keep employees then training new hires needs to be faster/easier and that could work against TUI and keyboard-based tools.</p><p>Of course, if that's a factor I'm guessing it's a small one in comparison to expectations about what "modern" software should look like.</p></div></td></tr></tbody></table></td></tr><tr id="45825906"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825906" href="https://news.ycombinator.com/vote?id=45825906&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I don't think it's an either/or situation.</p><p>An application I worked on was a GUI but (at the user's request) we loaded that thing up with hotkeys like no other.</p><p>Watching experienced employees operate a gui I worked on was a fascinating experience.  They were so fucking fast!</p><p>I think the problem is that GUI authors often put hotkeys in as an afterthought.</p></div></td></tr></tbody></table></td></tr><tr id="45824920"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824920" href="https://news.ycombinator.com/vote?id=45824920&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>It's also quite common that the customer is now the one that drives the interface.</p><p>It's the customer's time wasted by the UI, but also the customer typically can't be expected to perform enough orders to actually learn a complicated interface.</p><p>TUIs persist in industries where there is specialized knowledge needed to even complete the order. For example, an optometrist's office.</p></div></td></tr></tbody></table></td></tr><tr id="45824985"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824985" href="https://news.ycombinator.com/vote?id=45824985&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I was thinking about employee-facing tools, but I agree that TUIs present an even bigger challenge for casual users / customers.</p></div></td></tr></tbody></table></td></tr><tr id="45824741"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824741" href="https://news.ycombinator.com/vote?id=45824741&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>This is a definite reality and headache.  The learning curve was steep and I literally had somebody walk out after training them for less than two hours.</p></div></td></tr></tbody></table></td></tr><tr id="45825171"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825171" href="https://news.ycombinator.com/vote?id=45825171&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Only a few ago I had been installing new VoIP phones for a small business on the East Coast that had 2 or 3 green screen terminals and an IBM server running some variant of Unix. Most people in the office had terminal emulators, but one fellow in the warehouse section showed off his boxed terminals they had on hand incase one died. It is interesting to me to hear from someone that experienced these anachronistic machines and software. Very unique building, there was a floor between floors you could only get to via the warehouse. It made for an unnaturally long stairwell.</p></div></td></tr></tbody></table></td></tr><tr id="45824833"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824833" href="https://news.ycombinator.com/vote?id=45824833&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Costco. Go to a supervisor in a red vest and ask what other Costco has the item that has stocked out and you'll see. No idea what the backend is but the app they use is a terminal emulator that looks straight out of the late 80's.</p></div></td></tr></tbody></table></td></tr><tr id="45825981"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825981" href="https://news.ycombinator.com/vote?id=45825981&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>It's a network of high end as400's, the software is custom.</p><p>They've burned multiple 100's of millions of dollars on multiple projects trying to re-develop and move off as400's, but they just pulled the plug on their most recent project a year or two ago.</p><p>The biggest issue with adoption on new system (based on insiders I've talked to) is that the existing system is very efficient for people knowledgeable about how to use it and the newer GUI based systems just don't match it.</p></div></td></tr></tbody></table></td></tr><tr id="45825027"><td></td></tr><tr id="45826093"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45826093" href="https://news.ycombinator.com/vote?id=45826093&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; <i>that the original mainframe hardware has likely been virtualized at this point</i></p><p>The as400 is a mini-computer, the high end of this line overlaps the low end of mainframe.</p><p>When I did some consulting work out there many years ago, they had a network of the largest as400's that IBM makes, connected together in one image.</p><p>Regarding virtualization: It would have to be on IBM's power processors.  IBM does offer cloud services running as400, I have no info on whether Costco is using that or not.</p></div></td></tr></tbody></table></td></tr><tr id="45824879"><td></td></tr><tr id="45824887"><td></td></tr><tr id="45824877"><td></td></tr><tr id="45824996"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824996" href="https://news.ycombinator.com/vote?id=45824996&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>My parents' small businesses still run an xBase-based TUI accounting application for GL, AP, AR, and payroll they first purchased in 1988. Other than a Y2K update it has run unchanged since it was originally installed. Today I have to use DOSBox to make it run but it still works great. I've scabbed-on a few quality-of-life updates (mainly by capturing and processing print jobs) but it mostly just does its thing.</p><p>As you'd expect with having a TUI the users can absolutely fly through it. It's extremely efficient for them.</p></div></td></tr></tbody></table></td></tr><tr id="45825354"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825354" href="https://news.ycombinator.com/vote?id=45825354&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I don't think you're blinded by nostalgia. In the early 2000's, I worked in an organization that was migrating away from TUI to web apps. I was one of the web guys back then. We got modern, more maintainable code at the expense of usability. Those TUI interfaces are way faster.</p><p>The web failed to live up to the early promises in a lot of ways. We have complicated frameworks, complex architectures, browser headaches, etc. and what we got out of it are user interfaces that are slower than what we replaced and entire categories of bugs that didn't exist before. There's so much extra bullshit in place to overcome the fact that we are using a stateless protocol designed to deliver text documents.</p><p>The only things I would really be concerned about with your family company's app are maintainability, availability of security updates, and the use of obsolete software like XP. It sounds like you're already modernizing the code. That old OS is a disaster waiting to happen though.</p><p>I like the idea of an internal enterprise app running in the terminal on a reliable FreeBSD or Linux machine. The people who have to live in that app will be faster with a keyboard-driven workflow. A web front end is for customers and situations where you prioritize looks and accessibility over speed and usability. If you implement the the business rules in a modern middle tier and have a good database backing it, you can have the best of both - TUI for internal users and slap on a web front end for external users.</p></div></td></tr></tbody></table></td></tr><tr id="45823951"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45823951" href="https://news.ycombinator.com/vote?id=45823951&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Lowes and home depot come to mind.  Their POS/terminals are just a terminal into an TUI.  John Deere, kabota and other ag equipment service &amp; parts providers still largely use a TUI.</p></div></td></tr></tbody></table></td></tr><tr id="45824123"><td></td></tr><tr id="45825653"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825653" href="https://news.ycombinator.com/vote?id=45825653&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I'm not positive whether Target's system from ~15 years ago was a TUI, but a friend worked there in college. He mentioned the process for tax exempt purchases was a bit challenging/not the most common. There were some frequent shoppers who had heard the assistance from the manager enough times, they could walk an employee through what buttons to press to get it setup correctly.</p></div></td></tr></tbody></table></td></tr><tr id="45824362"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824362" href="https://news.ycombinator.com/vote?id=45824362&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I built my own ERP system for handling my business. It's also an TUI and has been here on Hacker News a few times.</p><p>About training new staff, there's actually studies done on it:
<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2655855/" rel="nofollow">https://pmc.ncbi.nlm.nih.gov/articles/PMC2655855/</a></p><p>My 2 cents is that GUI is good for exploring new software, while TUI is wonderful if you already have a mental map of what you're doing. So for everyday used software I would definitely hope that more TUI's where used.</p></div></td></tr></tbody></table></td></tr><tr id="45824999"><td></td></tr><tr id="45824494"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824494" href="https://news.ycombinator.com/vote?id=45824494&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Super interesting study.  Training new staff was always the most challenging aspect of the software.</p></div></td></tr></tbody></table></td></tr><tr id="45825752"><td></td></tr><tr id="45824936"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824936" href="https://news.ycombinator.com/vote?id=45824936&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I don't know if they're still using it but around 2010 or so a client from the early 2000s got in touch because the UPS they were using for their SCO Unix + serial terminals server had failed and they wanted to replace it. I was amazed that they were still using it. I was even more amazed that the APC UPS they were going to replace the old one with... had a new version of the SCO UPS Monitoring application that they used to automatically do a clean shut down of the server if the power was out too long. Got them all set up and everything kept humming along.</p></div></td></tr></tbody></table></td></tr><tr id="45824270"><td></td></tr><tr id="45824353"><td></td></tr><tr id="45824442"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824442" href="https://news.ycombinator.com/vote?id=45824442&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>There's a completely unironic obituary linked from the LA Times from 1994, which makes me wonder if the scandalous meaning even existed yet in those days?</p></div></td></tr></tbody></table></td></tr><tr id="45824510"><td></td></tr><tr id="45824370"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824370" href="https://news.ycombinator.com/vote?id=45824370&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>My dad recently retired but his company was still using Pick as of a year or two ago. They also had a one-dude maintenance plan. I wonder if it was the same dude.</p></div></td></tr></tbody></table></td></tr><tr id="45824956"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824956" href="https://news.ycombinator.com/vote?id=45824956&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>My first job out of college was over 2 decades ago, and I was hired to work on a web app which was considered new technology. But an important application there that was used by hundreds of people around the country was written with Pick, and the owner of the company also had some local Houston businesses whose Pick applications he occasionally did maintenance work on. The owner had moved from Chicago to Houston at the beginning of the 80s because he was able to get a high-paying job with no degree, but when the oil bust happened he learned Pick programming from an older guy and did so well when he started his own business that he retired early.</p></div></td></tr></tbody></table></td></tr><tr id="45825474"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825474" href="https://news.ycombinator.com/vote?id=45825474&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>This whole thread reminds me of when I saw my first Windows-based ticket dispensing machine at a movie theater.  Early in the year there was a screening of the Star Wars trilogy at the Cinema at the North Park Mall in Dallas.  Every geek for miles beat a path to the theater.  When I got there the line was moving along reasonably quickly and was maybe 20 people deep.  No problem.  You get to the front of the line, hand over a $10 for two $5 tickets and the cashier pressed the "dispense ticket" button  twice.  Two tickets came out immediately and you were on your way.</p><p>Later that same year Jurassic Park premiered at the same location.  Again, every geek for miles around beat a path to the theater.  But this time when I arrived, the line was hundreds of people deep and it took about 45 minutes to get to the head of the line (good thing we got there early.)  When I got up to the cashier I found they had a new Windows-3.1 based ticket dispensing system.  You said how many tickets you wanted and the cashier moved the mouse over a text field, took their hands off the mouse to type "1" or "2" or whatever.  If you bought a child's ticket or a senior ticket, that went in a different form field.  Then the cashier put their hands back on the mouse, scrolled down and hit the "calculate" button.  It told them how much cash to take.  They took their hands off the keyboard to collect the cash and then pressed the "dispense tickets" button.  Thankfully, the system seemed to actually dispense tickets without crashing.  (Windows 3.x had a very bad reliability reputation.)</p><p>What had taken 10-15 seconds with the "old school" interface now took about a minute.</p><p>Never let anyone tell you "the new system" is better just because it is new.</p><p>[[ Also, about this time I remembered Jef Raskin going on about keyboard interfaces, but this was long before the publication of The Humane Interface.  And I know we're using the initialism "TUI" in this thread to mean "Text UI", but some people use it to mean "Tactile UI."  No one ever got fired for recommending a React Single Page App optimized to quickly swap pages on the current model iPhone.  Whether or not that's the best interface for the application is irrelevant. ]]</p></div></td></tr></tbody></table></td></tr><tr id="45824428"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824428" href="https://news.ycombinator.com/vote?id=45824428&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Until recently I helped running an old Clipper/dBase TUI application from the late 80s for a family member. We managed to run it successfully until they retired.</p><p>vDos (vdos.info) was a huge life saver for this application. It's similar to DOSBox, but more tailored to business applications. The big issue was always to find compatible printers for the old application, vDOS includes some emulation to print to any Windows printer.</p><p>There might be free alternatives to vDos, but it worked very well and is  reasonably priced.</p><p>PS: we also tried to recompile the Clipper source code with Harbour to modern targets. It looked very promising, but they were extremely happy with the vDos solution, which only took 2 hours to deploy.</p></div></td></tr></tbody></table></td></tr><tr id="45825740"><td></td></tr><tr id="45826130"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45826130" href="https://news.ycombinator.com/vote?id=45826130&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>It was a customer management and billing system, for a specific industry. Tailored to local requirements and insurance regulations (a lot of things got billed to insurance). There is commercial software available for this purpose, but it's a very small target group, and the products are neither great, nor cheap.</p><p>Over time it even got extended to interface with a few external systems, mostly by reading and writing text files to specific locations.</p><p>It was deployed on one location with 2-5 concurrent users on the same database. The workflow was something like this: open customer/new customer, read/add notes, register products/services provided, print invoice for customer, print monthly invoice for insurance companies including all the required information (hundreds of pages).</p></div></td></tr></tbody></table></td></tr><tr id="45824959"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824959" href="https://news.ycombinator.com/vote?id=45824959&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Thanks for the link, afaik my clients are still stuck using their old DOS TUI in a windows 7 VM that has no network access</p></div></td></tr></tbody></table></td></tr><tr id="45825049"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45825049" href="https://news.ycombinator.com/vote?id=45825049&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I've been there, this doesn't work well at all. Actually since Windows NT the DOS subsystem is already an emulation, and it's not that good. DOS applications worked really well up to Windows ME, but with NT/XP/7 it got worse.</p><p>vDos was overall much better than running DOS applications directly on Windows. Only drawback was performance. It never ran as fast as on a Pentium III with Windows 98, but still much faster than the original hardware it was designed for (~30 mhz 80386).</p><p>Our application was designed for Novell NetWare, back then it even supported row/table locks for dBase files on the shared network drive. This didn't work with Windows NT anymore. But vDos brought back the feature to Windows 10 and SMB shares!</p></div></td></tr></tbody></table></td></tr><tr id="45824241"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824241" href="https://news.ycombinator.com/vote?id=45824241&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>If it’s survived this long, it likely because it has years of small fixes to make it reliable and useful, and more than anything—- predictable for the user.</p><p>Modernizing will roll some of that back; I would only consider it if there’s a plan to be around for the years it will take to get good again.</p></div></td></tr></tbody></table></td></tr><tr id="45825402"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45825402" href="https://news.ycombinator.com/vote?id=45825402&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>People who are good programmers say this, they have this fantasy, but it's a myth. The opposite is of course true, because there is no maintenance, there are a bajillion agonizing bugs and people simply work around them, the "small fixes" live inside the heads of the people using the application.</p><p>Like the fantasy is that the bank uses TUIs and the bank has accumulated years of knowledge and the bank doesn't make mistakes. The bank has extremely well paid staff. Joe Shmoe's TUI app looks like the bank's app, but it is unmaintained, it has accumulated years of problems, not fixes, nobody is fixing them, people who say they fix them cannot possibly be keeping up with the sheer amount of toil and bugs needed for production software. You can see this in any GitHub project, how much insane maintenance is required, for stuff people actually use and has few bugs.</p></div></td></tr></tbody></table></td></tr><tr id="45825418"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825418" href="https://news.ycombinator.com/vote?id=45825418&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I'm starting to maintain a COBOL codebase for my dad's small business. It uses MicroFocus's runtime so it runs fine on Windows 10/11 (but I'm trying to migrate it to OpenCOBOL). He helped write a good chunk of it, but doesn't make any major changes to it anymore. I'm not confident enough to make major changes to it, but I fix some bugs here and there. I ended up writing a python script to parse the database layout for a python-based fuzzy search tool, but I still stuck to a terminal UI for it.</p></div></td></tr></tbody></table></td></tr><tr id="45825187"><td></td></tr><tr id="45824375"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824375" href="https://news.ycombinator.com/vote?id=45824375&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Textbook example of a piece of software being a shark (perfectly adapted over millennia to being a perfect predator) not a dinosaur (obsolete/extinct).</p></div></td></tr></tbody></table></td></tr><tr id="45824697"><td></td></tr><tr id="45824298"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824298" href="https://news.ycombinator.com/vote?id=45824298&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I wrote the main application for my wife's business — she's a psychologist. That was only a few years ago, but as a senior lecturer in the more theoretical parts of computer science, I never really needed fancy UIs with flashy graphical effects. So I built a core engine and used the classic dialog tool as the thin user-facing layer.</p><p>At first, my wife was pretty disappointed — as a computer science teacher, wasn't I supposed to know how to build a “real” app? But a few years later, she doesn't want anything else. I even offered to have one of my students create a nicer UI without changing the engine or database, but by now she's completely used to the terminal menus.</p><p>The tool keeps a database, collects data through dialog forms, generates PDF invoices with groff, and launches Thunderbird when needed (to send invoices, etc.).</p></div></td></tr></tbody></table></td></tr><tr id="45824609"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824609" href="https://news.ycombinator.com/vote?id=45824609&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&lt;At first, my wife was pretty disappointed</p><p>I've got a mental picture of you excitedly unveiling your work to her.  Glad she came around and very cool.</p></div></td></tr></tbody></table></td></tr><tr id="45824126"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824126" href="https://news.ycombinator.com/vote?id=45824126&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Both of the lumberyards in my city are still running on DOS (or DOS emulation) for their systems, along with quotes printed on dot matrix printers (and no online price sheet). They’re so low margin and old school, I don’t think they get tech upgrades more often than once every two human generations except for new capital equipment, which sucks most of their surplus.</p></div></td></tr></tbody></table></td></tr><tr id="45824277"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824277" href="https://news.ycombinator.com/vote?id=45824277&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I supported a lumberyard that was like this too.  Also, some "modern" laser machines required ancient versions of Windows and required floppy discs.  This was about 20 years ago, though.</p></div></td></tr></tbody></table></td></tr><tr id="45824575"><td></td></tr><tr id="45825512"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825512" href="https://news.ycombinator.com/vote?id=45825512&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Just recently seen this sort of trend of text-based UI or "TUI" applications in the terminal which has caught my attention ever since Claude Code.</p><p>Where can I find these TUI applications to look at?</p></div></td></tr></tbody></table></td></tr><tr id="45825943"><td></td></tr><tr id="45824287"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824287" href="https://news.ycombinator.com/vote?id=45824287&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Anyone who has ever worked with legit 10-key operators understands why many companies were loathe to migrate to modern graphical interfaces.</p><p>Some of the fastest manual data entry I've ever seen was by operators entering claim information into a medical billing system based on MUMPS.</p><p>Keep all hands and feet away.</p></div></td></tr></tbody></table></td></tr><tr id="45824331"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824331" href="https://news.ycombinator.com/vote?id=45824331&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>It's been a while since I worked at a bank, but most there core stuff was running in a mainframe and while "modern" front ends exist, the core work uses terminal access.</p><p>A key thing modern replacements lose is the input buffer: One can type multiple screens ahead. In a modern GUI application I can enter a shortcut, but then have to wait till the corresponding view/popup/window appears and registered it's event handlers till I can put in the next command. In a mainframe-style TUI, if I remember the sequence, I can type ahead the shortcuts and input for next screen(s) before it's ready. For the experienced user, who runs the same sequence often this is really efficient.</p></div></td></tr></tbody></table></td></tr><tr id="45824066"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824066" href="https://news.ycombinator.com/vote?id=45824066&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Reminds me of this story from 2021</p><p><a href="https://hackaday.com/2021/10/06/atari-st-still-manages-campground-reservations-after-36-" rel="nofollow">https://hackaday.com/2021/10/06/atari-st-still-manages-campg...</a></p><p>I have also met some people who worked at large old insurance companies. They originally used old mainframes and TUI, and the companies still exist. They told me of various things that were done. Of course migrations happened. And interfaces were built so that modern systems could speak with the old, sometimes via terminal emulator. And of course, some old systems still in use far beyond their time.</p></div></td></tr></tbody></table></td></tr><tr id="45824533"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824533" href="https://news.ycombinator.com/vote?id=45824533&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; I got my start as a script kiddie writing automations for this system with Microsoft Access, VBA, and SendKeys to automate data entry</p><p>I've done exactly this for the likes of JP Morgan Chase. Many of their core banking systems are some COBOL/Fortran mainframe (that I know nothing about) but the interface through a TUI client. When they have a desire to work in a more modern fashion, it's SendKeys to the rescue. There's definitely still a lot of TUI's that run the world.</p></div></td></tr></tbody></table></td></tr><tr id="45824611"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824611" href="https://news.ycombinator.com/vote?id=45824611&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I recall guitar center is still on a green screen back when I worked there in my youth. It was pretty fun learning that interface, fancy keyboard shortcuts etc.</p></div></td></tr></tbody></table></td></tr><tr id="45824361"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824361" href="https://news.ycombinator.com/vote?id=45824361&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Costco still runs its warehouse operations on a TUI application running on AS/400 machines. At least the ones in Canada but I heard it's the same for the US warehouses.</p></div></td></tr></tbody></table></td></tr><tr id="45824143"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824143" href="https://news.ycombinator.com/vote?id=45824143&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>TUI were great for many business applications, specially those in warehouses or factories.  They were easier to write and modify. Many business applications were migrated to web for little gain. IMHO.</p></div></td></tr></tbody></table></td></tr><tr id="45824368"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824368" href="https://news.ycombinator.com/vote?id=45824368&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Quite a few large businesses are still running code that was originally written for mainframes in the 60s and 70s.  Usually it is large batch operations, but I know of at least two fortune 100 companies that still have non-technical users running terminal emulators to connect to their 'mainframe' to perform some tasks.</p><p>I was about to say that's what keeps Sungard in business, but then I googled and saw they are no longer in business.  So maybe it is starting to die down.</p></div></td></tr></tbody></table></td></tr><tr id="45823934"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45823934" href="https://news.ycombinator.com/vote?id=45823934&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>&gt; This got me thinking: Are other companies still using this type of interface to drive their core operations?</p><p>Probably a big chunk of businesses that developed their core systems before the PC era. I don't know if they still use it, but Avis Rent-a-car's main application used by its front-line people was a TUI like that, and the front desk people could fly around int it (like you said).</p><p>But most developers ape current trends rather than actually figuring out what would work best, so I'd guess very few user-facing TUIs are being built now.</p></div></td></tr></tbody></table></td></tr><tr id="45824182"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824182" href="https://news.ycombinator.com/vote?id=45824182&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Sam Ash (recently defunct U.S. musical instrument chain) infamously used a system called GERS with a TUI, the components of which IIRC were adapted from either a furniture or carpet store. Well into the 2000s, receipts were still printed in full size carbon paper (triplicate) on dot matrix printers. You'd get a gift "card" that was a literal greeting card with one sheet of that dot matrix printout stuffed in it.</p></div></td></tr></tbody></table></td></tr><tr id="45824438"><td></td></tr><tr id="45824303"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824303" href="https://news.ycombinator.com/vote?id=45824303&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Leroy Merlin (French multinational retail company, home improvement and gardening products) still runs these systems at the PoS, at least in Spain.</p></div></td></tr></tbody></table></td></tr><tr id="45825246"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825246" href="https://news.ycombinator.com/vote?id=45825246&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Somewhere in 2004 I upgraded a TUI interface for a major advertising company in Belgium to support €. They used it for many years since, AFAIK.</p></div></td></tr></tbody></table></td></tr><tr id="45824193"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824193" href="https://news.ycombinator.com/vote?id=45824193&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I worked on a PCI-DSS project at a major consumer electronics retailer almost 17 years ago as an AIX/Solaris specialist.</p><p>At that time their 'web store' just put paid orders in a queue and a room full of humans typed the orders into the green screen which had all the actual inventory.</p></div></td></tr></tbody></table></td></tr><tr id="45824247"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824247" href="https://news.ycombinator.com/vote?id=45824247&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I used to work for a major greeting card company that had a TUI based ERP system from the 90’s until like 5 years go. People were insanely efficient using it, but quite the learning curve to learn all shortcuts and commands.</p></div></td></tr></tbody></table></td></tr><tr id="45824828"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824828" href="https://news.ycombinator.com/vote?id=45824828&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>My buddy works at a rather large auto auction and uses a TUI extensively, only jumping out to copy stuff from a few GUIs and pasting it into the TUI.</p></div></td></tr></tbody></table></td></tr><tr id="45824419"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824419" href="https://news.ycombinator.com/vote?id=45824419&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>The last time I went to Steve's Music Store (Toronto, Canada) they were still using the green on black terminals.  This was pre-pandemic.  Maybe someone can confirm if they still are.</p></div></td></tr></tbody></table></td></tr><tr id="45824256"><td></td></tr><tr id="45825875"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45825875" href="https://news.ycombinator.com/vote?id=45825875&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>A fairly large GDS company has replaced their old “green screen” terminals with a web app that contains the same green screen but with syntax highlighting and hyperlinks inline controls that appear and other quality of life improvements.</p></div></td></tr></tbody></table></td></tr><tr id="45824987"><td></td></tr><tr id="45824429"><td></td></tr><tr id="45824083"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824083" href="https://news.ycombinator.com/vote?id=45824083&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Interesting. What sort of database are they running and what is the frontend? Dbase? Foxpro? Turbo Pascal with BDE?</p></div></td></tr></tbody></table></td></tr><tr id="45824269"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_45824269" href="https://news.ycombinator.com/vote?id=45824269&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Foxpro is alive and well in our town water utilities company. My fellow student still works on it. I don't know a worse way to waste your best years.</p></div></td></tr></tbody></table></td></tr><tr id="45824900"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_45824900" href="https://news.ycombinator.com/vote?id=45824900&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>What do you consider waste? Living in a small town? Working for a utility company? Working with outdated software?</p></div></td></tr></tbody></table></td></tr><tr id="45825881"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_45825881" href="https://news.ycombinator.com/vote?id=45825881&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Working with FoxPro, I'm assuming. I spent several years dealing with xBase systems, and it was honestly a nightmare. I suppose if you've never used any other language or database, you wouldn't notice. Plus, the bit relative to the OP, it's a mostly worthless skill.</p></div></td></tr></tbody></table></td></tr><tr id="45824327"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824327" href="https://news.ycombinator.com/vote?id=45824327&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>Wegmans’ cash registers still use a TUI. It looks quite clean and friendly compared to the GUI-heavy slop of, say, my time at a major retailer. Speaking of nostalgia, my old gaming store also used a TUI for transactions, and it was highly responsive for anything local (and a PITA anytime it had to communicate with the CO). Also been exposed to a number of businesses these past few years who still use old AIX/Unix/TUI boxes for critical business functions, and most seem happy with them.</p><p>And therein lies the rub: if the process works, and modern software doesn’t necessarily offer any better value proposition, then there’s no real reason to migrate. For a <i>lot</i> of companies, the status quo might literally be all they’ll ever need, and IT’s role is to just keep it up, available, and secure as times change. Sure, I’ll side-eye a theater using a Windows box as an intermediary for Ticketmaster to run transactions against their old AIX rig collecting dust in a corner of a closet, but if it works and it’s secure, well, more power to them keeping costs down.</p><p>The advice I’d give is not to knock something just because it doesn’t fit current narratives around technology. Our jobs - first and foremost - are to build and support solutions that amplify productivity of humans in a way they can use without external support; whether it’s an ancient TUI or a modern GUI isn’t as relevant as its efficacy.</p></div></td></tr></tbody></table></td></tr><tr id="45824084"><td></td></tr><tr id="45824236"><td></td></tr><tr id="45824227"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824227" href="https://news.ycombinator.com/vote?id=45824227&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I'm in the distribution/manufacturing ERP vertical in the US for SMB clients... yes we see it. No - not often</p><p>Most people are running on 90s-2000s era stuff rather than TUIs.</p><p>For the most part, it works well, and is not very costly.</p><p>Check out Sage100... flexible, cheap, on prem... runs everything from job / work tickets to inventory, purchasing, financials, payroll, etc.</p><p>Aint sexy but it works!</p></div></td></tr></tbody></table></td></tr><tr id="45824620"><td></td></tr><tr id="45824804"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824804" href="https://news.ycombinator.com/vote?id=45824804&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>I remember going to the Pasadena Public Library as a kid (90s) and there were terminals everywhere for interfacing with the digital card catalog system. Pretty sure they were made by Digital/DEC. The black screens with orange glowing text were such a pleasure to play around with. I've been thinking it would be fun to have one of these in my house 24x7 to interface with a Home Assistant TUI.</p></div></td></tr></tbody></table></td></tr><tr id="45825534"><td></td></tr><tr id="45824576"><td></td></tr><tr id="45824524"><td></td></tr><tr id="45824439"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_45824439" href="https://news.ycombinator.com/vote?id=45824439&amp;how=up&amp;goto=item%3Fid%3D45823234"></a></center></td><td><br>
<div><p>This is absolutely impossible in the EU where law is changed 100x times per day. You simply wouldn't comply.</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Carice TC2 – A non-digital electric car (245 pts)]]></title>
            <link>https://www.caricecars.com/</link>
            <guid>45823186</guid>
            <pubDate>Wed, 05 Nov 2025 14:25:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.caricecars.com/">https://www.caricecars.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45823186">Hacker News</a></p>
Couldn't get https://www.caricecars.com/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The shadows lurking in the equations (279 pts)]]></title>
            <link>https://gods.art/articles/equation_shadows.html</link>
            <guid>45823141</guid>
            <pubDate>Wed, 05 Nov 2025 14:21:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gods.art/articles/equation_shadows.html">https://gods.art/articles/equation_shadows.html</a>, See on <a href="https://news.ycombinator.com/item?id=45823141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<!-- START CONTENT -->

                        

                        <p>
                        <img src="https://gods.art/images/articles/slashdot_comparison.gif" alt="Slash Dot Equation comparison">
                        For all the history of computational mathematical visualization, <span>graphing equations has been done in binary mode</span> - where graphs show only where an equation is EXACTLY equal. But when you only see in black-and-white, some things are invisible. For all this time, lurking beneath the error == 0 surface, <span>mathematical shadows</span> have been lurking in the equations.</p>
                        <p>FuzzyGraph, on the other hand, <span>visualizes equations in Non-Binary mode</span> - showing not only where an equation are exactly equal, but also where the equation <span>nearly equal</span> and where the equation is <span>far from equal</span> (where the error is high). Sometimes, these high error areas form clear visual shadow-like features.</p>

                        <p>Let's look at some examples...</p>

                        <h2 id="slashdot">Example 1: Slash Dot Equation</h2>

                        <p>Here is the "Slash Dot" Equation ( \( \frac{y}{x^2+y^2} = \frac{x+1}{x^2+y^2} \)) as both a conventional and fuzzy graph...</p>

                        

                        <p>Note the giant black hole that is present in the Fuzzy/Non-Binary graph, but invisible in conventional/Binary graphing. This "black hole" feature represents a region of high error in the equation.</p>


                        <h2 id="quasar">Example 2: Quasar Equation</h2>

                        <p>Let's look at another example: \(y = \frac{x}{x^2 + y^2} \)

                        </p>

                        <p>Notice that the <span>black hole eye-looking features are COMPLETELY INVISIBLE</span> in the conventional/binary mode of graphing.</p>


                        <h2 id="simple-black-hole">Example 3: Simple Star and Black Hole</h2>

                        <p>To get a better idea of what these black hole things are, let's look at a simpler example. First let's look at the opposite of a black hole - a simple star/particle example: \( x^2 + y^2 = 0 \). For this equation, there is only 1 solution: (0, 0). So if you <a href="https://www.desmos.com/calculator/tkzm7jpjaf">graph this in a conventional graphing app</a>, it will only show a single dot at (0, 0). But in FuzzyGraph, it looks like a fuzzy particle or something.</p>

                        

                        <p>But now, let's invert this to get the "Black Hole Equation": \( \frac{1}{x^2+y^2} = 0 \)...</p>

                        

                        <p>In this case, there is absolutely nothing to show on a conventional graph, as there are actual solutions to this equations. However, there is still a mathematical <a href="https://en.wikipedia.org/wiki/Topography">topography</a> which can be visualized (as can be seen in the fuzzy graph).</p>


                        <h2 id="shadow-lines">Example 4: Shadow Line</h2>

                        <p>Not all of the <span>Shadows</span> are like black holes.</p>
                        
                        <p>In this example, let's start by combining 2 lines together: \(y=x\) and \(y=-x\).</p>
                        <p>We can visually add 2 equations together by refactoring them so they are both equal to 0, and then multiplying the two refactored equations together. \(y=x\) can be changed to \(y-x=0\), and \(y=-x\) can be refactored to \(y+x=0\).</p>
                        <p>We can then combine 2 into a single equation these like this: \( (y-x) \times (y+x) = 0 \)</p>

                        

                        <p>And now, <span>let's invert one of the equations using division</span>: \( \frac{x-y}{x+y} = 0 \)</p>

                        

                        <p>So as you can see, the line that was inverted (under the division line) is now a <span>Shadow Line</span>. And this seems like a more "correct" way to visualize this than as the conventional graph shows it (which is indistinguishable from the simpler equation, \(y-x=0\)).</p>

                        <h2 id="phi-equation">Example 5: Phi Equation</h2>

                        <p>This equation works almost exactly as the previous. And like before, let's start with multiplication to combine 2 equations (in this case, a circle and a vertical line equation): \( x \times (x^2+y^2-1) = 0 \). </p>

                        

                        <p>But now, let's <span>invert the circle by using division</span>, which makes the equation: \( \frac{x}{x^2+y^2-1} = 0 \).</p>

                        

                        <p>Note that the <span>Shadow Circle is invisible in the conventional graph</span>. In fact, the conventional graph looks identical to a conventional graph of the \(x=0\) equation (as if the denominator was not there).</p>


                        <h2 id="underwater-islands">Example 6: Underwater Islands</h2>

                        <p>In all of these previous examples, the "shadows" have represented areas of high error. But in this last example, we'll see some hidden details that represent areas of low error - areas that are <span>nearly</span> solutions to the equation.</p>

                        <p>Consider the equation, \( y=4 sin(x)+ sin(2.7y) \), as both a conventional graph and a fuzzy graph:</p>

                        

                        <p>Note the floating dots in the fuzzy graph version that are not there in the conventional/binary graph. These are like underwater islands - underwater mountains that are just below the surface of the water (or in this case, the \( error == 0 \) surface). These hidden islands represent area that are near-solutions to the equation (which are only visible in FuzzyGraph).</p>
                        <p>Their presense hints that we can tweak the equation slightly to cause them to burst above the surface of the water (which should also make them visible in conventional graphs).</p>
                        <p>So let's change the equation from: <br>  \( y=4 sin(x)+ sin(2.7y) \) to: <br> \( y=4 sin(x)+ sin(2.8y) \)...</p>

                        

                        <p>And as you can see, <span>those previously-hidden islands are now visible in the conventional graph</span>. </p><p>So Fuzzy/non-binary graphing can help us see features of the mathematical topography that are completely invisible with conventional/binary.</p>

						<hr>
                        <p>Date published: 2025-11-05</p>
                        <!-- END CONTENT -->

                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing XSLT for a more secure browser (169 pts)]]></title>
            <link>https://developer.chrome.com/docs/web-platform/deprecating-xslt</link>
            <guid>45823059</guid>
            <pubDate>Wed, 05 Nov 2025 14:14:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.chrome.com/docs/web-platform/deprecating-xslt">https://developer.chrome.com/docs/web-platform/deprecating-xslt</a>, See on <a href="https://news.ycombinator.com/item?id=45823059">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  
    
    




<div translate="no">
  
    
    
      <div>
        
          <p><img alt="Mason Freed" src="https://web.dev/images/authors/masonfreed.jpg" decoding="async" height="64" loading="lazy" width="64"></p>
      </div>
    
  
    
    
      <div>
        
          <p><img alt="Dominik Röttsches" src="https://web.dev/images/authors/drott.jpg" decoding="async" height="64" loading="lazy" width="64"></p>
      </div>
    
  
</div>

<p>
  Published: October 29, 2025
</p>


<p>Chrome intends to deprecate and remove XSLT from the browser. This document
details how you can migrate your code before the removal in late-2026.</p>

<p>Chromium has officially deprecated XSLT, including the
<a href="https://developer.mozilla.org/docs/Web/API/XSLTProcessor">XSLTProcessor</a>
JavaScript API and the <a href="https://en.wikipedia.org/wiki/Processing_Instruction#:%7E:text=The%20most%20common%20use%20of%20a%20processing%20instruction%20is%20to%20request%20the%20XML%20document%20be%20rendered%20using%20a%20stylesheet%20using%20the%20%27xml%2Dstylesheet%27%20target">XML stylesheet processing
instruction</a>.
We intend to remove support from version 155 (November 17, 2026). The
<a href="https://github.com/mozilla/standards-positions/issues/1287#issuecomment-3227145793">Firefox</a>
and
<a href="https://github.com/whatwg/html/issues/11523#issuecomment-3149280766">WebKit</a>
projects have also indicated plans to remove XSLT from their browser engines.
This document provides some history and context, explains how we are removing
XSLT to make Chrome safer, and provides a path for migrating before these
features are removed from the browser.</p>

<h2 id="what_is_being_removed" data-text="What is being removed?" tabindex="-1">What is being removed?</h2>

<p>There are two APIs in the browser that implement XSLT, and both are being
removed:</p>

<ul>
<li>The
<a href="https://developer.mozilla.org/docs/Web/API/XSLTProcessor">XSLTProcessor</a>
class (for example, <code translate="no" dir="ltr">new XSLTProcessor()</code>).</li>
<li>The <a href="https://developer.mozilla.org/docs/Web/XML/XSLT/Guides/Transforming_XML_with_XSLT">XSLT Processing
Instruction</a>
(for example, <code translate="no" dir="ltr">&lt;?xml-stylesheet … ?&gt;</code>).</li>
</ul>

<h2 id="timeline_for_chrome" data-text="Timeline For Chrome" tabindex="-1">Timeline For Chrome</h2>

<p>Chrome has the following plan:</p>

<ul>
<li>Chrome 142 (Oct 28, 2025): Early warning console messages added to Chrome.</li>
<li>Chrome 143 (Dec 2, 2025): Official deprecation of the API - deprecation
warning messages begin to show in the console and in lighthouse.</li>
<li>Chrome 148 (March 10, 2026 Canary): Canary, Dev, and Beta releases begin
disabling XSLT by default, as an early-warning.</li>
<li>Chrome 152 (Aug 25, 2026): Origin Trial (OT) and Enterprise Policy (EP) go
live for testing. These allow sites and enterprises to continue using
features past the removal date.</li>
<li>Chrome 155 (Nov 17, 2026): XSLT stops functioning on Stable releases, for
all users other than Origin Trial and Enterprise Policy participants.**</li>
<li>Chrome 164 (Aug 17, 2027): Origin Trial and Enterprise Policy stop
functioning. XSLT is disabled for all users.**</li>
</ul>

<h2 id="what_is_xslt" data-text="What is XSLT?" tabindex="-1">What is XSLT?</h2>

<p>XSLT, or Extensible Stylesheet Language Transformations, is a language used to
transform XML documents, commonly into other formats such as HTML. It uses an
XSLT stylesheet file to define the rules for this conversion, and an XML file
containing the data used as input.</p>

<p>In browsers, when an XML file is received that links to an XSLT stylesheet, the
browser uses the rules in that stylesheet to rearrange, format, and convert the
raw XML data into a structured page (often HTML) that can be rendered for the
user.</p>

<p>For example, an XSLT stylesheet could take the following XML input:</p>
<devsite-code><pre translate="no" dir="ltr" is-upgraded="" syntax="XML"><code translate="no" dir="ltr">&lt;?xml<span> </span>version="1.0"?&gt;
&lt;?xml-stylesheet<span> </span>type="text/xsl"<span> </span>href="demo.xsl"<span> </span>?&gt;
&lt;page&gt;
<span> </span>&lt;message&gt;
<span>  </span>Hello<span> </span>World.
<span> </span>&lt;/message&gt;
&lt;/page&gt;
</code></pre></devsite-code>
<p>and this XSL stylesheet:</p>
<devsite-code><pre translate="no" dir="ltr" is-upgraded="" syntax="XSLT"><code translate="no" dir="ltr">&lt;xsl:stylesheet<span> </span>xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;
<span>  </span>&lt;xsl:output<span> </span>method="html"/&gt;
<span>  </span>&lt;xsl:template<span> </span>match="/page/message"&gt;
<span>    </span>&lt;body&gt;
<span>      </span>&lt;p&gt;Message:<span> </span>&lt;xsl:value-of<span> </span>select="."/&gt;&lt;/p&gt;
<span>    </span>&lt;/body&gt;
<span>  </span>&lt;/xsl:template&gt;
&lt;/xsl:stylesheet&gt;
</code></pre></devsite-code>
<p>and process them into this HTML for the browser to display: HTML</p>
<devsite-code><pre translate="no" dir="ltr" is-upgraded="" syntax="HTML"><code translate="no" dir="ltr">&lt;body&gt;
  &lt;p&gt;Message: Hello World.&lt;/p&gt;
&lt;/body&gt;
</code></pre></devsite-code>
<p>In addition to the XSL processing instruction shown in the previous example,
there's also the
<a href="https://developer.mozilla.org/docs/Web/API/XSLTProcessor/XSLTProcessor">XSLTProcessor</a>
JavaScript API which can be used to process local XML documents with local XSLT
stylesheets.</p>

<h2 id="history_of_xslt" data-text="History of XSLT" tabindex="-1">History of XSLT</h2>

<p>XSLT was recommended by the World Wide Web Consortium (W3C) on <a href="https://www.w3.org/TR/xslt-10/">November 16,
1999</a>, as a language for transforming XML
documents into other formats, most commonly HTML for display in web browsers.
Before the official 1.0 recommendation, Microsoft took an early initiative by
shipping a proprietary implementation based on a W3C working draft in <a href="https://en.wikipedia.org/wiki/Internet_Explorer_5">Internet
Explorer 5.0</a>, released in
March 1999. Following the official standard, Mozilla implemented native XSLT 1.0
support in <a href="https://www-archive.mozilla.org/status/2000-09-06">Netscape 6</a> in
late 2000. Other major browsers, including Safari, Opera, and later Chrome, also
incorporated native XSLT 1.0 processors, making client-side XML-to-HTML
transformations a viable web technology in the early 2000s.</p>

<p>The XSLT language itself continued to evolve, with the release of <a href="https://www.w3.org/TR/xslt20/">XSLT 2.0 in
2007</a> and <a href="https://www.w3.org/TR/xslt-30/">XSLT 3.0 in
2017</a>, which introduced powerful features like
regular expressions, improved data types, and the ability to process JSON.
Browser support, however, stagnated. Today, all major web browser engines only
provide native support for the original XSLT 1.0 from 1999. This lack of
advancement, coupled with the rise of the use of JSON as a wire format, and
JavaScript libraries and frameworks (like jQuery, React, and Vue.js) that offer
more flexible and powerful DOM manipulation and templating, has led to a
significant decline in the use of client-side XSLT. Its role within the web
browser has been largely superseded by these JavaScript-based technologies.</p>

<h2 id="why_does_xslt_need_to_be_removed" data-text="Why does XSLT need to be removed?" tabindex="-1">Why does XSLT need to be removed?</h2>

<p>The continued inclusion of XSLT 1.0 in web browsers presents a significant and
unnecessary security risk. The underlying libraries that process these
transformations, such as <a href="https://github.com/GNOME/libxslt">libxslt</a> (used by
Chromium browsers), are complex, aging C/C++ codebases. This type of code is
notoriously susceptible to memory safety vulnerabilities like buffer overflows,
which can lead to arbitrary code execution. For example, security audits and bug
trackers have repeatedly identified high-severity vulnerabilities in these
parsers (e.g., <a href="https://nvd.nist.gov/vuln/detail/CVE-2025-7425">CVE-2025-7425</a>
and <a href="https://nvd.nist.gov/vuln/detail/CVE-2022-22834">CVE-2022-22834</a>, both in
libxslt). Because client-side XSLT is now a niche, rarely-used feature, these
libraries receive far less maintenance and security scrutiny than core
JavaScript engines, yet they represent a direct, potent attack surface for
processing untrusted web content. Indeed, XSLT is the source of several recent
<a href="https://www.offensivecon.org/speakers/2025/ivan-fratric.html">high-profile security
exploits</a> that
continue to put browser users at risk. The security risks of maintaining this
brittle, legacy functionality far outweighs its limited modern utility.</p>

<p>Furthermore, the original purpose of client-side XSLT—transforming data into
renderable HTML—has been superseded by safer, more ergonomic, and
better-maintained JavaScript APIs. Modern web development relies on things like
the Fetch API to retrieve data (typically JSON) and the DOMParser API to safely
parse XML or HTML strings into a DOM structure within the browser's secure
JavaScript sandbox. Frameworks like React, Vue, and Svelte then manage the
rendering of this data efficiently and securely. This modern toolchain is
actively developed, benefits from the massive security investment in JavaScript
engines, and is what virtually all web developers use today. Indeed, only about
<a href="https://chromestatus.com/metrics/feature/timeline/popularity/79">0.02%</a> of web
page loads today actually use XSLT at all, with less than
<a href="https://chromestatus.com/metrics/feature/timeline/popularity/78">0.001%</a> using
XSLT processing instructions.</p>

<p>This is not a Chrome or Chromium-only action: the other two major browser
engines also support the removal of XSLT from the web platform:
<a href="https://github.com/whatwg/html/issues/11523#issuecomment-3149280766">WebKit</a>,
<a href="https://github.com/whatwg/html/issues/11523#issuecomment-3149788558">Gecko</a>.</p>

<p>For these reasons, deprecating and removing XSLT reduce the browser's attack
surface for all users, simplify the web platform, and allow engineering
resources to be focused on securing the technologies that actually power the
modern web, with no practical loss of capability for developers.</p>

<h2 id="improving_xml_parsing_security" data-text="Improving XML parsing security" tabindex="-1">Improving XML parsing security</h2>

<p>Similar to the severe security issues in libxslt, severe
<a href="https://gitlab.gnome.org/GNOME/libxml2/-/issues/950">security</a>
<a href="https://project-zero.issues.chromium.org/issues/432450829">issues</a> were
recently reported against libxml2 which is used in Chromium for parsing,
serialization and testing the well-formedness of XML. To address future security
issues with XML parsing In Chromium we plan to phase out the usage of libxml2
and replace XML parsing with a memory-safe XML parsing library written in Rust.
Importantly, we won't be removing XML from the browser; only XSLT is being
considered for removal here. We intend to ensure that replacing libxml2 is
entirely transparent to web developers.</p>

<h2 id="how_to_migrate" data-text="How to migrate" tabindex="-1">How to migrate</h2>

<p>There are a few alternative paths for migration.</p>

<h3 id="json" data-text="JSON" tabindex="-1">JSON</h3>

<p>For sites that are fully built on XML and XSL there is no one-size-fits all way
to make the transition. Migration options include moving the XSLT processing
pipeline to the server side and sending down the rendered HTML to the client, or
migrating server-side XML API endpoints to
<a href="https://en.wikipedia.org/wiki/JSON">JSON</a>, and performing client-side rendering
using JavaScript to transform JSON into HTML DOM and CSS.</p>

<h3 id="client-side_xslt_in_javascript" data-text="Client-side XSLT in JavaScript" tabindex="-1">Client-side XSLT in JavaScript</h3>

<p>There are a few client-side (JavaScript-based) XSLT libraries available, but the
largest by far is produced by
<a href="https://www.saxonica.com/welcome/welcome.xml">Saxonica</a> (view the
<a href="https://www.saxonica.com/saxonjs/documentation3/index.html#!starting">comprehensive documentation for
Saxonica</a>).
The implementation goes well beyond the XSLT 1.0 implementation in web browsers,
implementing full support for the latest <a href="https://www.w3.org/TR/xslt-30/">v3.0
standard</a>, and eventually the <a href="https://qt4cg.org/specifications/xslt-40/Overview.html">in-progress v4.0
standard</a>.</p>

<h3 id="polyfill" data-text="Polyfill" tabindex="-1">Polyfill</h3>

<p>There is a polyfill that attempts to allow existing code, which depends on web
browsers' implementations of XSLT 1.0, to continue functioning, while not using
native XSLT features from the browser. The polyfill is <a href="https://github.com/search?q=XSLT%20polyfill&amp;type=repositories">located on
GitHub</a>.</p>

<p>The polyfill contains a functional WASM-based polyfilled replacement for the
XSLTProcessor class, so existing JavaScript code can continue to work as-is:</p>
<devsite-code><pre translate="no" dir="ltr" is-upgraded="" syntax="HTML"><code translate="no" dir="ltr">&lt;script src="xslt-polyfill.min.js"&gt;&lt;/script&gt;

&lt;script&gt;
const xsltProcessor = new XSLTProcessor();
xsltProcessor.importStylesheet(xsltDoc);
const fragment = xsltProcessor.transformToFragment(xmlDoc, document);
&lt;/script&gt;
</code></pre></devsite-code>
<p>The polyfill also provides an automatic utility function for an easy way to
replace XML documents that use XSLT processing instructions:</p>

<p>For an original <code translate="no" dir="ltr">demo.xml</code> file like this:</p>
<devsite-code><pre translate="no" dir="ltr" is-upgraded="" syntax="XML"><code translate="no" dir="ltr">&lt;?xml<span> </span>version="1.0"?&gt;
&lt;?xml-stylesheet<span> </span>type="text/xsl"<span> </span>href="demo.xsl"?&gt;
&lt;ROOT&gt;
...content...
</code></pre></devsite-code>
<p>One line can be added to invoke the polyfill and transform the document with the
referenced XSLT stylesheet:</p>
<devsite-code><pre translate="no" dir="ltr" is-upgraded="" syntax="XML"><code translate="no" dir="ltr">&lt;?xml<span> </span>version="1.0"?&gt;
&lt;?xml-stylesheet<span> </span>type="text/xsl"<span> </span>href="demo.xsl"?&gt;
&lt;ROOT&gt;
&lt;script<span> </span>src="xslt-polyfill.min.js"
<span>   </span>xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;/script&gt;
...content...
</code></pre></devsite-code>
<p>In this case, the new <code translate="no" dir="ltr">&lt;script&gt;</code> element loads the polyfill, which detects the
XML document type and the XSLT processing instruction and transparently loads
it, replacing the document.</p>

<h2 id="extension" data-text="Extension" tabindex="-1">Extension</h2>

<p>There's also a <a href="https://chromewebstore.google.com/search/xslt%20polyfill">Chrome
extension</a> that can be
added to supported browsers, which will apply the same XSLT polyfill to all raw
XML pages that contain XSLT processing instructions or calls to XSLTProcessor.
This can be used for applications where the source XML or XSLT cannot be
changed, to maintain functionality.</p>

<p>In particular, when XSLT is disabled, Chrome now shows a warning banner that
links directly to an extension search page, to help users locate an extension:</p>

<p><img src="https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message.png" alt="The message shown in Chrome when xslt is detected." srcset="https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_36.png 36w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_48.png 48w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_72.png 72w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_96.png 96w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_480.png 480w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_720.png 720w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_856.png 856w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_960.png 960w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_1440.png 1440w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_1920.png 1920w,https://developer.chrome.com/static/docs/web-platform/deprecating-xslt/image/deprecation-message_2880.png 2880w" sizes="(max-width: 840px) 100vw, 856px"></p>

<h2 id="specific_use_cases" data-text="Specific use cases" tabindex="-1">Specific use cases</h2>

<p>In the <a href="https://github.com/whatwg/html/issues/11523">discussion in HTML
standards</a>, several concrete use
cases were identified. This section talks specifically about each of them, to
recommend paths forward for developers publishing XML resources that use XSLT
today.</p>

<h3 id="rss_and_atom_feeds" data-text="RSS and Atom Feeds" tabindex="-1">RSS and Atom Feeds</h3>

<p>In many existing RSS or Atom feeds, XSLT is used to make raw XML feeds
human-readable when viewed directly in a browser. The primary use case is that
when a user accidentally clicks on a site's RSS feed link, rather than pasting
that link into their RSS reader, they get a formatted HTML response that they
can read, rather than the raw XML itself.</p>

<p>There are two paths forward for this use case. The "standard" HTML way to do
this is to add <code translate="no" dir="ltr">&lt;link rel="alternate" type="application/rss+xml"&gt;</code> to an
(HTML-based) site, rather than adding an explicit (user-visible) <code translate="no" dir="ltr">&lt;a
href="something.xml"&gt;</code> that users might accidentally click. This solution allows
RSS readers to find the feed if a user pastes in just the website URL, but it
also allows human users to see the regular HTML content without getting confused
by a link to an XML resource. This also follows the normal web paradigm that
HTML is for humans and XML is for machines. Of course this doesn't solve the
case where a user just "has" an RSS link from somewhere, and they paste it into
their web browser (rather than their RSS reader).</p>

<p>When that solution isn't wanted, the polyfill offers another path. As mentioned
previously, the RSS/Atom XML feed can be augmented with one line, <code translate="no" dir="ltr">&lt;script
src="xslt-polyfill.min.js" xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;/script&gt;</code>,
which will maintain the existing behavior of XSLT-based transformation to HTML.
That shouldn't affect RSS reader's ability to continue parsing the XML, since
the <code translate="no" dir="ltr">&lt;script&gt;</code> is a direct child of the root element.</p>

<h3 id="api_output_for_embedded_devices" data-text="API output for embedded devices" tabindex="-1">API output for embedded devices</h3>

<p>Some commercial embedded devices measure or otherwise generate XML data for
consumption by users on the local network. Some of these devices do this by
generating a single XML data feed that uses XSLT to transform it into a
human-readable HTML format. That allows the API to be directly viewed in a
browser without needing additional code on the device or in the browser.<br>
Since this is a very application specific use case, the shape of the solution
might vary. For applications where the source code of the embedded device can be
updated, any of the options described previously (JSON, Polyfill) could work. In
particular, however, many such devices are difficult or impossible to update,
for various reasons. In that case, the
<a href="https://chromewebstore.google.com/detail/xslt-polyfill/hlahhpnhgficldhfioiafojgdhcppklm">extension</a>
is likely the best option, since it allows client browsers to continue to read
the data in exactly the same way, without modifying the device.</p>

<h3 id="lazy_templating_for_web_sites" data-text="Lazy templating for web sites" tabindex="-1">Lazy templating for web sites</h3>

<p>Web developers sometimes use XSLT on the client side to apply presentation
markup to semantic markup, functioning as a lazy templating language that is
separate from the JavaScript ecosystem.</p>

<p>There are two solutions to this more general problem. For an existing site built
in this way, the easiest solution is likely just to add the polyfill to maintain
existing functionality. Or perhaps perform the XSLT transformation on the server
side, and serve the resulting HTML to the client, rather than the raw XML. The
more long-term solution for such properties would be to migrate to a more modern
JavaScript or JSON-based framework.</p>

<p>If you encounter a specific problem in Chrome related to this XSLT deprecation,
<a href="https://issues.chromium.org/issues/new?component=1456730&amp;template=2210866">report a bug here</a>.</p>

  

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Can't Keep EU Data Safe from US Authorities (265 pts)]]></title>
            <link>https://www.forbes.com/sites/emmawoollacott/2025/07/22/microsoft-cant-keep-eu-data-safe-from-us-authorities/</link>
            <guid>45822902</guid>
            <pubDate>Wed, 05 Nov 2025 14:00:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/emmawoollacott/2025/07/22/microsoft-cant-keep-eu-data-safe-from-us-authorities/">https://www.forbes.com/sites/emmawoollacott/2025/07/22/microsoft-cant-keep-eu-data-safe-from-us-authorities/</a>, See on <a href="https://news.ycombinator.com/item?id=45822902">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure role="presentation"><p><img src="https://specials-images.forbesimg.com/imageserve/687f7bbbcb4042a7d9157905/King-Charles-III-And-Queen-Camilla-Visit-France---Day-Two/960x0.jpg?fit=scale" alt="King Charles III And Queen Camilla Visit France - Day Two" data-height="1860" data-width="2604" fetchpriority="auto"></p><div><p><span>The French Senate (Photo by Samir Hussein - Pool/WireImage)</span></p><p><small>WireImage</small></p></div></figure><p>Microsoft has admitted that it can't protect EU data  from U.S. snooping.</p><p>In sworn <a href="https://www.senat.fr/compte-rendu-commissions/20250609/ce_commande_publique.html" target="_blank" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.senat.fr/compte-rendu-commissions/20250609/ce_commande_publique.html" aria-label="testimony">testimony</a> before a French Senate inquiry into the role of public procurement in promoting digital sovereignty, Anton Carniaux, Microsoft France's director of public and legal affairs, was asked whether he could guarantee that French citizen data would never be transmitted to U.S. authorities without explicit French authorization. And, he replied, "No, I cannot guarantee it."</p><p>He said that the company resisted requests from the US authorities "when they are not well-founded", but that under the U.S. Cloud Act, U.S. companies can be forced to  hand over data, regardless of where it is stored.</p><p>Carniaux did say that the situation had never arisen. However, the admission raises serious concerns around European data sovereignty.</p><p>“Microsoft has openly admitted what many have long known: under laws like the Cloud Act, US authorities can compel access to data held by American cloud providers, regardless of where that data physically resides. UK or EU servers make no difference when jurisdiction lies elsewhere, and local subsidiaries or ‘trusted’ partnerships don’t change that reality," commented Mark Boost, CEO of cloud provider Civo.</p><p>“This is more than a technicality. It is a real-world issue that can impact national security, personal privacy and business competitiveness."</p><p>The inquiry centers around Project Bleu - a partnership between Microsoft, Orange and Capgemini. There were concerns about the Health Data Hub medical research platform, which is hosted on Microsoft Azure. Senate members said they couldn't be sure that the two platforms were sufficiently separated, and that sensitive health data wouldn't be shared.</p><p>Carniaux's admission will increase concerns that the EU can't afford to be reliant on the big U.S. cloud providers such as Microsoft and AWS - even when they claim to be offering sovereign cloud services.</p><p>“The French Senate has set a precedent by demanding answers, and the UK and Europe have an opportunity to do the same," said Boost. "We’re already seeing a shift towards building homegrown solutions that support true data sovereignty rather than data residency."</p><p>However, a recent European Parliament report found that U.S. firms account for 69% of the cloud infrastructure market share in Europe, while EU suppliers hold only 13%.</p></div></div>]]></description>
        </item>
    </channel>
</rss>