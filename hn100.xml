<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 19 Oct 2024 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Love being interrupted when my monitor asks me to accept user agreements (114 pts)]]></title>
            <link>https://twitter.com/snwy_me/status/1847396175961641176</link>
            <guid>41889140</guid>
            <pubDate>Sat, 19 Oct 2024 17:27:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/snwy_me/status/1847396175961641176">https://twitter.com/snwy_me/status/1847396175961641176</a>, See on <a href="https://news.ycombinator.com/item?id=41889140">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Have McKinsey and its consulting rivals got too big? (120 pts)]]></title>
            <link>https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</link>
            <guid>41888061</guid>
            <pubDate>Sat, 19 Oct 2024 14:46:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big">https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</a>, See on <a href="https://news.ycombinator.com/item?id=41888061">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><span><a href="https://www.economist.com/business" data-analytics="sidebar:section"><span>Business</span></a></span><span> | <!-- -->The lost art of self-management</span></p><h2>The golden age for CEO whisperers may be coming to an end</h2></section><div><div><p><time datetime="2024-03-25T22:03:59.042Z"> <!-- -->Mar 25th 2024</time></p></div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">A</span><small>N ANONYMOUS MEMO</small> briefly circled the web in March. The authors, who claimed to be former partners at McKinsey, rebuked the illustrious strategy consultancy for its pursuit in recent years of “unchecked and unmanaged growth”, and chastised its leadership for, of all things, a “lack of strategic focus”. With humility typical of McKinseyites, they warned that “an organisation of genuine greatness” was at risk of being lost.</p></section><p>This article appeared in the Business section of the print edition under the headline “The lost art of self-management”</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/business">Business</a> <span>March 30th 2024</span></h2><ul><li><a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big"><span>Have McKinsey and its consulting rivals got too big?</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/making-accounting-sexy-again"><span>Making accounting sexy again</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/a-marketing-victory-for-nike-is-a-business-win-for-adidas"><span>A marketing victory for Nike is a business win for Adidas</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/the-pros-and-cons-of-corporate-uniforms"><span>The pros and cons of corporate uniforms</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/regulators-are-forcing-big-tech-to-rethink-its-ai-strategy"><span>Regulators are forcing big tech to rethink its AI strategy</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/dave-calhoun-bows-out-as-chief-executive-of-boeing"><span>Dave Calhoun bows out as chief executive of Boeing</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/meet-the-digital-david-taking-on-the-google-goliath"><span>Meet the digital David taking on the Google Goliath</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the March 30th 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-03-30" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div><div><p><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Have%20McKinsey%20and%20its%20consulting%20rivals%20got%20too%20big%3F&amp;publicationDate=2024-03-25&amp;contentID=%2Fcontent%2Fh2uo27nddgkvs01g3l6va42ufik5tavk&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><span>Reuse this content</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The long road to lazy preemption in the Linux CPU scheduler (185 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</link>
            <guid>41886256</guid>
            <pubDate>Sat, 19 Oct 2024 07:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/">https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</a>, See on <a href="https://news.ycombinator.com/item?id=41886256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
The kernel's CPU scheduler currently offers several preemption modes that
implement a range of tradeoffs between system throughput and response time.
Back in September 2023, a <a href="https://lwn.net/Articles/944686/">discussion
on scheduling</a> led to the concept of "lazy preemption", which could
simplify scheduling in the kernel while providing better results.  Things
went quiet for a while, but lazy preemption has returned in the form of <a href="https://lwn.net/ml/all/20241007074609.447006177@infradead.org">this patch series</a>
from Peter Zijlstra.  While the concept appears to work well, there is
still a fair amount of work to be done.
</p><h4>Some review</h4>
<p>
Current kernels have four different modes that regulate when one task can
be preempted in favor of another.  <tt>PREEMPT_NONE</tt>, the simplest
mode, only allows preemption to happen when the running task has exhausted
its time slice.  <tt>PREEMPT_VOLUNTARY</tt> adds a large number of points
within the kernel where preemption can happen if needed.
<tt>PREEMPT_FULL</tt> allows preemption at almost any point except places
in the kernel that prevent it, such as when a spinlock is held.  Finally,
<tt>PREEMPT_RT</tt> prioritizes preemption over most other things, even
making most spinlock-holding code preemptible.
</p><p>
A higher level of preemption enables the system to respond more quickly to
events; whether an event is the movement of a mouse or an "imminent
meltdown" signal from a nuclear reactor, faster response tends to be more
gratifying.  But a higher level of preemption can hurt the overall
throughput of the system; workloads with a lot of long-running,
CPU-intensive tasks tend to benefit from being disturbed as little as
possible.  More frequent preemption can also lead to higher lock
contention.  That is why the different modes exist; the optimal preemption
mode will vary for different workloads.
</p><p>
Most distributions ship kernels built with the <tt>PREEMPT_DYNAMIC</tt>
pseudo-mode, which allows any of the first three modes to be selected at
boot time, with <tt>PREEMPT_VOLUNTARY</tt> being the default.  On systems
with debugfs mounted, the current mode can be read from
<tt>/sys/kernel/debug/sched/preempt</tt>.
</p><p>
<tt>PREEMPT_NONE</tt> and <tt>PREEMPT_VOLUNTARY</tt> do not allow the
arbitrary preemption of code running in the kernel; there are times when
that can lead to excessive latency even in systems where minimal latency is
not prioritized.  This problem is the result of places in the kernel where
a large amount of work can be done; if that work is allowed to run
unchecked, it can disrupt the scheduling of the system as a whole.  To get
around this problem, long-running loops have been sprinkled with calls to
<tt>cond_resched()</tt>, each of which is an additional voluntary
preemption point that is active even in the <tt>PREEMPT_NONE</tt> mode.
There are hundreds of these calls in the kernel.
</p><p>
There are some problems with this approach.  <tt>cond_resched()</tt> is a
form of heuristic that only works in the places where a developer has
thought to put it.  Some calls are surely unnecessary, while there will be
other places in the kernel that could benefit from <tt>cond_resched()</tt>
calls, but do not have them.  The use of <tt>cond_resched()</tt>, at its
core, takes a decision that should be confined to the scheduling code and
spreads it throughout the kernel.  It is, in short, a bit of a hack that
mostly works, but which could be done better.
</p><h4>Doing better</h4>
<p>
The tracking of whether a given task can be preempted at any moment is a
complicated affair that must take into account several variables; see <a href="https://lwn.net/Articles/945422/">this article</a> and <a href="https://lwn.net/Articles/831678/">this article</a> for details.  One of those
variables is a simple flag, <tt>TIF_NEED_RESCHED</tt>, that indicates the
presence of a higher-priority task that is waiting for access to the CPU.
Events such as waking a high-priority task can cause that flag to be set in
whatever task is currently running.  In the absence of this flag, there is
no need for the kernel to consider preempting the current task.
</p><p>
There are various points where the kernel can notice that flag and cause
the currently running task to be preempted.  The scheduler's timer tick is
one example; any time a task returns to user space from a system call is
another.  The completion of an interrupt handler is yet another, but that
check, which can cause preemption to happen any time that interrupts are
enabled, is only enabled in <tt>PREEMPT_FULL</tt> kernels.  A call to
<tt>cond_resched()</tt> will also check that flag and, if it is set, call
into the scheduler to yield the CPU to the other task.
</p><p>
The lazy-preemption patches are simple at their core; they add another
flag, <tt>TIF_NEED_RESCHED_LAZY</tt>, that indicates a need for
rescheduling at some point, but not necessarily right away.  In the lazy
preemption mode (<tt>PREEMPT_LAZY</tt>), most events will set the new flag
rather than <tt>TIF_NEED_RESCHED</tt>.  At points like the return to user
space from the kernel, either flag will lead to a call into the scheduler.
At the voluntary preemption points and in the return-from interrupt path,
though, only <tt>TIF_NEED_RESCHED</tt> is checked.
</p><p>
The result of this change is that, in lazy-preemption mode, most events in
the kernel will not cause the current task to be preempted.  That task
<i>should</i> be preempted eventually, though.  To make that happen, the
kernel's timer-tick handler will check whether
<tt>TIF_NEED_RESCHED_LAZY</tt> is set; if so, <tt>TIF_NEED_RESCHED</tt>
will also be set, possibly causing the running task to be preempted.  Tasks
will generally end up running for something close to their full time slice
unless they give up the CPU voluntarily, which should lead to good
throughput. 
</p><p>
With these changes, the lazy-preemption mode can, like
<tt>PREEMPT_FULL</tt>, run with kernel preemption enabled at (almost) all
times.  Preemption <i>can</i> happen any time that the preemption counter
says that it should.  That allows long-running kernel code to be preempted
whenever other conditions do not prevent it.  It also allows preemption to
happen quickly in those cases where it is truly needed.  For example, 
should a realtime task become runnable, as the result of
handling an interrupt, for example, the <tt>TIF_NEED_RESCHED</tt> flag will
be set, leading to an almost immediate preemption.  There will be no need
to wait for the timer tick in such cases.
</p><p>
Preemption will <i>not</i> happen, though, if only
<tt>TIF_NEED_RESCHED_LAZY</tt> is set, which will be the case much of the
time. So a <tt>PREEMPT_LAZY</tt> kernel will be far less likely to preempt
a running task than a <tt>PREEMPT_FULL</tt> kernel.
</p><h4>Removing <tt>cond_resched()</tt> — eventually</h4>
<p>
The end goal of this work is to have a scheduler with only two non-realtime
modes: <tt>PREEMPT_LAZY</tt> and <tt>PREEMPT_FULL</tt>.  The lazy mode will
occupy a place between <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt>, replacing both of them.  It will, however, not
need the voluntary preemption points that were added for the two modes it
replaces.  Since preemption can now happen almost anywhere, there is no
longer a need to enable it in specific spots.
</p><p>
For now, though, the <tt>cond_resched()</tt> calls remain; if nothing else,
they are required for as long as the <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt> modes exist.  Those calls also help to ensure
that problems are not introduced while lazy preemption is being stabilized.
</p><p>
In the current patch set, <tt>cond_resched()</tt> only checks
<tt>TIF_NEED_RESCHED</tt>, meaning that preemption will be deferred in many
situations where it will happen immediately from <tt>cond_resched()</tt> in
<tt>PREEMPT_VOLUNTARY</tt> or <tt>PREEMPT_NONE</tt> mode.
Steve Rostedt <a href="https://lwn.net/ml/all/20241009100133.2569e2a7@gandalf.local.home">questioned</a>
this change, asking whether <tt>cond_resched()</tt> should retain its older
meaning, at least for the <tt>PREEMPT_VOLUNTARY</tt> case.  Even though
<tt>PREEMPT_VOLUNTARY</tt> is slated for eventual removal, he thought,
keeping the older behavior could help to ease the transition.
</p><p>
Thomas Gleixner
<a href="https://lwn.net/ml/all/87h69lqbk0.ffs@tglx">answered</a> that only checking
<tt>TIF_NEED_RESCHED</tt> is the correct choice, since it will help in the
process of removing the <tt>cond_resched()</tt> calls entirely:
</p><blockquote>
	That forces us to look at all of them and figure out whether they
	need to be extended to include the lazy bit or not. Those which do
	not need it can be eliminated when LAZY is in effect because that
	will preempt on the next possible preemption point once the
	non-lazy bit is set in the tick.
</blockquote>
<p>
He added that he expects "<q>less than 5%</q>" of the
<tt>cond_resched()</tt> calls need to check <tt>TIF_NEED_RESCHED_LAZY</tt>
and, thus, will need to remain even after the transition to
<tt>PREEMPT_LAZY</tt> is complete.
</p><p>
Before then, though, there are hundreds of <tt>cond_resched()</tt> calls
that need to be checked and, for most of them at least, removed.  Many
other details have to be dealt with as well; <a href="https://lwn.net/ml/all/20241009165411.3426937-1-ankur.a.arora@oracle.com">this patch
set</a> from Ankur Arora addresses a few of them.  There is
also, of course, the need for extensive performance testing; Mike Galbraith
has made <a href="https://lwn.net/ml/all/579b7ea34ef6e2f7c955abdfc0929fe1af36faef.camel@gmx.de">an
early start</a> on that work, showing that throughput with lazy preemption
falls just short of that with <tt>PREEMPT_VOLUNTARY</tt>.
</p><p>
It all adds up to a lot to be done still, but the end result
of the lazy-preemption work should be a kernel that is a bit smaller and
simpler while delivering predictable latencies without the need to
sprinkle scheduler-related calls throughout the code.  That seems like a
better solution, but getting there is going to take some time.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Preemption">Preemption</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US probes Tesla's Full Self-Driving software in 2.4M cars after fatal crash (139 pts)]]></title>
            <link>https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/</link>
            <guid>41884740</guid>
            <pubDate>Sat, 19 Oct 2024 00:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/">https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/</a>, See on <a href="https://news.ycombinator.com/item?id=41884740">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Express v5 (138 pts)]]></title>
            <link>https://expressjs.com/2024/10/15/v5-release.html</link>
            <guid>41882955</guid>
            <pubDate>Fri, 18 Oct 2024 20:02:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://expressjs.com/2024/10/15/v5-release.html">https://expressjs.com/2024/10/15/v5-release.html</a>, See on <a href="https://news.ycombinator.com/item?id=41882955">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="blog-doc" markdown="1">


<p>Ten years ago (July 2014) the <a href="https://github.com/expressjs/express/pull/2237">Express v5 release pull request</a> was opened, and now at long last it’s been merged and published!</p>
<p>We want to recognize the work of all our contributors, especially <a href="https://github.com/dougwilson">Doug Wilson</a>, who spent the last ten years ensuring Express was the most stable project around. Without his contributions and those of many others, this release could not have happened.</p>
<p>Eight months ago we went public with a plan to move <a href="https://github.com/expressjs/discussions/issues/160">Express forward</a>. This plan included re-committing to the governance outlined years ago and adding more contributors to help kickstart progress. Many people may not realize that robust project governance is critical to the health of a large open-source project. We want to thank the <a href="https://github.com/openjs-foundation/cross-project-council/">OpenJS Foundation Cross Project
Council</a> and its members for helping us put together this plan.</p>
<h2 id="so-what-about-v5">So what about v5?</h2>
<p>This release is designed to be boring!
That may sound odd, but we’ve intentionally kept it simple to unblock the ecosystem and enable more impactful changes in future releases. This is also about signaling to the Node.js ecosystem that Express is moving again.
The focus of this release is on dropping old Node.js version support, addressing security concerns, and simplifying maintenance.</p>
<p>Before going into the changes in this release, let’s address why it was released v5 on the <code>next</code> dist-tag. As part of reviving the project, we started a <a href="https://github.com/expressjs/security-wg">Security working group</a> and <a href="https://github.com/expressjs/security-wg?tab=readme-ov-file#security-triage-team">security triage team</a> to address the growing needs around open source supply chain security. We undertook a security audit (more details to come on that) and uncovered some problems that needed to be addressed. Thus, in addition to the “normal” work done in public issues, we also did a lot of security work in private forks.
This security work required orchestration when releasing, to ensure the code and CVE reports went out together. You can find a summary of the most recent vulnerabilities patched in <a href="https://expressjs.com/2024/09/29/security-releases.html">our security release notes</a>.</p>
<p>While we weren’t able to simultaneously release v5, this blog post, the changelog, and documentation, we felt it was most important to have a secure and stable release.</p>
<p>As soon as possible, we’ll provide more details on our long-term support (LTS) plans, including when the release will move from <code>next</code> to <code>latest</code>. For now, if you are uncomfortable being on the bleeding edge (even if it is a rather dull edge) then you should wait to upgrade until the release is tagged <code>latest</code>. That said, we look forward to working with you to address any bugs you encounter as you upgrade.</p>
<h2 id="breaking-changes">Breaking changes</h2>
<p>The v5 release has the minimum possible number of breaking changes, listed here in order of impact to applications.</p>
<ul>
<li><a href="#goodbye-nodejs-010-hello-node-18">Ending support for old Node.js versions</a></li>
<li><a href="#changes-to-path-matching-and-regular-expressions">Changes to path matching and regular expressions</a></li>
<li><a href="#promise-support">Promise support</a></li>
<li><a href="#body-parser-changes">Body parser changes</a></li>
<li><a href="#removing-deprecated-method-signatures">Removing deprecated method signatures</a></li>
</ul>
<p>There are also a number of subtle changes: for details, see <a href="http://expressjs.com/en/guide/migrating-5">Migrating to Express 5</a>.</p>
<h3 id="ending-support-for-old-nodejs-versions">Ending support for old Node.js versions</h3>
<p>Goodbye Node.js 0.10, hello Node 18 and up!</p>
<p>This release drops support for Node.js versions before v18. This is an important change because supporting old Node.js versions has been holding back many critical performance and maintainability changes. This change also enables more stable and maintainable continuous integration (CI), adopting new language and runtime features, and dropping dependencies that are no longer required.</p>
<p>We recognize that this might cause difficulty for some enterprises with older or “parked” applications, and because of this we are working on a <a href="https://expressjs.com/2024/10/01/HeroDevs-partnership-announcement.html">partnership with HeroDevs</a> to offer “never-ending support” that will include critical security patches even after v4 enters end-of-life (more on these plans soon). That said, we strongly suggest that you update to modern Node.js versions as soon as possible.</p>
<h3 id="changes-to-path-matching-and-regular-expressions">Changes to path matching and regular expressions</h3>
<p>The v5 releases updates to <code>path-to-regexp@8.x</code> from <code>path-to-regexp@0.x</code>, which incorporates many years of changes. If you were using any of the 5.0.0-beta releases, a last-minute update which greatly changed the path semantics to <a href="https://blakeembrey.com/posts/2024-09-web-redos/">remove the possibility of any ReDoS attacks</a>. For more detailed changes, <a href="https://github.com/pillarjs/path-to-regexp?tab=readme-ov-file#express--4x">see the <code>path-to-regexp</code> readme</a>.</p>
<h4 id="no-more-regex">No more regex</h4>
<p>This release no longer supports “sub-expression” regular expressions, for example <code>/:foo(\\d+)</code>.
This is a commonly-used pattern, but we removed it for security reasons. Unfortunately, it’s easy to write a regular expression that has exponential time behavior when parsing input: The dreaded regular expression denial of service (ReDoS) attack. It’s very difficult to prevent this, but as a library that converts strings to regular expressions, we are on the hook for such security aspects.</p>
<p><em>How to migrate:</em> The best approach to prevent ReDoS attacks is to use a robust input validation library. <a href="https://www.npmjs.com/search?q=validate%20express">There are many on <code>npm</code></a> depending on your needs. TC member Wes Todd maintains <a href="https://www.npmjs.com/package/@wesleytodd/openapi">a middleware-based “code first” OpenAPI library</a> for this kind of thing.</p>
<h4 id="splats-optional-and-captures-oh-my">Splats, optional, and captures oh my</h4>
<p>This release includes simplified patterns for common route patterns. With the removal of regular expression semantics comes other small but impactful changes to how you write your routes.</p>
<ol>
<li><code>:name?</code> becomes <code>{:name}</code>. Usage of <code>{}</code> for optional parts of your route means you can now do things like <code>/base{/:optional}/:required</code> and what parts are actually optional is much more explicit.</li>
<li><code>*</code> becomes <code>*name</code>.</li>
<li>New reserved characters: <code>(</code>, <code>)</code>, <code>[</code>, <code>]</code>, <code>?</code>, <code>+</code>, &amp; <code>!</code>. These have been reserved to leave room for future improvements and to prevent mistakes when migrating where those characters mean specific things in previous versions.</li>
</ol>
<h4 id="name-everything">Name everything</h4>
<p>This release no longer supports ordered numerical parameters.</p>
<p>In Express v4, you could get numerical parameters using regex capture groups (for example, <code>/user(s?)</code> =&gt; <code>req.params[0] === 's'</code>). Now all parameters must be named. Along with requiring a name, Express now supports all valid JavaScript identifiers or quoted (for example, <code>/:"this"</code>).</p>
<h3 id="promise-support">Promise support</h3>
<p>This one may be a bit contentious, but we “promise” we’re moving in the right direction. We added support for returned <em>rejected</em> promises from errors raised in middleware. This <em>does not include</em> calling <code>next</code> from returned <em>resolved</em> promises. There are a lot of edge cases in old Express apps that have expectations of <code>Promise</code> behavior, and before we can run we need to walk. For most folks, this means you can now write middleware like the following:</p>
<pre><code>app.use(async (req, res, next) =&gt; {
  req.locals.user = await getUser(req);
  next();
});
</code></pre>
<p>Notice that this example uses <code>async/await</code> and the <code>getUser</code> call may throw an error (if, for example, the user doesn’t exist, the user database is down, and so on), but we still call <code>next</code> if it is successful. We don’t need to catch the error in line anymore if we want to rely on error-handling middleware instead because the router will now catch the rejected promise and treat that as calling <code>next(err)</code>.</p>
<p>NOTE: Best practice is to handle errors as close to the site as possible. So while this is now handled in the router, it’s best to catch the error in the middleware and handle it without relying on separate error-handling middleware.</p>
<h3 id="body-parser-changes">Body parser changes</h3>
<p>There are a number of <code>body-parser</code> changes:</p>
<ul>
<li>Add option to customize the urlencoded body depth with a default value of 32 as mitigation for <a href="https://nvd.nist.gov/vuln/detail/CVE-2024-45590">CVE-2024-45590</a> (<a href="https://github.com/expressjs/body-parser/commit/b2695c4450f06ba3b0ccf48d872a229bb41c9bce">technical details</a>)</li>
<li>Remove deprecated <code>bodyParser()</code> combination middleware</li>
<li><code>req.body</code> is no longer always initialized to <code>{}</code></li>
<li><code>urlencoded</code> parser now defaults <code>extended</code> to false</li>
<li>Added support for Brotli lossless data compression</li>
</ul>
<h3 id="removing-deprecated-method-signatures">Removing deprecated method signatures</h3>
<p>Express v5 removes a number of deprecated method signatures, many of which were carried over from v3. Below are the changes you need to make:</p>
<ul>
<li><code>res.redirect('back')</code> and <code>res.location('back')</code>: The magic string <code>'back'</code> is no longer supported. Use <code>req.get('Referrer') || '/'</code> explicitly instead.</li>
<li><code>res.send(status, body)</code> and <code>res.send(body, status)</code> signatures: Use <code>res.status(status).send(body)</code>.</li>
<li><code>res.send(status)</code> signature: Use <code>res.sendStatus(status)</code> for simple status responses, or <code>res.status(status).send()</code> for sending a status code with an optional body.</li>
<li><code>res.redirect(url, status)</code> signature: Use <code>res.redirect(status, url)</code>.</li>
<li><code>res.json(status, obj)</code> and <code>res.json(obj, status)</code> signatures: Use <code>res.status(status).json(obj)</code>.</li>
<li><code>res.jsonp(status, obj)</code> and <code>res.jsonp(obj, status)</code> signatures: Use <code>res.status(status).jsonp(obj)</code>.</li>
<li><code>app.param(fn)</code>: This method has been deprecated. Instead, access parameters directly via <code>req.params</code>, or use <code>req.body</code> or <code>req.query</code> as needed.</li>
<li><code>app.del('/', () =&gt; {})</code> method: Use <code>app.delete('/', () =&gt; {})</code> instead.</li>
<li><code>req.acceptsCharset</code>: Use <code>req.acceptsCharsets</code> (plural).</li>
<li><code>req.acceptsEncoding</code>: Use <code>req.acceptsEncodings</code> (plural).</li>
<li><code>req.acceptsLanguage</code>: Use <code>req.acceptsLanguages</code> (plural).</li>
<li><code>res.sendfile</code> method: Use <code>res.sendFile</code> instead.</li>
</ul>
<p>As a framework, we aim to ensure that the API is as consistent as possible. We’ve removed these deprecated signatures to make the API more predictable and easier to use. By streamlining each method to use a single, consistent signature, we simplify the developer experience and reduce confusion.</p>
<h2 id="migration-and-security-guidance">Migration and security guidance</h2>
<p>For developers looking to migrate from v4 to v5, there’s a <a href="http://expressjs.com/en/guide/migrating-5">detailed migration guide</a> to help you navigate through the changes and ensure a smooth upgrade process.</p>
<p>Additionally, we’ve been working hard on a comprehensive <a href="https://github.com/expressjs/security-wg/blob/main/docs/ThreatModel.md">Threat Model</a> that helps illustrate our philosophy of a “Fast, unopinionated, minimalist web framework for Node.js.” It provides critical insights into areas like user input validation and security practices that are essential for safe and secure usage of Express in your applications.</p>
<h2 id="our-work-is-just-starting">Our work is just starting</h2>
<p>We see the v5 release as a milestone toward an Express ecosystem that’s a stable and reliable tool for companies, governments, educators, and hobby projects. It is our commitment as the new stewards of the Express project to move the ecosystem forward with this goal in mind. If you want to support this work, which we do on a volunteer basis, please consider supporting the project and its maintainers via <a href="https://opencollective.com/express">our sponsorship opportunities</a>.</p>
<p>We have an <a href="https://github.com/expressjs/discussions/issues/266">extensive working backlog</a> of tasks, PRs, and issues for Express and dependencies. Naturally, we expect developers will continue to report issues to add to this backlog and open PRs moving forward, and we’ll continue to collaborate with the community to triage and resolve them. We look forward to continuing to improve Express and making it useful for its users across the world.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>