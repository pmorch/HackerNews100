<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 03 Apr 2024 21:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[JPMorgan to sell customer transaction data to advertisers (119 pts)]]></title>
            <link>https://media.chase.com/news/chase-launches-chase-media-solutions</link>
            <guid>39921000</guid>
            <pubDate>Wed, 03 Apr 2024 18:18:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.chase.com/news/chase-launches-chase-media-solutions">https://media.chase.com/news/chase-launches-chase-media-solutions</a>, See on <a href="https://news.ycombinator.com/item?id=39921000">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            
            
            <i>New media platform delivers customers cash back while helping brands drive sales and business growth</i>
            
        </p><div>
    <p><b>NEW YORK, April 3, 2024</b> – Today, Chase launched <a href="https://www.chase.com/mediasolutions/home?jp_cmp=cc/launchpressrelease/ext/na/na" target="_self" data-pt-name="lnk_website" title="Chase Media Website">Chase Media Solutions</a>, its new digital media business, providing brands with the ability to connect directly with the financial institution’s 80 million customers. Chase Media Solutions serves as a key conduit for brands, connecting them with consumers’ personal passions and interests. In turn, Chase customers benefit from personalized offers and the ability to earn cash back with brands they love or are discovering for the first time.</p> 
<p>As the only bank-led media platform of its kind, Chase Media Solutions combines the scale and audience of a retail media network with the exclusive advantages of Chase’s first-party financial data, institutional credibility and precise targeting capabilities. Today, the bank’s large consumer base and 6 million small business customers benefit from Chase’s wide range of travel, dining and shopping offerings — generating unparalleled insights across consumer categories.</p> 
<p>The launch of Chase Media Solutions follows the integration of Figg, a leading card-linked marketing platform. JPMorgan Chase &amp; Co. acquired Figg in 2022 as a natural step in Chase’s effort to build out its owned, two-sided commerce platform, and as part of the firm's vision to bring win-win value to both business clients and banking customers.</p> 
<p>“Our deep understanding of consumer spending across categories has driven us to reimagine what retail media networks can offer,” said Rich Muhlstock, President of Chase Media Solutions. “Like retailers, we have first-party data and a dedicated audience. But what sets us apart is the unrivaled scale and insights from our customers – having long-served as a trusted guide for their financial decisions. Chase reaches across brands, merchants and shopping verticals, providing a comprehensive view of purchase behavior; this strengthens the degree of personalization, helping brands deliver offers that stoke consumer interests.”</p> 
<p><b>Chase Media Solutions platform advantages</b></p> 
<ul> 
 <li><b>First-party data: </b>With Chase’s owned transaction data, brands and agencies can precisely target customers at scale based on purchase history (such as targeting new, lapsed or loyal customers)</li> 
 <li><b>Better ROI and attribution: </b>Brands capture incremental spend on everyday purchases both in-store and online with clear attribution for every media dollar spent</li> 
 <li><b>Trust and brand safety:</b> The platform is built on the foundational trust and institutional credibility of Chase, including a verified audience and brand-safe owned channels</li> 
</ul> 
<p>Among initial pilot partners, Chase Media Solutions designed 30-day campaigns for Air Canada, Solo Stove, Blue Bottle and Whataburger, seeing significant traction for those brands in driving incremental sales and new customers growth.&nbsp;&nbsp;</p> 
<p>Regarding the success of their initial campaign, Scott O’Leary, Vice President of Loyalty and Product for Air Canada said, “The Chase team succeeded in creating a thoughtful, targeted offer that exceeded our expectations. Two distinct offer constructs drove incremental revenue and awareness for Air Canada amongst Chase’s cardmember base. These tests clearly demonstrated the potential of the Chase Media Solutions channel, and we look forward to working together more in the future.”</p> 
<p><b>About Chase</b></p> 
<p>Chase is the U.S. consumer and commercial banking business of JPMorgan Chase &amp; Co. (NYSE: JPM), a leading financial services firm based in&nbsp;the United States&nbsp;with assets of&nbsp;$3.9 trillion&nbsp;and operations worldwide. Chase serves nearly 80 million consumers and nearly 6 million small businesses, with a broad range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. Customers can choose how and where they want to bank: More than 4,700 branches in 48 states and the&nbsp;District of Columbia, more than 15,000 ATMs, mobile, online and by phone. For more information, go to chase.com.</p> 
<p><b>Media Contacts</b></p> 
<p>April Lee<br> <a href="mailto:april.k.lee@chase.com" target="_self" data-pt-name="lnk_lee" title="email April Lee">april.k.lee@chase.com</a><br> 201-788-9089</p> 
<p>Michael Sinatra<br> <a href="mailto:michael.sinatra@chase.com" target="_blank" data-pt-name="lnk_sinatra" title="Email Michael Sinatra">michael.sinatra@chase.com</a><br> 551-574-8031</p> 
 

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jpegli: A New JPEG Coding Library (146 pts)]]></title>
            <link>https://opensource.googleblog.com/2024/04/introducing-jpegli-new-jpeg-coding-library.html</link>
            <guid>39920644</guid>
            <pubDate>Wed, 03 Apr 2024 17:51:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.googleblog.com/2024/04/introducing-jpegli-new-jpeg-coding-library.html">https://opensource.googleblog.com/2024/04/introducing-jpegli-new-jpeg-coding-library.html</a>, See on <a href="https://news.ycombinator.com/item?id=39920644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5389050084529505915" itemprop="articleBody">
<meta content="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDa_aWprUuwxdb9QLGHWUyUy_kkJfNhH4uj-04R3BCpOBk4TcmDCRQLYyWFXu3VqVV9m41R63WlpeGTPzuu1rI6D6LmdTcSLY5mgpwXud-8S2G9b8_CFJvBCux3YZ0QJa7MwCZXIEyb1naPhbN8Mpx2xwMyKZuBK9pQYCizBO_Xf6FzYekhd34EvjWsjk/s1600/OS-New-Library-for-Network-Optimization-social%20%281%29%20%281%29.png" name="twitter:image">
<p>

<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhZqXT6XrEcBt5ZTrHKnKyi84ImsBnCFUWvVLRB5vE7t0hQlFcaBY2anBeyK34ABg6UyHkpYi-AZA3832Z4QBbSKbHQXV7cukNauqbdNwrceSO3tzDLIcrl6jiNwjdQbQT1NmPaPxmZsIK7tJO3Mzer4ZHFx72pchdvw_eHNeQUG25IY16uKhFXcuKhAk/s1600/OSS-Logo-Banner%20%281%29.png"><img data-original-height="800" data-original-width="1058" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhZqXT6XrEcBt5ZTrHKnKyi84ImsBnCFUWvVLRB5vE7t0hQlFcaBY2anBeyK34ABg6UyHkpYi-AZA3832Z4QBbSKbHQXV7cukNauqbdNwrceSO3tzDLIcrl6jiNwjdQbQT1NmPaPxmZsIK7tJO3Mzer4ZHFx72pchdvw_eHNeQUG25IY16uKhFXcuKhAk/s1600/OSS-Logo-Banner%20%281%29.png"></a></p><p>The internet has changed the way we live, work, and communicate. However, it can turn into a source of frustration when pages load slowly. At the heart of this issue lies the encoding of images. To improve on this, we are introducing <a href="https://github.com/libjxl/libjxl/tree/main/lib/jpegli" target="_blank">Jpegli</a>, an advanced JPEG coding library that maintains high backward compatibility while offering enhanced capabilities and a 35% compression ratio improvement at high quality compression settings.</p>
  
<p><b>Jpegli is a new JPEG coding library</b> that is designed to be faster, more efficient, and more visually pleasing than traditional JPEG. It uses a number of new techniques to achieve these goals, including:</p>

<ul>
<li>It provides both a fully interoperable <b>encoder and decoder</b> complying with the original JPEG standard and its most conventional 8-bit formalism, and API/ABI compatibility with libjpeg-turbo and MozJPEG.</li></ul><ul>

<li><b>High quality results</b>. When images are compressed or decompressed through Jpegli, more precise and psychovisually effective computations are performed and images will look clearer and have fewer observable artifacts.</li></ul><ul>
  
<li><b>Fast</b>. While improving on image quality/compression density ratio, Jpegli's coding speed is comparable to traditional approaches, such as libjpeg-turbo and MozJPEG. This means that web developers can effortlessly integrate Jpegli into their existing workflows without sacrificing coding speed performance or memory use.</li></ul><ul>
 
<li><b>10+ bits</b>. Jpegli can be encoded with 10+ bits per component. Traditional JPEG coding solutions offer only 8 bit per component dynamics causing visible banding artifacts in slow gradients. Jpegli's 10+ bits coding happens in the original 8-bit formalism and the resulting images are fully interoperable with 8-bit viewers. 10+ bit dynamics are available as an API extension and application code changes are needed to benefit from it.</li></ul><ul>
  
<li><b>More dense:</b> Jpegli compresses images more efficiently than traditional JPEG codecs, which can save bandwidth and storage space, and <b>speed up web pages</b>.</li>
  
</ul><br>

<h2><b>How Jpegli works</b></h2>
  
<p>Jpegli works by using a number of new techniques to reduce noise and improve image quality; mainly adaptive quantization heuristics from the <a href="https://github.com/libjxl/libjxl" target="_blank">JPEG XL</a> reference implementation, improved quantization matrix selection, calculating intermediate results precisely, and having the possibility to use a more advanced <a href="https://en.wikipedia.org/wiki/ICC_profile" target="_blank">colorspace</a>. All the new methods have been carefully crafted to use the traditional 8-bit JPEG formalism, so newly compressed images are compatible with existing JPEG viewers such as browsers, image processing software, and others.</p>

<h4><span><b>Adaptive quantization heuristics</b></span></h4> 
<p>Jpegli uses adaptive quantization to reduce noise and improve image quality. This is done by spatially modulating the dead zone in quantization based on <a href="https://github.com/google/butteraugli" target="_blank">psychovisual modeling</a>. Using adaptive quantization heuristics that we originally developed for JPEG XL, the result is improved image quality and reduced file size. These heuristics are much faster than a similar approach originally used in <a href="https://github.com/google/guetzli" target="_blank">guetzli</a>.<br>
  
  
</p><h4><span><b>Improved quantization matrix selection</b></span></h4>
<p>Jpegli also uses a set of quantization matrices that were selected by optimizing for a mix of psychovisual quality metrics. Precise intermediate results in Jpegli improve image quality, and both encoding and decoding produce higher quality results. Jpegli can use JPEG XL's XYB colorspace for further quality and density improvements.</p><br>

<h2><b>Testing Jpegli</b></h2>
  
<p>In order to quantify Jpegli's image quality improvement we enlisted the help of crowdsourcing raters to compare pairs of images from <a href="https://cloudinary.com/labs/cid22" target="_blank">Cloudinary Image Dataset '22</a>, encoded using three codecs: Jpegli, libjpeg-turbo and MozJPEG, at several bitrates.</p>
  
<p>In this comparison we limited ourselves to comparing the encoding only, decoding was always performed using libjpeg-turbo. We conducted the study with the XYB ICC color profile disabled since that is how we anticipate most users would initially use Jpegli. To simplify comparing the <a href="https://github.com/google-research/google-research/tree/master/mucped23" target="_blank">results</a> across the codecs and settings, we aggregated all the rater decisions using chess rankings inspired <a href="https://en.wikipedia.org/wiki/Elo_rating_system" target="_blank">ELO scoring</a>.</p>

<div><table><tbody><tr><td><center><img alt="A bar graph of ELO scores on the left and plot graph of ELO scores on the right" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgM2XmnDYP6bArTS8fmfeRWh4LDysiBMEITg0NYKH9whR1SACvuFl2JDUsoBXbm0oLSbXSzLH6e9urikKWM0rOIMuZshenEDEFB7nou4QZlXi85c-hml81ET1j6_6z2pqcAYWTj2elYi6j90YScxPZ4cib9dxob9Z-bf4rBtP-y-LbOrry9U5TcjnRJ7IU/s1600/Image1%20%284%29.png" td=""></center></td></tr><tr><td><i>A higher ELO score indicates a better aggregate performance in the rater study. We can observe that jpegli at 2.8 BPP received a higher ELO rating than libjpeg-turbo at 3.7 BPP, a bitrate 32 % higher than Jpegli's.</i></td></tr></tbody></table></div><br>


<h2><b>Results</b></h2>
  
<p>Our results show that <b>Jpegli can compress high quality images 35% more than traditional JPEG codecs.</b> </p>
  
<p><a href="https://github.com/libjxl/libjxl/tree/main/lib/jpegli" target="_blank">Jpegli</a> is a promising new technology that has the potential to make the internet faster and more beautiful.</p>

<p><em>By Zoltan Szabadka, Martin Bruse and Jyrki Alakuijala – Paradigms of Intelligence, Google Research</em></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tips for Linking Shell Companies to Their Secret Owners (465 pts)]]></title>
            <link>https://gijn.org/stories/tracking-shell-companies-secret-owners/</link>
            <guid>39919401</guid>
            <pubDate>Wed, 03 Apr 2024 16:22:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gijn.org/stories/tracking-shell-companies-secret-owners/">https://gijn.org/stories/tracking-shell-companies-secret-owners/</a>, See on <a href="https://news.ycombinator.com/item?id=39919401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For investigative journalists, the search for the actual owners of shell companies and trusts can sometimes seem as elusive and “fuzzy” as popular searches for UFOs. But there are powerful tools out there that can help newcomers to this complex field track breadcrumbs to people who go to great lengths to hide assets that the public should know about.</p>

<p>Shell corporations are companies that don’t actually do any business, but which are often incorporated for strategic reasons, such as legal tax avoidance for legitimate corporations — and <a href="https://www.occrp.org/en/the-pandora-papers/is-your-neighbor-a-shell-company">also to hide the identity and assets</a> of the individuals who truly control illegitimate or sanctioned enterprises.</p>
<p>Digging into shell companies and their ultimate benefit owners (UBOs) is a specialized investigative area, represented by networks such as the <a href="https://www.icij.org/">International Consortium of Investigative Journalists</a> (ICIJ) and the <a href="https://www.occrp.org/en/component/tags/tag/icij">Organized Crime and Corruption Reporting Project</a> (OCCRP). The advanced techniques they use, from tracking bank transfer routes to deferred corporate prosecution agreements, could fill several books.</p>
<p>However, in a solo presentation at the recent 2024 <a href="https://www.ire.org/training/conferences/nicar-2024/">NICAR data journalism summit</a> in the US, <a href="https://www.linkedin.com/in/karrie-kehoe-99304936/?originalSubdomain=ie">Karrie Kehoe</a>, deputy head of data and research at ICIJ, shared several tips, tools, and places to start that almost any reporter can try to track the person at the top of a shady empire — and their overseas assets. Kehoe invited attendees to first ask themselves: What words might appear in paperwork that must be filed for these front companies? And to then experiment with possible variations of those words that could be used in corporate registries and databases. For instance, might the name of a director or owner, like Ian, appear as “Iain”?</p>
<div id="attachment_1417393"><p><a href="https://www.icij.org/journalists/karrie-kehoe/"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-1417393" src="https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.19.17-336x389.png" alt="" width="250" height="289" srcset="https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.19.17-336x389.png 336w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.19.17.png 586w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-1417393">Karrie Kehoe, deputy head of data and research at ICIJ. Image: ICIJ</p></div>
<p>While often partly obscured by secrecy jurisdictions — such as the British Virgin Islands, Panama, Cyprus, or Cayman Islands — shell companies always need paperwork in order to be incorporated. Kehoe also invited reporters to think carefully about the people typically paid to fill out these forms, also known as “<a href="https://www.occrp.org/en/29leaks/what-is-a-company-formation-agent">formation agents</a>.” It’s their job to create companies for wealthy clients in friendly legal jurisdictions, which can offer country registration fees as low as US$14. For extra fees, formation agents can also provide clients with bank accounts, “straw man” director names, and secretarial services. But they can’t get around the basics on those forms: an official business address, real names of at least some directors, and documents about the nature of the business.</p>
<p>Searching for foreign assets of a Middle East king in 2021, Kehoe and her colleagues found that the monarch secretly owned 14 luxury homes in the UK and the US via a network of front companies in tax havens. They then got dramatic confirmation <a href="https://www.icij.org/investigations/pandora-papers/jordan-king-abdullah-luxury-property/">when the secret client’s home address was listed by formation agents</a> in registration documents as the kingdom’s “royal palace.”</p>
<p>Remember, she stressed, that you are always seeking the ultimate beneficial owner, rather than the director or owner names you may find early in your search.</p>
<p>“You could be sitting in the Netherlands, and you get your order off to a formation agent in, say, Hong Kong, and he starts setting up shells for you in the Cook Islands, Singapore, and other places,” said Kehoe, explaining one possible scenario. “From there, they will provide secretarial services, an address for you, and straw men — in other words, figureheads. One could be listed as the director of 100 companies, and that person could be a taxi driver in Azerbaijan. He has nothing to do with this — they may get a small bit of money; sometimes they are relatives or just people they know; sometimes they are strong-armed. But he is a body the formation agent needs.”</p>
<p>Shell companies represent one of several kinds of “proxy” methods that people use to disguise their wealth, <a href="https://www.occrp.org/en/asset-tracker/faq-whats-a-proxy-using-relatives-shell-companies-and-other-stand-ins-to-hide-illicit-wealth">as investigative journalist Will Neal recently explained at OCCRP</a>. For more on this, see GIJN’s detailed resource for <a href="https://gijn.org/resource/researching-corporations-and-their-owners/">Researching Corporations and their Owners</a>, which includes access portals for annual reports, and links to country-specific registries, from Germany to Hong Kong.</p>
<p>Here are some of the places-to-start tips Kehoe shared at NICAR24.</p>
<p><b>Start with a quick company or person name search in </b><a href="https://opencorporates.com/"><b>OpenCorporates</b></a><b>.</b> Drawing on company records from more than 140 government registries, OpenCorporates is a vast, open database that reporters love. “The first thing I do is go to this wonderful, searchable database – it has over 220 million companies listed there,” explained Kehoe. “It is wonderful for some jurisdictions; it struggles for others. For instance, you’d need to go somewhere else for Irish shell companies. If you want to look up a whole lot of companies, they do have API access too.”</p>
<div id="attachment_1417344"><p><a href="https://opencorporates.com/"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-1417344" src="https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.08.46-771x405.png" alt="" width="771" height="405" srcset="https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.08.46-771x405.png 771w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.08.46-336x176.png 336w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.08.46-768x403.png 768w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.08.46-1536x806.png 1536w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.08.46-2048x1075.png 2048w" sizes="(max-width: 771px) 100vw, 771px"></a></p><p id="caption-attachment-1417344">OpenCorporates is a vast, open database drawing on company records from more than 140 government registries. Image: Screenshot, OpenCorporates</p></div>
<p><b>Consider a subscription to a corporate risk database if you hit a wall with open source tools.</b> Kehoe showed one major shell company name that got no hits on the excellent OpenCorporates database, but which got a detailed profile from a simple name search in the paid-for <a href="https://sayari.com/financial-crime/"><b>Sayari</b></a> corporate risk platform– including helpful red flag icons to show sanctions listings, and national flags to show countries associated with listed directors. “This is a database I use all the time — it’s subscription-based, but they also have some free trials,” she said. “There are also other great paid-for corporate databases like <a href="https://login.bvdinfo.com/R0/Orbis"><b>Orbis</b></a> and <a href="https://www.dowjones.com/professional/factiva/?LS=Search&amp;utm_medium=cpc&amp;utm_source=google&amp;utm_campaign=AMER-US[EN]_GGL-Brand[GEN]-FA-Factiva_MT-Exact&amp;CID=7015Y000004FylCQAS&amp;utm_term=factiva_(e)&amp;utm_content=&amp;gad_source=1&amp;gclid=Cj0KCQjwwYSwBhDcARIsAOyL0fgmrbfqHGsRhTB984bRyKqKWwdwTOH8U7-c0br0U8gHvRNeG311DH4aAsXEEALw_wcB"><b>Factiva</b></a>.”</p>
<p><b>Put yourself in the shoes of billionaires and oligarchs.</b> Kehoe said it helps to refine database and registry searches for places and interests that appeal to the egos of oligarchs and UBOs. “The thing about super wealthy people is that they’re very predictable, and, if you’re a billionaire, there is only so much stuff you can buy,” Kehoe noted. “They often want luxury properties in London and the South of France; they want mega-yachts and jets and art and sports teams.” Simply identifying and searching for the wealthiest neighborhoods in certain jurisdictions, she said, can help narrow searches for hidden assets.</p>

<p><b>Use vetted investigative data in the </b><a href="https://offshoreleaks.icij.org/"><b>ICIJ Offshore Leaks Database</b></a><b>.&nbsp;</b>Many reporters don’t realize that the vast, searchable Offshore Leaks database — with vetted information on 810,000 offshore companies, foundations, and trusts in 200 countries — is freely available for any reporter, anywhere, to use, and to explore for new stories in their regions. “Please use it,” she said. “We know there are more stories in all that data, and we want reporters to find them.” Compiled by ICIJ, the database has been built from previous leaks and collaborative investigations into secret offshore assets and their hidden owners, such as the Panama Papers, the Pandora Papers, the Bahamas Leaks, and the Paradise Papers projects. “You can just put addresses into the search box, or the names of people or companies,” she explained. Reporters can also filter their search by the major leak investigations, which focus on different regions and jurisdictions — so a filter for Pandora Papers, for instance, will highlight more Asia data than Panama Papers.</p>
<p>Kehoe added one note of caution: “Just because someone’s name appears in this database does not mean they are guilty or associated with any wrongdoing at all. It just means they’re listed in an offshore jurisdiction.” (See ICIJ’s <a href="https://www.icij.org/investigations/pandora-papers/how-to-take-your-offshore-leaks-database-searches-to-the-next-level/">video tutorial series</a> for advanced search techniques for this database.)</p>
<p><b>Flag potential criminal links in OCCRP’s follow-the-money archive. </b>OCCRP’s <a href="https://aleph.occrp.org/"><b>Aleph database</b></a> has information on 439 million public entities in 141 countries. “It also has persons of interest datasets and gazettes,” said Kehoe. “Gazettes are huge in Europe — if a company is struck off [from company registers], it has to be listed in a gazette.” (Limited companies are typically struck off, or removed, from official registers for regulatory non-compliance, and are prohibited from further trading.) She added: “(Aleph) also has lots of court records, which is important for many countries, because most countries don’t have a court records tool like <a href="https://pacer.uscourts.gov/">Pacer</a> in the US.”</p>
<div id="attachment_1417369"><p><a href="https://aleph.occrp.org/"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-1417369" src="https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.12.58-771x396.png" alt="" width="771" height="396" srcset="https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.12.58-771x396.png 771w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.12.58-336x172.png 336w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.12.58-768x394.png 768w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.12.58-1536x788.png 1536w, https://gijn.org/wp-content/uploads/2024/03/Screenshot-2024-03-29-at-17.12.58.png 1902w" sizes="(max-width: 771px) 100vw, 771px"></a></p><p id="caption-attachment-1417369">OCCRP’s Aleph database has information on 439 million public entities in 141 countries.&nbsp;Image: Screenshot, OCCRP Aleph</p></div>
<p><b>Experiment with different spellings — and check against Google Maps.&nbsp;</b>Using the name of her own hometown in Ireland as an example, she said reporters searching for people or assets in Dún Laoghaire should also try spellings such as “Dún Laoire” and “Dunleary.” “If you try different spellings for places, you’d be surprised what you come up with,” she said. “Leaks data comes from many different languages, so if you want to find an address in Russia, there’s no point entering the word “street.” I recommend going to Google Maps, and, in this case, taking the Cyrillic phrase, and putting the English translation of that phrase into the search field of databases.” Even more important: use alternate spellings for the names of directors listed in corporate registries. This can be as simple as trying traditional alternatives, such as “Ann” and “Anne.” “But remember that when looking at Russian names, in particular, the spellings often change – “i”s become “y”s, “x”s become “ks”s etc,” Kehoe explained.</p>
<p><b><i>Tip:</i></b> Enter addresses you find on <a href="https://www.openstreetmap.org/#map=4/38.01/-95.84"><b>OpenStreetMap</b></a>, and check to see whether the director’s listed address is the mansion you’d expect, or a tiny office or apartment that could signal another false front.</p>
<p><b>Cross-search the “nuggets” you find in other free portals.</b> Kehoe suggested the following sites as other&nbsp; useful, free resources to search for hidden cross-border business connections: <a href="https://www.openownership.org/en/"><b>Open Ownership</b></a>, the UK-based <a href="https://www.gov.uk/government/collections/register-of-overseas-entities#:~:text=Overseas%20entities%20who%20want%20to,owners%20or%20managing%20officers%20are."><b>Register of Overseas Entities</b></a>, and <a href="https://ted.europa.eu/en/news/welcome-to-the-new-ted"><b>Tenders Electronic Daily</b></a> (TED). “TED is amazing — it involves public contracts for 27 EU member states, and it goes back a long time,” said Kehoe. “But it can be a little tricky as it has many different languages together.”</p>
<p><b><i>Tip:</i></b> Image search for society photos of the oligarch or UBO you’re investigating with the names listed in datasets and corporate registries as company directors.</p>
<p><b>Try a family connections tool to track oligarch assets. </b>“Russian oligarchs are the world masters of shell companies — they’ve been doing this since the 1990s, and reporters are always playing catch up,” said Kehoe. “The first thing to do is to <a href="https://www.opensanctions.org/">check if they are sanctioned</a>.”</p>
<p>She suggested a website called <a href="https://rupep.org/en/"><b>RuPEP</b></a>, which profiles thousands of “politically exposed persons” and sanctioned individuals in Russia, Belarus, and Kazakhstan, as well as their relatives, and their association with legal entities. She added: “These kinds of databases often give you nuggets of new information, but it’s a great place to start. This has profiles for a lot of oligarchs, and the research is amazing,” said Kehoe. “It gives you family members, which is important because a lot of the assets are in family members’ names.”</p>
<p><b>Paperwork tends to poke holes in secrecy — so keep digging.</b> “Be persistent,” Kehoe advised. “Ultimate beneficial owners really do trust their formation agents to keep them safe from scrutiny, and share a lot of stuff with them. And so, somewhere down the line, they send in a scan of their passport or their utility bill, and their home addresses often pop up in leaks and databases that way.”</p>
<hr>
<p><a href="https://gijn.org/wp-content/uploads/2023/02/336x336-staff-profile-photo-Rowan-Philp.png"><img loading="lazy" decoding="async" src="https://gijn.org/wp-content/uploads/2023/02/336x336-staff-profile-photo-Rowan-Philp-140x140.png" alt="" width="140" height="140" srcset="https://gijn.org/wp-content/uploads/2023/02/336x336-staff-profile-photo-Rowan-Philp-140x140.png 140w, https://gijn.org/wp-content/uploads/2023/02/336x336-staff-profile-photo-Rowan-Philp.png 336w" sizes="(max-width: 140px) 100vw, 140px"></a><a href="https://gijn.org/about/staff-member/rowan-philp/"><b><i>Rowan Philp</i></b></a> <i>is GIJN’s senior reporter. He was formerly chief reporter for South Africa’s </i><a href="https://www.timeslive.co.za/sunday-times/"><i>Sunday Times</i></a><i>. As a foreign correspondent, he has reported on news, politics, corruption, and conflict from more than two dozen countries around the world.</i></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Lavender': The AI machine directing Israel's bombing spree in Gaza (152 pts)]]></title>
            <link>https://web.archive.org/web/20240403151726/https://www.972mag.com/lavender-ai-israeli-army-gaza/</link>
            <guid>39919109</guid>
            <pubDate>Wed, 03 Apr 2024 15:57:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.archive.org/web/20240403151726/https://www.972mag.com/lavender-ai-israeli-army-gaza/">https://web.archive.org/web/20240403151726/https://www.972mag.com/lavender-ai-israeli-army-gaza/</a>, See on <a href="https://news.ycombinator.com/item?id=39919109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p>In partnership with</p>
<p><a href="https://web.archive.org/web/20240403151726/https://www.mekomit.co.il/"><img src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2022/11/LC-LOGO-ENG.png" alt=""></a>
</p>
</div> <p><span>In 2021, a </span><a href="https://web.archive.org/web/20240403151726/https://books.google.co.il/books/about/The_Human_Machine_Team_How_to_Create_Syn.html?id=hjl1zgEACAAJ&amp;redir_esc=y"><span>book</span></a><span> titled “The Human-Machine Team: How to Create Synergy Between Human and Artificial Intelligence That Will Revolutionize Our World” was released in English under the pen name “Brigadier General Y.S.” In it, the author — a man who we confirmed to be the current commander of the elite Israeli intelligence unit 8200 — makes the case for designing a special machine that could rapidly process massive amounts of data to generate thousands of potential “targets” for military strikes in the heat of a war. Such technology, he writes, would resolve what he described as a “human bottleneck for both locating the new targets and decision-making to approve the targets.”</span></p>
<p><span>Such a machine, it turns out, actually exists. A new investigation by +972 Magazine and Local Call reveals that the Israeli army has developed an artificial intelligence-based program known as “Lavender,” unveiled here for the first time. According to six Israeli intelligence officers, who have all served in the army during the current war on the Gaza Strip and had first-hand involvement with the use of AI to generate targets for assassination, Lavender has played a central role in the unprecedented bombing of Palestinians, especially during the early stages of the war. In fact, according to the sources, its influence on the military’s operations was such that they essentially treated the outputs of the AI machine “as if it were a human decision.”</span></p>
<p><span>Formally, the Lavender system is designed to mark all suspected operatives in the military wings of Hamas and Palestinian Islamic Jihad (PIJ), including low-ranking ones, as potential bombing targets. The sources told +972 and Local Call that, during the first weeks of the war, the army almost completely relied on Lavender, which clocked as many as 37,000 Palestinians as suspected militants — and their homes — for possible air strikes.</span></p>
<p><span>During the early stages of the war, the army gave sweeping approval for officers to adopt Lavender’s kill lists, with no requirement to thoroughly check why the machine made those choices or to examine the raw intelligence data on which they were based. One source stated that human personnel often served only as a “rubber stamp” for the machine’s decisions, adding that, normally, they would personally devote only about “20 seconds” to each target before authorizing a bombing — just to make sure the Lavender-marked target is male. This was despite knowing that the system makes what are regarded as “errors” in approximately 10 percent of cases, and is known to occasionally mark individuals who have merely a loose connection to militant groups, or no connection at all.</span></p>
<p><span>Moreover, the Israeli army systematically attacked the targeted individuals while they were in their homes — usually at night while their whole families were present — rather than during the course of military activity. According to the sources, this was because, from what they regarded as an intelligence standpoint, it was easier to locate the individuals in their private houses. Additional automated systems, including one called “Where’s Daddy?” also revealed here for the first time, were used specifically to track the targeted individuals and carry out bombings when they had entered their family’s residences.</span></p>
<div id="attachment_177456"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/F231117ARK97-1.jpg" data-featherlight="image"><img title="Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/F231117ARK97-1-1280x853.jpg" alt="Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>The result, as the sources testified, is that thousands of Palestinians — most of them women and children or people who were not involved in the fighting — were wiped out by Israeli airstrikes, especially during the first weeks of the war, because of the AI program’s decisions.</span></p>
<p><span>“We were not interested in killing [Hamas] operatives only when they were in a military building or engaged in a military activity,” A., an intelligence officer, told +972 and Local Call. “On the contrary, the IDF bombed them in homes without hesitation, as a first option. It’s much easier to bomb a family’s home. The system is built to look for them in these situations.”</span></p>
<p><span>The Lavender machine joins another AI system, “The Gospel,” about which information was revealed in a </span><a href="https://web.archive.org/web/20240403151726/https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/"><span>previous investigation</span></a><span> by +972 and Local Call in November 2023, as well as in the Israeli military’s own </span><a href="https://web.archive.org/web/20240403151726/https://www.israeldefense.co.il/node/57256#google_vignette"><span>publications</span></a><span>. A fundamental difference between the two systems is in the definition of the target: whereas The Gospel marks buildings and structures that the army claims militants operate from, Lavender marks people — and puts them on a kill list.&nbsp;</span></p>
<p><span>In addition, according to the sources, when it came to targeting alleged junior militants marked by Lavender, the army preferred to only use unguided missiles, commonly known as “dumb” bombs (in contrast to “smart” precision bombs), which can destroy entire buildings on top of their occupants and cause significant casualties. “You don’t want to waste expensive bombs on unimportant people — it’s very expensive for the country and there’s a shortage [of those bombs],” said C., one of the intelligence officers. Another source said that they had personally authorized the bombing of “hundreds” of private homes of alleged junior operatives marked by Lavender, with many of these attacks killing civilians and entire families as “collateral damage.”</span></p>
<p><span>In an unprecedented move, according to two of the sources, the army also decided during the first weeks of the war that, for every junior Hamas operative that Lavender marked, it was permissible to kill up to 15 or 20 civilians; in the past, the military did not authorize any “collateral damage” during assassinations of low-ranking militants. The sources added that, in the event that the target was a senior Hamas official with the rank of battalion or brigade commander, the army on several occasions authorized the killing of more than 100 civilians in the assassination of a single commander.</span></p>
<div id="attachment_177452"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/03/F231024ARK004.jpg" data-featherlight="image"><img title="Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/03/F231024ARK004-1280x853.jpg" alt="Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>The following investigation is organized according to the six chronological stages of the Israeli army’s highly automated target production in the early weeks of the Gaza war. First, we explain the Lavender machine itself, which marked tens of thousands of Palestinians using AI. Second, we reveal the “Where’s Daddy?” system, which tracked these targets and signaled to the army when they entered their family homes. Third, we describe how “dumb” bombs were chosen to strike these homes.&nbsp;</span></p>
<p><span>Fourth, we explain how the army loosened the permitted number of civilians who could be killed during the bombing of a target. Fifth, we note how automated software inaccurately calculated the amount of non-combatants in each household. And sixth, we show how on several occasions, when a home was struck, usually at night, the individual target was sometimes not inside at all, because military officers did not verify the information in real time.</span></p>
<h3><span>STEP 1: GENERATING TARGETS</span></h3>
<h3>‘Once you go automatic, target generation goes crazy’</h3>
<p><span>In the Israeli army, the term “human target” referred in the past to a senior military operative who, according to the rules of the military’s International Law Department, can be killed in their private home even if there are civilians around. Intelligence sources told +972 and Local Call that during Israel’s previous wars, since this was an “especially brutal” way to kill someone — often by killing an entire family alongside the target — such human targets were marked very carefully and only senior military commanders were bombed in their homes, to maintain the principle of proportionality under international law.</span></p>
<p><span>But after October 7 — when Hamas-led militants launched a deadly assault on southern Israeli communities, killing around 1,200 people and abducting 240 — the army, the sources said, took a dramatically different approach. Under “Operation Iron Swords,” the army decided to designate all operatives of Hamas’ military wing as human targets, regardless of their rank or military importance. And that changed everything.</span></p>
<p><span>The new policy also posed a technical problem for Israeli intelligence. In previous wars, in order to authorize the assassination of a single human target, an officer had to go through a complex and lengthy “incrimination” process: cross-check evidence that the person was indeed a senior member of Hamas’ military wing, find out where he lived, his contact information, and finally know when he was home in real time. When the list of targets numbered only a few dozen senior operatives, intelligence personnel could individually handle the work involved in incriminating and locating them.</span></p>
<div id="attachment_177464"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/main_image51785_4WLiR7887N.jpg" data-featherlight="image"><img title="Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/main_image51785_4WLiR7887N-1280x853.jpg" alt="Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun)" width="768" height="512" data-caption="Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun)"></a></p><p>Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>However, once the list was expanded to include tens of thousands of lower-ranking operatives, the Israeli army figured it had to rely on automated software and artificial intelligence. The result, the sources testify, was that the role of human personnel in incriminating Palestinians as military operatives was pushed aside, and AI did most of the work instead. According to four of the sources who spoke to +972 and Local Call, Lavender — which was developed to create human targets in the current war — has marked some 37,000 Palestinians as suspected “Hamas militants,” most of them junior, for assassination (the IDF Spokesperson denied the existence of such a kill list in a statement to +972 and Local Call).</span></p>
<p><span>“We didn’t know who the junior operatives were, because Israel didn’t track them routinely [before the war],” explained senior officer B. to +972 and Local Call, illuminating the reason behind the development of this particular target machine for the current war. “They wanted to allow us to attack [the junior operatives] automatically. That’s the Holy Grail. Once you go automatic, target generation goes crazy.”</span></p>
<p><span>The sources said that the approval to automatically adopt Lavender’s kill lists, which had previously been used only as an auxiliary tool, was granted about two weeks into the war, after intelligence personnel “manually” checked the accuracy of a random sample of several hundred targets selected by the AI system. When that sample found that Lavender’s results had reached 90 percent accuracy in identifying an individual’s affiliation with Hamas, the army authorized the sweeping use of the system. From that moment, sources said that if Lavender decided an individual was a militant in Hamas, they were essentially asked to treat that as an order, with no requirement to independently check why the machine made that choice or to examine the raw intelligence data on which it is based.</span></p>
<p><span>“At 5 a.m., </span><span>[the air force]</span><span> would come and bomb all the houses that we had marked,” B. said. “We took out thousands of people. We didn’t go through them one by one — we put everything into automated systems, and as soon as one of [the marked individuals] was at home, he immediately became a target. We bombed him and his house.”</span></p>
<p><span>The deadly results of this loosening of restrictions in the early stage of the war were staggering. According to data from the Palestinian Health Ministry in Gaza, on which the Israeli army has </span><a href="https://web.archive.org/web/20240403151726/https://www.mekomit.co.il/%d7%94%d7%a6%d7%91%d7%90-%d7%91%d7%93%d7%a7-%d7%95%d7%9e%d7%a6%d7%90-%d7%a9%d7%93%d7%99%d7%95%d7%95%d7%97%d7%99-%d7%94%d7%94%d7%a8%d7%95%d7%92%d7%99%d7%9d-%d7%91%d7%9e%d7%a9%d7%a8%d7%93-%d7%94%d7%91/"><span>relied almost exclusively</span></a><span> since the beginning of the war, Israel killed some 15,000 Palestinians — almost half of the death toll so far — in the </span><a href="https://web.archive.org/web/20240403151726/https://www.ochaopt.org/content/hostilities-gaza-strip-and-israel-flash-update-50"><span>first six weeks</span></a><span> of the war, up until a week-long ceasefire was agreed on Nov. 24.</span></p>
<div id="attachment_177466"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/main_image52901_dXsGme0t6F.jpg" data-featherlight="image"><img title="Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/main_image52901_dXsGme0t6F-1280x853.jpg" alt="Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)" width="768" height="512" data-caption="Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)"></a></p><p>Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)</p>
</div>
<h3>‘The more information and variety, the better’</h3>
<p><span>The Lavender software analyzes information collected on most of the 2.3 million residents of the Gaza Strip through a system of mass surveillance, then assesses and ranks the likelihood that each particular person is active in the military wing of Hamas or PIJ. According to sources, the machine gives almost every single person in Gaza a rating from 1 to 100, expressing how likely it is that they are a militant.&nbsp;</span></p>
<p><span>Lavender learns to identify characteristics of known Hamas and PIJ operatives, whose information was fed to the machine as training data, and then to locate these same characteristics — also called “features” — among the general population, the sources explained. An individual found to have several different incriminating features will reach a high rating, and thus automatically becomes a potential target for assassination.&nbsp;</span></p>
<p><span>In “The Human-Machine Team,” the book referenced at the beginning of this article, the current commander of Unit 8200 advocates for such a system without referencing Lavender by name. (The commander himself also isn’t named, but five sources in 8200 confirmed that the commander is the author, as </span><a href="https://web.archive.org/web/20240403151726/https://www.haaretz.com/israel-news/2021-10-01/ty-article/.highlight/top-israeli-intel-officer-goes-where-no-ones-gone-before-and-its-all-on-amazon/0000017f-e1fb-df7c-a5ff-e3fb21210000"><span>reported</span></a><span> also by Haaretz.) Describing human personnel as a “bottleneck” that limits the army’s capacity during a military operation, The commander laments: “We [humans] cannot process so much information. It doesn’t matter how many people you have tasked to produce targets during the war — you still cannot produce enough targets per day.”</span></p>
<p><span>The solution to this problem, he says, is artificial intelligence. The book offers a short guide to building a “target machine,” similar in description to Lavender, based on AI and machine-learning algorithms. Included in this guide are several examples of the “hundreds and thousands” of features that can increase an individual’s rating, such as being in a Whatsapp group with a known militant, changing cell phone every few months, and changing addresses frequently.&nbsp;</span></p>
<p><span>“The more information, and the more variety, the better,” the commander writes. “Visual information, cellular information, social media connections, battlefield information, phone contacts, photos.” While humans select these features at first, the commander continues, over time the machine will come to identify features on its own. This, he says, can enable militaries to create “tens of thousands of targets,” while the actual decision as to whether or not to attack them will remain a human one.</span></p>
<p><span>The book isn’t the only time a senior Israeli commander hinted at the existence of human target machines like Lavender. +972 and Local Call have obtained footage of a private lecture given by the commander of Unit 8200’s secretive Data Science and AI center, “Col. Yoav,” at Tel Aviv University’s AI week in 2023, which was </span><a href="https://web.archive.org/web/20240403151726/https://www.geektime.co.il/idf-fights-hamas-with-ai-and-data-science/"><span>reported on</span></a><span> at the time in the Israeli media.</span></p>
<p><span>In the lecture, the commander speaks about a new, sophisticated target machine used by the Israeli army that detects “dangerous people” based on their likeness to existing lists of known militants on which it was trained. “Using the system, we managed to identify Hamas missile squad commanders,” Col. Yoav said in the lecture, referring to Israel’s May 2021 military operation in Gaza, when the machine was used for the first time.&nbsp;</span></p>
<div id="attachment_177470"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/Slide-33.png" data-featherlight="image"><img title="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call." decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/Slide-33.png" alt="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023." width="1203" height="650" data-caption="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call."></a></p><p>Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call.</p>
</div>
<div id="attachment_177469"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/Slide-44.png" data-featherlight="image"><img title="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call." decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/Slide-44.png" alt="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call." width="1201" height="650" data-caption="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call."></a></p><p>Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call.</p>
</div>
<p><span>The lecture presentation slides, also obtained by +972 and Local Call, contain illustrations of how the machine works: it is fed data about existing Hamas operatives, it learns to notice their features, and then it rates other Palestinians based on how similar they are to the militants.&nbsp;</span></p>
<p><span>“We rank the results and determine the threshold [at which to attack a target],” Col. Yoav said in the lecture, emphasizing that “eventually, people of flesh and blood take the decisions. In the defense realm, ethically speaking, we put a lot of emphasis on this. These tools are meant to help [intelligence officers] break their barriers.”&nbsp;</span></p>
<p><span>In practice, however, sources who have used Lavender in recent months say human agency and precision were substituted for mass target creation and lethality.</span></p>
<h3>‘There was no “zero-error” policy’</h3>
<p><span>B., a senior officer who used Lavender, echoed to +972 and Local Call that in the current war, officers were not required to independently review the AI system’s assessments, in order to save time and enable the mass production of human targets without hindrances.&nbsp;</span></p>
<p><span>“Everything was statistical, everything was neat — it was very dry,” B. said. He noted that this lack of supervision was permitted despite internal checks showing that Lavender’s calculations were considered accurate only 90 percent of the time; in other words, it was known in advance that 10 percent of the human targets slated for assassination were not members of the Hamas military wing at all.</span></p>
<p><span>For example, sources explained that the Lavender machine sometimes mistakenly flagged individuals who had communication patterns similar to known Hamas or PIJ operatives — including police and civil defense workers, militants’ relatives, residents who happened to have a name and nickname identical to that of an operative, and Gazans who used a device that once belonged to a Hamas operative.&nbsp;</span></p>
<p><span>“How close does a person have to be to Hamas to be [considered by an AI machine to be] affiliated with the organization?” said one source critical of Lavender’s inaccuracy. “It’s a vague boundary. Is a person who doesn’t receive a salary from Hamas, but helps them with all sorts of things, a Hamas operative? Is someone who was in Hamas in the past, but is no longer there today, a Hamas operative? Each of these features — characteristics that a machine would flag as suspicious — is inaccurate.”</span></p>
<div id="attachment_177451"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/03/F240224ARK09.jpg" data-featherlight="image"><img title="Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/03/F240224ARK09-1280x853.jpg" alt="Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>Similar problems exist with the ability of target machines to assess the phone used by an individual marked for assassination. “In war, Palestinians change phones all the time,” said the source. “People lose contact with their families, give their phone to a friend or a wife, maybe lose it. There is no way to rely 100 percent on the automatic mechanism that determines which [phone] number belongs to whom.”</span></p>
<p><span>According to the sources, the army knew that the minimal human supervision in place would not discover these faults. “There was no ‘zero-error’ policy. Mistakes were treated statistically,” said a source who used Lavender. “Because of the scope and magnitude, the protocol was that even if you don’t know for sure that the machine is right, you know that statistically it’s fine. So you go for it.”</span></p>
<p><span>“It has proven itself,” said B., the senior source. “There’s something about the statistical approach that sets you to a certain norm and standard. There has been an illogical amount of [bombings] in this operation. This is unparalleled, in my memory. And I have much more trust in a statistical mechanism than a soldier who lost a friend two days ago. Everyone there, including me, lost people on October 7. The machine did it coldly. And that made it easier.”</span></p>
<p><span>Another intelligence source, who defended the reliance on the Lavender-generated kill lists of Palestinian suspects, argued that it was worth investing an intelligence officer’s time only to verify the information if the target was a senior commander in Hamas. “But when it comes to a junior militant, you don’t want to invest manpower and time in it,” he said. “In war, there is no time to incriminate every target. So you’re willing to take the margin of error of using artificial intelligence, risking collateral damage and civilians dying, and risking attacking by mistake, and to live with it.”</span></p>
<p>B. said that the reason for this automation was a constant push to generate more targets for assassination. “In a day without targets [whose feature rating was sufficient to authorize a strike], we attacked at a lower threshold. We were constantly being pressured: ‘Bring us more targets.’ They really shouted at us. We finished [killing] our targets very quickly.”</p>
<p><span>He explained that when lowering the rating threshold of Lavender, it would mark more people as targets for strikes. “At its peak, the system managed to generate 37,000 people as potential human targets,” said B. “But the numbers changed all the time, because it depends on where you set the bar of what a Hamas operative is. There were times when a Hamas operative was defined more broadly, and then the machine started bringing us all kinds of civil defense personnel, police officers, on whom it would be a shame to waste bombs. They help the Hamas government, but they don’t really endanger soldiers.”</span></p>
<div id="attachment_177448"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/03/F240318ARK048.jpg" data-featherlight="image"><img title="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/03/F240318ARK048-1280x851.jpg" alt="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" width="768" height="511" data-caption="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)</p>
</div>
<h3>‘We only checked that the target was a man’</h3>
<p><span>The Israeli military flatly rejects these claims. In a statement to +972 and Local Call, the IDF Spokesperson denied using artificial intelligence to incriminate targets, saying these are merely “auxiliary tools that assist officers in the process of incrimination.” The statement went on: “In any case, an independent examination by an [intelligence] analyst is required, which verifies that the identified targets are legitimate targets for attack, in accordance with the conditions set forth in IDF directives and international law.&nbsp;&nbsp;</span></p>
<p><span>However, sources said that the only human supervision protocol in place before bombing the houses of suspected “junior” militants marked by Lavender was to conduct a single check: ensuring that the AI-selected target is male rather than female. The assumption in the army was that if it were a woman, the machine had likely made a mistake, because there are no women among the ranks of the military wings of Hamas and PIJ.</span></p>
<p><span>“A human being had to [verify the target] for just a few seconds,” B. said, explaining that this became the protocol after realizing the Lavender system was “getting it right” most of the time. “At first, we did checks to ensure that the machine didn’t get confused. But at some point we relied on the automatic system, and we only checked that [the target] was a man — that was enough. It doesn’t take a long time to tell if someone has a male or a female voice.”&nbsp;</span></p>
<p><span>To conduct the male/female check, B. claimed that in the current war, “I would invest 20 seconds for each target at this stage, and do dozens of them every day. I had zero added value as a human, apart from being a stamp of approval. It saved a lot of time. If [the operative] came up in the automated mechanism, and I checked that he was a man, there would be permission to bomb him, subject to an examination of collateral damage.”</span></p>
<div id="attachment_177459"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/F231120ARK005-1.jpg" data-featherlight="image"><img title="Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/F231120ARK005-1-1280x853.jpg" alt="Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>In practice, sources said this meant that for civilian men marked in error by Lavender, there was no supervising mechanism in place to detect the mistake.&nbsp;</span></p>
<h3><span>STEP 2: LINKING TARGETS TO FAMILY HOMES</span></h3>
<h3>‘Most of the people you killed were women and children’</h3>
<p><span>The next stage in the Israeli army’s assassination procedure is identifying where to attack the targets that Lavender generates.</span></p>
<p><span>In a statement to +972 and Local Call, the IDF Spokesperson claimed in response to this article that “Hamas places its operatives and military assets in the heart of the civilian population, systematically uses the civilian population as human shields, and conducts fighting from within civilian structures, including sensitive sites such as hospitals, mosques, schools and UN facilities. The IDF is bound by and acts according to international law, directing its attacks only at military targets and military operatives.”&nbsp;</span></p>
<p><span>The six sources we spoke to echoed this to some degree, saying that Hamas’ extensive </span><a href="https://web.archive.org/web/20240403151726/https://www.nytimes.com/interactive/2024/02/12/world/middleeast/gaza-tunnel-israel-hamas.html"><span>tunnel system</span></a><span> deliberately passes under hospitals and schools; that Hamas militants use ambulances to get around; and that countless military assets have been situated near civilian buildings. The sources argued that many Israeli strikes kill civilians as a result of these tactics by Hamas — a characterization that human rights groups <a href="https://web.archive.org/web/20240403151726/https://www.hrw.org/news/2024/03/19/israeli-forces-conduct-gaza">warn</a> evades Israel’s onus for inflicting the casualties.&nbsp;</span></p>
<p><span>However, in contrast to the Israeli army’s official statements, the sources explained that a major reason for the unprecedented death toll from Israel’s current bombardment is the fact that the army has systematically attacked targets in their private homes, alongside their families — in part because it was easier from an intelligence standpoint to mark family houses using automated systems.</span></p>
<p><span>Indeed, several sources emphasized that, as opposed to numerous cases of Hamas operatives engaging in military activity from civilian areas, in the case of systematic assassination strikes, the army routinely made the active choice to bomb suspected militants when inside civilian households from which no military activity took place. This choice, they said, was a reflection of the way Israel’s system of mass surveillance in Gaza is designed.</span></p>
<div id="attachment_177465"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/main_image51496_c8EQed2mC6.jpg" data-featherlight="image"><img title="Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/main_image51496_c8EQed2mC6-1280x853.jpg" alt="Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)" width="768" height="512" data-caption="Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)"></a></p><p>Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>The sources told +972 and Local Call that since everyone in Gaza had a private house with which they could be associated, the army’s surveillance systems could easily and automatically “link” individuals to family houses. In order to identify the moment operatives enter their houses in real time, various additional automatic softwares have been developed. These programs track thousands of individuals simultaneously, identify when they are at home, and send an automatic alert to the targeting officer, who then marks the house for bombing. One of several of these tracking softwares, revealed here for the first time, is called “Where’s Daddy?”&nbsp;</span></p>
<p><span>“You put hundreds [of targets] into the system and wait to see who you can kill,” said one source with knowledge of the system. “It’s called broad hunting: you copy-paste from the lists that the target system produces.”</span></p>
<p><span>Evidence of this policy is also clear from the data: during the first month of the war, more than half of the fatalities — 6,120 people — belonged to 1,340 families, many of which were completely wiped out while inside their homes, according to </span><a href="https://web.archive.org/web/20240403151726/https://www.ochaopt.org/content/hostilities-gaza-strip-and-israel-reported-impact-day-45"><span>UN figures</span></a><span>. The proportion of entire </span><a href="https://web.archive.org/web/20240403151726/https://www.972mag.com/gaza-families-bombing-humanitarian-crisis/"><span>families</span></a><span> bombed in their houses in the current war is much higher </span><a href="https://web.archive.org/web/20240403151726/https://www.btselem.org/download/201501_black_flag_eng.pdf"><span>than in the 2014 Israeli operation</span></a><span> in Gaza, further suggesting the prominence of this policy.</span></p>
<p><span>Another source said that each time the pace of assassinations waned, more targets were added to systems like Where’s Daddy? to locate individuals that entered their homes and could therefore be bombed. He said that the decision of who to put into the tracking systems could be made by relatively low-ranking officers in the military hierarchy.&nbsp;</span></p>
<p><span>“One day, totally of my own accord, I added something like 1,200 new targets to the [tracking] system, because the number of attacks [we were conducting] decreased,” the source said. “That made sense to me. In retrospect, it seems like a serious decision I made. And such decisions were not made at high levels.”</span></p>
<p><span>The sources said that in the first two weeks of the war, “several thousand” targets were initially inputted into locating programs like Where’s Daddy?. These included all the members of Hamas’ elite special forces unit the Nukhba, all of Hamas’ anti-tank operatives, and anyone who entered Israel on October 7. But before long, the kill list was drastically expanded.&nbsp;</span></p>
<p><span>“In the end it was everyone [marked by Lavender],” one source explained. “Tens of thousands. This happened a few weeks later, when the [Israeli] brigades entered Gaza, and there were already fewer uninvolved people [i.e. civilians] in the northern areas.” According to this source, even some minors were marked by Lavender as targets for bombing. “Normally, operatives are over the age of 17, but that was not a condition.”</span></p>
<div id="attachment_175004"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2023/11/main_image51646_zQb2EotVH7.jpg" data-featherlight="image"><img title="Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2023/11/main_image51646_zQb2EotVH7-1280x853.jpg" alt="Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)" width="768" height="512" data-caption="Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)"></a></p><p>Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>Lavender and systems like Where’s Daddy? were thus combined with deadly effect, killing entire families, sources said. By adding a name from the Lavender-generated lists to the Where’s Daddy? home tracking system, A. explained, the marked person would be placed under ongoing surveillance, and could be attacked as soon as they set foot in their home, collapsing the house on everyone inside.</span></p>
<p><span>“Let’s say you calculate [that there is one] Hamas [operative] plus 10 [civilians in the house],” A. said. “Usually, these 10 will be women and children. So absurdly, it turns out that most of the people you killed were women and children.”</span></p>
<h3><span>STEP 3: CHOOSING A WEAPON</span></h3>
<h3>‘We usually carried out the attacks with “dumb bombs”’</h3>
<p><span>Once Lavender has marked a target for assassination, army personnel have verified that they are male, and tracking software has located the target in their home, the next stage is picking the munition with which to bomb them.</span></p>
<p><span>In December 2023, </span><a href="https://web.archive.org/web/20240403151726/https://edition.cnn.com/2023/12/13/politics/intelligence-assessment-dumb-bombs-israel-gaza/index.html"><span>CNN reported</span></a> <span>that according to U.S. intelligence estimates, about 45 percent of the munitions used by the Israeli air force in Gaza were “dumb” bombs, which are known to cause more collateral damage than guided bombs. In response to the CNN report, an army spokesperson quoted in the article said: “A</span><span>s a military committed to international law and a moral code of conduct, we are devoting vast resources to minimizing harm to the civilians that Hamas has forced into the role of human shields. Our war is against Hamas, not against the people of Gaza.”</span></p>
<p><span>Three intelligence sources, however, told +972 and Local Call that junior operatives marked by Lavender were assassinated only with dumb bombs, in the interest of saving more expensive armaments. The implication, one source explained, was that the army would not strike a junior target if they lived in a high-rise building, because the army did not want to spend a more precise and expensive “floor bomb” (with more limited collateral effect) to kill him. But if a junior target lived in a building with only a few floors, the army was authorized to kill him and everyone in the building with a dumb bomb.</span></p>
<div id="attachment_177445"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/03/F240318ARK043.jpg" data-featherlight="image"><img title="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/03/F240318ARK043-1280x851.jpg" alt="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" width="768" height="511" data-caption="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>“It was like that with all the junior targets,” testified C., who used various automated programs in the current war. “The only question was, is it possible to attack the building in terms of collateral damage? Because we usually carried out the attacks with dumb bombs, and that meant literally destroying the whole house on top of its occupants. But even if an attack is averted, you don’t care — you immediately move on to the next target. Because of the system, the targets never end. You have another 36,000 waiting.”</span></p>
<h3><span>STEP 4: AUTHORIZING CIVILIAN CASUALTIES</span></h3>
<h3>‘We attacked almost without considering collateral damage’</h3>
<p><span>One source said that when attacking junior operatives, including those marked by AI systems like Lavender, the number of civilians they were allowed to kill alongside each target was fixed during the initial weeks of the war at up to 20. Another source claimed the fixed number was up to 15. These “collateral damage degrees,” as the military calls them, were applied broadly to all suspected junior militants, the sources said, regardless of their rank, military importance, and age, and with no specific case-by-case examination to weigh the military advantage of assassinating them against the expected harm to civilians.&nbsp;</span></p>
<p><span>According to A., who was an officer in a target operation room in the current war, the army’s international law department has never before given such “sweeping approval” for such a high collateral damage degree. “It’s not just that you can kill any person who is a Hamas soldier, which is clearly permitted and legitimate in terms of international law,” A. said. “But they directly tell you: ‘You are allowed to kill them along with many civilians.’&nbsp;</span></p>
<p><span>“Every person who wore a Hamas uniform in the past year or two could be bombed with 20 [civilians killed as] collateral damage, even without special permission,” A. continued. “In practice, the principle of proportionality did not exist.”</span></p>
<p><span>According to A., this was the policy for most of the time that he served. Only later did the military lower the collateral damage degree. “In this calculation, it could also be 20 children for a junior operative … It really wasn’t like that in the past,” A. explained. Asked about the security rationale behind this policy, A. replied: “Lethality.”</span></p>
<div id="attachment_177453"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/03/F231107ARK20.jpg" data-featherlight="image"><img title="Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/03/F231107ARK20-1280x853.jpg" alt="Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>The predetermined and fixed collateral damage degree helped accelerate the mass creation of targets using the Lavender machine, sources said, because it saved time. B. claimed that the number of civilians they were permitted to kill per suspected junior militant marked by AI in the first week of the war, was fifteen, but that this number “went up and down” over time.&nbsp;</span></p>
<p><span>“At first we attacked almost without considering collateral damage,” B. said of the first week after October 7. “In practice, you didn’t really count people [in each house that is bombed], because you couldn’t really tell if they’re at home or not. After a week, restrictions on collateral damage began. The number dropped [from 15] to five, which made it really difficult for us to attack, because if the whole family was home, we couldn’t bomb it. Then they raised the number again.”</span></p>
<h3>‘We knew we would kill over 100 civilians’</h3>
<p><span>Sources told +972 and Local Call that now, partly due to American pressure, the Israeli army is no longer mass-generating junior human targets for bombing in civilian homes. The fact that most homes in the Gaza Strip were already destroyed or damaged, and almost the entire population has been displaced, also impaired the army’s ability to rely on intelligence databases and automated house-locating programs.&nbsp;</span></p>
<p><span>E. claimed that the massive bombardment of junior militants took place only in the first week or two of the war, and then was stopped mainly so as not to waste bombs. “There is a munitions economy,” E. said. “They were always afraid that there would be [a war] in the northern arena [with Hezbollah in Lebanon]. They don’t attack these kinds of [junior] people at all anymore.”&nbsp;</span></p>
<p><span>However, airstrikes against senior ranking Hamas commanders are still ongoing, and sources said that for these attacks, the military is authorizing the killing of “hundreds” of civilians per target — an official policy for which there is no historical precedent in Israel, or even in recent U.S. military operations.</span></p>
<p><span>“In the bombing of the commander of the Shuja’iya Battalion, we knew that we would kill over 100 civilians,” B. recalled of a Dec. 2 bombing that the IDF Spokesperson </span><a href="https://web.archive.org/web/20240403151726/https://www.timesofisrael.com/liveblog_entry/idf-strike-kills-gazan-terrorist-responsible-for-attack-that-killed-oron-shaul-in-2014/"><span>said</span></a><span> was aimed at assassinating Wisam Farhat. “For me, psychologically, it was unusual. Over 100 civilians — it crosses some red line.”</span></p>
<div id="attachment_174306"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2023/10/F231009AM354.jpg" data-featherlight="image"><img title="A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2023/10/F231009AM354-1280x853.jpg" alt="A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90)" width="768" height="512" data-caption="A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90) "></a></p><p>A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90)</p>
</div>
<p><span>Amjad Al-Sheikh, a young Palestinian from Gaza, said many of his family members were killed in that bombing. A resident of Shuja’iya, east of Gaza City, he was at a local supermarket that day when he heard five blasts that shattered the glass windows.&nbsp;</span></p>
<p><span>“I ran to my family’s house, but there were no buildings there anymore,” Al-Sheikh told +972 and Local Call. “The street was filled with screams and smoke. Entire residential blocks turned to mountains of rubble and deep pits. People began to search in the cement, using their hands, and so did I, looking for signs of my family’s house.&nbsp;</span></p>
<p><span>Al-Sheikh’s wife and baby daughter survived — protected from the rubble by a closet that fell on top of them — but he found 11 other members of his family, among them his sisters, brothers, and their young children, dead under the rubble. </span><a href="https://web.archive.org/web/20240403151726/https://www.btselem.org/hebrew/gaza_strip/20231205_israel_is_not_fighting_against_hamas_but_against_civilians_implementing_a_criminal_policy_of_bombings"><span>According to</span></a><span> the human rights group B’Tselem, the bombing that day destroyed dozens of buildings, killed dozens of people, and buried hundreds under the ruins of their homes.</span></p>
<h3>‘Entire families were killed’</h3>
<p><span>Intelligence sources told +972 and Local Call they took part in even deadlier strikes. In order to assassinate Ayman Nofal, the commander of Hamas’ Central Gaza Brigade, a source said the army authorized the killing of approximately 300 civilians, </span><a href="https://web.archive.org/web/20240403151726/https://www.ynet.co.il/news/article/ryxl6b2116"><span>destroying several buildings</span></a><span> in airstrikes on Al-Bureij refugee camp on Oct. 17 based on an imprecise pinpointing of Nofal. Satellite footage and </span><a href="https://web.archive.org/web/20240403151726/https://twitter.com/Roaastudies/status/1714253580792643820"><span>videos</span></a><span> from the scene show the destruction of several large multi-storey apartment buildings.</span></p>
<p><span>“Between 16 to 18 houses were wiped out in the attack,” Amro Al-Khatib, a resident of the camp, told +972 and Local Call. “We couldn’t tell one apartment from the other — they all got mixed up in the rubble, and we found human body parts everywhere.”</span></p>
<p><span>In the aftermath, Al-Khatib recalled around 50 dead bodies being pulled out of the rubble, and around 200 people wounded, many of them gravely. But that was just the first day. The camp’s residents spent five days pulling the dead and injured out, he said.</span></p>
<div id="attachment_177462"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/04/main_image52153_Ke1nD80YfY.jpg" data-featherlight="image"><img title="Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/04/main_image52153_Ke1nD80YfY-1280x853.jpg" alt="Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)" width="768" height="512" data-caption="Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)"></a></p><p>Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>Nael Al-Bahisi, a paramedic, was one of the first on the scene. He counted between 50-70 casualties on that first day. “At a certain moment, we understood the target of the strike was Hamas commander Ayman Nofal,” he told +972 and Local Call. “They killed him, and also many people who didn’t know he was there. Entire families with children were killed.”</span></p>
<p><span>Another intelligence source told +972 and Local Call that the army </span><a href="https://web.archive.org/web/20240403151726/https://www.israelhayom.co.il/news/defense/article/14992654"><span>destroyed a high-rise building</span></a><span> in Rafah in mid-December, killing “dozens of civilians,” in order </span><a href="https://web.archive.org/web/20240403151726/https://www.israelhayom.co.il/news/defense/article/14992654"><span>to try to kill</span></a><span> Mohammed Shabaneh, the commander of Hamas’ Rafah Brigade (it is not clear whether or not he was killed in the attack). Often, the source said, the senior commanders hide in tunnels that pass under civilian buildings, and therefore the choice to assassinate them with an airstrike necessarily kills civilians.</span></p>
<p><span>“Most of those injured were children,” said Wael Al-Sir, 55, who witnessed the large-scale strike believed by some Gazans to have been the assassination attempt. He told +972 and Local Call that the bombing on Dec. 20 destroyed an “entire residential block” and killed at least 10 children.</span></p>
<p><span>“There was a completely permissive policy regarding the casualties of [bombing] operations — so permissive that in my opinion it had an element of revenge,” D., an intelligence source, claimed. “The core of this was the assassinations of senior [Hamas and PIJ commanders] for whom they were willing to kill hundreds of civilians. We had a calculation: how many for a brigade commander, how many for a battalion commander, and so on.”</span></p>
<p><span>“There were regulations, but they were just very lenient,” said E., another intelligence source. “We’ve killed people with collateral damage in the high double digits, if not low triple digits. These are things that haven’t happened before.”</span></p>
<div id="attachment_175496"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2023/11/F231022ARK013.jpg" data-featherlight="image"><img title="Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2023/11/F231022ARK013-1280x853.jpg" alt="Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>Such a high rate of “collateral damage” is exceptional not only compared to what the Israeli army previously deemed acceptable, but also compared to the wars waged by the United States in Iraq, Syria, and Afghanistan.&nbsp;</span></p>
<p><span>General Peter Gersten, </span><span>Deputy Commander for Operations and Intelligence </span><span>in the operation to fight ISIS in Iraq and Syria, </span><a href="https://web.archive.org/web/20240403151726/https://www.defensedaily.com/pentagon-removed-non-combatant-casualty-cut-off-value-doctrine-2018/pentagon/"><span>told</span></a><span> a U.S. defense magazine in 2021 that an attack with collateral damage of 15 civilians deviated from procedure; to carry it out, he had to obtain special permission from the head of the U.S. Central Command, General Lloyd Austin, who is now Secretary of Defense.&nbsp;</span></p>
<p><span>“With Osama Bin Laden, you’d have an NCV [Non-combatant Casualty Value] of 30, but if you had a low-level commander, his NCV was typically zero,” Gersten said. “We ran zero for the longest time.”</span></p>
<h3>‘We were told: “Whatever you can, bomb”’</h3>
<p><span>All the sources interviewed for this investigation said that Hamas’ massacres on October 7 and kidnapping of hostages greatly influenced the army’s fire policy and collateral damage degrees. “At first, the atmosphere was painful and vindictive,” said B., who was drafted into the army immediately after October 7, and served in a target operation room. “The rules were very lenient. They took down four buildings when they knew the target was in one of them. It was crazy.</span></p>
<p><span>“There was a dissonance: on the one hand, people here were frustrated that we were not attacking enough,” B. continued. “On the other hand, you see at the end of the day that another thousand Gazans have died, most of them civilians.”</span></p>
<p><span>“There was hysteria in the professional ranks,” said D., who was also drafted immediately after October 7. “They had no idea how to react at all. The only thing they knew to do was to just start bombing like madmen to try to dismantle Hamas’ capabilities.”</span></p>
<div id="attachment_174647"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2023/10/F231019CG008.jpg" data-featherlight="image"><img title="Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2023/10/F231019CG008-1280x854.jpg" alt="Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)" width="768" height="512" data-caption="Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)"></a></p><p>Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)</p>
</div>
<p>D. stressed that they were not explicitly told that the army’s goal was “revenge,” but expressed that “as soon as every target connected to Hamas becomes legitimate, and with almost any collateral damage being approved, it is clear to you that thousands of people are going to be killed. Even if officially every target is connected to Hamas, when the policy is so permissive, it loses all meaning.”</p>
<p><span>A. also used the word “revenge” to describe the atmosphere inside the army after October 7. “No one thought about what to do afterward, when the war is over, or how it will be possible to live in Gaza and what they will do with it,” A. said. “We were told: now we have to fuck up Hamas, no matter what the cost. Whatever you can, you bomb.”</span></p>
<p><span>B., the senior intelligence source, said that in retrospect, he believes this “disproportionate” policy of killing Palestinians in Gaza also endangers Israelis, and that this was one of the reasons he decided to be interviewed.</span></p>
<p><span>“In the short term, we are safer, because we hurt Hamas. But I think we’re less secure in the long run. I see how all the bereaved families in Gaza — which is nearly everyone — will raise the motivation for [people to join] Hamas 10 years down the line. And it will be much easier for [Hamas] to recruit them.”</span></p>
<p><span>In a statement to +972 and Local Call, the Israeli army denied much of what the sources told us, claiming that “each target is examined individually, while an individual assessment is made of the military advantage and collateral damage expected from the attack … The IDF does not carry out attacks when the collateral damage expected from the attack is excessive in relation to the military advantage.”</span></p>
<h3><span>STEP 5: CALCULATING COLLATERAL DAMAGE</span></h3>
<h3>‘The model was not connected to reality’</h3>
<p><span>According to the intelligence sources, the Israeli army’s calculation of the number of civilians expected to be killed in each house alongside a target — a procedure examined in a </span><a href="https://web.archive.org/web/20240403151726/https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/"><span>previous investigation</span></a><span> by +972 and Local Call — was conducted with the help of automatic and inaccurate tools. In previous wars, intelligence personnel would spend a lot of time verifying how many people were in a house that was set to be bombed, with the number of civilians liable to be killed listed as part of a “target file.” After October 7, however, this thorough verification was largely abandoned in favor of automation.&nbsp;</span></p>
<p><span>In October, The New York Times </span><a href="https://web.archive.org/web/20240403151726/https://www.nytimes.com/2023/10/16/world/middleeast/gaza-invasion-israel-cellphone-data.html"><span>reported</span></a><span> on a system operated from a special base in southern Israel, which collects information from mobile phones in the Gaza Strip and provided the military with a live estimate of the number of Palestinians who fled the northern Gaza Strip southward. Brig. General Udi Ben Muha told the Times that “It’s not a 100 percent perfect system — but it gives you the information you need to make a decision.” The system operates according to colors: red marks areas where there are many people, and green and yellow mark areas that have been relatively cleared of residents.</span><span>&nbsp;</span></p>
<div id="attachment_175999"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2024/01/F231110AM03.jpg" data-featherlight="image"><img title="Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2024/01/F231110AM03-1280x853.jpg" alt="Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)" width="768" height="512" data-caption="Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)"></a></p><p>Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)</p>
</div>
<p><span>The sources who spoke to +972 and Local Call described a similar system for calculating collateral damage, which was used to decide whether to bomb a building in Gaza. They said that the software calculated the number of civilians residing in each home before the war — by assessing the size of the building and reviewing its list of residents — and then reduced those numbers by the proportion of residents who supposedly evacuated the neighborhood.&nbsp;</span></p>
<p><span>To illustrate, if the army estimated that half of a neighborhood’s residents had left, the program would count a house that usually had 10 residents as a house containing five people. To save time, the sources said, the army did not surveil the homes to check how many people were actually living there, as it did in previous operations, to find out if the program’s estimate was indeed accurate.</span></p>
<p><span>“This model was not connected to reality,” claimed one source. “There was no connection between those who were in the home now, during the war, and those who were listed as living there prior to the war. [On one occasion] we bombed a house without knowing that there were several families inside, hiding together.”</span><span>&nbsp;</span></p>
<p><span>The source said that although the army knew that such errors could occur, this imprecise model was adopted nonetheless, because it was faster. As such, the source said, “the collateral damage calculation was completely automatic and statistical” — even producing figures that were not whole numbers.</span></p>
<h3><span>STEP 6: BOMBING A FAMILY HOME</span></h3>
<h3>‘You killed a family for no reason’</h3>
<p><span>The sources who spoke to +972 and Local Call explained that there was sometimes a substantial gap between the moment that tracking systems like Where’s Daddy? alerted an officer that a target had entered their house, and the bombing itself — leading to the killing of whole families even without hitting the army’s target. “It happened to me many times that we attacked a house, but the person wasn’t even home,” one source said. “The result is that you killed a family for no reason.”</span></p>
<p><span>Three intelligence sources told +972 and Local Call that they had witnessed an incident in which the Israeli army bombed a family’s private home, and it later turned out that the intended target of the assassination was not even inside the house, since no further verification was conducted in real time.</span></p>
<div id="attachment_174976"><p><a href="https://web.archive.org/web/20240403151726/https://static.972mag.com/www/uploads/2023/11/F231106ARK01.jpg" data-featherlight="image"><img title="Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://web.archive.org/web/20240403151726im_/https://static.972mag.com/www/uploads/2023/11/F231106ARK01-1280x853.jpg" alt="Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>“Sometimes [the target] was at home earlier, and then at night he went to sleep somewhere else, say underground, and you didn’t know about it,” one of the sources said. “There are times when you double-check the location, and there are times when you just say, ‘Okay, he was in the house in the last few hours, so you can just bomb.’”</span><span>&nbsp;</span></p>
<p><span>Another source described a similar incident that affected him and made him want to be interviewed for this investigation. “We understood that the target was home at 8 p.m. In the end, the air force bombed the house at 3 a.m. Then we found out [in that span of time] he had managed to move himself to another house with his family. There were two other families with children in the building we bombed.”</span></p>
<p><span>In previous wars in Gaza, after the assassination of human targets, Israeli intelligence would carry out bomb damage assessment (BDA) procedures — a routine post-strike check to see if the senior commander was killed and how many civilians were killed along with him. As revealed in a </span><a href="https://web.archive.org/web/20240403151726/https://www.972mag.com/gaza-soldiers-civilians-intelligence/"><span>previous +972 and Local Call investigation</span></a><span>, this involved listening in to phone calls of relatives who lost their loved ones. In the current war, however, at least in relation to junior militants marked using AI, sources say this procedure was abolished in order to save time. The sources said they did not know how many civilians were actually killed in each strike, and for the low-ranking suspected Hamas and PIJ operatives marked by AI, they did not even know whether the target himself was killed.</span></p>
<div>
<h3>Most read on +972</h3>

</div>
<p><span>“You don’t know exactly how many you killed, and who you killed,” an intelligence source </span><a href="https://web.archive.org/web/20240403151726/https://twitter.com/yuval_abraham/status/1750123648533324158?lang=en"><span>told Local Call</span></a><span> for a previous investigation published in January. “Only when it’s senior Hamas operatives do you follow the BDA procedure. In the rest of the cases, you don’t care. You get a report from the air force about whether the building was blown up, and that’s it. You have no idea how much collateral damage there was; you immediately move on to the next target. The emphasis was to create as many targets as possible, as quickly as possible.”</span></p>
<p><span>But while the Israeli military may move on from each strike without dwelling on the number of casualties, Amjad Al-Sheikh, the Shuja’iya resident who lost 11 of his family members in the Dec. 2 bombardment, said that he and his neighbors are still searching for corpses.</span></p>
<p><span>“Until now, there are bodies under the rubble,” he said. “Fourteen residential buildings were bombed with their residents inside. Some of my relatives and neighbors are still buried.”</span></p>

<div>
<p>
<h2>Subscribe to The Landline</h2>
<h2>+972's weekly newsletter</h2>
</p>



</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Lavender': The AI machine directing Israel's bombing spree in Gaza (634 pts)]]></title>
            <link>https://www.972mag.com/lavender-ai-israeli-army-gaza/</link>
            <guid>39918245</guid>
            <pubDate>Wed, 03 Apr 2024 14:50:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/">https://www.972mag.com/lavender-ai-israeli-army-gaza/</a>, See on <a href="https://news.ycombinator.com/item?id=39918245">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p>In partnership with</p>
<p><a href="https://www.mekomit.co.il/"><img src="https://static.972mag.com/www/uploads/2022/11/LC-LOGO-ENG.png" alt=""></a>
</p>
</div> <p><span>In 2021, a </span><a href="https://books.google.co.il/books/about/The_Human_Machine_Team_How_to_Create_Syn.html?id=hjl1zgEACAAJ&amp;redir_esc=y"><span>book</span></a><span> titled “The Human-Machine Team: How to Create Synergy Between Human and Artificial Intelligence That Will Revolutionize Our World” was released in English under the pen name “Brigadier General Y.S.” In it, the author — a man who we confirmed to be the current commander of the elite Israeli intelligence unit 8200 — makes the case for designing a special machine that could rapidly process massive amounts of data to generate thousands of potential “targets” for military strikes in the heat of a war. Such technology, he writes, would resolve what he described as a “human bottleneck for both locating the new targets and decision-making to approve the targets.”</span></p>
<p><span>Such a machine, it turns out, actually exists. A new investigation by +972 Magazine and Local Call reveals that the Israeli army has developed an artificial intelligence-based program known as “Lavender,” unveiled here for the first time. According to six Israeli intelligence officers, who have all served in the army during the current war on the Gaza Strip and had first-hand involvement with the use of AI to generate targets for assassination, Lavender has played a central role in the unprecedented bombing of Palestinians, especially during the early stages of the war. In fact, according to the sources, its influence on the military’s operations was such that they essentially treated the outputs of the AI machine “as if it were a human decision.”</span></p>
<p><span>Formally, the Lavender system is designed to mark all suspected operatives in the military wings of Hamas and Palestinian Islamic Jihad (PIJ), including low-ranking ones, as potential bombing targets. The sources told +972 and Local Call that, during the first weeks of the war, the army almost completely relied on Lavender, which clocked as many as 37,000 Palestinians as suspected militants — and their homes — for possible air strikes.</span></p>
<p><span>During the early stages of the war, the army gave sweeping approval for officers to adopt Lavender’s kill lists, with no requirement to thoroughly check why the machine made those choices or to examine the raw intelligence data on which they were based. One source stated that human personnel often served only as a “rubber stamp” for the machine’s decisions, adding that, normally, they would personally devote only about “20 seconds” to each target before authorizing a bombing — just to make sure the Lavender-marked target is male. This was despite knowing that the system makes what are regarded as “errors” in approximately 10 percent of cases, and is known to occasionally mark individuals who have merely a loose connection to militant groups, or no connection at all.</span></p>
<p><span>Moreover, the Israeli army systematically attacked the targeted individuals while they were in their homes — usually at night while their whole families were present — rather than during the course of military activity. According to the sources, this was because, from what they regarded as an intelligence standpoint, it was easier to locate the individuals in their private houses. Additional automated systems, including one called “Where’s Daddy?” also revealed here for the first time, were used specifically to track the targeted individuals and carry out bombings when they had entered their family’s residences.</span></p>
<div id="attachment_177456"><p><a href="https://static.972mag.com/www/uploads/2024/04/F231117ARK97-1.jpg" data-featherlight="image"><img title="Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/F231117ARK97-1-1280x853.jpg" alt="Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians transport the wounded and try to put out a fire after an Israeli airstrike on a house in the Shaboura refugee camp in the city of Rafah, southern Gaza Strip, November 17, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>The result, as the sources testified, is that thousands of Palestinians — most of them women and children or people who were not involved in the fighting — were wiped out by Israeli airstrikes, especially during the first weeks of the war, because of the AI program’s decisions.</span></p>
<p><span>“We were not interested in killing [Hamas] operatives only when they were in a military building or engaged in a military activity,” A., an intelligence officer, told +972 and Local Call. “On the contrary, the IDF bombed them in homes without hesitation, as a first option. It’s much easier to bomb a family’s home. The system is built to look for them in these situations.”</span></p>
<p><span>The Lavender machine joins another AI system, “The Gospel,” about which information was revealed in a </span><a href="https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/"><span>previous investigation</span></a><span> by +972 and Local Call in November 2023, as well as in the Israeli military’s own </span><a href="https://www.israeldefense.co.il/node/57256#google_vignette"><span>publications</span></a><span>. A fundamental difference between the two systems is in the definition of the target: whereas The Gospel marks buildings and structures that the army claims militants operate from, Lavender marks people — and puts them on a kill list.&nbsp;</span></p>
<p><span>In addition, according to the sources, when it came to targeting alleged junior militants marked by Lavender, the army preferred to only use unguided missiles, commonly known as “dumb” bombs (in contrast to “smart” precision bombs), which can destroy entire buildings on top of their occupants and cause significant casualties. “You don’t want to waste expensive bombs on unimportant people — it’s very expensive for the country and there’s a shortage [of those bombs],” said C., one of the intelligence officers. Another source said that they had personally authorized the bombing of “hundreds” of private homes of alleged junior operatives marked by Lavender, with many of these attacks killing civilians and entire families as “collateral damage.”</span></p>
<p><span>In an unprecedented move, according to two of the sources, the army also decided during the first weeks of the war that, for every junior Hamas operative that Lavender marked, it was permissible to kill up to 15 or 20 civilians; in the past, the military did not authorize any “collateral damage” during assassinations of low-ranking militants. The sources added that, in the event that the target was a senior Hamas official with the rank of battalion or brigade commander, the army on several occasions authorized the killing of more than 100 civilians in the assassination of a single commander.</span></p>
<div id="attachment_177452"><p><a href="https://static.972mag.com/www/uploads/2024/03/F231024ARK004.jpg" data-featherlight="image"><img title="Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/03/F231024ARK004-1280x853.jpg" alt="Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians wait to receive the bodies of their relatives who were killed in an Israeli airstrike, at Al-Najjar Hospital in Rafah, southern Gaza Strip, October 24, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>The following investigation is organized according to the six chronological stages of the Israeli army’s highly automated target production in the early weeks of the Gaza war. First, we explain the Lavender machine itself, which marked tens of thousands of Palestinians using AI. Second, we reveal the “Where’s Daddy?” system, which tracked these targets and signaled to the army when they entered their family homes. Third, we describe how “dumb” bombs were chosen to strike these homes.&nbsp;</span></p>
<p><span>Fourth, we explain how the army loosened the permitted number of civilians who could be killed during the bombing of a target. Fifth, we note how automated software inaccurately calculated the amount of non-combatants in each household. And sixth, we show how on several occasions, when a home was struck, usually at night, the individual target was sometimes not inside at all, because military officers did not verify the information in real time.</span></p>
<h3><span>STEP 1: GENERATING TARGETS</span></h3>
<h3>‘Once you go automatic, target generation goes crazy’</h3>
<p><span>In the Israeli army, the term “human target” referred in the past to a senior military operative who, according to the rules of the military’s International Law Department, can be killed in their private home even if there are civilians around. Intelligence sources told +972 and Local Call that during Israel’s previous wars, since this was an “especially brutal” way to kill someone — often by killing an entire family alongside the target — such human targets were marked very carefully and only senior military commanders were bombed in their homes, to maintain the principle of proportionality under international law.</span></p>
<p><span>But after October 7 — when Hamas-led militants launched a deadly assault on southern Israeli communities, killing around 1,200 people and abducting 240 — the army, the sources said, took a dramatically different approach. Under “Operation Iron Swords,” the army decided to designate all operatives of Hamas’ military wing as human targets, regardless of their rank or military importance. And that changed everything.</span></p>
<p><span>The new policy also posed a technical problem for Israeli intelligence. In previous wars, in order to authorize the assassination of a single human target, an officer had to go through a complex and lengthy “incrimination” process: cross-check evidence that the person was indeed a senior member of Hamas’ military wing, find out where he lived, his contact information, and finally know when he was home in real time. When the list of targets numbered only a few dozen senior operatives, intelligence personnel could individually handle the work involved in incriminating and locating them.</span></p>
<div id="attachment_177464"><p><a href="https://static.972mag.com/www/uploads/2024/04/main_image51785_4WLiR7887N.jpg" data-featherlight="image"><img title="Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/main_image51785_4WLiR7887N-1280x853.jpg" alt="Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun)" width="768" height="512" data-caption="Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun)"></a></p><p>Palestinians try to rescue survivors and pull bodies from the rubble after Israeli airstrikes hit buildings near Al-Aqsa Martyrs Hospital in Deir al-Balah, central Gaza, October 22, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>However, once the list was expanded to include tens of thousands of lower-ranking operatives, the Israeli army figured it had to rely on automated software and artificial intelligence. The result, the sources testify, was that the role of human personnel in incriminating Palestinians as military operatives was pushed aside, and AI did most of the work instead. According to four of the sources who spoke to +972 and Local Call, Lavender — which was developed to create human targets in the current war — has marked some 37,000 Palestinians as suspected “Hamas militants,” most of them junior, for assassination (the IDF Spokesperson denied the existence of such a kill list in a statement to +972 and Local Call).</span></p>
<p><span>“We didn’t know who the junior operatives were, because Israel didn’t track them routinely [before the war],” explained senior officer B. to +972 and Local Call, illuminating the reason behind the development of this particular target machine for the current war. “They wanted to allow us to attack [the junior operatives] automatically. That’s the Holy Grail. Once you go automatic, target generation goes crazy.”</span></p>
<p><span>The sources said that the approval to automatically adopt Lavender’s kill lists, which had previously been used only as an auxiliary tool, was granted about two weeks into the war, after intelligence personnel “manually” checked the accuracy of a random sample of several hundred targets selected by the AI system. When that sample found that Lavender’s results had reached 90 percent accuracy in identifying an individual’s affiliation with Hamas, the army authorized the sweeping use of the system. From that moment, sources said that if Lavender decided an individual was a militant in Hamas, they were essentially asked to treat that as an order, with no requirement to independently check why the machine made that choice or to examine the raw intelligence data on which it is based.</span></p>
<p><span>“At 5 a.m., </span><span>[the air force]</span><span> would come and bomb all the houses that we had marked,” B. said. “We took out thousands of people. We didn’t go through them one by one — we put everything into automated systems, and as soon as one of [the marked individuals] was at home, he immediately became a target. We bombed him and his house.”</span></p>
<p><span>The deadly results of this loosening of restrictions in the early stage of the war were staggering. According to data from the Palestinian Health Ministry in Gaza, on which the Israeli army has </span><a href="https://www.mekomit.co.il/%d7%94%d7%a6%d7%91%d7%90-%d7%91%d7%93%d7%a7-%d7%95%d7%9e%d7%a6%d7%90-%d7%a9%d7%93%d7%99%d7%95%d7%95%d7%97%d7%99-%d7%94%d7%94%d7%a8%d7%95%d7%92%d7%99%d7%9d-%d7%91%d7%9e%d7%a9%d7%a8%d7%93-%d7%94%d7%91/"><span>relied almost exclusively</span></a><span> since the beginning of the war, Israel killed some 15,000 Palestinians — almost half of the death toll so far — in the </span><a href="https://www.ochaopt.org/content/hostilities-gaza-strip-and-israel-flash-update-50"><span>first six weeks</span></a><span> of the war, up until a week-long ceasefire was agreed on Nov. 24.</span></p>
<div id="attachment_177466"><p><a href="https://static.972mag.com/www/uploads/2024/04/main_image52901_dXsGme0t6F.jpg" data-featherlight="image"><img title="Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/main_image52901_dXsGme0t6F-1280x853.jpg" alt="Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)" width="768" height="512" data-caption="Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)"></a></p><p>Massive destruction is seen in Al-Rimal popular district of Gaza City after it was targeted by airstrikes carried out by Israeli colonial, October 10, 2023. (Mohammed Zaanoun)</p>
</div>
<h3>‘The more information and variety, the better’</h3>
<p><span>The Lavender software analyzes information collected on most of the 2.3 million residents of the Gaza Strip through a system of mass surveillance, then assesses and ranks the likelihood that each particular person is active in the military wing of Hamas or PIJ. According to sources, the machine gives almost every single person in Gaza a rating from 1 to 100, expressing how likely it is that they are a militant.&nbsp;</span></p>
<p><span>Lavender learns to identify characteristics of known Hamas and PIJ operatives, whose information was fed to the machine as training data, and then to locate these same characteristics — also called “features” — among the general population, the sources explained. An individual found to have several different incriminating features will reach a high rating, and thus automatically becomes a potential target for assassination.&nbsp;</span></p>
<p><span>In “The Human-Machine Team,” the book referenced at the beginning of this article, the current commander of Unit 8200 advocates for such a system without referencing Lavender by name. (The commander himself also isn’t named, but five sources in 8200 confirmed that the commander is the author, as </span><a href="https://www.haaretz.com/israel-news/2021-10-01/ty-article/.highlight/top-israeli-intel-officer-goes-where-no-ones-gone-before-and-its-all-on-amazon/0000017f-e1fb-df7c-a5ff-e3fb21210000"><span>reported</span></a><span> also by Haaretz.) Describing human personnel as a “bottleneck” that limits the army’s capacity during a military operation, The commander laments: “We [humans] cannot process so much information. It doesn’t matter how many people you have tasked to produce targets during the war — you still cannot produce enough targets per day.”</span></p>
<p><span>The solution to this problem, he says, is artificial intelligence. The book offers a short guide to building a “target machine,” similar in description to Lavender, based on AI and machine-learning algorithms. Included in this guide are several examples of the “hundreds and thousands” of features that can increase an individual’s rating, such as being in a Whatsapp group with a known militant, changing cell phone every few months, and changing addresses frequently.&nbsp;</span></p>
<p><span>“The more information, and the more variety, the better,” the commander writes. “Visual information, cellular information, social media connections, battlefield information, phone contacts, photos.” While humans select these features at first, the commander continues, over time the machine will come to identify features on its own. This, he says, can enable militaries to create “tens of thousands of targets,” while the actual decision as to whether or not to attack them will remain a human one.</span></p>
<p><span>The book isn’t the only time a senior Israeli commander hinted at the existence of human target machines like Lavender. +972 and Local Call have obtained footage of a private lecture given by the commander of Unit 8200’s secretive Data Science and AI center, “Col. Yoav,” at Tel Aviv University’s AI week in 2023, which was </span><a href="https://www.geektime.co.il/idf-fights-hamas-with-ai-and-data-science/"><span>reported on</span></a><span> at the time in the Israeli media.</span></p>
<p><span>In the lecture, the commander speaks about a new, sophisticated target machine used by the Israeli army that detects “dangerous people” based on their likeness to existing lists of known militants on which it was trained. “Using the system, we managed to identify Hamas missile squad commanders,” Col. Yoav said in the lecture, referring to Israel’s May 2021 military operation in Gaza, when the machine was used for the first time.&nbsp;</span></p>
<div id="attachment_177470"><p><a href="https://static.972mag.com/www/uploads/2024/04/Slide-33.png" data-featherlight="image"><img title="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call." decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/Slide-33.png" alt="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023." width="1203" height="650" data-caption="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call."></a></p><p>Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call.</p>
</div>
<div id="attachment_177469"><p><a href="https://static.972mag.com/www/uploads/2024/04/Slide-44.png" data-featherlight="image"><img title="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call." decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/Slide-44.png" alt="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call." width="1201" height="650" data-caption="Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call."></a></p><p>Slides from a lecture presentation by the commander of IDF Unit 8200’s Data Science and AI center at Tel Aviv University in 2023, obtained by +972 and Local Call.</p>
</div>
<p><span>The lecture presentation slides, also obtained by +972 and Local Call, contain illustrations of how the machine works: it is fed data about existing Hamas operatives, it learns to notice their features, and then it rates other Palestinians based on how similar they are to the militants.&nbsp;</span></p>
<p><span>“We rank the results and determine the threshold [at which to attack a target],” Col. Yoav said in the lecture, emphasizing that “eventually, people of flesh and blood take the decisions. In the defense realm, ethically speaking, we put a lot of emphasis on this. These tools are meant to help [intelligence officers] break their barriers.”&nbsp;</span></p>
<p><span>In practice, however, sources who have used Lavender in recent months say human agency and precision were substituted for mass target creation and lethality.</span></p>
<h3>‘There was no “zero-error” policy’</h3>
<p><span>B., a senior officer who used Lavender, echoed to +972 and Local Call that in the current war, officers were not required to independently review the AI system’s assessments, in order to save time and enable the mass production of human targets without hindrances.&nbsp;</span></p>
<p><span>“Everything was statistical, everything was neat — it was very dry,” B. said. He noted that this lack of supervision was permitted despite internal checks showing that Lavender’s calculations were considered accurate only 90 percent of the time; in other words, it was known in advance that 10 percent of the human targets slated for assassination were not members of the Hamas military wing at all.</span></p>
<p><span>For example, sources explained that the Lavender machine sometimes mistakenly flagged individuals who had communication patterns similar to known Hamas or PIJ operatives — including police and civil defense workers, militants’ relatives, residents who happened to have a name and nickname identical to that of an operative, and Gazans who used a device that once belonged to a Hamas operative.&nbsp;</span></p>
<p><span>“How close does a person have to be to Hamas to be [considered by an AI machine to be] affiliated with the organization?” said one source critical of Lavender’s inaccuracy. “It’s a vague boundary. Is a person who doesn’t receive a salary from Hamas, but helps them with all sorts of things, a Hamas operative? Is someone who was in Hamas in the past, but is no longer there today, a Hamas operative? Each of these features — characteristics that a machine would flag as suspicious — is inaccurate.”</span></p>
<div id="attachment_177451"><p><a href="https://static.972mag.com/www/uploads/2024/03/F240224ARK09.jpg" data-featherlight="image"><img title="Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/03/F240224ARK09-1280x853.jpg" alt="Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians at the site of an Israeli airstrike in Rafah, in the southern Gaza Strip, February 24, 2024. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>Similar problems exist with the ability of target machines to assess the phone used by an individual marked for assassination. “In war, Palestinians change phones all the time,” said the source. “People lose contact with their families, give their phone to a friend or a wife, maybe lose it. There is no way to rely 100 percent on the automatic mechanism that determines which [phone] number belongs to whom.”</span></p>
<p><span>According to the sources, the army knew that the minimal human supervision in place would not discover these faults. “There was no ‘zero-error’ policy. Mistakes were treated statistically,” said a source who used Lavender. “Because of the scope and magnitude, the protocol was that even if you don’t know for sure that the machine is right, you know that statistically it’s fine. So you go for it.”</span></p>
<p><span>“It has proven itself,” said B., the senior source. “There’s something about the statistical approach that sets you to a certain norm and standard. There has been an illogical amount of [bombings] in this operation. This is unparalleled, in my memory. And I have much more trust in a statistical mechanism than a soldier who lost a friend two days ago. Everyone there, including me, lost people on October 7. The machine did it coldly. And that made it easier.”</span></p>
<p><span>Another intelligence source, who defended the reliance on the Lavender-generated kill lists of Palestinian suspects, argued that it was worth investing an intelligence officer’s time only to verify the information if the target was a senior commander in Hamas. “But when it comes to a junior militant, you don’t want to invest manpower and time in it,” he said. “In war, there is no time to incriminate every target. So you’re willing to take the margin of error of using artificial intelligence, risking collateral damage and civilians dying, and risking attacking by mistake, and to live with it.”</span></p>
<p>B. said that the reason for this automation was a constant push to generate more targets for assassination. “In a day without targets [whose feature rating was sufficient to authorize a strike], we attacked at a lower threshold. We were constantly being pressured: ‘Bring us more targets.’ They really shouted at us. We finished [killing] our targets very quickly.”</p>
<p><span>He explained that when lowering the rating threshold of Lavender, it would mark more people as targets for strikes. “At its peak, the system managed to generate 37,000 people as potential human targets,” said B. “But the numbers changed all the time, because it depends on where you set the bar of what a Hamas operative is. There were times when a Hamas operative was defined more broadly, and then the machine started bringing us all kinds of civil defense personnel, police officers, on whom it would be a shame to waste bombs. They help the Hamas government, but they don’t really endanger soldiers.”</span></p>
<div id="attachment_177448"><p><a href="https://static.972mag.com/www/uploads/2024/03/F240318ARK048.jpg" data-featherlight="image"><img title="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/03/F240318ARK048-1280x851.jpg" alt="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" width="768" height="511" data-caption="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)</p>
</div>
<h3>‘We only checked that the target was a man’</h3>
<p><span>The Israeli military flatly rejects these claims. In a statement to +972 and Local Call, the IDF Spokesperson denied using artificial intelligence to incriminate targets, saying these are merely “auxiliary tools that assist officers in the process of incrimination.” The statement went on: “In any case, an independent examination by an [intelligence] analyst is required, which verifies that the identified targets are legitimate targets for attack, in accordance with the conditions set forth in IDF directives and international law.&nbsp;&nbsp;</span></p>
<p><span>However, sources said that the only human supervision protocol in place before bombing the houses of suspected “junior” militants marked by Lavender was to conduct a single check: ensuring that the AI-selected target is male rather than female. The assumption in the army was that if it were a woman, the machine had likely made a mistake, because there are no women among the ranks of the military wings of Hamas and PIJ.</span></p>
<p><span>“A human being had to [verify the target] for just a few seconds,” B. said, explaining that this became the protocol after realizing the Lavender system was “getting it right” most of the time. “At first, we did checks to ensure that the machine didn’t get confused. But at some point we relied on the automatic system, and we only checked that [the target] was a man — that was enough. It doesn’t take a long time to tell if someone has a male or a female voice.”&nbsp;</span></p>
<p><span>To conduct the male/female check, B. claimed that in the current war, “I would invest 20 seconds for each target at this stage, and do dozens of them every day. I had zero added value as a human, apart from being a stamp of approval. It saved a lot of time. If [the operative] came up in the automated mechanism, and I checked that he was a man, there would be permission to bomb him, subject to an examination of collateral damage.”</span></p>
<div id="attachment_177459"><p><a href="https://static.972mag.com/www/uploads/2024/04/F231120ARK005-1.jpg" data-featherlight="image"><img title="Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/F231120ARK005-1-1280x853.jpg" alt="Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians emerge from the rubble of houses destroyed in Israeli airstrikes in the city of Rafah, southern Gaza Strip, November 20, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>In practice, sources said this meant that for civilian men marked in error by Lavender, there was no supervising mechanism in place to detect the mistake.&nbsp;</span></p>
<h3><span>STEP 2: LINKING TARGETS TO FAMILY HOMES</span></h3>
<h3>‘Most of the people you killed were women and children’</h3>
<p><span>The next stage in the Israeli army’s assassination procedure is identifying where to attack the targets that Lavender generates.</span></p>
<p><span>In a statement to +972 and Local Call, the IDF Spokesperson claimed in response to this article that “Hamas places its operatives and military assets in the heart of the civilian population, systematically uses the civilian population as human shields, and conducts fighting from within civilian structures, including sensitive sites such as hospitals, mosques, schools and UN facilities. The IDF is bound by and acts according to international law, directing its attacks only at military targets and military operatives.”&nbsp;</span></p>
<p><span>The six sources we spoke to echoed this to some degree, saying that Hamas’ extensive </span><a href="https://www.nytimes.com/interactive/2024/02/12/world/middleeast/gaza-tunnel-israel-hamas.html"><span>tunnel system</span></a><span> deliberately passes under hospitals and schools; that Hamas militants use ambulances to get around; and that countless military assets have been situated near civilian buildings. The sources argued that many Israeli strikes kill civilians as a result of these tactics by Hamas — a characterization that human rights groups <a href="https://www.hrw.org/news/2024/03/19/israeli-forces-conduct-gaza">warn</a> evades Israel’s onus for inflicting the casualties.&nbsp;</span></p>
<p><span>However, in contrast to the Israeli army’s official statements, the sources explained that a major reason for the unprecedented death toll from Israel’s current bombardment is the fact that the army has systematically attacked targets in their private homes, alongside their families — in part because it was easier from an intelligence standpoint to mark family houses using automated systems.</span></p>
<p><span>Indeed, several sources emphasized that, as opposed to numerous cases of Hamas operatives engaging in military activity from civilian areas, in the case of systematic assassination strikes, the army routinely made the active choice to bomb suspected militants when inside civilian households from which no military activity took place. This choice, they said, was a reflection of the way Israel’s system of mass surveillance in Gaza is designed.</span></p>
<div id="attachment_177465"><p><a href="https://static.972mag.com/www/uploads/2024/04/main_image51496_c8EQed2mC6.jpg" data-featherlight="image"><img title="Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/main_image51496_c8EQed2mC6-1280x853.jpg" alt="Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)" width="768" height="512" data-caption="Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)"></a></p><p>Palestinians rush to bring the wounded, including many children, to Al-Shifa Hospital in Gaza City as Israeli forces continue pounding the Gaza Strip, October 11, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>The sources told +972 and Local Call that since everyone in Gaza had a private house with which they could be associated, the army’s surveillance systems could easily and automatically “link” individuals to family houses. In order to identify the moment operatives enter their houses in real time, various additional automatic softwares have been developed. These programs track thousands of individuals simultaneously, identify when they are at home, and send an automatic alert to the targeting officer, who then marks the house for bombing. One of several of these tracking softwares, revealed here for the first time, is called “Where’s Daddy?”&nbsp;</span></p>
<p><span>“You put hundreds [of targets] into the system and wait to see who you can kill,” said one source with knowledge of the system. “It’s called broad hunting: you copy-paste from the lists that the target system produces.”</span></p>
<p><span>Evidence of this policy is also clear from the data: during the first month of the war, more than half of the fatalities — 6,120 people — belonged to 1,340 families, many of which were completely wiped out while inside their homes, according to </span><a href="https://www.ochaopt.org/content/hostilities-gaza-strip-and-israel-reported-impact-day-45"><span>UN figures</span></a><span>. The proportion of entire </span><a href="https://www.972mag.com/gaza-families-bombing-humanitarian-crisis/"><span>families</span></a><span> bombed in their houses in the current war is much higher </span><a href="https://www.btselem.org/download/201501_black_flag_eng.pdf"><span>than in the 2014 Israeli operation</span></a><span> in Gaza, further suggesting the prominence of this policy.</span></p>
<p><span>Another source said that each time the pace of assassinations waned, more targets were added to systems like Where’s Daddy? to locate individuals that entered their homes and could therefore be bombed. He said that the decision of who to put into the tracking systems could be made by relatively low-ranking officers in the military hierarchy.&nbsp;</span></p>
<p><span>“One day, totally of my own accord, I added something like 1,200 new targets to the [tracking] system, because the number of attacks [we were conducting] decreased,” the source said. “That made sense to me. In retrospect, it seems like a serious decision I made. And such decisions were not made at high levels.”</span></p>
<p><span>The sources said that in the first two weeks of the war, “several thousand” targets were initially inputted into locating programs like Where’s Daddy?. These included all the members of Hamas’ elite special forces unit the Nukhba, all of Hamas’ anti-tank operatives, and anyone who entered Israel on October 7. But before long, the kill list was drastically expanded.&nbsp;</span></p>
<p><span>“In the end it was everyone [marked by Lavender],” one source explained. “Tens of thousands. This happened a few weeks later, when the [Israeli] brigades entered Gaza, and there were already fewer uninvolved people [i.e. civilians] in the northern areas.” According to this source, even some minors were marked by Lavender as targets for bombing. “Normally, operatives are over the age of 17, but that was not a condition.”</span></p>
<div id="attachment_175004"><p><a href="https://static.972mag.com/www/uploads/2023/11/main_image51646_zQb2EotVH7.jpg" data-featherlight="image"><img title="Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2023/11/main_image51646_zQb2EotVH7-1280x853.jpg" alt="Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)" width="768" height="512" data-caption="Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)"></a></p><p>Wounded Palestinians are treated on the floor due to overcrowding at Al-Shifa Hospital, Gaza City, central Gaza Strip, October 18, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>Lavender and systems like Where’s Daddy? were thus combined with deadly effect, killing entire families, sources said. By adding a name from the Lavender-generated lists to the Where’s Daddy? home tracking system, A. explained, the marked person would be placed under ongoing surveillance, and could be attacked as soon as they set foot in their home, collapsing the house on everyone inside.</span></p>
<p><span>“Let’s say you calculate [that there is one] Hamas [operative] plus 10 [civilians in the house],” A. said. “Usually, these 10 will be women and children. So absurdly, it turns out that most of the people you killed were women and children.”</span></p>
<h3><span>STEP 3: CHOOSING A WEAPON</span></h3>
<h3>‘We usually carried out the attacks with “dumb bombs”’</h3>
<p><span>Once Lavender has marked a target for assassination, army personnel have verified that they are male, and tracking software has located the target in their home, the next stage is picking the munition with which to bomb them.</span></p>
<p><span>In December 2023, </span><a href="https://edition.cnn.com/2023/12/13/politics/intelligence-assessment-dumb-bombs-israel-gaza/index.html"><span>CNN reported</span></a> <span>that according to U.S. intelligence estimates, about 45 percent of the munitions used by the Israeli air force in Gaza were “dumb” bombs, which are known to cause more collateral damage than guided bombs. In response to the CNN report, an army spokesperson quoted in the article said: “A</span><span>s a military committed to international law and a moral code of conduct, we are devoting vast resources to minimizing harm to the civilians that Hamas has forced into the role of human shields. Our war is against Hamas, not against the people of Gaza.”</span></p>
<p><span>Three intelligence sources, however, told +972 and Local Call that junior operatives marked by Lavender were assassinated only with dumb bombs, in the interest of saving more expensive armaments. The implication, one source explained, was that the army would not strike a junior target if they lived in a high-rise building, because the army did not want to spend a more precise and expensive “floor bomb” (with more limited collateral effect) to kill him. But if a junior target lived in a building with only a few floors, the army was authorized to kill him and everyone in the building with a dumb bomb.</span></p>
<div id="attachment_177445"><p><a href="https://static.972mag.com/www/uploads/2024/03/F240318ARK043.jpg" data-featherlight="image"><img title="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/03/F240318ARK043-1280x851.jpg" alt="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)" width="768" height="511" data-caption="Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians at the site of a building destroyed by an Israeli airstrike in Rafah, in the southern Gaza Strip, March 18, 2024. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>“It was like that with all the junior targets,” testified C., who used various automated programs in the current war. “The only question was, is it possible to attack the building in terms of collateral damage? Because we usually carried out the attacks with dumb bombs, and that meant literally destroying the whole house on top of its occupants. But even if an attack is averted, you don’t care — you immediately move on to the next target. Because of the system, the targets never end. You have another 36,000 waiting.”</span></p>
<h3><span>STEP 4: AUTHORIZING CIVILIAN CASUALTIES</span></h3>
<h3>‘We attacked almost without considering collateral damage’</h3>
<p><span>One source said that when attacking junior operatives, including those marked by AI systems like Lavender, the number of civilians they were allowed to kill alongside each target was fixed during the initial weeks of the war at up to 20. Another source claimed the fixed number was up to 15. These “collateral damage degrees,” as the military calls them, were applied broadly to all suspected junior militants, the sources said, regardless of their rank, military importance, and age, and with no specific case-by-case examination to weigh the military advantage of assassinating them against the expected harm to civilians.&nbsp;</span></p>
<p><span>According to A., who was an officer in a target operation room in the current war, the army’s international law department has never before given such “sweeping approval” for such a high collateral damage degree. “It’s not just that you can kill any person who is a Hamas soldier, which is clearly permitted and legitimate in terms of international law,” A. said. “But they directly tell you: ‘You are allowed to kill them along with many civilians.’&nbsp;</span></p>
<p><span>“Every person who wore a Hamas uniform in the past year or two could be bombed with 20 [civilians killed as] collateral damage, even without special permission,” A. continued. “In practice, the principle of proportionality did not exist.”</span></p>
<p><span>According to A., this was the policy for most of the time that he served. Only later did the military lower the collateral damage degree. “In this calculation, it could also be 20 children for a junior operative … It really wasn’t like that in the past,” A. explained. Asked about the security rationale behind this policy, A. replied: “Lethality.”</span></p>
<div id="attachment_177453"><p><a href="https://static.972mag.com/www/uploads/2024/03/F231107ARK20.jpg" data-featherlight="image"><img title="Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/03/F231107ARK20-1280x853.jpg" alt="Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians wait to receive the bodies of their relatives who were killed in Israeli airstrikes, at Al-Najjar Hospital in Rafah, southern Gaza Strip, November 7, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>The predetermined and fixed collateral damage degree helped accelerate the mass creation of targets using the Lavender machine, sources said, because it saved time. B. claimed that the number of civilians they were permitted to kill per suspected junior militant marked by AI in the first week of the war, was fifteen, but that this number “went up and down” over time.&nbsp;</span></p>
<p><span>“At first we attacked almost without considering collateral damage,” B. said of the first week after October 7. “In practice, you didn’t really count people [in each house that is bombed], because you couldn’t really tell if they’re at home or not. After a week, restrictions on collateral damage began. The number dropped [from 15] to five, which made it really difficult for us to attack, because if the whole family was home, we couldn’t bomb it. Then they raised the number again.”</span></p>
<h3>‘We knew we would kill over 100 civilians’</h3>
<p><span>Sources told +972 and Local Call that now, partly due to American pressure, the Israeli army is no longer mass-generating junior human targets for bombing in civilian homes. The fact that most homes in the Gaza Strip were already destroyed or damaged, and almost the entire population has been displaced, also impaired the army’s ability to rely on intelligence databases and automated house-locating programs.&nbsp;</span></p>
<p><span>E. claimed that the massive bombardment of junior militants took place only in the first week or two of the war, and then was stopped mainly so as not to waste bombs. “There is a munitions economy,” E. said. “They were always afraid that there would be [a war] in the northern arena [with Hezbollah in Lebanon]. They don’t attack these kinds of [junior] people at all anymore.”&nbsp;</span></p>
<p><span>However, airstrikes against senior ranking Hamas commanders are still ongoing, and sources said that for these attacks, the military is authorizing the killing of “hundreds” of civilians per target — an official policy for which there is no historical precedent in Israel, or even in recent U.S. military operations.</span></p>
<p><span>“In the bombing of the commander of the Shuja’iya Battalion, we knew that we would kill over 100 civilians,” B. recalled of a Dec. 2 bombing that the IDF Spokesperson </span><a href="https://www.timesofisrael.com/liveblog_entry/idf-strike-kills-gazan-terrorist-responsible-for-attack-that-killed-oron-shaul-in-2014/"><span>said</span></a><span> was aimed at assassinating Wisam Farhat. “For me, psychologically, it was unusual. Over 100 civilians — it crosses some red line.”</span></p>
<div id="attachment_174306"><p><a href="https://static.972mag.com/www/uploads/2023/10/F231009AM354.jpg" data-featherlight="image"><img title="A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2023/10/F231009AM354-1280x853.jpg" alt="A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90)" width="768" height="512" data-caption="A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90) "></a></p><p>A ball of fire and smoke rises during Israeli airstrikes in the Gaza Strip, October 9, 2023. (Atia Mohammed/Flash90)</p>
</div>
<p><span>Amjad Al-Sheikh, a young Palestinian from Gaza, said many of his family members were killed in that bombing. A resident of Shuja’iya, east of Gaza City, he was at a local supermarket that day when he heard five blasts that shattered the glass windows.&nbsp;</span></p>
<p><span>“I ran to my family’s house, but there were no buildings there anymore,” Al-Sheikh told +972 and Local Call. “The street was filled with screams and smoke. Entire residential blocks turned to mountains of rubble and deep pits. People began to search in the cement, using their hands, and so did I, looking for signs of my family’s house.&nbsp;</span></p>
<p><span>Al-Sheikh’s wife and baby daughter survived — protected from the rubble by a closet that fell on top of them — but he found 11 other members of his family, among them his sisters, brothers, and their young children, dead under the rubble. </span><a href="https://www.btselem.org/hebrew/gaza_strip/20231205_israel_is_not_fighting_against_hamas_but_against_civilians_implementing_a_criminal_policy_of_bombings"><span>According to</span></a><span> the human rights group B’Tselem, the bombing that day destroyed dozens of buildings, killed dozens of people, and buried hundreds under the ruins of their homes.</span></p>
<h3>‘Entire families were killed’</h3>
<p><span>Intelligence sources told +972 and Local Call they took part in even deadlier strikes. In order to assassinate Ayman Nofal, the commander of Hamas’ Central Gaza Brigade, a source said the army authorized the killing of approximately 300 civilians, </span><a href="https://www.ynet.co.il/news/article/ryxl6b2116"><span>destroying several buildings</span></a><span> in airstrikes on Al-Bureij refugee camp on Oct. 17 based on an imprecise pinpointing of Nofal. Satellite footage and </span><a href="https://twitter.com/Roaastudies/status/1714253580792643820"><span>videos</span></a><span> from the scene show the destruction of several large multi-storey apartment buildings.</span></p>
<p><span>“Between 16 to 18 houses were wiped out in the attack,” Amro Al-Khatib, a resident of the camp, told +972 and Local Call. “We couldn’t tell one apartment from the other — they all got mixed up in the rubble, and we found human body parts everywhere.”</span></p>
<p><span>In the aftermath, Al-Khatib recalled around 50 dead bodies being pulled out of the rubble, and around 200 people wounded, many of them gravely. But that was just the first day. The camp’s residents spent five days pulling the dead and injured out, he said.</span></p>
<div id="attachment_177462"><p><a href="https://static.972mag.com/www/uploads/2024/04/main_image52153_Ke1nD80YfY.jpg" data-featherlight="image"><img title="Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/04/main_image52153_Ke1nD80YfY-1280x853.jpg" alt="Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)" width="768" height="512" data-caption="Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)"></a></p><p>Palestinians digging with bear hands find a dead body in the rubble after an Israeli airstrike which killed dozens Palestinians in the middle of Al-Maghazi refugee camp, central Gaza Strip, November 5, 2023. (Mohammed Zaanoun/Activestills)</p>
</div>
<p><span>Nael Al-Bahisi, a paramedic, was one of the first on the scene. He counted between 50-70 casualties on that first day. “At a certain moment, we understood the target of the strike was Hamas commander Ayman Nofal,” he told +972 and Local Call. “They killed him, and also many people who didn’t know he was there. Entire families with children were killed.”</span></p>
<p><span>Another intelligence source told +972 and Local Call that the army </span><a href="https://www.israelhayom.co.il/news/defense/article/14992654"><span>destroyed a high-rise building</span></a><span> in Rafah in mid-December, killing “dozens of civilians,” in order </span><a href="https://www.israelhayom.co.il/news/defense/article/14992654"><span>to try to kill</span></a><span> Mohammed Shabaneh, the commander of Hamas’ Rafah Brigade (it is not clear whether or not he was killed in the attack). Often, the source said, the senior commanders hide in tunnels that pass under civilian buildings, and therefore the choice to assassinate them with an airstrike necessarily kills civilians.</span></p>
<p><span>“Most of those injured were children,” said Wael Al-Sir, 55, who witnessed the large-scale strike believed by some Gazans to have been the assassination attempt. He told +972 and Local Call that the bombing on Dec. 20 destroyed an “entire residential block” and killed at least 10 children.</span></p>
<p><span>“There was a completely permissive policy regarding the casualties of [bombing] operations — so permissive that in my opinion it had an element of revenge,” D., an intelligence source, claimed. “The core of this was the assassinations of senior [Hamas and PIJ commanders] for whom they were willing to kill hundreds of civilians. We had a calculation: how many for a brigade commander, how many for a battalion commander, and so on.”</span></p>
<p><span>“There were regulations, but they were just very lenient,” said E., another intelligence source. “We’ve killed people with collateral damage in the high double digits, if not low triple digits. These are things that haven’t happened before.”</span></p>
<div id="attachment_175496"><p><a href="https://static.972mag.com/www/uploads/2023/11/F231022ARK013.jpg" data-featherlight="image"><img title="Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2023/11/F231022ARK013-1280x853.jpg" alt="Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians inspect their homes and try to rescue their relatives from under the rubble after an Israeli airstrike in the city of Rafah, southern Gaza Strip, October 22, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>Such a high rate of “collateral damage” is exceptional not only compared to what the Israeli army previously deemed acceptable, but also compared to the wars waged by the United States in Iraq, Syria, and Afghanistan.&nbsp;</span></p>
<p><span>General Peter Gersten, </span><span>Deputy Commander for Operations and Intelligence </span><span>in the operation to fight ISIS in Iraq and Syria, </span><a href="https://www.defensedaily.com/pentagon-removed-non-combatant-casualty-cut-off-value-doctrine-2018/pentagon/"><span>told</span></a><span> a U.S. defense magazine in 2021 that an attack with collateral damage of 15 civilians deviated from procedure; to carry it out, he had to obtain special permission from the head of the U.S. Central Command, General Lloyd Austin, who is now Secretary of Defense.&nbsp;</span></p>
<p><span>“With Osama Bin Laden, you’d have an NCV [Non-combatant Casualty Value] of 30, but if you had a low-level commander, his NCV was typically zero,” Gersten said. “We ran zero for the longest time.”</span></p>
<h3>‘We were told: “Whatever you can, bomb”’</h3>
<p><span>All the sources interviewed for this investigation said that Hamas’ massacres on October 7 and kidnapping of hostages greatly influenced the army’s fire policy and collateral damage degrees. “At first, the atmosphere was painful and vindictive,” said B., who was drafted into the army immediately after October 7, and served in a target operation room. “The rules were very lenient. They took down four buildings when they knew the target was in one of them. It was crazy.</span></p>
<p><span>“There was a dissonance: on the one hand, people here were frustrated that we were not attacking enough,” B. continued. “On the other hand, you see at the end of the day that another thousand Gazans have died, most of them civilians.”</span></p>
<p><span>“There was hysteria in the professional ranks,” said D., who was also drafted immediately after October 7. “They had no idea how to react at all. The only thing they knew to do was to just start bombing like madmen to try to dismantle Hamas’ capabilities.”</span></p>
<div id="attachment_174647"><p><a href="https://static.972mag.com/www/uploads/2023/10/F231019CG008.jpg" data-featherlight="image"><img title="Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2023/10/F231019CG008-1280x854.jpg" alt="Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)" width="768" height="512" data-caption="Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)"></a></p><p>Defence Minister Yoav Gallant speaks with Israeli soldiers at a staging area not far from the Gaza fence, October 19, 2023. (Chaim Goldberg/Flash90)</p>
</div>
<p>D. stressed that they were not explicitly told that the army’s goal was “revenge,” but expressed that “as soon as every target connected to Hamas becomes legitimate, and with almost any collateral damage being approved, it is clear to you that thousands of people are going to be killed. Even if officially every target is connected to Hamas, when the policy is so permissive, it loses all meaning.”</p>
<p><span>A. also used the word “revenge” to describe the atmosphere inside the army after October 7. “No one thought about what to do afterward, when the war is over, or how it will be possible to live in Gaza and what they will do with it,” A. said. “We were told: now we have to fuck up Hamas, no matter what the cost. Whatever you can, you bomb.”</span></p>
<p><span>B., the senior intelligence source, said that in retrospect, he believes this “disproportionate” policy of killing Palestinians in Gaza also endangers Israelis, and that this was one of the reasons he decided to be interviewed.</span></p>
<p><span>“In the short term, we are safer, because we hurt Hamas. But I think we’re less secure in the long run. I see how all the bereaved families in Gaza — which is nearly everyone — will raise the motivation for [people to join] Hamas 10 years down the line. And it will be much easier for [Hamas] to recruit them.”</span></p>
<p><span>In a statement to +972 and Local Call, the Israeli army denied much of what the sources told us, claiming that “each target is examined individually, while an individual assessment is made of the military advantage and collateral damage expected from the attack … The IDF does not carry out attacks when the collateral damage expected from the attack is excessive in relation to the military advantage.”</span></p>
<h3><span>STEP 5: CALCULATING COLLATERAL DAMAGE</span></h3>
<h3>‘The model was not connected to reality’</h3>
<p><span>According to the intelligence sources, the Israeli army’s calculation of the number of civilians expected to be killed in each house alongside a target — a procedure examined in a </span><a href="https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/"><span>previous investigation</span></a><span> by +972 and Local Call — was conducted with the help of automatic and inaccurate tools. In previous wars, intelligence personnel would spend a lot of time verifying how many people were in a house that was set to be bombed, with the number of civilians liable to be killed listed as part of a “target file.” After October 7, however, this thorough verification was largely abandoned in favor of automation.&nbsp;</span></p>
<p><span>In October, The New York Times </span><a href="https://www.nytimes.com/2023/10/16/world/middleeast/gaza-invasion-israel-cellphone-data.html"><span>reported</span></a><span> on a system operated from a special base in southern Israel, which collects information from mobile phones in the Gaza Strip and provided the military with a live estimate of the number of Palestinians who fled the northern Gaza Strip southward. Brig. General Udi Ben Muha told the Times that “It’s not a 100 percent perfect system — but it gives you the information you need to make a decision.” The system operates according to colors: red marks areas where there are many people, and green and yellow mark areas that have been relatively cleared of residents.</span><span>&nbsp;</span></p>
<div id="attachment_175999"><p><a href="https://static.972mag.com/www/uploads/2024/01/F231110AM03.jpg" data-featherlight="image"><img title="Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2024/01/F231110AM03-1280x853.jpg" alt="Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)" width="768" height="512" data-caption="Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)"></a></p><p>Palestinians walk on a main road after fleeing from their homes in Gaza City to the southern part of Gaza, November 10, 2023. (Atia Mohammed/Flash90)</p>
</div>
<p><span>The sources who spoke to +972 and Local Call described a similar system for calculating collateral damage, which was used to decide whether to bomb a building in Gaza. They said that the software calculated the number of civilians residing in each home before the war — by assessing the size of the building and reviewing its list of residents — and then reduced those numbers by the proportion of residents who supposedly evacuated the neighborhood.&nbsp;</span></p>
<p><span>To illustrate, if the army estimated that half of a neighborhood’s residents had left, the program would count a house that usually had 10 residents as a house containing five people. To save time, the sources said, the army did not surveil the homes to check how many people were actually living there, as it did in previous operations, to find out if the program’s estimate was indeed accurate.</span></p>
<p><span>“This model was not connected to reality,” claimed one source. “There was no connection between those who were in the home now, during the war, and those who were listed as living there prior to the war. [On one occasion] we bombed a house without knowing that there were several families inside, hiding together.”</span><span>&nbsp;</span></p>
<p><span>The source said that although the army knew that such errors could occur, this imprecise model was adopted nonetheless, because it was faster. As such, the source said, “the collateral damage calculation was completely automatic and statistical” — even producing figures that were not whole numbers.</span></p>
<h3><span>STEP 6: BOMBING A FAMILY HOME</span></h3>
<h3>‘You killed a family for no reason’</h3>
<p><span>The sources who spoke to +972 and Local Call explained that there was sometimes a substantial gap between the moment that tracking systems like Where’s Daddy? alerted an officer that a target had entered their house, and the bombing itself — leading to the killing of whole families even without hitting the army’s target. “It happened to me many times that we attacked a house, but the person wasn’t even home,” one source said. “The result is that you killed a family for no reason.”</span></p>
<p><span>Three intelligence sources told +972 and Local Call that they had witnessed an incident in which the Israeli army bombed a family’s private home, and it later turned out that the intended target of the assassination was not even inside the house, since no further verification was conducted in real time.</span></p>
<div id="attachment_174976"><p><a href="https://static.972mag.com/www/uploads/2023/11/F231106ARK01.jpg" data-featherlight="image"><img title="Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)" decoding="async" loading="lazy" src="https://static.972mag.com/www/uploads/2023/11/F231106ARK01-1280x853.jpg" alt="Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)" width="768" height="512" data-caption="Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)"></a></p><p>Palestinians receive the bodies of relatives who were killed in Israeli airstrikes, Al-Najjar Hospital, southern Gaza Strip, November 6, 2023. (Abed Rahim Khatib/Flash90)</p>
</div>
<p><span>“Sometimes [the target] was at home earlier, and then at night he went to sleep somewhere else, say underground, and you didn’t know about it,” one of the sources said. “There are times when you double-check the location, and there are times when you just say, ‘Okay, he was in the house in the last few hours, so you can just bomb.’”</span><span>&nbsp;</span></p>
<p><span>Another source described a similar incident that affected him and made him want to be interviewed for this investigation. “We understood that the target was home at 8 p.m. In the end, the air force bombed the house at 3 a.m. Then we found out [in that span of time] he had managed to move himself to another house with his family. There were two other families with children in the building we bombed.”</span></p>
<p><span>In previous wars in Gaza, after the assassination of human targets, Israeli intelligence would carry out bomb damage assessment (BDA) procedures — a routine post-strike check to see if the senior commander was killed and how many civilians were killed along with him. As revealed in a </span><a href="https://www.972mag.com/gaza-soldiers-civilians-intelligence/"><span>previous +972 and Local Call investigation</span></a><span>, this involved listening in to phone calls of relatives who lost their loved ones. In the current war, however, at least in relation to junior militants marked using AI, sources say this procedure was abolished in order to save time. The sources said they did not know how many civilians were actually killed in each strike, and for the low-ranking suspected Hamas and PIJ operatives marked by AI, they did not even know whether the target himself was killed.</span></p>
<div>
<h3>Most read on +972</h3>

</div>
<p><span>“You don’t know exactly how many you killed, and who you killed,” an intelligence source </span><a href="https://twitter.com/yuval_abraham/status/1750123648533324158?lang=en"><span>told Local Call</span></a><span> for a previous investigation published in January. “Only when it’s senior Hamas operatives do you follow the BDA procedure. In the rest of the cases, you don’t care. You get a report from the air force about whether the building was blown up, and that’s it. You have no idea how much collateral damage there was; you immediately move on to the next target. The emphasis was to create as many targets as possible, as quickly as possible.”</span></p>
<p><span>But while the Israeli military may move on from each strike without dwelling on the number of casualties, Amjad Al-Sheikh, the Shuja’iya resident who lost 11 of his family members in the Dec. 2 bombardment, said that he and his neighbors are still searching for corpses.</span></p>
<p><span>“Until now, there are bodies under the rubble,” he said. “Fourteen residential buildings were bombed with their residents inside. Some of my relatives and neighbors are still buried.”</span></p>

<div>
<p>
<h2>Subscribe to The Landline</h2>
<h2>+972's weekly newsletter</h2>
</p>



</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Israel used AI to identify 37,000 Hamas targets (130 pts)]]></title>
            <link>https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes</link>
            <guid>39917727</guid>
            <pubDate>Wed, 03 Apr 2024 14:08:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes">https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes</a>, See on <a href="https://news.ycombinator.com/item?id=39917727">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>The Israeli military’s bombing campaign in <a href="https://www.theguardian.com/world/gaza" data-link-name="in body link">Gaza</a> used a previously undisclosed AI-powered database that at one stage identified 37,000 potential targets based on their apparent links to Hamas, according to intelligence sources involved in the war.</p><p>In addition to talking about their use of the AI system, called Lavender, the intelligence sources claim that Israeli military officials permitted large numbers of Palestinian civilians to be killed, particularly during the early weeks and months of the <a href="https://www.theguardian.com/world/israel-hamas-war" data-link-name="in body link">conflict</a>.</p><p>Their unusually candid testimony provides a rare glimpse into the first-hand experiences of Israeli intelligence officials who have been using machine-learning systems to help identify targets during the six-month war.</p><p>Israel’s use of powerful AI systems in its war on Hamas has entered uncharted territory for advanced warfare, raising a host of legal and moral questions, and transforming the relationship between military personnel and machines.</p><p>“This is unparalleled, in my memory,” said one intelligence officer who used Lavender, adding that they had more faith in a “statistical mechanism” than a grieving soldier. “Everyone there, including me, lost people on October 7. The machine did it coldly. And that made it easier.”</p><p>Another Lavender user questioned whether humans’ role in the selection process was meaningful. “I would invest 20 seconds for each target at this stage, and do dozens of them every day. I had zero added-value as a human, apart from being a stamp of approval. It saved a lot of time.”</p><figure id="f794142d-fd91-4a75-96e0-7c8df1309f90" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Palestinian children amid debris with items on a trolley" src="https://i.guim.co.uk/img/media/cb19de91e8cc4d2509a174156c683c28db7be9c3/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Palestinian children salvage items amid the destruction caused by Israeli bombing in Bureij, central Gaza, on 14 March.</span> Photograph: AFP/Getty Images</figcaption></figure><p>The testimony from the six intelligence officers, all who have been involved in using AI systems to identify Hamas and Palestinian Islamic Jihad (PIJ) targets in the war, was given to the journalist Yuval Abraham for a <a href="https://www.972mag.com/lavender-ai-israeli-army-gaza/" data-link-name="in body link">report published by the Israeli-Palestinian publication +972 Magazine and the Hebrew-language outlet Local Call</a>.</p><p>Their accounts were shared exclusively with the Guardian in advance of publication. All six said that Lavender had played a central role in the war, processing masses of data to rapidly identify potential “junior” operatives to target. Four of the sources said that, at one stage early in the war, Lavender listed as many as 37,000 Palestinian men who had been linked by the AI system to Hamas or PIJ.</p><p>Lavender was developed by the Israel Defense Forces’ elite intelligence division, Unit 8200, which is comparable to the US’s National Security Agency or GCHQ in the UK.</p><p>Several of the sources described how, for certain categories of targets, the IDF applied pre-authorised allowances for the estimated number of civilians who could be killed before a strike was authorised.</p><p>Two sources said that during the early weeks of the war they were permitted to kill 15 or 20 civilians during airstrikes on low-ranking militants. Attacks on such targets were typically carried out using unguided munitions known as “dumb bombs”, the sources said, destroying entire homes and killing all their occupants.</p><gu-island name="InteractiveBlockComponent" priority="critical" deferuntil="visible" props="{&quot;url&quot;:&quot;https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Story%20tips%3F&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Ainvestigations%40theguardian.com%22%3Einvestigations%40theguardian.com%3C%2Fa%3E%2C%20or%20use%20Signal%20or%20WhatsApp%20to%20message%20(UK)%20%2B44%207584%20640566%20or%20(US)%20%2B1%20646%20886%208761.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false&quot;,&quot;scriptUrl&quot;:&quot;https://interactive.guim.co.uk/embed/iframe-wrapper/0.1/boot.js&quot;,&quot;alt&quot;:&quot;story tips embed&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;elementId&quot;:&quot;05693281-63b5-480c-b23d-3116ace40f3a&quot;,&quot;isMainMedia&quot;:false}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"><figure id="05693281-63b5-480c-b23d-3116ace40f3a" data-alt="story tips embed" data-testid="interactive-element-story%20tips%20embed" data-spacefinder-role="inline"><a data-name="placeholder" href="https://interactive.guim.co.uk/embed/from-tool/generic/index.html?vertical=News&amp;opinion-tint=false&amp;title=Story%20tips%3F&amp;description=Do%20you%20have%20information%20about%20this%20story%3F%20Email%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22mailto%3Ainvestigations%40theguardian.com%22%3Einvestigations%40theguardian.com%3C%2Fa%3E%2C%20or%20use%20Signal%20or%20WhatsApp%20to%20message%20(UK)%20%2B44%207584%20640566%20or%20(US)%20%2B1%20646%20886%208761.%20For%20the%20most%20secure%20communications%2C%20use%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fsecuredrop%22%3ESecureDrop%3C%2Fa%3E%20or%20see%20%3Ca%20style%3D%22color%3A%23ab0613%22%20href%3D%22https%3A%2F%2Fwww.theguardian.com%2Fhelp%2Fng-interactive%2F2017%2Fmar%2F17%2Fcontact-the-guardian-securely%22%3Eour%20guide%3C%2Fa%3E.&amp;link=false">story tips embed</a></figure></gu-island><p>“You don’t want to waste expensive bombs on unimportant people – it’s very expensive for the country and there’s a shortage [of those bombs],” one intelligence officer said. Another said the principal question they were faced with was whether the “collateral damage” to civilians allowed for an attack.</p><p>“Because we usually carried out the attacks with dumb bombs, and that meant literally dropping the whole house on its occupants. But even if an attack is averted, you don’t care – you immediately move on to the next target. Because of the system, the targets never end. You have another 36,000 waiting.”</p><p>According to conflict experts, if Israel has been using dumb bombs to flatten the homes of thousands of Palestinians who were linked, with the assistance of AI, to militant groups in <a href="https://www.theguardian.com/world/gaza" data-link-name="in body link" data-component="auto-linked-tag">Gaza</a>, that could help explain the shockingly high death toll in the war.</p><p>The health ministry in the Hamas-run territory says 33,000 Palestinians have been killed in the conflict in the past six months. <a href="https://www.ochaopt.org/content/hostilities-gaza-strip-and-israel-reported-impact-day-45" data-link-name="in body link">UN data</a> shows that in the first month of the war alone, 1,340 families suffered multiple losses, with 312 families losing more than 10 members.</p><figure id="c87dbce8-192e-4e76-a6d9-2d1b4bc33e20" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Two Israeli soldiers with weapons stand on the Israeli side of the Israel-Gaza border looking into the Palestinian territory " src="https://i.guim.co.uk/img/media/6481d35124ba0b382a44ac7af90775c0d07b8bcd/0_0_5423_3615/master/5423.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.63931403282317" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Israeli soldiers stand on the Israeli side of the Israel-Gaza border surveying the Palestinian territory on 30 March.</span> Photograph: Amir Cohen/Reuters</figcaption></figure><p>Responding to the publication of the testimonies in +972 and Local Call, the <a href="https://www.theguardian.com/world/2024/apr/03/israel-defence-forces-response-to-claims-about-use-of-lavender-ai-database-in-gaza" data-link-name="in body link">IDF said in a statement</a> that its operations were carried out in accordance with the rules of proportionality under international law. It said dumb bombs are “standard weaponry” that are used by IDF pilots in a manner that ensures “a high level of precision”.</p><p>The statement described Lavender as a database used “to cross-reference intelligence sources, in order to produce up-to-date layers of information on the military operatives of terrorist organisations. This is not a list of confirmed military operatives eligible to attack.</p><p>“The IDF does not use an artificial intelligence system that identifies terrorist operatives or tries to predict whether a person is a terrorist,” it added. “Information systems are merely tools for analysts in the target identification process.”</p><h2 id="lavender-created-a-database-of-tens-of-thousands-of-individuals">Lavender created a database of tens of thousands of individuals</h2><p>In earlier military operations conducted by the IDF, producing human targets was often a more labour-intensive process. Multiple sources who described target development in previous wars to the Guardian, said the decision to “incriminate” an individual, or identify them as a legitimate target, would be discussed and then signed off by a legal adviser.</p><p>In the weeks and months after 7 October, this model for approving strikes on human targets was dramatically accelerated, according to the sources. As the IDF’s bombardment of Gaza intensified, they said, commanders demanded a continuous pipeline of targets.</p><p>“We were constantly being pressured: ‘Bring us more targets.’ They really shouted at us,” said one intelligence officer. “We were told: now we have to fuck up Hamas, no matter what the cost. Whatever you can, you bomb.”</p><p>To meet this demand, the IDF came to rely heavily on Lavender to generate a database of individuals judged to have the characteristics of a PIJ or Hamas militant.</p><p>Details about the specific kinds of data used to train Lavender’s algorithm, or how the programme reached its conclusions, are not included in the accounts published by +972 or Local Call. However, the sources said that during the first few weeks of the war, Unit 8200 refined Lavender’s algorithm and tweaked its search parameters.</p><p>After randomly sampling and cross-checking its predictions, the unit concluded Lavender had achieved a 90% accuracy rate, the sources said, leading the IDF to approve its sweeping use as a target recommendation tool.</p><p>Lavender created a database of tens of thousands of individuals who were marked as predominantly low-ranking members of Hamas’s military wing, they added. This was used alongside another AI-based decision support system, called <a href="https://www.theguardian.com/world/2023/dec/01/the-gospel-how-israel-uses-ai-to-select-bombing-targets" data-link-name="in body link">the Gospel</a>, which recommended buildings and structures as targets rather than individuals.</p><figure id="447778ad-5973-4fe4-af74-633fc12487a4" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Two Israeli air force F15 fighter jets in the air near the city of Gedera, southern Israel" src="https://i.guim.co.uk/img/media/b4d04d8cbb882eb861b641a725ef25e6038f1b21/0_0_1126_750/master/1126.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.4031971580817" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Two Israeli air force F15 fighter jets near the city of Gedera, southern Israel, on 27 March.</span> Photograph: Abir Sultan/EPA</figcaption></figure><p>The accounts include first-hand testimony of how intelligence officers worked with Lavender and how the reach of its dragnet could be adjusted. “At its peak, the system managed to generate 37,000 people as potential human targets,” one of the sources said. “But the numbers changed all the time, because it depends on where you set the bar of what a Hamas operative is.”</p><p>They added: “There were times when a Hamas operative was defined more broadly, and then the machine started bringing us all kinds of civil defence personnel, police officers, on whom it would be a shame to waste bombs. They help the Hamas government, but they don’t really endanger soldiers.”</p><p>Before the war, US and Israeli estimated membership of Hamas’s military wing at approximately 25-30,000 people.</p><figure id="da6b7cce-bfbd-4ff9-a2bf-52904e5aa14b" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:33,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;‘The Gospel’: how Israel uses AI to select bombing targets in Gaza&quot;,&quot;elementId&quot;:&quot;da6b7cce-bfbd-4ff9-a2bf-52904e5aa14b&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/world/2023/dec/01/the-gospel-how-israel-uses-ai-to-select-bombing-targets&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>In the weeks after the Hamas-led 7 October assault on southern Israel, in which Palestinian militants killed nearly 1,200 Israelis and kidnapped about 240 people, the sources said there was a decision to treat Palestinian men linked to Hamas’s military wing as potential targets, regardless of their rank or importance.</p><p>The IDF’s targeting processes in the most intensive phase of the bombardment were also relaxed, they said. “There was a completely permissive policy regarding the casualties of [bombing] operations,” one source said. “A policy so permissive that in my opinion it had an element of revenge.”</p><p>Another source, who justified the use of Lavender to help identify low-ranking targets, said that “when it comes to a junior militant, you don’t want to invest manpower and time in it”. They said that in wartime there was insufficient time to carefully “incriminate every target”.</p><p>“So you’re willing to take the margin of error of using artificial intelligence, risking collateral damage and civilians dying, and risking attacking by mistake, and to live with it,” they added.</p><h2 id="its-much-easier-to-bomb-a-familys-home">‘It’s much easier to bomb a family’s home’</h2><p>The testimonies published by +972 and Local Call may explain how such a western military with such advanced capabilities, with weapons that can conduct highly surgical strikes, has conducted a war with such a vast human toll.</p><p>When it came to targeting low-ranking Hamas and PIJ suspects, they said, the preference was to attack when they were believed to be at home. “We were not interested in killing [Hamas] operatives only when they were in a military building or engaged in a military activity,” one said. “It’s much easier to bomb a family’s home. The system is built to look for them in these situations.”</p><figure id="d53eafba-b19d-4bab-899c-d6c260e560ef" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Relatives cry as bodies of Palestinians killed in Israeli bombings lie outside the morgue  " src="https://i.guim.co.uk/img/media/3715ba6658084c5a9618ef4cc3723a17ad1bbd61/0_0_8192_5462/master/8192.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.702880859375" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Relatives outside the morgue of the al-Najjar hospital in Rafah mourn Palestinians killed in Israeli bombings on 1 February.</span> Photograph: Mohammed Abed/AFP/Getty Images</figcaption></figure><p>Such a strategy risked higher numbers of civilian casualties, and the sources said the IDF imposed pre-authorised limits on the number of civilians it deemed acceptable to kill in a strike aimed at a single Hamas militant. The ratio was said to have changed over time, and varied according to the seniority of the target.</p><p>According to +972 and Local Call, the IDF judged it permissible to kill more than 100 civilians in attacks on a top-ranking Hamas officials. “We had a calculation for how many [civilians could be killed] for the brigade commander, how many [civilians] for a battalion commander, and so on,” one source said.</p><p>“There were regulations, but they were just very lenient,” another added. “We’ve killed people with collateral damage in the high double digits, if not low triple digits. These are things that haven’t happened before.” There appears to have been significant fluctuations in the figure that military commanders would tolerate at different stages of the war.</p><p>One source said that the limit on permitted civilian casualties “went up and down” over time, and at one point was as low as five. During the first week of the conflict, the source said, permission was given to kill 15 non-combatants to take out junior militants in Gaza. However, they said estimates of civilian casualties were imprecise, as it was not possible to know definitively how many people were in a building.</p><p>Another intelligence officer said that more recently in the conflict, the rate of permitted collateral damage was brought down again. But at one stage earlier in the war they were authorised to kill up to “20 uninvolved civilians” for a single operative, regardless of their rank, military importance, or age.</p><p>“It’s not just that you can kill any person who is a Hamas soldier, which is clearly permitted and legitimate in terms of international law,” they said. “But they directly tell you: ‘You are allowed to kill them along with many civilians.’ … In practice, the proportionality criterion did not exist.”</p><p>The IDF statement said its procedures “require conducting an individual assessment of the anticipated military advantage and collateral damage expected … The IDF does not carry out strikes when the expected collateral damage from the strike is excessive in relation to the military advantage.” It added: “The IDF outright rejects the claim regarding any policy to kill tens of thousands of people in their homes.”</p><p>Experts in international humanitarian law who spoke to the Guardian expressed alarm at accounts of the IDF accepting and pre-authorising collateral damage ratios as high as 20 civilians, particularly for lower-ranking militants. They said militaries must assess proportionality for each individual strike.</p><figure id="7ea5910c-af07-43cf-8ab5-d268a6a02d5f" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-6"><picture><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Smoke rises over the Gaza Strip, as seen from from the Israeli side of the border" src="https://i.guim.co.uk/img/media/75fa67e98a9f1e391c7137354549872803b4501f/0_0_4100_2733/master/4100.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.63048780487804" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Smoke rises over the Gaza Strip, as seen from from the Israeli side of the border on 21 January.</span> Photograph: Amir Levy/Getty Images</figcaption></figure><p>An international law expert at the US state department said they had “never remotely heard of a one to 15 ratio being deemed acceptable, especially for lower-level combatants. There’s a lot of leeway, but that strikes me as extreme”.</p><p>Sarah Harrison, a former lawyer at the US Department of Defense, now an analyst at Crisis Group, said: “While there may be certain occasions where 15 collateral civilian deaths could be proportionate, there are other times where it definitely wouldn’t be. You can’t just set a tolerable number for a category of targets and say that it’ll be lawfully proportionate in each case.”</p><p>Whatever the legal or moral justification for Israel’s bombing strategy, some of its intelligence officers appear now to be questioning the approach set by their commanders. “No one thought about what to do afterward, when the war is over, or how it will be possible to live in Gaza,” one said.</p><p>Another said that after the 7 October attacks by Hamas, the atmosphere in the IDF was “painful and vindictive”. “There was a dissonance: on the one hand, people here were frustrated that we were not attacking enough. On the other hand, you see at the end of the day that another thousand Gazans have died, most of them civilians.”</p><p><em><a href="https://www.theguardian.com/guardian-live-events/2024/feb/16/guardian-newsroom-the-unfolding-crisis-in-the-middle-east" data-link-name="in body link">Guardian Newsroom: The unfolding crisis in the Middle East</a><br>On Tuesday 30 April, 7-8.15pm GMT, join Devika Bhat, Peter Beaumont, Emma Graham-Harrison and Ghaith Abdul-Ahad as they discuss the fast-developing crisis in the Middle East. Book tickets<a href="https://www.theguardian.com/guardian-live-events/2024/feb/16/guardian-newsroom-the-unfolding-crisis-in-the-middle-east" data-link-name="in body link"> here</a> or at <a href="https://www.theguardian.com/guardian-live-events" data-link-name="in body link">theguardian.live</a></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Mini liver' will grow in person's own lymph node in bold new trial (150 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-00975-z</link>
            <guid>39917551</guid>
            <pubDate>Wed, 03 Apr 2024 13:57:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-00975-z">https://www.nature.com/articles/d41586-024-00975-z</a>, See on <a href="https://news.ycombinator.com/item?id=39917551">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>A person has received an experimental treatment for the first time that, if successful, will lead them to grow an additional, ‘miniature liver’. The procedure, developed by the biotechnology firm LyGenesis, marks the beginning of a clinical trial designed for people whose livers are failing, but who have not received an organ transplant.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-00853-8" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-00975-z/d41586-024-00975-z_26888820.jpg"><p>First pig liver transplanted into a person lasts for 10 days</p></a>
 </article><p>The approach is unusual: researchers injected healthy liver cells from a donor into a lymph node in the upper abdomen of the person with liver failure. The idea is that in several months, the cells will multiply and take over the lymph node to form a structure that can perform the blood-filtering duties of the person’s failing liver.</p><p>“It’s a very bold and incredibly innovative idea,” says Valerie Gouon-Evans, a liver-regeneration specialist at Boston University in Massachusetts, who is not involved with the company.</p><p>The person who received the treatment, on 25 March, is recovering well from the procedure and was discharged from the clinic, says Michael Hufford, chief executive of LyGenesis, which is based in Pittsburgh, Pennsylvania. But physicians will need to closely monitor them for infection because the person needs to take immunosuppressive drugs so that their body doesn’t reject the donor cells, says Stuart Forbes, a hepatologist at the University of Edinburgh, UK, who is not affiliated with LyGenesis.</p><h2>Organ crisis</h2><p>More than 50,000 people in the United States die each year with liver disease. In the end stage of the disease, scar tissue that has accumulated prevents the organ from filtering toxic substances in the blood, and can lead to infection or liver cancer.</p><p>A liver transplant can help, but there is a shortage of organs: about 1,000 people in the United States die every year waiting for a transplant. Thousands more aren’t eligible because they are too ill to undergo the procedure.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-00975-z/d41586-024-00975-z_26933586.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-00975-z/d41586-024-00975-z_26933586.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Gloved hands holding up a fluid bag of the donor liver cells in a lab." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-00975-z/d41586-024-00975-z_26933586.jpg">
  <figcaption>
   <p><span>A person received donor liver cells on 25 March that were injected into one of their lymph nodes.</span><span>Credit: LyGenesis</span></p>
  </figcaption>
 </picture>
</figure><p>LyGenesis has been trialling an approach that could help people in this situation — and make use of donated livers that would otherwise go to waste because a person on the transplant waiting list with a compatible health profile hasn’t materialized in time. The company’s strategy delivers the donor cells through a tube in the throat, injecting them into a lymph node near the liver. Lymph nodes, which also filter waste in the body and are an important part of the immune system, are ideal for growing mini livers, Hufford says, because they receive a large supply of blood and there are hundreds of them throughout the body, so if a few are used to generate mini livers, plenty of others can continue to function as lymph nodes.</p><p>The treatment has so far worked in mice<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>, <a href="https://atcmeetingabstracts.com/abstract/ectopic-hepatocyte-transplantation-into-the-lymph-nodes-in-a-fully-mismatched-allogeneic-dog-model-using-tacrolimus-and-prednisone/" data-track="click" data-label="https://atcmeetingabstracts.com/abstract/ectopic-hepatocyte-transplantation-into-the-lymph-nodes-in-a-fully-mismatched-allogeneic-dog-model-using-tacrolimus-and-prednisone/" data-track-category="body text link">dogs</a> and pigs<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. To test the therapy in pigs, researchers restricted blood flow to the animals’ livers, causing the organs to fail, and injected donor cells into lymph nodes. Miniature livers formed within two months and had a cellular architecture resembling a healthy liver. Researchers even found cells that transport bile, a digestive fluid produced by the liver, in the mini livers of the pigs. In this case, they saw no build-up of bile acid, suggesting that the mini organs were processing the fluid.</p><p>Hufford says there’s reason to think that the organs won’t grow indefinitely in the lymph nodes. The mini organs rely on chemical distress signals from the failing liver to grow; once the new organs have stabilized blood filtering, they will stop growing because that distress signal disappears, he says. But it’s not yet clear precisely how large the mini-livers will become in humans, he adds.</p><p>The company aims to enrol 12 people into the phase II trial by mid-2025 and publish results the following year, Hufford says. The trial, which was approved by US regulators in 2020, will not only measure participant safety, survival time and quality of life post-treatment, but will also help to establish the ideal number of mini livers to stabilize someone’s health. The clinicians running the trial will inject liver cells in up to five of a person’s lymph nodes to determine whether the extra organs can boost the procedure’s success rate.</p><h2>A stop-gap measure</h2><p>However, mini livers might not relieve all of the complications of end-stage liver disease, says Forbes, who has formed his own company to tackle liver disease using genetically modified immune cells that stimulate repair. One of the most serious of these is portal hypertension, in which the build-up of scar tissue compresses blood vessels in the liver and can cause internal bleeding.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-019-01216-4" data-track="click" data-track-label="recommended article"><p>Pig brains kept alive outside body for hours after death</p></a>
 </article><p>Hufford acknowledges that the mini livers are not expected to address portal hypertension, but the hope is that they can provide a stopgap until a liver becomes available for transplant, or make people healthy enough to undergo a transplant. “That would be amazing, because these patients currently have no other treatment options,” Gouon-Evans says.</p><p>LyGenesis has ambitions beyond mini livers, too. The company is now testing similar approaches to grow kidney and pancreas cells in the lymph nodes of animals, Hufford says.</p><p>If the liver trial is successful, Gouon-Evans says, it would be worth investigating whether a person’s own stem cells could be used to generate the cells that seed the lymph nodes. This technique could create personalized cells that capture the diversity of cells in the liver and don’t require immunosuppressive drugs, she says.</p>
                </div><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Komori, J., Boone, L., DeWard, A., Hoppo, T. &amp; Lagasse, E. <i>Nature Biotechnol</i>. <b>30</b>, 976–983 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nbt.2379" data-track-action="article reference" href="https://doi.org/10.1038%2Fnbt.2379" aria-label="Article reference 1" data-doi="10.1038/nbt.2379">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23000933" aria-label="PubMed reference 1">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Nature%20Biotechnol&amp;doi=10.1038%2Fnbt.2379&amp;volume=30&amp;pages=976-983&amp;publication_year=2012&amp;author=Komori%2CJ.&amp;author=Boone%2CL.&amp;author=DeWard%2CA.&amp;author=Hoppo%2CT.&amp;author=Lagasse%2CE.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Fontes, P., Komori, J., Lopez, R., Marsh, W. &amp; Lagasse, E. <i>Liver Transplant</i>. <b>26</b>, 1629–1643 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/lt.25872" data-track-action="article reference" href="https://doi.org/10.1002%2Flt.25872" aria-label="Article reference 2" data-doi="10.1002/lt.25872">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Liver%20Transplant&amp;doi=10.1002%2Flt.25872&amp;volume=26&amp;pages=1629-1643&amp;publication_year=2020&amp;author=Fontes%2CP.&amp;author=Komori%2CJ.&amp;author=Lopez%2CR.&amp;author=Marsh%2CW.&amp;author=Lagasse%2CE.">
                    Google Scholar</a>&nbsp;
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/d41586-024-00975-z?format=refman&amp;flavour=references">Download references</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Seafloor Map Only 25% Done, with 6 Years to Go (134 pts)]]></title>
            <link>https://eos.org/articles/new-seafloor-map-only-25-done-with-6-years-to-go</link>
            <guid>39917547</guid>
            <pubDate>Wed, 03 Apr 2024 13:57:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eos.org/articles/new-seafloor-map-only-25-done-with-6-years-to-go">https://eos.org/articles/new-seafloor-map-only-25-done-with-6-years-to-go</a>, See on <a href="https://news.ycombinator.com/item?id=39917547">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-222049">
	<div>

		
		
<p>Ten years have passed since Malaysia Airlines Flight 370 vanished after departing from Kuala Lumpur, Malaysia, with 239 people aboard. Military and scientific personnel spent months combing unexplored reaches of the Indian Ocean, and though they failed to find the Boeing 777, the quest highlighted the fact that beneath the waves, vast areas of Earth’s ocean are still a mystery.</p>

<p><a href="https://seabed2030.org/" target="_blank" rel="noreferrer noopener">Seabed 2030</a> is a long-term mapping project attempting to fully chart the seafloor and reveal all features 100 meters or larger by 2030. But with just a quarter of the job now done, it still faces tremendous challenges.</p>

<figure><blockquote><p>“Maps enable us to manage how we utilize marine space, [guide] ocean commerce and use of resources, mitigate our impacts, and achieve an improved understanding of threats such as tsunami, storm surges, and underwater landslides.”</p></blockquote></figure>

<p>The <a href="https://www.gebco.net/" target="_blank" rel="noreferrer noopener">General Bathymetric Chart of the Oceans</a> (GEBCO) and <a href="https://www.nippon-foundation.or.jp/en" target="_blank" rel="noreferrer noopener">Nippon Foundation</a>, a Japanese nonprofit that funnels profits from motorboat racing to philanthropic causes, established <a href="https://eos.org/articles/momentum-grows-for-mapping-the-seafloor" target="_blank" rel="noreferrer noopener">Seabed 2030</a> in 2017. The aim was to use ocean mapping to support United Nations Sustainable Development Goal 14, namely, to “conserve and sustainably use the oceans, seas and marine resources for sustainable development.” At the time, only 6% of the ocean floor had been mapped to modern standards, according to the project.</p>


<p>“Maps enable us to manage how we utilize marine space, [guide] ocean commerce and use of resources, mitigate our impacts, and achieve an improved understanding of threats such as tsunami, storm surges, and underwater landslides,” said hydrographic surveyor <a href="https://seabed2030.org/people/jamiemcmichaelphillips/" target="_blank" rel="noreferrer noopener">Jamie McMichael-Phillips</a>, Seabed 2030’s project director. “Essentially, we cannot manage what we don’t know.”</p>

<h3>New Discoveries</h3>

<p>An oft-repeated observation is that we know more about the surface of Mars than Earth’s seafloor. But that has been changing with recent discoveries. Off the coasts of Central and South America, researchers with the Schmidt Ocean Institute, a Seabed 2030 partner, <a href="https://schmidtocean.org/cruise/seamounts-of-the-southeast-pacific/" target="_blank" rel="noreferrer noopener">found four seamounts in January 2024</a>, including a massive one covering 450 square kilometers that is 2,681 meters tall, which is about 5 times the <a href="https://www.wtc.com/about/buildings/1-world-trade-center#:~:text=Soaring%20to%20a%20symbolic%201%2C776,an%20iconic%20New%20York%20landmark.&amp;text=With%20entrances%20on%20all%204,traffic%20of%20visitors%20%26%20office%20tenants." target="_blank" rel="noreferrer noopener">height of New York City’s One World Trade Center</a>.</p>

<p>At a depth of 1,150 meters, the giant seamounts were well hidden beneath the waves. To find these features, researchers aboard the institute’s R/V <em>Falkor (too)</em> looked for clues on the surface of the ocean. <a href="https://www.star.nesdis.noaa.gov/socd/lsa/AltBathy/" target="_blank" rel="noreferrer noopener">Satellite altimetry</a> data can show variations in the height of the ocean surface caused by gravity anomalies. A slight depression could point to a trench, and a rise could reflect the presence of a seamount.</p>

<p>“The most significant aspect of our findings is the validation of the satellite altimetry data that we used to target these seamounts,” said <a href="https://schmidtocean.org/person/john-fulmer/" target="_blank" rel="noreferrer noopener">John Fulmer</a>, lead technician aboard the <em>Falkor (too)</em>. “As all of our findings were in international waters, there is no apparent political significance to speak of, but the ease with which we were able to identify potential seamounts is a testament to the importance of collective and open data resources at our disposal.”</p>

<h3>Bringing New Tools to Bear</h3>

<p>Crowdsourcing and the use of open-source data are crucial to the Seabed 2030 project. It relies on data donations from a range of sources: scientists and philanthropists; offshore survey companies; and fishing, cruise, and cargo vessel operators. In November 2023, for instance, Seabed 2030 announced the donation of a data set covering 8,000 square kilometers of remote areas that are difficult to reach. U.K.-based remote sensing company <a href="https://seabed2030.org/2023/11/22/sizeable-data-contribution-from-argans-to-seabed-2030-fills-critical-gaps-in-definitive-ocean-map/" target="_blank" rel="noreferrer noopener">ARGANS (Applied Research in Geomatics, Atmosphere, Nature and Space) provided the high-resolution bathymetric data</a> derived from satellite observations, one of the main data-gathering methods along with aircraft-based lidar sensing and sonar readings. In another example, the <a href="https://seabed2030.org/wp-content/uploads/2023/06/sawpap_rmc_march2019_final.pdf" target="_blank" rel="noreferrer noopener">Japan Coast Guard donated to GEBCO a large bathymetry data set</a> covering areas around Japan and Antarctica, according to Haruka Ogawa, a researcher in the coast guard’s <a href="https://www1.kaiho.mlit.go.jp/jhd-E.html" target="_blank" rel="noreferrer noopener">Hydrographic and Oceanographic Department</a>.</p>

<p>All Seabed 2030 data are uploaded to the free-access GEBCO grid of the seafloor. The grid shows that 24.9% has been mapped to the Seabed 2030 resolution, leaving about 75% to be done over the next 6 years if the project’s goal is to be met. That’s a massive undertaking considering challenges such as permanent ice cover near the poles and the fact that about half of the global ocean is deeper than 3,200 meters.</p>

<p>Because vessels are usually needed for the job, it makes for a slow, costly endeavor with a bias toward areas with expertly equipped ships, said <a href="https://www.mun.ca/geography/people/faculty/katleen-robert/" target="_blank" rel="noreferrer noopener">Katleen Robert</a>, a seafloor and habitat mapping researcher at Memorial University of Newfoundland, in Canada. She said she sees autonomous vehicles, both underwater and surface, as having the largest impact on how much of our oceans we will map in the near future.</p>

<p>“These will act as force multipliers and enable us to acquire higher-resolution data and repeat data sets to monitor changes over time,” said Robert, who is not directly involved with Seabed 2030, although expedition data she was involved with are supporting it.</p>

<p>In 2023, Seabed 2030 partnered with U.S. company <a href="https://www.saildrone.com/news/seabed-2030-partnership-to-map-the-ocean" target="_blank" rel="noreferrer noopener">Saildrone</a> to promote the use of uncrewed hydrographic vessels. Powered mainly by wind and solar, Saildrone’s 20-meter surveyor drone can gather multibeam sonar data to depths of 7,000 meters for a fraction of the operating cost of crewed ships. One surveyor found a 1,000-meter seamount off California during a months-long surveying mission that saw 35-knot winds and 5-meter swells, according to the company.</p>

<figure><blockquote><p>“We know that we will be much closer to a fully mapped planet than the 6% that had been mapped when the project started.”</p></blockquote></figure>

<p>Other researchers are hoping other forms of artificial intelligence will accelerate the mapping mission. In addition to surface and underwater exploration vessels, researchers at the Japan Agency for Marine-Earth Science and Technology (<a href="https://www.jamstec.go.jp/e/" target="_blank" rel="noreferrer noopener">JAMSTEC</a>) are deploying deep learning techniques to enhance the resolution of existing topographic data.</p>

<p>The approach using convolutional neural networks is “surprisingly effective” and can be used as a complementary method to direct depth sensing, said <a href="https://www.researchgate.net/scientific-contributions/Eiichi-Kikawa-2178206065" target="_blank" rel="noreferrer noopener">Eiichi Kikawa</a>, a data scientist at JAMSTEC. He added that a paper on the research has been submitted for publication.</p>

<p>It’s too early to tell whether these tools could help Seabed 2030 meet its goal in 6 years, but the project is relying on more partnerships to increase coverage of the seafloor.</p>

<p>“We are aware of the magnitude of the challenge that still remains and are working with the global community to push to complete the job by 2030,” McMichael-Phillips said. “However, with the progress that has already been made, and with the time left until the end of the decade, we know that we will be much closer to a fully mapped planet than the 6% that had been mapped when the project started.”</p>

<p>—Tim Hornyak (<a href="https://twitter.com/robotopia" target="_blank" rel="noreferrer noopener">@Robotopia</a>), Science Writer</p>

<h5><strong>Citation:</strong>&nbsp;Hornyak, T. (2024), New seafloor map only 25% done, with 6 years to go,&nbsp;<em>Eos, 105, </em><a href="https://doi.org/10.1029/2024EO240154" target="_blank" rel="noreferrer noopener">https://doi.org/10.1029/2024EO240154</a>. Published on 2 April 2024.</h5>

<h6><strong>Text © 2024. The authors.&nbsp;<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/" target="_blank" rel="noreferrer noopener">CC BY-NC-ND 3.0</a></strong><br><strong>Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.</strong></h6>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Improvements to static analysis in GCC 14 (173 pts)]]></title>
            <link>https://developers.redhat.com/articles/2024/04/03/improvements-static-analysis-gcc-14-compiler</link>
            <guid>39917509</guid>
            <pubDate>Wed, 03 Apr 2024 13:54:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.redhat.com/articles/2024/04/03/improvements-static-analysis-gcc-14-compiler">https://developers.redhat.com/articles/2024/04/03/improvements-static-analysis-gcc-14-compiler</a>, See on <a href="https://news.ycombinator.com/item?id=39917509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
<p>I work at Red Hat on <a href="https://gcc.gnu.org/">GCC, the GNU Compiler Collection</a>.&nbsp;For the last five releases of GCC, I've been working on <code>-fanalyzer</code>, a static analysis pass that tries to identify various problems at compile-time, rather than at runtime. It performs "symbolic execution" of <a href="https://developers.redhat.com/topics/c">C</a> source code—effectively simulating the behavior of the code along the various possible paths of execution through it.</p>

<p>This article summarizes what's new with <code>-fanalyzer</code> in <a href="https://gcc.gnu.org/gcc-14/changes.html">GCC 14</a>, which I hope will be officially released sometime in April 2024.</p>

<h2>Solving the halting problem?</h2>

<p>Obviously <a href="https://en.wikipedia.org/wiki/Halting_problem">I'm kidding with the title</a> here, but for GCC 14 I've implemented a new warning: <a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-infinite-loop">-Wanalyzer-infinite-loop</a>&nbsp;that's able to detect some simple cases of infinite loops.</p>

<p>For example, consider the following C code:</p>

<pre><code>void test (int m, int n)
{
  float arr[m][n];
  for (int i = 0; i &lt; m; i++)
    for (int j = 0; j &lt; n; i++)
      arr[i][j] = 0.f;
  /* etc */
}
</code></pre>

<p>If you look closely, you'll see that the user probably made the second <code>for</code> statement by copying the first one, but forgot to change the increment clause from an <code>i</code> to a <code>j</code>.</p>

<p>GCC 14's <a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-fanalyzer">-fanalyzer</a>&nbsp;option successfully detects this, with this output:</p>

<pre><code> warning: infinite loop [CWE-835] [-Wanalyzer-infinite-loop]
    5 |     for (int j = 0; j &lt; n; i++)
      |                     ~~^~~
  'test': events 1-5
    |
    |    5 |     for (int j = 0; j &lt; n; i++)
    |      |                     ~~^~~  ~~~
    |      |                       |     |
    |      |                       |     (4) looping back...
    |      |                       (1) infinite loop here
    |      |                       (2) when 'j &lt; n': always following 'true' branch...
    |      |                       (5) ...to here
    |    6 |       arr[i][j] = 0.f;
    |      |       ~~~~~~~~~        
    |      |             |
    |      |             (3) ...to here
    |
</code></pre>

<p>The output could be more readable here—you have to read the events in order of their numbers, from <code>(1)</code> to <code>(5)</code>. For GCC 15 I hope to improve this, perhaps with ASCII art that highlights the path taken by control flow.</p>

<p>I find the Compiler Explorer website very useful for trying out code snippets with different compilers and options. You can try the above example on it <a href="https://godbolt.org/z/vn55nn43z">here</a>.</p>

<h2>Visualizing buffer overflows</h2>

<p>The analyzer gained support in GCC 13 for bounds checking with a <a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-out-of-bounds">-Wanalyzer-out-of-bounds</a>&nbsp;warning.</p>

<p>For example, given the out-of-bounds write in <code>strcat</code> in:</p>

<pre><code>#include &lt;string.h&gt;

void test (void)
{
  char buf[10];
  strcpy (buf, "hello");
  strcat (buf, " world!");
}
</code></pre>

<p>The analyzer emits this message:</p>

<pre><code>&lt;source&gt;: In function 'test':
&lt;source&gt;:7:3: warning: stack-based buffer overflow [CWE-121] [-Wanalyzer-out-of-bounds]
    7 |   strcat (buf, " world!");
      |   ^~~~~~~~~~~~~~~~~~~~~~~
  'test': events 1-2
    |
    |    5 |   char buf[10];
    |      |        ^~~
    |      |        |
    |      |        (1) capacity: 10 bytes
    |    6 |   strcpy (buf, "hello");
    |    7 |   strcat (buf, " world!");
    |      |   ~~~~~~~~~~~~~~~~~~~~~~~
    |      |   |
    |      |   (2) out-of-bounds write from byte 10 till byte 12 but 'buf' ends at byte 10
    |
&lt;source&gt;:7:3: note: write of 3 bytes to beyond the end of 'buf'
    7 |   strcat (buf, " world!");
      |   ^~~~~~~~~~~~~~~~~~~~~~~
&lt;source&gt;:7:3: note: valid subscripts for 'buf' are '[0]' to '[9]'

</code></pre>

<p>I've been unhappy with the readability of these messages: it describes some aspects of the problem, but it's hard for the user to grasp exactly what the analyzer is "thinking."</p>

<p>So for GCC 14, I've added the ability for the analyzer to emit text-based diagrams visualizing the spatial relationships in a predicted buffer overflow. For the above example (which you can try <a href="https://godbolt.org/z/qM3hYKzjx">here in Compiler Explorer</a>) it emits the diagram shown in Figure 1.</p>

<figure role="group">
<figure><a href="https://developers.redhat.com/sites/default/files/screenshot_from_2024-03-28_16-05-22.png" data-featherlight="image"><img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2024-03-28_16-05-22.png?itok=DlDqiM5y" width="600" height="396" alt="Screenshot of diagram showing buffer overflow" typeof="foaf:Image"></a>

  </figure><figcaption>Figure 1:&nbsp;Visualizing buffer overflows in GCC 14.</figcaption></figure><p>This diagram shows the destination buffer populated by the content from the <code>strcpy</code> call, and thus the existing terminating <code>NUL</code> byte used for the start of the <code>strcat</code> call.</p>

<p>For non-ASCII strings such as this:</p>

<pre><code>#include &lt;string.h&gt;

void test (void)
{
  char buf[11];
  strcpy (buf, "サツキ");
  strcat (buf, "メイ");
}
</code></pre>

<p>It can show the UTF-8 representation of the characters (Figure 2).</p>

<figure role="group">
<figure><a href="https://developers.redhat.com/sites/default/files/screenshot_from_2024-03-28_16-04-16.png" data-featherlight="image"><img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2024-03-28_16-04-16.png?itok=U3zQXlQ_" width="600" height="453" alt="FIXME" typeof="foaf:Image"></a>

  </figure><figcaption>Figure 2: Visualizing non-ASCII strings in GCC 14.</figcaption></figure><p>This demonstrates that the overflow happens partway through the <a href="https://en.wiktionary.org/wiki/%E3%83%A1">メ character (U+30E1)</a>. (<a href="https://godbolt.org/z/eKn9rMTWG">Link to Compiler Explorer</a>).</p>

<h2>Analyzing C string operations</h2>

<p>I've put some work into better tracking C string operations in GCC 14's analyzer.</p>

<p>One of the improvements is that the analyzer now simulates APIs that scan a buffer expecting a null terminator byte, and will complain about code paths where a pointer to a buffer that isn't properly terminated is passed to such an API.</p>

<p>I've added a new function attribute <a href="http://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#index-null_005fterminated_005fstring_005farg-function-attribute">null_terminated_string_arg(<em>PARAM_IDX</em>)</a>&nbsp;for telling the analyzer (and human readers of the code) about parameters that are expected to be null-terminated strings. For example, given this buggy code:</p>

<pre><code>extern char *
example_fn (const char *p)
  __attribute__((null_terminated_string_arg (1)))
  __attribute__((nonnull));

char *
test_unterminated_str (void)
{
  char str[3] = "abc";
  return example_fn (str);
}
</code></pre>

<p>Here, the analyzer correctly complains that <code>str</code> doesn't have a null terminator byte, and thus <code>example_fn</code> will presumably read past the end of the buffer:</p>

<pre><code>&lt;source&gt;: In function 'test_unterminated_str':
&lt;source&gt;:10:10: warning: stack-based buffer over-read [CWE-126] [-Wanalyzer-out-of-bounds]
   10 |   return example_fn (str);
      |          ^~~~~~~~~~~~~~~~
  'test_unterminated_str': events 1-3
    |
    |    9 |   char str[3] = "abc";
    |      |        ^~~
    |      |        |
    |      |        (1) capacity: 3 bytes
    |   10 |   return example_fn (str);
    |      |          ~~~~~~~~~~~~~~~~
    |      |          |
    |      |          (2) while looking for null terminator for argument 1 ('&amp;str') of 'example_fn'...
    |      |          (3) out-of-bounds read at byte 3 but 'str' ends at byte 3
    |
&lt;source&gt;:10:10: note: read of 1 byte from after the end of 'str'
   10 |   return example_fn (str);
      |          ^~~~~~~~~~~~~~~~
&lt;source&gt;:10:10: note: valid subscripts for 'str' are '[0]' to '[2]'

                                                       ┌─────────────────┐
                                                       │ read of 1 byte  │
                                                       └─────────────────┘
                                                                ^
                                                                │
                                                                │
  ┌─────────────────┬────────────────┬────────────────┐┌─────────────────┐
  │       [0]       │      ...       │      [2]       ││                 │
  ├─────────────────┴────────────────┴────────────────┤│after valid range│
  │              'str' (type: 'char[3]')              ││                 │
  └───────────────────────────────────────────────────┘└─────────────────┘
  ├─────────────────────────┬─────────────────────────┤├────────┬────────┤
                            │                                   │
                     ╭──────┴──────╮                ╭───────────┴──────────╮
                     │size: 3 bytes│                │  over-read of 1 byte │
                     ╰─────────────╯                ╰──────────────────────╯

&lt;source&gt;:2:1: note: argument 1 of 'example_fn' must be a pointer to a null-terminated string
    2 | example_fn (const char *p)
      | ^~~~~~~~~~</code></pre>

<p>Again, you can <a href="https://godbolt.org/z/naoa6oq5b">try this example in Compiler Explorer here</a>.</p>

<h2>Taint analysis</h2>

<p>The analyzer has a form of "taint analysis", which tracks attacker-controlled inputs, places where they are sanitized, and places where they are used without sanitization. In previous GCC releases this was too buggy to enable by default, with lots of false positives, so I hid it behind an extra command-line argument. I've fixed many bugs with this, so for GCC 14 I've enabled this by default when <a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-fanalyzer">-fanalyzer</a>&nbsp;is selected. This also enables these 6 taint-based warnings:</p>

<ul><li><a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-tainted-allocation-size">-Wanalyzer-tainted-allocation-size</a></li>
	<li><a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-tainted-array-index">-Wanalyzer-tainted-array-index</a></li>
	<li><a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-tainted-assertion">-Wanalyzer-tainted-assertion</a></li>
	<li><a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-tainted-divisor">-Wanalyzer-tainted-divisor</a></li>
	<li><a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-tainted-offset">-Wanalyzer-tainted-offset</a></li>
	<li><a href="http://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html#index-Wanalyzer-tainted-size">-Wanalyzer-tainted-size</a></li>
</ul><p>For example, here's an excerpt from <a href="https://access.redhat.com/security/cve/CVE-2011-2210">CVE-2011-2210</a> from the Linux kernel:</p>

<pre><code>extern struct hwrpb_struct *hwrpb;

SYSCALL_DEFINE5(osf_getsysinfo, unsigned long, op, void __user *, buffer,
		unsigned long, nbytes, int __user *, start, void __user *, arg)
{
	/* [...snip...] */

	/* case GSI_GET_HWRPB: */
		if (nbytes &lt; sizeof(*hwrpb))
			return -1;

		if (copy_to_user(buffer, hwrpb, nbytes) != 0)
			return -2;

		return 1;

	/* [...snip...] */
}
</code></pre>

<p>You can see <a href="https://godbolt.org/z/sqsx8avfG">a more full version at Compiler Explorer</a>. In particular, I added <code>__attribute__((tainted_args))</code> to the <code>__SYSCALL_DEFINEx</code> macro to indicate to the analyzer that the arguments to <code>osf_getsysinfo</code> are coming from across a trust boundary, and thus should be considered tainted.</p>

<p>With GCC 14, the analyzer is able to detect the vulnerability (again, edited somewhat for brevity):</p>

<pre><code>&lt;source&gt;: In function 'sys_osf_getsysinfo':
&lt;source&gt;:55:21: warning: use of attacker-controlled value 'nbytes' as size without upper-bounds checking [CWE-129] [-Wanalyzer-tainted-size]
   55 |                 if (copy_to_user(buffer, hwrpb, nbytes) != 0)
      |                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  'sys_osf_getsysinfo': event 1
    |
    |   28 |         long sys##name(__SC_DECL##x(__VA_ARGS__))
    |      |              ^~~
    |      |              |
    |      |              (1) function 'sys_osf_getsysinfo' marked with '__attribute__((tainted_args))'
    |
    +--&gt; 'sys_osf_getsysinfo': event 2
           |
           |   28 |         long sys##name(__SC_DECL##x(__VA_ARGS__))
           |      |              ^~~
           |      |              |
           |      |              (2) entry to 'sys_osf_getsysinfo'
           |
         'sys_osf_getsysinfo': events 3-6
           |
           |   52 |                 if (nbytes &lt; sizeof(*hwrpb))
           |      |                    ^
           |      |                    |
           |      |                    (3) 'nbytes' has its lower bound checked here
           |      |                    (4) following 'false' branch (when 'nbytes &gt; 31')...
           |......
           |   55 |                 if (copy_to_user(buffer, hwrpb, nbytes) != 0)
           |      |                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           |      |                     |
           |      |                     (5) ...to here
           |      |                     (6) use of attacker-controlled value 'nbytes' as size without upper-bounds checking
           |
&lt;source&gt;:11:13: note: parameter 3 of 'copy_to_user' marked as a size via attribute 'access (write_only, 1, 3)'
   11 | extern long copy_to_user(void __user *to, const void *from, unsigned long n)
      |             ^~~~~~~~~~~~
</code></pre>

<p>The issue is that the attempt to sanitize <code>nbytes</code> was written as</p>

<pre><code>if (nbytes &lt; sizeof(*hwrpb))</code></pre>

<p>when it should have been</p>

<pre><code>if (nbytes &gt; sizeof(*hwrpb))</code></pre>

<p>With a fixed version of that conditional, the <a href="https://godbolt.org/z/vecezenKj">analyzer is silent</a>.</p>

<p>I'm continuing to work on running the analyzer on the kernel to look for vulnerabilities (and fix false positives in the analyzer).</p>

<h2>Try it out!</h2>

<p>We're still fixing bugs, but we hope that <a href="https://gcc.gnu.org/gcc-14/changes.html">GCC 14</a> will be ready to officially release (as 14.1) sometime in April 2024.</p>

<p>With my "downstream" hat on, we're already using the prerelease (GCC 14.0) within <a href="https://fedoramagazine.org/announcing-fedora-linux-40-beta/">Fedora 40 Beta</a>.</p>

<p>Finally, you can use the <a href="https://godbolt.org/z/YTx3Pfocn">excellent Compiler Explorer site</a> to play with the new compiler. Have fun!</p>

          
                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare R2 IA storage tier (127 pts)]]></title>
            <link>https://blog.cloudflare.com/r2-events-gcs-migration-infrequent-access</link>
            <guid>39916972</guid>
            <pubDate>Wed, 03 Apr 2024 13:08:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/r2-events-gcs-migration-infrequent-access">https://blog.cloudflare.com/r2-events-gcs-migration-infrequent-access</a>, See on <a href="https://news.ycombinator.com/item?id=39916972">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>04/03/2024</p><section><p>4 min read</p><div><figure><img src="https://blog.cloudflare.com/content/images/2024/04/image3-1.png" alt="R2 adds event notifications, support for migrations from Google Cloud Storage, and an infrequent access storage tier" loading="lazy" width="1800" height="1013"></figure><p>We’re excited to announce three new features for Cloudflare R2, our zero <a href="https://www.cloudflare.com/learning/cloud/what-are-data-egress-fees/">egress fee</a> <a href="https://www.cloudflare.com/learning/cloud/what-is-object-storage/">object storage</a> platform:</p><ul><li><a href="#event-notifications-open-beta">Event Notifications</a>: Automatically trigger Workers and take action when data in your R2 bucket changes.</li><li><a href="#super-slurper-for-google-cloud-storage">Super Slurper for Google Cloud Storage</a>: Easily migrate data from Google Cloud Storage to Cloudflare R2.</li><li><a href="#infrequent-access-private-beta">Infrequent Access Private Beta</a>: Pay less to store data that isn’t frequently accessed. Now in private beta (<a href="https://forms.gle/hnwHFjaZktWyzmbd9">sign up now</a>).</li></ul><h2 id="event-notifications-open-beta">Event Notifications Open Beta</h2><figure><img src="https://blog.cloudflare.com/content/images/2024/04/image1-1.png" alt="" loading="lazy" width="1200" height="384"></figure><p>The lifecycle of data often doesn’t stop immediately after upload to an R2 bucket – event data may need to be transformed and loaded into a data warehouse, media files may need to go through a post-processing step, etc. We’re releasing event notifications for R2 in open beta to enable building applications and workflows driven by your changing data.</p><p>Event notifications work by sending messages to your <a href="https://developers.cloudflare.com/queues/">queue</a> each time there is a change to your data. These messages are then received by a <a href="https://developers.cloudflare.com/queues/get-started/#5-create-your-consumer-worker">consumer Worker</a> where you can then define any subsequent action that needs to be taken. </p><p>To get started enabling event notifications on your R2 bucket, you can run the following <a href="https://developers.cloudflare.com/workers/wrangler/">Wrangler</a> command (replacing bucket_name and queue_name with your bucket and queue names respectively):</p><pre><code>wrangler r2 bucket notification create &lt;bucket_name&gt; --event-type object-create --queue &lt;queue_name&gt;
</code></pre><p>For more information on how to set up event notifications on your R2 buckets today and limitations during beta, please refer to the <a href="https://developers.cloudflare.com/r2/buckets/event-notifications/">documentation</a>.</p><h2 id="super-slurper-for-google-cloud-storage">Super Slurper for Google Cloud Storage</h2><figure><img src="https://blog.cloudflare.com/content/images/2024/04/image4-1.png" alt="" loading="lazy" width="1999" height="677"></figure><p><a href="https://developers.cloudflare.com/r2/data-migration/super-slurper/">Super Slurper</a> can now migrate data from Google Cloud Storage (GCS) to <a href="https://developers.cloudflare.com/r2/">Cloudflare R2</a>. We released Super Slurper <a href="https://blog.cloudflare.com/r2-super-slurper-ga">last year</a> with the goal of making one-time comprehensive data migrations fast, reliable, and easy: there’s no need to spin up migration VMs and implement complicated retry logic. Since then, thousands of developers have used Super Slurper to migrate petabytes of data from AWS S3 to R2. Now Google Cloud Storage customers can migrate data to Cloudflare R2 to benefit from Cloudflare’s zero egress fees, whether you are permanently moving data to another provider or not.</p><p>To get started migrating data from GCS:</p><ol><li>From the Cloudflare dashboard, select<strong> R2 &gt; Data Migration</strong>.</li><li>Select <strong>Migrate files</strong>.</li><li>Select <strong>Google Cloud Storage</strong> for the source bucket provider.</li><li>Enter your bucket name and associated credentials and select <strong>Next</strong>.</li><li>Enter your R2 bucket name and associated credentials and select <strong>Next</strong>.</li><li>After you finish reviewing the details of your migration, select <strong>Migrate files</strong>.</li></ol><p>You can view the status of your migration job at any time on the dashboard. For more information on how to use Super Slurper, please refer to the documentation <a href="https://developers.cloudflare.com/r2/data-migration/super-slurper/">here</a>.</p><h2 id="infrequent-access-private-beta">Infrequent Access Private Beta</h2><figure><img src="https://blog.cloudflare.com/content/images/2024/04/image2-1.png" alt="" loading="lazy" width="1999" height="898"></figure><p>We’re excited to introduce the private beta of our new Infrequent Access storage class. For use cases that involve data that isn’t frequently accessed (long tail user-generated content, logs, etc), Infrequent Access gives you the ability to pay less for storage while maintaining performance and durability.</p><p>Here’s an example of how you can upload an object to your R2 bucket with the new Infrequent Access storage class using <a href="https://developers.cloudflare.com/workers/">Workers</a>:</p><pre><code># wrangler.toml
[[r2_buckets]]
binding = 'MY_BUCKET'
bucket_name = '&lt;YOUR_BUCKET_NAME&gt;'

# index.ts
export default {
   async fetch(request: Request, env: Env): Promise&lt;Response&gt; {
      if (request.method === "PUT") {
         await env.MY_BUCKET.put("myobject", request.body, storageClass: "InfrequentAccess");
         return new Response("Put object successfully!");
      }
      return new Response("Not a PUT!");
   }
}
</code></pre><p>In addition to uploading objects directly to Infrequent Access, you can define an <a href="https://developers.cloudflare.com/r2/buckets/object-lifecycles/">object lifecycle policy</a> to move data to Infrequent Access after a period of time goes by and you no longer need to access your data as often. In the future, we plan to automatically optimize storage classes for data so you can avoid manually creating rules and better adapt to changing data access patterns.</p><p>For data stored in the Infrequent Access storage class, the pricing components will be similar to <a href="https://developers.cloudflare.com/r2/pricing/">what you’re used to with R2</a>: storage, <a href="https://developers.cloudflare.com/r2/pricing/#class-a-operations">Class A operations</a> (writes, lists), <a href="https://developers.cloudflare.com/r2/pricing/#class-b-operations">Class B operations</a> (reads), and data retrieval (processing). Data retrieval is charged per GB when data in the Infrequent Access storage class is retrieved and is what allows us to provide storage at a lower price. It reflects the additional computational resources required to fetch data from underlying storage optimized for less frequent access. And when the time comes, and you do need to use your data, there are still no egress fees.</p><!--kg-card-begin: html-->
<table>
<colgroup>
<col>
<col>
</colgroup>
<thead>
  <tr>
    <th><span>Component</span></th>
    <th><span>Price</span></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><span>Storage</span></td>
    <td><span>$0.01 / GB-month</span></td>
  </tr>
  <tr>
    <td><span>Class A Operations</span></td>
    <td><span>$9.00 / million requests</span></td>
  </tr>
  <tr>
    <td><span>Class B Operations</span></td>
    <td><span>$0.90 / million requests</span></td>
  </tr>
  <tr>
    <td><span>Data Retrieval (Processing)</span></td>
    <td><span>$0.01 / GB</span></td>
  </tr>
  <tr>
    <td><span>Egress (or Data Transfer)</span></td>
    <td><span>$0 - No Charge</span></td>
  </tr>
</tbody>
</table><!--kg-card-end: html--><h4 id="are-you-interested-in-participating-in-the-private-beta-for-infrequent-access">Are you interested in participating in the private beta for Infrequent Access?</h4><p><a href="https://forms.gle/hnwHFjaZktWyzmbd9">Join the private beta waitlist</a> to get access.</p><h3 id="have-any-feedback">Have any feedback?</h3><p>We would love to hear from you! To share your feedback about R2 and our data migration services, please join the <a href="https://discord.com/invite/cloudflaredev">Cloudflare Developer Discord</a>. If you're interested in learning more about R2, get started by visiting R2's <a href="https://developers.cloudflare.com/r2/">developer documentation</a> or see how much you could save with our <a href="https://r2-calculator.cloudflare.com/">pricing calculator</a>.</p></div></section><div><p>We protect <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, help customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerate any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">ward off DDoS attacks</a>, keep <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/developer-week">Developer Week</a><a href="https://blog.cloudflare.com/tag/developers">Developers</a><a href="https://blog.cloudflare.com/tag/cloudflare-r2">R2 Storage</a><a href="https://blog.cloudflare.com/tag/product-news">Product News</a><a href="https://blog.cloudflare.com/tag/developer-platform">Developer Platform</a></article></div><div data-testid="related-posts-section"><p>Related posts</p><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-04-03T14:03:09.000+01:00">April 03, 2024  1:03 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/prisma-orm-and-d1"><h2>Improving Cloudflare Workers and D1 developer experience with Prisma ORM</h2></a><p data-testid="related-posts-article-excerpt">Together, Cloudflare and Prisma make it easier than ever to deploy globally available apps with a focus on developer experience. To further that goal, Prisma ORM now natively supports Cloudflare Workers and D1 in Preview<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-04-03T14:00:17.000+01:00">April 03, 2024  1:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/data-anywhere-events-pipelines-durable-execution-workflows"><h2>Data Anywhere with Pipelines, Event Notifications, and Workflows</h2></a><p data-testid="related-posts-article-excerpt">We’re making it easier to build scalable, reliable, data-driven applications on top of our global network, and so we’re announcing a new Event Notifications framework; our take on durable execution, Workflows; and an upcoming streaming ingestion service, Pipelines<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-04-03T14:00:02.000+01:00">April 03, 2024  1:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/picsart-move-to-workers-huge-performance-gains"><h2>How Picsart leverages Cloudflare's Developer Platform to build globally performant services</h2></a><p data-testid="related-posts-article-excerpt">Picsart, one of the world’s largest digital creation platforms, encountered performance challenges in catering to its global audience. Adopting Cloudflare's global-by-default Developer Platform emerged as the optimal solution, empowering Picsart to enhance performance and scalability substantially<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-04-02T14:01:00.000+01:00">April 02, 2024  1:01 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/workers-ai-ga-huggingface-loras-python-support"><h2>Leveling up Workers AI: general availability and more new capabilities</h2></a><p data-testid="related-posts-article-excerpt">Today, we’re excited to make a series of announcements, including Workers AI, Cloudflare’s inference platform becoming GA and support for fine-tuned models with LoRAs and one-click deploys from HuggingFace. Cloudflare Workers now supports the Python programming language, and more<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li><li></li><li></li><li></li></ul></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No joke: FTC boss goes on the Daily Show and is told Apple tried to block her (163 pts)]]></title>
            <link>https://www.theregister.com/2024/04/02/ftc_boss_apple_daily_show/</link>
            <guid>39916939</guid>
            <pubDate>Wed, 03 Apr 2024 13:05:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/04/02/ftc_boss_apple_daily_show/">https://www.theregister.com/2024/04/02/ftc_boss_apple_daily_show/</a>, See on <a href="https://news.ycombinator.com/item?id=39916939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Comment</span> Generally the head of US government agencies and comedy don't mix, but on Monday night Lina Khan, boss of the Federal Trade Commission, was on the Daily Show recounting how the agency is going after Amazon, Facebook and others over monopolistic practices. She also got evidence of her <em>persona non grata</em> status with Cook &amp; Co.</p>
<p>Khan was welcomed onto the telly news commentary show, chaired once again by Jon Stewart, with cheers from the crowd - again not something many US government officials hear. The exception to this is possibly Rob Joyce, the former White House cybersecurity coordinator and recently <a target="_blank" rel="nofollow" href="https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3681065/national-security-agency-announces-retirement-of-cybersecurity-director/">retired</a> NSA cybersecurity director, who got a <a target="_blank" href="https://www.theregister.com/2018/01/22/rob_joyce_hacking/">standing ovation</a> at the Shmoocon infosec conference after a presentation on how he hacks Christmas tree lights for fun.</p>
<p>In the 20-minute interview, Khan gave details on an ongoing lawsuit against Amazon's behavior - notably allegedly spamming search results pages and hiking fees on small businesses, which she said was "harming customers."</p>

    

<p>You can replay her appearance on the Comedy Central / Paramount+ / kinda YouTube program below.</p>

        


        

<p>
  <a href="https://www.youtube.com/watch?v=oaDTiWaYfcM" data-media="x-videoplayer">Youtube Video</a>
</p>
<p>It was going to be a tough fight, she said, since her watchdog agency has just 1,200 staff and Amazon has "monopoly money," and can throw ten times that number of lawyers at the case. "We're pretty out-gunned but not out-matched," she asserted.</p>

        

<p>But then Stewart dropped his bombshell: After a two-season podcast series with Apple he told Khan he wanted to get her on the show but Cupertino really wasn't keen.</p>
<p>"Apple asked us not to do it, to have you. They literally said 'please don't talk to her'... I didn't think they cared for you," Stewart said. Khan made an admirable, and nearly successful, attempt to keep a straight face.</p>
<p>Stewart also alleged that Apple refused to let his team make jokes about AI. He quit the podcast abruptly last October, reportedly citing Apple's heavy handed approach to censoring certain topics and guests.</p>

        

<p>"This just shows the dangers when you concentrate so much power and so much decision-making in a small number of companies," she argued.</p>
<p>"Going back all the way to the founding there was a recognition that in the same way that you need the Constitution to create checks and balances in our political sphere, you also needed the antitrust and anti-monopoly laws to safeguard against concentration of economic power because you don't want an autocrat of trade in the same way you don't want a monarch."</p>
<ul>

<li><a href="https://www.theregister.com/2024/02/16/ftc_ai_fakes/">FTC asks normal folks if they'd like AI impersonation scam protection, too</a></li>

<li><a href="https://www.theregister.com/2024/02/14/amazon_ftc_antitrust/">Date set for for epic Amazon-FTC antitrust showdown</a></li>

<li><a href="https://www.theregister.com/2024/02/02/ftc_blackbaud_settlement/">Blackbaud settles with FTC after that IT breach exposed millions of people's info</a></li>

<li><a href="https://www.theregister.com/2024/01/25/ftc_ai_inquiry/">FTC drills into Amazon, Microsoft, Google over billions pledged to OpenAI, Anthropic</a></li>
</ul>
<p>The amount of consolidation in the tech industry is harming competition, she argued. The FTC's case against Meta (<a target="_blank" href="https://www.theregister.com/2020/12/09/facebook_crushed_competitors_to_maintain/">started</a> before Khan got the top job) was a case in point - Facebook realized it couldn't defeat Instagram and WhatsApp, so just bought them, she asserted.</p>
<h3>So, how's that working out? Pretty good it seems</h3>
<p>When Khan <a target="_blank" href="https://www.theregister.com/2021/06/16/lina_khan_ftc/">was appointed</a> FTC chair in 2021 it must have sent shivers down the spine of many in the tech industry, particularly in Seattle.</p>
<p>Her 2017 <a target="_blank" rel="nofollow" href="https://www.yalelawjournal.org/pdf/e.710.Khan.805_zuvfyyeh.pdf">paper</a> [PDF] titled "Amazon's antitrust paradox" lays out the case that too few players exert a disproportionate amount of power in the tech industry.</p>
<p>And while traditionally monopolies were thought of as a single company dominating the industry (<em>cough</em>, Microsoft in the 1990s), customers are still shafted if even a few businesses corner a market.</p>
<p>As an immigrant to Silicon Valley and the San Francisco Bay Area it is astonishing to this humble vulture that this free-market nation is anything but in so many areas. Though it depends on where one lives, good luck getting a decent, healthy choice of ISP or cellphone carrier. And for a region that is a major tech hub of America the internet speeds and prices came as a rude shock.</p>
<p>Coming from Europe where telcos fight for your business, the change was remarkable. This hack may have been somewhat terse with a Verizon staffer trying to tell me that paying for text messages (an engineering function that carries the most minimal of data loads) was cheap at the price of just $5 a month. But with so little choice such predatory pricing is possible.</p>
<p>So far, the FTC appears to be getting much more muscular in going after alleged monopolistic practices, and it's about time. Frankly it's insane that an agency with such an important role in ensuring fair and open markets has such tiny staffing levels and funding.</p>
<p>But while the regulator is small it does have legal powers, and is increasingly asserting them. The question is how far can they be pushed, and with what consequences.</p>
<p>On <em>The Register</em>, when folks get fined we generally cite the sometimes large figures involved as a proportion of current profit, to give some perspective. When the FTC imposed a $5bn fine on Facebook back in 2019 over the <a target="_blank" href="https://www.theregister.com/2019/07/12/ftc_facebook_settlement_proposal/">Cambridge Analytica scandal</a>, for example, that amounted to one percent of its market cap. Zuckerberg must have been shaking in his sneakers.</p>
<p>And this was the point Khan made: "Over the last couple of decades we've seen how businesses can just treat fines as a cost of doing business. And we need to make sure we're actually deterring illegal behavior."</p>
<p>The Tl;dr: Businesses only obey the bottom line. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LiveView Is Best with Svelte (220 pts)]]></title>
            <link>https://blog.sequin.io/liveview-is-best-with-svelte/</link>
            <guid>39916144</guid>
            <pubDate>Wed, 03 Apr 2024 11:41:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.sequin.io/liveview-is-best-with-svelte/">https://blog.sequin.io/liveview-is-best-with-svelte/</a>, See on <a href="https://news.ycombinator.com/item?id=39916144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>We’re <a href="https://sequin.io/?ref=blog.sequin.io">Sequin</a>. We stream data from services like Salesforce, Stripe, and AWS to messaging systems like Kafka and databases like Postgres. As an infrastructure company, we questioned if we really need a SPA. So, we started with LiveView, which helped us move fast but left us wanting more. This post is about that journey.
</p>
<p>Phoenix's <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html?ref=blog.sequin.io">LiveView</a> has polarized our team. Compared to SPA, there are components and features that we’re able to build 2-3x faster. Conversely, there are components and features that are frustrating to build or feel very counterintuitive.</p>
<p>Said another way, LiveView makes a lot of things easy. But it also makes some easy things hard.</p>
<p>This created tension. Do we keep forging down this path? Or do we give in and convert our app to a SPA?</p>
<p>Fortunately, we found a companion library called <a href="https://github.com/woutdp/live_svelte?ref=blog.sequin.io">LiveSvelte</a>. LiveView enables a development experience with Svelte that’s unlike any other fullstack paradigm I’ve used.</p>
<p>The team agrees: this is a killer way to build.</p>
<p>To appreciate the LiveView+Svelte paradigm, I’ll start by explaining how LiveView works and what makes it different. Then, I’ll detail the friction we encountered with a pure LiveView approach. At that point, you’ll be able to appreciate what LiveSvelte offers.</p>
<h2 id="what-is-liveview">What is LiveView</h2>
<p>LiveView offers a very unique way to build web applications.</p>
<p>In a traditional server-rendered web application, the server is stateless. The client requests a page and the server renders it. All client actions route back to the server, which re-renders the next page.</p>
<p>In a SPA, the client is in charge of building pages. It leverages a backend API to read and write data. Client apps are stateful (e.g. <code>useState</code> in React).</p>
<p>In LiveView, the server is in charge of rendering the page. But it’s stateful. Actions in the frontend are handled by the backend, but the server <em>incrementally</em> updates the DOM, much like in a SPA.</p>
<p>At a high-level, the reason a SPA is complex is because distributed systems are complex. Supporting a client JS app is supporting a microservice (and one that runs in a hostile, untrusted environment, no less!)</p>
<p>In <em>theory</em> your frontend app uses a backend REST API that <em>could</em> be used to support lots of different services and clients. In reality, the needs of your frontend app are unique. So your backend routes and controllers explode with functions that serve the needs of a single client.</p>
<p>If nothing else, this complexity just means shaving a lot of yaks. Each request requires a fair bit of plumbing on both the frontend and the backend. Callstacks can easily exceed half a dozen layers:</p>
<ul>
<li><code>onMount</code></li>
<li><code>await api.fetchUsers</code></li>
<li><code>parseResponse</code></li>
<li><code>Router.handle(/api/users)</code></li>
<li><code>AuthPlug.verify_cookie</code></li>
<li><code>UsersController.index</code></li>
<li><code>Users.list_for_org</code></li>
<li><code>ApiHelpers.prepare_response</code></li>
</ul>
<p>The promise of LiveView is that you get to create rich client-side experiences without the frontend microservice. You're back to the much simpler world where you can query the database in the function adjacent to the function that renders your table rows. If a new row comes in, you just need to push it to your table, and LiveView will update the client for you.</p>
<p>But in addition, you also get to enjoy building an app using the stateful paradigm of frontend frameworks. It's much easier and faster to build rich interaction patterns this way vs prior backend paradigms where you'd need to "rebuild the world" on each request.</p>
<h2 id="where-liveview-makes-easy-things-hard">Where LiveView makes easy things hard</h2>
<p>There's a lot of good stuff in LiveView. But there are also real thorns.</p>
<p>There are two primary areas that we struggled with LiveView:</p>
<h3 id="client-side-state-is-inevitable">Client-side state is inevitable</h3>
<p>There is a (literal) speed of light limitation with this approach: your server can only be <em>so close</em> to your users.</p>
<p>Invariably, you’re going to need to do some stuff client-side. Animations, tooltips, showing/hiding DOM elements, disabling form fields, etc.</p>
<p>For example, there’s a form in our app with two interdependent dropdowns. Selecting an option in the first dropdown allows our server to generate the list for the second dropdown. To get the best UX, you want to disable the second dropdown immediately after the first dropdown changes. Then, when it’s repopulated by the server, you can re-enable it:</p>
<p><img src="https://blog.sequin.io/content/images/2024/03/CleanShot-2024-03-28-at-10.58.11-1.gif" alt="Two dropdowns, the second is disabled after the first changes">
</p>
<p><em>Simulating 1000ms of roundtrip latency between the client and the server.</em></p>
<p>To pull this off, as far as we could tell, you need to use two independent concepts in LiveView:</p>
<ul>
<li>Use the <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.JS.html?ref=blog.sequin.io">JS module</a> to disable the second dropdown when the first dropdown changes.</li>
<li>Use a <a href="https://hexdocs.pm/phoenix_live_view/js-interop.html?ref=blog.sequin.io#client-hooks-via-phx-hook">hook</a> to register an event listener on the second dropdown. Then, send an action to re-enable the second dropdown from the backend.</li>
</ul>
<p>And for slightly more complex interaction patterns, you’ll need to incorporate a <em>third</em> concept, LiveView state. For example, maybe you only want to re-enable the second dropdown in certain conditions.</p>
<p>The way these three concepts fit together is not obvious (we’re still not sure this is the right pattern!)</p>
<p>So, while the server is in charge of a lot of DOM changes, it can’t command all of them. You use JS and hooks to sprinkle in JavaScript where needed. These tools feel side-chained to core LiveView, and therefore their patterns of use are not obvious. And the more JS and hooks you use, the more of your DOM state now exists <em>outside</em> of LiveView.</p>
<p>This is a stark contrast to a paradigm like React. In React, it’s state and actions all the way down. With that core concept, you can do most anything. And there is no blurry line between DOM state and component state.</p>
<p>React can take that approach because there’s no latency between client-side actions and client-side state. This means you can let React’s state paradigm handle every action and transition. Because all of LiveView’s state is server-side, it has to contend with the latency between client-side actions and server-side state. This means that while LiveView state <em>looks like</em> other frontend frameworks, the model is actually quite different.</p>
<p>Take input fields, for example. In React, a character can’t be inserted into an input field without routing through state. This unlocks a powerful programming model, where your component re-renders – and therefore responds – to every keystroke. It gives the state and action paradigm a lot of reach, where you can use one core concept (<code>useState</code>) to solve a huge space of problems.</p>
<p>In LiveView, it’s more accurate to say that the input field is changed by the user, <em>and then</em> a short while later LiveView finds out about it and reacts to it. With no latency, <em>it looks a lot like React</em>. But with increased latency, it’s quite a different paradigm.</p>
<p>In frontend frameworks like React, you need to contend with server-side latency all the time. But <em>when</em> a high-latency action is going to take place is clear (i.e. you’re fetching from a server). In LiveView, the boundary is murkier.</p>
<h3 id="three-components">Three components</h3>
<p>LiveView has three different types of components: LiveViews, LiveComponents, and Components.</p>
<p>LiveViews and LiveComponents are like stateful components in React, whereas Components are like functional components.</p>
<p>Importantly, a LiveView will always be the uppermost parent component. You render LiveComponents and Components as children underneath a LiveView.</p>
<p>In React, it's easy to switch between stateful and functional components–just add or remove <code>useState</code> hooks. The API for both are the same (they both accept props in the same way). And outside state, they have an identical feature set. For example, they can both register and respond to DOM events in the same way.</p>
<p>The ease of switching between component types is important. As an app matures, you’re constantly factoring out components. You’re figuring out which bits should be reused, what should be generalized, where state should live, etc.</p>
<p>In LiveView, all three components are very different. As a result, refactoring a LiveView into a LiveComponent is surprisingly cumbersome.</p>
<p>In particular:</p>
<ul>
<li>The syntax for rendering and passing props to LiveViews and LiveComponents is different.</li>
<li>The lifecycle of LiveViews and LiveComponents are different.</li>
<li>The <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveComponent.html?ref=blog.sequin.io#module-unifying-liveview-and-livecomponent-communication">communication options</a> between LiveViews and LiveComponents are different. For example, you <code>send</code> to LiveViews but <code>send_update</code> to LiveComponents.</li>
<li>LiveComponents are not processes, and so can't interact with the rest of the system like LiveViews can.</li>
</ul>
<p>That last point is what makes LiveComponents so different and so frustrating. The limitations <em>make sense</em>: A LiveView is a process. That's one of the best parts about a LiveView, they're "just processes" and so they can fit into your Elixir/OTP system like every other process. For example, you can use pub/sub in a LiveView to subscribe to system-wide changes.</p>
<p>A LiveComponent is <em>not</em> its own process, they are modules invoked by a LiveView. The parent LiveView process holds the state for all subcomponents. So, a LiveView has a <code>pid</code>, state, and an inbox; a LiveComponent does not. This means the LiveView also has to handle all message routing for its child LiveComponents.</p>
<p>This is in keeping with Elixir/OTP design principles: processes are the building blocks. To give LiveComponents the same powers of independent state management and action handling, they would each need to be their own process.</p>
<p>Still, for the life of me, I <em>really</em> struggled with LiveComponents. So often, I wanted to send my LiveComponent an event/action but didn't have a good way to do it. You end up using <code>send_update</code>, which is an awkward API. We couldn't decide: do we send <em>actions</em> via <code>send_update</code>, or do we use it to patch state? If we use it to patch state, how do we tell in our <code>update</code> clause whether we're mounting or updating?</p>
<h2 id="the-elusive-%E2%80%9Cliveview-way%E2%80%9D">The elusive “LiveView way”</h2>
<p>LiveView often made us feel like we were “missing something.” The “LiveView way” feels elusive.</p>
<p>Perhaps LiveView is in an uncanny valley. It shares a lot in common with contemporary frontend frameworks. So, our “React brains” and intuitions would kick in, driving us to use old patterns–but those would often lead to a dead end. More alienness would have forced us to recognize the differences and to approach problems differently.</p>
<p>You can do a lot with just LiveView state and actions. But there are limits, and when you hit them you need to switch paradigms.</p>
<p>It has components to help you organize and reuse code. But due to differences between JavaScript and Elixir, LiveView can’t really offer the same isomorphic component trees without a ton of abstraction, and so has LiveViews and LiveComponents.</p>
<p><strong>This is what makes LiveSvelte so promising</strong>. As you’ll see, it shifts more responsibility to the frontend. It embraces the fact that the frontend will have its own state. And it lets you take advantage of all the maturity of contemporary JavaScript component frameworks.</p>
<h2 id="liveview-svelte">LiveView + Svelte</h2>
<p>LiveSvelte lets you render Svelte components from LiveView. It's an awesome paradigm.</p>
<p>There’s a couple different ways to render Svelte from your LiveViews, but the most basic way looks like this:</p>
<pre><code># LiveView component
defmodule Web.SyncLive.Form do
  def render(assigns) do
    assigns = 
      assigns
      |&gt; Map.put(:encoded_collections, Enum.map(assigns.collections, &amp;encode_collection/1))
      |&gt; Map.put(:encoded_errors, encode_errors(assigns.changeset))
  
    ~H"""
      &lt;.svelte
        name="MyForm"
        props={
          %{
            collections: @encoded_collections,
            credential_options: @credential_options,
            errors: @encoded_errors,
          }
        }
        socket={@socket}
      /&gt;
    """
  end
end
</code></pre>
<p>This is an Elixir module, the LiveView. Inside the render, we first take our Elixir data structures and encode them for the frontend. We like the pattern of explicitly encoding Elixir structs and such as plain maps before passing to Svelte, like this:</p>
<pre><code>  defp encode_collection(%Collection{} = collection) do
    %{
      "id" =&gt; collection.id,
      "slug" =&gt; collection.slug,
      "name" =&gt; collection.name
    }
  end
</code></pre>
<p>We’re able to set props on the Svelte component. Those are passed down as you’d expect to the component:</p>
<pre><code>// Svelte component
&lt;script&gt;
  export let resource;
  export let credential_options = [];
  export let errors = {};
  export let live;
&lt;/script&gt;
</code></pre>
<p>One of the props that LiveSvelte sets for us is the <code>live</code> prop. To communicate from the Svelte component back up to the LiveView, we can call <code>live.pushEvent</code>. For example, check how easy it is to send the server changes to the form:</p>
<pre><code>&lt;script&gt;
  // ...
  $: {
    live.pushEvent("form_updated", { form }, () =&gt; {});
  }
&lt;/script&gt;
</code></pre>
<p>This is a reactive block in Svelte. It will be executed whenever the variable <code>form</code> is changed. (Kind of like a <code>useEffect</code>, where <code>form</code> is the dependency.)</p>
<p>The LiveView can handle and respond to the <code>pushEvent</code> using typical Elixir message handling semantics:</p>
<pre><code># In the LiveView
# ...
  @impl LiveView
  def handle_event("form_updated", %{"form" =&gt; form}, socket) do
    params = decode_params(socket, form)
    {:noreply, merge_changeset(socket, params)}
  end
  
  defp merge_changeset(socket, params) do
    changeset = Collection.create_changeset(socket.assigns.resource, params)

    assign(socket, :changeset, changeset)
  end
</code></pre>
<p>We first decode the params from the frontend, reversing any encoding/mapping we did on the way out. Then, <code>merge_changeset/2</code> updates our changeset. If there are any validation errors in the changeset, those will make their way back to the frontend via the <code>errors</code> prop.</p>
<p>So, you have data flow from Elixir down to the component via props. The LiveView process can update props at any time to cause the Svelte component to re-render. Any other communication can happen via the websocket.</p>
<p>The boundary between the two is very clear–just as clear as in any SPA.</p>
<p>What's most game-changing, though, is that you have a <em>backend, stateful process</em> that is collaborating with a <em>frontend, stateful process</em>.</p>
<p>And it's <em>so</em> fun and productive.</p>
<p>The three powerhouse properties:</p>
<ol>
<li>The backend controls the props on the frontend component.</li>
<li>The frontend <em>and</em> the backend are stateful.</li>
<li>You have a private, bi-directional communication channel between the two <em>where either side can initiate a message to the other</em>.</li>
</ol>
<p>#1 is made possible thanks to LiveView’s rendering paradigm: re-renders on the server are automatically pushed and applied to the client. This lets the server update props on the component just like a JS parent component can!</p>
<p>#2 is possible because a LiveView is a process. Processes are how Elixir encapsulates and reduces state.</p>
<p>#3 is made possible by the persistent websocket that LiveView gives you, wired to the frontend.</p>
<p>Consider the differences between this paradigm and a SPA:</p>
<p>First, all browser routing happens via the backend. This is a great simplifier. (In a regular SPA you have to maintain <em>two</em> sets of routes, one for the browser and one for your API.)</p>
<p>Second, the backend is stateful. It knows what route you’re on. Which resource you’re working with. Each action it handles can be far more incremental, as it’s applying a state change to itself vs rebuilding state from scratch.</p>
<p>Third, communication between the frontend and backend is private and coupled, as it should be. You’re not “polluting” your server’s public routes with a bunch of RPC calls that support a single component. When you see a <code>pushEvent</code> in the client, you know exactly where the handler for that is – in the collaborating Elixir module.</p>
<p>Fourth, functionality is split across just two files. Sure, the backend module will call out to your backend functions (e.g. fetch data from database) and the frontend will import components and styles. But roundtrips between the two aren’t routing through a stack of API modules, routers, and controllers.</p>
<p>Fifth, communication between frontend and backend is far less ceremonious. The backend can simply update props to inform frontend changes. And the frontend can <code>pushEvent</code> without needing handlers for expired tokens, timeouts, or outages. It’s binary: either the websocket is open which means the server is open for business, or it’s not in which case LiveView helpfully shows the user a global “disconnected” banner.</p>
<p>In the simplest terms, the frontend microservice is eliminated.</p>
<p>What you end up with feels like such a great split of responsibilities with very little boilerplate. All your business logic is on the backend – how you load data, <em>which</em> data to load, how to sort and filter the data, your validators, etc. Your frontend code is stupid simple. In Svelte, it’s all (1) <code>if/end</code> blocks to conditionally render stuff (2) animations and (3) a few dead simple <code>pushEvent</code> functions back to the server.</p>
<p>That last part has been blowing my mind. The typical SPA frontend is full of so much logic, usually <code>map</code>, <code>reduce</code>, and <code>filter</code> in order to process server data, prepare data for display, or prepare data for the server. In a LiveSvelte app, all this can just happen server-side. The LiveView can prepare data exactly as the Svelte component needs it. This keeps complexity in your server language, in your server's data structures, and in your server's test suite.</p>
<p>The backend LiveView and the frontend Svelte component aren't so much coupled as they are two halves: the LiveView only renders that Svelte component, and that Svelte component is only ever rendered by that LiveView.</p>
<p>In contrast to a “regular” LiveView, this paradigm:</p>
<ul>
<li>Embraces state and state transitions in the frontend.</li>
<li>Creates a clear boundary layer between the frontend and backend.</li>
<li>Leverages Svelte’s component paradigm, which like other contemporary JS frameworks is very mature and familiar.</li>
<li>In general, lets great frontend frameworks do what they do best! A pure LiveView approach doesn’t let you tap into this huge ecosystem. (For example, Svelte comes with great animation primitives.)</li>
</ul>
<p>By moving more into the frontend, we no longer felt like we were straddling an awkward middleground.</p>
<p>We chose LiveSvelte because React didn't have a similarly complete LiveView library. The joy of working with Svelte has been a very happy bonus. Because LiveView does the heavy lifting with state management, our state management in Svelte is very simple. For basic state and reactivity, Svelte is the lightest and fastest frontend framework I've worked with. We also prefer its templating features to React's, namely getting to use <code>if/else</code> instead of ternary operators and its conditional property setting.</p>
<p>Further, Svelte 5 is around the corner, and we're bullish on its <a href="https://svelte.dev/blog/runes?ref=blog.sequin.io">runes</a>. We think it makes Svelte even easier to pick up and reason about, meaning everyone on the team is empowered to traverse the stack.</p>
<p>I’m now convinced LiveView shines brightest as a backend-for-frontend. By rendering frontend components, incrementally updating them, maintaining a stateful backend process, and providing a websocket API, it creates a tremendously productive platform for frontend applications.</p>
<p>If you’re using LiveView and resonated with any of the friction I highlighted, you need to give this a try. If you’ve never used LiveView, you’ll find that this paradigm <em>lowers</em> the learning curve. This is because you’re able to use a lot of the JavaScript framework primitives you’re used to.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[White House wants Moon to have its own time zone, Coordinated Lunar Time (CLT) (198 pts)]]></title>
            <link>https://www.bbc.co.uk/news/science-environment-68722032</link>
            <guid>39916102</guid>
            <pubDate>Wed, 03 Apr 2024 11:36:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/science-environment-68722032">https://www.bbc.co.uk/news/science-environment-68722032</a>, See on <a href="https://news.ycombinator.com/item?id=39916102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="main-content" data-testid="main-content"><article><header data-component="legacy-header-block"></header><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg.webp 240w, https://ichef.bbci.co.uk/news/320/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg.webp 320w, https://ichef.bbci.co.uk/news/480/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg.webp 480w, https://ichef.bbci.co.uk/news/624/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg.webp 624w, https://ichef.bbci.co.uk/news/800/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg.webp 800w, https://ichef.bbci.co.uk/news/976/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg.webp 976w" type="image/webp"><img alt="The Bulging Moon rises over the sky at the early morning hours as a flag of the United States waving, in New Jersey, United States on March 30, 2024." srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg 240w, https://ichef.bbci.co.uk/news/320/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg 320w, https://ichef.bbci.co.uk/news/480/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg 480w, https://ichef.bbci.co.uk/news/624/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg 624w, https://ichef.bbci.co.uk/news/800/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg 800w, https://ichef.bbci.co.uk/news/976/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg 976w" src="https://ichef.bbci.co.uk/news/976/cpsprodpb/22B6/production/_133068880_moonpic_3.jpg" width="976" height="549" loading="eager"></picture></span><span role="text"><span>Image source, </span>Islam Dogru/Anadolu via Getty Images</span></p></figure></div><div data-component="text-block"><p><b>The White House wants US space agency Nasa to develop a new time zone for the Moon - Coordinated Lunar Time (LTC).</b></p></div><div data-component="text-block"><p>Because of the different gravitational field strength on the Moon, time moves quicker there relative to Earth - 58.7 microseconds every day.</p></div><div data-component="text-block"><p>This might not seem like much, but it can have a significant impact when trying to synchronise spacecraft.</p></div><div data-component="text-block"><p>The US government hopes the new time will help keep national and private efforts to reach the moon co-ordinated.</p></div><div data-component="text-block"><p>Prof Catherine Heymans, Scotland's Astronomer Royal, told BBC Radio 4's Today programme: "This fundamental theory of gravity in our Universe has an important consequence that time runs differently in different places in the Universe. </p></div><div data-component="text-block"><p>"The gravity on the Moon is slightly weaker and the clocks run differently."</p></div><div data-component="text-block"><p>Time is currently measured on Earth by hundreds of atomic clocks stationed around our planet which measure the changing energy state of atoms to record time to the nanosecond. If they were placed on the Moon, over 50 years they would be running one second faster. </p></div><div data-component="text-block"><p>"An atomic clock on the Moon will tick at a different rate than a clock on Earth," said Kevin Coggins, Nasa's top communications and navigation official. </p></div><div data-component="text-block"><p>"It makes sense that when you go to another body, like the Moon or Mars, that each one gets its own heartbeat," he said.</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Bettmann/Getty Images</span></p><figcaption><span>Image caption, </span><p>An early atomic clock "maser", in the mid-1950s</p></figcaption></figure></div><div data-component="text-block"><p>But Nasa is not the only one trying to make lunar time a reality. The European Space Agency has also been developing a new time system for a while. There will need to be agreement between countries and a centralised co-ordinating body - currently this is done by the International Bureau of Weights and Measures for time on Earth. </p></div><div data-component="text-block"><p>At the moment on the International Space Station, Coordinated Universal Time is used because it remains low in orbit. Another element that countries will have to agree on is where the new time frame begins from and to where it extends.</p></div><div data-component="text-block"><p>The US wants LTC to be ready by 2026 in time for its manned mission to the Moon. </p></div><div data-component="text-block"><p>Artemis-3 will be the first mission to return to the Moon's surface since Apollo 17 in 1972. It is set to land at the lunar south pole, which is thought to hold vast stores of water-ice in craters that never see sunlight. </p></div><div data-component="text-block"><p>Locating and directing this mission requires extreme precision down to the nanosecond, errors in navigation which could risk spacecraft entering the wrong orbits.</p></div><div data-component="text-block"><p>But Artemis-3 is also one of numerous planned national missions to the Moon as well as private endeavours. If time is not co-ordinated between them it could lead to challenges in sending data and communication between spacecraft, satellites and Earth.</p></div><section data-component="links-block"><p><h2>More on this story</h2></p></section><section data-component="around-the-bbc"><p><h2>Around the BBC</h2></p><ul role="list" spacing="responsive"><li></li></ul></section></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every Dunder Method in Python (141 pts)]]></title>
            <link>https://www.pythonmorsels.com/every-dunder-method/</link>
            <guid>39915968</guid>
            <pubDate>Wed, 03 Apr 2024 11:18:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pythonmorsels.com/every-dunder-method/">https://www.pythonmorsels.com/every-dunder-method/</a>, See on <a href="https://news.ycombinator.com/item?id=39915968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>You've just made a class.
You made a <code>__init__</code> method.
Now what?</p>
<p>Python includes <em>tons</em> of <a href="https://www.pythonmorsels.com/what-are-dunder-methods/" target="_blank">dunder methods</a> ("double underscore" methods) which allow us to deeply customize how our custom classes interact with Python's many features.
What dunder methods could you add to your class to make it friendly for other Python programmers who use it?</p>
<p>Let's take a look at <strong>every dunder method in Python</strong>, with a focus on when each method is useful.</p>
<p>Note that the Python documentation refers to these as <a href="https://docs.python.org/3/glossary.html#term-special-method" target="_blank">special methods</a> and notes the synonym "magic method" but <em>very</em> <a href="https://docs.python.org/3/reference/lexical_analysis.html#reserved-classes-of-identifiers" target="_blank">rarely</a> uses the term "dunder method".
However, "dunder method" is a fairly common Python colloquialism, as noted in my <a href="https://www.pythonmorsels.com/terms/" target="_blank">unofficial Python glossary</a>.</p>
<p>You can use the links scattered throughout this page for more details on any particular dunder method.
For a list of all of them, see the cheat sheet in the final section.</p>
<div>
<p><a href="#cheat-sheet">Just show me the cheat sheet</a>
</p></div>
<h2 id="the-3-essential-dunder-methods">The 3 essential dunder methods 🔑</h2>
<p>There are 3 dunder methods that <em>most</em> classes should have: <a href="https://www.pythonmorsels.com/what-is-init/" target="_blank"><code>__init__</code></a>, <a href="https://www.pythonmorsels.com/customizing-string-representation-your-objects/" target="_blank"><code>__repr__</code></a>, and <a href="https://www.pythonmorsels.com/overloading-equality-in-python/" target="_blank"><code>__eq__</code></a>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>T(a, b=3)</code></td>
<td><code>T.__init__(x, a, b=3)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>repr(x)</code></td>
<td><code>x.__repr__()</code></td>
<td><code>str</code></td>
</tr>
<tr>
<td><code>x == y</code></td>
<td><code>x.__eq__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
</tbody>
</table>
<p>The <a href="https://www.pythonmorsels.com/what-is-init/" target="_blank"><code>__init__</code></a> method is the <strong>initializer</strong> (not to be confused with the <a href="#construction-and-finalizing" target="_blank">constructor</a>), the <a href="https://www.pythonmorsels.com/customizing-string-representation-your-objects/" target="_blank"><code>__repr__</code></a> method customizes an object's string representation, and the <a href="https://www.pythonmorsels.com/overloading-equality-in-python/" target="_blank"><code>__eq__</code></a> method customizes what it means for objects to be <em>equal</em> to one another.</p>
<p>The <code>__repr__</code> method is particularly helpful at the <a href="https://www.pythonmorsels.com/using-the-python-repl/" target="_blank">the Python REPL</a> and when debugging.</p>
<h2 id="equality-and-hashability">Equality and hashability 🟰</h2>
<p>In addition to the <code>__eq__</code> method, Python has 2 other dunder methods for determining the "value" of an object in relation to other objects.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x == y</code></td>
<td><code>x.__eq__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>x != y</code></td>
<td><code>x.__ne__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>hash(x)</code></td>
<td><code>x.__hash__()</code></td>
<td><code>int</code></td>
</tr>
</tbody>
</table>
<p>Python's <code>__eq__</code> method typically returns <code>True</code>, <code>False</code>, or <a href="https://www.pythonmorsels.com/when-to-use-notimplemented/" target="_blank"><code>NotImplemented</code></a> (if objects can't be compared).
The default <code>__eq__</code> implementation relies on the <code>is</code> operator, which checks for <strong><a href="https://www.pythonmorsels.com/equality-vs-identity/" target="_blank">identity</a></strong>.</p>
<p>The default implementation of <code>__ne__</code> calls <code>__eq__</code> and negates any boolean return value given (or returns <code>NotImplemented</code> if <code>__eq__</code> did).
This default behavior is usually "good enough", so <strong>you'll almost never see <code>__ne__</code> implemented</strong>.</p>
<p>Hashable objects can be used as keys in dictionaries or values in sets.
All objects in Python are <a href="https://www.pythonmorsels.com/what-are-hashable-objects/" target="_blank">hashable</a> by default, but if you've written a custom <code>__eq__</code> method then your objects <em>won't</em> be hashable without a custom <code>__hash__</code> method.
But <strong>the hash value of an object must never change</strong> or <a href="https://pym.dev/p/2ysgz/" target="_blank">bad things will happen</a> so <strong>typically only <em>immutable</em> objects implement <code>__hash__</code></strong>.</p>
<p>For implementing equality checks, see <a href="https://www.pythonmorsels.com/overloading-equality-in-python/" target="_blank"><code>__eq__</code> in Python</a>.
For implementing hashability, see <a href="https://www.pythonmorsels.com/making-hashable-objects/" target="_blank">making hashable objects in Python</a>.</p>
<h2 id="orderability">Orderability ⚖️</h2>
<p>Python's comparison operators (<code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>) can all be overloaded with dunder methods as well.
The comparison operators also power functions that rely on the relative ordering of objects, like <code>sorted</code>, <code>min</code>, and <code>max</code>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>&lt;</code></td>
<td><code>__lt__</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>&gt;</code></td>
<td><code>__gt__</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>&lt;=</code></td>
<td><code>__le__</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td><code>&gt;=</code></td>
<td><code>__ge__</code></td>
<td>Typically <code>bool</code></td>
</tr>
</tbody>
</table>
<p>If you plan to implement all of these operators in the <em>typical</em> way (where <code>x &lt; y</code> would be the same as asking <code>y &gt; x</code>) then the <a href="https://docs.python.org/3/library/functools.html#functools.total_ordering" target="_blank"><code>total_ordering</code> decorator</a> from Python's <code>functools</code> module will come in handy.</p>
<h2 id="type-conversions-and-string-formatting">Type conversions and string formatting ⚗️</h2>
<p>Python has a number of dunder methods for converting objects to a different type.</p>
<table>
<thead>
<tr>
<th>Function</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>str(x)</code></td>
<td><code>x.__str__()</code></td>
<td><code>str</code></td>
</tr>
<tr>
<td><code>bool(x)</code></td>
<td><code>x.__bool__()</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td><code>int(x)</code></td>
<td><code>x.__int__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td><code>float(x)</code></td>
<td><code>x.__float__()</code></td>
<td><code>float</code></td>
</tr>
<tr>
<td><code>bytes(x)</code></td>
<td><code>x.__bytes__()</code></td>
<td><a href="https://pym.dev/p/2ysgz/" target="_blank"><code>bytes</code></a></td>
</tr>
<tr>
<td><code>complex(x)</code></td>
<td><code>x.__complex__()</code></td>
<td><a href="https://docs.python.org/3/glossary.html#term-complex-number" target="_blank"><code>complex</code></a></td>
</tr>
<tr>
<td><code>f"{x:s}"</code></td>
<td><code>x.__format__(s)</code></td>
<td><code>str</code></td>
</tr>
<tr>
<td><code>repr(x)</code></td>
<td><code>x.__repr__()</code></td>
<td><code>str</code></td>
</tr>
</tbody>
</table>
<p>The <code>__bool__</code> function is used for <a href="https://www.pythonmorsels.com/truthiness/" target="_blank">truthiness</a> checks, though <code>__len__</code> is used as a fallback.</p>
<p>If you needed to make an object that acts like a number (like <a href="https://docs.python.org/3/library/decimal.html" target="_blank"><code>decimal.Decimal</code></a> or <a href="https://docs.python.org/3/library/fractions.html" target="_blank"><code>fractions.Fraction</code></a>), you'll want to implement <code>__int__</code>, <code>__float__</code>, and <code>__complex__</code> so your objects can be converted to other numbers.
If you wanted to make an object that could be used in a <code>memoryview</code> or could otherwise be converted to <code>bytes</code>, you'll want a <code>__bytes__</code> method.</p>
<p>The <code>__format__</code> and <code>__repr__</code> methods are different string conversion flavors.
Most string conversions rely the <code>__str__</code> method, but the default <code>__str__</code> implementation simply calls <code>__repr__</code>.</p>
<p>The <code>__format__</code> method is used by all <a href="https://www.pythonmorsels.com/string-formatting/" target="_blank">f-string conversions</a>, by the <code>str</code> class's <code>format</code> method, and by the (rarely used) built-in <code>format</code> function.
This method allows <code>datetime</code> objects to <a href="https://www.pythonmorsels.com/string-formatting/#formatting-datetime-objects" target="_blank">support custom format specifiers</a>.</p>
<h2 id="context-managers">Context managers 🚪</h2>
<p>A context manager is an object that can be used in a <code>with</code> block.</p>
<table>
<thead>
<tr>
<th>Use</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>with</code> block enter</td>
<td><code>x.__enter__()</code></td>
<td>A value given to <code>as</code></td>
</tr>
<tr>
<td><code>with</code> block exit</td>
<td><code>x.__exit__(exc_type, exc, traceback)</code></td>
<td>Truthy/falsey value</td>
</tr>
</tbody>
</table>
<p>For more on context managers see, <a href="https://www.pythonmorsels.com/what-is-a-context-manager/" target="_blank">what is a context manager</a> and <a href="https://www.pythonmorsels.com/creating-a-context-manager/" target="_blank">creating a context manager</a>.</p>
<h2 id="containers-and-collections">Containers and collections 🗃️</h2>
<p>Collections (a.k.a. containers) are essentially data structures or objects that act like data stuctures.
Lists, dictionaries, sets, strings, and tuples are all examples of collections.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Return Type</th>
<th>Implemented</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>len(x)</code></td>
<td><code>x.__len__()</code></td>
<td>integer</td>
<td>Very common</td>
</tr>
<tr>
<td><code>iter(x)</code></td>
<td><code>x.__iter__()</code></td>
<td>iterator</td>
<td>Very common</td>
</tr>
<tr>
<td><code>for item in x: ...</code></td>
<td><code>x.__iter__()</code></td>
<td>iterator</td>
<td>Very common</td>
</tr>
<tr>
<td><code>x[a]</code></td>
<td><code>x.__getitem__(a)</code></td>
<td>any object</td>
<td>Common</td>
</tr>
<tr>
<td><code>x[a] = b</code></td>
<td><code>x.__setitem__(a, b)</code></td>
<td>None</td>
<td>Common</td>
</tr>
<tr>
<td><code>del x[a]</code></td>
<td><code>x.__delitem__(a)</code></td>
<td>None</td>
<td>Common</td>
</tr>
<tr>
<td><code>a in x</code></td>
<td><code>x.__contains__(a)</code></td>
<td>bool</td>
<td>Common</td>
</tr>
<tr>
<td><code>reversed(x)</code></td>
<td><code>x.__reversed__()</code></td>
<td>iterator</td>
<td>Common</td>
</tr>
<tr>
<td><code>next(x)</code></td>
<td><code>x.__next__()</code></td>
<td>any object</td>
<td>Uncommon</td>
</tr>
<tr>
<td><code>x[a]</code></td>
<td><code>x.__missing__(a)</code></td>
<td>any object</td>
<td>Uncommon</td>
</tr>
<tr>
<td><code>operator.length_hint(x)</code></td>
<td><code>x.__length_hint__()</code></td>
<td>integer</td>
<td>Uncommon</td>
</tr>
</tbody>
</table>
<p>The <code>__iter__</code> method is used by the <code>iter</code> function <em>and</em> for all forms of iteration: <a href="https://www.pythonmorsels.com/writing-a-for-loop/" target="_blank"><code>for</code> loops</a>, <a href="https://www.pythonmorsels.com/what-are-list-comprehensions/" target="_blank">comprehensions</a>, <a href="https://www.pythonmorsels.com/tuple-unpacking/" target="_blank">tuple unpacking</a>, and <a href="https://www.pythonmorsels.com/unpacking-iterables-iterables/" target="_blank">using <code>*</code> for iterable unpacking</a>.</p>
<p>While the <code>__iter__</code> method is necessary for creating a custom iterable, the <code>__next__</code> method is necessary for creating a custom iterator (which is much less common).
The <code>__missing__</code> method is only ever called by the <code>dict</code> class on itself, unless another class decides to implement <code>__missing__</code>.
The <code>__length_hint__</code> method supplies a length guess for structures which do not support <code>__len__</code> so that lists or other structures can be pre-sized more efficiently.</p>
<p>Also see: <a href="https://www.pythonmorsels.com/iterator-protocol/" target="_blank">the iterator protocol</a>, <a href="https://www.pythonmorsels.com/making-the-len-function-work-on-your-python-objects/" target="_blank">implementing <code>__len__</code></a>, and <a href="https://www.pythonmorsels.com/supporting-index-and-key-lookups/" target="_blank">implementing <code>__getitem__</code></a>.</p>
<h2 id="callability">Callability ☎️</h2>
<p>Functions, classes, and all other <a href="https://www.pythonmorsels.com/callables/" target="_blank">callable objects</a> rely on the <code>__call__</code> method.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Return Type</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x(a, b=c)</code></td>
<td><code>x.__call__(a, b=c)</code></td>
<td>any object</td>
</tr>
</tbody>
</table>
<p>When a class is called, its <a href="https://docs.python.org/3/glossary.html#term-metaclass" target="_blank">metaclass</a>'s <code>__call__</code> method is used.
When a class <em>instance</em> is called, the class's <code>__call__</code> method is used.</p>
<p>For more on callability, see <a href="https://www.pythonmorsels.com/class-function-and-callable/" target="_blank">Callables: Python's "functions" are sometimes classes</a>.</p>
<h2 id="arithmetic-operators">Arithmetic operators ➗</h2>
<p>Python's dunder methods are often described as a tool for "operator overloading".
Most of this "operator overloading" comes in the form of Python's various arithmetic operators.</p>
<p>There are two ways to break down the arithmetic operators:</p>
<ul>
<li>Mathematical (e.g. <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code>) versus bitwise (e.g. <code>&amp;</code>, <code>|</code>, <code>^</code>, <code>&gt;&gt;</code>, <code>~</code>)</li>
<li>Binary (between 2 values, like <code>x + y</code>) versus unary (before 1 value, like <code>+x</code>)</li>
</ul>
<p>The mathematical operators are much more common than the bitwise ones and the binary ones are a bit more common than the unary ones.</p>
<p>These are the binary mathematical arithmetic operators:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Left-Hand Method</th>
<th>Right-Hand Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x + y</code></td>
<td><code>__add__</code></td>
<td><code>__radd__</code></td>
<td>Add / Concatenate</td>
</tr>
<tr>
<td><code>x - y</code></td>
<td><code>__sub__</code></td>
<td><code>__rsub__</code></td>
<td>Subtract</td>
</tr>
<tr>
<td><code>x * y</code></td>
<td><code>__mul__</code></td>
<td><code>__rmul__</code></td>
<td>Multiply</td>
</tr>
<tr>
<td><code>x / y</code></td>
<td><code>__truediv__</code></td>
<td><code>__rtruediv__</code></td>
<td>Divide</td>
</tr>
<tr>
<td><code>%</code></td>
<td><code>__mod__</code></td>
<td><code>__rmod__</code></td>
<td>Modulo</td>
</tr>
<tr>
<td><code>x // y</code></td>
<td><code>__floordiv__</code></td>
<td><code>__rfloordiv__</code></td>
<td><a href="https://www.pythonmorsels.com/integer-division/" target="_blank">Integer division</a></td>
</tr>
<tr>
<td><code>**</code></td>
<td><code>__pow__</code></td>
<td><code>__rpow__</code></td>
<td>Exponentiate</td>
</tr>
<tr>
<td><code>x @ y</code></td>
<td><code>__matmul__</code></td>
<td><code>__rmatmul__</code></td>
<td>Matrix multiply</td>
</tr>
</tbody>
</table>
<p>Each of these operators includes left-hand and right-hand methods.
If <code>x.__add__(y)</code> returns <a href="https://www.pythonmorsels.com/when-to-use-notimplemented/" target="_blank"><code>NotImplemented</code></a>, then <code>y.__radd__(x)</code> will be attempted.
See <a href="https://www.pythonmorsels.com/arithmetic-dunder-methods/" target="_blank">arithmetic dunder methods</a> for more.</p>
<p>These are the binary bitwise arithmetic operators:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Left-Hand Method</th>
<th>Right-Hand Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x &amp; y</code></td>
<td><code>__and__</code></td>
<td><code>__rand__</code></td>
<td>AND</td>
</tr>
<tr>
<td><code>x | y</code></td>
<td><code>__or__</code></td>
<td><code>__ror__</code></td>
<td>OR</td>
</tr>
<tr>
<td><code>x ^ y</code></td>
<td><code>__xor__</code></td>
<td><code>__rxor__</code></td>
<td>XOR</td>
</tr>
<tr>
<td><code>x &gt;&gt; y</code></td>
<td><code>__rshift__</code></td>
<td><code>__rrshift__</code></td>
<td>Right-shift</td>
</tr>
<tr>
<td><code>x &lt;&lt; y</code></td>
<td><code>__lshift__</code></td>
<td><code>__rlshift__</code></td>
<td>Left-shift</td>
</tr>
</tbody>
</table>
<p>These are Python's unary arithmetic operators:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method</th>
<th>Variety</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-x</code></td>
<td><code>__neg__</code></td>
<td>Mathematical</td>
<td>Negate</td>
</tr>
<tr>
<td><code>+x</code></td>
<td><code>__pos__</code></td>
<td>Bitwise</td>
<td>Affirm</td>
</tr>
<tr>
<td><code>~x</code></td>
<td><code>__invert__</code></td>
<td>Bitwise</td>
<td>Invert</td>
</tr>
</tbody>
</table>
<p>The unary <code>+</code> operator typically <a href="https://stackoverflow.com/questions/16819023/whats-the-purpose-of-the-pos-unary-operator-in-python" target="_blank">has no effect</a>, though some objects use it for a specific operation.
For example <a href="https://www.pythonmorsels.com/using-counter/#removing-negative-counts" target="_blank">using <code>+</code> on <code>collections.Counter</code> objects</a> will remove non-positive values.</p>
<p>Python's arithmetic operators are often used for non-arithmetic ends: <a href="https://www.pythonmorsels.com/sequence/" target="_blank">sequences</a> use <code>+</code> to concatenate and <code>*</code> to self-concatenate and <a href="https://www.pythonmorsels.com/practical-uses-of-sets/" target="_blank">sets</a> use <code>&amp;</code> for intersection, <code>|</code> for union, <code>-</code> for asymmetric difference, and <code>^</code> for symmetric difference.
Arithmetic operators are sometimes overloaded for more creative uses too.
For example, <code>pathlib.Path</code> objects <a href="https://docs.python.org/3/library/pathlib.html#operators" target="_blank">use <code>/</code> to create child paths</a>.</p>
<h2 id="in-place-arithmetic-operations">In-place arithmetic operations ♻️</h2>
<p>Python includes many dunder methods for <strong>in-place</strong> operations.
If you're making a <a href="https://www.pythonmorsels.com/terms/#mutable" target="_blank">mutable</a> object that supports any of the arithmetic operations, you'll want to implement the related in-place dunder method(s) as well.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x += y</code></td>
<td><code>x.__iadd__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x -= y</code></td>
<td><code>x.__isub__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x *= y</code></td>
<td><code>x.__imul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x /= y</code></td>
<td><code>x.__itruediv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x %= y</code></td>
<td><code>x.__imod__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x //= y</code></td>
<td><code>x.__ifloordiv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x **= y</code></td>
<td><code>x.__ipow__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x @= y</code></td>
<td><code>x.__imatmul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x &amp;= y</code></td>
<td><code>x.__iand__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x |= y</code></td>
<td><code>x.__ior__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x ^= y</code></td>
<td><code>x.__ixor__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x &gt;&gt;= y</code></td>
<td><code>x.__irshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td><code>x &lt;&lt;= y</code></td>
<td><code>x.__ilshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
</tbody>
</table>
<p>All of Python's binary arithmetic operators work in <strong>augmented assignment statements</strong>, which involve using an operator followed by the <code>=</code> sign to assign to an object while performing an operation on it.</p>
<p>Augmented assignments on <strong>mutable objects</strong> are <a href="https://www.pythonmorsels.com/augmented-assignments-mutate/" target="_blank">expected to mutate the original object</a>, thanks to the mutable object implementing the appropriate dunder method for in-place arithmetic.</p>
<p>When no dunder method is found for an in-place operation, Python performs the operation followed by an assignment.
<strong>Immutable objects typically do <em>not</em> implement dunder methods for in-place operations</strong>, since they should return a new object instead of changing the original.</p>
<h2 id="built-in-math-functions">Built-in math functions 🧮</h2>
<p>Python also includes dunder methods for many math-related functions, both <a href="https://www.pythonmorsels.com/built-in-functions-in-python/#type" target="_blank">built-in functions</a> and some functions in the <code>math</code> library.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>divmod(x, y)</code></td>
<td><code>x.__divmod__(y)</code></td>
<td>2-item tuple</td>
</tr>
<tr>
<td><code>divmod(x, y)</code></td>
<td><code>y.__rdivmod__(x)</code></td>
<td>2-item tuple</td>
</tr>
<tr>
<td><code>abs(x)</code></td>
<td><code>x.__abs__()</code></td>
<td><code>float</code></td>
</tr>
<tr>
<td><code>sequence[x]</code></td>
<td><code>x.__index__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td><code>round(x)</code></td>
<td><code>x.__round__()</code></td>
<td>Number</td>
</tr>
<tr>
<td><code>math.trunc(x)</code></td>
<td><code>x.__trunc__()</code></td>
<td>Number</td>
</tr>
<tr>
<td><code>math.floor(x)</code></td>
<td><code>x.__floor__()</code></td>
<td>Number</td>
</tr>
<tr>
<td><code>math.ceil(x)</code></td>
<td><code>x.__ceil__()</code></td>
<td>Number</td>
</tr>
</tbody>
</table>
<p>Python's <code>divmod</code> function performs <a href="https://www.pythonmorsels.com/integer-division/" target="_blank">integer division</a> (<code>//</code>) and a modulo operation (<code>%</code>) at the same time.
Note that, just like the many binary arithmetic operators, <code>divmod</code> will also check for an <code>__rvidmod__</code> method if it needs to ask the <em>second</em> argument to handle the operation.</p>
<p>The <code>__index__</code> method is for making integer-like objects.
This method losslessly converts to an integer, unlike <code>__int__</code> which may perform a "lossy" integer conversion (e.g. from <code>float</code> to <code>int</code>).
It's used by operations that require <em>true</em> integers, such as <a href="https://www.pythonmorsels.com/slicing/" target="_blank">slicing</a>, indexing, and <code>bin</code>, <code>hex</code>, and <code>oct</code> functions (<a href="https://pym.dev/p/2k9zt/" target="_blank">example</a>).</p>
<h2 id="attribute-access">Attribute access 📜</h2>
<p>Python even includes dunder methods for controlling what happens when you access, delete, or assign any attribute on an object!</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>x.missing</code></td>
<td><code>x.__getattr__("missing")</code></td>
<td>Attribute value</td>
</tr>
<tr>
<td><code>x.anything</code></td>
<td><code>x.__getattribute__("anything")</code></td>
<td>Attribute value</td>
</tr>
<tr>
<td><code>x.thing = value</code></td>
<td><code>x.__setattr__("thing", value)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>del x.thing</code></td>
<td><code>x.__delattr__("thing")</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>dir(x)</code></td>
<td><code>x.__dir__()</code></td>
<td>List of strings</td>
</tr>
</tbody>
</table>
<p>The <code>__getattribute__</code> method is called for <em>every</em> attribute access, while the <code>__getattr__</code> method is only called after Python <em>fails</em> to find a given attribute.
All method calls and attribute accesses call <code>__getattribute__</code> so implementing it correctly is challenging (due to accidental <a href="https://www.pythonmorsels.com/what-is-recursion/" target="_blank">recursion</a>).</p>
<p>The <code>__dir__</code> method should return an iterable of attribute names (as strings).
When <a href="https://www.pythonmorsels.com/built-in-functions-in-python/#dir" target="_blank">the <code>dir</code> function</a> calls <code>__dir__</code>, it converts the returned iterable into a sorted list (like <a href="https://www.pythonmorsels.com/sorting-in-python/" target="_blank"><code>sorted</code></a> does).</p>
<p>The built-in <code>getattr</code>, <a href="https://www.pythonmorsels.com/python-setattr/" target="_blank"><code>setattr</code></a>, and <code>delattr</code> functions correspond to the dunder methods of the same name, but they're only intended for dynamic attribute access (not <em>all</em> attribute accesses).</p>

<p>Now we're getting into the really unusual dunder methods.
Python includes many dunder methods for metaprogramming-related features.</p>
<table>
<thead>
<tr>
<th>Implemented on</th>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Metaclasses</td>
<td><code>class T: ...</code></td>
<td><code>type(base).__prepare__()</code></td>
<td>mapping</td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>isinstance(x, T)</code></td>
<td><code>T.__instancecheck__(x)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>issubclass(U, T)</code></td>
<td><code>T.__subclasscheck__(U)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Any class</td>
<td><code>class U(T): ...</code></td>
<td><code>T.__init_subclass__(U)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Any class</td>
<td>(Called manually)</td>
<td><code>T.__subclasses__()</code></td>
<td><code>list</code></td>
</tr>
<tr>
<td>Any class</td>
<td><code>class U(x): ...</code></td>
<td><code>x.__mro_entries__([x])</code></td>
<td><code>tuple</code></td>
</tr>
<tr>
<td>Any class</td>
<td><code>T[y]</code></td>
<td><code>T.__class_getitem__(y)</code></td>
<td>an item</td>
</tr>
</tbody>
</table>
<p>The <code>__prepare__</code> method customizes the dictionary that's used for a class's initial namespace.
This is used to pre-populate dictionary values or customize the dictionary type (<a href="https://pym.dev/p/23wfv/" target="_blank">silly example</a>).</p>
<p>The <code>__instancecheck__</code> and <code>__subclasscheck__</code> methods override the functionality of <code>isinstance</code> and <code>issubclass</code>.
Python's ABCs use these to practice <a href="https://www.pythonmorsels.com/goose-typing/" target="_blank">goose typing</a> (<a href="https://www.pythonmorsels.com/duck-typing/" target="_blank">duck typing</a> <em>while</em> type checking).</p>
<p>The <code>__init_subclass__</code> method allows classes to hook into subclass initialization (<a href="https://pym.dev/p/246z6/" target="_blank">example</a>).
Classes <em>also</em> have a <code>__subclasses__</code> method (on their <a href="https://docs.python.org/3/glossary.html#term-metaclass" target="_blank">metaclass</a>) but it's not typically overridden.</p>
<p>Python calls <code>__mro_entries__</code> during <a href="https://www.pythonmorsels.com/inheriting-one-class-another/" target="_blank">class inheritance</a> for any base classes that are not <em>actually</em> classes.
The <a href="https://docs.python.org/3/library/typing.html#typing.NamedTuple" target="_blank"><code>typing.NamedTuple</code></a> function uses this to pretend it's a class (<a href="https://pym.dev/p/2qgzd/" target="_blank">see here</a>).</p>
<p>The <code>__class_getitem__</code> method allows a class to be subscriptable (<em>without</em> its metaclass needing a <code>__getitem__</code> method).
This is typically used for enabling fancy type annotations (e.g. <code>list[int]</code>).</p>
<h2 id="descriptors">Descriptors 🏷️</h2>
<p><a href="https://docs.python.org/3/glossary.html#term-descriptor" target="_blank">Descriptors</a> are objects that, when attached to a class, can hook into the access of the attribute name they're attached to on that class.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>class T: x = U()</code></td>
<td><code>T.x.__set_name__(T, 'x')</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>t.x</code></td>
<td><code>T.x.__get__(t, T)</code></td>
<td>The value</td>
</tr>
<tr>
<td><code>t.x = y</code></td>
<td><code>T.x.__set__(t, y)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>del t.x</code></td>
<td><code>T.x.__delete__(t)</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>The descriptor protocol is <em>mostly</em> a feature that exists to make Python's <code>property</code> decorator work, though it is also used by a number of third-party libraries.</p>
<h2 id="buffers">Buffers 💾</h2>
<p>Implementing a low-level memory array?
You need Python's <a href="https://docs.python.org/3/reference/datamodel.html#emulating-buffer-types" target="_blank">buffer protocol</a>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>memoryview(x)</code></td>
<td><code>x.__buffer__(flags)</code></td>
<td><code>memoryview</code></td>
</tr>
<tr>
<td><code>del memoryview(x)</code></td>
<td><code>x.__release_buffer__(m)</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>The <code>__release_buffer__</code> method is called when the buffer that's returned from <code>__buffer__</code> is deleted.</p>
<p>Python's buffer protocol is typically implemented in C, since it's meant for low level objects.</p>
<h2 id="asynchronous-operations">Asynchronous operations 🤹</h2>
<p>Want to implement an asynchronous context manager?
You need these dunder methods:</p>
<ul>
<li><code>__aenter__</code>: just like <code>__enter__</code>, but it returns an awaitable object</li>
<li><code>__aexit__</code>: just like <code>__exit__</code>, but it returns an awaitable object</li>
</ul>
<p>Need to support asynchronous iteration?
You need these dunder methods:</p>
<ul>
<li><code>__aiter__</code>: must return an asynchronous iterator</li>
<li><code>__anext__</code>: like <code>__next__</code> or non-async iterators, but this must return an awaitable object and this should raise <code>StopAsyncIteration</code> instead of <code>StopIteration</code></li>
</ul>
<p>Need to make your own awaitable object?
You need this dunder method:</p>
<ul>
<li><code>__await__</code>: returns an iterator</li>
</ul>
<p>I have little experience with custom asynchronous objects, so look elsewhere for more details.</p>
<h2 id="construction-and-finalizing">Construction and finalizing 🏭</h2>
<p>The last few dunder methods are related to object creation and destruction.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>T(a, b=3)</code></td>
<td><code>T.__new__(T, a, b=3)</code></td>
<td>New instance (<code>x</code>)</td>
</tr>
<tr>
<td><code>T(a, b=3)</code></td>
<td><code>T.__init__(x, a, b=3)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>del x</code></td>
<td><code>x.__del__()</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>Calling a class returns a new class instance thanks to the <code>__new__</code> method.
The <code>__new__</code> method is Python's <strong>constructor method</strong>, though unlike constructors in many programming languages, you should almost <em>never</em> define your own <code>__new__</code> method.
To control object creation, prefer the initializer (<code>__init__</code>), not the constructor (<code>__new__</code>).
<a href="https://pym.dev/p/28r9m/" target="_blank">Here's an odd <code>__new__</code> example</a>.</p>
<p>You could think of <code>__del__</code> as a "destructor" method, though it's actually called the <strong>finalizer method</strong>.
Just before an object is deleted, its <code>__del__</code> method is called (<a href="https://pym.dev/p/2hexg/" target="_blank">example</a>).
Files implement a <code>__del__</code> method that closes the file and any binary file buffer that it may be linked to.</p>
<h2 id="library-specific-dunder-methods">Library-specific dunder methods 🧰</h2>
<p>Some standard library modules define custom dunder methods that aren't used anywhere else:</p>
<ul>
<li><a href="https://www.pythonmorsels.com/dataclasses/" target="_blank">dataclasses</a> support a <code>__post_init__</code> method</li>
<li><code>abc.ABC</code> classes have a <code>__subclasshook__</code> method which <code>abc.ABCMeta</code> calls in its <code>__subclasscheck__</code> method (more in <a href="https://www.pythonmorsels.com/goose-typing/" target="_blank">goose typing</a>)</li>
<li>Path-like objects have a <code>__fspath__</code> method, which returns the file path as a string</li>
<li>Python's <code>copy</code> module will use the <code>__copy__</code> and <code>__deepcopy__</code> methods if present</li>
<li>Pickling relies on <code>__getnewargs_ex__</code> or <code>__getargs__</code>, though <code>__getstate__</code> and <code>__setstate__</code> can customize further and <code>__reduce__</code> or <code>__reduce_ex__</code> are even lower-level</li>
<li><code>sys.getsizeof</code> relies on the <code>__sizeof__</code> method to get an object's size (in bytes)</li>
</ul>
<h2 id="dunder-attributes">Dunder attributes 📇</h2>
<p>In addition to dunder methods, Python has many non-method <strong>dunder attributes</strong>.</p>
<p>Here are some of the more common dunder attributes you'll see:</p>
<ul>
<li><code>__name__</code>: name of a function, classes, or module</li>
<li><code>__module__</code>: module name for a function or class</li>
<li><code>__doc__</code>: <a href="https://www.pythonmorsels.com/docstrings/" target="_blank">docstring</a> for a function, class, or module</li>
<li><code>__class__</code>: an object's class (call <a href="https://www.pythonmorsels.com/built-in-functions-in-python/#type" target="_blank">Python's <code>type</code> function</a> instead)</li>
<li><code>__dict__</code>: most objects store their attributes here (see <a href="https://www.pythonmorsels.com/where-are-attributes-stored/" target="_blank">where are attributes stored?</a>)</li>
<li><code>__slots__</code>: classes using this are more memory efficient than classes using <code>__dict__</code></li>
<li><code>__match_args__</code>: classes can define a tuple noting the significance of positional attributes when the class is used in structural pattern matching (<code>match</code>-<code>case</code>)</li>
<li><code>__mro__</code>: a class's method resolution order used when for attribute lookups and <code>super()</code> calls</li>
<li><code>__bases__</code>: the direct parent classes of a class</li>
<li><code>__file__</code>: the file that defined the module object (though not always present!)</li>
<li><code>__wrapped__</code>: functions decorated with <a href="https://docs.python.org/3/library/functools.html#functools.wraps" target="_blank"><code>functools.wraps</code></a> use this to point to the original function</li>
<li><code>__version__</code>: commonly used for noting the version of a package</li>
<li><code>__all__</code>: modules can use this to customize the behavior of <code>from my_module import *</code></li>
<li><code>__debug__</code>: running Python with <code>-O</code> sets this to <code>False</code> and disables Python's <code>assert</code> statements</li>
</ul>
<p>Those are only the more commonly seen dunder attributes.
Here are some more:</p>
<ul>
<li>Functions have <code>__defaults__</code>, <code>__kwdefaults__</code>, <code>__code__</code>, <code>__globals__</code>, and <code>__closure__</code></li>
<li>Both functions and classes have <code>__qualname__</code>, <code>__annotations__</code>, and <code>__type_params__</code></li>
<li>Instance methods have <code>__func__</code> and <code>__self__</code></li>
<li>Modules may also have <code>__loader__</code>, <code>__package__</code>, <code>__spec__</code>, and <code>__cached__</code> attributes</li>
<li>Packages have a <code>__path__</code> attribute</li>
<li>Exceptions have <code>__traceback__</code>, <code>__notes__</code>, <code>__context__</code>, <code>__cause__</code>, and <code>__suppress_context__</code></li>
<li>Descriptors use <code>__objclass__</code></li>
<li>Metaclasses use <code>__classcell__</code></li>
<li>Python's <code>weakref</code> module uses <code>__weakref__</code></li>
<li><a href="https://docs.python.org/3/library/stdtypes.html#type-annotation-types-generic-alias-union" target="_blank">Generic aliases</a> have <code>__origin__</code>, <code>__args__</code>, <code>__parameters__</code>, and <code>__unpacked__</code></li>
<li>The <code>sys</code> module has <code>__stdout__</code> and <code>__stderr__</code> which point to the original <code>stdout</code> and <code>stderr</code> versions</li>
</ul>
<p>Additionally, these dunder attributes are used by various standard library modules: <code>__covariant__</code>, <code>__contravariant__</code>, <code>__infer_variance__</code>, <code>__bound__</code>, <code>__constraints__</code>.
And Python includes a built-in <code>__import__</code> function which you're not supposed to use (<code>importlib.import_module</code> is preferred) and CPython has a <code>__builtins__</code> variable that points to the <code>builtins</code> module (but this is an implementation detail and <code>builtins</code> should be explicitly imported when needed instead).
Also importing from the <code>__future__</code> module can enable specific Python feature flags and Python will look for a <code>__main__</code> module within packages to make them runnable as CLI scripts.</p>
<p>And that's just <em>most</em> of the dunder attribute names you'll find floating around in Python. 😵</p>
<h2 id="cheat-sheet">Every dunder method: a cheat sheet ⭐</h2>
<p>This is every Python dunder method organized in categories and ordered very roughly by the <strong>most commonly seen</strong> methods first.
Some caveats are noted below.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Object Creation</td>
<td><code>x = T(a, b)</code></td>
<td><code>x.__init__(a, b)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Object Creation</td>
<td><code>x = T(a, b)</code></td>
<td><code>T.__new__(T, a, b)</code></td>
<td>New instance (<code>x</code>)</td>
</tr>
<tr>
<td>Finalizer</td>
<td><code>del x</code> (ish)</td>
<td><code>x.__del__()</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x == y</code></td>
<td><code>x.__eq__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x != y</code></td>
<td><code>x.__ne__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &lt; y</code></td>
<td><code>x.__lt__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &gt; y</code></td>
<td><code>x.__rt__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &lt;= y</code></td>
<td><code>x.__le__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Comparisons</td>
<td><code>x &gt;= y</code></td>
<td><code>x.__ge__(y)</code></td>
<td>Typically <code>bool</code></td>
</tr>
<tr>
<td>Hashability</td>
<td><code>hash(x)</code></td>
<td><code>x.__hash__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>repr(x)</code></td>
<td><code>x.__repr__()</code></td>
<td>Always <code>str</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>str(x)</code></td>
<td><code>x.__str__()</code></td>
<td>Always <code>str</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>bool(x)</code></td>
<td><code>x.__bool__()</code></td>
<td>Always <code>bool</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>int(x)</code></td>
<td><code>x.__int__()</code></td>
<td>Always <code>int</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>float(x)</code></td>
<td><code>x.__float__()</code></td>
<td>Always <code>float</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>bytes(x)</code></td>
<td><code>x.__bytes__()</code></td>
<td>Always <code>bytes</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>complex(x)</code></td>
<td><code>x.__complex__()</code></td>
<td>Always <code>complex</code></td>
</tr>
<tr>
<td>Conversions</td>
<td><code>format(x, s)</code></td>
<td><code>x.__format__(s)</code></td>
<td>Always <code>str</code></td>
</tr>
<tr>
<td>Context Managers</td>
<td><code>with x as c:</code></td>
<td><code>x.__enter__()</code></td>
<td>The <code>c</code> object</td>
</tr>
<tr>
<td>Context Managers</td>
<td><code>with x as c:</code></td>
<td><code>x.__exit__()</code></td>
<td>Truthy/falsey value</td>
</tr>
<tr>
<td>Collections</td>
<td><code>len(x)</code></td>
<td><code>x.__len__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>iter(x)</code></td>
<td><code>x.__iter__()</code></td>
<td>An iterator</td>
</tr>
<tr>
<td>Collections</td>
<td><code>x[a]</code></td>
<td><code>x.__getitem__(a)</code></td>
<td></td>
</tr>
<tr>
<td>Collections</td>
<td><code>x[a] = b</code></td>
<td><code>x.__setitem__(a, b)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>del x[a]</code></td>
<td><code>x.__delitem__(a)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>a in x</code></td>
<td><code>x.__contains__(a)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Collections</td>
<td><code>reversed(x)</code></td>
<td><code>x.__reversed__()</code></td>
<td>An iterator</td>
</tr>
<tr>
<td>Collections</td>
<td><code>next(x)</code></td>
<td><code>x.__next__()</code></td>
<td>Next iterator item</td>
</tr>
<tr>
<td>Collections</td>
<td><code>x[a]</code></td>
<td><code>x.__missing__(a)</code></td>
<td></td>
</tr>
<tr>
<td>Collections</td>
<td></td>
<td><code>x.__length_hint__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x + y</code></td>
<td><code>x.__add__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x + y</code></td>
<td><code>y.__radd__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x - y</code></td>
<td><code>x.__sub__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x - y</code></td>
<td><code>y.__rsub__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x * y</code></td>
<td><code>x.__mul__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x * y</code></td>
<td><code>y.__rmul__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x / y</code></td>
<td><code>x.__truediv__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x / y</code></td>
<td><code>y.__rtruediv__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x % y</code></td>
<td><code>x.__mod__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x % y</code></td>
<td><code>y.__rmod__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x // y</code></td>
<td><code>x.__floordiv__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x // y</code></td>
<td><code>y.__rfloordiv__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ** y</code></td>
<td><code>x.__pow__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ** y</code></td>
<td><code>y.__rpow__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x @ y</code></td>
<td><code>x.__matmul__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x @ y</code></td>
<td><code>y.__rmatmul__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &amp; y</code></td>
<td><code>x.__and__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &amp; y</code></td>
<td><code>y.__rand__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x | y</code></td>
<td><code>x.__or__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x | y</code></td>
<td><code>y.__ror__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ^ y</code></td>
<td><code>x.__xor__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x ^ y</code></td>
<td><code>y.__rxor__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &gt;&gt; y</code></td>
<td><code>x.__rshift__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &gt;&gt; y</code></td>
<td><code>y.__rrshift__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &lt;&lt; y</code></td>
<td><code>x.__lshift__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>x &lt;&lt; y</code></td>
<td><code>y.__rlshift__(x)</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>-x</code></td>
<td><code>x.__neg__()</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>+x</code></td>
<td><code>x.__pos__()</code></td>
<td></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>~x</code></td>
<td><code>x.__invert__()</code></td>
<td></td>
</tr>
<tr>
<td>Math functions</td>
<td><code>divmod(x, y)</code></td>
<td><code>x.__divmod__(y)</code></td>
<td>2-item tuple</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>abs(x)</code></td>
<td><code>x.__abs__()</code></td>
<td><code>float</code></td>
</tr>
<tr>
<td>Math functions</td>
<td></td>
<td><code>x.__index__()</code></td>
<td><code>int</code></td>
</tr>
<tr>
<td>Math functions</td>
<td><code>round(x)</code></td>
<td><code>x.__round__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>math.trunc(x)</code></td>
<td><code>x.__trunc__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>math.floor(x)</code></td>
<td><code>x.__floor__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Math functions</td>
<td><code>math.ceil(x)</code></td>
<td><code>x.__ceil__()</code></td>
<td>Number</td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x += y</code></td>
<td><code>x.__iadd__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x -= y</code></td>
<td><code>x.__isub__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x *= y</code></td>
<td><code>x.__imul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x /= y</code></td>
<td><code>x.__itruediv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x %= y</code></td>
<td><code>x.__imod__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x //= y</code></td>
<td><code>x.__ifloordiv__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x **= y</code></td>
<td><code>x.__ipow__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x @= y</code></td>
<td><code>x.__imatmul__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x &amp;= y</code></td>
<td><code>x.__iand__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x |= y</code></td>
<td><code>x.__ior__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x ^= y</code></td>
<td><code>x.__ixor__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x &gt;&gt;= y</code></td>
<td><code>x.__irshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Assignment</td>
<td><code>x &lt;&lt;= y</code></td>
<td><code>x.__ilshift__(y)</code></td>
<td>Typically <code>self</code></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>x.y</code></td>
<td><code>x.__getattribute__('y')</code></td>
<td></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>x.y</code></td>
<td><code>x.__getattr__('y')</code></td>
<td></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>x.y = z</code></td>
<td><code>x.__setattr__('y', z)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>del x.y</code></td>
<td><code>x.__delattr__('y')</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Attributes</td>
<td><code>dir(x)</code></td>
<td><code>x.__dir__()</code></td>
<td>An iterable</td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>class T: x = U()</code></td>
<td><code>T.x.__set_name__(T, 'x')</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>t.x</code></td>
<td><code>T.x.__get__(t, T)</code></td>
<td></td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>t.x = y</code></td>
<td><code>T.x.__set__(t, y)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Descriptors</td>
<td><code>del t.x</code></td>
<td><code>T.x.__delete__(t)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Class stuff</td>
<td><code>class U(T): ...</code></td>
<td><code>T.__init_subclass__(U)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Class stuff</td>
<td><code>class U(x): ...</code></td>
<td><code>x.__mro_entries__([x])</code></td>
<td><code>tuple</code></td>
</tr>
<tr>
<td>Class stuff</td>
<td><code>T[y]</code></td>
<td><code>T.__class_getitem__(y)</code></td>
<td></td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>class T: ...</code></td>
<td><code>type(base).__prepare__()</code></td>
<td><code>dict</code>/mapping</td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>isinstance(x, T)</code></td>
<td><code>T.__instancecheck__(x)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Metaclasses</td>
<td><code>issubclass(U, T)</code></td>
<td><code>T.__subclasscheck__(U)</code></td>
<td><code>bool</code></td>
</tr>
<tr>
<td>Async</td>
<td><code>await x</code> (ish)</td>
<td><code>x.__await__()</code></td>
<td>An iterator</td>
</tr>
<tr>
<td>Async</td>
<td><code>async with x:</code></td>
<td><code>x.__aenter__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Async</td>
<td><code>async with x:</code></td>
<td><code>x.__aexit__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Async</td>
<td><code>async for a in x:</code></td>
<td><code>x.__aiter__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Async</td>
<td><code>async for a in x:</code></td>
<td><code>x.__anext__()</code></td>
<td>An awaitable</td>
</tr>
<tr>
<td>Buffers</td>
<td><code>memoryview(x)</code></td>
<td><code>x.__buffer__(flags)</code></td>
<td><code>memoryview</code></td>
</tr>
<tr>
<td>Buffers</td>
<td><code>del memoryview(x)</code></td>
<td><code>x.__release_buffer__(m)</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<p>The above table has a slight but consistent <em>untruth</em>.
Most of these dunder methods are not <em>actually</em> called on an object directly but are instead called on the <em>type</em> of that object: <code>type(x).__add__(x, y)</code> instead of <code>x.__add__(y)</code>.
This distinction mostly matters with metaclass methods.</p>
<p>I've also purposely excluded library-specific dunder methods (like <code>__post_init__</code>) and dunder methods you're unlikely to ever define (like <code>__subclasses__</code>).
See those below.</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Operation</th>
<th>Dunder Method Call</th>
<th>Returns</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dataclasses</td>
<td><code>x = T(a, b)</code></td>
<td><code>T.__post_init__(a, b)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>Copying</td>
<td><code>copy.copy(x)</code></td>
<td><code>x.__copy__()</code></td>
<td>New object</td>
</tr>
<tr>
<td>Copying</td>
<td><code>copy.deepcopy(x)</code></td>
<td><code>x.__deepcopy__(memo)</code></td>
<td>New object</td>
</tr>
<tr>
<td><a href="https://docs.python.org/3/library/pickle.html#pickling-class-instances" target="_blank">Pickling</a></td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__getnewargs__()</code></td>
<td>A 2-item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__getnewargs_ex__()</code></td>
<td>A 2-item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__getstate__()</code></td>
<td>A meaningful state</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__reduce__()</code></td>
<td>A 2-6 item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.dumps(x)</code></td>
<td><code>x.__reduce_ex__(4)</code></td>
<td>A 2-6 item tuple</td>
</tr>
<tr>
<td>Pickling</td>
<td><code>pickle.loads(b)</code></td>
<td><code>x.__setstate__(state)</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td>pathlib</td>
<td><a href="https://docs.python.org/3/library/os.html#os.fspath" target="_blank"><code>os.fspath(x)</code></a></td>
<td><code>p.__fspath__()</code></td>
<td><code>str</code> or <code>bytes</code></td>
</tr>
<tr>
<td>sys</td>
<td><code>sys.getsizeof(x)</code></td>
<td><code>x.__sizeof__()</code></td>
<td><code>int</code> (size in bytes)</td>
</tr>
<tr>
<td>Class stuff</td>
<td>None?</td>
<td><code>x.__subclasses__()</code></td>
<td>Subclasses iterable</td>
</tr>
<tr>
<td>ABCs</td>
<td><code>issubclass(U, T)</code></td>
<td><code>T.__subclasshook__(U)</code></td>
<td><code>bool</code></td>
</tr>
</tbody>
</table>
<p>So, Python includes 103 "normal" dunder methods, 12 library-specific dunder methods, and at least 52 other dunder attributes of various types.
That's over 150 unique <code>__dunder__</code> names!
I <strong>do not recommend</strong> memorizing these: let Python do its job and look up the dunder method or attribute that you need to implement/find whenever you need it.</p>
<p>Keep in mind that <strong>you're not meant to invent your own dunder methods</strong>.
Sometimes you'll see third-party libraries that <em>do</em> invent their own dunder method, but this isn't encouraged and it can be quite confusing for users who run across such methods and assume they're "<em>real</em>" dunder methods.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyTorch Library for Running LLM on Intel CPU and GPU (250 pts)]]></title>
            <link>https://github.com/intel-analytics/ipex-llm</link>
            <guid>39915594</guid>
            <pubDate>Wed, 03 Apr 2024 10:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/intel-analytics/ipex-llm">https://github.com/intel-analytics/ipex-llm</a>, See on <a href="https://news.ycombinator.com/item?id=39915594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><p dir="auto">Important</p><p dir="auto"><em><strong><code>bigdl-llm</code> has now become <code>ipex-llm</code> (see the migration guide <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/bigdl_llm_migration.html" rel="nofollow">here</a>); you may find the original <code>BigDL</code> project <a href="https://github.com/intel-analytics/BigDL-2.x">here</a>.</strong></em></p>
</div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">💫 IPEX-LLM</h2><a id="user-content--ipex-llm" aria-label="Permalink: 💫 IPEX-LLM" href="#-ipex-llm"></a></p>
<p dir="auto"><strong><code>IPEX-LLM</code></strong> is a PyTorch library for running <strong>LLM</strong> on Intel CPU and GPU <em>(e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max)</em> with very low latency<sup><a href="#user-content-fn-1-81ce39395d1a85f86f714ef670a086f0" id="user-content-fnref-1-81ce39395d1a85f86f714ef670a086f0" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<div dir="auto"><p dir="auto">Note</p>
<ul dir="auto">
<li><em>It is built on top of <strong>Intel Extension for PyTorch</strong> (<strong><code>IPEX</code></strong>), as well as the excellent work of <strong><code>llama.cpp</code></strong>, <strong><code>bitsandbytes</code></strong>, <strong><code>vLLM</code></strong>, <strong><code>qlora</code></strong>, <strong><code>AutoGPTQ</code></strong>, <strong><code>AutoAWQ</code></strong>, etc.</em></li>
<li><em>It provides seamless integration with <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/llama_cpp_quickstart.html" rel="nofollow">llama.cpp</a>, <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/webui_quickstart.html" rel="nofollow">Text-Generation-WebUI</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels">HuggingFace tansformers</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning">HuggingFace PEFT</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LangChain">LangChain</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LlamaIndex">LlamaIndex</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Deepspeed-AutoTP">DeepSpeed-AutoTP</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">vLLM</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/src/ipex_llm/serving/fastchat">FastChat</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">HuggingFace TRL</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Applications/autogen">AutoGen</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/ModelScope-Models">ModeScope</a>, etc.</em></li>
<li><em><strong>50+ models</strong> have been optimized/verified on <code>ipex-llm</code> (including LLaMA2, Mistral, Mixtral, Gemma, LLaVA, Whisper, ChatGLM, Baichuan, Qwen, RWKV, and more); see the complete list <a href="#verified-models">here</a>.</em></li>
</ul>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Latest Update 🔥</h2><a id="user-content-latest-update-" aria-label="Permalink: Latest Update 🔥" href="#latest-update-"></a></p>
<ul dir="auto">
<li>[2024/03] <code>bigdl-llm</code> has now become <code>ipex-llm</code> (see the migration guide <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/bigdl_llm_migration.html" rel="nofollow">here</a>); you may find the original <code>BigDL</code> project <a href="https://github.com/intel-analytics/bigdl-2.x">here</a>.</li>
<li>[2024/02] <code>ipex-llm</code> now supports directly loading model from <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/ModelScope-Models">ModelScope</a> (<a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/ModelScope-Models">魔搭</a>).</li>
<li>[2024/02] <code>ipex-llm</code> added inital <strong>INT2</strong> support (based on llama.cpp <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF-IQ2">IQ2</a> mechanism), which makes it possible to run large-size LLM (e.g., Mixtral-8x7B) on Intel GPU with 16GB VRAM.</li>
<li>[2024/02] Users can now use <code>ipex-llm</code> through <a href="https://github.com/intel-analytics/text-generation-webui">Text-Generation-WebUI</a> GUI.</li>
<li>[2024/02] <code>ipex-llm</code> now supports <em><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Inference/Self_Speculative_Decoding.html" rel="nofollow">Self-Speculative Decoding</a></em>, which in practice brings <strong>~30% speedup</strong> for FP16 and BF16 inference latency on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Speculative-Decoding">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Speculative-Decoding">CPU</a> respectively.</li>
<li>[2024/02] <code>ipex-llm</code> now supports a comprehensive list of LLM <strong>finetuning</strong> on Intel GPU (including <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/LoRA">LoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">DPO</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QA-LoRA">QA-LoRA</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/ReLora">ReLoRA</a>).</li>
<li>[2024/01] Using <code>ipex-llm</code> <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA</a>, we managed to finetune LLaMA2-7B in <strong>21 minutes</strong> and LLaMA2-70B in <strong>3.14 hours</strong> on 8 Intel Max 1550 GPU for <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA/alpaca-qlora">Standford-Alpaca</a> (see the blog <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/finetuning-llms-on-intel-gpus-using-bigdl-llm.html" rel="nofollow">here</a>).</li>
</ul>
<details><summary>More updates</summary>
<br>
<ul dir="auto">
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/ReLora">ReLoRA</a> (see <em><a href="https://arxiv.org/abs/2307.05695" rel="nofollow">"ReLoRA: High-Rank Training Through Low-Rank Updates"</a></em>).</li>
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mixtral">Mixtral-8x7B</a> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mixtral">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mixtral">CPU</a>.</li>
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QA-LoRA">QA-LoRA</a> (see <em><a href="https://arxiv.org/abs/2309.14717" rel="nofollow">"QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"</a></em>).</li>
<li>[2023/12] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">FP8 and FP4 inference</a> on Intel <em><strong>GPU</strong></em>.</li>
<li>[2023/11] Initial support for directly loading <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF">GGUF</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/AWQ">AWQ</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GPTQ">GPTQ</a> models into <code>ipex-llm</code> is available.</li>
<li>[2023/11] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">vLLM continuous batching</a> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/vLLM-Serving">CPU</a>.</li>
<li>[2023/10] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA finetuning</a> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/QLoRA-FineTuning">CPU</a>.</li>
<li>[2023/10] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/src/ipex_llm/llm/serving">FastChat serving</a> on on both Intel CPU and GPU.</li>
<li>[2023/09] <code>ipex-llm</code> now supports <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU">Intel GPU</a> (including iGPU, Arc, Flex and MAX).</li>
<li>[2023/09] <code>ipex-llm</code> <a href="https://github.com/intel-analytics/ipex-llm-tutorial">tutorial</a> is released.</li>
</ul>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>ipex-llm</code> Demos</h2><a id="user-content-ipex-llm-demos" aria-label="Permalink: ipex-llm Demos" href="#ipex-llm-demos"></a></p>
<p dir="auto">See the <em><strong>optimized performance</strong></em> of <code>chatglm2-6b</code> and <code>llama-2-13b-chat</code> models on 12th Gen Intel Core CPU and Intel Arc GPU below.</p>
<table>
  <tbody><tr>
    <td colspan="2">12th Gen Intel Core CPU</td>
    <td colspan="2">Intel Arc GPU</td>
  </tr>
  <tr>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-6b.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/5187917ac33da777422df36def0302560f3b9d9d79b4b020764e0fa701b611c7/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f63686174676c6d322d36622e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-6b.gif"></a>
    </td>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/llama-2-13b-chat.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/4a27da6ff50259d31abd699ed6c247d3fc6e6d1f893437eb8d724aca3a397cf8/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f6c6c616d612d322d3133622d636861742e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/llama-2-13b-chat.gif"></a>
    </td>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-arc.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/c2e9977f1f6da5638a29338d6ab92626b5f145c477702172a57fd56a6f051c49/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f63686174676c6d322d6172632e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-arc.gif"></a>
    </td>
    <td>
      <a href="https://llm-assets.readthedocs.io/en/latest/_images/llama2-13b-arc.gif" rel="nofollow"><img src="https://camo.githubusercontent.com/72c7b4450963b24247649726d8f4cefe1f7d70ae75729309fae63447e8b55995/68747470733a2f2f6c6c6d2d6173736574732e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f6c6c616d61322d3133622d6172632e676966" data-animated-image="" data-canonical-src="https://llm-assets.readthedocs.io/en/latest/_images/llama2-13b-arc.gif"></a>
    </td>
  </tr>
  <tr>
    <td><code>chatglm2-6b</code></td>
    <td><code>llama-2-13b-chat</code></td>
    <td><code>chatglm2-6b</code></td>
    <td><code>llama-2-13b-chat</code></td>
  </tr>
</tbody></table>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>ipex-llm</code> Quickstart</h2><a id="user-content-ipex-llm-quickstart" aria-label="Permalink: ipex-llm Quickstart" href="#ipex-llm-quickstart"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install <code>ipex-llm</code></h3><a id="user-content-install-ipex-llm" aria-label="Permalink: Install ipex-llm" href="#install-ipex-llm"></a></p>
<ul dir="auto">
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/install_windows_gpu.html" rel="nofollow">Windows GPU</a>: installing <code>ipex-llm</code> on Windows with Intel GPU</li>
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/install_linux_gpu.html" rel="nofollow">Linux GPU</a>: installing <code>ipex-llm</code> on Linux with Intel GPU</li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/docker/llm">Docker</a>: using <code>ipex-llm</code> dockers on Intel CPU and GPU</li>
<li><em>For more details, please refer to the <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Overview/install.html" rel="nofollow">installation guide</a></em></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run <code>ipex-llm</code></h3><a id="user-content-run-ipex-llm" aria-label="Permalink: Run ipex-llm" href="#run-ipex-llm"></a></p>
<ul dir="auto">
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/llama_cpp_quickstart.html" rel="nofollow">llama.cpp</a>: running <strong>ipex-llm for llama.cpp</strong> (<em>using C++ interface of <code>ipex-llm</code> as an accelerated backend for <code>llama.cpp</code> on Intel GPU</em>)</li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">vLLM</a>: running <code>ipex-llm</code> in <code>vLLM</code> on both Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/vLLM-Serving">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/vLLM-Serving">CPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/src/ipex_llm/serving/fastchat">FastChat</a>: running <code>ipex-llm</code> in <code>FastChat</code> serving on on both Intel GPU and CPU</li>
<li><a href="https://github.com/intel-analytics/Langchain-Chatchat">LangChain-Chatchat RAG</a>: running <code>ipex-llm</code> in <code>LangChain-Chatchat</code> (<em>Knowledge Base QA using <strong>RAG</strong> pipeline</em>)</li>
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/webui_quickstart.html" rel="nofollow">Text-Generation-WebUI</a>: running <code>ipex-llm</code> in <code>oobabooga</code> <strong>WebUI</strong></li>
<li><a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Quickstart/benchmark_quickstart.html" rel="nofollow">Benchmarking</a>: running  (latency and throughput) benchmarks for <code>ipex-llm</code> on Intel CPU and GPU</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code Examples</h3><a id="user-content-code-examples" aria-label="Permalink: Code Examples" href="#code-examples"></a></p>
<ul dir="auto">
<li>Low bit inference
<ul dir="auto">
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model">INT4 inference</a>: <strong>INT4</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model">CPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">FP8/FP4 inference</a>: <strong>FP8</strong> and <strong>FP4</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">GPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">INT8 inference</a>: <strong>INT8</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/More-Data-Types">GPU</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/More-Data-Types">CPU</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF-IQ2">INT2 inference</a>: <strong>INT2</strong> LLM inference (based on llama.cpp IQ2 mechanism) on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF-IQ2">GPU</a></li>
</ul>
</li>
<li>FP16/BF16 inference
<ul dir="auto">
<li><strong>FP16</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Speculative-Decoding">GPU</a>, with possible <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Inference/Self_Speculative_Decoding.html" rel="nofollow">self-speculative decoding</a> optimization</li>
<li><strong>BF16</strong> LLM inference on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Speculative-Decoding">CPU</a>, with possible <a href="https://ipex-llm.readthedocs.io/en/latest/doc/LLM/Inference/Self_Speculative_Decoding.html" rel="nofollow">self-speculative decoding</a> optimization</li>
</ul>
</li>
<li>Save and load
<ul dir="auto">
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Save-Load">Low-bit models</a>: saving and loading <code>ipex-llm</code> low-bit models</li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GGUF">GGUF</a>: directly loading GGUF models into <code>ipex-llm</code></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/AWQ">AWQ</a>: directly loading AWQ models into <code>ipex-llm</code></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/GPTQ">GPTQ</a>: directly loading GPTQ models into <code>ipex-llm</code></li>
</ul>
</li>
<li>Finetuning
<ul dir="auto">
<li>LLM finetuning on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning">GPU</a>, including <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/LoRA">LoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QLoRA">QLoRA</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">DPO</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/QA-LoRA">QA-LoRA</a> and <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/ReLora">ReLoRA</a></li>
<li>QLoRA finetuning on Intel <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/QLoRA-FineTuning">CPU</a></li>
</ul>
</li>
<li>Integration with community libraries
<ul dir="auto">
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels">HuggingFace tansformers</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models">Standard PyTorch model</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/Deepspeed-AutoTP">DeepSpeed-AutoTP</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/HF-PEFT">HuggingFace PEFT</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LLM-Finetuning/DPO">HuggingFace TRL</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LangChain">LangChain</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/LlamaIndex">LlamaIndex</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Applications/autogen">AutoGen</a></li>
<li><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/ModelScope-Models">ModeScope</a></li>
</ul>
</li>
<li><a href="https://github.com/intel-analytics/ipex-llm-tutorial">Tutorials</a></li>
</ul>
<p dir="auto"><em>For more details, please refer to the <code>ipex-llm</code> document <a href="https://ipex-llm.readthedocs.io/" rel="nofollow">website</a>.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Verified Models</h2><a id="user-content-verified-models" aria-label="Permalink: Verified Models" href="#verified-models"></a></p>
<p dir="auto">Over 50 models have been optimized/verified on <code>ipex-llm</code>, including <em>LLaMA/LLaMA2, Mistral, Mixtral, Gemma, LLaVA, Whisper, ChatGLM2/ChatGLM3, Baichuan/Baichuan2, Qwen/Qwen-1.5, InternLM</em> and more; see the list below.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>CPU Example</th>
<th>GPU Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLaMA <em>(such as Vicuna, Guanaco, Koala, Baize, WizardLM, etc.)</em></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/vicuna">link2</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/vicuna">link</a></td>
</tr>
<tr>
<td>LLaMA 2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/llama2">link2</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/llama2">link</a></td>
</tr>
<tr>
<td>ChatGLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/chatglm">link</a></td>
<td></td>
</tr>
<tr>
<td>ChatGLM2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/chatglm2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/chatglm2">link</a></td>
</tr>
<tr>
<td>ChatGLM3</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/chatglm3">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/chatglm3">link</a></td>
</tr>
<tr>
<td>Mistral</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mistral">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mistral">link</a></td>
</tr>
<tr>
<td>Mixtral</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mixtral">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mixtral">link</a></td>
</tr>
<tr>
<td>Falcon</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/falcon">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/falcon">link</a></td>
</tr>
<tr>
<td>MPT</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/mpt">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/mpt">link</a></td>
</tr>
<tr>
<td>Dolly-v1</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/dolly_v1">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/dolly-v1">link</a></td>
</tr>
<tr>
<td>Dolly-v2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/dolly_v2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/dolly-v2">link</a></td>
</tr>
<tr>
<td>Replit Code</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/replit">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/replit">link</a></td>
</tr>
<tr>
<td>RedPajama</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/redpajama">link2</a></td>
<td></td>
</tr>
<tr>
<td>Phoenix</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phoenix">link2</a></td>
<td></td>
</tr>
<tr>
<td>StarCoder</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/Native-Models">link1</a>, <a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/starcoder">link2</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/starcoder">link</a></td>
</tr>
<tr>
<td>Baichuan</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/baichuan">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/baichuan">link</a></td>
</tr>
<tr>
<td>Baichuan2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/baichuan2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/baichuan2">link</a></td>
</tr>
<tr>
<td>InternLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/internlm">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/internlm">link</a></td>
</tr>
<tr>
<td>Qwen</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/qwen">link</a></td>
</tr>
<tr>
<td>Qwen1.5</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen1.5">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/qwen1.5">link</a></td>
</tr>
<tr>
<td>Qwen-VL</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/qwen-vl">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/qwen-vl">link</a></td>
</tr>
<tr>
<td>Aquila</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/aquila">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/aquila">link</a></td>
</tr>
<tr>
<td>Aquila2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/aquila2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/aquila2">link</a></td>
</tr>
<tr>
<td>MOSS</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/moss">link</a></td>
<td></td>
</tr>
<tr>
<td>Whisper</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/whisper">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/whisper">link</a></td>
</tr>
<tr>
<td>Phi-1_5</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phi-1_5">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/phi-1_5">link</a></td>
</tr>
<tr>
<td>Flan-t5</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/flan-t5">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/flan-t5">link</a></td>
</tr>
<tr>
<td>LLaVA</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/PyTorch-Models/Model/llava">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/llava">link</a></td>
</tr>
<tr>
<td>CodeLlama</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/codellama">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/codellama">link</a></td>
</tr>
<tr>
<td>Skywork</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/skywork">link</a></td>
<td></td>
</tr>
<tr>
<td>InternLM-XComposer</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/internlm-xcomposer">link</a></td>
<td></td>
</tr>
<tr>
<td>WizardCoder-Python</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/wizardcoder-python">link</a></td>
<td></td>
</tr>
<tr>
<td>CodeShell</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/codeshell">link</a></td>
<td></td>
</tr>
<tr>
<td>Fuyu</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/fuyu">link</a></td>
<td></td>
</tr>
<tr>
<td>Distil-Whisper</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/distil-whisper">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/distil-whisper">link</a></td>
</tr>
<tr>
<td>Yi</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/yi">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/yi">link</a></td>
</tr>
<tr>
<td>BlueLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/bluelm">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/bluelm">link</a></td>
</tr>
<tr>
<td>Mamba</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/PyTorch-Models/Model/mamba">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/mamba">link</a></td>
</tr>
<tr>
<td>SOLAR</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/solar">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/solar">link</a></td>
</tr>
<tr>
<td>Phixtral</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phixtral">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/phixtral">link</a></td>
</tr>
<tr>
<td>InternLM2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/internlm2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/internlm2">link</a></td>
</tr>
<tr>
<td>RWKV4</td>
<td></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/rwkv4">link</a></td>
</tr>
<tr>
<td>RWKV5</td>
<td></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/rwkv5">link</a></td>
</tr>
<tr>
<td>Bark</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/PyTorch-Models/Model/bark">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/bark">link</a></td>
</tr>
<tr>
<td>SpeechT5</td>
<td></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/PyTorch-Models/Model/speech-t5">link</a></td>
</tr>
<tr>
<td>DeepSeek-MoE</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deepseek-moe">link</a></td>
<td></td>
</tr>
<tr>
<td>Ziya-Coding-34B-v1.0</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/ziya">link</a></td>
<td></td>
</tr>
<tr>
<td>Phi-2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/phi-2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/phi-2">link</a></td>
</tr>
<tr>
<td>Yuan2</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/yuan2">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/yuan2">link</a></td>
</tr>
<tr>
<td>Gemma</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/gemma">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/gemma">link</a></td>
</tr>
<tr>
<td>DeciLM-7B</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deciLM-7b">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/deciLM-7b">link</a></td>
</tr>
<tr>
<td>Deepseek</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/deepseek">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/deepseek">link</a></td>
</tr>
<tr>
<td>StableLM</td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/stablelm">link</a></td>
<td><a href="https://github.com/intel-analytics/ipex-llm/blob/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/stablelm">link</a></td>
</tr>
</tbody>
</table>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-1-81ce39395d1a85f86f714ef670a086f0">
<p dir="auto">Performance varies by use, configuration and other factors. <code>ipex-llm</code> may not optimize to the same degree for non-Intel products. Learn more at <a href="http://www.intel.com/PerformanceIndex">www.Intel.com/PerformanceIndex</a>. <a href="#user-content-fnref-1-81ce39395d1a85f86f714ef670a086f0" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Redict 7.3.0, a copyleft fork of Redis, is now available (188 pts)]]></title>
            <link>https://redict.io/posts/2024-04-03-redict-7.3.0-released/</link>
            <guid>39915473</guid>
            <pubDate>Wed, 03 Apr 2024 10:10:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://redict.io/posts/2024-04-03-redict-7.3.0-released/">https://redict.io/posts/2024-04-03-redict-7.3.0-released/</a>, See on <a href="https://news.ycombinator.com/item?id=39915473">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <h2>
    <a href="https://redict.io/posts/2024-04-03-redict-7.3.0-released/">Redict 7.3.0 is now available</a>
    <br><small>Drew DeVault</small>
  </h2>
  
  <h5>April 3, 2024</h5>



  

  



<p>The Redict community is pleased to announce the release of Redict 7.3.0, the
first stable version of our copyleft fork of Redis® OSS 7.2.4.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> You can
download the release <a href="https://codeberg.org/redict/redict/releases/tag/7.3.0">on Codeberg</a>, or download one of our official
<a href="https://redict.io/docs/install/containers/">container images</a> from registry.redict.io.</p>
<p>We have written comprehensive documentation detailing our <a href="https://redict.io/docs/redis-compat/">compatibility with
Redis® OSS 7.2.4</a>, which also provides detailed documentation for
various migration scenarios, such as for users of the official Redis®
containers on Docker Hub, downstream package maintainers, and so on.</p>
<p>We have tested Redict thoroughly with a variety of migration scenarios, but we
may have missed a detail that pertains to your use-case. If you have any issues
or questions with respect to the migration process, please <a href="https://redict.io/docs/community">join our community
spaces</a> to get help.</p>
<h2 id="why-redict">
  Why Redict?
  <a href="#why-redict">#</a>
</h2>
<p>You may be wondering why Redict would be of interest to you, particularly when
compared with <a href="https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community">Valkey</a>, another Redis® fork that was announced on Thursday.</p>
<p>In technical terms, we are focusing on stability and long-term maintenance, and
on achieving excellence within our current scope. We believe that Redict is near
feature-complete and that it is more valuable to our users if we take a
conservative stance to innovation and focus on long-term reliability instead.
This is in part a choice we’ve made to distinguish ourselves from Valkey, whose
commercial interests are able to invest more resources into developing more
radical innovations, but also an acknowledgement of a cultural difference
between our projects, in that the folks behind Redict place greater emphasis on
software with a finite scope and ambitions towards long-term stability
rather than focusing on long-term growth in scope and complexity.</p>
<p>We will happily pull useful changes from software with permissive licenses, such
as Valkey, to improve Redict; such is the value of permissive software and the
key advantage of free software generally. However, we will do so at a more
conservative pace, so that our users can enjoy stability first and shiny new
features second. We are also going to focus on establishing and maintaining a
good relationship with downstream distributions, prioritizing their needs with
respect to tasks such as de-vendoring Lua and jemalloc.</p>
<p>Redict also has social and political aims which differ from other forks. In
short, we believe in an approach which is built from an independent, grassroots,
and community-focused means of building our software. We are not governed by the
consensus of a small group of commercial interests, but rather by an independent
and community-driven consensus. Importantly, we have also chosen to protect our
software from further exploitation by applying the Lesser GNU General Public
License (LGPL) to our work.</p>
<p>Our choice of license prevents the hard work of our contributors from being
incorporated into the now-proprietary Redis® software, and from any future
attempts to create proprietary distributions of Redict. However, our choice of
the LGPL balances this concern with the needs of commercial users&nbsp;– we
have selected this license in part to ensure that cloud providers can continue
to offer Redict to their customers without being subject to onerous compliance
regimes.</p>
<blockquote>
  <strong>Note</strong>: Check out our <a href="https://redict.io/docs/license">About the license</a> page for more
information about the license of Redict.
</blockquote>

<p>We’ve made these choices because we believe they are essential in providing for
a future which is based on free software, and in which the rug cannot be pulled
out from under our users and contributors again. We believe it is essential to
make these choices now, at the onset of our fork, especially in response to the
crisis that the Redis® community is faced with at the hands of its
commercial stewards. If you don’t want your investment in this software to risk
another artificial crisis in the name of profit, if you want to enjoy the
protection of copyleft and a guarantee that your software will remain free, then
we encourage you to adopt Redict for your needs.</p>
<p>We have also taken this opportunity to re-evaluate our infrastructure and double
down on using free software. Rather than continuing to use the proprietary
GitHub forge, we have elected to use the non-profit, free software
<a href="https://codeberg.org/">Codeberg</a> as our home, and we run our continuous
integration on <a href="https://sourcehut.org/">SourceHut</a>, which is also free software.
Moreover, rather than gathering on Discord, we have chosen instead to set up our
community on <a href="https://redict.io/docs/community">Matrix and IRC</a>. We believe that the Redis® license
change provides us an opportunity to focus on our values as members of the free
software community, to exercise solidarity, and to lend our strength to
re-enforce the broader free software ecosystem. As such, we felt it important to
choose free software solutions for our infrastructure needs.</p>
<h2 id="acknowledgements">
  Acknowledgements
  <a href="#acknowledgements">#</a>
</h2>
<p>I’d like to extend a personal “thanks” to everyone who was involved in bringing
this fork to life. In particular, Micke Nordin and Hugo, for their work on the
Redict containers; Lucas Dohmen, for his extensive work on the documentation and
website; and Anna, for her work forking and maintaining <a href="https://codeberg.org/redict/hiredict">hiredict</a>; as well as
everyone who contributed small patches here and there, and everyone who helped
with the rapid turn-around and testing of Redict’s release candidates. Shoutout
to @janWilejan for designing our logo, and to everyone else who submitted their
artwork for consideration.</p>
<p>Thanks are also due, of course, to all of the many contributors who worked on
Redis® OSS, commercial contributors and independent contributors alike,
whose work forms the foundation of our codebase, as well as all of those who
worked on the extensive Creative Commons documentation that was adapted for
Redict. We also extend our gratitude to the community downstream of Redis®
OSS, including downstream distributions, cloud services, and countless users,
all of whom nourished its growth as free software.</p>
<h2 id="whats-next">
  What’s next?
  <a href="#whats-next">#</a>
</h2>
<p>We focused on a very conservative set of changes for the initial release, to
maximize backwards compatibility and ease the transition for new users. Going
forward, we do have some plans to make conservative improvements.</p>
<p>Among the planned changes are:</p>
<ul>
<li>Modernizing the build system (<a href="https://muon.build/">muon</a> is the leading
candidate)</li>
<li>Forking the <em>ecosystem</em>, in particular Redis® client libraries (this is a
great way for you to help!)</li>
<li>De-vendoring dependencies such as Lua and jemalloc</li>
</ul>
<p>Lucas is also planning to invest heavily in Redict’s documentation, such that we
become the reference of choice for all participants in this ecosystem. Anna has
some changes planned for <a href="https://codeberg.org/redict/hiredict">hiredict</a> as well (our fork of the official Redis®
C client library), including build system improvements and better conformance
with Unix norms.</p>
<p>We will also be happy to consider improvements from any community member – come
join us! We will welcome you as equals – independent and commercial users
alike!</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reflections on Distrusting xz (264 pts)]]></title>
            <link>https://joeyh.name/blog/entry/reflections_on_distrusting_xz/</link>
            <guid>39914981</guid>
            <pubDate>Wed, 03 Apr 2024 08:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joeyh.name/blog/entry/reflections_on_distrusting_xz/">https://joeyh.name/blog/entry/reflections_on_distrusting_xz/</a>, See on <a href="https://news.ycombinator.com/item?id=39914981">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">







<section id="pagebody" role="main">
<p>Was the ssh backdoor the only goal that "Jia Tan" was pursuing
with their multi-year operation against xz?</p>

<p>I doubt it, and if not, then every fix so far has been incomplete,
because everything is still running code written by that entity.</p>

<p>If we assume that they had a multilayered plan, that their every action was
calculated and malicious, then we have to think about the full threat
surface of using xz. This quickly gets into nightmare scenarios of the
"trusting trust" variety.</p>

<p>What if xz contains a hidden buffer overflow or other vulnerability, that
can be exploited by the xz file it's decompressing? This would let the
attacker target other packages, as needed.</p>

<p>Let's say they want to target gcc. Well, gcc contains a lot of
documentation, which includes png images. So they spend a while getting
accepted as a documentation contributor on that project, and get added to
it a png file that is specially constructed, it has additional binary data
appended that exploits the buffer overflow. And instructs xz to modify the
source code that comes later when decompressing <code>gcc.tar.xz</code>.</p>

<p>More likely, they wouldn't bother with an actual trusting trust attack on
gcc, which would be a lot of work to get right. One problem with the ssh
backdoor is that well, not all servers on the internet run ssh. (Or
systemd.) So webservers seem a likely target of this kind of second stage
attack. Apache's docs include png files, nginx does not, but there's always
scope to add improved documentation to a project.</p>

<p>When would such a vulnerability have been introduced? In February, "Jia
Tan" wrote a <a href="https://git.tukaani.org/?p=xz.git;a=commitdiff;h=de5c5e417645ad8906ef914bc059d08c1462fc29">new decoder for xz</a>.
This added 1000+ lines of new C code across several commits. So much code
and in just the right place to insert something like this. And why take on
such a significant project just two months before inserting the ssh
backdoor? "Jia Tan" was already fully accepted as maintainer, and doing
lots of other work, it doesn't seem to me that they needed to start this
rewrite as part of their cover.</p>

<p>They were working closely with xz's author Lasse Collin in this, by
indications exchanging patches offlist as they developed it. So Lasse
Collin's commits in this time period are also worth scrutiny, because
they could have been influenced by "Jia Tan". One that
caught my eye comes immediately afterwards:
<a href="https://git.tukaani.org/?p=xz.git;a=commitdiff;h=e0c0ee475c0800c08291ae45e0d66aa00d5ce604">"prepares the code for alternative C versions and inline assembly"</a>
Multiple versions and assembly mean even more places to hide such a
security hole.</p>

<p>I stress that I have not found such a security hole, I'm only considering
what the worst case possibilities are. I think we need to fully consider
them in order to decide how to fully wrap up this mess.</p>

<p>Whether such stealthy security holes have been introduced into xz by "Jia
Tan" or not, there are definitely indications that the ssh backdoor was not
the end of what they had planned.</p>

<p>For one thing, the "test file" based system they introduced
<a href="https://openwall.com/lists/oss-security/2024/03/30/15">was extensible</a>.
They could have been planning to add more test files later, that backdoored
xz in further ways.</p>

<p>And then there's the matter of the disabling of the Landlock sandbox. This
was not necessary for the ssh backdoor, because the sandbox is only used by
the <code>xz</code> command, not by liblzma. So why did they potentially tip their
hand by adding that rogue "." that disables the sandbox?</p>

<p>A sandbox would not prevent the kind of attack I discuss above, where xz is
just modifying code that it decompresses. Disabling the sandbox suggests
that they were going to make xz run arbitrary code, that perhaps wrote to
files it shouldn't be touching, to install a backdoor in the system.</p>

<p>Both deb and rpm use xz compression, and with the sandbox disabled,
whether they link with liblzma or run the <code>xz</code> command, a backdoored xz can
write to any file on the system while dpkg or rpm is running and noone is
likely to notice, because that's the kind of thing a package manager does.</p>

<p>My impression is that all of this was well planned and they were in it for
the long haul. They had no reason to stop with backdooring ssh, except for
the risk of additional exposure. But they decided to take that risk, with
the sandbox disabling. So they planned to do more, and every commit
by "Jia Tan", and really every commit that they could have influenced
needs to be distrusted.</p>

<p>This is why I've suggested to Debian that they
<a href="https://bugs.debian.org/1068024">revert to an earlier version of xz</a>.
That would be my advice to anyone distributing xz.</p>

<p>I do have a <a href="https://git.joeyh.name/index.cgi/xz-unscathed/">xz-unscathed</a>
fork which I've carefully constructed to avoid all "Jia Tan" involved
commits. It feels good to not need to worry about <code>dpkg</code> and <code>tar</code>.
I only plan to maintain this fork minimally, eg security fixes.
Hopefully Lasse Collin will consider these possibilities and address
them in his response to the attack.</p>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP Disables Printer Functionality Until You Install the HP Smart App (133 pts)]]></title>
            <link>https://twitter.com/Schappi/status/1775384892970533208/photo/1</link>
            <guid>39914293</guid>
            <pubDate>Wed, 03 Apr 2024 06:38:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Schappi/status/1775384892970533208/photo/1">https://twitter.com/Schappi/status/1775384892970533208/photo/1</a>, See on <a href="https://news.ycombinator.com/item?id=39914293">Hacker News</a></p>
Couldn't get https://twitter.com/Schappi/status/1775384892970533208/photo/1: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Full EU chat control proposal attack on digital privacy and encryption (101 pts)]]></title>
            <link>https://www.patrick-breyer.de/en/full-chat-control-proposal-leaked-attack-on-digital-privacy-of-correspondence-and-secure-encryption/</link>
            <guid>39913946</guid>
            <pubDate>Wed, 03 Apr 2024 05:35:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.patrick-breyer.de/en/full-chat-control-proposal-leaked-attack-on-digital-privacy-of-correspondence-and-secure-encryption/">https://www.patrick-breyer.de/en/full-chat-control-proposal-leaked-attack-on-digital-privacy-of-correspondence-and-secure-encryption/</a>, See on <a href="https://news.ycombinator.com/item?id=39913946">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
	<article id="post-601836">
		
	
		<div>
			
<p>The French news service contexte.com has today published the latest Belgian Presidency’s proposal for introducing indiscriminate <a href="https://www.patrick-breyer.de/wp-content/uploads/2024/04/2024-03-28-conseil-csam-compromis-presidence-belge.pdf">chat control scanning of private messages for illegal content. </a>The proposal covers the entire regulation and is therefore ready for endorsement. The proposal is to be discussed tomorrow in a Council law enforcement working party. The <a href="https://netzpolitik.org/2024/internes-protokoll-eu-staaten-weiter-uneins-ueber-chatkontrolle/">political points of contention will then be decided in COREPER</a> in order to adopt the position by June.</p>



<p>The leaked proposal shows that the core of the EU Commission’s extreme initial proposal is to be retained unchanged, warns MEP and most prominent opponent of chat control Patrick Breyer (Pirate Party):</p>



<p>“As the Council’s legal service has confirmed, the latest move does not change the nature of detection orders. Millions of private chats and private photos of law-abiding citizens are to be searched and leaked using flawed technology, without them being even remotely connected to child sexual abuse – this destroys our digital privacy of correspondence. Despite lip service being paid to encryption, client-side scanning is to be used to undermine previously secure end-to-end encryption in order to turn our smartphones into spies – this destroys secure encryption.</p>



<p>Now is the time to take to the barricades in favour of privacy and secure encryption, because EU governments that have been critical so far are praising the repackaged plans, which means that the blocking minority no longer stands. Not even a written opinion of the Council’s legal service on this obvious violation of fundamental rights has been requested, it seems.</p>



<p>If the EU governments actually go into trilogue negotiations with this radical position, experience shows that the Parliament risks gradually abandoning its initial position behind closed doors and agreeing to bad and dangerous compromises that fundamentally put our online security at risk.”</p>



<p>In detail Breyer criticises the proposed text as follows: „Limiting bulk chat searches to ‘high-risk services’ is meaningless because every communication service is misused also for sharing illegal images and therefore has an imminently high risk of abuse. Ireland – one of the strongest proponents of chat control – would be classifying the major services. In any case, the service used is no justification for searching the private chats of millions of citizens who are not even remotely connected to any wrongdoing.</p>



<p>Informing law enforcement only of repeat hits is also meaningless, as falsely flagged beach pictures or consensual sexting rarely involve just a single photo. The EU Commissioner for Home Affairs has herself herself stated that three out of four of the disclosed chats and photos are not actionable for the police. These algorithms and hash databases are totally unreliable in distinguishing legal from illegal content.”</p>



<p>Breyer’s information portal and document archive on the proposal: chatcontrol.eu</p>
		
		</div>
	
		
	</article>
	
					
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ancient world before computers had stacks or heaps (240 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20240401-00/?p=109599</link>
            <guid>39913616</guid>
            <pubDate>Wed, 03 Apr 2024 04:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20240401-00/?p=109599">https://devblogs.microsoft.com/oldnewthing/20240401-00/?p=109599</a>, See on <a href="https://news.ycombinator.com/item?id=39913616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="featured">
                         <p>
            April 1st, 2024</p><!-- .entry-meta -->
        <p>We take stacks and heaps for granted nowadays, but back in the very old days of computing, computers operated without a stack or a heap.</p>
<p>Tell a recent college graduate this, and you may as well tell them that there was a time when you didn’t have instant access to millions of cat videos.</p>
<p>It’s not too hard to imagine computing without dynamic memory allocation. You just have to use fixed-size memory buffers for everything. If you have to operate on variable-sized data, you reserved a fixed-size buffer of some capacity that is large enough to accommodate any data you would reasonably be expected to process, and if somebody asked for more, you just exited the program with a fatal error. If you were really nice, you would provide a compile-time configuration so your clients could adjust the maximum capacity to suit their datasets. And if you were really fancy, you wrote a custom allocator that operated on that fixed-size buffer so people could “allocate” and “free” memory from the buffer.</p>
<p>But operating without a stack? How did you call a function if you didn’t have a stack for the return address or local variables?</p>
<p>Here’s how it worked.</p>
<p>First, the compiler defined a secret global variable for each inbound function parameter, plus another secret global variable for each function to hold the return address. It also defined a secret global variable for each of the function’s local variables.</p>
<p>To generate a function call, the compiler assigned the parameter values to the corresponding secret global variables, assigned the return address to the function’s secret “return address variable”, and then jumped to the start of the function.</p>
<p>The function read its parameters from its secret global variables, and used the pre-defined secret global variables that corresponded to its logically local variables. When the function was finished, it jumped to the address held in the function’s secret “return address variable.”</p>
<p>For example, suppose you had code like this, written in a C-like language:</p>
<pre>int add_two_values(int a, int b)
{
    int c = a + b;
    return c;
}

void sample()
{
    int x = add_two_values(31415, 2718);
}
</pre>
<p>This would be transformed by the compiler into something like this:</p>
<pre>int a2v_a;
int a2v_b;
int a2v_c;
void* a2v_retaddr;

int add_two_values()
{
    a2v_c = a2v_a + a2v_b;

    return_value_register = a2v_c;
    goto a2v_retaddr;
}

int sample_x;
void sample()
{
    a2v_a = 31415;
    a2v_b = 2718;
    a2v_retaddr = &amp;resume;
    goto add_two_values;
resume:
    sample_x = return_value_register;
}
</pre>
<p>Check it out: We did a function call and return without a stack!</p>
<p>Now, you can optimize the ABI by, say, passing some of these values in registers rather than globals. For example, most processors had a special “link” register and a special instruction “branch with link” that automatically set the link register equal to the address of the instruction after the “branch with link” instruction, And maybe you optimize the calling convention to pass the first two parameters in registers, resulting in this:</p>
<pre>int a2v_a;
int a2v_b;
int a2v_c;
void* a2v_retaddr;

int add_two_values()
{
    a2v_a = argument_register_1;
    a2v_b = argument_register_2;
    a2v_retaddr = link_register;

    a2v_c = a2v_a + a2v_b;

    return_value_register = a2v_c;
    goto a2v_retaddr;
}

int sample_x;
void sample()
{
    argument_register_1 = 31415;
    argument_register_2 = 2718;
    branch_with_link add_two_values;
    sample_x = return_value_register;
}
</pre>
<p>There was just one catch: You can’t do recursion.</p>
<p>Recursion doesn’t work because a recursive call would overwrite the return-address variable with the return address of the recursive call, and when the outer call completed, it would jump to the wrong place.</p>
<p>The programming languages of the day solved this problem by simply declaring it illegal: They didn’t support recursion.¹</p>
<p><b>Bonus chatter</b>: Some compilers were even sneakier and used self-modifying code: The special return-address variable was really the address field of the jump instruction at the end of the function!</p>
<p>This was occasionally not so much a sneaky trick as a practical necessity: <a href="https://en.wikipedia.org/wiki/MIX"> The processor might not support indirect jumps either</a>!</p>
<p>After the practical value of subroutines was recognized, quite a few processors added a subroutine call instruction that worked by storing the return address at the first word of the subroutine, and beginning execution at the second word of the subroutine. To return from a subroutine, you execute an indirect jump through the subroutine start label. (As I recall, some processors stored the return address at the word <i>before</i> the first instruction of the subroutine.) Here’s what it looked like using a made-up assembly language:</p>
<pre>add_two_values:
    nop                     ; return address goes here
    add   r1 = r1, r2       ; actual subroutine begins here
    jmp   @add_two_values   ; indirect jump to return address

sample:
    mov   r1 = 31415        ; first parameter
    mov   r2 = 2718         ; second parameter
    bsr   add_two_values    ; call subroutine
    st    sample_x = r1     ; save return value
</pre>
<p>When the CPU executed the <code>bsr</code> branch-to-subroutine instruction, it stored the return address into the first word of <code>add_two_values</code> (overwriting the sacrificial <code>nop</code>) and began execution at the following instruction, the <code>add r1 = r1, r2</code>.</p>
<p>¹ FORTRAN initially didn’t even support subroutines! Those were added in 1958. And support in FORTRAN for recursion didn’t become standard until 1991, and even then, you had to explicitly declare your subroutine as <code>RECURSIVE</code>.</p>

        

        
		
        
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Rise and Fall of 3M's Floppy Disk (151 pts)]]></title>
            <link>https://spectrum.ieee.org/3m-floppy</link>
            <guid>39913505</guid>
            <pubDate>Wed, 03 Apr 2024 04:05:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/3m-floppy">https://spectrum.ieee.org/3m-floppy</a>, See on <a href="https://news.ycombinator.com/item?id=39913505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="The Rise and Fall of 3M’s Floppy Disk" data-elid="2667647674" data-post-url="https://spectrum.ieee.org/3m-floppy" data-authors="Ernie Smith" data-page-title="The Rise and Fall of 3M’s Floppy Disk - IEEE Spectrum"><p><em>A version of this post </em><a href="https://tedium.co/2023/11/17/3m-floppy-disks-history/" rel="noopener noreferrer" target="_blank"><em>originally appeared</em></a><em> on</em><a href="https://tedium.co/" target="_blank"><em>Tedium</em></a><em>, Ernie Smith’s newsletter, which hunts for the end of the long tail. </em></p><p>
	If you ask the average person what the company 3M does, odds are if they have a few gray hairs hanging out on their scalp, they might say that the company makes floppy disks. Now, this was once true, but 
	<a href="https://www.3m.com/" rel="noopener noreferrer" target="_blank">if you look on 3M’s own website</a>, you will see no mention of this legacy—it’s a firm that sells abrasive materials, adhesive tapes, filters, films, personal protective equipment, and medical equipment. (Younger people, if they recognize 3M, it’s probably because of Post-it notes, or more recently its N95 masks)
</p><p>
	Floppies have had a surprisingly long life—in January 2024, 
	<a href="https://arstechnica.com/gadgets/2024/01/floppy-disk-requirements-finally-axed-from-japan-government-regulations/" rel="noopener noreferrer" target="_blank">Japan announced</a> it will no longer require floppy-disk copies of government submissions. But 3M got out of the data-storage business about 28 years ago, when it transferred its floppy disk manufacturing to a spin-off called Imation. Imation is still around, under the name Glassbridge Enterprises, but with a much smaller profile.
</p><p><img alt="One yellow and one orange Imation 3M 3 \u00bd inch floppy diskettes on a gray background." data-rm-shortcode-id="09f8f834227ac15c2241ffede9966750" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/one-yellow-and-one-orange-imation-3m-3-u00bd-inch-floppy-diskettes-on-a-gray-background.jpg?id=51890455&amp;width=980" height="1250" id="d995a" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/one-yellow-and-one-orange-imation-3m-3-u00bd-inch-floppy-diskettes-on-a-gray-background.jpg?id=51890455&amp;width=980" width="2000"><small placeholder="Add Photo Caption...">3M’s spin-off, Imation, continued producing floppy disks after 3M itself left the business. </small><small placeholder="Add Photo Credit..."><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></small></p><p>
	Even with that said, those gray-hairs will frequently claim that of the many makers of floppies out there, 3M made the best ones. Given that, I was curious to figure out exactly why 3M became the most memorable brand in data storage during the formative days of computing, and why it abandoned the product.
</p><h2>How 3M Became a Key Innovator in the Production of Magnetic Data Storage</h2><p>
	Now, to be clear, 3M did not invent magnetic storage—that was done by Austro-German engineer 
	<a href="https://www.computerhistory.org/storageengine/audio-recorder-uses-low-cost-magnetic-tape/" rel="noopener noreferrer" target="_blank">Fritz Pfleumer</a>, in 1928. He created audio tape, a recording medium that started as broad strips of paper coated with iron-powder granules, and eventually moved to less-fragile cellulose acetate with help from what would become another big name in floppy disks, BASF. At first, the innovation didn’t spread outside of Germany because of World War II.
</p><p>
	Nor was 3M the first company to popularize magnetic media—
	<a href="https://tedium.co/2022/08/26/tape-hiss-noise-history/" rel="noopener noreferrer" target="_blank">that was Ampex</a>, which commercialized the tape recorder in the late 1940s. That was the point when magnetic tape turned into a major innovation in the world of music—one that, famously, <a href="https://ethw.org/First-Hand:Bing_Crosby_and_the_Recording_Revolution" rel="noopener noreferrer" target="_blank">Bing Crosby got to first</a> because he gave financial support to Ampex. Incidentally, Ampex’s later spinoff, Memorex, represented <a href="https://tedium.co/2021/09/03/memorex-tape-history/" rel="noopener noreferrer" target="_blank">Silicon Valley’s first true startup</a>.
</p><blockquote>“Of all the businesses 3M has shed over its 100 years, the two seminal decisions that people point to as most significant involved the sale of 3M’s Duplicating Products business to Harris Corporation in Atlanta, Georgia, and the spin-off of 3M’s data-storage and imaging-systems businesses in 1996 creating a new company called Imation in Oakdale, Minnesota...”</blockquote><p>
	Before World War II, one company did attempt to manufacture a tape recorder in the U.S. based on Pfluemer’s magnetic-tape invention. That firm, the Brush Development Co., 
	<a href="https://www.radiomuseum.org/dsp_hersteller_detail.cfm?company_id=2092" rel="noopener noreferrer" target="_blank">had developed a device called the Soundmirror</a>, produced by a Hungarian inventor named Semi J. Begun, who was likely something of a competitor to Pfleumer: Also a German, he had moved to the United States and developed a steel-based magnetic tape. The invention was used by the U.S. military during the war, and the company revisited the idea immediately after. But, it needed someone to manufacture magnetic tape for it to use.
</p><p>
	As author David Morton noted in his 2006 book 
	<em>Sound Recording: The Life Story of a Technology</em>, <a href="https://www.google.com/books/edition/Sound_Recording/0ZmjkJwxyWcC?hl=en&amp;gbpv=1&amp;pg=PA121&amp;printsec=frontcover" rel="noopener noreferrer" target="_blank">3M was one of the best-suited companies on the market</a> to help Brush out. That’s because the groundbreaking work that the company had done to develop pressure-sensitive adhesive tape was an essential element of making magnetic tape effective.
</p><p><img alt="Black and white historical photo of a man in worker overall and a cap applying newspaper and tape to an old car." data-rm-shortcode-id="7b3354061aa56d651ce26122330f6db6" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-historical-photo-of-a-man-in-worker-overall-and-a-cap-applying-newspaper-and-tape-to-an-old-car.jpg?id=51890488&amp;width=980" height="930" id="8f6d5" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-historical-photo-of-a-man-in-worker-overall-and-a-cap-applying-newspaper-and-tape-to-an-old-car.jpg?id=51890488&amp;width=980" width="1240"><small placeholder="Add Photo Caption...">3M’s adhesive-tape technology transferred readily to magnetic tape. </small><small placeholder="Add Photo Credit...">3M</small></p><p>
	Strangely enough, Richard Gurley Drew, the inventor of much of 3M’s tape technology, was a musician—he played banjo in a local orchestra—when he took a job with the company. He probably didn’t realize he was inventing a key element of 20th-century recording technology when he observed that auto body shops needed a way to “mask off” areas of vehicles that were being whittled down with sandpaper, but his observation would prove useful to the invention of masking tape.
</p><p data-rm-resized-container="25%"><img alt="Zoom in of disordered rectangles on the left and ordered rectangles on the right, over advertisement text. " data-rm-shortcode-id="ee09b3f7acae42e757ef6377cf6773be" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/zoom-in-of-disordered-rectangles-on-the-left-and-ordered-rectangles-on-the-right-over-advertisement-text.jpg?id=51890495&amp;width=980" height="850" id="7d359" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/zoom-in-of-disordered-rectangles-on-the-left-and-ordered-rectangles-on-the-right-over-advertisement-text.jpg?id=51890495&amp;width=980" width="620"><small placeholder="Add Photo Caption...">In the mid-1950s, 3M advertised its Scotch audio reel-to-reel tape.</small><small placeholder="Add Photo Credit..."><a href="https://archive.org/details/am-1955-03/page/n3/mode/2up" rel="noopener noreferrer" target="_blank">Audio Magazine/Internet Archive</a>/Scotch</small></p><p><a href="https://www.smithsonianmag.com/innovation/how-invention-scotch-tape-led-revolution-how-companies-managed-employees-180972437/" rel="noopener noreferrer" target="_blank">As <em>Smithsonian Magazine</em> notes</a>, the formulation he developed, combining cabinetmaker’s glue with glycerin, proved to be just the right level of easy-to-remove adhesive that it became an out-and-out phenomenon. You might know his invention, developed in 1925, as Scotch Tape.
</p><p>
	In 1930, he followed it up with another invention that was even more amazing—tape made from cellophane, which by its nature was totally transparent. Another 3M employee developed the tape dispenser, and the two inventions reshaped offices the world over.
</p><p>
	So, when Brush looked to others to produce its recording medium, 3M was well positioned to help out due to magnetic tape’s similarity with its Scotch Tape. Brush eventually moved to other manufacturers, like Dupont. But the experience led 3M to continue developing metal-oxide tape technology, leading to the creation of the Scotch 111 reel-to-reel tape, which was one of the most popular types used in recording studios throughout the 1950s, according to the 
	<a href="https://museumofmagneticsoundrecording.org/Manufacturers3M.html" rel="noopener noreferrer" target="_blank"><em>Museum of Magnetic Sound Recording</em></a>.
</p><p>
	I admittedly have long had a fascination with these reel-to-reel tapes. A number of years ago, back when I lived in Milwaukee, I found a couple of blank reel-to-reel tapes created by 3M using the Scotch name. I bought them from a junk store, and maybe paid $2 for them. They managed to follow me through three states and five cities, and now sit on 
	<a href="https://midrange.tedium.co/issues/bless-this-mess/" rel="noopener noreferrer" target="_blank">my intentionally organized pile of junk</a>. Based on my analysis of the container and the logotype it uses, they date to the mid-1960s or earlier. (No, I have not tried to record on them.)
</p><p><img alt="A hand holds a rectangular package labeled Scotch magnetic tape." data-rm-shortcode-id="dba7c144e1565d8d93e5eca846dc9f37" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-hand-holds-a-rectangular-package-labeled-scotch-magnetic-tape.jpg?id=51890540&amp;width=980" height="1536" id="7458c" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-hand-holds-a-rectangular-package-labeled-scotch-magnetic-tape.jpg?id=51890540&amp;width=980" width="2048"><small placeholder="Add Photo Caption...">I’ve owned this blank Scotch 150 reel-to-reel tape for nearly 20 years. It is 50 to 60 years old. </small><small placeholder="Add Photo Credit...">Ernie Smith</small></p><p>
	For years, 3M’s reel-to-reels had one of the strongest reputations in the music industry; they were built to be of superhigh quality. But you might be wondering, how did 3M make the leap from reel-to-reel tape to floppies? It feels like just as strange a leap as a masking tape company developing reel-to-reel audio tape.
	<br></p><p>
	But, again, it happened.
</p><h3>How 3M’s Tapes Went From Music to Data</h3><p>
	3M didn’t develop the floppy disk drive, either. 
	<a href="https://tedium.co/2023/07/22/alan-shugart-floppy-disk-history/" target="_blank">IBM did, and Shugart Associates further improved it</a> by making it small enough for regular users.
</p><p><img alt="One 3M 5 \u00bc\u201d Floppy disk in a sleeve stands against a gray background." data-rm-shortcode-id="43b65ca8e6f0dca5e3362d6bde5ec2b0" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/one-3m-5-u00bc-u201d-floppy-disk-in-a-sleeve-stands-against-a-gray-background.jpg?id=51890553&amp;width=980" height="1250" id="f22da" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/one-3m-5-u00bc-u201d-floppy-disk-in-a-sleeve-stands-against-a-gray-background.jpg?id=51890553&amp;width=980" width="2000"><small placeholder="Add Photo Caption...">3M manufactured a signature 5.25-inch floppy disk. </small><small placeholder="Add Photo Credit...">IEEE Spectrum</small></p><p>
	But 3M, much as with mechanical tape, was well positioned to improve on it, leveraging its skills with mechanical media in the budding computing industry. In a way, 3M came to media manufacturing from the opposite direction than its disk-selling competitor Memorex did. Memorex started with computers and gradually came to develop and improve tape-based technology, which eventually evolved into floppy disks. On the other hand, 3M started with the raw materials and the manufacturing processes, and combined those into computing’s greatest commodity item, the floppy disk.
</p><p>
	3M got into the floppy disk market around the 
	<a href="https://books.google.com/books?id=pWBoOXVjuZ0C&amp;pg=PT10#v=onepage&amp;q&amp;f=false" rel="noopener noreferrer" target="_blank">fall of 1973</a>. It was not the only manufacturer of disks out there—some names from this era include Verbatim, Control Data, Dysan, and BASF. Most of these companies started with computing technology—for example, Dysan worked closely with Shugart Associates on the 5.25-inch floppy. But 3M wasn’t alone in starting with the raw materials. BASF, a German chemical manufacturer, has a somewhat similar corporate history and logo design to fellow thick-Helvetica enthusiast 3M. (Though 3M obviously <a href="https://www.basf.com/global/en/who-we-are/history/chronology/1925-1944/1939-1945.html" rel="noopener noreferrer" target="_blank">never associated with the Nazis</a> during World War II, so there’s that.)
</p><p data-rm-resized-container="25%"><img alt="Four different magnetic storage devices on a purple background. " data-rm-shortcode-id="08705882c5d1fc80ce7ccd70dfbe7c2a" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/four-different-magnetic-storage-devices-on-a-purple-background.jpg?id=51890570&amp;width=980" height="1633" id="8ae6d" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/four-different-magnetic-storage-devices-on-a-purple-background.jpg?id=51890570&amp;width=980" width="1246"><small placeholder="Add Photo Caption...">3M branched out beyond standard floppy disks with a variety of magnetic-tape storage media.</small><small placeholder="Add Photo Credit..."><a href="https://books.google.com/books?id=VFLlZVMEa_EC&amp;pg=PA52&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiR4LTHxMyCAxUeFlkFHTdCCdgQ6AF6BAgSEAI#v=onepage&amp;q=Floptical%203m&amp;f=false" rel="noopener noreferrer" target="_blank">ComputerWorld/Google Books</a>/3M</small></p><p>
	3M didn’t rest on its laurels with the floppy disk either, and tried to push the technology further, most notably with 
	<a href="https://www.storagenewsletter.com/2018/09/25/history-1991-floptical-by-insite-peripherals/" rel="noopener noreferrer" target="_blank">Floptical disk technology</a>, which Jim Adkisson, who helped create the 5.25-inch floppy at Shugart Associates, developed in the 1980s. A partnership of 3M, Maxell, and <a href="https://tedium.co/2016/12/06/iomega-zip-disk-click-of-death-history/" rel="noopener noreferrer" target="_blank">Iomega</a> created the Floptical disk, which could hold 20 megabytes of data on something that looked a lot like a 3.5-inch floppy. Unfortunately the floptical disk flopped, losing out to products like Iomega’s iconic <a href="https://www.computinghistory.org.uk/det/22978/Iomega-Zip-Drive-100-Parallel/" rel="noopener noreferrer" target="_blank">Zip drives</a>.
</p><p>
	3M also worked in more specialized media, developing high-capacity optical disks that fit into standard floppy and optical disk mechanisms, as well as high-end tape drives intended for the server room rather than your cassette player.
</p><p>
	In many ways, 3M was out front on one of the most important elements of computing and was making huge profits from it. But by the end of 1995, those days were done. What changed?
</p><p><span data-rm-shortcode-id="7620f5c6d1db2474feabc8fb1ec83bbc"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/bOHKgENMcGQ?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">3M advertised its floppy disk as more reliable than the competition in no uncertain terms. </small></p><h3>What Led 3M to Kick a Multibillion-Dollar Business to the Curb</h3><p>
	By 1995, 3M’s magnetic-media arm had evolved into a US $2.3 billion business, according to
	<a href="https://content.time.com/time/subscriber/article/0,33009,985024-1,00.html" rel="noopener noreferrer" target="_blank"><em>Time</em></a>, which made it a significant chunk of 3M’s overall offering.
</p><p>
	But at that time, high technology—
	<em>especially</em> consumer technology—was starting to look like a bad bet for legacy companies. This was around the same period that AT&amp;T, still smarting from misadventures like the <a href="https://www.inverse.com/input/features/fax-on-the-beach-the-story-of-atts-eo-communicator-90s-ipad-flop" rel="noopener noreferrer" target="_blank">EO Personal Communicator</a>, spun off Bell Labs as Lucent Technologies.
</p><p>
	3M’s story, in its own words, suggests a similar crisis of culture. In 
	<a href="https://multimedia.3m.com/mws/media/171240O/3m-century-of-innovation-book.pdf" rel="noopener noreferrer" target="_blank"><em>A Century of Innovation</em></a>, a book published by the company in 2002, around the time of its 100-year anniversary, the company compared the creation of the spin-off, which it called “the most wrenching decision in its history,” to that of its determination eight years earlier to sell its Duplicating Products Division, which sold copying machines:
</p><p><em>Of all the businesses 3M has shed over its 100 years, the two seminal decisions that people point to as most significant involved the sale of 3M’s Duplicating Products business to Harris Corporation in Atlanta, Georgia, and the spin-off of 3M’s data-storage and imaging-systems businesses in 1996 creating a new company called Imation in Oakdale, Minnesota, near 3M headquarters. The two decisions have several elements in common—both involved businesses that 3M created and, in fact, ranked number one in the marketplace for decades. They were “homegrown” businesses—largely created within 3M and commercialized and built with the energy of many internal sponsors and champions. The businesses were risky because the products were based on pioneering technologies. They not only changed the basis of competition; they also created all new, global industries. The businesses were highly profitable for decades, and they represented a significant share of the company’s total annual revenues. They also produced many of 3M’s next generation of leaders.</em></p><p>
	So what happened? Essentially, despite the company’s success working in industrial and professional settings, doing things for consumers like producing videotapes, floppy disks, and cassettes meant moving out of its comfort zone. These products, initially developed for businesses, grew so popular that they suddenly needed to be available at every big-box store and drugstore alike, and, Post-its aside, retail was not a fit for the kind of company 3M was.
</p><p>
	But more significantly, other companies were simply better at undercutting, and per the corporate biography, that required some tough decisions to be made:
</p><p><em>While it sold its products for little or no profit, its competition sold their products for even less. Even though the consumer business had huge growth potential, 3M had little experience with a low-cost, low-profit-margin model.</em></p><p><em> The markings were clear—exit this business, even though 3M invented it. To stay in the “dog fight” meant 3M had to invest enormous amounts of money in order to remain the low-cost producer, with no assurance that profit margins ever would improve. “Exiting it was the right decision,” [former senior vice president Al] Huber said.</em></p><p>
	Seeing what came after, it’s hard to disagree. While floppies were still a significant medium in the mid-1990s, it was obvious that they would not be enough capacity for the next generation of data hoarders. It would only be a couple of years before Apple would put the first dagger in the heart of the floppy disk with 
	<a href="https://en.wikipedia.org/wiki/IMac_G3" rel="noopener noreferrer" target="_blank">the iMac</a>, breaking with tradition by releasing a personal computer in 1998 with no built-in floppy disk drive.
</p><p><span data-rm-shortcode-id="5b53a6e7ab0f74ffc4d7a5fed5a851a5"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/3qkQi3zZVhg?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">Imation carried on a floppy-disk ad campaign through the late 1990s. </small></p><p>
	That was a harbinger of what was to come. Within a decade of the decision, floppy drives, compact cassettes, and videotapes—the three key elements of 3M’s move into consumer-driven magnetic media—had fallen by the wayside. Imation, still active today, is owned by O-Jin Corp., a Korean technology company 
	<a href="http://www.imation.com/board/bbs/board.php?bo_table=news_en&amp;wr_id=11" rel="noopener noreferrer" target="_blank">that basically bought it for its trademarked name</a>.</p><p>Much like its one-time competitor Memorex, Imation is a technology ghost kitchen. Its former corporate parent 3M, meanwhile, has a market cap of $51.33 billion at the time of this writing.</p><h3>3M’s Magnetic Legacy</h3><p>
	In a lot of ways, I think 3M’s persisting deep association with computing, despite the fact that the company left the field decades ago, comes down to the fact that it had a very recognizable logo design during its computer heyday.</p><p><span></span>My first experience with 3M was seeing its bright red logo on floppy disks used in classrooms with Apple IIe computers in the late 1980s and early ’90s. 3M was instantly recognizable among those responsible for creating the disks we needed to load up <em>Number Munchers</em> and <em>Commander Keen</em>, and as a result, its name is forever imprinted into the brains of retro-tech nerds the world over. It is a memory that gives me warm feelings.
</p><p>
	But 3M, for a number of reasons, is not a company that carries a lot of goodwill with younger generations. For example, the company is closely associated with the manufacturing of a variety of chemicals, including PFOS (Perfluorooctane sulfonate), a key ingredient in Scotchguard and other water-resistant materials. It’s one of many PFAS (perfluoroalkyl and polyfluoroalkyl) substances that are believed to be harmful to humans.
</p><p>
	The floppy disks that I and other elder millennials associate with a company that was essential to our youthful computing experience are long gone, shuttled away as a non-core business for a giant corporation that is best described as an amalgamation of non-core businesses loosely held together by a logo and backing in chemistry and raw materials.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Portr – open-source ngrok alternative designed for teams (121 pts)]]></title>
            <link>https://github.com/amalshaji/portr</link>
            <guid>39913197</guid>
            <pubDate>Wed, 03 Apr 2024 03:01:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/amalshaji/portr">https://github.com/amalshaji/portr</a>, See on <a href="https://news.ycombinator.com/item?id=39913197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/amalshaji/portr/blob/main/docs/src/assets/logo.svg"><img src="https://github.com/amalshaji/portr/raw/main/docs/src/assets/logo.svg" height="75px"></a>
</p>

<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/86544955af6556a5c8f662e6be50b96712d13214bd0e22d64f52e5576bf3abe7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616d616c7368616a692f706f727472"><img alt="GitHub License" src="https://camo.githubusercontent.com/86544955af6556a5c8f662e6be50b96712d13214bd0e22d64f52e5576bf3abe7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616d616c7368616a692f706f727472" data-canonical-src="https://img.shields.io/github/license/amalshaji/portr"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/62bd3c4fbf9520c348d39c04f68056ff7bd45311a04b323e28842b4f47cda0ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f616d616c7368616a692f706f727472"><img alt="GitHub Release" src="https://camo.githubusercontent.com/62bd3c4fbf9520c348d39c04f68056ff7bd45311a04b323e28842b4f47cda0ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f616d616c7368616a692f706f727472" data-canonical-src="https://img.shields.io/github/v/release/amalshaji/portr"></a>
  <a href="https://portr.dev/" rel="nofollow"><img alt="Documentation" src="https://camo.githubusercontent.com/eef05d5c6c5e20b43d56c8c890ac3157e5013299fef33c2d4010f1ef1c5fce97/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63756d656e746174696f6e2d706f7274722e6465762d303039364646" data-canonical-src="https://img.shields.io/badge/Documentation-portr.dev-0096FF"></a>
</p>

<p dir="auto">Portr is a tunnel solution that allows you to expose local HTTP and TCP connections to the public internet. It utilizes SSH remote port forwarding under the hood to securely tunnel connections.</p>
<p dir="auto">Portr is primarily designed for small teams looking to expose development servers on a public URL. It is not recommended for use alongside production servers.</p>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto">Portr is currently in beta. Expect bugs and anticipate breaking changes.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>🎉 Easily tunnel HTTP and TCP connections.</li>
<li>👾 Admin dashboard for team/user management. <a href="https://youtu.be/P37la8DjrzA" rel="nofollow">Watch video</a>.</li>
<li>🚨 Portr inspector for inspecting and replaying requests. <a href="https://youtu.be/hhbte2JI3qk" rel="nofollow">Watch video</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<ul dir="auto">
<li><a href="https://portr.dev/server/" rel="nofollow">Server setup guide</a></li>
<li><a href="https://portr.dev/client/installation/" rel="nofollow">Client installation guide</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Please read through <a href="https://github.com/amalshaji/portr/blob/main/.github/contributing.md">our contributing guide</a> and set up your <a href="https://portr.dev/local-development/admin/" rel="nofollow">development environment</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0). See the  <a href="https://github.com/amalshaji/portr/blob/main/LICENSE">LICENSE</a> file for the full license text.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel discloses $7B operating loss for chip-making unit (199 pts)]]></title>
            <link>https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/</link>
            <guid>39912854</guid>
            <pubDate>Wed, 03 Apr 2024 01:56:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/">https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/</a>, See on <a href="https://news.ycombinator.com/item?id=39912854">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/intel-discloses-financials-foundry-business-2024-04-02/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Choose your weapon: Survival strategies for depressed AI academics (118 pts)]]></title>
            <link>https://ar5iv.labs.arxiv.org/html/2304.06035</link>
            <guid>39912597</guid>
            <pubDate>Wed, 03 Apr 2024 01:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ar5iv.labs.arxiv.org/html/2304.06035">https://ar5iv.labs.arxiv.org/html/2304.06035</a>, See on <a href="https://news.ycombinator.com/item?id=39912597">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article lang="en">

<p><span>
<span>
Julian Togelius, <em id="id3.1.id1">Senior Member, IEEE</em>,
Georgios N. Yannakakis, <em id="id4.2.id2">Fellow, IEEE</em>

<br>
</span><span>JT is with New York University, GNY is with University of Malta. The word “depressed” in the title does not refer to either the clinical or economic concept of depression, but rather the word’s everyday use as signifying an unhappy and/or hopeless state of mind.</span></span>
</p>

<section id="S1">
<h2>
<span>I </span><span id="S1.1.1">Introduction</span>
</h2>

<p id="S1.p1.1">As someone who does Artificial Intelligence (AI) research in a university, you develop a complicated relationship to the corporate AI research powerhouses, such as Googe DeepMind, OpenAI, and Meta AI. Whenever you see one of these papers that train some kind of gigantic neural net model to do something you were not even sure a neural network could do, unquestionably pushing the state of the art and reconfiguring your ideas of what is possible, you get conflicting emotions. On the one hand: it is very impressive. Good on you for pushing AI forward. On the other hand: how could we possibly keep up? As an AI academic, leading a lab with a few PhD students and (if you’re lucky) some postdoctoral fellows, perhaps with a few dozen Graphics Processing Units (GPUs) in your lab, this kind of research is simply not possible to do.</p>
<p id="S1.p2.1">To be clear, this was not always the case. As recently as ten years ago, if you had a decent desktop computer and an internet connection you had everything you needed to compete with the best of researchers out there. Ground-breaking papers were often written by one or two people who ran all the experiments on their regular workstations. It is useful to point this out particularly for those who have come into the research field within the last decade, and for which the need for gigantic compute resources is a given.</p>
<p id="S1.p3.1">If we have learned one thing from deep learning <cite>[<a href="#bib.bib9" title="">9</a>]</cite>, it is that scaling works. From the ImageNet&nbsp;<cite>[<a href="#bib.bib19" title="">19</a>]</cite> competitions and their various winners to ChatGPT, Gato&nbsp;<cite>[<a href="#bib.bib17" title="">17</a>]</cite>, and most recently to GPT-4&nbsp;<cite>[<a href="#bib.bib1" title="">1</a>]</cite>, we have seen that more data and more compute yield quantitatively and often even qualitatively better results. (By the time you are reading this, that list of very recent AI milestones might very well be outdated.). Of course there are improvements to learning algorithms and network architectures as well, but these improvements are mostly useful in the context of the massive scale of experiments. (Sutton talks about the “Bitter Pill”, referring to the insight that simple methods that scale well always win the day when more compute becomes available&nbsp;<cite>[<a href="#bib.bib22" title="">22</a>]</cite>.) A scale that is not achievable by academic researchers nowadays. As far as we can tell, the gap between the amount of compute available to ordinary researchers and the amount available to stay competitive is growing every year.</p>
<p id="S1.p4.1">This goes a long way to explain the resentment that many AI researchers in academia feel towards these companies. Healthy competition from your peers is one thing, but competition from someone that has so much resources that they can easily do things you could never do, no matter how good your ideas are, is another thing. When you have been working on a research topic for a while and, say, DeepMind or OpenAI decides to work on the same thing, you will likely feel the same way as the owner of a small-town general store feels when Walmart sets up shop next door. Which is sad, because we want to believe in research as an open and collaborative endeavor where everybody gets their contribution recognized, don’t we?</p>
<p id="S1.p5.1">So, if you are but a Professor, with a limited team size and limited compute resources, what can you do to stay relevant in face of the onslaught of incredibly well-funded research companies? This is a question that has been troubling us and many of our colleagues for years now. Recent events, with models such as GPT-4 being shockingly capable and shockingly closed-sourced and devoid of published details, has made the question even more urgent. We have heard from multiple researchers at various levels of seniority, both in-person and via social media, who worry about the prospects of doing meaningful research given the lack of resources and the unfair competition from big tech companies.</p>
<p id="S1.p6.1">Let us make this clear at the outset: both of us are secure. We hold tenured academic Professorships and we rose up on the academic ladder pretty fast, in part because of finding an academic niche: we systematically pushed the envelope of AI in the domain of video games. While we obviously care about continuing to do relevant AI research ourselves, we are writing this mostly for our more junior colleagues, postdocs and doctoral students, who may wonder about which career path to choose. Is it worthwhile to go into academia, or is it better to join a big tech company, or maybe kick off a startup? Is a career in AI a good idea, or is it better to become a plumber? Should you be a cog in the machinery, or a rebel? (It’s usually easier to be a rebel when you have nothing to lose, which is either at the beginning of your career or when you have tenure.) As skilled as one may be, is this glorious battle to stay competitive lost already? Are we about to lie here, obedient to our laws? This Point of View article is partly meant as serious advice, and partly as emotional encouragement, but perhaps most of all to start a discussion with all of you so we improve our position as academics before the battle is long lost. We do not wish to stop the evolution of AI technology (even if we could); quite the contrary: we wish to discuss the strategies that will equip as many as possible to be part of this journey. While the challenges are real and many, we both feel the are even more opportunities and the time is right to grab them!</p>
<p id="S1.p7.1">In the remainder of this article we list a number of ideas (or strategies) for what to do if you are an AI academic despairing about your options. These options are presented in no particular order. We also don’t make any particular recommendations here or ranking the options for you. It is up to you to pick one, more than one, or none of them as your favourite direction. Towards the end of the article, however, we discuss what big tech companies and universities can do to help the situation. There, we make some specific suggestions.</p>
</section>
<section id="S2">
<h2>
<span>II </span><span id="S2.1.1">Give Up!</span>
</h2>

<p id="S2.p1.1">Giving up is always an option. Not giving up on doing research, but giving up on doing things that are really impactful and pushing the envelope. There are still plenty of technical details and sub-sub-questions to publish papers about in mid-tier journals and conferences. Please note, however: (1) This works best if you already have a secure permanent position and you do not care much about promotions, (2) this wasn’t really what you dreamed of doing when you decided on a research career, right? Forcing yourself to reframe your research agenda because of this fierce competition is similar to adjusting your research to the priorities of funding bodies like the European Commission or US National Science Foundation. At least going for the latter might secure some funding for your lab which can, in turn, help you work with some talented AI researchers and doctoral students. It is important to note that we both consider ourselves lucky enough as we have coordinated or have been part of several small- and large-scale research projects<span id="footnote1"><sup>1</sup><span><span><sup>1</sup><span>1</span>Examples include the H2020 AI4Media (<a target="_blank" href="https://www.ai4media.eu/" title="">https://www.ai4media.eu/</a>) and the FP7 C2Learn (<a target="_blank" href="http://project.c2learn.eu/" title="">http://project.c2learn.eu/</a>) projects.</span></span></span> that allowed us to support our research agendas and helped us (in part) to secure our positions.</p>
</section>
<section id="S3">
<h2>
<span>III </span><span id="S3.1.1">Try Scaling Anyway</span>
</h2>

<p id="S3.p1.1">Going head-to-head with an overwhelming competition is an admirable sentiment. If scaling works, let’s do it in our university labs! Let’s go tilting at windmills (GPU fans)!</p>
<p id="S3.p2.1">The most obvious problem is access to central processing units (CPUs) and GPUs. So, let’s say you secure $50k of funding for cloud compute from somewhere and go ahead running your big experiment. But this is a very small amount of money compared to what training something like GPT-3 costs. The recent open AI agent that learned to craft a diamond pickaxe in Minecraft required training of 9 days on 720 V100 GPUs&nbsp;<cite>[<a href="#bib.bib2" title="">2</a>]</cite>; this amounts to a few hundred thousand dollars for a single experiment. Not even prestigious European Research Council (EU) or National Science Foundation (US) grants can support such a level of investment. Still, spending $50k on cloud compute will give you significantly more compute than a bunch of gaming PCs taped together, so you could scale at least a little bit. At least for that very experiment. But as we all know, most experiments don’t work the first time you try them. For every big successful experiment we see reported, we have unreported months or maybe years of prototypes, proofs of concept, debugging, parameter tuning, and failed starts. You need this level of compute available constantly.</p>
<p id="S3.p3.1">The less obvious problem is that you need the right kind of team to build experimental software that scales, and that is generally not compatible with academic career structures. Most of the members of a typical academic research lab in computer science are PhD students that need to graduate within a few years, and need to have an individual project to work on which results in multiple first-author papers so they can get a job afterwards. A large-scale AI project typically means that most members of the team work for many months or years on the same project, where only one of them can be the first author on the paper. The team will probably also include people who do “mundane” software engineering tasks that are crucial to the success of the project, but which are not seen as AI research in themselves. The structures needed for successful large scale projects are simply not compatible with the structures of academia.</p>
</section>
<section id="S4">
<h2>
<span>IV </span><span id="S4.1.1">Scale Down</span>
</h2>

<p id="S4.p1.1">One popular way to bypass the issue is to focus on simple yet representative (toy) problems that will either prove the benefits of a new approach theoretically or showcase the comparative advantages of a novel method. Indicatively, a recent paper on Behaviour Transformers <cite>[<a href="#bib.bib21" title="">21</a>]</cite> showcased the benefits of the method on a toy navigation task that only took a simple multi layer perceptron to solve. A similar approach was later used in <cite>[<a href="#bib.bib15" title="">15</a>]</cite>. Both studies will likely be impactful despite the limited scale because they demonstrated the capacity of the algorithms in popular game and robotic benchmark problems that require large models and significant compute to train. In <cite>[<a href="#bib.bib14" title="">14</a>]</cite> we observe the same pattern once again: a case is made in a toy (gambling) environment but the impact, one would argue, comes from the comparative advantages the algorithm shows in more complex but computationally heavy problems.</p>
<p id="S4.p2.1">A downside with this approach is that people are wowed by pretty colors in high resolution, and take a real car navigating a road more seriously than a toy car, even though the challenges may be the same. So you will get less media exposure, perhaps less funding. There are also domains, such as language, which are very hard to scale down beyond some limit.</p>
</section>
<section id="S5">
<h2>
<span>V </span><span id="S5.1.1">Reuse and Remaster</span>
</h2>

<p id="S5.p1.1">A key reason that AI has advanced so rapidly over the last decade is that researchers make their code and models available to the scientific community. Model sharing and code accessibility was neither the norm nor the priority of AI researchers back in the days. Having access to pretrained large models like ViT in vision <cite>[<a href="#bib.bib4" title="">4</a>]</cite> or the Llama family for text&nbsp;<cite>[<a href="#bib.bib25" title="">25</a>]</cite> saves you time and effort as you can simply resue them, and fine-tune them for your own specific problem. Arguably, one needs to assume that the representations of those large models is general enough to be able to perform well to your downstream task with limited training. Unfortunately the fine-tuning and post-hoc analysis of a large model is sometimes not enough for good performance, especially if your domain is quite different from what they were pre-trained for. Relying on pre-trained models is therefore limiting the scope of research you can do.</p>
</section>
<section id="S6">
<h2>
<span>VI </span><span id="S6.1.1">Analysis Instead of Synthesis</span>
</h2>

<p id="S6.p1.1">Another thing one can do with the publicly available pretrained models is to analyze them. While this may not directly contribute to new capabilities, it can still make scientific progress. The current state of things is that we have great models for text and image generation publicly available, but we don’t understand them very well. You could even argue that we barely understand them all. Let’s face it: a transformer is not an intuitive thing to anyone, and the scale of data these models are trained on is almost incomprehensible in itself. There is plenty of work to do in analyzing them, for example by probing them in creative ways, and developing visualizations and conceptual machinery to help us understand them.</p>
<p id="S6.p2.1">One can do analysis with different mindsets. Trying to find and describe specific circuits and mechanisms that have been learnt is useful, and can help us (well, someone else, with resources) to create better models in the future. But one can also play the role of the gadfly, incessantly finding ways to break them! This is scientifically and societally valuable, no matter what those who try to make a business out of large models say. But it might not be the kind of research you want to do.</p>
</section>
<section id="S7">
<h2>
<span>VII </span><span id="S7.1.1">RL! No Data!</span>
</h2>

<p id="S7.p1.1">One might scale down one’s requirements with respect to data and instead approach AI problems through the lens of (online) reinforcement learning (RL). Following the RL path might allow you to bypass issues related to data availability, analysis, storage and handling; it does not however minimize the computational effort required necessarily. In fact, even the most efficient RL methods are known to be computationally heavy as the very process of exploration is costly. Moreover, shaping a reward function often involves forms of black art (informally) or practical wisdom (more formally). That is, a researcher often needs to continuously run lengthy experiments with different types of reward (among other hyperparameters) for a breakthrough result. So ultimately one has to downscale the complexity of the problem once again. The bottom line is that if you want to break free from large data sets you might be still faced with large compute requirements unless you work on simple (toy) problems, specialized domains, or work with small models; the next section is dedicated to the latter strategy.</p>
</section>
<section id="S8">
<h2>
<span>VIII </span><span id="S8.1.1">Small Models! No Compute!</span>
</h2>

<p id="S8.p1.1">Another valid strategy is to compromise on model scale to save on compute. There are many circumstances where you want or need a smaller model. Think of the smallest possible models that are capable of solving a problem or completing a task. This is particularly important to and relevant for real-world applications. <em id="S8.p1.1.1">In-the-wild</em> domains such as games, internet of things, and autonomous vehicles could allow AI to be deployed next to their end user and the data the user generates, i.e. at the edge of the network. This is often called <em id="S8.p1.1.2">edge AI</em> <cite>[<a href="#bib.bib10" title="">10</a>]</cite>, the operation of AI applications in devices of the physical world is possible when memory requirements are low and inference occurs rapidly. Neuroevolution and neural architecture search <cite>[<a href="#bib.bib10" title="">10</a>]</cite>, and knowledge distillation <cite>[<a href="#bib.bib6" title="">6</a>, <a href="#bib.bib13" title="">13</a>]</cite> methods are only a few of the available methods for edge AI. Note that beyond learning more from smaller models one could also attempt to learn more from less data <cite>[<a href="#bib.bib7" title="">7</a>]</cite>.
Following this research path may lead to significant into models’ inner workings. Studying small AI models makes the analysis far easier and increases the explainability of whatever the model does. Moreover, deploying such models on devices helps with privacy concerns. You can also argue for small models from the perspective of <em id="S8.p1.1.3">green AI</em>&nbsp;<cite>[<a href="#bib.bib20" title="">20</a>]</cite>&nbsp;, as it minimizes the environmental footprint of the research. Obviously there are limits to what a small model is capable of doing but the importance of this research direction, we feel, will be growing drastically over the years.</p>
</section>
<section id="S9">
<h2>
<span>IX </span><span id="S9.1.1">Work on Specialized Application Areas or Domains</span>
</h2>

<p id="S9.p1.1">One rather efficient strategy is to pick a niche but somewhat established area of research––that is likely beyond the immediate interest of the industry—and try to innovate within and through that area. It is often a successful strategy to bring and test your ideas to an entirely new domain but it is less often that the outcomes will have a large impact beyond that domain. There are plenty of examples of niche areas eventually becoming dominant due to the push of a few dedicated researchers. We are both currently mostly taking this strategy: we have the AI for games community as primary scientific community where we can perform state-of-art work, as few large companies put serious efforts into modern AI for games.</p>
<p id="S9.p2.1">Think of video games as a domain that penetrated the research communities of robotics and computer vision back in early 00s, and again with video games as deep RL benchmarks after 2015. Think of neural networks and deep learning methods that came to dominate communities invested in support vector machines and regression models (e.g. NeurIPS a decade ago). Also think of the ways reinforcement learning and deep learning have altered the core principles of multi-agent learning and cognitive/affect modeling in communities represented by the AAMAS, ACII and IVA conferences, for instance.</p>
<p id="S9.p3.1">A core downside to this strategy is the difficulty getting your paper accepted in the kind of large venues that are most influential in AI, such as NeurIPS, AAAI, ICML and IJCAI. Your paper and its results might end up sitting out-of-the-interest-distribution. It is, however, very possible to start your own community with its own publication venues.</p>
<p id="S9.p4.1">If you do not have the requisite domain expertise—and/or datasets—yourself, you can fruitfully approach domain experts to collaborate. The good news is that as an academic, you have plenty of such experts in other departments of your university or institute and they all have interesting AI problems to solve if you spend some time talking to them. One of the authors recently ran in to an anthropologist and an analytical chemist in a corridor, and started discussing projects that would include all three. Another example is a recent collaboration of one of the authors with urban designers resulting in the reconstruction of urban areas around MIT and Harvard for improving the comfort levels of Bostonians <cite>[<a href="#bib.bib5" title="">5</a>]</cite>.</p>
<p id="S9.p5.1">These projects may not end up advancing the state of AI much, but may make big differences in the particular disciplines. And sometimes big AI advances come from application-specific work.</p>
</section>
<section id="S10">
<h2>
<span>X </span><span id="S10.1.1">Solve Problems Few Care About (For Now!)</span>
</h2>

<p id="S10.p1.1">While focusing on an established niche or application field is a relatively safe strategy, a somewhat riskier one is to find a niche or application that does not exist yet. Basically, focus on a problem that almost no-one sees the importance of, or a method that nobody finds promising.</p>
<p id="S10.p2.1">One approach is to go looking for applications that people have not seriously applied AI to. A good idea is to look into a field that is neither timely nor “sexy”. The bet here is that this particular application domain will become important in the future, either in its own right or because it enables something else. We both took this path. Procedural content generation for games was a very niche topic 15 years ago and we helped nuild a research community around it<cite>[<a href="#bib.bib24" title="">24</a>, <a href="#bib.bib28" title="">28</a>]</cite>; recently it has become more important not only for the games industry, but also as a way to help generalize (deep) reinforcement learning <cite>[<a href="#bib.bib18" title="">18</a>, <a href="#bib.bib23" title="">23</a>]</cite>. Research on reinforcement learning is a core AI topic with thousands of papers published per year, lending more importance to this once somewhat obscure topic. This high-risk high-gain mindset might lead to a lonely path that nevertheless could end up being highly rewarding in the long run.</p>
<p id="S10.p3.1">So, look around you, and talk to people who are not AI researchers. What problem domains do you see where AI is rarely applied, and which AI researchers seem to not know or care about? Might someone care about these domains in the future? If so, you may want to dig deeper in one of those domains.</p>
</section>
<section id="S11">
<h2>
<span>XI </span><span id="S11.1.1">Try Things that Shouldn’t Work</span>
</h2>

<p id="S11.p1.1">Another comparative advantage of small academic teams is the ability to try things that “shouldn’t work”, in the sense that they are unsupported by theory or experimental evidence. The dynamics of large industry research labs are typically such that researchers are incentivized to try things that are likely to work; if not, money is lost. In academia, failure can be as instructive and valuable as success and the stakes are lower overall. Many important inventions and ideas in AI come from trying the “wrong” thing. In particular, all of deep learning stems from researchers stubbornly working on neural networks even though there were good theoretical reasons why they shouldn’t work.</p>
</section>
<section id="S12">
<h2>
<span>XII </span><span id="S12.1.1">Do Things that Have Bad Optics</span>
</h2>

<p id="S12.p1.1">The larger and more important a company is, the more constrained it is by ethics and optics. Any company is ultimately responsible to their shareholders, and if the shareholders perceive that the company suffers “reputational damage” they can easily fire the CEO. So large companies will try to avoid to do anything that looks bad. To get around this, large companies sometimes fund startups to do their more experimental work that might go wrong (think Microsoft and OpenAI). But even such plays have limits, as bad PR can come washing back like the tide in San Francisco Bay.</p>
<p id="S12.p2.1">As an individual researcher, who either has no position or who already has a secure position, you have nothing to lose. You can do things that are as crazy as you like. You are only constrained by the law and your own personality. Now, we are in no way arguing that you should do research that is unethical. By all means, try to do the right thing. But what you find objectionable might be very different from what a group of mostly-white liberal overeducated engineers in coastal USA find objectionable. The PR departments, ethics committees, and boards of directors of the rich tech companies espouse a very particular set of values. But the world is large, and full of very different people and cultures. So there is a big opportunity to do research that these tech companies will not do even though they could.</p>
<p id="S12.p3.1">As an example of a project that exploits such an opportunity, one of us participated in a project critically examining the normativity of the “neutral English” in current writing support systems by creating an autocomplete system with a language model that assumes you write in the tone of Chuck Tingle, the famous author of absurd sci-fi political satire gay erotica&nbsp;<cite>[<a href="#bib.bib8" title="">8</a>]</cite>. Our guess is that this project would not have been cleared for publication by Amazon or Google. Another example is this very paper.</p>
<p id="S12.p4.1">Similarly, you may find that you deviate from the cultural consensus in big tech companies regarding topics relating to nudity, sexuality, rudeness, religion, capitalism, communism, law and order, justice, equality, welfare, representation, history, reproduction, violence, or something else. As all AI research happens in and is influenced by a cultural and political context, see your deviation from the norm as an opportunity. If you can’t do the research they couldn’t do, do the research they wouldn’t do.</p>
</section>
<section id="S13">
<h2>
<span>XIII </span><span id="S13.1.1">Start it Up; Spin it Out!</span>
</h2>

<p id="S13.p1.1">By now it should be rather clear that academia is somewhat, paradoxically, limiting academic AI research. Even if one manages to secure large-scale multimillion projects this covers only a fraction of human and computational resources that are necessary for contemporary AI research, and the career structures and IP rights regimes of universities often impose further limits. One popular alternative among AI scientists is to spin out their idea from their university lab and found a company that will gradually transfer AI research to a set of commercial-standard services or products. Both authors have been part of this journey through co-founding modl.ai <cite>[<a href="#bib.bib16" title="">16</a>]</cite> and have learned a lot from this.</p>
<p id="S13.p2.1">Being part of the applied AI world offers many benefits. In principle you get access to rich data from real-world applications that you wouldn’t be able to have otherwise. Moreover your AI algorithms are tested on challenging commercial-standard, applications and have to be operational in the wild. Finally, you usually gain access to more compute and, if the start-up scales up, growing access to human resources.</p>
<p id="S13.p3.1">This journey is far from straightforward, however, as there are several limiting factors to consider. First, not all research ideas are directly applicable to a startup business model. Your best research ideas might be brilliant in terms of understanding the world, or at least getting published in highly prestigious venues, but that does not mean that one can easily make products out of them. Second, many outstanding results one obtained in the lab today may have to go through a long runway until they turn into a business case of some sort. Most startups do development rather than research, as the runways are short and you need to have a functioning product, preferably with some market traction, before the next funding round in two years or so. Third, even if you do get some investment, this does not mean you have an unlimited compute budget. With seed grants often in the range of a few millions, this does not buy you the capacity to do OpenAI-level experiments, especially as you need to pay real salaries (not PhD stipends) to your employees. Fourth, not every AI academic enjoys this type of an adventure. At the end of the day most academics have long agreed on their priorities when they opted to follow the academic career path. You don’t become a professor for the money. The security of an academic environment (given that it is both safe and creative), means to some far more than any potentially higher salary or other corporate benefits.</p>
<p id="S13.p4.1">Here, we might point out that both of us publish many more papers with our academic research teams than with the company we co-founded and work part-time at. On the other hand, we believe we have more direct impact on the games industry through our company.</p>
</section>
<section id="S14">
<h2>
<span>XIV </span><span id="S14.1.1">Collaborate, or Jump Ship!</span>
</h2>

<p id="S14.p1.1">If none of the above options work for you and you still want to innovate though large scale methods that are trained on lots of data you can always collaborate with those that have them both: compute and data. There are several ways to move forward with this approach.</p>
<p id="S14.p2.1">Universities in the vicinity of leading AI companies have a comparative advantage as local social networks and in-person meetings make the collaboration easier. Researchers from remote universities can still establish collaborations though research visits, placements and internships as part of a joint-research project. More radically, some established AI professors decide to dedicate some (if not all) of their research time to an industrial partner or even move their entire lab in there. Results from such partnerships, placements or lab transfers can be astonishing <cite>[<a href="#bib.bib26" title="">26</a>, <a href="#bib.bib27" title="">27</a>]</cite>. At a glance, this looks like the best way forward for AI academics, however, 1) the generated IP cannot always be published and 2) not everyone can or want to work in an industry-based AI lab.</p>
<p id="S14.p3.1">One might even argue that innovation should be driven by public institutions as supported by the industry, not the other way around. It is arguably the university’s responsibility to maintain (part of, or some of) the talented AI researchers it educates (academics and students) and the IP they generate. Otherwise AI education and research will eventually become redundant within a University environment. This would be bad for everyone, as knowledge would be less open, and there would be no-one to train the next generation of AI researchers. Next, let’s look at this relationship more closely and outline ways industrial corporations and universities may be able to help.</p>
</section>
<section id="S15">
<h2>
<span>XV </span><span id="S15.1.1">How Can Large Players in Industry Help?</span>
</h2>

<p id="S15.p1.1">It is not clear that large companies with well-financed AI labs actually want to help alleviate this situation. Individual researchers and managers might care about the depression of academic AI research, but what the companies care about is the bottom line and shareholder value, and having a competitive academic research community might or might not be in their best interest. However, to the extent that large private sector actors do care, there are multiple things they can do.</p>
<p id="S15.p2.1">At the most basic level, open-sourcing models, including both weights and training scripts, helps a lot. It allows academic AI researchers to study the trained models, fine-tune them, and build systems around them. It still leaves academic researchers uncompetitive when it comes to training new models, but it is a start. To their credit, several large industrial research organizations regularly release their most capable models publicly; Meta in particular stands out. Others don’t, and could rightly be shamed for not doing so. In particular if their name implies some degree of openness.</p>
<p id="S15.p3.1">The next step for remedying this situation is to collaborate with academia. As discussed earlier (see Section <a href="#S14" title="XIV Collaborate, or Jump Ship! ‣ Choose Your Weapon: Survival Strategies for Depressed AI Academics"><span>XIV</span></a>) some large institutions regularly do this, mostly through accepting current PhD students as interns, allowing these students to do large-scale work. Some offer joint appointments to certain academic researchers, and a few even occasionally offer research grants. All of this is good, but more can be done. In particular there could be mechanisms where academics initiate collaborations by proposing work they would do collaboratively, and there could be more stable research funding mechanisms.</p>
<p id="S15.p4.1">Going even further, private companies that really wanted to help mend this academia-industry divide could choose to work in public: post their plans, commit code, models, and development updates to public repositories and allowing academics to contribute freely. This is not how most companies work, and often they have good reasons for their secrecy. On the other hand, a lot could be gained from having academics contributing to your code and training for free.</p>
</section>
<section id="S16">
<h2>
<span>XVI </span><span id="S16.1.1">How Can Universities Help?</span>
</h2>

<p id="S16.p1.1">As much as industry might be willing to help, the primary initiative should come from those universities that wish to drive innovation. Universities have a strong initiative to stay on top of (or if possible be in the driving seat for) AI research for many reasons, including their role in educating students who will look for jobs in a world transformed by AI, and the many ways in which AI systems transform education&nbsp;<cite>[<a href="#bib.bib12" title="">12</a>]</cite>. It is worth noting that many of the most influential papers in AI involve a university department. Those papers are typically co-authored by researchers that either collaborate with or are involved in a company. The successful examples are out there <cite>[<a href="#bib.bib26" title="">26</a>, <a href="#bib.bib27" title="">27</a>, <a href="#bib.bib3" title="">3</a>]</cite>, but more is needed from the university’s end to enable such partnerships. And actually, there are many ways an academic institution can initiate and foster collaboration with the industry.</p>
<p id="S16.p2.1">Universities can also help their faculty manage the changed competitive landscape by encouraging and allowing them to be more risk-taking. The comparative advantage of academic researchers in AI is to do more high-risk exploration, and incentive structures at universities must change to account for this. For example, it is unreasonable to expect a steady stream of papers at top-tier conferences such as NeurIPS and AAAI; large, well-funded industry research labs will have large advantages at writing such papers. Similarly, the grant funding structure is such that it rewards safe and incremental research on popular topics; this seems to be an inherent feature of the way grant applications are evaluated, and it is unlikely to change however often funding agencies use words like “disruptive”. The kind of research that is favored by some of the most traditional (closed-call) grant mechanisms is mostly the kind of research where academic AI researchers will not be able to compete with industry. Therefore, universities should probably avoid making grant funding a condition for hires and promotions. If universities are serious about incentivizing their faculty to leverage their competitive advantage, they should reward trying and failing and promote high-risk high-gain funding schemes and research initiatives. It is then likely that funding agencies will follow the trend and invest even more on basic and blue sky research.</p>
<p id="S16.p3.1">Such a mindset might further open the possibilities for academics to attract large amounts of funding and collectively start building their own large (foundation) models that would be entirely open to any researcher. European research funding, for instance, has long supported the AI-on-Demand Platform<span id="footnote2"><sup>2</sup><span><span><sup>2</sup><span>2</span><a target="_blank" href="https://www.ai4europe.eu/" title="">https://www.ai4europe.eu/</a></span></span></span>—a community-driven channel featuring open access AI tools—that could host such collaborative efforts on model building and sharing. The seeds of collaborative open-source projects are already planted; think of StarCoder, the recent large model built by an open-science community involving both universities and industrial partners <cite>[<a href="#bib.bib11" title="">11</a>]</cite>. We feel it is only a matter of time that more and larger academic-driven models and data will be shared openly.</p>
</section>
<section id="S17">
<h2>
<span>XVII </span><span id="S17.1.1">Parting Words</span>
</h2>

<p id="S17.p1.1">We wrote this Point of View article with several purposes in mind. First, to share our concerns with other fellow AI researchers with a hope of finding a common cause (and a collective remedy?) as a community. Second, to offer a set of guidelines based on our own experiences but also the discussions we had in the academic and industrial AI venues we participate or organize. Third, to spur an open dialogue and solicit ideas for potentially more efficient strategies for us all. Arguably, the list of strategies we ended up discussing here are far from inclusive of all possibilities that are available out there; we believe, however, that they are seeds of a conversation that—in our opinion—is very timely.</p>
</section>
<section id="S18">
<h2>
<span>XVIII </span><span id="S18.1.1">Acknowledgements</span>
</h2>

<p id="S18.p1.1">We would like to thank all anonymous and eponymous reviewers for their insightful comments. This work has been supported by NSF Award 1956200 and by a GoodAI award (JT) and from the European Union’s Horizon 2020 programme under grant agreement No 951911 (GNY).</p>
</section>
<section id="bib">
<h2>References</h2>

<ul>
<li id="bib.bib1">
<span>[1]</span>
<span>
Rick Astley.

</span>
<span><span id="bib.bib1.1.1">Never Gonna Give You Up</span>.

</span>
<span>RCA, New York, 1987.

</span>
</li>
<li id="bib.bib2">
<span>[2]</span>
<span>
Bowen Baker, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien
Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune.

</span>
<span>Video pretraining (vpt): Learning to act by watching unlabeled online
videos.

</span>
<span><span id="bib.bib2.1.1">Advances in Neural Information Processing Systems</span>,
35:24639–24654, 2022.

</span>
</li>
<li id="bib.bib3">
<span>[3]</span>
<span>
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha
Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.

</span>
<span>Decision transformer: Reinforcement learning via sequence modeling.

</span>
<span><span id="bib.bib3.1.1">Advances in neural information processing systems</span>,
34:15084–15097, 2021.

</span>
</li>
<li id="bib.bib4">
<span>[4]</span>
<span>
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et&nbsp;al.

</span>
<span>An image is worth 16x16 words: Transformers for image recognition at
scale.

</span>
<span><span id="bib.bib4.1.1">arXiv preprint arXiv:2010.11929</span>, 2020.

</span>
</li>
<li id="bib.bib5">
<span>[5]</span>
<span>
Theodoros Galanos, Antonios Liapis, Georgios&nbsp;N Yannakakis, and Reinhard Koenig.

</span>
<span>Arch-elites: Quality-diversity for urban design.

</span>
<span>In <span id="bib.bib5.1.1">Proceedings of the Genetic and Evolutionary Computation
Conference Companion</span>, pages 313–314, 2021.

</span>
</li>
<li id="bib.bib6">
<span>[6]</span>
<span>
Jianping Gou, Baosheng Yu, Stephen&nbsp;J Maybank, and Dacheng Tao.

</span>
<span>Knowledge distillation: A survey.

</span>
<span><span id="bib.bib6.1.1">International Journal of Computer Vision</span>, 129:1789–1819, 2021.

</span>
</li>
<li id="bib.bib7">
<span>[7]</span>
<span>
Souhila Kaci.

</span>
<span><span id="bib.bib7.1.1">Working with preferences: Less is more</span>.

</span>
<span>Springer Science &amp; Business Media, 2011.

</span>
</li>
<li id="bib.bib8">
<span>[8]</span>
<span>
Ahmed Khalifa, Gabriella&nbsp;AB Barros, and Julian Togelius.

</span>
<span>Deeptingle.

</span>
<span>In <span id="bib.bib8.1.1">International Conference on Computational Creativity</span>, 2017.

</span>
</li>
<li id="bib.bib9">
<span>[9]</span>
<span>
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.

</span>
<span>Deep learning.

</span>
<span><span id="bib.bib9.1.1">nature</span>, 521(7553):436–444, 2015.

</span>
</li>
<li id="bib.bib10">
<span>[10]</span>
<span>
En&nbsp;Li, Liekang Zeng, Zhi Zhou, and Xu&nbsp;Chen.

</span>
<span>Edge ai: On-demand accelerating deep neural network inference via
edge computing.

</span>
<span><span id="bib.bib10.1.1">IEEE Transactions on Wireless Communications</span>, 19(1):447–457,
2019.

</span>
</li>
<li id="bib.bib11">
<span>[11]</span>
<span>
Raymond Li, Loubna&nbsp;Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov,
Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et&nbsp;al.

</span>
<span>Starcoder: may the source be with you!

</span>
<span><span id="bib.bib11.1.1">arXiv preprint arXiv:2305.06161</span>, 2023.

</span>
</li>
<li id="bib.bib12">
<span>[12]</span>
<span>
Weng&nbsp;Marc Lim, Asanka Gunasekara, Jessica&nbsp;Leigh Pallant, Jason&nbsp;Ian Pallant, and
Ekaterina Pechenkina.

</span>
<span>Generative ai and the future of education: Ragnarök or
reformation? a paradoxical perspective from management educators.

</span>
<span><span id="bib.bib12.1.1">The International Journal of Management Education</span>,
21(2):100790, 2023.

</span>
</li>
<li id="bib.bib13">
<span>[13]</span>
<span>
Konstantinos Makantasis, David Melhart, Antonios Liapis, and Georgios&nbsp;N
Yannakakis.

</span>
<span>Privileged information for modeling affect in the wild.

</span>
<span>In <span id="bib.bib13.1.1">2021 9th International Conference on Affective Computing and
Intelligent Interaction (ACII)</span>, pages 1–8. IEEE, 2021.

</span>
</li>
<li id="bib.bib14">
<span>[14]</span>
<span>
Keiran Paster, Sheila McIlraith, and Jimmy Ba.

</span>
<span>You can’t count on luck: Why decision transformers fail in stochastic
environments.

</span>
<span><span id="bib.bib14.1.1">arXiv preprint arXiv:2205.15967</span>, 2022.

</span>
</li>
<li id="bib.bib15">
<span>[15]</span>
<span>
Tim Pearce, Tabish Rashid, Anssi Kanervisto, Dave Bignell, Mingfei Sun, Raluca
Georgescu, Sergio&nbsp;Valcarcel Macua, Shan&nbsp;Zheng Tan, Ida Momennejad, Katja
Hofmann, et&nbsp;al.

</span>
<span>Imitating human behaviour with diffusion models.

</span>
<span><span id="bib.bib15.1.1">arXiv preprint arXiv:2301.10677</span>, 2023.

</span>
</li>
<li id="bib.bib16">
<span>[16]</span>
<span>
Christoffer&nbsp;Holmgård Pedersen, Benedikte Mikkelsen, Julian Togelius,
Georgios&nbsp;N Yannakakis, Sebastian Risi, and Lars Henriksen.

</span>
<span>Experience based game development and methods for use therewith,
May&nbsp;17 2022.

</span>
<span>US Patent 11,331,581.

</span>
</li>
<li id="bib.bib17">
<span>[17]</span>
<span>
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio&nbsp;Gomez Colmenarejo, Alexander
Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
Jost&nbsp;Tobias Springenberg, et&nbsp;al.

</span>
<span>A generalist agent.

</span>
<span><span id="bib.bib17.1.1">arXiv preprint arXiv:2205.06175</span>, 2022.

</span>
</li>
<li id="bib.bib18">
<span>[18]</span>
<span>
Sebastian Risi and Julian Togelius.

</span>
<span>Increasing generality in machine learning through procedural content
generation.

</span>
<span><span id="bib.bib18.1.1">Nature Machine Intelligence</span>, 2(8):428–436, 2020.

</span>
</li>
<li id="bib.bib19">
<span>[19]</span>
<span>
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et&nbsp;al.

</span>
<span>Imagenet large scale visual recognition challenge.

</span>
<span><span id="bib.bib19.1.1">International journal of computer vision</span>, 115:211–252, 2015.

</span>
</li>
<li id="bib.bib20">
<span>[20]</span>
<span>
Roy Schwartz, Jesse Dodge, Noah&nbsp;A Smith, and Oren Etzioni.

</span>
<span>Green ai.

</span>
<span><span id="bib.bib20.1.1">Communications of the ACM</span>, 63(12):54–63, 2020.

</span>
</li>
<li id="bib.bib21">
<span>[21]</span>
<span>
Nur&nbsp;Muhammad Shafiullah, Zichen Cui, Ariuntuya&nbsp;Arty Altanzaya, and Lerrel
Pinto.

</span>
<span>Behavior transformers: Cloning <math id="bib.bib21.1.m1.1" alttext="k" display="inline"><semantics id="bib.bib21.1.m1.1a"><mi id="bib.bib21.1.m1.1.1" xref="bib.bib21.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="bib.bib21.1.m1.1b"><ci id="bib.bib21.1.m1.1.1.cmml" xref="bib.bib21.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib21.1.m1.1c">k</annotation></semantics></math> modes with one stone.

</span>
<span><span id="bib.bib21.2.1">Advances in neural information processing systems</span>,
35:22955–22968, 2022.

</span>
</li>
<li id="bib.bib22">
<span>[22]</span>
<span>
Richard Sutton.

</span>
<span>The bitter lesson.

</span>
<span><span id="bib.bib22.1.1">Incomplete Ideas (blog)</span>, 13(1), 2019.

</span>
</li>
<li id="bib.bib23">
<span>[23]</span>
<span>
Adaptive&nbsp;Agent Team, Jakob Bauer, Kate Baumli, Satinder Baveja, Feryal
Behbahani, Avishkar Bhoopchand, Nathalie Bradley-Schmieg, Michael Chang,
Natalie Clay, Adrian Collister, et&nbsp;al.

</span>
<span>Human-timescale adaptation in an open-ended task space.

</span>
<span><span id="bib.bib23.1.1">arXiv preprint arXiv:2301.07608</span>, 2023.

</span>
</li>
<li id="bib.bib24">
<span>[24]</span>
<span>
Julian Togelius, Georgios&nbsp;N Yannakakis, Kenneth&nbsp;O Stanley, and Cameron Browne.

</span>
<span>Search-based procedural content generation: A taxonomy and survey.

</span>
<span><span id="bib.bib24.1.1">IEEE Transactions on Computational Intelligence and AI in
Games</span>, 3(3):172–186, 2011.

</span>
</li>
<li id="bib.bib25">
<span>[25]</span>
<span>
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
et&nbsp;al.

</span>
<span>Llama 2: Open foundation and fine-tuned chat models.

</span>
<span><span id="bib.bib25.1.1">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib26">
<span>[26]</span>
<span>
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan&nbsp;N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span>Attention is all you need.

</span>
<span><span id="bib.bib26.1.1">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li id="bib.bib27">
<span>[27]</span>
<span>
Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Hasselt, Marc Lanctot, and Nando
Freitas.

</span>
<span>Dueling network architectures for deep reinforcement learning.

</span>
<span>In <span id="bib.bib27.1.1">International conference on machine learning</span>, pages
1995–2003. PMLR, 2016.

</span>
</li>
<li id="bib.bib28">
<span>[28]</span>
<span>
Georgios&nbsp;N Yannakakis and Julian Togelius.

</span>
<span>Experience-driven procedural content generation.

</span>
<span><span id="bib.bib28.1.1">IEEE Transactions on Affective Computing</span>, 2(3):147–161, 2011.

</span>
</li>
</ul>
</section>
<figure id="id1">
<table id="id1.1">
<tbody><tr id="id1.1.1">
<td id="id1.1.1.1"><img src="https://ar5iv.labs.arxiv.org/html/2304.06035/assets/figures/togelius.jpg" id="id1.1.1.1.g1" width="96" height="125" alt="[Uncaptioned image]"></td>
<td id="id1.1.1.2">
<span id="id1.1.1.2.1">
<span id="id1.1.1.2.1.1"><span id="id1.1.1.2.1.1.1">Julian Togelius</span>  (S’05-M’07-SM’22) is an Associate Professor in the Department of Computer Science and Engineering, New York University, and a co-founder of modl.ai. He works on artificial intelligence for games and on games for artificial intelligence. His current main research directions involve procedural content generation in games, general video game playing, player modeling, and fair and relevant benchmarking of AI through game-based competitions. Additionally, he works on topics in evolutionary computation, quality-diversity algorithms, and reinforcement learning. From 2018 to 2021, he was the Editor-in-Chief of the IEEE Transactions on Games. Togelius holds a BA from Lund University, an MSc from the University of Sussex, and a PhD from the University of Essex. He has previously worked at IDSIA in Lugano and at the IT University of Copenhagen.</span>
</span>
</td>
</tr>
</tbody></table>
</figure>
<figure id="id2">
<table id="id2.1">
<tbody><tr id="id2.1.1">
<td id="id2.1.1.1"><img src="https://ar5iv.labs.arxiv.org/html/2304.06035/assets/figures/yannakakis.jpg" id="id2.1.1.1.g1" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="id2.1.1.2">
<span id="id2.1.1.2.1">
<span id="id2.1.1.2.1.1"><span id="id2.1.1.2.1.1.1">Georgios N. Yannakakis</span> (S’04-M’05-SM’14-F’24) is a Professor at the Institute of Digital Games, University of Malta, and a co-founder of modl.ai. He does research at the crossroads of artificial intelligence, computational creativity, affective computing, advanced game technology, and human-computer interaction. He has published more than 350 papers in the aforementioned fields and his work has been cited broadly. He is currently the Editor in Chief of <span id="id2.1.1.2.1.1.2">IEEE Transactions on Games</span> and an Associate Editor of <span id="id2.1.1.2.1.1.3">IEEE Transactions on Evolutionary Computation</span>.</span>
</span>
</td>
</tr>
</tbody></table>
</figure>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[7.4 earthquake in Taiwan, 34km depth (460 pts)]]></title>
            <link>https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&amp;extent=28.51697,-223.43994</link>
            <guid>39912330</guid>
            <pubDate>Wed, 03 Apr 2024 00:24:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&#x26;extent=28.51697,-223.43994">https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&#x26;extent=28.51697,-223.43994</a>, See on <a href="https://news.ycombinator.com/item?id=39912330">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>
            The Latest Earthquakes application supports most recent browsers,
            <a href="https://angular.io/guide/browser-support" target="_blank">view supported browsers</a>.
          </p>
          <p>
            If the application does not load, try our
            <a href="https://earthquake.usgs.gov/legacy/map/" target="_blank"> legacy Latest Earthquakes application</a>.
          </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ReALM: Reference Resolution as Language Modeling (121 pts)]]></title>
            <link>https://arxiv.org/abs/2403.20329</link>
            <guid>39911961</guid>
            <pubDate>Tue, 02 Apr 2024 23:26:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.20329">https://arxiv.org/abs/2403.20329</a>, See on <a href="https://news.ycombinator.com/item?id=39911961">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2403.20329">View PDF</a>
    <a href="https://arxiv.org/html/2403.20329v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user's screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of references, with our smallest model obtaining absolute gains of over 5% for on-screen references. We also benchmark against GPT-3.5 and GPT-4, with our smallest model achieving performance comparable to that of GPT-4, and our larger models substantially outperforming it.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Joel Ruben Antony Moniz [<a href="https://arxiv.org/show-email/954052bb/2403.20329">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 29 Mar 2024 17:59:06 UTC (7,019 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Gentle Introduction to the Art of Mathematics (206 pts)]]></title>
            <link>https://giam.southernct.edu/GIAM/</link>
            <guid>39911587</guid>
            <pubDate>Tue, 02 Apr 2024 22:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://giam.southernct.edu/GIAM/">https://giam.southernct.edu/GIAM/</a>, See on <a href="https://news.ycombinator.com/item?id=39911587">Hacker News</a></p>
<div id="readability-page-1" class="page">
<center>
</center>

<hr>

<center><img src="https://giam.southernct.edu/GIAM/GIAM-3.1-cover-small.jpg"></center>

<hr>

<p>GIAM (a Gentle Introduction to the Art of Mathematics) is a free,
open-source textbook -- the current version is 3.1.  GIAM covers several 
topics in the foundations of mathematics (logic, sets, relations, 
functions and cardinality) and introduces the reader to many techniques 
of mathematical proof (direct, indirect, contradiction, contrapositive, 
mathematical induction, combinatorial proofs and magic).  There are 
amusing quotations at the start of each chapter.

</p><hr>
<p>The <a href="https://giam.southernct.edu/GIAM/GIAM.pdf">text</a>.
</p><p>The exercise <a href="https://giam.southernct.edu/GIAM/GIAM-hw.pdf">workbook</a>.
</p><p>The hints and solutions <a href="https://giam.southernct.edu/GIAM/GIAM-solutions_manual.pdf">manual</a>.
</p><hr>

<p>
Some links to <a href="https://giam.southernct.edu/GIAM/review-links.html">reviews</a>.

</p><p>
GIAM is licensed under the <a href="https://giam.southernct.edu/GIAM/fdl-1.3-standalone.html">GNU Free Documentation License version 1.3</a>

</p><p>
GIAM is typeset using PDFLaTeX.  Figures were produced with XFiG.  
Photographs were modified using GIMP.  A compressed tarball of the
source files for GIAM is <a href="https://giam.southernct.edu/GIAM/GIAM-src-1_14_2014.tar.gz">here</a>. The source code for
GIAM is hosted at <a href="https://github.com/osj1961/giam.git">GitHub</a>.

</p><p>GIAM is now available in hardcopy as a printed-on-demand paperback 
from <a href="https://www.createspace.com/4609716">CreateSpace</a>.  
Please rest assured that GIAM will remain available for free download from this site. 

</p><p>There are alternative versions of GIAM available <a href="https://giam.southernct.edu/GIAM/versions.html">here</a>.










</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the XZ Backdoor Works (184 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/967192/6c39d47b5f299a23/</link>
            <guid>39911311</guid>
            <pubDate>Tue, 02 Apr 2024 22:00:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/967192/6c39d47b5f299a23/">https://lwn.net/SubscriberLink/967192/6c39d47b5f299a23/</a>, See on <a href="https://news.ycombinator.com/item?id=39911311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-trial,v 1.1 2005-11-04 21:27:01 corbet Exp $ -->
<center>
<table>
<tbody><tr><td>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider accepting the trial offer on the right.  Thank you
for visiting LWN.net!
</p></td><td>
<div>
<h3>Free trial subscription</h3>
           <p>
           Try LWN for free for 1 month: no payment
           or credit card required.  <a href="https://lwn.net/Promo/slink-trial2-3/claim">Activate
           your trial subscription now</a> and see why thousands of
           readers subscribe to LWN.net.
           
</p></div>
</td>
</tr>

</tbody></table>
</center>

<p>
Versions 5.6.0 and 5.6.1 of the
<a href="https://git.tukaani.org/?p=xz.git;a=summary">XZ</a>
compression utility and library
were shipped with <a href="https://lwn.net/Articles/967180">a backdoor</a> that targeted
<a href="https://www.openssh.com/">OpenSSH</a>.
Andres Freund
<a href="https://lwn.net/ml/oss-security/20240329155126.kjjfduxw2yrlxgzm@awork3.anarazel.de/">
discovered</a> the backdoor by
noticing that <a href="https://lwn.net/Articles/967194/">failed SSH logins were taking a lot of
CPU time</a> while doing some
micro-benchmarking, and tracking down the backdoor from there. It was introduced
by XZ co-maintainer "Jia Tan" — a probable alias for person or persons unknown.
The backdoor is a sophisticated attack with multiple parts, from the build
system, to link time, to run time.
</p>

<p>
The community response to the attack is just as interesting as the technical
aspects. For more information on that, refer to <a href="https://lwn.net/Articles/967866">this
companion article</a>.
</p>

<h4>Build time</h4>

<p>
The backdoor consists of several distinct phases, starting when the package is
being built. Gynvael Coldwind wrote
<a href="https://gynvael.coldwind.pl/?lang=en&amp;id=782">an in-depth investigation</a>
of the build-time parts of the backdoor.
Releases of XZ were provided via GitHub, which has since disabled
the maintainers' accounts and taken the releases offline. Like many projects that
use <a href="https://www.gnu.org/software/autoconf/">GNU Autoconf</a>,
XZ made releases that provided
several versions of the source for
download — an automatically generated tarball containing the source and related
files in the repository, along with versions containing the generated
build files. Those extra files include the <tt>configure</tt> script and makefiles for
the project.
Releasing
versions that contain the generated files allows downstream users of the software to
build without needing to install Autoconf.
</p>

<p>
In this case, however, the scripts in the maintainer-provided source tarballs
were not generated by Autoconf. Instead, one of the build scripts
contained the first stage of the exploit in <tt>m4/build-to-host.m4</tt>. This
script is originally from the <a href="https://www.gnu.org/software/gnulib/">Gnulib</a>
library; it provides a macro that converts
between the style of pathname used by the build environment and the
run-time environment of the program.
The version in these XZ releases was modified to extract the next stage
of the exploit, which is contained in
<tt>tests/files/bad-3-1corrupt_lzma2.xz</tt>.
</p>

<p>
This file is included in the repository, ostensibly as part of XZ's test suite,
though it was never used by those tests. It was committed well before the
release of version 5.6.0. The file, supposedly a corrupted XZ file,
is actually a valid XZ stream with some bytes
swapped — for example, <tt>0x20</tt> is swapped with occurrences of <tt>0x09</tt>
and vice versa.
When decoded, it yields <a href="https://lwn.net/Articles/967979">a shell script</a> that
unpacks and executes the next stage of the backdoor.
</p>

<p>
The next stage of the backdoor is located in
<tt>tests/files/good-large_compressed.lzma</tt>. This is the
<tt>injected.txt</tt> file
attached to Freund's message. That file contains more than just the
next stage of the script — it also contains additional binary data that forms
the actual backdoor itself. The final script skips over the header of the file
from which it was extracted, and then uses <tt>awk</tt> to decrypt the remainder
of the file. Finally, that decrypted stream is
decompressed using the XZ command-line program,
in order to extract a pre-compiled file called
<tt>liblzma_la-crc64-fast.o</tt>, which is also attached to Freund's message.
</p>

<h4>Link time</h4>

<p>
The extracted file is a 64-bit relocatable ELF library.
The remainder of the build process links it into the final <tt>liblzma</tt>
library which ends up being loaded into OpenSSH on some distributions.
Those distributions
<a href="https://sources.debian.org/patches/openssh/1:9.2p1-2%2Bdeb12u2/systemd-readiness.patch/">
patch</a> OpenSSH to use systemd for daemon-readiness notifications;
<tt>libsystemd</tt> in turn depends on liblzma for compressing journal files.
Lennart Poettering has since
<a href="https://mastodon.social/@pid_eins/112202687764571433">posted</a> some
example code showing how to let applications use systemd readiness notifications without
pulling in the entire library.
When the malicious
<tt>liblzma</tt> is used by a dynamically linked process, it uses the
<a href="https://sourceware.org/glibc/wiki/GNU_IFUNC">indirect function</a>
mechanism to involve itself in the <a href="https://lwn.net/Articles/961117">linking process</a>.
</p>

<p>
Indirect functions are a feature of the GNU C library (glibc) that permits a developer to
include several versions of a function and select which version to use at
dynamic linking time. Indirect functions are useful for including optimized versions of a
function that rely on specific hardware features, for example. In this case, the
backdoor provides its own version of the indirect function
resolvers <tt>crc32_resolve()</tt> and <tt>crc64_resolve()</tt> that select
versions of <tt>crc32()</tt> and <tt>crc64()</tt> to use, respectively.
<tt>liblzma</tt> does not usually use indirect functions, but using faster
functions to calculate checksums does sound like a plausible use of the feature.
This plausible deniability is probably why the exploit itself lives in a file
called <tt>liblzma_la-crc64-fast.o</tt>.
</p>

<p>
When the dynamic linker finalizes the locations of those functions, it
calls the backdoor's resolver functions. At
this point, dynamic linking is still in progress, so many of the
linker's internal data structures have not yet been made read-only. This would
let the backdoor manipulate libraries that had already been loaded by
overwriting entries in the procedure linkage table (PLT) or global offset table
(GOT). However, <tt>liblzma</tt> is loaded fairly early in the link order of
OpenSSH, which
means that the <a href="https://www.openssl.org/">OpenSSL</a>
cryptography functions that are the backdoor's ultimate
target may not have been loaded yet.
</p>

<p>
To deal with that, the backdoor adds an
<a href="https://www.man7.org/linux/man-pages/man7/rtld-audit.7.html">
audit hook</a>. The dynamic linker calls all the registered audit hooks
when it is resolving a symbol. The backdoor uses this to wait until it
sees the <a href="https://linux.die.net/man/3/rsa_public_decrypt">
<tt>RSA_public_decrypt@got.plt</tt></a> symbol being resolved. Despite the
name, this function is actually part of handling an RSA signature (which is a
decryption operation) — OpenSSH calls
it while validating an RSA certificate provided by the client
during a connection.
</p>

<h4>Run time</h4>

<p>
Once the backdoor detects this function being linked, it replaces the function
with its
own version. What the altered version does is still being investigated, but at
least one of its functions is to attempt to extract a command from the
public-key
field of the provided RSA certificate (which means that certificates that are
used in this attack cannot actually be used to authenticate normally).
The backdoor checks whether the command is
signed by the attacker's private key and has valid formatting. If it does, then
the backdoor directly runs the given command as the user running <tt>sshd</tt>,
which is usually root.
</p>

<p>
Anthony Weems has put together
<a href="https://github.com/amlweems/xzbot">an explanation</a> of the run-time
portion of the exploit, including a honeypot to detect attempts to use the
exploit, and code to generate command payloads.
Using the backdoor involves signing the command to be executed with a private
key, but the attacker's is not available, so the backdoored server needs to be
patched to use another private key.
This also means that detecting backdoored servers remotely is nearly
impossible, since they will not react any differently to connections that don't
use the attacker's private key.
</p>

<p>
Ultimately, the effect of the backdoor appears to be that a compromised SSH
server which receives a connection with a hand-crafted RSA certificate for
authentication can be made to run attacker-controlled code.
</p>

<h4>Anti-analysis</h4>

<p>
The design of the backdoor makes it difficult to notice without directly inspecting
<tt>liblzma</tt>. For example, the choice to enable remote code execution rather
than an authentication bypass means that use of the exploit does not detect a
login session that could be noticed by traditional administration tools.
The backdoor's code
also uses several techniques to make discovery more
difficult.
For example, the string "RSA_public_decrypt@got.plt",
which is used by the audit hook, never appears in the binary of the exploit.
Instead, it uses a <a href="https://en.wikipedia.org/wiki/Trie">trie</a>
to hold various strings. Serge Bazanski posted
<a href="https://gist.github.com/q3k/af3d93b6a1f399de28fe194add452d01">a
list</a> of strings in the malicious <tt>liblzma</tt> encoded this way.
</p>

<p>
Examining that list shows that <tt>RSA_public_decrypt</tt> is likely not the
only function interfered with; several other cryptography routines are listed.
It also shows various functions and strings that are used to interfere with
OpenSSH's logging. This is not yet confirmed, but it seems likely that a
compromised SSH server would not actually log any connection attempts that use
the exploit.
</p>

<p>
The backdoor also includes many checks to ensure it is running in the expected
environment — a standard precaution for modern malware that is intended to make
reverse-engineering more difficult. The backdoor is only active
under specific circumstances, including: running in a non-graphical
environment, as root, in a binary located at <tt>/usr/sbin/sshd</tt>, with
<tt>sshd</tt> having the expected ELF header, and where none
of its functions have had a breakpoint inserted by a debugger. Despite these
obstacles,
community efforts to reverse-engineer and explain the remainder of the
backdoor's code
<a href="https://gist.github.com/smx-smx/a6112d54777845d389bd7126d6e9f504">
remain underway</a>.
</p>

<p>
The backdoor also includes code that patches the binary of <tt>sshd</tt> itself
to disable <a href="https://man7.org/linux/man-pages/man2/seccomp.2.html">
<tt>seccomp()</tt></a> and prevent the program from creating a
<a href="https://en.wikipedia.org/wiki/Chroot">chroot sandbox</a> for
its children. In total, the code of the backdoor is 87KB, which is plenty of
space for additional unpleasant surprises. Many people have put together their
own summaries of the exploit, including
<a href="https://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27">
this comprehensive FAQ</a> by Sam James, which links to other resources.
</p>

<h4>Being safe</h4>

<p>
The exploit was caught promptly, so almost no users were affected. Debian sid,
Fedora Rawhide, the Fedora 40 beta,
openSUSE Tumbleweed, and Kali Linux all briefly shipped the
compromised package. NixOS unstable also shipped the compromised version, but was not
vulnerable because it does not patch OpenSSH to link <tt>libsystemd</tt>.
Tan also included
some other changes to the XZ code to make detecting and mitigating the backdoor
more difficult, such as
<a href="https://git.tukaani.org/?p=xz.git;a=blobdiff;f=CMakeLists.txt;h=d2b1af7ab0ab759b6805ced3dff2555e2a4b3f8e;hp=76700591059711e3a4da5b45cf58474dac4e12a7;hb=328c52da8a2bbb81307644efdb58db2c422d9ba7;hpb=eb8ad59e9bab32a8d655796afd39597ea6dcc64d">
sabotaging</a> sandboxing measures and making preemptive efforts to redirect
security reports. Even though the exploit did not reach their stable versions,
several distributions are nonetheless
taking steps to move to a version of XZ that does not contain
any commits from Tan, so users should expect to see security updates related to
that soon. Readers may also
wish to refer to the security notice for their distribution for more specific
information.
</p><br clear="all">
               <br clear="all">
               <blockquote>
<p>
<b>Did you like this article?</b>  Please accept our 
<a href="https://lwn.net/Promo/slink-trial2-3/claim">trial subscription offer</a> to be
able to see more content like it and to participate in the discussion.
</p>
</blockquote>
<hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/967192/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Science fiction and the death of the sun (116 pts)]]></title>
            <link>https://www.typebarmagazine.com/2024/03/24/science-fiction-and-the-death-of-the-sun/</link>
            <guid>39911155</guid>
            <pubDate>Tue, 02 Apr 2024 21:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.typebarmagazine.com/2024/03/24/science-fiction-and-the-death-of-the-sun/">https://www.typebarmagazine.com/2024/03/24/science-fiction-and-the-death-of-the-sun/</a>, See on <a href="https://news.ycombinator.com/item?id=39911155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3><strong>By Gwen C. Katz</strong></h3><p><span>Why is early speculative fiction so grim?</span></p><p><span>From potions that turn people into psychopathic murderers to alien invasions only defeated by coincidental quirks of biology, turn-of-the-20th-century sci-fi carries a distinct tone that the arc of history bends towards catastrophe. Most commentators have looked to social and political factors to explain this tone. There are plenty to choose from—runaway income inequality, rampant corruption, crushing working-class living conditions. These issues were certainly present in the minds of early sci-fi authors, many of whom—such as H.G. Wells, who drafted a precursor to the UN Declaration of Human Rights—were progressive reformists.&nbsp;</span></p><p><span>But there’s another factor that isn’t often mentioned: They thought the sun was on the brink of death.</span></p><p><span>Contextualizing stories to their moment in the history of science is more difficult than placing them within political and social history. We don’t all take mandatory science history classes in school. Yet important scientific discoveries have a major impact on culture, from Cold War nuclear anxiety to the neon-drenched cyberpunk of the early computer era. And in the 19</span><span>th</span><span> and early 20</span><span>th</span><span> centuries, one of the biggest unanswered scientific questions was: How does the sun work?</span></p><p><span>During the Age of Enlightenment (yes, we really are starting that far back), as the scientific method replaced religion as the explanation for physical phenomena, the predominant scientific belief was that the universe and the bodies within it were endless. If God didn’t create the universe 6000 years ago, maybe it had simply always existed. Observationally, the sun has always been there throughout human history and it’s just as bright today as it was yesterday, so it’s logical to conclude that it will always be there. This basic belief in the static nature of the universe proved to be a hurdle for many scientific discoveries—for instance, one of the reasons the theory of evolution took time to be accepted was that extinction was not a widely-accepted phenomenon.</span></p><p><span>Science fiction was not yet a codified genre in this era, and few other than theologians were pondering the eventual fate of the earth. Yet there were premonitions. In 1815, Mount Tambora exploded in the most powerful volcanic eruption in recorded history. The resultant ash darkened skies around the world and plunged the planet into a cold spell dubbed The Year Without a Summer.</span></p><p><span>In the midst of this, Lord Byron wrote his 1816 poem </span><a href="https://www.poetryfoundation.org/poems/43825/darkness-56d222aeeee1b"><i><span>Darkness</span></i></a><span>, envisioning a world where the sun never returned:</span></p><blockquote><p><span>The bright sun was extinguish’d, and the stars</span></p><p><span>Did wander darkling in the eternal space,</span></p><p><span>Rayless, and pathless, and the icy earth</span></p><p><span>Swung blind and blackening in the moonless air…</span></p><p><span>The waves were dead; the tides were in their grave,</span></p><p><span>The moon, their mistress, had expir’d before;</span></p><p><span>The winds were wither’d in the stagnant air,</span></p><p><span>And the clouds perish’d; Darkness had no need</span></p><p><span>Of aid from them—She was the Universe.</span></p></blockquote><p><span>Byron’s primary focus was the human drama of these final days, and he drew primarily from imagination, not scientific theory. Yet his vision of a frozen, sunless earth foreshadowed later discoveries with remarkable prescience.</span></p><p><span>The codifying of the laws of thermodynamics in the mid-19</span><span>th</span><span> century prompted a major reevaluation of scientists’ assumptions about the universe. The first law of thermodynamics stated that energy had to come from somewhere. The second stated that it had to eventually run out.</span></p><p><span>Outside of fundamentalist Christian circles, most natural laws don’t inspire strong emotional reactions beyond interest and curiosity. But there’s a certain ennui to the second law of thermodynamics. While the billiard-hall laws of Newtonian mechanics run just as happily in reverse, entropy does not. It leaks out from every system, every interaction, always larger than before. What is broken can never be truly mended, it reminds us. What is lost can never be truly regained. Your every action, however mindful, is one more step on the inevitable journey to the heat-death of the universe.</span></p><p><span>The sun could no longer simply be an infinite energy source in the sky. The&nbsp; magnificent beacon’s energy had to be finite, and it had to be caused by something. But what? Such a vast amount of power was a major challenge to the 19</span><span>th</span><span>-century model of physics.</span></p><p><span>The first explanation was offered by Robert Mayer in 1848, and again by Lord Kelvin a few years later: The sun is glowing because meteors are constantly crashing into it. This theory raised immediate and obvious problems. Where are all these meteors coming from? Why can’t we see them? </span><i><span>How are we not all dead</span></i><span>, since the meteors would presumably be raining their fiery fury on the earth at the same rate? “No doubt meteors fall into the sun, as assumed by Mayer and Thomson [Kelvin],” </span><a href="https://www.scientificamerican.com/article/the-age-of-the-sun-and-the-earth/"><span>wrote Florian Cajori</span></a><span> for </span><i><span>Scientific American</span></i><span> in 1908, “but the Mayer-Thomson theory made demands upon these meteors that bordered on extravagance.”</span></p><p><span>The first tenable explanation arrived in 1854 by Herman von Helmholtz: Gravitational contraction. As the heavy sun collapses under its own weight, the immense heat and pressure cause it to incandesce. Mathematically, this works. Stars are blackbodies, a type of material that’s black when cool and glows different colors when heated in a predictable sequence: Red, orange, yellow, white, and at its hottest, blue (iron being forged is a familiar example, though it never gets hot enough to glow blue). This suggested a very simple stellar life cycle: Hot, blue-white stars must be the youngest, gradually cooling to yellow, then red, before ceasing to glow altogether.</span></p><p><span>Moreover, unlike the mystery meteors, this theory is finite and quantifiable. Eventually, the sun would finish collapsing, the heat would dissipate, and it would slowly cool and darken into an inert lump of…stuff. (They were still hazy on that point; as late as the 1920s Arthur Eddington would be using models that assumed stars were almost entirely iron.) Knowing its mass, they could calculate how fast this would happen. So for the first time, it was possible to estimate the lifetime of the sun.</span></p><p><span>And the number was not large.</span></p><p><span>Initial estimates put the sun’s lifespan at around 20 million years. It could hardly be much younger than that, so its lifetime appeared to be mostly over. Soon it would burn out. What about the earth? It would freeze over, its orbit would decay, and it would draw closer to the husk of the sun, becoming tidally locked. Ultimately, it would fall into the remains of the sun and be destroyed, but not until long after all life went extinct. Humanity had, perhaps, a couple million years left before the sky darkened and the earth succumbed to eternal winter. Not a cheery thought.</span></p><p><span>Of course, a million years is hardly an imminent deadline on a human timescale—it’s still a hundred times the duration of all human civilization to date—but nevertheless, the idea that our world’s time was mostly up cast a bit of a pall.</span></p><p><span>Smack in the middle of these discussions, the natural world provided a most vivid illustration. In 1883, Krakatoa erupted nearly as violently as Tambora, ushering in another volcanic winter. (The 1800s were not a good century for volcanoes. Unless you were a geologist.) For the scientifically-minded, it must have felt like a premonition of earth’s eventual fate.</span></p><p><span>And yet the gravitation theory didn’t add up. For one thing, there was geology. While astrophysicists examined the sun, geologists were estimating the age of the earth based on its internal temperature, and their research dated the earth to some hundreds of millions or billions of years old. Biologists studying fossils estimated a similar age. Everyone agreed that the sun had to be older than the earth, so where did the discrepancy lie? “Lord Kelvin,” </span><a href="https://zenodo.org/records/1429642"><span>quoth Eddington</span></a><span> in 1920, “…made strenuous efforts to induce geologists and biologists to accommodate their demands to this time-scale. I do not think they proved altogether tractable.”</span></p><p><span>For another thing, if the light came from incandescence, what on earth was a pulsar? Surely a star couldn’t be alternately collapsing and un-collapsing.</span></p><p><span>Still, gravitation was the best anyone had, and this theory was taught to students for a solid seventy years. Among these students were the early luminaries of science fiction. The image of the earth’s long, slow descent into an endless ice age lodged itself firmly into their voracious minds, to percolate out in their works. Sometimes this was subconscious, in the form of the melancholic speculative fiction that dominated the genre’s early years. Other times, the sun’s imminent demise and its effect on humanity are the subject of the story itself: The dying-earth genre, which peaked in the first decades of the 20</span><span>th</span><span> century.</span></p><p><span>The most well-known example is </span><a href="https://gutenberg.org/cache/epub/35/pg35-images.html#chap14"><i><span>The Time Machine</span></i></a><span> by H.G. Wells (1895). In one of the book’s most memorable scenes, in a frenzied struggle to escape the Morlocks, the Time Traveler accidentally sends his machine forward in time instead of back and briefly journeys to the end of the Earth. The scene that greets him is a dismal one:</span></p><blockquote><p><span>The sky was no longer blue. North-eastward it was inky black, and out of the blackness shone brightly and steadily the pale white stars. Overhead it was a deep Indian red and starless, and south-eastward it grew brighter to a glowing scarlet where, cut by the horizon, lay the huge hull of the sun, red and motionless…There were no breakers and no waves, for not a breath of wind was stirring. Only a slight oily swell rose and fell like a gentle breathing, and showed that the eternal sea was still moving and living…</span></p><p><span>I cannot convey the sense of abominable desolation that hung over the world. The red eastern sky, the northward blackness, the salt Dead Sea, the stony beach crawling with these foul, slow-stirring monsters, the uniform poisonous-looking green of the lichenous plants, the thin air that hurts one’s lungs: all contributed to an appalling effect…</span></p><p><span>All the sounds of man, the bleating of sheep, the cries of birds, the hum of insects, the stir that makes the background of our lives—all that was over.</span></p></blockquote><p><span>The bright red sky evokes the dramatic volcanic sunsets following Krakatoa, which, twelve years later, must have still been a vivid memory. The still, lifeless sea recalls Byron.</span></p><p><span>But of particular note is the large, motionless red sun. The description resembles a red giant, and other than the cold temperature it would be easy to mistake this for modern astrophysics, where growing into a red giant marks the end of the sun’s life. In fact, Wells is depicting something completely different: The earth growing much closer to the sun due to orbital decay. Tidally locked, it no longer has day and night, but exists in a perpetual twilight with the sun fixed in a single place. The sun is larger because it’s closer; it’s red because it’s a cooling blackbody. The image of the large, red, cold, stationary sun would appear over and over in melancholic science fiction.</span></p><p><span>But horror author/sailor/bodybuilder William Hope Hodgson proved to be the champion of the dying-earth genre. Hodgson (who was an impressionable six-year-old at the time of Krakatoa) returned to this well twice at length. The first was his slightly brilliant, entirely delirious 1908 novel </span><i><span>The House on the Borderland</span></i><span>. In its </span><a href="https://www.gutenberg.org/cache/epub/10002/pg10002-images.html#XVII"><span>extended flash-forward sequence</span></a><span>, he flexes his understanding of the scientific theory of the day, describing the sun as:</span></p><blockquote><p><span>…a tremendous globe of a glowing copper-bronze hue; in parts ringed with blood-red bands; in others, with the dusky ones, that I have already mentioned…these markings were due, probably, to differences in temperature of the various areas; the red representing those parts where the heat was still fervent, and the black those portions which were already comparatively cool.</span></p></blockquote><p><span>In a moment of drama, the sun devours Mercury:</span></p><blockquote><p><span>All at once, during one of these periods of life, a sudden flame cut across the night—a quick glare that lit up the dead earth, shortly; giving me a glimpse of its flat lonesomeness. The light appeared to come from the sun—shooting out from somewhere near its center, diagonally. A moment, I gazed, startled. Then the leaping flame sank, and the gloom fell again. But now it was not so dark; and the sun was belted by a thin line of vivid, white light. I stared, intently. Had a volcano broken out on the sun? Yet, I negatived the thought, as soon as formed. I felt that the light had been far too intensely white, and large, for such a cause.</span></p><p><span>Another idea there was, that suggested itself to me. It was, that one of the inner planets had fallen into the sun—becoming incandescent, under that impact…</span></p><p><span>After that one burst of flame, the light had shown, only as an encircling band of bright fire. Now, however, as I watched, it began slowly to sink into a ruddy tint, and, later, to a dark, copper-red color; much as the sun had done. Presently, it sank to a deeper hue; and, in a still further space of time, it began to fluctuate; having periods of glowing, and anon, dying. Thus, after a great while, it disappeared.</span></p><p><span>Long before this, the smoldering edge of the sun had deadened into blackness. And so, in that supremely future time, the world, dark and intensely silent, rode on its gloomy orbit around the ponderous mass of the dead sun.</span></p></blockquote><p><span>Hodgson’s second foray into the death of the earth comes from his magnum opus, </span><a href="https://gutenberg.org/cache/epub/10662/pg10662-images.html"><i><span>The Night Land</span></i></a> <span>(1912), a 600-page slog so notoriously impenetrable that even H.P. Lovecraft </span><a href="https://www.hplovecraft.com/writings/texts/essays/shil.aspx"><span>criticized its</span></a><span> “painful verboseness.” The novel is set millions of years in the future, when the sun has long since burned out and the earth is a frozen wasteland inhabited by monsters. The last few million humans all live in one giant, technologically advanced pyramid, remembering the death of the sun only as a legendary creation story.</span></p><p><span>Hodgson’s depictions contain fanciful embellishments, but they are also peppered with meticulous scientific detail. In </span><i><span>The House on the Borderland</span></i><span>, carbon dioxide precipitates out of the atmosphere and falls as snow, and in the absence of an atmosphere, all sound becomes inaudible. In </span><i><span>The Night Land</span></i><span>, the earth’s crust has cracked as it cooled, creating fissures hundreds of miles deep. In one of the book’s most melancholic moments, the protagonist finds a book predicting that humanity’s remnants might relocate from the frozen surface to the bottom of these fissures, where it was still warm—only to realize that the icy wasteland he inhabits </span><i><span>is</span></i><span> the bottom of the fissure, that humanity made the journey thousands of years ago, and that there is no deeper refuge to flee to.</span></p><p><span>But while Wells and Hodgson were writing, science was progressing. In 1898, an upstart named Marie Curie showed up with some glowing rocks and upended everything.</span></p><p><span>Radium gave off impossibly vast amounts of energy seemingly out of nowhere, in defiance of all known physical laws. Atomic theory, mechanics, astrophysics—all had to rethink their fundamental assumptions in a true scientific revolution. There had to be another source of energy, enormous in magnitude, locked within the atoms themselves.</span></p><p><span>Nuclear energy.</span></p><p><span>Nuclear science opened up intriguing new possibilities to explain the sun. What if it was radiating energy from radioactive isotopes? No more was the sun on the brink of death—radium could fuel the sun for billions of years. And the problem of the sun’s age suddenly dissipated like polonium in a test tube.</span></p><p><span>“The sun is full of radium” may sound like an outlandish theory, but it was more sensible than it seems: scientists knew the sun contained helium (that is, in fact, where helium gets its name), and at the time, the only known source of helium was the radioactive decay of radium.</span></p><p><span>Gravitation did not go down without a fight. Lord Kelvin adamantly defended it against a battalion of younger scientists, including George Darwin (son of That Other Darwin), who Cajori quotes saying, “I think we have no right to assume that the sun is incapable of liberating atomic energy to a degree at least comparable with that which it would do if made of radium.” Despite the evidence against it, the gravitation theory would shamble on for another couple of decades, says Eddington, “not alive, but an unburied corpse.”</span></p><p><span>As it happens, the radium theory wasn’t correct either. It took another couple of decades before Arthur Eddington, in the same 1920 article quoted above, spitballed the theory which ultimately turned out to be correct: “The atoms of all elements are built of hydrogen atoms bound together…wherever it did occur a great amount of energy must have been set free; in a star a vast quantity of energy is being set free which is hitherto unaccounted for. You may draw a conclusion if you like.” In other words, nuclear fusion.</span></p><p><span>Like the radium theory, fusion allowed for a sun that might be billions of years old. These theories offered only a reprieve, but did not alter the ultimate sentence. Regardless of its power source, the sun would eventually run out of fuel, cool off, and go dark. All life on earth would die.</span></p><p><span>These new theories took the “we’re-all-about-to-die” urgency out of the death of the sun, and the dying-earth genre began to lose popularity. Yet the image of the dying sun was still a poignant one. Several sci-fi authors were drawn to the topic in this era, armed with the new scientific knowledge.</span></p><p><span>Now-disgraced sci-fi patriarch John W. Campbell tackled the dying earth in his short story </span><a href="https://archive.org/details/sim_astounding-science-fiction_1935-10_16_2/page/n9/mode/1up"><span>“Night”</span></a><span> (1935, published under the pseudonym Don A. Stuart). An experimental device accidentally transports a pilot to the end of the universe. He is met with an earth long since frozen, its automated machinery broken down long after all humans had perished:</span></p><blockquote><p><span>There were frozen, huddled heaps that might once have been men. Little fellows with fear forever frozen on their faces huddled helplessly over something that must once have been a heating device. Dead perhaps, since the last storm old Earth had known, tens of billions of years ago…</span></p><p><span>Again I saw that agonizing struggle of the eternally faithful machines trying to repair themselves once more to serve their masters who were dead a million million years. I could see it again in the frozen, exhausted postures of the repair machines, stilled forever in their hopeless endeavors, the last poor dregs of energy spilled in fruitless conflict with time.</span></p></blockquote><p><span>Campbell was well-versed in the latest science. “From hydrogen,” he says, “the heaviest of elements can be built up, and energy released,” but the stars “had burned their hydrogen until it was a remnant so small the action could not go on.” And this future is not a few millions of years off, but “billions on billions of years,” when not only the sun, but all the stars have burned out.&nbsp;</span></p><p><span>And yet the imagery of the sun remains familiar:</span></p><blockquote><p><span>It was four times—six times—the size of the Sun I knew. And it wasn’t setting. It was forty-five degrees from the horizon. It was red. Blood-red. And there wasn’t the slightest bit of radiant heat reaching my face from it. That Sun was cold.</span></p></blockquote><p><span>(Note, however, that Wells’s vivid red sunset is not present. Campbell, born in 1910, did not experience Krakatoa.)</span></p><p><span>Astrophysics can show up in the smallest of traces. Did I mention Lovecraft? In </span><a href="https://www.hplovecraft.com/writings/texts/fiction/sot.aspx"><i><span>The Shadow out of Time</span></i></a><span> (1936), he briefly mentions the Yith’s future fate:</span></p><blockquote><p><span>Later, as the earth’s span closed, the transferred minds would again migrate through time and space—to another stopping-place in the bodies of the bulbous vegetable entities of Mercury. But there would be races after them, clinging pathetically to the cold planet and burrowing to its horror-filled core, before the utter end.</span></p></blockquote><p><span>The Yith moving </span><i><span>inward</span></i><span> in the solar system, not outward, indicates that Lovecraft, like his contemporaries, believed the sun would cool.</span></p><p><span>The modern stellar life cycle took several more years to work out. Red giants were the sticking point. Discovered at the turn of the century, they simply didn’t fit into any of the models. A first guess, during the era of the gravitation theory, suggested that they were young stars. Instead of hottest to coldest, the stellar life cycle moved from largest to smallest. A star began life as a red giant, and then gravitational contraction shrank it into a sunlike star, then a red dwarf. When that didn’t hold up, most astronomers concluded that red giants were their own thing.</span></p><p><span>The idea that red giants were in fact very old stars was first tenuously proposed in 1933, but only seriously considered in 1939. In the years that followed, a series of increasingly sophisticated models made it clear that red giants were a late stage of stellar evolution. Instead of gradually burning out, the sun would inflate into a flaming behemoth. The earth would not “go gently into that good night,” but would be devoured by this ball of fire.</span></p><p><span>The idea of being incinerated by the sun is not exactly a delightful one, but it’s significantly less angsty than the image of the lifeless, cold earth floating for eternity in the black void. Perhaps it’s simply that it’s a quicker end. Or perhaps it’s the part where the red giant collapses, spewing its gasses out across the galaxy to become the next generation of stars. Star stuff we are, and to star stuff we shall return.</span></p><p><span>The image of the earth being devoured by the sun is not without a certain drama of its own, and it makes an occasional appearance in sci-fi to this day. </span><a href="https://www.seizethepress.com/2023/09/04/the-dream-with-no-dreamer-stp8/"><span>“The Dream with no Dreamer”</span></a><span> by Evan Forman (2023) eloquently envisions this end:</span></p><blockquote><p><span>After the cities had been put down and the planet flayed of life, the pyramids and pharaoh’s tombs were melted down to slag beneath the light of an expanding star. Then the buried dead were cremated in liquifying soil, the mountains tucked away into its volcanic folds.</span></p></blockquote><p><span>Overall, though, this end just doesn’t have the same narrative potential, and certainly nowhere near the same urgency. Thus, the discovery of the modern stellar life cycle heralded the end of the melancholic depictions of the dying earth. Meanwhile, science fiction at large had evolved from Victorian pessimism to the techno-optimism of the pulp era. The dying-earth genre didn’t vanish on the spot, but it transformed into a stock setting for sword-and-sorcery stories set in the far future where modern civilization’s technology has long since been lost, beginning with Clark Ashton Smith’s </span><i><span>Zothique</span></i><span> stories, and the scientific underpinnings gradually dwindled away. You can see the modern descendants of these stories in the likes of </span><i><span>Horizon Zero Dawn</span></i><span>.</span></p><p><span>Yet the dying-earth imagery would linger in the minds of a generation of writers who had grown up with it, occasionally percolating to the surface outside of science fiction, in genres that had no reason to be bound by scientific accuracy. In </span><i><span>The Magician’s Nephew</span></i><span> (1955), C.S. Lewis references the image of the burned-out sun to depict the dying world of Charn:</span></p><blockquote><p><span>“Was it the Deplorable Word that made your sun like that?” asked Digory.</span></p><p><span>“Like what?” said Jadis.</span></p><p><span>“So big, so red, and so cold.”</span></p><p><span>“It has always been so,” said Jadis. “At least, for hundreds of thousands of years. Have you a different sort of sun in your world?”</span></p></blockquote><p><span>It wasn’t only sci-fi authors who found literary inspiration in the image of the dying sun. In fact, one of the genres most profoundly affected was poetry. Many prominent poets were deeply interested in the natural world and studied astronomy, and they too were influenced by the melancholia of the dying-earth era.</span></p><p><span>T.S. Eliot was an admirer of Arthur Eddington and kept up on his discoveries. Sometimes this knowledge of astronomy surfaces in his works with great clarity.</span><a href="https://allpoetry.com/the-hollow-men"><span> “The Hollow Men”</span></a><span> (1925) is one of Eliot’s darkest works. Written (by his own admission) during a severe bout of depression, the scarecrow-like titular hollow men whisper meaninglessly to each other in a “valley of dying stars” that bears striking resemblance to the dying-earth stories:</span></p><blockquote><p><span>This is the dead land</span></p><p><span>This is cactus land</span></p><p><span>Here the stone images</span></p><p><span>Are raised, here they receive</span></p><p><span>The supplication of a dead man’s hand</span></p><p><span>Under the twinkle of a fading star.</span></p></blockquote><p><span>Cosmic death saturates the poem. The wind is described as “More distant and more solemn/Than a fading star.” “Death’s twilight kingdom” makes several appearances—but is it the underworld or is it a description of earth in its final days, “This last meeting place” where the hollow men hopelessly gather, awaiting an inevitable death like the frozen men from “Night”?</span></p><p><span>The poem ends with the most famous lines of T.S. Eliot’s oeuvre:</span></p><blockquote><p><i><span>This is the way the world ends</span></i></p><p><i><span>This is the way the world ends</span></i></p><p><i><span>This is the way the world ends</span></i></p><p><i><span>Not with a bang but a whimper.</span></i></p></blockquote><p><span>The “bang” here is the Apocalypse that marks the end of the earth in traditional Christian theology (not, as one might guess, a supernova). In the depths of depression, Eliot rejects the church’s image of a fiery doomsday, finding more to relate to in the painfully slow, cold death offered by science.</span></p><p><span>Nor was he the only poet to observe the dichotomy between the cold death presented by science and the hot death presented by religion. But first, a story. There is an </span><a href="https://www.amerlit.com/poems/POEMS%20Frost,%20Robert%20Fire%20and%20Ice%20(1920%201923)%20analysis%20by%204%20critics.pdf"><span>oft-repeated anecdote</span></a><span> that, in 1920, Robert Frost asked astronomer Harlow Shapley how the world would end, and Shapley told him that it would either be incinerated by the sun, or somehow escape and slowly freeze—and was blindsided a few months later when a reference to this conversation appeared in a poem.</span></p><p><span>You should find this story immediately suspect. Neither Shapley nor anyone else in 1920 had any reason to think the sun would destroy the earth. And the provenance of the story doesn’t inspire confidence: Frost commentator Tom Hansen claimed in 2000 that Shapley had related the story in a talk in 1960. The meteor theory had more compelling evidence than this. So, unfortunately, we’ve got to mark this one as an urban legend.</span></p><p><span>But Frost </span><i><span>did</span></i><span> enjoy astronomy, and it makes an appearance in many of his poems. In </span><a href="https://www.poetryfoundation.org/poems/44273/the-star-splitter"><span>“The Star-Splitter”</span></a><span> (1923), a farmer buys a telescope “To satisfy a lifelong curiosity/About our place among the infinities.” And he kept up with the latest discoveries. </span><a href="https://www.englishliterature.info/2021/07/skeptic-by-robert-frost-analysis.html"><span>“Skeptic”</span></a><span> (1947), for instance, references Edwin Hubble’s discovery of redshift (while simultaneously expressing doubt about it:</span></p><blockquote><p><span>I don’t believe what makes you red in the face</span></p><p><span>Is after explosion going away so fast.</span></p></blockquote><p><span>So while Shapley may never have spoken to frost, we have every reason to believe that Frost had theories of the death of the sun in mind when he wrote his 1920 poem </span><a href="https://www.poetryfoundation.org/poems/44263/fire-and-ice"><span>“Fire and Ice”</span></a><span>. You already know the poem—some of you, no doubt, by heart—but I’m including it here anyways:</span></p><blockquote><p><span>Some say the world will end in fire,</span></p><p><span>Some say in ice.</span></p><p><span>From what I’ve tasted of desire</span></p><p><span>I hold with those who favor fire.</span></p><p><span>But if it had to perish twice,</span></p><p><span>I think I know enough of hate</span></p><p><span>To say that for destruction ice</span></p><p><span>Is also great</span></p><p><span>And would suffice.</span></p></blockquote><p><span>The poem’s metaphorical message is so resonant that it’s easy to overlook its literal meaning. Scientists at the time really did believe the world would end in ice, disagreeing with theologians, who claimed it would end in fire. For Frost, this disagreement about the physical world created an analogy for the different forms of human cruelty.</span></p><p><span>And so our journey takes us from the roots of science fiction to perhaps the most famous poem of the 20</span><span>th</span><span> century. It’s a cosmic microcosm of the creative arts’ relationship to all science: Curiosity and inspiration mingled with doubt and pessimism, the love of discovery colliding with the fear that we might wish we had never found out.</span></p><p><span>For while the dying-earth genre came to an end in the 1940s, physics was not done inspiring nihilistic visions of the future. I leave you with one final prescient quote from Arthur Eddington: “If, indeed, the sub-atomic energy in the stars is being freely used to maintain their great furnaces, it seems to bring a little nearer to fulfilment our dream of controlling this latent power for the well-being of the human race—or for its suicide.”&nbsp;</span><img decoding="async" src="https://e7tj565ac8j.exactdn.com/wp-content/uploads/2023/11/cropped_transparent_T.png." data-src="https://e7tj565ac8j.exactdn.com/wp-content/uploads/2023/11/cropped_transparent_T.png." alt=""></p><h5>Gwen C. Katz is the lead developer and wolfmaster of Nightwell Games, as well as an author, artist, and former mad scientist. She lives in Pasadena, California with her husband and a revolving door of transient animals. Her upcoming game, Surradia, is a deduction game that unravels the disappearance of three magical artists in interbellum France. You can visit her game studio at&nbsp;<a href="http://nightwellgames.com/" target="_blank" rel="noopener" data-saferedirecturl="https://www.google.com/url?q=http://nightwellgames.com&amp;source=gmail&amp;ust=1705506002308000&amp;usg=AOvVaw2VOx-ZSgXVrPUcOmbHxo7y">nightwellgames.com</a>.</h5><h6>Photo by Chris Barbalis.</h6></div></div>]]></description>
        </item>
    </channel>
</rss>