<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 29 Dec 2024 14:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[We've not been trained for this: life after the Newag DRM disclosure [video] (206 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure</link>
            <guid>42538914</guid>
            <pubDate>Sun, 29 Dec 2024 09:48:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure">https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure</a>, See on <a href="https://news.ycombinator.com/item?id=42538914">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-we-ve-not-been-trained-for-this-life-after-the-newag-drm-disclosure: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[38C3: Illegal Instructions (243 pts)]]></title>
            <link>https://media.ccc.de/c/38c3</link>
            <guid>42537631</guid>
            <pubDate>Sun, 29 Dec 2024 04:54:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/c/38c3">https://media.ccc.de/c/38c3</a>, See on <a href="https://news.ycombinator.com/item?id=42537631">Hacker News</a></p>
Couldn't get https://media.ccc.de/c/38c3: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[WebGL Fluid Simulation (178 pts)]]></title>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid>42537567</guid>
            <pubDate>Sun, 29 Dec 2024 04:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paveldogreat.github.io/WebGL-Fluid-Simulation/">https://paveldogreat.github.io/WebGL-Fluid-Simulation/</a>, See on <a href="https://news.ycombinator.com/item?id=42537567">Hacker News</a></p>
Couldn't get https://paveldogreat.github.io/WebGL-Fluid-Simulation/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Jeju Air accident in South Korea kills at least 47 (203 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</link>
            <guid>42536647</guid>
            <pubDate>Sun, 29 Dec 2024 01:40:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap">https://www.bloomberg.com/news/articles/2024-12-29/plane-crashes-at-s-korea-airport-killing-at-least-23-yonhap</a>, See on <a href="https://news.ycombinator.com/item?id=42536647">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[38C3: Blinkencity, radio controlling street lamps and power plants [video] (124 pts)]]></title>
            <link>https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants</link>
            <guid>42535622</guid>
            <pubDate>Sat, 28 Dec 2024 23:02:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants">https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants</a>, See on <a href="https://news.ycombinator.com/item?id=42535622">Hacker News</a></p>
Couldn't get https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fish 4.0: The Fish of Theseus (662 pts)]]></title>
            <link>https://fishshell.com/blog/rustport/</link>
            <guid>42535217</guid>
            <pubDate>Sat, 28 Dec 2024 22:07:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fishshell.com/blog/rustport/">https://fishshell.com/blog/rustport/</a>, See on <a href="https://news.ycombinator.com/item?id=42535217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>About two years ago, our head maintainer @ridiculousfish opened what quickly became our most-read pull request:</p>

<ul>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/9512">#9512 - Rewrite it in Rust</a></li>
</ul>

<p>Truth be told, we did not quite expect that to be as popular as it was.
It was written as a bit of an in-joke for the fish developers first, and not really as a press release to be shared far and wide.
We didn’t post it anywhere, but other people did, and we got a lot of reactions.</p>

<p>Observant readers will note that the PR was a proposal to rewrite the entirety of fish in Rust, from C++.</p>

<p>Fish is no stranger to language changes - it was ported from pure C to C++ earlier in its life,
but this was a much bigger project, porting to a much more different language that didn’t even exist when fish was started in 2007.</p>

<p>Now that we’ve released the beta of fish 4.0, containing 0% C++ and almost 100% pure Rust, let’s look back to see what we’ve learned, what went well, what could have gone better and what we can do now.</p>

<p>We’re writing this so others can learn from our experience, but it is <em>our</em> experience and not an exhaustive study.
We hope that you’ll be able to follow along even if you have never written any rust, but
experience with a roughly C++-shaped language should help.</p>

<h2 id="why-are-we-doing-this-again">Why are we doing this again?</h2>

<p>We’ve experienced some pain with C++. In short:</p>

<ul>
  <li>tools and compiler/platform differences</li>
  <li>ergonomics and (thread) safety</li>
  <li>community</li>
</ul>

<p>Frankly, the tooling around the language isn’t good, and we had to take on some additional pain in order to support our users.
We want to provide up-to-date fish packages for systems that aren’t up-to-date, like LTS Linux and older macOS.
But there is no ‘rustup’ for C++, no standard way to install recent C++ compilers on these operating systems.
This means adopting recent C++ standards would complicate the lives of packagers and would-be contributors<sup id="fnref:Contributions"><a href="#fn:Contributions" rel="footnote" role="doc-noteref">1</a></sup>.
For example, we started using C++11 in 2016, and yet we still needed to upgrade the compilers on our build machines until 2020.</p>

<p>Fish also uses threads for its award-winning (<em>note to editor</em>: find an actual award) autosuggestions and syntax highlighting,
and one long-term project is to add concurrency to the language.</p>

<p>Here’s a dirty secret: while external commands run in parallel, fish’s execution of internal commands (builtins and functions) is currently serial and can’t be backgrounded. Lifting this limitation will enable features like asynchronous prompts or non-blocking completions, as well as performance gains.</p>

<p>POSIX shells use subshells to get around this, but subshells are a leaky abstraction that can bite you in the behind when you least expect it.
For instance, you can’t set variables from inside a pipe (except on some shells, but only in the last part of the pipe, maybe, if you have enabled the correct option).
We would like to avoid that, and so the heavy hand of forking off a process isn’t appealing.</p>

<p>We prototyped true multithreaded execution in C++, but it just didn’t work out. For example, it was too easy to accidentally share objects across threads, with only post-hoc tools like Thread Sanitizer to prevent it.</p>

<p>The ergonomics of C++ are also simply not good - header files are annoying, templates are complicated, you can easily cause a compile error that throws <em>pages</em> of overloads in the standard library at you. Many functions are unsafe to use. C++ string handling is very verbose with
easily confusable overloads of many methods, making it attractive to drop down to C-style char pointers, which are quite unsafe.</p>

<p>And the standard prioritizes performance over ergonomics. Consider for instance string_view, which provides a non-owning slice of a string. This is an extremely modern, well-liked feature that C++ programmers often claim is a great reason to switch to C++17. And it is extremely easy to run into use-after-free bugs with it, because the ergonomics weren’t a priority.</p>

<p>One good case study of the deficiencies of C++-in-practice is a C library: curses. This is a venerable library to access terminal features, and we use it to access the terminfo database, which describes differences in terminal features and behavior.</p>

<p>This not only caused us grief by being unsafe to use in weird ways - the “cur_term” pointer (or sometimes macro!) can be NULL, and it is dereferenced in surprising places, but also caused a surprisingly high number of issues when building from source. This was either because there are multiple implementations of it with differences as useless as “this function takes a char on system X but an int on system Y”, but also because users kept coming to us with new and exciting(ly terrible) ways to package and install it. The dependency system is the system package manager.</p>

<p>Finally, subjectively, C++ isn’t drawing in the crowds. We have never had a lot of C++ contributors. Over the 11 years fish used C++, only 17 people have at least 10 commits to the C++ code. We also don’t know a lot of people who would love to work on a C++ codebase in their free time.</p>

<p>Some parting thoughts we can give the C++ community: We would like to see improvements to ergonomics and safety of the language and the tools prioritized over performance, and we would like to see efforts to make C++ compilers easier to upgrade on real systems.</p>

<h2 id="why-rust">Why Rust?</h2>

<p>We need to get one thing out of the way: Rust is cool. It’s fun.</p>

<p>It’s tempting to try to sweep this under the rug because it feels gauche to say, but it’s actually important for a number of reasons.</p>

<p>For one, fish is a hobby project, and that means we want it to be fun for us. Nobody is being paid to work on fish, so we <em>need</em> it to be fun.
Being fun and interesting also attracts contributors.</p>

<p>Rust also has great tooling. The tools have really paid a lot of attention to use, and the compiler errors are terrific. Not even “compared to C++”, they just actually rule. And as we have tried to pay attention to our own error messages (fish has a bespoke error for if it thinks a file you told it to run has Windows line endings),
we like it.</p>

<p>And it is <em>easy</em> to get that tooling installed - <code>rustup</code> is magic, and allows people to get started quickly, with minimal fuss or root permissions.
When the answer to “how to upgrade C++ compiler” is “find a repository (with root permissions), compile it yourself, install some <em>other</em> repository or a docker image”,
it is amazing how the Rust answer can just be “use rustup”.</p>

<p>Rust has great ergonomics - the difference between C++’s pointers (which can always be NULL) and Rust’s Options are apparent very quickly even to those of us who had never used it before. We did have a backport of C++’s optional, and liked using it, but it was never as integrated as Rust’s Options were.</p>

<p>Having an explicit <code>use</code> system where you know exactly which function comes from which module is a great improvement over <code>#include</code>.</p>

<p>Rust makes it nice to add dependencies. We don’t want to go overboard with it, but we do want to change our history format from our homegrown “I can’t believe it’s not YAML” to something specified that other tools can actually read, and Rust makes it easy to add support for YAML/JSON/KDL.</p>

<p>But the killer feature of Rust, from fish-shell’s perspective, is Send and Sync, statically enforcing rules around threading. “Fearless concurrency” is too strong - you can still blow your leg off with fork or signal handlers - but Send and Sync will be the key to unlocking fully multithreaded execution, with confidence in its correctness.</p>

<p>We did not do a comprehensive survey of other languages. We were confident Rust was up to the task and either already knew it or wanted to learn it, so we picked it.</p>

<h2 id="platform-support">Platform Support</h2>

<p>A lot of hay has also been made online about Rust’s platform support (e.g. <a href="https://lwn.net/Articles/998115/">in the git project</a>). We don’t see a big problem here - all of our big platforms (macOS, Linux, the BSDs) are supported, as are Opensolaris/Illumos and Haiku. We have never heard of anyone trying to run fish on NonStop.</p>

<p>Architecture support is even less of a problem - going by <a href="https://popcon.debian.org/">Debian’s popcon</a>, 99.9995% (the actual result, not an exaggeration) of machines run an architecture that has Rust packages in Debian. Given that fish is <a href="https://qa.debian.org/popcon.php?package=fish">installed on 1.92% of Debian systems</a>, we would project two (2) or three (3) machines of the quarter million responses to have fish on an unsupported architecture <sup id="fnref:stats"><a href="#fn:stats" rel="footnote" role="doc-noteref">2</a></sup>.</p>

<p>Unlike what some online have assumed, a native Windows port was not a reason for switching to Rust as it was never in the cards. Fish is, at heart, a UNIX shell that relies not only on UNIX APIs but also their semantics, and exposes them in the scripting language. What would <code>test -x</code> say on Windows, which has no executable bit? These are issues that <em>could</em> be solved with a lot of work, but we’re unix nerds making a unix shell, not one for Windows.</p>

<p>The one platform we care about a bit that it does not currently seem to have enough support for is Cygwin, which is sad, but we have to make a cut somewhere.</p>

<h2 id="the-story-of-the-port">The Story Of The Port</h2>

<p>We had decided we were gonna do a “Fish <a href="https://en.wikipedia.org/wiki/Ship_of_Theseus">Of Theseus</a>” port - we would move over, component by component, until no C++ was left.
And at every stage of that process, it would remain a working fish.</p>

<p>This was a necessity - if we didn’t, we would not have a working program for months, which is not only demoralizing but would also have precluded us from
using most of our test suite - which is end-to-end tests that run a script or fake a terminal interaction. We would also not have been able to do another C++ release,
putting some cool improvements into the hands of our users.</p>

<p>Had we chosen to disappear into a hole we might not have finished at all, and we would have to re-do a bunch of work once it became testable.
We also mostly kept the structure of the C++ code intact - if a function is in the “env” subsystem, it would stay there. Resisting the temptation to
clean up allowed us to compare the before and after to find places where we had mistranslated something.</p>

<p>So we used <a href="https://google.github.io/autocxx/">autocxx</a> to generate bindings between C++ and Rust code, allowing us to port one component at a time.</p>

<p>We started<sup id="fnref:technically"><a href="#fn:technically" rel="footnote" role="doc-noteref">3</a></sup> by porting the builtins. These are essentially little self-contained programs, with their own arguments, streams, exit code, etc.
That means it’s easy to port them separately from the rest of the shell once you have a way to call a Rust builtin from C++, which we had as part of the initial pull request.</p>

<p>Where they connected to the main shell, we used one of three approaches:</p>

<ol>
  <li>Add some FFI glue to the C++ to make it callable from Rust, port the caller and leave the callee for later</li>
  <li>Move the callee to Rust and, if necessary, make it callable from C++</li>
  <li>Write a Rust version of the callee and call it from the ported caller, but leave the C++ version around</li>
</ol>

<p>For instance, almost every builtin needs to parse its options. We have our own implementation of getopt, that we reimplemented in Rust in the initial PR,
but the C++ version stuck around until it had no more callers remaining. Otherwise we would have had to write a C++-to-Rust bridge and adjust the C++ callers to use it.</p>

<p>Or the <code>builtin</code> builtin (the builtin called <code>builtin</code>) needs access to the names of all builtins to print them for <code>builtin --get-names</code>. In that case we bridged some access to what amounts to a constant vector of strings in the C++, and eventually moved it over once the users were in Rust.</p>

<p>That’s how it went for a while, but we finally hit the more entangled systems, where porting larger chunks felt more productive,
since that reduced the amount of tricky FFI code to be written only to be thrown away. These were ported in solo efforts.
This includes the input/output “reader”, which is, unsurprisingly, one of fish’s biggest parts, ending up at about 13000 lines of Rust.</p>

<p>During the port, we hit a bunch of snags with (auto)cxx. Sometimes it would just not understand a particular C++ construct, and we spent a lot of time trying to figure out ways to please it. As an example, we introduced a struct on the C++ side that wrapped C++’s <code>vector</code>, because for some reason autocxx liked to complain about <code>vector&lt;wstring&gt;</code>. We had to fork it to add support for wstring/wchar, which is understandable because using wchar is a horrible decision - we only do it because it’s a historical mistake.</p>

<p>Similarly, we had to wrap some C++ variables in <code>unique_ptr</code> and similar to make the ownership rules understandable to (auto)cxx, or copy values that didn’t strictly need to be copied. This caused the performance during the port to go down quite a bit, but we regained all of it in most spots, and even beat the C++ version in some.</p>

<p>We also patched autocxx to remove the requirement to use <code>unsafe</code> to invoke any C++ API, because that would have obscured uses of <code>unsafe</code> that wouldn’t disappear just by porting the callee. We were building something temporary, so sometimes it is okay to do something a little underhanded.
If you used this for a permanent bridge between Rust and C++ in a few parts of your code, the <code>unsafe</code> markers might be useful, but in our case they were noise.</p>

<p>Because autocxx generated a lot of code, some tools also were less helpful than they’d usually be. rust-analyzer for instance was extremely slow.</p>

<p>So, even though our codebase was fairly amenable to being moved to Rust because we didn’t use exceptions or a lot of templates, autocxx isn’t the easiest to work with.
It is absolutely magical that it works at all, and it enabled us to do this port, but it has a hard task to perform and isn’t perfect at it.</p>

<h3 id="the-timeline">The Timeline</h3>

<ul>
  <li>
    <p>The initial PR was opened on 28th January 2023, merged on 19th February 2023</p>
  </li>
  <li>
    <p>fish 3.7.0, another release in the C++ branch to flush out some accumulated improvements, was released in January 2024</p>
  </li>
  <li>
    <p>The last C++ code was removed in January 2024 (and some additional test code was ported from C++ to C 12th of June 2024)</p>
  </li>
  <li>
    <p>The first beta was released 17th of December 2024</p>
  </li>
</ul>

<p>The initial PR had a timeline of “handwaving, half a year”. It was clear to all of us that it might very well be entirely off, and we’re not
disappointed that it was. Frankly, 14 months was still a pretty good pace, especially considering that we made a C++ release in-between, so it did not throw off our usual release cadence.</p>

<p>Most of the work was done by 7 people (going by those with at least 10 commits to “.rs” files), but we got a lot of help from interested community members.</p>

<p>The delay after that was down to a few reasons:</p>

<ol>
  <li>The “second 90%” - testing that everything worked. We flushed out a lot of bugs in this time, and if we made a release at that time it would have been a bad one.</li>
  <li>Having something to release that’s visible to users - there’s no point in making a release that does the same thing in new code, you need it to do different things.
So we held off until we had something.</li>
  <li>Simple availability - sometimes, some of us took time off.</li>
</ol>

<p>So if you are trying to draw any conclusions from this, consider the context: A group of people working on a thing in their free time,
diverting some effort to work on something else, <em>and</em> deciding that after the work is finished it actually isn’t.</p>

<h2 id="the-gripes">The Gripes</h2>

<p>It won’t surprise anyone who has spent any time on this world of ours that Rust is not, in fact, perfect. We have some gripes with it.</p>

<p>Chief among them is how Rust handles portability. While it offers many abstractions over systems, allowing you to target a variety of systems with the same code,
when it comes to <em>adapting</em> your code to systems at a lower-level, it’s all based on enumerating systems by hand, using checks like <code>#[cfg(any(target_os = "freebsd", target_os = "netbsd", target_os = "openbsd"))]</code>.</p>

<p>This is an imperfect solution, allowing you to miss systems and ignoring version differences entirely. From what we can tell, if FreeBSD 12 gains a function that we want to use, libc would add it, but calling it would then fail on FreeBSD 11 without a good way to check, at the moment.</p>

<p>But listing targets in our code is also fundamentally duplicating work that the libc crate (in our case) has already done. If you want to call libc::X, which is only defined on systems A, B and C, you need to put in that check for A, B and C yourself and if libc adds system D you need to add it as well. Instead of doing that, we are using our own <a href="https://github.com/mqudsi/rsconf">rsconf</a> crate to do compile-time feature detection in build.rs.</p>

<p>Most of this would be solved if Rust had some form of saying “compile this if that function exists” - <code>#[cfg(has_fn = "fstatat")]</code>. With that, the libc crate could do whatever checks it wants and fish would just follow what it did, and we could remove a lot of the use for rsconf. It would not really help support older distributions that lack some features, tho. That could be solved by something like the <a href="https://github.com/rust-lang/rfcs/pull/3036">min_target_API_version</a> cfg.</p>

<p>While we’re on portability, the tools also sometimes fail to consider other targets - clippy may warn about a conversion being useless when it isn’t on another system, it is often better to use <code>if cfg!(...)</code> instead of <code>#[cfg(...)]</code> because code behind the latter is eliminated very early, so it may be entirely wrong and only shows up when building on the affected system.</p>

<p>We’ve also had issues with localization - a lot of the usual Rust relies on format strings that are checked at compile-time, but unfortunately they aren’t translatable.
We ported printf from musl, which we required for our own <code>printf</code> builtin anyway, which allows us to reuse our preexisting format strings at runtime.</p>

<h3 id="the-mistakes">The Mistakes</h3>

<p>We’ve hit some false starts, dead ends and other kinds of mistakes. For instance we originally used a fancy macro to allow us to write our strings as <code>"foo"L</code>, but that did not end up carrying its weight and we removed it in favor of a regular <code>L!("foo")</code> macro call.</p>

<p>We were confused by a deprecation warning in the libc crate, which explains that “time_t” will be switched to 64-bit on musl in the future.
We initially tried to work around it, adding a lot of wrappers to try to stay agnostic on that size, but only later figured out that it does not affect us,
as we do not pass a time_t we get from one C library to another. (https://github.com/fish-shell/fish-shell/issues/10634)</p>

<p>Some bugs appeared because we missed subtleties of the original code.
Often this turned into a crash because we used asserts or assert’s modern cousin “.unwrap()”. This was often the easiest way to translate the C++,
and sometimes it simply turned out to be not accurate, and had to be replaced with different error handling.</p>

<p>But overall most of these were, once found, pretty shallow - “it panics here, why would it do that? oh, this can be an Err? Okay, what leads to that? Ah, okay, let’s handle that in this way”.</p>

<p>We’ve also caused some friction by turning on link-time-optimization combined with having release builds as the default in CMake (currently needed to run the full test suite),
which makes it easy to accidentally have very long build time.</p>

<h2 id="the-good">The Good</h2>

<p>A lot of the benefits of porting to Rust will appear over time, but some are already here.</p>

<p>Remember our issues with (n)curses? We will no longer have any, because we no longer use curses. Instead we switched to <a href="https://github.com/meh/rust-terminfo">a Rust crate</a> that gives us just what we need, which is access to terminfo and expanding its sequences. This removes some awkward global state, and means those building from source no longer need to ensure that curses is installed “correctly” on their system - cargo just downloads a crate and builds it.</p>

<p>We do still read terminfo, which means users need to install that, but that can be done at runtime, is preinstalled on all mainstream systems <em>and</em> if it can’t be found we just use an included copy of the xterm-256color definitions<sup id="fnref:terminfo"><a href="#fn:terminfo" rel="footnote" role="doc-noteref">4</a></sup>.</p>

<p>We have also managed to create “self-installable” fish packages that include all the functions, completions and other asset files in the fish binary to be written out at runtime.
That allowed us to create statically linked versions of fish (for linux this uses musl, because glibc has unavoidable crashes!), so for the first time we have <em>one file</em> you can download and run on <em>any linux</em> (the only requirement being that the architecture matches!).</p>

<p>This is a pretty big boon for people who want to use fish but sometimes ssh to servers, where they might not have root access to install a package. So they can just <code>scp</code> a single file and it’s available.</p>

<p>This might be possible with C23’s <code>#embed</code>, but Rust allowed us to do it now and, overall, pretty easily.</p>

<h2 id="the-sad">The Sad</h2>

<p>The one goal of the port we did not succeed in was removing CMake.</p>

<p>That’s because, while <code>cargo</code> is great at <em>building</em> things, it is very simplistic at <em>installing</em> them. Cargo wants everything in a few neat binaries,
and that isn’t our use case. Fish has about 1200 .fish scripts (961 completions, 217 associated functions), as well as about 130 pages of documentation (as html and man pages),
and the web-config tool and the man page generator (both written in python).</p>

<p>It also has a test suite that is light on unit tests but heavy on end-to-end script and interactive tests. The scripted tests run through our own littlecheck tool,
which runs a script and compares its output to embedded comments. The interactive tests are driven by pexpect, which fakes terminal interaction and checks that the right thing happens when you press buttons.</p>

<p>We kept cmake, in a simplified form, for these tasks, but let it hand over the responsibility of <em>building</em> to cargo.</p>

<p>It would be possible to switch all that to a simpler task runner like Just or even plain old makefiles, but since we already have this system we’re keeping it for now.
The upside is that the build process hasn’t really changed for packagers.</p>

<p>We’re also losing Cygwin as a supported platform for the time being, because there is no Rust target for Cygwin and so no way to build binaries targeting it.
We hope that this situation changes in future, but we had also hoped it would improve during the almost two years of the port.
For now, the only way to run fish on Windows is to use WSL.</p>

<h2 id="the-present--the-future">The Present &amp; The Future</h2>

<p>We’ve succeeded. This was a gigantic project and <em>we made it</em>. The sheer scale of this is perhaps best expressed in numbers:</p>

<ul>
  <li>1155 files changed, 110247 insertions(+), 88941 deletions(-) (excluding translations)</li>
  <li>2604 commits by over 200 authors</li>
  <li>498 issues</li>
  <li>Almost 2 years of work</li>
  <li>57K Lines of C++ to 75K Lines of Rust <sup id="fnref:formatting"><a href="#fn:formatting" rel="footnote" role="doc-noteref">5</a></sup> (plus 400 lines of C <sup id="fnref:ccode"><a href="#fn:ccode" rel="footnote" role="doc-noteref">6</a></sup>)</li>
  <li><a href="https://github.com/fish-shell/fish-shell/pull/10564">C++–</a></li>
</ul>

<p>The beta works very well. Performance is usually slightly better in terms of time taken, memory use has a slightly higher floor but a lower ceiling - it will use 8M instead of 7M at rest, but e.g. globbing a big directory won’t make it go up as much. These things can all be improved, of course, but for a first result it is encouraging.</p>

<p>Fish is still a bit of an odd duck…fish as a Rust program. It has some bits that smell like C spirit, directly using the C API and e.g. passing around file descriptors instead of File objects. It still uses UTF-32 strings - which is why we are using a fork of the pcre2 crate because we couldn’t convince the pcre2-crate maintainer to add UTF-32 support. We hope to find a nicer solution here, but it wasn’t necessary for the first release.</p>

<p>The port wasn’t without challenges, and it did not all go <em>entirely</em> as planned. But overall, it went pretty dang well. We’re now left with a codebase that we like a lot more, that has already gained some features that would have been much more annoying to add with C++,
with more on the way, and we did it while creating a separate 3.7 release that also included some cool stuff.</p>

<p>And we had fun doing it.</p>

<hr>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel's $475M error: the silicon behind the Pentium division bug (262 pts)]]></title>
            <link>https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</link>
            <guid>42535071</guid>
            <pubDate>Sat, 28 Dec 2024 21:48:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html">https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html</a>, See on <a href="https://news.ycombinator.com/item?id=42535071">Hacker News</a></p>
Couldn't get https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Family of OpenAI whistleblower Suchir Balaji demand FBI investigate death (255 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</link>
            <guid>42535057</guid>
            <pubDate>Sat, 28 Dec 2024 21:46:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji">https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji</a>, See on <a href="https://news.ycombinator.com/item?id=42535057">Hacker News</a></p>
Couldn't get https://www.theguardian.com/us-news/2024/dec/28/openai-whistleblower-suchir-balaji: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Anki AI Utils (150 pts)]]></title>
            <link>https://github.com/thiswillbeyourgithub/AnkiAIUtils</link>
            <guid>42534931</guid>
            <pubDate>Sat, 28 Dec 2024 21:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/thiswillbeyourgithub/AnkiAIUtils">https://github.com/thiswillbeyourgithub/AnkiAIUtils</a>, See on <a href="https://news.ycombinator.com/item?id=42534931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Anki AI Utils</h2><a id="user-content-anki-ai-utils" aria-label="Permalink: Anki AI Utils" href="#anki-ai-utils"></a></p>
<p dir="auto">A powerful suite of AI-powered tools to enhance your <a href="https://en.wikipedia.org/wiki/Anki_(software)" rel="nofollow">Anki</a> flashcard learning experience by automatically improving cards you struggle with, tested through medical school. For example think of it like this: every time you fail a card you get a ChatGPT explanation, a Dall-E illustration, mnemonics, etc but supporting your own mnemonics.</p>
<p dir="auto"><strong>Check out my other Anki and AI related projects on my <a href="https://github.com/thiswillbeyourgithub">GitHub profile</a>!</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Simple example</h3><a id="user-content-simple-example" aria-label="Permalink: Simple example" href="#simple-example"></a></p>
<p dir="auto"><strong>Those scripts make it so that every failed note will automatically have new fields containing explanations, mnemonics, and illustrations.</strong> This is done in a way that respects <strong>your own mnemonics</strong>, can even use the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">major system</a>, and has <strong>many</strong> more features.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developer's note / call for help</h2><a id="user-content-developers-note--call-for-help" aria-label="Permalink: Developer's note / call for help" href="#developers-note--call-for-help"></a></p>
<p dir="auto">This collection of scripts is the culmination of my efforts to contributes the AI features I wish existed when I started medical school. All scripts should be working but I released them hastily after documenting them heavily with the help of <a href="https://aider.chat/" rel="nofollow">aider</a>. It is possible that some aspects of the documentation is slightly off or imprecise. It is also possible that some of the scripts where slighly broken during the release process. In any case, <strong>by releasing this project made with love and care my hope is to motivate others to package it into addons.</strong> I have too little time to learn how to package those scripts into addons and make the appropriate GUI so any help is absolutely welcome.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Adaptive Learning</strong>: Uses <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> to dynamically match your cards with the most relevant examples from your training datasets. The more examples you add, the better it gets!</p>
</li>
<li>
<p dir="auto"><strong>Personalized Memory Hooks</strong>: Reuses consistent mnemonics from your custom collection, building a personalized memory system. Includes a dedicated tool to help create and manage your mnemonic library.</p>
</li>
<li>
<p dir="auto"><strong>Automation Ready</strong>: Run programmatically - for example, use cron to automatically enhance cards you struggled with yesterday, making them easier to remember through images, mnemonics, and explanations.</p>
</li>
<li>
<p dir="auto"><strong>Universal Compatibility</strong>: Modifies Anki notes directly in-place, working seamlessly across all Anki clients (Windows, Mac, Linux, Android, iOS). Extensive logging ensures you can track changes and rollback if needed.</p>
</li>
<li>
<p dir="auto"><strong>Provider Agnostic</strong>: Supports all LLM providers and models through LiteLLM, letting you choose the best option for your needs.</p>
</li>
<li>
<p dir="auto"><strong>Infinitely Extensible</strong>: Add as many examples as you want to your training datasets - the semantic filtering automatically picks the most relevant ones for each card.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator" aria-label="Permalink: Illustrator" href="#illustrator"></a></p>
<p dir="auto">Creates custom mnemonic images for your cards using AI image generation. It:</p>
<ul dir="auto">
<li>Analyzes card content to identify key concepts</li>
<li>Generates creative visual memory hooks</li>
<li>Preserves a history of generated images</li>
<li>Supports both DALL-E2, DALL-E3 and Stable Diffusion</li>
<li>Automatically formats images for optimal display (centered, proper sizing)</li>
<li>Handles multiple images per card with consistent layout</li>
</ul>
<p dir="auto">Perfect for visual learners or complex topics that benefit from imagery.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, I had this French flashcard:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever.png" alt=""></a></p>
<details>
<summary>Click here if you can't read French</summary>
<p dir="auto">Here's the note content translated to English:</p>
<div data-snippet-clipboard-copy-content="Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total"><pre><code>Diagnostic criteria for simple febrile seizures:
- Age greater than 1 year
- Seizure occurring with fever above 38°C (100.4°F)
- Symmetrical motor manifestations lasting less than 15 minutes and without deficit
- Single seizure per febrile episode
- Less than 3 episodes in total
</code></pre></div>
</details>
<p dir="auto"><code>illustrator.py</code> generated to me this image:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/thiswillbeyourgithub/AnkiAIUtils/blob/public/screenshots/illustrator_fever_generated.png"><img src="https://github.com/thiswillbeyourgithub/AnkiAIUtils/raw/public/screenshots/illustrator_fever_generated.png" alt=""></a></p>
<p dir="auto">As well as this text content to understand its thought process: (Note that this part is always in English no matter the original language)</p>
<div data-snippet-clipboard-copy-content="Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]"><pre><code>Topic: 'Diagnostic criteria for a simple febrile seizure'
Anchors: 'Febrile / Fever: a fireplace (sounds like febrile)'
Phonetic: '1 as T link in thai, tea, tie; 3 as M link in mow, my, meh; 8 as F link in fire, faux, few; 5 as L link in low, lee, lie'
Remarks:
* The criteria are specific and should be presented in a way that is easy to remember.
Step by step decomposition:
* Age over 1 year: a toddler holding a teacup (T for 1)
* Seizure with fever over 38°C: a thermometer with flames around it (F for 8)
* Symmetric motor manifestations lasting less than 15 minutes without deficit: a clock showing 15 minutes with two identical figurines moving symmetrically on either side
* 1 unique seizure per febrile episode: a single lightning bolt striking a fireplace (fireplace for fever)
* Less than 3 episodes in total: three thermometers, but only two showing a high temperature
Imagining:
* A toddler holding a teacup, standing next to a fireplace with a single lightning bolt striking it.
* Above the fireplace, a clock showing 15 minutes with two identical figurines moving symmetrically.
* Next to the toddler, a thermometer surrounded by flames, and three thermometers, two of which show high temperatures.
Subject: 'a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures'
Description words: 'educational, colorful, engaging, vivid, detailed'
Style: 'illustration'
Realism: 'semi-realistic'
a toddler holding a teacup next to a fireplace struck by a single lightning bolt, a clock showing 15 minutes with symmetric figurines, a flaming thermometer, and three thermometers with two showing high temperatures, educational, colorful, engaging, vivid, detailed, illustration, semi-realistic

[DATE:09/04/2024 VERSION:2.5 LLMMODEL:openai/gpt-4-0125-preview IMAGEMODEL:openai/dall-e-3]
</code></pre></div>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator" aria-label="Permalink: Reformulator" href="#reformulator"></a></p>
<p dir="auto">An intelligent tool that rephrases your flashcards while preserving their core meaning and structure. It helps when:</p>
<ul dir="auto">
<li>Cards are poorly worded or unclear</li>
<li>You want to vary the phrasing to strengthen recall</li>
<li>Cards need to be more concise or natural sounding</li>
<li>Your preferred card format has evolved over time</li>
</ul>
<p dir="auto">The tool uses LLMs to reformulate content while carefully preserving cloze deletions and media. This is especially valuable for long-term Anki users - for example, during medical school, your idea of what makes a "perfect" flashcard often evolves after a few semesters. The Reformulator lets you easily update all your older cards to match your current preferred format and style.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">For example, given this poorly worded flashcard:</p>
<div data-snippet-clipboard-copy-content="bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}"><pre><code>bilateral and symmetric alveolar syndrome, perihilar, often with effusion, what to consider?
{{c1::APE}}
</code></pre></div>
<p dir="auto">The reformulator would improve it to:</p>
<div data-snippet-clipboard-copy-content="What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}"><pre><code>What should be considered in presence of bilateral and symmetric alveolar syndrome, perihilar, often with effusion?
{{c1::In case of bilateral and symmetric alveolar syndrome, perihilar, often with effusion, one should consider APE.}}
</code></pre></div>
<p dir="auto">Note how the reformulation:</p>
<ul dir="auto">
<li>Makes the question grammatically complete and clear</li>
<li>Structures it as a proper question</li>
<li>Makes the answer self-contained by repeating key context</li>
<li>Preserves the exact medical terminology</li>
<li>Maintains the cloze deletion format</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator"></a></p>
<p dir="auto">Generates memorable mnemonics tailored to your cards by:</p>
<ul dir="auto">
<li>Creating multiple mnemonic options per card</li>
<li>Using proven memory techniques like the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a></li>
<li>Incorporating your existing memory anchors</li>
<li>Preserving context and accuracy</li>
</ul>
<p dir="auto">Helps create lasting memory connections, especially for numbers and sequences.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiMnemonics field:</p>
<hr>
<ol dir="auto">
<li>'Heureux Hephaistos fébrile tend sa banane unique près du feu'<br>* <b>Heureux </b> Âge supérieur à 1 an  Heureux évoque la maturité et donc un âge déjà avancé, supérieur à 1 an <br>* <b>Hephaistos fébrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  Hephaistos évoque la fièvre du fait de son rôle de forgeron et fébrile réitère ce concept <br>* <b>tend sa banane unique </b> 1 unique crise par épisode fébrile donné  banane unique évoque une seule occurrence, ici la crise unique par épisode fébrile <br>* <b>près du feu </b> Moins de 3 épisodes au total  feu évoque la fièvre et sa proximité suggère une limite, ici moins de 3 épisodes en tout <p>2.  'Un enfant trébuche dans le feu, danse symétriquement, a un seul coup et moins de trois feux'<br>* <b>Un enfant trébuche </b> Âge supérieur à 1 an  l'idée d'un enfant qui commence juste à marcher évoque l'âge juste après un an <br>* <b>dans le feu, </b> Survenue de la crise avec une fièvre supérieure à 38°C  le feu évoque la chaleur, donc la fièvre <br>* <b>danse symétriquement, </b> Manifestations motrices symétriques  danser évoque le mouvement, et symétriquement évoque les deux côtés du corps bougeant de la même manière <br>* <b>a un seul coup </b> 1 unique crise par épisode fébrile donné  un seul coup évoque l'unicité de la crise pendant l'épisode fébrile <br>* <b>et moins de trois feux </b> Moins de 3 épisodes au total  moins de trois feux évoque le nombre total d'épisodes, utilisant l'analogie avec la fièvre comme feu </p><p>3.  'Un enfant febrile symetrique forge une unique bulle dans la prairie'<br>* <b>Un enfant </b> Âge supérieur à 1 an  enfant indique que le sujet concerne un jeune individu, donc plus d'un an <br>* <b>febrile </b> Survenue de la crise avec une fièvre supérieure à 38°C  fébrile se lie à la notion de fièvre <br>* <b>symetrique </b> Manifestations motrices symétriques  directement lié à symétrique <br>* <b>forge </b> durant moins de 15 minutes et sans déficit  forger évoque une action courte et intense, comme la crise qui dure moins de 15 minutes sans laisser de séquelles <br>* <b>une unique </b> 1 unique crise par épisode fébrile donné  unique précise le nombre de crises <br>* <b>bulle </b> Moins de 3 épisodes au total  une bulle évoque quelque chose de rare et limité, semblable à moins de 3 épisodes au total <br>* <b>dans la prairie </b> hyperthermique  la prairie évoque un espace ouvert et naturel, hyperthermique évoque la chaleur comme celle du soleil sur une prairie </p><p>[DATE:09/04/2024 VERSION:2.1 MODEL:openai/gpt-4-0125-preview]</p></li>
</ol>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Explainer</h3><a id="user-content-explainer" aria-label="Permalink: Explainer" href="#explainer"></a></p>
<p dir="auto">Provides clear, detailed explanations when you struggle with cards by:</p>
<ul dir="auto">
<li>Breaking down complex concepts</li>
<li>Highlighting key relationships</li>
<li>Adding helpful context</li>
<li>Using analogies and examples</li>
</ul>
<p dir="auto">Particularly useful for understanding why you got a card wrong and filling knowledge gaps.</p>
<details>
<summary>
Click to see an example
</summary>
<p dir="auto">The mnemonics made for the card above about infant fever ended up with this content in the AnkiExplainer field (I translated it french to English for universal documentation):</p>
<hr>
<ul dir="auto">
<li><b>EXPLANATION</b> A simple febrile seizure is characterized by its uniqueness and brevity during a febrile episode, which helps distinguish it from complex seizures or other neurological disorders.<br>* <b>MECHANISM</b> Fever can lower the seizure threshold in certain children, which explains why an elevation in body temperature can trigger a seizure in predisposed individuals.<p>[DATE:09/04/2024 VERSION:1.7 LLMMODEL:openai/gpt-4-0125-preview]</p></li>
</ul>
<hr>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Helper</h3><a id="user-content-mnemonics-helper" aria-label="Permalink: Mnemonics Helper" href="#mnemonics-helper"></a></p>
<p dir="auto">A lightweight interactive CLI tool for quick mnemonic generation that:</p>
<ul dir="auto">
<li>Takes a concept and finds semantically similar existing mnemonics</li>
<li>Generates multiple new mnemonic options using LLMs</li>
<li>Lets you choose from generated options with vim-style navigation</li>
<li>Automatically saves selected mnemonics for future reference</li>
<li>Works independently of Anki, perfect for brainstorming sessions</li>
</ul>
<p dir="auto">Unlike the Mnemonics Creator which processes Anki cards in batch, this tool provides an interactive interface for generating mnemonics one concept at a time. Those new mnemonics can automatically be added to a dataset file that can readily be used by the other tools. This allows rapidly tailoring the scripts to your own imagination.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are the core benefits of those tools?</h3><a id="user-content-what-are-the-core-benefits-of-those-tools" aria-label="Permalink: What are the core benefits of those tools?" href="#what-are-the-core-benefits-of-those-tools"></a></p>
<p dir="auto">Basically if you run these tools each evening on cards you failed that day it will steadily improve your deck quality and learning effectiveness:</p>
<ul dir="auto">
<li>Automatically enhance cards you struggle with</li>
<li>Save time on manual card improvements</li>
<li>Create stronger memory connections</li>
<li>Track improvements with detailed history</li>
<li>Preserve card structure while enhancing content</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What is the <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a>?</h3><a id="user-content-what-is-the-major-system" aria-label="Permalink: What is the Major System?" href="#what-is-the-major-system"></a></p>
<p dir="auto">The Major System is a powerful memory technique that converts numbers into consonant sounds, which can then be turned into memorable words. For example:</p>
<ul dir="auto">
<li>0 = S sound (as in "sea")</li>
<li>1 = T sound (as in "tea")</li>
<li>2 = N sound (as in "new")</li>
<li>etc.</li>
</ul>
<p dir="auto">This makes it easier to remember numbers by turning them into words. For example, "92" could become "pen" (P=9, N=2).</p>
<p dir="auto">You can read more about it <a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">on wikipedia</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What are Memory Anchors?</h3><a id="user-content-what-are-memory-anchors" aria-label="Permalink: What are Memory Anchors?" href="#what-are-memory-anchors"></a></p>
<p dir="auto">Memory anchors are existing associations you already know well that can be used to create new memories. For example, if you already strongly associate "Napoleon" with "France", you can use Napoleon as an anchor when learning new facts about French history.</p>
<p dir="auto">The tools can use your personal set of memory anchors to generate mnemonics that build on your existing knowledge.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Which LLM providers are supported?</h3><a id="user-content-which-llm-providers-are-supported" aria-label="Permalink: Which LLM providers are supported?" href="#which-llm-providers-are-supported"></a></p>
<p dir="auto">The tools use <a href="https://docs.litellm.ai/docs/" rel="nofollow">LiteLLM</a> which provides a unified interface to virtually any LLM provider including:</p>
<ul dir="auto">
<li>OpenAI</li>
<li>Anthropic</li>
<li>Google</li>
<li>OpenRouter</li>
<li>Azure</li>
<li>AWS Bedrock</li>
<li>Local models</li>
<li>And many more</li>
</ul>
<p dir="auto">Just specify the model in LiteLLM format (e.g. "openai/gpt-4" or "anthropic/claude-3-opus") and it will handle the rest.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What languages are supported?</h3><a id="user-content-what-languages-are-supported" aria-label="Permalink: What languages are supported?" href="#what-languages-are-supported"></a></p>
<p dir="auto">The tools work in any language supported by the LLM you choose to use. Since these scripts support virtually all LLM providers through LiteLLM, you can use any model that works well with your language. For example:</p>
<ul dir="auto">
<li>OpenAI's models support 100+ languages</li>
<li>Anthropic's Claude supports 100+ languages</li>
<li>You can use local models specifically trained for your language</li>
<li>etc.</li>
</ul>
<p dir="auto">The tools will preserve all language-specific formatting, including:</p>
<ul dir="auto">
<li>Right-to-left text</li>
<li>Special characters and diacritics</li>
<li>Language-specific punctuation</li>
<li>etc.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How do the Mnemonics Work?</h3><a id="user-content-how-do-the-mnemonics-work" aria-label="Permalink: How do the Mnemonics Work?" href="#how-do-the-mnemonics-work"></a></p>
<p dir="auto">The mnemonics tools use several proven memory techniques:</p>
<ul dir="auto">
<li><a href="https://en.wikipedia.org/wiki/Mnemonic_major_system" rel="nofollow">Major System</a> for numbers</li>
<li>Vivid imagery and visualization</li>
<li>Personal memory anchors</li>
<li>Phonetic similarities</li>
<li>Humor and absurdity</li>
<li>Story-based connections</li>
</ul>
<p dir="auto">This creates memorable associations that help strengthen recall while preserving accuracy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where can I find example datasets for each tool?</h3><a id="user-content-where-can-i-find-example-datasets-for-each-tool" aria-label="Permalink: Where can I find example datasets for each tool?" href="#where-can-i-find-example-datasets-for-each-tool"></a></p>
<p dir="auto">The <code>examples/</code> folder contains training datasets and example files for each tool. While these were originally written in French and hastily translated to English, they provide good templates for creating your own datasets. Check the Example Files section below for details on each file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the future of this project?</h3><a id="user-content-whats-the-future-of-this-project" aria-label="Permalink: What's the future of this project?" href="#whats-the-future-of-this-project"></a></p>
<p dir="auto">This toolkit was developed and battle-tested while studying tens of thousands of Anki cards during medical school. It proved invaluable for maintaining and enhancing a large flashcard collection during intense study periods.</p>
<p dir="auto">However, as research commitments have grown, I now have limited time to transform these scripts into a more user-friendly package. The tools work well but need:</p>
<ul dir="auto">
<li>Packaging as a proper Anki addon</li>
<li>Installation via PyPI</li>
<li>Code deduplication and cleanup</li>
<li>Better documentation</li>
</ul>
<p dir="auto">I'm actively looking for contributors of all skill levels to help make these tools more accessible to the wider Anki community. Whether you're a seasoned developer or just getting started, all contributions are welcome! I can provide guidance and direction based on extensive experience with the codebase, while you help with the technical aspects of packaging and distribution.</p>
<p dir="auto">Check out the detailed roadmap below to see what needs improving. If you're interested in helping transform these battle-tested scripts into a polished Anki addon, please don't hesitate to reach out - I'm always happy to chat and help you get started!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why is there code duplication across the tools?</h3><a id="user-content-why-is-there-code-duplication-across-the-tools" aria-label="Permalink: Why is there code duplication across the tools?" href="#why-is-there-code-duplication-across-the-tools"></a></p>
<p dir="auto">This project evolved organically alongside my Python skills while solving real needs during medical school. Each tool was developed independently when needed, prioritizing functionality over code elegance. While they all work reliably, there's significant opportunity to unify their codebases around a common API.</p>
<p dir="auto">I can provide detailed guidance on refactoring and consolidating the code, but lack the time to implement these changes myself. Check the roadmap below if you're interested in helping streamline the codebase while preserving its battle-tested functionality.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">When Should I Use Each Tool?</h3><a id="user-content-when-should-i-use-each-tool" aria-label="Permalink: When Should I Use Each Tool?" href="#when-should-i-use-each-tool"></a></p>
<ul dir="auto">
<li><strong>Mnemonics Creator</strong>: Best for memorizing numbers, sequences, lists, and abstract concepts</li>
<li><strong>Illustrator</strong>: Ideal for visual learners and complex topics that benefit from imagery</li>
<li><strong>Reformulator</strong>: Use when card wording is unclear or you want variety in phrasing. Don't worry about running it on well-formatted cards - the LLM is trained to recognize and preserve cards that already follow best practices, avoiding unnecessary changes that could disrupt your learning</li>
<li><strong>Explainer</strong>: Great for understanding why you got a card wrong and filling knowledge gaps</li>
<li><strong>Mnemonics Helper</strong>: Simple script to quickly ask an LLM to come up with new mnemonics by taking into accountsthe <a href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="nofollow">semantic similarity</a> of the new subject vs your previous mnemonics.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What happens if I run a script multiple times on the same card?</h3><a id="user-content-what-happens-if-i-run-a-script-multiple-times-on-the-same-card" aria-label="Permalink: What happens if I run a script multiple times on the same card?" href="#what-happens-if-i-run-a-script-multiple-times-on-the-same-card"></a></p>
<p dir="auto">For most tools (Mnemonics Creator, Illustrator, Explainer), the previous content will be preserved in a collapsible HTML section using the <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code> tags. The new content appears above this section. This makes it easy to:</p>
<ul dir="auto">
<li>See the latest generated content first</li>
<li>Access previous versions by expanding the collapsible sections</li>
<li>Track how the card evolved over time</li>
</ul>
<p dir="auto">The Reformulator works differently - it replaces the content of the original field directly, but saves all previous versions and metadata in a separate <code>AnkiReformulator</code> field. This preserves the card's readability while maintaining a complete history.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How can I track which cards were modified?</h3><a id="user-content-how-can-i-track-which-cards-were-modified" aria-label="Permalink: How can I track which cards were modified?" href="#how-can-i-track-which-cards-were-modified"></a></p>
<p dir="auto">Each tool meticulously tracks modifications through tags and metadata to ensure transparency and reversibility. For example, when a tool processes a card, it adds a dated tag like <code>AnkiIllustrator::done::02/07/2023</code>. This makes it easy to:</p>
<ul dir="auto">
<li>Quickly identify which cards were modified by each tool</li>
<li>Track when modifications were made</li>
<li>Find cards that haven't been processed yet</li>
<li>Rollback changes if needed (especially with the Reformulator)</li>
</ul>
<p dir="auto">You can use these tags in the Anki browser to assess how many cards could benefit from each tool and review the modifications made. Note that notes for which a script failed will have a tag added to it. For example <code>AnkiI ::failed</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How much does it cost to run these tools?</h3><a id="user-content-how-much-does-it-cost-to-run-these-tools" aria-label="Permalink: How much does it cost to run these tools?" href="#how-much-does-it-cost-to-run-these-tools"></a></p>
<p dir="auto">The cost depends on your usage patterns and which features you enable:</p>
<ul dir="auto">
<li>Start small with a few cards to get comfortable with each tool</li>
<li>Built-in safeguards prevent accidental overspending:
<ul dir="auto">
<li>Maximum cards per run can be limited</li>
<li>Cost tracking per script is stored in the database</li>
<li>Failed API calls don't count towards your quota</li>
<li>You can set hard spending limits</li>
</ul>
</li>
<li>Typical costs per card:
<ul dir="auto">
<li>Reformulator: ~$0.02-0.04 (text only)</li>
<li>Mnemonics: ~$0.02-0.04 (text only)</li>
<li>Explainer: ~$0.03-0.06 (more complex reasoning)</li>
<li>Illustrator: ~$0.02 + image cost ($0.04-0.12 per image)</li>
</ul>
</li>
</ul>
<p dir="auto">The database tracks total spending per script, making it easy to budget and monitor costs. You can also use cheaper models for initial testing before scaling up to more capable ones.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Can I use these tools on mobile?</h3><a id="user-content-can-i-use-these-tools-on-mobile" aria-label="Permalink: Can I use these tools on mobile?" href="#can-i-use-these-tools-on-mobile"></a></p>
<p dir="auto">While you need to run the scripts themselves from a computer (not your phone), all changes are made directly to your Anki notes. This means:</p>
<ul dir="auto">
<li>Run the scripts from your computer/server</li>
<li>Sync Anki on your computer</li>
<li>The improved cards will appear on AnkiMobile/AnkiDroid after syncing</li>
<li>All generated content (reformulations, mnemonics, images, etc.) works perfectly on mobile</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Files</h3><a id="user-content-example-files" aria-label="Permalink: Example Files" href="#example-files"></a></p>
<p dir="auto">The <code>examples/</code> folder contains example files to help you get started. Note that these examples were originally written in French (except for system prompts) and were quickly translated to English - some examples may not make perfect sense but should still demonstrate the basic usage:</p>
<ul dir="auto">
<li><code>anki_ai_utils_tmux_launcher.sh</code>: A tmux-based launcher script I used every morning to automatically process cards I struggled with the previous day</li>
<li><code>anchors.json</code>: Example memory anchors mapping file</li>
<li><code>dataset_anchors.txt</code>: Training examples for memory anchor processing</li>
<li><code>explainer_dataset.txt</code>: Examples for the Explainer tool</li>
<li><code>illustrator_dataset.txt</code>: Training data for image generation</li>
<li><code>illustrator_sanitize_dataset.txt</code>: Examples for sanitizing image prompts</li>
<li><code>mnemonics_dataset.txt</code>: Training data for mnemonic generation</li>
<li><code>reformulator_dataset.txt</code>: Examples for card reformulation</li>
<li><code>string_formatting.py</code>: Handles cloze deletions and text formatting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's the format of dataset files?</h3><a id="user-content-whats-the-format-of-dataset-files" aria-label="Permalink: What's the format of dataset files?" href="#whats-the-format-of-dataset-files"></a></p>
<p dir="auto">Dataset files (like <code>explainer_dataset.txt</code>, <code>reformulator_dataset.txt</code>, etc.) are simple text files where messages are separated by <code>----</code>. The first message is assumed to be a system prompt, followed by alternating user and assistant messages. This format mirrors a typical LLM conversation flow while remaining easy to read and edit.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Reformulator</h4><a id="user-content-reformulator-1" aria-label="Permalink: Reformulator" href="#reformulator-1"></a></p>
<p dir="auto">The Reformulator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python reformulator.py \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/reformulator_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --main_field_index 0 \
    --llm &quot;openai/gpt-4&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --max_token 4000 \
    --llm_temp 0"><pre>python reformulator.py \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/reformulator_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --main_field_index 0 \
    --llm <span><span>"</span>openai/gpt-4<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --max_token 4000 \
    --llm_temp 0</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for reformulation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>main_field_index</code>: Index of the field to reformulate (0 for first field)</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>max_token</code>: Maximum tokens per query</li>
<li><code>llm_temp</code>: LLM temperature (0 for consistent output)</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if already reformulated</li>
<li><code>--print_db_then_exit</code>: Display database contents and exit</li>
<li><code>--parallel</code>: Number of parallel processes (default 4)</li>
<li><code>--exclude_media</code>: Skip cards containing media</li>
<li><code>--mode</code>: Either 'reformulate' or 'reset' to restore original content. Note that the 'reset' feature is not absolutely guaranteed to work, but if things go wrong there are tons of logs on purpose to make sure you don't lose anything.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics</h4><a id="user-content-mnemonics" aria-label="Permalink: Mnemonics" href="#mnemonics"></a></p>
<p dir="auto">The Mnemonics Creator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/mnemonics_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --n_mnemonic 1"><pre>python mnemonics.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/mnemonics_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --n_mnemonic 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for mnemonic generation</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>n_mnemonic</code>: Number of mnemonics to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have mnemonics</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mnemonics Creator CLI</h4><a id="user-content-mnemonics-creator-cli" aria-label="Permalink: Mnemonics Creator CLI" href="#mnemonics-creator-cli"></a></p>
<p dir="auto">The Mnemonics Creator CLI provides an interactive interface for generating mnemonics:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embed_model &quot;openai/text-embedding-3-small&quot;"><pre>python mnemonics_creator.py \
    --top_k 100 \
    --n_gen 10 \
    --model <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embed_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span></pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>top_k</code>: Number of similar existing mnemonics to use as examples (default: 100)</li>
<li><code>n_gen</code>: Number of new mnemonics to generate per query (default: 10)</li>
<li><code>model</code>: LLM model to use in litellm format</li>
<li><code>embed_model</code>: Model for semantic similarity search</li>
<li><code>query</code>: Optional initial query to process</li>
<li><code>gui</code>: Enable GUI interface (not yet implemented)</li>
</ul>
<p dir="auto">The CLI provides an interactive interface where you can:</p>
<ul dir="auto">
<li>Enter concepts to generate mnemonics for</li>
<li>See similar existing mnemonics as context</li>
<li>Choose from multiple generated options</li>
<li>Navigate with vim-style keys (j/k) or numbers</li>
<li>Save selected mnemonics to your collection</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Explainer</h4><a id="user-content-explainer-1" aria-label="Permalink: Explainer" href="#explainer-1"></a></p>
<p dir="auto">The Explainer can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python explainer.py \
    --field_names &quot;body&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --dataset_path &quot;data/explainer_dataset.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --llm &quot;openrouter/anthropic/claude-3-sonnet&quot; \
    --embedding_model &quot;openai/text-embedding-3-small&quot; \
    --llm_max_token 3000"><pre>python explainer.py \
    --field_names <span><span>"</span>body<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --dataset_path <span><span>"</span>data/explainer_dataset.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --llm <span><span>"</span>openrouter/anthropic/claude-3-sonnet<span>"</span></span> \
    --embedding_model <span><span>"</span>openai/text-embedding-3-small<span>"</span></span> \
    --llm_max_token 3000</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>dataset_path</code>: Example prompts for generating explanations</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>llm</code>: LLM model to use in litellm format</li>
<li><code>embedding_model</code>: Model for semantic similarity search</li>
<li><code>llm_max_token</code>: Maximum tokens per query</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have explanations</li>
<li><code>--note_mode</code>: Don't count cards of the same note twice</li>
<li><code>--do_sync</code>: Sync Anki before and after processing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Illustrator</h4><a id="user-content-illustrator-1" aria-label="Permalink: Illustrator" href="#illustrator-1"></a></p>
<p dir="auto">The Illustrator can be run from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python illustrator.py \
    --field_names &quot;front,back&quot; \
    --query &quot;(rated:2:1 OR rated:2:2) -is:suspended&quot; \
    --memory_anchors_file &quot;data/anchors.json&quot; \
    --dataset_path &quot;data/illustrator_dataset.txt&quot; \
    --dataset_sanitize_path &quot;data/illustrator_sanitize.txt&quot; \
    --string_formatting &quot;data/string_formatting.py&quot; \
    --ntfy_url &quot;ntfy.sh/YOUR_TOPIC&quot; \
    --n_image 1"><pre>python illustrator.py \
    --field_names <span><span>"</span>front,back<span>"</span></span> \
    --query <span><span>"</span>(rated:2:1 OR rated:2:2) -is:suspended<span>"</span></span> \
    --memory_anchors_file <span><span>"</span>data/anchors.json<span>"</span></span> \
    --dataset_path <span><span>"</span>data/illustrator_dataset.txt<span>"</span></span> \
    --dataset_sanitize_path <span><span>"</span>data/illustrator_sanitize.txt<span>"</span></span> \
    --string_formatting <span><span>"</span>data/string_formatting.py<span>"</span></span> \
    --ntfy_url <span><span>"</span>ntfy.sh/YOUR_TOPIC<span>"</span></span> \
    --n_image 1</pre></div>
<p dir="auto">Key arguments:</p>
<ul dir="auto">
<li><code>field_names</code>: Comma-separated list of note fields to analyze</li>
<li><code>query</code>: Anki browser query to select cards (defaults to recently failed cards)</li>
<li><code>memory_anchors_file</code>: JSON file mapping concepts to memory anchors</li>
<li><code>dataset_path</code>: Example prompts for image generation</li>
<li><code>dataset_sanitize_path</code>: Examples for sanitizing unsafe prompts</li>
<li><code>string_formatting</code>: Custom text formatting functions</li>
<li><code>ntfy_url</code>: Optional notifications via ntfy.sh</li>
<li><code>n_image</code>: Number of images to generate per card</li>
</ul>
<p dir="auto">Additional options:</p>
<ul dir="auto">
<li><code>--debug</code>: Enable debug mode</li>
<li><code>--force</code>: Process cards even if they already have illustrations</li>
<li><code>--disable_notif</code>: Disable ntfy.sh notifications</li>
</ul>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Roadmap</h3><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<details>
<summary>
Click to read more
</summary>
<p dir="auto"><i>This TODO list is maintained automatically by <a href="https://github.com/thiswillbeyourgithub/MdXLogseqTODOSync">MdXLogseqTODOSync</a></i></p>

<ul dir="auto">
<li>turn those scripts into addons</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Applies to all tools</h3><a id="user-content-applies-to-all-tools" aria-label="Permalink: Applies to all tools" href="#applies-to-all-tools"></a></p>
</li>
<li>use beartype everywhere</li>
<li>add an arg to include tags or not in the LLM context for a given note, as otherwise the LLM can get confused by some acronyms
<ul dir="auto">
<li>but with a regex arg to keep only the tags that match the regex. This way we can keep only a portion of them for the LLM</li>
</ul>
</li>
<li>store all inference in a compressed sqlite db instead of a json. It gets too large</li>
<li>add check that we indeed removed all the done tags</li>
<li>actually there's no need to store the "Done" tags because all important info is stored in the field</li>
<li>use xml formatting for the examples
<ul dir="auto">
<li>make use of  tags too</li>
</ul>
</li>
<li>make it installable with a setup.py on pypi</li>
<li>add images to illustrate the benefits of using each</li>
<li>do a unique class that could be used to unify all those codes
<ul dir="auto">
<li>arguments:
<ul dir="auto">
<li>name (to differentiate each children: for example "illustrator")</li>
<li>string_format (can be overloaded)</li>
<li>in the init, check that indeed there is a version attribute</li>
</ul>
</li>
</ul>
</li>
<li>use toml instead of json, it allows setting comments too</li>
<li>tell user how much time each answer took</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mnemonics Creator</h3><a id="user-content-mnemonics-creator-1" aria-label="Permalink: Mnemonics Creator" href="#mnemonics-creator-1"></a></p>
<ul dir="auto">
<li>Add keybindings
<ul dir="auto">
<li>binding e to edit a proposition</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Illustrator</h3><a id="user-content-illustrator-2" aria-label="Permalink: Illustrator" href="#illustrator-2"></a></p>
</li>
<li>use an llm to extract numbers
<ul dir="auto">
<li>ask it to do quick transformations like turn 48h into 2 days, modify units, etc,</li>
</ul>
</li>
<li>add support for note containing media like audio, images etc</li>
<li>add a mode without actually creating images. This could be used like a mnemonics after all.</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Reformulator</h3><a id="user-content-reformulator-2" aria-label="Permalink: Reformulator" href="#reformulator-2"></a></p>
</li>
<li>Add 5 to 10 example for the LLM of how to manage media like iimages etc then add support for them</li>
<li>make it work with specific fstring template for field replacement. Otherwise it can only reformulate a single field
<ul dir="auto">
<li>better: add an arg to specify the single output field, and an arg to specify a comma separated list of input fields</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">explainer</h3><a id="user-content-explainer-2" aria-label="Permalink: explainer" href="#explainer-2"></a></p>
</li>
<li>compute all embeddings at the start, making it faster</li>
<li>it's actually quite terrible. Use one LLM call to ask for which follow up questions to ask, then another LLM call to answer each using async
<ul dir="auto">
<li>save each new question answer as a <details> tag to make it easy to access on phones by touching the field</details></li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ankimnemonics</h3><a id="user-content-ankimnemonics" aria-label="Permalink: Ankimnemonics" href="#ankimnemonics"></a></p>
</li>
<li>comment out the mnemonics that dont respect the rule of adding the subject first</li>
<li>understand why it sometimes hangs during a run</li>
<li>make it distinguish 'has to appear in plain' vs 'has to appear as mnemonic'?</li>
<li></li>
<li>
<p dir="auto"><h3 tabindex="-1" dir="auto">AnkiAiFilter</h3><a id="user-content-ankiaifilter" aria-label="Permalink: AnkiAiFilter" href="#ankiaifilter"></a></p>
</li>
<li>use an eval llm like in <a href="https://wdoc.readthedocs.io/en/latest/" rel="nofollow">wdoc</a> to better filer an anki query
<ul dir="auto">
<li>actually wdoc can already be used for that! Maybe it should be converted into an addon?</li>
</ul>
</li>
<li></li>
<li>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tagger (In project)</h2><a id="user-content-tagger-in-project" aria-label="Permalink: Tagger (In project)" href="#tagger-in-project"></a></p>
</li>
<li>always prepend tags by ankitagger: but customizable</li>
<li>always sort those tags by alphabetical order</li>
<li>add modes:
<ul dir="auto">
<li>mode "predefined": the user gives a list of tags and the LLM finds which to apply to each note given a query
<ul dir="auto">
<li>loop over each note and ask it to generate tags</li>
</ul>
</li>
</ul>
</li>
<li>arg for image support if media found
<ul dir="auto">
<li>if the card contains an image, it should be hashed, then a cached call to a func that asks a vision model to describe the type of image, then use the embedding of this answer to suggest the appropriate tags to suggest to the LLM for classification</li>
</ul>
</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">This project makes heavy use of <a href="https://git.foosoft.net/alex/anki-connect" rel="nofollow">AnkiConnect</a> to interact with Anki.</p>
</details>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU law mandating universal chargers for devices comes into force (235 pts)]]></title>
            <link>https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</link>
            <guid>42534851</guid>
            <pubDate>Sat, 28 Dec 2024 21:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force">https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force</a>, See on <a href="https://news.ycombinator.com/item?id=42534851">Hacker News</a></p>
Couldn't get https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Photos phones home on iOS 18 and macOS 15 (845 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2024/12/3.html</link>
            <guid>42533685</guid>
            <pubDate>Sat, 28 Dec 2024 19:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2024/12/3.html">https://lapcatsoftware.com/articles/2024/12/3.html</a>, See on <a href="https://news.ycombinator.com/item?id=42533685">Hacker News</a></p>
Couldn't get https://lapcatsoftware.com/articles/2024/12/3.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Google's Results Are Infested, Open AI Is Using Their Playbook from the 2000s (419 pts)]]></title>
            <link>https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</link>
            <guid>42532441</guid>
            <pubDate>Sat, 28 Dec 2024 17:06:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook">https://chuckwnelson.com/blog/google-search-results-infested-open-ai-using-google-playbook</a>, See on <a href="https://news.ycombinator.com/item?id=42532441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You know when you go on a picnic, sometimes there's a fly that decides to join you.</p>
<p>You wave your hand to shoo it away from the tasty lunch you're about to enjoy and think nothing more of it.</p>
<p>But it returns, only for you to swipe again, and that tinge of frustration starts to bloom. It returns, and now your lunch is no longer the focus, but this annoying fly whose buzzing is now an obstacle to a perfectly nice picnic.</p>
<h2>The 2000s were a picnic</h2>
<p>When Google came onto the scene, I credit its success to the tried and true paradigm that makes companies successful: <strong>simple and easy to use</strong>.</p>
<p>Yahoo was dominant back then, and it tried to put everyone and everything in front of you. Then we learned about the paralysis of choice. Too many choices, the mental fatigue weighed in, and the product became difficult to use.</p>
<p><img src="https://chuckwnelson.com/images/yahoo-vs-google.jpg" alt="Yahoo vs Google"></p>
<p>Enter Google, and it was <strong>Feeling Lucky</strong>. Just a search input, logo, and some minor text. The next step was clear. And the search results were a simple list. Sequential to avoid mental fatigue, and just enough description to make an informed choice.</p>
<p><img src="https://chuckwnelson.com/images/google-serp.jpg" alt="Trustworthy Google"></p>
<p>Then a fly came buzzing to the picnic.</p>
<h2>Enter the buzz</h2>
<p>Google added advertising. Their first iteration was clearly marked and outside the search list. Trust in the organic results mattered to Google, and it would be off-brand to show you could pay to be at the top of that list.</p>
<p>And even these ads weren't that bad. What made Google successful was showing ads you wanted to see. I'm searching for a bottle of wine, and ads for bottles of wine were shown to me. This is okay because it's not interrupting the picnic. Google's success is from active intent advertising.</p>
<p>But then ads were placed over search results, still clearly marked, but pushing down organic results. Buzz.</p>
<p>Then the SEO industry got its footing. Organic results are now optimized advertorials, or aggregation websites like Yelp and Pinterest, which have their own ad models.</p>
<p>It's a layer cake of ads all the way down the list.</p>
<p>Google lost its credibility.</p>
<h2>Google is infested with these little annoyances</h2>
<p>Enter 2024 with AI. The top 20% of search results are a wall of text from AI, then a Google product such as maps or shopping listings (with ads), then search ads, then YouTube videos, then search results (hidden ads), then some sprinkling of what you are looking for.</p>
<p>I don't want to watch a 10-minute video for a quick answer.</p>
<p>No longer can you flip back and forth from search results quickly to find the answer.</p>
<p>You need a machete to cut through the visual noise in order to find even a website that may have your lunch.</p>
<p>We are back to Yahoo in the 2000s, choice paralysis, visual clutter, and no trust in the results I do see.</p>
<p>I'm no longer feeling lucky.</p>
<p><img src="https://chuckwnelson.com/images/google-serp-today.jpg" alt="Google Search Results Today"></p>
<h2>OpenAI's search is becoming Google in the 2000s, if it can remain trustworthy.</h2>
<p>Open AI's ChatGPT search results have entered the scene. It's not perfect, but it's not Google.</p>
<p>The visual clutter is not there because it's a conversation, not a list. It's one answer instead of 10.</p>
<p>It's active intent searching, the thing that made Google successful. Plus, it's conversational. We are trained monkeys to be able to keep asking questions, with the context of the information that came before. It's simple because we are use to it.</p>
<p><strong>Active intent conversations</strong> is just a overly fancy way to say "recommendations." Just like a friend would recommend a restaurant to you based on what you ask for. But we trust our friends.</p>
<p><img src="https://chuckwnelson.com/images/openai-serp.jpg" alt="Open AI Search Results"></p>
<p>Does ChatGPT Search have trust? Open AI isn't monetizing its search just yet, but AI has its own issues with hallucinations.</p>
<p>If Open AI can build its brand and its trust with the consumer, it can dethrone the king.</p>
<p>They know this is important as well. Their website is littered with media quotes stating <a href="https://openai.com/index/introducing-chatgpt-search/">ChatGPT's search</a> links to trustworthy sources, and bringing premium journalism.</p>
<p>This is the fork in the road. There are entire industries waiting to see the direction this goes in. If Open AI goes the way of Google with tons of choices and mental fatigue, it can still be successful, but will be battling to be king of the hill.</p>
<p>But if it can keep it simple <strong>and trustworthy</strong>, it can own the most valuable digital real estate as the sidekick with the single answer.</p>
<p>Google is losing trust with all these buzzing results, and its answer is to throw more spaghetti at the wall to see what sticks. But this just attracts more problems.</p>
<p>In order for Google to keep its crown, it needs to remember what it was in the 2000s and a bit of luck.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. homelessness jumps to record high amid affordable housing shortage (109 pts)]]></title>
            <link>https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</link>
            <guid>42532311</guid>
            <pubDate>Sat, 28 Dec 2024 16:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants">https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants</a>, See on <a href="https://news.ycombinator.com/item?id=42532311">Hacker News</a></p>
Couldn't get https://www.npr.org/2024/12/27/nx-s1-5241115/us-homeless-hud-housing-costs-migrants: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[My history with Forth and stack machines (2010) (103 pts)]]></title>
            <link>https://yosefk.com/blog/my-history-with-forth-stack-machines.html</link>
            <guid>42532157</guid>
            <pubDate>Sat, 28 Dec 2024 16:34:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yosefk.com/blog/my-history-with-forth-stack-machines.html">https://yosefk.com/blog/my-history-with-forth-stack-machines.html</a>, See on <a href="https://news.ycombinator.com/item?id=42532157">Hacker News</a></p>
Couldn't get https://yosefk.com/blog/my-history-with-forth-stack-machines.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Are you unable to find employment? (261 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42531830</link>
            <guid>42531830</guid>
            <pubDate>Sat, 28 Dec 2024 15:48:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42531830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="42531830">
      <td><span></span></td>      <td><center><a id="up_42531830" href="https://news.ycombinator.com/vote?id=42531830&amp;how=up&amp;goto=item%3Fid%3D42531830"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=42531830">Ask HN: Are you unable to find employment?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_42531830">117 points</span> by <a href="https://news.ycombinator.com/user?id=w4ffl35">w4ffl35</a> <span title="2024-12-28T15:48:02 1735400882"><a href="https://news.ycombinator.com/item?id=42531830">3 hours ago</a></span> <span id="unv_42531830"></span> | <a href="https://news.ycombinator.com/hide?id=42531830&amp;goto=item%3Fid%3D42531830">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Are%20you%20unable%20to%20find%20employment%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=42531830&amp;auth=53e534d335780effb0dc1b295eec39a0de8d5081">favorite</a> | <a href="https://news.ycombinator.com/item?id=42531830">136&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I am seeing many anecdotal experiences shared online on various platforms stating that it is difficult to find employment in tech. I myself have had a difficult time landing an interview over the last year despite having two decades of experience.</p><p>I am attempting to gain some insight into the issue. My situation is somewhat unique in that I am self-taught without a CS degree. I'm a very experienced, diligent worker, etc, but an algorithm doesn't care about this and so getting through the filters is difficult.</p><p>However I see many discussions being posted (primarily on X) stating that it is nearly impossible for people with CS degrees (especially white males) to get an interview let alone a job. There have been mass layoffs, less money being invested etc. 
Many people have claimed AI is taking jobs, or that there aren't as many jobs available, yet at the same time, Elon Musk and others claim there is an engineer shortage and we must increase the number of H-1B visas in order to fill this gap. When I apply to a position on linkedin I can see that even the most Jr positions have over 100 applicants.</p><p>I know that X can be slanted, and really anything posted online must be taken with a grain of salt - but I'm seeing many people claiming to be in the same situation as myself, and most of them claim to be white males.</p><p>Furthermore, in the last two years I experienced two layoffs. In both situations it was white males let go in favor of Indian and KZ foreigners. Again - this is anecdotal and could be a coincidence, but its awfully telling that Vivek and Elon are calling American tech workers uncultured, lazy and stupid in the wake of these experiences and those that I've read about online.</p><p>I don't want to start a war here on hackernews, but I'm looking for people's personal experiences. Do they match up? Are you having a hard time finding employment? Have you been fired in favor of foreign workers? Is this racism / ageism / sexism at play or is that being overblown by political actors?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Automated My Job Application Process (457 pts)]]></title>
            <link>https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</link>
            <guid>42531695</guid>
            <pubDate>Sat, 28 Dec 2024 15:26:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1">https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1</a>, See on <a href="https://news.ycombinator.com/item?id=42531695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>Look, I'll be honest - job hunting sucks.</p>
<p>It's this soul-crushing cycle of copying and pasting the same information over and over again, tweaking your resume for the 100th time, and writing cover letters that make you sound desperate without actually sounding desperate.</p>
<p>But here's the thing: repetitive tasks + structured process = perfect automation candidate.</p>
<p>So I did what any sane developer would do - I built a system to automate the whole damn thing. By the end, I had sent out 250 job applications in 20 minutes. (The irony? I got a job offer before I even finished building it. More on that later.)</p>
<p>Let me walk you through how I did it.</p>
<h2 id="heading-the-job-application-process-is-broken">The Job Application Process is Broken</h2>
<p>Think about it - every job application follows the same basic pattern:</p>
<ol>
<li><p>Find job posting</p>
</li>
<li><p>Check if you're qualified</p>
</li>
<li><p>Research company (let's be real, most people skip this)</p>
</li>
<li><p>Submit resume + cover letter</p>
</li>
<li><p>Wait... and wait... and wait...</p>
</li>
</ol>
<p>It's like a really boring video game where you do the same quest over and over, hoping for different results.</p>
<h2 id="heading-building-the-proof-of-concept">Building the Proof of Concept</h2>
<p>I started by writing some quick Python scripts to test if this crazy idea could work. Here's how I broke it down:</p>
<h3 id="heading-step-1-getting-the-job-listings-the-manual-part">Step 1: Getting the Job Listings (The Manual Part)</h3>
<p>First challenge: getting job listings at scale. I tried web scraping but quickly realized something: job boards are like snowflakes - each one is uniquely annoying to scrape.</p>
<p>I tested dumping entire web pages into an LLM to clean the data, but:</p>
<ul>
<li><p>It was expensive as hell</p>
</li>
<li><p>I didn't want the AI hallucinating job requirements (imagine explaining that in an interview)</p>
</li>
</ul>
<p>So I went old school - manual HTML copying. Yes, it's primitive. Yes, it works. Sometimes the simplest solution is the best solution.</p>
<h3 id="heading-step-2-cleaning-the-raw-html">Step 2: Cleaning the Raw HTML</h3>
<p>The raw HTML was a mess, but I needed structured data like this:</p>
<pre><code>{
    <span>"job_link"</span>: <span>"https://example.com/job/12345"</span>,
    <span>"job_id"</span>: <span>"12345"</span>,
    <span>"job_role"</span>: <span>"software developer"</span>,
    <span>"employer"</span>: <span>"Tech Corp Inc"</span>,
    <span>"location"</span>: <span>"San Francisco, CA"</span>,
    <span>"work_arrangement"</span>: <span>"Remote"</span>,
    <span>"salary"</span>: <span>"$150,000"</span>
}
</code></pre>
<p>Pro tip: You can just show ChatGPT a sample of your HTML and the output format you want, and it'll write the parsing script for you. Work smarter, not harder.</p>
<h3 id="heading-step-3-getting-the-full-job-details">Step 3: Getting the Full Job Details</h3>
<p>This part was straightforward but required some finesse. For each job listing, I made a GET request to fetch the full description. Each request returns raw HTML that still has all the website scaffolding - navigation bars, popups, footer junk, the works.</p>
<p>I wrote a simple HTML parser to strip out everything except the actual job description. Sometimes you'll hit extra hurdles - like having to click a button to reveal the recruiter's email or company details. The good news? Since you're working with one job board at a time, you only need to figure out these patterns once.</p>
<p>Pro tip: Always add delays between requests. I set mine to 2-3 seconds. Sure, it makes the process slower, but it's better than getting your IP banned. Don't be that person who DDOSes job boards - I added delays between requests because I'm not a monster.</p>
<h3 id="heading-step-4-converting-raw-html-to-structured-data">Step 4: Converting Raw HTML to Structured Data</h3>
<p>This is where it gets interesting. Job postings are like people - they all have the same basic parts but the organization is chaos. Some list skills at the top, others bury them in paragraphs of corporate speak.</p>
<p>Enter the LLM prompt that saved my sanity:</p>
<pre><code><span>const</span> prompt = <span>`Please analyze these HTML contents from a job posting and extract information into a structured JSON format.

[... HTML content ...]

Format the response as valid JSON object with these exact keys:
- contact_email
- application_instructions
- job_posting_text (in markdown)
- job_posting_link
- additional_info (salary, location, etc.)
- job_title
- job_company
- job_department
- job_location
- job_skills
- job_instructions (how to apply)

optional keys

- hiring_manager_name
- 
- job_portal
`</span>
</code></pre>
<h3 id="heading-step-5-generating-cover-letters-that-dont-suck">Step 5: Generating Cover Letters That Don't Suck</h3>
<p>The secret to good cover letters? Context. I fed my resume into the LLM along with the job details. This way, the AI could match my experience with their requirements. Suddenly, those "I'm excited about this opportunity" letters actually had substance.</p>
<p>Here's the prompt that made it happen:</p>
<pre><code><span>const</span> prompt = <span>`Please help me write a professional job application email based on the following information:

=== MY RESUME ===
<span>${resumeMarkdown}</span>

=== JOB DETAILS ===
Job Title: <span>${job_title}</span>
Company: <span>${job_company}</span>
Department: <span>${job_department || <span>''</span>}</span>
Location: <span>${job_location || <span>''</span>}</span>
Job Description: <span>${job_posting_text }</span>
Required Skills: <span>${job_skills?.join(<span>', '</span>) || <span>''</span>}</span>
Application Instructions: <span>${job_instructions || <span>''</span>}</span>

Additional Context:
- Hiring Manager Name: <span>${hiring_manager_name || <span>''</span>}</span>
- Referral Source: <span>${referral_source || <span>'Job board'</span>}</span>
- Application Portal: <span>${job_portal || <span>''</span>}</span>

Instructions:
1. Create an email that is ready to send without any placeholders or edits needed
2. If any critical information is missing (like company name or job title), respond with an error message instead of generating incomplete content
3. Skip any optional fields if they're empty rather than including placeholder text
4. Use natural sentence structure instead of obvious template language
5. Include specific details from both the resume and job description to show genuine interest and fit
6. Any links or contact information should be properly formatted and ready to use

Format the response as a JSON object with these keys:
{
  "status": "success" or "error",
  "error_message": "Only present if status is error, explaining what critical information is missing",
  "email": {
    "subject": "The email subject line",
    "body_html": "The email body in HTML format with proper formatting",
    "body_text": "The plain text version of the email",
    "metadata": {
      "key_points_addressed": ["list of main points addressed"],
      "skills_highlighted": ["list of skills mentioned"],
      "resume_matches": ["specific experiences/skills from resume that match job requirements"],
      "missing_recommended_info": ["optional fields that were missing but would strengthen the application if available"],
      "tone_analysis": "brief analysis of the email's tone"
    }
  }
}

Critical required fields (will return error if missing):
- Job title
- Company name
- Job description
- Resume content

Recommended but optional fields:
- Hiring manager name
- Department
- Location
- Application instructions
- Referral source
- Required skills list

Please ensure all HTML in body_html is properly escaped for JSON and uses only basic formatting tags (p, br, b, i, ul, li) to ensure maximum email client compatibility.
`</span>
</code></pre>
<p>The prompt does a few clever things:</p>
<ol>
<li><p>Forces structured output - no wishy-washy responses</p>
</li>
<li><p>Tracks which of your skills match the job requirements</p>
</li>
<li><p>Identifies any missing info that could strengthen the application</p>
</li>
<li><p>Generates both HTML and plain text versions (because some job portals hate formatting)</p>
</li>
</ol>
<p>And here's the kicker - it fails fast if critical info is missing. No more generic "I saw your job posting" emails. Either the cover letter has substance, or it doesn't get sent. Period.</p>
<p>(I start all all my prompts with ‘please’, so that when AI eventually takes over, they would consider me friendly 😁)</p>
<h3 id="heading-step-6-sending-the-emails-the-moment-of-truth">Step 6: Sending the Emails (The Moment of Truth)</h3>
<p>Last step - actually sending these beautifully crafted applications. Sounds simple, right? Just hook up an email service and blast away?</p>
<p>Not so fast. I needed a way to:</p>
<ul>
<li><p>Send professional-looking emails</p>
</li>
<li><p>Track what was actually sent</p>
</li>
<li><p>Monitor responses (can't ghost the recruiters)</p>
</li>
<li><p>Not get flagged as spam (crucial!)</p>
</li>
</ul>
<p>For testing, I sent all emails to a test account first. Pro tip: when you do send to actual recruiters, BCC yourself. Nothing worse than wondering "did that email actually go through?"</p>
<p>At this stage of the POC, I just used a simple email provider like Mailgun. Quick, dirty, but effective. Don't worry - in Part 2, I'll tell you about the rabbit hole I went down trying to build a full email management system. (Spoiler: it involves rejected AWS applications and a failed attempt at running my own email server. Good times.)</p>
<h2 id="heading-the-results">The Results</h2>
<p>The proof of concept worked better than expected. I could take a job board, extract listings, parse them, and generate personalized applications - all with a few Python scripts.</p>
<p>But this was just the beginning. The real challenge? Turning these scripts into a proper application that could:</p>
<ul>
<li><p>Handle multiple job boards</p>
</li>
<li><p>Track applications</p>
</li>
<li><p>Manage email responses</p>
</li>
<li><p>Not get me blacklisted from every HR system in existence</p>
</li>
</ul>
<p>In Part 2, I'll show you how I built the actual application, complete with all the technical decisions, trade-offs, and "what was I thinking" moments.</p>
<p>Stay tuned - it gets even better.</p>
<hr>
<p><em>Want to know when Part 2 drops? Follow me on</em> <a target="_blank" href="https://x.com/DavidDodda_"><em>Twitter</em></a> <em>or</em> <a target="_blank" href="https://www.linkedin.com/in/arundavidreddy/"><em>LinkedIn</em></a><em>. And yes, I'll eventually tell you how I got a job offer before finishing this project. It's a good story.</em></p>
</div></div>]]></description>
        </item>
    </channel>
</rss>