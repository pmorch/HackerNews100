(ignoring known css parsing error)
(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 11 Jan 2025 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[De-smarting the Marshall Uxbridge Bluetooth speaker (152 pts)]]></title>
            <link>https://tomscii.sig7.se/2025/01/De-smarting-the-Marshall-Uxbridge</link>
            <guid>42666572</guid>
            <pubDate>Sat, 11 Jan 2025 15:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tomscii.sig7.se/2025/01/De-smarting-the-Marshall-Uxbridge">https://tomscii.sig7.se/2025/01/De-smarting-the-Marshall-Uxbridge</a>, See on <a href="https://news.ycombinator.com/item?id=42666572">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">
  
  <div itemprop="articleBody">
    <!--more-->

<p><strong>This is the story of a commercially unavailable <em>stereo pair</em> of the
bi-amped Marshall Uxbridge, with custom-built replacement electronics:
active filters feeding two linear power amps. Listening to this
high-fidelity set has brought me immense enjoyment. Play a great album
on these near-fields, and the result is close to pure magic! Over and
above the accurate reproduction of a wide audio range, the precision
and depth of its stereo imaging is stunning.</strong></p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/muxbridge-pair.jpg"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/muxbridge-pair-thumb.jpg" alt=""></a><br>
<em>Odd socks, rock’n’roll! (click to enlarge)</em></p>

<p>Dumpster diving electronics is a way of life, which sometimes brings
great moments of joy.  One of these moments happened when I stumbled
upon… the <a href="https://duckduckgo.com/?q=marshall+uxbridge&amp;iax=images&amp;ia=images">Marshall Uxbridge
Voice</a>,
a smart speaker, in seemingly pristine condition. And not just one,
but <em>two</em> of them! One was black, the other white. What a find!</p>

<p>What to do with these babies? Intrigued by the question “what could be
wrong with them, why would someone throw them out like that?” –
I set out to investigate. Plugging in one of them, after a few seconds
of waiting, a female voice was heard: <em>«NOW IN SETUP MODE. FOLLOW THE
INSTRUCTIONS IN YOUR DEVICE’S COMPANION APP.»</em></p>

<p>Sounded like a command: clear, loud and demanding. But no, that won’t
happen. Instead, let’s see if we can use this gadget as a plain old
Bluetooth speaker?  Yes indeed! With the help of <code>blueman-manager</code>, I
was able to hook it up to my Linux desktop (running Debian stable, as
ever) and select it as a speaker output. And it worked, and music
filled the room!</p>

<p>I was delighted, and immediately impressed by the sound quality. The
low end was punchy and deep, much deeper than the modest dimensions
led me to believe. The high end was crisp and detailed. Good drivers,
I thought, and a good amp – there’s got to be some iron and
copper inside, no wonder the thing is quite heavy! I liked it even
though the sound reminded me of the “disco smile” (hollowed out mids),
but I chalked that up to overly consumer-friendly default EQ
settings. Maybe it can be improved.</p>

<p>The other device was similarly well functioning. I still could not
believe my luck. Why would anyone throw out these excellent
Bluetooth-enabled, powered speakers? They are doing such a great job!</p>

<p>Being in the market for a couple high-end speakers, I started to
fantasize about making a stereo pair out of these two.  Is that even
possible? Probably not out of the box, as I could only
Bluetooth-connect one at a time with the computer.  While listening to
a video, I also learned that the speaker added some 300ms of delay
(compared to my wired headphones), which could be compensated, but was
going to be a pain nevertheless. I had no idea if it came from the
Bluetooth link or further processing in the “smart” speaker.  Probably
both. And any small differences between the latencies of two devices
would certainly destroy the stereo imaging, if I ever got that to
work…</p>

<p>Then the bland female voice suddenly came in over the music again,
loud and clear: <em>«CONNECTION UNSUCCESSFUL. CHECK YOUR APP FOR
INSTRUCTIONS AND TRY AGAIN.»</em> Oh my poor ears! And there goes my
listening experience!  <em>Don’t you dare open your filthy mouth again!</em></p>

<p>At that moment I knew I was not into <em>smart speakers</em>. Or at least not
into the smartness. The speakers were good. Oh, they were excellent!
But they had to be <em>de-smarted</em>. Preferably with a single, dumb,
analog RCA line input on their backs, so nobody but me gets to decide
over the program material. That way I could also drive them as a
stereo pair. No Bluetooth, no latency, no female robot overlord, just
a good old-fashioned line input!</p>

<p>Seems like a modest ask. Can we have it? Well, time to look inside!</p>

<h2 id="inside-the-uxbridge">Inside the Uxbridge</h2>

<p>Opening the enclosure by removing the backplate is a matter of pulling
the six ordinary Phillips screws on the back. Then, the box can be
pried open with some thin lever (screwdriver edge) – it fits
snugly and is made even tighter with some air-tight foam.</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/original-innards.jpg"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/original-innards-thumb.jpg" alt=""></a><br>
<em>Original innards (click to enlarge)</em></p>

<p>The main electronics is on a board fastened to the back; it receives
power from a separate PSU hidden under the woofer via the big JST plug
(disconnected in the photo); the two smaller (connected) JST plugs
connect to the woofer and tweeter (red and white, respectively). There
are a couple flexible flat cables connecting to auxiliary boards
hosting the volume and tone controls (plus the mics and push-buttons)
on the top, and four RGB LEDs at the bottom of the front plate. I had
to disconnect some of these, as well as the JST power plug, so as to
take the above photo.</p>

<p>The main board comes with a smaller daughter board with <em>Linkplay</em>
written on it. This is supposedly an <a href="https://w.dspconcepts.com/reference-designs/amlogic-a113x-smart-speaker">OEM
module</a>
for wireless connectivity and the “smarts” of the speaker: it contains
an Amlogic A113X SoC, memory chips plus wireless module. The daughter
board slides into an edge connector (not entirely unlike PCIe) on the
main board. From the radio module, wires run off to two rectangular
patch antennas fastened near opposite upper corners of the backplane.
All wiring is covered in foam, and apparent care has been taken to
make the enclosure air-tight.</p>

<p>The audio amplifier itself is built around an ESMT AD85050. This
48-pin device is apparently a knock-off of <a href="https://www.ti.com/product/TAS5727">some class D power
amplifiers</a>, with rather <a href="http://www.micro-bridge.com/data/ESMT/AD85050.pdf">scarce
documentation</a> of
its own. It is employed in a two channel configuration, with separate
power amplifiers dedicated to both drivers. These, both the tweeter
and the woofer, measure close to 4Ω.</p>

<p>Looking at the circuit boards in some detail (and using a connectivity
checker), it becomes apparent that the I<sup>2</sup>C control, the
I<sup>2</sup>S two-channel digital audio stream and the 3.3V power all
come from the daughter board. Which, unfortunately, is also the source
of that vexing female robot commander voice.</p>

<p>Can we use the electronics? That depends on whether we are able to
oust the resident voice of terror, and get hold of an analog input.
Initially, I was hopeful, and felt that discarding everything between
the PSU and the speakers, including a ready-made power amp already
coupled to the speakers, would be a waste. As a first experiment, I
removed the daughter board.  Nothing worked – but in light of my
earlier findings, I was not surprised. So then, assuming I cut the
I<sup>2</sup>S lines to mute the damn robot, would it be possible to
somehow inject an analog input to the (otherwise digital) amp?</p>

<p>With an “I’m feeling lucky” attitude, I somehow managed to solder some
very thin wires connecting to the ESMT chip’s LINP, LINN and AGND
lines in the hope of finding out. In case you were wondering, these
are supposed to act as analog differential inputs for the power
amplifier’s “left” channel (non-inverting and inverting, plus analog
ground). As a first step, I tried asymetrically driving LINP (with
LINN tied to ground). Nothing came out of the speaker; evidently,
there is ample built-in fault-protection and shutdown mechanisms built
into the ESMT chip to combat such abuse.</p>

<p>Next, using an op-amp on a breadboard, I attached a very temporary
symmetrical driving circuit on the inputs. This did the trick of
making sound come out, and it did sound pretty good (no obvious noise,
distortion or interference), except that only the woofer was driven.
Ah, of course! The tweeter is wired to the other (“right”) channel! So
I would need to supply <em>two</em> symmetrical audio inputs to drive this
amp.  These would preferably be driven by an active loudspeaker filter
circuit that limits the frequency range for each driver.</p>

<p>Considering the need for so many “patch” wires and the prospect of
stuffing additional electronics into an already cramped box, this
route seemed less than optimal. I also briefly played with the thought
of keeping the digital-input amplifier; capturing the configuration
sent to it via I<sup>2</sup>C and duplicating that from some
microcontroller; then coming up with some way to drive the
I<sup>2</sup>S digital audio input… somehow. Replace the daughter
board? But too many unknowns remained, and I felt constrained by
choices already made by others.</p>

<h2 id="going-all-in">Going all-in</h2>

<p>At the same time, the initially dismissed prospect of completely
replacing the electronics started to look attractive. If I need to
build a bunch of active filter circuits to separate the frequency
bands <em>before</em> the power amps, sure I can add two power amps to that
lot… and throw out the existing board! Which is not especially
small, so there is plenty of real estate for its replacement.</p>

<p>And on the plus side, I could get rid of the idle power consumption of
a full-blown embedded computer system (complete with Bluetooth/WiFi
radio, so less EM pollution and potential interference), and less
dissipated heat (I could sense the closed back of the idling Uxbridge
get warm after half an hour or so). What’s not to like?</p>

<p>So let’s establish some requirements:</p>
<ul>
  <li>The PSU supplies 18V DC. The whole system needs to be single-supply.</li>
  <li>Analog RCA line input on the back. Air-tight construction.</li>
  <li>Active pre-amp filter with the customary crossover of about
2&nbsp;kHz.</li>
  <li>Possibly some further audio equalization / speaker compensation.</li>
  <li>Two power amplifiers, one for the woofer and one for the tweeter.</li>
  <li>Output impedance (both amps): 4Ω.</li>
  <li>Non-obvious thermal constraints: dissipation in a hermetically
sealed box…?</li>
  <li>Obvious mechanical constraints (board size and JST connectors).</li>
</ul>

<p>The first step in the circuit design (with the constraints on DC power
input and speaker impedance set in place) was to find a suitable power
amplifier architecture with actual, existing components. After very
little searching, I settled on the
<a href="https://git.hq.sig7.se/muxbridge-biamp.git/blob_plain/HEAD:/doc/contrib/LM1875.pdf">LM1875T</a>
which seemed like a safe bet and promised high-end audio quality.  The
datasheet even has a reference circuit for single-supply operation.</p>

<p>Next, I decided on the crossover filters. Again, after a little
reading up on this subject, I found no reason to search beyond the
ubiquitous 4-th order
<a href="https://linkwitzlab.com/filters.htm">Linkwitz-Riley</a> filter
architecture (two cascaded, identical Sallen-Key low-pass or high-pass
filters to provide a steepness of 24&nbsp;dB/octave) with the
theoretical advantage of the channels neatly summing to 0&nbsp;dB (in
phase) throughout the crossover range.</p>

<p>What op-amp to use? I picked the
<a href="https://git.hq.sig7.se/muxbridge-biamp.git/blob_plain/HEAD:/doc/contrib/LM833.pdf">LM833</a>,
not too expensive but quite capable with its 15&nbsp;MHz
gain-bandwidth, 7&nbsp;V/μs slew rate and 4.5&nbsp;nV/√Hz
voltage noise. This is certainly a low noise, high speed op-amp when
targeting the audio range, and as it is a dual op-amp, we can build a
complete Linkwitz-Riley high-pass or low-pass filter out of a single
piece.</p>

<h2 id="the-complete-circuit">The complete circuit</h2>

<p>At this point, there is nothing left to do but <a href="https://tomscii.sig7.se/images/muxbridge-biamp/rest.jpg">draw the rest of the
fucking owl</a>, so that is exactly
what I did. The complete schematic is available as a
<a href="https://git.hq.sig7.se/muxbridge-biamp.git/blob_plain/HEAD:/doc/schematic.pdf">PDF</a>;
below I will highlight the functional blocks one by one.</p>

<p>At all times, keep in mind that we are building an analog circuit with
op-amps, customarily fed with symmetrical supplies (with ground in the
middle). Due to the existing power supply, we need to make the whole
thing run from a single supply with respect to ground, and that is not
how these circuits are usually drawn. It’s a technical detail, but an
important one!</p>

<p>For this exact reason, let’s start with the virtual grounds for
supporting single supply operation:</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-vgnd.png"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-vgnd-thumb.jpg" alt=""></a><br>
<em>Virtual ground circuitry (click to enlarge)</em></p>

<p>We could be more fancy and use an active device (a dedicated
“rail-splitter” like the
<a href="https://www.ti.com/product/TLE2426">TLE2426</a>, or just a regular
op-amp) to lower the source impedances driving these grounds, but in
practice, given the tiny loads, a well bypassed, moderate impedance
source will do just fine. With a non-obvious CAVEAT: For preserving
adequate separation between the woofer and tweeter signal paths (or,
rather, preventing cross-talk via the virtual ground), we use two
separate virtual grounds, each dedicated to one signal path.</p>

<p>The single power rail VCC itself comes directly from the PSU connector
J1; it supplies the three op-amps, each decoupled with a 100&nbsp;nF
poly capacitor:</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-power.png"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-power-thumb.jpg" alt=""></a><br>
<em>Power input; op-amp supply &amp; decoupling (click to enlarge)</em></p>

<p>These are sort of trivial details, and are customarily omitted when
presenting analog circuits. It is important not to forget about
them. With these out of the way, let’s look at the meatier parts of
the circuit.</p>

<h2 id="active-filters">Active filters</h2>

<p>The incoming signal is AC-coupled into the circuit via C1, after which
R1 and R2 set the DC level to mid-supply (our virtual ground) for the
signal to ride from there on. C2, together with R3 and the source
impedance driving the line input, forms a first-order low-pass filter
(f<sub>c</sub>&nbsp;≈&nbsp;50&nbsp;kHz assuming a source
impedance of 600&nbsp;Ω) to eliminate any RF interference just
before the signal reaches the input follower U1A, which drives the
rest of the filter circuits with low impedance.</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-filters.png"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-filters-thumb.jpg" alt=""></a><br>
<em>Input buffer &amp; active filter schematics (click to enlarge)</em></p>

<p>From here, the signal feeds two downstream signal paths. The upper
one, built around U2B and U2A, consists of two cascaded Sallen-Key
high-pass filters forming a 4-th order Linkwitz-Riley high-pass with
24&nbsp;dB/octave steepness below its corner frequency. The passive
component values are optimized to allow realisation with uniform
values of commonly available high-quality polymer capacitors, and
relatively small-value resistors in order to keep thermal noise
contributions as low as feasible. This path ends in the signal TWR_IN,
driving the tweeter’s power amplifier.</p>

<p>The lower signal path begins with a low-shelving filter around U1B,
augmented with the divider-degenerating capacitor C7 to roll off DC
response to unity. The purpose of this shelving filter is to provide
emphasis towards the woofer’s lower end, in order to compensate its
inevitable rolloff. The component values are the result of simulation
and real-world tuning (as described below).</p>

<p>The bass-enhanced signal then goes through a Linkwitz-Riley low-pass
filter (around U3A and U3B), a close counterpart to the tweeter HPF.
Component values were guided by the same optimization criteria. The
LPF comes last so as to attenuate the noise of preceding stages. The
resulting signal WFR_IN drives the woofer’s power amplifier.</p>

<p>Note the nodes labeled VGNDT on R5 and R7: these are tied to a virtual
ground dedicated to tweeter-side circuitry, set at half-supply.  This
ensures correct single-supply operation of U2B and U2A, as well as
correct DC level on TWR_IN. In the woofer path, the equivalent circuit
points can be tied to the real ground, as the DC level on the “cold”
side of the capacitors C10 and C12 has no influence on the filter’s
operation. The DC level on WFR_IN is determined by the R1/R2 divider
right at the input; the whole signal path up to WFR_IN is DC-coupled
(with a DC transfer of unity) from there.</p>

<h3 id="spice-simulation">SPICE simulation</h3>

<p>To validate the above circuit, I first built a simulation model in the
excellent <a href="https://xschem.sourceforge.io/index.html">XSchem</a>, and
asked <a href="https://ngspice.sourceforge.io/">ngspice</a> to compute the
frequency and phase response on both outputs.</p>

<p><img src="https://tomscii.sig7.se/images/muxbridge-biamp/spice-ac.png" alt=""><br>
<em>AC simulation: magnitude and phase response of filter outputs</em></p>

<p>The (electrical) crossover frequency is 2&nbsp;kHz, with some slight
bump in the summed output (as evidenced by each channel being a bit
over -6&nbsp;dB). The <em>real</em> (acoustical) response will, however, also
be affected by driver response. According to listening tests, the
woofer’s high-frequency roll-off roughly compensates the “electrical”
bump in the crossover area.</p>

<p>What about the phase difference between the woofer and tweeter signal
paths? According to SPICE, at the crossover frequency the tweeter
output phase lags the woofer output by ~19°. That is equivalent to a
delay of 19/360 times one cycle duration at 2&nbsp;kHz, which works
out to around 26&nbsp;μs. Factoring in the speed of sound
(340&nbsp;m/s), this (electronic) delay is equivalent to an acoustic
propagation path difference of about 9&nbsp;mm.</p>

<p>In other words, the difference in signal propagation across the two
filters is equivalent to the tweeter being 9&nbsp;mm farther away from
the listener than the woofer. In reality, the tweeter is going to be a
bit closer to the listener, because the speakers will land on a table
below head height, and the tweeter is mounted higher up in the
enclosure. The exact geometry can vary quite a bit, but the geometric
path difference will be in the ballpark – <em>but with opposite
sign!</em></p>

<p>As a consequence, the filter delay does not pose a problem; on the
contrary, it might actually help the drivers’ sound waves arrive
perfectly in-phase around the crossover frequency. Given the inexact
nature of this problem (unknown variations in driver characteristics,
plus the uncontrolled acoustic environment), we won’t bother with a
delay compensator (allpass filter). It’s bound to be close to
“perfect” anyway.</p>

<h2 id="power-amplifiers">Power amplifiers</h2>

<p>The power amps for the tweeter and woofer are principally identical,
themselves closely following the single supply reference circuit in
the
<a href="https://git.hq.sig7.se/muxbridge-biamp.git/blob_plain/HEAD:/doc/contrib/LM1875.pdf">LM1875T</a>
datasheet. The voltage gain is set to 10 (via R16/R15 and R20/R19),
the lowest gain with guaranteed stability. A higher gain is not
desired, because the line input would then become overly sensitive
(its useful range, given the practical limitations on output volume,
would be too low).</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-power-amp.png"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/schematic-power-amp-thumb.jpg" alt=""></a><br>
<em>Power amplifier schematics (click to enlarge)</em></p>

<p>Between the amps, only capacitors differ in two positions. In both
cases, we exploit the fact that the tweeter amp, given its useful
frequency range, can get away with higher corner frequencies. The
feedback loop degeneration caps C15 and C20 roll off the gain to unity
at DC; here, C15 can be made significantly smaller than its
counterpart.  Similarly, the output coupling (DC-blocking) capacitors
C17 and C22 form high-pass filters together with the load impedance,
where we can again get away with a much higher corner frequency
(smaller capacitance) in the tweeter amp. We do not max out this
possibility (see the respective f<sub>c</sub> annotations), only to
the extent that a significantly cheaper and smaller component can be
used.  We choose high-quality capacitors specifically intended for
audio applications.</p>

<p>If you looked real close, you might have noticed one more discrepancy
across the amps: opposite polarities of output connectors J3 and J4.
That’s right, and reflect the fact that the Uxbridge driver cables
have their JST connectors crimped with opposite polarities; however,
both our amps are “straight” so one of them needs to have its output
polarity reversed.</p>

<p>What kind of output power can we expect? The PSU just clears the lower
end of the LM1875 supply range, so it’s going to be on the low
end. The low driver impedance (4Ω) certainly helps a bit.
Between the datasheet and some back of the envelope calculations, I
expect about 5W of peak output power per driver (in practice, this
applies to the woofer only; the tweeter will always be driven with
much less power).  That might seem low, but in practice, it is plenty
for near-field listening in a quiet room. Thankfully, the low supply
voltage also keeps dissipation down – a couple watts at most,
and a mere fraction of a watt idling.</p>

<h2 id="prototyping-and-tuning">Prototyping and tuning</h2>

<p>To validate the design in actual reality, I built a breadboard version
of the complete circuit, from line input to the actual speakers. To
ferret out any possible incompatibility, I powered it from the actual
Uxbridge PSU removed from one of the units.  This unit became my test
harness: I removed the original electronics, extended the speaker
wires and led them out via a small hole on the backplane (left in
place of the Bluetooth button). I fastened the backplane in place and
did my best to close the hole (with speaker wires protruding) using
some tape. This way I could evaluate circuit performance with the real
(non-ideal) speaker loads, together with real acoustics, and tune the
filters after listening to music and pure sine tones. I was also able
to A/B test, going back and forth between my circuit driving the
prepared (closed) enclosure and the other complete, intact Uxbridge
unit via Bluetooth.</p>

<p>I still haven’t built my first real DDS VFO / signal generator
instrument (it’s in the pipeline, should be complete any year now…).
For the time being, I reached for a “virtual” one by playing sine
frequencies via online tone generators (<a href="https://tonegen.net/">first</a>,
<a href="https://onlinetonegenerator.com/frequency-sweep-generator.html">second</a>).
I used them to establish general sanity, verify driver polarities, and
equalize levels through the crossover range. I also tuned the woofer
rolloff compensation filter with this method; I got satisfactory
results down to about 35&nbsp;Hz, which is on par with the original
unit. The upper end? Limited by my hearing abilities… N.B.: All
tuning and fiddling is already reflected in the circuits presented
above.</p>

<p>Speaking of A/B tests: I also listened to lots of music, mostly
assorted tracks and albums I enjoy and have been listening to all my
life across a wide range of equipment and acoustic environments. I
carefully compared the sound of the speakers; in a couple days, I
reached the point where I preferred the sound of the new circuit. I
believe it gives a flatter, more precise response especially in the
midrange, where the original Uxbridge sounded hollow. I’m no fan of
the “disco smile”; I prefer the mid to have some real bite.</p>

<p>Another reason I wanted a full prototype was to get a grip on the
thermal situation. Having done those back of the envelope estimates, I
was still quite uncertain about the amount of heat I could expect the
LM1875’s to dissipate, and wanted to gauge heatsink temperatures (with
the scientific “finger method”) both while idle and with realistic
listening volumes. My estimates were validated; the TO-220 heating
fins I planned for (and prototyped with) only got seriously warm at a
loudness level I could not hope to sustain without creating “social
problems”. Good, because there is not much point in putting a bigger
heatsink into the air-tight enclosure…</p>

<p>Apart from the sorry fact that I was listening in mono (and in a bad
way: only hearing one of the stereo channels!), everything seemed
rather promising. Now comes the part which is, by now, a routine job:
casting the circuit into permanent form by designing a professional
PCB.</p>

<h2 id="pcb-design">PCB design</h2>

<p>This is a small-ish analog circuit, and we have plenty of real estate!
We only need to match board size and hole patterns. We could go
high-tech and use SMT components, and easily reduce the PCB area by a
factor of two… but why bother?  All the components are readily
available, plugged into the breadboard. I would prefer to use them.</p>

<p>The complexity of this design is so low that the board is, in effect,
single layer. Almost all wiring is on the component side, the rest of
which is filled with a ground plane. The solder side is a complete
ground plane (except a single, short copper bridge connecting VCC
between C18 and C19). This double-sided, massive ground plane
contributes to the low noise and high performance of this amplifier.
A bunch of thermal vias under the heatsinks help the PCB take its part
in spreading and dissipating heat.</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/pcb.png"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/pcb-thumb.jpg" alt=""></a><br>
<em>Printed circuit board (click to enlarge)</em></p>

<p>The dimensions are about half of the original panel – call me a
dinosaur, but I see no need to <a href="https://tomscii.sig7.se/2024/03/SMT-and-the-ultimate-LCD-SPI-interface">design with
SMT</a> (requiring a
stencil mask for applying the paste) to make it even smaller!</p>

<p>Below, a side-by-side comparison of the new dumb analog dinosaur and
the original, fully digital smart technology:</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/panels-new-old.jpg"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/panels-new-old-thumb.jpg" alt=""></a><br>
<em>Electronics, new vs. old (click to enlarge)</em></p>

<h2 id="connectors-and-mechanics">Connectors and mechanics</h2>

<p>Given the already crimped plugs on the PSU and speaker cables, I
naturally wanted to keep the connectors on the new panel identical.
The DC power connector was easily identified as JST-VH, and I had no
trouble buying it. On the other hand, it took me some time to identify
the speaker connectors as JST-XA. Worse, my local parts store did not
carry it. The dimensions of the XA are rather similar to the more
common JST-XH, except for the pin spacing (2.5 vs. 2.54&nbsp;mm, not a
big deal on a 2-pin connector). A more important detail is that the XH
lacks the XA’s locking mechanism.  In the end, I prototyped with XH
(mating with the XA counterparts on the speaker wires). Eventually, I
de-soldered the XA sockets from the original boards so I could solder
them into my PCBs.</p>

<p>For the audio input, I picked a 2-pin JST-PH connector (2&nbsp;mm
pitch), using a matching plug with a pre-crimped short pair of wires.
The bare ends were soldered to the female panel-mount RCA connector
conveniently fastened into the backplane hole
(⌀&nbsp;=&nbsp;6.5&nbsp;mm) formerly occupied by the Bluetooth
button. The back of the RCA connector was filled with hot glue to make
it air-tight.</p>

<p>When the time has come to assemble my born-again speakers, it became
clear that there was some obstacle preventing the back side from
settling into place. At first, I feared the biggest capacitor (C22)
colliding with the woofer magnet (during the design process, I
convinced myself there was enough clearance, but now got the scare
– my 3D skills suck!).  Finally, it turned out that omitting the
small cut-out on the board outline (visible on the left edge of the
original panel) was a mistake. That space was taken by the plastic
stem receiving the middle-left Phillips screw (looking from behind the
box). The issue is clearly visible in the below photo (look at the
middle hole along the left edge):</p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/backplane-assembly.jpg"><img src="https://tomscii.sig7.se/images/muxbridge-biamp/backplane-assembly-thumb.jpg" alt=""></a><br>
<em>New panel in its place: can you spot the bug? (click to enlarge)</em></p>

<p><a href="https://tomscii.sig7.se/images/muxbridge-biamp/backplane-assembly-2.jpg">Another image</a> of
the second unit, exhibiting the same issue.</p>

<p>Well, out with the rasping set! I managed to remove just enough
material (about 2&nbsp;mm) from the plastic stem down to the required
depth to make space for the PCB edge. Plastic filings carefully
vacuumed out of the box. Success, with footnotes (there are <em>always</em>
footnotes)!</p>

<h2 id="conclusion">Conclusion</h2>

<p>In the past several weeks, I listened and re-listened to many of my
long-time favourite albums and all I can say is, I absolutely love the
sound of this pair of odd socks!  The listening experience is on par
with, or easily surpasses, any stereo I ever had (and I’ve had a few).
Even though I don’t have the means to measure, in the first hours of
listening I felt a dramatic step up in fidelity from the original
Uxbridge. I am convinced that tuning the active filters with the
speakers in the loop has given me a superior frequency response, and
the linear power amps at low power are likely to have less noise and
distortion. The sharp stereo imaging is another sign of high fidelity.
The fact that I got these “from the bin” for free (at least the
enclosures, power supplies and drivers) gives me a smile each time I
turn them on.</p>

<p>It appears that analog electronics in the audio range is more or less
a solved problem: discounting the obvious extremities of high power
(hundreds of watts) or really miniscule signal levels (microvolts), it
is not too difficult to create, with contemporary semiconductors, a
simple circuit charting seriously audiophile territory!</p>

<p>As always, the sources of this article (in this case, the KiCAD
hardware design plus XSchem workspace and ngspice simulation files)
are <a href="https://git.hq.sig7.se/muxbridge-biamp.git">published online</a>
with everything licensed under the terms of the very permissive MIT
license.</p>


  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: TypeScript/React/Vue Window Layout Manager (Tabs, Floating, Popouts) (107 pts)]]></title>
            <link>https://github.com/mathuo/dockview</link>
            <guid>42666492</guid>
            <pubDate>Sat, 11 Jan 2025 15:31:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mathuo/dockview">https://github.com/mathuo/dockview</a>, See on <a href="https://news.ycombinator.com/item?id=42666492">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p dir="auto"><h2 tabindex="-1" dir="auto">dockview</h2><a id="user-content-dockview" aria-label="Permalink: dockview" href="#dockview"></a></p>
<p dir="auto">Zero dependency layout manager supporting tabs, groups, grids and splitviews. Supports React, Vue and Vanilla TypeScript</p>
</div>
<hr>
<p dir="auto"><a href="https://www.npmjs.com/package/dockview" rel="nofollow"><img src="https://camo.githubusercontent.com/b3abfd21f5412229945ac452a4a9a1cf43afff3bf2b7e0fc8a51e736e07d6957/68747470733a2f2f62616467652e667572792e696f2f6a732f646f636b766965772e737667" alt="npm version" data-canonical-src="https://badge.fury.io/js/dockview.svg"></a>
<a href="https://www.npmjs.com/package/dockview" rel="nofollow"><img src="https://camo.githubusercontent.com/5ef1ae305fbf0e93605185ae7e681df2c517ec66b9a82967c924efe8525a2bab/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f646f636b76696577" alt="npm" data-canonical-src="https://img.shields.io/npm/dm/dockview"></a>
<a href="https://github.com/mathuo/dockview/actions?query=workflow%3ACI"><img src="https://github.com/mathuo/dockview/workflows/CI/badge.svg" alt="CI Build"></a>
<a href="https://sonarcloud.io/summary/overall?id=mathuo_dockview" rel="nofollow"><img src="https://camo.githubusercontent.com/290f766799c5c4b9d17db671992adad56c6d586207dc416ba5844d82332f26d3/68747470733a2f2f736f6e6172636c6f75642e696f2f6170692f70726f6a6563745f6261646765732f6d6561737572653f70726f6a6563743d6d617468756f5f646f636b76696577266d65747269633d636f766572616765" alt="Coverage" data-canonical-src="https://sonarcloud.io/api/project_badges/measure?project=mathuo_dockview&amp;metric=coverage"></a>
<a href="https://sonarcloud.io/summary/overall?id=mathuo_dockview" rel="nofollow"><img src="https://camo.githubusercontent.com/f5b1d1e9d93827e6b1f42a3861da644843ffeefbad1561143db0ab05f1dc77ac/68747470733a2f2f736f6e6172636c6f75642e696f2f6170692f70726f6a6563745f6261646765732f6d6561737572653f70726f6a6563743d6d617468756f5f646f636b76696577266d65747269633d616c6572745f737461747573" alt="Quality Gate Status" data-canonical-src="https://sonarcloud.io/api/project_badges/measure?project=mathuo_dockview&amp;metric=alert_status"></a>
<a href="https://bundlephobia.com/result?p=dockview" rel="nofollow"><img src="https://camo.githubusercontent.com/74986b2c390e2f9cd4c4607d9370f71bae318cdd7fc4738947b60bb110a561c2/68747470733a2f2f62616467656e2e6e65742f62756e646c6570686f6269612f6d696e7a69702f646f636b76696577" alt="Bundle Phobia" data-canonical-src="https://badgen.net/bundlephobia/minzip/dockview"></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mathuo/dockview/blob/master/packages/docs/static/img/splashscreen.gif"><img src="https://github.com/mathuo/dockview/raw/master/packages/docs/static/img/splashscreen.gif" alt="" data-animated-image=""></a></p>
<p dir="auto">Please see the website: <a href="https://dockview.dev/" rel="nofollow">https://dockview.dev</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Serialization / deserialization with full layout management</li>
<li>Support for split-views, grid-views and 'dockable' views</li>
<li>Themeable and customizable</li>
<li>Tab and Group docking / Drag n' Drop</li>
<li>Popout Windows</li>
<li>Floating Groups</li>
<li>Extensive API</li>
<li>Supports Shadow DOMs</li>
<li>High test coverage</li>
<li>Documentation website with live examples</li>
<li>Transparent builds and Code Analysis</li>
<li>Security at mind - verifed publishing and builds through GitHub Actions</li>
</ul>
<p dir="auto">Want to verify our builds? Go <a href="https://www.npmjs.com/package/dockview#Provenance" rel="nofollow">here</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A Better Log Service (124 pts)]]></title>
            <link>https://txtlog.net/</link>
            <guid>42666139</guid>
            <pubDate>Sat, 11 Jan 2025 14:34:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://txtlog.net/">https://txtlog.net/</a>, See on <a href="https://news.ycombinator.com/item?id=42666139">Hacker News</a></p>
Couldn't get https://txtlog.net/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Track your devices via Apple FindMy network in Go/TinyGo (170 pts)]]></title>
            <link>https://github.com/hybridgroup/go-haystack</link>
            <guid>42665367</guid>
            <pubDate>Sat, 11 Jan 2025 12:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hybridgroup/go-haystack">https://github.com/hybridgroup/go-haystack</a>, See on <a href="https://news.ycombinator.com/item?id=42665367">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">go-haystack</h2><a id="user-content-go-haystack" aria-label="Permalink: go-haystack" href="#go-haystack"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hybridgroup/go-haystack/blob/main/images/go-haystack.png"><img src="https://github.com/hybridgroup/go-haystack/raw/main/images/go-haystack.png" alt="Go Haystack gopher"></a></p>
<p dir="auto">Go Haystack lets you track personal Bluetooth devices via Apple's massive <a href="https://developer.apple.com/find-my/" rel="nofollow">"Find My"</a> network.</p>
<p dir="auto">It uses <a href="https://github.com/seemoo-lab/openhaystack">OpenHaystack</a> together with <a href="https://github.com/dchristl/macless-haystack">Macless-Haystack</a> to help you setup a custom FindMy network with tools written in Go/TinyGo. No Apple hardware required!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hybridgroup/go-haystack/blob/main/images/macless-haystack.png"><img src="https://github.com/hybridgroup/go-haystack/raw/main/images/macless-haystack.png" alt="image of macless-haystack web UI"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build Your Own Beacon</h2><a id="user-content-build-your-own-beacon" aria-label="Permalink: Build Your Own Beacon" href="#build-your-own-beacon"></a></p>
<p dir="auto">This package provides firmware written using <a href="https://tinygo.org/" rel="nofollow">TinyGo</a> and the <a href="https://github.com/tinygo-org/bluetooth">TinyGo Bluetooth package</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hybridgroup/go-haystack/blob/main/images/tinygo-beacons.jpg"><img src="https://github.com/hybridgroup/go-haystack/raw/main/images/tinygo-beacons.jpg" alt="tinygo beacons"></a></p>
<p dir="auto">As a result, any of the following hardware devices should work:</p>
<ul dir="auto">
<li>Adafruit Bluefruit boards using nRF SoftDevice - <a href="https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#adafruit-bluefruit-boards">https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#adafruit-bluefruit-boards</a></li>
<li>BBC Microbit using nRF SoftDevice - <a href="https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#bbc-microbit">https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#bbc-microbit</a></li>
<li>Other Nordic Semi SoftDevice boards - <a href="https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#flashing-the-softdevice-on-other-boards">https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#flashing-the-softdevice-on-other-boards</a></li>
<li>Boards using the NINA-FW with an ESP32 co-processor - <a href="https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#esp32-nina">https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#esp32-nina</a></li>
<li>Boards such as the RP2040 Pico-W using the CYW43439 co-processor - <a href="https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#cyw43439-rp2040-w">https://github.com/tinygo-org/bluetooth?tab=readme-ov-file#cyw43439-rp2040-w</a></li>
</ul>
<p dir="auto">You can also run the beacon code on any Linux that has Bluetooth hardware, such as a Raspberry Pi or other embedded system.</p>
<p dir="auto">The beacon code is located in the <a href="https://github.com/hybridgroup/go-haystack/blob/main/firmware">firmware</a> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">TinyScan</h2><a id="user-content-tinyscan" aria-label="Permalink: TinyScan" href="#tinyscan"></a></p>
<p dir="auto">Go Haystack also includes TinyScan, a hardware scanner for local devices.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/hybridgroup/go-haystack/blob/main/images/tinyscan.gif"><img src="https://github.com/hybridgroup/go-haystack/raw/main/images/tinyscan.gif" alt="tinyscan" data-animated-image=""></a></p>
<p dir="auto">TinyScan runs on several different microcontrollers boards with Bluetooth and miniature displays, such as those made by <a href="https://www.adafruit.com/" rel="nofollow">Adafruit</a> and <a href="https://shop.pimoroni.com/" rel="nofollow">Pimoroni</a></p>
<p dir="auto">The TinyScan code is located in the <a href="https://github.com/hybridgroup/go-haystack/blob/main/tinyscan">tinyscan</a> directory in this repository.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to install</h2><a id="user-content-how-to-install" aria-label="Permalink: How to install" href="#how-to-install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Apple ID</h3><a id="user-content-apple-id" aria-label="Permalink: Apple ID" href="#apple-id"></a></p>
<p dir="auto">You must have an Apple-ID with 2FA enabled. Only sms/text message as second factor is supported!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">anisette-v3-server</h3><a id="user-content-anisette-v3-server" aria-label="Permalink: anisette-v3-server" href="#anisette-v3-server"></a></p>
<p dir="auto">Start <a href="https://github.com/Dadoum/anisette-v3-server"><code>anisette-v3-server</code></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker network create mh-network
docker run -d --restart always --name anisette -p 6969:6969 --volume anisette-v3_data:/home/Alcoholic/.config/anisette-v3 --network mh-network dadoum/anisette-v3-server"><pre>docker network create mh-network
docker run -d --restart always --name anisette -p 6969:6969 --volume anisette-v3_data:/home/Alcoholic/.config/anisette-v3 --network mh-network dadoum/anisette-v3-server</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">macless-haystack</h3><a id="user-content-macless-haystack" aria-label="Permalink: macless-haystack" href="#macless-haystack"></a></p>
<ol dir="auto">
<li>Start and set up your Macless Haystack endpoint in interactive mode:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -it --restart unless-stopped --name macless-haystack -p 6176:6176 --volume mh_data:/app/endpoint/data --network mh-network christld/macless-haystack"><pre>docker run -it --restart unless-stopped --name macless-haystack -p 6176:6176 --volume mh_data:/app/endpoint/data --network mh-network christld/macless-haystack</pre></div>
<p dir="auto"><h6 tabindex="-1" dir="auto">You will be asked for your Apple-ID, password and your 2FA. If you see <code>serving at port 6176 over HTTP</code> you have all set up correctly</h6><a id="user-content-you-will-be-asked-for-your-apple-id-password-and-your-2fa-if-you-see-serving-at-port-6176-over-http-you-have-all-set-up-correctly" aria-label="Permalink: You will be asked for your Apple-ID, password and your 2FA. If you see serving at port 6176 over HTTP you have all set up correctly" href="#you-will-be-asked-for-your-apple-id-password-and-your-2fa-if-you-see-serving-at-port-6176-over-http-you-have-all-set-up-correctly"></a></p>
<p dir="auto">Hit ctrl-C to exit the process once it has been configured.</p>
<ol start="2" dir="auto">
<li>Restart the macless-haystack server</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="docker restart macless-haystack"><pre>docker restart macless-haystack</pre></div>
<p dir="auto">See <a href="https://github.com/dchristl/macless-haystack/blob/main/README.md#server-setup">https://github.com/dchristl/macless-haystack/blob/main/README.md#server-setup</a> for the original instructions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">go-haystack</h3><a id="user-content-go-haystack-1" aria-label="Permalink: go-haystack" href="#go-haystack-1"></a></p>
<p dir="auto">Install the go-haystack command line tool</p>
<div dir="auto" data-snippet-clipboard-copy-content="go install github.com/hybridgroup/go-haystack/cmd/haystack@latest"><pre>go install github.com/hybridgroup/go-haystack/cmd/haystack@latest</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to use" href="#how-to-use"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scanning for local devices</h3><a id="user-content-scanning-for-local-devices" aria-label="Permalink: Scanning for local devices" href="#scanning-for-local-devices"></a></p>

<p dir="auto">Should return any local devices within range:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ haystack scan                                                                                                             
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
FE:B0:67:9B:9A:5C -55 feb0679b9a5c55b1141c5cc6c8f65224ae9bc6bc2d998ccf5c56a02d - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
FE:B0:67:9B:9A:5C -56 feb0679b9a5c55b1141c5cc6c8f65224ae9bc6bc2d998ccf5c56a02d - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
FE:B0:67:9B:9A:5C -56 feb0679b9a5c55b1141c5cc6c8f65224ae9bc6bc2d998ccf5c56a02d - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full"><pre>$ haystack scan                                                                                                             
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
FE:B0:67:9B:9A:5C -55 feb0679b9a5c55b1141c5cc6c8f65224ae9bc6bc2d998ccf5c56a02d - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
FE:B0:67:9B:9A:5C -56 feb0679b9a5c55b1141c5cc6c8f65224ae9bc6bc2d998ccf5c56a02d - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full
FE:B0:67:9B:9A:5C -56 feb0679b9a5c55b1141c5cc6c8f65224ae9bc6bc2d998ccf5c56a02d - battery full
CE:8B:AD:5F:8A:02 -53 ce8bad5f8a0271538ff5afda87498cb067e9a020d6e4167801d55d83 - battery full</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Adding a new device</h3><a id="user-content-adding-a-new-device" aria-label="Permalink: Adding a new device" href="#adding-a-new-device"></a></p>
<ol dir="auto">
<li>Generate keys for a device</li>
</ol>

<p dir="auto">The keys will be saved in a file named <code>DEVICENAME.keys</code> and the configuration file for Haystack will be saved in <code>DEVICENAME.json</code>. Replace "DEVICENAME" with whatever you want to name the actual device.</p>
<ol start="2" dir="auto">
<li>Flash the hardware with the TinyGo target and the name of your device.</li>
</ol>
<p dir="auto">For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="haystack flash DEVICENAME nano-rp2040"><pre>haystack flash DEVICENAME nano-rp2040</pre></div>
<p dir="auto">This will use TinyGo to compile the firmware using your keys, and then flash it to the device. See <a href="https://tinygo.org/getting-started/overview/" rel="nofollow">https://tinygo.org/getting-started/overview/</a> for more information about TinyGo.</p>
<ol start="3" dir="auto">
<li>Upload the JSON file for that device to your running instance of <code>macless-haystack</code> using the web UI.</li>
</ol>
<p dir="auto">Point your web browser to <a href="https://dchristl.github.io/macless-haystack/" rel="nofollow"><code>https://dchristl.github.io/macless-haystack/</code></a> which is a single-page web application that only reads/writes local data. Click on the link for "Accessories", then on the "+" button. Choose the <code>DEVICENAME.json</code> file for your device.</p>
<p dir="auto">That's it, your device is now setup.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Objects in your data may be closer than they appear</h2><a id="user-content-objects-in-your-data-may-be-closer-than-they-appear" aria-label="Permalink: Objects in your data may be closer than they appear" href="#objects-in-your-data-may-be-closer-than-they-appear"></a></p>
<p dir="auto">Eventually, if your device is in range of any iPhone, they will appear in your Macless-Haystack data in the web UI.</p>
<p dir="auto">Note that it might take a while for the first data to show up.</p>
<p dir="auto">Have fun, be good!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The State of Vim (141 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1002342/a8d8a17f30968b93/</link>
            <guid>42665222</guid>
            <pubDate>Sat, 11 Jan 2025 11:42:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1002342/a8d8a17f30968b93/">https://lwn.net/SubscriberLink/1002342/a8d8a17f30968b93/</a>, See on <a href="https://news.ycombinator.com/item?id=42665222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>The death of Bram Moolenaar, <a href="https://www.vim.org/">Vim</a>
founder and benevolent dictator for life (BDFL), in 2023 sent a shock
through the community, and raised concern about the future of the
project. At <a href="https://vimconf.org/">VimConf</a> 2024 in
November, current Vim maintainer Christian Brabandt delivered a
keynote on "<q>the new Vim project</q>" that detailed how the
community has reorganized itself to continue maintaining Vim and what
the future looks like.</p> <h4>Vim after Bram</h4>

<p>Brabandt began with his history with Vim: he has been involved in
Vim since&nbsp;2006, and said his first commit to the project was made
in the&nbsp;7.0/7.1 days (sometime around 2006). He started by
contributing small patches and fixes, and then contributed larger
features such as the <a href="https://vimhelp.org/visual.txt.html#gn"><tt>gn</tt> and
<tt>gN</tt> commands</a>, which combine searching and visual-mode
selection, improved cryptographic support using <a href="https://doc.libsodium.org/"><tt>libsodium</tt></a>, 
maintained the Vim <a href="https://appimage.org/">AppImage</a>, and
more. He said he became less active in the project around 2022 due to
personal and work-related reasons.</p>

<p>That changed in August&nbsp;2023, when
Moolenaar <a href="https://lwn.net/Articles/940551/">passed
away</a>. Moolenaar had been the maintainer of Vim for more than&nbsp;30
years; while he had added Brabandt and Ken Takata as
co-maintainers of Vim in the years before, most development still
flowed through him. With his death, a considerable amount of
knowledge was lost—but Brabandt and others stepped up to keep the
project alive.</p>

<blockquote>
<b>No slop, all substance: subscribe to LWN today</b>
<p>
LWN has always been about quality over quantity; we need your help
to continue publishing in-depth, reader-focused articles about Linux
and the free-software community. Please subscribe today to support our work
and keep LWN on the air; we are offering <a href="https://lwn.net/Promo/no-slop/claim">a free one-month trial subscription</a> to get you started.
</p></blockquote>


<p>Moolenaar was the only owner of the Vim GitHub organization at the
time, so only his account could change certain
settings. Initially, contributors tried to use the GitHub <a href="https://github.com/github/docs/blob/main/content/site-policy/other-site-policies/github-deceased-user-policy.md">deceased
user policy</a> to add owners to the organization. That was quite an
involved process, and it soon became apparent that the end result
would be the deactivation of Moolenaar's account. Having Moolenaar's
account be accessible by his family was important, so they abandoned
that approach, and instead the family granted access to it as needed
for organizational changes.</p>

<p>Charles Campbell (known as "<a href="http://www.drchip.org/astronaut/vim/index.html">Dr Chip</a>"), a
Vim contributor for more than&nbsp;25 years also decided to retire
soon after Moolenaar's death. His departure was followed by an
expansion of the team of maintainers, as Yegappan Lakshmanan joined
it, with Dominique Pellé, Doug Kearns, and GitHub users "glepnir",
"mattn", and "zeertzjq" joining soon after.</p>

<h4>More than just the source code</h4>

<p>He stressed that maintaining Vim is not just about the source
code. There are quite a few other things to be managed, such as the
Vim web site, FTP server, security disclosures, Vim communities on
other sites such as <a href="https://www.reddit.com/r/vim/">Reddit</a> and
<a href="https://vi.stackexchange.com/">Stack Exchange</a>, and
more.</p>

<p>Vim's site needed work. The design, and most of the code,
had been unchanged for quite a while—until 2023, it was based on
PHP&nbsp;5. In recent times, there had been a few occasions where the
web site was unstable, and so he started looking for a new host
in&nbsp;2024. The move involved an upgrade to PHP&nbsp;8, for which
some of the code had to be rewritten. Brabandt thanked Mark
Schöchlin, who stepped up to take care of all this.</p>

<p>He acknowledged that the design has been pretty much unchanged
since&nbsp;2001, doesn't look modern, and can be scary to new
users. There has been some work on redesigning it, but the first
attempt hasn't been that successful. He prioritizes consistency and
does not wish to scare away longtime users.</p>

<p>DNS was also troublesome—the <tt>vim.org</tt>
domain was managed by Stefan Zehl, but Moolenaar also owned a number
of other domains such as <tt>vim8.org</tt>, <tt>vim9.org</tt>,
etc. Thankfully, SSL certificates were already managed using Let's
Encrypt, so Brabandt had no problems there. Several email addresses, such as
<tt>bram@vim.org</tt>, <tt>bugs@vim.org</tt>, etc., were
forwarded to Moolenaar's personal email; those have since been updated
to point to Brabandt's address instead. The FTP server was hosted by
<a href="https://nluug.nl/">NLUUG</a>, but he decided to retire
it and says that he hasn't received any complaints so far.</p>

<h4>ICCF Holland</h4>

<p>As readers might know, Vim is <a href="https://vimhelp.org/uganda.txt.html#license">charityware</a>,
and the charity of choice is <a href="https://iccf-holland.org/">ICCF
Holland</a>, founded by Moolenaar. Brabandt said that the ICCF is very
much alive, and plans to reorganize and restructure itself. Quite a
few users started donating after Moolenaar's passing, and
in&nbsp;2023, it raised about €90,000. The project plans to continue
to work with ICCF and doesn't want to change ICCF's association with
Vim. He noted that there is no sponsorship for the maintainers, all of
whom are working for free. Traditionally, all money raised has been
given to the ICCF and he has no plans to change that. Brabandt
said he earns enough from his job that he doesn't need assistance to
work on Vim, so he's happy to let all donations go to ICCF.</p>

<p>As an incentive to donate, Moolenaar had allowed people who donated
to ICCF to vote on Vim feature requests. Donors to the ICCF could link
to their Vim.org account when donating, and then vote on
features. This is one aspect that he no longer sees a need for,
now that issues and enhancements are discussed on GitHub, and so has
decided to shut this down. Linking the accounts and donations was also
not easy for Brabandt—he was not sure how Moolenaar did this in
the past.</p>

<h4>Communication channels</h4>

<p>He also talked about the community centered around the Vim
mailing lists, which are hosted on Google Groups. In May&nbsp;2024,
he <a href="https://groups.google.com/g/vim_use/c/skARx2yAEWc/m/U69NrKAgAgAJ">received
an automated message</a> from Google informing him that all
content from the vim-dev list had been blocked due to spam or
malware. This caused a fair bit of trouble, and while it was
restored in around a day or so, he still does not know what the
exact problem was. There has been some consideration of self-hosting the
list, but one drawback is that everyone would have to sign up
again. The mailing list is no longer that active now, with more of the
community conversations happening on Reddit or Stack Exchange.</p>

<p>Security reporting had to be addressed as well. A couple of years
ago, people were reporting issues on <a href="https://huntr.com/repos/vim/vim">the Huntr platform</a>. There
were quite a few open issues which have since been taken care
of. Huntr was acquired by another company in&nbsp;2023, which
refocused it entirely on AI and shut down general open-source
vulnerability reporting.</p>

<p>Now, Vim is accepting security reports via email or <a href="https://github.com/vim/vim/security">GitHub</a>, and publishing
vulnerabilities via GitHub security advisories. There is a
private mailing list for as-yet unpublished security issues, and
emails are forwarded to all maintainers. Brabandt has started adding a
<tt>[security]</tt> tag to commit messages for marking security fixes,
and such commits are announced on the <tt>oss-security</tt> list (the
<a href="https://lwn.net/ml/all/ZwKwrSltz1Zj7wCR@256bit.org">most
recent</a> being from October) and
to maintainers of distribution packages.</p>

<h4>Maintenance mode</h4>

<p>Brabandt then showed the contribution graph, to demonstrate that
development did not stop after Moolenaar passed away. There was a
slowdown as Moolenaar's health deteriorated, and then a spike as
he cleaned up the open pull requests (PRs). <a href="https://www.vim.org/vim-9.1-released.php">Version&nbsp;9.1</a>,
dedicated to Moolenaar, was released on
January&nbsp;2,&nbsp;2024—about four months after his
passing.</p>

<p>The&nbsp;9.1 release included improvements to <a href="https://vimhelp.org/textprop.txt.html#virtual-text">virtual text</a> (which
enables completion suggestions and such to appear in the
editing area, while not being part of the actual text), smooth
scrolling, and OpenVMS support. After&nbsp;9.1, he started adding
more potentially controversial changes, such as support
for <a href="https://specifications.freedesktop.org/basedir-spec/latest/">the
XDG base directory specification</a>. Now Vim does not need to litter
your top-level home directory: <tt>~/.vimrc</tt>
or
<tt>~/.vim/vimrc</tt> still work, but <a href="https://vimhelp.org/starting.txt.html#xdg-vimrc"><tt>$XDG_CONFIG_HOME/vim/vimrc</tt></a>
will now work if neither of the above are present. Another such
change is Wayland support. It is not complete yet, and he says he is
not sure whether remaining problems with clipboard support are Vim bugs or 
Wayland ones.</p>

<p>As he went through the backlog of PRs, he started developing
a policy for merging PRs, prioritizing the need to test things well.
Tests are now running with continuous integration (CI). He said that
it's also important to have good documentation.</p>

<p>Vim has interfaces to quite a few languages, including
Python&nbsp;2 and&nbsp;3, Ruby, Lua, Tcl, and MzScheme. But Brabandt
isn't sure which of these are really needed these days. For example,
Python&nbsp;2, Tcl, and MzScheme (which does not build
with the latest version of the language) might need to be retired to
reduce the maintenance burden. Other areas to improve include the GUI
(GTK&nbsp;4 has been around for a while, <a href="https://github.com/vim/vim/issues/8038">but Vim does not use
it</a> yet), support for advanced terminal features, and better spell
checking (which has largely remained unchanged since
Vim&nbsp;7). Support for the <a href="https://en.wikipedia.org/wiki/Tree-sitter_%28parser_generator%29">tree-sitter</a>
parser generator is wished-for, but it is controversial, and he does not see it coming to Vim soon.</p>

<p>He knows there have been some significant changes in Neovim, but
he's not sure how many of those can come to Vim. There have been small
changes in Vim, but for major changes, you need community support. He
does not want to make backward-incompatible changes and is quite
hesitant to merge changes that might break things. He said he has to
keep in the mind the whole picture, especially the expectations of
users, when dealing with PRs. Currently, he said that Vim is
more-or-less in maintenance mode.</p>

<p>He said he has created an internal repository to keep track of
stakeholders and to ensure that if something were to happen to him,
other maintainers could pick up where he left off.</p>

<p>Brabandt recommended that those new to the project 
start by making small contributions and becoming familiar with
the codebase. He had some pointers for developers. He said it is
important to use a defensive style with C to ensure that new bugs
aren't being introduced. One should use <a href="https://scan.coverity.com/">Coverity</a>, a static-analysis
tool, to scan for defects. Some parts of the Vim codebase are complex,
he said, and need to be refactored into more manageable units if
possible.</p>

<p>Maintaining Vim is a full-time job, he said, and it is not only
about maintaining the code, but also the community—managing
expectations and listening to users' needs. He has to understand the
community: what does it want Vim to be? An IDE? Bug-for-bug
compatibility with old Vim? How can we
make <a href="https://vimhelp.org/vim9.txt.html#Vim9-script">Vim9 script</a>, the
new Vim scripting language, more widely used? How can we ensure that the
Vim community remains healthy? He ended his talk by thanking all
the Vim contributors and then took a few questions.</p>

<h4>Questions</h4>

<p>One audience member asked about the difference between Vim and
Neovim's maintenance model. Since most PRs are still merged by
Brabandt, would that make him the new <a href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life">BDFL</a> for Vim?</p>

<p>Brabandt emphatically denied being a BDFL. Currently, he merges
most changes because the version number has to be incremented with
each change, so multiple people merging can introduce
conflicts. However, when he was on vacation, he handed over the main
maintainership to Lakshmanan. He emphasized that it's a community
project, and he listens to the community before making decisions. It
just happens that at this time the other maintainers don't want to
merge changes themselves and instead defer to Brabandt, which is fine
with him.</p>

<p>Another member of the audience wondered about language barriers,
since there are many Japanese members of the Vim community as well as
many languages in Europe, etc. Brabandt answered that, as an
international project, the primary language for working on Vim is
English. He also noted that it is easier these days to collaborate
across languages thanks to ChatGPT and translation tools, but it still
happens that some users do not communicate in English well, and that
makes it harder to understand their needs.</p>

<h4>The rest of VimConf 2024</h4>

<p>VimConf was <a href="https://vimconf.org/2013/">first held in&nbsp;2013</a> by the
Japanese Vim user group <a href="https://vim-jp.org/">vim-jp</a>. Since then, the group has organized
it every year, until&nbsp;2020 when VimConf was canceled due to COVID.
After a hiatus, it resumed in&nbsp;2023 with a scaled-down version. The
full-fledged edition returned to Akihabara, Tokyo on
November&nbsp;23,&nbsp;2024.</p>

<p>Even though most of the organizers and
attendees are Japanese, VimConf strives to be welcoming to
all. Presentation materials are expected to be in English, and live
translation is provided in both Japanese and English for keynotes and
regular presentations, except for lightning talks. PDFs for the talks
are available on <a href="https://vimconf.org/2024/">VimConf's
website</a>, and all of the talks are now on <a href="https://www.youtube.com/playlist?list=PLx8bw5NQypsmPvVXXRVmF7bvCjFKv1MuN">YouTube</a>.</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Mohanan_Murukesh">Mohanan, Murukesh</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ingrid Daubechies Awarded National Medal of Science (102 pts)]]></title>
            <link>https://today.duke.edu/2025/01/ingrid-daubechies-awarded-national-medal-science</link>
            <guid>42664893</guid>
            <pubDate>Sat, 11 Jan 2025 10:35:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://today.duke.edu/2025/01/ingrid-daubechies-awarded-national-medal-science">https://today.duke.edu/2025/01/ingrid-daubechies-awarded-national-medal-science</a>, See on <a href="https://news.ycombinator.com/item?id=42664893">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>President Joe Biden also announced that Duke alumnus and former trustee chair David Rubenstein will receive the Presidential Medal of Freedom, and Kristina Johnson, the former dean of the Pratt School of Engineering, will receive the National Medal of Technology and Innovation.</p><p>In addition, Duke alumni Eleanor Smeal and Ted Kaufman received the Presidential Citizens Medal.</p><p>The Medal of Freedom is the country’s highest civilian honor. Rubenstein and 18 others will be presented the award in a White House ceremony on Saturday.</p><p>A University Medal winner, Rubenstein, T’70,  has made a mark at Duke and across the country with his philanthropy. He has supported the restoration of historic landmarks and cultural institutions, including the Kennedy Center and Monticello. </p><p>Johnson, a pioneer in applications of liquid crystals, including micro displays for high-definition projection television, served as Pratt dean from 1999 to 2007. She left Duke to become provost of Johns Hopkins University and has also served as chancellor of the State University of New York and president of Ohio State University.</p><p>Women’s rights activist Eleanor Smeal, ’61, is the former president of the National Organization for Women. She received a Duke honorary degree in 1991.</p><p>Ted Kaufman, E ’60, was honored for his national service, including as U.S. senator from Delaware. Kaufman taught classes at Duke in law, public policy and business.  He served as co-chair of Duke’s Center for the Study of the Congress from 1995-99.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PrivTracker – Private BitTorrent tracker for everyone (106 pts)]]></title>
            <link>https://privtracker.com/</link>
            <guid>42664409</guid>
            <pubDate>Sat, 11 Jan 2025 08:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://privtracker.com/">https://privtracker.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42664409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<h2>PrivTracker</h2>
		
		<p>
			PrivTracker allows to share torrent files just with your friends, nobody else.
			Unlike public trackers, it shares peers only within a group which is using the same Announce URL.
			It really works like a private tracker, but can be generated with one click of a button.
		</p>

		
		
		<h2>How to create private torrent?</h2>
		<h3>Using <a href="https://transmissionbt.com/" target="_blank">transmission</a> on Linux:</h3>
		<ul>
			<li>File <b>→</b> New…</li>
			<li>Select file to share</li>
			<li>In <b>Trackers</b> field enter <code>https://{{hostname}}/{{room}}/announce</code></li>
			<li>Select <b>Private torrent</b></li>
			<li>Click <b>New</b></li>
			<li>Click <b>Add</b> in next window</li>
			<li>Click <b>Open</b> to start seeding</li>
			<li>Done. Now you can send torrent file to your friends…</li>
		</ul>
		<p><img src="https://privtracker.com/new_torrent_gtk.png" alt="New Torrent screenshot"></p><h3>Using <a href="https://transmissionbt.com/" target="_blank">transmission</a> on Mac:</h3>
		<ul>
			<li>File <b>→</b> Create Torrent File…</li>
			<li>Select file to share</li>
			<li>Click <b>+</b> under <b>Trackers</b> field and enter <code>https://{{hostname}}/{{room}}/announce</code></li>
			<li>Select <b>Private</b>
			</li><li>Select <b>Open when created</b></li>
			<li>Click <b>Create</b></li>
			<li>Click <b>Add</b> to start seeding</li>
			<li>Done. Now you can send torrent file to your friends…</li>
		</ul>
		<p><img src="https://privtracker.com/new_torrent_mac.png" alt="New Torrent screenshot">

	</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly All Binary Searches and Mergesorts Are Broken (2006) (148 pts)]]></title>
            <link>https://research.google/blog/extra-extra-read-all-about-it-nearly-all-binary-searches-and-mergesorts-are-broken/</link>
            <guid>42664400</guid>
            <pubDate>Sat, 11 Jan 2025 08:46:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/extra-extra-read-all-about-it-nearly-all-binary-searches-and-mergesorts-are-broken/">https://research.google/blog/extra-extra-read-all-about-it-nearly-all-binary-searches-and-mergesorts-are-broken/</a>, See on <a href="https://news.ycombinator.com/item?id=42664400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-id="rich_text" data-gt-component-name="" data-gt-publish-date="20060602">
    




    <div><p>I remember vividly Jon Bentley's first Algorithms lecture at CMU, where he asked all of us incoming Ph.D. students to write a binary search, and then dissected one of our implementations in front of the class. Of course it was broken, as were most of our implementations. This made a real impression on me, as did the treatment of this material in his wonderful <em>Programming Pearls</em> (Addison-Wesley, 1986; Second Edition, 2000). The key lesson was to carefully consider the invariants in your programs.</p><p>Fast forward to 2006. I was shocked to learn that the binary search program that Bentley proved correct and subsequently tested in Chapter 5 of <em>Programming Pearls</em> contains a bug. Once I tell you what it is, you will understand why it escaped detection for two decades. Lest you think I'm picking on Bentley, let me tell you how I discovered the bug: The version of binary search that I wrote for the JDK contained the same bug. It was reported to Sun recently when it broke someone's program, after lying in wait for nine years or so.</p><p>So what's the bug? Here's a standard binary search, in Java. (It's one that I wrote for the <code>java.util.Arrays</code>):</p></div>
<pre>1:     public static int binarySearch(int[] a, int key) {<br>2:         int low = 0;<br>3:         int high = a.length - 1;<br>4:<br>5:         while (low &lt;= high) {<br>6:             int mid = (low + high) / 2;<br>7:             int midVal = a[mid];<br>8:<br>9:             if (midVal &lt; key)<br>10:                 low = mid + 1<br>11:             else if (midVal &gt; key)<br>12:                 high = mid - 1;<br>13:             else<br>14:                 return mid; // key found<br>15:         }<br>16:         return -(low + 1);  // key not found.<br>17:     }</pre>
<p><br>The bug is in this line:</p>
<pre> 6:             int mid =(low + high) / 2;</pre>
<div><p>In <em>Programming Pearls</em> Bentley says that the analogous line "sets m to the average of l and u, truncated down to the nearest integer." On the face of it, this assertion might appear correct, but it fails for large values of the <code>int</code> variables <code>low</code> and <code>high</code>. Specifically, it fails if the sum of <code>low</code> and <code>high</code> is greater than the maximum positive <code>int</code> value (2<sup>31</sup> - 1). The sum overflows to a negative value, and the value stays negative when divided by two. In C this causes an array index out of bounds with unpredictable results. In Java, it throws <code>ArrayIndexOutOfBoundsException</code>.</p><p>This bug can manifest itself for arrays whose length (in elements) is 2<sup>30</sup> or greater (roughly a billion elements). This was inconceivable back in the '80s, when <em>Programming Pearls</em> was written, but it is common these days at Google and other places. In <em>Programming Pearls</em>, Bentley says "While the first binary search was published in 1946, the first binary search that works correctly for all values of <span>n</span> did not appear until 1962." The truth is, very few correct versions have ever been published, at least in mainstream programming languages.</p><p>So what's the best way to fix the bug? Here's one way:</p></div>
<pre> 6:             int mid = low + ((high - low) / 2);</pre>
<p><br>Probably faster, and arguably as clear is:</p>
<pre> 6:             int mid = (low + high) &gt;&gt;&gt; 1;</pre>
<p><br>In C and C++ (where you don't have the <code>&gt;&gt;&gt;</code> operator), you can do this:</p>
<pre> 6:             mid = ((unsigned int)low + (unsigned int)high)) &gt;&gt; 1;</pre>
<div><p>And now we <em>know</em> the binary search is bug-free, right? Well, we strongly suspect so, but we don't know. It is not sufficient merely to prove a program correct; you have to test it too. Moreover, to be really certain that a program is correct, you have to test it for all possible input values, but this is seldom feasible. With concurrent programs, it's even worse: You have to test for all internal states, which is, for all practical purposes, impossible.</p><p>The binary-search bug applies equally to mergesort, and to other divide-and-conquer algorithms. If you have any code that implements one of these algorithms, fix it now before it blows up. The general lesson that I take away from this bug is humility: It is hard to write even the smallest piece of code correctly, and our whole world runs on big, complex pieces of code.</p><p>We programmers need all the help we can get, and we should never assume otherwise. Careful design is great. Testing is great. Formal methods are great. Code reviews are great. Static analysis is great. But none of these things alone are sufficient to eliminate bugs: They will always be with us. A bug can exist for half a century despite our best efforts to exterminate it. We must program carefully, defensively, and remain ever vigilant.</p><p><span>Update 17 Feb 2008</span>: Thanks to Antoine Trux, Principal Member of Engineering Staff at Nokia Research Center Finland for pointing out that the original proposed fix for C and C++ (Line 6), was not guaranteed to work by the relevant C99 standard (<span>INTERNATIONAL STANDARD - ISO/IEC - 9899 - Second edition - 1999-12-01</span>, <a href="http://3.4.3.3/" target="_blank" rel="noopener noreferrer">3.4.3.3</a>), which says that if you add two signed quantities and get an overflow, the result is undefined. The older C Standard, C89/90, and the C++ Standard are both identical to C99 in this respect. Now that we've made this change, we <span>know</span> that the program is correct;)</p></div>
<h3>Resources</h3>

<ul>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/358027.381121" target="_blank" rel="noopener noreferrer"><em>Programming Pearls</em></a> - Highly recommended. Get a copy today!</li>
<li><a href="http://www.google.com/url?sa=D&amp;q=http%3A%2F%2Fbugs.sun.com%2Fbugdatabase%2Fview_bug.do%3Fbug_id%3D5045582" target="_blank" rel="noopener noreferrer"> The Sun bug report describing this bug in the JDK</a></li>
<li><a href="http://www.google.com/url?sa=D&amp;q=http%3A%2F%2Fwww.di.unipi.it%2F%7Eruggieri%2FPapers%2Fsemisum.pdf" target="_blank" rel="noopener noreferrer"> A 2003 paper by Salvatore Ruggieri</a> discussing a related problem - The problem is a bit more general but perhaps less interesting: the average of two numbers of arbitrary sign. The paper does not discuss performance, and its solution is not fast enough for use in the inner loop of a mergesort.</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Be Aware of the Makefile Effect (261 pts)]]></title>
            <link>https://blog.yossarian.net/2025/01/10/Be-aware-of-the-Makefile-effect</link>
            <guid>42663231</guid>
            <pubDate>Sat, 11 Jan 2025 04:13:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.yossarian.net/2025/01/10/Be-aware-of-the-Makefile-effect">https://blog.yossarian.net/2025/01/10/Be-aware-of-the-Makefile-effect</a>, See on <a href="https://news.ycombinator.com/item?id=42663231">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2>ENOSUCHBLOG</h2>
<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/series">Series</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
    <li><a href="https://yossarian.net/">Main Site</a></li>
    <li><a href="https://yossarian.net/til">TILs</a></li>
    
</ul>

<hr>



<h2>
  <p>
    <span><em>Jan 10, 2025</em></span>

    &nbsp; &nbsp;

    
      <span>
        Tags:
        
        
          <a href="https://blog.yossarian.net/tags#programming">programming</a>
        
      </span>
    

    &nbsp; &nbsp;

    
  </p>
</h2>






<hr>


<p>I’m not aware of a <em>perfect</em><sup id="fnref:perfect" role="doc-noteref"><a href="#fn:perfect" rel="footnote">1</a></sup> term for this, so I’m making one up:
the Makefile effect<sup id="fnref:aware" role="doc-noteref"><a href="#fn:aware" rel="footnote">2</a></sup>.</p>

<p>The Makefile effect boils down to this:</p>

<blockquote>
  <p>Tools of a certain complexity or routine unfamiliarity are not run <em>de novo</em>,
but are instead copy-pasted and tweaked from previous known-good examples.</p>
</blockquote>

<p>You see this effect frequently with engineers of all stripes and skill/experience
levels, with <a href="https://en.wikipedia.org/wiki/Make_(software)">Make</a> being a common example<sup id="fnref:example" role="doc-noteref"><a href="#fn:example" rel="footnote">3</a></sup>:</p>

<ol>
  <li>A task (one of a common shape) needs completing. A very similar (or even
identical) task has been done before.</li>
  <li><a href="https://en.wikipedia.org/wiki/Make_(software)">Make</a> (or another tool susceptible to this effect) is the correct or
“best” (given expedience, path dependencies, whatever) tool for the task.</li>
  <li>Instead of writing a <code>Makefile</code>, the engineer copies a previous (sometimes
very large and complicated<sup id="fnref:large" role="doc-noteref"><a href="#fn:large" rel="footnote">4</a></sup>) <code>Makefile</code> from a previous instance of the task
and tweaks it until it works in the new context.</li>
</ol>

<p>On one level, this is a perfectly good (even ideal) <em>engineering</em> response
at the <em>point of solution</em>: applying a working example is often the parsimonious
thing to do, and runs a lesser (in theory) risk of introducing bugs, since
most of the work is unchanged.</p>

<p>However, at the <em>point of design</em>, this suggests a tool design (or tool <em>application</em><sup id="fnref:application" role="doc-noteref"><a href="#fn:application" rel="footnote">5</a></sup>)
that is <em>flawed</em>: the tool (or system) is too complicated (or annoying) to use from scratch. Instead
of using it to solve a problem from scratch, users repeatedly copy a known-good solution
and accrete changes over time.</p>

<p>Once you notice it, you start to see this pattern all over the place.
Beyond Make:</p>

<ul>
  <li>CI/CD configurations like GitHub Actions and GitLab CI/CD, where users
copy their YAML spaghetti from the <em>last</em> working setup and tweak it
(often with repeated re-runs) until it works again;</li>
  <li>Linter and formatter configurations, where a basic set of rules gets
copied between projects and strengthened/loosened as needed for local
conditions;</li>
  <li>Build systems themselves, where everything non-trivial begins to resemble
the previous build system.</li>
</ul>

<h2 id="does-this-matter">Does this matter?</h2>

<p>In many cases, perhaps not. However, I think it’s worth thinking about, especially
when designing tools and systems:</p>

<ul>
  <li>
    <p>Tools and systems that enable this pattern often have less-than-ideal
diagnostics or debugging support: the user has to run the tool repeatedly,
often with long delays, to get back relatively small amounts of information.
Think about CI/CD setups, where users diagnose their copy-pasted
CI/CD by doing print-style debugging <em>over the network with a layer
of intermediating VM orchestration.</em> Ridiculous!</p>
  </li>
  <li>
    <p>Tools that enable this pattern often <em>discourage broad learning</em>:
a few mavens know the tool well enough to configure it, and others
copy it with <em>just</em> enough knowledge to do targeted tweaks.
This is sometimes inevitable, but often not: dependency graphs
are an inherent complexity of build systems, but remembering the difference
between <code>$&lt;</code> and <code>$^</code> in Make is not.</p>
  </li>
  <li>
    <p>Tools that enable this pattern are <em>harder to use securely</em>: security
actions typically require deep knowledge of the <em>why</em> behind a piece of
behavior. Systems that are subject to the Makefile effect are also often ones
that enable confusion between code and data (or any kind of
<a href="https://en.wikipedia.org/wiki/In-band_signaling">in-band signalling</a> more generally), in large part because functional
solutions are not always secure ones. Consider, for example, about
<a href="https://woodruffw.github.io/zizmor/audits/#template-injection">template injection</a> in GitHub Actions.</p>
  </li>
</ul>

<p>In general, I think well-designed tools (and systems) should aim to minimize
this effect. This can be hard to do in a fully general manner, but some
things I think about when designing a new tool:</p>

<ul>
  <li>Does it <em>need</em> to be configurable?</li>
  <li>Does it <em>need</em> syntax of its own?
    <ul>
      <li>As a corollary: can it <em>reuse</em> familiar syntax or idioms from other tools/CLIs?</li>
    </ul>
  </li>
  <li>Do <em>I</em> end up copy-pasting my use of it around? If so, are <em>others</em> likely to do the same?</li>
</ul>

<hr>




<hr>




  






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Very Wrong Math (174 pts)]]></title>
            <link>https://www.charlespetzold.com/blog/2025/01/Very-Wrong-Math.html</link>
            <guid>42661432</guid>
            <pubDate>Fri, 10 Jan 2025 23:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.charlespetzold.com/blog/2025/01/Very-Wrong-Math.html">https://www.charlespetzold.com/blog/2025/01/Very-Wrong-Math.html</a>, See on <a href="https://news.ycombinator.com/item?id=42661432">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            <header>
                

                <p>January 10, 2025<br>New York, N.Y.</p>
            </header>

            
            <p>
            The difference between misinformation and disinformation is the difference between ignorance and malice. Trolling is somewhat different, incorporating an element of provocation and narcissism. But what the hell is this?
            </p>
            <p>
                <img src="https://www.charlespetzold.com/blog/2025/01/FaultyFlightTimes.png" alt="Image from Facebook about Flight Times" width="538" height="537">
            </p>
            <p>
            This was posted by a design and construction company that Facebook thinks I should follow. A cursory glance at their other posts reveals nothing quite as egregiously wrong. So I’m confused. Is it supposed to be a joke?
            </p>
            <p>
            Of course, me being me, I was curious exactly how wrong it was.
            </p>
            <p>
            Let me ignore the “flight time” part of the problem and focus on the length of those two arcs. The length of a circular arc is proportional to the subtending angle and the radius of the circle, specifically:
            </p>
            <math display="block">
            <mi>length of arc</mi><mo>=</mo><mn>2</mn><mo>·</mo><mn>π</mn><mo>·</mo><mfrac><mi>angle</mi><mn>360°</mn></mfrac><mo>·</mo><mi>radius</mi>
            </math>
            <p>
            The angle for the two arcs in the illustration is the same, but in calculating the length of those arcs, the radius of the earth has to be taken into account as well as the distance above the surface of the earth. If the radius of the earth is <i>R</i>, then this illustration implies that:
            </p>
            <math display="block">
            <mi>R</mi><mo>+</mo><mn>33,000′</mn><mo>=</mo><mn>4</mn><mo>·</mo><mo>(</mo><mi>R</mi><mo>+</mo><mn>5,000′</mn><mo>)</mo>
            </math>
            <p>
            The radius of the earth would therefore be:
            </p>
            <math display="block">
            <mi>R</mi><mo>=</mo><mn>4,333′</mn>
            </math>
            <p>
            That’s a distance in feet! That would make the circumference of the earth a bit over 5 miles, which is considerably less than the actual circumference.
            </p>
            <p>
            The mean radius of the earth is actually 3,459 miles or over 18 <i>million</i> feet. Setting <i>R</i> to that value, the ratio of the length of the outer arc to the inner arc is therefore:
            </p>
            <math display="block">
                 <mfrac>
                 <mrow><mi>R</mi><mo>+</mo><mn>33,000′</mn></mrow>
                 <mrow><mi>R</mi><mo>+</mo><mn>5,000′</mn></mrow>
                 </mfrac>
                 <mo>=</mo><mn>1.0015</mn>
            </math>
            <p>
            In other words, the outer arc is less than 1% longer than the inner arc, but the flight time at that altitude would likely be less because of the decreased air resistance.
            </p>


        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Portals and Quake (184 pts)]]></title>
            <link>https://30fps.net/pages/pvs-portals-and-quake/</link>
            <guid>42661185</guid>
            <pubDate>Fri, 10 Jan 2025 22:48:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://30fps.net/pages/pvs-portals-and-quake/">https://30fps.net/pages/pvs-portals-and-quake/</a>, See on <a href="https://news.ycombinator.com/item?id=42661185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text">

<blockquote>
<p>This is the first installment in the “Demystifying the PVS” series.</p>
<ol type="1">
<li><strong>Portals and Quake</strong></li>
<li><a href="https://30fps.net/pages/pvs-coarse-visibility/">Coarse base visibility</a></li>
<li><a href="https://30fps.net/pages/pvs-fine-visibility/">Fine visibility via clipping</a></li>
<li>Portal flow brings it all together (to be published)</li>
</ol>
</blockquote>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/e1m1_pvs.jpg" alt="Precomputed visibility in Quake’s first level. The camera location is shown in red.">

</figure>
<p><em>Ever wanted to know how exactly did Quake’s precomputed visibility work?
I did, so I wrote <a href="https://github.com/pekkavaa/vis.py">vis.py</a>, a reimplementation of their algorithm in Python.
This guide has all the information you need to understand <strong>vis</strong>, the tool used by Quake, Half-Life and Source Engine games.</em></p>
<p>During the development of Quake, <em>overdraw</em> became a concern.
It means the same pixel getting written many times during the rendering of a frame.
Only the last color stays visible and the earlier writes go to waste.
This is bad if your game is software rendered and already pushing the mid 90’s PCs to their limits.</p>
<p>How to reduce overdraw?
Let’s begin with a very high-level overview of the solution landscape.</p>
<h2 id="portal-culling-helps-with-overdraw">Portal culling helps with overdraw</h2>
<p>In 3D games, it’s a good idea to reduce the number of drawn objects.
<!-- The earlier they can get culled, the better. -->
<em>Frustum culling</em> is one fundamental method for this, in which objects confirmed to be outside the virtual camera’s view are skipped during rendering.
This can be done for example with object bounding boxes or bounding spheres.</p>
<p>Frustum culling still leaves some performance on the table.
Many objects may still be within the field of view of the camera even if they don’t contribute any pixels to the final image. This is not a performance catastrophe if everything is rendered from front to back.
GPU’s early-z testing will help here.
Still, in large worlds it would be faster to never submit these objects for rendering in the first place.</p>
<p><em>Occlusion culling</em> is a process where you discard objects that you deem to lie behind other objects in the scene. Its purpose is to discard as many <em>occluded</em> objects as possible. It’s not strictly needed, since you’ll get the correct image thanks to the z-buffer anyway. There are a few ways to do this such as the hierarchical z-buffer, occlusion queries, portal culling, and potentially visible sets (PVS). In this article I talk about the last two: portals and the PVS.</p>
<p>In portal culling, the world is divided into spaces where the virtual camera can move around and the openings between them. The spaces are called <em>cells</em>, <em>viewcells</em>, <em>zones</em>, <em>clusters</em> or <em>sectors</em>, and the openings <em>portals</em>. This is a useful split especially in architectural models with cleanly separated rooms connected by doorways or windows.
It also works for mostly-indoor video game levels :)</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portals_topdown_crop.png" alt="The floorplan of our example level with three hand-placed portals shown. Cells have the color of their entry portal. In this case also the cell where the camera lies is visible.">

</figure>
<p>Portal rendering starts from the camera’s cell.
The game renders everything inside that cell, and then recursively looks into portals leading away from that first cell to find out what else to draw.
It renders all objects in every cell and then examines the cell’s portals.
If a portal doesn’t line up with another one on screen, it won’t be visited.
Each successive portal shrinks the visible screen area smaller and smaller until the whole portal is clipped away.</p>
<p>A straightforward way to test portals for visibility is to intersect their screenspace bounding boxes.
Those are shown in white in the picture below.
If two bounding boxes overlap, we can see through the respective portals.
More accurate tests can be performed with 3D clipping or per-pixel operations.</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portals_sprite.jpg" alt="This is how three portals could look in game. Portal openings are shown as colored polygons and their screenspace bounding boxes are in white. Objects have dashed bounding boxes. The star object is culled because it doesn’t overlap with the red portal.">

</figure>
<p>The Quake engine uses portals but only during map preparation time.
At runtime, the portals are nowhere to be seen.
This technique is a variant of Seth Teller’s PVS method presented <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/1992/CSD-92-708.pdf">in his 1992 dissertation</a> that only worked with axis-aligned walls.</p>
<h2 id="portals-of-a-quake-map-disappear">Portals of a Quake map disappear</h2>
<p>Often portals are placed by hand by a level designer. Quake’s <strong>bsp</strong> map compilation tool places portals automatically, which is nice, but unfortunately it creates a lot of them!</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/e1m1_start_withportals.jpg" alt="Quake’s first map viewed in the TrenchBroom map editor with portals shown in red. As you can see, not just doorways act as portals.">

</figure>
<p>You see, in Quake the cells are very small.
But no portals are tested at runtime.
Instead, each cell gets a precomputed list of other cells that can been seen from it.
This is the <em>Potentially Visible Set</em> (PVS) for that cell.</p>
<p>In Quake, a cell is a small convex volume of space, so a single room will usually get split into multiple cells.
These cells correspond to leaves of a binary space partitioning (BSP) tree.
The BSP tree was used to divide the map into cells and portals.
For us, the exact method is irrelevant though.
But BSP does make it easy to find the cell the camera is in at runtime.</p>
<p>Since we have now entered the Quake territory in our discussion, I’ll start calling a cell a <em>leaf</em>.
Leaf is the term used in all source code, level editors, error messages, and other resources on Quake.
The meaning stays exactly the same though, it’s just a convex cell connected to other cells via portals.
This is how leaves look in our example level:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/colored_leaves.png" alt="The example map divided to convex leaves. Leaf colors are random.">

</figure>
<p>The portals appear in between leaves, as expected:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/example_top_notextures_small.png" alt="Portals placed automatically by the bsp tool. This map is pretty much 2D but everything discussed works just fine in 3D too. Leaf indices are shown in white.">

</figure>
<p>Nothing would’ve stopped them from grouping multiple leaves to form larger cells with fewer portals in between.
In fact, this is exactly what they did for Quake 2 with its “clusters” of leaves.</p>
<p>With larger clusters of leaves, you do get more overdraw.
Also, a cluster made of convex leaves may not be convex itself any more.
But even in that case you can still act as if it still is, and assume the portals inside can be seen from anywhere in the cluster.
It’s less accurate but works.</p>
<!-- More overdraw 
I don't know how they clusters looked for Quake 2.
assume other portals to be visible and just render a bit too much in the worst case.

and may not be convex (I don't know if that was the case for Quake 2).
In general, the cells in a portal system don't have to be convex.
I mean it's neat, since you can be sure that all portals of a cell are visible to each other (unless coplanar). -->
<h2 id="high-level-overview-of-vis">High-level overview of vis</h2>
<p>The Quake map tool <strong>vis</strong> takes in portals generated by another tool, <strong>bsp</strong>, precomputes a leaf-to-leaf visibility matrix, and writes the matrix back to the compiled map file.
This article series describes how <strong>vis</strong> functions.</p>
<p>We know that leaves can see each other only through portals.
So we don’t even need to know how exactly the leaves look like, only how they are connected together.</p>
<p>At its most basic level, <strong>vis</strong> does two recursive depth-first traversals, followed by a quick resolve pass before writing the visibility results back to a compiled map file. Three steps:</p>
<ol type="1">
<li><strong>Base visibility.</strong> Estimate a coarse leaf-to-portal visibility.</li>
<li><strong>Full visibility.</strong> Refine the coarse results via portal clipping.</li>
<li><strong>Resolve.</strong> Combine the refined portal-to-leaf results to the final leaf-to-leaf visibility.</li>
</ol>
<p>For a quick visual overview, I can recommend Matthew Earl’s <a href="https://www.youtube.com/watch?v=IfCRHSIg6zo">great video on Quake’s PVS</a>.</p>
<h3 id="portals-have-a-direction">Portals have a direction</h3>
<p>In a portal system, the cells and portals are structured as a cell-and-portal graph.
Quake’s map tooling follows this pattern and connects leaves with portals, even though this structure isn’t present at runtime.
Leafs are connected by portals:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/undirected_graph.png" alt="Leaves (nodes) connected by portals (edges) in a cell-and-portal graph.">

</figure>
<p>Each portal is a 3D polygon.
They are written by <strong>bsp</strong> to a plain text file with a version code, the number of leaves and portals, followed by one portal per line. Like this:</p>
<pre><code>PRT1
11
12
4 0 1 (880 -224 -8 ) (880 -272 -8 ) (880 -272 72 ) (880 -224 72 ) 
4 1 2 (832 -224 -8 ) (832 -272 -8 ) (832 -272 72 ) (832 -224 72 ) 
4 2 4 (768 -272 -8 ) (768 -320 -8 ) (768 -320 72 ) (768 -272 72 ) 
4 2 3 (768 -112 72 ) (768 -112 -8 ) (768 -160 -8 ) (768 -160 72 ) 
4 3 5 (720 -112 72 ) (720 -112 -8 ) (720 -160 -8 ) (720 -160 72 ) 
4 4 5 (720 -272 -8 ) (720 -320 -8 ) (720 -320 72 ) (720 -272 72 ) 
4 5 6 (640 -224 -8 ) (640 -288 -8 ) (640 -288 72 ) (640 -224 72 ) 
4 6 7 (592 -224 -8 ) (592 -288 -8 ) (592 -288 72 ) (592 -224 72 ) 
4 7 10 (384 -304 -8 ) (384 -368 -8 ) (384 -368 72 ) (384 -304 72 ) 
4 7 8 (384 -112 -8 ) (384 -176 -8 ) (384 -176 72 ) (384 -112 72 ) 
4 8 9 (240 -176 -8 ) (336 -176 -8 ) (336 -176 72 ) (240 -176 72 ) 
4 9 10 (240 -304 -8 ) (336 -304 -8 ) (336 -304 72 ) (240 -304 72 ) </code></pre>
<p>Each portal is a loop of 3D points:</p>
<pre><code>┌ the number of points
│ 
▽      x    y    z   x     y    z    x    y   z     x    y   z
4 0 1 (880 -224 -8 ) (880 -272 -8 ) (880 -272 72 ) (880 -224 72 ) 
  △ △ 
  └─┴─ the two leaves the portal is in between</code></pre>
<p>Since portals are interfaces between convex leaves, the polygons are also convex.
In 3D, a portal looks like this:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portal_onedirection.jpg" alt="Each portal is stored as a convex polygon.">

</figure>
<p>Conceptually, each portal is a two way opening. You can see through it in both directions.
However, it’s convenient to make the portals directed.
This way we can keep track on what’s visible in different directions.
We give each portal a normal vector, the direction the portal can be seen through.</p>
<p>Now a single input portal becomes two directed portals:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portal_two_directions.jpg" alt="Each input portal is split into a so called forward (red) and backward (yellow) portal before processing. There’s a small gap here for demonstration purposes but actually they overlap. The arrows show the directions the portals can be seen through.">

</figure>
<p>Therefore the graph will now have directed edges instead:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/directed_graph_with_colors.png" alt="Each portal is represented by two edges in the graph. The earlier forward and backwards portal edges are highlighted with red and gold, respectively.">

</figure>
<h3 id="the-graph-in-code">The graph in code</h3>
<p>Now is the time to present the main data structures of <strong>vis.py</strong>, the <a href="https://github.com/pekkavaa/vis.py/blob/main/portaltypes.py"><strong>Portal</strong> and <strong>Leaf</strong> classes</a>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>class</span> Portal:</span>
<span id="cb3-2">  winding: <span>list</span>[np.ndarray]   <span># polygon's 3D points</span></span>
<span id="cb3-3">  leaf: <span>int</span>                   <span># the leaf this portal leads to</span></span>
<span id="cb3-4">  plane: Plane                <span># plane normal points to destination leaf</span></span>
<span id="cb3-5">  ...                         <span># (other class attributes omitted)</span></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span>class</span> Leaf:</span>
<span id="cb3-8">  portals: <span>list</span>[<span>int</span>]    <span># indices of portals leading away from this leaf</span></span></code></pre></div>
<p>Note that a leaf stores only indices of portals <em>leading away</em> from that leaf.
The graph is stored in two global arrays called <strong>portals</strong> and <strong>leaves</strong> with objects of the respective types.
Since the graph is accessed both via indices and direct object references, I came up with the following naming convention:</p>
<ul>
<li><code>pi</code> is the index of a portal, <code>Pi</code> is the actual object <code>Pi = portals[pi]</code>, and</li>
<li><code>li</code> is the index of a leaf, <code>Li</code> is the actual object <code>Li = leaves[li]</code>.</li>
</ul>
<p>Our goal is to compute which nodes can reach each other in this graph while honoring the 3D visibility relations between portals associated with each edge.
But what on earth are those “visibility relations”?</p>
<p><em>In <a href="https://30fps.net/pages/pvs-coarse-visibility/">the next part</a> we’ll use the graph for some quick checks.</em></p>
<hr>
<p><em>I’m also thinking of writing a book. <a href="https://30fps.net/book">Sign up here</a> if you’re interested.</em></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building Bauble (171 pts)]]></title>
            <link>https://ianthehenry.com/posts/bauble/building-bauble/</link>
            <guid>42660942</guid>
            <pubDate>Fri, 10 Jan 2025 22:22:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ianthehenry.com/posts/bauble/building-bauble/">https://ianthehenry.com/posts/bauble/building-bauble/</a>, See on <a href="https://news.ycombinator.com/item?id=42660942">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<div><p>I made something that I think is pretty neat, and I want to tell you about it.</p>
<a href="https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_1536x1536_fit_box_3.png"><picture><source type="image/webp" srcset="https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_768x768_fit_q75_h2_box_3.webp 768w,
https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_1536x1536_fit_q75_h2_box_3.webp 1536w,
https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_375x375_fit_q75_h2_box_3.webp 375w,
https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_750x750_fit_q75_h2_box_3.webp 750w" sizes="(max-width: 400px) 375px, 768px"><img srcset="https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_768x768_fit_box_3.png 768w,
https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_1536x1536_fit_box_3.png 1536w,
https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_375x375_fit_box_3.png 375w,
https://ianthehenry.com/posts/bauble/building-bauble/balloon_hu61af7d15d560861d79c4cc0f3adfa0ec_4858488_750x750_fit_box_3.png 750w" alt="" title="" sizes="(max-width: 400px) 375px, 768px" width="768" height="432"></picture></a>
<p>This is a little hot air balloon made out of alternating layers of brass and bronze that stack together with these angled facets:</p>
<a href="https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_1536x1536_fit_box_3.png"><picture><source type="image/webp" srcset="https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_768x768_fit_q75_h2_box_3.webp 768w,
https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_1536x1536_fit_q75_h2_box_3.webp 1536w,
https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_375x375_fit_q75_h2_box_3.webp 375w,
https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_750x750_fit_q75_h2_box_3.webp 750w" sizes="(max-width: 400px) 375px, 768px"><img srcset="https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_768x768_fit_box_3.png 768w,
https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_1536x1536_fit_box_3.png 1536w,
https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_375x375_fit_box_3.png 375w,
https://ianthehenry.com/posts/bauble/building-bauble/layers_hud04b4e21bf34736dfa3c4b5bc0350dcb_5728706_750x750_fit_box_3.png 750w" alt="" title="" sizes="(max-width: 400px) 375px, 768px" width="768" height="432"></picture></a>
<p>It’s 3D printed, sort of, but it really is solid metal – it’s not a metallic filament. It’s made by “lost wax casting,” where you 3D print a model out of resin, then pack it in plaster, and then once the plaster dries you melt out the resin and fill the void with molten–</p>
<p>You know what? This is neat, but this actually isn’t what I wanted to tell you about.</p>

<p>Neither is that, but we’re getting closer.</p>
<p>That’s the 3D model that the balloon is cast from. I didn’t actually cast the balloon – I paid someone else to do that for me – but I <em>did</em> make the 3D model.</p>
<p>And it’s an interesting 3D model. It’s not a triangle mesh, like most 3D shapes you encounter. It has no faces; it has no vertices. Instead, it’s made entirely out of math: this balloon is a pure function of 3D space.</p>
<p>Here, take a look:</p>
<pre tabindex="0"><code data-lang="bauble">(def thickness 25)
(def sections 12)
(def angle (pi * 0.25))
(def lobe-intensity 1)
(def bezel 1)
(def bronziness 1.5)
(def branzino false)
(ball [(100 / (lobe-intensity + 1)) 100 100]
| union :r 50 (cylinder y 25 50 | move [0 -100 0])
| scale y (ss p.y -100 100 1 0.8)
| intersect :r bezel
  (plane y | shell thickness
  | color (gl/if (mod $i.y 2 | = 0) (pow default-3d-color bronziness) default-3d-color)
  | tile: $i [0 thickness 0]
  | rotate z (remap- parity * angle)
  | gl/let [parity (mod $i 2)] _)
| radial: $i y sections
| move y 40
)
</code></pre><p>There’s the source code to that hot air balloon. Mess around with it. Edit some constants. Pull up the autocomplete with <code>ctrl-space</code>, and see what else it can do.</p>
<p>This is called <a href="https://bauble.studio/">Bauble</a>, and <em>this</em> is what I wanted to tell you about.</p>
<p>Bauble is a tool – toy? – that I wrote in 2022, because I wanted to make pictures with math on my computer. And not just simple geometrical things like that. I wanted to make pictures like this:</p>
<pre tabindex="0"><code data-lang="bauble">(defn fork [shape f1 f2]
  (union (f1 shape) (f2 shape)))

(defn spoon [shape f1 f2]
  (union shape (f1 shape) (f2 shape)))

(defn cel [shape rgb]
  (shade shape :f (fn [light] (gl/do
    (var cel-shadow (step 0.8 light.brightness + 1 / 2))
    (var cel-shading (dot light.direction normal * light.color | quantize 2 * cel-shadow))
    (var regular-shading (dot light.direction normal * light.color * cel-shadow))
    (var b (mix cel-shading regular-shading 0.5 + 0.5))
    (b * rgb)))))

(setdyn *lights* [(light/directional 1 [-2 -2 -1] 1024 :shadow 0.25)])

(def ear
  (cone y 40 153 :r 12
  | morph 0.15 (sphere 46 | move y 64)
  | union :r 13
    (cylinder y 26 30 | move y -10)
  | scale z 0.5))

(def ears
  (ear
  | move x 134
  | rotate z (tau * -0.01)
  | mirror x))

(def body
  (ball [1 0.75 0.5 * 100]
  | union :r 72 (ball [0.58 (.84 * 0.75) 0.5 * 250] | move y -156)))

(defn body-color [$] (cel $ (hsv (4 / 6) 0.1 0.3)))

(def decoration (rect [32 10] :r 10 | rotate (q.x * 0.044 - pi) | rotate pi))
(def top-decorations
  (fork decoration
    (fn [$] ($ | rotate -0.21))
    (fn [$] ($ | scale 0.9 | move x 71 | rotate -0.30))
  | move x 40
  | mirror x))
(def bottom-decorations
  (spoon decoration
    (fn [$] ($ | scale 0.95 | move x 76 y 0 | rotate -0.14))
    (fn [$] ($ | scale 0.9  | rotate -0.59 | move x 140 y -37))
  | mirror x))

(def decorations (union top-decorations (bottom-decorations | move y -80)))

(def tummy-patch
  (box 110 :r 64
  | morph 0.70 (sphere 118)
  | move z 60 y -137
  | cel (hsl (/ 69 255) 0.10 0.65)))

(def body-and-ears
  (union :r 6
    body
    (ears | scale 0.42 | move y 81)
  | body-color
  | union-color (subtract tummy-patch (decorations | extrude z inf | scale 0.5 | move y -46))))

(def eyes
  ( sphere 14
  | union :r 4 (box [14 0 1] | move z 4)
  | cel 10 | union-color (sphere 5 | move z 14 | cel 0.05)
  | scale z 0.5
  | rotate x -0.37 y 0.34
  | move [52 28 43]
  | mirror x))

(def arms
  (box [15 100 (ss p.y -100 50 25 40)] :r 15
  | rotate z (p.y * 0.002)
  | rotate z 0.30
  | move x 131 y -122
  | mirror x
  | body-color))

(def whiskers
  (union
    (line [0 0 0] [85 0 0] 1.5 0.5 | rotate z 0.03 | move [0 6 0])
    (line [0 0 0] [82 0 0] 1.5 0.5 | rotate z -0.03)
    (line [0 0 0] [87 0 0] 1.5 0.5 | rotate z -0.10 | move [0 -6 3])
  | move [60 0 41]
  | mirror x
  | color 0.1))

(def floor (ground -300 | cel (hsv 0.7 0.1 0.04)))

(def nostrils
  (cylinder z 2.5 3
  | move [7 1 4]
  | mirror x
  | color [0 0 0]))

(def nose
  (ball 11
  | subtract :r 2 (cylinder z 10 10 | move x 11 y -12 | mirror x :r 1)
  | scale z 0.6 y 0.7 x 1.5
  | rotate x -0.5
  | cel (hsv 0 0.0 0.02)
  | union-color nostrils
  | scale 1.20
  | move z 48 y 30))

(def lilypad
  (cylinder y (5 * sin (theta + 1 * 3) * cos (theta - 1 * 2) + 40) 0.3
  | move y (sin (theta * 4) * cos (theta * 2 + (length p.xz / 8 + 18)) * dot p.xz * 0.005 + (ss p.z 0 40 0 -10))
  | slow 0.7
  | union :r 5 (cylinder y 1 10 :r 1 | move y 10 | rotate x 0.2 z (sin (p.y / 4) * 0.1))
  | move y 77
  | cel (hsv (2 / 6) 0.9 0.5)
  | gl/let [theta (atan2 p.xz)] _))

(union
  eyes
  (union body-and-ears
  arms :r (10 - (distance [(abs p.x) p.y p.z] [120 -78 -1] / 10) | max 0)
  | expound (perlin p 15) 0.05 2)
  whiskers
  floor
  nose
  lilypad
| tint white (fresnel 5 * 0.3))
</code></pre><p>I had just discovered <em>signed distance functions</em>, and I was enamored by the power that they give you to sculpt space with simple mathematical expressions.</p>
<p>Signed distance functions – SDFs – are amazing, and if this is the first time you’re hearing about them, you should probably drop everything you’re doing today and <a href="https://www.youtube.com/watch?v=8--5LwHRhjk">watch this twenty-five minute video of Inigo Quilez using signed distance functions to create an animation</a> instead. Yes, twenty-five minutes is a lot of minutes. It’s worth it.</p>
<p>I know you didn’t actually watch the video, but the overall gist is that someone very smart and very good at math describes an animation he created out of pure functions of time and space. But the description is pretty high-level: he says things like “<a href="https://www.youtube.com/watch?v=8--5LwHRhjk&amp;t=944s">we’ll define three circles that we spin as we move down the parameterization of the curve</a>,” which is a beautiful way to <em>think about</em> the effect he uses to create the braids in that video – but how do you actually <em>do</em> that?</p>
<p>Well, you write several hundred lines of something called GLSL, plumbing arguments around and looking up how to construct rotation matrices and forgetting that matrices are column-major in GLSL and trying to remember what you stuck in the <code>w</code> component of this vector and, well, you can <em>do it</em>, and <a href="https://www.shadertoy.com/results?sort=newest">lots of people have</a>, but not without losing some of the mathematical elegance of the original, intuitive presentation.</p>
<p>Because I really just want to write “gimme three circles extruded along a bezier curve, and rotate them by an angle that varies with the current position along the curve,” you know?</p>
<pre tabindex="0"><code data-lang="bauble">(circle 10
| color (hsv ($i + 3 / 6) 0.6 1)
| radial: $i 3 5
| rotate ($t * tau * 4 + t)
| bezier: $t [-100 0 100] [0 100 0] [100 0 -100]
    :to (osc t 5 0 1 | ss 0.1 1))
</code></pre><p>(You can click to pause any of the animations on this page.)</p>
<p>So: Bauble. I wrote Bauble to solve this impedance mismatch, so that I could play around with the SDFs the way that I wanted to play around with SDFs: in a functional, expression-oriented programming language. SDFs are signed distance <em>functions</em>, remember, and primitive operations on SDFs like rotation or translation are literal <em>function composition</em>. You can write a function that takes an SDF and an angle and returns a new SDF – a new function – for the rotated shape.</p>
<p>But you can’t write that in GLSL! GLSL doesn’t have first-class functions, so you actually have to do this composition by hand: if you want to rotate a shape, you have to rotate its input coordinate first, then pass the newly-rotated point in space to the SDF. Which, like, is <em>fine</em>, but it’s friction, and that’s the very simplest sort of operation – once you get into more interesting higher-order operations like instanced tiling, the friction stops feeling fine.</p>
<pre tabindex="0"><code data-lang="bauble">(gl/def apothem (osc t 15 5 10))
(circle (oss t 7 (apothem * 0.5) (apothem * 2 / sqrt 3))
| shade (hsv (hash $i + (t / 10)) 0.75 0.8)
| with-lights (light/point 1 (P + normal))
| move x (mod $i.y 2 * apothem)
| tile: $i [(apothem * 2) (apothem * sqrt 3)] :oversample true
| revolve z | rotate x (t / 20) z (t / 5)
| intersect (cylinder x 150 20 :r 20) :r 2)
(set camera (camera/perspective [403 0 0] :fov 45))
</code></pre><p>Bauble is not just a higher-level language, though. It’s more accurate to say that I started working on Bauble because I was frustrated with the speed at which I was able to write shaders using SDFs. Not just the verbose manual composition, but the verbose manual <em>composition:</em> it’s hard to compose a detailed scene in pure code! I didn’t only want to make abstract “shadery” looking things. I wanted to be able to make characters too, and that requires a degree of precise and subjective control: I wanted to be able to drag things around, edit shapes interactively, see my shader update live, look at it from different angles… but instead I was over here backspacing over a <code>1.4</code>, typing <code>1.5</code>, recompiling, and deciding if it looks better or worse.</p>
<pre tabindex="0"><code data-lang="bauble"># "manta raymarching"
(gl/def bg (ok/mix [0.1 0.1 0.25] sky (ray.direction.y | remap+)))
(triangle [(ss (q.y * gl/if (&lt; q.x 0) 1 0) 0 65 65 40) 130] | rotate (q.y / 270)
| extrude y | expand (ss p.z 140 0 1 3)
| union :r 10 (cone x 18 -184 :r 10 | scale [1 1 2] | move x 49)
| shell 4
| subtract :r 5 (ball [30 30 30] | move x 75)
| union :r 10
  (rect [11 5] :r [0 5 5 0]
    | extrude z
    | expand 1
    | rotate x (p.y / -30)
    | rotate x (p.x / 40) | pivot [-10 0 0]
    | rotate y (p.x / 200 + (sin+ t * 0.5)) | pivot [-10 0 0]
    | move x 70 z 28)
| scale [1 (ss p.x 0 -100 1 0.2) 1]
| union :r 3 (cone x 5 -100 | move x -45)
| shade (mix (blue * 0.03) [0.9 1 1]
(2000 / (distance (abs p.xz) [57 117] | pow 3) | clamp 0 1)
) :g 20
| mirror z
| union-color (
  (shape/2d
    (gl/if (&gt; (hash ($i + 100) * (14 / length ($i * [2 1]))) 0.5)
      (distance q (hash2 $i * 4) - (ss (hash $i) 0 1 1 1 * (ss normal.y 0.5 1)))
      1000))
  | tile: $i [4 4] :oversample true | shade white | extrude y inf)
| morph (shade r3 gray) :distance 0 :color (1 - occlusion :dist 40 | ss 0.4 0.5
+ (dot normal -y | max 0)
)
| union (ball 2 | move [61 -3 32] | mirror z | shade [0 0 0] :g 20 :s 1)
| rotate x (ss p.z 200 0 1 0 * osc t 3 pi/4 -pi/4) | pivot [0 0 10]
| rotate x (ss p.z -200 0 1 0 * osc (t + (sin t * 0.1)) 3 -pi/4 pi/4) | pivot [0 0 -10]
| rotate z (p.x / 800 * osc t 3 -1 1 + osc t 3 -0.1 0.1) | pivot [(oss t 6 -100 100) 0 0]
| rotate x (osc t 6 -0.1 0.1) y (osc t 12 -0.2 0.2)
| bound (ball 140 | move x -20) 20
| move (hash3 $i * 400 + [(osc t 3 -10 10) (oss t 6 -40 40) 0])
| gl/let [t (hash $i * 10 + t)] _
| tile: $i (vec3 700) :limit [50000 8 10] :oversample true
| move x (t * 150)
| map-color (fn [c] (mix c bg (depth / 5000 | pow 2 | clamp 0 1)))
| slow 0.8)

(set background-color bg)
</code></pre><p>And the camera, gosh – modeling in 3D with a fixed camera is <em>hard</em>. And – while I realize this sounds really dumb – I think the math to calculate a perspective matrix and position a camera where you want pointed in the direction that you want is actually <em>much harder</em> than any the math related to the actual SDFs that you’re trying to render.</p>
<p>So I whipped up a little hack that would basically just concatenate strings of GLSL for me, and put them in a little window with a moving camera.</p>
<p>It took me a few days to get it working: I decided that I wanted to use <a href="https://janet-lang.org/">Janet</a> as my “high level” language, because <a href="https://ianthehenry.com/posts/janet-game/">I’d had a positive experience with the language before</a>, and I knew that it could <em>at least in theory</em> run inside the browser. I had never used WebAssembly before, and I had <em>barely</em> used Janet at this point, and even following existing examples I had quite a time getting it to work. Nevermind that it had been almost a decade since I’d done web development seriously, and my sole experience with WebGL at that point was <a href="https://ianthehenry.com/posts/delaunay/">making a few visuals for an old blog post</a>.</p>
<p>But I got <em>something</em> working, eventually. Here’s the very first demo I ever recorded of the thing that would become Bauble:</p>

<p>Notice the dark, oversaturated colors. I didn’t know I had to do my own gamma correction! This was like my third ever shader. I had no idea what I was doing.</p>
<p>But even though this was extremely crude – it was literally GLSL string concatenation, of a few fixed primitive shapes, with no dynamic expressions of any kind – it was already <em>so much better</em> than writing GLSL by hand. Even just being able to type <code>[1 2 3]</code> instead of <code>vec3(1.0, 2.0, 3.0)</code> was worth the time I’d spent on it.</p>
<p>And it was <em>fun</em>. There’s something so viscerally satisfying about making something you can touch and play with and see in real time like this. I was having fun working on this little toy, so I kept working on it.</p>
<p>I implemented an orbital camera. I switched the editor to <a href="https://codemirror.net/">CodeMirror</a>, and learned how to write a Janet grammar for it, so that I could directly manipulate the parsed AST to edit values with my mouse (ctrl-click and drag on any number!). With CodeMirror came TypeScript, which I had never used before, and some cruel prank called “rollup,” and I got to experience firsthand the hell of the modern JavaScript ecosystem. I wrote a UI, and decided to try something called SolidJS, which I’ve mildly regretted ever since.</p>
<pre tabindex="0"><code data-lang="bauble">(union
  (revolve shape y radius
  | move y (atan2+ p.xz / tau * sep + (round (p.y / sep) * sep))
  )
  (revolve shape y radius
  | move y (atan2+ p.xz / tau * sep + (round (p.y / sep) - 1 * sep))
  )
| let [shape (circle 2
  | shade (hsv (hash $i + hash $j + (t * 0.1)) 0.7 1) :s 1 :g 10
  | with-lights (light/ambient 1 normal)
  | tile: $i [10 10] :limit 4
  | radial: $j 5 50
  | rotate (t / 3))] _
| gl/let [radius (osc p.y 1000 50 200) sep 146] _
| rotate y t)
</code></pre><p>Everything was very new and exciting, and I learned a lot about Wasm and Janet and OpenGL and SDFs and procedural art in general.</p>
<p>And I kept growing the capabilities of Bauble’s… compiler? Would we call it a compiler? It was still, at this point, a glorified string concatenator. But I taught it how to concatenate real fancy-like; I added support for custom dynamic expressions so that you could write things like “rotate space around the y-axis by an angle that varies with the current <code>y</code> coordinate:”</p>
<pre tabindex="0"><code data-lang="bauble">(star 100 50 | extrude y 100
| rotate y (osc t 3 | ss 0.1 0.9 * pi/2 * p.y / 100 + (0.5 * t))
| slow 0.5)
</code></pre><p>Eventually I even implemented animations, and complex surface-blending operations, and higher-order bounding operations to improve rendering performance, and domain repetition, and, and…</p>
<p>And finally my crowning achievement: custom dynamic lighting, with raymarched soft shadows, which you could specify on a shape-by-shape basis, and whose properties could vary over time and space to produce complex, interesting effects.</p>
<pre tabindex="0"><code data-lang="bauble">(def light-count 6)
(defn light [i]
  (gl/def at (rotate [0 (osc t 5 20 200) 60] y (i / light-count * tau + t)))
  (light/point  (hsv (i / light-count) 1 1) at :shadow 0.25
    :brightness (100 / (dot P at | abs | pow (osc t 3 0.7 1.2)) | min 2)))
(octahedron 20 :r 5 | rotate x (t + $i) y (t + $i) z (t + $i)
| shade (hsv $i 0.6 0.5)
| union (ground -40 | shade gray)
| with-lights ;(seq [i :range [0 light-count]] (light i))
| gl/let [$i (hash $i)] _
| tile: $i [80 0 80])
</code></pre><p>It was the most complicated feature of Bauble, one that stretched its string concatenator to the absolute limits, one that had to be special-cased in the typechecker in order to generate correct code, and one that would still occasionally generate invalid GLSL if you looked at it wrong.</p>
<p>It was also the last “must-have” feature. Once lighting was done, Bauble was “finished.” I wrote some token documentation, and a little tutorial, and I announced Bauble to the world. I forced myself to stop hacking on it for a little while, because I had more important things to do, and I went outside for the first time in two months.</p>
<pre tabindex="0"><code data-lang="bauble">(cylinder y 100 20 :r 20
| union (cone y 30 50 :r 5) :r 50
| expound (fbm 5 simplex [p.x p.z (distance p [0 50 0] - (t * 20) + (atan2+ p.xz / pi * -150) )] [50 50 20]) 3
| shade (mix blue sky 0.5) :g 30 :s 1
| slow 0.5
| tint sky (fresnel 5))
(set camera (camera/perspective [-180 100 0]))
</code></pre><p>I didn’t set it aside for long. But when I returned to it, when I looked back over what I had wrought in this furious coding binge, I found…</p>
<p>You know that scene in <em>Raiders of the Lost Ark</em> where they open up the roof of the Well of Souls, and they drop a torch down there, and the ground is just a solid mass of writhing snakes?</p>
<p>That was basically the codebase that I had produced.</p>
<pre tabindex="0"><code data-lang="bauble">(morph 0.88
(ball 40 | move x 10 | rotate y (t * 2) | move y (osc t 20 -150 150))
(hexagon :r 5 10
| revolve x (80 + (40 * hash [$i $j]))
| shade (hsv (hash ($i + $j) * 0.04 - 0.03) 1 0.8) :g 15 :s 0.2
| radial: $j y 20 :oversample true :sample-from -1)
| rotate y (p.y / 40 | sin * (mod $i 2 * 2 - 1))
| rotate y (mod $i 2 * tau)
| radial: $i y 2 :oversample true :sample-from -1
| rotate y (t / 10)
| with-lights (light/directional white [-1 -2 0 | normalize] 300 :shadow 0.1)
  (light/ambient 0.25 normal)
| slow 0.5)
</code></pre><p>See, the string concatenation never just <em>went away</em>. The whole core “compiler” was still based on this fragile web of carefully crafted, hardcoded GLSL primitives. There was never, at any point, an abstract syntax tree. There was a sort of weird builder-like imperative “code printer” <em>thing</em> that <em>sort of</em> implicitly tracked an AST and like knew what was in scope at some times, but, like, if you ever wrote a function with a local variable called <code>p</code> you’d break everything, because <code>p</code> is, obviously, the name of a dynamic variable that–</p>
<p>You know what? I don’t need to explain it. I’m sure you can believe me when I say that it was awful code.</p>
<pre tabindex="0"><code data-lang="bauble">(color r2 (teal * 0.1 *
  (fbm 8 :f (fn [q] (rotate (q * 2) (pi * sin (t / 100))))
    (fn [q] (cos q.x + sin q.y /)) q (osc t 20 30 90))))
(set aa-grid-size 2)
</code></pre><p>But it wasn’t just the code. It was also a bad <em>product</em>. It was too limiting: Bauble was a tool for making shaders with SDFs, but it didn’t give you any way to actually write your own signed distance functions. You just couldn’t write arbitrary shader code. You could write some custom <em>expressions</em>, using a limited subset of the functions available to you in real GLSL, but there was no way that you, as a Bauble user, could have implemented any of the provided built-ins. There was no “escape hatch” to pure GLSL.</p>
<p>So you were limited to the built-ins, and there just wasn’t that much built-into it. It was missing so many things: I wanted 2D SDFs, and extrusions into 3D space. I wanted to be able to distort normals without altering distance fields. I wanted to be able to define custom material shaders that could use Bauble’s native shadow casting – you could define custom <em>colors</em> of course, but the only light-aware material in all of Bauble was a simple Blinn-Phong shader. And that fact was, of course, hardcoded.</p>
<pre tabindex="0"><code data-lang="bauble">(defn strip [axis q]
  (revolve (trapezoid (mix lo hi h) (mix hi lo h) 20 :r 2 | rotate (h * pi) t
  | gl/let [lo 0 hi 10 h (atan2+ q / tau)] _) axis 100))
(union
  (strip y p.xz | move x -50 | shade sky)
  (strip z p.xy | move x 50 | shade orange)
| rotate z (t / 3) y (t / 2)
| tint purple (fresnel 5 * 0.5))
</code></pre><p>Maybe more than anything else, I wanted to add 3D mesh export – I wanted to be able to export Bauble shapes into OBJ files or STL files or whatever the right one is today, because I wanted to 3D print my Baubles. But I also wanted to add custom camera support, and anti-aliasing, and video export…</p>
<p>But I had stretched my strings to the breaking point. Even I couldn’t understand what I’d written, and I knew that, if I wanted to keep growing Bauble, I would have to rewrite the core compiler from scratch.</p>
<pre tabindex="0"><code data-lang="bauble">(gl/let [t1 (t / 4)
         t2 (ss (fract t1) 0.2 1 (floor t1) (ceil t1))]
  (defn nudge [i]
    (hash3 i - 0.5
    | normalize
    | rotate y (osc t2 4 -0.5 0.5) z (osc t2 3 -0.5 0.5) x (osc t2 2 -0.5 0.5)))
  (intersect :r (s * 20 + 1)
    (plane [+1 +1 +1 + nudge 0 | normalize] 80)
    (plane [+1 +1 -1 + nudge 1 | normalize] 80)
    (plane [+1 -1 +1 + nudge 2 | normalize] 80)
    (plane [+1 -1 -1 + nudge 3 | normalize] 80)
    (plane [-1 +1 +1 + nudge 4 | normalize] 80)
    (plane [-1 +1 -1 + nudge 5 | normalize] 80)
    (plane [-1 -1 +1 + nudge 6 | normalize] 80)
    (plane [-1 -1 -1 + nudge 7 | normalize] 80)
  | expound (perlin p (20 * s + 30)) (20 * s) 20
  | shade (ok/hcl (t2 * 0.4) 0.4 0.6) | with-lights (light/ambient 1 normal)
  | gl/let [s (osc t2 1 0 1)] _
  | rotate [1 -1 -1 | normalize] (t / 10)
  | tint normal+ (fresnel 3)
  | tint white (fresnel 0.5 * 0.3)
  | map-color (fn [c] (c * (mix 0.1 1 (dot normal [-1 1 1 | normalize] | max 0))))))
</code></pre><p>Fortunately though, over the course of Bauble’s development, I had produced a comprehensive suite of test scripts with reference images that demonstrated all of the edge cases and problems that I had faced and already fixed and…</p>
<p>No, of course not. I can’t even type that with straight fingers. There were no tests. Actually, worse: there was <em>one</em> test. And it was failing.</p>
<p>I tried to fix it, when I finally noticed it was broken. I tried to reverse engineer my own code, untangle my spaghetti mess to figure out how it had ever worked in the first place, but eventually I gave up. It just wasn’t worth it. There was nothing worth salvaging, and the thought of starting over from scratch after all of the work I’d already done was so discouraging that I just stopped working on Bauble altogether.</p>
<p>And that’s the story of Bauble. It’s a sad story, a story of a codebase collapsing under its own weight, of a prototype trying to grow into a product, and finding that the old aphorism still holds true.</p>
<pre tabindex="0"><code data-lang="bauble">(defn half-hour [offset]
  (capsule y 300 (ss p.y 0 300 0 100) (ss p.y 0 300 80 100)
  | expound (perlin [0 (t + 2 | log * 300 + offset) 0 + p] 50) 20 10
  ))
(defn cel [shape color1 color2]
  (color shape (mix color1 color2 (fresnel 5 | quantize 3))
  | tint (vec3 -0.3) (fresnel 1 | quantize 3)))
(union :r 10
  (half-hour 0 | move y 4 | cel sky white)
  (gl/with [p [1 -1 1 * p]] (half-hour 1000 | move y 0 | cel orange red))
  | scale [1 0.5 1])
(set camera (camera/perspective [0 100 400]))
</code></pre><p>Two years passed.</p>
<pre tabindex="0"><code data-lang="bauble">(color r2
  (ok/mix (ok/hcl (length q | ss 0 150 0.2 0.4 + (t / 30)) (length q / 200 | ss 0 1 0.3 0.1) 0.9)
    (vec3 0.1)
  (fbm 3 perlin (normalize [q 10] * (ss t 0 20 0 20 + t)) [(vec2 (length q | sqrt)) 6]
+ (length q / 150)))
| rotate (t / 20))
</code></pre><p>I used Bauble on and off, but found myself increasingly annoyed by its limitations. Occasionally I would even try adding new features, but I could barely type through my hazmat suit.</p>
<p>I kept meaning to write a blog post about Bauble, about everything that I’d learned – how to embed Janet into a website and make an interactive art project that doesn’t use JavaScript – but I never got around to it. Meanwhile I wrote <a href="https://janet.guide/">a book about Janet</a>, and <a href="https://janet.guide/embedding-janet/">dedicated a chapter</a> to my embedding experience, but it never even mentions Bauble.</p>
<p>Despite being the most interesting side project that I’ve ever worked on, I haven’t written anything about it until now.</p>
<pre tabindex="0"><code data-lang="bauble">(gl/def sun-dir [0 -0.5 -1 | normalize])
(defn broad-height [xz] (perlin xz 10000 * 2000))
(gl/def sky-color (mix [1 0.5 1] [0 0 0] (ray.direction.y * 2) * 0.5
| mix (hsv (1 / 6) 0.5 1) (dot ray.direction (- sun-dir) | clamp 0 1)))
(plane y (perlin p.xz 600 * 200 + broad-height P.xz)
| expound (osc p.y 30) 10
| shade (hsv (0.6 / 6) 0.6 0.5 + (normal.yzx * 0.1)) :g (normal.y * 10) :s 0.1
| with-lights (light/directional 1 sun-dir 500 :shadow 0.5) (light/ambient (hsv 0.3 0.3 0.5) normal)
| map-color (fn [c] (mix c sky-color (1 - exp (* -0.0001 depth)) | pow [1.5 2 1.5]))
| slow 0.9)
(set background-color sky-color)
(gl/def camera-xz [(t * -500) 0])
(set camera (camera/perspective [camera-xz.x (broad-height camera-xz + 500) camera-xz.y] :dir [-1 -0.5 -0.10 | normalize]
| camera/tilt (osc t 20 -0.1 0.1)
| camera/pan (osc t 30 -0.1 0.1)))
</code></pre><p>I’m writing about it now because I recently took a few months off work, for the usual reason, and after some weeks of sleep deprivation and exhaustion and elation I found that I had a few cycles to spend on a side project.</p>
<p>But not a <em>hard</em> side project. Not something that required concentration, or prolonged stretches of focus – luxuries that I have temporarily foresworn. I needed something that I could, almost literally, do in my sleep.</p>
<pre tabindex="0"><code data-lang="bauble">(torus y 100 50
| expound (fbm 6 simplex p [100 50 100])
  (osc t 10 | ss 0.25 0.75 | mix 1 (simplex+ (p + 1000 + (t * 10)) 300 | ss 0.2 1 * 15 + 1) _)
  16
| shade 0.8 :g 40 :s 0.5
| rotate y (t / 2.5)
| slow 0.4
| tint [1 0.5 0.5] (fresnel 0.25 * 0.1)
| tint white (fresnel 5 * 0.1))
(set camera (camera/perspective [0 250 300 | rotate y (t / 2)]))
</code></pre><p>So I rewrote Bauble. Or rather, I <em>didn’t</em> rewrite Bauble – instead, I did all of the boring things that I never bothered with the first time around. I wrote a GLSL AST library, with a little pretty-printer. I wrote a typed expression-oriented language that adds “first-class” functions to GLSL. I wrote a Janet DSL for constructing programs in this high-level language, and I added Janet wrappers for (<em>almost</em>) all of GLSL’s built-in functions. I made a command-line interface to Bauble, using vanilla OpenGL instead of WebGL, so that I could finally write a real test suite.</p>
<p>I wrote a real test suite.</p>
<pre tabindex="0"><code data-lang="bauble">(def mouth (ball 50 | subtract (ball 200 | move y 200) | move z 100 | shade black))

(defn fork [shape f1 f2]
  (union (f1 shape) (f2 shape)))

(def teeth
  (box :r 2 [5 10 2]
  | rotate x 0.30
  | move y -40
  | fork
    (fn [$] ($ | move x 6))
    (fn [$] ($ | rotate x -0.04 | move x -6 z -1))
  | shade white :g 10 :s 1 )) # :ambient 0.5
(def eye-center [39 265 41])
(def eyelid
  (ball 40
  | move eye-center
  | subtract :r 10
    (ball 30 | move eye-center | move [0 -10 16])))
(def eye-color
  (shade r3 white  :g 10 :s 1 # :ambient 0.3
  | union (ball 10 | move z 30 | shade black :g 10 :s 1)))
(def eyeball
  (ball 35
  | shade white :g 10 :s 1
  | union-color (ball 10 | move [0 0 30] | shade black :g 10 :s 1)
  | rotate x 0.34 y (sin t | ss 0 0.1 * 0.2 - 0.1)
  | move eye-center))
(def neck
  (cylinder y 30 100
  | move y 100
  | rotate z (p.y * -0.001)
  | rotate x (p.y * 0.0010)
  | move y 85
  | union :r 10 eyelid))
(def head (ball 100 | scale y 0.9))

(def feet (box [20 30 20] :r 15
  | union :r 15 (box :r 10 [10 20 30]
  | fork
    (fn [$] ($ | rotate y 0.1 | move x 8))
    (fn [$] ($ | rotate y -0.1 | move x -11))
  | rotate x 0.015 y 0.37
  | move [15 -31 22])
  | move [50 -82 0]
  | rotate y 0.12
  | subtract :r 5 (plane y -110)
  | mirror x))

(union
  (union :r 60 head neck | union :r 10 feet | shade green :s 0.5 :g 6 | tint white (fresnel 15 * 0.5) | subtract :s 2 mouth)
  eyeball
  (teeth | move z 80)
  (ground -110 | shade gray)
| scale 0.5)
</code></pre><p>I worked bottom-up this time, building one boring primitive at a time and stacking them on top of each other. It was not the joyful exploratory everything-is-new interactive process of building Bauble for the first time, but it was still rewarding: I could see where it was going, and how to get there. It was delayed gratification this time, knowing that if I just got through the slog of the rewrite, I would be rewarded with something that I could be proud of.</p>
<pre tabindex="0"><code data-lang="bauble">(union :r 10
  (cone y 120 200)
  (cone y 100 150 | move [80 0 -44])
  (cone y 89 137 | move [-110 0 -9])
| expound (fbm :f 2.2 5 perlin [2 1 2 * p] 80) 20 40
| slow 0.5
| shade (normal+ | rotate y 1.34 | pow 2)
| move y (osc t 10 | ss 0 0.8 -230 -50)
| union :s 20 (plane y (osc (perlin [1 2 * p.xz] 200 + (t * 0.5)) 1 0 10) | shade sky :g 20 :s 1 | tint (fresnel 3))
)
</code></pre><p>And I am, now. This is a new Bauble, and it is, across every axis, a better Bauble.</p>
<p>You’ve already seen it of course, but let me give you a quick tour of what you can do with it now.</p>
<p>You can edit complicated shaders without lag: Bauble uses “web workers” now, so that all of the Janet evaluation and compilation and rendering takes place off of the UI thread. This… this doesn’t actually seem to work very well in Chrome or Safari, at least on my “Apple Silicon” MacBook – recompilation is pretty stuttery, taking around 100ms with both the OpenGL and Metal backends. But it’s buttery smooth in Firefox. Weird. WebGL rendering performance is also just universally better in Firefox – if any of the examples on this page are dipping below 60fps, maybe try switching?</p>
<p>You can export 3D models, and you can 3D print them:</p>
<a href="https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_1536x1536_fit_box_3.png"><picture><source type="image/webp" srcset="https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_768x768_fit_q75_h2_box_3.webp 768w,
https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_1536x1536_fit_q75_h2_box_3.webp 1536w,
https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_375x375_fit_q75_h2_box_3.webp 375w,
https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_750x750_fit_q75_h2_box_3.webp 750w" sizes="(max-width: 400px) 375px, 768px"><img srcset="https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_768x768_fit_box_3.png 768w,
https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_1536x1536_fit_box_3.png 1536w,
https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_375x375_fit_box_3.png 375w,
https://ianthehenry.com/posts/bauble/building-bauble/prints_hu39220f391f1ca3dd36179dd7d6b84420_6987945_750x750_fit_box_3.png 750w" alt="" title="" sizes="(max-width: 400px) 375px, 768px" width="768" height="386"></picture></a>
<p>That shape on the left is called a “gyroid,” and it was the first Bauble that I ever 3D printed (or, well, had someone cast in bronze for me). There’s no gyroid primitive in Bauble, but you can create custom shapes by writing out an implicit function directly:</p>
<pre tabindex="0"><code data-lang="bauble">(def gyroid (shape/3d (gl/with [p (p / 15)]
  (dot (cos p) (sin p.yzx)) + 1 * 10)))

(intersect :r 2.5 gyroid (ball 145))

# Er okay so this is not a "real" gyroid;
# it's more like a half-filled gyroid,
# because it's hard to print thin walls.
# The real deal looks like this:

# (def gyroid (shape/3d (gl/with [p (p / 15)]
#   (dot (cos p) (sin p.yzx)) * 10)))
#
# (intersect :r 2.5 (gyroid | shell 1) (ball 145))
</code></pre><p>I don’t have a 3D printer, and this feature is pretty new, so I haven’t really explored this very much yet. Also Bauble’s mesh export is… primitive, to say the least. It’s just marching cubes, which means you have to generate pretty large models if you want to preserve fine details. I realize that there are many better algorithms for triangulating SDFs, and Bauble should probably use one of them. But… I can only code for a few minutes a week now, and I spent my whole budget on the next feature.</p>
<p>You can embed Bauble on other pages. Not the way that I’ve been doing – the crimes I committed to Bauble’s build system in order to embed the editor here are not really replicable. But you can export your shaders to GLSL, and embed them on any page to add interactive 3D examples in a few lines of code. No one even needs to know you’re using Bauble:</p>
<div>
<h2>How do planet work?</h2>
<canvas id="planet"></canvas>
<p><label><span>Innard</span>

</label>
</p></div>
<p>Since Bauble pre-compiles the shader, the actual “<code>bauble.js</code>” that you have to embed is just a single 8kb pure-JS file.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> You don’t need to include the Janet compiler or WebAssembly or anything fancy like that – in fact, you don’t even have to use the Bauble library at all. You can construct the graphics context and compile the shader and draw it yourself, if you’d like.</p>
<p>There’s a biannual event called the “<a href="https://itch.io/jam/autumn-lisp-game-jam-2024">lisp game jam</a>,” and I think it would be fun to use Bauble to render the graphics for a game. Janet has <a href="https://github.com/janet-lang/jaylib">pretty good bindings</a> to <a href="https://www.raylib.com/">Raylib</a>, and you could use that to handle the input and sounds, but render all the graphics with Bauble.</p>
<p>Here, click on this, and then move around with WASD:</p>

<p>Obviously that’s not… a game, exactly. There’s no hit detection, and fire <em>probably</em> shouldn’t cast shadows. But, you know, that’s 30 lines of Bauble code plus 40 lines of JS for the event handling? Imagine what you could do if you weren’t furiously trying to finish the blog post you started writing months ago.</p>
<p>One of my favorite new features of Bauble is that you can edit vectors interactively. Not just the ctrl-click-and-drag on scalars that I mentioned already, but actual dragging vectors around in 3D. Here: put your cursor inside the <code>[50 100 150]</code>, and then open quad view with <code>alt-q</code>. You should see crosshairs, and then you can cmd- or ctrl-click and drag one of the orthographic viewports to edit the vector with your mouse. Try it on the <code>[0 0 0]</code> too, to move the box around!</p>
<pre tabindex="0"><code data-lang="bauble">(box [50 100 150]
| move [0 0 0])
</code></pre><p>So that’s everything you can do with Bauble.</p>
<p>Except… it’s not, is it? I just listed all of the things that <em>I</em> can do with Bauble. Because I know some things about SDFs, and I know Janet, and I understand this weird DSL that I’ve created. But <em>you</em> don’t – yet. How could you?</p>
<p>Which brings me to the last, biggest, and most important new feature of Bauble:</p>

<p>This is <a href="https://bauble.studio/help">https://bauble.studio/help</a>. I wrote a giant reference page with hundreds of interactive examples of every primitive and operation and <em>thing</em> that you can possibly do with Bauble. And it’s available right in the editor, any time you trigger autocomplete: the reference page and completions are both generated from the docstrings of the actual Janet functions. And in case the docstrings aren’t sufficient, there is a little <code>source</code> link next to every single definition that will take you straight to the code.</p>
<p>The documentation isn’t perfect: some some small helpers are missing examples; the “escape hatch” to writing raw GLSL isn’t really described at all, and it doesn’t include any of the functions that Bauble lifts directly from GLSL. And I fully realize that a reference like this is no substitute for a decent tutorial.</p>
<p>Bauble still needs a proper tutorial, and one day I’ll write it.</p>
<p>One day I’ll write the Book of Bauble, and explain SDFs and procedural noise and periodic distortions of space and all the tricks that I’ve learned, and how you can apply them to Bauble.</p>
<p>One day.</p>
<p>Let’s say… eighteen years from now, just to be on the safe side.</p>

<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>This is a little misleading, because the compiled shaders themselves are like 5-15kb each. I could minify their source, which would help a bit, but even without doing that, a single Bauble and the player library clocks in around 2% the size of embedding <code>p5.js</code>. (Comparing minified, uncompressed sizes, which is, again, misleading.)&nbsp;<a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's bot crushed this seven-person company's web site 'like a DDoS attack' (112 pts)]]></title>
            <link>https://techcrunch.com/2025/01/10/how-openais-bot-crushed-this-seven-person-companys-web-site-like-a-ddos-attack/</link>
            <guid>42660377</guid>
            <pubDate>Fri, 10 Jan 2025 21:21:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/01/10/how-openais-bot-crushed-this-seven-person-companys-web-site-like-a-ddos-attack/">https://techcrunch.com/2025/01/10/how-openais-bot-crushed-this-seven-person-companys-web-site-like-a-ddos-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=42660377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">On Saturday, <a href="https://triplegangers.com/" target="_blank" rel="noreferrer noopener nofollow">Triplegangers</a> CEO Oleksandr Tomchuk was alerted that his company’s e-commerce site was down. It looked to be some kind of distributed denial-of-service attack.&nbsp;</p>

<p>He soon discovered the culprit was a bot from OpenAI that was relentlessly attempting to scrape his entire, enormous site.&nbsp;</p>







<p>“We have over 65,000 products, each product has a page,” Tomchuk told TechCrunch. “Each page has at least three photos.”&nbsp;</p>

<p>OpenAI was sending “tens of thousands” of server requests trying to download all of it, hundreds of thousands of photos, along with their detailed descriptions.&nbsp;</p>

<p>“OpenAI used 600 IPs to scrape data, and we are still analyzing logs from last week, perhaps it’s way more,” he said of the IP addresses the bot used to attempt to consume his site.&nbsp;</p>

<p>“Their crawlers were crushing our site,” he said “It was basically a DDoS attack.”</p>

<p>Triplegangers’ website is its business. The seven-employee company has spent over a decade assembling what it calls the largest database of “human digital doubles” on the web, meaning 3D image files scanned from actual human models.&nbsp;</p>


<p>It sells the 3D object files, as well as photos — everything from hands to hair, skin, and full bodies — to 3D artists, video game makers, anyone who needs to digitally recreate authentic human characteristics.</p>

<p>Tomchuk’s team, based in Ukraine but also licensed in the U.S. out of Tampa, Florida, has a <a href="https://triplegangers.com/terms-of-use" target="_blank" rel="noreferrer noopener nofollow">terms of service page</a> on its site that forbids bots from taking its images without permission. But that alone did nothing. Websites must use a properly configured robot.txt file with tags specifically telling OpenAI’s bot, GPTBot, to leave the site alone. (OpenAI also has a couple of other bots, ChatGPT-User and OAI-SearchBot, that have their own tags, <a href="https://platform.openai.com/docs/bots/overview-of-openai-crawlers" target="_blank" rel="noreferrer noopener nofollow">according to its information page on its crawlers</a>.)</p>

<p>Robot.txt, otherwise known as the Robots Exclusion Protocol, was created to tell search engine sites what not to crawl as they index the web. OpenAI says on its informational page that it honors such files when configured with its own set of do-not-crawl tags, though it also warns that it can take its bots up to 24 hours to recognize an updated robot.txt file.</p>







<p>As Tomchuk experienced, if a site isn’t properly using robot.txt, OpenAI and others take that to mean they can scrape to their hearts’ content. It’s not an opt-in system.</p>

<p>To add insult to injury, not only was Triplegangers knocked offline by OpenAI’s bot during U.S. business hours, but Tomchuk expects a jacked-up AWS bill thanks to all of the CPU and downloading activity from the bot.</p>

<p>Robot.txt also isn’t a failsafe. AI companies voluntarily comply with it. Another AI startup, Perplexity, pretty famously got called out last summer by a Wired investigation <a href="https://techcrunch.com/2024/07/02/news-outlets-are-accusing-perplexity-of-plagiarism-and-unethical-web-scraping/">when some evidence implied Perplexity wasn’t </a>honoring it.</p>

<figure><img loading="lazy" decoding="async" width="2516" height="1732" data-destinationlink="https://triplegangers.com/browse/scans/full-body" data-event="clickable_image" src="https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?w=680" alt="Triplegangers product page" srcset="https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png 2516w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=150,103 150w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=300,207 300w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=768,529 768w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=680,468 680w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=1200,826 1200w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=1280,881 1280w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=430,296 430w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=720,496 720w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=900,620 900w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=800,551 800w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=1536,1057 1536w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=2048,1410 2048w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=668,460 668w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=545,375 545w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=896,617 896w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=708,487 708w" sizes="auto, (max-width: 2516px) 100vw, 2516px"><figcaption><span>Each of these is a product, with a product page that includes multiple more photos. Used by permission.</span><span><strong>Image Credits:</strong><a rel="nofollow" href="https://triplegangers.com/browse/scans/full-body" target="_blank">Triplegangers <span>(opens in a new window)</span></a></span></figcaption></figure>

<h2 id="h-can-t-know-for-certain-what-was-taken">Can’t know for certain what was taken</h2>

<p>By Wednesday, after days of OpenAI’s bot returning, Triplegangers had a properly configured robot.txt file in place, and also a Cloudflare account set up to block its GPTBot and several other bots he discovered, like Barkrowler (an SEO crawler) and Bytespider (TokTok’s crawler). Tomchuk is also hopeful he’s blocked crawlers from other AI model companies. On Thursday morning, the site didn’t crash, he said.</p>

<p>But Tomchuk still has no reasonable way to find out exactly what OpenAI successfully took or to get that material removed. He’s found no way to contact OpenAI and ask. OpenAI did not respond to TechCrunch’s request for comment. And OpenAI has so far <a href="https://techcrunch.com/2025/01/01/openai-failed-to-deliver-the-opt-out-tool-it-promised-by-2025/">failed to deliver its long-promised opt-out tool</a>, as TechCrunch recently reported.</p>

<p>This is an especially tricky issue for Triplegangers. “We’re in a business where the rights are kind of a serious issue, because we scan actual people,” he said. With laws like Europe’s GDPR, “they cannot just take a photo of anyone on the web and use it.”</p>

<p>Triplegangers’ website was also an especially delicious find for AI crawlers. <a href="https://techcrunch.com/2025/01/09/scale-ai-hit-by-its-second-employee-wage-lawsuit-in-less-than-a-month/">Multibillion-dollar-valued startups, like Scale AI</a>, have been created where humans painstakingly tag images to train AI. Triplegangers’ site contains photos tagged in detail: ethnicity, age, tattoos versus scars, all body types, and so on.</p>

<p>The irony is that the OpenAI bot’s greediness is what alerted Triplegangers to how exposed it was. Had it scraped more gently, Tomchuk never would have known, he said.</p>







<p>“It’s scary because there seems to be a loophole that these companies are using to crawl data by saying “you can opt out if you update your robot.txt with our tags,” says Tomchuk, but that puts the onus on the business owner to understand how to block them.</p>

<figure><img loading="lazy" decoding="async" width="2079" height="1206" src="https://techcrunch.com/wp-content/uploads/2025/01/openai-crawler-log-2-e1736526937976.jpg?w=680" alt="openai crawler log"><figcaption><span>Triplegangers’ server logs showed how ruthelessly an OpenAI bot was accessing the site, from hundreds of IP addresses. Used by permission.</span></figcaption></figure>

<p>He wants other small online businesses to know that the only way to discover if an AI bot is taking a website’s copyrighted belongings is to actively look. He’s certainly not alone in being terrorized by them. Owners of other websites recently told <a href="https://www.businessinsider.com/openai-anthropic-ai-bots-havoc-raise-cloud-costs-websites-2024-9" target="_blank" rel="noreferrer noopener nofollow">Business Insider</a> how OpenAI bots crashed their sites and ran up their AWS bills.</p>

<p>The problem grew magnitudes in 2024. New research from digital advertising company DoubleVerify <a href="https://doubleverify.com/ai-crawlers-and-scrapers-are-contributing-to-an-increase-in-general-invalid-traffic/" target="_blank" rel="noreferrer noopener nofollow">found that AI crawlers</a> and scrapers caused an 86% increase in “general invalid traffic” in 2024 — that is, traffic that doesn’t come from a real user.</p>

<p>Still, “most sites remain clueless that they were scraped by these bots,” warns Tomchuk. “Now we have to daily monitor log activity to spot these bots.”</p>

<p>When you think about it, the whole model operates a bit like a mafia shakedown: The AI bots will take what they want unless you have protection.</p>

<p>“They should be asking permission, not just scraping data,” Tomchuk says.</p>

<p><em>TechCrunch has an AI-focused newsletter!&nbsp;<a href="https://techcrunch.com/newsletters/" target="_blank" rel="noreferrer noopener">Sign up here</a>&nbsp;to get it in your inbox every Wednesday.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phi-4 Bug Fixes (177 pts)]]></title>
            <link>https://unsloth.ai/blog/phi4</link>
            <guid>42660335</guid>
            <pubDate>Fri, 10 Jan 2025 21:17:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unsloth.ai/blog/phi4">https://unsloth.ai/blog/phi4</a>, See on <a href="https://news.ycombinator.com/item?id=42660335">Hacker News</a></p>
Couldn't get https://unsloth.ai/blog/phi4: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>