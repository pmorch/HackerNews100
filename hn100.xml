<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 14 Sep 2024 01:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Lisp implemented in Rust macros (113 pts)]]></title>
            <link>https://github.com/RyanWelly/lisp-in-rs-macros</link>
            <guid>41535354</guid>
            <pubDate>Fri, 13 Sep 2024 21:31:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RyanWelly/lisp-in-rs-macros">https://github.com/RyanWelly/lisp-in-rs-macros</a>, See on <a href="https://news.ycombinator.com/item?id=41535354">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto"><code>lisp-in-rs-macros</code></h2><a id="user-content-lisp-in-rs-macros" aria-label="Permalink: lisp-in-rs-macros" href="#lisp-in-rs-macros"></a></p>
<p dir="auto">A simple, lexically scoped Lisp interpreter that operates fully in Rust's declarative macros. The <code>lisp!</code> macro expands to the lisp value computed by the code, and then stringifies it. This means that <code>lisp!(CAR (CONS (QUOTE A) (QUOTE (B))))</code> expands to the string "A" and that all this computation happens at compile time by rustc expanding macros.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why</h2><a id="user-content-why" aria-label="Permalink: Why" href="#why"></a></p>
<p dir="auto">It's a lisp interpreter written fully in Rust's macros, I think that's pretty cool. It's also less than 250 lines, which is neat.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="let output = lisp!(CAR (LIST (QUOTE A) (QUOTE B) (QUOTE C)));
assert_eq!(output, &quot;A&quot;); 

lisp!(PROGN
(DEFINE message (LAMBDA () (QUOTE &quot;hello there&quot;)))
(DISPLAY (message))
(DEFINE NOT (LAMBDA (X) (COND (X NIL) (TRUE TRUE))) )
(DISPLAY (NOT NIL))
); // will print &quot;hello there&quot; and &quot;TRUE&quot;
// &quot;DISPLAY&quot; forms first evaluate their arguments, then expand to a println!(&quot;{}&quot;, stringify!(evaled_argument))
"><pre><span>let</span> output = <span>lisp</span><span>!</span><span>(</span><span>CAR</span> <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>A</span><span>)</span> <span>(</span><span>QUOTE</span> <span>B</span><span>)</span> <span>(</span><span>QUOTE</span> <span>C</span><span>)</span><span>)</span><span>)</span><span>;</span>
<span>assert_eq</span><span>!</span><span>(</span>output, <span>"A"</span><span>)</span><span>;</span> 

<span>lisp</span><span>!</span><span>(</span><span>PROGN</span>
<span>(</span><span>DEFINE</span> message <span>(</span><span>LAMBDA</span> <span>(</span><span>)</span> <span>(</span><span>QUOTE</span> <span>"hello there"</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>DISPLAY</span> <span>(</span>message<span>)</span><span>)</span>
<span>(</span><span>DEFINE</span> <span>NOT</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>COND</span> <span>(</span><span>X</span> <span>NIL</span><span>)</span> <span>(</span><span>TRUE</span> <span>TRUE</span><span>)</span><span>)</span><span>)</span> <span>)</span>
<span>(</span><span>DISPLAY</span> <span>(</span><span>NOT</span> <span>NIL</span><span>)</span><span>)</span>
<span>)</span><span>;</span> <span>// will print "hello there" and "TRUE"</span>
<span>// "DISPLAY" forms first evaluate their arguments, then expand to a println!("{}", stringify!(evaled_argument))</span></pre></div>
<p dir="auto">As another fun example, here is a quine:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisp!
       ((LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s)))
       (QUOTE (LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s)))));"><pre><span>lisp</span><span>!</span>
       <span>(</span><span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span>
       <span>(</span><span>QUOTE</span> <span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>;</span></pre></div>
<p dir="auto">This code expands to:</p>
<div dir="auto" data-snippet-clipboard-copy-content="stringify!(((LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s)))
       (QUOTE (LAMBDA (s) (LIST s (LIST (QUOTE QUOTE) s))))));"><pre><span>stringify</span><span>!</span><span>(</span><span>(</span><span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span>
       <span>(</span><span>QUOTE</span> <span>(</span><span>LAMBDA</span> <span>(</span>s<span>)</span> <span>(</span><span>LIST</span> s <span>(</span><span>LIST</span> <span>(</span><span>QUOTE</span> <span>QUOTE</span><span>)</span> s<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>;</span></pre></div>
<p dir="auto">In other words, the code evaluates to itself. Isn't that wonderful?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Recursion</h2><a id="user-content-recursion" aria-label="Permalink: Recursion" href="#recursion"></a></p>
<p dir="auto">This lisp does not currently support any explicit form of recursion. Luckily, explicit recursion is not needed, all we need is lambda.</p>
<p dir="auto">You can write a simple function that appends two lists by using self application:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisp!(PROGN
(DEFINE append 
    (LAMBDA (self X Y) 
        (COND 
            ((EQ X NIL) Y) 
            (TRUE (CONS (CAR X) (self self (CDR X) Y))) 
        )))
(append append (QUOTE (A B)) (QUOTE (C D)))

)"><pre><span>lisp</span><span>!</span><span>(</span><span>PROGN</span>
<span>(</span><span>DEFINE</span> append 
    <span>(</span><span>LAMBDA</span> <span>(</span><span>self</span> <span>X</span> <span>Y</span><span>)</span> 
        <span>(</span><span>COND</span> 
            <span>(</span><span>(</span><span>EQ</span> <span>X</span> <span>NIL</span><span>)</span> <span>Y</span><span>)</span> 
            <span>(</span><span>TRUE</span> <span>(</span><span>CONS</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span> <span>(</span><span>self</span> <span>self</span> <span>(</span><span>CDR</span> <span>X</span><span>)</span> <span>Y</span><span>)</span><span>)</span><span>)</span> 
        <span>)</span><span>)</span><span>)</span>
<span>(</span>append append <span>(</span><span>QUOTE</span> <span>(</span><span>A</span> <span>B</span><span>)</span><span>)</span> <span>(</span><span>QUOTE</span> <span>(</span><span>C</span> <span>D</span><span>)</span><span>)</span><span>)</span>

<span>)</span></pre></div>
<p dir="auto">This results in "(A B C D)". The append function does not mention <code>append</code> in its body, yet we can call it recursively. Wonderful!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notes for use</h2><a id="user-content-notes-for-use" aria-label="Permalink: Notes for use" href="#notes-for-use"></a></p>
<p dir="auto">The lisp! macro only evaluates a single expression; if you want to evaluate multiple expressions, use <code>(PROGN expr1 expr2 expr3)</code>. This evaluates all the expressions, and returns the value of the last expression. The DISPLAY form evaluates a single expression, then generates a <code>println!("{}", stringify!(...))</code> statement which prints the stringified version of the tokens. The empty list is not self evaluating, you can use <code>NIL</code> or <code>(QUOTE ())</code> to obtain an empty list value. The empty list is the sole "falsy" object.
Dotted lists aren't supported, cons assumes its last argument is a list. The define form can be used anywhere and evaluates to the empty list, but does not support recursion. TRUE is the only self evaluating atom (that isn't a function).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported forms</h2><a id="user-content-supported-forms" aria-label="Permalink: Supported forms" href="#supported-forms"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="DEFINE 
QUOTE 
LAMBDA 
LET
PROGN 
CAR 
CDR 
CONS
LIST
EQ
ATOM
APPLY"><pre><span>DEFINE</span> 
<span>QUOTE</span> 
<span>LAMBDA</span> 
<span>LET</span>
<span>PROGN</span> 
<span>CAR</span> 
<span>CDR</span> 
<span>CONS</span>
<span>LIST</span>
<span>EQ</span>
<span>ATOM</span>
<span>APPLY</span></pre></div>
<p dir="auto">Note: dotted lists are not supported, CONS assumes its latter argument is a list. Define does not handle recursive definitions, it's more like internal definitions in Scheme than a true lispy define.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Metacircular interpreter</h2><a id="user-content-metacircular-interpreter" aria-label="Permalink: Metacircular interpreter" href="#metacircular-interpreter"></a></p>
<p dir="auto">Here is a lisp interpreter written in my lisp:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lisp!(PROGN
            // Y &quot;combinator&quot; for two arguments
        (DEFINE Y2 
                        (LAMBDA (h)
                            ((LAMBDA (x) (h (LAMBDA (a b) ((x x) a b))))
                                (LAMBDA (x) (h (LAMBDA (a b) ((x x) a b)))))))
        
        (DEFINE CADR (LAMBDA (X) (CAR (CDR X))))
        (DEFINE CAAR (LAMBDA (X) (CAR (CAR X))))
        (DEFINE CADAR (LAMBDA (X) (CAR (CDR (CAR X)))))
        (DEFINE CADDR (LAMBDA (X) (CAR (CDR (CDR X)))))
        (DEFINE CADDAR (LAMBDA (X) (CAR (CDR (CDR (CAR X))))))
        (DEFINE CAADAR (LAMBDA (X) (CAR (CAR (CDR (CAR X))))))

        (DEFINE ASSOC (Y2 (LAMBDA (ASSOC) (LAMBDA (X ENV) 
                        (IF (EQ (CAAR ENV) X) (CADAR ENV) (ASSOC X (CDR ENV)))
                    )))
                )


            
        (DEFINE eval (Y2 (LAMBDA (EVAL) (LAMBDA (E A) 
                (COND
                    ((ATOM E) (ASSOC E A))
                    ((ATOM (CAR E)) 
                        (COND 
                            ((EQ (CAR E) (QUOTE quote)) (CADR E))
                            ((EQ (CAR E) (QUOTE atom)) (ATOM (EVAL (CADR E) A)))
                            ((EQ (CAR E) (QUOTE car)) (CAR (EVAL (CADR E) A)))
                            ((EQ (CAR E) (QUOTE cdr)) (CDR (EVAL (CADR E) A)))
                            ((EQ (CAR E) (QUOTE equal)) (EQ (EVAL (CADR E) A) (EVAL (CADDR E) A)))
                            ((EQ (CAR E) (QUOTE cons)) (CONS (EVAL (CADR E) A) (EVAL (CADDR E) A)))
                            (TRUE (EVAL (CONS (ASSOC (CAR E) A) (CDR E)) A)) 
                        )
                    )
                    ((EQ (CAAR E) (QUOTE lambda)) (EVAL (CADDAR E) (CONS (LIST (CAADAR E) (EVAL (CADR E) A)) A)  )) //Evaluate the inner expression of the lambda, in the environment with the argument bound to the parameter
                
                )
            ))))

        (eval (QUOTE (quote (A))) NIL)
        // (eval (QUOTE (atom (quote A))) NIL )
        // (eval (QUOTE (cdr (cdr (quote (A B))))) NIL)
        // (eval (QUOTE (cons (quote a) (quote (a)))) NIL)
        // (eval (QUOTE ((lambda (x) (quote a)) (quote b))) NIL)
        (eval (QUOTE ((lambda (X) X) (quote a))) NIL)

        );"><pre><span>lisp</span><span>!</span><span>(</span><span>PROGN</span>
            <span>// Y "combinator" for two arguments</span>
        <span>(</span><span>DEFINE</span> <span>Y2</span> 
                        <span>(</span><span>LAMBDA</span> <span>(</span>h<span>)</span>
                            <span>(</span><span>(</span><span>LAMBDA</span> <span>(</span>x<span>)</span> <span>(</span>h <span>(</span><span>LAMBDA</span> <span>(</span>a b<span>)</span> <span>(</span><span>(</span>x x<span>)</span> a b<span>)</span><span>)</span><span>)</span><span>)</span>
                                <span>(</span><span>LAMBDA</span> <span>(</span>x<span>)</span> <span>(</span>h <span>(</span><span>LAMBDA</span> <span>(</span>a b<span>)</span> <span>(</span><span>(</span>x x<span>)</span> a b<span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        
        <span>(</span><span>DEFINE</span> <span>CADR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CAAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CADAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CADDR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CDR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CADDAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CDR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>DEFINE</span> <span>CAADAR</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>CAR</span> <span>(</span><span>CDR</span> <span>(</span><span>CAR</span> <span>X</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span>

        <span>(</span><span>DEFINE</span> <span>ASSOC</span> <span>(</span><span>Y2</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>ASSOC</span><span>)</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>X</span> <span>ENV</span><span>)</span> 
                        <span>(</span><span>IF</span> <span>(</span><span>EQ</span> <span>(</span><span>CAAR</span> <span>ENV</span><span>)</span> <span>X</span><span>)</span> <span>(</span><span>CADAR</span> <span>ENV</span><span>)</span> <span>(</span><span>ASSOC</span> <span>X</span> <span>(</span><span>CDR</span> <span>ENV</span><span>)</span><span>)</span><span>)</span>
                    <span>)</span><span>)</span><span>)</span>
                <span>)</span>


            
        <span>(</span><span>DEFINE</span> eval <span>(</span><span>Y2</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>EVAL</span><span>)</span> <span>(</span><span>LAMBDA</span> <span>(</span><span>E</span> <span>A</span><span>)</span> 
                <span>(</span><span>COND</span>
                    <span>(</span><span>(</span><span>ATOM</span> <span>E</span><span>)</span> <span>(</span><span>ASSOC</span> <span>E</span> <span>A</span><span>)</span><span>)</span>
                    <span>(</span><span>(</span><span>ATOM</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span><span>)</span> 
                        <span>(</span><span>COND</span> 
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> quote<span>)</span><span>)</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> atom<span>)</span><span>)</span> <span>(</span><span>ATOM</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> car<span>)</span><span>)</span> <span>(</span><span>CAR</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> cdr<span>)</span><span>)</span> <span>(</span><span>CDR</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> equal<span>)</span><span>)</span> <span>(</span><span>EQ</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADDR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> cons<span>)</span><span>)</span> <span>(</span><span>CONS</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADDR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span><span>)</span>
                            <span>(</span><span>TRUE</span> <span>(</span><span>EVAL</span> <span>(</span><span>CONS</span> <span>(</span><span>ASSOC</span> <span>(</span><span>CAR</span> <span>E</span><span>)</span> <span>A</span><span>)</span> <span>(</span><span>CDR</span> <span>E</span><span>)</span><span>)</span> <span>A</span><span>)</span><span>)</span> 
                        <span>)</span>
                    <span>)</span>
                    <span>(</span><span>(</span><span>EQ</span> <span>(</span><span>CAAR</span> <span>E</span><span>)</span> <span>(</span><span>QUOTE</span> lambda<span>)</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADDAR</span> <span>E</span><span>)</span> <span>(</span><span>CONS</span> <span>(</span><span>LIST</span> <span>(</span><span>CAADAR</span> <span>E</span><span>)</span> <span>(</span><span>EVAL</span> <span>(</span><span>CADR</span> <span>E</span><span>)</span> <span>A</span><span>)</span><span>)</span> <span>A</span><span>)</span>  <span>)</span><span>)</span> <span>//Evaluate the inner expression of the lambda, in the environment with the argument bound to the parameter</span>
                
                <span>)</span>
            <span>)</span><span>)</span><span>)</span><span>)</span>

        <span>(</span>eval <span>(</span><span>QUOTE</span> <span>(</span>quote <span>(</span><span>A</span><span>)</span><span>)</span><span>)</span> <span>NIL</span><span>)</span>
        <span>// (eval (QUOTE (atom (quote A))) NIL )</span>
        <span>// (eval (QUOTE (cdr (cdr (quote (A B))))) NIL)</span>
        <span>// (eval (QUOTE (cons (quote a) (quote (a)))) NIL)</span>
        <span>// (eval (QUOTE ((lambda (x) (quote a)) (quote b))) NIL)</span>
        <span>(</span>eval <span>(</span><span>QUOTE</span> <span>(</span><span>(</span>lambda <span>(</span><span>X</span><span>)</span> <span>X</span><span>)</span> <span>(</span>quote a<span>)</span><span>)</span><span>)</span> <span>NIL</span><span>)</span>

        <span>)</span><span>;</span></pre></div>
<p dir="auto">It appears to work, but trying to evaluate <code>((lambda (X) X) (quote a))</code> in the interpreter takes more than 30 seconds and generates far more than 1 million+ tokens before cargo gets sigkilled. Using the explicit y combinator for recursion isn't particularly efficient here! To fix this, I should add an explicit recursion primitive.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical explanation</h2><a id="user-content-technical-explanation" aria-label="Permalink: Technical explanation" href="#technical-explanation"></a></p>
<p dir="auto">Look at EXPLANATION.md. The macro essentially simulates a SECD machine, which is a simple stack-basd abstract machine for evaulating lambda calculus terms.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Awesome resources</h2><a id="user-content-awesome-resources" aria-label="Permalink: Awesome resources" href="#awesome-resources"></a></p>
<ul dir="auto">
<li>Functional Programming: Application and Implementation by Peter Henderson</li>
<li>Ager, Mads Sig, et al. "A functional correspondence between evaluators and abstract machines." Proceedings of the 5th ACM SIGPLAN international conference on Principles and practice of declaritive programming. 2003.</li>
<li>The Implementation of Functional Programming Languages by Simon Peyton Jones</li>
<li>Anything Matt Might has ever written about lisp on his blog (<a href="https://matt.might.net/" rel="nofollow">https://matt.might.net</a>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODO</h2><a id="user-content-todo" aria-label="Permalink: TODO" href="#todo"></a></p>
<ul dir="auto">
<li>Add letrec</li>
<li>Add recursive defines</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CrowdStrike ex-employees: 'Quality control was not part of our process' (231 pts)]]></title>
            <link>https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage</link>
            <guid>41534716</guid>
            <pubDate>Fri, 13 Sep 2024 20:17:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage">https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage</a>, See on <a href="https://news.ycombinator.com/item?id=41534716">Hacker News</a></p>
Couldn't get https://www.semafor.com/article/09/12/2024/ex-crowdstrike-employees-detail-rising-technical-errors-before-july-outage: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Janet Jackson had the power to crash laptop computers (2022) (111 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994</link>
            <guid>41534483</guid>
            <pubDate>Fri, 13 Sep 2024 19:44:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994">https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994</a>, See on <a href="https://news.ycombinator.com/item?id=41534483">Hacker News</a></p>
Couldn't get https://devblogs.microsoft.com/oldnewthing/20220816-00/?p=106994: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI threatens to revoke o1 access for asking it about its chain of thought (403 pts)]]></title>
            <link>https://twitter.com/SmokeAwayyy/status/1834641370486915417</link>
            <guid>41534474</guid>
            <pubDate>Fri, 13 Sep 2024 19:43:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/SmokeAwayyy/status/1834641370486915417">https://twitter.com/SmokeAwayyy/status/1834641370486915417</a>, See on <a href="https://news.ycombinator.com/item?id=41534474">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[I won't be renewing my Pinboard subscription (150 pts)]]></title>
            <link>https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html</link>
            <guid>41533958</guid>
            <pubDate>Fri, 13 Sep 2024 18:47:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html">https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html</a>, See on <a href="https://news.ycombinator.com/item?id=41533958">Hacker News</a></p>
Couldn't get https://notes.kateva.org/2024/09/the-end-times-have-come-for-pinboardin.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Meta fed its AI on everything adults have publicly posted since 2007 (162 pts)]]></title>
            <link>https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data</link>
            <guid>41533060</guid>
            <pubDate>Fri, 13 Sep 2024 17:05:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data">https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data</a>, See on <a href="https://news.ycombinator.com/item?id=41533060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Meta has acknowledged that all text and photos that adult Facebook and Instagram users have publicly published since 2007 have been fed into its artificial intelligence models. <a href="https://www.abc.net.au/news/2024-09-11/facebook-scraping-photos-data-no-opt-out/104336170">Australia’s ABC News reports</a> that Meta’s global privacy director, Melinda Claybaugh, initially rejected claims about user data from 2007 being leveraged for AI training during a local government inquiry about AI adoption before relenting after additional questioning.</p><p>“The truth of the matter is that unless you have consciously set those posts to private since 2007, Meta has just decided that you will scrape all of the photos and all of the texts from every public post on Instagram or Facebook since 2007 unless there was a conscious decision to set them on private,” Green Party senator David Shoebridge pushed in the inquiry. “That’s the reality, isn’t it?”</p><p>“Correct,” Claybaugh responded.</p><p>Meta’s <a href="https://www.facebook.com/privacy/guide/generative-ai/">privacy center</a> and <a href="https://about.fb.com/news/2023/09/privacy-matters-metas-generative-ai-features/">blog posts</a> acknowledge hoovering up public posts and comments from Facebook and Instagram to train generative AI:</p><div><blockquote><p>We use public posts and comments on Facebook and Instagram to train generative AI models for these features and for the open source community.</p><p>We don’t use posts or comments with an audience other than Public for these purposes.</p></blockquote></div><p>But the company has been vague about how data is used, when it started scraping, and how far back its collection goes. Asked by <em>The New York Times</em> in June, Meta didn’t answer, other than to confirm that setting posts <a href="https://www.nytimes.com/2024/06/07/technology/meta-ai-scraping-policy.html">to anything besides “public” will prevent future scraping</a>. That still won’t delete data that has already been collected — and people posting back in 2007 (who may have been minors at the time) wouldn’t have known their photos and posts would be used in this way.</p><p>Claybaugh said that Meta doesn’t scrape data from users who are under the age of 18. When Labor Party senator Tony Sheldon asked if Meta would scrape the public photos of his children on his own account, Claybaugh confirmed it would and was unable to clarify if the company also scraped adult accounts that were created when the user was still a child.</p><p>European users can opt out <a href="https://www.theverge.com/2024/6/14/24178591/meta-ai-assistant-europe-ireland-privacy-objections">due to local privacy regulations</a>, and Meta was recently <a href="https://www.theverge.com/2024/7/3/24191405/meta-anpd-stop-training-ai-on-brazilian-facebook-instagram-data">banned from using Brazilian personal data</a> for AI training, but the billions of Facebook and Instagram users in other regions can’t opt out if they want to keep their posts public. Claybaugh was unable to say if Australian users (or anyone else) would be given a choice to opt out in the future, arguing that the option was given to European users because of <a href="https://www.theverge.com/2024/7/18/24201041/meta-multimodal-llama-ai-model-launch-eu-regulations">uncertainty regarding its regulatory landscape</a>.</p><p>“Meta made it clear today that if Australia had these same laws Australians’ data would also have been protected,” Shoebridge said to ABC News. “The government’s failure to act on privacy means companies like Meta are continuing to monetize and exploit pictures and videos of children on Facebook.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zero-Click Calendar invite – Critical zero-click vulnerability chain in macOS (335 pts)]]></title>
            <link>https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b</link>
            <guid>41532946</guid>
            <pubDate>Fri, 13 Sep 2024 16:50:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b">https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b</a>, See on <a href="https://news.ycombinator.com/item?id=41532946">Hacker News</a></p>
Couldn't get https://mikko-kenttala.medium.com/zero-click-calendar-invite-critical-zero-click-vulnerability-chain-in-macos-a7a434fc887b: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Defend against vampires with 10 gbps network encryption (147 pts)]]></title>
            <link>https://www.synacktiv.com/en/publications/defend-against-vampires-with-10-gbps-network-encryption</link>
            <guid>41531699</guid>
            <pubDate>Fri, 13 Sep 2024 14:42:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.synacktiv.com/en/publications/defend-against-vampires-with-10-gbps-network-encryption">https://www.synacktiv.com/en/publications/defend-against-vampires-with-10-gbps-network-encryption</a>, See on <a href="https://news.ycombinator.com/item?id=41531699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="schema:text"><p>Let's say you have a fiber optic line running between two buildings, or between two spaces you rent in the same building. You use trunk ports on the switches connected to the fiber, in order to "stretch" your L2 Ethernet network and its different VLANs, so computers, servers, printers, cameras, etc. in both offices easily communicate with their peers.</p>
<p>But there is next to no physical security in the shared wiring closets and common cabling paths, and so you are concerned about someone <em>tapping</em>&nbsp;into the fiber line and capturing data.</p>
<p>First you may ask, is that really possible? And if so, is it easy to do? Would you need NSA-level hardware and skills or could anyone do it?</p>
<p>Turns out, it is both possible and easy, so you're right to worry! But there is a solution...</p>

<h3>Tapping on copper cables<br>
&nbsp;</h3>
<p>It's so simple to tap on copper network cables that back in the 80s, it was the official way to expand your 10BASE5 Ethernet network. IT people&nbsp;used so-called "vampire taps" that truly <em>bit</em> through the insulation of the cable to make contact with the conductors inside, enabling a new connection without interrupting ongoing data transmission.</p>
<figure role="group">
<img alt="photo of a 80s vampire tap showing bite marks on the cable" data-entity-type="file" data-entity-uuid="239417dc-b316-4b38-8a2e-a7a6589df581" src="https://www.synacktiv.com/sites/default/files/inline-images/vampiretap.jpg">
<figcaption>Vampire tap and 10BASE5 Ethernet cable showing "bite marks"</figcaption>
</figure>
<p><a href="https://www.tiktok.com/@davidbombal/video/7246772712696335643">This&nbsp;TikTok video</a> shows one of these devices in action.</p>
<p>Nowadays, people might still use copper cables instead of fiber for distances &lt; 100m, and <a href="https://en.wikipedia.org/wiki/Network_tap#Gigabit_Ethernet_issues">it's a bit more difficult to tap on 1000BASE-T modern cables</a>. Anyway, since our typical LAN-to-LAN scenario rather involves optical fibers running along not-well-protected cable runways, let's see if optical fibers are&nbsp;vulnerable too.</p>
<h3><br>
Tapping on optical fiber<br>
&nbsp;</h3>
<p>For a number of years it was commonly believed that tapping on optical fibers was possible, but that it needed both expertise and expensive hardware.</p>
<p>But in 2015, the late <a href="https://www.zdnet.com/article/infamous-hacker-kevin-mitnick-sniffs-fiber-reads-email/">Kevin Mitnick demonstrated just how easy it is to tap into a fiber and sniff the traffic</a>, using a 200$ optical "clip-on coupler".</p>
<p>These&nbsp;couplers are originally designed to be used by line technicians to talk to one another over long distances using so-called "optical talk sets", and&nbsp;coordinate with one another while installing these&nbsp;fibers, even when they have no access to the ends of the fiber.</p>
<p>They work by exposing a portion of the fiber core and bending it slightly,&nbsp;reflecting some 2-3% of the light inside the fiber (but still 100% of its data) and also allowing to inject light in it. Of course, it's better to have some practice and a steady hand in order to expose the fiber core without damaging the fiber.</p>
<p>In true hacker fashion, these&nbsp;couplers are creatively used by attackers to read data from the fiber, and inject data of their own.&nbsp;</p>
<figure role="group">
<img alt="clip-on coupler like the one used by Mitnick" data-entity-type="file" data-entity-uuid="f8ad2517-2643-41eb-b7d6-358848d41033" src="https://www.synacktiv.com/sites/default/files/inline-images/clip_on_coupler_small.jpg">
<figcaption>The&nbsp;FOD5516 Clip-on Coupler that can detect and inject light in (singlemode) optical fiber</figcaption>
</figure>
<p>This opens many classical man-in-the-middle attack scenarios such as forcing the downgrade&nbsp;of crypto protocols, redirecting traffic, etc. on top of simple sniffing.</p>

<h2>Encrypt ALL the things !<br>
&nbsp;</h2>
<p>So it seems there's not much you can do to prevent vampire tapping onto your easily-accessible cable paths. In fact, they might already be there...</p>
<p>As with any confidentiality issue, the best solution lies in encryption. If your whole network traffic is encrypted, the data vampires might still suck on your network cables, but instead of draining the very blood of your company, they will only gather encrypted gibberish of no use to them.</p>
<p>But how exactly can you encrypt "everything" in such a LAN-to-LAN scenario? And at what cost?</p>
<p>If you had routers on both ends of the fiber, with each site having its own dedicated IP zones with no overlap, you could easily setup a VPN tunnel like IPSec or Wireguard between the two routers and solve your problem.<br>
That said, if you used a "stretched L2" approach like in our scenario, it would not be easy to go back and re-segment&nbsp;all your networking, moving&nbsp;from bridging&nbsp;to&nbsp;routing traffic.<br>
You could try instead to enforce the policy that every applicative stream on your network, even print jobs, realtime video, DNS, etc. uses only a "secure" (encrypted) version of its protocol. It's certainly an impressive feat if you've managed to achieve that in a typical office environment ☺️.&nbsp;Even so, you'd likely still be interested into setting some kind of encrypted tunnel on the fiber, just in case someone sets up accidentaly some unsecure applicative stream...</p>
<p>The idea we had to solve such a problem, with the least disruption to existing networks and protocols, was to mix "802.1q trunk links" and VPN-like encryption between the two ends of the fiber. So&nbsp;instead of plugging the fiber directly into your switches, you plug them to an equipment with two network interfaces, that will on one end "swallow" all your 802.1q traffic (VLANs and all) and then transfer them over the fiber, through an encrypted tunnel, to a second "mirror" equipment that will decrypt the packets and transform them again into 802.1q frames and "spit them out" to its&nbsp;local network. This was dubbed the "wormhole" project.</p>
<h2>The quest for the encrypted trunk : MACsec</h2>
<p>If you search for ways to "encrypt/secure a 802.1q trunk" you will probably read about MACsec, aka the Cisco-designed 802.1ae standard, which on paper seems to do exactly what we want, with the added benefit that if you use MACsec-capable switches on each end of the fiber, you don't need additionnal equipements to do the secure tunneling.</p>
<p>MACsec creates point-to-point Secure Channels pairs (one for Tx, one for Rx) between two devices over an untrusted connection, using first a negotiation protocol called MKA (MACsec Key Agreement) and for example pre-shared keys (or a PKI). Over these Secure Channels, MACSec Frames are sent, which are only slightly modified Ethernet frames with their layer-3+ payload encrypted using GCM-AES-128 (or GCM-AES-256 in newer hardware). Since they are essentially Ethernet frames, MACSec can natively support 802.1q VLAN headers for example.</p>
<p>In order to test these promises, we bought a pair of the smallest Cisco switch that supports MACsec : the Catalyst 3560 CX WS-3560CX-8XPD-S, at ~1600€ each.</p>
<h3><br>
Testing MACsec</h3>
<p>Unfortunately, during our testing we found MACsec underwhelming for our LAN-to-LAN scenario.</p>
<p>First, it's difficult to find accurate MACsec documentation since it supports a variety of use cases (securing a link between a workstation and a switch, securing a link between two switches...) and as usual with Cisco, there are configuration directives that may or may not exist on a given Cisco switch, depending on its IOS image, feature level, generation, etc. So it was a bit of a pain to get it working for our trunk ports.</p>
<p>Then, we found out something that in hindsight was pretty clear in the MACsec specification&nbsp;: MACsec <em>does not hide the real MAC addresses of devices talking on your network</em> to the eavesdropping attacker. It may make sense, in order for traffic to be able go through MACsec-unaware bridges, to preserve the original MAC adresses of (for example) two computers talking to each other, but we expected to be able to see only the MAC Adresses of the two switches directly connected to the untrusted network and doing the MACsec tunnel. This could have been considered a minor inconvenience, but as MAC addresses are assigned by device manufacturers, it gives an attacker quite a good intel on what brand of computer, printer, appliances, etc. devices you have on your network, so that may help them plan a targeted attack. And if you're worried about industrial espionage, maybe you don't want your spying concurrent to know what brand of components you use on your R&amp;D VLANs either.</p>
<p>Last but not least, on several occasions during our offensive testing, we were able to mess with the MKA/MACsec traffic enough (using not-so-transparent software bridges and resetting MKA sessions on the switches ) so that half of the traffic (corresponding to one of the two secure channels) was being sent fully unencrypted, despite the <code>linksec policy must-secure</code> settings on the ports specifying to never send traffic in the clear on this interface according to Cisco documentation ("Must-Secure imposes that only MACsec encrypted traffic can flow. Hence, until the MKA session is secured, traffic is dropped."). Moreover, the switches were not reporting errors at all and happily continued sending/receiving clear traffic on MACsec must-secure interfaces. The end-user devices (laptops) had no way to know their traffic was being read, since their communications continued as usual (minus the loss of a few ICMP or UDP packets during MKA renegociation).</p>
<figure role="group">
<img alt="wireshard capture showing half the traffic in clear" data-entity-type="file" data-entity-uuid="7101fb11-ea1d-4bcb-81c4-10ca1c3fa7fb" src="https://www.synacktiv.com/sites/default/files/inline-images/pcap_macsec_clair.png">
<figcaption>Wireshark traffic capture : the ping replies are sent in clear over the MACsec link, although the ping echo requests are still sent encrypted.</figcaption>
</figure>
<p>This behaviour was observed with the most recent IOS firmware at that time, and although it then required both 1) an attacker on the fiber doing Man-in-the-Middle and dropping some frames, and 2) an admin action on the switch CLI itself (<code>clear mka sessions</code>), given that the MKA sessions have an expiry and must be renegociated after some time or when a port goes down, we think it's likely that there's a way to trigger that behavior only by "sitting on the wire" with no CLI access to the switch.</p>
<p>The bug tracker from Cisco showed bugs and behaviour that, although apparently not applying to our model, looked close to what we found:</p>
<ul>
<li><a href="https://bst.cisco.com/quickview/bug/CSCvx83835">"MACsec access-control must-secure is allowing the unencrypted traffic to pass through a link"</a></li>
<li><a href="https://bst.cisco.com/quickview/bug/CSCvw36505">"MACsec ports in Auth-pending state after changing to should secure policy with Empty keychain"</a></li>
<li><a href="https://bst.cisco.com/quickview/bug/CSCus74990">"MKA sessions struck in "pending" state after clear MKA sess"</a></li>
</ul>
<p>We had to drop there our experiments with our Cisco switches since the goal of this mission was to "find a reliable way to encrypt LAN to LAN fiber links at high speed", not to "break MACsec", but we may go back to it sometime in the future :)</p>
<h2>Native Linux solution : VXLAN+Wireguard</h2>
<p>Having set MACsec aside, we decided to PoC something that would use only native and well-known Linux kernel features on commodity hardware.</p>
<p>Since Wireguard is the state-of-the-art, in-kernel tunneling, was there a way to shove 802.1q L2 traffic inside a wireguard tunnel, and what speeds could be reached on customer-level hardware costing approximately the same as the Cisco switches we just tested ?</p>
<p>The "missing bit" to go from an L2 trunk to a L3 tunnel was solved by using VXLAN.&nbsp;</p>
<h3>VXLAN</h3>
<p>VXLAN is a protocol used to carry over L2 frames using UDP encapsulation (port 4789 or 8472 depending on the implementation) to a distant endpoint (called VTEP, for "VXLAN termination endpoint"). It works by hooking onto L2 forwarding tables (like on a Linux bridge), and sending to the remote VTEP the frames that must be broadcasted on the segment, along with the frames that have no local destination ("flood and learn"). The remote VTEP decapsulates the L2 frame from the UDP packet and sends it to its local network.</p>
<p>VXLAN real-world use case mostly involves "datacenter bridging", so that VMs from Datacenter 1 could behave like they are "on the same Ethernet segment" than VMs from Datacenter 2 so they can really share the same IP subnet (respond to ARP "who-has", etc).&nbsp;</p>
<p>Despite its name, VXLAN is only "inspired" by the concept of L2 VLANs : it is not something that will, out-of-the box, listen on a trunk port and carry 802.1q tagged frames to the remote endpoint. But it's very possible to do so using Linux wonderful networking stack ! You just need to to map each&nbsp;802.1q VLAN ID to a VXLAN "vid" and do the same thing in reverse on the other VTEP.</p>
<p>Most of the documentation you find online about injecting L2 VLAN info into a VXLAN&nbsp;tunnel has you creating a Linux bridge + a VLAN interface + a VXLAN interface <em>per VLAN </em>that&nbsp;you want to transmit.&nbsp;<br>
If you use all 4096 VLANs, or want to be able to add/drop VLANs on your network without having to do so many steps each time, you can use iproute2 commands <code>bridge</code> and <code>ip</code>&nbsp;with some recent feature flags (<code>vlan_filtering, vlan_default_pvid,&nbsp;vlan_tunnel + tunnel_info</code>)&nbsp;to spare yourself some time and have less clutter on your Linux "wormhole" boxes. The <code>vlan_default_pvid&nbsp;</code>flag is very important to be able to keep 802.1q headers "inside the bridge" and have them reach the vxlan interface where they will then be mapped to a vxlan <code>vid</code>.</p>
<p>With these commands you can have a single bridge and VXLAN interface that handles every VLAN coming its way.</p>
<pre><code># Create a Linux bridge with the right options
/sbin/ip link add br0 type bridge vlan_filtering 1 vlan_default_pvid 0 vlan_stats_enabled 1 vlan_stats_per_port 1

# Enslave the trunk eth interface (connected to the switch trunk port)
# to the bridge
/sbin/ip link set dev ${TRUNK_IFACE} master br0

# Create a vxlan interface and enslave it to the same bridge
/sbin/ip link add vxlan0 type vxlan vni ${VXLAN_DEFAULT_VNI} local ${VTEP_LOCALIP} remote ${VTEP_REMOTEIP} dstport 4789
/sbin/ip link set dev vxlan0 master br0

# Activate vlan tunneling !
/sbin/bridge link set dev vxlan0 vlan_tunnel on</code></pre>
<p>Then, adding a specific VLAN ID to the bridge so its extracted and mapped to a VXLAN vid requires these 3 commands</p>
<pre><code>/sbin/bridge vlan add vid $vid dev ${TRUNK_IFACE}
/sbin/bridge vlan add vid $vid dev vxlan0
/sbin/bridge vlan set dev vxlan0 vid $vid tunnel_info id $vid</code></pre>
<p>You can easily run a little script to do the mapping once and for all for every possible VLAN ID :</p>
<pre><code># extract vlans from trunk, map them to same vxlan vid
for vid in $(seq 2 4095); do
/sbin/bridge vlan add vid $vid dev ${TRUNK_IFACE}
/sbin/bridge vlan add vid $vid dev vxlan0
/sbin/bridge vlan set dev vxlan0 vid $vid tunnel_info id $vid
done</code></pre>

<h3>Wireguard</h3>
<p><br>
Plugging this VXLAN configuration to a wireguard tunnel is surprisingly easy. We won't be covering setting up a wireguard tunnel between two Linux hosts since there are many great resources online (and it just&nbsp;works out of the box).</p>
<p>Indeed, if you've already set up a wg0 interface over the (insecure) fiber connection, with (secure) IP addresses for both of your "wormholes", you can specify the remote peer's wireguard IP address directly as ${VTEP_REMOTEIP}. Linux in-kernel networking will then do its magic and dutifully forward over the wire your 802-1q frames, encapsulated in UDP VXLAN, and encapsulated again in UDP Wireguard.</p>
<p>Having read that, you might worry like we did at the potential performance cost of such many-levels of encapsulation and encryption on top of it.</p>

<h2>Performance&nbsp;</h2>
<p><img alt="scheme of the multiple layers of encapsulation between the wormholes" data-entity-type="file" data-entity-uuid="3c48c427-11f2-416a-b2fe-c228fc8c3a54" src="https://www.synacktiv.com/sites/default/files/inline-images/max-encap.png"></p><p>So, the final packets that will transit "on the wire" between our wormholes will end up looking something&nbsp;&nbsp;like&nbsp;<code>Eth/IP/UDP/WG/IP/UDP/VXLAN/Eth/802.1q/IP/Payload</code>. That's quite an overhead indeed!</p>
<p>But this overhead is only present during the&nbsp;transit on the fiber, which on our&nbsp;scenario is a local, short-distance (read : low latency) optical fiber, typically using at least&nbsp;10 Gbps SFP+ optical transceivers. So the latency and bandwidth should be good, and we will be able to maximize the Maximum Transfer Unit (MTU) on the fiber interface ports, so that a typical Ethernet data payload of 1500 bytes will be able to&nbsp;"sit" easily in the payload of our jumbo wireguard+vxlan frame :&nbsp;&nbsp;there will be&nbsp;no need for segmentation and retransmits.&nbsp;</p>
<p>Regarding wireguard encryption, we did a little research and felt confident after reading&nbsp;<a href="https://restoreprivacy.com/optimizations-in-wireguard-achieve-record-10gbit-sec-throughput/">resources</a> &nbsp;that we could reach high speeds with the right hardware offloads, altough 10 Gbps seemed like the "record".</p>
<p>The corresponding <code>ethtool</code> vars that matched offloads that enabled good performance for VXLAN+wireguard were determined to be :&nbsp;<code>tx-udp_tnl-segmentation,&nbsp;generic-segmentation-offload,&nbsp;generic-receive-offload,&nbsp;rx-vlan-offload</code> and&nbsp;<code>tx-vlan-offload</code>.</p>
<p>The next step was to find server hardware that had&nbsp;10 Gbps SFP+ ports with&nbsp;<strong>UDP Segmentation Offload</strong>&nbsp;(Generic Segmentation Offload),&nbsp;<strong>UDP Receive Coalescing</strong>&nbsp;(Generic Receive Offload) and <strong>VXLAN offloading</strong> capabilites</p>
<p>The search was over when we found out about SuperMicro SuperServer&nbsp;5019D-4C-FN8TP, that had everything we needed with an&nbsp;Intel Xeon D-2123IT&nbsp;SoC that directly handles 2x 10Gbps SFP+ and 2x 10Gbps base-T ports, both the CPU and NICs supporting the aforementioned offload instructions. It costed about 1300€ (you then have to add ECC RAM and local hard drive yourself).</p>
<p><img alt="picture of chosen supermicro server" data-entity-type="file" data-entity-uuid="ff622867-34b4-409c-b904-49fc587e2ef8" src="https://www.synacktiv.com/sites/default/files/inline-images/supermicro.png"></p><h3>Test setup</h3>
<p>Our test setup was like this :</p>
<p><img alt="schema of our test setup described below" data-entity-type="file" data-entity-uuid="592259de-dcc4-40cd-bac4-bb474ba78e6b" src="https://www.synacktiv.com/sites/default/files/inline-images/maquette_0.png"></p><p>We planned to measure throughput using <code>iperf3</code> in the following conditions:</p>
<ul>
<li>Between the Supermico wormholes on the untrusted fiber</li>
<li>Between the&nbsp;Supermico wormholes through the wireguard tunnel built over the untrusted fiber (to measure wireguard encryption penalty)</li>
<li>Between a pair of two 1 Gbps laptops, each on one side&nbsp;of the wormholes, to measure end-device to end-device performance</li>
<li>Between <em>two</em> pairs of such laptops, each pair on a different VLAN and simultaneously trying to use their 1 Gbps max bandwidth, just&nbsp;to be sure we were scaling... and this was quite a good intuition to do this test, as you will read further.</li>
</ul>
<p>We also measured the base performance of the four laptops with a classical setup (just the network switches linked by a trunk port, no vxlan or wireguard, no "wormholing") : they were able to reach 942 Mbps.</p>
<p>Just out-of-the box, with no particular tuning, here were the first&nbsp;tests results:</p>
<ul>
<li>9.81 Gbits/sec between the&nbsp;Supermicros on&nbsp;untrusted fiber (no crypto) - so it seems we really did buy 10 Gbps-capable NICs!&nbsp;nice</li>
<li>8.18 Gbits/sec between the Supermicros on&nbsp;wg0 (AES) - a 17% performance penalty, seemed to be expected from encrypting...</li>
<li>874 Mbits/sec between two&nbsp;laptops (compared to 942 Mbps in a classical setup) - a 8% performance "end-user" penalty, did not seem so bad</li>
<li>But only 658 Mbits/sec when there&nbsp;were 4 laptops each connected in pairs (again compared to 942 Mbps for each pair) - oops, something seemed off!&nbsp;</li>
</ul>
<p>It looked like we were stalling somewhere around a ~1 Gbps shared bandwith for every end-user devices. Looked like a waste of our "next to 10 Gbps" bandwidth, surely there was something to do about it.</p>
<h3>Tuning Linux networking</h3>
<p>So we activated all the network-related tuning we had thought off beforehand:</p>
<pre><code># enable Jumbo frames (9000 bytes MTU) on 10 Gbps fiber
/sbin/ip li set dev ${UNTRUSTED_IFACE} mtu 9000

# https://cromwell-intl.com/open-source/performance-tuning/ethernet.html
/sbin/ip link set dev ${UNTRUSTED_IFACE} txqueuelen 13888 
/sbin/ethtool -G ${UNTRUSTED_IFACE} rx 4096 tx 4096

# setup a 8020 MTU on wg0 interface to account for the 80 bytes wireguard headers overhead
# 20-byte IPv4 header or 40 byte IPv6 header,&nbsp;8-byte UDP header&nbsp;&nbsp;4-byte type,&nbsp;4-byte key index,&nbsp;8-byte nonce,&nbsp;16-byte authentication tag)
/sbin/ip li set dev wg0 mtu 8020</code></pre>
<p>we added some <code>sysctl</code> tuning for 10Gbps ethernet as well:</p>
<pre><code># Maximum receive socket buffer size
net.core.rmem_max = 134217728 

# Maximum send socket buffer size
net.core.wmem_max = 134217728 

# Minimum, initial and max TCP Receive buffer size in Bytes
net.ipv4.tcp_rmem = 4096 87380 134217728 

# Minimum, initial and max buffer space allocated
net.ipv4.tcp_wmem = 4096 65536 134217728 

# Maximum number of packets queued on the input side
net.core.netdev_max_backlog = 300000 

# Auto tuning
net.ipv4.tcp_moderate_rcvbuf =1

# Don't cache ssthresh from previous connection
net.ipv4.tcp_no_metrics_save = 1

# If you are using jumbo frames set this to avoid MTU black holes.
net.ipv4.tcp_mtu_probing = 1</code></pre>

<p>After that we had the following test results:</p>
<ul>
<li>9.91&nbsp;Gbits/sec between the&nbsp;Supermicros on&nbsp;untrusted fiber (no crypto) - 100 Mbps better than&nbsp;9.81 Gbits/sec !</li>
<li>8.41&nbsp;Gbits/sec between the Supermicros on&nbsp;wg0 (wireguard) - more than 200 Mbps better than&nbsp;8.18 Gbits/sec !!</li>
<li>942 Mbits/sec between two&nbsp;laptops - now equivalent to the legacy setup without wormholes - yay !</li>
<li>still 658 Mbits/sec when they were 4 laptops each connected in pairs - something's still off...</li>
</ul>
<p>Having tuned everything network-related we could think of, it then occured to us that a good part of the networking ( bridging, forwarding, encapsulating) was really done in-kernel (read: "in-memory") and not on NICs. So surely some default Linux performance setting was stalling us around ~ 1 Gbps .</p>
<h3>Last tunables</h3>
<p>We then set the CPU governor to <code>performance</code> and tuned virtual memory <code>sysctl</code>s to match what RedHat's <code>tuned</code> tool does when setting the profile <code>throughput-performance</code>:</p>
<pre><code>vm.dirty_ratio = 40
vm.dirty_background_ratio = 10
vm.swappiness=10
# set cpu/power options
governor=performance
energy_perf_bias=performance
min_perf_pct=100</code></pre>
<p>And<em> lo&nbsp;and behold</em>, here were the tests results:</p>
<ul>
<li>9.86&nbsp;Gbits/sec between the&nbsp;Supermicros on&nbsp;untrusted fiber (no crypto) - bit lower than previous test</li>
<li><strong>9.71 Gbits/sec</strong> between the Supermicros on&nbsp;wg0 &nbsp;- the crypto impact was becoming negligible!</li>
<li>942 Mbits/sec between two&nbsp;laptops (still equivalent to the legacy setup without wormholes)</li>
<li>finally 942 Mbits/sec even when they were 4 laptops each connected in pairs - job done!</li>
</ul>
<p>In fact, the performance was so great we felt the need to vampire tap the&nbsp;fiber to make sure everythink was still encrypted - and it&nbsp;still was ;-)</p>
<h2>Conclusion</h2>
<p>So, we were able to build a fully open-source pair of appliances that will strongly encrypt a 10 Gbps 802.1q trunk at almost wire-speed (less than 2% performance penalty), defeating any spying vampire tapping onto the underlying network link. And this appliance costs less than a flagship smartphone.</p>
<p>This truly speaks levels about the performance of today's affordable server hardware&nbsp;and the maturity of Linux networking stack. You can chain network technologies like trunking, bridging, routing, VXLAN and Wireguard almost like you chain CLI commands in true UNIX fashion, and the kernel makes it "just work". It just takes quite a bit of time and trial &amp; error to find the right feature flags and tuning settings so you can get the most out of it. We hope this blog article will do its part as well for future researchers.</p>
<p>If you liked this article and building secure-yet-performant infrastructure, speak French and are living near Paris, note that we are hiring an experienced profile to join&nbsp;our Infrastructure team ! More info (in French) :&nbsp;<a href="https://www.synacktiv.com/apt-search-sysadmin">https://www.synacktiv.com/apt-search-sysadmin</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porting SBCL to the Nintendo Switch (298 pts)]]></title>
            <link>https://reader.tymoon.eu/article/437</link>
            <guid>41530783</guid>
            <pubDate>Fri, 13 Sep 2024 12:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reader.tymoon.eu/article/437">https://reader.tymoon.eu/article/437</a>, See on <a href="https://news.ycombinator.com/item?id=41530783">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      
        <header>
          
        </header>
        <div id="article-body">
          <blockquote><article><figure><a href="https://filebox.tymoon.eu//file/TWpjNU5nPT0=" target="_blank"><img alt="https://filebox.tymoon.eu//file/TWpjNU5nPT0=" src="https://filebox.tymoon.eu//file/TWpjNU5nPT0="></a></figure><p>For the past two years Charles Zhang and I have been working on getting my game engine, Trial, running on the Nintendo Switch. The primary challenge in doing this is porting the underlying Common Lisp runtime to work on this platform. We knew going into this that it was going to be hard, but it has proven to be quite a bit more tricky than expected. I'd like to outline some of the challenges of the platform here for posterity, though please also understand that due to Nintendo's NDA I can't go into too much detail.</p><h2 id="current status">Current Status</h2><p>I want to start off with where we are at, at the time of writing this article. We managed to port the runtime and compiler to the point where we can compile and execute arbitrary lisp code directly on the Switch. We can also interface with shared libraries, and I've ported a variety of operating system portability libraries that Trial needs to work on the Switch as well.</p><p>The above photo shows Trial's REPL example running on the Switch devkit. Trial is setting up the OpenGL context, managing input, allocating shaders, all that good stuff, to get the text shown on screen; the Switch does not offer a terminal of its own.</p><figure><iframe width="100%" height="240" frameborder="no" allowfullscreen="yes" src="//www.youtube.com/embed/zLoEkvnoGKY?"></figure><p>Unfortunately it also crashes shortly after as SBCL is trying to engage its garbage collector. The Switch has some unique constraints in that regard that we haven't managed to work around quite yet. We also can't output any audio yet, since the C callback mechanism is also broken. And of course, there's potentially a lot of other issues yet to rear their head, especially with regards to performance.</p><p>Whatever the case, we've gotten pretty far! This work hasn't been free, however. While I'm fine not paying myself a fair salary, I can't in good conscience have Charles invest so much of his valuable time into this for nothing. So I've been paying him on a monthly basis for all the work he's been doing on this port. Up until now that has cost me ~17'000 USD. As you may or may not know, I'm self-employed. All of my income stems from sales of <a class="external-link" href="https://kandria.com">Kandria</a> and donations from generous supporters on <a class="external-link" href="https://patreon.com/shinmera">Patreon</a>, <a class="external-link" href="https://github.com/sponsors/shinmera">GitHub</a>, and <a class="external-link" href="https://ko-fi.com/shinmera">Ko-Fi</a>. On a good month this totals about 1'200 USD. On a bad month this totals to about 600 USD. That would be hard to get by in a cheap country, and it's practically impossible in Zürich, Switzerland.</p><p>I manage to get by by living with my parents and being relatively frugal with my own personal expenses. Everything I actually earn and more goes back into hiring people like Charles to do cool stuff. Now, I'm ostensibly a game developer by trade, and I am working on a currently unannounced project. Games are very expensive to produce, and I do not have enough reserves to bankroll it anymore. As such, it has become very difficult to decide what to spend my limited resources on, and especially a project like this is much more likely to be axed given that I doubt Kandria sales on the Switch would even recoup the porting costs.</p><p>To get to the point: if you think this is a cool project and you would like to help us make the last few hurdles for it to be completed, please consider supporting me on <a class="external-link" href="https://patreon.com/shinmera">Patreon</a>, <a class="external-link" href="https://github.com/sponsors/shinmera">GitHub</a>, or <a class="external-link" href="https://ko-fi.com/shinmera">Ko-Fi</a>. On Patreon you get news for every new library I release (usually at least one a month) and an exclusive monthly roundup of the current development progress of the unannounced game. Thanks!</p><h2 id="an overview">An Overview</h2><p>First, here's what's publicly known about the Switch's environment: user code runs on an ARM64 Cortex-A57 chip with four cores and 4 GB RAM, and on top of a proprietary microkernel operating system that was initially developed for the Nintendo 3Ds.</p><p>SBCL already has an ARM64 Linux port, so the code generation side is already solved. Kandria also easily fits into 4GB RAM, so there's no issues there either. The difficulties in the port reside entirely in interfacing with the surrounding proprietary operating system of the switch. The system has some constraints that usual PC operating systems do not have, which are especially problematic for something like Lisp as you'll see in the next section.</p><p>Fortunately for us, and this is the reason I even considered a port in the first place, the Switch is also the only console to support the OpenGL graphics library for rendering, which Trial is based upon. Porting Trial itself to another graphics library would be a gigantic effort that I don't intend on undertaking any time soon. The Xbox only supports DirectX, though supposedly there's an OpenGL -&gt; DirectX layer that Microsoft developed, so that <em>might</em> be possible. The Playstation on the other hand apparently still sports a completely proprietary graphics API, so I don't even want to think about porting to that platform.</p><p>Anyway, in order to get started developing I had to first get access. I was lucky enough that Nintendo of Europe is fairly accommodating to indies and did grant my request. I then had to buy a devkit, which costs somewhere around 400 USD. The devkit and its SDK only run on Windows, which isn't surprising, but will also be a relevant headache later.</p><p>Before we can get on to the difficulties in building SBCL for the Switch, let's first take a look at how SBCL is normally built on a PC.</p><h2 id="building sbcl">Building SBCL</h2><p>SBCL is primarily written in Lisp itself. There is a small C runtime as well, which you use a usual C compiler to compile, but before it can do that, there's some things it needs to know about the operating system environment it compiles for. The runtime also doesn't have a compiler of its own, so it can't compile any Lisp code. In order to get the whole process kicked off, SBCL requires another Lisp implementation to bootstrap with, ideally another version of itself.</p><p>The build then proceeds in roughly five phases:</p><ol><li value="1"><p><code>build-config</code><br/>This step just gathers whatever build configuration options you want for your target and spits them out into a readable format for the rest of the build process.</p></li><li value="2"><p><code>make-host-1</code></p><p>Now we build the cross-compiler with the host Lisp compiler, and at the same time emit C header files describing Lisp object layouts in memory as C structs for the next step.</p></li><li value="3"><p><code>make-target-1</code></p><p>Next we run the target C compiler to create the C runtime. As mentioned, this uses a standard C compiler, which can itself be a cross-compiler. The C runtime includes the garbage collector and other glue to the operating system environment. This step also produces some constants the target Lisp compiler and runtime needs to know about by using the C compiler to read out relevant operating system headers.</p></li><li value="4"><p><code>make-host-2</code></p><p>With the target runtime built, we build the target Lisp system (compiler and the standard library) using the Lisp cross-compiler built by the Lisp host compiler in <code>make-host-1</code>. This step produces a &quot;cold core&quot; that the runtime can jump into, and can be done purely on the host machine. This cold core is not complete, and needs to be executed on the target machine with the target runtime to finish bootstrapping, notably to initialize the object system, which requires runtime compilation. This is done in</p></li><li value="5"><p><code>make-target-2</code></p><p>The cold core produced in the last step is loaded into the target runtime, and finishes the bootstrapping procedure to compile and load the rest of the Lisp system. After the Lisp system is loaded into memory, the memory is dumped out into a &quot;warm core&quot;, which can be loaded back into memory in a new process with the target runtime. From this point on, you can load new code and dump new images at will.</p></li></ol><p>Notable here is the need to run Lisp code on the <em>target machine</em> itself. We can't cross-compile &quot;purely&quot; on the host, not in the least because user Lisp code cannot be compiled without also being run like batch-compiled C code can, and when it is run it assumes that it is in the target environment. So we really don't have much of a choice in the matter.</p><p>In order to deploy an application, we proceed similar to <code>make-target-2</code>: We compile in Lisp code incrementally and then when we have everything we need we dump out a core with the runtime attached to it. This results in a single binary with a data blob attached.</p><p>When the SBCL runtime starts up it looks for a core blob, maps it into memory, marks pages with code in them as executable, and then jumps to the entry function the user designated. This all is a problem for the Switch.</p><h2 id="building for the switch">Building for the Switch</h2><p>The Switch is not a PC environment. It doesn't have a shell, command line, or compiler suite on it to run the build as we usually do. Worse still, its operating system does not allow you to create executable pages, so even if we could run the compilation steps on there we couldn't incrementally compile anything on it like we usually do for Lisp code.</p><p>But all is not lost. Most of the code is not platform dependent and can simply be compiled for ARM64 as usual. All we need to do is make sure that anything that touches the surrounding environment in some way knows that we're actually trying to compile for the Switch, then we can use another ARM64 environment like Linux to create our implementation.</p><p>With that in mind, here's what our steps look like:</p><ol><li value="1"><p><code>build-config</code><br/>We run this on some host system, using a special flag to indicate that we're building for the Switch. We also enable the <code>fasteval</code> contrib. We need <code>fasteval</code> to step in for any place where we would usually invoke the compiler at runtime, since we absolutely cannot do that on the Switch.</p></li><li value="2"><p><code>make-host-1</code></p><p>This step doesn't change. We just get different headers that prep for the Switch platform.</p></li><li value="3"><p><code>make-target-1</code></p><p>Now we use the C compiler the Nintendo SDK provides for us, which can cross-compile for the Switch. Unfortunately the OS is not POSIX compliant, so we had to create a custom runtime target in SBCL that stubs out and papers over the operating system environment differences that we care about, like dynamic linking, mapping pages, and so on.<br/>Here is where things get a bit weird. We are now moving on to compiling Lisp code, and we want to do so on a Linux host system. So we have to...</p></li><li value="4"><p><code>build-config</code> (2)</p><p>We now create a normal ARM64 Linux system with the same feature set as for the Switch. This involves the usual steps as before, though with a special flag to inform some parts of the Lisp process that we're going to ultimately target the Switch.</p></li><li value="5"><p><code>make-host-1</code> (2)</p></li><li value="6"><p><code>make-target-1</code> (2)</p></li><li value="7"><p><code>make-host-2</code></p></li><li value="8"><p><code>make-target-2</code></p><p>With all of this done we now have a slightly special SBCL build for Linux ARM64. We can now move on to compiling user code.</p></li><li value="9"><p>For user code we now perform some tricks to make it think it's running on the Switch, rather than on Linux. In particular we modify <code>*features*</code> to include <code>:nx</code> (the Switch code name) and not <code>:linux</code>, <code>:unix</code>, or <code>:posix</code>. Once that is set up and ASDF has been neutered, we can compile our program (like Trial) &quot;as usual&quot; and at the end dump out a new core.</p></li></ol><p>We've solved the problem of actually compiling the code, but we still need to figure out how to get the code started on the Switch, since it does not allow us to do the usual core-mapping strategy. As such, attaching the new core to the runtime we made for the Switch won't work.</p><p>To make this work, we make use of two relatively unknown features of SBCL: immobile-code, and elfination. Usually when SBCL compiles code at runtime, it sticks it into a page somewhere, and marks that page executable. The code itself however could become unneeded at some point, at which point we'd like to garbage collect it. We can then reclaim the space it took up, and to do so compact the rest of the code around it. The immobile-code feature allows SBCL to take up a different strategy, where code is put into special reserved code pages and remains there. This means it can't be garbage collected, but it instead can take advantage of more traditional operating system support. Typically executables have pre-marked sections that the operating system knows to contain code, so it can take care of the mapping when the program is started, rather than the program doing it on its own like SBCL usually does.</p><p>OK, so we can generate code and prevent it from being moved. But we still have a core at the end of our build that we now need to transform into the separate code and data sections needed for a typical executable. This is done with the elfination step.</p><p>The elfinator looks at a core and performs assembly rewriting to make the code position-independent (a requirement for Address Space Layout Randomisation), and then tears it out into two separate files, a pure code assembly file, and a pure data payload file.</p><p>We can now take those two files and link them together with the runtime that the C compiler produced and get a completed SBCL that runs like any other executable would. So here's the last steps of the build process:</p><ol><li value="10"><p>Run the elfinator to generate the assembly files</p></li><li value="11"><p>Link the final binary</p></li><li value="12"><p>Run the Nintendo SDK's authoring tools to bundle metadata, shared libraries, assets, and the application binary into one final package</p></li></ol><p>That's quite an involved build setup. Not to mention that we need at least an ARM64 Linux machine to run most of the build on, as well as either an AMD64 Windows machine (or an AMD64 Linux machine with Wine) to run the Nintendo SDK compiler and authoring tools.</p><p>I usually use an AMD64 Linux machine, so there's a total of three machines involved: The AMD64 &quot;driver,&quot; the ARM64 build host, and a Windows VM to talk to the devkit with.</p><p>I wrote a special build system with all sorts of messed up caching and cross-machine synchronisation logic to automate all of this, which was quite a bit of work to get going, especially since the build should also be drivable from an MSYS2/Windows setup. Lots of fun with path mangling!</p><p>So now we have a full Lisp system, including user code, compiling for and being able to run on the Switch. Wow! I've skipped over a lot of the nitty-gritty dealing with getting the build properly aware of which target it's building for, making the elfinator and immobile-code working on ARM64, and porting all of the support libraries like pathname-utils, libmixed, cl-gamepad, etc. Again, most of the details we can't openly talk about due to the NDA. However, we have upstreamed what work we could, and all of the Lisp libraries don't have a private fork.</p><p>It's worth noting though that elfination wasn't initially designed to produce position independent executable Lisp code, which is usually full of absolute pointers. So we needed to do a lot of work in the SBCL compiler and runtime to support load time relocation of absolute pointers and make sure code objects (which usually contain code constants) no longer have absolute pointers, as the GC can't modify executable sections. Not even the OS loader is allowed to modify executable sections to relocate absolute pointer. We did this by relocating absolute pointers like code constants outside of the text space into a read-writable space close enough to rewrite constant references in code to load from this r/w space instead, which the loader and the moving GC can fixup pointers at.</p><p>Instead of interfacing directly with the Nintendo SDK, I've opted to create my own C libraries that have a custom interface the Lisp libraries interface with in order to access the operating system functionality it needs. That way I can at least publish the Lisp bits openly, and only keep the small C library private. Anyway, now that we can run stuff we're not done yet. Our system actually needs to keep running, too, and that brings us to</p><h2 id="the garbage collector">The Garbage Collector</h2><p>Garbage collection is a huge topic in itself and there's a ton of different techniques to make it work efficiently. The standard GC for SBCL is called &quot;gencgc&quot;, a Generational Garbage Collector. Generational meaning it keeps separate &quot;generations&quot; of objects and scans the generations in different frequencies, copying them over to another generation's location to compact the space. None of this is inherently an issue for the Switch, if it weren't for multithreading.</p><p>When multiple threads are involved, we can't just move objects around, as another thread could be accessing it at any time. The easiest way to resolve this conflict is to park all threads before engaging garbage collection. So the question becomes: when a thread wants to start garbage collection, how does it get the other threads to park?</p><p>On Unix systems a pretty handy trick is used: we can use the signalling mechanism to send a signal to the other threads, which then take that hint to park.</p><p>On the Switch we don't have any signal mechanism. In fact, we can't interrupt threads at all. So we instead need to somehow get each thread to figure out that it should park on its own. The typical strategy for this is called &quot;safepoints&quot;.</p><p>Essentially we modify the compiler a little bit to inject some extra code that checks whether the thread should park or not. This strategy has some issues, namely:</p><ul><li><p>Adding a check isn't free. So we want to check as little as possible</p></li><li><p>If we don't check frequently enough, we are going to stall all the other threads because GC can't begin until they're all parked</p></li><li><p>If we have to inject a lot of instructions for a check, it is going to disrupt CPU cache lines and pipelining optimisations</p></li></ul><p>The current safepoint system in SBCL was written for Windows, which similarly does not have inter-process signal handlers. However, unlike the Switch, it <em>does</em> still have signal handling for the current thread. So the current safepoint implementation was written with this strategy:</p><p>Each thread keeps a page around that a safepoint just writes a word to. When GC is engaged, those pages are marked as read-only, so that when the safepoint is hit and the other thread tries to write to the page, a segmentation fault is triggered and the thread can park. This is efficient, since we only need a single instruction to write into the page.</p><p>On the Switch we can't use this trick either, so we have to actually insert a more complex check, which can be tricky to get working as intended, as all parallel algorithms tend to be.</p><p>Since safepoints aren't necessary on any other platform than Windows, it also hasn't been tested anywhere else, so aside from modifying it for this new platform it's also just unstable. It is apparently quite a big mess in the code base and would ideally be redone from scratch, but hopefully we don't have to go quite that far.</p><p>I'd also like to give special mention to the issue that CLOS presents. Usually SBCL defers compilation of the &quot;discriminating function&quot; that is needed to dispatch to methods to the first call of the generic function. This is done because CLOS is highly dynamic and allows adding and removing methods pretty much at any time, and there's usually no good point in time that the system knows it is complete. Of course, on the Switch we can't invoke the compiler, so we can't really do this. For now our strategy has been to instead rely on the fast evaluator. We stub out the <code>compile</code> function to create a lambda that executes the code via the evaluator instead. This has the advantage of working with any user code that relies on <code>compile</code> as well, though it is obviously much slower for execution than it would be if we could actually compile.</p><p>This neatly brings us to</p><h2 id="future work">Future Work</h2><p>The fasteval trick is mostly a fallback. Ideally I'd like to explore options to freeze as much of CLOS in place as possible right before the final image is dumped and compile as much as possible ahead of time. I'd also like to investigate the block compilation mode that Charles restored some years back more closely.</p><p>It's very possible that the Switch's underpowered processor will also force us to implement further optimisations, especially on the side of my engine and the code in Kandria itself. Up until now I've been able to get away with comparatively little optimisation, since even computers of ten years ago are more than fast enough to run what I need for the game. However, I'm not so sure that the Switch could match up to that even if it didn't also introduce additional constraints on performance with its lack of operating system support.</p><p>First, though, we need to get the garbage collector running fully. It runs enough to boot up and get into Trial's main loop, but as soon as it hits multi-generation compaction, it falls flat on its face.</p><p>Next we need to get callbacks from C working again. Apparently this is a part of the SBCL codebase that can only be described as &quot;a mess,&quot; involving lots of hand-rolled assembly routines, which probably need some adjustments to work correctly with immobile-code and elfination. Callbacks fortunately are relatively rare, Trial only needs them for sound playback via libmixed.</p><p>There's also been some other issues that we've kept in the back of our heads but don't require our immediate attention, as well as some extra portability features I know I'll have to work on in Trial before its selftest suite fully passes on the Switch.</p><h2 id="conclusion">Conclusion</h2><p>I'll be sure to add an addendum here should the state of the port significantly change in the future. Some people have also asked me if the work could be made public, or if I'd be willing to share it.</p><p>The answer to that is that while I would desperately like to share it all publicly, the NDA prevents us from doing so. We still upstream and publicise whatever we can, but some bits that tie directly into the Nintendo SDK cannot be shared with anyone that hasn't <em>also</em> signed the NDA. So, in the very remote possibility that someone other than me is crazy enough to want to publish a Common Lisp game on the Nintendo Switch, they can reach out to me and I'll happily give them access to our porting work once the NDA has been signed.</p><p>Naturally, I'll also keep people updated more closely on what's going on in the monthly updates for Patrons. With that all said, I once again plead with you to consider supporting me on <a class="external-link" href="https://patreon.com/shinmera">Patreon</a>, <a class="external-link" href="https://github.com/sponsors/shinmera">GitHub</a>, or <a class="external-link" href="https://ko-fi.com/shinmera">Ko-Fi</a>. All the income from these will, for the foreseeable future, be going towards funding the SBCL port to the Switch as well as the current game project.</p><p>Thank you as always for reading, and I hope to share more exciting news with you soon!</p></article></blockquote>
          <div class="notice">
            Written by <a href="https://user.tymoon.eu/shinmera/" id="author-avatar" title="shinmera">shinmera</a>
          </div>
        </section>
      
      <footer>
        <nav id="move">
          
            <a class="prev" href="https://reader.tymoon.eu/article/436">SRS, Zürich 2024 Edition</a>
          
          
        </nav>
        <nav id="default-linkage">
          <ul/>
        </nav>
      </footer>
    </article>
  </body>
</html>
</iframe></figure></article></blockquote></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: FlowTracker – Track data flowing through Java programs (252 pts)]]></title>
            <link>https://github.com/coekie/flowtracker</link>
            <guid>41530190</guid>
            <pubDate>Fri, 13 Sep 2024 11:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/coekie/flowtracker">https://github.com/coekie/flowtracker</a>, See on <a href="https://news.ycombinator.com/item?id=41530190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">FlowTracker</h2><a id="user-content-flowtracker" aria-label="Permalink: FlowTracker" href="#flowtracker"></a></p>
<p dir="auto"><em>Track data flowing through Java programs, gain new understanding at a glimpse.</em></p>
<p dir="auto">FlowTracker is a Java agent that tracks how a program reads, manipulates, and writes data.
By watching a program run, it can show what file and network I/O happened, but more importantly connecting its inputs and outputs to show where its output came from.
This helps you understand what any Java program's output means and why it wrote it.</p>
<p dir="auto">This proof-of-concept explores what insights we get by looking at program behaviour from this perspective.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto">Spring PetClinic is a demo application for the Spring framework.
To demonstrate FlowTracker's abilities, we let it observe PetClinic handling an HTTP request and generating an HTML page based on a template and data from a database.
You can use this demo in your browser, without installing anything.
Open the <a href="https://flowtracker-demo.coekie.com/petclinic/#Server%20socket/*/%2F127.0.0.1%3A*/Write" rel="nofollow">FlowTracker PetClinic demo</a>, or watch the video below.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description petclinic.mp4">petclinic.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/271022/352298644-af1af08e-0a7c-4d10-b105-c60d4222e13c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjYyNDE3MDMsIm5iZiI6MTcyNjI0MTQwMywicGF0aCI6Ii8yNzEwMjIvMzUyMjk4NjQ0LWFmMWFmMDhlLTBhN2MtNGQxMC1iMTA1LWM2MGQ0MjIyZTEzYy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxM1QxNTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NTAyNTAwYmIwMWYwZTk0NjAwNDc3MGQ5NTZhMjlkMjQ5NTU3MDI0ZTNhNGRkMDYxNzhjZWE5NDk3ZmE4MmI3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.tFdJnmlbL4dcWi2x4iKNe1_Jjc7HzkTLo72dtMWqzwI" data-canonical-src="https://private-user-images.githubusercontent.com/271022/352298644-af1af08e-0a7c-4d10-b105-c60d4222e13c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjYyNDE3MDMsIm5iZiI6MTcyNjI0MTQwMywicGF0aCI6Ii8yNzEwMjIvMzUyMjk4NjQ0LWFmMWFmMDhlLTBhN2MtNGQxMC1iMTA1LWM2MGQ0MjIyZTEzYy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTEzJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxM1QxNTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NTAyNTAwYmIwMWYwZTk0NjAwNDc3MGQ5NTZhMjlkMjQ5NTU3MDI0ZTNhNGRkMDYxNzhjZWE5NDk3ZmE4MmI3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.tFdJnmlbL4dcWi2x4iKNe1_Jjc7HzkTLo72dtMWqzwI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You see the HTTP response that FlowTracker saw PetClinic send over the network.
Click on a part of the contents of the HTTP response to see in the bottom view where that part came from.
You can select another tracked origin/input or sink/output in the tree on the left (or bottom left button on mobile).</p>
<p dir="auto">Exploring this HTTP response, we navigate through multiple layers of the software stack:</p>
<ul dir="auto">
<li><strong>HTTP handling</strong> <em>FlowTracker shows what code produced what output</em>.
Click on "HTTP/1.1" or the HTTP headers. You see that this part of the response was generated by apache coyote (classes in the <code>org.apache.coyote</code> package), pointing you to where exactly each header came from.</li>
<li><strong>Thymeleaf templates</strong> <em>FlowTracker shows how the input the program reads (the HTML templates) corresponds to the output</em>.
Click on an HTML tag name, like "html" or "head". You see the <code>layout.html</code> file, where this part of the HTML page comes from.
If you click on <code>layout.html</code>, and then on the colorful <code>+</code> button at the bottom, then everything coming from that file will be marked in the same color.
Scrolling down you'll then notice part of the response comes from a different file, <code>ownerDetails.html</code>.
Click on a <code>&lt;</code> or <code>&gt;</code> to see that those characters were written by the Thymeleaf templating library.</li>
<li><strong>Database</strong>
The HTML page contains a table with information that comes from the database.
Clicking on <code>George</code> in that table does not only show that that value came from the database.
It goes further: it traced it all the way back to the SQL script that inserted that value in the database in first place.</li>
</ul>
<p dir="auto">In that demo, the tracking up to the SQL script works because it was using an in-memory database.
The database content never left the JVM, so FlowTracker could fully keep track of it.
When we run the same demo but with a mysql database, then we track those values up to the database connection: we see the SQL query sent before to produce them, and details of how the mysql jdbc driver talks to the database.
See <a href="https://flowtracker-demo.coekie.com/petclinic-mysql/#Server%20socket/*/%2F127.0.0.1%3A*/Write" rel="nofollow">FlowTracker PetClinic mysql demo</a>.
Notice that FlowTracker intercepts the decrypted contents sent over the SSL connection to the database.</p>
<p dir="auto">This Spring PetClinic demo is just an example.
FlowTracker does not depend on your application using any particular framework or library.</p>
<p dir="auto">Another demo, showing how by watching the java compiler, FlowTracker helps you understand the format of the generated class file and the bytecode in it:
<a href="https://flowtracker-demo.coekie.com/javac/#Files/home/coekie/flowtracker-demo/HelloWorld.class" rel="nofollow">javac demo</a>, <a href="https://github.com/user-attachments/assets/5884c8fd-342b-471e-b13d-a2fe7219e8e6">video</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Warning:
In its current state, FlowTracker is closer to a proof of concept than production ready.
It has proven itself to work well on a number of example programs, but it is not going to work well for everything, your mileage may vary.
Also be aware that it adds a lot of overhead, making programs run much slower.</p>
<p dir="auto">Download the FlowTracker agent jar from the <a href="https://github.com/coekie/flowtracker/releases">Github releases pages</a> (<code>flowtracker-*.jar</code> under "Assets").
Add the agent to your java command line: <code>-javaagent:path/to/flowtracker.jar</code>.
Disable some JVM optimizations that disrupt flowtracker by also adding the output of <code>java -jar flowtracker.jar jvmopts</code> to the command line.
By default, FlowTracker starts a webserver on port 8011, so open <a href="http://localhost:8011/" rel="nofollow">http://localhost:8011/</a> in your browser.</p>
<p dir="auto">For more detailed instructions, including configuration options, see <a href="https://github.com/coekie/flowtracker/blob/master/USAGE.md">USAGE.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works internally</h2><a id="user-content-how-it-works-internally" aria-label="Permalink: How it works internally" href="#how-it-works-internally"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Short version</h2><a id="user-content-short-version" aria-label="Permalink: Short version" href="#short-version"></a></p>
<p dir="auto">FlowTracker is an instrumenting agent.
The agent injects its code into class files (bytecode) when the JVM loads them.
That code maintains a mapping of in-memory data to its origin, while the program reads, passes around, and writes data.
The focus is on tracking textual and binary data (like Strings, char and byte arrays), not on numerical, structured or computed data.</p>
<p dir="auto">This achieved with a combination of:</p>
<ul dir="auto">
<li>Replacing some calls to JDK methods with calls to FlowTracker's version of those methods.</li>
<li>Injecting code into key places in the JDK, mostly to track input and output.</li>
<li>Dataflow analysis and deeper instrumentation within methods to track local variables and values on the stack.</li>
<li>Adding code before and after method invocations, and at the start and end of invoked methods, to track method arguments and return values using ThreadLocals.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Data model: Trackers</h2><a id="user-content-data-model-trackers" aria-label="Permalink: Data model: Trackers" href="#data-model-trackers"></a></p>
<p dir="auto">Core classes and concepts of FlowTracker's data model:</p>
<ul dir="auto">
<li>Tracker: holds information about a tracked object's content and source:
<ul dir="auto">
<li>content: the data that passed through them. e.g. all bytes passed through an <code>InputStream</code> or <code>OutputStream</code>.</li>
<li>source: associate ranges of its content to their source ranges in other trackers. For example, for the bytes of a <code>String</code> that could be pointing to the range of the tracker of the <code>FileInputStream</code> that the <code>String</code> was read from; telling us from which file and where exactly in that file it came from.</li>
</ul>
</li>
<li>TrackerRepository: holds a large global <code>Map&lt;Object, Tracker&gt;</code> that associates interesting objects with their tracker.</li>
<li>TrackerPoint: Pointer to a position in a tracker, representing a single primitive value being tracked, e.g. the source of one <code>byte</code>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Basic instrumentation</h2><a id="user-content-basic-instrumentation" aria-label="Permalink: Basic instrumentation" href="#basic-instrumentation"></a></p>
<p dir="auto">To keep Trackers up-to-date, our instrumentation inserts calls to <em>hook</em> methods in flowtracker when some specific JDK methods are being called.</p>
<p dir="auto">The simplest example of that is for System.arraycopy.
We intercept that on the caller's side: Calls to <code>java.lang.System.arraycopy</code> are replaced with calls to <code>com.coekie.flowtracker.hook.SystemHook.arraycopy</code>.
For this and other instrumentation, we use the ASM bytecode manipulation library.
In <code>SystemHook</code> we call the real <code>arraycopy</code>, get the <code>Trackers</code> of the source and destination arrays from the <code>TrackerRepository</code>, and update the target <code>Tracker</code> to point to its source.</p>
<p dir="auto">For example, given this code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="char[] abc = ...; char[] abcbc = new char[5];
System.arraycopy(abc, 0, abcbc, 0, 3);
System.arraycopy(abc, 1, abcbc, 3, 2);"><pre><span>char</span>[] <span>abc</span> = ...; <span>char</span>[] <span>abcbc</span> = <span>new</span> <span>char</span>[<span>5</span>];
<span>System</span>.<span>arraycopy</span>(<span>abc</span>, <span>0</span>, <span>abcbc</span>, <span>0</span>, <span>3</span>);
<span>System</span>.<span>arraycopy</span>(<span>abc</span>, <span>1</span>, <span>abcbc</span>, <span>3</span>, <span>2</span>);</pre></div>
<p dir="auto">This gets rewritten to the following.
Note that instrumentation happens on bytecode, not source code, but we show equivalent source code here because that's much easier to read.</p>
<div dir="auto" data-snippet-clipboard-copy-content="char[] abc = ...; char[] abcbc = new char[5];
SystemHook.arraycopy(abc, 0, abcbc, 0, 3);
SystemHook.arraycopy(abc, 1, abcbc, 3, 2);"><pre><span>char</span>[] <span>abc</span> = ...; <span>char</span>[] <span>abcbc</span> = <span>new</span> <span>char</span>[<span>5</span>];
<span>SystemHook</span>.<span>arraycopy</span>(<span>abc</span>, <span>0</span>, <span>abcbc</span>, <span>0</span>, <span>3</span>);
<span>SystemHook</span>.<span>arraycopy</span>(<span>abc</span>, <span>1</span>, <span>abcbc</span>, <span>3</span>, <span>2</span>);</pre></div>
<p dir="auto">After executing this, the tracker for abcbc would look like: <code>{[0-2]: {tracker: abcTracker, sourceIndex: 0, length: 3}, [3-4]: {tracker: abcTracker, sourceIndex: 1, length: 2}}</code></p>
<p dir="auto">That was an example of a hook on the caller side.
But most calls to <em>hook</em> methods are added on the callee side, inside the methods in the JDK.
For example take <code>FileInputStream.read(byte[])</code>, which reads data from a File and stores the result in the provided <code>byte[]</code>.
We add the call to our hook method (<code>FileInputStreamHook.afterReadByteArray</code>) at the end of the <code>FileInputStream.read(byte[])</code> method.
We have our own instrumentation micro-framework for that, driven by annotations, implemented using ASM's <code>AdviceAdapter</code>.</p>
<p dir="auto">That way we add hooks to a number of classes in the JDK responsible for input and output, such as <code>java.io.FileInputStream</code>, <code>java.io.FileOutputStream</code>, and internal classes like <code>sun.nio.ch.FileChannelImpl</code>, <code>sun.nio.ch.IOUtil</code>, <code>sun.nio.ch.NioSocketImpl</code> and more.</p>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/hook/SystemHook.java">SystemHook</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/hook/FileInputStreamHook.java">FileInputStreamHook</a>,
and other classes in the <a href="https://github.com/coekie/flowtracker/tree/master/core/src/main/java/com/coekie/flowtracker/hook">hook package</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Primitive values, dataflow analysis</h2><a id="user-content-primitive-values-dataflow-analysis" aria-label="Permalink: Primitive values, dataflow analysis" href="#primitive-values-dataflow-analysis"></a></p>
<p dir="auto">A bigger challenge is tracking primitive values.
Consider this example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="byte[] x; byte[] y;
// ...
byte b = x[1];
// ...
y[2] = b;"><pre><span>byte</span>[] <span>x</span>; <span>byte</span>[] <span>y</span>;
<span>// ...</span>
<span>byte</span> <span>b</span> = <span>x</span>[<span>1</span>];
<span>// ...</span>
<span>y</span>[<span>2</span>] = <span>b</span>;</pre></div>
<p dir="auto">When that code is executed, we would need to update the Tracker of <code>y</code>, to remember that the value at index 2 comes from the value at index 1 in <code>x</code>.
If those had been <code>String[]</code>s and <code>b</code> was a <code>String</code> instead of a <code>byte</code>, then we wouldn't need to modify code like this, because the TrackerRepository would know what the Tracker of the String is, and keeps that association no matter how that String object is passed around.
But the TrackerRepository can't keep a mapping of primitive values like bytes to Trackers, because primitive values don't have an identity: any <code>Map</code> having a byte as key would mix up different occurrences of the same byte.
Instead, we store the association of <code>b</code> to its tracker in a local variable in the method itself.
The code gets rewritten to roughly something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="byte[] x; byte[] y;
// ...
byte b = x[1];
TrackerPoint bTracker = ArrayHook.getElementTracker(x, 1);
// ...
y[2] = b;
ArrayHook.setElementTracker(y, 2, bTracker);"><pre><span>byte</span>[] <span>x</span>; <span>byte</span>[] <span>y</span>;
<span>// ...</span>
<span>byte</span> <span>b</span> = <span>x</span>[<span>1</span>];
<span>TrackerPoint</span> <span>bTracker</span> = <span>ArrayHook</span>.<span>getElementTracker</span>(<span>x</span>, <span>1</span>);
<span>// ...</span>
<span>y</span>[<span>2</span>] = <span>b</span>;
<span>ArrayHook</span>.<span>setElementTracker</span>(<span>y</span>, <span>2</span>, <span>bTracker</span>);</pre></div>
<p dir="auto">To do that FlowTracker needs to understand how exactly values flow through a method.
We build upon ASM's analysis support to analyze the code (<em>symbolic interpretation</em>).
That way we construct a model of where values in local variables and on the stack come from at every point in the method, and where they end up.</p>
<p dir="auto">This is implemented in</p>
<ul dir="auto">
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FlowValue.java">FlowValue</a> and its subclasses (e.g. <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ArrayLoadValue.java">ArrayLoadValue</a>) that model where values come from, and can generate the instructions that create the TrackerPoints that point to that source.
A particularly interesting one is <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/MergedValue.java">MergedValue</a>, which handles situations where because of control flow (e.g. if-statements, loops) a value can come from multiple possible places.</li>
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FlowInterpreter.java">FlowInterpreter</a>: extension of ASM's <code>Interpreter</code>, <em>interprets</em> bytecode instructions, creates the appropriate <code>FlowValue</code>s.</li>
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/Store.java">Store</a> and its subclasses (e.g. <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ArrayStore.java">ArrayStore</a>) that represent places that FlowValues go to, that consume the TrackerPoints.</li>
<li><a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FlowTransformer.java">FlowTransformer</a>: drives the whole analysis and instrumentation process. See its docs for a more detailed walkthrough of how this all fits together.</li>
</ul>
<p dir="auto">We don't track the source of <em>all</em> primitive values.
The focus is on <code>byte</code> and <code>char</code> values, and to a lesser extent <code>int</code>s and <code>long</code>s.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Method invocations</h2><a id="user-content-method-invocations" aria-label="Permalink: Method invocations" href="#method-invocations"></a></p>
<p dir="auto">The dataflow analysis from the previous section is limited to handling flow of primitive values within a single method.
Those values also flow into other methods, as arguments and return values of method invocations.
We model that in <code>Invocation</code>, which stores <code>PointTracker</code>s for arguments and return values.
The <code>Invocation</code> is stored in a <code>ThreadLocal</code> just before a method invocation, and retrieved at the start of the implementation of the method.</p>
<p dir="auto">For example, take this code passing a primitive value to a "write" method:</p>
<div dir="auto" data-snippet-clipboard-copy-content="void caller() {
  byte b = ...;
  out.write(b);  
}

...

class MyOutputStream {
  void write(byte value) {
    ... // do something with value
  }
}"><pre><span>void</span> <span>caller</span>() {
  <span>byte</span> <span>b</span> = ...;
  <span>out</span>.<span>write</span>(<span>b</span>);  
}

...

<span>class</span> <span>MyOutputStream</span> {
  <span>void</span> <span>write</span>(<span>byte</span> <span>value</span>) {
    ... <span>// do something with value</span>
  }
}</pre></div>
<p dir="auto">To get the TrackerPoint of <code>b</code> into the <code>write</code> method, the code is instrumented like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="void caller() {
  byte b = ...;
  TrackerPoint bTracker = ...;
  Invocation.create(&quot;write(byte)&quot;)
    .setArg(0, bTracker)
    // this puts the Invocation in the ThreadLocal
    .calling(); 
  out.write(b);  
}

...

class MyOutputStream {
  void write(byte value) {
    // this extracts the Invocation from the ThreadLocal
    Invocation invocation = Invocation.start(&quot;write(byte)&quot;);
    TrackerPoint valueTracker = invocation.getArg0();
    ... // do something with value &amp; valueTracker
  }
}"><pre><span>void</span> <span>caller</span>() {
  <span>byte</span> <span>b</span> = ...;
  <span>TrackerPoint</span> <span>bTracker</span> = ...;
  <span>Invocation</span>.<span>create</span>(<span>"write(byte)"</span>)
    .<span>setArg</span>(<span>0</span>, <span>bTracker</span>)
    <span>// this puts the Invocation in the ThreadLocal</span>
    .<span>calling</span>(); 
  <span>out</span>.<span>write</span>(<span>b</span>);  
}

...

<span>class</span> <span>MyOutputStream</span> {
  <span>void</span> <span>write</span>(<span>byte</span> <span>value</span>) {
    <span>// this extracts the Invocation from the ThreadLocal</span>
    <span>Invocation</span> <span>invocation</span> = <span>Invocation</span>.<span>start</span>(<span>"write(byte)"</span>);
    <span>TrackerPoint</span> <span>valueTracker</span> = <span>invocation</span>.<span>getArg0</span>();
    ... <span>// do something with value &amp; valueTracker</span>
  }
}</pre></div>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/tracker/Invocation.java">Invocation</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationArgStore.java">InvocationArgStore</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationArgValue.java">InvocationArgValue</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationReturnStore.java">InvocationReturnStore</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationReturnValue.java">InvocationReturnValue</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationOutgoingTransformation.java">InvocationOutgoingTransformation</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/InvocationIncomingTransformation.java">InvocationIncomingTransformation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Code as origin</h2><a id="user-content-code-as-origin" aria-label="Permalink: Code as origin" href="#code-as-origin"></a></p>
<p dir="auto">There are two main types of tracked origins of data.
There is I/O, which is tracked as explained in the "Basic instrumentation" section.
And there are values coming from the code itself, such as primitive and String constants (<code>'a'</code>, <code>"abc"</code>).
For those, we create a tracker for each class (a <code>ClassOriginTracker</code>), that contains a textual representation of that class and the constants that it references.
When those constants are referenced, we then point the trackers for those values at the corresponding place in that textual representation.
That is <em>as if</em> our textual representation of the class is where the values were read from.
That makes our model for constants look very similar to how we model I/O.</p>
<p dir="auto">For example for this code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MyClass {
  void myMethod() {
    char a = 'x';
    ... // do something with a
  }
}"><pre><span>class</span> <span>MyClass</span> {
  <span>void</span> <span>myMethod</span>() {
    <span>char</span> <span>a</span> = <span>'x'</span>;
    ... <span>// do something with a</span>
  }
}</pre></div>
<p dir="auto">We generate a <code>ClassOriginTracker</code> with content that looks like this:</p>
<div data-snippet-clipboard-copy-content="class MyClass
void myMethod():
  (line 3): x"><pre><code>class MyClass
void myMethod():
  (line 3): x
</code></pre></div>
<p dir="auto">And the code gets rewritten to something like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class MyClass {
  void myMethod() {
    char a = 'x';
    TrackerPoint aTracker = ConstantHook.constantPoint(
      1234 /* id for MyClass*/,
      81 /* offset of 'x' in the ClassOriginTracker content */);
    
    ... // do something with a and aTracker
  }
}"><pre><span>class</span> <span>MyClass</span> {
  <span>void</span> <span>myMethod</span>() {
    <span>char</span> <span>a</span> = <span>'x'</span>;
    <span>TrackerPoint</span> <span>aTracker</span> = <span>ConstantHook</span>.<span>constantPoint</span>(
      <span>1234</span> <span>/* id for MyClass*/</span>,
      <span>81</span> <span>/* offset of 'x' in the ClassOriginTracker content */</span>);
    
    ... <span>// do something with a and aTracker</span>
  }
}</pre></div>
<p dir="auto">For performance reasons, we actually use ConstantDynamic (<a href="https://openjdk.org/jeps/309" rel="nofollow">JEP 309</a>) to ensure that the <code>constantPoint</code> methods are only invoked once instead of every time <code>myMethod</code> executes.</p>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/tracker/ClassOriginTracker.java">ClassOriginTracker</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ConstantValue.java">ConstantValue</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ConstantsTransformation.java">ConstantsTransformation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">String literals</h2><a id="user-content-string-literals" aria-label="Permalink: String literals" href="#string-literals"></a></p>
<p dir="auto">For String literals, we create a new copy of the String, and associate the content of the String (the <code>byte[]</code> in <code>String.value</code>) with the <code>ClassOriginTracker</code>.
A statement like <code>String s = "abc";</code> gets rewritten to <code>String s = StringHook.constantString("abc", 1234, 81);</code>.
This breaks a guarantee that the JVM normally provides, that all String constants are <em>interned</em>: all occurrences of the same String constant should refer to the same instance.
Most code doesn't actually rely on String interning, but code that does would get broken by our instrumentation.
We avoid most of the issues that could cause because:</p>
<ul dir="auto">
<li>We use ConstantDynamic, so the same String literal (at the same line of code) executed multiple times still gives the same instance every time.</li>
<li>We rewrite some <code>stringA == stringB</code> expressions as <code>Objects.equals(stringA, stringB)</code>, so that from some points of view they look like the same instance again.</li>
<li>We disable tracking of String literals in some packages (such as <code>java.lang.*</code>). This is configurable (see <code>breakStringInterning</code> in <a href="https://github.com/coekie/flowtracker/blob/master/USAGE.md">USAGE.md</a>).</li>
</ul>
<p dir="auto">Implementation:
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/StringLdc.java">StringLdc</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/ConstantsTransformation.java">ConstantsTransformation</a>
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/StringComparison.java">StringComparison</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Fallback for untracked values</h2><a id="user-content-fallback-for-untracked-values" aria-label="Permalink: Fallback for untracked values" href="#fallback-for-untracked-values"></a></p>
<p dir="auto">FlowTracker does not track every value in the program.
That is partly because of performance concerns, partly because we just haven't implemented everything we would want, and partly because it just doesn't seem relevant or would require building a more complicated data model where values can come from a combination of places (e.g. calculated numerical values).
When values that are not being tracked end up in places where we do want to start tracking them, then we treat them similar to constants: we add a link to the <code>ClassOriginTracker</code>, to where they became tracked, represented there as <code>"&lt;?&gt;"</code>.
For example, lengths of arrays are values that are not tracked, so suppose a method calls <code>write(array.length)</code>, then in that <code>Invocation</code> we pass a <code>PointTracker</code> that refers to that place in the code where the <code>write</code> method is called.</p>
<p dir="auto">In practice, the result of that is when you look at some output, particularly if it's in a binary format, while you don't see where a value originally came from, you can often still quickly decipher what it means (e.g. "that value just before that tracked String points to <code>write(array.length)</code>, so that must be the length of that String").</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">More</h2><a id="user-content-more" aria-label="Permalink: More" href="#more"></a></p>
<p dir="auto">More topics about the implementation that could be talked about, but didn't make the cut. Most of this is documented in the code, if you really want to learn more:</p>
<ul dir="auto">
<li>Details of <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/MergedValue.java">MergedValue</a>: the hardest part of dataflow analysis, how to instrument code to keep track of values through branches and loops.</li>
<li>How we hook String concatenation through its indification (<a href="https://openjdk.org/jeps/280" rel="nofollow">JEP 280</a>) by adding hooks to the MethodHandles returned by StringConcatFactory in <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/StringConcatenation.java">StringConcatenation</a> and <a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/hook/StringConcatFactoryHook.java">StringConcatFactoryHook</a>.</li>
<li>Finding the source code, decompiling with Vineflower, associating bytecode with source code lines.
See <a href="https://github.com/coekie/flowtracker/blob/master/web/src/main/java/com/coekie/flowtracker/web/SourceCodeGenerator.java">SourceCodeGenerator</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/web/src/main/java/com/coekie/flowtracker/web/VineflowerCodeGenerator.java">VineflowerCodeGenerator</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/web/src/main/java/com/coekie/flowtracker/web/AsmCodeGenerator.java">AsmCodeGenerator</a>.</li>
<li>The ClassLoader setup. How we avoid dependencies on the bootclasspath colliding with the app, without shading (because that makes debugging annoying) and without nested jars.
Development setup that allows changing an agent without repackaging it, to ensure fast development cycles.
See <a href="https://github.com/coekie/flowtracker/blob/master/agent/src/main/java/com/coekie/flowtracker/agent/FlowTrackerAgent.java">FlowTrackerAgent</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/agent/src/main/java/com/coekie/flowtracker/agent/DevAgent.java">DevAgent</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/agent/src/main/java/com/coekie/flowtracker/agent/SpiderClassLoader.java">SpiderClassLoader</a>.</li>
<li>How class loading can intervene with tracking of method invocations, and how we work around that.
See <a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/SuspendInvocationTransformer.java">SuspendInvocationTransformer</a>,
<a href="https://github.com/coekie/flowtracker/blob/72ab61da96cbbb236a7395f9226f1797fa851892/core/src/main/java/com/coekie/flowtracker/tracker/Invocation.java#L163-L189">Invocation#suspend</a>.
<em>Interesting problem, simple solution kinda obvious in retrospect.</em></li>
<li>Tracking of primitive values stored in fields:
<a href="https://github.com/coekie/flowtracker/blob/master/core/src/main/java/com/coekie/flowtracker/tracker/FieldRepository.java">FieldRepository</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FieldStore.java">FieldStore</a>,
<a href="https://github.com/coekie/flowtracker/blob/master/weaver/src/main/java/com/coekie/flowtracker/weaver/flow/FieldValue.java">FieldValue</a>.
<em>Just more of the same, nothing surprising.</em></li>
<li>How we add comments into instrumented code to help understand and debug instrumentation. <em>ASM/Bytecode doesn't support comments, but that won't stop me!</em></li>
<li>Avoiding circularity problems when instrumenting core JDK classes. <em>I eat <code>ClassCircularityError</code>s and <code>StackOverFlowError</code>s for breakfast</em>.</li>
<li>Front-end: Web server with jetty, JAX-RS. Web UI built with Svelte. <em>Beautiful UI design by... nobody.</em></li>
<li>Our optimized ThreadLocal abomination in <code>ContextSupplier</code>. <em>On second thought, never mind, you don't want to know.</em></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Entire staff of game publisher Annapurna Interactive has reportedly resigned (382 pts)]]></title>
            <link>https://www.theverge.com/games/2024/9/12/24243317/annapurna-interactive-staff-reportedly-resigns</link>
            <guid>41528266</guid>
            <pubDate>Fri, 13 Sep 2024 05:34:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/games/2024/9/12/24243317/annapurna-interactive-staff-reportedly-resigns">https://www.theverge.com/games/2024/9/12/24243317/annapurna-interactive-staff-reportedly-resigns</a>, See on <a href="https://news.ycombinator.com/item?id=41528266">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Annapurna Interactive, the game company famous for publishing indie hits like <a href="https://www.theverge.com/2022/7/18/23220428/stray-video-game-review-ps4-ps5-steam"><em>Stray</em></a>, <a href="https://www.polygon.com/2019/12/13/21011871/outer-wilds-goty-best-games-of-the-year"><em>Outer Wilds</em></a>, <a href="https://www.theverge.com/2017/12/14/16774194/gorogoa-game-review-iphone-switch-steam"><em>Gorogoa</em></a>, <a href="https://www.theverge.com/23169390/neon-white-review-steam-nintendo-switch"><em>Neon White</em></a>, <a href="https://www.theverge.com/2017/3/24/15042182/what-remains-of-edith-finch-preview-interview"><em>What Remains of Edith Finch</em></a><em>,</em> <a href="https://en.wikipedia.org/wiki/Annapurna_Interactive#Games_published">and many more</a>, may not be the same company anymore. </p></div><p><a href="https://www.bloomberg.com/news/articles/2024-09-12/annapurna-video-game-team-resigns-leaving-partners-scrambling?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcyNjE3NzQyOSwiZXhwIjoxNzI2NzgyMjI5LCJhcnRpY2xlSWQiOiJTSlBZWklUMEFGQjQwMCIsImJjb25uZWN0SWQiOiJCMUVBQkI5NjQ2QUM0REZFQTJBRkI4MjI1MzgyQTJFQSJ9.BpoA_wBJDrNbDbgj_LjnVUJQg6SM_vsIzWUEM6v85xE"><em>Bloomberg </em>reports</a> that the entire staff of Annapurna Interactive, the gaming division of Megan Ellison’s Annapurna, has resigned after failing to convince Ellison to let them spin off its games division into a new company. <a href="https://www.ign.com/articles/annapurnas-entire-gaming-team-has-resigned"><em>IGN </em>is corroborating the report</a>. </p><p>“All 25 members of the Annapurna Interactive team collectively resigned,’’ former president Nathan Gary and staffers told <em>Bloomberg. </em>“This was one of the hardest decisions we have ever had to make and we did not take this action lightly.”</p><p>An Annapurna spokesperson told <em>Bloomberg</em> that existing games and projects will remain under the company. Annapurna didn’t immediately reply to a request for comment from <em>The Verge</em>. </p><p>Last week, <a href="https://www.hollywoodreporter.com/movies/movie-news/annapurna-president-nathan-gary-exits-1235993653/"><em>The Hollywood Reporter</em> said</a> that Gary and the coheads of Annapurna Interactive, Deborah Mars and Nathan Vella,&nbsp;would be leaving. <em>THR</em> also reported that Annapurna planned to “integrate its in-house gaming operations with the rest of Annapurna’s divisions, which include film, TV and theater.” Hector Sanchez, who most recently headed up the Unreal Engine games business at Epic Games<strong> </strong>and is an Annapurna Interactive cofounder, <a href="https://www.linkedin.com/feed/update/urn:li:activity:7232373566179094528/">announced last month</a> that he would be president of interactive and new media at Annapurna.</p><p>Annapurna Pictures, the company’s film arm, has won countless awards for a variety of films, including <em>Her</em>,&nbsp;<em>American Hustle</em>, and&nbsp;<em>Zero Dark Thirty, </em>and the company had only been expanding its ambitions alongside its video game publishing hot streak. </p><div><p>In 2020, Annapurna announced that it would <a href="https://www.theverge.com/2020/10/29/21540676/annapurna-games-indie-publisher-development-studio">begin developing its own games, too</a>; it launched <a href="https://www.theverge.com/2022/12/1/23487911/annapurna-animation-nimona-andrew-millstein-robert-baird">an in-house animation division in 2022</a>, one that soon announced <a href="https://www.theverge.com/2023/9/5/23859805/stray-movie-cat-video-game-annapurna-interactive-animation">a movie based on <em>Stray</em></a>. Annapurna Pictures produced the <a href="https://www.theverge.com/2023/5/18/23728236/nimona-teaser-trailer">excellent animated film <em>Nimona</em></a> for Netflix, and it just last month partnered with Remedy Entertainment to begin exploring <a href="https://www.theverge.com/2024/8/29/24231469/control-sequel-movie-tv-remedy-annapurna">film and TV adaptations of <em>Control</em> and <em>Alan Wake</em></a>. </p></div><p>This year, Annapurna Interactive published <a href="https://www.theverge.com/24157530/lorelei-and-the-laser-eyes-review-switch-steam"><em>Lorelei and the Laser Eyes</em></a> and <a href="https://www.theverge.com/24119962/open-roads-annapurna-xbox-ps5-switch-steam"><em>Open Roads</em></a>; upcoming games include its own developed <em>Blade Runner 2033: Labyrinth </em>as well as<em> Ghost Bike</em> and <em>Wanderstop</em>. </p><p><strong>Update, September 12th: </strong>Added Gary’s statement to <em>Bloomberg </em>about how all 25 staffers have resigned.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing workers vote to strike in resounding defeat for troubled company (520 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/</link>
            <guid>41528075</guid>
            <pubDate>Fri, 13 Sep 2024 04:41:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/">https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/</a>, See on <a href="https://news.ycombinator.com/item?id=41528075">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2024/09/13/boeing-union-contract-strike/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Who Owns Nebula? (243 pts)]]></title>
            <link>https://medium.com/@cameron-paul/who-actually-owns-nebula-952a1c12d9c0</link>
            <guid>41527991</guid>
            <pubDate>Fri, 13 Sep 2024 04:18:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@cameron-paul/who-actually-owns-nebula-952a1c12d9c0">https://medium.com/@cameron-paul/who-actually-owns-nebula-952a1c12d9c0</a>, See on <a href="https://news.ycombinator.com/item?id=41527991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@cameron-paul?source=post_page-----952a1c12d9c0--------------------------------"><div aria-hidden="false"><p><img alt="Cameron Paul" src="https://miro.medium.com/v2/resize:fill:88:88/1*rr5Iev9o7nMZL4SvDmFOgA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><figure><figcaption>Photo by <a href="https://unsplash.com/@bryangoffphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Bryan Goff</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b6e1">If this was a video essay this is where I’d put a supercut of content creators saying the phrase “my streaming service Nebula”. Unfortunately this is a blog post so you’ll have to use your imagination.</p><p id="121d">Nebula is a video on demand streaming service focusing primarily on educational content. Unlike other streaming services such as Netflix and YouTube, Nebula is distinct in that it was built by content creators. So surely the title of this post is a silly question then, right? Nebula is owned by the content creators. They say so themselves in all their videos.</p><p id="a181">I wasn’t so sure though. I never could pinpoint why, but the “creator owned” narrative at the forefront of all their promotional material just felt too good to be true. I’ve spent most of my career working in the venture capital funded tech industry, and based on that experience my gut told me Nebula was just like all those other tech companies and was only masquerading as a co-op. Up until recently I ignored that feeling assuming it was just me being overly cynical, but then I saw <a href="https://youtu.be/mXoZWCdaD5E?feature=shared" rel="noopener ugc nofollow" target="_blank">this Philosophy Tube video</a> announcing Abigail Thorn’s upcoming movie. Much of that video was spent discussing the structure of Nebula and it seemed to confirm something I had previously assumed wasn’t true: that the creators own 50% of Nebula.</p><p id="0b5e">I’ve seen various sources report that Nebula is owned 50% by a company called Standard Broadcast, and 50% by the creators on the platform. I could never find a first hand source for this information though and thought it was a misunderstanding of some very carefully crafted answers on the company’s FAQ page.</p><blockquote><p id="193c"><strong>How do the creators get paid?</strong></p><p id="3720">Nebula profit is divided 50/50 between the creators and Standard. The creator pool is paid out based on watch time.</p><p id="bdab"><strong>Who owns Nebula?</strong></p><p id="fd9a">Nebula is owned and operated by Standard and the creators, with Curiosity Inc (CuriosityStream) holding a minority stake and a board seat. There are no plans to bring in additional investment.</p></blockquote><p id="092b">The first answer indicates that there is a 50/50 profit share. This means that the content creators on the platform get to take half of the profit that Nebula makes, but that doesn’t tell us anything about how much of the platform the creators actually own.</p><p id="c01f">The second answer <em>is</em> about ownership but is much more vague. It doesn’t specify who owns what percent, and includes a the extra verb “operated” which makes things more unclear. It could be that both ownership and operation are shared between Standard and the creators, but one could also interpret that to mean that Standard owns and the creators operate. What I can say is that it’s mathematically impossible to have a 50/50 split between three parties, and there are three parties listed. This is no big deal though. Nebula never claimed there was a 50% ownership split. That claim was just some unaffiliated people on the internet misinterpreting the FAQ.</p><p id="c05e">But then I watched that Philosophy Tube video. It began with the familiar rhetoric of “Nebula is owned by the creators who are on it”. But there was more. “50% of the equity in Nebula is distributed between the creators”. This was the first time I had heard a Nebula creator say the number 50% referring to ownership. “The other 50% is owned by the parent company, an agency called Standard”. At this point the math really wasn’t adding up. A parent company by definition owns more than 50% of a subsidiary, that’s what makes it a “parent”. Also a 50/50 split would mean there’s no percentage left over for Curiosity Stream. But then there’s the real kicker: “When you’ve been on Nebula for a certain amount of time you get the option to buy a piece of the parent company. Standard actually invented an entirely new kind of cooperative corporate governance to make this happen”.</p><p id="3db8">The fact that there’s interest in buying into Standard seems to indicate there’s something lacking about the ownership you get from just being a Nebula creator, but what really sets off the alarm bells for me is the “entirely new kind of cooperative corporate governance”. If you want to have a creator-owned cooperative you can just do that. There’s nothing novel about co-ops. So why not just do that?</p><p id="b833">My intuition after watching this video was that Standard Broadcast, which is owned by a small subset of Nebula creators, actually owned the vast majority of Nebula. I suspected the options were offered as a way for the most successful creators (that is to say the ones with the most money) to buy their way into the organization that actually holds all the cards. Intuition is often wrong though so I decided I needed to do some actual investigation.</p><h2 id="bc40">The Wendover Documentary</h2><p id="6b1e">The first source I found when looking for more information was a video from Wendover Productions, a YouTube/Nebula channel created by Sam Denby. I thought this would be a good place to start because Denby is one of the original content creators on Nebula, and as I was about to learn one of the owners of Standard Broadcast.</p><p id="eb38"><a href="https://www.youtube.com/watch?v=Alqt6RCEWdM" rel="noopener ugc nofollow" target="_blank">The Inside Story of Nebula</a> is an interesting “documentary” (propaganda piece might be more accurate) chronicling the rise of Nebula. It has all the hallmarks you’d expect to find in a tech company marketing pitch. There’s an absurd and unsubstantiated valuation of $150 million dollars, talk of infinite growth, the “minimum viable product” model, and even an enlarging pie analogy.</p><p id="1d72">More interesting to me though was how carefully phrased the information about profits and sharing was. “So, through complex financial and legal wizardry, we developed a system where 50% of Nebula profits were distributed to the creators, including crucially, if the platform were ever to be sold”. This clarifies that creators get 50% of the profit as well as 50% of the proceeds from a sale of the company, but very specifically doesn’t mention ownership. Do they get paid 50% because they own 50%? Do they own less than that but get 50% through some other mechanism such as liquidation preference? Is there just some contract that says the company owes them money in the event of a sale?</p><p id="d56e">The ownership structure of Standard Broadcast is described with slightly less ambiguity. The company was initially founded by Dave Wiskus, CGP Grey, and Philip Dettmer, but Gray and Dettmer later sold their stake in the company to five other creators. So at that point ownership of Standard was split between six individuals:</p><ul><li id="9fef">Dave Wiskus</li><li id="02dc">Brian McManus (Real Engineering)</li><li id="efde">Alex (LowSpecGamer)</li><li id="e590">Devin Stone (Legal Eagle)</li><li id="df8f">Thomas Frank</li><li id="0081">Sam Denby (Wendover Productions)</li></ul><p id="d093">As I mentioned previously, some ownership of Standard has since been offered to other creators through stock options, but it’s unclear how much or what type of stock those options represent.</p><p id="1dc1">The firsthand information about Nebula and Standard Broadcast was turning out to be less useful than I had hoped, but the documentary did provide one valuable lead: the investment from Curiosity Stream. “While the exact numbers are not public, what is is that they bought a significant minority stake that valued Nebula, the company that did not exist just three years prior, at over $50 million.” That’s a little vague, but an investment and a valuation number was something I could start to do math with.</p><p id="c870">Whenever a company makes shares available for purchase, they have to file that information with the SEC through what’s called a Form D notice. Watch Nebula LLC has only ever made <a href="https://www.sec.gov/Archives/edgar/data/1881238/000188123821000001/xslFormDX01/primary_doc.xml" rel="noopener ugc nofollow" target="_blank">one Form D filing</a> so it’s not hard to find the investment. Nebula sold precisely $6 million worth of shares, so if we take $50 million as a lower bound for the valuation we can calculate the upper bound of what Curiosity Stream owns. $6 million is 12% of $50 million, so Curiosity Stream could own as much as 12% of Nebula. There’s also another $6.5 million that was authorized but not sold (at least at the time the Form D was filed).</p><h2 id="d4dc">The Reddit AMA</h2><p id="2ef1">Following the announcement that Nebula was taking investment from Curiosity Stream, Standard Broadcast’s CEO did an <a href="https://www.reddit.com/r/watchnebula/comments/pj0cyw/nebula_has_taken_investment_from_curiositystream/" rel="noopener ugc nofollow" target="_blank">AMA on Reddit</a>. I figured this would be a good place to look for more info about that investment, especially since the answers came straight from the top.</p><p id="0027">One user was curious about the leverage Curiosity Stream would have over the platform.</p><figure><figcaption>Reddit exchange between Oddtail and dwiskus, transcribed below</figcaption></figure><blockquote><p id="a807"><strong>Oddtail</strong>: What, if any, leverage CS has over Nebula and how it operates? If none, what does CS get in return for the investment?</p><p id="7b83"><strong>dwiskus</strong>: CS gets a board seat and a percentage of ownership, meaning a cut of future profits. They get a vote on things like budget approval, but operational and creative control remains with us. Practically speaking CS is well-aware of our plans, and how our plans will significantly benefit them. They aren’t interested in changing our course or slowing us down even if they could. Quite the opposite.</p><p id="d011"><strong>__law</strong>: can we know what % cs own? And who are the other owners of the company?</p><p id="4cdc"><strong>dwiskus</strong>: Percentages weren’t disclosed, but it’s a minority stake. There are no other investors.</p></blockquote><p id="a44c">This confirms that Curiosity Stream does own a portion of Nebula (which is undeniable based on the Form D filing I talked about before), but it also adds that they get a single board seat out of the deal. Furthermore, and possibly more importantly, this confirms that the board controls the budget.</p><p id="3b9f">Another user wanted to know about the relationship between Standard and Nebula.</p><figure><figcaption>Reddit exchange between PatrickStirling and dwiskus, transcribed below</figcaption></figure><blockquote><p id="7a04"><strong>PatrickStirling</strong>: are Nebula and Standard completely separate entities? or is one technically under the other?</p><p id="f1a6"><strong>dwiskus</strong>: Nebula is a subsidiary. Standard holds the majority of Nebula LLC equity.</p></blockquote><p id="4447">If we assume that words mean things (specifically the word majority in this case), this confirms my earlier suspicion that Standard owns more than 50% of Nebula.</p><p id="ace8">Another user seemed to be connecting some of the same dots I was and started asking questions about dilution. In case you’re unfamiliar with dilution, when companies take investment they typically do so by issuing new shares for the investor to purchase. This means the total number of shares increases, thus lowering the value of any existing shares as a percent of the total.</p><figure><figcaption>Reddit exchange between yolomatic_swagmaster, dwiskus, and gurgelblaster, transcribed below</figcaption></figure><blockquote><p id="532d"><strong>yolomatic_swagmaster</strong>: How does Curiosity Stream’s investment affect the other creators in terms of them being part-owners? I’m not super clear on how that works anyway. but wondering if anything changes for their set up.</p><p id="ae0c"><strong>dwiskus</strong>: Complicated question, but in short: creators still have full control and have lost no equity value.</p><p id="f0d7"><strong>gurgelblaster</strong>: …but the equity <em>share</em> is lower?</p><p id="f12f"><strong>dwiskus</strong>: Nope! Like I said, it’s complicated.</p></blockquote><p id="241a">And once again we have a contradiction. We added new shares but nobody lost equity. How is that possible? “It’s complicated”.</p><h2 id="716a">Some Actual Answers</h2><p id="8a25">At this point I’d grown tired of non-answers. I’m not ok with impossible equity numbers being hand waved away as “a new kind of corporate governance”, “financial and legal wizardry”, or just simply “complicated”. These are not the kind of answers people who are being entirely truthful give.</p><p id="5283">Luckily there was one other place I could think to look for hard numbers. The Wendover documentary may have claimed that “the exact numbers aren’t public”, but that’s only partially true. Nebula is a private company, and as such only has to file the unfortunately sparse Form D when offering stock. Curiosity Stream, on the other hand, is publicly traded and has to make much more detailed quarterly filings about all their financials. This includes their investments.</p><p id="392f">So what does <a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001776909/700b53ed-0101-4c70-96d5-a67734e7f50d.pdf" rel="noopener ugc nofollow" target="_blank">Curiosity Stream’s SEC filing</a> say about the Nebula investment?</p><blockquote><p id="a6f2"><strong>Watch Nebula LLC (“Nebula”)</strong></p><p id="1b0a">On August 23, 2021, the Company purchased a 12% ownership interest in Watch Nebula LLC for $6,000. Nebula is an SVOD technology platform built for and by a group of content creators. The Company is committed to purchasing an additional 13% ownership interest through eight quarterly payments of $813, which after each payment, the Company will obtain an additional 1.625% of equity ownership interests. Prior to the Company’s investment, Nebula was a 100% wholly owned subsidiary of Standard Broadcast LLC (“Standard”). The Company obtained 25% of the representation on Nebula’s Board of Directors, providing the Company with significant influence, but not a controlling interest.</p></blockquote><p id="ebbe">So let’s go down the list of what we can learn from this:</p><ul><li id="87bc">The initial $6 million was for 12% ownership</li><li id="61b5">They had offered enough stock for a potential ownership of 25%. (that’s the additional 6.5 million from the Form D)</li><li id="dd00">Standard Broadcast owned 100% of Nebula prior to this investment</li><li id="b708">Curiosity Stream controls 25% of Nebula’s board</li></ul><p id="076b">From this we can infer:</p><ul><li id="69e1">Nebula was valued at <em>exactly</em> $50 million, not over</li><li id="68bd">Nebula has 4 board members</li><li id="170d">The creators directly own 0% of Nebula</li></ul><p id="e853">As a side note, if they want to say owning part of Standard Broadcast means you own part of Nebula, then owning part of Curiosity Stream also means you own part of Nebula. Since Curiosity Stream is partly owned but venture capitalists, that would mean that Nebula has in fact taken VC investment. They don’t get to have that cake and eat it too.</p><h2 id="04ff">How Can 0% Be Right?</h2><p id="f017">At this point I got frustrated and typed something like “Nebula creators don’t own any of the company” into Google. This was mostly just me shouting into the void. I didn’t expect to get good results from a query like that, but somehow those turned out to be the magic words that returned the one firsthand source I hadn’t found yet.</p><p id="91d4">It turns out the answer can be found in <a href="https://www.theverge.com/23076663/nebula-youtube-creator-business-future-startup-ceo-dave-wiskus" rel="noopener ugc nofollow" target="_blank">an episode of the Decoder podcast</a>. After all that time I spent digging through cagey answers and SEC filings, it turns out Dave Wiskus just straight up tells us (assuming you know what to listen for). It also turns out that the reality is neither novel nor particularly complicated.</p><blockquote><p id="98d4">There is also a structure in place that if Nebula is ever sold, 50 percent of the proceeds go to the creators as a pool. It is a form of what is called shadow equity.</p></blockquote><p id="39d6">Shadow Equity (sometimes called Phantom Stock) isn’t real stock. It’s basically just an IOU that’s worth the same dollar value as the actual stock. The creators will get paid 50% of the proceeds in the event the company sells, but legally they don’t actually own any of the company.</p><h2 id="6795">The Final Tally</h2><p id="4e4b">So what does that leave us with? Who actually owns Nebula? After looking through <a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001776909/fac6815d-9eae-4e0a-8736-c4e95b4fc4a0.pdf" rel="noopener ugc nofollow" target="_blank">a more recent SEC filing</a> to figure out how many of those subsequent stock purchases Curiosity Stream actually made we’re left with the following final numbers:</p><ul><li id="d05c">83.125% Standard Broadcast</li><li id="4d60">16.875% Curiosity Stream</li><li id="18c1">0% The Creators (Directly)</li></ul><h2 id="d658">Conclusion</h2><p id="27d1">Unfortunately, without access to one of their contracts, we can’t know for sure what power the broader group of creators actually has. It’s possible that the terms are so favorable for creators that their shadow equity is as good as actual ownership. It’s equally possible, however, that the system was set up in order to keep any meaningful power away from the creators. If the creators don’t control the board then creators don’t control the budget, which means they don’t control the platform. While some creators may have the means to buy into the stock options offered by Standard Broadcast, that only serves to create a class hierarchy divided by wealth. Even if the contract terms are stellar, that’s still a system that completely undermines the progressive values of the creators who make the platform great.</p><p id="8106">Nebula is trading on the idea that it’s a creator owned platform and isn’t like those other tech companies that take VC funding. They utilize the language of cooperatives in order to craft an image that appeals to their left leaning audience, but it appears actual ownership lies primarily in the hands of six (mostly white) men. When you pull away the progressive veneer it turns out Nebula probably <em>is</em> just another tech company. While they may be operating in the best interests of the creators for the moment, I wouldn’t be surprised if that doesn’t continue forever.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Better-performing “25519” elliptic-curve cryptography (201 pts)]]></title>
            <link>https://www.amazon.science/blog/better-performing-25519-elliptic-curve-cryptography</link>
            <guid>41527675</guid>
            <pubDate>Fri, 13 Sep 2024 02:51:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amazon.science/blog/better-performing-25519-elliptic-curve-cryptography">https://www.amazon.science/blog/better-performing-25519-elliptic-curve-cryptography</a>, See on <a href="https://news.ycombinator.com/item?id=41527675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Cryptographic algorithms are essential to online security, and at Amazon Web Services (AWS), we implement cryptographic algorithms in our open-source cryptographic library, <a href="https://github.com/aws/aws-lc" target="_blank" data-cms-ai="0">AWS LibCrypto</a> (AWS-LC), based on code from Google’s BoringSSL project. AWS-LC offers AWS customers implementations of cryptographic algorithms that are secure and optimized for AWS hardware.</p><p>Two cryptographic algorithms that have become increasingly popular are <a href="https://doi.org/10.1007/11745853_14" target="_blank" data-cms-ai="0">x25519</a> and <a href="https://doi.org/10.1007/s13389-012-0027-1" target="_blank" data-cms-ai="0">Ed25519</a>, both based on an <a href="https://en.wikipedia.org/wiki/Elliptic_curve" target="_blank" data-cms-ai="0">elliptic curve</a> known as curve25519. To improve the customer experience when using these algorithms, we recently took a deeper look at their implementations in AWS-LC. Henceforth, we use x/Ed25519 as shorthand for “x25519 and Ed25519”.</p><div data-align-left-rail=""><ps-related-content>
  <div data-media="" data-content-type="blog post">
        
            <div>
                
                    <a aria-label="Formal verification makes RSA faster — and faster to deploy" href="https://www.amazon.science/blog/formal-verification-makes-rsa-faster-and-faster-to-deploy" data-cms-ai="0"><picture><source type="image/webp" width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/36c5aec/2147483647/strip/true/crop/1017x575+0+0/resize/400x226!/format/webp/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F41%2Fad%2F75576be04568aa5a011408123c26%2Fgraviton-chip.png" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4="><source width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/12958c9/2147483647/strip/true/crop/1017x575+0+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F41%2Fad%2F75576be04568aa5a011408123c26%2Fgraviton-chip.png" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    
        <img data-image-size="relatedContent" alt="Graviton chip.png" width="400" height="226" data-src="https://assets.amazon.science/dims4/default/12958c9/2147483647/strip/true/crop/1017x575+0+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F41%2Fad%2F75576be04568aa5a011408123c26%2Fgraviton-chip.png" data-lazy-load="true" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    </picture>
</a>
                
            </div>
        

        <div>
            
              <p>
                  Related content
              </p>
            
            
                
            

            
    <p>Optimizations for Amazon's Graviton2 chip boost efficiency, and formal verification shortens development time.</p>


          </div>
    </div>
</ps-related-content>
</div><p>In 2023, AWS released multiple assembly-level implementations of x/Ed25519 in AWS-LC. By combining <a href="https://aws.amazon.com/what-is/automated-reasoning" target="_blank" data-cms-ai="0">automated reasoning</a> and state-of-the-art optimization techniques, these implementations improved performance over the existing AWS-LC implementations and also increased assurance of their correctness.</p><p>In particular, we prove functional correctness using automated reasoning and employ optimizations targeted to specific CPU microarchitectures for the instruction set architectures x86_64 and Arm64. We also do our best to execute the algorithms in <i>constant time</i>, to thwart side-channel attacks that infer secret information from the durations of computations.</p><p>In this post, we explore different aspects of our work, including the process for proving correctness via automated reasoning, microarchitecture (<i>μ</i>arch) optimization techniques, the special considerations for constant-time code, and the quantification of performance gains.<br></p><h2><p>Elliptic-curve cryptography</p></h2><p>Elliptic-curve cryptography is a method for doing public-key cryptography, which uses a pair of keys, one public and one private. One of the best-known public-key cryptographic schemes is RSA, in which the public key is a very large integer, and the corresponding private key is prime factors of the integer. The RSA scheme can be used both to encrypt/decrypt data and also to sign/verify data. (Members of our team recently blogged on Amazon Science about how we used automated reasoning to make the RSA implementation on Amazon’s Graviton2 chips <a href="https://www.amazon.science/blog/formal-verification-makes-rsa-faster-and-faster-to-deploy" data-cms-ai="0">faster and easier to deploy</a>.)</p><div data-align-right-narrow=""><figure>
    

    
        <p><figcaption>Example of an elliptic curve.</figcaption></p>
    
</figure></div><p>Elliptic curves offer an alternate way to mathematically relate public and private keys; sometimes, this means we can implement schemes more efficiently. While the mathematical theory of elliptic curves is both broad and deep, the elliptic curves used in cryptography are typically defined by an equation of the form <i>y<sup>2</sup> = x<sup>3</sup> + ax<sup>2</sup> + bx + c</i>, where <i>a, b,</i> and <i>c</i> are constants. You can plot the points that satisfy the equation on a 2-D graph.</p><p>An elliptic curve has the property that a line that intersects it at two points intersects it at at most one other point. This property is used to define operations on the curve. For instance, the addition of two points on the curve can be defined not, indeed, as the third point on the curve collinear with the first two but as that third point’s reflection around the axis of symmetry.</p><div data-align-center=""><figure>
    

    
        <p><figcaption>Addition on an elliptic curve.</figcaption></p>
    
</figure></div><p>Now, if the coordinates of points on the curve are taken modulo some integer, the curve becomes a scatter of points in the plane, but a scatter that still exhibits symmetry, so the addition operation remains well defined. Curve25519 is named after a large prime integer — specifically, 2<sup>255</sup> – 19. The set of numbers modulo the curve25519 prime, together with basic arithmetic operations such as multiplication of two numbers modulo the same prime, define the <i>field </i>in which our elliptic-curve operations take place.</p><p>Successive execution of elliptic-curve additions is called scalar multiplication, where the scalar is the number of additions. With the elliptic curves used in cryptography, if you know only the result of the scalar multiplication, it is intractable to recover the scalar, if the scalar is sufficiently large. The result of the scalar multiplication becomes the basis of a public key, the original scalar the basis of a private key.<br></p><h2><p>The x25519 and Ed25519 cryptographic algorithms</p></h2><p>The x/Ed25519 algorithms have distinct purposes. The x25519 algorithm is a key agreement algorithm, used to securely establish a shared secret between two peers; Ed25519 is a digital-signature algorithm, used to sign and verify data.</p><p>The x/Ed25519 algorithms have been adopted in transport layer protocols such as TLS and SSH. In 2023, NIST announced an update to its FIPS185-6 Digital Signature Standard that included the addition of Ed25519. The x25519 algorithm also plays a role in post-quantum safe cryptographic solutions, having been included as the classical algorithm in the TLS 1.3 and SSH hybrid scheme specifications for post-quantum key agreement.<br></p><h2><p>Microarchitecture optimizations</p></h2><p>When we write assembly code for a specific CPU architecture, we use its instruction set architecture (ISA). The ISA defines resources such as the available assembly instructions, their semantics, and the CPU registers accessible to the programmer. Importantly, the ISA defines the CPU in abstract terms; it doesn’t specify how the CPU should be realized in hardware.</p><div data-align-left-rail=""><ps-related-content>
  <div data-media="" data-content-type="blog post">
        
            <div>
                
                    <a aria-label="Amazon's Tal Rabin wins Dijkstra Prize in Distributed Computing" href="https://www.amazon.science/blog/amazons-tal-rabin-wins-dijkstra-prize-in-distributed-computing" data-cms-ai="0"><picture><source type="image/webp" width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/558f174/2147483647/strip/true/crop/1147x648+3+0/resize/400x226!/format/webp/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F43%2Fad%2Fe70e95ba40b387030b7671cddbcb%2Fsecure-multiparty-computation.gif" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4="><source width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/9dd0011/2147483647/strip/true/crop/1147x648+3+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F43%2Fad%2Fe70e95ba40b387030b7671cddbcb%2Fsecure-multiparty-computation.gif" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    
        <img data-image-size="relatedContent" alt="Secure multiparty computation.gif" width="400" height="226" data-src="https://assets.amazon.science/dims4/default/9dd0011/2147483647/strip/true/crop/1147x648+3+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F43%2Fad%2Fe70e95ba40b387030b7671cddbcb%2Fsecure-multiparty-computation.gif" data-lazy-load="true" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    </picture>
</a>
                
            </div>
        

        <div>
            
              <p>
                  Related content
              </p>
            
            
                
            

            
    <p>Prize honors Amazon senior principal scientist and Penn professor for a protocol that achieves a theoretical limit on information-theoretic secure multiparty computation.</p>


          </div>
    </div>
</ps-related-content>
</div><p>The detailed implementation of the CPU is called the microarchitecture, and every <i>μ</i>arch has unique characteristics. For example, while the AWS Graviton 2 CPU and AWS Graviton 3 CPU are both based on the Arm64 ISA, their <i>μ</i>arch implementations are different. We hypothesized that if we could take advantage of the <i>μ</i>arch differences, we could create x/Ed25519 implementations that were even faster than the existing implementations in AWS-LC. It turns out that this intuition was correct.</p><p>Let us look closer at how we took advantage of <i>μ</i>arch differences. Different arithmetic operations can be defined on curve25519, and different combinations of those operations are used to construct the x/Ed25519 algorithms. Logically, the necessary arithmetic operations can be considered at three levels:<br></p><ol><li><b>Field operations:</b> Operations within the field defined by the curve25519 prime 2<sup>255</sup> – 19.</li><li><b>Elliptic-curve group operations:</b> Operations that apply to elements of the curve itself, such as the addition of two points, P1 and P2.</li><li><b>Top-level operations:</b> Operations implemented by iterative application of elliptic-curve group operations, such as scalar multiplication.</li></ol><div data-align-center-expanded=""><figure>
    

    
        <p><figcaption>Examples of operations at different levels. Arrows indicate dependency relationships between levels.</figcaption></p>
    
</figure></div><p>Each level has its own avenues for optimization. We focused our <i>μ</i>arch-dependent optimizations on the level-one operations, while for levels two and three our implementations employ known state-of-the-art techniques and are largely the same for different <i>μ</i>archs. Below, we give a summary of the different <i>μ</i>arch-dependent choices we made in our implementations of x/Ed25519.<br></p><ul><li>For modern x86_64 <i>μ</i>archs, we use the instructions MULX, ADCX, and ADOX, which are variations of the standard assembly instructions MUL (multiply) and ADC (add with carry) found in the instruction set extensions commonly called <a href="https://en.wikipedia.org/wiki/X86_Bit_manipulation_instruction_set" target="_blank" data-cms-ai="0">BMI</a> and <a href="https://en.wikipedia.org/wiki/Intel_ADX" target="_blank" data-cms-ai="0">ADX</a>. These instructions are special because, when used in combination, they can maintain two carry chains in parallel, which has been observed to boost performance up to 30%. For older x86_64 <i>μ</i>archs that don’t support the instruction set extensions, we use more traditional single-carry chains.<br></li><li>For Arm64 <i>μ</i>archs, such as AWS Graviton 3 with improved integer multipliers, we use relatively straightforward schoolbook multiplication, which turns out to give good performance. AWS Graviton 2 has smaller multipliers. For this Arm64 <i>μ</i>arch, we use subtractive forms of <a href="https://en.wikipedia.org/wiki/Karatsuba_algorithm" target="_blank" data-cms-ai="0">Karatsuba multiplication</a>, which breaks down multiplications recursively. The reason is that, on these <i>μ</i>archs, 64x64-bit multiplication producing a 128-bit result has substantially lower throughput relative to other operations, making the number size at which Karatsuba optimization becomes worthwhile much smaller.</li></ul><p>We also optimized level-one operations that are the same for all <i>μ</i>archs. One example concerns the use of the binary greatest-common-divisor (GCD) algorithm to compute <a href="https://en.wikipedia.org/wiki/Modular_multiplicative_inverse" target="_blank" data-cms-ai="0">modular inverses</a>. We use the <a href="https://gcd.cr.yp.to/safegcd-20190413.pdf" target="_blank" data-cms-ai="0">“divstep” form of binary GCD</a>, which lends itself to efficient implementation, but it also complicates the second goal we had: formally proving correctness.</p><div data-align-right-rail=""><ps-related-content>
  <div data-media="" data-content-type="blog post">
        
            <div>
                
                    <a aria-label="Computing on private data" href="https://www.amazon.science/blog/computing-on-private-data" data-cms-ai="0"><picture><source type="image/webp" width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/141ff88/2147483647/strip/true/crop/796x450+2+0/resize/400x226!/format/webp/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fae%2Fcc%2Fd5f245aa4d2d9d6e567f20c8fe4d%2Fsecure-multiparty-computation.gif" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4="><source width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/cbf6c70/2147483647/strip/true/crop/796x450+2+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fae%2Fcc%2Fd5f245aa4d2d9d6e567f20c8fe4d%2Fsecure-multiparty-computation.gif" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    
        <img data-image-size="relatedContent" alt="Secure multiparty computation.gif" width="400" height="226" data-src="https://assets.amazon.science/dims4/default/cbf6c70/2147483647/strip/true/crop/796x450+2+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fae%2Fcc%2Fd5f245aa4d2d9d6e567f20c8fe4d%2Fsecure-multiparty-computation.gif" data-lazy-load="true" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    </picture>
</a>
                
            </div>
        

        <div>
            
              <p>
                  Related content
              </p>
            
            
                
            

            
    <p>Both secure multiparty computation and differential privacy protect the privacy of data used in computation, but each has advantages in different contexts.</p>


          </div>
    </div>
</ps-related-content>
</div><p>Binary GCD is an iterative algorithm with two arguments, whose initial values are the numbers whose greatest common divisor we seek. The arguments are successively reduced in a well-defined way, until the value of one of them reaches zero. With two <i>n</i>-bit numbers, the standard implementation of the algorithm removes at least one bit total per iteration, so 2<i>n</i> iterations suffice.</p><p>With divstep, however, determining the number of iterations needed to get down to the base case seems analytically difficult. The most tractable proof of the bound uses an elaborate inductive argument based on an intricate “stable hull” provably overapproximating the region in two-dimensional space containing the points corresponding to the argument values. Daniel Bernstein, one of the inventors of x25519 and Ed25519, proved the <a href="https://cr.yp.to/papers.html#pwccp" target="_blank" data-cms-ai="0">formal correctness</a> of the bound using <a href="https://hol-light.github.io/" target="_blank" data-cms-ai="0">HOL Light</a>, a proof assistant that one of us (John) created. (For more on HOL Light, see, again, our earlier <a href="https://www.amazon.science/blog/formal-verification-makes-rsa-faster-and-faster-to-deploy" data-cms-ai="0">RSA post</a>.)<br></p><h2><p>Performance results</p></h2><p>In this section, we will highlight improvements in performance. For the sake of simplicity, we focus on only three <i>μ</i>archs: AWS Graviton 3, AWS Graviton 2, and Intel Ice Lake. To gather performance data, we used EC2 instances with matching CPU <i>μ</i>archs — c6g.4xlarge, c7g.4xlarge, and c6i.4xlarge, respectively; to measure each algorithm, we used the <a href="https://github.com/aws/aws-lc/tree/main/tool#benchmarking-tools" target="_blank" data-cms-ai="0">AWS-LC speed tool</a>.</p><p>In the graphs below, all units are operations per second (ops/sec). The “before” columns represent the performance of the existing x/Ed25519 implementations in AWS-LC. The “after” columns represent the performance of the new implementations.</p><div data-align-center=""><figure>
    

    
        <p><figcaption>For the Ed25519 signing operation, the number of operations per second, over the three μarchs, is, on average, 108% higher with the new implementations.</figcaption></p>
    
</figure></div><div data-align-center=""><figure>
    

    
        <p><figcaption>For the Ed25519 verification operation, we increased the number of operations per second, over the three μarchs, by an average of 37%.</figcaption></p>
    
</figure></div><p>We observed the biggest improvement for the x25519 algorithm. Note that an x25519 operation in the graph below includes the two major operations needed for an x25519 key exchange agreement: base-point multiplication and variable-point multiplication.</p><div data-align-center=""><figure>
    

    
        <p><figcaption>With x25519, the new implementation increases the number of operations per second, over the three μarchs, by an average of 113%.</figcaption></p>
    
</figure></div><p>On average, over the AWS Graviton 2, AWS Graviton 3, and Intel Ice Lake microarchitectures, we saw an 86% improvement in performance.<br></p><h2><p>Proving correctness</p></h2><p>We develop the core parts of the x/Ed25519 implementations in AWS-LC in <a href="https://github.com/awslabs/s2n-bignum" target="_blank" data-cms-ai="0">s2n-bignum</a>, an AWS-owned library of integer arithmetic routines designed for cryptographic applications. The s2n-bignum library is also where we prove the functional correctness of the implementations using <a href="https://hol-light.github.io/" target="_blank" data-cms-ai="0">HOL Light</a>. HOL Light is an interactive theorem prover for higher-order logic (hence HOL), and it is designed to have a particularly simple (hence light) “correct by construction” approach to proof. This simplicity offers assurance that anything “proved” has really been proved rigorously and is not the artifact of a prover bug.</p><div data-align-right-rail=""><ps-related-content>
  <div data-media="" data-content-type="blog post">
        
            <div>
                
                    <a aria-label="Building machine learning models with encrypted data" href="https://www.amazon.science/blog/building-machine-learning-models-with-encrypted-data" data-cms-ai="0"><picture><source type="image/webp" width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/dcee87a/2147483647/strip/true/crop/1646x930+0+0/resize/400x226!/format/webp/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F36%2F3e%2F30afc01048579a618100b6cb7b25%2Flow-depth-circuit.wide-crop.png" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4="><source width="400" height="226" data-image-size="relatedContent" data-srcset="https://assets.amazon.science/dims4/default/64e1b73/2147483647/strip/true/crop/1646x930+0+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F36%2F3e%2F30afc01048579a618100b6cb7b25%2Flow-depth-circuit.wide-crop.png" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    
        <img data-image-size="relatedContent" alt="Diagram of a circuit with a multiplicative depth of two" width="400" height="226" data-src="https://assets.amazon.science/dims4/default/64e1b73/2147483647/strip/true/crop/1646x930+0+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F36%2F3e%2F30afc01048579a618100b6cb7b25%2Flow-depth-circuit.wide-crop.png" data-lazy-load="true" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSIyMjZweCIgd2lkdGg9IjQwMHB4Ij48L3N2Zz4=">
    </picture>
</a>
                
            </div>
        

        <div>
            
              <p>
                  Related content
              </p>
            
            
                
            

            
    <p>New approach to homomorphic encryption speeds up the training of encrypted machine learning models sixfold.</p>


          </div>
    </div>
</ps-related-content>
</div><p>We follow the same principle of simplicity when we write our implementations in assembly. Writing in assembly is more challenging, but it offers a distinct advantage when proving correctness: our proofs become independent of any compiler.</p><p>The diagram below shows the process we use to prove x/Ed25519 correct. The process requires two different sets of inputs: first is the algorithm implementation we’re evaluating; second is a proof script that models both the correct mathematical behavior of the algorithm and the behavior of the CPU. The proof is a sequence of functions specific to HOL Light that represent proof strategies and the order in which they should be applied. Writing the proof is not automated and requires developer ingenuity.</p><p>From the algorithm implementation and the proof script, HOL Light either determines that the implementation is correct or, if unable to do so, fails. HOL Light views the algorithm implementation as a sequence of machine code bytes. Using the supplied specification of CPU instructions and the developer-written strategies in the proof script, HOL Light reasons about the correctness of the execution.</p><div data-align-left=""><figure>
    

    
        <p><figcaption>CI integration provides assurance that no changes to the algorithm implementation code can be committed to s2n-bignum’s code repository without successfully passing a formal proof of correctness.</figcaption></p>
    
</figure></div><p>This part of the correctness proof is automated, and we even implement it inside s2n-bignum’s continuous-integration (CI) workflow. The workflow covered in the CI is highlighted by the red dotted line in the diagram below. CI integration provides assurance that no changes to the algorithm implementation code can be committed to s2n-bignum’s code repository without successfully passing a formal proof of correctness.</p><p>The CPU instruction specification is one of the most critical ingredients in our correctness proofs. For the proofs to be true in practice, the specification must capture the real-world semantics of each instruction. To improve assurance on this point, we apply randomized testing against the instruction specifications on real hardware, “fuzzing out” inaccuracies.<br></p><h2><p>Constant time</p></h2><p>We designed our implementations and optimizations with security as priority number one. Cryptographic code must strive to be free of <a href="https://en.wikipedia.org/wiki/Side-channel_attack" target="_blank" data-cms-ai="0">side channels</a> that could allow an unauthorized user to extract private information. For example, if the execution time of cryptographic code depends on secret values, then it might be possible to infer those values from execution times. Similarly, if CPU cache behavior depends on secret values, an unauthorized user who shares the cache could infer those values.</p><p>Our implementations of x/Ed25519 are designed with constant time in mind. They perform exactly the same sequence of basic CPU instructions regardless of the input values, and they avoid any CPU instructions that might have data-dependent timing.<br></p><h2><p>Using x/Ed25519 optimizations in applications</p></h2><p>AWS uses AWS-LC extensively to power cryptographic operations in a diverse set of AWS service subsystems. You can take advantage of the x/Ed25519 optimizations presented in this blog by using AWS-LC in your application(s). Visit <a href="https://github.com/aws/aws-lc" target="_blank" data-cms-ai="0">AWS-LC on Github</a> to learn more about how you can integrate AWS-LC into your application.</p><p>To allow easier integration for developers, AWS has created bindings from AWS-LC to multiple programming languages. These bindings expose cryptographic functionality from AWS-LC through well-defined APIs, removing the need to reimplement cryptographic algorithms in higher-level programming languages. At present, AWS has open-sourced bindings for Java and Rust — the Amazon Corretto Cryptographic Provider (<a href="https://aws.amazon.com/blogs/security/accelerating-jvm-cryptography-with-amazon-corretto-crypto-provider-2" target="_blank" data-cms-ai="0">ACCP</a>) for Java, and AWS-LC for Rust (<a href="https://aws.amazon.com/blogs/opensource/introducing-aws-libcrypto-for-rust-an-open-source-cryptographic-library-for-rust" target="_blank" data-cms-ai="0">aws-lc-rs</a>). Furthermore, we have contributed patches allowing <a href="https://discuss.python.org/t/support-building-ssl-and-hashlib-modules-against-aws-lc/44505/8" target="_blank" data-cms-ai="0">CPython</a> to build against AWS-LC and use it for all cryptography in the Python standard library. Below we highlight some of the open-source projects that are already using AWS-LC to meet their cryptographic needs.</p><div data-align-center=""><figure>
    

    
        <p><figcaption>Open-source projects using AWS-LC to meet their cryptographic needs.</figcaption></p>
    
</figure></div><p>We are not done yet. We continue our efforts to improve x/Ed25519 performance as well as pursuing optimizations for other cryptographic algorithms supported by s2n-bignum and AWS-LC. Follow the <a href="https://github.com/awslabs/s2n-bignum" target="_blank" data-cms-ai="0">s2n-bignum</a> and <a href="https://github.com/aws/aws-lc" target="_blank" data-cms-ai="0">AWS-LC</a> repositories for updates.</p></div><div>
                        
                            
    <div>
            
                
            
            
            
                <p>
                    Torben Hansen is an applied scientist with AWS Cryptography.
                </p>
            
        </div>


                        
                            
    <div>
            
                
            
            
            
                <p>
                    John Harrison is a senior principal applied scientist in Amazon’s Automated Reasoning Group. He is a maintainer of s2n-bignum and the HOL Light theorem prover.
                </p>
            
        </div>


                        
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does Your Startup Need Complex Cloud Infrastructure? (251 pts)]]></title>
            <link>https://www.hadijaveed.me/2024/09/08/does-your-startup-really-need-complex-cloud-infrastructure/</link>
            <guid>41527564</guid>
            <pubDate>Fri, 13 Sep 2024 02:29:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hadijaveed.me/2024/09/08/does-your-startup-really-need-complex-cloud-infrastructure/">https://www.hadijaveed.me/2024/09/08/does-your-startup-really-need-complex-cloud-infrastructure/</a>, See on <a href="https://news.ycombinator.com/item?id=41527564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="main"> <!-- Page content --> <article>   <p>I recently listened to <a href="https://x.com/levelsio" target="_blank">Pieter Levels</a> on the <a href="https://www.youtube.com/watch?v=oFtjKbXKqbg&amp;ab_channel=LexFridman" target="_blank">Lex Friedman Podcast</a>, and it was eye-opening. Pieter has built numerous successful micro-SaaS businesses by running his applications on single server, avoiding cloud infrastructure complexity, and focusing on what truly matters: product-market fit.</p> <!-- more --> <p>While his approach might not suit teams and generally every startup, but it raises a valid point: we've often made deployment and infrastructure management complex for complexity's sake.</p> <p>For small dev teams moving past the MVP stage, managing deployments and databases can be challenging. But here's the truth: not every project needs Kubernetes, complex distributed systems, or auto-scaling from day one. Simple infrastructure can often suffice, allowing teams to focus on building a great product and finding market fit.</p> <h2 id="recent-observations">Recent Observations<a href="#recent-observations" title="Permanent link">¶</a></h2> <p>Let me share two recent examples of projects I've worked on that highlight this issue:</p> <h3 id="project-1-lambda-overload">Project 1: Lambda Overload<a href="#project-1-lambda-overload" title="Permanent link">¶</a></h3> <ul> <li>20-30 Lambda functions for different services</li> <li>SQS and various background jobs backed by Lambda</li> <li>Logs scattered across CloudWatch</li> </ul> <p>Result? Painful debugging, difficult changes, and complex deployments, even in a monorepo. Could this have been simplified to a single NodeJS container or Python Flask/FastAPI app with Redis for background tasks? Absolutely.</p> <h3 id="project-2-microservices-mayhem">Project 2: Microservices Mayhem<a href="#project-2-microservices-mayhem" title="Permanent link">¶</a></h3> <ul> <li>7 small microservices on Kubernetes (EKS)</li> <li>Separate services for CRUD and business logic</li> </ul> <p>While Kubernetes is powerful, the team spent more time on infrastructure than building features. Was this level of separation necessary for their scale?</p> <div> <p>Note</p> <p>Enterprise-scale companies face different challenges with compliance and large workforces. Startups don't need to mimic this complexity. Early-stage companies should prioritize product-market fit and rapid iteration.</p> </div> <h2 id="the-power-of-single-server-setups">The Power of Single Server Setups<a href="#the-power-of-single-server-setups" title="Permanent link">¶</a></h2> <p>Modern servers pack a punch. You can get powerful VMs from <a href="https://www.hetzner.com/" target="_blank">Hetzner</a> or <a href="https://www.latitude.sh/" target="_blank">latitude.sh</a> at budget-friendly prices. Even <a href="https://cloud.google.com/compute/vm-instance-pricing" target="_blank">GCP VMs</a> and <a href="https://aws.amazon.com/ec2/pricing/on-demand/" target="_blank">EC2</a> instances are reasonably priced.</p> <p>These machines offer robust compute power - think 40GB RAM and multiple cores - often outperforming distributed services or multiple Lambdas or ECS tasks. Plus, everything's centralized and easier to manage.</p> <p>Worried about scaling to millions of QPS? Cross that bridge when you come to it. By then, you'll likely have an infrastructure team to handle it.</p> <p>For a reliable single VM setup, you need:</p> <ol> <li>A robust machine (EC2, GCP VM, Hetzner, etc.)</li> <li>Secure access (HTTPS for web, IP-restricted SSH or SSM for deployment)</li> <li>CI/CD for zero-downtime deployments</li> <li>DNS configuration</li> <li>Regular database backups</li> <li>A standby VM for redundancy</li> </ol> <p>Yes, you'll need a solid disaster recovery strategy and tested mean recovery time, but it's achievable with a backup VM.</p> <h2 id="docker-compose">Docker Compose<a href="#docker-compose" title="Permanent link">¶</a></h2> <p>Docker Compose is fantastic for local development, managing multiple services with a single command. Surprisingly, it's underutilized in production environments, and Docker Swarm was deprecated..</p> <p>While Docker Compose can cause downtime during updates, there are <a href="https://docs.docker.com/compose/production/" target="_blank">guides for production deployment</a>. It's a balance between simplicity and production readiness.</p> <h2 id="docker-compose-anywhere-a-weekend-project">Docker Compose Anywhere: A Weekend Project<a href="#docker-compose-anywhere-a-weekend-project" title="Permanent link">¶</a></h2> <p>To simplify this setup further, I created <a href="https://github.com/hadijaveed/docker-compose-anywhere" target="_blank">Docker Compose Anywhere</a> over the weekend. This opinionated template offers:</p> <ul> <li>One-click Linux server setup via GitHub Actions</li> <li>Zero-downtime continuous deployment using GitHub Container Registry and <a href="https://github.com/Wowu/docker-rollout" target="_blank">Docker Rollout</a></li> <li>Environment variable and secret management (considering <a href="https://github.com/FiloSottile/age" target="_blank">age</a> or <a href="https://github.com/getsops/sops" target="_blank">sops</a> for improved security)</li> <li>Automated Postgres backups via GitHub Actions</li> <li>Multi-app support on a single VM</li> <li>Automated SSL with <a href="https://traefik.io/traefik/" target="_blank">Traefik</a> and <a href="https://letsencrypt.org/" target="_blank">Let's Encrypt</a></li> <li>Deploy Next.js apps, GO, Python, Node.js, and more</li> </ul> <h3 id="few-considerations">Few Considerations<a href="#few-considerations" title="Permanent link">¶</a></h3> <p>For security, remember to:</p> <ul> <li>Set strict firewall rules (open only necessary ports)</li> <li>Secure SSH keys (prefer SSM on AWS or CLI on GCP)</li> <li>Use a bastion host for enhanced security</li> <li>Protect secrets and consider using a WAF or Cloudflare</li> </ul> <p>Don't forget about data protection:</p> <ul> <li>Send encrypted database backups to secure cloud storage (e.g., S3 or equivalent)</li> <li>Regularly snapshot your disks for added redundancy</li> <li>Implement a retention policy for backups and snapshots</li> </ul> <p>As engineers, our primary goal should be advocating for simplicity in our setup and focusing on the core product. </p> <p>It's all too easy to get distracted by shiny new tools or complex setups that mimic what Google engineers or large enterprises are doing. But here's the truth: whether you're in a startup or not, what truly matters is talking to your users and finding product-market fit.</p> </article> </div></div>]]></description>
        </item>
    </channel>
</rss>