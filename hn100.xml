<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 29 Oct 2024 14:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What happens when people with acute psychosis meet the voices in their heads? (118 pts)]]></title>
            <link>https://www.theguardian.com/news/2024/oct/29/acute-psychosis-inner-voices-avatar-therapy-psychiatry</link>
            <guid>41980986</guid>
            <pubDate>Tue, 29 Oct 2024 08:43:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/news/2024/oct/29/acute-psychosis-inner-voices-avatar-therapy-psychiatry">https://www.theguardian.com/news/2024/oct/29/acute-psychosis-inner-voices-avatar-therapy-psychiatry</a>, See on <a href="https://news.ycombinator.com/item?id=41980986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>I</span>n the summer of 2019, when Joe was 21, he went on a university rugby tour of California. One night, one of his teammates bought some cannabis edibles to share, and Joe ate some. For the next 12 hours, he believed he was in hell. He was on fire; his body was suffused with pain. His ears were filled first with incoherent screaming and then with sinister whispering. Joe’s friends thought their teammate’s bad trip was funny, even as they wrestled him away from the windows when he tried to jump from the seventh floor of their hotel.</p><p>When he woke up the next morning, Joe was still in hell. A devilish, humanoid form lurking in the periphery of his vision was telling him he had died the previous night. A chorus of other voices joined in, wailing in agony. They were entirely real to him, even though he knew they couldn’t be. He had a rugby match to play, and 10 minutes in, he couldn’t see or feel his hands; he couldn’t move. His teammates laughed as he came off the pitch. Poor old Joe.</p><p>The voices came back to the UK with him. “You’re not real,” they told him incessantly. “You’re already dead, so it doesn’t matter if you end it all again.” He saw blurred, demonic faces smirking at him, sometimes at the edge of his eye line, sometimes up against his face, too close to be in focus.</p><figure id="75c14611-ab14-42df-aff4-7dc45fd0a0d4" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Using avatars in psychosis therapy can help those who hear voices, study finds &quot;,&quot;elementId&quot;:&quot;75c14611-ab14-42df-aff4-7dc45fd0a0d4&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2024/oct/28/using-avatars-in-psychosis-therapy-can-help-those-who-hear-voices-study-finds&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:1,&quot;theme&quot;:0}}"></gu-island></figure><p>His parents knew he had struggled with depression and anxiety before, but Joe didn’t want to tell anyone about the voices. He drank heavily, every blackout providing temporary respite. He would walk for hours, playing music on his headphones, desperate to drown out the voices. At other times Joe would tell the voices to fuck off, shut up, leave him alone. He would find himself saying these things out loud, in public. Seeing himself reflected in the fearful eyes of those he walked past, he was terrified that he would never find a way to be normal among them again.</p><p>Joe was later told he was experiencing acute psychosis. About <a href="https://www.derbyshirehealthcareft.nhs.uk/services/mental-health-and-emotional-wellbeing/early-intervention-psychosis" data-link-name="in body link">two or three people in every 100</a> experience psychosis, when reality is disrupted by delusions or hallucinations. It can be a symptom of schizophrenia or severe depression, but can also be experienced without any other mental health condition. The acute form – the sudden, rapid onset of auditory or visual hallucinations that Joe experienced – can be triggered by drugs in people who, <a href="https://journals.sagepub.com/doi/10.1177/0020764018801690" data-link-name="in body link">because of existing biological and social factors</a>, might be predisposed to psychosis. Hearing voices is <a href="https://www.sciencedirect.com/science/article/abs/pii/S0272735809001615?via%3Dihub" data-link-name="in body link">the most common form</a> of psychosis, affecting <a href="https://pubmed.ncbi.nlm.nih.gov/22446568/" data-link-name="in body link">as many as 70%</a> of people with schizophrenia, and the voices heard tend to be persecutory and distressing. More than one in 10 people with schizophrenia end up <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1845151/" data-link-name="in body link">taking their own lives</a>.</p><p>Antipsychotic medications, the go-to treatment since the mid-20th century, can come with serious side-effects, including weight gain, exhaustion, bed-wetting, sexual dysfunction and severe constipation. And they don’t work for everyone: a quarter of people on antipsychotics will continue to hear voices. The most effective medication, Clozapine, is only used where other antipsychotics have failed because it can cause even more severe side-effects. It was developed in the 1950s; there has been little drug innovation for psychosis in recent decades. There are also non-pharmacological treatments; cognitive behavioural therapy for psychosis (CBTp), when combined with medication, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6280425/" data-link-name="in body link">improves symptoms</a> for about 50% of people.</p><p>After hearing the voices for two and a half years, Joe went to his GP in winter 2021 and received his formal diagnosis. He was put on a low dose of antipsychotic medication, which he hated: he couldn’t get out of bed, couldn’t function and, while it helped with his visual hallucinations, the voices remained. He came off the medication after two months. Depressed, despairing and starting to spiral, he got back in touch with his GP, who told him there was something else to try: an experimental therapy, a clinical trial he could be part of, that turned the traditional treatment model for psychosis on its head.</p><p>If you hear voices, clinicians don’t generally ask what they’re saying to you, beyond whether they are asking you to harm yourself or others. “There’s been a reluctance to engage much with the content of voices,” Ben Alderson-Day, an associate professor of psychology at Durham University who specialises in psychosis, told me. “That’s in part because of a concern that if you ask voice-hearers to elaborate, you might engage in ‘collusion’: you may make [the voices] more real for people.” A clinician may diagnose a patient with psychosis, and prescribe them medication or CBT, without knowing what the patient’s voices say to them.</p><p>This new therapy demanded that voices were listened to closely, and responded to as if they were spoken by entirely real external beings. Trial participants would create an avatar of their voice: a moving, three-dimensional digital embodiment that looks and sounds like the persecutor inside their heads. They would be guided by a therapist to have a dialogue with the voice – and the hope was, through doing so, gain control over it.</p><p>Within a few weeks, the voice that told Joe he was dead – the one he so feared could be real – was manifested in colour in front of him. For the therapy to work, he needed to find the courage to look the demon in the eyes; to challenge and conquer it. If he succeeded, the voices might fade away.</p><hr><p><span>P</span>rof Julian Leff was seven years into his retirement when the idea of avatar therapy came to him. After a celebrated career as a social psychiatrist and schizophrenia specialist at University College London, Leff was sitting at home in Hampstead, pondering the results of a survey that reported the most distressing aspect of hearing voices was the feeling of helplessness. On the rare occasions when his patients had had meaningful exchanges with their voices, he knew they had felt more in control. “I thought, how can I enable the patient to have a dialogue with an invisible voice?” Leff said in an interview for a documentary made in 2018, three years before his death. “If I can somehow manage to create for the patient the image and voice of the person who they hear abusing them, maybe they could learn to overcome this awful persecution.”</p><p>Leff was awarded a small grant for a pilot study in 2008. He recruited Mark Huckvale, professor of speech, hearing and phonetic sciences at UCL, to be in charge of the tech. They tinkered with existing police identikit software, animating digitally created faces in three dimensions so they could nod, smile and maintain eye contact. They combined this with an off-the-shelf programme called Lip Synch, so that the mouth would move appropriately, and voice-changing software, so the avatar could be made to sound male or female, rougher or smoother, higher or lower, older or younger.</p><p>The avatar was a floating, moving head on a computer screen, voiced by Leff, who would be in a separate room to the patient, watching via webcam. He could speak to the patient in his own voice, guiding them through the dialogue, and then switch with the click of a mouse to the role of the avatar on the patient’s screen, its lips synched to his speech. The setup allowed him to act as a therapist to the patient and a puppeteer to the avatar. At first, the avatar would say typical lines the patient had shared with Leff: often degrading, abusive phrases. But over the course of six sessions, the dialogue would change, with the avatar yielding to the patient, transforming from omnipotent to submissive. At all times, Leff and the patient were to treat the avatar as if it were an entirely real third party.</p><p>Sixteen people – all of whom had heard voices for years, despite being on medication – participated in this pilot study. A man who had heard the devil incessantly for 16 years was instructed by Leff to tell his demon avatar he didn’t deserve to be persecuted and he should go back to hell and torment those who did. An older man, who had been woken every morning at 5am for more than three years by the voice of a woman conducting noisy business meetings in his head, was encouraged by Leff to tell her it was unprofessional to allow him to overhear her discussions. To Leff’s surprise, both of these men stopped hearing their voices entirely after only three sessions. While most patients did not experience such a dramatic change, the results were still impressive: for 13 of the 16 participants, voices remained, but they were less frequent and intrusive, and suicidal feelings were significantly reduced.</p><p>The therapy had made a significant difference to a sample group composed of people for whom all other forms of treatment had failed. But other clinicians were wary of taking the results of the pilot seriously, believing they might be a consequence of Leff’s skill as a therapist, rather than the therapy itself. “He did have a magic touch,” Tom Craig, professor of psychiatry at King’s College London (KCL), told me. But Craig was sufficiently impressed by the results to lead a randomised controlled trial on 150 patients, along with Philippa Garety, professor of clinical psychology. Leff trained Craig and the clinical psychologist Tom Ward to deliver the therapy in his place, giving them audio recordings of his sessions and a checklist of how he thought things ought to be done, which Craig and Ward turned into a manual.</p><p>“Within the first couple of cases, we thought: this is extraordinary – something’s really happening here that we’ve never seen before,” Craig said. One participant, Chris, had been persecuted for years by the voices of high court judges who denounced him for intrusive sexual thoughts. Through the therapy, Chris came to accept his sexual urges as normal, and his high court judge avatar ultimately told him he had no case to answer. Free from persecution, Chris was able to go on dates for the first time in years.</p><p>Avatar therapy was <a href="https://www.thelancet.com/journals/lanpsy/article/PIIS2215-0366(17)30427-3/fulltext" data-link-name="in body link">found to be quicker,</a> cheaper and more effective after 12 weeks than any other non-pharmacological intervention currently available for people with psychosis. It worked, even without Leff, on a larger scale, and it worked faster than the control therapy delivered by highly trained clinicians.</p><p>As for the concern that engaging with auditory hallucinations exacerbates psychosis, Al Powers, associate professor of psychiatry at Yale University, told me it was not backed by empirical data. “Despite popular wisdom about not wanting to collude with the voices, the evidence that’s emerging seems to indicate that engagement-based approaches are most effective in terms of increasing control over voices, and also achieving some degree of mastery over them.”</p><p>Despite its early success in trials, Alderson-Day warns against viewing avatar therapy as a cure-all for psychosis. “The idea of a single therapeutic option for all kinds of voices is very unlikely,” he said. “Some people’s auditory experiences aren’t even voice-like, so there won’t be content to work with,” he told me. But if avatar therapy could be quicker and more cost-effective than existing treatments, he said, it was worth pursuing.</p><p>The research team’s next step was to demonstrate that avatar therapy could work when delivered by a broad range of therapists in different locations. A new trial, <a href="https://www.avatartherapytrial.com/" data-link-name="in body link">Avatar 2</a>, began in 2021, and involved 19 trained therapists in four different sites across the UK. There were 345 individuals enrolled in it – including Joe.</p><hr><p><span>J</span>oe was nervous about designing his avatar. No one had ever asked him to describe what his voices looked or sounded like before. He had spent so much energy telling himself they couldn’t be real and now he had to manifest them in the real world. There were other challenges: like most people with psychosis, Joe heard several voices, and he experienced them more as a felt presence, rather than a single entity with a definite physical appearance and a familiar face.</p><p>Tom Ward, who was assigned to be Joe’s therapist, told me the average number of voices heard by people with psychosis is four. “We are looking for the dominant voice that’s causing the most distress.” Joe chose the voice who told him there was no point in living because he was already dead.</p><p>He and Ward began creating the avatar’s face. There was a blizzard of choices in drop-down menus on Ward’s laptop screen: <em>is it a human or non-human entity</em>? If it’s human, what is its <em>gender, age, height (tall, medium, short), ethnicity (European, </em><em>east Asian, </em><em>south Asian, African)</em>? If it’s non-human, <em>does it take the form of a devil, angel, alien, vampire, robot, witch, goblin, elf, beast</em>? Once a basic form is chosen, there are sliders to change the physiognomy: making the nose broader, thinner, shorter or longer; adjusting the eyes, brow and chin; modifying the hairstyle.</p><p>Joe found it hard to describe what the voice looked like: it was often hooded, masked, out of focus, only partially visible. It was demonic, but it didn’t look like a devil. Together, they created the head of a bald man with olive skin, like Joe’s. He chose between five versions of voices, and used sliders to change the pitch, tilt and roughness. The final voice was deeper than any human’s. That’s what made it demonic, for Joe.</p><figure id="1607a6ea-93ed-414d-b6d7-0520c2c5746b" data-spacefinder-role="immersive" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 740px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="AI Avatars Long Read | Illustration 02 | DIGITAL" src="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" width="465" height="279" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span> Illustration: Nick Kempton</figcaption></figure><p>It wasn’t exactly right, but once Joe was alone with the screen there was something about the avatar that resonated. Ward reminded Joe he was there to support him. Before they went into their separate rooms, they had practised what the avatar was going to say, and how Joe might respond to it. Still, he felt terrified.</p><p>“You’re already dead,” the avatar told him, in a voice that was almost monotone. “You’ve been in hell all this time and this is your existence from now on.”</p><p>“If this is death, it’s exactly the same as what my idea of life was,” Joe replied, a little meekly. He was surprised by how realistic the experience was, how true to life this felt.</p><p>“You’re lying to yourself,” the voice retorted.</p><p>In his own, encouraging voice, Ward reassured Joe, reminding him to hold eye contact, to communicate in strong messages that he was in charge.</p><p>“You’re harder to get hold of today,” the avatar said towards the end of the first session. “You can’t keep it up.”</p><p>“I can keep this up for ever, and I will,” Joe replied. “It’s my life. I have the autonomy here. I’m in control.”</p><p>Joe had 12 weekly sessions. The darkest exchange came in the fourth.</p><p>“You should end it,” the avatar said, casually. “What have you done that’s of any use to anyone?”</p><p>Joe couldn’t answer this.</p><p>In his own voice, Ward interjected to remind Joe about his relationships, his family, the life he had been able to make for himself. “What the avatar is saying is actually not true,” Ward said. “Can you come back with positives?”</p><p>Ward switched back to voicing the avatar. “You agree with me deep down,” it sneered. “You haven’t done anything of use.”</p><p>“No,” Joe said, firmly. “I have a lot of good friendships. I think on balance I have had a good life. It’s been positive. I’ve got more to do.”</p><p>“You’re handling yourself better than I thought,” the avatar replied. “I’d thought you’d be falling apart by now.”</p><hr><p><span>A</span>ll therapy sessions are recorded, and the audio given to the trial participants so they can listen back in their own time and be reminded of how they managed to gain mastery over their voices. With Joe’s agreement, Ward shared the recordings of his sessions with me.</p><p>Ward had delivered avatar therapy to about 80 people before he met Joe. He told me that people with psychosis often feel disempowered and marginalised; they feel as if they don’t have the right to talk. Avatar therapy is about equipping them with the tools to answer back.</p><p>I met Ward in his office at KCL’s Institute of Psychiatry in Denmark Hill, south London. He gave me a demonstration of the avatar design process, so that when we sat down to talk, a disembodied male head was blinking from his laptop in front of us, looking shiftily from side to side throughout our conversation. It still looked like an animated police photofit to me. Perhaps, with a voice to go with it, it would be easier to suspend disbelief.</p><p>Ward told me it can be helpful for many patients to understand their voices as a coping strategy arising from a previous trauma. (While there is no consensus among clinicians about the precise relationship between trauma and hearing voices, there is widespread acceptance that there is often a <a href="https://academic.oup.com/schizophreniabulletin/article/38/4/661/1870563?login=false" data-link-name="in body link">link between the two</a>.) But discovering whether or not a patient’s voices have arisen as a response to trauma isn’t important, Ward told me; the point of the therapy is to find any explanation that gives them a sense of mastery over their voices. This is the principle followed in any psychological intervention, he said.</p><p>Using the manual created from Leff’s instructions as a guide, the therapist plots out how the voice will change as the person is supported to stand up to it. When the voice is a bully, the avatar will begin to recognise the impact of their behaviour, perhaps revealing that they too have once been a victim of bullying. When the voice is a devil, a djinn or some other malevolent spirit, the avatar will reveal that they are not actually very powerful (“‘I’m not a high-ranking demon, I’m a trickster’ – that sort of thing. Things are quite interesting when you voice demons,” Ward said). When the voice resembles someone who abused the patient when the patient was a child, the avatar gradually acknowledges that they are no longer talking to a defenceless boy or girl but instead to an adult with agency.</p><p>Psychiatry professor Al Powers told me he saw potential problems in cases where the voice represented by the avatar belonged to a person who existed in the real world. “That can negatively impact one’s conceptualisation of your relationships with the world, and your family, and other people who are important to you, and that can contain some risks,” he said.</p><p>Before anyone can gain power over their voices, they have to tell their therapist what the voices say to them. It’s often the most degrading content imaginable; racist, sexist, sexually shaming and taboo. In his clinical experience, “You’re a paedophile” is one of the most common phrases repeatedly heard, Ward said. The avatar therapist has to reassure their patient that these phrases are nothing to be ashamed of, but also has to be prepared to deploy them when they are playing the role of avatar.</p><p>For the therapy to work, the therapist has to commit to playing the role of their patient’s tormentor. “You never break the fourth wall,” Ward said. The avatar can be direct – can go for the jugular – <em>because</em> it is not the therapist, and it can lie, or say things that are wrong. Hearing the avatar say these things can give the patient enough distance for them to reflect on and respond to what they usually only hear inside their own head.</p><p>In the Avatar 2 trial, for the first time, therapists went as far as allowing avatars to say things like, “You should end it.” When I brought this up with Ward, he stiffened. This kind of content is only used in specific circumstances, he said, when the patient’s risk of suicide has been assessed as minimal. “You don’t start the first dialogue with that. It comes at a point where you know how the person engages in the dialogue; you know that there is a clinical benefit to [them] voicing a commitment to life, and you know that they will be able to do it.” (I asked three specialists who work on the treatment of psychosis, but were not involved in the trial, about the dangers of the avatar therapist voicing commands to self-harm, and they all told me that, while unconventional, in these circumstances, it would not harm the patient.)</p><p>None of the avatar trials have shown that the therapy could exacerbate psychosis, even if people drop out before they have completed the run of sessions. “People do drop out,” Ward acknowledged. “Sometimes people will say, ‘It was just a bit too much for me.’” They have monitored all the people who had the therapy, tracking any mental health deterioration or hospital admission during and after treatment, and there has been no documented evidence of any crises directly related to avatar therapy during the Avatar 2 trials.</p><p>We are used to imagining those who hear voices as fragile, but Ward sees them as extraordinarily resilient: they can survive both years of the worst kind of internal persecution from their voices, and also the stigma and discrimination their condition is met with by the general public. Nothing simulated on a computer screen could be any more traumatic, he says, than what the people he works with endure in daily life.</p><hr><p><span>B</span>efore and after Joe’s dialogues with the avatar, he and Ward discussed how Joe’s voices might have developed in response to the extreme, heightened terror he had felt during his bad trip. Joe began to think of his voices as an overactive defence mechanism, a maladaptation of his brain as it tried to keep him safe and alert in a world he’d experienced as full of danger.</p><p>“The voices are just your paranoia, your anxiety, your fight-or-flight response gone mad. Give them space, and then you can have a conversation with them,” Joe told me. “I like to think that’s the reason why they started initially, but even if it isn’t, it doesn’t really matter, because it meant I was able to talk to them.”</p><p>By Joe’s seventh session, he was having insightful, poignant conversations with the avatar.</p><p>“Things are going to shit,” it grumbled.</p><p>“It’s not a bad assessment. They aren’t going fantastically,” Joe conceded. “You and I want the same thing – things not to be shit. That’s the goal. Rest assured, we’ll get there. It might take a while.”</p><p>“It’s why you need me.”</p><p>“In a way yeah, I guess. I think we’re working towards the same goal of just being the best version of myself I can be.”</p><p>“That’s what I need from you – to be the best,” the avatar said. “It’s what I’ve always needed.”</p><p>“Yours is not always the most helpful way to go about it, is it?” Joe said. “But I appreciate the sentiment.”</p><p>The dialogue had become a strange kind of couples therapy, in which Ward was playing the avatar and the therapist.</p><p>After four years of arguing with his voice, Joe began to feel compassion – even pity – for his tormentor. In the 10th session, Joe and the avatar discussed what happened in California. Joe described what he went through that night: not only the horror of it (“It was fucking scary, wasn’t it? It felt like a Hitchcock score sounds”) but also the alienation (“I was surrounded by people who found it funny”).</p><p>“You tried to tell yourself it didn’t matter, I wasn’t real,” the avatar said. And then, with resignation, “I’m fading from your life.”</p><p>“You’ll always be there in some form,” Joe reassured it. “But yeah.”</p><p>“Is that OK with you?” it asked. Joe’s tormenting voice had become his anxious companion.</p><p>“Yeah. I can live with that. So long as we’re able to coexist,” he replied.</p><p>“Thank you for listening,” were the avatar’s final words. “Thank you for making room for me.”</p><hr><p><span>A</span>vatar 2 set out to investigate how effective the therapy could be when delivered by therapists with far less experience than Ward and Craig. Some of the participants had been living with voices for decades. Claire was in her early 50s when she enrolled in Avatar 2, at the Manchester research site. She had heard the first voice when she was 10: an adult male, casually telling her to jump out of her bedroom window. It was entirely real to her, external and authoritative, “like an adult telling me what to do”. Claire had been abused from the age of seven. She grew up in a state of constant hypervigilance.</p><p>The nasty voice, the one that told her she was a stupid bitch, arrived when she was 13. “I remember saying, ‘Oh, shut up,’ out loud, and the other girls laughed and said, ‘There’s no one there!’ And then I realised I had to be quiet about them.” The voices became one among many secrets Claire kept, alongside the abuse and her self-harm.</p><p>She spent much of her adult life in psychiatric hospitals. By the time her mental health team’s care coordinator told her about the Avatar 2 trial in 2021, Claire had tried to end her life many times. She had been diagnosed with bipolar disorder, psychotic depression and, at one point, schizoaffective disorder. She was taking antidepressants, mood stabilisers and tranquillisers, as well as antipsychotics; she had tried CBT, cognitive analytic therapy, compassion-focused therapy and group survivor therapy. Still the voices persisted.</p><p>“The state I was in at the time, I thought, they’re not going to accept me on the trial – I’m too unstable,” Claire told me. But she was given a place on the trial, coordinated by Hannah Ball. Ball had only qualified as a psychologist a year before she was trained to deliver avatar therapy. She was assigned to be Claire’s therapist. “Hannah reassured me that nobody had ever had a crisis because of avatar therapy, and I thought, <em>that will be me. I’ll be the first one</em>,” Claire said.</p><p>Claire chose to make an avatar out of the first voice, which she felt shaped all the others. While she and Ball were putting together its angular male face, with its dark eyes and spiky hair that made Claire laugh because it wasn’t quite right, the voices over her right shoulder were enraged: “Don’t do this, you stupid fucking bitch.” The avatar’s northern accent was also not quite right, but there was something about its menacing tone that jolted Claire. As soon as she heard it, it was real to her.</p><p>She felt dizzy and sick in her first session, and Ball had to constantly check in to provide reassurance in her own voice. The dialogue lasted barely 10 minutes and left Claire exhausted, but as she walked home, she was smiling: she had been able to stand up to her voices for the first time in her life. Between sessions, she listened to the audio recordings that Ball had given her to take home, so she could remember what she had achieved and steel herself for her next encounter. (Claire agreed to share these recordings with me.)</p><p>By the third week, she was answering back to the avatar, asserting herself without any prompting from her therapist.</p><p>“Stop saying such nasty things to me. I’m not going to listen to you any more while you say such nasty things,” she told the avatar.</p><p>“I’m not sure what’s got into you,” it replied.</p><p>“I’m going to lay down some rules,” Claire said. “We can still talk, but on my terms, not yours.”</p><p>By the fourth week, Claire’s voices had gone entirely. For the first time in 40 years, she was alone with her own thoughts. Quiet.</p><p>She hadn’t expected them to go. “My aim wasn’t to get rid of them – just to get along with them,” she told me. “I wasn’t quite sure I wanted to let go. I’d never really been on my own. As abusive as it was, it’s still a relationship.”</p><p>Like Joe, she had been encouraged to understand her voices as a faulty self-defence mechanism. They had been trying to look after her: when they told her to end her life, they were trying to find a way to stop her suffering. Their departure was a kind of bereavement.</p><figure id="c77b1fdc-b178-46b7-9399-9bb77acb1aee" data-spacefinder-role="immersive" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 740px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="AI Avatars Long Read | Illustration 03 | DIGITAL" src="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" width="465" height="279" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span> Illustration: Nick Kempton</figcaption></figure><p>In the remaining sessions, Ball helped Claire accept the loss of the voices, and she had an opportunity to say a definitive goodbye. The avatar promised to stay alongside her at a distance, there if needed, but no longer interfering in her life. “I wish you all the best,” it said at the end of the final session.</p><p>“Thank you. I wish you all the best, too,” Claire replied. “I know you had good intentions at heart.”</p><p>Nearly two years on, Claire’s voices have not returned. She’s coming off all her medications. She can go out in public, eat in a noisy restaurant, do voluntary work, give interviews to a journalist – all things that once seemed impossible. “I’m stronger. I’ve gained so much. I now feel I have a life worth living.”</p><p>Ball didn’t have the same level of experience as Leff, Craig or Ward, but she was able to achieve the same outcomes using the manual they developed as her guide. I asked to see the manual, but Ward told me he couldn’t share it with me, because it was “core IP”. The Wellcome Trust, which funds the trial, has been protective of its intellectual property in the past: research teams in Denmark, Australia and Canada that have been experimenting with avatars have been told there are restrictions around calling the work “avatar therapy”.</p><p>Ball told me the manual is not a script, more a set of objectives to aim for in each session: a general structure of how the avatar should change to empower the patient. She listened to recordings of one of Ward’s cases from the first trial, did two closely supervised pilot cases and was then delivering the therapy herself, alone.</p><p>I wondered how comfortable she felt, taking on the role of a malevolent entity that has enormous power over her patient. “It requires a lot of active formulation and reformulation on the spot, and listening out for things that might change how you were initially going to approach a dialogue,” she said.</p><p>I had imagined that only skilled clinicians could be avatar therapists, but Ball was convinced that, if they were willing to take on the challenge, a very wide range of mental health practitioners could do it. “I think you need people who understand relationships and dynamics,” she said. “If you’ve got a sense of who you are as the avatar and the relationship [to the patient], you know how to respond.”</p><hr><p><span>T</span>he results of the Avatar 2 trial, published on Monday, were dramatic. Avatar therapy has been shown to deliver rapid and significant reduction in distress caused by voices. No other psychological intervention has been shown to cause such a significant reduction in the frequency of intrusive voices.</p><p>Earlier this year, the National Institute for Health and Care Excellence announced that it has found avatar therapy to be safe and effective and recommended that it be offered for testing in clinical NHS settings over the next three years. Thirty-eight people have so far been trained to deliver it in the UK, from experienced clinicians to newly qualified psychologists and nurses. The most effective psychological therapy currently offered on the NHS, CBTp, is typically delivered by qualified clinical psychologists in 16 sessions over 12 months. In comparison, avatar therapy could work out as “half the length of time, with less skilled people, so a bit cheaper, and a bit more available”, Tom Craig told me. He hopes it will be part of NHS treatment within five years.</p><p>A small number of practitioners remain hesitant about avatar therapy being delivered by support workers and less experienced psychologists. Prof Neil Thomas, director of the Voices clinic in Melbourne, and lead investigator on the Australian Amethyst avatar therapy trial, said: “Working with people who hear voices is <em>already</em> an area of specialist practice. Using technology as well makes it even more specialist. The process is actually not particularly intuitive for people that have trained in therapy – which involves being supportive to people – to have to role play a nasty voice.”</p><p>But the British team are taking things even further. A newly announced Avatar 3 trial will investigate whether the avatar could be entirely digital and voiced by an artificial intelligence, which would remove the requirement for real-time human voicing of the avatar, and mean it could be widely disseminated. Humans would always be necessary to support the person in their interaction with the avatar and help make meaning of the voices, Craig said, but that would not need to be a trained therapist. It could be “a community nurse, or a nursing assistant”.</p><p>Louise Birkedal Glenthøj, associate professor of psychology at University of Copenhagen and the trial coordinator for Challenge, the Danish trial using avatars in the treatment of psychosis, told me she feared a fully digital avatar powered by AI might have the potential to exacerbate psychosis. “As people with psychosis struggle with grasping reality,” she said, “being in a dialogue with a machine that is not controlled by a therapist might generate psychotic experiences.”</p><p>The Danish team enrolled 270 participants in a trial that investigated how people who hear voices respond to having dialogues with an avatar using virtual reality. “We thought if [we could] integrate this in fully immersive VR, then we would perhaps get some additional benefit in terms of this potentially having a greater treatment effect,” Glenthøj told me. <em>“</em>Having the therapist close by would intuitively be more secure for the patient. We capitalise on this notion of ‘it’s real but it’s not real’. It’s so real that they feel they are in this dialogue with their voice, but it’s not real, and if they take off the headset, then it’s gone.”</p><p>The VR allows the user to situate the avatar in daily life settings, such as on the bus, or in the participant’s home. They also added emotions to the face, so the avatar could smile more and look more friendly as the dialogues progress.</p><p>Glenthøj conceded that VR avatar therapy can be overwhelming for some. “We <em>do </em>see people reacting. They destabilise. They get <em>more</em> psychotic.” As a result, the Danish team progressed more slowly than clinicians on the Avatar 2 trial, and have added safety features, such as a virtual panic button, and regular contact with the participants’ primary care providers throughout treatment. They also gave participants booster sessions at three and six months after treatment, in the hope of making any positive effects more durable. The <a href="https://www.researchsquare.com/article/rs-5180922/v1" data-link-name="in body link">trial ultimately found</a> that VR avatar therapy was significantly more effective at reducing voices compared with supportive counselling.</p><p>Avatar therapy may help in treating mental health conditions beyond psychosis. <a href="https://link.springer.com/article/10.1186/s40337-023-00900-1" data-link-name="in body link">Preliminary research</a> from Ward’s team with an avatar embodying the “anorexic voice” has shown it to be a promising intervention for eating disorders. Glenthøj is researching VR-based avatar therapy for obsessive compulsive disorder. Ward also wants to investigate whether dialogues with avatars could help people who struggle with anxiety or depression. “The technology is about creating this external representation of the dark side of yourself,” Craig said. “At some level, this is about thoughts, isn’t it?”</p><p>In Australia, avatar therapy can take place via telehealth, with therapist and participant often in different parts of the country. “We’ve got a lot of people living in regional areas who have limited access to mental healthcare – let alone to specialist therapies,” Thomas told me. They have drawn on how the British team worked during lockdown to see how it can be delivered remotely.</p><p>Some therapists have tried, in the past, to guide their patients through dialogue with voices via role play, or “chair work” – where the voices are represented by an empty chair with content spoken by the patient – but both these techniques require a leap of faith. With an avatar, it’s the recreation of the voice, not the face, that makes this radical, Thomas said. “It’s called avatar therapy, and that sounds like it’s primarily about the visual representation, but not everyone has an existing image that goes with their voice. I think the auditory transformation is particularly powerful.”</p><p>“The suspension of disbelief is remarkable,” Craig told me. Even though trial participants have signed consent forms and know it is the therapist voicing the avatar, they still relate to it as if it were the voice in their head. “They are put in front of this not very wonderful computer animation, and they’re <em>right in there</em>, talking to their voice.”</p><hr><p><span>‘I</span>t was liberating just to talk to Tom [Ward] about it, because I didn’t speak to anyone else,” Joe told me over coffee in south London. He still had the imposing presence of a rugby player, but he was so softly spoken that I had to strain to hear him talk over the hubbub of the cafe.</p><figure id="a0a9aad5-ad1d-46dc-bd41-dd6cc1c71ae2" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:108,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Therapy wars: the revenge of Freud | Oliver Burkeman&quot;,&quot;elementId&quot;:&quot;a0a9aad5-ad1d-46dc-bd41-dd6cc1c71ae2&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2016/jan/07/therapy-wars-revenge-of-freud-cognitive-behavioural-therapy&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:1,&quot;theme&quot;:0}}"></gu-island></figure><p>A year on from avatar therapy, Joe’s voice was still there, a presence just out of eyeshot, still a distinct external entity and not just an inner monologue. But it was quieter, easier to manage and allowed him to get on with daily life. When it spoke, it was to have the same kind of conversations they’d had in his final sessions with the avatar. “I get it – you’re very on edge,” Joe would tell his voice. “I don’t feel great either. But we are just walking to work at the moment. I promise, we’re good.”</p><p>“It worked because I understood the voices more, I think,” he told me. “My general levels of anxiety stayed pretty high, but I’ve started interpreting the hallucinations as a part of the anxiety.” He still has panic attacks. The anxiety and self-doubt that existed before his bad trip are still there. “You do have to address everything that’s going on to address the voices themselves. They feed on everything else.”</p><p>Joe recently went back to his GP in search of help with his anxiety, but there was no cutting-edge experimental solution delivered by renowned psychologists for him this time. The GP put him on a waiting list for NHS talking therapy, and warned that he could be in for a very long wait.</p><p><em>Names of patients have been changed. </em></p><p><em><span data-dcr-style="bullet"></span> </em>In the UK and Ireland, <a href="https://www.samaritans.org/" data-link-name="in body link">Samaritans</a> can be contacted on freephone 116 123, or email <a href="mailto:jo@samaritans.org" data-link-name="in body link | mailto:jo@samaritans.org">jo@samaritans.org</a> or <a href="mailto:jo@samaritans.ie" data-link-name="in body link | mailto:jo@samaritans.ie">jo@samaritans.ie</a>. In the US, you can call or text the <a href="https://988lifeline.org/" data-link-name="in body link">National Suicide Prevention Lifeline</a> on 988, chat on <a href="https://988lifeline.org/chat/" data-link-name="in body link">988lifeline.org</a>, or <a href="https://www.crisistextline.org/" data-link-name="in body link">text HOME</a> to 741741 to connect with a crisis counsellor. In Australia, the crisis support service <a href="https://www.lifeline.org.au/" data-link-name="in body link">Lifeline</a> is 13 11 14. Other international helplines can be found at <a href="http://www.befrienders.org/" data-link-name="in body link">befrienders.org</a></p><p><span data-dcr-style="bullet"></span> In the UK, the charity <a href="https://www.mind.org.uk/" data-link-name="in body link">Mind</a> is available on 0300 123 3393 and <a href="https://www.childline.org.uk/" data-link-name="in body link">Childline</a> on 0800 1111. In the US, call or text <a href="https://www.mhanational.org/" data-link-name="in body link">Mental Health America</a> at 988 or chat 988lifeline.org. In Australia, support is available at <a href="https://www.beyondblue.org.au/" data-link-name="in body link">Beyond Blue</a> on 1300 22 4636, <a href="https://www.lifeline.org.au/" data-link-name="in body link">Lifeline</a> on 13 11 14, and at <a href="https://mensline.org.au/" data-link-name="in body link">MensLine</a> on 1300 789 978</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I write code using Cursor (301 pts)]]></title>
            <link>https://www.arguingwithalgorithms.com/posts/cursor-review.html</link>
            <guid>41979203</guid>
            <pubDate>Tue, 29 Oct 2024 03:50:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.arguingwithalgorithms.com/posts/cursor-review.html">https://www.arguingwithalgorithms.com/posts/cursor-review.html</a>, See on <a href="https://news.ycombinator.com/item?id=41979203">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>In forums relating to AI and AI coding in particular, I see a common inquiry
from experienced software developers: <em>Is anyone getting value out of tools like
Cursor, and is it worth the subscription price?</em></p>
<p>A few months into using Cursor as my daily driver for both personal and work
projects, I have some observations to share about whether this is a
"need-to-have" tool or just a passing fad, as well as strategies to get the most
benefit quickly which may help you if you'd like to trial it. Some of you may
have tried Cursor and found it underwhelming, and maybe some of these
suggestions might inspire you to give it another try.</p>
<p>I am not sponsored by Cursor, and I am not a product reviewer. I am neither
championing nor dunking on this as a product, but rather sharing my own
experience with it.</p>
<p><strong>Who am I, and who is the audience for this article?</strong></p>
<p>I have been writing code for 36 years in a number of languages, but
professionally focused on C-heavy computer game engines and Go/Python/JS web
development. I am expecting readers to be similarly reasonably comfortable and
productive working in large codebases, writing and debugging code in their
chosen language, etc. I would give very different advice to novices who might
want an AI to teach them programming concepts or write code for them that is way
beyond their level!</p>
<p>For me, the appeal of an AI copilot is in taking care of boilerplate and
repetitive tasks for me so I can focus on the interesting logic for any given
problem. I am also not especially interested in cranking out large quantities of
code automatically; I am highly skeptical of "lines of code written" as an
efficiency metric. I would prefer to spend less time writing the same amount of
code and more time thinking through edge cases, maintainability, etc.</p>
<p>So, without further ado:</p>
<h2>What is Cursor?</h2>
<p>Cursor<sup id="fnref:1"><a href="#fn:1">1</a></sup> is a fork of Visual Studio Code (VS Code) which has Large Language Model (LLM)
powered features integrated into the core UI. It is a proprietary product with a
free tier and a subscription option; however, the pricing sheet doesn't cover
what the actual subscriber benefits are and how they compare to competing
products. I'll try to clarify that when discussing the features below based on
my own understanding, but a quick summary:</p>
<ul>
<li><strong>Tab completion</strong>: This is a set of proprietary fine-tuned models that both
  provide code completion in the editor, as well as navigate to the next
  recommended action, all triggered by the Tab key. Only available to subscribers.</li>
<li><strong>Inline editing</strong>: This is a chat-based interface for making edits to
  selected code with a simple diff view using a foundation model such as GPT or
  Claude. Available to free and paid users.</li>
<li><strong>Chat sidebar</strong>: This is also a chat-based interface for making larger edits
  in a sidebar view, allowing more room for longer discussion, code sample
  suggestions across multiple files, etc. using a foundation model such as GPT
  or Claude. Available to free and paid users.</li>
<li><strong>Composer</strong>: This is yet another chat-based interface specifically meant for
  larger cross-codebase refactors, generating diffs for multiple files that you
  can page through and approve, also using a foundation model such as GPT or Claude.
  Available to free and paid users.</li>
</ul>
<h2>Tab completion</h2>
<p>While other LLM-powered coding tools focus on a chat experience, so far in my
usage of Cursor it's the tab completion that fits most naturally into my
day-to-day practice of coding and saves the most time. A lot of thought and
technical research has apparently gone into this feature, so that it can not
only suggest completions for a line, several lines, or a whole function, but it
can also suggest the next line to go to for the next edit. What this amounts to
is being able to make part of a change, and then auto-complete related changes
throughout the entire file just by repeatedly pressing Tab.</p>
<p>One way to use this is as a code refactoring tool on steroids. For example,
suppose I have a block of code with variable names in <code>under_score</code> notation
that I want to convert to <code>camelCase</code>. It is sufficient to rename one instance
of one variable, and then tab through all the lines that should be updated,
including the other related variables. Many tedious, error-prone tasks can be
automated in this way without having to write a script to do so:</p>
<video controls="">
  <source src="https://www.arguingwithalgorithms.com/videos/cursor-review/example1.webm" type="video/webm">
  <p>
    Your browser doesn't support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example1.webm" download="example1.webm">link to the video</a> instead.
  </p>
</video>

<p>Sometimes tab completion will indepedently find a bug and propose a fix. Many
times it will suggest imports when I add a dependency in Python or Go. If I wrap
a string in quotes, it will escape the contents appropriately. And, as with
other tools, it can write whole functions based on just the function signature
and optional docstring:</p>
<video controls="">
  <source src="https://www.arguingwithalgorithms.com/videos/cursor-review/example2.webm" type="video/webm">
  <p>
    Your browser doesn't support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example2.webm" download="example2.webm">link to the video</a> instead.
  </p>
</video>

<p>All in all, this tool feels like it is reading my mind, guessing at my next
action, and allowing me to think less about the code and more about the
architecture of I am building.</p>
<p>Also worth noting: The completions are <em>incredibly fast</em>, and I never felt a delay
waiting for a suggestion. They appear basically as soon as I stop typing. Having
too long a wait would surely be a deal-breaker for me.</p>
<p>So, what are my complaints with Tab completion? One is a minor annoyance:
Sometimes I don't see the suggestion in time and continue typing, and the
completion disappears. Once it is gone, there doesn't appear to be any way to
get it to come back, so I have to type something else and hope.</p>
<p>My other complaint is the exact opposite situation: Sometimes a completion is
dead wrong, and I intentionally dismiss it. Subsequently, but very infrequently,
I will accept a totally different completion and the previously-declined
suggestion will quietly be applied as well. This has already caused some
hard-to-track-down bugs because I wasn't aware the wrong logic had been
accepted. I haven't found these cases to be frequent enough to cancel out the
productivity boost of tab completion, but they do detract from it.</p>
<h2>Inline editing, chat sidebar, and composer</h2>
<p>As far as I can tell, these features are all very similar in their interaction
with a foundational model - I use Claude 3.5 Sonnet almost exclusively - and the
variance is in the user interface.</p>
<p>Inline editing can be invoked by selecting some code and pressing Ctrl-K/Cmd-K.
I type in the desired changes, and get a nice diff in the file that I can accept
or reject. I use this mostly to implement bits of code inside a function or make
minor refactors.</p>
<p>A good example of where this works great is if I have a loop over some tasks and
I want to parallelize them:</p>
<video controls="">
  <source src="https://www.arguingwithalgorithms.com/videos/cursor-review/example3.webm" type="video/webm">
  <p>
    Your browser doesn't support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example3.webm" download="example3.webm">link to the video</a> instead.
  </p>
</video>

<p>The chat sidebar is opened with Ctrl+L/Cmd+L, and gives more real estate for a
multi-turn conversation, though one pet peeve I have with the LLM models I've
tested so far is they will <em>always</em> return code first, rather than ask for
clarification if there is any ambiguity. The suggested code has an Apply button
that will create a diff in the currently selected file. This is useful for
larger refactors within a single file, or creating a brand new file based on the
file I have open. If additional files are relevant they can be added manually to
the context, but Cursor will try to guess which files are relevant based on the
query and an index it generates in the background.</p>
<p>Here is an example which takes an application's database API and creates a REST
API to access it, with parameter validation and correct HTTP status codes,
<em>then</em> writes a client library to access that REST API:</p>
<video controls="">
  <source src="https://www.arguingwithalgorithms.com/videos/cursor-review/example4.webm" type="video/webm">
  <p>
    Your browser doesn't support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example4.webm" download="example4.webm">link to the video</a> instead.
  </p>
</video>

<p>As another example, here I am using the chat sidebar to convert the client
library from Python to Go. Note how the loosely-typed Python is converted to
well-defined struct types and idiomatic Go including error handling! This is not
a 1:1 rewrite at all:</p>
<video controls="">
  <source src="https://www.arguingwithalgorithms.com/videos/cursor-review/example5.webm" type="video/webm">
  <p>
    Your browser doesn't support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example5.webm" download="example5.webm">link to the video</a> instead.
  </p>
</video>

<p>Finally, Composer is specifically meant for cross-file refactors. This is also
the feature I use least, but provides a better user experience for reviewing
multiple file diffs one at a time.</p>
<h2>.cursorrules file</h2>
<p>I did not realize this feature existed until I came across it in the (in my
opinion too minimal) documentation, but the various chat modalities always
include the contents of a <code>.cursorrules</code> file located at the root of the
workspace to provide additional context. I've been experimenting with using this
to inform the LLM of the repository's coding standards, common packages, and
other documentation.</p>
<p>This feature might help to solve one of the big roadblocks I have observed with
Cursor: It does not follow coding styles and patterns unless they already exist
in the same file you are editing. For example, at Khan Academy we use a
proprietary library <sup id="fnref:2"><a href="#fn:2">2</a></sup> for passing context between functions in Go. This is
used for logging, HTTP requests, etc. so the LLM needs to be able to use it.
This has been difficult in the past, but perhaps a well-written <code>.cursorrules</code>
is a good first step.</p>
<p>One current limitation is that there is only one of these files per workspace,
so a monorepo like ours containing code in multiple languages is going to be
more difficult to set up than a small repository with a small set of very
consistently styled code.</p>
<p>Also the documentation suggests that the <code>.cursorrules</code> file is only used for
the chat modalities, not the tab completion. However I've experimented with
having that file open in a pinned tab in the workspace and confirmed that it is
possible to include it in the tab completion context that way at least.</p>
<h2>Changes to my workflow</h2>
<p>The most exciting thing about a tool like Cursor is not that I can write code
faster, because honestly the actual writing of code is not the bottleneck; in
fact, I often have to slow myself down to avoid focusing too much on the code
and not enough on the high-level problem being solved. The real value is in
changing <em>how</em> I code.</p>
<p>It's still early days with this technology, but this is what I've found has
changed about how I work and what I expect to see changing in the near future:</p>
<ol>
<li>
<p>I am <em>much</em> less likely to reach for a new library or a framework. No, I'm
not going to start writing my own crypto libraries, but for small utilities it's
easy enough to let the LLM write them to my bespoke needs than to pull in a
general-purpose library. These libraries tend to start small and lightweight and
then, because they are open and used by many people, accumulate functionality
and cruft that I don't need.</p>
<p>Many of these libraries only exist to reduce boilerplate, which felt like a
necessary tradeoff when balanced against my time writing and maintaining that
boilerplate but now that I can have the LLM do it for me it feels less worth the
cost. And the cost can be substantial: Have you tried getting a Node.js project
running a year or more after it was written? You may as well start from scratch.</p>
</li>
<li>
<p>I also worry less about adhering to DRY (Don't Repeat Yourself) in my own code.
Prematurely defining abstractions can create a lot of technical debt later on,
so being able to create a lot of code with reference to other code without
trying to pull it into a function or class allows me more flexibility, and I
know that if I have to refactor shared logic out later, the LLM can help with
that too.</p>
</li>
<li>
<p>My willingness to use a language or framework I am less familiar with is much
higher. For example, I've dabbled in R for years, especially for visualizing
data. However, to be frank, I suck at it. I don't have a deep understanding of
<code>dplyr</code> and it seems like there are always a dozen different ways to accomplish
the same task. Now I describe the visualization I want, and I get correct data
manipulation and <code>ggplot</code> visualization for it. Tasks that took an hour or more
now take five minutes, so I am much less likely to give up and do it in Python
instead.</p>
<p>Maybe one of these days I'll even write something in Rust. Maybe.</p>
</li>
<li>
<p>I find myself iterating quickly on small components before integrating them
into the larger codebase. This is partly to work around the limitations of LLMs
when working with larger codebases, but it also opens up interesting ways of
working I hadn't considered before. As per the example above, I can prototype
some logic in a dynamically typed language like Python, work out the technical
details and then convert it to well-typed Go instantly to integrate into a web
application. I can have the LLM generate test data automatically, or mock up a
backend for me to write a frontend against. Why pay the tax of working in a
mature codebase while I'm still proving out an idea?</p>
</li>
</ol>
<h2>Summary</h2>
<p>Whether I'll be using Cursor in a few years or have moved on to another tool, I
can't really tell. I am confident that at the time of writing this, Cursor is
the best example of the potential of LLM coding assistants, and if you want to
explore how this type of tool might be of value I suggest you give it a spin.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An indie studio created a game based on Stanislaw Lem's novel (123 pts)]]></title>
            <link>https://invinciblethegame.com/?hn</link>
            <guid>41978246</guid>
            <pubDate>Tue, 29 Oct 2024 00:52:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://invinciblethegame.com/?hn">https://invinciblethegame.com/?hn</a>, See on <a href="https://news.ycombinator.com/item?id=41978246">Hacker News</a></p>
Couldn't get https://invinciblethegame.com/?hn: Error: aborted]]></description>
        </item>
        <item>
            <title><![CDATA[What's New in POSIX 2024 (174 pts)]]></title>
            <link>https://blog.toast.cafe/posix2024-xcu</link>
            <guid>41978197</guid>
            <pubDate>Tue, 29 Oct 2024 00:42:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.toast.cafe/posix2024-xcu">https://blog.toast.cafe/posix2024-xcu</a>, See on <a href="https://news.ycombinator.com/item?id=41978197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
        <h2 id="toc">Table of Contents</h2>
<ul id="toc-list">
<li>
<a href="#highlights" rel="nofollow">Highlights</a><ul>
<li>
<a href="#handling-of-filenames-in-shell" rel="nofollow">Handling of Filenames in Shell</a></li>
<li>
<a href="#modern-c" rel="nofollow">Modern C</a></li>
<li>
<a href="#limits--cooperation" rel="nofollow">Limits &amp; Cooperation</a></li>
<li>
<a href="#makefiles" rel="nofollow">Makefiles</a></li>
<li>
<a href="#logging" rel="nofollow">Logging</a></li>
<li>
<a href="#internationalization" rel="nofollow">Internationalization</a></li>
<li>
<a href="#minor-changes" rel="nofollow">Minor Changes</a></li>
</ul>
</li>
<li>
<a href="#changes-index" rel="nofollow">Changes Index</a></li>
</ul>
<p>In the 1950s, computers did not really interoperate. ARPANET has not yet happened (that would become a thing in the 60s), and every operating system was typically tied to the hardware that was meant to run on. Most communication actually happened over telephone, and no company was more present in that space than the Bell System. Unfortunately, the way they were so present was through exclusive supply contracts (with its subsidiary Western Electric) and a vast array of patents that it would refuse to license to competitors. So they got an antitrust suit aimed at them, which after seven years of litigation culminated in the 1956 consent decree. The Bell System was broken up, obliged to license all of its patents royalty-free, and barred from entering any industry other than telecommunications. So they made Unix.</p>
<p>Unix was unique, because the focus was on the software (since Bell couldn’t compete in this space anyway, as per the above). An evolution of Multics, it was developed on a PDP-7 (by cross-compiling). They then ported a compiler-compiler to it, leading to the development of B. Once their internal needs outgrew the PDP-7, it got ported to the PDP-11, and gained full typesetting capabilities. Gaining some traction internally, when Bell acquired other PDP-11s, instead of running DEC’s own OS for the machine, they simply ran Unix on it. This has led to the rewrite of the OS in C, a higher level (comparatively, of course) language, which enabled the porting of it to other machines (like the Interdata 7/32 and 8/32). Interest grew, and Bell (not being allowed to turn Unix into a product) simply shipped it at manufacturing cost for the media. Notably, ARPANET used it (see: RFC 681).</p>
<p>In the early 1980s, Unix had become a univeral operating system, used on virtually every serious machine. Then, AT&amp;T got hit by an antitrust suit again. The exact details matter less, but freed it from the old restriction. System V immediately turned into a product, almost killing it. That very year, the GNU project was created, and the BSD project was started in Berkeley. Having grown accustomed to interoperability (since up until that point, there was only really one serious Unix), several standardization attempts were created. The System V Interface Definition was the AT&amp;T one, Europe created the X/Open consortium of Single UNIX Specification fame, and the IEEE put out POSIX. These latter two would eventually merge and become equivalent, developed by the Austin Group, defining the only interface said to be universally interoperable on the OS level that we have to this day.</p>
<p>As of the previous release of POSIX, the Austin Group gained more control over the specification, having it be more working group oriented, and they got to work making the POSIX specification more modern. POSIX 2024 is the first release that bears the fruits of this labor, and as such, the changes made to it are particularly interesting, as they will define the direction of the specification going forwards. This is what this article is about!</p>
<p>Well, mostly. POSIX is composed of a couple of sections. Notably XBD (Base Definitions, which talk about things like what a file is, how regular expressions work, etc), XSH (System Interfaces, the C API that defines POSIX’s internals), and XCU (which defines the shell command language, and the standard utilities available for the system). There’s also XRAT, which explains the rationale of the authors, but it’s less relevant for our purposes today. XBD and XRAT are both interesting as context for XSH and XCU, but those are the real meat of the specification. This article will focus on the XCU section, in particular the utilities part of that section. If you’re more interested in the XSH section, there’s an excellent summary page by <a href="https://sortix.org/" rel="nofollow">sortix’s</a> Jonas Termansen that you can read <a href="https://sortix.org/blog/posix-2024/" rel="nofollow">here</a>.</p>
<h2 id="highlights">Highlights <a href="#highlights" rel="nofollow">#</a></h2>
<h3 id="handling-of-filenames-in-shell">Handling of Filenames in Shell <a href="#handling-of-filenames-in-shell" rel="nofollow">#</a></h3>
<p>One of the most common errors in shell scripts when working with files tends to be the presumption that the newline character (<code>\n</code>) will not be present in the filename. Consider, for example, wanting to do some processing of files in a directory, processing the most recently modified ones first, with some custom break condition. The most common (naive) way of implementing this looks like this<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>:</p>
<pre><code><span><span>1</span><span>ls -t <span>|</span> <span>while</span> <span>read</span> -r f<span>;</span> <span>do</span>
</span></span><span><span>2</span><span>	<span># if my condition; then break; fi</span>
</span></span><span><span>3</span><span>	<span># do something with $f</span>
</span></span><span><span>4</span><span><span>done</span>
</span></span></code></pre><p>After all, <code>read(1p)</code> reads logical lines from stdin into a variable, and <code>ls(1p)</code> outputs one entry per line. The problem is that pathnames<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> (as per section <code>3.254</code> of POSIX 2024) are just strings (meaning they can contain any bytes except the NUL character), meaning it’s incorrect to even treat it as a character string, let alone something you can put in a newline-separated form. As such, the correct solution, historically, has been to loop over the files in some other way (such as wildcards, which aren’t subject to expansion, or using <code>find(1p)</code>), then sort them, then run on the sorted datatype. This question is probably one of the most talked about in shell. POSIX 2024 addresses this issue in two ways.</p>
<h4 id="the-null-option">The Null Option <a href="#the-null-option" rel="nofollow">#</a></h4>
<p><code>find(1p)</code> now supports the <code>-print0</code> primary, which makes <code>find</code> use the NUL character as a separator. To go along with it, <code>xargs(1p)</code> now supports the <code>-0</code> argument, which reads arguments expecting them to be separated with NUL characters. Finally, for (most) other usecases, <code>read(1p)</code> now supports the <code>-d</code> (delimiter) argument, where <code>-d ''</code> means the NUL character is the delimiter. This is a non-ideal resolution though. Previous POSIX releases have considered <code>-print0</code> before, but never ended up adopting it because using a null terminator meant that any utility that would need to process that output would need to have a new option to parse that type of output.</p>
<p>More precisely, this approach does not resolve our original problem. <code>xargs(1p)</code> can’t sort, and therefore we still have to handle that logic separately, unless <code>sort(1p)</code> also grows this support, even after <code>read(1p)</code>. This problem continues with every other type of use-case. Importantly, it breaks the interoperability that POSIX was made to uphold.</p>
<p>Thankfully, there is the second way that they’re fixing this issue.</p>
<h4 id="the-nuclear-option">The Nuclear Option <a href="#the-nuclear-option" rel="nofollow">#</a></h4>
<p>We’ve established that, yes, pathnames can include newlines. We have not established <em>why</em> they can do that. After some deliberation, the Austin Group could not find a single use-case for newlines in pathnames besides breaking naive scripts. Wouldn’t it be nice if the naive scripts were just correct now? Ok, that might be a bit much all at once. We’re heading there though!
A bunch of C functions<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup> are now encouraged to report <code>EILSEQ</code> if the last component of a pathname to a file they are to create contains a newline (put differently, they’re to error out instead of creating a filename that contains a newline).</p>
<p>As for the utilities, the following utilities are now either encouraged to error out if they are to create a filename that contains a newline, and/or encouraged to error out if they are about to print a pathname that contains a newline in a context where newlines may be used as a separator: <code>admin(1p)</code>, <code>ar(1p)</code>, <code>awk(1p)</code>, <code>basename(1p)</code>, <code>cd(1p)</code>, <code>cksum(1p)</code>, <code>cmp(1p)</code>, <code>command(1p)</code>, <code>compress(1p)</code>, <code>cp(1p)</code>, <code>csplit(1p)</code>, <code>ctags(1p)</code>, <code>cxref(1p)</code>, <code>dd(1p)</code>, <code>df(1p)</code>, <code>diff(1p)</code>, <code>dirname(1p)</code>, <code>du(1p)</code>, <code>ed(1p)</code>, <code>ex(1p)</code>, <code>file(1p)</code>, <code>find(1p)</code>, <code>fuser(1p)</code>, <code>get(1p)</code>, <code>grep(1p)</code>, <code>hash(1p)</code>, <code>head(1p)</code>, <code>ipcs(1p)</code>, <code>link(1p)</code>, <code>ln(1p)</code>, <code>localedef(1p)</code>, <code>ls(1p)</code>, <code>m4(1p)</code>, <code>mailx(1p)</code>, <code>make(1p)</code>, <code>man(1p)</code>, <code>mkdir(1p)</code>, <code>mkfifo(1p)</code>, <code>mv(1p)</code>,<code>nm(1p)</code>, <code>patch(1p)</code>, <code>pax(1p)</code>, <code>prs(1p)</code>, <code>pws(1p)</code>, <code>rm(1p)</code>, <code>rmdel(1p)</code>, <code>sact(1p)</code>, <code>sccs(1p)</code>, <code>sh(1p)</code>, <code>sort(1p)</code>, <code>split(1p)</code>, <code>tee(1p)</code>, <code>touch(1p)</code>, <code>type(1p)</code>, <code>uncompress(1p)</code>, <code>unget(1p)</code>, <code>uniq(1p)</code>,<code>uucp(1p)</code>, <code>uudecode(1p)</code>, <code>val(1p)</code>, <code>vi(1p)</code>, <code>wc(1p)</code>, <code>what(1p)</code>, <code>yacc(1p)</code>, and <code>zcat(1p)</code>.</p>
<p>Furthermore, <code>sh(1p)</code> talks about future direction, which may require the above to be treated as errors, and <code>pr(1p)</code> has a new section talking about “problematic pathnames” (since, for its use-case, tabs and vertical tabs are also problem-causing).</p>
<p>This is a much better solution, even in its current form. Unless your threat model includes attackers targeting you in particular (which, for example, immediately excludes all “home use” scripts), you can reasonably expect people to be discouraged from creating newline-containing characters, where before it might have been perceived as a “clever hack”. You can’t rely on your system enforcing those files not exist, but this is a major step in that direction.</p>
<h4 id="tldr">TL;DR <a href="#tldr" rel="nofollow">#</a></h4>
<p>While code like <code>ls -t | while read -r f</code> isn’t strictly correct yet, it’s likely to become strictly correct eventually. It’s also much more reasonable to opt into this early, unless you’re writing software with security requirements, are deleting files based on inputs, or similar.</p>
<h3 id="modern-c">Modern C <a href="#modern-c" rel="nofollow">#</a></h3>
<p>C has come a pretty long way in the last half-century, but for most intents and purposes, we haven’t been able to really benefit from it. Did you know that since <code>c11</code> we actually have built-in unicode support via <code>&lt;uchar.h&gt;</code> (ISO/IEC TR 19769:2004)? Most modern programs can’t actually utilize this, because they target <code>c89</code> (often incorrectly called “ANSI C”) or (if you’re lucky) <code>c99</code>. Why does this happen?</p>
<p>Well, when you’re building a new C program, you must decide what version of C to target. Target something too new, and no one will be able to build it. An example of this is <a href="https://github.com/aristocratos/btop" rel="nofollow">btop++</a>, which targetted some newer C++ features (notably <code>&lt;ranges&gt;</code>) that at the time of its publishing LLVM simply did not support: <code>libc++</code> simply didn’t have them yet (at least not in a stable format available on most distributions), and you couldn’t use gcc’s <code>libstdc++</code> because its <code>&lt;ranges&gt;</code> implementation depended on concepts (which LLVM also did not have yet).</p>
<p>As such, what you do, is you look at the platforms you want your program to run on, and try to figure out what the least common denominator would be. It just so happens that for the longest time, that denominator would be <code>c89</code>. For a little while now, it’s been <code>c99</code>. As for why that is, POSIX is a large part. You see, up until POSIX 2024, POSIX required that the <code>c89</code> compiler be present on the system. If you have <code>c89</code> you’re compliant, and if you do not, you are not. Most operating systems try to be POSIX compliant, and so it becomes a typical expectation (so you don’t have to worry about not having C at all, something other languages do have to worry about). This broad presumption of availability also pushes the embedded developers to provide something along those lines as well (setting the expectation of expectations), so most microcontrollers will have a <code>c89</code> (or again, recently, <code>c99</code>) toolchain available for them.</p>
<p>In short, application authors will tend not to target something until it’s fairly common, unless there’s a disproportionate advantage for their specific use-case (such as with <code>c99</code> over <code>c89</code>). What’s fairly common is strongly influenced by what is pseudo-guaranteed by the only portable standard we have.</p>
<p>Anyway, POSIX 2024 now requires <code>c17</code>, and does not require <code>c89</code>. Furthermore, the rationale mentions that future editions will not require <code>c17</code>, but will simply require whatever C specification version is the most modern and already implemented by major toolchains. So going forward, it’ll be much easier to justify using actually modern C for your new projects, and we can expect more and more embedded tools to provide modern C versions (something we’re already seeing, especially on microcontrollers that are based on ARM or RISC-V).</p>
<h3 id="limits--cooperation">Limits &amp; Cooperation <a href="#limits--cooperation" rel="nofollow">#</a></h3>
<p>Operating systems impose limits (often arbitrary) on what runs inside of them, and your applications (and scripts, and interactive usage) may also want to impose some limits and cooperation on what you run. As such, it’s important that you be able to interact with these limits. This is what the <code>nice(1p)</code>, <code>renice(1p)</code>, and <code>ulimit(1p)</code> utilities are meant to do.</p>
<p>Unfortunately, <code>renice(1p)</code> only worked in absolutes, and <code>ulimit(1p)</code> only let you set a maximum write size for files (and didn’t differentiate between hard and soft limits), and was only available as part of the XSI extension.</p>
<p>With POSIX 2024, <code>ulimit(1p)</code> now supports reporting hard and soft limits and defines how those are used and interact. Additionally, the core image size, data segment size, open file descriptor amount, stack size, cpu time<sup id="fnref:4"><a href="#fn:4" rel="nofollow">4</a></sup>, and address space limits now exist. This means that you can now (or rather, in the near future) reasonably rely on those existing and actually make use of them in portable scripts. <code>renice(1p)</code> is also updated to support the <code>-n</code> option (just like <code>nice(1p)</code>) to change the niceness value relatively.</p>
<p>Finally, we get a new utility: <code>timeout(1p)</code>. A lot of tools over the years have added options to handle their own timeouts (<code>curl(1)</code> in particular comes to mind, having several different types of timeouts for various use-cases), but with <code>timeout(1p)</code> you don’t need those (except for the added flexibility) anymore. It even handles child processes (in several implementation defined ways) and (importantly) lets you customize the signal and send a secondary <code>SIGKILL</code> after a secondary timeout.</p>
<h3 id="makefiles">Makefiles <a href="#makefiles" rel="nofollow">#</a></h3>
<p><code>make(1p)</code> remains the default build system to this day. Or at least sort of. Most people tend to write large scripts that wrap around make for various reasons, but in the end they will tend to produce a <code>Makefile</code> (though ninja has been gaining a lot of traction). Let’s take a look at a typical example to explain what the improvements are.</p>
<p>Our use-case is simple: we have a bunch of <code>.c</code> files in <code>./</code>. We want to compile and link them together. We also have a dependency (let’s say it’s libcurl) that requires some additional <code>CFLAGS</code> and <code>LDFLAGS</code>, which we query using <code>pkg-config</code> (well, I’m going to use <code>pkgconf</code>, it’s compatible). Importantly, we’re lazy in that we don’t want to specify every <code>.c</code> file in the directory in our Makefile. We also want to be able to clean our <code>.o</code> files without resorting to something like <code>git clean -fx</code> (that might clean some temporary artifacts that we do want to keep). With GNU Make, that might look something like so:</p>
<pre><code><span><span> 1</span><span><span>SRC</span> <span>:=</span> <span>$(</span>wildcard *.c<span>)</span>
</span></span><span><span> 2</span><span><span>OBJ</span> <span>:=</span> <span>$(</span>SRC:.c<span>=</span>.o<span>)</span>
</span></span><span><span> 3</span><span>
</span></span><span><span> 4</span><span><span>CC</span> <span>?=</span> cc
</span></span><span><span> 5</span><span>
</span></span><span><span> 6</span><span><span>CFLAGS</span>  <span>?=</span> -Os -pipe
</span></span><span><span> 7</span><span><span>LDFLAGS</span> <span>?=</span> -Wl,-O2
</span></span><span><span> 8</span><span><span>LIBS</span>    <span>?=</span>
</span></span><span><span> 9</span><span>
</span></span><span><span>10</span><span><span>PKGCONF</span> <span>?=</span> pkgconf
</span></span><span><span>11</span><span>
</span></span><span><span>12</span><span><span>CURLC</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --cflags libcurl
</span></span><span><span>13</span><span><span>CURLL</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --libs   libcurl
</span></span><span><span>14</span><span>
</span></span><span><span>15</span><span><span>CFLAGS</span>  <span>:=</span> <span>$(</span>CFLAGS<span>)</span>  <span>$(</span>CURLC<span>)</span>
</span></span><span><span>16</span><span><span>LDFLAGS</span> <span>:=</span> <span>$(</span>LDFLAGS<span>)</span> <span>$(</span>CURLL<span>)</span>
</span></span><span><span>17</span><span>
</span></span><span><span>18</span><span><span>myprog</span><span>:</span> <span>$(</span><span>OBJ</span><span>)</span>
</span></span><span><span>19</span><span>	<span>$(</span>CC<span>)</span> -o <span>$@</span> <span>$(</span>LDFLAGS<span>)</span> <span>$(</span>LIBS<span>)</span> $^
</span></span><span><span>20</span><span>
</span></span><span><span>21</span><span><span>.PHONY</span><span>:</span> <span>clean</span>
</span></span><span><span>22</span><span><span>clean</span><span>:</span>
</span></span><span><span>23</span><span>	rm -f <span>$(</span>OBJ<span>)</span> myprog
</span></span></code></pre><p>This will not work on anything but GNU Make. MacOS make<sup id="fnref:5"><a href="#fn:5" rel="nofollow">5</a></sup> won’t be happy with the <code>!=</code> used for <code>CURLC</code>, while bsdmake and bmake won’t be happy with <code>$^</code>. POSIX make would be unhappy with the <code>:=</code>, <code>wildcard</code> and <code>.PHONY</code>. Similarly, if we targetted <code>bmake</code> initially, the result would not properly run on <code>gmake</code>, and so on. The various implementations are mutually incompatible in diverging ways, since the POSIX implementation lacked critical features required for writing such small (and the vast majority of Makefiles <em>should</em> be this small) Makefiles.</p>
<p>While there’s still no good solution for the <code>$(wildcard *.c)</code> portion of this<sup id="fnref:6"><a href="#fn:6" rel="nofollow">6</a></sup>, the following, annotated with comments for changes, should now work in strict POSIX compatibility<sup id="fnref:7"><a href="#fn:7" rel="nofollow">7</a></sup>:</p>
<pre><code><span><span> 1</span><span><span># .POSIX: is meant to make the Make implementation behave as though
</span></span></span><span><span> 2</span><span><span># it is standard POSIX-make, since there may be conflicts
</span></span></span><span><span> 3</span><span><span></span><span>.POSIX</span><span>:</span>
</span></span><span><span> 4</span><span><span># we use ::= here, since POSIX does not define :=.
</span></span></span><span><span> 5</span><span><span># we also strictly enumerate the sources
</span></span></span><span><span> 6</span><span><span></span><span>SRC </span><span>::</span>= <span>one</span>.<span>c</span> <span>two</span>.<span>c</span>
</span></span><span><span> 7</span><span><span>OBJ </span><span>::</span>= <span>$(</span><span>SRC</span>:.<span>c</span>=.<span>o</span><span>)</span>
</span></span><span><span> 8</span><span>
</span></span><span><span> 9</span><span><span>CC</span> <span>?=</span> cc
</span></span><span><span>10</span><span>
</span></span><span><span>11</span><span><span>CFLAGS</span>  <span>?=</span> -Os -pipe
</span></span><span><span>12</span><span><span>LDFLAGS</span> <span>?=</span> -Wl,-O2
</span></span><span><span>13</span><span><span>LIBS</span>    <span>?=</span>
</span></span><span><span>14</span><span>
</span></span><span><span>15</span><span><span>PKGCONF</span> <span>?=</span> pkgconf
</span></span><span><span>16</span><span>
</span></span><span><span>17</span><span><span>CURLC</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --cflags libcurl
</span></span><span><span>18</span><span><span>CURLL</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --libs   libcurl
</span></span><span><span>19</span><span>
</span></span><span><span>20</span><span><span># ditto re: ::=
</span></span></span><span><span>21</span><span><span></span><span>CFLAGS  </span><span>::</span>= <span>$(</span><span>CFLAGS</span><span>)</span>  <span>$(</span><span>CURLC</span><span>)</span>
</span></span><span><span>22</span><span><span>LDFLAGS </span><span>::</span>= <span>$(</span><span>LDFLAGS</span><span>)</span> <span>$(</span><span>CURLL</span><span>)</span>
</span></span><span><span>23</span><span>
</span></span><span><span>24</span><span><span>myprog</span><span>:</span> <span>$(</span><span>OBJ</span><span>)</span>
</span></span><span><span>25</span><span>	<span>$(</span>CC<span>)</span> -o <span>$@</span> <span>$(</span>LDFLAGS<span>)</span> <span>$(</span>LIBS<span>)</span> $^
</span></span><span><span>26</span><span>
</span></span><span><span>27</span><span><span>.PHONY</span><span>:</span> <span>clean</span>
</span></span><span><span>28</span><span><span>clean</span><span>:</span>
</span></span><span><span>29</span><span>	rm -f <span>$(</span>OBJ<span>)</span> myprog
</span></span></code></pre><p>That’s very few changes! Importantly, <code>gmake</code> can already handle this, meaning that by targeting this feature set you are strictly improving compatibility.</p>
<p>To be very specific, POSIX 2024 added support for the <code>$^</code> and <code>$+</code> internal macros, <code>::=</code>, <code>:::=</code>, <code>!=</code>, <code>?=</code>, and <code>+=</code> macro assignment forms, silent includes via <code>-include</code>, <code>.NOTPARALLEL</code>, <code>.PHONY</code>, and <code>.WAIT</code> special targets (of which I did not cover the parallelism ones, as those will typically be mostly useful to meta build systems), and other less important changes that will be listed out in full below.</p>
<h3 id="logging">Logging <a href="#logging" rel="nofollow">#</a></h3>
<p>Our computers have more and more cores. In early 2017 (when the previous version of the standard was being finalized), most consumer grade hardware still maxed out at 4 cores (likely with SMT). This was also the segment of the market most likely to have background batch processing done in shell (as more enterprise-grade uses tend to write in a programming language that can integrate with their numerous external APIs). As such, while background processes were certainly common, it wasn’t as much of a common expectation that one might be doing some major processing (e.g. video re-encoding) in the background while performing other tasks. Of course, right after that point, in March 2017, the first generation of AMD Ryzen CPUs dropped on the scene and put processors with as many as 16 threads into the hands of consumers at more than reasonable prices. Today, in 2024, it’s difficult to buy a new workstation cpu with fewer than 12 threads, making the abovementioned scenarios all the more common.</p>
<p>The original specification of <code>logger(1p)</code> was written with a fairly uncommon, albeit necessary, use-case in mind. Today, such use-cases are much more common, and could be even more common if logging was easier to do correctly<sup id="fnref:8"><a href="#fn:8" rel="nofollow">8</a></sup>. This original specification basically said that <code>logger(1p)</code> takes arguments like echo, but instead of outputting the text into stdout, it does so into syslog. It also means that logging the output of commands is unduly complicated.</p>
<p>In POSIX 2024, <code>logger(1p)</code> becomes a more fully-qualified command, with arguments and stdin interpretation. Notably, if there are no non-option arguments, <code>logger(1p)</code> will read the contents to log from stdin. It is also possible to ask the contents of a specific file to be logged using <code>-f</code>. Additionally, the syslog priority can be specified with <code>-p</code>, the <code>pid</code> of the logger process on each message using <code>-i</code>, and a syslog tag string using <code>-t</code>. Of additional importance, every non-empty line in the input or file shall be logged as a separate message, which means that the <code>-i</code> argument can be used to perform bulk logging where you can differentiate between failed runs.</p>
<h3 id="internationalization">Internationalization <a href="#internationalization" rel="nofollow">#</a></h3>
<p>Different people speak different languages, and it’s important to be able to translate your program for those. While you’re writing a C program or something along those lines, you can always reach for a library that you link into (such as GNU intl). While you’re writing a shell script, however, your options tend to be far more limited, since you can’t distribute it alongside the script very easily. Wouldn’t it be helpful if the standard everyone follows to various degrees actually settled on whatever interface was the most used in practice? Anyway, POSIX 2024 has adopted the <code>gettext</code> suite ala GNU, both as a system interface (<code>gettext(3p)</code> and co) and in the CLI (<code>gettext(1p)</code>, <code>ngettext(1p)</code>, <code>xgettext(1p)</code>, <code>msgmft(1p)</code>).</p>
<p>Since the target audience for this article is primarily shell people and advanced end-users, I’ll quickly go over the utilization in a shell context. <em>If you’re already familiar with the basics of GNU’s implementation, you can skip the rest of this section!</em> Translations are organized by message IDs (<code>msgid</code>) which can then be turned into arbitrary message strings (<code>msgstr</code>). These are encoded in a Portable Object file (<code>.po</code>), which you compile into a Machine Object file (<code>.mo</code>) using <code>msgfmt(1p)</code>. You then place them on your system in such a way that the <code>gettext(1p)</code> utilities will be able to find them, and the typical <code>LANG</code>/<code>LANGUAGE</code>/<code>LC_ALL</code>/<code>LC_MESSAGES</code> mechanism will get you the correct translations.</p>
<p>For the purposes of this minimal example, we’re going to write a very small program that talks about pets. The program will either print <code>you like cats</code>, <code>you like dogs</code>, or <code>you have %d pets</code> (where the <code>%d</code> will be used for <code>printf</code> output). We’ll also demonstrate how special-case plural forms work. We’ll be making a French and an English translation, and everything will be done relative to a directory of your choosing, that I will refer to as <code>$PWD</code> or <code>.</code> interchangeably. We’ll start by writing our two annotated <code>.po</code> files.</p>
<pre><code># ./en/pets.po : the filename and location is arbitrary
# empty messageid and str signals the header
# different languages deal with plural forms differently
# English only has a special case for "one"
# the `plural=` section is a C-like conditional expression
msgid ""
msgstr ""
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=n != 1;\n"
"Language: en\n"

# the IDs here are identical the messages
# since English is the source language for us
msgid "you like cats"
msgstr "you like cats"

msgid "you like dogs"
msgstr "you like dogs"

# note that if a translation isn't found
# the msgid is used as is
msgid "you have a pet"
msgid_plural "you have %d pets"
msgstr[0] "you have a pet"
msgstr[1] "you have %d pets"
</code></pre>
<pre><code># ./fr/pets.po
# we'll have a special case for 0 (aucun) and 1 (un)
# then the rest will be general case plural
msgid ""
msgstr ""
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=3; plural=(n==0)?0: (n==1)?1: 2\n"

msgid "you like cats"
msgstr "vous aimez les chats"

msgid "you like dogs"
msgstr "vous aimez les chiens"

# I translated "pet" as "little companion"
# as there's no satisfactory direct translation
msgid "you have a pet"
msgid_plural "you have %d pets"
msgstr[0] "vous n'avez pas de petits compagnons"
msgstr[1] "vous avez un petit compagnon"
msgstr[2] "vous avez %d petits compagnons"
</code></pre>
<p>These files aren’t usable as-is. We need to compile them into <code>.mo</code> files. We’ll start by compiling them in the same directory: <code>msgfmt en/pets.po -o en/pets.mo; msgfmt fr/pets.po -o fr/pets.mo</code>. We now need to place them in a location that <code>gettext(1p)</code> and co. will be able to find it in. For those specific commands there are numerous special cases, and we’ll take advantage of those via <code>TEXTDOMAINDIR</code>. Under <code>$TEXTDOMAINDIR</code>, the system will try to look for your <code>$LC_MESSAGES</code> locale followed by <code>LC_MESSAGES</code>, then your textdomain. For convenience, we’ll make some symlinks: <code>ln -s . en/LC_MESSAGES; ln -s . fr/LC_MESSAGES</code>. We can now demonstrate the messages manually!</p>
<pre><code><span><span> 1</span><span><span>export</span> <span>TEXTDOMAINDIR</span><span>=</span><span>$PWD</span>
</span></span><span><span> 2</span><span>
</span></span><span><span> 3</span><span><span># the system will access $TEXTDOMAINDIR/${locales…}/$TEXTDOMAIN.mo</span>
</span></span><span><span> 4</span><span><span># you can avoid setting $TEXTDOMAIN if you specify it on the CLI</span>
</span></span><span><span> 5</span><span><span>export</span> <span>TEXTDOMAIN</span><span>=</span>pets
</span></span><span><span> 6</span><span>
</span></span><span><span> 7</span><span><span># we can now translate simple messages!</span>
</span></span><span><span> 8</span><span><span>LC_MESSAGES</span><span>=</span>fr gettext -s <span>'you like cats'</span>
</span></span><span><span> 9</span><span><span># =&gt; "vous aimez les chats"</span>
</span></span><span><span>10</span><span><span>LC_MESSAGES</span><span>=</span>en gettext -s <span>'you like dogs'</span>
</span></span><span><span>11</span><span><span># =&gt; "you like dogs"</span>
</span></span><span><span>12</span><span><span># if you try to access a translation that doesn't exist,</span>
</span></span><span><span>13</span><span><span># it will simply print the ID, thus why it needs to be representative</span>
</span></span><span><span>14</span><span><span>LC_MESSAGES</span><span>=</span>it gettext -s <span>'you like cats'</span>
</span></span><span><span>15</span><span><span># =&gt; "you like cats"</span>
</span></span><span><span>16</span><span>
</span></span><span><span>17</span><span><span># for plural forms, you use ngettext(1p)</span>
</span></span><span><span>18</span><span><span># because we probably also want to show the real number,</span>
</span></span><span><span>19</span><span><span># ngettext can output printf-compatible format strings</span>
</span></span><span><span>20</span><span><span># so we'll write a wrapper</span>
</span></span><span><span>21</span><span><span># $1: locale; $2: msgid; $3: msgid_plural; $4: quantity</span>
</span></span><span><span>22</span><span>plural<span>()</span> <span>{</span>
</span></span><span><span>23</span><span>	<span>printf</span> <span>"</span><span>$(</span><span>LC_MESSAGES</span><span>=</span><span>"</span><span>$1</span><span>"</span> ngettext <span>"</span><span>$2</span><span>"</span> <span>"</span><span>$3</span><span>"</span> <span>"</span><span>$4</span><span>"</span><span>)</span><span>\n"</span> <span>"</span><span>$4</span><span>"</span>
</span></span><span><span>24</span><span><span>}</span>
</span></span><span><span>25</span><span><span># we can now demonstrate how the translation system adapts to plurals</span>
</span></span><span><span>26</span><span><span>for</span> i in <span>$(</span>seq <span>0</span> 2<span>)</span><span>;</span> <span>do</span>
</span></span><span><span>27</span><span>	plural en <span>'you have a pet'</span> <span>'you have %d pets'</span> <span>$i</span>
</span></span><span><span>28</span><span><span>done</span>
</span></span><span><span>29</span><span><span># =&gt; you have 0 pets</span>
</span></span><span><span>30</span><span><span># =&gt; you have a pet</span>
</span></span><span><span>31</span><span><span># =&gt; you have 2 pets</span>
</span></span><span><span>32</span><span>
</span></span><span><span>33</span><span><span># in French, we had a special case for 0, let's see it in action:</span>
</span></span><span><span>34</span><span><span>for</span> i in <span>$(</span>seq <span>0</span> 2<span>)</span><span>;</span> <span>do</span>
</span></span><span><span>35</span><span>	plural fr <span>'you have a pet'</span> <span>'you have %d pets'</span> <span>$i</span>
</span></span><span><span>36</span><span><span>done</span>
</span></span><span><span>37</span><span><span># =&gt; vous n'avez pas de petits compagnons</span>
</span></span><span><span>38</span><span><span># =&gt; vous avez un petit compagnon</span>
</span></span><span><span>39</span><span><span># =&gt; vous avez 2 petits compagnons</span>
</span></span><span><span>40</span><span>
</span></span><span><span>41</span><span><span># if you try to access a translation that doesn't exist,</span>
</span></span><span><span>42</span><span><span># the system will follow typical English rules, as above:</span>
</span></span><span><span>43</span><span><span>for</span> i in <span>$(</span>seq <span>0</span> 2<span>)</span><span>;</span> <span>do</span>
</span></span><span><span>44</span><span>	plural it <span>'you have a pet'</span> <span>'you have %d pets'</span> <span>$i</span>
</span></span><span><span>45</span><span><span>done</span>
</span></span><span><span>46</span><span><span># you have 0 pets</span>
</span></span><span><span>47</span><span><span># you have a pet</span>
</span></span><span><span>48</span><span><span># you have 2 pets</span>
</span></span></code></pre><p>In short, you can now rely on GNU-style <code>gettext</code> and <code>ngettext</code> utilities to be present, and write your script with the presumption that they are there. If the translation files are not installed, the message ID will be used (intelligently, in the case of plural forms), so you don’t need to worry about the possibility of them not being installed.</p>
<h3 id="minor-changes">Minor Changes <a href="#minor-changes" rel="nofollow">#</a></h3>
<p>These are changes that are relatively minor, but I still think deserve a spotlight.</p>
<ul>
<li><code>readlink(1p)</code> and <code>realpath(1p)</code> are now part of the standard, meaning you can reliably find where a symlink points to.</li>
<li><code>rm(1p)</code> takes a <code>-d</code> argument to remove empty directories too, enabling <code>rm -d *</code> and similar use-cases. You also get <code>-v</code>.</li>
<li><code>printf(1p)</code> now supports numbered conversion specs. For example, <code>printf '%2$s%1$s' a b</code> will print out <code>ba</code>.</li>
<li><code>sed(1p)</code> got several interesting upgrades, though for me the highlights are being able to use EREs like in <code>grep(1p)</code> using <code>-E</code>, as well as the <code>i</code> flag on the <code>s</code> command.</li>
<li><code>test(1p)</code> now has <code>-ef</code>, <code>-nt</code>, <code>-ot</code>. String comparisons (<code>&gt;</code> and <code>&lt;</code>) are now affected by collation.</li>
<li>There is a new category of utility, notably intrinsic utilities. These are like a special built-in that can be overridden by a user function, or as a regular built-in that cannot be substituted on the PATH nor need to be possible to exec (except for kill). It’s an important change, but it’s not very relevant for anyone that’s not writing a shell interpreter.</li>
</ul>
<h2 id="changes-index">Changes Index <a href="#changes-index" rel="nofollow">#</a></h2>
<p>If you’re here early, hi! I’ve been working on this piece (I have a good chunk of an MB in plaintext notes) since the middle of the summer. Instead of letting it continue to drag on, I decided to radically reduce the scope just to the highlights, and only the XCU Utilities section. Thanks to sortix (linked above), I feel like I can stick with that latter, but I still plan to actually write out the full changes index here, as well as go over any of the Shell Command Language changes. It’s just going to take a long time still, since I’m not interested in simply dumping out the change notifications, but rather explain every change being made (albeit not as completely as I do in the highlights section). I will update this page in-place and post a second announcement when this section is complete. Don’t expect it any time soon though (probably not until early 2025).</p>



        

        
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steve Ballmer was an underrated CEO (278 pts)]]></title>
            <link>https://danluu.com/ballmer/</link>
            <guid>41976754</guid>
            <pubDate>Mon, 28 Oct 2024 21:48:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danluu.com/ballmer/">https://danluu.com/ballmer/</a>, See on <a href="https://news.ycombinator.com/item?id=41976754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>There's a common narrative that Microsoft was moribund under Steve Ballmer and then later saved by the miraculous leadership of Satya Nadella. This is the dominant narrative in every online discussion about the topic I've seen and it's a commonly expressed belief "in real life" as well. While I don't have anything negative to say about Nadella's leadership in this post, this narrative underrates Ballmer's role in Microsoft's success. Not only did Microsoft's financials, revenue and profit, look great under Ballmer, Microsoft under Ballmer made deep, long-term bets that set up Microsoft for success in the decades after his reign. At the time, the bets were widely panned, indicating that they weren't necessarily obvious, but we can see in retrospect that the company made very strong bets despite the criticism at the time.</p> <p>In addition to overseeing deep investments in areas that people would later credit Nadella for, Ballmer set Nadella up for success by clearing out political barriers for any successor. Much like <a href="https://x.com/danluu/status/1129519029192757249">Gary Bernhardt's talk, which was panned because he made the problem statement and solution so obvious that people didn't realize they'd learned something non-trivial</a>, Ballmer set up Microsoft for future success so effectively that it's easy to criticize him for being a bum because his successor is so successful.</p> <h3 id="criticisms-of-ballmer">Criticisms of Ballmer</h3> <p>For people who weren't around before the turn of the century, in the 90s, Microsoft used to be considered the biggest, baddest, company in town. But it wasn't long before people's opinions on Microsoft changed — by 2007, many people thought of Microsoft as the next IBM and Paul Graham wrote Microsoft is Dead, in which he noted that Microsoft being considered effective was ancient history:</p> <blockquote> <p>A few days ago I suddenly realized Microsoft was dead. I was talking to a young startup founder about how Google was different from Yahoo. I said that Yahoo had been warped from the start by their fear of Microsoft. That was why they'd positioned themselves as a "media company" instead of a technology company. Then I looked at his face and realized he didn't understand. It was as if I'd told him how much girls liked Barry Manilow in the mid 80s. Barry who?</p> <p>Microsoft? He didn't say anything, but I could tell he didn't quite believe anyone would be frightened of them.</p> </blockquote> <p>These kinds of comments often came with comments that Microsoft's revenue was destined to fall, such as these comments by Graham:</p> <blockquote> <p>Actors and musicians occasionally make comebacks, but technology companies almost never do. Technology companies are projectiles. And because of that you can call them dead long before any problems show up on the balance sheet. Relevance may lead revenues by five or even ten years.</p> </blockquote> <p>Graham names Google and the web as primary causes of Microsoft's death, which we'll discuss later. Although Graham doesn't name Ballmer or note his influence in Microsoft is Dead, Ballmer has been a favorite punching bag of techies for decades. Ballmer came up on the business side of things and later became EVP of Sales and Support; techies love belittling non-technical folks in tech<sup id="fnref:P"><a rel="footnote" href="#fn:P">1</a></sup>. A common criticism, then and now, is that Ballmer didn't understand tech and was a poor leader because all he knew was sales and the bottom line and all he can do is copy what other people have done. Just for example, if you look at online comments on tech forums (minimsft, HN, slashdot, etc.) when Ballmer pushed Sinofsky out in 2012, Ballmer's leadership is nearly universally panned<sup id="fnref:H"><a rel="footnote" href="#fn:H">2</a></sup>. Here's a fairly typical comment from someone claiming to be an anonymous Microsoft insider:</p> <blockquote> <p>Dump Ballmer. Fire 40% of the workforce starting with the loser online services (they are never going to get any better). Reinvest the billions in start-up opportunities within the puget sound that can be accretive to MSFT and acquisition targets ... Reset Windows - Desktop and Tablet. Get serious about business cloud (like Salesforce ...)</p> </blockquote> <p>To the extent that Ballmer defended himself, it was by pointing out that <a href="https://x.com/janettu/status/380824535714377728">the market appeared to be undervaluing Microsoft</a>. Ballmer noted that Microsoft's market cap at the time was extremely low relative to its fundamentals/financials relative to Amazon, Google, Apple, Oracle, IBM, and Salesforce. This seems to have been a fair assessment by Ballmer as <abbr title="as of my writing the draft of this post, in July 2024, if you include dividend reinvestment">Microsoft has outperformed all of those companies since then</abbr>.</p> <p>When Microsoft's market cap took off after Nadella became CEO, it was only natural the narrative would be that Ballmer was killing Microsoft and that the company was struggling until Nadella turned it around. You can pick other discussions if you want, but just for example, if we look at the most recent time Microsoft is Dead hit #1 on HN, a quick ctrl+F has Ballmer's name showing up 24 times. Ballmer has some defenders, but the standard narrative that Ballmer was holding Microsoft back is there, and one of the defenders even uses part of the standard narrative: Ballmer was an unimaginative hack, but he at least set up Microsoft well financially. If you look at high ranking comments, they're all dunking on Ballmer.</p> <p>And if you look on less well informed forums, like Twitter or Reddit, you see the same attacks, but Ballmer has fewer defenders. On Twitter, when I search for "Ballmer", the first four results are unambiguously making fun of Ballmer. The fifth hit could go either way, but from the comments, seems to generally be taken as making of Ballmer, and as I far as I scrolled down, all but one of the remaining videos was making fun of Ballmer (the one that wasn't was an interview where Ballmer notes that he offered Zuckerberg "$20B+, something like that" for Facebook in 2009, which would've been the 2nd largest tech acquisition ever at the time, second only to Carly Fiorina's acquisition of Compaq for $25B in 2001). Searching reddit (incognito window with no history) is the same story (excluding the stories about him as an NBA owner, where he's respected by fans). The top story is making fun of him, the next one notes that he's wealthier than Bill Gates and the top comment on his performance as a CEO starts with "The irony is that he is Microsofts [sic] worst CEO" and then has the standard narrative that the only reason the company is doing well is due to Nadella saving the day, that Ballmer missed the boat on all of the important changes in the tech industry, etc.</p> <p>To sum it up, for the past twenty years, people having been dunking on Ballmer for being a buffoon who doesn't understand tech and who was, at best, some kind of bean counter who knew how to keep the lights on but didn't know how to foster innovation and caused Microsoft to fall behind in every important market.</p> <h3 id="ballmer-s-wins">Ballmer's wins</h3> <p>The common view is at odds with what actually happened under Ballmer's leadership. In financially material positive things that happened under Ballmer since Graham declared Microsoft dead, we have:</p> <ul> <li>2009: Bing launched. This is considered a huge failure, but the bar here is fairly high. A quick web search finds that Bing allegedly made $1B in profit in 2015 and $6.4B in FY 2024 on $12.6B of revenue (given Microsoft's PE ratio in 2022, a rough estimate for Bing's value in 2022 would be $240B)</li> <li>2010: Microsoft creates Azure <ul> <li>I can't say that I personally like it as a product, but in terms of running large scale cloud infrastructure, the three companies that are head-and-shoulders ahead of everyone else in the world are Amazon, Google, and Microsoft. From a business standpoint, the worst thing you could say about Microsoft here is that they're a solid #2 in terms of the business and the biggest threat to become the #1</li> <li>The enterprise sales arm, built and matured under Ballmer, was and is critical to the success of Azure and Office</li> </ul></li> <li>2010: Office 365 released <ul> <li>Microsoft transitioned its enterprise / business suite of software from boxed software to subscription-based software with online options <ul> <li>there isn't really a fixed date for this; the official release of Office 365 seems like as good a year as any</li> </ul></li> <li>Like Azure, I don't personally like these products, but if Microsoft were to split up into major business units, the enterprise software suite is the business unit that could possibly rival Azure in market cap</li> </ul></li> </ul> <p>There are certainly plenty of big misses as well. From 2010-2015, HoloLens was one of Microsoft's biggest bets, behind only Azure and then Bing, but no one's big AR or VR bets have had good returns to date. Microsoft failed to capture the mobile market. Although Windows Phone was generally well received by reviewers who tried it, depending on who you ask, Microsoft was either too late or wasn't willing to subsidize Windows Phone for long enough. Although .NET is still used today, in terms of marketshare, .NET and Silverlight didn't live up to early promises and critical parts were hamstrung or killed as a side effect of internal political battles. Bing is, by reputation, a failure and, at least given Microsoft's choices at the time, <a href="https://danluu.com/ftc-google-antitrust/">probably needed antitrust action against Google to succeed</a>, but this failure still resulted in a business unit worth hundreds of billions of dollars. And despite all of the failures, the biggest bet, Azure, is probably worth on the order of a trillion dollars.</p> <p>The enterprise sales arm of Microsoft was built out under Ballmer before he was CEO (he was, for a time, EVP for Sales and Support, and actually started at Microsoft as the first business manager) and continued to get built out when Ballmer was CEO. Microsoft's sales playbook was so effective that, when I was Microsoft, Google would offer some customers on Office 365 Google's enterprise suite (Docs, etc.) for free. Microsoft salespeople noted that they would still usually be able to close the sale of Microsoft's paid product even when competing against a Google that was giving their product away. For the enterprise, the combination of Microsoft's offering and its enterprise sales team was so effective that Google couldn't even give its product away.</p> <p>If you're reading this and you work at a "tech" company, the company is overwhelmingly likely to choose the Google enterprise suite over the Microsoft enterprise suite and the enterprise sales pitch Microsoft sales people have probably sounds ridiculous to you.</p> <p>An acquaintance of mine who ran a startup had a Microsoft Azure salesperson come in and try to sell them on Azure, opening with "You're on AWS, the consumer cloud. You need Azure, the enterprise cloud". For most people in tech companies, enterprise is synonymous with overpriced, unreliable, junk. In the same way it's easy to make fun of Ballmer because he came up on the sales and business side of the house, it's easy to make fun of an enterprise sales pitch when you hear it but, overall, Microsoft's enterprise sales arm does a good job. When I worked in Azure, I looked into how it worked and, having just come from Google, there was a night and day difference. This was in 2015, under Nadella, but the culture and processes that let Microsoft scale this up were built out under Ballmer. I think there were multiple months where Microsoft hired and onboarded more salespeople than Google employed in total and every stage of the sales pipeline was fairly effective.</p> <h3 id="microsoft-s-misses-under-ballmer">Microsoft's misses under Ballmer</h3> <p>When people point to a long list of failures like Bing, Zune, Windows Phone, and HoloLens as evidence that Ballmer was some kind of buffoon who was holding Microsoft back, this demonstrates a lack of understanding of the tech industry. This is like pointing to a list of failed companies a VC has funded as evidence the VC doesn't know what they're doing. But that's silly in a hits based industry like venture capital. If you want to claim the VC is bad, you need to point out poor total return or a lack of big successes, which would imply poor total return. Similarly, a large company like Microsoft has a large portfolio of bets and one successful bet can pay for a huge number of failures. Ballmer's critics can't point to a poor total return because Microsoft's total return was very good under his tenure. Revenue increased from <abbr title="Most sources cite $22B to $78B, which probably stems from not understanding that the fiscal year and the calendar year are not the same. The revenue from the last four quarters Ballmer presided over was 20.403B+24.519B+18.529B+19.114B=82.565B">$14B or $22B to $83B</abbr>, depending on whether you want to count from when Ballmer became President in July 1998 or when Ballmer became CEO in January 2000. The company was also quite profitable when Ballmer left, recording $27B in profit the previous four quarters, more than the revenue of the company he took over. By market cap, Azure alone would be in the top 10 largest public companies in the world and the enterprise software suite minus Azure would probably just miss being in the top 10.</p> <p>As a result, critics also can't point to a lack of hits when Ballmer presided over the creation of Azure, the conversion of Microsoft's enterprise software from set of local desktop apps to Office 365 et al., the creation of the world's most effective enterprise sales org, the creation of Microsoft's video game empire (among other things, Ballmer was CEO when Microsoft acquired Bungie and made Halo the Xbox's flagship game on launch in 2001), etc. Even Bing, widely considered a failure, on last reported revenue and <abbr title="as of when the draft of this post was written in mid-2024">current P/E ratio, would be 12th most valuable tech company in the world</abbr>, between Tencent and ASML. When attacking Ballmer, people cite Bing as a failure that occurred on Ballmer's watch, which tells you something about the degree of success Ballmer had. Most companies would love to have their successes be as successful as Bing, let alone their failures. Of course it would be better if Ballmer was prescient and all of his bets succeeded, making Microsoft worth something like $10T instead of the lowly $3T market cap it has today, but the criticism of Ballmer that says that he had some failures and some $1T successes is a criticism that he wasn't the greatest CEO of all time by a gigantic margin. True, but not much of a criticism.</p> <p>And, unlike Nadella, Ballmer didn't inherit a company that was easily set up for success. As we noted earlier, it wasn't long into Ballmer's tenure that Microsoft was considered a boring, irrelevant company and the next IBM, mostly due to decisions made when Bill Gates was CEO. As a very senior Microsoft employee from the early days, Ballmer was also partially responsible for the state of Microsoft at the time, so Microsoft's problems are also at least partially attributable to him (but that also means he should get some credit for the success Microsoft had through the 90s). Nevertheless, he navigated Microsoft's most difficult problems well and set up his successor for smooth sailing.</p> <p>Earlier, we noted that Paul Graham cited Google and the rise of the web as two causes for Microsoft's death prior to 2007. <a href="https://danluu.com/ftc-google-antitrust/">As we discussed in this look at antitrust action in tech</a>, these both share a common root cause, antitrust action against Microsoft. If we look at <a href="https://danluu.com/us-v-ms/">the documents from the Microsoft antitrust case</a>, it's clear that Microsoft knew how important the internet was going to be and had plans to control the internet. As part of these plans, they used their monopoly power on the desktop to kill Netscape. They technically lost an antirust case due to this, but if you look at the actual outcomes, Microsoft basically got what they wanted from the courts. The remedies levied against Microsoft are widely considered to have been useless (the initial decision involved breaking up Microsoft, but they were able to reverse this on appeal), and the case dragged on for long enough that Netscape was doomed by the time the case was decided, and the remedies that weren't specifically targeted at the Netscape situation were meaningless.</p> <p>A later part of the plan to dominate the web, discussed at Microsoft but never executed, was to kill Google. If we're judging Microsoft by how "dangerous" it is, how effectively it crushes its competitors, <abbr title="Graham notes that Microsoft is dead because it's no longer dangerous">like Paul Graham did when he judged Microsoft to be dead</abbr>, then Microsoft certainly became less dangerous, but the feeling at Microsoft was that their hand was forced due to the circumstances. One part of the plan to kill Google was to redirect users who typed google.com into their address bar to MSN search. This was before Chrome existed and before mobile existed in any meaningful form. Windows desktop marketshare was 97% and IE had between 80% to 95% marketshare depending on the year, with most of the rest of the marketshare belonging to the rapidly declining Netscape. If Microsoft makes this move, Google is killed before it can get Chrome and Android off the ground and, barring extreme antitrust action, such as a breakup of Microsoft, Microsoft owns the web to this day. And then for dessert, it's not clear there wouldn't be a reason not to go after Amazon.</p> <p>After internal debate, Microsoft declined to kill Google not due to fear of antitrust action, but due to fear of bad PR from the ensuing antitrust action. Had Microsoft redirected traffic away from Google, the impact on Google would've been swifter and more severe than their moves against Netscape and in the time it would take for the DoJ to win another case against Microsoft, Google would suffer the same fate as Netscape. It might be hard to imagine this if you weren't around at the time, but the DoJ vs. Microsoft case was regular front-page news in a way that we haven't seen since (in part because companies learned their lesson on this one — Google <a href="https://danluu.com/ftc-google-antitrust/">supposedly killed the 2011-2012 FTC against them with lobbying</a> and has cleverly maneuvered the more recent case so that it doesn't dominate the news cycle in the same way). The closest thing we've seen since the Microsoft antitrust media circus was the media response to the Crowdstrike outage, but that was a flash in the pan compared to the DoJ vs. Microsoft case.</p> <p>If there's a criticism of Ballmer here, perhaps it's something like Microsoft didn't pre-emptively learn the lessons its younger competitors learned from its big antitrust case before the big antitrust case. A sufficiently prescient executive could've advocated for heavy lobbying to head the antitrust case off at pass, like Google did in 2011-2012, or maneuvered to make the antitrust case just another news story, like Google has been doing for the current case. Another possible criticism is that Microsoft didn't correctly read the political tea leaves and realize that there wasn't going to be serious US tech antitrust for at least two decades after the big case against Microsoft. In principle, Ballmer could've overridden the decision to not kill Google if he had the right expertise on staff to realize that the United States was entering a two decade period of reduced antitrust scrutiny in tech.</p> <p>As criticisms go, I think the former criticism is correct, but not an indictment of Ballmer unless you expect CEOs to be <abbr title="in terms of maximizing the bottom line">infallible</abbr>, so as evidence that Ballmer was a bad CEO, this would be a very weak criticism. And it's not clear that the latter criticism is correct. While Google was able to get away with things like <a href="https://x.com/danluu/status/1016164712030134272">hardcoding the search engine in Android to prevent users from changing their search engine setting</a> to <a href="https://x.com/danluu/status/887724695558205440">having badware installers trick users into making Chrome the default browser</a>, they were considered the "good guys" and didn't get much scrutiny for these sorts of actions, Microsoft wasn't treated with kid gloves in the same way by the press or the general public. Google didn't trigger a serious antitrust investigation until 2011, so it's possible the lack of serious antitrust action between 2001 and 2010 was an artifact of Microsoft being careful to avoid antitrust scrutiny and Google being too small to draw scrutiny and that a move to kill Google when it was still possible would've drawn serious antitrust scrutiny and another PR circus. That's one way in which the company Ballmer inherited was in a more difficult situation than its competitors — Microsoft's hands were perceived to be tied and may have actually been tied. Microsoft could and did get severe criticism for taking an action when the exact same action taken by Google would be lauded as clever.</p> <p>When I was at Microsoft, there was a lot of consternation about this. One funny example was when, in 2011, Google officially called out Microsoft for unethical behavior and the media jumped on this as yet another example of Microsoft behaving badly. A number of people I talked to at Microsoft were upset by this because, according to them, Microsoft got the idea to do this when they noticed that Google was doing it, but reputations take a long time to change and actions taken while Gates was CEO significantly reduced Microsoft's ability to maneuver.</p> <p>Another difficulty Ballmer had to deal with on taking over was Microsoft's intense internal politics. Again, as a very senior Microsoft employee going back to almost the beginning, he bears some responsibility for this, but Ballmer managed to clear the board of the worst bad actors so that Nadella didn't inherit such a difficult situation. If we look at why Microsoft didn't dominate the web under Ballmer, in addition to concerns that killing Google would cause a PR backlash, internal political maneuvering killed most of Microsoft's most promising web products and reduced the appeal and reach of most of the rest of its web products. For example, Microsoft had <a href="https://x.com/danluu/status/790599349491212288">a working competitor to Google Docs in 1997</a>, one year before Google was founded and nine years before Google acquired <abbr title="Writely would later become Google Docs">Writely</abbr>, but it was killed for political reasons. And likewise for <a href="https://x.com/danluu/status/1572839354434977795">NetMeeting</a> and other promising products. <a href="https://www.patreon.com/posts/20571244">Microsoft certainly wasn't alone in having internal political struggles</a>, <a href="https://web.archive.org/web/20110911005705/https://www.bonkersworld.net/organizational-charts/">but it was famous for having more brutal politics than most</a>.</p> <p>Although Ballmer certainly didn't do a perfect job at cleaning house, when I was at Microsoft and asked about promising projects that were sidelined or killed due to internal political struggles, <a href="https://www.patreon.com/posts/22091116">the biggest recent sources of those issues</a> were shown the door under Ballmer, leaving a much more functional company for Nadella to inherit.</p> <h3 id="the-big-picture">The big picture</h3> <p>Stepping back to look at the big picture, Ballmer inherited a company that was a financially strong position that was hemmed in by internal and external politics in a way that caused outside observers to think the company was overwhelmingly likely to slide into irrelevance, leading to predictions like Graham's famous prediction that Microsoft is dead, with revenues expected to decline in five to ten years. In retrospect, we can see that moves made under Gates limited Microsoft's ability to use its monopoly power to outright kill competitors, but there was no inflection point at which a miraculous turnaround was mounted. Instead, Microsoft continued its very strong execution on enterprise products and continued making reasonable bets on the future in a successful effort to supplant revenue streams that were internally viewed as long-term dead ends, even if they were going to be profitable dead ends, such as Windows and boxed (non-subscription) software.</p> <p>Unlike most companies in that position, Microsoft was willing to very heavily subsidize a series of bets that leadership thought could power the company for the next few decades, such as Windows Phone, Bing, Azure, Xbox, and HoloLens. From the internal and external commentary on these bets, you can see why it's so hard for companies to use their successful lines of business to subsidize new lines of business when the writing is on the wall for the successful businesses. People panned these bets as stupid moves that would kill the company, saying the company should focus is efforts on its most profitable businesses, such as Windows.</p> <p>Not all of the bets panned out, but if we look at comments from critics who were saying that Microsoft was doomed because it was subsidizing the wrong bets or younger companies would surpass it, well, today, Microsoft is worth 50% more than Google and twice as much as Meta. If we look at the broader history of the tech industry, Microsoft has had sustained strong execution from its founding in 1975 until today, a nearly fifty year run, a run that's arguably been unmatched in the tech industry. Intel's been around as bit longer, but they stumbled very badly around the turn of the century and <a href="https://danluu.com/cpu-bugs/">they've had a number of problems over the past decade</a>. IBM has a long history, but it just wasn't all that big during its early history, e.g., when T.J. Watson renamed Computing-Tabulating-Recording Company to International Business Machines, its revenue was still well under $10M a year (inflation adjusted, on the order of $100M a year). Computers started becoming big and IBM was big for a tech company by the 50s, but the antitrust case brought against IBM in 1969 that dragged on until it was dropped for being "without merit" in 1982 hamstrung the company and its culture in ways that are still visible when you look at, for example, why IBM's various cloud efforts have failed and, in the 90s, the company was on its deathbed and only managed to survive at all due to Gerstner's turnaround. If we look at older companies that had long sustained runs of strong execution, most of them are gone, like DEC and Data General, or had very bad stumbles that nearly ended the company, like IBM and Apple. There are companies that have had similarly long periods of strong execution, like Oracle, but those companies haven't been nearly as effective as Microsoft in expanding their lines of business and, as a result, Oracle is worth perhaps two Bings. That makes Oracle the 20th most valuable public company in the world, which certainly isn't bad, but it's no Microsoft.</p> <p>If Microsoft stumbles badly, a younger company like Nvidia, Meta, or Google could overtake Microsoft's track record, but that would be no fault of Ballmer's and we'd still have to acknowledge that Ballmer was a very effective CEO, not just in terms of bringing the money in, but in terms of setting up a vision that set Microsoft up for success for the next fifty years.</p> <h3 id="appendix-microsoft-s-relevance-under-ballmer">Appendix: Microsoft's relevance under Ballmer</h3> <p>Besides the headline items mentioned above, off the top of my head, here are a few things I thought were interesting that happened under Ballmer since Graham declared Microsoft to be dead</p> <ul> <li>2007: Microsoft releases LINQ, still fairly nice by <a href="https://www.scattered-thoughts.net/writing/against-sql/">in-use-by-practitioners standards today</a></li> <li>2011: Suimt Gulwani, at MSR, publishes "Automating string processing in spreadsheets using input-output examples", named a most influential POPL paper 10 years later <ul> <li>This paper is about using program synthesis for spreadsheet "autocomplete/inference"</li> <li>I'm not a fan of patents, but I would guess that the reason autocomplete/inference works fairly well in Excel and basically doesn't work at all in Google Sheets is that MS has a patent on this based on this work</li> </ul></li> <li>2012: Microsoft releases TypeScript <ul> <li>This has to be the most widely used programming language released this century and it's a plausible candidate for becoming the most widely used language, period (as long as you don't also count TS usage as JS)</li> </ul></li> <li>2012: Microsoft Surface released <ul> <li>Things haven't been looking so good for the Surface line since Panos Panay left in 2022, and this was arguably failure even in 2022, but this was a $7B/yr line of business in 2022, which goes to show you how big and successful Microsoft is — most companies would love to have something doing as well as a failed $7B/yr business</li> </ul></li> <li>2015: Microsoft releases vscode (after the end of Ballmer's tenure in 2014, but this work came out of work under Ballmer's tenure in multiple ways) <ul> <li>This seems like the most widely used editor among programmers today by a very large margin. When I looked at survey data on this a number of years back, I was shocked by how quickly this happened. It seems like vscode has achieved a level of programmer editor dominance that's <abbr title="excluding the very early days, when you could say that there was only one programmer using one thing">never been seen before</abbr>. Probably the closest thing was Visual Studio a decade before Paul declared Microsoft dead, but that never achieved the same level of marketshare due to a combination of effectively being Windows only software and also costing quite a bit of money</li> <li>Heath Borders notes that Erich Gamma, hired in 2011, was highly influential here</li> </ul></li> </ul> <p>One response to Microsoft's financial success, both the direct success that happened under Ballmer as well as later success that was set up by Ballmer, is that Microsoft is financially successful but irrelevant for trendy programmers, like IBM. For one thing, rounded to the nearest Bing, IBM is probably worth either zero or one Bings. But even if we put aside the financial aspect and we just look at how much each $1T tech company (Apple, Nvidia, Microsoft, Google, Amazon, and Meta) has impacted programmers, Nvidia, Apple, and Microsoft all have a lot of programmers who are dependent on the company due to some kind of ecosystem dependence (CUDA; iOS; .NET and Windows, the latter of which is still the platform of choice for many large areas, such as AAA games).</p> <p>You could make a case for the big cloud vendors, but I don't think that companies have a nearly forced dependency on AWS in the same way that a serious English-language consumer app company really needs an iOS app or an AAA game company has to release on Windows and overwhelmingly likely develops on Windows.</p> <p>If we look at programmers who aren't pinned to an ecosystem, Microsoft seems highly relevant to a lot of programmers due to the creation of tools like vscode and TypeScript. I wouldn't say that it's necessarily more relevant than Amazon since so many programmers use AWS, but it's hard to argue that the company that created (among many other things) vscode and TypeScript under Ballmer's watch is irrelevant to programmers.</p> <h3 id="appendix-my-losing-bet-against-microsoft">Appendix: my losing bet against Microsoft</h3> <p>Shortly after joining Microsoft in 2015, I bet Derek Chiou that Google would beat Microsoft to $1T market cap. Unlike most external commentators, I agreed with the bets Microsoft was making, but when I looked around at the kinds of internal dysfunction Microsoft had at the time, I thought that would cause them enough problems that Google would win. That was wrong —&nbsp;Microsoft beat Google to $1T and is now worth $1T more than Google.</p> <p>I don't think I would've made the bet even a year later, after seeing Microsoft from the inside and how effective Microsoft sales was and how good Microsoft was at shipping things that are appealing to enterprises and the comparing that to Google's cloud execution and strategy. But you could say that I made a mistake that was fairly analogous to what external commentators made until I saw how Microsoft operated in detail.</p> <p><i>Thanks to Laurence Tratt, Yossi Kreinin, Heath Borders, Justin Blank, and Fabian Giesen for comments/corrections/discussion</i></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTML Form Validation is heavily underused (292 pts)]]></title>
            <link>https://expressionstatement.com/html-form-validation-is-heavily-underused</link>
            <guid>41976529</guid>
            <pubDate>Mon, 28 Oct 2024 21:28:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://expressionstatement.com/html-form-validation-is-heavily-underused">https://expressionstatement.com/html-form-validation-is-heavily-underused</a>, See on <a href="https://news.ycombinator.com/item?id=41976529">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article>HTML Forms have powerful validation mechanisms, but they are heavily underused. In fact, not many people even know much about them. Is this because of some flaw in their design? Let’s explore.<!-- -->
<h2 id="attributes-methods-and-properties">Attributes, methods, and properties</h2>
<p>It’s easy to disallow empty inputs by adding
a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/required"><code>required</code></a> attribute:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>&lt;</span><span>input</span><span> required</span><span>=</span><span>{</span><span>true</span><span>}</span><span> /&gt;</span></span></code></pre></figure>
<p>Beyond that, there is a bunch of other ways that you can add constraints to your input. Precisely, there are three ways to do it:</p>
<ul>
<li>Using specific <code>type</code> attribute values, such as <code>"email"</code>, <code>"number"</code>, or <code>"url"</code></li>
<li>Using other input attributes that create constraints, such as <code>"pattern"</code> or <code>"maxlength"</code></li>
<li><strong>Using the <code>setCustomValidity</code> DOM method of the input</strong></li>
</ul>
<p>The last one is the most powerful as it allows to create arbitrary validation logic and handle
complex cases.
Do you notice how it differs from the first two techniques? The first two are defined with <em>attributes</em>, but <code>setCustomValidity</code>
is a <em>method</em>.</p>
<p>Here’s a great write-up that explains the differences between DOM attributes and properties: <a href="https://jakearchibald.com/2024/attributes-vs-properties/">https://jakearchibald.com/2024/attributes-vs-properties/</a></p>
<h2 id="the-nuance-of-an-imperative-api">The nuance of an imperative API</h2>
<p>The fact that <code>setCustomValidity</code> API is exposed only as a method and doesn’t have an attribute equivalent
leads to some terrible ergonomics. I’ll show you with an example.</p>
<p>But first, a very quick intro to how this API works:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>// Make input invalid</span></span>
<span data-line=""><span>input</span><span>.</span><span>setCustomValidity</span><span>(</span><span>"Any text message"</span><span>)</span><span>;</span></span></code></pre></figure>
<p>This would make input <em>invalid</em> and the browser will show the reason as “Any text message”.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>// Remove custom constraints and make input valid</span></span>
<span data-line=""><span>input</span><span>.</span><span>setCustomValidity</span><span>(</span><span>""</span><span>)</span><span>;</span></span></code></pre></figure>
<p>Passing an empty string makes the input <em>valid</em> (unless other constraints are applied).</p>
<p>That’s pretty much it! Now let’s apply this knowledge.<br>
Let’s say we want to implement an equivalent of the <code>required</code> attribute.
That means that an empty input must be prevent the form from being submitted.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>&lt;</span><span>input</span></span>
<span data-line=""><span>  name</span><span>=</span><span>"example"</span></span>
<span data-line=""><span>  placeholder</span><span>=</span><span>"..."</span></span>
<span data-line=""><span>  onChange</span><span>=</span><span>{(</span><span>event</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>    const</span><span> input </span><span>=</span><span> event</span><span>.</span><span>currentTarget</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>    if</span><span> (input</span><span>.</span><span>value </span><span>===</span><span> ""</span><span>) </span><span>{</span></span>
<span data-line="" data-highlighted-line=""><span>      input</span><span>.</span><span>setCustomValidity</span><span>(</span><span>"Custom message: input is empty"</span><span>)</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>    }</span><span> else</span><span> {</span></span>
<span data-line="" data-highlighted-line=""><span>      input</span><span>.</span><span>setCustomValidity</span><span>(</span><span>""</span><span>)</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>    }</span></span>
<span data-line=""><span>  }}</span></span>
<span data-line=""><span>/&gt;</span></span></code></pre></figure>
<p>This kind of looks like we’re done and this code should be enough to accomplish the task.
But try to see it in action:</p>

<p>It may seem to work, but there’s just one important edge case: the input is
in a valid state <em>initially</em>. If you reset the component and press the “submit”
button, the form submission will go through.
But surely, before we ever touch the input, it is empty, and therefore must be invalid.
But we only ever do something when the input value <em>changes</em>.</p>
<p>How can we fix this?</p>
<p>Let’s execute some code when the component mounts:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line="" data-highlighted-line=""><span>import</span><span> {</span><span> useRef</span><span>,</span><span> useLayoutEffect </span><span>}</span><span> from</span><span> "react"</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>function</span><span> Form</span><span>()</span><span> {</span></span>
<span data-line="" data-highlighted-line=""><span>  const</span><span> ref </span><span>=</span><span> useRef</span><span>()</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>  useLayoutEffect</span><span>(</span><span>()</span><span> =&gt;</span><span> {</span></span>
<span data-line="" data-highlighted-line=""><span>    // Make input invalid on initial render if it's empty</span></span>
<span data-line="" data-highlighted-line=""><span>    const</span><span> input </span><span>=</span><span> ref</span><span>.</span><span>current</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>    const</span><span> empty </span><span>=</span><span> input</span><span>.</span><span>value </span><span>!==</span><span> ""</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>    input</span><span>.</span><span>setCustomValidity</span><span>(empty </span><span>?</span><span> "Initial message: input is empty"</span><span> :</span><span> ""</span><span>)</span><span>;</span></span>
<span data-line="" data-highlighted-line=""><span>  },</span><span> [])</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>  return</span><span> (</span></span>
<span data-line=""><span>    &lt;</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>input</span></span>
<span data-line=""><span>        ref</span><span>=</span><span>{</span><span>ref</span><span>}</span></span>
<span data-line=""><span>        name</span><span>=</span><span>"example"</span></span>
<span data-line=""><span>        onChange</span><span>=</span><span>{(</span><span>event</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>          const</span><span> input </span><span>=</span><span> event</span><span>.</span><span>currentTarget</span><span>;</span></span>
<span data-line=""><span>          if</span><span> (input</span><span>.</span><span>value </span><span>===</span><span> ""</span><span>) </span><span>{</span></span>
<span data-line=""><span>            input</span><span>.</span><span>setCustomValidity</span><span>(</span><span>"Custom message: input is empty"</span><span>)</span><span>;</span></span>
<span data-line=""><span>          }</span><span> else</span><span> {</span></span>
<span data-line=""><span>            input</span><span>.</span><span>setCustomValidity</span><span>(</span><span>""</span><span>)</span><span>;</span></span>
<span data-line=""><span>          }</span></span>
<span data-line=""><span>        }}</span></span>
<span data-line=""><span>      /&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>button</span><span>&gt;</span><span>Submit</span><span>&lt;/</span><span>button</span><span>&gt;</span></span>
<span data-line=""><span>    &lt;/</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>  )</span><span>;</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>

<p>Great! Now everything works as expected. But at what cost?</p>
<h2 id="the-boilerplate-problem">The boilerplate problem</h2>
<p>Let’s look at our clumsy way to validate the initial value:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>const</span><span> ref </span><span>=</span><span> useRef</span><span>()</span><span>;</span></span>
<span data-line=""><span>useLayoutEffect</span><span>(</span><span>()</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>  // Make input invalid on initial render if it's empty</span></span>
<span data-line=""><span>  const</span><span> input </span><span>=</span><span> ref</span><span>.</span><span>current</span><span>;</span></span>
<span data-line=""><span>  const</span><span> empty </span><span>=</span><span> input</span><span>.</span><span>value </span><span>!==</span><span> ""</span><span>;</span></span>
<span data-line=""><span>  input</span><span>.</span><span>setCustomValidity</span><span>(empty </span><span>?</span><span> "Initial message: input is empty"</span><span> :</span><span> ""</span><span>)</span><span>;</span></span>
<span data-line=""><span>},</span><span> [])</span><span>;</span></span></code></pre></figure>
<p>Ugh! Wouldn’t want to write that one each time. Let’s think about what’s wrong with this.</p>
<ul>
<li>The validation logic is duplicated between the onChange handler and the initial render phase</li>
<li>The initial validation is not co-located with the input, so we’re losing code cohesion.
It’s fragile: if you update validation logic, you might forget to update code in both places.</li>
<li>The <code>useRef</code> + <code>useLayouEffect</code> + <code>onChange</code> combo is just too much ceremony,
especially when a form has a lot of inputs. And it gets even more confusing if only some of those inputs use <code>customValidity</code></li>
</ul>
<p>This is what happens when you deal with a purely imperative API in a declarative component.</p>
<blockquote>
<p>Unlike validation attributes, <code>CustomValidity</code> is a purely imperative API.
In other words, there’s no input attribute that we can use to set custom validity.</p>
</blockquote>
<p>In fact, I would argue that this is <strong>the main reason for poor adoption of native form validation</strong>. If the API is cumbersome, sometimes it just does not matter how powerful it is.</p>
<h2 id="the-missing-part">The missing part</h2>
<p>In essence, this is the attribute we need:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="html" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="html" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>&lt;</span><span>input</span><span> custom-validity</span><span>=</span><span>"error message"</span><span> /&gt;</span></span></code></pre></figure>
<p>In a declarative framework, this would allow to define input validations in a very powerful way:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>function</span><span> Form</span><span>()</span><span> {</span></span>
<span data-line=""><span>  const</span><span> [</span><span>value</span><span>,</span><span> setValue</span><span>]</span><span> =</span><span> useState</span><span>()</span><span>;</span></span>
<span data-line=""><span>  const</span><span> handleChange</span><span> =</span><span> (</span><span>event</span><span>)</span><span> =&gt;</span><span> setValue</span><span>(event</span><span>.</span><span>target</span><span>.</span><span>value)</span><span>;</span></span>
<span data-line=""><span>  return</span><span> (</span></span>
<span data-line=""><span>    &lt;</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>input</span></span>
<span data-line=""><span>        name</span><span>=</span><span>"example"</span></span>
<span data-line=""><span>        value</span><span>=</span><span>{</span><span>value</span><span>}</span></span>
<span data-line=""><span>        onChange</span><span>=</span><span>{</span><span>handleChange</span><span>}</span></span>
<span data-line="" data-highlighted-line=""><span>        custom-validity</span><span>=</span><span>{</span><span>value</span><span>.</span><span>length </span><span>?</span><span> "Fill out this field"</span><span> :</span><span> ""</span><span>}</span></span>
<span data-line=""><span>      /&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>button</span><span>&gt;</span><span>Submit</span><span>&lt;/</span><span>button</span><span>&gt;</span></span>
<span data-line=""><span>    &lt;/</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>  )</span><span>;</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>Pretty cool! In my opinion, at least. Though you can rightfully argue that this accomplishes only what
the existing <code>required</code> attribute is already capable of. Where’s the “power”?</p>
<p>Let me show you, but first, since there’s no actual <code>custom-validity</code> currently
in the <a href="https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#the-constraint-validation-api">HTML Spec</a>,
let’s implement it in userland.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>function</span><span> Input</span><span>({</span><span> customValidity</span><span>,</span><span> ...</span><span>props</span><span> })</span><span> {</span></span>
<span data-line=""><span>  const</span><span> ref </span><span>=</span><span> useRef</span><span>()</span><span>;</span></span>
<span data-line=""><span>  useLayoutEffect</span><span>(</span><span>()</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>    if</span><span> (customValidity </span><span>!=</span><span> null</span><span>) </span><span>{</span></span>
<span data-line=""><span>      const</span><span> input </span><span>=</span><span> ref</span><span>.</span><span>current</span><span>;</span></span>
<span data-line=""><span>      input</span><span>.</span><span>setCustomValidity</span><span>(customValidity)</span><span>;</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>  },</span><span> [customValidity])</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>  return</span><span> &lt;</span><span>input</span><span> ref</span><span>=</span><span>{</span><span>ref</span><span>}</span><span> {</span><span>...</span><span>props</span><span>}</span><span> /&gt;</span><span>;</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>This will work well for our demo purposes.<br>
For a production-ready component check out
a more <a href="https://gist.github.com/everdimension/a5c1e991a8a6b6aab060ce349b37b825" target="_blank" rel="nooopener">complete implementation</a>.</p>
<h2 id="the-power">The power</h2>
<p>Now we’ll explore which non-trivial cases this design can help solve.</p>
<p>In real-world apps, validation often gets more complex than local checks.
Imagine a username input that should be <strong>valid only if the username is not taken</strong>.
This would require async calls to your server and an intermediary state: the form
should not be valid while the check is in progress.
Let’s see how our abstraction can handle this.</p>

<p>Play around with this example. It uses the <code>required</code> to prevent empty inputs. But then it relies on <code>customValidity</code> to mark input as invalid during the loading state and based on the response.</p>
<h3 id="implementation">Implementation</h3>
<p>First, we create an async function to check whether the username is unique that imitates a server request with a delay.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="js" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>export</span><span> async</span><span> function</span><span> verifyUsername</span><span>(</span><span>userValue</span><span>)</span><span> {</span></span>
<span data-line=""><span>  // imitate network delay</span></span>
<span data-line=""><span>  await</span><span> new</span><span> Promise</span><span>(</span><span>(</span><span>r</span><span>)</span><span> =&gt;</span><span> setTimeout</span><span>(r</span><span>,</span><span> 3000</span><span>))</span><span>;</span></span>
<span data-line=""><span>  const</span><span> value </span><span>=</span><span> userValue</span><span>.</span><span>trim</span><span>()</span><span>.</span><span>toLowerCase</span><span>()</span><span>;</span></span>
<span data-line=""><span>  if</span><span> (value </span><span>===</span><span> "bad input"</span><span>) </span><span>{</span></span>
<span data-line=""><span>    throw</span><span> new</span><span> Error</span><span>(</span><span>"Bad Input"</span><span>)</span><span>;</span></span>
<span data-line=""><span>  }</span></span>
<span data-line=""><span>  const</span><span> validationMessage </span><span>=</span><span> value </span><span>===</span><span> "taken"</span><span> ?</span><span> "Username is taken"</span><span> :</span><span> ""</span><span>;</span></span>
<span data-line=""><span>  return</span><span> {</span><span> validationMessage </span><span>};</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>Next, we’ll create a controlled form component and use <a href="https://tanstack.com/query/latest">react-query</a> to manage to server request when the input value changes:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>import</span><span> {</span><span> useState </span><span>}</span><span> from</span><span> "react"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> useQuery </span><span>}</span><span> from</span><span> "@tanstack/react-query"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> verifyUsername </span><span>}</span><span> from</span><span> "./verifyUsername"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> Input </span><span>}</span><span> from</span><span> "./Input"</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>function</span><span> Form</span><span>()</span><span> {</span></span>
<span data-line=""><span>  const</span><span> [</span><span>value</span><span>,</span><span> setValue</span><span>]</span><span> =</span><span> useState</span><span>(</span><span>""</span><span>)</span><span>;</span></span>
<span data-line=""><span>  const</span><span> {</span><span> data</span><span>,</span><span> isLoading</span><span>,</span><span> isError </span><span>}</span><span> =</span><span> useQuery</span><span>(</span><span>{</span></span>
<span data-line=""><span>    queryKey</span><span>:</span><span> [</span><span>"verifyUsername"</span><span>,</span><span> value]</span><span>,</span></span>
<span data-line=""><span>    queryFn</span><span>:</span><span> ()</span><span> =&gt;</span><span> verifyUsername</span><span>(value)</span><span>,</span></span>
<span data-line=""><span>    enabled</span><span>:</span><span> Boolean</span><span>(value)</span><span>,</span></span>
<span data-line=""><span>  }</span><span>)</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>  return</span><span> (</span></span>
<span data-line=""><span>    &lt;</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>Input</span></span>
<span data-line=""><span>        name</span><span>=</span><span>"username"</span></span>
<span data-line=""><span>        required</span><span>=</span><span>{</span><span>true</span><span>}</span></span>
<span data-line=""><span>        value</span><span>=</span><span>{</span><span>value</span><span>}</span></span>
<span data-line=""><span>        onChange</span><span>=</span><span>{(</span><span>event</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>          setValue</span><span>(event</span><span>.</span><span>currentTarget</span><span>.</span><span>value)</span><span>;</span></span>
<span data-line=""><span>        }}</span></span>
<span data-line=""><span>      /&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>button</span><span>&gt;</span><span>Submit</span><span>&lt;/</span><span>button</span><span>&gt;</span></span>
<span data-line=""><span>    &lt;/</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>  )</span><span>;</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>Great! We have the setup in place. It consists of two crucial parts:</p>
<ul>
<li>Verification request state managed by <code>useQuery</code></li>
<li>Our custom <code>&lt;Input /&gt;</code> component that is capable of taking the <code>customValidity</code> prop</li>
</ul>
<p>Let’s put those pieces together:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>import</span><span> {</span><span> useState </span><span>}</span><span> from</span><span> "react"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> useQuery </span><span>}</span><span> from</span><span> "@tanstack/react-query"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> verifyUsername </span><span>}</span><span> from</span><span> "./verifyUsername"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> Input </span><span>}</span><span> from</span><span> "./Input"</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>function</span><span> Form</span><span>()</span><span> {</span></span>
<span data-line=""><span>  const</span><span> [</span><span>value</span><span>,</span><span> setValue</span><span>]</span><span> =</span><span> useState</span><span>(</span><span>""</span><span>)</span><span>;</span></span>
<span data-line=""><span>  const</span><span> {</span><span> data</span><span>,</span><span> isLoading</span><span>,</span><span> isError </span><span>}</span><span> =</span><span> useQuery</span><span>(</span><span>{</span></span>
<span data-line=""><span>    queryKey</span><span>:</span><span> [</span><span>"verifyUsername"</span><span>,</span><span> value]</span><span>,</span></span>
<span data-line=""><span>    queryFn</span><span>:</span><span> ()</span><span> =&gt;</span><span> verifyUsername</span><span>(value)</span><span>,</span></span>
<span data-line=""><span>    enabled</span><span>:</span><span> Boolean</span><span>(value)</span><span>,</span></span>
<span data-line=""><span>  }</span><span>)</span><span>;</span></span>
<span data-line=""> </span>
<span data-line="" data-highlighted-line=""><span>  const</span><span> validationMessage </span><span>=</span><span> data</span><span>?.</span><span>validationMessage</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>  return</span><span> (</span></span>
<span data-line=""><span>    &lt;</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>Input</span></span>
<span data-line=""><span>        name</span><span>=</span><span>"username"</span></span>
<span data-line=""><span>        required</span><span>=</span><span>{</span><span>true</span><span>}</span></span>
<span data-line="" data-highlighted-line=""><span>        customValidity</span><span>=</span><span>{</span></span>
<span data-line="" data-highlighted-line=""><span>          isLoading</span></span>
<span data-line="" data-highlighted-line=""><span>            ?</span><span> "Verifying username..."</span></span>
<span data-line="" data-highlighted-line=""><span>            :</span><span> isError</span></span>
<span data-line="" data-highlighted-line=""><span>            ?</span><span> "Could not verify"</span></span>
<span data-line="" data-highlighted-line=""><span>            :</span><span> validationMessage</span></span>
<span data-line="" data-highlighted-line=""><span>        }</span></span>
<span data-line=""><span>        value</span><span>=</span><span>{</span><span>value</span><span>}</span></span>
<span data-line=""><span>        onChange</span><span>=</span><span>{(</span><span>event</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>          setValue</span><span>(event</span><span>.</span><span>currentTarget</span><span>.</span><span>value)</span><span>;</span></span>
<span data-line=""><span>        }}</span></span>
<span data-line=""><span>      /&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>button</span><span>&gt;</span><span>Submit</span><span>&lt;/</span><span>button</span><span>&gt;</span></span>
<span data-line=""><span>    &lt;/</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>  )</span><span>;</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>That’s it! We’re describing the whole async validation flow, including
loading, error and success states, <em>in one attribute</em>. You can go back to see <a href="#example-async-username">the result</a> again if you wish</p>
<h3 id="one-more">One more</h3>
<p>This one will be shorter, but also interesting, because it covers dependent input
fields. Let’s implement a form that requires to repeat the entered password:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><code data-language="jsx" data-theme="catppuccin-macchiato catppuccin-frappe"><span data-line=""><span>import</span><span> {</span><span> useState </span><span>}</span><span> from</span><span> "react"</span><span>;</span></span>
<span data-line=""><span>import</span><span> {</span><span> Input </span><span>}</span><span> from</span><span> "./Input"</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>function</span><span> ConfirmPasswordForm</span><span>()</span><span> {</span></span>
<span data-line=""><span>  const</span><span> [</span><span>password</span><span>,</span><span> setPassword</span><span>]</span><span> =</span><span> useState</span><span>(</span><span>""</span><span>)</span><span>;</span></span>
<span data-line=""><span>  const</span><span> [</span><span>confirmedPass</span><span>,</span><span> setConfirmedPass</span><span>]</span><span> =</span><span> useState</span><span>(</span><span>""</span><span>)</span><span>;</span></span>
<span data-line=""> </span>
<span data-line="" data-highlighted-line=""><span>  const</span><span> matches </span><span>=</span><span> confirmedPass </span><span>===</span><span> password</span><span>;</span></span>
<span data-line=""><span>  return</span><span> (</span></span>
<span data-line=""><span>    &lt;</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>Input</span></span>
<span data-line=""><span>        type</span><span>=</span><span>"password"</span></span>
<span data-line=""><span>        name</span><span>=</span><span>"password"</span></span>
<span data-line=""><span>        required</span><span>=</span><span>{</span><span>true</span><span>}</span></span>
<span data-line=""><span>        value</span><span>=</span><span>{</span><span>password</span><span>}</span></span>
<span data-line=""><span>        onChange</span><span>=</span><span>{(</span><span>event</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>          setPassword</span><span>(event</span><span>.</span><span>currentTarget</span><span>.</span><span>value)</span><span>;</span></span>
<span data-line=""><span>        }}</span></span>
<span data-line=""><span>      /&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>Input</span></span>
<span data-line=""><span>        type</span><span>=</span><span>"password"</span></span>
<span data-line=""><span>        name</span><span>=</span><span>"confirmedPassword"</span></span>
<span data-line=""><span>        required</span><span>=</span><span>{</span><span>true</span><span>}</span></span>
<span data-line=""><span>        value</span><span>=</span><span>{</span><span>confirmedPass</span><span>}</span></span>
<span data-line="" data-highlighted-line=""><span>        customValidity</span><span>=</span><span>{</span><span>matches </span><span>?</span><span> ""</span><span> :</span><span> "Password must match"</span><span>}</span></span>
<span data-line=""><span>        onChange</span><span>=</span><span>{(</span><span>event</span><span>)</span><span> =&gt;</span><span> {</span></span>
<span data-line=""><span>          setConfirmedPass</span><span>(event</span><span>.</span><span>currentTarget</span><span>.</span><span>value)</span><span>;</span></span>
<span data-line=""><span>        }}</span></span>
<span data-line=""><span>      /&gt;</span></span>
<span data-line=""><span>      &lt;</span><span>button</span><span>&gt;</span><span>Submit</span><span>&lt;/</span><span>button</span><span>&gt;</span></span>
<span data-line=""><span>    &lt;/</span><span>form</span><span>&gt;</span></span>
<span data-line=""><span>  )</span><span>;</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>You can try it out:</p>

<h2 id="conclusion">Conclusion</h2>
<p>I hope I’ve been able to show you how <code>setCustomValidity</code> can cover
validation needs of all kinds.</p>
<p>But the real power comes from great APIs.</p>
<p>And hopefully, you are now equipped with one of those.<br>
And even more hopefully, we will see it natively in the HTML Spec one day.</p>
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<div><p><img src="https://pbs.twimg.com/profile_images/826440416371302400/HosO7Uze_400x400.jpg" alt=""></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A return to hand-written notes by learning to read and write (477 pts)]]></title>
            <link>https://research.google/blog/a-return-to-hand-written-notes-by-learning-to-read-write/</link>
            <guid>41976311</guid>
            <pubDate>Mon, 28 Oct 2024 21:08:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/a-return-to-hand-written-notes-by-learning-to-read-write/">https://research.google/blog/a-return-to-hand-written-notes-by-learning-to-read-write/</a>, See on <a href="https://news.ycombinator.com/item?id=41976311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20241028">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="sge1e">Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in a vectorized form. However, a substantial gap remains between digital note-taking and traditional pen-and-paper note-taking, a practice still favored by a majority of people.</p><p data-block-key="8vfmv">Bridging this gap by converting a note taker’s physical writing into a digital form is a process called derendering. The result is a sequence of strokes, or trajectories of a writing instrument like a pen or finger, recorded as points and stored digitally. This is also known as an “online” representation of writing, or “digital ink”.</p><p data-block-key="7jll9">The conversion to digital ink offers users who still prefer traditional handwritten notes access to their notes in a digital form. Instead of simply using <a href="https://en.wikipedia.org/wiki/Optical_character_recognition" target="_blank" rel="noopener noreferrer">optical character recognition</a> (OCR), which would allow the writing to be transcribed to a text document, by capturing the handwritten documents as a collection of strokes, it's possible to reproduce them in a form that can be edited freely by hand in a way that is more natural. It allows the user to create documents with a realistic look that captures their handwriting style, rather than simply a collection of text. This representation allows the user to later inspect, modify or complete their handwritten notes, which gives their notes enhanced durability, seamless organization and integration with other digital content (images, text, links) or digital assistance.</p><p data-block-key="durd6">For these reasons, this field has gained significant interest in both <a href="https://arxiv.org/abs/2009.04284" target="_blank" rel="noopener noreferrer">academia</a> and <a href="https://support.gingerlabs.com/hc/en-us/articles/5044440428570-Image-to-Ink-Conversion" target="_blank" rel="noopener noreferrer">industry</a>, with software solutions that digitize handwriting and hardware solutions that leverage <a href="https://us.livescribe.com/" target="_blank" rel="noopener noreferrer">smart pens</a> or <a href="https://getrocketbook.com/" target="_blank" rel="noopener noreferrer">special paper</a> for capture. The need for additional hardware and accompanying software stack is, however, an obstacle for wider adoption, as it creates both onboarding friction and carries additional expense for the user.</p><p data-block-key="fdelg">With this in mind, in “<a href="https://arxiv.org/abs/2402.05804" target="_blank" rel="noopener noreferrer">InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write</a>”, we propose an approach to derendering that can take a picture of a handwritten note and extract the strokes that generated the writing without the need for specialized equipment. We also remove the reliance on typical geometric constructs, where gradients, contours, and shapes in an image are utilized to extract writing strokes. Instead, we train the model to build an understanding of “reading”, so it can recognize written words, and “writing”, so it can output strokes that resemble handwriting. This results in a more robust model that performs well across diverse scenarios and appearances, including challenging lighting conditions, occlusions, etc. You can access the model and the inference code on our <a href="https://github.com/google-research/inksight/" target="_blank" rel="noopener noreferrer">GitHub repo</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
        
            
                <h2>Overview</h2>
            
        
        
            <p data-block-key="69haq">The key goal of this approach is to capture the stroke-level trajectory details of handwriting. The user can then store the resulting strokes in the note taking app of their choice.</p>
        
    </div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="4vw5g">Under the hood, we apply an off the shelf OCR model to identify handwritten words, then use the model to convert them to strokes. To foster reproducibility, reusability, and ease of adoption, we combine the widely popular and readily available <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener noreferrer">ViT</a> encoder with an <a href="https://arxiv.org/abs/2010.11934" target="_blank" rel="noopener noreferrer">mT5</a> encoder-decoder.</p>

    </div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Challenges</h2>
            
        
        
    </p>



    <p data-block-key="4vw5g">While the fundamental concept of derendering appears straightforward — training a model that generates digital ink representations from input images — the practical implementation for arbitrary input images presents two significant challenges:</p><ol><li data-block-key="jn7b"><i>Limited Supervised Data:</i> Acquiring paired data with corresponding images and ground truth digital ink for supervised training can be expensive and time-consuming. To our knowledge, no datasets with sufficient variety exist for this task.</li><li data-block-key="5khqr"><i>Scalability to large images:</i> The model must effectively handle arbitrarily large input images with varying resolutions and amount of content.</li></ol>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Method</h2>
            
        
        
    </p>



    
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Learning to read and write</h3>
            
        
        
    </p>



    <p data-block-key="4vw5g">To address the first problem while avoiding onerous data collection, we propose a multi-task training setup that combines recognition and derendering tasks. This enables the model to generalize on derendering tasks with various styles of images as input, and injects the model with both semantic understanding and knowledge of the mechanics of writing handwritten text.</p><p data-block-key="9d2mr">This approach thus differs from methods that rely on geometric constructs, where gradients, contours, and shapes in an image are utilized to extract writing strokes. Learning to read enhances the model's capability in precisely locating and extracting textual elements from the images. Learning to write ensures that the resulting vector representation, the digital ink, closely aligns with the typical human approach of writing in terms of physical dynamics and the order of strokes. Combined, these allow us to train a model in the absence of large amounts of paired samples, which are difficult to obtain.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>System workflow</h3>
            
        
        
    </p>



    <p data-block-key="4vw5g">One solution to the problem of scalability is to train a model with very high-resolution input images and very long output sequences. However, this is computationally prohibitive. Instead, we break down the derendering of a page of notes into three steps: (1) OCR to extract word-level bounding boxes, (2) derendering each of the words separately, and (3) replacing the offline (pixel) representation of the words with the derendered strokes using the color coding described above to improve visualization.</p><p data-block-key="eq6q1">To narrow the domain gap between the synthetic images of rendered inks and the real photos, we augment the data in tasks that take rendered ink as input. Data augmentation is done by randomizing the ink angle, color, stroke width, and by adding Gaussian noise and cluttered backgrounds.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Vision-language model for digital ink</h2>
            
        
        
    </p>



    <p data-block-key="4vw5g">We create a training mixture that comprises five different task types. The first two tasks are derendering tasks (i.e., they generate a digital ink output). One uses only an image as input and the other uses both an image and the accompanying text that has been recognized by the OCR model. The following two tasks are recognition tasks that produce text output, the first of which leverages real images and the latter, synthetic ones. Finally, a fifth task is a combination of recognition and derendering, hence a mixed task with text-and-ink output.</p><p data-block-key="2aaog">Each type of task utilizes a task-specific input text, enabling the model to distinguish between tasks during both training and inference. Below you will find a recognition and a derendering task.</p>
</div>

                    
                    
    




                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="4vw5g">To train the system, we pair images of text and corresponding digital ink. The digital ink is sampled from real-time writing trajectories and subsequently represented as a sequence of strokes. Each stroke is represented by a sequence of points, obtained by sampling from the writing or drawing trajectory at a constant rate (e.g., 50 points per second). The corresponding image is created by rendering the ink - creating a bitmap at a prespecified resolution. This creates a pixel-stroke correspondence, that is a precursor for the model input-output pairs.<br></p><p data-block-key="5caji">A further necessary step, and a unique one for this modality, is the ink tokenizer, which represents the points in a format that is friendly to a large language model (LLM). Each point is converted into two tokens, one each encoding its <i>x</i> and <i>y</i> coordinates. The token sequence for this ink begins with <i>b</i>, signifying the beginning of the stroke, followed by the tokens for the coordinates of the sampled points.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Results</h2>
            
        
        
    </p>



    <p data-block-key="4vw5g">To evaluate the performance of our approach, we first collected an evaluation dataset. We started with OCR data, and then added paired samples that we collected manually by asking people to trace text images they were shown (human-generated traces).</p><p data-block-key="bfisu">We then trained three variants of the model: Small-p (∼340M parameters, “-p” for “public” setup), Small-i (“-i” for “in-house”), and Large-i (∼1B parameters). We compared our approach to a <a href="https://esslab.jp/publications/HaoranSIGRAPH2021.pdf" target="_blank" rel="noopener noreferrer">General Virtual Sketching</a> (GVS) baseline.</p><p data-block-key="eh6dt">We show that the vector representations produced by our system are both semantically and geometrically similar to the input images, and are similar to human-generated digital ink data, as measured by both automatic and human evaluations.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Qualitative evaluation</h3>
            
        
        
    </p>



    <p data-block-key="4vw5g">We show the performance of our models and GVS compared to two public evaluation datasets, <a href="https://fki.tic.heia-fr.ch/databases/iam-handwriting-database" target="_blank" rel="noopener noreferrer">IAM</a> and <a href="https://paperswithcode.com/dataset/imgur5k" target="_blank" rel="noopener noreferrer">IMGUR5K</a>, and an out of domain dataset of sketches. Our models mostly produce results that accurately reflect the text content, disregarding semantically irrelevant background. They can also handle occlusions, highlighting the benefit of the learned reading prior. In contrast, GVS produces multiple duplicate strokes and has difficulty distinguishing between background and foreground. Our Large-i model is further able to retain more details and accommodate more diverse image styles. See the <a href="https://arxiv.org/abs/2402.05804" target="_blank" rel="noopener noreferrer">paper</a> for more examples.</p>
</div>

                    
                    
    




                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Quantitative evaluation</h3>
            
        
        
    </p>



    <p data-block-key="4vw5g">At present, the field has not established metrics or benchmarks for quantitative evaluation of this task. So, we conduct both human and automated evaluation to compare the similarity of our model output to the original image and to human-generated digital inks.</p><p data-block-key="cf74k">Here we present the human evaluation results, with numerous other results derived from automated evaluations and an ablation study in our <a href="https://arxiv.org/abs/2402.05804" target="_blank" rel="noopener noreferrer">paper</a>. We performed a human evaluation of the quality of the derendered inks produced by the three model variants. We used the “golden” human traced data from the <a href="https://github.com/google-research-datasets/hiertext" target="_blank" rel="noopener noreferrer">HierText dataset</a> as the control group and the output of our model on these samples as the experimental group.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="4vw5g">In the figure above, notice the error in the quote for all models on the top row (the double-quote mark), which the human tracing got correct. On the bottom row the situation is reversed, with the human tracing focusing solely on the main word, missing most other elements. The human tracing is also not perfectly aligned with the underlying image, emphasizing the complexity and tracing difficulty of the handwritten parts of the HierText dataset.</p><p data-block-key="2qlkk">Evaluators were shown the original image alongside a rendered digital ink sample, which was either model-generated or human-traced (unknown to the evaluators). They were asked to answer two questions: (1) Is the digital ink output a reasonable tracing of the input image? (Answers: “Yes, it’s a good tracing,” “It’s an okay tracing, but has some small errors,” “It’s a bad tracing, has some major artifacts.”) (2) Could this digital ink output have been produced by a human? (Answers: “Yes” or “No”.) The evaluation included 16 individuals familiar with digital ink, but not involved in this research. Each sample was evaluated by three raters and aggregated with majority voting.</p>
</div>

                    
                    
    




                    
                    
    


<div>
        
  <p data-block-key="4vw5g">The results show that a majority of derendered inks, generated with the Large-i model perform about as well as human-generated ones. Moreover 87% of the Large-i outputs are marked as good or having only small errors.</p>

    </div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Conclusion</h2>
            
        
        
    </p>



    <p data-block-key="4vw5g">In this work we present a first-of-its-kind approach to convert photos of handwriting into digital ink. We propose a training setup that works without paired training data. We show that our method is robust to a variety of inputs, can work on full handwritten notes, and generalizes to out-of-domain sketches to some extent. Furthermore, our approach does not require complex modeling and can be constructed from standard building blocks.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Acknowledgements</h2>
            
        
        
    </p>



    <p data-block-key="4vw5g"><i>We want to thank all the authors of this work,</i> <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rak,+A" target="_blank" rel="noopener noreferrer"><i>Arina Rak</i></a><i>,</i> <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schnitzler,+J" target="_blank" rel="noopener noreferrer"><i>Julian Schnitzler</i></a><i>, and</i> <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+C" target="_blank" rel="noopener noreferrer"><i>Chengkun Li</i></a><i>, who formed a student team working with Google Research for the duration of the project, as well as Claudiu Musat, Henry Rowley and Jesse Berent. All authors, with the exception of the student team, are now part of Google Deepmind.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why so few Matt Levines? (224 pts)]]></title>
            <link>https://gwern.net/matt-levine</link>
            <guid>41975993</guid>
            <pubDate>Mon, 28 Oct 2024 20:37:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gwern.net/matt-levine">https://gwern.net/matt-levine</a>, See on <a href="https://news.ycombinator.com/item?id=41975993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-metadata">
        
        <p>Why are popularizing educational newsletter-frequency writers of important fields like Matt Levine for finance so rare? Because most fields are too slow or ambiguous, and writers of the right combination of expertise, obsession, and persistence are also rare.</p>
        
      </div><div id="markdownBody">
        
        <p><a href="https://en.wikipedia.org/wiki/Matt_Levine_(columnist)" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-html="https://en.m.wikipedia.org/wiki/Matt_Levine_(columnist)#bodyContent" title="Matt Levine (columnist)">Matt Levine</a> is the most well-known newslettrist (<a href="https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine" id="levine-2024" data-link-icon="𝐁" data-link-icon-type="text" title="‘Matt Levine, Bloomberg Opinion Columnist’, Levine 2024">“Money Stuff”</a>) in the financial industry, having blogged or written since <span>2011<sub><span title="2011 was 13 years ago.">13ya</span></sub></span>, finding his niche in popularization after stints in Wall Street &amp; law. His commentary is influential, people leak to him, he sometimes interviews major figures (notoriously, Sam Bankman-Fried) or recounts inside information, and a number of phrases like his “laws of insider trading” (specifically, how not to) have gained currency to the point where readers can now do much of the work of sourcing an issue for him.</p>
        <p>He is read by hundreds of thousands of readers (including myself)—everyone from shoeshine boy to billionaire. The size of his audience is respectable, but perhaps its most remarkable feature is that many of those readers have nothing to do with the financial industry. Though his newsletter is officially a Bloomberg News newsletter which he simply writes, many of his readers will visit Bloomberg solely for him, and indeed, might have little idea who or what a Bloomberg is. Nevertheless, readers loyally tune in for each installment every few days to learn about arcane financial instruments they have never heard of before, and (except for Levine) never will again.</p>
        <p>One might ask (and indeed, a billionaire once did), “where are the other Matt Levines?” or <a href="https://www.reddit.com/r/slatestarcodex/comments/hze13t/who_are_the_matt_levines_of_other_fields/" data-link-icon="reddit" data-link-icon-type="svg" data-url-html="https://old.reddit.com/r/slatestarcodex/comments/hze13t/who_are_the_matt_levines_of_other_fields/">“who are the Matt levines of other fields?”</a> That is, where are the Matt Levines of, say, chemistry or drug development<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>, who explain &amp; popularize other major industries which are vital to modern life, directly or indirectly appear in the news often, and yet people are widely ignorant of it, and deeply misunderstand its fundamental dynamics? Why don’t we have a Matt Levine for every industry? Where is the Levine of, I don’t know, petroleum refining or fracking, of shipping containers? Are we just in need of a good list of recommendations? Or could we just set up a prize to coax out some potential Levines in other industries?</p>
        <div>
          <blockquote>
            <p>When I first met Matt, the first thing I said was “Matt Levine, only you can do what you do!”</p>
            <p><a href="https://marginalrevolution.com/marginalrevolution/2024/09/sunday-assorted-links-488.html" id="cowen-2024" data-link-icon="M𝐑" data-link-icon-type="text" title="'Sunday assorted links', Tyler Cowen 2024-09-29">Tyler Cowen</a></p>
          </blockquote>
        </div>
        <p>My pessimistic conclusion is that Matt Levines are not made, they are born, and that the Matt Levine formula is largely irreproducible: there are few industries where it makes sense, and there are few people suited for this job, and that is the simple answer why there are not many Levines.</p>
        <p>So, what is the formula, exactly? The Matt Levine formula is weighty matters, leavened by humor, with basic explanations of complicated financial matters. As Levine has been doing this online for so long (~13 years), relatively speaking, he can often refer to his previous coverage and comment on how things turned out. Certain themes repeat periodically so often that they receive their own catchphrases, like “worries about bond market liquidity” or the laws of insider trading.</p>
        <p>Many people owe most of what they know about stock trading, bonds, arcane but controversial matters like naked shorts, meme stocks etc to Levine; and I would be embarrassed to admit how much of my economics knowledge comes through Levine rather than some more rigorous source like my old economics textbooks. This is because Levine provides 3 key ingredients which foster learning:</p>
        <ol>
          <li>
            <p>cases with <strong>known outcomes/answers</strong>: to develop expertise in a subject, the subject ideally provides many problems, with known answers, of high accuracy. Most subjects do <em>not</em>. But Levine’s subject (finance &amp; law) does.</p>
            <p>A good subject for developing expertise is something like chess: an endless number of chess games can be played rapidly, they all have a clear outcome (win/draw/loss), and one can study each one carefully to understand what went right or wrong. A bad subject is something like military strategy: there are not many large-scale wars which have been documented adequately, each war is unique and unrepeatable and a general may participate in only a few in a lifetime, and the outcomes (never mind any individual’s contribution) are often difficult or impossible to judge. Many areas are more like military strategy than chess—how do you judge the expertise of a CEO, or a Hollywood director, or a scientist forecasting the distant future?</p>
            <p>Levine works in an area which <em>does</em> provide many clearcut examples, because he focuses on lawsuits, prosecutions, crimes, and deals. These are examples where the outcome will usually be known in a few years, at most, or at least a major update/development, and where the involved parties do all the research necessary, and where the evidence is often completely unambiguous—Levine just has to read their filings, and excerpt the text message where someone boasts about their insider trading in no uncertain terms.</p>
            <p>In relying on reporting &amp; filings for his commentary, Levine is very much like the dying local newspaper crime reporter, who relies on the police blotter &amp; courtroom access to rapidly file their articles. These articles are nearly endless, and mostly forgettable because there are, broadly speaking, not really any <em>principles</em> governing local crime. “Some guy got drunk and into a fight and killed another guy” is something that happens frequently, but it illuminates no universal principle; it sheds no light on anything else. It was just something horrible that often happens at random when people take dangerous drugs like alcohol rather than safe ones like <a href="https://gwern.net/nicotine" id="gwern-nicotine" title="'Nicotine', Gwern 2011">nicotine</a>, and is of no broader importance; true-crime addicts consume it for its entertainment value, like darker versions of Hollywood tabloids—“who murdered who” instead of “who’s sleeping with who”. It’s just “one d—n thing after another”. (The TV show <a href="https://en.wikipedia.org/wiki/Cops_(TV_program)" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-html="https://en.m.wikipedia.org/wiki/Cops_(TV_program)#bodyContent" title="Cops (TV program)"><em>Cops</em></a> has run for 36 years now, and could run for another 36 years without breaking a sweat, but after 72 seasons, what would you have <em>learned</em> that you didn’t learn after the first few?)</p>
            <p>But in Levine’s area, this is not the case. Many of these examples are due to highly intelligent, motivated, competent people and organizations clashing for deep reasons. This means that to understand them, you need…</p>
          </li>
          <li>
            <p><strong>first-principles explanations</strong>: most people experience an “illusion of depth”, in that they believe they understand the causal mechanics of an area far better than they do. But in fact, they have learned only a superficial model of the area. Levine corrects this.</p>
            <p>Particularly in economic matters, people believe many intuitive folk economics like eg. building new houses cannot lower prices, or that businesses raise prices simply “when they feel greedy”, or that voluntary transactions must have a loser &amp; a winner when other people transact (but not themselves personally), or that a policy will have only intended effects because everyone will just do what they are ordered to (even though they personally work around policies or rules all the time for doubtless noble reasons).</p>
            <p>Levine patiently gives from first-principles (supply-and-demand, market efficiency &amp; adverse selection, people following incentives, <a href="https://en.wikipedia.org/wiki/Public_choice" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-html="https://en.m.wikipedia.org/wiki/Public_choice#bodyContent" title="Public choice">public choice theory</a>) explanations of why some thing about markets or contracts is the way it is, how it operated (or failed to operate) in a particular case, and what (and why) the various counterfactual future outcomes are.</p>
            <p>These repeated explanations—however simplified and abstracted—gradually build up genuine knowledge which can transfer to the real world beyond some crammed supply-and-demand schematics in a long-forgotten economics class.</p>
          </li>
          <li>
            <p><a href="https://gwern.net/spaced-repetition" id="gwern-spaced-repetition" title="‘Spaced Repetition for Efficient Learning’, Gwern 2009">spaced repetition</a> enabled by <strong>fast turnover</strong>: a newsletter is inherently spaced in time, and by returning to themes repeatedly, with various twists or instantiations, the reader learns due to the spacing effect.</p>
            <p>In normal news consumption, as opposed to the drip-feed of a columnist on a steady beat, one might read about some instance of financial malfeasance in great depth in the <em>WSJ</em> or <em>NYT</em>, say—but once.</p>
            <p>This coverage might be extremely high quality, but nevertheless, such “massed presentation” is a recipe for forgetting. It is like cramming flashcards the night before the test: no matter how good the flashcards are or how much you remember while taking the test, most of it will be forgotten.</p>
            <p>However, in Levine’s case, even if specific cases or events resolve quickly, the same principle will show up again soon enough.</p>
          </li>
        </ol>
        <p>So, that is the Levine formula: the global economy furnishes him many rapidly-resolved examples which he can use to entertainingly illustrate basic principles of economics, and by doing that so regularly over so long, readers gain a genuine durable education in economics which they will remember and where they can apply those principles on their own.</p>
        <p>Analyzed into parts, we can see why many areas cannot support a Levine: they lack one of the 3 ingredients:</p>
        <ul>
          <li>
            <p>Crime reporting covers crimes which are numerous and rapidly-resolved, but there is not much to learn.</p>
          </li>
          <li>
            <p>Logistics like fracking or oil or containers may cover many cases which have broad principles, but those cases are often resolved in secrecy and due to the extreme boom-bust cycle of those industries, may take decades to ‘mature’ (eg. an over-extended oil company might not go bust for decades depending on how exactly cycles play out).</p>
          </li>
          <li>
            <p>And areas like drug development may be cursed by all 3: drug development often ends in failure for unknown reasons, in the dark, decades later, and what reasons are known may be totally idiosyncratic to a specific drug or disease; what is known may be at best a loose rule of thumb.</p>
            <p>It would be nice to have a blog like Matt Levine covering, say, evolutionary biology or Greco-Roman philosophy, but it’s obvious why that isn’t going to work—you can’t have a very entertaining <em>news</em>letter when it might take centuries for a debate to resolve, if anyone can agree it was resolved at all, and you certainly aren’t going to be able to provide so many clear illustrations of basic principles that reading the newsletter constitutes an education. (You can read &amp; learn about them, but their natural form would be, well, a textbook or a monograph or something like that, and definitely not a newsletter.)</p>
            <p>And most areas are more like drug development than they are like hedge funds suing each other over some contractual gimmick or clerical error.</p>
          </li>
        </ul>
        <p>OK, but surely there are still plenty of areas where the preconditions are met? (Particularly rapidly-developing ones, like cryptocurrency or AI recently?) So where are <em>their</em> Matt Levines?</p>
        <p>This brings us to the second half of the equation of the Matt Levine formula: the Matt Levine part.</p>
        <p>Consider the implication of the 3 requirements for the <em>author</em>, rather than the reader: they are going to see the same human comedies play out, again and again, and have to shout it into the void again, only to watch it happen yet again. The author feels the weight of the repetition far more than any reader does.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> It is like a teacher who must teach the same curriculum for the 30<sup>th</sup> time—and again read &amp; grade each of dozens of assignments on it by hundreds of students.</p>
        <p>It is not every person who can do so well, or at all. Often a great expert will make a terrible teacher, because they are unable to endure the repetition, or understand the ignorance of the beginner, or treat the floundering student with kindness.</p>
        <p>I personally appreciate Levine’s <a href="https://slatestarcodex.com/2013/06/30/the-lottery-of-fascinations/" data-link-icon="SSC" data-link-icon-type="text,tri" title="The Lottery of Fascinations">permanent fascination with finance</a>, his willingness to explain the same things over and over. But I don’t think I (or most people) would be able to do so for a long time without turning it into a dull ticket-punching exercise as part of a mundane job rather than <em>an avocation</em>; and indeed, I have shunned my opportunities to become a Levine of some area, when I felt my interest &amp; patience for fools rapidly waning. (Particularly darknet markets: there was considerable demand for commentators like Eileen Ormsby or DeepDotWeb, but I could see no new principles to maintain my interest and just an endless infosec churn of temporary trivia—a warning that burnout was approaching—and quit the area while I was ahead.)</p>
        <p>Indeed, expertise is a reason to stop teaching entirely: if you are really interested in an area, and good at it (good enough to understand and commentate ongoing events), then even if you are a great teacher who is gifted at explaining the area to laymen, why would you settle for teaching <em>about</em> it instead of <em>doing</em> it? But if you do it, then you will struggle to write about it regularly publicly: actually doing something, instead of reading a court summary of it, can take years of hard work, and prohibit you from writing about it in various ways. (It will also usually pay much worse—Matt Levine is doubtless compensated handsomely by Bloomberg, but perhaps not as handsomely as if he had kept rising through Big Law, and superstar outcomes imply most would-be newslettrists are paid peanuts.)</p>
        <p>So you have a serious problem: anyone good enough to be ‘the Matt Levine of an area’ is also under considerable pressure to <em>not</em> be him.</p>
        <p>Why would anyone want to? Well, if you ask someone like <a href="https://en.wikipedia.org/wiki/Richard_Feynman" data-link-icon="wikipedia" data-link-icon-type="svg" data-url-html="https://en.m.wikipedia.org/wiki/Richard_Feynman#bodyContent" title="Richard Feynman">Richard Feynman</a> or Andrej Karpathy or Tom Lehrer why they pursued pedagogy instead of the professional pursuits that brought them fame &amp; wealth, the answer would have to be that “they love to teach”. Which is a fine reason, but a passion for teaching a particular subject is far from common.</p>
        <p>So you have a filter with many layers: you need areas which fulfill a stringent set of conditions for such an educational newsletter, and you need a very unusual sort of individual, someone who is expert in the area and has preferably gotten their hands dirty, who is good enough to work professionally in it, but who also is capable of explaining it well, at a beginner level, many times, endlessly without burning out or getting bored, because of their intense interest in the area (but again, not quite intense enough to make them go do it instead of write about it).</p>
        <p>Each step here filters out most candidates, and by the end, there’s just not that much left. You can’t fix these filters easily. No prize or Substack tweak will suddenly make drug discovery happen fast and fail for clear reasons, or conjure up a Levine in a specific area when you want one.</p>
        <p>So, that’s why there are so few Matt Levines, and explains where the other Matt Levines are: they don’t, and usually can’t, exist.</p>
        <section id="footnotes" role="doc-endnotes">
          <hr>
          <ol>
            <li id="fn1">
              <p>While I enjoy <a href="https://www.science.org/blogs/pipeline" data-link-icon="S" data-link-icon-type="text">Derek Lowe</a>, the extent to which his posts are inside-baseball and do not repeat themes, or only repeat many years apart, emphasize the contrast with Levine.<a href="#fnref1" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn2">
              <p>I know as an author, one thing that has surprised me is the extent to which you have to repeat something before a reader will remember it, in large part because they never read it in the first place. I often feel exhausted by discussing something, and feel like I must look like a crank ranting on about an obsession and thoroughly worn out my readers’ tolerance, when a reader says they just heard of it for the first time. This is because as an author, you know every time you wrote about something, across all the years, but a reader may well have read <em>none</em> of them. So if you repeat yourself only as often as you can bear to, you have usually fallen short of the mark.<a href="#fnref2" role="doc-backlink">↩︎</a></p>
            </li>
          </ol>
        </section>
        <section id="similars-section">
          <h2><a href="#similars-section" title="Link to section: § 'Similar Links'">Similar Links</a></h2><a id="similars" href="https://gwern.net/metadata/annotation/similar/%252Fmatt-levine.html" title="Similar links for this link (by text embedding). Lazily-transcluded version at footer of page for easier scrolling." data-link-icon="≈" data-link-icon-type="text">[Similar links by topic]</a>
        </section>
        <section id="link-bibliography-section">
          <h2><a href="#link-bibliography-section" title="Link to section: § 'Bibliography'">Bibliography</a></h2><!-- NOTE: In theory, '.collapse' on a '<h1>' is redundant with the '<section>'; but added to parallel Pandoc-generated headers which set all attributes/classes on both. -->
          <a id="link-bibliography" href="https://gwern.net/metadata/annotation/link-bibliography/%252Fmatt-levine.html" title="Bibliography of links cited in this page (forward citations). Lazily-transcluded version at footer of page for easier scrolling." data-link-icon="bibliography" data-link-icon-type="svg">[Bibliography of links/references used in page]</a>
        </section>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Improving Xwayland window resizing (126 pts)]]></title>
            <link>https://blog.vladzahorodnii.com/2024/10/28/improving-xwayland-window-resizing/</link>
            <guid>41975741</guid>
            <pubDate>Mon, 28 Oct 2024 20:18:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.vladzahorodnii.com/2024/10/28/improving-xwayland-window-resizing/">https://blog.vladzahorodnii.com/2024/10/28/improving-xwayland-window-resizing/</a>, See on <a href="https://news.ycombinator.com/item?id=41975741">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1217">
	
	<!-- .entry-header -->

	<div>
		
<p>One of the quickest ways to determine whether particular application runs using Xwayland is to resize one of its windows and see how it behaves, for example</p>



<figure></figure>



<p>While it can be handy for the debugging purposes, overall, it makes the Plasma Wayland session look less polished. So, one of the goals for 6.3 was to fix this visual glitch.</p>



<p>This article will provide some background behind what caused the glitch and how we addressed it. Just in case, here’s the same application, which was shown in a screen cast above, but with the corresponding resizing fixes in:</p>



<figure></figure>



<h2>X11 frame synchronization protocol(s)</h2>



<p>On X11, all window changes typically take place immediately, including resizing. This can lead to some issues. For example, if a window is resized, it can take a while until the application repaints the window with the new size. What if the compositing manager decides to compose the screen in meanwhile? You’re likely going to see some sort of visual glitches, e.g. the window contents getting cropped or seeing parts of the window that have not been repainted yet.</p>



<p>In order to address this issue, there exists an X11 protocol to synchronize window repaints during interactive resize. An application/client wishing to participate in this protocol needs to list <code>_NET_WM_SYNC_REQUEST</code> in the <code>WM_PROTOCOLS</code> property of the client window and also set the <code>XID</code> of the XSync counter in the <code>_NET_WM_SYNC_REQUEST_COUNTER</code> property. When the WM wants to resize the window, the following will happen:</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="660" height="463" data-attachment-id="1218" data-permalink="https://blog.vladzahorodnii.com/2024/10/28/improving-xwayland-window-resizing/basic-sync/" data-orig-file="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?fit=2254%2C1582&amp;ssl=1" data-orig-size="2254,1582" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="basic-sync" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?fit=300%2C211&amp;ssl=1" data-large-file="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?fit=660%2C463&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=660%2C463&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=1024%2C719&amp;ssl=1 1024w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=300%2C211&amp;ssl=1 300w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=768%2C539&amp;ssl=1 768w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=1536%2C1078&amp;ssl=1 1536w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=2048%2C1437&amp;ssl=1 2048w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=1200%2C842&amp;ssl=1 1200w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?resize=388%2C272&amp;ssl=1 388w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?w=1320&amp;ssl=1 1320w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/basic-sync.png?w=1980&amp;ssl=1 1980w" sizes="(max-width: 660px) 100vw, 660px"></figure>



<ol>
<li>The window manager sends a <code>_NET_WM_SYNC_REQUEST</code> client message containing a serial that the client will need to put in the XSync counter after processing a <code>ConfigureNotify</code> event that will be generated after the window is resized. The compositing manager and the window manager will block window updates until the XSync request acknowledgement is received;</li>



<li>The WM resizes the client window, for example by calling the <code>xcb_configure_window()</code> function;</li>



<li>The client would then repaint the window with the new size and update the XSync counter with the serial that it had received in step 1;</li>



<li>The window manager and the compositing manager unblock window updates after receiving receiving the XSync request acknowledgement. For example, now, the window can be repainted by the compositing manager and there shouldn’t be glitches as long as the client behaves well.</li>
</ol>



<p>Note that the window manager and the compositing manager are often the same. For example, both KWin and Mutter are compositing managers <em>and</em> window managers.</p>



<p>The frame synchronization protocol described above is called <em>basic frame synchronization</em> protocol. There is also an <em>extended frame synchronization</em> protocol, but it is not standardized and it is implemented only by a few compositing managers.</p>



<h2><code>_NET_WM_SYNC_REQUEST</code> and Xwayland</h2>



<p>KWin supports the basic frame synchronization protocol, so there should be no visual glitches when resizing X11 windows in the Plasma Wayland session, right? At quick glance, yes, but we forget about the most important detail: Wayland compositors don’t use <code>XCompositeNameWindowPixmap()</code> or <code>xcb_composite_name_window_pixmap()</code> to grab the contents of X11 windows, instead they rely on Xwayland attaching graphics buffers to <code>wl_surface</code> objects, so there is no strict order between the Wayland compositor receiving an XSync request acknowledgement and graphics buffers for the new window size.</p>



<p>In order to help better understand the issue, let’s consider a concrete example. Assume that a window with geometry <code>0,0 100x100</code> is being resized by dragging its left edge. If the left edge is dragged <code>10</code>px to the right, the following will happen:</p>



<ol>
<li>A <code>_NET_WM_SYNC_REQUEST</code> client message will be sent to the client containing the XSync counter serial that must be set after processing the <code>ConfigureNotify</code> event that will be generated after the Wayland compositor calls <code>xcb_configure_window()</code> with the new window size;</li>



<li>The Wayland compositor calls <code>xcb_configure_window()</code> to actually resize the window;</li>



<li>The client receives the sync request client message and the ConfigureNotify event, repaints the window, and acknowledges the sync request;</li>



<li>The Wayland compositor receives the sync request acknowledgement and updates the window position to <code>10,0</code>.</li>
</ol>



<p>But here is the problem, when the window position is updated to 10,0, it’s not guaranteed that the <code>wl_surface</code> associated with the X11 window has a buffer with the new window size, i.e. <code>90x100</code>. It can take a while until Xwayland commits a graphics buffer with the right size. In meanwhile, the compositor could compose the next frame with the new window position, i.e. <code>10,0</code>, but old surface size, i.e. <code>100x100</code>. It would look as if the right window edge sticks out of the window decoration. After Xwayland attaches a buffer with the right size, the right window edge will correct itself.</p>



<p>So, ideally, the Wayland compositor should update the window position after receiving the XSync request acknowledgement <em>and</em> Xwayland attaching a new graphics buffer to the <code>wl_surface</code>.</p>



<p>With that in mind, the frame synchronization procedure looks as follows:</p>



<figure><img data-recalc-dims="1" decoding="async" width="660" height="628" data-attachment-id="1219" data-permalink="https://blog.vladzahorodnii.com/2024/10/28/improving-xwayland-window-resizing/new-sync/" data-orig-file="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?fit=2232%2C2122&amp;ssl=1" data-orig-size="2232,2122" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="new-sync" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?fit=300%2C285&amp;ssl=1" data-large-file="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?fit=660%2C628&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=660%2C628&amp;ssl=1" alt="" srcset="https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=1024%2C974&amp;ssl=1 1024w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=300%2C285&amp;ssl=1 300w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=768%2C730&amp;ssl=1 768w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=1536%2C1460&amp;ssl=1 1536w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=2048%2C1947&amp;ssl=1 2048w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=1200%2C1141&amp;ssl=1 1200w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?resize=286%2C272&amp;ssl=1 286w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?w=1320&amp;ssl=1 1320w, https://i0.wp.com/blog.vladzahorodnii.com/wp-content/uploads/2024/10/new-sync.png?w=1980&amp;ssl=1 1980w" sizes="(max-width: 660px) 100vw, 660px"></figure>



<ol>
<li>The compositor blocks <code>wl_surface</code> commits by setting the <code>_XWAYLAND_ALLOW_COMMITS</code> property to <code>0</code> for the toplevel X11 window. This is needed to ensure the consistent order between XSync request acknowledgements and <code>wl_surface</code> commits. As long as the <code>_XWAYLAND_ALLOW_COMMITS</code> property is set to <code>0</code>, Xwayland will not attempt to commit the wayland surface, for example attach a new graphics buffer after the client repaints the window;</li>



<li>The compositor sends a <code>_NET_WM_SYNC_REQUEST</code> client message as before;</li>



<li>The compositor resizes the client window as before;</li>



<li>The client repaints the window and acknowledges the XSync request as before;</li>



<li>After receiving the XSync acknowledgement, the compositor unblocks surface commits by setting the <code>_XWAYLAND_ALLOW_COMMITS</code> property to <code>1</code>. Note that the window updates are still blocked, i.e. the window position is not updated yet;</li>



<li>After Xwayland commits the <code>wl_surface</code> with a new graphics buffer, the window updates are unblocked, e.g. the window position is updated.</li>
</ol>



<p>The frame synchronization process looks more involved with Xwayland, but it is still manageable.</p>



<h2><code>_NET_WM_SYNC_REQUEST</code> support in applications</h2>



<p>Most applications that use GTK and Qt support <code>_NET_WM_SYNC_REQUEST</code>, but there are applications that don’t participate in the frame synchronization protocol. If you use one of those apps, you <strong>will observe visual glitches</strong> during interactive resize.</p>



<h2>Closing words</h2>



<p>Frame synchronization is a difficult problem, and requires some very intricate code both on the compositor and the client side. But with the changes that we’ve made, I’m proud to say that KWin is one of the few compositors that properly handles frame synchronization for X11 windows on Wayland!</p>

	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[200k subscribers flee 'Washington Post' after Bezos blocks Harris endorsement (117 pts)]]></title>
            <link>https://www.npr.org/2024/10/28/nx-s1-5168416/washington-post-bezos-endorsement-president-cancellations-resignations</link>
            <guid>41975395</guid>
            <pubDate>Mon, 28 Oct 2024 19:50:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/10/28/nx-s1-5168416/washington-post-bezos-endorsement-president-cancellations-resignations">https://www.npr.org/2024/10/28/nx-s1-5168416/washington-post-bezos-endorsement-president-cancellations-resignations</a>, See on <a href="https://news.ycombinator.com/item?id=41975395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="resg-s1-30387">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3500x2432+0+0/resize/1100/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc6%2F03%2F9840fe174ca8b214599dabf7423e%2Fap24073157209871.jpg" type="image/webp" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3500x2432+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc6%2F03%2F9840fe174ca8b214599dabf7423e%2Fap24073157209871.jpg" data-format="webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3500x2432+0+0/resize/1100/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc6%2F03%2F9840fe174ca8b214599dabf7423e%2Fap24073157209871.jpg" type="image/jpeg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3500x2432+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc6%2F03%2F9840fe174ca8b214599dabf7423e%2Fap24073157209871.jpg" data-format="jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3500x2432+0+0/resize/1100/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc6%2F03%2F9840fe174ca8b214599dabf7423e%2Fap24073157209871.jpg" alt="Owner Jeff Bezos blocked 'The Washington Post' from endorsing a presidential candidate less than two weeks before Election Day. The editorial board had drafted an endorsement for Kamala Harris." data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/3500x2432+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc6%2F03%2F9840fe174ca8b214599dabf7423e%2Fap24073157209871.jpg" data-format="jpeg">
        </picture>
</div>
<div>
    <div>
        <p>
                Owner Jeff Bezos blocked <em>The Washington Post</em> from endorsing a presidential candidate less than two weeks before Election Day. The editorial board had drafted an endorsement for Kamala Harris.
                <b aria-label="Image credit">
                    
                    Evan Agostini/Invision/AP
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Evan Agostini/Invision/AP
        
    </span>
</p></div>
   </div>
   <p><em>The Washington Post</em> has been rocked by a tidal wave of cancellations from digital subscribers and a series of resignations from columnists, as the paper grapples with the fallout of owner Jeff Bezos’s decision to block an endorsement of Vice President Kamala Harris for president.</p>   <p>More than 200,000 people had canceled their digital subscriptions by midday Monday, according to two people at the paper with knowledge of internal matters. Not all cancellations take effect immediately. Still, the figure represents about 8% of the paper’s paid circulation of 2.5 million subscribers, which includes print as well. The number of cancellations continued to grow Monday afternoon.</p>   
   <p>A corporate spokesperson declined to comment, citing The Washington Post Co.'s status as a privately held company.</p>   <p>“It’s a colossal number,” former <em>Post </em>Executive Editor Marcus Brauchli told NPR. “The problem is, people don’t know why the decision was made. We basically know the decision was made but we don’t know what led to it.”</p>   
   
<!-- END ID="RESNX-S1-5168416-100" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Chief Executive and Publisher Will Lewis <a href="https://www.npr.org/2024/10/25/nx-s1-5165353/washington-post-presidential-endorsement-trump-harris"><u>explained the decision</u></a> not to endorse in this year’s presidential race or in future elections as a return to the <em>Post</em>’s roots: It has for years styled itself an “independent paper.”</p>   <p>Few people inside the paper credit that rationale given the timing, however, just days before a neck-and-neck race between Harris and former President Donald Trump. </p>   <p>Former Executive Editor Marty Baron <a href="https://www.npr.org/2024/10/28/nx-s1-5166796/washington-post-decides-not-to-endorse-a-presidential-candidate">voiced that skepticism</a> in an interview with NPR's <em>Morning Edition</em> on Monday.</p>   <p>"If this decision had been made three years ago, two years ago, maybe even a year ago, that would've been fine," Baron said. "It's a certainly reasonable decision. But this was made within a couple of weeks of the election, and there was no substantive serious deliberation with the editorial board of the paper. It was clearly made for other reasons, not for reasons of high principle."</p>   
   <p><em>Post</em> reporters have revealed repeated instances of wrongdoing and allegations of illegality by Trump and his associates. The editorial page, which operates separately, has characterized Trump as a <a href="https://www.washingtonpost.com/opinions/2020/08/21/second-trump-term-might-injure-democratic-experiment-beyond-recovery/">threat to the American democratic experiment</a>. Several <em>Post&nbsp;</em>journalists say their relatives are among those canceling subscriptions.</p>   
   
<!-- END ID="RESNX-S1-5168416-101" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>The mass cancellations point “to the polarization of the times we’re living in, and the energy people feel about these issues,” Brauchli says. “This gave people a reason to act on this mood.”</p>   <p>Brauchli has publicly encouraged people not to cancel their <em>Post</em> subscriptions in protest.</p>   <p>“It is a way to send a message to ownership but it shoots you in the foot if you care about the kind of in-depth, quality journalism like the <em>Post</em> produces,” he said. “There aren’t many organizations that can do what the <em>Post </em>does. The range and depth of reporting by the <em>Post’s </em>journalists is among the best in the world.”</p>   <p>Even at the rival <em>New York Times</em>, with a much higher circulation level, a significant protest might register in the low thousands. Earlier this year, Lewis, the <em>Post </em>publisher, had touted the paper's net gain of 4,000 subscribers as noteworthy.</p>   <p>Three of the top 10 viewed stories on the <em>Post’s </em>website Sunday were articles written by <em>Post </em>staffers outraged by Bezos’ decision. The top one was humor columnist Alexandra Petri’s <a href="https://www.washingtonpost.com/opinions/2024/10/26/washington-post-endorses-kamala-harris-satire/"><u>piece</u></a>, headlined, “It has fallen to me, the humor columnist, to endorse Harris for president.” More than 174,000 people read it online.</p>   <h3>Resignations follow Bezos' decision</h3>   <p>The decision by Bezos, the billionaire founder of Amazon, was first reported by NPR on Friday. In the days since, two columnists have resigned from the paper and two writers have stepped down from the editorial board.</p>   <p>One of those writers, Molly Roberts, warned of the possible consequences of the eleventh-hour decision to stay quiet rather than publish the editorial endorsing Harris. "Donald Trump is not yet a dictator," she wrote in a statement <a href="https://x.com/mollylroberts/status/1850959925683351776">she posted on social media</a>. "But the quieter we are, the closer he comes."</p>   
   <p>The other writer is David Hoffman, who accepted a Pulitzer Prize for editorial writing on Thursday, the day before Bezos’ decision was made public. Pulitzer judges recognized him “for a compelling and well-researched series on new technologies and the tactics authoritarian regimes use to repress dissent in the digital age, and how they can be fought.”</p>   <p>“For decades, the Washington Post's editorials have been a beacon of light, signaling hope to dissidents, political prisoners and the voiceless,” David Hoffman wrote in a letter Monday explaining his decision to leave the editorial board. “When victims of repression were harassed, exiled, imprisoned and murdered, we made sure the whole world knew the truth.</p>   <p>“I believe we face a very real threat of autocracy in the candidacy of Donald Trump,” Hoffman added in his letter to Editorial Page Editor David Shipley, which was obtained by NPR. “I find it untenable and unconscionable that we have lost our voice."</p>   <p>Hoffman says he intends to remain at the paper, saying he "refuses to give up on The Post, where I have spent 42 years." He writes of being launched on several projects, including "the expanded effort to support press freedom around the world."</p>   <p>Shipley held a contentious meeting on Monday with scores of opinion section staffers, who posed tough questions to the editorial page chief, including appeals for Bezos to address them. </p>   <p>As recently as last week, according to a person present, Shipley said he sought to talk Bezos out of his decision. Shipley added, “I failed.”</p>   <h3>Questions about Bezos' timing and motives</h3>   <p>Former columnist Robert Kagan, an editor-at-large, explained his decision on CNN Friday night to resign from the paper. </p>   <p>“We are in fact bending the knee to Donald Trump because we're afraid of what he will do,” Kagan said, noting that officials from Bezos’ Blue Origin aerospace company <a href="https://apnews.com/live/2024-election-trump-harris-news-updates#00000192-c592-d7d8-a7be-efbf2ca80000">met with Trump</a> a few hours after the decision became public.</p>   
   <p>Blue Origin has a multi-billion dollar <a href="https://www.nasa.gov/news-release/nasa-selects-blue-origin-as-second-artemis-lunar-lander-provider/">contract with NASA</a>. During the Trump administration, Amazon sued the government after alleging it had blocked a <a href="https://www.npr.org/2021/07/06/1013420036/pentagon-scraps-10-billion-contract-with-microsoft-bitterly-contested-by-amazon">$10 billion cloud-computing-services contract </a>with the Pentagon over the then-president’s ire about coverage in the <em>Post</em>, which Bezos owns personally.</p>   <p>Yet Bezos resolutely supported the staff's coverage during the Trump presidency (and has not interfered with reporting on his own business interests or personal life).</p>   <p>“In Trump’s previous — and perhaps only — presidential term, at no point did Bezos flinch when it came to Trump,” Brauchli says. “So there’s no reason to think he is doing so on this.”</p>   <p>Bezos brought in Lewis as publisher and chief executive at the start of the year in part, according to people with knowledge of the process, because he had worked closely with powerful conservative figures and had appealed successfully to conservative audiences.</p>   
   
<!-- END ID="RESNX-S1-5168416-102" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Lewis had been editor of the <em>Telegraph</em> in the U.K., which is considered closely allied with the right wing of the Conservative party. He served as a top executive in London for Rupert Murdoch and became publisher and chief executive of his most prestigious title, the <em>Wall Street Journal</em>. After departing, he briefly became a consultant for the Conservative British Prime Minister Boris Johnson. </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We're forking Flutter (726 pts)]]></title>
            <link>https://flutterfoundation.dev/blog/posts/we-are-forking-flutter-this-is-why/</link>
            <guid>41975047</guid>
            <pubDate>Mon, 28 Oct 2024 19:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flutterfoundation.dev/blog/posts/we-are-forking-flutter-this-is-why/">https://flutterfoundation.dev/blog/posts/we-are-forking-flutter-this-is-why/</a>, See on <a href="https://news.ycombinator.com/item?id=41975047">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  

  <p>Over the years, Flutter has attracted millions of developers who built user interfaces across
every platform. Flutter began as a UI toolkit for mobile - iOS and Android, only. Then Flutter
added support for web. Finally, Flutter expanded to Mac, Windows, and Linux. Across this massive
expansion of scope and responsibility, the Flutter team has only marginally increased its size.
To help expand Flutter's available labor, and accelerate development, we're creating a fork
of Flutter, called Flock.</p>
<h2 id="flutters-labor-shortage">Flutter's labor shortage</h2>
<p>Let's do some back-of-the-napkin math to appreciate the Flutter team's labor shortage.</p>
<p>How many Flutter developers exist in the world, today? My guess is that it's on the order of
1,000,000 developers. The real number is probably higher, but one million should be reasonably
conservative.</p>
<p>How large is the Flutter team, today? Google doesn't publish this information, but my guess is
that the team is about 50 people strong.</p>
<p>That's 50 people serving the needs of 1,000,000. Doing a little bit of division, that means
that every single member of the Flutter team is responsible for the needs of 20,000 Flutter
developers! That ratio is clearly unworkable for any semblance of customer support.</p>
<p>A labor shortage can always be fixed through hiring. However, due to company-wide issues
at Google, the Flutter team's head count was frozen circa 2023, and then earlier in 2024
we learned of a small number of layoffs. It seems that the team may now be expanding again,
through outsourcing, but we're not likely to see the Flutter team double or quadruple its
size any time soon.</p>
<p>To make matters worse, Google's corporate re-focus on AI caused the Flutter team to
de-prioritize all desktop platforms. As we speak, the Flutter team is in maintenance mode
for 3 of its 6 supported platforms. Desktop is quite possibly the greatest untapped value
for Flutter, but it's now mostly stagnant.</p>
<h2 id="the-cost-of-limited-labor">The cost of limited labor</h2>
<p>Limited labor comes at a great cost for a toolkit that has rapidly expanded its user base, along
with its overall scope.</p>
<p>With so few developers to work on tickets, many tickets linger in the backlog. They can easily linger
for years, if they're ever addressed at all.</p>
<p>By the time a member of the Flutter team begins to investigate a ticket, the ticket might be years
old. At that point, the Flutter team developer typically asks for further information from the person
who filed the ticket. In my experience, when this happens to me, I've long since stopped working with
the client who had the initial issue. I've written hundreds of thousands of lines of code since then.
I often don't even remember filing the issue, let alone the obscure details related to the original
issue. The team can't fix the bug without information from me, and it's been too long for me to provide
information to the team. So the bug gets buried for a future developer to rediscover.</p>
<p>Timing isn't just an issue for eventually root causing and fixing bugs. It's also a major product
problem. Imagine that you're the engineering director, or CTO of a company whose next release is
blocked by some Flutter bug. What do you do if the team won't work on that bug for 2 years? Well,
if it's a serious bug for your company, then you stop using Flutter. You don't have a choice. You
need to keep moving forward. Your team doesn't know how to work on the Flutter framework, and the
Flutter framework team is either unresponsive, or at least completely non-committal towards a
fix. Oh well - can't use Flutter any more. Flutter won't survive if these kinds of experiences become
common.</p>

<p>Flutter has two very valuable qualities. First, it's open source, so any developer can see how
any part of Flutter is implemented, and can even change it. Second, the Flutter framework is
written in the same language as Flutter apps. Because of these two qualities, experienced Flutter
app developers, and package developers can contribute to the Flutter framework.</p>
<p>How many Flutter developers exist in the world today who are capable of contributing at a
productive level to the Flutter framework? Conservatively, I would guess there are about 1,000
of them. In other words, there are at least 1,000 Flutter developers in the world who could
conceivably be hired to the Flutter team, if the team wanted to hire that many developers.</p>
<p>Remember that ratio of 1 Flutter team member per 20,000 developers? If every capable Flutter
framework contributor in the world regularly contributed to Flutter, that ratio of 1:20,000
would drop to 1:1,000. That's still a big ratio, but it's <strong>much</strong> better than what it is
now.</p>
<p>Moreover, as more external contributors get comfortable submitting fixes and features to
Flutter, they'll tend to help train others to do the same. Thus, the support ratio would
continue to move in a better direction.</p>
<h2 id="why-not-work-directly-with-the-flutter-team">Why not work directly with the Flutter team?</h2>
<p>If increased external contributions is the path to a better Flutter world, then why fork
Flutter when everyone could just work directly with the Flutter team?</p>
<p>It's a tempting proposition to setup a concerted effort to contribute directly to Flutter.
After all, the Flutter team regularly touts the number of external contributions that it
rolls into each release. According to the Flutter public relations effort, they'd love all
those external contributions!</p>
<p>But, sadly, trying to work with the Flutter team delivers a different reality. While some
developers have had success working with the Flutter team, many other developers have found
it frustrating, if not unworkable. There are, no doubt, a number of factors that contribute
to this result. Different developers will experience different issues. But here are some of
them:</p>
<ul>
<li>Limited review labor:
<ul>
<li>The developers who don't have enough time to write code are the same developers tapped
to review contributions. Therefore, it can take a long time for review or updates.</li>
<li>The time crunch also seems to lend itself to contentious review conversations.</li>
</ul>
</li>
<li>Everything takes forever, and it always seems to be about non-critical details.</li>
<li>Communication monoculture - most of the team seems to expect a certain way of communicating,
which doesn't match the variety of personalities in the world. Thus, some people have an
exceptionally difficult time navigating otherwise quick and simple conversations.</li>
</ul>
<p>The result of the aforementioned issues, and probably others that aren't listed, is that the
total number of people who have ever contributed to the Flutter framework is currently less
than 1,500. That number includes people who dropped by, one time, to fix a typo in a Dart Doc
and then never contributed again. That's <strong>not</strong> the number of regular contributors who add
significant value.</p>
<p>Whatever your experience with contributions to Flutter, one has to critically assess why a
team that loves external contributions has only managed to merge contributions from 1,500
developers over a span of nearly a decade. My humble suggestion is that it's because the
inviting message of the PR team doesn't match the experience of actually pushing a change
through the team's policies, developer availability, and technical culture.</p>
<p>The only people who can change this reality are the people within the Flutter organization.
However, most of those people don't actually think any of this is a problem. I know, because
a number of them have expressed this to me, directly. There are a number of significant blind
spots for the Flutter team, which largely revolve around the fact that members of the team
have never been responsible for routinely delivering app features and fixes that are built
upon Flutter. In other words, I believe there are blind spots because Flutter team members
don't actually use Flutter. Thus, the urgency around many issues isn't appreciated, nor is
the urgency and time cost associated with submitting fixes directly to Flutter as an
external contributor.</p>
<p>If the Flutter team doesn't recognize the contribution problem, and therefore won't take
steps to address it, then what else can be done? That's where we find ourselves in this
post, and in this effort. We've decided that the one thing we can do to help the labor
issue is to fork Flutter.</p>
<h2 id="introducing-flock">Introducing Flock</h2>
<p>Our fork of Flutter is called Flock. We describe Flock as "Flutter+". In other words, we
<strong>do not</strong> want, or intend, to fork the Flutter community. Flock will remain constantly
up to date with Flutter. Flock will add important bug fixes, and popular community features,
which the Flutter team either can't, or won't implement.</p>
<p>By forking Flutter, we get to decide what gets merged. We won't lower the quality bar, but
by controlling merge decisions, we do gain the following opportunities:</p>
<ul>
<li>Recruit a much larger PR review team than the Flutter team. This means faster review times.</li>
<li>Recruit PR reviewers who are ready to facilitate contributions, instead of merely tolerating them.
This means support for a wider contributor audience.</li>
<li>Optimize policies. E.g., don't blindly demand design docs and conference calls when they won't
substantially add to the effectiveness of the task at hand.</li>
<li>Use contribution successes to socially promote more contributions.</li>
<li>We're all Flutter users - leverage team and company relationships to identify market priority.</li>
</ul>
<p>As Flock ships important bug fixes and features, the Flutter team can then choose to add those
to Flutter, on their schedule. The community will no longer be limited by the Flutter team's
availability, nor will the community need to beg the Flutter team to please accept a change. The
Flutter team can use Flock's solutions, or not, but all Flock users will have access to them,
eliminating your company and team's urgency and desperation.</p>
<h2 id="how-you-can-get-involved">How you can get involved</h2>
<p>Flock, as the name implies, will only go as far as the community that supports it. We would
love for you to get involved.</p>
<h3 id="alpha-test-the-fork">Alpha test the fork</h3>
<p>Flock's first step is to mirror Flutter. This means automatically mirroring the <code>master</code>,
<code>beta</code>, and <code>stable</code> branches, along with replicating all release tags. Additionally,
once the framework is mirrored, Flock will need to automatically build and upload the
engine, and make those engine binaries available to Flock users.</p>
<p>As we work through the mirroring process, it would be a big help if you would try building
your apps with Flock. You shouldn't see any difference between Flock and Flutter, and you
can configure Flock with a tiny Flutter Version Manager (FVM) configuration.</p>
<p>Check our instructions to <a href="https://flutterfoundation.dev/">get started</a>.</p>
<h3 id="become-a-reviewer">Become a reviewer</h3>
<p>Flock needs to recruit dozens of reviewers. Reviewers are responsible for enforcing a
quality bar that's similar to Flutter's. This includes requiring descriptive class, method,
and property names, effective Dart Docs, and appropriate tests.</p>
<p>But we want reviewers to go even further than that. We don't just want to tolerate contributions -
we want to facilitate them. Many of us have had the experience of getting a PR 90% to the finish
line only to have a Flutter team reviewer declare that it can't merge until we do something that
we don't know how to do. It's an awful experience, and we aim to avoid it with Flock.</p>
<p>We want Flock reviewers who are willing to step in and help a contributor achieve the final 10% of
the PR. This doesn't mean contributors get to be lazy. But if a contributor has done everything
that he knows how to do, and the PR is close to complete, then we want the reviewer to step in
and provide direction for the final 10%. This is how we educate contributors and ensure that the
next PR is 100% complete.</p>
<p>If you'd like to become a Flock reviewer, <a href="https://x.com/suprdeclarative">please reach out to us</a>.</p>
<h3 id="become-a-lead">Become a Lead</h3>
<p>Maintaining and extending a long-lived fork of Flutter requires some number of experts who
direct specific areas of the project. For example, I'm initially stepping up at the Director
of Flock, as well as the Framework Lead. Jesse Ezell has stepped up as the Engine Lead.</p>
<p>We'd like to bring in a Flutter Tool lead, who directs extensions to the <code>flutter</code> CLI tool.</p>
<p>We'd also like to break up the engine responsibilities with a Lead per platform: Android, iOS,
Mac, Windows, Linux.</p>
<p>If you'd like to direct efforts for an area of Flock, <a href="https://x.com/suprdeclarative">please reach out to us</a>.</p>
<h2 id="lets-flock-together">Let's Flock together</h2>
<p>Let's shift Flutter into overdrive and help make it the universal UI toolkit it should
have been. Flutter has the potential to outshine every alternative in the market. But
it needs the community to Flock together to help get it there. Let's do this!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Standardizing Automotive Connectivity (143 pts)]]></title>
            <link>https://www.tesla.com/en_CA/blog/standardizing-automotive-connectivity</link>
            <guid>41974882</guid>
            <pubDate>Mon, 28 Oct 2024 19:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tesla.com/en_CA/blog/standardizing-automotive-connectivity">https://www.tesla.com/en_CA/blog/standardizing-automotive-connectivity</a>, See on <a href="https://news.ycombinator.com/item?id=41974882">Hacker News</a></p>
Couldn't get https://www.tesla.com/en_CA/blog/standardizing-automotive-connectivity: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[So long WordPress (309 pts)]]></title>
            <link>https://chriswiegman.com/2024/10/so-long-wordpress/</link>
            <guid>41974637</guid>
            <pubDate>Mon, 28 Oct 2024 18:47:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriswiegman.com/2024/10/so-long-wordpress/">https://chriswiegman.com/2024/10/so-long-wordpress/</a>, See on <a href="https://news.ycombinator.com/item?id=41974637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><figure><img width="3680" height="2394" src="https://chriswiegman.com/images/2024/10/so-long-wordpress.png" alt="/images/2024/10/so-long-wordpress.png" decoding="async" fetchpriority="high" srcset="https://chriswiegman.com/images/2024/10/so-long-wordpress_hu1013444024394249332.png 850w,https://chriswiegman.com/images/2024/10/so-long-wordpress_hu13339974964986964901.png 710w,https://chriswiegman.com/images/2024/10/so-long-wordpress_hu2970326728706429584.png 300w" sizes="(max-width: 850px) 850w, (max-with: 710px) 710w, (max-with: 300px) 300w"></figure><p>This has been a hard post for me to write after participating in WordPress since before I even started a career in tech and, until 3 months ago, for my entire tech career. That said, it has been in the making for quite a while now and it is time that I make it official.</p><p>I’ve officially left the WordPress project after 14+ years of <a href="https://profiles.wordpress.org/chriswiegman/">contributing</a> including:</p><ul><li><a href="https://chriswiegman.com/speaking/">Meetup and WordCamp Speaker</a></li><li>Meetup and WordCamp Organizer</li><li>Core code contributor</li><li>Plugin developer</li><li>Photo contributor</li><li>Over 11 years as mostly the sole moderator for the official WordPress jobs site</li></ul><h2 id="why-leave-now">Why leave now?</h2><p>It’s true that I had largely been moving away from the WordPress project since at least 2017. I think that is when I realized just how dishonest so much of the “community” around WordPress really is.</p><p>I’ve watched people pour their lives into giving back only to have it all tossed out because their important work isn’t what Matt wanted people to focus on.</p><p>I’ve watched good people try to make the community stronger and protect users by contributing to privacy, accessibility, governance and so many more vital areas only to, not only have their contributions ignored, but to see the contributors themselves abused and pushed out of the community entirely for their basic advocacy.</p><p>I’ve watched WordPress company after WordPress company claim to be “better” in how it treats its people. The truth is nearly all of them used WordPress’ virtues as an excuse to under pay people and abuse them. From some of the most respected product companies to some of the most prominent agencies I’ve watched them chew up good people with threats that they “aren’t good enough to leave” and similar to continue to justify low pay and benefits.</p><p>I’ve watched a full cult form around Automattic, the company behind wordpress.com. In 2014 I even applied to work there but by that point I was already at a stage where I didn’t trust the org due to abuse I had seen a friend go through. I confess I took the paid trial but I intentionally did not take it seriously and I accepted another role before the trial started. All that is to say, Automattic was never honest about who it is so I really didn’t feel too bad at the time about going through such motions. They had the chance to change my mind then but that not only didn’t happen but the whole experience instead lowered my respect for the org even further.</p><p>The list goes on and on but WordPress was never an honest community, yet I stayed, for far too long.</p><p>I joined WP Engine in 2018 because it was the one company that really did seem to be honest about who they were. Like every other company they were in it to make money, but unlike every other company they didn’t hide that fact behind abusive language. They didn’t claim I was “family.” They didn’t claim their work was virtuous and therefore somehow “better” than non-WordPress orgs. No, they said they wanted to be the biggest host and went after that with the best pay I saw in the WordPress ecosystem and interesting work on top of it.</p><p>I left WP Engine in July of this year for a lot of reasons, but I don’t regret why I joined them. I stand by the fact that they were the most honest company in WordPress, an ecosystem where honesty is often harder to come by than in any other I’ve worked in.</p><h3 id="the-current-wordpress-implosion">The current WordPress implosion</h3><p>So that brings us to the current WordPress <del>drama</del> implosion. There are plenty of folks writing the timeline of events of what is going on. That isn’t why I’m writing this post. That said, up until September I was happily still working on Kana, my WordPress development environment, and exploring a few plugin ideas I’ve had, even if WordPress isn’t the best tool for blogging anymore.</p><p>I can’t do it anymore.</p><p>The utter hypocrisy of Matt Mullenweg’s actions isn’t really unsurprising to anyone who has watched Automattic for the last decade or more but it is my final straw. Yes, I should’ve left earlier when I saw friends hurt. Somehow I guess I always thought my actions would somehow help the situation. It was a naive position, I now realize.</p><p>I won’t say WP Engine is blameless in the wider world of WordPress and open source, I didn’t leave there on a whim after all. The nature of the attack on them now, however, is beyond the pale. It finally shows the world what WordPress really is, an abusive, predatory organization/community lying about its virtues to abuse other companies and organizations in an effort to get free work.</p><p>The truth is that WordPress is, at best, past its peak and we’re going to see more fights between the companies in its orbit as they each battle for a larger slice of a shrinking pie. That isn’t something anyone can change with its current leadership and project structure.</p><h2 id="so-long-wordpress">So Long WordPress</h2><p>With this action I finally see that there is no helping the situation and I fear that my continued involvement can only serve to signal to others that their own work and efforts are both safe and worthwhile. They are neither. I won’t be responsible for leading good people to an abusive ecosystem.</p><p>With this I’ve archived my last remaining WordPress projects, Kana and the theme for this site, until such a time as there is proper governance in the WordPress project. I’ve also stepped back and will no longer contribute to Meetups or other WordPress events (<a href="https://chriswiegman.com/2024/06/back-to-speaking/">something I was excited about rejoining just this past summer</a>). I’ve even stopped moderating jobs.wordpress.net, something I had done almost daily since the summer of 2013.</p><p>Should the project find new life, preferably with lesser ambitions that a huge share of the whole internet, and competent governance in the spirit of the virtues it claims to represent I will rethink my position. For now, however, <strong>So Long WordPress, and thanks for all the fish</strong>.</p><h2 id="a-note-to-the-many-good-people-still-in-wordpress">A note to the many good people still in WordPress</h2><p>Finally, a note to the many good people still working in WordPress:</p><p>Thank you, all of you, for the years of conversation and support. While I speak of WordPress as a whole there are many of you both individually and in smaller communities that have done so much for the people in WordPress. I look forward to continuing conversations and support for your work in the future, regardless of where we all wind up.</p><p>I do, however, ask that you please consider the effects your actions have on others and be careful not to lead new victims to future abuse.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NY Times gets 230 wrong again (139 pts)]]></title>
            <link>https://www.techdirt.com/2024/10/28/ny-times-gets-230-wrong-again-misrepresenting-history-law-and-the-first-amendment/</link>
            <guid>41973732</guid>
            <pubDate>Mon, 28 Oct 2024 17:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/10/28/ny-times-gets-230-wrong-again-misrepresenting-history-law-and-the-first-amendment/">https://www.techdirt.com/2024/10/28/ny-times-gets-230-wrong-again-misrepresenting-history-law-and-the-first-amendment/</a>, See on <a href="https://news.ycombinator.com/item?id=41973732">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-452739">

				


				


				<h3>from the <i>that's-not-how-it-works</i> dept</h3>
				


				<p>The NY Times has real difficulty not misrepresenting Section 230. <a href="https://www.techdirt.com/2021/04/06/another-day-another-ridiculous-ny-times-opinion-piece-that-is-confused-about-section-230-free-speech-online/">Over</a> and <a href="https://www.techdirt.com/2019/08/13/ny-times-publishes-second-blatantly-incorrect-trashing-section-230-day-after-first-incorrect-article/">over</a> and <a href="https://www.techdirt.com/2020/03/06/why-does-ny-times-seem-literally-incapable-reporting-accurately-section-230/">over</a> and <a href="https://www.techdirt.com/2021/10/29/ny-times-continues-inability-to-report-accurately-section-230-content-moderation/">over</a> and <a href="https://www.techdirt.com/2019/09/11/ny-times-got-it-backwards-section-230-helps-limit-spread-hate-speech-online/">over</a> again it has misrepresented how Section 230 works, even having to once run this astounding correction (to an article that had a half-page headline saying Section 230 was at fault):</p>
<div>
<figure><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/lex-img-p.s3.us-west-2.amazonaws.com/img/7c3c67c0-30e7-4759-8ccb-20e3eb5d5f2d-RackMultipart20241026-165-31sqs8.png?ssl=1" alt=""></figure>
</div>
<p>A day later, it had to run another correction on a different article also misrepresenting Section 230:</p>
<div>
<figure><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/lex-img-p.s3.us-west-2.amazonaws.com/img/ba1ed61c-a51c-4054-a911-b3db1b9e00e9-RackMultipart20241026-149-ok91so.png?ssl=1" alt=""></figure>
</div>
<p>You would think with all these mistakes and corrections that the editors at the NY Times might take things a bit more slowly when either a reporter or a columnist submits a piece purportedly about Section 230.</p>
<p>Apparently not.</p>
<p>Julia Angwin has done some amazing reporting on privacy issues in the past and has exposed plenty of legitimately bad behavior by big tech companies. But, unfortunately, she appears to have been sucked into nonsense about Section 230.</p>
<p>She recently wrote a terribly misleading opinion piece, <a href="https://www.nytimes.com/2024/10/21/opinion/tiktok-meta-social-media-law.html?unlocked_article_code=1.T04.otNY.oQ-Di6hLTB_u&amp;smid=url-share">bemoaning social media algorithms</a> and blaming Section 230 for their existence. The piece is problematic and wrong on multiple levels. It’s disappointing that it ever saw the light of day without someone pointing out its many flaws.</p>
<p><strong>A history lesson:</strong></p>
<p>Before we get to the details of the article, let’s take a history lesson on recommendation algorithms, because it seems that many people have very short memories.</p>
<p>The early internet was both great and a mess. It was great because anyone could create anything and communicate with anyone. But it was a mess because that came with a ton of garbage and slop. There were attempts to organize that information and make it useful. Things like Yahoo became popular not because they had a search engine (that came later!) but because they were an attempt to “organize” the internet (Yahoo originally stood for “Yet Another Hierarchical Officious Oracle”, recognizing that there were lots of attempts to “organize” the internet at that time).</p>
<p>After that, searching and search algorithms became a central way of finding stuff online. In its simplest form, search is a recommendation algorithm based on the keywords you provide run against its index. In the early days, Google cracked the code to make that recommendation algorithm for content on the wider internet.</p>
<p>The whole point of a search recommendation is “the algorithm thinks these are the most relevant bits of content for you.”</p>
<p>The next generation of the internet was content in various silos. Some of those were user-generated silos of content, such as Facebook and YouTube. And some of them were professional content, like Netflix or iTunes. But, once again, it wasn’t long before users felt overwhelmed with the sheer amount of content at their fingertips. Again, they sought out recommendation algorithms to help them find the relevant or “good” content, and to avoid the less relevant “bad” content. Netflix’s algorithm isn’t very different from Google’s recommendation engine. It’s just that, rather than “here’s what’s most relevant for your search keywords,” it’s “here’s what’s most relevant based on your past viewing history.”</p>
<p>Indeed, Netflix somewhat famously perfected the content recommendation algorithm in those years, even <a href="https://www.techdirt.com/2006/10/02/winner-take-all-outsourcing-netflix-will-pay-1-million-to-whoever-improves-their-recommendation-engine/">offering up a $1 million prize</a> to anyone who could build a better version. Years later, a team of researchers <a href="https://www.techdirt.com/2009/09/22/netflix-1-million-award-shows-the-value-of-collaboration-but-kicks-up-new-privacy-questions/">won the award</a>, but Netflix <a href="https://www.techdirt.com/2012/04/13/why-netflix-never-implemented-algorithm-that-won-netflix-1-million-challenge/">never implemented it</a>, saying that the marginal gains in quality were not worth the expense.</p>
<p>Either way, though, it was clearly established that the benefit and the curse of the larger internet is that in enabling anyone to create and access content, too much content is created for anyone to deal with. Thus, <em>curation</em> and <em>recommendation</em> is absolutely necessary. And handling both at scale requires some sort of algorithms. Yes, some personal curation is great, but it does not scale well, and the internet is all about scale.</p>
<p>People also seem to forget that recommendation algorithms aren’t just telling you what content they think you’ll <em>want</em> to see. They’re also helping to minimize the content you probably <em>don’t want to see</em>. Search engines choosing which links show up first are also choosing which links they won’t show you. My email is only readable because of the recommendation engines I run against it (more than just a spam filter, I also run algorithms that automatically put emails into different folders based on likely importance and priority).</p>
<p>Algorithms aren’t just a necessary part of making the internet usable today. They’re a key part of improving our experiences.</p>
<p>Yes, sometimes algorithms get things wrong. They could recommend something you don’t want. Or demote something you do. Or maybe they recommend some problematic information. But sometimes people get things wrong too. Part of internet literacy is recognizing that what an algorithm presents to you is just a suggestion and not wholly outsourcing your brain to the algorithm. If the problem is people outsourcing their brain to the algorithm, it won’t be solved by outlawing algorithms or adding liability to them.</p>
<p>It being just a suggestion or a recommendation is also important from a legal standpoint: because recommendation algorithms are simply <em>opinions</em>. They are opinions of what content that algorithm thinks is most relevant to you at the time based on what information it has at that time.</p>
<p>And <em>opinions</em> are protected free speech under the First Amendment.</p>
<p>If we held anyone liable for opinions or recommendations, we’d have a massive speech problem on our hands. If I go into a bookstore, and the guy behind the counter recommends a book to me that makes me sad, I have no legal recourse, because no law has been broken. If we say that tech company algorithms mean they should be liable for their recommendations, we’ll create a huge mess: spammers will be able to sue if email is filtered to spam. Terrible websites will be able to sue search engines for downranking their nonsense.</p>
<p>On top of that, First Amendment precedent has long been clear that the only way a distributor can be held liable for <em>even harmful</em> recommendation is if the distributor had <em>actual knowledge of the law-violating nature of the recommendation</em>.</p>
<p>I know I’ve discussed this case before, but it always gets lost in the mix. In <a href="https://law.justia.com/cases/federal/appellate-courts/F2/938/1033/294363/">Winter v. GP Putnam</a>, the Ninth Circuit said a publisher was not liable for publishing a mushroom encyclopedia that literally “recommended” people eat poisonous mushrooms. The issue was that the publisher had no way to know that the mushroom was, in fact, inedible.</p>
<blockquote>
<p><em>We conclude that the defendants have no duty to investigate the accuracy of the contents of the books it publishes. A publisher may of course assume such a burden,&nbsp; but there is nothing inherent in the role of publisher or the surrounding legal doctrines to suggest that such a duty should be imposed on publishers. Indeed the cases uniformly refuse to impose such a duty.&nbsp; Were we tempted to create this duty, the gentle tug of the First Amendment and the values embodied therein would remind us of the social costs.</em></p>
</blockquote>
<p>It’s not hard to transpose this to the internet. If Google recommends a link that causes someone to poison themselves, precedent says we can hold the <em>author</em> liable, but <em>not the distributor/recommender</em> unless they have actual knowledge of the illegal nature of the content. Absent that, there is nothing to actually sue over.</p>
<p>And, that’s good. Because you can’t demand that anyone recommending anything know with certainty whether or not the content they are recommending is good or bad. That puts way too much of a burden on the recommender, and makes the mere process of recommending <em>anything</em> a legal minefield.</p>
<p>Note that the issue of Section 230 does not come up even once in this history lesson. All that Section 230 does is say that websites and users (that’s important!) are immune from their editorial choices for third party content. That doesn’t change the underlying First Amendment protections for their editorial discretion, it just allows them to get cases tossed out earlier (at the very earliest motion to dismiss stage) rather than having to go through expensive discovery/summary judgment and possibly even all the way to trial.</p>
<p><strong>Section 230 isn’t the issue here:</strong></p>
<p>Now back to Angwin’s piece. She starts out by complaining about Mark Zuckerberg talking up Meta’s supposedly improved algorithms. Then she takes the trite and easy route of dunking on that by pointing out that Facebook is full of AI slop and clickbait. That’s true! But… that’s got nothing to do with legal liability. That simply has to do with… how Facebook works and how you use Facebook? My Facebook feed has no AI slop or clickbait, perhaps because I don’t click on that stuff (and I barely use Facebook). If there was no 230 and Facebook were somehow incentivized to do less algorithmic recommendation, feeds would still be full of nonsense. That’s why the algorithms were created in the first place. Indeed, studies have shown that when you remove algorithms, feeds are filled with more nonsense, because the algorithms don’t filter out the crap any more.</p>
<p>But Angwin is sure that Section 230 is to blame and thinks that if we change it, it will magically make the algorithms better.</p>
<blockquote>
<p><em>Our legal system is starting to recognize this shift and hold tech giants responsible for the effects of their algorithms — a significant, and even possibly transformative, development that over the next few years could finally force social media platforms to be answerable for the societal consequences of their choices.</em></p>
<p><em>Let’s back up and start with the problem.</em> <a href="https://www.justice.gov/archives/ag/department-justice-s-review-section-230-communications-decency-act-1996"><em>Section 230, a snippet of law</em></a> <em>embedded in the 1996 Communications Decency Act, was initially intended to protect tech companies from defamation claims related to posts made by users. That protection made sense in the early days of social media, when we largely chose the content we saw, based on whom we “friended” on sites such as Facebook. Since we selected those relationships, it was relatively easy for the companies to argue they should not be blamed if your Uncle Bob insulted your strawberry pie on Instagram.</em></p>
</blockquote>
<p>So, again, this is wrong. From the earliest days of the internet, we always relied on recommendation systems and moderation, as noted above. And “social media” didn’t even come into existence until years after Section 230 was created. So, it’s not just wrong to say that Section 230’s protections made sense for early social media, it’s backwards.</p>
<p>Also, it is somewhat misleading to call Section 230 “a snippet of law embedded in the 1995 Communications Decency Act.” Section 230 was an entirely different law, designed to be a replacement for the CDA. It was the Internet Freedom and Family Empowerment Act and was put forth by then Reps. Cox and Wyden as an alternative to the CDA. Then, Congress, in its infinite stupidity, took both bills and merged them.</p>
<p>But it was also intended to help protect companies from being sued <em>for recommendations</em>. Indeed, two years ago, <a href="https://www.supremecourt.gov/DocketPDF/21/21-1333/252645/20230119135536095_21-1333%20bsac%20Wyden%20Cox.pdf">Cox and Wyden explained this</a> to the Supreme Court in a case about recommendations:</p>
<blockquote>
<p><em>At the same time, Congress drafted Section 230 in a technology-neutral manner that would enable the provision to apply to subsequently developed methods of presenting and moderating user-generated content. The targeted recommendations at issue in this case are an example of a more contemporary method of content presentation. Those recommendations, according to the parties, involve the display of certain videos based on the output of an algorithm designed and trained to analyze data about users and present content that may be of interest to them.</em> <strong><em>Recommending systems that rely on such algorithms are the direct descendants of the early content curation efforts that Congress had in mind when enacting Section 230</em></strong><em>. And because Section 230 is agnostic as to the underlying technology used by the online platform, a platform is eligible for immunity under Section 230 for its targeted recommendations to the same extent as any other content presentation or moderation activities.</em></p>
</blockquote>
<p>So the idea that 230 wasn’t meant for recommendation systems is wrong and ahistorical. It’s strange that Angwin would just claim otherwise, without backing up that statement.</p>
<p>Then, Angwin presents a very misleading history of court cases around 230, pointing out cases where Section 230 has been successful in getting <em>bad</em> cases dismissed at an early stage, but in a way that makes it sound like the cases would have succeeded absent 230:</p>
<blockquote>
<p><em>Section 230 now has been used to shield tech from consequences for facilitating deadly</em> <a href="https://law.justia.com/cases/federal/appellate-courts/ca9/18-15175/18-15175-2019-08-20.html#:~:text=content%2Dneutral%20tools.-,DYROFF%20V.,drug%20transactions%20was%20not%20plausible."><em>drug sales</em></a><em>,</em> <a href="https://www.lawfareblog.com/herrick-v-grindr-why-section-230-communications-decency-act-must-be-fixed"><em>sexual harassment</em></a><em>,</em> <a href="https://s3.documentcloud.org/documents/5984807/Armslist-Decision.pdf"><em>illegal arms sales</em></a> <em>and</em> <a href="https://law.justia.com/cases/federal/appellate-courts/ca1/15-1724/15-1724-2016-03-14.html"><em>human trafficking</em></a><em>. And in the meantime, the companies grew to be some of the most valuable in the world.</em></p>
</blockquote>
<p>But again, these links misrepresent and misunderstand how Section 230 functions under the umbrella of the First Amendment. None of those cases would have succeeded under the First Amendment, again because the companies had no actual knowledge of the underlying issues, and thus could not be held liable. All Section 230 did was speed up the resolution of those cases, without stopping the plaintiffs from taking legal action against <em>those actually responsible for the harms.</em></p>
<p>And, similarly, we could point to another list of cases where Section 230 “shielded tech firms from consequences” for things <strong>we want them shielded from consequences</strong> on, like <a href="https://blog.ericgoldman.org/archives/2023/10/section-230-protects-gmails-spam-filter-rnc-v-google.htm">spam filters</a>, <a href="https://www.techdirt.com/2018/08/20/appeals-court-says-course-twitter-can-kick-racists-off-platform/">kicking Nazis off your platform</a>, <a href="https://www.techdirt.com/2024/08/15/court-to-rfk-jr-fact-checking-doesnt-violate-1st-amendment-nor-does-section-230-make-meta-a-state-actor/">fact-checking vaccine misinformation</a> and <a href="https://www.techdirt.com/2019/07/23/section-230-works-russian-trolls-dont-get-to-sue-facebook-being-kicked-off-facebook/">election denial disinformation</a>, <a href="https://www.techdirt.com/2021/06/22/changing-section-230-wont-make-internet-kinder-gentler-place/">removing hateful content</a> and much much more. Remove 230 and you lose that ability as well. And those two functions are tied together at the hip. You can’t get rid of the protections for the stuff Julia Angwin says is bad without also losing the protections for things we want to protect. At least not without violating the First Amendment.</p>
<p>This is the part that 230 haters refuse to understand. Platforms rely on the immunity from liability that Section 230 gives them to <em>make editorial decisions on all sorts of content</em>. Yet, somehow, they think that taking away Section 230 would magically lead to more removals of “bad” content. That’s the opposite of true. Remove 230 and things like removing hateful information, putting in place spam filters, and stopping medical and election misinfo becomes a bigger challenge, since it will cost much more to defend (even if you’d win on First Amendment grounds years later).</p>
<p>Angwin’s issue (as is the issue with so many Section 230 haters) is that she wants to blame tech companies for harms <strong>created by users</strong> of those technologies. At its simplest level, Section 230 is just <strong>putting the liability on the party actually responsible</strong>. Angwin’s mad because she’d rather blame tech companies than the people actually selling drugs, sexually harassing people, selling illegal arms or engaging in human trafficking. And I get the instinct. Big tech companies suck. But pinning liability on them won’t fix that. It’ll just allow them to get out of having important editorial discretion (making everything worse) while simultaneously building up a bigger legal team, making sure competitors can never enter the space.</p>
<p>That’s the underlying issue.</p>
<p>Because if you blame the tech companies, you don’t get less of those underlying activities. You get companies who won’t even look to moderate such content, because that would be used in lawsuits against them as a sign of “knowledge.” Or if the companies do decide to more aggressively moderate, you would get any attempt to speak out about sexual harassment blocked (goodbye to the #MeToo movement… is that what Angwin really wants?)</p>
<p><strong>Changing 230 would make things worse, not better:</strong></p>
<p>From there, Angwin takes the absolutely <a href="https://www.techdirt.com/2024/08/29/third-circuits-section-230-tiktok-ruling-deliberately-ignores-precedent-defies-logic/">batshit crazy 3rd Circuit opinion in Anderson v. TikTok</a>, which <em>explicitly ignored</em> a long list of other cases based on misreading a non-binding throwaway line in a Supreme Court ruling, and gave no other justification for its ruling, as being a good thing?</p>
<blockquote>
<p><em>If the court holds platforms liable for their algorithmic amplifications, it could prompt them to limit the distribution of noxious content such as nonconsensual nude images and <a href="https://www.nytimes.com/2023/05/06/opinion/fear-speech-social-media.html">dangerous lies intended to incite violence</a>. It could force companies, including TikTok, to ensure they are not algorithmically promoting harmful or discriminatory products. And, to be fair, it could also lead to some overreach in the other direction, with platforms having a greater incentive to censor speech.</em></p>
</blockquote>
<p>Except, it won’t do that. Because of the First Amendment it does the opposite. The First Amendment requires actual knowledge of the violative actions and content, so doing this will mean two things: companies taking either a much less proactive stance or, alternatively, taking one that will be much quicker to remove any controversial content (so goodbye #MeToo, #BlackLivesMatter or protests against the political class).</p>
<p>Even worse, Angwin seems to have spoken to no one with actual expertise on this if she thinks this is the end result:</p>
<blockquote>
<p><em>My hope is that the erection of new legal guardrails would create incentives to build platforms that give control back to users. It could be a win-win: We get to decide what we see, and they get to limit their liability.</em></p>
</blockquote>
<p>As someone who is actively working to help create systems that give control back to users, I will say flat out that Angwin gets this backwards. Without Section 230 it becomes way more difficult to do so. Because the users themselves would now face much greater liability, and unlike the big companies, the users won’t have buildings full of lawyers willing and able to fight such bogus legal threats.</p>
<p>If you face liability for giving users more control, users get less control.</p>
<p>And, I mean, it’s incredible to say we need legal guardrails and less 230 and then say this:</p>
<blockquote>
<p><em>In the meantime, there are alternatives. I’ve already moved most of my social networking to</em> <a href="https://bsky.social/about/"><em>Bluesky</em></a><em>, a platform that allows me to manage</em> <a href="https://bsky.social/about/blog/03-12-2024-stackable-moderation"><em>my content moderation settings</em></a><em>. I also subscribe to several</em> <a href="https://www.nytimes.com/2023/08/17/opinion/social-media-algorithm-choice.html"><em>other feeds</em></a> <em>— including one that provides news from verified news organizations and another that shows me what posts are popular with my friends.</em></p>
<p><em>Of course, controlling our own feeds is a bit more work than passive viewing. But it’s also educational. It requires us to be intentional about what we are looking for — just as we decide which channel to watch or which publication to subscribe to.</em></p>
</blockquote>
<p>As a <a href="https://www.techdirt.com/2024/08/06/why-im-joining-the-bluesky-board-to-support-a-vision-of-a-more-open-decentralized-internet/">board member of Bluesky</a>, I can say that those content moderation settings and the ability for others to make feeds and for them to be available for Angwin to choose what she wants are possible in large part due to Section 230. Without Section 230 to protect both Bluesky and its users, it makes it much more difficult to defend lawsuits over those feeds.</p>
<p>Angwin literally has this backwards. Without Section 230, is Bluesky as open to offering up third-party feeds? Are they as open to allowing users to create their own feeds? Under the world that Angwin claims to want, where platforms have to crack down on “bad” content, it would be a lot more legally risky to allow user control and third-party feeds. Not because providing the feeds would lead to legal losses, but without 230 it would encourage more bogus lawsuits, and cost way more to get those lawsuits tossed out under the First Amendment.</p>
<p>Bluesky doesn’t have a building full of lawyers like Meta has. If Angwin got her way, Bluesky would need that if it wanted to continue offering the features Angwin claims she finds so encouraging.</p>
<p>This is certainly not the first time that the NY Times has directly misled the public about how Section 230 works. But Angwin certainly <em>knows</em> many of the 230 experts in the field. It appears she spoke to none of them and wrote a piece that gets almost everything backwards. Angwin is a powerful and important voice towards fixing many of the downstream problems of tech companies. I just wish that she would spend some time understanding the nuances of 230 and the First Amendment to be more accurate in her recommendations.</p>
<p>I’m quite happy that Angwin likes Bluesky’s approach to giving power to end users. I only wish she wasn’t advocating for something that would make that way more difficult.</p>

				
<p>

	Filed Under: <a href="https://www.techdirt.com/tag/1st-amendment/" rel="tag">1st amendment</a>, <a href="https://www.techdirt.com/tag/algorithms/" rel="tag">algorithms</a>, <a href="https://www.techdirt.com/tag/content-moderation/" rel="tag">content moderation</a>, <a href="https://www.techdirt.com/tag/free-speech/" rel="tag">free speech</a>, <a href="https://www.techdirt.com/tag/history/" rel="tag">history</a>, <a href="https://www.techdirt.com/tag/julia-angwin/" rel="tag">julia angwin</a>, <a href="https://www.techdirt.com/tag/recommendations/" rel="tag">recommendations</a>, <a href="https://www.techdirt.com/tag/section-230/" rel="tag">section 230</a>
	<br>

	
</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using reinforcement learning and $4.80 of GPU time to find the best HN post (184 pts)]]></title>
            <link>https://openpipe.ai/blog/hacker-news-rlhf-part-1</link>
            <guid>41973591</guid>
            <pubDate>Mon, 28 Oct 2024 17:17:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openpipe.ai/blog/hacker-news-rlhf-part-1">https://openpipe.ai/blog/hacker-news-rlhf-part-1</a>, See on <a href="https://news.ycombinator.com/item?id=41973591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p><em>Background: I’m Kyle, the founder of OpenPipe. OpenPipe is a managed fine-tuning service that makes it easy to build your own LLMs that achieve very high accuracy on a specific task. In this post we’ll go under the covers and explain RLHF, which is one of the techniques we use to accomplish this.</em></p><p>What do the following Hacker News stories have in common?</p><p>None reached the front page; in fact none of them even got any upvotes! But <strong>they were all identified by a fine-tuned model as being likely to do well on HN</strong>. And subjectively (as someone who spends far more time on HN than I should) I actually agree with the model on this one; those all look like stories that deserved more attention than they got.</p><p>In this post we’ll discuss how to build a <!--$--><a href="https://huggingface.co/docs/trl/main/en/reward_trainer" rel="noopener">reward model</a><!--/$--> that can predict the upvote count that a specific HN story will get. And in follow-up posts in this series, we’ll use that reward model along with reinforcement learning to create a model that can write high-value HN stories!</p><h3>RL and RLHF: A 2-Minute Intro</h3><p><!--$--><a href="https://huggingface.co/tasks/reinforcement-learning" rel="noopener">Reinforcement learning</a><!--/$--> (RL) is a set of ML techniques that improves a model's performance by letting it take actions in an environment, and then get rewarded or penalized for those actions. Based on the rewards or penalties, the model’s behavior is updated over time to (hopefully) do more of the actions that are rewarded, and avoid those that are penalized.</p><p>Reinforcement learning from human feedback (RLHF) was developed by OpenAI and first described <!--$--><a href="https://openai.com/index/learning-from-human-preferences/" rel="noopener">here</a><!--/$--> as a way of adapting RL techniques to LLMs specifically. The first key step is to develop a <!--$--><a href="https://huggingface.co/docs/trl/main/en/reward_trainer" rel="noopener">reward model</a><!--/$-->, which is a model that takes an input and output from an LLM, and tries to predict how “good” the output is. The “human feedback” part of RLHF refers to using humans to rate or compare outputs, and using that human preference data to train reward models. However, there are often other signals you can use to determine an output’s quality and train your model, as we’ll see.</p><p>Once you have a reward model, the second step is to use it to improve the performance of your generation model, by training your model to create outputs that have a higher reward on average. There are lots of techniques possible here depending on your domain and the tools you have available—we’ll cover these in the next post!</p><h3>Whence Data?</h3><p>To train a good reward model, the most critical input is <strong>high-quality feedback data</strong>. This can take many forms. At OpenPipe we have some customers building “co-pilot” or autocomplete flows, where the model suggests an action that the user can accept or reject. In this case, tracking whether an output was accepted or rejected is a great signal. For certain applications like chatbots or recommendation systems, you can proactively offer the user several potential outputs to choose from, and use which option they preferred as your feedback signal.</p><p>In our case we’ll go with a readily available dataset: HN stories along with their upvote counts. Upvote counts are a great reward signal; while they’re somewhat noisy, upvote count is usually correlated with post quality. For convenience in this project, I’ve scraped every HN post and comment ever (all 41 million of them!) and uploaded the full set <!--$--><a href="https://huggingface.co/datasets/OpenPipe/hacker-news" rel="noopener">here</a><!--/$-->. Using <!--$--><a href="https://pola.rs/" rel="noopener">Polars</a><!--/$-->, let’s take a quick look at how many posts and comments we have(1):</p><p><img alt="" data-framer-asset="data:framer/asset-reference,0cjXCFjnUcqeVy47SLH96YNpvdw.png" data-framer-height="622" data-framer-width="1206" height="311" src="https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png" srcset="https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png?scale-down-to=512 512w,https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png 1206w" width="603" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><h3>Defining the Task</h3><p>Ok, we have 5 million stories, that’s plenty to train a model! But we also have a problem. Our dataset has the story title, URL, date and submitter, but for most of the stories it doesn’t have the content, because it’s just an off-platform link. This might cause trouble for our reward model; a story’s content is often very important to whether users choose to upvote it or not. Without that information the reward model might not be able to make a good prediction!</p><p>One option would be to scrape the URLs for those 5 million posts (and hope they still exist). But to simplify, instead I’ll just limit to stories that have only text bodies, instead of links. That leaves us with ~150K stories to deal with.</p><p><img alt="" data-framer-asset="data:framer/asset-reference,G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png" data-framer-height="573" data-framer-width="1754" height="286" src="https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png" srcset="https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png?scale-down-to=512 512w,https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png 1754w" width="877" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><p>Nice, that should be manageable! Let’s take a look at how those are distributed chronologically:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,FbKFUkZPfeL9a1UuvFvZkhdaBs.png" data-framer-height="1470" data-framer-width="2970" height="735" src="https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png" srcset="https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png?scale-down-to=512 512w,https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png?scale-down-to=2048 2048w,https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png 2970w" width="1485" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><p><strong>Woah</strong>, the graph looks remarkably flat… as long as you focus on the 2008-2015 period, or 2016-2024 period. But in 2015 there is a stark discontinuity, where the number of stories (with text) shoots up by &gt;10x, and the average score drops by 5x! Is this some kind of <!--$--><a href="https://en.wikipedia.org/wiki/Eternal_September" rel="noopener">eternal September</a><!--/$-->?</p><p>To avoid potential data drift issues from that discontinuity, we’ll limit our dataset to the post-2016 stories. That way the model we create will be more attuned to what makes an HN story good or bad <em>today</em>, which will be helpful for future posts in the series.</p><p>Next, let’s quickly plot the distribution of story scores. For the rest of this exercise we’ll actually use the <strong>natural log of post score</strong> as the number we’re tracking, instead of the raw score itself. This smooths out the distribution a bit, which will hopefully make life easier for our model. Effectively, this transformation means that its task will be to predict the “order of magnitude” of a score rather than the score directly. This intuitively maps more closely to what we want, which is a prediction of the “order of magnitude” of a post’s score. A model that can tell us whether a story should get popular at all is more tractable than one that tries to guess whether it will get 120 vs 200 upvotes (a harder task).</p><p><img alt="" data-framer-asset="data:framer/asset-reference,wgwpMwqZBHayeABYiwohFXlJA.png" data-framer-height="569" data-framer-width="1769" height="284" src="https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png" srcset="https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png?scale-down-to=512 512w,https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png 1769w" width="884" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><h3>Training the Model</h3><p>Actually training the model is easy and fun! You can find the full code I used <!--$--><a href="https://github.com/OpenPipe/best-hn/blob/main/stories_train_model_v3.py" rel="noopener">here</a><!--/$-->. A few things to call out:</p><ul><li data-preset-tag="p"><p>Since this isn’t a generative task (we’re just trying to predict a single score, not a string of text) our model architecture options are wide open! We could use classic encoder models like <!--$--><a href="https://arxiv.org/abs/1907.11692" rel="noopener">RoBERTa</a><!--/$--> or <!--$--><a href="https://arxiv.org/abs/2111.09543" rel="noopener">DeBERTaV3</a><!--/$-->, which are often used for this kind of problem. <strong>However</strong>, in practice I’ve found that modern LLMs that do well on generative tasks are also extremely strong on this kind of predictive task, so I’ve used <!--$--><a href="https://huggingface.co/meta-llama/Llama-3.1-8B" rel="noopener">Llama 3.1 8B</a><!--/$--> here(2).</p></li><li data-preset-tag="p"><p>It’s super important that your training inputs includes all the information your model will need to make predictions. In this case, I included the post title, author, date, and content. All of those factors could be relevant to the chance a story gets voted up.</p></li><li data-preset-tag="p"><p>I used the <!--$--><a href="https://github.com/linkedin/Liger-Kernel" rel="noopener">Liger Kernel</a><!--/$--> optimizations for both training and later inference. This sped up training time by ~30% and cut RAM usage significantly while maintaining model quality.</p></li></ul><p>Training on 114K stories for one epoch on an H100 on <!--$--><a href="https://www.runpod.io/" rel="noopener">Runpod</a><!--/$--> took about 1.5 hours and cost $4.05. That’s not much time for a model that (hopefully) understands all of HN!</p><p>We can also follow along the performance on our validation set as training happens:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,pUUrTFODxi4Q2PACKEb2QTMGd4I.png" data-framer-height="842" data-framer-width="1398" height="421" src="https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png" srcset="https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png?scale-down-to=512 512w,https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png 1398w" width="699" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><p>The model finishes with a root mean-square error (RMSE) of 1.11. Remember, we’re asking the model to predict log(score). To translate that back to its accuracy on the real score we reverse the log: <em>e</em>^1.11 ~= 3. This means that <em>on average</em>, our model’s predicted score is off by a factor of <strong>3</strong>. Is that still good enough to be useful? We'll see!</p><h3>Running Inference</h3><p>Let’s see what our model thinks of all the HN stories! I used <!--$--><a href="https://github.com/OpenPipe/best-hn/blob/main/inference.py" rel="noopener">this code</a><!--/$--> to run our model against the entire corpus of HN stories. I found that using the <!--$--><a href="https://huggingface.co/docs/transformers/en/index" rel="noopener">Transformers</a><!--/$--> library, along with the Liger Kernels we used for training gave adequate performance without resorting to an inference-focused library like <!--$--><a href="https://github.com/sgl-project/sglang" rel="noopener">sglang</a><!--/$-->. I again ran this on an H100 on RunPod, and it only took 15 minutes to process all 140K stories in the corpus.</p><p>Ok, let’s limit to our test set and see how well our model does at predicting scores! Here’s a heatmap comparing the model’s predicted log(Score) on the Y-axis to the real log(Score) on the X-axis:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,pNpLANmHNfqWhOQC5OtE1BCVc4.png" data-framer-height="1170" data-framer-width="1750" height="585" src="https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png" srcset="https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png?scale-down-to=512 512w,https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png 1750w" width="875" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><p>Interesting! The correlation is actually not bad (0.53), but our model is very consistently over-estimating the score at the low end, and underestimating it at the high end. This is surprising; some variation on any given data point is expected, but such a consistent mis-estimation trend isn’t what we’d expect.</p><p>What causes this? I don’t know for sure, but I suspect this is an artifact of the <strong>randomness in getting to the HN front page</strong>. You can think of a post’s predicted score as</p><p><code>predicted_score = (probability_of_hitting_front_page * final_score_if_it_hits_front_page)</code></p><p>Even if the model gets <em>extremely good</em> at predicting <code>final_score_if_it_hits_front_page</code>, there’s still the inherent randomness of <code>probability_of_hitting_front_page</code> that is fundamentally unpredictable. As a result, the model learns to “hedge its bets” by predicting a score somewhere between 0 and the “true” predicted score if this story were to hit the front page.</p><p>So, <strong>how good are the stories it picks</strong>? Let’s take a look!</p><h3>Let’s see the stories!</h3><p>How well does the model do on identifying great HN stories? Here are the top 10 stories it predicts as most successful, with both the predicted and actual score(3).</p><p><img alt="" data-framer-asset="data:framer/asset-reference,fsY5awADsmvk74RkQJiPtZXtRrM.png" data-framer-height="964" data-framer-width="1736" height="482" src="https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png" srcset="https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png?scale-down-to=512 512w,https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png 1736w" width="868" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><p>Ok, those seem… interesting. It seems like the model has correctly identified that service complaints (8/10) and people talking about indie apps making money (2/10) very reliably make it to the front page, which all 10 apparently did!</p><p>We can also look at the top stories that the model believes should be successful, but actually fell through the cracks. Here are the top-predicted-score stories with a real score of 1 (zero upvotes):</p><p><img alt="" data-framer-asset="data:framer/asset-reference,ZkpuvOPGIH6TT7Nua9dFWQXCg.png" data-framer-height="962" data-framer-width="1760" height="481" src="https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png" srcset="https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png?scale-down-to=512 512w,https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png 1760w" width="880" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"></p><p>There are some nice gems on this list! Still a lot of complaints (4/10) but some more interesting content as well. There are some good diamonds in the rough there that probably should have sparked more discussion like <!--$--><a href="https://news.ycombinator.com/item?id=33413945" rel="noopener">dealing with Machiavellian co-founders</a><!--/$-->, <!--$--><a href="https://news.ycombinator.com/item?id=28747573" rel="noopener">pushing through burn-out</a><!--/$-->, and <!--$--><a href="https://news.ycombinator.com/item?id=25162971" rel="noopener">recording a signal from a single electron</a><!--/$-->.</p><h2>Part 2: Writing a Great HN Post</h2><p>Our reward model helps us define what a good HN post looks like. Is there anything else we can do with it? <strong>Yes</strong>! A fundamental property of machine learning is that if something can be measured, it can be optimized! So now that we can <strong>measure</strong> post quality, can we actually <strong>improve</strong> it? RLHF gives us a powerful set of techniques to do so, which we’ll cover in the next post in the series. 🙂</p><p>And as a final plug: if you have an AI-powered app deployed in production and a possible source of feedback, please <strong>contact me</strong> at <!--$--><a href="mailto:kyle@openpipe.ai" rel="noopener">kyle@openpipe.ai</a><!--/$-->. We are working closely with a number of design partners on improving our RLHF stack and would love to help you get better quality on your tasks!</p><p><strong>Footnotes</strong></p><ol><li data-preset-tag="p"><p>This query took 17 seconds to load the dataset into RAM and then aggregating by type was almost instant. It is absolutely incredible to me that I can load <em>every HN post and comment ever</em> into RAM in a few seconds on my (admittedly beefy) dev laptop, and analyze them at will. What an age of abundance!</p></li><li data-preset-tag="p"><p>We actually do <em>slightly</em> modify the architecture of the model to make it work more naturally as a reward model. Instead of the model’s final layer having a separate output for every possible token, we just have a single output that we train to predict the reward signal.</p></li><li data-preset-tag="p"><p>Since 80% of our stories were in the training set we have to worry about memorization here. Maybe the model is just <em>remembering</em> that these specific stories got a high score? After looking at the data a bit more closely though I don’t think that’s the case. only 7/10 of these stories were in the training set, less than the 80% proportion that were in the training set overall. So the model doesn’t seem to have the bias towards high-scoring stories in the training set you’d expect if it were just memorizing the distribution.</p></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Buy payphones and retire (437 pts)]]></title>
            <link>https://computer.rip/2024-10-26-buy-payphones-and-retire.html</link>
            <guid>41973065</guid>
            <pubDate>Mon, 28 Oct 2024 16:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computer.rip/2024-10-26-buy-payphones-and-retire.html">https://computer.rip/2024-10-26-buy-payphones-and-retire.html</a>, See on <a href="https://news.ycombinator.com/item?id=41973065">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<blockquote>
<p>PAYPHONES at High Volume</p>
<p>Existing sites! Earn BIG $$. Money Back Guarantee!</p>
</blockquote>
<p>Dropshipping AliExpress watches, AI-generated SEO spam websites... marginally
legal and ethical passive income schemes, that serve to generate that income
mostly for their promoters, can feel like a modern phenomenon. The promise of
big money for little work is one of the fundamental human weaknesses, though,
and it has been exploited by "business coaches" and "investment promoters" for
about as long as the concept of securities has existed. We used to refer mostly
to the "get rich quick" scheme, but fashions change with the time, and at the
moment "passive income" is the watchword of business YouTubers and Instagram
advertising.</p>
<p>And what income is more passive than vending machine coin revenue? Automated
vending has had a bit of a renaissance, with social media influencers buying
old machines and turning them into a business. The split of their revenue
between vending machine income and social media sponsorship is questionable,
but it's definitely brought some younger eyes to an industry that is as rife
with passive income scams as your average spam folder. Perhaps it's the
enforcement efforts of the SEC, or perhaps today's youth just need a little
more time to advance their art, but I haven't so far seen a vending machine
hustle quite as financialized as the post-divestiture payphone industry.</p>
<p>For much of the history of the telephone system, payphones were owned and
operated by telephone carrier. As with the broader telephone monopoly, there
were technical reasons for this integration. Payphones, more specifically
called coin operated telephones, were "dumb" devices that relied on the
telephone exchange for control. In the case of a manual exchange, you would
pick up a payphone and ask the operator for your party---and they would advise
you of the price and tell you to insert coins. The coin acceptor in the
payphone used a simple electrical signaling scheme to notify the operator of
which and how many coins you had inserted, and it was up to the operator to
check that it was correct and connect the call. If coins needed to be returned
after the call, the operator would signal the phone to do so.</p>
<p>With the introduction of electromechanical and then digital exchanges, coin
control became automated, but payphones continued to use specialized signaling
schemes to communicate with the coin control system. They had to be connected
to special loops, usually called "coin lines," with the equipment to receive
and send these signals. The payphone itself was a direct extension of the
telephone system, under remote control of the exchange, much like later devices
like line concentrators. It was only natural that they would be operated by the
same company that operated the control system they relied on.</p>
<p>Well, a lot of things have changed about the payphone industry. The 1968
Carterfone decision revolutionized the telephone industry by allowing the
customer to connect their own device. Coin operated telephones in the
traditional sense were unaffected, but Carterfone opened the door to a whole
new kind of payphone.</p>
<p>In 1970, burglar alarm manufacturer Robotguard blazed the trail into a new
telephone business. They imported a Japanese payphone that was a little
different from the American models of the time: it implemented coin payment
internally. Robotguard connected the payphone through one of their burglar
alarm autodialers, a device that was already fully compliant with telephone
industry regulations, and then hooked it up to a Southwestern Bell telephone
line in a department store in in St. Louis. By inserting a dime, the phone was
enabled and you could make a local call (the autodialer was used, in part, to
limit dialing to 7 digits to ensure that only local calls were made).</p>
<p>Robotguard had done their homework, consulting the same law firm that
represented Carterfone in the 1968 case. They believed the scheme to be legal,
since the modified Japanese payphone behaved, to the telephone company, just
like any other customer-owned phone. The New York Times quotes Southwestern
Bell, whose attitude is perhaps best described as resignation:</p>
<blockquote>
<p>Spokesmen for the Southwestern Bell Telephone Company, the operating company
in that area, acknowledge that the equipment is in the store, that it is
working as described and that it appears completely legal. There is nothing
they can do about it at this time, they say.</p>
</blockquote>
<p>There was, indeed, nothing that they could do about it. Robotguard had
introduced the Customer-Owned Coin-Operated Telephone, or COCOT, to the United
States. Payphones were now a competitive business.</p>
<p>Despite a certain air of inevitability, COCOTs had a slow start. First, there
would indeed be an effort by telephone companies to legally restrict COCOTs.
This was never entirely successful, but did result in a set of state
regulations (and to a lesser extent, federal regulations related to
long-distance calls) that made the payphone business harder to get into. More
importantly, though, the technical capabilities of COCOTs were limited. The
Robotguard design could charge only a fixed fee per call, which made it a
practical necessity to limit the payphone to local calls. Telephone company
payphones, which allowed long-distance calls at a higher rate, had an
advantage. Long-distance calls were also typically billed by minute, which made
it important for a payphone to impose a time limit before charging more. These
capabilities were difficult to implement in a reasonably compact, robust device
in the 1970s.</p>
<p>A number of articles will tell you that COCOTs became far more common as a
result of payphone deregulation stemming from the 1984 breakup of AT&amp;T. I would
love to hear evidence to the contrary, but from my research I believe this is a
misconception, or at least not the entire story. In fact, payphones were
deregulated by the Telecommunications Act of 1996, but that was done in large
part because COCOTs were already common and telephone companies were unhappy
that conventional payphones were subject to rate regulation while COCOTs were
not [1].</p>
<p>Divestiture did definitely open the floodgates of COCOTs, although I think that
the advances in electronics around that time were also a significant factor in
their proliferation. In any case, several manufacturers introduced COCOTs in
1984 and 1985.</p>
<p>These later-generation COCOTs were significantly more sophisticated than the
mechanical system used by Robotguard. To the user, they were pretty much
indistinguishable from carrier-operated payphones, charging varying rates based
on call duration and local or long distance. This local simulation of the
telephone exchange's charging decisions required that each COCOT have, in
internal memory, a prefix and rate table to determine charges. Early examples
used ROM chips shipped by their manufacturer, but over time the industry
shifted to remote programming via modems. These sophisticated,
electronically-controlled coin operated phones that did not rely on an
exchange-provided coin line came to be known as "smart payphones" and even,
occasionally, as "smartphones."</p>
<p>Smart payphones greatly simplified payphone operations and were even adopted by
the established telephone companies, where they could save money compared to
the more complex exchange-controlled system. But they also made COCOTs
completely practical, as good to the consumer as any other payphone. As COCOTs
became remotely programmable, the payphone business started to feel like a way
to generate---dare I say it---passive income. All you had to do was collect the
coins. Well, that and keep the phone in working order, which would become a
struggle for the thinly staffed and overleveraged Payphone Service Providers
(PSPs) that would come to dominate the industry.</p>
<p>One of the new entrants into the payphone business was a company that
specialized in exactly the kind of remote management these new smart payphones
required: Jaroth Inc., which would do business as Pacific Telemanagement
Solutions or PTS. Today, PTS is the largest PSP in the United States, but that
isn't saying a whole lot. They enjoyed great success in the 1990s, though, and
were so well-positioned as a PSP in the '00s that they often purchased the
existing payphone fleet from former Bell Operating Companies that decided to
abandon the payphone business.</p>
<p>The 1990s were a good time for payphones, and they were also a good time for
investment scams. Loose enforcement of regulations around investment offerings,
the Dot Com Boom, and a generally strong economy created a lot of opportunities
for "telecom entrepreneurs" that were more interested in moving money than
information.</p>
<hr>
<p>The problem of 1990s telecommunications companies funded in unscrupulous ways
is not at all unique to payphones, although it did reach a sort of apex there.
I will take this opportunity to go on a tangent, one of those things that I
have always wanted to write an article about but have never quite had enough
material for: MMDS, the Multichannel Multipoint Distribution Service.</p>
<p>MMDS was, essentially, cable television upconverted to a microwave band and
then put through directional antennas. It was often marketed as "Wireless
Cable," sort of an odd term, but it was intended as a direct competitor to
conventional cable television. I think it's fair to call it an ancestor of what
we now call WISPs, using small roof-mounted parabolic antennas as an
alternative to costly CATV outside plant. Some MMDS installations literally
were early WISPs: MMDS could carry a modified version of DOCSIS.</p>
<p>Wireless cable got a pretty bad rap, though. If you pay attention to WISPs, you
will no doubt have noticed that while the low capital investment required can
enable beneficial competition, it also enables a lot of companies that you
might call "fly by night." Some start out with good intentions and just aren't
up to the task, while some come from "entrepreneurs" with a history of fraud,
but either way they end up collecting money and then disappearing with it.</p>
<p>MMDS had a <em>huge</em> problem with shady operators, and more often of the "history
of fraud" type. Supposed MMDS startups would take out television and newspaper
ads nationwide offering an incredible opportunity to invest in this exciting
new industry. The scam took different forms in the details, but the most common
model was to sell "shares" of a new MMDS company in the four-to-five-digit
range. Investors were told that the company was using the capital to build
out their network and would shortly have hundreds of customers.</p>
<p>In practice, most of these "MMDS startups" were in cities with powerful
incumbent cable companies and, even worse, preexisting MMDS operators using the
limited spectrum available for such a wideband service. They never had any
chance of getting a license, and didn't have anyone with the expertise to
actually build an MMDS system even if they got one. They just pocketed the
money and were next seen on a beach in Mexico or in prison, depending on the
whims of fortune.</p>
<p>These wireless cable schemes became so common, and so notorious, that if you
asked a lot of people what wireless cable was the two answers you'd get are
probably "no idea" and "an old scam."</p>
<hr>
<p>It only takes a brief look at newspaper archives to find that the payphone
industry was a little sketchy. There are constant, nationwide, near-identical
classified ads with text like "buy and retire now" and "$150k yearly potential"
and "CALL NOW!". Sometimes more than one appear back to back, and they're still
nearly identical. None of these ads give a company name or really anything but
a phone number, and the phone numbers repeat so infrequently that I suspect the
advertisers were intentionally rotating them. This was pretty much the
Craigslist "work from home" post of the era.</p>
<p>To understand payphone economics better, let's talk a little about how the
payphone business operated. Telephone companies had long run payphones on the
same payment model, by finding a location for the payphone (or being contacted
by the proprietor of a location) and then offering the location a portion of
revenue. In the case of incumbent telcos, this was often a fixed rate per
call. So someone owned the location and the payphone operator paid them in
the form of a royalty.</p>
<p>COCOTs enabled a somewhat more complex model. A COCOT might be located in a
business, connected to a telephone company line, and remotely programmed by a
service provider, all of which were different companies from the person that
actually collected the money. The revenue had to get split between all of these
parties somehow, but COCOTS weren't regulated and that was all a matter of
negotiation.</p>
<p>Much like the vending machine industry today, one of the most difficult parts
of making money with a payphone was actually finding a good location---one that
wasn't already taken by another operator. As more and more PSPs spread across
the country, this became more and more of a challenge. So you can imagine the
appeal of getting into the payphone hustle without having to do all that
location scouting and negotiation. Thus all the ads for payphone routes for
sale... ostensibly a turnkey business, ready to go.</p>
<p>Ah, but people with turnkey, profitable businesses don't tend to sell them.
Something is up.</p>
<p>Not all of these were outright scams, or at least I assume some of them
weren't. There probably were some PSPs that financed expansion by selling
or leasing rights to some of their devices. But there were also a lot of...
well, let's talk about the second largest PSP of the late '90s.</p>
<p>Somewhere around 1994, Charles Edwards of Atlanta, Georgia had an idea. His
history is obscure, but he seems to have been an experienced salesman, perhaps
in the insurance industry. He put his talent for sales to work raising capital
ETS Payphones, Inc., which would place and operate payphones on the behalf of
investors.</p>
<p>The deal was something like this: ETS identified locations for payphones and
negotiated an agreement to place them. Then, they sold the payphone itself,
along with rights to the location, to an investor for five to seven thousand
dollars a pop. ETS would then operate and maintain the payphone while paying
a fixed monthly lease to the investor who had purchased it---something like
$83 a month.</p>
<p>It was a great deal for the investors---they didn't need any expertise or
really to do any work, since ETS arranged the location, installed the phones,
and even collected the coins. In fact, most investors purchased phones in
cities far from where they lived, such was the convenience of the ETS model.
There was virtually no risk for investors, either. ETS promised a monthly
payment up front, and the contract said that they would refund the investor
if the payphone didn't work out.</p>
<p>The ETS network was far larger than just Edwards could manage. Most of the
investment deals were sold by independent representatives, the majority of them
insurance agents, who could pick it up as a side business to earn some
commission. Edwards sold nearly 50,000 payphones on this basis, many of them in
deals of over $100,000. Small-time investors convinced of the value by their
insurance agents, many of them retirees, put over $300 million into ETS from
1996 to 2000.</p>
<p>There was, as you might have guessed, a catch. One wonders if the payphones
were even real. I think that at least many of them were; ETS ran job listings
for payphone technicians in multiple cities and occasionally responded to press
inquiries and complaints about malfunctioning payphones bearing their logo.
Besides, the telecom industry recognized ETS as a huge PSP in terms of both
installed base and call volume.</p>
<p>What definitely wasn't real was the revenue. ETS was a ponzi scheme. In 2000,
the SEC went for Charles Edwards, showing that ETS had never been profitable.
Edwards sponsored a NASCAR team and directed millions of dollars in salary and
consulting fees to himself, but in the first half of 2000 ETS lost $33 million.
The monthly lease payments to investors were being made from the capital put in
by newer investors, and even that was drying up.</p>
<p>SEC v. ETS went on for six years, in good part due to an appeal to the Supreme
Court based on ETS' theory that a contract that paid a fixed, rather than
variable, monthly rate could not be considered a security. In 2006, Charles
Edwards was convicted of 83 counts of wire fraud and sentenced to thirteen
years in prison.</p>
<p>Edwards was far from the only coin-op fraudster. ETS was not unusual except in
that it managed to be the largest. When a class-action firm and several state
attorneys general went after ETS, their press releases almost always mentioned
a few other similar payphone schemes facing similar legal challenges. Remember
all of those classified ads? I suspect some of them <em>were</em> ETS, but ETS also
had a more sophisticated sales operation than two-line classified ads. Most of
them were probably from competitors.</p>
<p>The payphone industry crashed alongside ETS; ETS almost certainly would have
collapsed (albeit likely more slowly) even if it had been above board.
Increasing cellphone ownership from the '90s to '00s made payphones
increasingly obsolete, and more and more established telcos and PSPs decided to
drop payphones. One of the reasons for PTS's ascent was its willingness to buy
out operators who wanted out: in 2008, PTS bought most of AT&amp;T's fleet. In
2011, they bought most of Verizon's fleet. Almost every incumbent telephone
company got out of the payphone business and most of them sold to PTS.</p>
<p>Given all that, you might think that payphone scams were only a thing of the
'90s. And they mostly were, but you can imagine that there was an opportunity
for anyone who could adapt the ETS model to the internet age.</p>
<p>Pantheon Holdings did just that. It's even more difficult to untangle the early
days of Pantheon than it is ETS. Pantheon operated through a variety of shell
companies and brands, but "the Internet Machine Company" was perhaps the most
to the point. Around 2005, Pantheon built "internet kiosks" where customers
could check their email, print documents, and even make phone calls for a
nominal cash or credit card payment. Sometimes called "global business
centers," these kiosks were presented as an exciting business opportunity to
mostly elderly investors who were given the opportunity to buy one for just
$18,000.</p>
<p>Once again, the kiosks were real, but the revenue was not. Pantheon placed the
machines in low-traffic locations and did nothing to market them. By 2009, more
than a dozen people had been convicted of fraud in relation to Prometheus.</p>
<p>Prometheus kiosks still turn up on the junk market.</p>
<p>[1] I spent quite a bit of time researching the history of payphone regulation
to try to understand exactly what did change in 1984, how many COCOTs operated
and on what legal basis from 1970-1984, etc. I did not have much success. What
I can tell is that COCOTs were very rare prior to 1984 (so rare that the FCC
apparently didn't know of any, according to a 1984 memo, despite the 1970
example), and by the late '80s were very common. The FCC seems to have taken
the view, in 1984, that COCOTs had <em>always</em> been legal, and just weren't being
made or used on any significant scale. That's somewhat inconsistent, though,
with the fact that suddenly after 1984 divestiture a bunch of companies started
making COCOTs for the first time. My best guess right now is that from 1970-1984
COCOTs were probably legal but were something of a gray area because of the lack
of any regulations specifically applying to them. Some combination of divestiture
broadly "shaking up" the phone industry, electronics making COCOTs much more
feasible, and who knows what else lead multiple companies to get into the COCOT
business in the mid-'80s. That lead the FCC to issue a series of regulatory
opinions on COCOTs that consistently upheld them as legal, culminating in the
1996 act dropping payphone regulation entirely.</p>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The sins of the 90s: Questioning a puzzling claim about mass surveillance (229 pts)]]></title>
            <link>https://blog.cr.yp.to/20241028-surveillance.html</link>
            <guid>41972172</guid>
            <pubDate>Mon, 28 Oct 2024 15:34:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cr.yp.to/20241028-surveillance.html">https://blog.cr.yp.to/20241028-surveillance.html</a>, See on <a href="https://news.ycombinator.com/item?id=41972172">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>The cr.yp.to <a href="https://blog.cr.yp.to/index.html" accesskey="i">blog</a></h2>
<hr>
<div>
<p>Older (Access-J): <a href="https://blog.cr.yp.to/20240803-clang.html" accesskey="j"><b>2024.08.03: Clang vs. Clang:</b></a> <span>You're making Clang angry. You wouldn't like Clang when it's angry. #compilers #optimization #bugs #timing #security #codescans</span></p>
<details><summary>Table of contents (Access-I for index page)</summary>
<table>
<tbody><tr><td><b>2024.10.28: The sins of the 90s:</b> Questioning a puzzling claim about mass surveillance. #attackers #governments #corporations #surveillance #cryptowars</td></tr>
<tr><td><a href="https://blog.cr.yp.to/20240803-clang.html"><b>2024.08.03: Clang vs. Clang:</b></a> <span>You're making Clang angry. You wouldn't like Clang when it's angry. #compilers #optimization #bugs #timing #security #codescans</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20240612-bibkeys.html"><b>2024.06.12: Bibliography keys:</b></a> <span>It's as easy as [1], [2], [3]. #bibliographies #citations #bibtex #votemanipulation #paperwriting</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20240102-hybrid.html"><b>2024.01.02: Double encryption:</b></a> <span>Analyzing the NSA/GCHQ arguments against hybrids. #nsa #quantification #risks #complexity #costs</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231125-kyber.html"><b>2023.11.25: Another way to botch the security analysis of Kyber-512:</b></a> <span>Responding to a recent blog post. #nist #uncertainty #errorbars #quantification</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231023-clumping.html"><b>2023.10.23: Reducing "gate" counts for Kyber-512:</b></a> <span>Two algorithm analyses, from first principles, contradicting NIST's calculation. #xor #popcount #gates #memory #clumping</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231003-countcorrectly.html"><b>2023.10.03: The inability to count correctly:</b></a> <span>Debunking NIST's calculation of the Kyber-512 security level. #nist #addition #multiplication #ntru #kyber #fiasco</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20230609-turboboost.html"><b>2023.06.09: Turbo Boost:</b></a> <span>How to perpetuate security problems. #overclocking #performancehype #power #timing #hertzbleed #riskmanagement #environment</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20220805-nsa.html"><b>2022.08.05: NSA, NIST, and post-quantum cryptography:</b></a> <span>Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20220129-plagiarism.html"><b>2022.01.29: Plagiarism as a patent amplifier:</b></a> <span>Understanding the delayed rollout of post-quantum cryptography. #pqcrypto #patents #ntru #lpr #ding #peikert #newhope</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20201206-msword.html"><b>2020.12.06: Optimizing for the wrong metric, part 1: Microsoft Word:</b></a> <span>Review of "An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development" by Knauff and Nejasmic. #latex #word #efficiency #metrics</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20191024-eddsa.html"><b>2019.10.24: Why EdDSA held up better than ECDSA against Minerva:</b></a> <span>Cryptosystem designers successfully predicting, and protecting against, implementation failures. #ecdsa #eddsa #hnp #lwe #bleichenbacher #bkw</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20190430-vectorize.html"><b>2019.04.30: An introduction to vectorization:</b></a> <span>Understanding one of the most important changes in the high-speed-software ecosystem. #vectorization #sse #avx #avx512 #antivectors</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20171105-infineon.html"><b>2017.11.05: Reconstructing ROCA:</b></a> <span>A case study of how quickly an attack can be developed from a limited disclosure. #infineon #roca #rsa</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20171017-collisions.html"><b>2017.10.17: Quantum algorithms to find collisions:</b></a> <span>Analysis of several algorithms for the collision problem, and for the related multi-target preimage problem. #collision #preimage #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20170723-random.html"><b>2017.07.23: Fast-key-erasure random-number generators:</b></a> <span>An effort to clean up several messes simultaneously. #rng #forwardsecrecy #urandom #cascade #hmac #rekeying #proofs</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20170719-pqbench.html"><b>2017.07.19: Benchmarking post-quantum cryptography:</b></a> <span>News regarding the SUPERCOP benchmarking system, and more recommendations to NIST. #benchmarking #supercop #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20161030-pqnist.html"><b>2016.10.30: Some challenges in post-quantum standardization:</b></a> <span>My comments to NIST on the first draft of their call for submissions. #standardization #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160607-dueprocess.html"><b>2016.06.07: The death of due process:</b></a> <span>A few notes on technology-fueled normalization of lynch mobs targeting both the accuser and the accused. #ethics #crime #punishment</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160516-quantum.html"><b>2016.05.16: Security fraud in Europe's "Quantum Manifesto":</b></a> <span>How quantum cryptographers are stealing a quarter of a billion Euros from the European Commission. #qkd #quantumcrypto #quantummanifesto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160315-jefferson.html"><b>2016.03.15: Thomas Jefferson and Apple versus the FBI:</b></a> <span>Can the government censor how-to books? What if some of the readers are criminals? What if the books can be understood by a computer? An introduction to freedom of speech for software publishers. #censorship #firstamendment #instructions #software #encryption</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20151120-batchattacks.html"><b>2015.11.20: Break a dozen secret keys, get a million more for free:</b></a> <span>Batch attacks are often much more cost-effective than single-target attacks. #batching #economics #keysizes #aes #ecc #rsa #dh #logjam</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20150314-optimizing.html"><b>2015.03.14: The death of optimizing compilers:</b></a> <span>Abstract of my tutorial at ETAPS 2015. #etaps #compilers #cpuevolution #hotspots #optimization #domainspecific #returnofthejedi</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20150218-printing.html"><b>2015.02.18: Follow-You Printing:</b></a> <span>How Equitrac's marketing department misrepresents and interferes with your work. #equitrac #followyouprinting #dilbert #officespaceprinter</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140602-saber.html"><b>2014.06.02: The Saber cluster:</b></a> <span>How we built a cluster capable of computing 3000000000000000000000 multiplications per year for just 50000 EUR. #nvidia #linux #howto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140517-insns.html"><b>2014.05.17: Some small suggestions for the Intel instruction set:</b></a> <span>Low-cost changes to CPU architecture would make cryptography much safer and much faster. #constanttimecommitment #vmul53 #vcarry #pipelinedocumentation</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140411-nist.html"><b>2014.04.11: NIST's cryptographic standardization process:</b></a> <span>The first step towards improvement is to admit previous failures. #standardization #nist #des #dsa #dualec #nsa</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140323-ecdsa.html"><b>2014.03.23: How to design an elliptic-curve signature system:</b></a> <span>There are many choices of elliptic-curve signature systems. The standard choice, ECDSA, is reasonable if you don't care about simplicity, speed, and security. #signatures #ecc #elgamal #schnorr #ecdsa #eddsa #ed25519</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140213-ideal.html"><b>2014.02.13: A subfield-logarithm attack against ideal lattices:</b></a> <span>Computational algebraic number theory tackles lattice-based cryptography.</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140205-entropy.html"><b>2014.02.05: Entropy Attacks!</b></a> <span>The conventional wisdom says that hash outputs can't be controlled; the conventional wisdom is simply wrong.</span></td></tr>
</tbody></table></details></div><hr>
<h2>2024.10.28: The sins of the 90s: <span>Questioning a puzzling claim about mass surveillance. #attackers #governments #corporations #surveillance #cryptowars</span></h2>
<p>Meredith Whittaker,
president of the Signal Foundation,
gave an interesting
<a href="https://www.ndss-symposium.org/ndss2024/keynote-meredith-whittaker/">talk</a>
at NDSS 2024
titled "AI, Encryption, and the Sins of the 90s".</p>
<p>I won't try to summarize everything the talk is saying:
go watch the talk video yourself,
or at least read through the transcript.
But I'll say something here about
what the "sins" part of the talk's title is referring to.</p>
<p>The talk says that, in the 1990s,
"cryptosystems were still classified as munitions and subject to strict export controls".
The talk describes the "crypto wars" as
"a series of legal battles, campaigns, and policy debates that played out in the US across the 1990s",
resulting in "the liberalization of strong encryption in 1999",
allowing people to "develop and use strong encryption without being subject to controls".</p>
<p>OK, that sounds familiar.
Which parts are the "sins"?</p>
<p>Answer:
the talk claims that
"the legacy of the crypto wars was to trade privacy for encryption—and to usher in an age of mass corporate surveillance".</p>
<p>Wow.
That sounds bad, and surprising,
definitely something worth understanding better.
If cryptographic export controls had instead remained in place after 1999,
how would that have improved privacy and reduced corporate surveillance?</p>
<p>Answer:
the talk claims that,
without strong cryptography,
"the metastatic growth of SSL-protected commerce and
RSA-protected corporate databases would not have been possible".</p>
<p>Wait, what?
Let's look at the facts.</p>
<h2>1. Would commerce exist without strong cryptography?</h2>
<p>Internet commerce was already booming by 1999.
Let's look specifically at the history of Amazon.</p>
<p>Amazon was founded in 1994.
Its initial public stock offering was in
<a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/566f6509-4b15-4cd4-929a-1cba79f822b2.pdf">1997</a>.
Amazon was sued
by Barnes &amp; Noble in
<a href="https://www.cnet.com/tech/tech-industry/book-giant-attacks-amazon/">1997</a>,
and was sued
by Wal-Mart
in <a href="https://money.cnn.com/1998/10/16/companies/walmart/">1998</a>.
Bezos was named Time Magazine's Person of the Year
in <a href="https://time.com/archive/6737319/jeffrey-preston-bezos-1999-person-of-the-year/">1999</a>:</p>
<blockquote>
<p>Bezos’ vision of the online retailing universe was so complete, his Amazon.com site so elegant and appealing, that it became from Day One the point of reference
for anyone who had anything to sell online. And that, it turns out, is everyone.</p>
</blockquote>
<p>Amazon's
<a href="https://ycharts.com/companies/AMZN/revenues_annual">revenue</a>
was
15.75 million dollars in 1996,
147.79 million dollars in 1997,
609.82 million dollars in 1998,
and 1.64 billion dollars in 1999.
Amazon was competently executing a business plan that from the outset
<a href="https://www.aboutamazon.com/news/company-news/amazons-original-1997-letter-to-shareholders">explicitly prioritized growth</a>.</p>
<p>Where does anyone get the idea that
continued cryptographic export controls
would have stopped the growth of Internet commerce,
rather than simply limiting the <em>security level</em> of Internet commerce?
How do we reconcile this idea
with the observed facts of Amazon already growing rapidly in the 1990s?
The export controls were still in place;
to the extent that
Internet commerce was encrypted at all,
it was encrypted primarily with
a weak cryptosystem, namely 512-bit RSA.</p>
<p>Just to emphasize how fast Amazon's growth was at that point:
Amazon's revenue was more than doubling every year.
If that had kept up,
Amazon's revenue in 2023 would have been more than 26000000 billion dollars.
In reality, Amazon's revenue in 2023 was <em>only</em> 575 billion dollars.</p>
<p>Okay, okay, 575 billion dollars is a lot of money,
and Amazon is now
<a href="https://www.reuters.com/legal/amazon-wins-partial-dismissal-us-ftcs-antitrust-lawsuit-2024-10-01/">fighting antitrust regulators</a>.
But how is Amazon's growth before and after 1999
a story about a change in cryptography regulation,
rather than a story about
customers liking a convenient shopping site
that provided fast, reasonably reliable deliveries
of an ever-expanding collection of products
at competitive prices?</p>
<p>These are natural questions
for anyone checking whether the talk's claims match the available evidence.
But the talk doesn't answer any of these questions.
Look, for example, at the full paragraph containing
the "would not have been possible" quote:</p>
<blockquote>
<p>It’s not that 1999 wasn’t a win, at least in a narrow sense. Indeed, we can craft a
counterfactual history in which the liberalization of encryption didn’t happen, in which we
instead accepted some janky, backdoored, government-standard cryptosystem—some
sad Clipper chip DES admixture—and that instead became the thing: a world in which
strong cryptosystems did not receive the benefit of many eyes and open scrutiny. But of
course the future from then to now would have been very different—not least of all
because the metastatic growth of SSL-protected commerce and RSA-protected
corporate databases would not have been possible.</p>
</blockquote>
<p>Aside from irrelevant details,
how is the "counterfactual history"
of a "janky, backdoored, government-standard cryptosystem"
different from the reality
of export-controlled cryptography in the late 1990s,
when <a href="https://link.springer.com/chapter/10.1007/3-540-45539-6_1">95%</a>
of SSL connections were limited to RSA-512?
The explosion of Internet commerce <em>was already happening</em> at that point.</p>
<p>Where does the "would not have been possible"
claim come from?
I'm not allergic to the phrase "of course",
but I try to limit it to cases where things are <em>really</em> obvious,
which is definitely not the situation here.</p>
<h2>2. Would commerce exist without security?</h2>
<p>Government regulations
are just one of many sources of weak cryptography.
Weak cryptography, in turn,
is just one of many sources of Internet-security failures.</p>
<p>Companies reported spending
<a href="https://www2.deloitte.com/content/dam/Deloitte/il/Documents/risk/cybersecurity-insights-2023-budgets-benchmarks-financial-services-institutions.pdf">more than 0.5% of revenue in 2023</a>
on things labeled as "cybersecurity".
A cybersecurity company named CrowdStrike accidentally
<a href="https://www.reuters.com/technology/microsoft-says-about-85-million-its-devices-affected-by-crowdstrike-related-2024-07-20/">took down millions of Windows computers</a>
in July 2024,
causing long service outages for many other companies.
CrowdStrike had been given control over all those computers
because it was saying that this would help
protect those computers against attacks.
Delta Airlines,
in a lawsuit filed this month against CrowdStrike,
<a href="https://apnews.com/article/delta-airlines-crowdstrike-outage-lawsuit-43bb230d2edf235bb9f7928c4279fec2">said that</a>
the outage
"crippled its operations for several days,
costing more than $500 million in lost revenue and extra expenses".
Meanwhile there are endless reports of ransomware running rampant,
as illustrated by BlackCat
disrupting various health-care services for
<a href="https://techcrunch.com/2024/02/29/unitedhealth-change-healthcare-ransomware-alphv-blackcat-pharmacy-outages/">weeks</a>
starting in February 2024.</p>
<p>And yet, despite the evident disruptions,
Internet commerce continues.</p>
<p>Do we want better security to stop the attacks?
Yes.
Does not having better security
mean that the entire system of Internet commerce will be destroyed?</p>
<p>Um, well, it's <em>conceivable</em> that there will be <em>such</em> a dramatic increase in attacks
that we'll all retreat to non-Internet commerce
(because, y'know, non-Internet commerce is secure).
But somehow the attackers don't seem interested in
killing the goose that lays the golden eggs.</p>
<p>Let's rewind to 1999.
The CIH virus had destroyed data on
<a href="https://www.zdnet.com/article/is-the-cih-virus-on-the-endangered-list/">a million computers</a>,
and was just one of many examples of attacks.
This didn't stop the Internet from skyrocketing in popularity;
it simply prompted effort to fix vulnerabilities.</p>
<p>One of the vulnerabilities at that time was the use of RSA-512.
From the perspective of stopping attacks,
this vulnerability was
<a href="https://eprint.iacr.org/2015/1000">important</a> to fix.
But, from the same perspective,
there were many other vulnerabilities
that were also important to fix,
including many that were
<a href="https://xkcd.com/538/">cheaper to exploit</a>
than attacking RSA-512.
My own experience is that exploitable buffer overflows
were very easy to find back then.</p>
<p>Does it sound plausible if someone picks <em>one</em> of the system vulnerabilities in 1999
and claims that fixing <em>this</em> vulnerability
is what made the difference between Internet commerce succeeding
and Internet commerce failing?
I'd expect such a claim to be backed by</p>
<ul>
<li>
<p>evidence that Internet commerce was on such a knife's edge
  (rather than being a clear win for its convenience)
  and</p>
</li>
<li>
<p>an explanation of what was so special about <em>this</em> vulnerability.</p>
</li>
</ul>
<p>Otherwise the claim sounds like nothing more than wishful thinking
about the importance of some particular area of security.</p>
<h2>3. Would corporate databases exist without strong cryptography?</h2>
<p>Let's move on to the second part of the claim that,
without strong cryptography,
"the metastatic growth of SSL-protected commerce and
RSA-protected corporate databases would not have been possible".</p>
<p>The mass-surveillance industry is much older than 1999.
See, for example,
the book
<a href="https://ibmandtheholocaust.com/about-ibm-and-holocaust">"IBM and the Holocaust"</a>,
which traces how IBM's punch-card databases were used to
"organize nearly everything in Germany and then Nazi Europe,
from the identification of the Jews in censuses, registrations, and ancestral tracing programs to the
running of railroads and organizing of concentration camp slave labor".</p>
<p>Does a database not count as a "corporate database"
if the decisions of what's going into the database
are being made by a government,
in this case the Nazis?
Does that make the database less evil?
Also, does the level of evil depend on
whether this was a database operated <em>by IBM for the Nazis</em>
or a database operated <em>by the Nazis using technology provided by IBM</em>?
Somehow I don't think these distinctions mattered
for people in the concentration camps.</p>
<p>As the 20th century continued,
more and more powerful technology
made surveillance less and less expensive.
Here's a
<a href="https://nap.nationalacademies.org/read/11896/chapter/13#360">quote</a>
from a 2007 study
"Engaging privacy and information technology in a digital age",
issued by a committee formed by
the U.S. National Academies of Sciences, Engineering, and Medicine:</p>
<blockquote>
<p>Beginning in the late 1950s, the computer became a central tool of organizational surveillance. It addressed problems of space and time in the management of records and data analysis and fueled the trend of centralization of records. The power of databases to aggregate information previously scattered across diverse locations gave institutions the ability to create comprehensive personal profiles of individuals, frequently without their knowledge or cooperation. The possibility of the use of such power for authoritarian purposes awakened images of Orwellian dystopia in the minds of countless journalists, scholars, writers, and politicians during the 1960s, drawing wide-scale public attention to surveillance and lending urgency to the emerging legal debate over privacy rights.</p>
<p>One of the sectors that immediately benefited from the introduction of computer database technology was the credit-reporting industry. ...
But the credit and insurance industries were not alone. Banks, utility companies, telephone companies, medical institutions, marketing firms, and many other businesses were compiling national and regional dossiers about their clients and competitors in quantities never before seen in the United States.</p>
</blockquote>
<p>Surely the 1960s surveillance dossiers
by "the credit-reporting industry"
and "marketing firms" and so on
count as examples of "corporate databases".</p>
<p>What's the mechanism by which continued cryptographic export controls
would have supposedly stopped the growth of surveillance?
How do we reconcile this with the observed facts
of government surveillance and corporate surveillance
already exploding in the second half of the 20th century,
when cryptographic export controls were in place?
Why does it matter for this growth whether databases were "RSA-protected" or not?
Or, more to the point, whether they were protected by
something stronger than RSA-512?</p>
<p>The talk doesn't answer any of these questions either.</p>
<h2>4. Getting personal</h2>
<p>I was, as the talk mentions,
one of the people fighting export controls in the 1990s.
The reason I was taking action
is that I had studied the situation and was troubled by it.
In particular,
I had concluded that the export controls were contributing to attacks.
If I was wrong about that,
then I'd like to understand why.</p>
<p>The talk claims that moving to stronger cryptography
had the negative effect of creating attacks:
specifically, of creating corporate mass surveillance.
I'd like to understand the rationale for this claim.
But I don't see where the talk explains the supposed mechanism,
or provides any evidence,
or addresses the contrary evidence
provided by 20th-century surveillance.</p>
<p>Beyond claiming that
the <em>actions</em> against export controls contributed to corporate surveillance,
the talk claims that these actions came from a narrow <em>perspective</em>
of seeing the government as the only problem.
For example:</p>
<ul>
<li>
<p>The talk claims that
  "strategic mistakes in the 1990s—in particular, the mistake of
  trusting industry and 'the free market'
  while viewing the government as the sole threat to
  fundamental rights—is a big part of how we got here".</p>
</li>
<li>
<p>The talk criticizes the
  "dated, market-centric folk wisdom that is
  content to leave the governance of significant choices about fundamental rights—like
  expression and privacy—to a handful of private companies, assuming the invisible hand
  will work some BCorp magic".</p>
</li>
<li>
<p>The talk criticizes
  "conflating encryption with privacy and focusing narrowly on the tech itself—on
  encryption as the goal, not a means to the goal—while focusing concerns about privacy
  invasion solely on governments, assumed to be always on the verge of tyranny—while
  ignoring (or even celebrating) the interests of market actors".</p>
</li>
</ul>
<p>In context,
the talk is attributing these perspectives to those of us fighting the "crypto wars".</p>
<p>Here the talk is simply wrong.
We're on record publicly explaining our goals,
and those records demonstrate a much broader perspective
than what the talk claims.</p>
<p>Consider, for example,
the 1993
<a href="https://web.archive.org/web/20230917050735/https://www.activism.net/cypherpunk/manifesto.html">"Cypherpunk's Manifesto"</a>
from Eric Hughes.
The manifesto is all about real-world privacy.
Encryption isn't mentioned until the fifth paragraph;
it's one of multiple items that privacy is described as <em>relying</em> upon.
The next paragraph after that is as follows:</p>
<blockquote>
<p>We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy out of their beneficence. It is to their advantage to speak
of us, and we should expect that they will speak. To try to prevent their speech is to fight against the realities of information. Information does not just want
to be free, it longs to be free. Information expands to fill the available storage space. Information is Rumor's younger, stronger cousin; Information is fleeter
of foot, has more eyes, knows more, and understands less than Rumor. </p>
</blockquote>
<p>This document isn't "viewing the government as the sole threat":
it's explicitly stating the opposite.
It also isn't "conflating encryption with privacy".</p>
<p>As another example,
here's are some 1995 quotes from the first
<a href="https://cr.yp.to/export/1995/0922-cohn-1.txt">brief</a>
that my lawyers filed in <em>Bernstein v. U.S.</em>:</p>
<blockquote>
<p>The uses for cryptography range from protecting the privacy of
attorney/client correspondence, financial transactions and medical records
transmitted over wires, to preventing piracy of cable TV, cellular phone,
telephone lines or satellite signals.  Every bank ATM uses cryptography.
...
If the government is successful here, it will eliminate
anonymity, forcing citizens to reveal their private associations to the
government and others, including high-tech criminals.</p>
</blockquote>
<p>This isn't "focusing concerns about privacy invasion solely on governments":
it explicitly includes other attackers.
As the U.S. Court of Appeals for the Ninth Circuit put it in its
<a href="https://cr.yp.to/export/1999/0506-order.html">1999 decision</a>
in the case:</p>
<blockquote>
<p>Whether we are surveilled by our government, by criminals, or by our neighbors,
it is fair to say that never has our
ability to shield our affairs from prying eyes been at such a
low ebb. The availability and use of secure encryption may
offer an opportunity to reclaim some portion of the privacy
we have lost.</p>
</blockquote>
<p>The government was the <em>defendant</em> in my court case.
That's because this was a court case
against regulations imposed by the government.
But the records show that we were considering a broader range of <em>attackers</em>.</p>
<p>Export regulations weren't the only problems
I started taking actions to address.
Example from 1993: I
<a href="https://seclists.org/interesting-people/1993/Jul/94">wrote</a>
<a href="https://seclists.org/interesting-people/1993/Jul/127">letters</a>
that stopped NIST's announced
<a href="https://www.mhonarc.org/archive/html/pem-dev/1993-06/msg00058.html">plan</a>
to give its DSA patent to PKP,
a partnership between Caro-Kann Corporation and the RSA corporation.
Example from 1995: I
<a href="https://groups.google.com/g/gnu.misc.discuss/c/eW5MsGzJWoQ/m/HSW0FSdeR5QJ">helped</a>
<a href="https://groups.google.com/g/gnu.misc.discuss/c/eW5MsGzJWoQ/m/usmbCdsq5UsJ">people</a>
understand that DH could be used as a replacement for RSA;
the DH patent was due to expire in 1997,
whereas the RSA patent wasn't due to expire until 2000.
Do these actions sound like
"ignoring (or even celebrating) the interests of market actors"?</p>
<p>The talk's narrative of supposed 1990s blindness
is everywhere in the talk,
not just in the quotes I've given above.
For example,
the talk says that 
"one of the world's most profitable business models" in 2024
is
"mass surveillance of a scale and granularity unimaginable in the 1990s".</p>
<p>"Unimaginable"?
Seriously?
How is this not the scale and granularity of surveillance
predicted by Orwell in the 1940s?</p>
<p>Oh, you want a surveillance-capitalism version?
Richard Stallman's 1997 essay
<a href="https://www.gnu.org/philosophy/right-to-read.en.html">"The right to read"</a>
started with a dystopian short story
about a future in which
"you could go to prison for many years for letting someone else read your books".
Here are two sentences from the story:</p>
<blockquote>
<p>In his software class, Dan had learned that each book had a copyright
monitor that reported when and where it was read, and by whom, to
Central Licensing. (They used this information to catch reading
pirates, but also to sell personal interest profiles to retailers.)</p>
</blockquote>
<p>That's worldwide fine-grained surveillance
for an unholy alliance of
marketers and the government,
just like the reality in 2024.</p>
<h2>5. Searching for sources</h2>
<p>The talk has a general statement that it draws on analyses by
"Dr. Sarah Myers West, Dr. Chris Gilliard, Dr. Karina Rider, and Dr. Matthew Crain".
The talk transcript ends with a list of references and URLs.</p>
<p>One of those sources is Rider's 2016 master's thesis
<a href="https://digital.lib.washington.edu/researchworks/items/b1857a13-d974-4d04-b4cc-d00e1560cf1c">"The Privacy Paradox: Privacy, Surveillance, and Encryption"</a>.
Rider searched Congressional hearings starting in 1993 for the word "encryption",
and then reviewed and summarized the arguments.</p>
<p>As an interesting example,
the thesis quotes
Microsoft lawyer Ira Rubinstein telling Congress in 1997
that "industry is in a position to assist law enforcement
and national security in achieving their objectives because we are able to
sell U.S. products in mass volume".</p>
<p>The thesis doesn't mention that
there was already a well-established tradition
of corporations making money by enabling government surveillance.
Remember IBM working with the Nazis?
How about IBM working with NSA
<a href="https://blog.cr.yp.to/20220805-nsa.html">to make DES weak enough for NSA to break</a>?</p>
<p>Regular readers of my blog will recall that,
in the 1990s,
NSA modified its export controls to create
<a href="https://cr.yp.to/export/dtn/V3N4_10_92.pdf">special exceptions</a>
for low-security cryptography from the RSA corporation,
specifically 40-bit RC2 and 40-bit RC4.
This was the result of a public
<a href="https://web.archive.org/web/20240617211107/http://cpsr.org/prevsite/conferences/cfp93/rosenthal.html/">agreement</a>
between the government and the Software Publishers Association.
Presumably NSA was happy
solidifying the market position of cryptography that NSA could break.
It's not as if the corporations involved
were putting a higher priority on <em>security</em> than on <em>making money</em>.</p>
<p>As another example,
consider Project Shamrock,
in which
telegraph companies sent NSA copies of millions of telegrams,
even though the lawyers at three of those companies had
<a href="https://www.intelligence.senate.gov/sites/default/files/94755_II.pdf#page=161">"recommended against participation because they considered the program
to be in violation of the law and FCC regulations"</a>.
That's a quote from a 400-page Congressional study
"Intelligence activities and the rights of Americans: Book II"
issued in 1976.</p>
<p>The arrangement between telegraph companies and NSA was secret for
<a href="https://arstechnica.com/tech-policy/2013/06/how-a-30-year-old-lawyer-exposed-nsa-mass-surveillance-of-americans-in-1975/">decades</a>.
As one historian put it:</p>
<blockquote>
<p>Data created and collected by these firms
could be shared with the government quietly, protected from public scrutiny and outrage
by the twin concealments of classification and corporate secrecy.</p>
</blockquote>
<p>Oh, oops, that isn't actually a quote about the telegraph companies.
It's a quote from the talk
that this blog post is commenting upon,
a quote specifically about what happened with Internet companies "following the 90s",
as if the mass-surveillance industry were something new.</p>
<p>For people who study the history and incentives,
it's completely unsurprising to see 21st-century examples
of corporations and governments working together on surveillance.
I mentioned some examples in a
<a href="https://cr.yp.to/talks.html#2012.09.24">2012 talk</a>.
The 2013 Snowden disclosures included
<a href="https://www.theguardian.com/world/2013/jun/06/us-tech-giants-nsa-data">more examples</a>.
I'll take a moment here to recommend
<a href="https://www.youtube.com/watch?v=Cj3PN5-n108">my own 2015 talk</a>
about the corporate incentives,
including further examples
of attack activities by corporations.
But the point I'd like to emphasize here is that
corporate surveillance was already burgeoning in the 20th century.
The surveillance scandals that Congress investigated in the 1970s
weren't just government scandals.</p>
<p>Let's get back to the thesis:</p>
<blockquote>
<p>The ability to ensure privacy for consumers in
market transactions against criminals was therefore paired with offers to work cooperatively with
government to ensure LEAs and intelligence agencies obtained decrypted communications.</p>
</blockquote>
<p>What does "paired" mean?</p>
<p>Yes,
there was an overlap between
(1) the corporations asking Congress for freedom to sell strong cryptographic software
and
(2) the corporations offering to support government surveillance.
Sometimes the corporations were pointing to #2 as an argument for #1.</p>
<p>But "paired" sounds to me like it's saying
that one of these wouldn't exist without the other.
That's not true.
 #1 and #2 are each examples of
corporations pursuing their money-making goals;
neither one relies on the other.
The telegraph companies secretly delivering copies of telegrams to NSA
weren't selling cryptographic software.</p>
<p>The thesis continues as follows:</p>
<blockquote>
<p>Privacy from criminals in the market had the paradoxical effect of facilitating the contraction of
privacy from police surveillance.</p>
</blockquote>
<p>I guess this is the specific source of the surprising claim
highlighted at the beginning of this blog post,
namely that
"the legacy of the crypto wars was to trade privacy for encryption—and to usher in an age of mass corporate surveillance".
But, again,
what's the mechanism that's
supposed to have created this negative effect,
and how do we reconcile this with the observed facts of what was happening already?</p>
<p>The thesis continues by claiming that
"in the year 2000 ...
NSA began investing billions of dollars in secret efforts to break commercial
encryption systems".</p>
<p>No, 2000 isn't when that began.
Tanja Lange and I recently wrote a paper
<a href="https://cr.yp.to/papers.html#safecurves">"Safe curves for elliptic-curve cryptography"</a>,
including an appendix that summarizes
NSA's resources in the mid-1990s:</p>
<blockquote>
<p>The Federation of American Scientists used public data to conclude in 1996 [98]
that the "NSA budget is around $3.6 billion", including "roughly 20,000
direct-hire NSA staff". Even if personnel expenses for an average staff member
were as high as $100000, NSA would have had $1.6 billion in 1996 to spend on
equipment.</p>
<p>Declassification requests by journalists led to partial declassification in 2013
of internal NSA history books from 1998 and 1999. These books confirm the
20,000 number; see, e.g., [145, page 23]. These books also say [146, page 291]
that NSA spent $199 million in 1984 on a single contract to buy 21,000 IBM PC
XTs so as to put a PC on each desk; that NSA spent $150 million in 1985 on a
single network-hardware contract; and that "computer power was the essential
ingredient in cryptanalysis".</p>
</blockquote>
<p>Another internal NSA document says that
<a href="https://web.archive.org/web/20230430105513/https://www.nsa.gov/portals/75/documents/news-features/declassified-documents/nsa-early-computer-history/6586785-nsa-key-role-in-major-developments-in-computer-science.pdf">"since the middle of the last century, automation has been used as a way to greatly
ease the making and breaking of codes"</a>
and gives examples of NSA's investments in cryptanalytic hardware.</p>
<p>Meanwhile NSA was also spending money attacking cryptography in other ways.
NSA and CIA
<a href="https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/">secretly purchased Crypto AG</a>
in 1970,
and sabotaged the cryptography that Crypto AG was selling.
As another example,
NSA hoped that developing DES would
<a href="https://archive.org/details/cold_war_iii-nsa/cold_war_iii-ISCAP/page/n239/mode/2up">"drive out competitors"</a>
such as
<a href="https://www.ithistory.org/honor-roll/dr-martin-john-m-atalla">Atalla Corporation</a>.</p>
<p>The thesis attributes its claimed 2000 starting date to the Snowden documents.
This doesn't have pinpoint references,
but seems to be alluding to an
<a href="https://cdn.prod.www.spiegel.de/media/f94a2e13-0001-0014-0000-000000035532/media-35532.pdf">internal GCHQ presentation</a>
from 2010.
The presentation says that
"for the past decade, NSA has lead an aggressive, multipronged effort to break widely used Internet encryption technologies"
such as "SSL" and "SSH" and "VPNs";
that "cryptanalytic capabilities are now coming on line";
and that
"vast amounts of encrypted Internet data which have up till now been discarded are now exploitable."</p>
<p>Is this saying that NSA started attacking cryptography around 2000?
No.
It's talking specifically about NSA trying,
evidently with some level of success,
to attack particular "Internet encryption technologies".</p>
<p>How is any of this supposed to show that
<em>preserving</em> cryptographic export controls
would have made surveillance <em>harder</em>?</p>
<p>Later the thesis describes the corporate-plus-government objectives as follows:
"how could informational privacy in the market be assured so that American
technology firms could dominate world markets,
all while securing avenues for LEA surveillance?"</p>
<p>Yes, there's an objective of world domination
for big technology firms such as,
to take a 21st-century example, Facebook.
Yes, mass surveillance is the centerpiece of Facebook's business model.
Yes, Facebook shares data with the government.</p>
<p>But how did Facebook's rise to dominance supposedly rely on "informational privacy"?
What's the mechanism
by which preserving cryptographic export controls
would supposedly have prevented Facebook's dominance?
How do we reconcile this with reports from 2010 saying that
connections to Facebook
<a href="https://cdt.org/insights/dont-get-hijacked-on-the-net-firesheep-and-https/">weren't even encrypted</a>?
Facebook had already grown to half a billion users at that point.</p>
<h2>6. The future</h2>
<p>I hope you're troubled by mass surveillance.
I hope you have the time and energy to do something about it.
I know many of my readers are doing this already.</p>
<p>Doing something doesn't mean
magically solving the whole problem all at once.
It means picking a specific task
where you can reasonably hope to make progress,
and working on that.</p>
<p>For example,
maybe you engage in the policy fight against
<a href="https://homes.esat.kuleuven.be/~preneel/Open_letter_CSAR_aug24_still_unacceptable.pdf">surveillance mandates</a>.
Or maybe you expose
<a href="https://balkaninsight.com/2023/09/25/who-benefits-inside-the-eus-fight-over-scanning-for-child-sex-content/">the money flow behind those mandates</a>.
Or, as a programming example, maybe you work on tools for
<a href="https://ar.al/2020/08/07/what-is-the-small-web/">decentralization</a>.
There's much more to do.</p>
<p>But wait: what if there's some fundamental incompatibility
between stopping government surveillance
and stopping corporate surveillance?
If you try to stop government surveillance
then maybe you're helping the corporations!
If you try to stop corporate surveillance
then maybe you're helping the government!</p>
<p>Instead of enthusiastically working on making the situation better,
you start worrying that you might be making the situation worse.
This sort of concern can be paralyzing.
Safest not to do anything, right?
No matter how bad the status quo is,
if you avoid action then
at least you know you aren't doing any damage.
Primum non nocere.</p>
<p>When a talk claims that preserving cryptographic export controls
would have stopped the mass-surveillance industry,
the talk isn't just making a claim for an audience of historians.
It's influencing future action.
It's telling you that there's a tradeoff:
an unhappy choice between stopping one bad thing
and stopping another bad thing.
It's telling you to pause,
and to worry that <em>your</em> actions will similarly have bad effects.
That's the most important reason
to look at whether the claim is actually true,
as I've been doing in this blog post.</p>
<p>I'll close with a recommendation for further reading:
Phil Rogaway's paper
<a href="https://web.cs.ucdavis.edu/~rogaway/papers/moral.html">"The moral character of cryptographic work"</a>.</p><hr><span size="1"><b>Version:</b>
This is version 2024.10.28 of the 20241028-surveillance.html web page.
</span>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[New iMac with M4 (496 pts)]]></title>
            <link>https://www.apple.com/newsroom/2024/10/apple-introduces-new-imac-supercharged-by-m4-and-apple-intelligence/</link>
            <guid>41971726</guid>
            <pubDate>Mon, 28 Oct 2024 15:03:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2024/10/apple-introduces-new-imac-supercharged-by-m4-and-apple-intelligence/">https://www.apple.com/newsroom/2024/10/apple-introduces-new-imac-supercharged-by-m4-and-apple-intelligence/</a>, See on <a href="https://news.ycombinator.com/item?id=41971726">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 28, 2024</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple unveils the new iMac with M4, supercharged by Apple&nbsp;Intelligence and available in fresh colors
    

                    </h2>
                
            </div>

        <div>
                
                
                    The world’s best all-in-one desktop features even more performance, a nano-texture display option, a 12MP Center Stage camera, and Thunderbolt 4 connectivity — all in a strikingly thin design
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, The new iMac is shown in green, yellow, orange, ink, purple, blue, and silver.">
        <div>
             
              
              <div>
                Featuring the powerful M4 chip and the incredible capabilities of Apple Intelligence — all in its impossibly thin, all-in-one design — iMac is available in a parade of playful new colors.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-hero.zip" download="" data-analytics-title="download image - Apple-iMac-M4-hero_big" aria-label="Download media, The new iMac is shown in green, yellow, orange, ink, purple, blue, and silver."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong><span>CUPERTINO, CALIFORNIA</span></strong> Apple today announced the new <a href="https://www.apple.com/imac/" target="_blank">iMac</a>, featuring the powerful M4 chip and Apple Intelligence, in its stunning, ultra-thin design. With M4, iMac is up to 1.7x faster for daily productivity, and up to 2.1x faster for demanding workflows like photo editing and gaming, compared to iMac with M1.<sup>1</sup> With the Neural Engine in M4, iMac is the world’s best all-in-one for AI and is built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves, while protecting their privacy. The new iMac is available in an array of beautiful new colors, and the 24-inch 4.5K Retina display offers a new nano-texture glass option.<sup>2</sup> iMac features a new 12MP Center Stage camera with Desk View, up to four Thunderbolt 4 ports,<sup>3</sup> and color-matched accessories that include USB-C. Starting at just $1,299, now with 16GB of unified memory, the new iMac is available to pre-order today, with availability beginning Friday, November 8.
</div>
                 
             
                 <div>“iMac is beloved by millions of users, from families at home to entrepreneurs hard at work. With the incredible features of Apple Intelligence and the powerful performance of Apple silicon, the new iMac changes the game once again,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “With M4 and Apple Intelligence, gorgeous new colors that pop in any space, an advanced 12MP Center Stage camera, and a new nano-texture glass display option, it’s a whole new era for iMac.”
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="imac-lifestyle">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1fa9c68ce7284845790b2bb956e0210f" href="#gallery-1fa9c68ce7284845790b2bb956e0210f" data-ac-gallery-trigger="gallery-1fa9c68ce7284845790b2bb956e0210f"><span>Three people watch a scene from an animated movie on iMac.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-3ae24290341d987a5944a3cf1dbd1eff" href="#gallery-3ae24290341d987a5944a3cf1dbd1eff" data-ac-gallery-trigger="gallery-3ae24290341d987a5944a3cf1dbd1eff"><span>iMac is shown in the storefront of a business.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-1fa9c68ce7284845790b2bb956e0210f" aria-labelledby="gallery-dotnav-1fa9c68ce7284845790b2bb956e0210f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:people-watching-screen">
                                
                                <div>
                                    <div>The new iMac brings even more fun with bold new colors, enabling users to add a pop of personalization in their homes, workspaces, or storefronts.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-lifestyle-24-inch-Retina-display.zip" download="" data-analytics-title="download image - Apple-iMac-M4-lifestyle-24-inch-Retina-display_big" aria-label="Download media, Three people watch a scene from an animated movie on iMac."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-3ae24290341d987a5944a3cf1dbd1eff" aria-labelledby="gallery-dotnav-3ae24290341d987a5944a3cf1dbd1eff" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:business-storefront">
                                
                                <div>
                                    <div>The new iMac brings even more fun with bold new colors, enabling users to add a pop of personalization in their homes, workspaces, or storefronts.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-lifestyle-business-storefront.zip" download="" data-analytics-title="download image - Apple-iMac-M4-lifestyle-business-storefront_big" aria-label="Download media, iMac is shown in the storefront of a business."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Supercharged by M4</strong>
</h2>
                 
             
                 <div>The M4 chip brings a boost in performance to iMac. Featuring a more capable CPU with the world’s fastest CPU core,<sup>4</sup> the new iMac is up to 1.7x faster than iMac with M1. Users will feel this performance across everyday activities like multitasking between their favorite apps and browsing webpages in Safari. And with an immensely powerful GPU featuring Apple’s most advanced graphics architecture, iMac with M4 handles more intense workloads like photo editing and gaming up to 2.1x faster than iMac with M1. This also enables a smoother gameplay experience in titles like the upcoming Civilization VII. The new iMac comes standard with 16GB of faster unified memory — configurable up to 32GB. The Neural Engine in M4 is now over 3x faster than on iMac with M1, making it the world’s best all-in-one for AI, and accelerating the pace at which users can get things done.
</div>
                 
             
                 <div><strong>M4 takes iMac performance even further:</strong>
</div>
                 
             
                 <div><ul>
<li>Families, small businesses, and entrepreneurs can fly through daily productivity tasks with up to 1.7x faster performance<sup>1</sup> in apps like Microsoft Excel, and up to 1.5x faster browsing performance<sup>5</sup> in Safari compared to iMac with M1.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Gamers can enjoy incredibly smooth gameplay, with up to 2x higher frame rates<sup>5</sup> than on iMac with M1.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Content creators can edit like never before, with up to 2.1x faster photo and video editing performance when applying complex filters and effects in apps like Adobe Photoshop<sup>1</sup> and Adobe Premiere Pro<sup>5</sup> compared to iMac with M1.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Compared to the most popular 24-inch all-in-one PC with the latest Intel Core 7 processor, the new iMac is up to 4.5x faster.<sup>1</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Compared to the most popular Intel-based iMac model, the new iMac is up to 6x faster.<sup>1</sup></li>
</ul>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="imac-apps-and-games">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1975973939a0f1093d71502d61e55703" href="#gallery-1975973939a0f1093d71502d61e55703" data-ac-gallery-trigger="gallery-1975973939a0f1093d71502d61e55703"><span>On a purple iMac, a user has two windows open as they multitask between Safari and Excel.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-2907aed9f81d4a5d8d28a56464be1382" href="#gallery-2907aed9f81d4a5d8d28a56464be1382" data-ac-gallery-trigger="gallery-2907aed9f81d4a5d8d28a56464be1382"><span>On a green iMac, a user plays Civilization VII.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-03594bd5f78912542331e9445dac31a3" href="#gallery-03594bd5f78912542331e9445dac31a3" data-ac-gallery-trigger="gallery-03594bd5f78912542331e9445dac31a3"><span>On a blue iMac, a user uses Photoshop.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-1975973939a0f1093d71502d61e55703" aria-labelledby="gallery-dotnav-1975973939a0f1093d71502d61e55703" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:multitasking-safari-excel">
                                
                                <div>
                                    <div>iMac with M4 features the world’s fastest CPU core, making multitasking across apps like Safari and Excel lightning fast.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-Safari-and-Excel.zip" download="" data-analytics-title="download image - Apple-iMac-M4-Safari-and-Excel_big" aria-label="Download media, On a purple iMac, a user has two windows open as they multitask between Safari and Excel."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-2907aed9f81d4a5d8d28a56464be1382" aria-labelledby="gallery-dotnav-2907aed9f81d4a5d8d28a56464be1382" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:gaming-civilization-vii">
                                
                                <div>
                                    <div>With the power of M4 and its advanced GPU, iMac enables incredibly smooth gameplay in titles like the highly anticipated Civilization VII.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-Civilization-7.zip" download="" data-analytics-title="download image - Apple-iMac-M4-Civilization-7_big" aria-label="Download media, On a green iMac, a user plays Civilization VII."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-03594bd5f78912542331e9445dac31a3" aria-labelledby="gallery-dotnav-03594bd5f78912542331e9445dac31a3" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:photoshop">
                                
                                <div>
                                    <div>The new iMac with M4 flies through demanding creative workflows, such as applying complex filters and effects in apps like Adobe Photoshop and Adobe Premiere Pro.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-Photoshop.zip" download="" data-analytics-title="download image - Apple-iMac-M4-Photoshop_big" aria-label="Download media, On a blue iMac, a user uses Photoshop."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A New Era with Apple Intelligence on the Mac</strong>
</h2>
                 
             
                 <div><a href="https://www.apple.com/newsroom/2024/10/apple-intelligence-is-available-today-on-iphone-ipad-and-mac/" target="_blank">Apple Intelligence</a> ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user’s personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>With systemwide Writing Tools powered by Apple Intelligence, users can rewrite, proofread, and summarize text nearly everywhere they write — from Apple apps like Keynote, to third-party apps like Craft and Bear.</div>
        
            <a aria-label="Download video: Writing Tools Powered by Apple Intelligence" data-analytics-title="Download video - Writing Tools Powered by Apple Intelligence" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-intelligence-writing-tools/downloads/Apple-Intelligence-Writing-Tools.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>Apple Intelligence does all this while protecting users’ privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple’s even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. For those who choose to connect their account, OpenAI’s data-use policies apply.
</div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>The redesigned Siri helps users accelerate tasks throughout their day. Siri can be placed anywhere on the desktop for easy access, and with the option to type requests, users can get Siri’s help in even a quiet space like an office.</div>
        
            <a aria-label="Download video: Redesigned Siri Powered by Apple Intelligence" data-analytics-title="Download video - Redesigned Siri Powered by Apple Intelligence" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-intelligence-type-to-siri/downloads/Apple-Intelligence-type-to-Siri.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Array of Gorgeous New Colors</strong>
</h2>
                 
             
                 <div>The new iMac comes in seven vibrant colors, bringing fresh shades of green, yellow, orange, pink, purple, and blue, alongside silver. The back of iMac features bold colors designed to stand out, while the front expresses subtle shades of the new palette so users can focus on doing their best work. Every iMac comes with a color-matched Magic Keyboard and Magic Mouse or optional Magic Trackpad, all of which now feature a USB-C port, so users can charge their favorite devices with a single cable.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The new iMac in green is shown from the back.">
        <div>
             
              
              <div>
                The back of iMac features bold colors designed to stand out, while the front expresses subtle shades of the new palette so users can focus on doing their best work.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-green-iMac.zip" download="" data-analytics-title="download image - Apple-iMac-M4-green-iMac_big" aria-label="Download media, The new iMac in green is shown from the back."></a>
          </div>
      </figure>
    
  






    
    
    






    
    
    
    <div data-analytics-activitymap-region-id="Photo Grid: imac-and-accessories">
                <div>
                    <div><span>From left to right:</span> (1) iMac features a color-matched keyboard and mouse or trackpad. (2) These accessories now come with USB-C ports, so users can charge all of their favorite devices with just a single cable.</div>
                    
                    <div><span>From top to bottom:</span> (1) iMac features a color-matched keyboard and mouse or trackpad. (2) These accessories now come with USB-C ports, so users can charge all of their favorite devices with just a single cable.</div>
                </div>
                
                <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-green-Magic-Keyboard-green-Magic-Mouse.zip" download="" data-analytics-title="download" aria-label="Download both images"></a>
            </div>


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>New Nano-Texture Display Option</strong>
</h2>
                 
             
                 <div>The expansive 24-inch 4.5K Retina display on iMac is its highest-rated feature, and for the first time, it’s available with a nano-texture glass option that drastically reduces reflections and glare, while maintaining outstanding image quality.<sup>2</sup> With nano-texture glass, users can place iMac in even more spaces, such as a sun-drenched living room or bright storefront.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>With a new nano-texture glass option, which reduces glare while delivering outstanding image quality, users can place iMac in even more spaces, such as a sun-drenched living room or bright storefront.</div>
        
            <a aria-label="Download video: iMac Nanotexture Display Option" data-analytics-title="Download video - iMac Nanotexture Display Option" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-imac-m4-nano-texture-display/downloads/Apple-iMac-M4-nano-texture-display.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Enhanced Video Calls with 12MP Center Stage Camera</strong>
</h2>
                 
             
                 <div>A new 12MP Center Stage camera with support for Desk View makes video calls even more engaging. Center Stage keeps everyone perfectly centered on a video call — great for families gathered on FaceTime. Desk View makes use of the wide-angle lens to simultaneously show the user and a top-down view of their desk, which is useful for educators presenting a lesson to students, or creators showing off their latest DIY project. Rounding out the unrivaled audio and video experience is the beloved studio-quality three-microphone array with beamforming and an immersive six-speaker sound system.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>A new 12MP Center Stage camera makes video calls even more engaging, perfectly centering users and those around them in the frame, even when moving around.</div>
        
            <a aria-label="Download video: iMac Video Calls with Center Stage" data-analytics-title="Download video - iMac Video Calls with Center Stage" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-imac-m4-center-stage-camera/downloads/Apple-iMac-M4-Center-Stage-camera.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Advanced Connectivity</strong>
</h2>
                 
             
                 <div>On the new iMac, all four USB-C ports support Thunderbolt 4 for superfast data transfers, so users can connect even more accessories like external storage, docks, and up to two 6K external displays, creating a massive canvas with more than 50M pixels for users to spread out their work.<sup>3</sup> iMac also supports both Wi-Fi 6E and Bluetooth 5.3. And with the advanced security of Touch ID, users can easily and securely unlock their computer, make online purchases with Apple Pay, and download apps.<sup>6</sup> Additionally, Touch ID works with Fast User Switching, so customers can switch between different user profiles with just the press of a finger.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The back of the new iMac in orange shows four USB-C ports.">
        <div>
             
              
              <div>
                All four USB-C ports support Thunderbolt 4 for superfast data transfers, so users can connect even more accessories like external storage, docks, and up to two high-resolution displays.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apple-introduces-new-imac-supercharged-by-m4/article/Apple-iMac-M4-Thunderbolt-4-ports.zip" download="" data-analytics-title="download image - Apple-iMac-M4-Thunderbolt-4-ports_big" aria-label="Download media, The back of the new iMac in orange shows four USB-C ports."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>An Unrivaled Experience with macOS Sequoia</strong>
</h2>
                 
             
                 <div><a href="https://www.apple.com/macos/macos-sequoia-preview/" target="_blank">macOS Sequoia</a> completes the new iMac experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and its notifications directly from their Mac.<sup>7</sup> Safari, the world’s fastest browser,<sup>8</sup> now offers Highlights, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin’s Creed Shadows. Easier window tiling means users can stay organized with a windows layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials, all stored in one place. And users can apply beautiful new built-in backgrounds for video calls, including a variety of color gradients and system wallpapers, or upload their own photos.
</div>
                 
             
                 <h2><strong>Better for the Environment</strong>
</h2>
                 
             
                 <div>The new iMac with M4 is designed with the environment in mind, with 100 percent recycled aluminum in the stand, and 100 percent recycled gold plating, tin soldering, and copper in multiple printed circuit boards. iMac meets Apple’s high standards for energy efficiency, and is free of mercury, brominated flame retardants, and PVC. New this year, the packaging of iMac is entirely fiber-based, bringing Apple closer to its goal to remove plastic from its packaging by 2025.
</div>
                 
             
                 <div>Today, Apple is carbon neutral for global corporate operations and, as part of its ambitious Apple 2030 goal, plans to be carbon neutral across its entire carbon footprint by the end of this decade.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>Customers can pre-order the new iMac with M4 starting today, October 28, on <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a> and in the Apple Store app in 28 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, beginning Friday, November 8.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iMac starts at <strong>$1,299</strong> (U.S.) and <strong>$1,249</strong> (U.S.) for education, and is available in green, yellow, orange, pink, purple, blue, and silver. It features an 8-core CPU, an 8-core GPU, 16GB of unified memory configurable up to 24GB, 256GB SSD configurable up to 1TB, two Thunderbolt/USB 4 ports, Magic Keyboard, and Magic Mouse or Magic Trackpad.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iMac with a 10-core CPU and 10-core GPU starts at <strong>$1,499</strong> (U.S.) and <strong>$1,399</strong> (U.S.) for education, and is available in green, yellow, orange, pink, purple, blue, and silver. It features 16GB of unified memory configurable up to 32GB, 256GB SSD configurable up to 2TB, four Thunderbolt 4 ports, Magic Keyboard with Touch ID, and Magic Mouse or Magic Trackpad.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Additional technical specifications — including the nano-texture display option, configure-to-order options, and accessories — are available at <a href="https://www.apple.com/mac/" target="_blank">apple.com/mac</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a> to see what their device is worth.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in <em>Australia</em>, <em>Canada</em>,<em> Ireland,</em> <em>New Zealand</em>, <em>South Africa</em>, and the <em>U.K.</em>, and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Testing was conducted by Apple in September and October 2024. See <a href="https://www.apple.com/imac/" target="_blank">apple.com/imac</a> for more information.</li>
<li>Actual diagonal screen measurement is 23.5 inches. Nano-texture display is an option on models with 10-core CPU and 10-core GPU.</li>
<li>All four USB-C ports support Thunderbolt 4 on models with 10-core CPU and 10-core GPU.</li>
<li>Testing was conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks.</li>
<li>Results are compared to previous-generation 24-inch iMac systems with Apple M1, 8-core CPU, 8-core GPU, 16GB of RAM, and 2TB SSD.</li>
<li>iMac with 8-core CPU and 8-core GPU can configure to Magic Keyboard with Touch ID and Numeric Keypad, and iMac with 10-core CPU and 10-core GPU comes standard with Touch ID.</li>
<li>Available on Mac computers with Apple&nbsp;silicon and Intel-based Mac computers with a T2 Security Chip. Requires that the user’s iPhone and Mac are signed in with the same Apple&nbsp;Account using two-factor authentication, their iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and their Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone&nbsp;Mirroring.</li>
<li>Testing was conducted by Apple in August 2024. See <a href="https://www.apple.com/safari/" target="_blank">apple.com/safari</a> for more information.</li>
</ol>

        </div>



    
    
    






    

















		
		
			
























		
		

</article>



</section>
</main>


	

</div>]]></description>
        </item>
    </channel>
</rss>