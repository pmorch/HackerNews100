<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 29 May 2025 13:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Google is using AI to censor independent websites like mine (113 pts)]]></title>
            <link>https://travellemming.com/perspectives/ftc-letter-google-censors-indie-publishers-with-ai/</link>
            <guid>44124820</guid>
            <pubDate>Thu, 29 May 2025 11:05:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://travellemming.com/perspectives/ftc-letter-google-censors-indie-publishers-with-ai/">https://travellemming.com/perspectives/ftc-letter-google-censors-indie-publishers-with-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=44124820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p><em>[Note: What follows is a blog-post formatted version of the 34 page letter I submitted to the FTC on May 21, 2025 in response to the agency’s <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/P251203CensorshipRFI.pdf" target="_blank" rel="noopener">RFI entitled</a>: “Request for Public Comment Regarding Technology Platform Censorship.” I have also added a section at the end on <a href="#what-you-can-do">what you can do</a> to save the open web from Google’s AI takeover.]</em></p><p><strong>Introduction:</strong></p><p>I am an American citizen and founder of the Florida company Travel Lemming LLC. Travel Lemming runs a website, <a href="https://travellemming.com/">TravelLemming.com</a>, that provides online travel advice.&nbsp;</p><p>In this letter I will explain how Google censored my travel website – and thousands of small and independent web publishers like me – all so that it can use AI to control the flow of information online.&nbsp;</p><p>In late 2023 and early 2024, Google released an unprecedented series of algorithm updates that utterly decimated thousands of independent websites.&nbsp;</p><p>Travel Lemming lost more than 95% of our Google organic search referral traffic in these updates.&nbsp;</p><p>The shadowban algorithm that hit us was supposedly based on the content on our websites. But we later realized the shadowban really was about the <em>type </em>of website we are (i.e., small and independent).&nbsp;</p><p>While Google gives large publishers an appeal and recovery process, small and independent publishers have no path to appeal our shadowbans.&nbsp;</p><div><p>This is true even though Google <em>admitted </em>our shadowbans are its fault and not ours.</p><p><strong>In fact, last October, Google even flew me and 19 other publishers out to its headquarters for a tour, an admission of wrongdoing, and an apology.</strong></p></div><p>Though Google apologized, it also said that search has permanently changed with AI and thus our traffic may never return.&nbsp;</p><p>In this letter I will describe how I believe Google has been laying the groundwork for a grand plan to rethink search from the ground-up so as to profit from AI.&nbsp;</p><p><strong>Google isn’t satisfied with its monopoly on the questions we search.&nbsp;</strong></p><p><strong>Google wants to use AI to monopolize the very </strong><strong><em>answers </em></strong><strong>themselves.&nbsp;</strong></p><p>As one Google executive recently explained: “<em>Organizing information is clearly a trillion-dollar opportunity, but a trillion dollars is not cool anymore. What’s cool is a quadrillion dollars</em>.”</p><p>Google plans to use AI to consume and replace the open web.&nbsp;</p><p><strong>I believe demolishing independent sites like mine was Google’s first step in clearing ground so it has space to rebuild search from the ground up for an “AI-first” future.&nbsp;</strong></p><p>Google envisions a future where “<em>Google does the Googling for you</em>,” its AI and ads do the answering – and users never need to leave Google.&nbsp;</p><p>Google will just source information from a handful of sources and partner websites <em>that it controls and selects </em>– effectively creating an information cartel.&nbsp;</p><p>If Google can use AI to censor a travel website from the web arbitrarily and without opportunity for appeal – it can do the same to any source of information it wants.&nbsp;</p><p>And American citizens and Internet users everywhere will be worse off for it.&nbsp;</p><p>So while you may not really care about the plight of some random travel website getting censored, everyone should care about the way Google is deploying AI to build a censorship cartel that lets it control the flow of information online.&nbsp;</p><p>What follows is a lengthy summary of my experiences and my opinions as an independent publisher trying to survive in a monopolist’s information economy.&nbsp;</p><p>To start, let me explain how we got to this point where Google has the power to do this:&nbsp;</p><h2>Google Promised Publishers a “<em>fundamental fair exchange between Google and the web</em>”&nbsp;</h2><p>To lay the context for Google’s censorship, I need to briefly explain the social contract between Google and the open web – and how AI threatens to change it.&nbsp;</p><p><a href="https://www.google.com/intl/en_us/search/howsearchworks/our-approach/" target="_blank" rel="noopener">According to Google</a>, its “<em>mission is to organize the world’s information and make it universally accessible and useful</em>.”&nbsp;</p><p>In the early days of the Internet, Google gained popularity by promising to be a “<em>pure search engine</em>” that just provided links to websites with <em>“no distractions</em>”:&nbsp;&nbsp;</p><figure><img decoding="async" width="1024" height="768" src="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg" alt="A graphic showing the Google ad from 1999" srcset="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='768'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Ad-from-1999.jpg 1200w"><figcaption><em>A Google ad from 1999 (</em><a href="https://www.uniladtech.com/news/tech-news/google-ad-from-1999-588164-20240314" target="_blank" rel="noopener"><em>Source</em></a><em>)</em></figcaption></figure><p><strong><br></strong>To this day, Google’s official <a href="https://about.google/company-info/philosophy/" target="_blank" rel="noopener">corporate philosophy page</a> still states: “<em>We may be the only people in the world who can say our goal is to have people leave our website as quickly as possible</em>.”</p><div><p><strong>Google created a social contract with the online publishing industry: publishers provide content for Google to crawl and, in exchange, Google sends valuable clicks back to publishers.</strong></p><p>As recently as 2020, Google’s official blog recognized the existence of this social contract:&nbsp;</p></div><blockquote><p>“<em>Google Search has evolved since its early beginnings, but one thing that hasn’t changed is the </em><strong><em><mark>fundamental fair exchange between Google and the web</mark></em></strong><em>. Google crawls, indexes and links to websites in search results, and each search result includes a short preview of what to expect at the site. Websites gain free traffic from users interested in what they have to offer, and each user visit is an opportunity to build a long-term relationship and monetize through advertising or subscriptions</em>.”<br>–<a href="https://blog.google/outreach-initiatives/google-news-initiative/setting-record-straight-news/#:~:text=Google%20Search%20has%20evolved%20since,monetize%20through%20advertising%20or%20subscriptions" target="_blank" rel="noopener"><em>Google’s The Keyword Blog</em></a> (June 26, 2020, emphasis added)</p></blockquote><p>To this day, Google’s website <em>still </em>says the company believes search should “<strong><em>help creators succeed online</em></strong>” and that:&nbsp;</p><blockquote><p><em>“To support a healthy ecosystem of fresh and useful content in all the world’s languages, we help people, publishers, and businesses of all sizes succeed and be found by others. </em><strong><em><mark>We do this by sending visitors to websites small and large through our search results</mark></em></strong><em>, or by connections such as listing business addresses and phone numbers. We don’t charge to be in our search listings, and we also provide free tools and resources to help site owners be successful.” <br>–</em><a href="https://www.google.com/intl/en_us/search/howsearchworks/our-approach/" target="_blank" rel="noopener"><em>Google’s “Our approach to search” webpage</em></a> (accessed May 18, 2025, emphasis added)&nbsp;</p></blockquote><h2>Google Encouraged Americans to “Create Millions of Sustainable Content-First Businesses on the Web”</h2><p>Google didn’t just promise a fair exchange of content for clicks – Google <em>actively encouraged</em> Americans to start small online businesses creating content.&nbsp;</p><p>In 2018, shortly after I started Travel Lemming, <a href="https://blog.google/products/adsense/looking-back-looking-forward/" target="_blank" rel="noopener">Google told publishers</a>: “<em>the world has an insatiable appetite for great content and publishers like you remain the beating heart of the open web. Sharing in this mission with you, helping to create </em><strong><em><mark><span>millions of sustainable content-first businesses on the web</span></mark></em></strong><em>, keeps us going</em>.”</p><h2>Google Promised to Give Small &amp; Independent Publishers a Fair Shot on the Open Web</h2><div><p>Importantly, Google promised that its “<em>fundamental fair exchange</em>” of content for clicks would be a marketplace open not just to massive legacy news publications, but also to new, small, and independent websites.&nbsp;</p><p>In 2014, Google representative <a href="https://www.youtube.com/watch?v=7XHAhn8HCzs" target="_blank" rel="noopener">Matt Cuts told publishers in a video</a>: “<em>The small guys absolutely can outperform the larger guys as long as they do a really good job at it.</em>”&nbsp;</p></div><p>The way smaller publishers could compete? Quality content!&nbsp;</p><p>Cutts encouraged sites: “<em>don’t stop trying to produce superior content, because over time that’s one of the best ways to rank higher on the web</em>.”&nbsp;</p><p>But what makes content “superior” and worthy of receiving Google clicks?&nbsp;</p><p>Well, Google had things to say about that too …&nbsp;</p><h2>Google Promised to Reward Publishers Who Invest Resources Into Content Created “<em>By People, For People</em>”&nbsp;</h2><div><p>Google provides websites with <a href="https://developers.google.com/search/docs/fundamentals/seo-starter-guide" target="_blank" rel="noopener">extensive documentation</a> on what kind of content Google <em>says </em>it seeks to reward with search traffic.</p><p>Google says “<em>While there’s no guarantee that any particular site will be added to Google’s index, sites that follow the </em><a href="https://developers.google.com/search/docs/essentials" target="_blank" rel="noopener"><em>Search Essentials</em></a><em> are more likely to show up in Google’s search results</em>.”</p><p>At the top of Google’s list of “key best practices” for websites is an instruction to “<em>[c]reate helpful, reliable, people-first content</em>.”&nbsp;</p></div><p>Google <a href="https://developers.google.com/search/docs/fundamentals/creating-helpful-content" target="_blank" rel="noopener">has a whole page</a> that with questions webmasters can ask to self-assess whether they are creating the kind of content Google seeks to reward. Some examples are:&nbsp;</p><ul><li><em>“Does your content clearly demonstrate first-hand expertise and a depth of knowledge (for example, expertise that comes from having actually used a product or service, or visiting a place)?”</em></li>

<li><em>“Is this content written or reviewed by an expert or enthusiast who demonstrably knows the topic well?”</em></li>

<li><em>“Does the content provide original information, reporting, research, or analysis?</em>”</li></ul><p>In short, <strong>Google </strong><strong><em>claims </em></strong><strong>it rewards publishers who invest resources and effort into their content</strong> – as opposed to spammers, who often use automated or low-effort content production systems.&nbsp;</p><p>In August 2022, Google summed up this guidance in a now-infamous blog post announcing Google was “<em>rolling out a series of improvements to Search to make it easier for people to find helpful content made by, and for, people</em>.”&nbsp;</p><figure><img decoding="async" width="1024" height="535" src="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg" alt="A Google's blog post, titled more content by people, for people in Search" srcset="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-300x157.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-768x401.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-600x314.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='535'%20viewBox='0%200%201024%20535'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-Blog-Post-1024x535.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-300x157.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-768x401.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post-600x314.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Blog-Post.jpg 1200w"><figcaption><em>Google’s </em><a href="https://blog.google/products/search/more-content-by-people-for-people-in-search/?utm_source=newsletter&amp;utm_medium=referral&amp;utm_campaign=content-by-people-for-people-is-at-the-core-of-the-new-google-update" target="_blank" rel="noopener"><em>blog post</em></a><em> calling for “more content by people, for people in Search”</em></figcaption></figure><h2>Like Many Small &amp; Independent Publishers, My Website Invested Enormous Resources Into Creating Content “By People, For People”&nbsp;</h2><p>While Google’s Gemini AI will create you a blog post with just a click of a button, creating content by people, for people, is — by contrast – an enormously expensive and laborious proposition.&nbsp;</p><p>At Travel Lemming, we ban AI content flat out. Instead, we produce guides written by knowledgeable locals and destination experts. We hire employees and freelance creators in destinations around the United States and the world, and pay them fair wages.&nbsp;</p><p>Our creators actually visit the places we write about.&nbsp;</p><p>Our creators take and publish thousands of original photos.&nbsp;</p><p>Our creators create original videos, podcasts, and multimedia content to share on the site.&nbsp;</p><p>And, because the world is constantly changing, we also invest significant resources into updating our guides and keeping them fresh and accurate over time.&nbsp;</p><p>We also invest considerable resources engaging with our community. We respond to thousands of reader comments, emails, and messages with personalized travel advice.&nbsp;</p><p>We also host free community meetups in 8 cities in the US and Canada.&nbsp;</p><p>We are not a perfect travel guide. If you look hard enough at any website you’ll find imperfections, and we have many. But we really do <em>try </em>to create the kind of content Google claims it rewards.&nbsp;</p><p><strong><span>And here’s the thing – creating content by people, for people, is incredibly expensive.</span></strong></p><p>Travel Lemming invests tens of thousands of dollars every month on the costs of producing and maintaining our travel guides.&nbsp;</p><p>And that doesn’t even include the opportunity cost of my time as founder.&nbsp;</p><p>For me, founding Travel Lemming <a href="https://thepenngazette.com/vagabond-publisher/" target="_blank" rel="noopener">meant leaving behind</a> a much more stable and promising legal career.</p><p>The path of online content creation is one of enormous risk and uncertainty. There is no guarantee of a paycheck each month. No one gives you health insurance, benefits, or paid vacation. If you fail, you often fail hard.&nbsp;</p><div><p>At the time I started the blog, I still had nearly six figures in law school debt (debt I only finally paid off in 2023, just months before Google’s shadowban devastated Travel Lemming).</p><p>In 2020, pandemic-related restrictions on travel devastated Travel Lemming’s traffic and, with it, my personal finances.&nbsp;</p></div><p>I was faced with a choice: close the business, or take drastic action.&nbsp;</p><p>Against the advice of nearly everyone close to me, I doubled down on my passion and invested in myself. I sold my one remaining significant financial asset – my house in Denver – and invested the proceeds into Travel Lemming’s content.&nbsp;</p><div><p>I say none of this to elicit sympathy for me personally. I have done well in life and I am enormously grateful for all I have given. Travel Lemming, despite the challenges and the betrayal by Google, persists in our mission of helping our readers wherever they can still find us.</p><p>But I do want to show that <span><strong>creating content “by people, for people” has a very real human cost</strong>.</span></p></div><p><strong><span>And that cost is only worth it if there is an open web ecosystem that properly incentivizes talented entrepreneurs to create high quality content for the web.</span></strong></p><p>Google says it supports such an ecosystem, but let’s look at what it really does …&nbsp;</p><h2>Meanwhile, Google Monopolized Search, Subjugating Publishers of All Sizes Into a Dependent Relationship&nbsp;</h2><p>Google promised publishers a “fair exchange” of content for valuable traffic. But exchanges seldom remain fair when one party wields unfair leverage over the other.&nbsp;</p><p>Over the past decade, Google has come to dominate – and monopolize – the way that Americans search for and retrieve information.&nbsp;</p><p>A <a href="https://www.courtlistener.com/docket/18552824/1033/united-states-of-america-v-google-llc/" target="_blank" rel="noopener">federal court recently found</a> Google illegally built and maintained a monopoly over the search market, noting that Google has a 90+% search market share.&nbsp;</p><p>One consequence of Google’s illegal search monopoly is that web publishers have been forced into a dependent relationship with Google.&nbsp;</p><p>The reality is that search is the main driver of traffic to most content websites.&nbsp;&nbsp;</p><p>A <a href="https://sparktoro.com/blog/who-sends-traffic-on-the-web-and-how-much-new-research-from-datos-sparktoro/" target="_blank" rel="noopener">2024 report by SparkToro</a> found that more than <strong><span>74% of web traffic referrals come from search engines – and 64% come from Google</span></strong>.&nbsp;</p><p>Search referral traffic is an even more important revenue source for informational websites, such as travel guides like ours. Search is where users seek out the type of long-form guide content we create. Social media may be great for quick visual inspiration, but search is still where most travelers plan the specifics of their trips.&nbsp;&nbsp;</p><p>And, because Google has a monopoly on search, online publishers are fundamentally dependent on Google.&nbsp;</p><p><strong><span>It’s a monopolist’s web, and we’re just publishing in it.</span></strong></p><p>Which gives Google a lot of power, including the power to effectively hide entire businesses from being found.&nbsp;</p><h2>After ChatGPT, Google Executives Announced a Plan to “Reimagine” and “Reinvent” Search for an “AI-First” Future&nbsp;</h2><div><p>In late 2022, just a few months after Google’s call for “<em>more content by people, for people in Search</em>,” ChatGPT took the world by storm.</p><p>Though Google had been working on its own AI ambitions for years, the emergence of ChatGPT reportedly caused Google to <a href="https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html" target="_blank" rel="noopener">declare a “code red”</a> internally – dramatically restructuring the company, calling in its former founders, and reworking everything around AI.&nbsp;</p></div><p>In February 2023, then-Google SVP Prabhakar Raghavan <a href="https://edition.cnn.com/2023/02/08/tech/google-search-event/index.html" target="_blank" rel="noopener">announced</a> that Google was “<em>reinventing what it means to search</em>.”&nbsp;</p><p>At Google’s annual I/O event in May, 2023, CEO Sundar Picahi <a href="https://www.reuters.com/technology/google-expected-unveil-its-answer-microsofts-ai-search-challenge-2023-05-10/#:~:text=Sign%20up%20here" target="_blank" rel="noopener">reiterated</a> the scope of the change, saying: “<em>We are reimagining all of our core products, including search</em>.”&nbsp;</p><p>After the event, <a href="https://www.theverge.com/2023/5/10/23717120/google-search-ai-results-generated-experience-io" target="_blank" rel="noopener"><em>The Verge</em></a> declared in a headline: “<em>The AI takeover of Google Search starts now</em>.”&nbsp;</p><p>That article astutely observed: “<em>The future of Google Search is AI. But not in the way you think</em>.”&nbsp;</p><p>You see, Google wasn’t planning to compete head on in a chatbot war with OpenAI.&nbsp;</p><p>Instead, as <em>The Verge </em>explained, Google decided to leverage its search market share to put “<em>AI front and center in the most valuable real estate on the internet: its existing search results</em>.”&nbsp;</p><h2>“Reimagining Search” Means Reworking the Open Web’s Social Contract&nbsp;</h2><div><p>Reimagining search means reworking the social contract that had underpinned the open web ecosystem for decades, something Google CEO Sundar Pichai acknowledged in <a href="https://abc.xyz/2023-q2-earnings-call/" target="_blank" rel="noopener">Alphabet’s 2023 Q2 earnings call</a> in July, 2023.</p><p>In that call, Pichai told investors in that call that AI presented “<em>an opportunity to reimagine many of our products, including our most important product, Search</em>” and that Google was “<em>engaging with the broader ecosystem and </em><strong><em>will continue to prioritize approaches that send valuable traffic and support a healthy, open web</em></strong>.” (emphasis added)</p></div><p>That same month, Google <a href="https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/" target="_blank" rel="noopener">published a blog post</a> for webmasters entitled “<em>A principled approach to evolving choice and control for web content</em>,” saying:</p><blockquote><p>“<em>We believe everyone benefits from a vibrant content ecosystem. Key to that is web publishers having choice and control over their content, and opportunities to derive value from participating in the web ecosystem. However, </em><strong><em><mark><span>we recognize that existing web publisher controls were developed before new AI and research use cases</span></mark></em></strong>.” (emphasis added)&nbsp;</p></blockquote><p>In short, Google was acknowledging that any fair approach to an AI-first web would require re-writing the web’s underlying social contract.</p><h2>So Google Promised Publishers a “Public Discussion” About the Future of the Web and AI (But Never Gave Us A Chance to Speak)</h2><p>In that 2023 <a href="https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/" target="_blank" rel="noopener">blog post</a>, Google promised a “<em>public discussion</em>” to “<em>evolve standards and protocols that support the web’s future development</em>.”&nbsp;</p><p>Specifically Google was speaking about robots.txt – the <a href="https://en.wikipedia.org/wiki/Robots.txt" target="_blank" rel="noopener">voluntary protocol</a> that publishers use to control which crawlers crawl our sites for which purposes.&nbsp;</p><p>This protocol lets publishers block Google’s crawlers if we don’t want our content to appear in Google’s search results.&nbsp;</p><p>However, robots.txt was designed decades ago, well before the AI age.&nbsp;</p><p>The protocol provides a very “all or nothing” choice, and doesn’t give publishers the type of granular control we need to really be able to control how our content is used by AI systems (and <em>which </em>AI<em> </em>systems).&nbsp;</p><p>Why is granular control so important to publishers?&nbsp;</p><p>Well, because publishers want Google to pay us when it uses our content for its AI features.&nbsp;</p><p>But we have no real leverage to negotiate if Google <em>already </em>has access to our content for its search indexing.&nbsp;</p><p>As the US Department of Justice <a href="https://www.courtlistener.com/docket/18552824/1052/united-states-of-america-v-google-llc/" target="_blank" rel="noopener">recently explained its proposed remedies</a> in the search antitrust case, <strong><mark>web publishers “<em>have little-to-no bargaining power against Google’s monopoly</em>”</mark></strong> because Google can “<em>leverage its monopoly power to feed artificial intelligence features</em>” our content, which we have to provide if we want our websites to be visible in online search.</p><p>Google now opposes the DOJ’s proposed remedy to give publishers more granular control over how AI companies use our content.&nbsp;</p><p>But back in <a href="https://blog.google/technology/ai/ai-web-publisher-controls-sign-up/" target="_blank" rel="noopener">its July, 2023 blog post</a>, Google seemed to <em>agree </em>robots.txt isn’t enough:</p><blockquote><p>“<em>As new technologies emerge, they present opportunities for the web community to evolve standards and protocols that support the web’s future development. One such community-developed web standard, robots.txt, was created nearly 30 years ago and has proven to be a simple and transparent way for web publishers to control how search engines crawl their content. </em><strong><em><span>We believe it’s time for the web and AI communities to explore <mark>additional machine-readable means for web publisher choice and control</mark> for emerging AI and research use cases</span></em></strong>.” (emphasis added)</p></blockquote><p>After that blog post, Google’s promised “public discussion” about web publisher control never actually happened.&nbsp;</p><p>The blog post led to a <a href="https://services.google.com/fb/forms/ai-web-publisher-controls-external/" target="_blank" rel="noopener">now-closed form</a> that only asked for contact info and didn’t even give us a field to write comments.&nbsp;</p><p>I filled my contact info into the form, but there was never really a public discussion apart from a single one-off webinar.&nbsp;</p><p>Months later, in March 2024, I complained about this silent treatment <a href="https://x.com/natejhake/status/1772215355475185729" target="_blank">on X</a>.&nbsp;</p><p>Google representative John Mueller replied (in a post he has <a href="https://x.com/natejhake/status/1772371278998950029" target="_blank">since apparently <s>deleted </s>restricted</a>):&nbsp;</p><figure><img decoding="async" width="1024" height="511" src="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg" alt="A reply from Google representative John Mueller" srcset="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg 1024w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-300x150.jpg 300w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-768x383.jpg 768w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-600x300.jpg 600w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='511'%20viewBox='0%200%201024%20511'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg" data-srcset="https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-1024x511.jpg 1024w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-300x150.jpg 300w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-768x383.jpg 768w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet-600x300.jpg 600w, https://travellemming.com/wp-content/uploads/John-Mueller-Tweet.jpg 1200w"><figcaption><em>A restricted X post by Google rep John Mueller from March 26, 2024</em></figcaption></figure><p>A single one-off “webinar” and a few unpublicized discussions at foreign conferences abroad do not, in my opinion, constitute a “public discussion” on an issue of such importance.&nbsp;</p><p>And what about the “Google-Extended” directive Mueller mentions?&nbsp;</p><p>Well, Google <a href="https://searchengineland.com/google-extended-crawler-432636" target="_blank" rel="noopener">announced</a> that in October 2023. But Google-Extended <em>is a robots.txt directive</em> – in other words, <em>precisely </em>what Google’s initial blog post admitted was an insufficient control mechanism for the AI age.&nbsp;</p><p><strong>So why did Google do a 180 on publisher controls in late 2023?&nbsp;</strong></p><p>Well, I can only speculate – but it might have had something to do with my question back to Mueller in the tweet above (which he never answered).&nbsp;</p><p>Because as it turns out …&nbsp;</p><h2>Behind Closed Doors, Google Was Secretly Negotiating a <em>Private </em>Contract with Reddit&nbsp;</h2><div><p>Publishers were not the only ones concerned about Google scraping our content to feed its AI systems.</p><p>The owners of the social media platform Reddit were very vocal that they didn’t think it was fair for AI companies to scrape and use Reddit’s content for free.&nbsp;</p></div><p>They even started making noises about Reddit blocking Google’s search crawlers.&nbsp;</p><p>In an April 2023 <a href="https://www.nytimes.com/2023/04/18/technology/reddit-ai-openai-google.html" target="_blank" rel="noopener"><em>New York Times</em> article</a>, Reddit CEO Steve Huffman said: “<em>Crawling Reddit, generating value and not returning any of that value to our users is something we have a problem with … It’s a good time for us to tighten things up</em>.”&nbsp;</p><p>Unlike independent publishers, though, Reddit actually had leverage over Google. Reddit was the owner of a trove of historical user generated content that Google wanted for its grand AI plans.&nbsp;</p><p>If Google could secure a deal for Reddit’s content, maybe that would spare Google the expense of negotiating licensing deals with the web’s many disparate publishers and rightsholders.&nbsp;</p><p>We didn’t know it at the time, but <strong>even as Google strung publishers along in 2023 with false promises of a public discussion, behind closed doors the search monopolist was negotiating a private contract with Reddit</strong>.&nbsp;</p><p>Although I and others had our suspicions at the time, the existence of the Reddit-Google negotiations remained a secret until their eventual deal <a href="https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/" target="_blank" rel="noopener">was announced</a> in February, 2024.&nbsp;</p><p>(more on that later)&nbsp;</p><p>Meanwhile, as summer 2023 drew to a close, Google was working on algorithm updates that would start laying the groundwork for its “reimagined” AI-first version of search – and for a new social contract for the web that it would unilaterally write.&nbsp;</p><p>A new social contract that, as it would turn out, excluded independent publishers …&nbsp;</p><h2>Google Begins Demolishing the Open Web So It Can “Reimagine Search” from the “Ground Up” for an AI-First Future</h2><p>In summer 2023, we and many other publishers were very apprehensive about AI. But some of us held out hope Google might responsibly guide the open web through the transition to the AI future.&nbsp;</p><p>At Travel Lemming, we continued to invest exclusively in content “written by people, for people” even as pressure grew in the industry to use new AI tools to create cheaper content at scale.&nbsp;</p><p>Importantly, <em>Google still claimed</em> in its webmaster documentation that it wanted to prioritize human-created content in its ranking algorithms.&nbsp;</p><p>Surely, I thought, Google would realize that publishers are the beating heart of the open web ecosystem – and that even an AI-first future requires publishers who create fresh material for AIs to use and learn from.&nbsp;</p><p>In my view, AI is a poor substitute for human publishers.&nbsp;</p><p>AI is inherently derivative.&nbsp;</p><p>AI cannot experience the world.&nbsp;</p><div><p>AI cannot visit a place.</p><p>AI cannot handle a product.&nbsp;</p></div><p>AI can only take, summarize, and regurgitate what <em>other </em>actual humans have created.&nbsp;</p><p>And, most importantly, Google had spent the prior years making <em>such </em>a big deal about wanting to elevate content “by people, for people.”&nbsp;</p><p><strong>After making such a big deal about the importance of human content, wouldn’t it be hypocritical for Google to suddenly put AI content at the center of search?&nbsp;</strong></p><p>Well, yes, it would be.&nbsp;</p><p>So …&nbsp;</p><h2>Google Quietly Erased “Written by People” From Its Guidance for Websites</h2><p>Google did what any good monopolist does when it gets caught breaking the rules. It just changed the rulebook.&nbsp;</p><p>On September 14, 2023, <a href="https://gizmodo.com/google-search-written-by-people-helpful-content-update-1850848956" target="_blank" rel="noopener">Google quietly updated its documentation</a> to remove “written by people” from its guidance for websites:</p><figure><img decoding="async" width="1024" height="427" src="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg" alt="A graphic showing changes from Google" srcset="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Change-300x125.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Change-768x320.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Change-600x250.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Change.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='427'%20viewBox='0%200%201024%20427'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-Change-1024x427.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Change-300x125.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Change-768x320.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Change-600x250.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Change.jpg 1200w"><figcaption><em>A before and after screenshot showing Google’s change (Source: </em><a href="https://searchengineland.com/google-september-2023-helpful-content-system-update-rolling-out-431978" target="_blank" rel="noopener"><em>Search Engine Land</em></a><em>)</em></figcaption></figure><h2>The Same Day, Google Unleashed an Algorithmic Wrecking Ball on Independent Web Publishers</h2><p>To reimagine search from the ground up, Google had to begin by tearing down what was currently there.&nbsp;</p><p>By this summer 2023, Google knew it wanted to insert AI directly into search results.&nbsp;</p><p>But rolling out AI all at once would mean a massive drop in clicks for publishers – and a potential litigation threat for Google.&nbsp;</p><p><strong>So Google started its AI demolition project by razing the parts of the open web least capable of fighting back: independent publishers.&nbsp;</strong></p><p>Google implemented this demolition project under the pretext of search ranking algorithm updates.&nbsp;</p><p>Google frequently adjusts its rankings algorithms to change how its systems rank web content. Announced algorithm updates happen several times a year and are a recurring part of life for publishers on the open web.&nbsp;</p><p>As a publisher focused on human-first content, Travel Lemming had never really worried too much about Google’s updates.&nbsp;</p><p>Indeed, Google’s <a href="https://developers.google.com/search/updates/core-updates#:~:text=updates%20status" target="_blank" rel="noopener">guidance to webmasters</a> still states that “<em>most sites don’t need to worry about core updates and may not even realize one has happened</em>.”&nbsp;</p><p>And, indeed, Travel Lemming had never once seen a negative effect from a Google update.&nbsp;</p><p>Plus, even when I witnessed other sites getting hit by past updates, the effect typically was only partial (something on the order of a 10-25% drop in traffic). And those webmasters were usually given opportunities to improve their site and to recover ranking, which they often did.&nbsp;</p><p>But this time was different.&nbsp;</p><p><strong>On September 14, 2023 – the same day Google removed “written by people” from its guidance – a massive Google algo was announced.&nbsp;</strong></p><p><strong>Almost immediately, search referral traffic to Travel Lemming plummeted:&nbsp;</strong></p><figure><img decoding="async" width="1024" height="566" src="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg" alt="A graphic showing the Travel Lemming's search traffic in Google Search Console" srcset="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg 1024w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-768x424.jpg 768w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-600x332.jpg 600w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='566'%20viewBox='0%200%201024%20566'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-1024x566.jpg 1024w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-768x424.jpg 768w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console-600x332.jpg 600w, https://travellemming.com/wp-content/uploads/Travel-Lemmings-Google-Search-Console.jpg 1200w"><figcaption><em>A graphic of Travel Lemming’s search referral traffic report in Google Search Console, overlaid with contemporaneous headlines</em><sup data-fn="ce0a92e3-1027-45cd-a7ba-0c787e4a8635"><a id="ce0a92e3-1027-45cd-a7ba-0c787e4a8635-link" href="#ce0a92e3-1027-45cd-a7ba-0c787e4a8635">1</a></sup></figcaption></figure><p>The effect on Travel Lemming’s traffic and business was swift and devastating.&nbsp;</p><p>That September update that hit us was nicknamed “The Helpful Content Update.” It was an update to the content system Google had announced a year earlier.&nbsp;</p><p>And it was only the beginning of the carnage …&nbsp;</p><h2>Between Fall 2023 and Spring 2024, Google Updates Systematically Demolished Independent Publishers&nbsp;</h2><p>Between fall 2023 and spring 2024, <a href="https://www.bbc.com/future/article/20240524-how-googles-new-algorithm-will-shape-your-internet" target="_blank" rel="noopener">Google unleashed a flurry of updates</a> on a scale that hadn’t been seen in nearly a decade, both in terms of their frequency and their overall effect on the web ecosystem.&nbsp;</p><p><span><strong>By the time this wave of updates finished in May 2024, Travel Lemming’s organic search referrals from Google had been reduced by more than 97%.</strong></span></p><p>At least our site was not alone in our misery.&nbsp;</p><p>Google’s flurry of updates decimated independent sites across the board: <a href="https://housefresh.com/david-vs-digital-goliaths/" target="_blank" rel="noopener">product review sites</a>, <a href="https://retrododo.com/google-is-killing-retro-dodo/" target="_blank" rel="noopener">gaming sites</a>, <a href="https://www.giantfreakinrobot.com/ent/independent-ends.html" target="_blank" rel="noopener">entertainment websites</a>, <a href="https://www.youtube.com/watch?v=FozpcXclAtU" target="_blank" rel="noopener">fitness websites</a>, and more verticals felt the pain.<sup data-fn="e12e5083-12e3-4b59-89d8-3ea5f445a7db"><a id="e12e5083-12e3-4b59-89d8-3ea5f445a7db-link" href="#e12e5083-12e3-4b59-89d8-3ea5f445a7db">2</a></sup></p><p><strong>In short, the period from fall 2023 to spring 2024 was an absolute bloodbath for independent websites.</strong></p><p>As <a href="https://www.cnet.com/tech/services-and-software/google-search-changes-are-killing-websites-in-an-age-of-ai-spam/" target="_blank" rel="noopener"><em>CNET </em>described it in an article</a> I was interviewed for, “<em>Google’s major search algorithm updates this past year have left many smaller websites with no other choice than to lay off staff. The internet is worse for it.</em>”</p><p>The travel vertical in particular was hit particularly hard.&nbsp;</p><p>An <a href="https://digitaloft.co.uk/the-impact-of-googles-helpful-content-update-on-travel-publishers/" target="_blank" rel="noopener">analysis by Digitaloft</a> found that <strong>78% of travel publishers lost organic traffic during these updates – and 32% lost more than 90% of their organic traffic</strong>.&nbsp;</p><p>Furthermore, the handful of travel publishers who survived were almost all owned by large mainstream media corporations.</p><h2>Google Initially Claimed It Was Only Shadowbanning Websites of “Little Value”&nbsp;</h2><p>When the September, 2023 “HCU” update rolled out, Google provided written guidance to affected site owners.&nbsp;</p><div><p>Google has since deleted those statements but they are archived <a href="http://web.archive.org/web/20231101203407/https://developers.google.com/search/updates/helpful-content-update" target="_blank" rel="noopener">here</a>.</p><p>Google initially claimed the shadowbanning algorithm that hit my site “<em>automatically identifies content that seems to have little value, low-added value or is otherwise not particularly helpful to people</em>.”</p></div><p>It was hurtful to hear Google thought our site was of “little value” to the web.</p><p>As creators, we at Travel Lemming pride ourselves on sharing our personal travel experiences and pouring our soul into making original, helpful guides. Our readers agree, consistently rating our guides an average of 4.7 out of 5 stars.&nbsp;</p><p>But now Google’s algorithms were saying our entire site was of “little value.”&nbsp;</p><div><p>But Google Promised Siteowners Like Us That We Could Recover</p><p>But Google’s <a href="http://web.archive.org/web/20231101203407/https://developers.google.com/search/updates/helpful-content-update" target="_blank" rel="noopener">guidance</a> was also telling us that recovery was possible if we just “removed” our “unhelpful” on-page content:&nbsp;</p></div><blockquote><p><em>“If you’ve noticed a change in traffic you suspect may be related to this system (such as after a publicly-posted ranking update to the system), then </em><strong><em><span>you should self-assess your content and fix or remove any that seems unhelpful</span></em></strong><em>. Our help page on how to create helpful, reliable people-first content has questions that you can use to self-assess your content to be successful with the helpful content system.</em></p></blockquote><blockquote><p><em>A natural question some will have is how long will it take for a site to do better, if it removes unhelpful content? Sites identified by this system may find the signal applied to them over a period of months. </em><strong><em><span>Our classifier runs continuously</span></em></strong><em>, allowing it to monitor newly-launched sites and existing ones. </em><strong><em><span>As it determines that the unhelpful content hasn’t returned in the long-term, the classification will no longer apply</span></em></strong><em>.” </em></p></blockquote><blockquote><p><em>-Source: </em><a href="http://web.archive.org/web/20231101203407/https://developers.google.com/search/updates/helpful-content-update" target="_blank" rel="noopener"><em>archived version of Google’s since-deleted guidance</em></a><em> (emphasis added)</em></p></blockquote><p>Note Google represented that these were <em>content</em>-based updates, and said that making content more “helpful” – or deleting a site’s weakest content entirely – could lead to recovery.</p><p>Google’s <a href="https://developers.google.com/search/blog/2022/08/helpful-content-update" target="_blank" rel="noopener">documentation</a> further stated that the “classifier” that had shadowbanned our sites ran “<em>continuously</em>,” meaning it would be constantly re-calculated in “<em>real-time</em>.”&nbsp;</p><p>Further, Google said the classifier was “<em>weighted</em>.” Had that been true (it wasn’t), it would have meant that at least partial recovery was possible even with just partial content “improvement.”&nbsp;</p><p>In retrospect, the first sign of Google’s lies was that it replaced indie sites with content that clearly violated Google’s own guidelines (but more on that later).&nbsp;</p><h2>My Site, And Many Others, Invested Precious Time and Resources Chasing Google’s False Promises</h2><p>Despite being hurt by Google calling us of “little value” and brutally shadowbanning us from the web, many of us affected site owners actually took Google’s statements to heart.&nbsp;</p><p>Us independent site owners are also small business owners.&nbsp;</p><p>For many of us, our sites aren’t just our livelihoods – they are also our passion projects.&nbsp;</p><p>I consider Travel Lemming my life’s work. I’ve always wanted it to be the most helpful site it can be, and not just because Google tells me so.&nbsp;</p><p>And, while I thought Travel Lemming’s guides were high quality, every site can always improve further. So that’s what we set out to do.&nbsp;</p><p>The entire team at Travel Lemming invested nearly a year of time and more than six-figures of resources turning our content upside down in an effort to “improve it” and meet Google’s guidelines for content guidelines even more.&nbsp;</p><p>We even removed the majority of our content from Google’s index – leaving only the guides we were 100% confident were abundantly “helpful” beyond any doubt.&nbsp;</p><p>Many other <a href="https://medium.com/@lucwiesman/looking-to-recover-from-the-google-helpful-content-update-or-any-algorithm-update-45c25d0d2b62" target="_blank" rel="noopener">sites invested similar resources</a> trying to recover in vain.&nbsp;</p><p>This investment came at great cost to many of us – because <strong><span>we had to invest such significant resources precisely at the time that our websites were completely starved of search referral traffic</span></strong>.&nbsp;</p><p>But it turns out we were all just chasing Google’s shadows – shadows that kept us all busy while Google worked on its blueprint for reimagining search around AI.&nbsp;</p><h2>But, Despite Those Efforts, Recovery Proved Impossible&nbsp;</h2><div><p>Nearly a year went by and, despite massive efforts, we didn’t recover at all.</p><p>Neither did anyone else.</p><p>In fact, like almost all affected indie sites, we continued to <em>lose </em>rankings further – no matter how much we changed our content.&nbsp;</p></div><p>Something seemed …. wrong.&nbsp;</p><div><p>As it turns out, the algorithms that hit ours and other sites were not really based on content at all.</p><p>Instead, it eventually became clear that these were really “authority” based algorithms. Which is a fancy way of saying that Google decided to promote larger sites over small ones – and it actually had nothing to do with content all along.</p><p>That explained why all our investments in overhauling or deleting content didn’t move the needle.</p></div><p>But it didn’t explain <em>what </em>we indie publishers should do next – other than, as one site owner snarkingly put it to me, “becoming <em>Forbes</em>.”&nbsp;</p><h2>Google Does Not Let Small Independent Sites Appeal Their Shadowbans (But Large Media Companies Can)</h2><p>By mid-2024, we and other affected sites were in a truly terrible position: not only were shadowbanned, but there didn’t seem like there was anything we could even do about it.&nbsp;</p><p><span><strong>Google offers no way to appeal an algorithmic shadow ban like the classifier that hit our site</strong>.</span></p><p>This is why Google usually avoids deploying algorithmic shadowbans against big sites owned by media conglomerates, even when big sites knowingly break Google’s spam policies.&nbsp;</p><p>Instead, when large sites break Google’s rules, Google instead issues them “manual penalties.”&nbsp;</p><p><span><strong>The big publishers then get access to a structured appeal and reconsideration process</strong>.</span></p><p>Google representatives will even help guide these sites through what changes they need to make, until they eventually recover their rankings.&nbsp;</p><p>For example, in March 2024, <a href="https://developers.google.com/search/blog/2024/03/core-update-spam-policies" target="_blank" rel="noopener">Google announced it would supposedly crack down on “site reputation abuse”</a> – a practice where large big-brand websites are able to abuse their site’s authority score to pump out low-effort content en masse.&nbsp;</p><p>Some of these large publications are even known for <a href="https://larslofgren.com/parasite-seo/" target="_blank" rel="noopener">renting out urls on their webpages to third party spammers</a>, a practice known in the spamming community as “Parasite SEO.”&nbsp;</p><p>This spammy practice is only possible because of how heavily Google’s algorithm now favors a site’s “authority” signals (as opposed to actually measuring content helpfulness).&nbsp;</p><p>These large sites were abusing Google’s long-existing policies against low effort content. And they were doing it intentionally.&nbsp;</p><p>But, nonetheless, Google did something unprecedented: it gave these large sites several months advance notice to clean up their act.</p><p><a href="https://developers.google.com/search/blog/2024/03/core-update-spam-policies" target="_blank" rel="noopener">Google said</a>: “<em>To allow time for site owners to prepare for this change, this new policy will take effect starting May 5, 2024</em>.”</p><div><p>I initially expected this meant Google would unleash an algorithm to punish these large sites. But no algorithm update ever hit these sites.</p><p>Instead, in June 2024, <a href="https://x.com/searchliaison/status/1797682174407463280?s=46" target="_blank">Google explained</a> it would “<em>only [be] doing manual actions on scaled content abuse, not algorithmic</em>.”</p></div><p>Why only manual and not algorithmic?&nbsp;</p><p>Google Search Liaison Danny Sullivan answered this in an <a href="https://www.seroundtable.com/interview-google-august-core-update-38024.html" target="_blank" rel="noopener">August, 2024 interview</a>:&nbsp;</p><blockquote><p><em>“There’s no algorithmic action, I don’t expect there to be any algorithmic action anytime in the near future,” Sullivan told me. He said if and when it becomes algorithmic, Google will announce it. Until then, it is not.</em></p></blockquote><blockquote><p><strong><em><span>Why is it not algorithmic?</span></em></strong><em> “The reason we probably won’t have it any time in the near future is </em><strong><em><span>because we wouldn’t be exceedingly careful and, and thoughtful in how we do it</span>.</em></strong><em> So that’s just taking time and for the moment, the manual actions are the way for us to go,” Sullivan explained. </em>(emphasis added)</p></blockquote><p>Google was admitting that it uses manual actions for sites owned by large media conglomerates because it treats them differently than independent sites.&nbsp;</p><p>Large sites are allowed to <em>knowingly and intentionally</em> abuse Google – and the worst risk they face is a manual action that comes with an opportunity to appeal and work with Google to get the manual action lifted.&nbsp;</p><p>As an example of this, a few months later <a href="https://arstechnica.com/gadgets/2024/11/google-cracks-down-on-parasite-seo-punishing-established-publishers/" target="_blank" rel="noopener">Google hit the website <em>Forbes</em></a> for violating Google’s “site reputation abuse” policy.&nbsp;</p><p>This meant <em>Forbes </em>was given access to an appeals and recovery process – <a href="https://www.linkedin.com/posts/lily-ray-44755615_seo-activity-7302339364578066433-H_Vp/" target="_blank" rel="noopener">and was able to recover from the penalty</a> just a few months later.&nbsp;</p><p>Shortly thereafter, a <em>Forbes </em>representative <a href="https://www.wsj.com/business/media/google-search-change-product-recommendation-websites-02394b79" target="_blank" rel="noopener">told <em>The Wall Street Journal</em></a> that “<em>Forbes continues to partner closely with Google</em>” and that Google “<em>has a careful review and appeals process for site owners</em>” that <em>Forbes </em>was able to use to get the manual action lifted quickly.&nbsp;</p><p>Independent sites like us, however, get no such appeals procedure.&nbsp;</p><p>Our entire sites can be permanently shadowbanned from Google by an algorithm.&nbsp;</p><p>Independent site owners exist on Google’s web in a permanent state of anxiety and insecurity. We can be erased by an algorithm at any time – arbitrarily, brutally, and with zero opportunity for appeal.&nbsp;</p><div><p>The one thing we could do was use our voice on our blogs and on platforms like X.</p><p>So, even though many site owners were scared of retaliation by Google, some of us started speaking out publicly about what was happening (examples <a href="https://housefresh.com/how-google-decimated-housefresh/" target="_blank" rel="noopener">here</a>, <a href="https://retrododo.com/google-is-killing-retro-dodo/" target="_blank" rel="noopener">here</a>, <a href="https://healthyframework.com/an-open-letter-to-google-from-a-small-publisher/" target="_blank" rel="noopener">here</a>, <a href="https://worldtravelfamily.com/is-google-destroying-blogging/" target="_blank" rel="noopener">here</a>, and <a href="https://wanderingwheatleys.com/how-google-screwed-the-blogging-community/" target="_blank" rel="noopener">here</a>).&nbsp;</p></div><h2>Google Eventually Admitted Fault – And Invited 20 Creators (Including Me) Out to Google’s Headquarters to Apologize</h2><p>At a certain point the evidence was just too overwhelming to ignore. Too many quality independent sites had been hit too hard for too long.</p><p>Google’s algorithms obviously weren’t working the way Google said they should.</p><div><p>Google even admitted it.</p><p><strong>In October 2024, Google invited me and 19 other independent web creators out to Google’s headquarters in Mountain View, California.</strong></p></div><p>Google gave us a tour of its (mostly empty) campus.</p><figure><img decoding="async" width="1024" height="767" src="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg" alt="Travel Lemming founder Nate Hake outside the Google’s Headquarters" srcset="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-768x575.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Headquarters.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='767'%20viewBox='0%200%201024%20767'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-Headquarters-1024x767.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-768x575.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-Headquarters-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-Headquarters.jpg 1200w"><figcaption><em>Me at Google’s Headquarters during the event</em></figcaption></figure><p><strong>And Google gave us a clear and unequivocal apology.</strong></p><p><strong>Google said our sites didn’t deserve our shadowbans, and that it wasn’t our fault.</strong></p><p>Personally, I at least felt validated by the apology. I had let the events of the past year shake my sense of self-worth, and it was nice to not be gaslit anymore.</p><p>But, as a fellow creator said at the event, “apologies don’t pay the bills.”</p><p>We all still had no idea of how we could get our sites un-shadowbanned.&nbsp;</p><p>Unfortunately, Google didn’t really have an idea either.</p><h2>Google Told Us There Was Nothing We Could Do to Recover, Because Search Had Permanently Changed With AI</h2><p>We all gave Google a mouthful of our opinions at the event.&nbsp;</p><p>The Commission can review some public accounts of the event from other creator attendees <a href="https://x.com/ichbinGisele/status/1851785266152739289" target="_blank">here</a>, <a href="https://x.com/CharlestonCraft/status/1851467133412393319" target="_blank">here</a>, <a href="https://www.giantfreakinrobot.com/tech/google-creators-event.html" target="_blank" rel="noopener">here</a>, <a href="https://techraptor.net/blog/google-web-creator-conversation-event-2024" target="_blank" rel="noopener">here</a>, <a href="https://betweenenglandandiowa.com/google-web-creator-conversation/" target="_blank" rel="noopener">here</a>, <a href="https://www.linkedin.com/pulse/yesterdays-google-creator-event-seos-take-steve-weber-1f2we/" target="_blank" rel="noopener">here</a>, <a href="https://x.com/TravelerAddicts/status/1851674228308988090" target="_blank">here</a>, <a href="https://goingawesomeplaces.com/google-web-creator-conversation-event-2024-retrospective/" target="_blank" rel="noopener">here</a>, and <a href="https://googhell.substack.com/p/i-was-invited-to-google-hq-to-talk" target="_blank" rel="noopener">here</a>.&nbsp;</p><p>You can read my own post-event reflections <a href="https://x.com/natejhake/status/1851776985724522789" target="_blank">here</a>.&nbsp;</p><p>And you can also read <a href="https://www.bloomberg.com/news/articles/2025-04-07/google-ai-search-shift-leaves-website-makers-feeling-betrayed" target="_blank" rel="noopener">this <em>Bloomberg </em>article</a> for more context.&nbsp;</p><p>At one point I aggressively pressured Google executive Pandu Nayak for specific guidance on how web creators are supposed to survive in Google’s AI-first future.&nbsp;</p><p>Nayak appeared visibly shaken by my questioning, but he ultimately gave no real answers. He made an offhand comment about how we could try using AI to create content (umm, no thank you!). But beyond that, he just blustered about how AI was changing search.</p><div><p>And, ultimately, that was really the main takeaway from the event:</p><p><strong><span>Googlers clearly told us that, even if our algorithmic shadowbans got lifted, our traffic might never return because search had been fundamentally changed by AI over the previous year.</span></strong></p></div><p>I’d note that Googlers used passive phrasing to make it seem like the changing search landscape was a result of forces of nature – and not of Google’s very deliberate decisions.</p><p>But, regardless, the message was clear – AI is fundamentally changing how Google works, and the old ecosystem of search isn’t ever coming back.</p><p>Google did promise to work on improving its algorithms so as to elevate more independent sites like ours.</p><p>While I initially held out some hope, most of my fellow creators left pessimistic that Google actually planned to change anything.</p><p>Unfortunately, time has proven them right.</p><p>As I write this 8 months after the event, Travel Lemming and most other affected sites remain shadowbanned by Google’s algorithms.</p><p>Meanwhile, Google continues to press full-steam ahead on its project of rebuilding search from the ground up with AI …</p><h2>“Rebuilding Search from the Ground Up” – What Did Google Build on the Ground It Demolished?&nbsp;</h2><p>Which brings me to the obvious question you may have:<em> if Google cleared out so many independent publishers, what took their place in search results</em>?&nbsp;</p><p>Well, let’s rewind to spring, 2024, when Google wrapped up its demolition job.&nbsp;</p><div><p>The last of Google’s ground-clearing updates was <a href="https://searchengineland.com/google-march-2024-core-update-rollout-is-now-complete-438713" target="_blank" rel="noopener">announced</a> as complete on April 26, 2024.</p><p>The foundation for Google’s “re-imagining” of search had been laid.&nbsp;</p></div><p>Now it was time for Google to start the process of rebuilding search from the ground up.&nbsp;</p><h2>Google Rolled Out AI Overviews – Two Weeks After Purging Indie Publishers</h2><p>Just two weeks after Google finished clearing out independent publishers <a href="https://www.theguardian.com/technology/article/2024/may/14/google-ai-search-results" target="_blank" rel="noopener">Google announced</a> the next phase in its plans at its annual “I/O’ event:&nbsp;</p><p>Google was putting AI content directly into search results with AI Overviews.&nbsp;</p><figure><img decoding="async" width="1024" height="483" src="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg" alt="Google's blog post about AI Overviews" srcset="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overviews-300x142.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overviews-768x362.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overviews-600x283.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overviews.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='483'%20viewBox='0%200%201024%20483'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg" data-srcset="https://travellemming.com/wp-content/uploads/AI-Overviews-1024x483.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overviews-300x142.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overviews-768x362.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overviews-600x283.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overviews.jpg 1200w"><figcaption><em>Google’s </em><a href="https://blog.google/products/search/generative-ai-google-search-may-2024/" target="_blank" rel="noopener"><em>blog post</em></a><em> announcing the roll out of AI Overviews</em></figcaption></figure><p>Google’s AI Overviews work by scraping content from websites, summarizing it with an LLM, and presenting a summarized answer right on Google.&nbsp;</p><p>In its I/O presentation, Google demo’ed of an AI Overview for a question about a broken record player (<a href="https://www.youtube.com/live/XEzRZ35urlk?si=UYUbQroNcWLfZzqy&amp;t=3087" target="_blank" rel="noopener">video here</a>, starting around minute 51):&nbsp;</p><figure><img decoding="async" width="1024" height="556" src="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg" alt="A woman during a Google’s 2024 demo of an AI Overview" srcset="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg 1024w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-300x163.jpg 300w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-768x417.jpg 768w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-600x326.jpg 600w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='556'%20viewBox='0%200%201024%20556'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-1024x556.jpg 1024w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-300x163.jpg 300w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-768x417.jpg 768w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview-600x326.jpg 600w, https://travellemming.com/wp-content/uploads/Demo-of-an-AI-Overview.jpg 1200w"><figcaption><em>Google’s 2024 demo of an AI Overview at Google I/O</em></figcaption></figure><p><strong>Google’s on stage AI Overview demo showed the fabric of the web’s social contract fraying in real time:&nbsp;&nbsp;</strong></p><p>The AI Overview pulled, summarized, and slightly reworded content from the source website <em><a href="https://www.audio-technica.com/en-us/support/balance-tone-arm-set-tracking-force-lp120-usb-lp1240-usb-turntables" target="_blank" rel="noopener">Audio-Technica</a></em>.&nbsp;</p><figure><img decoding="async" width="1024" height="470" src="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg" alt="A text similarity analysis showing the similarity of AI Overview demo’s text to a website's content" srcset="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-300x138.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-768x353.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-600x276.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='470'%20viewBox='0%200%201024%20470'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg" data-srcset="https://travellemming.com/wp-content/uploads/AI-Overview-Demo-1024x470.jpg 1024w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-300x138.jpg 300w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-768x353.jpg 768w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo-600x276.jpg 600w, https://travellemming.com/wp-content/uploads/AI-Overview-Demo.jpg 1200w"><figcaption><em>A text similarity analysis showing the AI Overview demo’s text was lifted from the source website</em></figcaption></figure><div><p>Notably, the Googler performing the demo was able to “solve” her problem without actually clicking through to the website that created the content that helped her.</p><p>This presents an existential problem for publishers – if searchers can find the information we create without ever visiting our websites, how are we supposed to earn revenue to fund content creation?&nbsp;</p></div><p>Indeed, in the year since, <strong>multiple independent studies have found that the presence of AI Overviews in search results reduces click through rates to web publishers by anywhere from 15% to 55%</strong>. (<em>Sources: </em><a href="https://www.seerinteractive.com/insights/ctr-aio" target="_blank" rel="noopener"><em>Seer Interactive</em></a><em>, </em><a href="https://ahrefs.com/blog/ai-overviews-reduce-clicks/" target="_blank" rel="noopener"><em>Ahrefs</em></a><em>, </em><a href="https://www.amsive.com/insights/seo/google-ai-overviews-new-research-reveals-how-to-navigate-click-drop-off/" target="_blank" rel="noopener"><em>Amisive</em></a>)</p><p>Instead of clicking through to websites, AI Overviews keep searchers clicking around Google – letting Google generate more profit at the expense of the hard work of publishers.&nbsp;</p><h2>Google Plans to Use AI to Monetize Not Just Searchers’ Questions, But Also the Answers</h2><figure><img decoding="async" width="1024" height="768" src="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg" alt="A graphic showing Google's AI" srcset="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='768'%20viewBox='0%200%201024%20768'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-1024x768.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-300x225.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-768x576.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews-600x450.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-AI-Overviews.jpg 1200w"></figure><p>As <a href="https://zyppy.com/list/ai-overviews-to-google-ads/" target="_blank" rel="noopener">one prominent search expert</a> put it, “<em>Google’s AI Overviews are seemingly designed to shift user clicks away from websites and nudge them towards Google ads</em>.”&nbsp;</p><div><p>At I/O 2024, Google announced its vision for an AI-first future where “<a href="https://www.youtube.com/live/XEzRZ35urlk?si=5wFkl-QLS0_7_9Uz&amp;t=2608" target="_blank" rel="noopener"><em>Google will do the Googling for You</em></a>.”</p><p>Just a week later, at Google’s Marketing Live Keynote, revealed plans for “<a href="https://www.youtube.com/live/feezAE_YAmc?si=ET85SIonmg0bWDfB&amp;t=2130" target="_blank" rel="noopener"><em>Ads that Answer</em></a>” – letting Google monetize not just questions but also the answers themselves.&nbsp;</p></div><div><p>Google’s plan is working.</p><p>Google’s search ad revenue has surged <a href="https://searchengineland.com/us-search-ad-revenues-2024-454410" target="_blank" rel="noopener">16% over the last year</a> – and that’s <em>despite </em>competition from ChatGPT, the maturity of the search market, and the fact that Google’s market share has not grown.&nbsp;</p></div><h2>Google Also Favors Its Own Properties in Search Results&nbsp;</h2><p>Google cut down independent publishers to create space for AI and ads – but also so it could promote its own web properties.&nbsp;</p><div><p>Remember how I said that Google’s algorithmic wrecking balls <a href="https://digitaloft.co.uk/the-impact-of-googles-helpful-content-update-on-travel-publishers/" target="_blank" rel="noopener">hit the travel sector</a> especially hard?</p><p>Well, <strong><span>consider this chart of Google Travel’s search visibility</span></strong> over the past few years:&nbsp;</p></div><figure><img decoding="async" width="1024" height="360" src="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg" alt="A graphic showing the Google Travel search visibility" srcset="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-300x106.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-768x270.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-600x211.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='360'%20viewBox='0%200%201024%20360'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-1024x360.jpg 1024w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-300x106.jpg 300w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-768x270.jpg 768w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility-600x211.jpg 600w, https://travellemming.com/wp-content/uploads/Google-Travels-Search-Visibility.jpg 1200w"><figcaption><em>(Source: </em><a href="https://x.com/lilyraynyc/status/1907130140280385741" target="_blank"><em>Lily Ray X post</em></a><em>)</em></figcaption></figure><p>You may notice that Google Travel’s graph looks like a near-perfect inverse of Travel Lemming’s search referral graph.&nbsp;</p><p>Google also favors its other properties like Youtube and Maps.&nbsp;</p><p>And Google aggressively injecting links back to its own search results within AI Overviews, to keep searchers from clicking out to third party websites.&nbsp;</p><p>One recent study found that “<a href="https://www.searchenginejournal.com/google-links-to-itself-43-of-ai-overviews-point-back-to-google/546574/" target="_blank" rel="noopener"><em>43% Of AI Overviews Point Back To Google</em></a>.”</p><p>Google consistently favors itself above all other websites.</p><p>Though Google does have another favorite recently …&nbsp;</p><h2>Reddit Got an AI Licensing Deal With Google – Plus an “Unprecedented” Boost in Search Visibility – Right Before Its IPO</h2><p>Apart from Google, there is one clear winner from Google’s project of reimagining search: Reddit.&nbsp;</p><p>The same algorithm updates that removed independent publishers from search results also elevated Reddit to a degree never before seen in Google search history:</p><figure><img decoding="async" width="1024" height="343" src="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg" alt="A graphic showing the search visibility of Reddit" srcset="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg 1024w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-300x101.jpg 300w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-768x257.jpg 768w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-600x201.jpg 600w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='343'%20viewBox='0%200%201024%20343'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-1024x343.jpg 1024w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-300x101.jpg 300w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-768x257.jpg 768w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph-600x201.jpg 600w, https://travellemming.com/wp-content/uploads/Reddits-Sistrix-Visibility-Graph.jpg 1200w"><figcaption><em>Reddit’s Sistrix visibility graph (Source: </em><a href="https://x.com/lilyraynyc/status/1922377910951805244" target="_blank"><em>Lily Ray, X</em></a><em>)&nbsp;</em></figcaption></figure><p>In summer 2024, Steve Paine of the search visibility tool Sistrix told <a href="https://www.businessinsider.com/why-reddit-is-taking-over-google-right-now-2024-4" target="_blank" rel="noopener"><em>Business Insider</em></a> that Reddit’s growth was “<em>unprecedented</em>.”&nbsp;</p><p>He continued: “<em>There hasn’t been a website that’s grown so much search visibility so quickly in the US in at least the last five years</em>.”</p><p><strong>But search visibility was only part of what Google gave Reddit.&nbsp;</strong></p><div><p>Reddit also got cold hard cash.</p><p><strong>On February 22, 2024, </strong><a href="https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/" target="_blank" rel="noopener"><strong>Reddit and Google announced</strong></a><strong> a $60 million per year AI licensing deal.</strong></p><p>Reddit’s sabre-rattling in 2023 about blocking Google’s crawlers had apparently worked.&nbsp;</p></div><p>The deal, as well as the search visibility boost, came at an <em>incredibly </em>convenient time for Reddit and its executives. You see, almost exactly one month after the deal announcement, Reddit completed its IPO and went public on the NYSE.&nbsp;</p><p>Reddit priced its IPO at $34 per share, which was “the top of the target range set by Reddit’s investment bankers” according to <a href="https://www.theguardian.com/technology/2024/mar/20/reddit-stock-market-debut-new-york-exchange" target="_blank" rel="noopener"><em>The Guardian</em></a>. The shares <a href="https://www.theguardian.com/technology/2024/mar/20/reddit-stock-market-debut-new-york-exchange" target="_blank" rel="noopener">popped 48% higher</a> just in their first day of trading.&nbsp;</p><p><strong><span>As of mid-May, 2025, Reddit is </span></strong><a href="https://www.cnbc.com/quotes/RDDT" target="_blank" rel="noopener"><span><strong>trading</strong></span></a><strong><span> at over $100 per share – giving it a market cap of almost $20 billion.</span></strong></p><p>Now, to be fair, Google will say that the two things – Reddit’s boost in search, and its AI licensing deal – are completely unrelated and a total coincidence.&nbsp;</p><p>You can judge the facts for yourself.</p><p>Collusive or coincidence, one thing is clear: <strong>the whole incident shows just how much power Google wields to reshape the entire Internet to its whims all in the span of a few months</strong>.&nbsp;&nbsp;</p><p>And AI will give Google even more power to re-write the Internet:&nbsp;</p><h2>Google Plans to Use AI Licensing Fees to Let It Control Which Websites Survive In the AI-First Future</h2><p>How will websites survive when users don’t need to click through?&nbsp;</p><p>Well, many web experts believe that an AI licensing fee model is the logical replacement for the current “clicks for content” web social contract.&nbsp;</p><p>Google apparently agrees.&nbsp;</p><p><strong>Sundar Pichai </strong><a href="https://deadline.com/2024/12/creators-get-paid-training-ai-google-ceo-sundar-pichai-1236194395/" target="_blank" rel="noopener"><strong>recently said</strong></a><strong>: “</strong><strong><em>There will be a marketplace in the future, I think. There will be creators who create for AI models and get paid for it. I really think that’s part of the future and people will figure it out</em></strong><strong>.”</strong></p><p>But Pichai doesn’t seem to be in a rush to create that marketplace just yet.&nbsp;</p><p>Google paid Reddit $60 million a year for AI licensing fees, but so far refuses to seriously discuss licensing with most other publishers.&nbsp;</p><p>Why?&nbsp;</p><p>Well, Google explained its AI licensing position in a <a href="https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/Google_response_to_UK_Copyright__AI_Consultation_February_2025_hLpZUuW.pdf" target="_blank" rel="noopener">recent letter to the UK government</a>.&nbsp;</p><p>Google said that publishers have a right to opt out of their content appearing in Google search but that “<em>this does not extend to a right to be paid</em>.”&nbsp;</p><p>Google’s letter goes on to explain that Google is open to “<em>negotiating agreements and partnership deals for a variety of situations, including programmatic access to custom APIs, access to data, digitisation, etc</em>.”</p><p>But, Google said: “<em>No single piece of content has value, and as such, pricing becomes </em><strong><em><mark><span>a pure bargaining issue</span></mark></em></strong>.”</p><p>In other words: Google is only willing to pay AI licensing fees to parties (like Reddit) with enough leverage to bargain against the monopolist.&nbsp;</p><p>And, conveniently for Google, the more Google rolls out AI, the less leverage publishers have.&nbsp;</p><p><strong>Like a reality TV game show, Google can slowly eliminate publishers from the web – winnowing Google’s final bargaining counterparties to a small handful of contestants Google gets to select.&nbsp;</strong></p><p>And there are indications Google has already chosen which sites will get a chance to survive in its AI-first future …&nbsp;</p><h2>Google Is Heavily Biased Towards A Few Large Media Conglomerates&nbsp;</h2><p>When Google needed to raze ground to build out its reimagined AI search, independent publishers were an obvious first target for Google.&nbsp;</p><p>After all, small websites typically don’t have the resources to sue, as some larger publications have threatened to do over the years (or, as some like <a href="https://www.courtlistener.com/docket/69668109/1/chegg-inc-v-google-llc/" target="_blank" rel="noopener"><em>Chegg, </em>have actually done recently</a>).</p><div><p>But Google has, at least so far, treated the mega media companies differently – sparing them from its AI wrecking ball (at least so far).</p><p>This, in turn, has led to incredible consolidation of the information ecosystem. In fact, “<strong><em><span>close to half of all of Google’s traffic is going to just a handful, a few hundred websites</span></em></strong>.” (<em>Source: </em><a href="https://sparktoro.com/blog/content-marketing-needs-to-evolve-beyond-seo/" target="_blank" rel="noopener"><em>SparkToro</em></a>)&nbsp;</p></div><div><p>Most of those websites are owned by just 16 VC-backed media conglomerates.</p><p>This consolidation of the information ecosystem hurts users in many invisible ways.&nbsp;</p></div><p>Gisele Navarro of the website <em>HouseFresh</em> has extensively documented how some big brands owned by some of these conglomerates often flood Google with questionable content.&nbsp;</p><p><strong><span>I strongly recommend Commission’s staff review these articles from Gisele:</span></strong></p><ul><li><em>“</em><a href="https://housefresh.com/how-google-decimated-housefresh/" target="_blank" rel="noopener"><em>HouseFresh has virtually disappeared from Google Search results. Now what?</em></a><em>”</em></li>

<li><em>“</em><a href="https://housefresh.com/david-vs-digital-goliaths/" target="_blank" rel="noopener"><em>How Google is killing independent sites like ours</em></a><em>”</em></li>

<li><em>“</em><a href="https://housefresh.com/finding-helpful-content-in-an-enshittified-google/" target="_blank" rel="noopener"><em>How to find helpful content in a sea of made-for-Google BS</em></a><em>”&nbsp;</em></li></ul><p>I personally think many of these large companies are living on borrowed time, and that Google is likely to come for their slots in search results in the next round of its game show.&nbsp;</p><p>I hold out hope some of them will see the light and join independent publishers in speaking out more forcefully against Google.&nbsp;</p><p>But, at least for now, many of these large media conglomerates seem content to be permitted by Google to exist within the monopolist’s walled garden (for now).&nbsp;</p><h2>Google Is Planning to Use AI to Consolidate the Flow of Information Online&nbsp;</h2><p>Google already has the power to control which sources of information users find and click on when they search.</p><p>And, as I’ve shown above, Google is not afraid of abusing its monopoly power to direct users to itself, its partners, or its preferred sources of media.</p><p><strong>But what happens when Google controls not just the </strong><strong><em>sources</em></strong><strong> of information – but also </strong><strong><em>the actual information itself</em></strong><strong>?</strong></p><p><strong>That is exactly what Google aims to do with AI: to become the singular source of all information, opinions, and advice on the web.</strong></p><p>Soon we may not have to worry at all about which websites get clicks from search – because Google won’t be sending clicks to anyone at all.</p><p>Unless, of course, you pay Google to show an “ad that answers” users’ questions.</p><p>And therein lies the rub …</p><h2>Google Isn’t Satisfied With Its Search Monopoly – It Wants a Monopoly on <em>Answers</em></h2><div><p>Google executive Noam Shazeer recently let slip Google’s real plans for AI <a href="https://www.youtube.com/watch?v=v0gjI__RyCY&amp;t=1801s" target="_blank" rel="noopener">in a podcast interview</a>:</p><p>“<strong><em><mark><span>Organizing information is clearly a trillion-dollar opportunity, but a trillion dollars is not cool anymore. What’s cool is a quadrillion dollars</span></mark></em></strong>.”</p></div><p>Indeed, Google is well on its way to realizing that quadrillion dollar opportunity – silently, and with less fanfare than OpenAI.</p><p>Already AI Overviews are used by 1.5 billion users.&nbsp;</p><p>Of course, those 1.5 billion didn’t choose to use AI Overviews – Google just leveraged its monopoly to force AI Overviews on users.</p><p>At <a href="https://www.youtube.com/live/o8NiE3XMPrM?si=QhU951K9WKDuEuqx" target="_blank" rel="noopener">Google’s 2025 I/O event</a>, Google CEO Sundar Pichai even bragged about how Google is leveraging its search monopoly to force AI Overviews on “<em>more people than any product in the world</em>”:</p><figure><img decoding="async" width="1024" height="567" src="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg" alt="The Google CEO during the Google’s 2025 I/O event" srcset="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-768x426.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-600x333.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='1024'%20height='567'%20viewBox='0%200%201024%20567'%3E%3C/svg%3E" data-src="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg" data-srcset="https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-1024x567.jpg 1024w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-300x166.jpg 300w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-768x426.jpg 768w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event-600x333.jpg 600w, https://travellemming.com/wp-content/uploads/Googles-2025-IO-event.jpg 1200w"></figure><p>Because, for Google, taking away user choice is precisely the goal anyway …&nbsp;</p><h2>Because Once Google Controls the Answers, It Will Control the People Too</h2><p>Google envisions a future where “Google does the Googling for you” and its AI and ads supply the answers right there on Google – all sourced from a handful of large media conglomerates forced to license their content to Google via contracts of adhesion.&nbsp;</p><p>For Google, a monopoly on answers is the ultimate goal.&nbsp;</p><p>Answers are so powerful because answers dictate people’s decisions.</p><p><strong>So when you control the answers, you actually control the people themselves.</strong></p><p>Americans already use Google to find answers to so much more than relatively frivolous questions like where to travel.</p><p>Americans use Google to find answers on where to live.</p><p>Americans use Google to find answers on what careers to pursue.</p><p>Americans use Google to find answers on whether to have kids.</p><p>Americans use Google to find answers to what medical procedures to get.</p><p>Americans use Google to find answers to what faith to follow.</p><p>Americans use Google to find answers on who to trust.</p><p>And Americans use Google to find answers on how to vote.</p><p><strong><span>I believe that our sources for those answers should be diffuse, varied, and independent – not monopolized by a single tech company.</span></strong></p><p><strong><span>Because if one company can monopolize the people’s answers, it can also monopolize the people’s decisions.</span></strong></p><h2 id="what-you-can-do">What You (Yes, You!) Can Do to Save the Open Web from Google’s AI Takeover<sup data-fn="ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209"><a href="#ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209" id="ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209-link">3</a></sup></h2><p>The open web is under attack by Google and AI – but there is still time to save it, so long as we all act together swiftly. </p><p><strong>Here is what you can do right now to save the open web: </strong></p><ul><li><strong>Share what Google is doing to the open web</strong>. You could start by sharing this article. Alternatively, I’ve left other good articles to share in the <a href="#further-reading">further reading</a> section below.  </li>

<li><strong>Switch your default search engine</strong> to literally anything except Google. Here are <a href="https://www.wikihow.com/Change-Your-Browser's-Default-Search-Engine" target="_blank" rel="noopener">instructions</a>. I use <a href="https://kagi.com/" target="_blank" rel="noopener">Kagi</a> (paid) on desktop and <a href="https://duckduckgo.com/" target="_blank" rel="noopener">DuckDuckGo</a> on mobile. Both are 10x better than Google, and better citizens of the open web. But switching to literally any other search engine will help de-centralize the Internet. </li>

<li><strong>Visit independent publishers directly</strong>. You won’t find many of us on Google anymore, but many of us are still publishing helpful content written by humans — we just need you to find and support us directly. My friend Gisele has a <a href="https://housefresh.com/finding-helpful-content-in-an-enshittified-google/" target="_blank" rel="noopener">good guide on how to do this</a>. If you find an independent website you like, bookmark it. Subscribe to their newsletter. And go straight to that site for your next question. </li>

<li><strong>De-Googlefy your life as much as possible. </strong>From Gmail to to Workspace to Maps to Photos to Calendar to Android to Chrome to hundreds of other products, Google’s grip on our digital lives goes way beyond search. And though many of these products are free (and you may even love some of them), they also fuel Google’s monopolistic ways by providing data about you that Google uses to train its AI systems and entrench its control over the web. Switching away from as many Google products as possible will help starve the monopolist of the data it feeds on. <a href="https://proton.me/blog/how-to-de-google" target="_blank" rel="noopener">Here is a guide</a> with more details.</li>

<li><strong>Call Congress to express support the efforts of the DOJ and the FTC to hold Google to account. </strong>These agencies have been battling Google in court across multiple administrations. No matter your party, you should support these agencies in their fight to break Google’s hold on the open web. One way to do that is to <a href="https://www.house.gov/representatives/find-your-representative" target="_blank" rel="noopener">contact your representatives</a> and express your support for the breakup of Google.</li>

<li><strong>If you are a independent publisher, share your story. </strong>Talk to your audience wherever they can still find you. Tell them what Google is doing to the open web and how they can help. If you publish a post, send it to me so I can help amplify. </li>

<li><strong>If you are a large publisher, now is the time to stop your silence. </strong>I know many large publications are scared to speak up against Google. You may think you’ll get an AI licensing deal. You may think Google will spare you from the AI carnage. I doubt it. And, even if your publication is among the privileged few permitted to exist behind Google’s walled garden, Google will still squeeze you for every penny it can. If you work at one of these publications, please push your editors to stop being silent about what Google is doing to the open web with AI. If you need sources or material, reach out to me. </li></ul><p>There was a web before Google and there will be a web after Google, so long as we all decide to take back control of our online lives before it’s too late. </p><h2>Recommendations for the Commission</h2><ul><li>Investigate Google’s algorithm updates in 2023 and 2024 for evidence that they were pretextual efforts to wrongly censor specific categories of web publishers and/or to unfairly promote Google’s AI ambitions</li>

<li>Require Google to treat independent websites the same way as large publications, including by for example giving siteowners an explanation for shadowbans and an appeals process</li>

<li>Continue to support the Department of Justice’s effort to break Google’s monopoly on Search, so publishers have more leverage in the information economy of the future</li>

<li>Investigate Google’s potentially collusive actions with other information market participants like Reddit</li>

<li>Require Google to publicly report important statistics necessary for publishers to fairly compete in an AI-first online economy, such as click through rates for AI Overviews and AI Mode</li>

<li>Require AI companies like Google to disclose their AI training material</li>

<li>Require AI companies like Google to give rightsholders granular consent and control mechanisms</li>

<li>Take steps to force AI companies like Google to pay just compensation to rightsholders when they use our content to train their AI models&nbsp;</li></ul><h2>Conclusion</h2><p>If you’ve read this far, I thank you from the bottom of my heart for hearing me out. Believe it or not, this was the abbreviated version of my story. If the Commission wants further information or explanation, I’ve got a lot more to say and would be happy to be contacted.</p><p>I realize few people care about the plight of a struggling travel blogger.</p><p>But I truly believe that we independent publishers were the canaries in the coal mine.</p><p>What Google did to censor us with AI it can do to others – and America and the world will be worse off for it.</p><p>I pray that the Commission and the Department of Justice will stop this evil monopolist before it’s too late for us all.</p><p><strong><mark>I truly believe you are the last best hope for freedom online.</mark></strong></p><p id="further-reading"><strong><em>Further reading:&nbsp;</em></strong></p><ul><li>“<a href="https://www.bbc.com/future/article/20240524-how-googles-new-algorithm-will-shape-your-internet" target="_blank" rel="noopener">Google just updated its algorithm. The Internet will never be the same</a>” –<em>BBC </em>(May 25, 204)</li>

<li>“<a href="https://housefresh.com/david-vs-digital-goliaths/" target="_blank" rel="noopener">How Google is killing independent sites like ours</a>” –<em>HouseFresh</em> (February 19, 2024)</li>

<li>“<a href="https://www.cnet.com/tech/services-and-software/google-search-changes-are-killing-websites-in-an-age-of-ai-spam/" target="_blank" rel="noopener">Google Search Changes Are Killing Websites in an Age of AI Spam</a>” –<em>CNET</em> (December 23, 2024)</li>

<li>“<a href="https://www.bloomberg.com/news/articles/2025-04-07/google-ai-search-shift-leaves-website-makers-feeling-betrayed" target="_blank" rel="noopener">Google AI Search Shift Leaves Website Makers Feeling ‘Betrayed’</a>” – <em>Bloomberg </em>(April 7, 2025)</li>

<li>“<a href="https://podcasts.apple.com/us/podcast/the-open-web-is-under-attack/id1514456916?i=1000704428299" target="_blank" rel="noopener">The Open Web is Under Attack</a>” –<em>Next in Media Podcas</em>t (April 22, 2025)</li></ul><p><strong><em>Footnotes</em></strong>:</p><ol><li id="ce0a92e3-1027-45cd-a7ba-0c787e4a8635">&nbsp;“<a href="https://gizmodo.com/google-search-written-by-people-helpful-content-update-1850848956" target="_blank" rel="noopener">Google Quietly Removes ‘Written By People’ From Suggestions for Website Owners</a>” –<em>Gizmodo</em> (September 18, 2023)<br>“<a href="https://www.theverge.com/2024/5/2/24147152/google-search-seo-publishing-housefresh-product-reviews" target="_blank" rel="noopener">Google is getting even worse for independent sites</a>” –<em>The Verge</em> (May 2, 2024)<br>“<a href="https://www.theverge.com/2024/10/30/24283871/google-cant-guarantee-that-independent-sites-will-recover-from-search-changes" target="_blank" rel="noopener">Google “can’t guarantee” that independent sites will recover from Search changes</a>” –<em>The Verge</em> (October 31, 2024)<br> <a href="#ce0a92e3-1027-45cd-a7ba-0c787e4a8635-link" aria-label="Jump to footnote reference 1">↩︎</a></li><li id="e12e5083-12e3-4b59-89d8-3ea5f445a7db">Curiously, based on my own observations, one significant vertical <em>does </em>seem to have been at least partially spared from the carnage: recipes. I think it is relevant that recipes is the <em>only </em>vertical where <a href="https://www.androidcentral.com/apps-software/google-is-working-with-publishers-to-show-you-a-quick-view-for-recipes-in-a-limited-test" target="_blank" rel="noopener">Google has done direct content licensing deals</a> with (select) independent publishers. <a href="#e12e5083-12e3-4b59-89d8-3ea5f445a7db-link" aria-label="Jump to footnote reference 2">↩︎</a></li><li id="ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209"><em>Editor’s Note: this section with action items for readers was added to this blog post and did not appear in my original letter to the FTC. I also fixed a few typos from the original and added a link to the BBC article in the “further reading” section, and clarified that Mueller’s post was restricted, not entirely deleted. The original letter was directed to the FTC’s specific requests, but I didn’t want to leave readers without actionable steps.</em> <a href="#ddb3fe20-e1d8-4a4d-b2fc-8bd141d6f209-link" aria-label="Jump to footnote reference 3">↩︎</a></li></ol><!-- FeedbackWP Plugin --><!-- [element-154392] --><!-- [/element-154392] --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gurus of 90s Web Design: Zeldman, Siegel, Nielsen (176 pts)]]></title>
            <link>https://cybercultural.com/p/web-design-1997/</link>
            <guid>44123852</guid>
            <pubDate>Thu, 29 May 2025 07:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cybercultural.com/p/web-design-1997/">https://cybercultural.com/p/web-design-1997/</a>, See on <a href="https://news.ycombinator.com/item?id=44123852">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
<article data-pagefind-body="">
  <div>
        
    <p>With the rise of Flash and CSS in 1997, three web design philosophies emerged. David Siegel advocated for 'hacks', Jakob Nielsen kept it simple, while Jeffrey Zeldman combined flair with usability.</p>
    <p><picture><source type="image/webp" srcset="https://cybercultural.com/img/QzPzOzmZqg-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="eager" decoding="async" src="https://cybercultural.com/img/QzPzOzmZqg-1280.jpeg" alt="classic web design books" width="1280" height="720"></picture>
<em>My well-thumbed copies of three classic web design books: 'Creating Killer Web Sites' by David Siegel (1996-97), 'Taking your Talent to the Web' by Jeffrey Zeldman (2001), and 'Designing Web Usability' by Jakob Nielsen (1999).</em></p>
<p>Like many of the first wave of web designers, Jeffrey Zeldman — who turned 42 in early 1997 — had begun his career in a completely different profession. He’d started out as an aspiring fiction author, briefly worked as a journalist, tried his hand as a touring musician, and then spent ten years in the advertising business. “Writing billboards and coming up with quick visuals was good training for the web because you have to communicate something instantly,” he <a href="https://thegreatdiscontent.com/interview/jeffrey-zeldman/" target="_blank" rel="noopener">later said</a> in an interview.</p>
<p>It was the <a href="https://cybercultural.com/p/multimedia-gulch-1994/">rise of multimedia</a> that attracted creatives like Zeldman, who made his first website in 1995. “Hyperlinked text made the web, graphics made it a consumer playground,” <a href="https://web.archive.org/web/19961219052244fw_/http://www.zeldman.com/abtgraph.html" target="_blank" rel="noopener">he wrote</a> on his personal website at the end of 1996.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/S0uFcNRnMR-1200.webp 1200w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/S0uFcNRnMR-1200.jpeg" alt="Zeldman website, 30 March 1997" width="1200" height="1240"></picture>
<em>Jeffrey Zeldman's homepage, March 1997. Note that the typical display size at the time was 800x600 pixels, so this and other websites would likely have been designed for those dimensions. <a href="https://web.archive.org/web/19970330110648/http://zeldman.com/toc.html" target="_blank" rel="noopener">Via Wayback Machine</a>.</em></p>
<p>But if the web was a “consumer playground” now, it was still one with many constraints. As Zeldman told budding web designers, “the accepted wisdom is to use as few images as possible, and make them as small as you can (small in file size, though not necessarily in height or width).”</p>
<p>To create his webpages, <a href="https://web.archive.org/web/19961219052231fw_/http://www.zeldman.com/faq.html" target="_blank" rel="noopener">Zeldman used</a> a plain text editor on a Macintosh computer to compose the HTML, along with Photoshop to create his graphics. He encouraged people to keep to HTML fundamentals, but he was also pragmatic — copy other designers to learn, he advised, and select “File: View Source” to see how different pages on the web were created.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/3U8yOAxhag-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/3U8yOAxhag-1000.jpeg" alt="Zeldman view source" width="1000" height="688"></picture>
<em>"Imitation is the sincerest form of theft, and most every web author starts by stealing." From an FAQ on Zeldman's site, March 1997; <a href="https://web.archive.org/web/19970330110530/http://zeldman.com/faq.html" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<h2>The 3 Musketeers</h2>
<p>Early in his new career as a web designer, Zeldman was heavily influenced by David Siegel, who had published a book in 1996 entitled <em>Creating Killer Web Sites: The Art of Third-Generation Site Design</em>. This was before <a href="https://cybercultural.com/p/1996-flash-css-web-design/">CSS (Cascading Style Sheets) or Flash</a>, so the book advocated for “hacks” to HTML in order to make websites more visually appealing. The primary hacks were using invisible tables and single-pixel GIFs to help control layout. The book had a chapter entitled “A PDF Primer,” but did not mention CSS (as the final spec hadn’t yet been released). The second edition, published in 1997, replaced the PDF primer with a new chapter: “A CSS Primer.” That’s how fast web design was changing at this time.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/ssdC2IvUCa-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/ssdC2IvUCa-1000.jpeg" alt="David Siegel's homepage, February 1997" width="1000" height="927"></picture>
<em>David Siegel's homepage, February 1997; <a href="https://web.archive.org/web/19970213054442/http://dsiegel.com/home.html" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>Siegel was around 37 years old at the start of 1997, but unlike Zeldman he had a background in digital design. He’d started his career in digital typography and so when he moved to the web, his goal was purely aesthetic. “I will use any means necessary to achieve quality typography and clear communication,” <a href="https://web.archive.org/web/19970213055012/http://dsiegel.com/tips/me.html" target="_blank" rel="noopener">he wrote</a> on his website. One of the ways he chose to do this was to focus his efforts on <a href="https://cybercultural.com/p/netscape-1994/">Netscape Navigator</a>. “I will not make pages that are optimized for ALL browsers,” he wrote.</p>
<p>This was the beginning of browser optimization on the web, which forced web users to view certain websites in a specific browser. Siegel styled himself as an “HTML terrorist,” so he was willing to take a contrary stance to achieve perfect typography on the web.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/USmS-2C-A2-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/USmS-2C-A2-1000.jpeg" alt="David Siegel tips, February 1997" width="1000" height="908"></picture>
<em>David Siegel's "Web Wonk" HTML tips site, February 1997; <a href="https://web.archive.org/web/19970213055004/http://www.dsiegel.com/tips/index.html" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>If Siegel was a self-described web design terrorist, then 39-year old Jakob Nielsen positioned himself as a web sheriff. <a href="https://www.nngroup.com/articles/trends-for-the-web-in-1997/" target="_blank" rel="noopener">He wrote</a> that his goal was to “get rid of superficial coolness and make websites into serious business tools.” He wasn’t a trained designer (instead, he <a href="https://web.archive.org/web/19980128103620/http://www.useit.com/jakob/" target="_blank" rel="noopener">called himself</a> a “usability guru”), but Nielsen strongly advocated for designs that were accessible on all the main browsers. For this reason he encouraged designers to use “semantic encoding” to keep content and presentation separate.</p>
<p>At first, Nielsen was talking about sticking to the structure defined in the HTML specification — such as using H1 and H2 for headers, rather than encoding something like "18 pixels tall bold Garamond.” Essentially, he was saying that each browser should define how headers would be displayed to their users. But he quickly got behind the emerging web standard, CSS. “Style sheets are a new development on the Web and currently not widely used,” <a href="https://www.nngroup.com/articles/trends-for-the-web-in-1997/" target="_blank" rel="noopener">wrote Nielsen</a> at the end of 1996, “but they are the only solution to getting nice presentation with ever-increasing numbers of browsers and display devices.”</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/aYV_7OwrnD-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/aYV_7OwrnD-1000.jpeg" alt="Useit, February 1997" width="1000" height="858"></picture>
<em>Jakob Nielsen's Useit website, February 1997; <a href="https://web.archive.org/web/19970218113042/http://www.useit.com/" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>The problem was, CSS support from the two main browsers at the start of 1997 was <a href="https://www.quirksmode.org/css/quirksmode.html" target="_blank" rel="noopener">patchy at best</a>. Internet Explorer 3.0 was the closest to supporting the W3C standard for CSS, but it was <a href="https://cybercultural.com/p/1996-microsoft-activates-the-internet-with-activex-jscript/">buggy and inconsistent</a>. As for Netscape, its 3.0 browser had <a href="https://cybercultural.com/p/1996-netscape-lays-the-groundwork-for-web-applications/">poor CSS support</a>. In fact, the company even tried to create an alternative to CSS, with a JavaScript-powered styling mechanism called JavaScript-Based Style Sheets (JSSS). Thankfully JSSS went nowhere, but it did serve to delay Netscape getting behind the nascent web standard for style sheets.</p>
<p>As 1997 progressed, the schism between the aesthetic approach to web design (personified by Siegel) and the semantic approach (personified by Nielsen) widened. Jeffrey Zeldman found himself in the middle of this. He was a proponent of CSS, but he also wasn’t above using new tools that disregarded semantic coding — like Shockwave and Flash. Over the coming years, Zeldman continued to insist that web design could be both aesthetic and standards-compliant. “Images, table layouts, style sheets, JavaScript, server-side technologies like PHP, and embedded technologies like Flash and Quicktime are all compatible with the rigors of accessible site design,” <a href="https://zeldman.com/daily/0602b.html" target="_blank" rel="noopener">he wrote</a> as late as July 2002.</p>
<h2>Flash Point</h2>
<p>Zeldman would eventually turn his back on Flash, which of all the web design tools available in the 90s was probably the least semantic. But when it first became popular, over 1997, it was seen as an animation tool that could take multimedia on the web to the next level.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/_1A4unOU4z-800.webp 800w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/_1A4unOU4z-800.jpeg" alt="Flash 1997" width="800" height="572"></picture>
<em>In May 1997, Macromedia <a href="https://web.archive.org/web/19980613005908/http://www.macromedia.com/macromedia/proom/pr/1997/flash2rel.html" target="_blank" rel="noopener">released Flash 2</a>, "the first tool for creating and animating vector-based resolution-independent graphics without programming"; <a href="https://www.webdesignmuseum.org/software/macromedia-flash-2-0-in-1997" target="_blank" rel="noopener">image via Web Design Museum</a>.</em></p>
<p>Flash had a few important things going for it. Firstly, the tool was easy to learn (unlike CSS). Secondly, it could do much more, visually, than CSS at that time. Almost anything was possible using Flash, with the only constraint being bandwidth limitations. Thirdly, and most crucially, Flash didn’t rely on the leading browser companies implementing it. The Flash player was a browser plug-in, so all it needed was for users to download that plug-in. Which they did, en masse.</p>
<p>Siegel quickly embraced Flash. In the second edition of <em>Creating Killer Websites</em>, published in September 1997, <a href="https://archive.org/details/creatingkiller1997sieg/page/266/mode/2up?view=theater&amp;q=flash" target="_blank" rel="noopener">he wrote</a> that “Flash is the best bet for bringing vector graphics into mainstream use on the Web.” To be fair, he also devoted an entire new chapter to CSS. However, he clearly wasn’t impressed by what CSS could actually deliver at the time. “To a certain extent, this chapter represents an exercise in futility — it demonstrates the appalling degree to which the browsers fail to deliver on the promise of style sheets in August 1997,” he wrote. In his summary, he expressed hope for CSS, but warned that “I will continue to commit HTML terrorism to accomplish my design objectives on today’s browsers.”</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/iQfeqWCstG-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/iQfeqWCstG-1280.jpeg" alt="Killer Websites Flash" width="1280" height="802"></picture>
<em>The Flash section of the second edition of Killer Websites; via Internet Archive.</em></p>
<p>As quickly as Siegel and Zeldman embraced Flash, Nielsen just as quickly rejected it — primarily because presentation and content were mashed together into one file, so there was nothing at all semantic about the code it produced. A few years later, he <a href="https://www.nngroup.com/articles/flash-99-percent-bad/" target="_blank" rel="noopener">famously wrote</a> that Flash was “99% bad” and that it was almost always “a usability disease.”</p>
<p>Even Siegel was concerned that Flash was a proprietary tool, owned and controlled by Macromedia (which had <a href="https://cybercultural.com/p/internet-1996/">acquired the technology</a> from a company called FutureWave at the end of 1996). Flash couldn’t have been more different from CSS — the software was not open source, the file format (.fla) was proprietary, and the output did not conform to web standards.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/Mb7oi42AMI-1000.webp 1000w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/Mb7oi42AMI-1000.jpeg" alt="W3C Style, June 1997" width="1000" height="728"></picture>
<em>The W3C Style page, June 1997; <a href="https://web.archive.org/web/19970605010635/https://www.w3.org/Style/" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>For all their differences, CSS and Flash did have similar goals: both aimed to expand the state of web design on the web. Yet only one of them led to an explosion of visual creativity on the web over the rest of the 1990s…and it wasn’t the open web standard. If you wanted to create a killer website in 1997, Flash was the tool many web designers of that time reached for.</p>
<h2>Whatever Happened To…</h2>
<p>As for Zeldman, Siegel and Nielsen, for all <em>their differences</em>, the three musketeers of web design all wanted to move their fledgling profession forward. Because the web platform was in flux in 1997 — epitomised by the emergence of Flash and CSS, two diametrically opposed technologies — web design was necessarily experimental that year.</p>
<p>It’s only by looking at the careers of all three men in the following decades that you get a sense of which web design philosophy eventually ‘won’.</p>
<p>Post-90s, Jakob Nielsen became ever more defined by his barebones website, Useit, which eschewed any design flourishes. Like Craigslist, another famously minimalist website, Useit didn't change its design over the years. By the Web 2.0 period, it was seen my most in the web design profession as being <a href="https://css-tricks.com/the-usability-problems-of-useitcom/" target="_blank" rel="noopener">hopelessly outdated</a>. The site lasted several more years, before Nielsen announced that Useit would be <a href="https://www.nngroup.com/news/item/useitcom-moves-to-nngroupcom/" target="_blank" rel="noopener">folded into</a> his main corporate website, NNGroup, at the end of 2012.</p>
<p>It may not surprise you to know that in 2025, Jakob Nielsen is writing <a href="https://jakobnielsenphd.substack.com/" target="_blank" rel="noopener">about AI on Substack</a>.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/Vez2PrOeV9-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/Vez2PrOeV9-1280.jpeg" alt="Useit, December 2012" width="1280" height="728"></picture>
<em>Useit website in December 2012, just before it was closed down. The design (purposefully) hadn't changed much since 1997. <a href="https://web.archive.org/web/20121223175349/http://www.useit.com/" target="_blank" rel="noopener">via Wayback Machine</a>.</em></p>
<p>David Siegel has had a surprisingly varied career. He was the most qualified design professional of the three, having earned a master's degree in digital typography from Stanford University in 1985 and then working at Pixar. But after two editions of his hugely influential “Killer Web Sites” book over 1996-97, he switched gears and moved from web design to web business in the late-90s. I had <a href="https://web.archive.org/web/20100404072141/http://www.readwriteweb.com/archives/david_siegel_pull_semantic_web.php" target="_blank" rel="noopener">some contact</a> with him in 2010, when he was promoting his fourth book, <a href="https://archive.org/details/isbn_9781591842774" target="_blank" rel="noopener">Pull: The Power of the Semantic Web to Transform Your Business</a>.</p>
<p>Later, Siegel got interested in the blockchain and pursued that for a few years. His current website, cuttingthroughthenoise.net, shows that he now has a variety of business and personal interests.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/ovJladicCl-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/ovJladicCl-1280.jpeg" alt="David Siegel 2025" width="1280" height="641"></picture>
<em><a href="https://www.cuttingthroughthenoise.net/" target="_blank" rel="noopener">David Siegel's website in 2025</a> reflects his eclectic interests.</em></p>
<p>Jeffrey Zeldman is still very much a web designer. Since 2019 he’s been Executive Creative Director at Automattic, the company behind the WordPress blogging system, Tumblr, and other web products. He still regularly blogs about web design topics on his website, <a href="https://zeldman.com/" target="_blank" rel="noopener">zeldman.com</a> — although the current site design is one of the default WordPress themes.</p>
<p>I was curious why he no longer has a custom design, so before I published this article I reached out to him via a Bluesky DM. He replied: "I'm working on a redesign of my site as we speak. It will go live soon." He added that the default WordPress theme, which he switched to in February 2019, "wasn't so different from one I might have designed myself at the time. That said, after living with the default theme for six years, I'm ready to move on."</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/pS6DflLQU2-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/pS6DflLQU2-1280.jpeg" alt="Zeldman website May 2025" width="1280" height="738"></picture>
<em>Jeffrey Zeldman's website as at 28 May 2025...but stay tuned, a redesign is coming soon!</em></p>
<p>I must say, I'm thrilled to hear that Zeldman is working on a redesign. I'd argue that his pragmatic approach to web design — combining web standards with design flair — was what won out during the 90s and early 2000s. Certainly, of the three web design gurus in 1997, Zeldman’s website back then was by far the most interesting and exotic. So I look forward to seeing that design philosophy return to zeldman.com — and indeed, let's hope it proliferates again across the rest of the indie web.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/SuLShqpEyb-400.webp 400w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/SuLShqpEyb-400.jpeg" alt="Bonus photo of ricmac in 2010" width="400" height="533"></picture>
<em>A sneaky pic of me <a href="https://www.flickr.com/photos/zeldman/4699929293/in/album-72157623550476154" target="_blank" rel="noopener">taken by Jeffrey Zeldman</a> in June 2010, during one of my trips to NYC.</em></p>


<hr>


 

<h2>Buy the Book</h2>
<p>My <a href="https://cybercultural.com/p/book-release-bubbleblog/">Web 2.0 memoir</a>, <em>Bubble Blog: From Outsider to Insider in Silicon Valley's Web 2.0 Revolution</em>, is now available to purchase:</p>
<ul>
<li>Paperback, US$19.99: <a href="https://www.amazon.com/Bubble-Blog-Outsider-Insider-Revolution/dp/B0DQKRB3P5?&amp;linkCode=ll1&amp;tag=richardmacman-20&amp;linkId=b38f92f2c0bd2c9f05cda3a07413fd40&amp;language=en_US&amp;ref_=as_li_ss_tl" target="_blank" rel="noopener">Amazon</a>; <a href="https://bookshop.org/p/books/bubble-blog-from-outsider-to-insider-in-silicon-valley-s-web-2-0-revolution-richard-macmanus/22135084" target="_blank" rel="noopener">Bookshop.org</a></li>
<li>eBook, US$9.99: <a href="https://www.amazon.com/Bubble-Blog-Outsider-Insider-Revolution-ebook/dp/B0DQJQ4LJ9?&amp;linkCode=ll1&amp;tag=richardmacman-20&amp;linkId=63e982f1c9d1ded8c83666d8b6917ff7&amp;language=en_US&amp;ref_=as_li_ss_tl" target="_blank" rel="noopener">Amazon Kindle Store</a>; <a href="http://books.apple.com/us/book/id6739734992" target="_blank" rel="noopener">Apple Books</a>; <a href="https://play.google.com/store/books/details?id=Sug5EQAAQBAJ" target="_blank" rel="noopener">Google Play</a></li>
</ul>

<p>Or search for "Bubble Blog MacManus" on your local online bookstore.</p>
  </div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Typed-FFmpeg 3.0–Typed Interface to FFmpeg and Visual Filter Editor (239 pts)]]></title>
            <link>https://github.com/livingbio/typed-ffmpeg</link>
            <guid>44123098</guid>
            <pubDate>Thu, 29 May 2025 04:23:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/livingbio/typed-ffmpeg">https://github.com/livingbio/typed-ffmpeg</a>, See on <a href="https://news.ycombinator.com/item?id=44123098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">typed-ffmpeg</h2><a id="user-content-typed-ffmpeg" aria-label="Permalink: typed-ffmpeg" href="#typed-ffmpeg"></a></p>
<p dir="auto"><a href="https://github.com/livingbio/typed-ffmpeg/actions?query=workflow%3Aci-package"><img src="https://github.com/livingbio/typed-ffmpeg/actions/workflows/ci-package.yml/badge.svg" alt="CI Package"></a>
<a href="https://livingbio.github.io/typed-ffmpeg/" rel="nofollow"><img src="https://camo.githubusercontent.com/5a4414aacd5db4051f8ae830d1eca85ffd60e261f2855e432d7e3b7f210bb0af/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6d6b646f63732532306d6174657269616c2d626c75652e7376673f7374796c653d666c6174" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-mkdocs%20material-blue.svg?style=flat"></a>
<a href="https://pypi.org/project/typed-ffmpeg/" rel="nofollow"><img src="https://camo.githubusercontent.com/afd329fb15a52d6e6b60b2e1b302be4823ae665e5555e848075599f6af367443/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f74797065642d66666d7065672e737667" alt="PyPI Version" data-canonical-src="https://img.shields.io/pypi/v/typed-ffmpeg.svg"></a>
<a href="https://codecov.io/gh/livingbio/typed-ffmpeg" rel="nofollow"><img src="https://camo.githubusercontent.com/8fd3d468cf99ef7221b9000544bf1e7df476dcb551634338fd03525f0307839d/68747470733a2f2f636f6465636f762e696f2f67682f6c6976696e6762696f2f74797065642d66666d7065672f67726170682f62616467652e7376673f746f6b656e3d42393550523632394c50" alt="codecov" data-canonical-src="https://codecov.io/gh/livingbio/typed-ffmpeg/graph/badge.svg?token=B95PR629LP"></a></p>
<p dir="auto"><strong>typed-ffmpeg</strong> offers a modern, Pythonic interface to FFmpeg, providing extensive support for complex filters with detailed typing and documentation. Inspired by <code>ffmpeg-python</code>, this package enhances functionality by addressing common limitations, such as lack of IDE integration and comprehensive typing, while also introducing new features like JSON serialization of filter graphs and automatic FFmpeg validation.</p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#quick-usage">Quick Usage</a></li>
<li><a href="https://livingbio.github.io/typed-ffmpeg/" rel="nofollow">Documentation</a></li>
<li><a href="#interactive-playground">Interactive Playground</a></li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/autocomplete.png"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/autocomplete.png" alt="typed-ffmpeg"></a></p>
<ul dir="auto">
<li><strong>Zero Dependencies:</strong> Built purely with the Python standard library, ensuring maximum compatibility and security.</li>
<li><strong>User-Friendly:</strong> Simplifies the construction of filter graphs with an intuitive Pythonic interface.</li>
<li><strong>Comprehensive FFmpeg Filter Support:</strong> Out-of-the-box support for most FFmpeg filters, with IDE auto-completion.</li>
<li><strong>Integrated Documentation:</strong> In-line docstrings provide immediate reference for filter usage, reducing the need to consult external documentation.</li>
<li><strong>Robust Typing:</strong> Offers static and dynamic type checking, enhancing code reliability and development experience.</li>
<li><strong>Filter Graph Serialization:</strong> Enables saving and reloading of filter graphs in JSON format for ease of use and repeatability.</li>
<li><strong>Graph Visualization:</strong> Leverages <code>graphviz</code> for visual representation, aiding in understanding and debugging.</li>
<li><strong>Validation and Auto-correction:</strong> Assists in identifying and fixing errors within filter graphs.</li>
<li><strong>Input and Output Options Support:</strong> Provide a more comprehensive interface for input and output options, including support for additional codecs and formats.</li>
<li><strong>Partial Evaluation:</strong> Enhance the flexibility of filter graphs by enabling partial evaluation, allowing for modular construction and reuse.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Planned Features</h3><a id="user-content-planned-features" aria-label="Permalink: Planned Features" href="#planned-features"></a></p>
<p dir="auto">Please note that the following features are under consideration or development for future releases:</p>
<ul dir="auto">
<li><strong>Extended FFmpeg Version Support:</strong> While <code>typed-ffmpeg</code> is currently built with FFmpeg version 6.0 in mind, we are working to ensure compatibility across different FFmpeg versions. Feedback and issue reports are welcome to improve version support.</li>
<li><strong>Additional Filter Support:</strong> We aim to expand the range of FFmpeg filters supported by <code>typed-ffmpeg</code>. Continuous updates will be made to include more complex and varied filters.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install <code>typed-ffmpeg</code>, simply use pip:</p>

<p dir="auto">Note: FFmpeg must be installed on your system.</p>
<p dir="auto">Note: If you need to install <code>ffmpeg-python</code> at the same time, use <code>pip install typed-ffmpeg-compatible</code> to prevent conflicts with the module name.​</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Visualization Support</h3><a id="user-content-visualization-support" aria-label="Permalink: Visualization Support" href="#visualization-support"></a></p>
<p dir="auto">To enable graph visualization features:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install 'typed-ffmpeg[graph]'"><pre>pip install <span><span>'</span>typed-ffmpeg[graph]<span>'</span></span></pre></div>
<p dir="auto">Note: This requires Graphviz to be installed on your system.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Usage</h2><a id="user-content-quick-usage" aria-label="Permalink: Quick Usage" href="#quick-usage"></a></p>
<p dir="auto">Here's how to quickly start using <code>typed-ffmpeg</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import ffmpeg

# Flip video horizontally and output
f = (
    ffmpeg
    .input(filename='input.mp4')
    .hflip()
    .output(filename='output.mp4')
)
f"><pre><span>import</span> <span>ffmpeg</span>

<span># Flip video horizontally and output</span>
<span>f</span> <span>=</span> (
    <span>ffmpeg</span>
    .<span>input</span>(<span>filename</span><span>=</span><span>'input.mp4'</span>)
    .<span>hflip</span>()
    .<span>output</span>(<span>filename</span><span>=</span><span>'output.mp4'</span>)
)
<span>f</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_1_0.svg"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_1_0.svg" alt="svg"></a></p>
<p dir="auto">For a more complex example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import ffmpeg.filters
import ffmpeg

# Complex filter graph example
in_file = ffmpeg.input(&quot;input.mp4&quot;)
overlay_file = ffmpeg.input(&quot;overlay.png&quot;)

f = (
    ffmpeg.filters
    .concat(
        in_file.trim(start_frame=10, end_frame=20),
        in_file.trim(start_frame=30, end_frame=40),
    )
    .video(0)
    .overlay(overlay_file.hflip())
    .drawbox(x=&quot;50&quot;, y=&quot;50&quot;, width=&quot;120&quot;, height=&quot;120&quot;, color=&quot;red&quot;, thickness=&quot;5&quot;)
    .output(filename=&quot;out.mp4&quot;)
)
f"><pre><span>import</span> <span>ffmpeg</span>.<span>filters</span>
<span>import</span> <span>ffmpeg</span>

<span># Complex filter graph example</span>
<span>in_file</span> <span>=</span> <span>ffmpeg</span>.<span>input</span>(<span>"input.mp4"</span>)
<span>overlay_file</span> <span>=</span> <span>ffmpeg</span>.<span>input</span>(<span>"overlay.png"</span>)

<span>f</span> <span>=</span> (
    <span>ffmpeg</span>.<span>filters</span>
    .<span>concat</span>(
        <span>in_file</span>.<span>trim</span>(<span>start_frame</span><span>=</span><span>10</span>, <span>end_frame</span><span>=</span><span>20</span>),
        <span>in_file</span>.<span>trim</span>(<span>start_frame</span><span>=</span><span>30</span>, <span>end_frame</span><span>=</span><span>40</span>),
    )
    .<span>video</span>(<span>0</span>)
    .<span>overlay</span>(<span>overlay_file</span>.<span>hflip</span>())
    .<span>drawbox</span>(<span>x</span><span>=</span><span>"50"</span>, <span>y</span><span>=</span><span>"50"</span>, <span>width</span><span>=</span><span>"120"</span>, <span>height</span><span>=</span><span>"120"</span>, <span>color</span><span>=</span><span>"red"</span>, <span>thickness</span><span>=</span><span>"5"</span>)
    .<span>output</span>(<span>filename</span><span>=</span><span>"out.mp4"</span>)
)
<span>f</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_3_0.svg"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/README_files/README_3_0.svg" alt="svg"></a></p>
<p dir="auto">See the <a href="https://livingbio.github.io/typed-ffmpeg/usage/typed/" rel="nofollow">Usage</a> section in our documentation for more examples and detailed guides.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interactive Playground</h2><a id="user-content-interactive-playground" aria-label="Permalink: Interactive Playground" href="#interactive-playground"></a></p>
<p dir="auto">Try out <code>typed-ffmpeg</code> directly in your browser with our <a href="https://livingbio.github.io/typed-ffmpeg-playground/" rel="nofollow">Interactive Playground</a>! The playground provides a live environment where you can:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/playground-screenshot.png"><img src="https://raw.githubusercontent.com/livingbio/typed-ffmpeg/main/docs/media/playground-screenshot.png" alt="Interactive Playground"></a></p>
<ul dir="auto">
<li>Experiment with FFmpeg filters and commands</li>
<li>Visualize filter graphs in real-time</li>
<li>Test different input/output configurations</li>
<li>Learn through interactive examples</li>
<li>Share your filter graphs with others</li>
</ul>
<p dir="auto">The playground is perfect for learning and prototyping FFmpeg filter chains without setting up a local environment.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">This project was initially inspired by the capabilities of GPT-3, with the original concept focusing on using GPT-3 to generate an FFmpeg filter SDK directly from the FFmpeg documentation. However, during the development process, I encountered limitations with GPT-3's ability to fully automate this task.</p>
<p dir="auto">As a result, I shifted to traditional code generation methods to complete the SDK, ensuring a more robust and reliable tool. Despite this change in approach, both GitHub Copilot and GPT-3 were instrumental in accelerating the development process, providing valuable insights and saving significant time.</p>
<p dir="auto">I would also like to extend my gratitude to the <code>ffmpeg-python</code> project, which inspired this project significantly. The API style and design ideas from <code>ffmpeg-python</code> have been influential, and I have utilized these aspects to shape the development of our SDK.</p>
<p dir="auto">This project is dedicated to my son, Austin, on his seventh birthday (February 24, 2024), whose curiosity and zest for life continually inspire me.</p>
<hr>
<p dir="auto">Feel free to check the <a href="https://livingbio.github.io/typed-ffmpeg/" rel="nofollow">Documentation</a> for detailed information and more advanced features.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Run a C# file directly using dotnet run app.cs (167 pts)]]></title>
            <link>https://devblogs.microsoft.com/dotnet/announcing-dotnet-run-app/</link>
            <guid>44122582</guid>
            <pubDate>Thu, 29 May 2025 02:30:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-run-app/">https://devblogs.microsoft.com/dotnet/announcing-dotnet-run-app/</a>, See on <a href="https://news.ycombinator.com/item?id=44122582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-56905">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>We are super excited to introduce a new feature that was released as part of .NET 10 Preview 4 that makes getting started with C# easier than ever. You can now run a C# file directly using <code>dotnet run app.cs</code>. This means you no longer need to create a project file or scaffold a whole application to run a quick script, test a snippet, or experiment with an idea. It’s simple, intuitive, and designed to streamline the C# development experience, especially for those just getting started.</p>
<h2>What is <code>dotnet run app.cs</code>?</h2>
<p>Until now, executing C# code using the <code>dotnet</code> CLI required a project structure that included a <code>.csproj</code> file. With this new capability, which we call <em>file-based apps</em>, you can run a standalone <code>.cs</code> file directly, much like you would with scripting languages such as Python or JavaScript.</p>
<p>This lowers the entry barrier to trying out C# and makes the language a much more attractive choice for learning, prototyping, or automation scenarios.</p>
<ul>
<li><strong>Quick Start, No Project File Required</strong> – Great for learning, experimentation, and small scripts.</li>
<li><strong>First-Class CLI Integration</strong> – No extra tools, no dependencies, just <code>dotnet</code> and your <code>.cs</code> file.</li>
<li><strong>Scales to Real Applications</strong> – This isn’t a separate dialect or runtime. When your script grows up, it can evolve into a full-fledged project using the same language, syntax, and tooling.</li>
</ul>
<h2>New file-level directives for file-based C# apps</h2>
<p>With .NET 10 Preview 4, file-based apps also support a set of powerful <strong>file-level directives</strong> that allow to declare a small number of important things that are stored in project files for project-based apps, all without leaving your single <code>.cs</code> file. These directives make file-based apps more flexible and expressive while maintaining compatibility with MSBuild concepts.</p>
<h3>Referencing NuGet packages with <code>#:package</code></h3>
<p>You can add NuGet package references directly in your <code>.cs</code> file using the <code>#:package</code> directive:</p>
<pre><code>#:package Humanizer@2.14.1

using Humanizer;

var dotNet9Released = DateTimeOffset.Parse("2024-12-03");
var since = DateTimeOffset.Now - dotNet9Released;

Console.WriteLine($"It has been {since.Humanize()} since .NET 9 was released.");</code></pre>
<h3>Specifying an SDK with <code>#:sdk</code></h3>
<p>By default, file-based apps use the <code>Microsoft.NET.Sdk</code> SDK. If you’re building something like a web API, you can change the SDK using the <code>#:sdk</code> directive:</p>
<pre><code>#:sdk Microsoft.NET.Sdk.Web</code></pre>
<p>This tells the tooling to treat the file as if it were part of a web project, enabling features of ASP.NET Core like Minimal APIs and MVC.</p>
<h3>Setting MSBuild properties with <code>#:property</code></h3>
<p>You can configure additional build properties using <code>#:property</code>. For example:</p>
<pre><code>#:property LangVersion preview</code></pre>
<p>This allows your file-based app to opt into advanced language features and platform targeting, without needing a full project file.</p>
<h3>Using shebang lines for shell scripts</h3>
<p>File-based apps also support <a href="https://en.wikipedia.org/wiki/Shebang_%28Unix%29">shebang</a> lines (<code>#!</code>), allowing you to write cross-platform C# shell scripts that are executable directly on Unix-like systems. For example:</p>
<pre><code>#!/usr/bin/dotnet run
Console.WriteLine("Hello from a C# script!");</code></pre>
<p>You can make the file executable and run it directly:</p>
<pre><code>chmod +x app.cs
./app.cs</code></pre>
<p>This makes C# a convenient option for CLI utilities, automation scripts, and tooling, no project setup required.</p>
<h2>Converting to a project-based app</h2>
<p>When your file-based app grows in complexity, or you simply want the extra capabilities afforded in project-based apps, you can convert it to a standard project with:</p>
<pre><code>dotnet project convert app.cs</code></pre>
<p>This command creates a new directory named for your file, scaffolds a <code>.csproj</code> file, moves your code into a <code>Program.cs</code> file, and translates any <code>#:</code> directives into MSBuild properties and references.</p>
<h3>Example</h3>
<p>Given this file:</p>
<pre><code>#:sdk Microsoft.NET.Sdk.Web
#:package Microsoft.AspNetCore.OpenApi@10.*-*

var builder = WebApplication.CreateBuilder();

builder.AddOpenApi();

var app = builder.Build();

app.MapGet("/", () =&gt; "Hello, world!");
app.Run();</code></pre>
<p>The generated <code>.csproj</code> would be:</p>
<pre><code>&lt;Project Sdk="Microsoft.NET.Sdk.Web"&gt;

  &lt;PropertyGroup&gt;
    &lt;TargetFramework&gt;net10.0&lt;/TargetFramework&gt;
    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;
    &lt;Nullable&gt;enable&lt;/Nullable&gt;
  &lt;/PropertyGroup&gt;

  &lt;ItemGroup&gt;
    &lt;PackageReference Include="Microsoft.AspNetCore.OpenApi" Version="10.*-*" /&gt;
  &lt;/ItemGroup&gt;

&lt;/Project&gt;</code></pre>
<p>This makes the transition seamless, from a single file to a fully functional, buildable, and extensible project.</p>
<h2>Existing ways to run C# without projects</h2>
<p>This is far from the first time developers have wanted to run C# without a project. Community projects like <a href="https://github.com/oleg-shilo/cs-script">CS-Script</a>, <a href="https://github.com/dotnet-script/dotnet-script">dotnet-script</a>, <a href="https://cakebuild.net/">Cake</a>, and others have long filled this role, enabling scripting workflows, REPL experiences, and other experiences with C#. Here’s a <a href="https://www.hanselman.com/blog/c-and-net-core-scripting-with-the-dotnetscript-global-tool">blog post by Scott Hanselman from 2018 detailing the <code>dotnet-script</code> global tool</a>.</p>
<p>These tools remain valuable and are worth checking out, especially for more advanced scripting scenarios. However, with this new built-in support, developers can get started immediately: no additional installation, configuration, or discovery steps required.</p>
<p>Equally important: this isn’t a separate dialect or mode of C#. We’re being intentional about making this feature a natural earlier “click-stop” from a regular C# project-based app. You’re writing the same C#, using the same compiler, and when your code grows up, it transitions naturally into a project-based app, if and when you want.</p>
<h2>Getting Started</h2>
<ol>
<li><strong>Install .NET 10 Preview 4</strong>
Download and install it from <a href="https://dotnet.microsoft.com/download/dotnet/10.0">dotnet.microsoft.com</a>.</li>
<li><strong>Install Visual Studio Code (recommended)</strong>
If you’re using Visual Studio Code, install the <a href="https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csdevkit">C# Dev Kit</a> and then follow these instructions to update the C# extension for file-based apps support:
<blockquote><p>To enable support for file-based apps and directives, you’ll need the latest <strong>pre-release version</strong> of the C# extension:</p>
<ul>
<li>Open the Extensions sidebar (<code>Ctrl+Shift+X</code>)</li>
<li>Search for “C#”</li>
<li>In the extension page, click the <strong>Switch to Pre-Release Version</strong> button</li>
<li>Ensure the version installed is at least <code>2.79.8</code></li>
</ul>
</blockquote>
</li>
<li><strong>Write your code</strong>
Create a file called <code>hello.cs</code>:
<pre><code>Console.WriteLine("Hello, world!");</code></pre>
</li>
<li><strong>Run it!</strong>
Open a terminal in the same folder and run:
<pre><code>dotnet run hello.cs</code></pre>
</li>
<li><strong>Convert to a project</strong>
To convert the file to a project, run:
<pre><code>dotnet project convert hello.cs</code></pre>
</li>
</ol>
<h2>Learn more</h2>
<p>Watch this feature in action in this <a href="https://build.microsoft.com/sessions/DEM518?source=sessions">demo session from Microsoft Build</a>:
<a href="https://www.youtube.com/watch?v=98MizuB7i-w">No projects, just C# with <code>dotnet run app.cs</code></a></p>
<p>You’ll see how easy it is to get started, explore directives, and convert to a full project when ready.
<iframe width="800" height="450" src="https://www.youtube.com/embed/98MizuB7i-w?si=l_k3YRlViQR-rCpr" allowfullscreen=""></iframe></p>
<p>You’ll see how easy it is to get started, explore directives, and convert to a full project when ready.</p>
<h2>The road ahead</h2>
<p>With <code>dotnet run app.cs</code>, we’re making C# more approachable, while preserving the full power and depth of the .NET ecosystem. Whether you’re prototyping, teaching, or building production systems, this new capability helps you move faster from idea to execution.</p>
<p>In upcoming .NET 10 previews we’re aiming to improve the experience of working with file-based apps in VS Code, with enhnanced IntelliSense for the new file-based directives, improved performance, and support for debugging. At the command line we’re exploring support for file-based apps with <a href="https://github.com/dotnet/sdk/blob/main/documentation/general/dotnet-run-file.md#multiple-c-files">multiple files</a>, and ways to make running file-based apps faster.</p>
<p>Try it out today and send your <a href="https://github.com/dotnet/sdk/issues/new">feedback to GitHub</a> as we continue to shape this experience during .NET 10 and beyond.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2023/06/Damian-Edwards-Profile-Pic-2020-square-96x96.jpg" alt="Damian Edwards"></p></div><p>Damian's a Principal Architect on the .NET product team at Microsoft.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Trade Court Finds Trump Tariffs Illegal (489 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court</link>
            <guid>44121732</guid>
            <pubDate>Thu, 29 May 2025 00:06:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court">https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court</a>, See on <a href="https://news.ycombinator.com/item?id=44121732">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HTAP is Dead (130 pts)]]></title>
            <link>https://www.mooncake.dev/blog/htap-is-dead</link>
            <guid>44121177</guid>
            <pubDate>Wed, 28 May 2025 22:22:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mooncake.dev/blog/htap-is-dead">https://www.mooncake.dev/blog/htap-is-dead</a>, See on <a href="https://news.ycombinator.com/item?id=44121177">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>This blog is inspired by Jordan Tigani’s blog titled <a href="https://motherduck.com/blog/big-data-is-dead/">“Big Data is Dead”</a>. Jordan and I actually spent some time building a HTAP database at SingleStore. 
</p><h2>The good old days ('70s)</h2><p>Back in the ’70s, one relational database did everything. Transactions (OLTP) during the day and reports after hours (OLAP). Databases like Oracle V2 and IBM DB2 ran OLTP and OLAP on the same system; largely because data sets still fit on a few disks and compute was costly.</p><p>Nobody called it Hybrid Transactional/Analytical Processing (HTAP); it was simply the <strong>database.</strong>
</p><h2>The great divide (‘80s)</h2><p>As businesses had more data and asked tougher questions, the database began to show its limits.</p><p>See, transactional and analytical workloads pull in opposite directions. OLTP requires microsecond inserts and single-row lookups, while OLAP demands full-table scans and large-scale aggregates. This created constant contention; analytics consuming I/O and cache needed for latency-sensitive transactions, and vice versa. </p><p>The solution? Isolate the workloads. By the early ’80s, the Great Divide had begun.
</p><h2>The storage split (‘90s)</h2><p>A key technical driver behind this divide was storage architecture. OLTP systems optimized for row-based storage (fast writes + point queries). While OLAP systems chose columnar storage for efficient scans and aggregations.</p><p>By the mid-2000s, this split had become industry standard. Database pioneer Michael Stonebraker marked this shift in his <a href="https://dl.acm.org/doi/abs/10.1145/3226595.3226636">paper</a>, “One Size Fits All”: An Idea Whose Time Has Come and Gone. The database started breaking up into specialized engines.
</p><h2>OLTP and OLAP both ditched the SQL (2000–2010s)</h2><p>Horizontal scaling pushed OLTP and OLAP even further apart.</p><p>Early distributed OLTP databases (NoSQL engines like MongoDB) dropped SQL and analytical capabilities entirely. On the analytics side, we saw the adoption of MapReduce and Data Lake architectures (Hadoop/HDFS): trading traditional RDBMS properties like strict consistency for massive throughput.
</p><h2>The unexpected reconciliation (2010s)</h2><p>In the 2010s, two distinct database movements gained momentum:</p><p>1. <strong>NewSQL</strong> (Spanner, CockroachDB, Vitess). OLTP should remain SQL-based. <br>2. <strong>Cloud Data Warehouses</strong> (Redshift, Snowflake). OLAP should be on SQL systems with stronger consistency guarantees.</p><p>On paper, these systems served very different workloads. But under the hood, they shared a lot: distributed, MPP-style execution, and SQL. OLTP and OLAP systems, in isolation, had converged on many of the same architectural principles. There was one big difference: storage engines.</p><p>We asked ourselves: what if you could combine both row and columnstore storage engines in a single database? </p><h2>Voilà, HTAP (2014)</h2><p>In 2014, Gartner <a href="https://www.gartner.com/en/documents/2657815#:~:text=Summary,memory%20computing%20technologies%20as%20enablers">introduced</a> the term HTAP (Hybrid Transactional and Analytical Processing): the next big DB architecture. </p><p>The goal was to close the gap between operational and analytical systems. This was a necessity for emerging workloads like pricing, fraud detection, and personalization. Even at the business level, decision makers wanted now’s data. Early HTAP systems showed it could be done. Well, mostly…</p><p><a href="https://dl.acm.org/doi/10.1145/3514221.3526055">SingleStoreDB</a> combined an in-memory rowstore, a disk-based columnstore, and a vectorized execution engine—supporting fast scans, seeks, filters, aggregations, and updates in a single system. Over time, we found that with modern hardware, the columnstore alone could handle a surprising number of OLTP-style queries, including point lookups and low-latency access patterns.</p><p><a href="https://docs.pingcap.com/tidb/stable/tidb-architecture">TiDB</a> took a different route, pairing its TiKV rowstore with a separate columnar engine based on ClickHouse—maintaining two copies of the data to serve both workloads.</p><p>So that should be it, right? ‘70s data nirvana, alas.
</p><h2>The Cloud Data Warehouse was the only winner (2020s)</h2><p>Cloud data warehouses have clearly won. The NewSQL movement stalled… And HTAP? It never got the attention it deserved. Despite real technical progress, it remained pre-product market fit. </p><p><strong>1. It’s really, really hard to replace someone’s OLTP system.</strong> Take <a href="https://db-engines.com/en/ranking">DBEngines’</a> word for this: Oracle and SQL Server still sit at #1 and #3. </p><p><strong>2. Most workloads don’t need distributed OLTP.</strong> Hardware got faster and cheaper. A single beefy machine can handle the majority of transactional workloads.
<a href="https://www.youtube.com/watch?v=4jDQi9P9UIw">Cursor</a> and <a href="https://www.pixelstech.net/article/1747708863-openai%3a-scaling-postgresql-to-the-next-level">OpenAI</a> are powered by a single-box Postgres instance. You’ll be just fine. </p><p><strong>3. Cloud-native architectures favored shared-disk, not shared-nothing.</strong> While NewSQL systems demanded fast local storage (and even in-memory durability), cloud platforms pushed toward object storage and elastic compute. </p><p><strong>4. OLTP and OLAP are owned by different teams.</strong> OLTP is owned by product engineering; OLAP belongs to the data team. The incentives rarely align. No one gets promoted for “consolidating the stack”. </p><h2>Your data-stack forms the HTAP database (Today)</h2><p>The cloud also started the move away from tightly coupled warehouses toward modular lakes built on object storage.<br>In trying to escape the traditional warehouse/database, data teams started assembling their own custom systems. Made of ‘best-in-class’ building blocks:</p><p>1. OLTP systems and stream processors as the WAL<br>2. Open table formats like Iceberg serve as the storage engine<br>3. Query engines like Spark and Trino for execution<br>4. Real-time systems like ClickHouse or Elastic function as indexes</p><p>Even in today’s disaggregated data stack, the need remains the same: fast OLAP queries on fresh transactional data. This now happens through a web of streaming pipelines, cloud data lakes, and real-time query layers.</p><p>It’s still HTAP; but through composition instead of consolidation of databases. It comes down to questions like:</p><p><strong>1. How do I apply the WAL to my storage engine?</strong>
AKA: How do I CDC from my OLTP system to the data lake efficiently?</p><p><strong>2. Can I build a lower-cost index on my data lake, and keep it in sync?</strong>
AKA: How do I ingest real-time data into the lake? Or how do I query Lake data with Postgres or Elastic functionality?</p><p>The HTAP challenge of our time comes down to making the lakehouse real-time ready.</p><p>After spending my best 10 years first starting and then rescuing it, HTAP as a database is dead. <br>But let the spirit live on.<br>🥮</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Long live American Science and Surplus (which needs your help) (323 pts)]]></title>
            <link>https://milwaukeerecord.com/city-life/long-live-american-science-surplus-which-needs-your-help/</link>
            <guid>44120507</guid>
            <pubDate>Wed, 28 May 2025 20:47:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://milwaukeerecord.com/city-life/long-live-american-science-surplus-which-needs-your-help/">https://milwaukeerecord.com/city-life/long-live-american-science-surplus-which-needs-your-help/</a>, See on <a href="https://news.ycombinator.com/item?id=44120507">Hacker News</a></p>
Couldn't get https://milwaukeerecord.com/city-life/long-live-american-science-surplus-which-needs-your-help/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[A toy RTOS inside Super Mario Bros. using emulator save states (219 pts)]]></title>
            <link>https://prettygoodblog.com/p/what-threads-are-part-2</link>
            <guid>44120241</guid>
            <pubDate>Wed, 28 May 2025 20:15:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prettygoodblog.com/p/what-threads-are-part-2">https://prettygoodblog.com/p/what-threads-are-part-2</a>, See on <a href="https://news.ycombinator.com/item?id=44120241">Hacker News</a></p>
Couldn't get https://prettygoodblog.com/p/what-threads-are-part-2: Error: getaddrinfo ENOTFOUND prettygoodblog.com]]></description>
        </item>
        <item>
            <title><![CDATA[What does “Undecidable” mean, anyway (120 pts)]]></title>
            <link>https://buttondown.com/hillelwayne/archive/what-does-undecidable-mean-anyway/</link>
            <guid>44119890</guid>
            <pubDate>Wed, 28 May 2025 19:37:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/hillelwayne/archive/what-does-undecidable-mean-anyway/">https://buttondown.com/hillelwayne/archive/what-does-undecidable-mean-anyway/</a>, See on <a href="https://news.ycombinator.com/item?id=44119890">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <date>
                
                
                May 28, 2025
                
                
            </date>
            

            

            
            <h2>
                An explainer for people who don't know computer science and are mildly curious
            </h2>
            

            

            
            
            <h3>Systems Distributed</h3>
<p>I'll be speaking at <a href="https://systemsdistributed.com/" target="_blank">Systems Distributed</a> next month! The talk is brand new and will aim to showcase some of the formal methods mental models that would be useful in mainstream software development. It has added some extra stress on my schedule, though, so expect the next two monthly releases of <em>Logic for Programmers</em> to be mostly minor changes.</p>
<h2>What does "Undecidable" mean, anyway</h2>
<p>Last week I read <a href="https://liamoc.net/forest/loc-000S/index.xml" target="_blank">Against Curry-Howard Mysticism</a>, which is a solid article I recommend reading. But this newsletter is actually about <a href="https://lobste.rs/s/n0whur/against_curry_howard_mysticism#c_lbts57" target="_blank">one comment</a>:</p>
<blockquote>
<p>I like to see posts like this because I often feel like I can’t tell the difference between BS and a point I’m missing. Can we get one for questions like “Isn’t XYZ (Undecidable|NP-Complete|PSPACE-Complete)?” </p>
</blockquote>
<p>I've already written one of these for <a href="https://www.hillelwayne.com/post/np-hard/" target="_blank">NP-complete</a>, so let's do one for "undecidable". Step one is to pull a technical definition from the book <a href="https://link.springer.com/book/10.1007/978-1-4612-1844-9" target="_blank"><em>Automata and Computability</em></a>:</p>
<blockquote>
<p>A property P of strings is said to be decidable if ... there is a total Turing machine that accepts input strings that have property P and rejects those that do not. (pg 220)</p>
</blockquote>
<p>Step two is to translate the technical computer science definition into more conventional programmer terms. Warning, because this is a newsletter and not a blog post, I might be a little sloppy with terms.</p>
<h3>Machines and Decision Problems</h3>
<p>In automata theory, all inputs to a "program" are strings of characters, and all outputs are "true" or "false". A program "accepts" a string if it outputs "true", and "rejects" if it outputs "false". You can think of this as automata studying all pure functions of type <code>f :: string -&gt; boolean</code>. Problems solvable by finding such an <code>f</code> are called "decision problems".</p>
<p>This covers more than you'd think, because we can bootstrap more powerful functions from these. First, as anyone who's programmed in bash knows, strings can represent any other data. Second, we can fake non-boolean outputs by instead checking if a certain computation gives a certain result. For example, I can reframe the function <code>add(x, y) = x + y</code> as a decision problem like this:</p>
<div><pre><span></span><code>IS_SUM(str) {
    x, y, z = split(str, "#")
    return x + y == z
}
</code></pre></div>
<p>Then because <code>IS_SUM("2#3#5")</code> returns true, we know <code>2 + 3 == 5</code>, while <code>IS_SUM("2#3#6")</code> is false. Since we can bootstrap parameters out of strings, I'll just say it's <code>IS_SUM(x, y, z)</code> going forward.</p>
<p>A big part of automata theory is studying different models of computation with different strengths. One of the weakest is called <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton" target="_blank">"DFA"</a>. I won't go into any details about what DFA actually can do, but the important thing is that it <em>can't</em> solve <code>IS_SUM</code>. That is, if you give me a DFA that takes inputs of form <code>x#y#z</code>, I can always find an input where the DFA returns true when <code>x + y != z</code>, <em>or</em> an input which returns false when <code>x + y == z</code>.</p>
<p>It's really important to keep this model of "solve" in mind: a program solves a problem if it correctly returns true on all true inputs and correctly returns false on all false inputs.</p>
<h3>(total) Turing Machines</h3>
<p>A Turing Machine (TM) is a particular type of computation model. It's important for two reasons: </p>
<ol>
<li>
<p>By the <a href="https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis" target="_blank">Church-Turing thesis</a>, a Turing Machine is the "upper bound" of how powerful (physically realizable) computational models can get. This means that if an actual real-world programming language can solve a particular decision problem, so can a TM. Conversely, if the TM <em>can't</em> solve it, neither can the programming language.<sup id="fnref:caveat"><a href="#fn:caveat">1</a></sup></p>
</li>
<li>
<p>It's possible to write a Turing machine that takes <em>a textual representation of another Turing machine</em> as input, and then simulates that Turing machine as part of its computations. </p>
</li>
</ol>
<p>Property (1) means that we can move between different computational models of equal strength, proving things about one to learn things about another. That's why I'm able to write <code>IS_SUM</code> in a pseudocode instead of writing it in terms of the TM computational model (and why I was able to use <code>split</code> for convenience). </p>
<p>Property (2) does several interesting things. First of all, it makes it possible to compose Turing machines. Here's how I can roughly ask if a given number is the sum of two primes, with "just" addition and boolean functions:</p>
<div><pre><span></span><code>IS_SUM_TWO_PRIMES(z):
    x := 1
    y := 1
    loop {
        if x &gt; z {return false}
        if IS_PRIME(x) {
            if IS_PRIME(y) {
                if IS_SUM(x, y, z) {
                    return true;
                }
            }
        }
        y := y + 1
        if y &gt; x {
            x := x + 1
            y := 0
        }
    }
</code></pre></div>
<p>Notice that without the <code>if x &gt; z {return false}</code>, the program would loop forever on <code>z=2</code>. A TM that always halts for all inputs is called <strong>total</strong>.</p>
<p>Property (2) also makes "Turing machines" a possible input to functions, meaning that we can now make decision problems about the behavior of Turing machines. For example, "does the TM <code>M</code> either accept or reject <code>x</code> within ten steps?"<sup id="fnref:backticks"><a href="#fn:backticks">2</a></sup></p>
<div><pre><span></span><code>IS_DONE_IN_TEN_STEPS(M, x) {
    for (i = 0; i &lt; 10; i++) {
        `simulate M(x) for one step`
        if(`M accepted or rejected`) {
            return true
        }
    }
    return false
}
</code></pre></div>
<h3>Decidability and Undecidability</h3>
<p>Now we have all of the pieces to understand our original definition:</p>
<blockquote>
<p>A property P of strings is said to be decidable if ... there is a total Turing machine that accepts input strings that have property P and rejects those that do not. (220)</p>
</blockquote>
<p>Let <code>IS_P</code> be the decision problem "Does the input satisfy P"? Then <code>IS_P</code> is decidable if it can be solved by a Turing machine, ie, I can provide some <code>IS_P(x)</code> machine that <em>always</em> accepts if <code>x</code> has property P, and always rejects if <code>x</code> doesn't have property P. If I can't do that, then <code>IS_P</code> is undecidable. </p>
<p><code>IS_SUM(x, y, z)</code> and <code>IS_DONE_IN_TEN_STEPS(M, x)</code> are decidable properties. Is <code>IS_SUM_TWO_PRIMES(z)</code> decidable? Some analysis shows that our corresponding program will either find a solution, or have <code>x&gt;z</code> and return false. So yes, it is decidable.</p>
<p>Notice there's an asymmetry here. To prove some property is decidable, I need just to need to find <em>one</em> program that correctly solves it. To prove some property is undecidable, I need to show that any possible program, no matter what it is, doesn't solve it.</p>
<p>So with that asymmetry in mind, do are there <em>any</em> undecidable problems? Yes, quite a lot. Recall that Turing machines can accept encodings of other TMs as input, meaning we can write a TM that checks <em>properties of Turing machines</em>. And, by <a href="https://en.wikipedia.org/wiki/Rice%27s_theorem" target="_blank">Rice's Theorem</a>, almost every nontrivial semantic<sup id="fnref:nontrivial"><a href="#fn:nontrivial">3</a></sup> property of Turing machines is undecidable. The conventional way to prove this is to first find a single undecidable property <code>H</code>, and then use that to bootstrap undecidability of other properties.</p>
<p>The canonical and most famous example of an undecidable problem is the <a href="https://en.wikipedia.org/wiki/Halting_problem" target="_blank">Halting problem</a>: "does machine M halt on input i?" It's pretty easy to prove undecidable, and easy to use it to bootstrap other undecidability properties. But again, <em>any</em> nontrivial property is undecidable. Checking a TM is total is undecidable. Checking a TM accepts <em>any</em> inputs is undecidable. Checking a TM solves <code>IS_SUM</code> is undecidable. Etc etc etc.</p>
<h3>What this doesn't mean in practice</h3>
<p>I often see the halting problem misconstrued as "it's impossible to tell if a program will halt before running it." <strong>This is wrong</strong>. The halting problem says that we cannot create an algorithm that, when applied to an arbitrary program, tells us whether the program will halt or not. It is absolutely possible to tell if many programs will halt or not. It's possible to find entire subcategories of programs that are guaranteed to halt. It's possible to say "a program constructed following constraints XYZ is guaranteed to halt." </p>
<p>The actual consequence of undecidability is more subtle. If we want to know if a program has property P, undecidability tells us</p>
<ol>
<li>We will have to spend time and mental effort to determine if it has P</li>
<li>We may not be successful.</li>
</ol>
<p>This is subtle because we're so used to living in a world where everything's undecidable that we don't really consider what the counterfactual would be like. In such a world there might be no need for Rust, because "does this C program guarantee memory-safety" is a decidable property. The entire field of formal verification could be unnecessary, as we could just check properties of arbitrary programs directly. We could automatically check if a change in a program preserves all existing behavior. Lots of famous math problems could be solved overnight. </p>
<p>(This to me is a strong "intuitive" argument for why the halting problem is undecidable: a halt detector can be trivially repurposed as a program optimizer / theorem-prover / bcrypt cracker / chess engine. It's <em>too powerful</em>, so we should expect it to be impossible.)</p>
<p>But because we don't live in that world, all of those things are hard problems that take effort and ingenuity to solve, and even then we often fail.</p>
<h3>Update for the Internet</h3>
<p>This was sent as a weekly newsletter, which is usually on topics like <a href="https://buttondown.com/hillelwayne/archive/why-do-we-call-it-boilerplate-code" target="_blank">software history</a>, <a href="https://buttondown.com/hillelwayne/archive/the-seven-specification-ur-languages/" target="_blank">formal methods</a>, <a href="https://buttondown.com/hillelwayne/archive/i-formally-modeled-dreidel-for-no-good-reason/" target="_blank">unusual technologies</a>, and the <a href="https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/" target="_blank">theory of software engineering</a>. You <a href="https://buttondown.email/hillelwayne/" target="_blank">can subscribe here</a>.</p>

            
            

            
            
            <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.com/hillelwayne" target="_blank">here</a>. Updates are once a week. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
<p><em>My new book, </em>Logic for Programmers<em>, is now in early access! Get it <a href="https://leanpub.com/logic/" target="_blank">here</a>.</em></p>
            
            

            





        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deepseek R1-0528 (377 pts)]]></title>
            <link>https://huggingface.co/deepseek-ai/DeepSeek-R1-0528</link>
            <guid>44118818</guid>
            <pubDate>Wed, 28 May 2025 17:59:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-0528">https://huggingface.co/deepseek-ai/DeepSeek-R1-0528</a>, See on <a href="https://news.ycombinator.com/item?id=44118818">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section>
				
				
				
				
				<p>No model card</p></section>
			<section><div><dl><dt>Downloads last month</dt><dd>0
							</dd></dl>
						</div>
					

				<div data-target="ModelTensorsParams" data-props="{&quot;modelId&quot;:&quot;deepseek-ai/DeepSeek-R1-0528&quot;,&quot;safetensors&quot;:{&quot;parameters&quot;:{&quot;BF16&quot;:3918786560,&quot;F8_E4M3&quot;:680571043840,&quot;F32&quot;:41555600},&quot;total&quot;:684531386000,&quot;sharded&quot;:true},&quot;isGated&quot;:false,&quot;query&quot;:{},&quot;model&quot;:{&quot;author&quot;:&quot;deepseek-ai&quot;,&quot;config&quot;:{&quot;architectures&quot;:[&quot;DeepseekV3ForCausalLM&quot;],&quot;auto_map&quot;:{&quot;AutoConfig&quot;:&quot;configuration_deepseek.DeepseekV3Config&quot;,&quot;AutoModel&quot;:&quot;modeling_deepseek.DeepseekV3Model&quot;,&quot;AutoModelForCausalLM&quot;:&quot;modeling_deepseek.DeepseekV3ForCausalLM&quot;},&quot;model_type&quot;:&quot;deepseek_v3&quot;,&quot;quantization_config&quot;:{&quot;quant_method&quot;:&quot;fp8&quot;},&quot;tokenizer_config&quot;:{&quot;bos_token&quot;:{&quot;__type&quot;:&quot;AddedToken&quot;,&quot;content&quot;:&quot;<｜begin▁of▁sentence｜>&quot;,&quot;lstrip&quot;:false,&quot;normalized&quot;:true,&quot;rstrip&quot;:false,&quot;single_word&quot;:false},&quot;eos_token&quot;:{&quot;__type&quot;:&quot;AddedToken&quot;,&quot;content&quot;:&quot;<｜end▁of▁sentence｜>&quot;,&quot;lstrip&quot;:false,&quot;normalized&quot;:true,&quot;rstrip&quot;:false,&quot;single_word&quot;:false},&quot;pad_token&quot;:{&quot;__type&quot;:&quot;AddedToken&quot;,&quot;content&quot;:&quot;<｜end▁of▁sentence｜>&quot;,&quot;lstrip&quot;:false,&quot;normalized&quot;:true,&quot;rstrip&quot;:false,&quot;single_word&quot;:false},&quot;unk_token&quot;:null,&quot;chat_template&quot;:&quot;{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\\n\\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{ bos_token }}{{ ns.system_prompt }}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' in message %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls'] %}{%- if not ns.is_first %}{%- if message['content'] is none %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- else %}{{'<｜Assistant｜>' + message['content'] + '<｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- endif %}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- endif %}{%- endfor %}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' not in message %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}&quot;}},&quot;createdAt&quot;:&quot;2025-05-28T09:46:42.000Z&quot;,&quot;discussionsDisabled&quot;:false,&quot;downloads&quot;:0,&quot;downloadsAllTime&quot;:0,&quot;id&quot;:&quot;deepseek-ai/DeepSeek-R1-0528&quot;,&quot;isLikedByUser&quot;:false,&quot;availableInferenceProviders&quot;:[],&quot;inference&quot;:&quot;&quot;,&quot;lastModified&quot;:&quot;2025-05-28T18:01:18.000Z&quot;,&quot;likes&quot;:251,&quot;librariesOther&quot;:[],&quot;trackDownloads&quot;:true,&quot;private&quot;:false,&quot;repoType&quot;:&quot;model&quot;,&quot;gated&quot;:false,&quot;pwcLink&quot;:{&quot;error&quot;:&quot;Unknown error, can't generate link to Papers With Code.&quot;},&quot;tags&quot;:[&quot;safetensors&quot;,&quot;deepseek_v3&quot;,&quot;custom_code&quot;,&quot;fp8&quot;,&quot;region:us&quot;],&quot;tag_objs&quot;:[{&quot;id&quot;:&quot;safetensors&quot;,&quot;label&quot;:&quot;Safetensors&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;deepseek_v3&quot;,&quot;label&quot;:&quot;deepseek_v3&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;custom_code&quot;,&quot;label&quot;:&quot;custom_code&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;fp8&quot;,&quot;label&quot;:&quot;fp8&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;type&quot;:&quot;region&quot;,&quot;label&quot;:&quot;🇺🇸 Region: US&quot;,&quot;id&quot;:&quot;region:us&quot;}],&quot;safetensors&quot;:{&quot;parameters&quot;:{&quot;BF16&quot;:3918786560,&quot;F8_E4M3&quot;:680571043840,&quot;F32&quot;:41555600},&quot;total&quot;:684531386000,&quot;sharded&quot;:true},&quot;hasBlockedOids&quot;:false,&quot;region&quot;:&quot;us&quot;,&quot;isQuantized&quot;:false,&quot;xetEnabled&quot;:false},&quot;canWrite&quot;:false}"><div><p>Safetensors</p><a target="_blank" href="https://huggingface.co/docs/safetensors"></a></div>
		<div><div><p>Model size</p>
				<p>685B params</p></div>
			<div><p>Tensor type</p>
				<div><p>BF16
						</p><p>·</p><p>F8_E4M3
						</p><p>·</p><p>F32
						</p><p>·</p></div></div>
			</div></div>
					

				<div data-target="InferenceWidget" data-props="{&quot;model&quot;:{&quot;author&quot;:&quot;deepseek-ai&quot;,&quot;config&quot;:{&quot;architectures&quot;:[&quot;DeepseekV3ForCausalLM&quot;],&quot;auto_map&quot;:{&quot;AutoConfig&quot;:&quot;configuration_deepseek.DeepseekV3Config&quot;,&quot;AutoModel&quot;:&quot;modeling_deepseek.DeepseekV3Model&quot;,&quot;AutoModelForCausalLM&quot;:&quot;modeling_deepseek.DeepseekV3ForCausalLM&quot;},&quot;model_type&quot;:&quot;deepseek_v3&quot;,&quot;quantization_config&quot;:{&quot;quant_method&quot;:&quot;fp8&quot;},&quot;tokenizer_config&quot;:{&quot;bos_token&quot;:{&quot;__type&quot;:&quot;AddedToken&quot;,&quot;content&quot;:&quot;<｜begin▁of▁sentence｜>&quot;,&quot;lstrip&quot;:false,&quot;normalized&quot;:true,&quot;rstrip&quot;:false,&quot;single_word&quot;:false},&quot;eos_token&quot;:{&quot;__type&quot;:&quot;AddedToken&quot;,&quot;content&quot;:&quot;<｜end▁of▁sentence｜>&quot;,&quot;lstrip&quot;:false,&quot;normalized&quot;:true,&quot;rstrip&quot;:false,&quot;single_word&quot;:false},&quot;pad_token&quot;:{&quot;__type&quot;:&quot;AddedToken&quot;,&quot;content&quot;:&quot;<｜end▁of▁sentence｜>&quot;,&quot;lstrip&quot;:false,&quot;normalized&quot;:true,&quot;rstrip&quot;:false,&quot;single_word&quot;:false},&quot;unk_token&quot;:null,&quot;chat_template&quot;:&quot;{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\\n\\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{ bos_token }}{{ ns.system_prompt }}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' in message %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls'] %}{%- if not ns.is_first %}{%- if message['content'] is none %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- else %}{{'<｜Assistant｜>' + message['content'] + '<｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- endif %}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- endif %}{%- endfor %}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' not in message %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}&quot;}},&quot;createdAt&quot;:&quot;2025-05-28T09:46:42.000Z&quot;,&quot;discussionsDisabled&quot;:false,&quot;downloads&quot;:0,&quot;downloadsAllTime&quot;:0,&quot;id&quot;:&quot;deepseek-ai/DeepSeek-R1-0528&quot;,&quot;isLikedByUser&quot;:false,&quot;availableInferenceProviders&quot;:[],&quot;inference&quot;:&quot;&quot;,&quot;lastModified&quot;:&quot;2025-05-28T18:01:18.000Z&quot;,&quot;likes&quot;:251,&quot;librariesOther&quot;:[],&quot;trackDownloads&quot;:true,&quot;private&quot;:false,&quot;repoType&quot;:&quot;model&quot;,&quot;gated&quot;:false,&quot;pwcLink&quot;:{&quot;error&quot;:&quot;Unknown error, can't generate link to Papers With Code.&quot;},&quot;tags&quot;:[&quot;safetensors&quot;,&quot;deepseek_v3&quot;,&quot;custom_code&quot;,&quot;fp8&quot;,&quot;region:us&quot;],&quot;tag_objs&quot;:[{&quot;id&quot;:&quot;safetensors&quot;,&quot;label&quot;:&quot;Safetensors&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;deepseek_v3&quot;,&quot;label&quot;:&quot;deepseek_v3&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;custom_code&quot;,&quot;label&quot;:&quot;custom_code&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;fp8&quot;,&quot;label&quot;:&quot;fp8&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;type&quot;:&quot;region&quot;,&quot;label&quot;:&quot;🇺🇸 Region: US&quot;,&quot;id&quot;:&quot;region:us&quot;}],&quot;safetensors&quot;:{&quot;parameters&quot;:{&quot;BF16&quot;:3918786560,&quot;F8_E4M3&quot;:680571043840,&quot;F32&quot;:41555600},&quot;total&quot;:684531386000,&quot;sharded&quot;:true},&quot;hasBlockedOids&quot;:false,&quot;region&quot;:&quot;us&quot;,&quot;isQuantized&quot;:false,&quot;xetEnabled&quot;:false},&quot;canWrite&quot;:false,&quot;shouldUpdateUrl&quot;:true,&quot;inferenceContextData&quot;:{&quot;billableEntities&quot;:[],&quot;entityName2Providers&quot;:{}},&quot;linkToInferenceDiscussion&quot;:{&quot;url&quot;:&quot;/spaces/huggingface/InferenceSupport/discussions/2216&quot;,&quot;numReactions&quot;:10}}">

<div>
					<p><span>Inference Providers</span>
					<a target="_blank" href="https://huggingface.co/docs/inference-providers">NEW
					</a></p></div>


		<div><p><span>This model isn't deployed by any Inference Provider.</span>

					<a href="https://huggingface.co/spaces/huggingface/InferenceSupport/discussions/2216"><span><span>🙋</span>
							<span>10</span></span>
						<span>Ask for provider support</span></a></p></div></div>

				
	<h2>
		Model tree for <span>deepseek-ai/DeepSeek-R1-0528</span>
		<a href="https://huggingface.co/docs/hub/model-cards#specifying-a-base-model" target="_blank"></a></h2>
	<div><div>
				<svg width="19" height="28" viewBox="0 0 19 28" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 0C1 7.42391 7.4588 13.5 15.5 13.5V14.5C6.9726 14.5 0 8.04006 0 0H1Z" fill="currentColor"></path></svg></div>
			<p>Finetunes</p>
			
			<p><a href="https://huggingface.co/models?other=base_model:finetune:deepseek-ai/DeepSeek-R1-0528">1 model</a>
		</p></div>

				
				
				
					<h2>
						Collection including
						<span>deepseek-ai/DeepSeek-R1-0528</span></h2>
					<div><article><a href="https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d"><header title="DeepSeek-R1"><h4>DeepSeek-R1</h4>
				<div><p>
					Collection
				</p></div></header>

			<div>
				<p><span>9 items</span>
				<span>• </span>
				<span>Updated
					<time datetime="2025-05-28T17:43:04" title="2025-05-28T17:43:04.961Z">about 2 hours ago</time></span>
				<span>•</span></p><p>

					645</p></div></a></article>
	</div>

				
				</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compiling a Neural Net to C for a 1,744× speedup (259 pts)]]></title>
            <link>https://slightknack.dev/blog/difflogic/</link>
            <guid>44118373</guid>
            <pubDate>Wed, 28 May 2025 17:22:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slightknack.dev/blog/difflogic/">https://slightknack.dev/blog/difflogic/</a>, See on <a href="https://news.ycombinator.com/item?id=44118373">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            

            <!-- <div class="text-input-container">
                <input
                    id="search"
                    type="search"
                    placeholder="Jump to..."
                    autocomplete="off"
                />
                <div class="search-results" style="display: none">
                    <div class="search-results__items"></div>
                </div>
            </div> -->

            
<!-- <div> -->

<p>2025-05-27 · About 25 minutes long</p>
<p><strong>tl;dr:</strong> I trained a neural network (NN), with logic gates in the place of activation functions, to learn a 3×3 kernel function for Conway’s Game of Life. I wanted to see if I could speed up inference by extracting the learned logic circuit from the NN. So, I wrote some code to extract and compile the extracted logic circuit to bit-parallel C (with some optimizations to remove gates that don’t contribute to the output). I benchmarked the original NN against the extracted 300-line single-threaded C program.; compiling the NN to C resulted in a 1,744× speedup! Crazy, right? <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic">Here’s the repo</a>: <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/6f01c83a0e6d02dcec59ab91c64eaf91ee4a3776/main.py">~354 lines of Python/JAX</a>, <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/master/gate.c">~331 lines of C</a>, if you want to <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/tree/89e2ed2f2c018122132598ea610a960900079bea?tab=readme-ov-file#to-reproduce">reproduce it</a> and/or mess around.</p>
<!-- <iframe src="/conway" width="100%" frameborder="0"></iframe> -->
<p><img alt="ghostty with 512 by 512 board of conway's game of life on it" src="https://slightknack.dev/content/conway-tui.png"></p><h2 id="the-longer-story">The longer story</h2>
<p>While plumbing the intertubes (as one does), I came across <a rel="noopener nofollow" target="_blank" href="https://google-research.github.io/self-organising-systems/difflogic-ca/">this fun publication</a> by the <a rel="noopener nofollow" target="_blank" href="https://google-research.github.io/self-organising-systems/"><em>Self Organising Systems</em></a> group at Google, about <em>Differentiable Logic Cellular Automata</em>. This research caught my attention (I mean, who doesn’t love a pretty picture), and as I read it, I realized the whole idea wouldn’t be <em>too</em> hard to replicate. (Which is crazy, because <em>this</em> is crazy. I mean, the authors cite <em>creating <a rel="noopener nofollow" target="_blank" href="https://en.wikipedia.org/wiki/Computronium">computronium</a></em> as a source of inspiration. Awesome!)</p>
<p>To break things down a little bit: <em><a rel="noopener nofollow" target="_blank" href="https://arxiv.org/abs/2210.08277">Differentiable Logic</a> <a rel="noopener nofollow" target="_blank" href="https://distill.pub/2020/growing-ca/">Cellular Automata</a></em> is a quite a mouthful, I know, but the idea is the straightforward composition of two existing ideas:</p>
<ol>
<li>
<p><strong>Cellular Automata (CA)</strong> are grids of cells, where each cell changes over time according to some <em>local</em> rule. The most famous cellular automata are <a rel="noopener nofollow" target="_blank" href="https://blog.oimo.io/2023/04/10/life-universe-en/"><em>Conway’s Game of Life</em></a> and perhaps <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/machine-110"><em>Rule 110</em></a>. We call this local update rule a <em>kernel</em>, a function that looks at the local neighborhood around a cell to calculate the cell’s next state. By applying the kernel to each cell in our grid, we step the cellular automata forward through time. Simple rules can give rise to <a rel="noopener nofollow" target="_blank" href="https://www.youtube.com/watch?v=C2vgICfQawE">strikingly complex behaviour</a>. <a rel="noopener nofollow" target="_blank" href="https://distill.pub/2020/growing-ca/"><strong>Neural Cellular Automata (NCA)</strong></a> are a variant of CA that replace the kernel function with a neural network. NCA can be trained to learn known kernels (what I do), or more generally, to learn kernels that give rise to a specified target behavior.</p>
</li>
<li>
<p><strong>Deep Differentiable Logic Gate Networks (DLGNs)</strong> are like neural networks, with two key differences. First, the <strong>weights are fixed</strong>, and set to 0 or 1; each neuron has exactly two inputs (one left, one right) We call these weights <em>wires</em>. Since wires are fixed, we <strong>learn the activation function</strong>. In this case, our activation function is a weighted linear combination of a set of 16 logic gates, applied to the two inputs. Essentially, we learn which logic gate should be used for each node in a fixed circuit. (If you’re a little lost, don’t worry, later, I’ll go into more detail to describe what this looks like in practice.)</p>
</li>
</ol>
<p>After reading the <a rel="noopener nofollow" target="_blank" href="https://google-research.github.io/self-organising-systems/difflogic-ca/">original publication</a>, I wanted to play with a few different experiments. To start, I wanted to replicate the research without looking at it too closely, to give room for creative misinterpretation, to understand what decisions were important. I also wanted to mess around with whatever the result of that was, until something <em>interesting</em> fell out. Consider this to be something of a pilot episode: there is a lot I still would like to experiment with. (Like fluid simulation! We could find a circuit for the kernel rule for <em><a rel="noopener nofollow" target="_blank" href="https://michaelmoroz.github.io/Reintegration-Tracking/">Reintegration Tracking</a></em>. Wouldn’t that be neat?)</p>
<p>I tried something new for the first time, which was to keep a <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic?tab=readme-ov-file#journal">journal</a> during development. I have no idea why I’ve never done this before, because it made recording training runs, figuring out what to debug, tracking next steps, and scoping changes <em>so</em> much easier. (Not to mention writing this write-up!) This project took three days (well, <del>four</del> five if you count this write-up), and it’s cool to see how much progress I made each day.</p>
<h2 id="conway-s-what-a-quick-recap">Conway’s what? A quick recap</h2>
<p><em>Conway’s Game of Life</em> is a Cellular Automata that takes place on a 2D grid of square cells. Each cell has 8 neighbors. At each step, looking at this 3×3 neighborhood,  we decide whether each cell is alive or dead, according to two rules:</p>
<ol>
<li>If the cell has exactly 3 live neighbors, it is alive.</li>
<li>If the cell has exactly 2 live neighbors, and is alive, it remains alive.</li>
</ol>
<p>I guess there’s a harsh third rule which is, “if the cell is dead, it stays dead”. You may already begin to see how this could be written as a logic circuit. Here’s one way: given an array, <code>inputs</code>, with 9 cells where <code>0</code> is dead, <code>1</code> is alive, we can write:</p>
<pre data-lang="python"><code data-lang="python"><span>n = </span><span>sum</span><span>(inputs) - alive </span><span># neighbors excluding center
</span><span>alive_next = (n == </span><span>3</span><span>) or ((n == </span><span>2</span><span>) and alive)
</span></code></pre>
<p>The hard part, you might glean, would be coming up with a compact circuit for counting <code>n</code>, the number of neighbors. That’s what we’re up against: given a 9-bit input, we’re going to try to learn a circuit of logic gates whose output matches the 1-bit <code>alive_next</code> output, end-to-end.</p>
<blockquote>
<p><em>N.B.</em> You should try coming up with a circuit yourself, by hand! I did, it’s not too crazy. Here’s a hint: A cell has 8 neighbors. You can count how many cells are alive for any pair of inputs: <code>xor</code> for 1, <code>and</code> for 2. Can you use two pairs to count 4? What about 8? Once you can determine whether the neighborhood count is 2 or 3, the rest is fairly straightforward. How many logic gates did you use? How deep is your circuit?</p>
</blockquote>
<h2 id="in-the-beginning-was-jax">In the beginning was JAX</h2>
<p>Now, I suppose I’ll show my age by saying that my knowledge of ML frameworks is stuck around 2017, with <em>old</em> Keras (never change, <code>Sequential</code>) and TensorFlow (<em>before</em> 2.0). I used to mess around with GANs (<em>StyleGAN</em> &lt;3) and I even implemented <a rel="noopener nofollow" target="_blank" href="https://openai.com/index/reinforcement-learning-with-prediction-based-rewards/">RND</a> on top of <a rel="noopener nofollow" target="_blank" href="https://arxiv.org/abs/1707.06347">PPO</a> at some point! So I have a good intuition of the basics. Much has been lost to the sands of time, aside from a <a rel="noopener nofollow" target="_blank" href="https://github.com/Tloru/CommaSpeedChallenge">handful of random projects</a> shotgunned across GitHub. Sigh.</p>
<p>Well, as Oogway would say, “Yesterday is <em>history</em>, tomorrow is a <em>mystery</em>, but today… is a gift. That is why it is called the <em>present</em>.” There is no better day than today to get back on your A-game.</p>
<p><strong>JAX</strong> is a <a rel="noopener nofollow" target="_blank" href="https://docs.jax.dev/en/latest/quickstart.html">machine learning framework</a> for Python. I think of it as numpy on steroids. JAX has an API-compatible implementation of numpy living at <code>jax.jnp</code>: you can do all the fun matrix stuff (like multiplication!) and you get a couple things for free:</p>
<ol>
<li><strong>grad</strong> will <a rel="noopener nofollow" target="_blank" href="https://docs.jax.dev/en/latest/automatic-differentiation.html">compute the gradient</a> of any non-sadistic function. It does this using automatic <a rel="noopener nofollow" target="_blank" href="https://docs.jax.dev/en/latest/advanced-autodiff.html#jacobian-vector-products-jvps-a-k-a-forward-mode-autodiff">reverse-mode differentiation</a>, but you can get as fancy as you’d like.</li>
<li><strong>vmap</strong> will <a rel="noopener nofollow" target="_blank" href="https://docs.jax.dev/en/latest/autodidax.html">automatically parallelize</a> and vectorize computations that can be run in parallel. For example, I use vmap to batch training in my implementation.</li>
<li><strong>jit</strong> will <a rel="noopener nofollow" target="_blank" href="https://docs.jax.dev/en/latest/jit-compilation.html">just-in-time compile</a> all of the above, and can produce code that runs on the GPU. Compiling Python at the library level using decorators is crazy!</li>
</ol>
<p>JAX has an ecosystem of libraries that mix and match these operations to build more powerful primitives. <strong>Optax</strong>, for example, implements common <a rel="noopener nofollow" target="_blank" href="https://optax.readthedocs.io/en/latest/api/optimizers.html">optimization strategies</a>, like <code>adamw</code>, on top of <code>jax.grad</code>. <strong>Flax</strong>, is a NN library built on top of JAX. (Tbh, flax is a little confusing: there’s <code>nn</code> (<a rel="noopener nofollow" target="_blank" href="https://docs.google.com/document/d/1hYavTVPaKVVe9Be8pCB7yW7r6dDv3RALVNit8NZca4c/edit?tab=t.0">deprecated</a>), <a rel="noopener nofollow" target="_blank" href="https://flax-linen.readthedocs.io/en/latest/"><code>linen</code></a>, <a rel="noopener nofollow" target="_blank" href="https://flax.readthedocs.io/en/latest/index.html"><code>nnx</code></a>. Everyone uses linen but the flax devs want people to use nnx it seems).</p>
<blockquote>
<p><em>N.B.</em> One other thing I like about JAX is that randomness is reproducible. All functions that generate non-deterministic output take a RNG <em>key</em>, and keys can be split into subkeys. The root key is generated when you set the seed; everything else derives from the root key. This means if you run a program twice, you’ll have the same initialization, same training samples, same convergence. It makes debugging a lot easier, because you can reproduce e.g. a blow-up during training with some patience.</p>
</blockquote>
<h2 id="continuous-relaxation">Continuous relaxation</h2>
<p>To learn a circuit, we need some way to translate the hard, discrete language of logic into the smooth, continuous language of <em>gradients</em>. (Gradients, now those are something an optimizer can get a handle on!)</p>
<p>A logic gate, like <code>and(a, b)</code>, is a function of two inputs; we can arrange them into a table like so:</p>

<p>Here, inputs are defined to be exactly <code>0</code> or <code>1</code>. What if the inputs <em>vary</em> between <code>0.0</code> and <code>1.0</code>; is there a continuous function of two inputs <code>f(a, b)</code> that behaves like <code>and(a, b)</code> at the boundary? Well, yes, <code>f(a, b) = a * b</code> fits the bill. We can say that <code>a * b</code> a <em>continuous relaxation</em> of <code>and(a, b)</code>. There are 16 fundamental logical functions of two inputs; here they all are, along with a continuous relaxation for each:</p>
<table><thead><tr><th>gate</th><th>relaxation</th><th>gate</th><th>relaxation</th></tr></thead><tbody>
<tr><td><code>false</code></td><td><code>0.</code></td><td><code>true</code></td><td><code>1.</code></td></tr>
<tr><td><code>and</code></td><td><code>a*b</code></td><td><code>nand</code></td><td><code>1. - a*b</code></td></tr>
<tr><td><code>a&amp;~b</code></td><td><code>a - a*b</code></td><td><code>b/~a</code></td><td><code>1. - a + a*b</code></td></tr>
<tr><td><code>a</code></td><td><code>a</code></td><td><code>not a</code></td><td><code>1. - a</code></td></tr>
<tr><td><code>b&amp;~a</code></td><td><code>b - a*b</code></td><td><code>a/~b</code></td><td><code>1. - b + a*b</code></td></tr>
<tr><td><code>b</code></td><td><code>b</code></td><td><code>not b</code></td><td><code>1. - b</code></td></tr>
<tr><td><code>xor</code></td><td><code>a+b - 2.*a*b</code></td><td><code>xnor</code></td><td><code>1. - (a+b - 2.*a*b)</code></td></tr>
<tr><td><code>or</code></td><td><code>a+b - a*b</code></td><td><code>nor</code></td><td><code>1. - (a+b - a*b)</code></td></tr>
</tbody></table>
<p><img alt="graphs of and, or, and xor" src="https://slightknack.dev/content/cont-relax.svg"></p><p>This is great! (It’s fun to try to derive continuous relaxations yourself.) With this groundwork in place, we could create a “learnable logic gate” of sorts by taking a weighted sum of each relaxation. In JAX, using <code>jnp</code>:</p>
<pre data-lang="python"><code data-lang="python"><span>jnp.</span><span>sum</span><span>(gate_weight * </span><span>gate_all</span><span>(left, right)) </span><span># axis=0
</span></code></pre>
<p>Here, <code>gate_all</code> returns a vector where each entry is the result of one of the functions above. If we want to make sure that the gate weights stay in a reasonable range, we can apply a <em>softmax</em> to the learned vector <code>w</code>, which squashes each gate weight to be between <code>0.0</code> and <code>1.0</code>:</p>
<pre data-lang="python"><code data-lang="python"><span>gate_weight = jnp.</span><span>exp</span><span>(w) / jnp.</span><span>sum</span><span>(jnp.</span><span>exp</span><span>(w)) </span><span># axis=0, keepdims=True
</span></code></pre>
<p>We can train a network to learn these gate weights. Once we have a trained network, can replace the softmax with an <em>argmax</em> (taking the gate with the highest weight). This gives us a circuit with a hard <code>0</code> or <code>1</code> as an output; a discrete logic gate is also much cheaper to compute. (It’s almost as if computers are full of them!)</p>
<h2 id="hardness-zero">Hardness zero</h2>
<p>Well, we have our continuous relaxations and we have a NN. Let’s just put them together, replace <code>relu</code> with <code>gate</code>, and call it a day? Not so fast.</p>
<p>Machine learning papers almost make research look <em>effortless</em>, as though NNs magically converge when enough data is forced through their weights. This could not be further from the truth: there are so many failure modes; so many experiments that have to be run to guess the right hyperparameters; training a NN requires a weird combination of patience (giving the model enough time to converge) and urgency (stopping runs early when something is wrong). It’s fun, but it can also be frustrating, yet somehow addicting.</p>
<p>I could skip over the two days of elbow grease it took to get this working. However, differentiable logic gate networks train a little differently than your standard dense relu network, and there were a couple things, like how you initialize DLGNs, that surprised me.</p>
<h2 id="wiring">Wiring</h2>
<p>At the start of this project, I wanted to see if I could learn the wires in addition to the gates. I still think it’s possible, but it’s something I had to abandon to get the model to converge.</p>
<p>I started this project by writing a simple dense NN with relu activation and standard SGD, just to see if things were working. They were, and my small model converged very quickly!</p>
<p>In traditional NNs, it’s commonly-accepted wisdom that you should initialize the wire weight matrices according to a tight normal distribution centered around zero. This is what I did for the relu network above, and it worked like a charm!</p>
<p>I switched from <code>relu</code> to <code>gate</code> by adding two weight matrices per layer, one for the right gate input, the other for the left. After this switch, however, try as I might, the model <em>would not</em> converge. I also started to worry about whether having <em>negative</em> wire weights would make it hard to extract the logical circuit after training. So, I thought some more, and decided to initialize wire weights <em>uniformly</em> between 0 and 1. This performed even worse!</p>
<p>Thinking some more, I had an epiphany: “well, since the goal is to learn a wiring, we should softmax the wires in the same way we softmax the gates!” In desperation, I implemented a row-wise softmax over wire weights initialized uniformly… this also went about as well as you would expect. (Poorly.)</p>
<p>At this point I realized: maybe a fixed <code>1</code> or <code>0</code> wiring is not just a random choice, but <em>highly</em> essential! Wouldn’t a fixed wiring let the gradients propagate all the way to the gates at the <em>input</em> end of the network, so the gates at the <em>output</em> end of the network could begin to converge? I began to look at how wiring was implemented in the paper; I decided to abandon my learned-wiring dreams for the time being.</p>
<p>In hindsight, it’s obvious that how you wire a network determines how information flows through it, so it’s important that the wiring is <em>good</em>, especially if the wiring is fixed. I don’t know why it took me so long to realize this.</p>
<p>After I refactored everything to use fixed wiring, I first I tried completely random wiring. This did a lot better than any of the previous approaches, but was still nowhere <em>near</em> the publication. After careful inspection, I realized that with this approach, you risk not wiring gates, or wiring two gates the same way, losing information as it flows through the network.</p>
<p>My next thought was to wire the network like a tree. We had descending power-of-two layers: 64, 32, 16, 8, 4, 2, 1; what if each layer was connected to the corresponding two cells in the layer before it? This way there is total information flow. Tree wiring worked like a charm, and it was at this point that I started to have hope.</p>
<p>I read the publication more closely, and at this point I looked at the <a rel="noopener nofollow" target="_blank" href="https://colab.research.google.com/github/google-research/self-organising-systems/blob/master/notebooks/diffLogic_CA.ipynb">colab notebook</a>. The wiring technique used is interesting: it guarantees we get unique pairs, like tree wiring, but we also shuffle the branches between layers to allow for some cross-pollination. The algorithm looks something like this:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>wire_rand_unique</span><span>(</span><span>key</span><span>, </span><span>m</span><span>, </span><span>n</span><span>):
</span><span>    key_rand, key_perm = random.</span><span>split</span><span>(key)
</span><span>    evens   = [(</span><span>0</span><span>, </span><span>1</span><span>), (</span><span>2</span><span>, </span><span>3</span><span>), ...]
</span><span>    odds    = [(</span><span>1</span><span>, </span><span>2</span><span>), (</span><span>3</span><span>, </span><span>4</span><span>), ...]
</span><span>    padding = </span><span>rand_pairs_pad</span><span>(key_rand, m, n)
</span><span>    pairs   = jnp.</span><span>array</span><span>([*evens, *odds, *padding])
</span><span>    perm    = random.</span><span>permutation</span><span>(key_perm, pairs)
</span><span>    </span><span>return </span><span>wire_from_pairs</span><span>(perm.T, m, n)
</span></code></pre>
<p>(Note that as long as n ≤ m ≤ 2×n, there will be total network connection with no random padding.)</p>
<p>With the wiring from the publication implemented, the model was within spitting distance of fully converging! That’s when one last revelation <em>shook me to my bones</em>.</p>
<h2 id="initialize-gates-to-pass-through">Initialize gates to pass through</h2>
<p>The biggest surprise was the way you’re supposed to <em>initialize</em> the gate weights of a differentiable logic gate network; of course, it now makes <em>100% sense</em> in hindsight.</p>
<p>Here’s the big idea: we want the gradients to reach the input of the network, but if we initialize gate weights uniformly, or even randomly, we’ll get a flat activation function. Flat activation functions <em>kill</em> all gradients, period. I realized this was happening when I wrote code to visualize each layer in the network, and watched it change over time:</p>
<pre><code><span># [...]
</span><span>layer 3 (16, 8)
</span><span>▄ ▄ ▄ ▄ ▄ ▄ ▄ ▁ ▄ ▄ ▄ ▁ ▄ ▁ ▁ ▁
</span><span>▄ ▄ ▄ ▄ ▄ ▄ ▄ ▁ ▄ ▄ ▄ ▁ ▄ ▁ ▁ ▁
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ █
</span><span>▁ ▁ ▁ ▄ ▁ ▄ ▄ ▄ ▁ ▄ ▄ ▄ ▄ ▄ ▄ ▄
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▄ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁
</span><span>▄ ▄ ▄ ▁ ▄ ▁ ▁ ▁ ▄ ▁ ▁ ▁ ▁ ▁ ▁ ▁
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ █
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ █ ▁ ▁ ▁ ▁ ▁ ▁ ▁
</span><span>layer  4 (16, 4)
</span><span>▁ ▁ ▁ ▁ ▁ █ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁
</span><span>▄ ▄ ▄ ▁ ▄ ▁ ▁ ▁ ▄ ▁ ▁ ▁ ▁ ▁ ▁ ▁
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▁ █ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▄
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ █ ▁ ▁ ▁ ▁ ▁
</span><span>layer 5 (16, 2)
</span><span>▁ ▁ ▁ ▁ ▄ ▁ █ ▁ ▁ ▁ ▁ ▁ ▄ ▁ ▄ ▁
</span><span>▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ █ ▁ ▁ ▁ ▁ ▁
</span><span>layer 6 (16, 1)
</span><span>▁ ▁ █ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁
</span><span>F &amp; . A . B X / / X B . A . &amp; F
</span><span>                ~~~~~~~~~~~~~~~
</span><span># gate order
</span><span>| FALSE | AND  | A&amp;!B  | A    |
</span><span>| B&amp;!A  | B    | XOR   | OR   |
</span><span>| NOR   | XNOR | NOT B | A/!B |
</span><span>| NOT A | B/!A | NAND  | TRUE |
</span></code></pre>
<p>With dead gradients, I’d see the output gate converge, then the one before it, and so on until the gradients reached the input, at which point the later gates were so fixed in their ways that they were impossible to change, even as better earlier gate weights were discovered. Obviously, the performance of the network plateaus shortly thereafter.</p>
<p>I didn’t see an obvious way around this problem, so I started to wonder if there was some weird trick to get around the problem… and there was. So I read the code.</p>
<p>Of all the gates, these two stand out:</p>
<table><thead><tr><th>gate</th><th>relaxation</th><th>explanation</th></tr></thead><tbody>
<tr><td><code>a</code></td><td><code>a</code></td><td>Forward a, drop b.</td></tr>
<tr><td><code>b</code></td><td><code>b</code></td><td>Forward b, drop a.</td></tr>
</tbody></table>
<p>These pass-through gates do no mixing, and will propagate gradients straight along their wires, all the way to the input! This is critical! And in retrospect, I had missed a seemingly-innocuous line:</p>
<blockquote>
<p>To facilitate training stability, the initial distribution of gates is biased toward the pass-through gate.</p>
</blockquote>
<p><em>Of course</em> it is biased! There’s no way to train the network otherwise! So I made a simple one-line change, and, like that, <code>test_loss_hard: 0</code>. <strong>Perfect convergence:</strong></p>
<pre><code><span>Epoch (3001/3001) in 0.0031 s/epoch
</span><span>[ 0.999 0.999 0.00173 0.000287 0.000537 ] [1. 1. 0. 0. 0.] [1. 1. 0. 0. 0.]
</span><span>train_loss: 0.000738; test_loss: 9.91e-05; test_loss_hard: 0
</span></code></pre>
<p>At long last, it all fits together.</p>
<h2 id="hyperfrustration">Hyperfrustration</h2>
<p>What frustrates me is that, after correctly implementing the architecture from the publication, the main issues preventing convergence were seemingly arbitrary hyperparameter choices. In my journal I wrote:</p>
<div>
<p>The model training code was good, as was the gate implementation. So what <em>was</em> wrong?</p>
<ul>
<li>The model was the wrong size (way too small).</li>
<li>The model was initialized the wrong way (randomly, instead of with gate passthrough).</li>
<li>The model did not have clipping in the optimizer, which seems like a rather arbitrary, hacky hyperparameter choice.</li>
</ul>
<p>Hyperparameters suck! I hate that I was pulling my hair out over why I wasn’t getting the same results when all that was different were the hyperparameters at play.</p>
<p>I wonder how many research breakthroughs are possible but just sitting in hyperparameters beyond reach?</p>
</div>
<p>Rather existential, I suppose. There are lots of other things I tried that didn’t work. Earlier, I tried to learn the <em>wiring</em> in addition to gates, but the network wouldn’t converge. I thought it was because the network was too complex, but now I’m convinced it’s because it was too small and initialized incorrectly. There is so much more I would like to try.</p>
<blockquote>
<p><em>N.B.</em> All this wiring got me thinking about gaussian splatting of all things. You see, I was recently reading a paper about <a rel="noopener nofollow" target="_blank" href="https://arxiv.org/abs/2505.05587">when to split gaussian splats</a>; the rough idea is to split whenever the optimizer encounters a saddle with respect to any one splat. While watching underparameterized gate networks train, I would see them get stuck between a handful of gates on a given layer, and not converge further. I wonder if it would be possible to build a circuit network that grows over time, splitting gate saddles when loss stops going down? I suppose that’s what inspired the splat paper, so we’ve come full circle.</p>
</blockquote>

<p>At this point we have learned a <em>perfect</em> binary circuit that looks at a 3×3 cell neighborhood and computes the game of life kernel. Only one problem: This circuit is stuck as a pile of floating point numbers, tangled up in the vast sea of gate weights and wires. How will we ever get it out?</p>
<p>By compiling it to C.</p>
<p>This isn’t as hard as it sounds. All we have to do is <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/89e2ed2f2c018122132598ea610a960900079bea/main.py#L269-L279">traverse the network</a>, layer by layer. We use our old friend <em>argmax</em> to figure out <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/89e2ed2f2c018122132598ea610a960900079bea/main.py#L258-L267">which wires and gate to use</a> for each gate in the circuit.</p>
<p>At this point, we have a massive network. However, only a tiny fraction of the gates are used! (Most gates are still pass-through.) So I implemented two optimizations to clean up the circuit:</p>
<p><strong>Dead code elimination</strong> gets rid of all gates that do not contribute to the output. We’re not doing anything fancy here, like testing for truisms; just doing the simple thing and taking the transitive closure of all dependencies, starting from the root output, going backwards:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>ext_elim</span><span>(</span><span>instrs</span><span>, </span><span>root</span><span>):
</span><span>    out = []
</span><span>    req = </span><span>set</span><span>([root])
</span><span>    </span><span>for </span><span>instr </span><span>in </span><span>instrs[::-</span><span>1</span><span>]:
</span><span>        (o, idx, l, r) = instr
</span><span>        </span><span>if </span><span>o in req:
</span><span>            req = </span><span>ext_add_deps</span><span>(req, idx, l, r)
</span><span>            out.</span><span>append</span><span>(instr)
</span><span>    </span><span>return </span><span>list</span><span>(out[::-</span><span>1</span><span>])
</span></code></pre>
<p><strong>Copy propagation</strong> lets us get rid of all those pesky useless pass-through gates by forwarding their output to all downstream gates. This time we go forward, and keep track of what to rename pass-through gates.</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>ext_copy_prop</span><span>(</span><span>instrs</span><span>, </span><span>root</span><span>):
</span><span>    out = []
</span><span>    rename = </span><span>dict</span><span>()
</span><span>    </span><span>for </span><span>instr </span><span>in </span><span>instrs:
</span><span>        (o, idx, l, r) = instr
</span><span>        </span><span>if </span><span>l in rename: l = rename[l]
</span><span>        </span><span>if </span><span>r in rename: r = rename[r]
</span><span>        </span><span>if </span><span>o == root: out.</span><span>append</span><span>((o, idx, l, r))
</span><span>        </span><span>elif </span><span>idx == </span><span>3</span><span>: rename[o] = l
</span><span>        </span><span>elif </span><span>idx == </span><span>5</span><span>: rename[o] = r
</span><span>        </span><span>else</span><span>: out.</span><span>append</span><span>((o, idx, l, r))
</span><span>    </span><span>return </span><span>out
</span></code></pre>
<p>(Index <code>3</code> and <code>5</code> are the indices of the pass-through gates.)</p>
<p>After this, we do a simple rename for all gates (since we’ve decimated the number of gates in use), and emit C. This is just a big switch-case:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>ext_gate_name</span><span>(</span><span>idx</span><span>, </span><span>l</span><span>, </span><span>r</span><span>):
</span><span>    names = [
</span><span>        </span><span>lambda </span><span>a</span><span>, </span><span>b</span><span>: </span><span>"</span><span>0</span><span>"</span><span>,
</span><span>        </span><span>lambda </span><span>a</span><span>, </span><span>b</span><span>: </span><span>f</span><span>"</span><span>{a}</span><span> &amp; </span><span>{b}</span><span>"</span><span>,
</span><span>        </span><span>lambda </span><span>a</span><span>, </span><span>b</span><span>: </span><span>f</span><span>"</span><span>{a}</span><span> &amp; ~</span><span>{b}</span><span>"</span><span>,
</span><span>        </span><span># ...
</span><span>        </span><span>lambda </span><span>a</span><span>, </span><span>b</span><span>: </span><span>f</span><span>"</span><span>~(</span><span>{a}</span><span> &amp; </span><span>{b}</span><span>)</span><span>"</span><span>,
</span><span>        </span><span>lambda </span><span>a</span><span>, </span><span>b</span><span>: </span><span>"</span><span>~0</span><span>"</span><span>,
</span><span>    ]
</span><span>    </span><span>return </span><span>names[idx](l, r)
</span></code></pre>
<p>After formatting, we get a <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/89e2ed2f2c018122132598ea610a960900079bea/gate.c#L7-L172">long list of instructions</a> that looks like this:</p>
<pre data-lang="c"><code data-lang="c"><span>cell </span><span>conway</span><span>(cell </span><span>in</span><span>[</span><span>9</span><span>]) {
</span><span>    </span><span>// ... 157 lines hidden
</span><span>    cell hh = hc ^ gs;
</span><span>    cell hi = hb &amp; ~gy;
</span><span>    cell hj = hh &amp; hi;
</span><span>    cell hk = hg &amp; cy;
</span><span>    cell out = hj | hk;
</span><span>    </span><span>return</span><span> out;
</span><span>}
</span></code></pre>
<p>And like that, all your floats are belong to us. Here’s the final tally for each basic logical operation used in the circuit. (Note that some gates, e.g. nand, are composed of multiple operations):</p>
<table><thead><tr><th>Gate</th><th>Count</th></tr></thead><tbody>
<tr><td><code>and</code></td><td>69</td></tr>
<tr><td><code>or</code></td><td>68</td></tr>
<tr><td><code>xor</code></td><td>17</td></tr>
<tr><td><code>not</code></td><td>16</td></tr>
<tr><td><strong>total</strong></td><td><strong>170</strong></td></tr>
</tbody></table>
<p>Nice. I don’t know why, but it’s satisfying to see a pretty even split between <code>and</code> and <code>or</code>, as with <code>xor</code> and <code>not</code>. I wonder what the distribution looks like in real-world code. (I thought I never used <code>xor</code>, but then I realized that <code>!=</code> is really just <code>xor</code> in disguise.)</p>
<h2 id="bit-crunching-c">Bit-crunching C</h2>
<p>I pulled a sneaky little trick. I don’t know if you noticed. Here’s a hint:</p>
<pre data-lang="c"><code data-lang="c"><span>typedef </span><span>uint64_t </span><span>cell</span><span>;
</span></code></pre>
<p>That’s right: a <code>cell</code> is not one grid cell, but 64! When we calculate <code>cell conway(cell in[9]);</code>, we are, through <em>bit-parallelism</em>, computing the rule on 64 cells at once!</p>
<p>We compile to C and produce a function containing the circuit, <code>conway</code>, but we need a runtime to saturate it. I took a compilers class this semester (6.1100), so I have been writing a lot of <em>Unnamed Subset of C</em> this semester. With C on the mind, I wrote a little runtime. Here’s how it works.</p>
<p>First, I define a board as a collection of cells:</p>
<pre data-lang="c"><code data-lang="c"><span>typedef struct </span><span>{
</span><span>    cell* cells;
</span><span>    size_t cells_len;
</span><span>    size_t width;
</span><span>    size_t height;
</span><span>} </span><span>board_t</span><span>;
</span></code></pre>
<p>Each <code>cell</code> is just a horizontal slab, 64 bits wide. I’m lazy here, so I require <code>width</code> be a multiple of 64. We initialize this board with random state using an <code>xorshift</code> prng I am currently lending from Wikipedia:</p>
<pre data-lang="c"><code data-lang="c"><span>// https://en.wikipedia.org/wiki/Xorshift
</span><span>// constant is frac(golden_ratio) * 2**64
</span><span>// global state bad cry me a river
</span><span>uint64_t rand_state = </span><span>0x9e3779b97f4a7c55</span><span>;
</span><span>
</span><span>uint64_t </span><span>rand_uint64_t</span><span>() {
</span><span>    uint64_t x = rand_state;
</span><span>    x ^= x &lt;&lt; </span><span>13</span><span>;
</span><span>    x ^= x &gt;&gt; </span><span>7</span><span>;
</span><span>    x ^= x &lt;&lt; </span><span>17</span><span>;
</span><span>    rand_state = x;
</span><span>    </span><span>return</span><span> x;
</span><span>}
</span></code></pre>
<p>On to the meat and potatoes. The function <code>conway</code> requires a list of <code>9</code> cells. The neighbors directly above and below are easy: we just index forward or back a row in <code>cells</code>. The side-by-side neighbors are a bit harder. Luckily, we can just bitshift to the left and right to create two new boards. This works as long as we’re careful to <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/89e2ed2f2c018122132598ea610a960900079bea/gate.c#L243-L271">catch all bits</a> that might fall into the bitbucket when we shift:</p>
<pre data-lang="c"><code data-lang="c"><span>void </span><span>board_step_scratch_mut</span><span>(
</span><span>    board_t *</span><span>board</span><span>,
</span><span>    board_t *</span><span>scratch_left</span><span>,
</span><span>    board_t *</span><span>scratch_right</span><span>, </span><span>// syntax highlighting breaks without a comma here, sigh
</span><span>) {
</span><span>    </span><span>// 5: dense loops and bitshifts,
</span><span>    </span><span>// 7: no beauty I can present.
</span><span>    </span><span>// 5: click the link above.
</span><span>}
</span></code></pre>
<p>I guess a better illustration would be, to analogize:</p>
<table><thead><tr><th>ceos hate these seats</th><th>8-bit analogy</th></tr></thead><tbody>
<tr><td><code>scratch_left</code></td><td><code>10011010 10011010 10011010 ...</code></td></tr>
<tr><td><code>board</code></td><td><code>01001101 01001101 01001101 ...</code></td></tr>
<tr><td><code>scratch_right</code></td><td><code>10100110 10100110 10100110 ...</code></td></tr>
</tbody></table>
<p>With all this machinery in place, we can step the board! I’m proud of this code:</p>
<div>
<pre data-lang="c"><code data-lang="c"><span>void </span><span>board_step_mut</span><span>(
</span><span>    board_t *</span><span>board</span><span>,
</span><span>    board_t *</span><span>s_left</span><span>, </span><span>// scratch
</span><span>    board_t *</span><span>s_right</span><span>,
</span><span>    board_t *</span><span>s_out</span><span>,  </span><span>// sigh
</span><span>) {
</span><span>    </span><span>board_step_scratch_mut</span><span>(board, s_left, s_right);
</span><span>
</span><span>    size_t step = board-&gt;width / </span><span>64</span><span>;
</span><span>    size_t wrap = board-&gt;cells_len;
</span><span>
</span><span>    </span><span>for </span><span>(size_t i = </span><span>0</span><span>; i &lt; board-&gt;cells_len; i++) {
</span><span>        cell in[</span><span>9</span><span>];
</span><span>        size_t i_top = (i + wrap - step) % wrap;
</span><span>        size_t i_bottom = (i + step) % wrap;
</span><span>        </span><span>// top row
</span><span>        in[</span><span>0</span><span>] = s_left-&gt;cells[i_top];
</span><span>        in[</span><span>1</span><span>] = board-&gt;cells[i_top];
</span><span>        in[</span><span>2</span><span>] = s_right-&gt;cells[i_top];
</span><span>        </span><span>// middle row
</span><span>        in[</span><span>3</span><span>] = s_left-&gt;cells[i];
</span><span>        in[</span><span>4</span><span>] = board-&gt;cells[i];
</span><span>        in[</span><span>5</span><span>] = s_right-&gt;cells[i];
</span><span>        </span><span>// bottom row
</span><span>        in[</span><span>6</span><span>] = s_left-&gt;cells[i_bottom];
</span><span>        in[</span><span>7</span><span>] = board-&gt;cells[i_bottom];
</span><span>        in[</span><span>8</span><span>] = s_right-&gt;cells[i_bottom];
</span><span>        </span><span>// update output
</span><span>        s_out-&gt;cells[i] = </span><span>conway</span><span>(in);
</span><span>    }
</span><span>
</span><span>    </span><span>// double-buffering
</span><span>    cell* tmp_cells = board-&gt;cells;
</span><span>    board-&gt;cells = s_out-&gt;cells;
</span><span>    s_out-&gt;cells = tmp_cells;
</span><span>}
</span></code></pre>
<p>*waves* welcome to the club. mention bananas in any comment about this project for immediate +10 respect.</p>
</div>
<p>And there you have it. There’s some more code for printing that I haven’t included here. One call to <code>main</code>, and you’re off to the races! If you’d like to absorb the monstrosity in full, <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/blob/master/gate.c">here’s a link</a>.</p>
<p>(I mean, 331 lines of C, half generated. That can’t hurt anyone.)</p>
<h2 id="benchmarks">Benchmarks</h2>
<p>Benchmarking is always fraught with peril, especially for bold claims like <span>"GUYS! I found a 1,744× speedup!!"</span> so I'd like to qualify exactly what I'm measuring:</p><p>I am comparing the <em>inference speed</em> of my Python JAX (with JIT) implementation against that of my bit-parallel C implementation.</p>
<p><strong>Disclaimer,</strong> because I’m certain someone won’t read the above. You can definitely simulate <em>Conway’s Game of Life</em> with JAX a lot faster by not using a DLGN, if that’s your goal. (Indeed, I have a faster pure-JAX kernel to prepare the boards used for training!) Here, I want to compare floating-point GPU inference to bit-parallel CPU inference. And for fun, if you just want to simulate Conway’s Game of Life, you can totally shred with a faster algorithm like <em>Hashlife</em>, which I’ve <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/hashlife">half-implemented before</a>. These benchmarks, while semi-rigorous, are just for fun!</p>
<p>If you want the exact setup, there are <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic/tree/89e2ed2f2c018122132598ea610a960900079bea?tab=readme-ov-file#to-reproduce">reproduction steps</a> in the repository, with more details in the <a rel="noopener nofollow" target="_blank" href="https://github.com/slightknack/difflogic?tab=readme-ov-file#journal">journal</a>. Here’s my approach:</p>
<p>I use a board of size 512×512 cells. I find the average time per <em>step</em> in the C implementation, by running <em>step</em> on the board 100k times. I find the average time per pass in the Python JAX+JIT implementation, by predicting 512 batches of 512. Here are the results:</p>
<table><thead><tr><th>method</th><th>μs/pass (512×512)</th><th>μs/step (512×512)</th><th>fps</th><th>speedup</th></tr></thead><tbody>
<tr><td>Python</td><td>71200</td><td>—</td><td>14</td><td>1×</td></tr>
<tr><td>C</td><td>—</td><td>40.9</td><td>24,400</td><td>1,744×</td></tr>
</tbody></table>
<p>And there it is: <strong>1,744×</strong>.</p>
<blockquote>
<p><em>N.B.</em> Computing 512 batches of 512 was faster than a single batch of size 512×512 = 262,144, which would have been a more direct comparison. Take 1,744× with a grain of salt, if anything.</p>
</blockquote>
<p>I did some back-of-the-napkin math, and this seems to check out. On the JAX side, the network I’m evaluating is of size [9, 128×17, 64, 32, 16, 8, 4, 2, 1]. Each 128 matrix-vector product requires ~16k floating-point multiplications. We have 17 of them, so we’re looking at at least ~270k flop for a single cell; we have 512×512 cells to evaluate, so lower bound is 70.7 gflop. All things considered, JAX is doing a <em>very</em> good job optimizing the workload. My machine can apparently do about 4.97 tflop/s: dividing that by the estimated 70.7 gflop workload, I get 70.3 fps, and as a lower bound, is ~within an order of magnitude of the 14 fps from the benchmark.</p>
<p>The bit-parallel C implementation, on the other hand, is about <a rel="noopener nofollow" target="_blank" href="https://godbolt.org/z/e3xsYsaYE">~349 instructions long</a> (Godbolt). Each instruction processes 64 bits in parallel, which works out to about 5.45 instructions per bit. There’s quite a bit of register spilling going on, and it takes time to write to memory. Given we have 512×512 cells, it should take around 1.43 million instrs per step. A core on my machine runs at about 3.70 gcycles/s. If we assume instruction latency is 1 cycle, we should expect 2,590 fps. But we measure a number nearly 10× higher! What gives? I expect something along the lines of “insane instruction-level parallelism”, but this is something I’ll have to come back to. Regardless, this is also within an order of magnitude of the measured figure. (Now I’m really curious! I’ll have to dig into it…)</p>
<p>Well, there you have it: <strong>doing less work is indeed faster!</strong> News at 11.</p>
<h2 id="next-steps">Next steps</h2>
<p>I have lots of ideas about what to do next. Some ideas:</p>
<ul>
<li>
<p>Try learning a bigger circuit, like one for fluid simulation, using <a rel="noopener nofollow" target="_blank" href="https://michaelmoroz.github.io/Reintegration-Tracking/">reintegration tracking</a>.</p>
</li>
<li>
<p>Try optimizing further, by vectorizing with SIMD, or outputting a bit-parallel compute shader that runs on the GPU.</p>
</li>
<li>
<p>Try letting <em>you</em> mess around with the project in-browser, by exporting various circuits at different points in training, so you can get a feel for how the network learns.</p>
</li>
</ul>
<p>Well, if you made it this far, you’re one of the real ones. I hope you enjoyed the read and learned something new. I certainly did in writing this! This post isn’t finished; I’d like to add a little in-browser demo, or visualization. Perfect is the enemy of the good. I’m saying adios to this project for now as I have a week off between finishing my first year at MIT and starting an internship writing Rust in SF this summer. I’m sure there will be plenty of time to stress the heck out about optimizing things later in life! Peace out homie.</p>
<p>(Please don’t kill me for writing thousands of words about Conway’s Game of Life without a <em>single</em> picture or animation; I know, I’m working on it. Update: added a 600kb picture LOL. Animation coming soon.)</p>
<p>Thank you to Shaw, Anthony, Mike, Clara and friends for taking a look, fixing typos, and providing feedback/moral support while I worked on <em>difflogic</em>.</p>

<!-- </div> -->

        </div><p>
                Padded so you can keep scrolling. I know. I love you.
                How about we take you <a href="#top">back up to the top of this page</a>?
            </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I rewrote my Mac Electron app in Rust (553 pts)]]></title>
            <link>https://desktopdocs.com/?v=2025</link>
            <guid>44118023</guid>
            <pubDate>Wed, 28 May 2025 16:53:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://desktopdocs.com/?v=2025">https://desktopdocs.com/?v=2025</a>, See on <a href="https://news.ycombinator.com/item?id=44118023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-j7pv25f6=""> <!-- Hero Section --> <div data-astro-cid-j7pv25f6=""> <!-- Header Content --> <div data-astro-cid-j7pv25f6=""> <!-- Product badge --> <p><img src="https://cosmos-media-content.s3.us-east-1.amazonaws.com/public-content/desktop-docs/mr-desktop-docs_240.png" alt="Desktop Docs mascot" data-astro-cid-j7pv25f6=""> <span data-astro-cid-j7pv25f6="">Meet Desktop Docs: Your AI File Explorer</span> </p> <h2 data-astro-cid-j7pv25f6="">
We make it easy <br data-astro-cid-j7pv25f6=""> to
<span data-astro-cid-j7pv25f6="">work with your files</span> </h2> <p data-astro-cid-j7pv25f6="">
Desktop Docs is the all-in-one platform for advanced image and video search.
</p> <!-- CTA -->  </div> <!-- Hero Product Image --> <div data-astro-cid-j7pv25f6=""> <!-- Window chrome -->  <!-- App screenshot with adjusted height and object position --> <p><img src="https://cosmos-media-content.s3.us-east-1.amazonaws.com/public-content/desktop-docs/dd_search_street_art_cropped.webp" alt="Desktop Docs main interface showing AI-powered file organization and search capabilities" loading="eager" data-astro-cid-j7pv25f6=""> </p> </div> <!-- Benefits --> <div data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">🧠</span> </p> <h3 data-astro-cid-j7pv25f6="">AI Understanding</h3> <p data-astro-cid-j7pv25f6="">Analyzes content, not just filenames</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">🔒</span> </p> <h3 data-astro-cid-j7pv25f6="">100% Private</h3> <p data-astro-cid-j7pv25f6="">All processing happens locally</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">⚡</span> </p> <h3 data-astro-cid-j7pv25f6="">Lightning Fast</h3> <p data-astro-cid-j7pv25f6="">Results in under 0.3 seconds</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">💰</span> </p> <h3 data-astro-cid-j7pv25f6="">One-Time Payment</h3> <p data-astro-cid-j7pv25f6="">No subscription required</p> </div> </div> </div> <!-- Social Proof Section --> <div data-astro-cid-j7pv25f6=""> <!-- Header with modern styling --> <div data-astro-cid-j7pv25f6=""> <p data-astro-cid-j7pv25f6="">TRUSTED WORLDWIDE</p> <h2 data-astro-cid-j7pv25f6="">
Trusted by Professionals Worldwide
</h2> <p data-astro-cid-j7pv25f6="">
Join thousands of creators and studios who rely on Desktop Docs daily
</p> </div> <div data-astro-cid-j7pv25f6=""> <!-- Studio Card --> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Production Studios</h3> <p data-astro-cid-j7pv25f6="">Trusted by leading production houses for efficient media management</p> </div> <!-- Creators Card --> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Professional Creators</h3> <p data-astro-cid-j7pv25f6="">Empowering content creators with smart file organization</p> </div> <!-- Award Card --> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Featured App</h3> <p data-astro-cid-j7pv25f6="">Recognized in AI Tech Suite for innovation in file management</p> </div> </div> </div> <!-- Trust Badges Section -->  <!-- Social Testimonials Section --> <div data-astro-cid-j7pv25f6=""> <p> Testimonials </p> <p> <h2 data-astro-cid-j7pv25f6="">
What Our Users Say
</h2>  </p> <div> <p data-astro-cid-j7pv25f6="">
Hear from professionals who use Desktop Docs every day
</p>  </div> </div> <!-- Product Showcase Section --> <div data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <p> Browsing Benefits </p> <p> <h2 data-astro-cid-j7pv25f6="">
Do less admin work
</h2>  </p> <div> <p data-astro-cid-j7pv25f6="">
Let AI do the boring work of finding files for you
</p>  </div> </div> <!-- Main Product Demo --> <div data-astro-cid-j7pv25f6=""> <!-- Window chrome -->  <!-- App screenshot container --> <p><img src="https://cosmos-media-content.s3.us-east-1.amazonaws.com/public-content/desktop-docs/dd_image_search_couple_273.webp" alt="Desktop Docs color search interface showing AI-powered palette matching" loading="eager" data-astro-cid-j7pv25f6=""> </p> </div> <!-- Feature Grid with Product Focus --> <div data-astro-cid-j7pv25f6=""> <!-- AI Search Feature --> <div data-astro-cid-j7pv25f6="">  <h3 data-astro-cid-j7pv25f6="">Find Files 10x Faster</h3> <p data-astro-cid-j7pv25f6="">
Desktop Docs analyzes your images and videos' actual content, not just filenames. Search for "sunset photos" or "videos with dogs" and get instant results.
</p> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Natural language queries</span> </p> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Content-based matching</span> </p> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Instant results</span> </p> </div> </div> <!-- Visual Search Feature --> <div data-astro-cid-j7pv25f6="">  <h3 data-astro-cid-j7pv25f6="">Image Similarity Search</h3> <p data-astro-cid-j7pv25f6="">
Upload a reference image and instantly find matching content across your entire library. Perfect for finding variations, duplicates, or related images.
</p> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Advanced visual matching</span> </p> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Duplicate detection</span> </p> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Cross-format support</span> </p> </div> </div> <!-- Privacy Feature --> <div data-astro-cid-j7pv25f6="">  <h3 data-astro-cid-j7pv25f6="">Your Files Stay on Your Mac</h3> <p data-astro-cid-j7pv25f6="">
No cloud uploads needed. Search right where your files already are, with AI sprinkled on top.
</p> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">100% local processing</span> </p> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">No cloud uploads</span> </p> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Your data stays yours</span> </p> </div> </div> </div> </div> <!-- Value Proposition Section --> <section data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">⚡</span> <span data-astro-cid-j7pv25f6="">Stop wasting time. Start getting organized.</span> </p> </div> <div data-astro-cid-j7pv25f6=""> <!-- Key Features Highlight --> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">
Find What You Need, When You Need It
</h3> <p data-astro-cid-j7pv25f6="">
Smart search that understands your files, not just their names
</p> </div> <!-- Color Search Product Demo -->  <div data-astro-cid-j7pv25f6=""> <!-- Feature 1 --> <div data-astro-cid-j7pv25f6="">  <h4 data-astro-cid-j7pv25f6="">Index Everything</h4> <p data-astro-cid-j7pv25f6="">Index unlimited files and never lose track of important documents again.</p> </div> <!-- Feature 2 --> <div data-astro-cid-j7pv25f6="">  <h4 data-astro-cid-j7pv25f6="">Smart Search</h4> <p data-astro-cid-j7pv25f6="">Find media files by their content, not just names.</p> </div> <!-- Feature 3 --> <div data-astro-cid-j7pv25f6="">  <h4 data-astro-cid-j7pv25f6="">Quick Edits</h4> <p data-astro-cid-j7pv25f6="">Make changes on the fly without opening heavy applications.</p> </div> <!-- Feature 4 --> <div data-astro-cid-j7pv25f6="">  <h4 data-astro-cid-j7pv25f6="">Get Organized</h4> <p data-astro-cid-j7pv25f6="">Transform chaos into clarity with a structured knowledge base.</p> </div> </div> </div> </section> <!-- CTA (2) Section --> <div data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">Feel Inspired</h2> <p data-astro-cid-j7pv25f6="">
Join thousands of professionals who've transformed their digital chaos into organized creativity with Desktop Docs.
</p> <!-- Product Showcase -->   </div> <!-- Support Formats Section --> <div data-astro-cid-j7pv25f6=""> <p> File Compatibility </p> <p> <h2 data-astro-cid-j7pv25f6="">
Works with All Your Files
</h2>  </p> <div> <p data-astro-cid-j7pv25f6="">
Desktop Docs supports all major image and video formats, so you can organize everything in one place.
</p>  </div> </div> <!-- FAQ Section --> <div data-astro-cid-j7pv25f6=""> <p> FAQ </p> <p> <h2 data-astro-cid-j7pv25f6="">
Frequently Asked Questions
</h2>  </p> <div> <p data-astro-cid-j7pv25f6="">
Everything you need to know about Desktop Docs
</p>  </div> </div> <!-- Newsletter Section --> <div data-astro-cid-j7pv25f6=""> <p> Stay Connected </p> <p> <h2 data-astro-cid-j7pv25f6="">
Get the Latest Updates
</h2>  </p> <div> <p data-astro-cid-j7pv25f6="">
Subscribe for tips, updates, and insights to maximize your productivity with Desktop Docs.
</p>  </div> </div> <!-- CTA (3) Section --> <div data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">Ready to get organized?</h2> <p data-astro-cid-j7pv25f6="">
Turn creative chaos into beautiful organization - join the Desktop Docs community.
</p>  </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan Post launches 'digital address' system (367 pts)]]></title>
            <link>https://www.japantimes.co.jp/business/2025/05/27/companies/japan-post-digital-address/</link>
            <guid>44117779</guid>
            <pubDate>Wed, 28 May 2025 16:33:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.japantimes.co.jp/business/2025/05/27/companies/japan-post-digital-address/">https://www.japantimes.co.jp/business/2025/05/27/companies/japan-post-digital-address/</a>, See on <a href="https://news.ycombinator.com/item?id=44117779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                      <p>Japan Post said Monday that it has launched a "digital address" system that links seven-digit combinations of numbers and letters to physical addresses.</p>

<p>Under the system, users can input these seven-digit codes on online shopping websites, and their addresses will automatically appear on the sites.</p>

<p>People can obtain digital addresses by registering with Japan Post's Yu ID membership service. Their digital addresses will not change even if their physical addresses change. Their new addresses will be linked to the codes if they submit notices of address changes.</p>

<p>With Japan Post opening up a system for obtaining address information using the codes, e-commerce giant Rakuten and others are considering adopting it.</p>

<p>Japan Post plans to spend about a decade to promote broad adoption of the new system.</p>
                    

                                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compiler Explorer and the promise of URLs that last forever (316 pts)]]></title>
            <link>https://xania.org/202505/compiler-explorer-urls-forever</link>
            <guid>44117722</guid>
            <pubDate>Wed, 28 May 2025 16:28:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xania.org/202505/compiler-explorer-urls-forever">https://xania.org/202505/compiler-explorer-urls-forever</a>, See on <a href="https://news.ycombinator.com/item?id=44117722">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        <p>The history is this: back in the old days (2012), we used to store the entire <a href="https://godbolt.org/">Compiler Explorer</a> state in the URL. That got unwieldy (who would have thought encoding an entire compiler state in a URL might get a bit long?), so we added support for Google’s link shortener <a href="https://goo.gl/">goo.gl</a> in March 2014. That meant short links were of the form <code>goo.gl/abc123</code>. Clicking a goo.gl link would eventually redirect you to the full URL link on our site, and we’d decode the state from the URL.</p>
<p>In 2016, <a href="https://stackoverflow.com/">Stack Overflow</a> banned link shorteners because of how they cloak the actual destination of links. Abusers could post innocent goo.gl links that directed folks unwittingly to bad content. However, that meant our Compiler Explorer links were also affected. At the time, we had no intention of storing any user data, so we came up with a hack: we still used goo.gl, but we then rewrote the link we handed out to be <code>godbolt.org/g/abc123</code> (where the abc123 is the goo.gl unique ID). We then redirected any hits to <code>/g/abc123</code> to <code>goo.gl/abc123</code>, which then (finally) redirected back to godbolt.org with the appropriate state in the URL. If you’re keeping track, that’s three redirects to show you some assembly code. We were really committed to making things complicated. Later, we used Google’s API to avoid the redirection dance.</p>
<p>By 2018, the limitations of storing state in the URL started to bite. There’s a limit to how long a URL can be (and we’d already started compressing the data in the URL), so we needed a better solution. We finally implemented our own storage solution: we hash the input, save the state as a JSON document on <a href="https://aws.amazon.com/s3/">S3</a> under the hash, and then give out a shortened form of the hash as a <code>godbolt.org/z/hashbit</code> URL. We use <a href="https://aws.amazon.com/dynamodb/">DynamoDB</a> to store the mapping of shortened hashes to the full paths (accounting for partial collisions, etc.). And, amusingly, we check the short link’s hash for rude words and add deliberate extra information into the document until we no longer get a rude word. Yes, we literally check if your shortened URL contains profanity. Because apparently even random hashes can’t be trusted to keep it clean. This led to <a href="https://github.com/compiler-explorer/compiler-explorer/issues/1297">bug #1297</a>, which remains one of my favourite issues we’ve ever had to fix.</p>
<p>We still support the <code>godbolt.org/g/abc123</code> links, but… despite Google <a href="https://developers.googleblog.com/en/transitioning-google-url-shortener-to-firebase-dynamic-links/">solemnly promising</a> that “all existing links will continue to redirect to the intended destination,” it went read-only a few years back, and now they’re <a href="https://developers.googleblog.com/en/google-url-shortener-links-will-no-longer-be-available/">finally sunsetting it</a> in August 2025. Here I was in 2014, thinking I was so clever using Google’s shortener. “It’ll be around forever!” I said. “Google never discontinues products!” I said. Er…</p>
<p>That means we’ll no longer be able to resolve goo.gl-based links! Which is, to use technical terminology, a bit pants. One of my founding principles is that Compiler Explorer links should last forever. I can’t do anything about the <em>really</em> legacy actual <code>goo.gl</code> links, but I can do something about the <code>godbolt.org/g/abc123</code> links!</p>
<p>Over the last few days, I’ve been scraping everywhere I can think of, collating the links I can find out in the wild, and compiling my own database of links<sup id="fnref:2"><a href="#fn:2">1</a></sup> – and importantly, the URLs they redirect to. So far, I’ve found 12,000 links from scraping:</p>
<ul>
<li><a href="https://developers.google.com/custom-search">Google</a> (using their web search API)</li>
<li><a href="https://docs.github.com/en/rest">GitHub</a> (using their API)</li>
<li>Our own (somewhat limited) web logs</li>
<li>The <a href="https://archive.org/">archive.org</a> Stack Overflow data dumps</li>
<li>Archive.org’s own list of archived webpages</li>
</ul>
<p>
<img src="https://xania.org/202505/sqlite.png" width="600" height="128" alt="SQLite terminal showing query result: SELECT COUNT(*) from google_links; returning 12298 rescued links">
<br>12,298 rescued links and counting - not bad for a few days of digital archaeology
</p>

<p>We’re now <a href="https://github.com/compiler-explorer/compiler-explorer/pull/7724">using the database in preference</a> to <code>goo.gl</code> internally, so I’m also keeping an eye on new “g” links that we don’t yet have.</p>
<p>Thanks to <a href="https://stackoverflow.com/users/224132/peter-cordes">Peter Cordes</a> for reminding us about this issue and <a href="https://github.com/compiler-explorer/compiler-explorer/discussions/7719">bringing it to our attention</a><sup id="fnref:1"><a href="#fn:1">2</a></sup>.</p>
<p>If you have a secret cache of godbolt.org/g/abc123 links you have lying around, now’s the time to visit each of them! That will ensure they’re in my web logs and I’ll add them to the database. Otherwise, sadly, in August 2025 those links will stop working, joining the great digital graveyard alongside Flash games and GeoCities pages.</p>
<h2>The Bigger Picture</h2>
<p>This whole saga reinforces why I’m skeptical of relying on third-party services for critical infrastructure. Google’s URL shortener was supposed to be permanent. The redirect chains we built were clever workarounds that bought us time, but ultimately, the only way to truly keep a promise of “URLs that last forever” is to own the entire stack.</p>
<p>It’s been a fascinating archaeological dig through the internet, hunting down these legacy links like some sort of digital Indiana Jones, except instead of ancient artifacts I’m rescuing compiler flags and optimization examples. Each one represents someone’s attempt to share knowledge, ask a question, or demonstrate a concept. Preserving them feels like preserving a small piece of programming history.</p>
<p>So if you’ve got old Compiler Explorer links bookmarked somewhere, dust them off and give them a click. You’ll be helping preserve a little corner of the internet’s shared knowledge – and keeping a promise I made back in 2012. And hey, at least this time I’m in control of the infrastructure. What could possibly go wrong?</p>
<hr>
<h3>Disclaimer</h3>
<p>This article was written by a human, but links were suggested by and grammar checked by an LLM.</p>

    </div><div>
                
                
                <p>Posted at 10:12:00 CDT on 28<sup>th</sup> May 2025.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting a Cease and Desist from Waffle House (329 pts)]]></title>
            <link>https://www.jack.bio/blog/wafflehouse</link>
            <guid>44117302</guid>
            <pubDate>Wed, 28 May 2025 15:48:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jack.bio/blog/wafflehouse">https://www.jack.bio/blog/wafflehouse</a>, See on <a href="https://news.ycombinator.com/item?id=44117302">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>Editor's Note:</span> <!-- -->This post is written in good faith and with a spirit of humor and admiration. It recounts events between myself, Waffle House, its legal and marketing teams, and affiliated parties. Nothing here is meant with malice, and it was a pleasure corresponding with a breakfast chain I'm quite fond of.</p><article><p>In late September of 2024, Hurricane Helene was spiraling towards Florida, my home state. My university had cancelled classes for the week, and while people were barricading their homes, I was spending time reverse-engineering Waffle House’s website.</p>
<p>Why, you may ask? If you’ve never heard of the Waffle House Index, you’re in for a bit of weirdly fascinating disaster response lore. The Waffle House Index is an (incredibly) unofficial tool used by FEMA to gauge the severity of natural disasters. Why Waffle House? Because they’re infamous for not closing even during the worst of storms. If the House is closed, that means things are getting real.</p>
<p>The problem with the Waffle House Index is that there’s not really an actual “index” you can check. No live feed, no map, and certainly no counter of closed restaurants — just a few wisps of a mention on Wikipedia pages and articles throughout the web (<a href="https://www.wafflehouse.com/how-to-measure-a-storms-fury-one-breakfast-at-a-time/">including one blog post on their actual website!</a>).</p>
<p>...so, naturally, I built one.</p>
<p>I already dove into the technical side of things in a YouTube video I published, which I’ll link below, but here’s the technical gist of how the site worked.</p>
<h2>The Technicals</h2>
<p>Waffle House uses Next.js for their site (or at least, their location information site). Incredibly based choice, by the way. This meant that they also utilized React Server Components, which made it hard to scrape or find any single source of truth for data about the websites.</p>
<p>React Server Components run on the server, and unlike client-side components, they don’t return raw HTML you can easily inspect in Dev Tools. That means you’ll need to get a bit creative to see how data is being fetched.</p>
<p>After spending more time than I’d like to admit digging through their source code, I ended up finding a Next.js file that had a JSON body of the data injected into the client after being executed on the server. This file had information about every single open location, their status (if they were busy or not), and more importantly, <strong>if they were closed</strong>.</p>
<p>Using some light data scraping and processing with Python, along with a Next.js frontend and Redis implementation for caching, I was able to make a live map that tracked which Waffle Houses were closed, and by extension, which parts of the country might be going south.</p>
<p>If you're curious about how I ended up finding the file and the technical implications of the site, watch the YouTube video below:</p>
<p><iframe src="https://www.youtube.com/embed/TBrR3AEutsI?si=k9J_72704VCVnwRq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<h2>The Beginning of the End</h2>
<p>After I created the site, I snapped up wafflehouseindex[.]org, threw it up on Vercel, and sent out a tweet about it.</p>
<p>At the time, my account had fewer than 200 followers. I genuinely didn’t expect anyone at the company to see the tweet, let alone for it to blow up.</p>
<p>But then they <em>did</em> see it. And suddenly, the corporate account was replying, saying that the information was incorrect and reminding everyone that information about closures would come from their official communication channels.</p>
<p><img src="https://www.jack.bio/images/whstress.png" alt="F"></p>
<p>Which — first of all — I can understand. But I was quite literally USING their data for this, so it wasn’t really incorrect at all. Either way, seeing as the entire situation was making me laugh, I quote-tweeted their response and jokingly said, “haha, now you do!”, not really thinking much of it. Who would think the mega-chain breakfast place would be spending time replying to a teenager online talking about if their stores were closed?</p>
<p>That was the case, until Frank Luntz (American political commentator commonly seen on CNBC, Bloomberg, who also has a 400,000+ follower count on Twitter) somehow saw my tweet and took interest in the site.</p>
<h3>Mom, get the cameras!</h3>
<p>At that point, I started sweating a little. Obviously being recognized for your work online is very cool, but it’s another thing entirely to be casually chatting with a major media figure about a random half-joke, half-engineering marvel I’d made.</p>
<p><img src="https://www.jack.bio/images/whfrank.png" alt="F"></p>
<p>Frank decided to share the site with a tweet directly linking to it. Within minutes, I had a few hundred people browsing the site, poking and prodding at the index and checking out the map.</p>
<p>Unfortunately, the devil works hard, but Waffle House’s marketing (and at this point, probably legal) team works harder. They swiftly replied to Frank’s tweet, echoing what they’d said to me: - the site was unofficial and incorrect, and that any closure info would come from an official Waffle House account. Frank, wanting to maintain credibility, quickly apologized and deleted the tweet.</p>
<p>I figured that would be the end of it until I went to look back at what they said.</p>
<p>Their tweet was gone.</p>
<p>What?</p>
<p>And then I clicked their profile.</p>
<p><img src="https://www.jack.bio/images/waffleblocked.png" alt="Waffle House emailing me"></p>
<h3>Kicked (and scolded) out the House</h3>
<p>In a million years did I not expect that one coming. Two responses to their tweets about an “unofficial” website and I get blocked?</p>
<p>In hindsight, I can imagine that my actions probably stressed some poor marketing person out and they needed to do damage control somehow. Regardless, it’s incredibly funny that I got <em>blocked</em> by the breakfast chain.</p>
<p>Shortly after getting blocked (and after the hurricane had passed), I woke up to an email from someone with a Very High Up Position at Waffle House informing me that I needed to immediately “cease and desist all unauthorized use of Trademarks owned by WH Intellectual, LLC and any confusingly similar marks in connection with your website.”</p>
<p><img src="https://www.jack.bio/images/whemail.png" alt="Waffle House emailing me"></p>
<p>Honestly, I was more surprised that the silly logo I made (a very great representation, if I do say so myself) was what got me in trouble, and less so the scraping or reverse-engineering part.</p>
<p>You may be asking yourself: <em>How did I reply?</em></p>
<p>Great question.</p>
<h3>With Respect and Syrup</h3>
<p>I gave my response the same treatment as I did the rest of this entire process: complete silliness.</p>
<p><img src="https://www.jack.bio/images/whemailreply.png" alt="Me replying to Waffle House"></p>
<ul>
<li>“huge fan of the House”</li>
<li>"Waffle House has become much like the American Flag in the Star Spangled Banner"</li>
<li>“honor and respect Waffle House with this data”</li>
<li>and finally, “with respect and syrup”.</li>
</ul>
<p>The Very High Up Person actually did reply to this with much less legal jargon than the first email and was very down to earth with me, even thanking me for wanting to help out with the recovery efforts. But at the end of the day, I was still violating their trademarks and needed to take it down.</p>
<p>I did take it down and even emailed back asking if there was anything I could do to keep the site running officially under the same branding I had created, but unfortunately got ghosted after that.</p>
<h2>The End of the End</h2>
<p>One of my favorite parts of programming is the ability to simply build things just for the fun of it, and this project was nothing short of exactly that. While I do wish I could have kept it up for longer than a few weeks, being able to use data that seems meaningless on the surface to build something bigger is always such an adventure.</p>
<p>Thanks again to Waffle House for being good sports in the end, even after I may have violated their trademarks…and stole their data along the way :)</p>
<i><small><p>Thanks to Moo, Kai, and the Babgel GC for proofreading &amp; editing. &lt;3</p></small></i></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tesseral – Open-Source Auth (177 pts)]]></title>
            <link>https://github.com/tesseral-labs/tesseral</link>
            <guid>44117059</guid>
            <pubDate>Wed, 28 May 2025 15:27:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tesseral-labs/tesseral">https://github.com/tesseral-labs/tesseral</a>, See on <a href="https://news.ycombinator.com/item?id=44117059">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/splash.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/splash.png" alt=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tesseral</h2><a id="user-content-tesseral" aria-label="Permalink: Tesseral" href="#tesseral"></a></p>
<p dir="auto">Tesseral is <strong>open source auth infrastructure for business software</strong> (i.e., B2B
SaaS).</p>
<p dir="auto">Tesseral is a multi-tenant, API-first service designed to run on the cloud. It
is not an authentication library tied to a particular language or framework;
Tesseral works with any tech stack.</p>
<p dir="auto">Most developers should start by using Tesseral's managed service, available at
<a href="https://console.tesseral.com/" rel="nofollow">console.tesseral.com</a>. You can also <a href="https://tesseral.com/docs/features/self-hosting-tesseral" rel="nofollow">self-host
Tesseral</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<p dir="auto">Tesseral bundles everything that a developer needs to manage users in business software.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><a target="_blank" rel="noopener noreferrer" href=""></a></th>
<th><a target="_blank" rel="noopener noreferrer" href=""></a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://tesseral.com/docs/features/customizing-your-login-experience" rel="nofollow"><strong>Hosted, customizable login pages</strong></a><p>Prebuilt UIs, customizable to your brand. Add and remove login methods with just a few clicks in the Tesseral Console.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/hosted_custom_login_pages.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/hosted_custom_login_pages.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/b2b-multitenancy" rel="nofollow"><strong>B2B multitenancy</strong></a><p>Tesseral is built for B2B SaaS. Your customer's admins control how their users log in to their tenant, and can add or remove users at will.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/b2b_multitenancy.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/b2b_multitenancy.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/user-impersonation" rel="nofollow"><strong>User impersonation</strong></a><p>See exactly what your users see. Debug and support faster by logging in as your users.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/impersonate.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/impersonate.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/self-serve-organization-settings" rel="nofollow"><strong>Self-service config for your customers</strong></a><p>Pre-built settings pages where your customers can invite coworkers, edit their login settings, and everything else they need.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/self_serve.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/self_serve.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/login-methods/primary-factors/log-in-with-email-magic-links" rel="nofollow"><strong>Magic Links</strong></a><p>Add "Log in with Email" support using magic links, without writing any code.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/magic_links.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/magic_links.png"></a></td></tr><tr></tr>

<tr>
<td><strong>Social Login</strong><p>Add <a href="https://tesseral.com/docs/login-methods/primary-factors/log-in-with-google" rel="nofollow">Log in with Google</a>, <a href="https://tesseral.com/docs/login-methods/primary-factors/log-in-with-github" rel="nofollow">Log in with GitHub</a>, and <a href="https://tesseral.com/docs/login-methods/primary-factors/log-in-with-microsoft" rel="nofollow">Log in with Microsoft</a> support without writing any code.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/social_login.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/social_login.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/saml-sso" rel="nofollow"><strong>SAML (Enterprise Single Sign-On)</strong></a><p>Add SAML support to your product without writing any code.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/saml.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/saml.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/scim-provisioning" rel="nofollow"><strong>SCIM (Enterprise Directory Sync)</strong></a><p>Add SCIM support to your product without writing any code.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/scim.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/scim.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/role-based-access-control" rel="nofollow"><strong>Role-based access control (RBAC)</strong></a><p>Add fine-grained permissions to your product. The UI's done for you, just plug in <code>hasPermission</code> calls wherever you need them.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/rbac.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/rbac.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/multifactor-authentication-mfa" rel="nofollow"><strong>Multi-factor authentication (MFA)</strong></a><p>Add 2FA to your product without writing any code. Your customers can choose to require MFA for their users if they wish.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/mfa.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/mfa.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/login-methods/secondary-factors/login-with-passkey" rel="nofollow"><strong>Passkeys / WebAuthn</strong></a><p>Add "Log in with Passkey" support to your product without writing any code. Supports all passkey platforms, including Touch ID, Yubikeys, and more.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/passkeys.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/passkeys.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/login-methods/secondary-factors/login-with-authenticator-app" rel="nofollow"><strong>Authenticator apps (TOTPs)</strong></a><p>Add time-based one-time-password (TOTP) support to your product without writing any code.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/totp.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/totp.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/managed-api-keys" rel="nofollow"><strong>API key management</strong></a><p>Not just user authentication. If you want your customers to call your endpoints automatically, give them API keys. UIs, permissions, and authentication checks all come pre-built.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/api_keys.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/api_keys.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/concepts/user-invites" rel="nofollow"><strong>User invitations</strong></a><p>Your users can invite their coworkers, or you can invite them yourself from the Tesseral Console.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/invites.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/invites.png"></a></td></tr><tr></tr>

<tr>
<td><a href="https://tesseral.com/docs/features/webhooks" rel="nofollow"><strong>Webhooks</strong></a><p>Live-sync data from Tesseral into your database with realtime webhook delivery.</p></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/tesseral-labs/tesseral/blob/main/.github/img/webhooks.png"><img src="https://github.com/tesseral-labs/tesseral/raw/main/.github/img/webhooks.png"></a></td></tr><tr></tr>

</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Read the documentation</h3><a id="user-content-read-the-documentation" aria-label="Permalink: Read the documentation" href="#read-the-documentation"></a></p>
<p dir="auto">We encourage all developers to read the full documentation first, which is
available at tesseral.com/docs. This README provides only a very brief subset of
the docs to illustrate some basic ideas.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SDKs</h3><a id="user-content-sdks" aria-label="Permalink: SDKs" href="#sdks"></a></p>
<p dir="auto">Tesseral currently offers several SDKs for common web development frameworks.</p>
<ul dir="auto">
<li>Clientside SDKs
<ul dir="auto">
<li><a href="https://tesseral.com/docs/sdks/clientside-sdks/tesseral-sdk-react" rel="nofollow">React</a></li>
</ul>
</li>
<li>Serverside SDKs
<ul dir="auto">
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-express" rel="nofollow">Express</a></li>
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask" rel="nofollow">Flask</a></li>
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-go" rel="nofollow">Golang</a></li>
</ul>
</li>
</ul>
<p dir="auto">More SDKs, in particular Next.js, are in active development. If you do not see
your preferred framework listed here, please get in touch with
<a href="mailto:support@tesseral.com">support@tesseral.com</a>; we may be able to give you early access.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sign up</h3><a id="user-content-sign-up" aria-label="Permalink: Sign up" href="#sign-up"></a></p>
<p dir="auto">For Tesseral’s managed service, you will first need to create an account at
<a href="https://console.tesseral.com/" rel="nofollow">https://console.tesseral.com</a>.</p>
<p dir="auto">You will need to create a Project and generate a Publishable Key. Publishable
Keys always look like this: <code>publishable_key_...</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Integrate your frontend</h3><a id="user-content-integrate-your-frontend" aria-label="Permalink: Integrate your frontend" href="#integrate-your-frontend"></a></p>
<p dir="auto">To integrate Tesseral into your app, you'll first need to integrate your
frontend. This example uses the <a href="https://tesseral.com/docs/sdks/clientside-sdks/tesseral-sdk-react" rel="nofollow">Tesseral React
SDK</a>.</p>
<p dir="auto">Install the SDK like this:</p>
<div data-snippet-clipboard-copy-content="npm install @tesseral/tesseral-react"><pre><code>npm install @tesseral/tesseral-react
</code></pre></div>
<p dir="auto">Then, using your Publishable Key (starts with <code>publishable_key_...</code>), wrap your
React app in the <code>&lt;TesseralProvider&gt;</code> component:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { createRoot } from &quot;react-dom/client&quot;
import { TesseralProvider } from &quot;@tesseral/tesseral-react&quot;;
import App from &quot;./App.tsx&quot;

const root = createRoot(document.getElementById(&quot;root&quot;)) 
root.render(
  // use your Project's Publishable Key here
  <TesseralProvider publishableKey=&quot;publishable_key_...&quot;>
    <App />
  </TesseralProvider>
)"><pre><span>import</span> <span>{</span> <span>createRoot</span> <span>}</span> <span>from</span> <span>"react-dom/client"</span>
<span>import</span> <span>{</span> <span>TesseralProvider</span> <span>}</span> <span>from</span> <span>"@tesseral/tesseral-react"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App.tsx"</span>

<span>const</span> <span>root</span> <span>=</span> <span>createRoot</span><span>(</span><span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span><span>)</span> 
<span>root</span><span>.</span><span>render</span><span>(</span>
  <span>// use your Project's Publishable Key here</span>
  <span>&lt;</span><span>TesseralProvider</span> <span>publishableKey</span><span>=</span><span>"publishable_key_..."</span><span>&gt;</span>
    <span>&lt;</span><span>App</span> <span>/&gt;</span>
  <span>&lt;/</span><span>TesseralProvider</span><span>&gt;</span>
<span>)</span></pre></div>
<p dir="auto">The <code>&lt;TesseralProvider&gt;</code> will handle a variety of auth-related tasks for you,
including:</p>
<ul dir="auto">
<li>Redirecting unauthenticated users to the login page ("login gating")</li>
<li>Refreshing users' access tokens in the background when they're close to
expiring</li>
<li>Automatically including access tokens in requests from your frontend
to your backend</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Integrate your backend</h3><a id="user-content-integrate-your-backend" aria-label="Permalink: Integrate your backend" href="#integrate-your-backend"></a></p>
<p dir="auto">Once you have your frontend integrated with Tesseral, you'll then need to
integrate your backend.</p>
<p dir="auto">Tesseral works with any backend or framework. SDKs are available for the
following:</p>
<ul dir="auto">
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-express" rel="nofollow">Express</a></li>
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask" rel="nofollow">Flask</a></li>
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-go" rel="nofollow">Golang</a></li>
</ul>
<p dir="auto">Your app might look something like this example, using the <a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask" rel="nofollow">Flask
SDK</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from flask import Flask
from tesseral_flask import access_token_claims, require_auth


app = Flask(__name__)

# use the same Publishable Key you used for your frontend
app.before_request(require_auth(publishable_key=&quot;publishable_key_...&quot;))


@app.route(&quot;/api/hello&quot;, methods=[&quot;GET&quot;])
def hello():
    # get the user's email from the current request
    # Tesseral ensures that user emails are always verified
    email = access_token_claims().user.email
    return (&quot;hello, &quot; + email)


if __name__ == &quot;__main__&quot;:
    app.run(debug=True, port=5050)"><pre><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>from</span> <span>tesseral_flask</span> <span>import</span> <span>access_token_claims</span>, <span>require_auth</span>


<span>app</span> <span>=</span> <span>Flask</span>(<span>__name__</span>)

<span># use the same Publishable Key you used for your frontend</span>
<span>app</span>.<span>before_request</span>(<span>require_auth</span>(<span>publishable_key</span><span>=</span><span>"publishable_key_..."</span>))


<span>@<span>app</span>.<span>route</span>(<span>"/api/hello"</span>, <span>methods</span><span>=</span>[<span>"GET"</span>])</span>
<span>def</span> <span>hello</span>():
    <span># get the user's email from the current request</span>
    <span># Tesseral ensures that user emails are always verified</span>
    <span>email</span> <span>=</span> <span>access_token_claims</span>().<span>user</span>.<span>email</span>
    <span>return</span> (<span>"hello, "</span> <span>+</span> <span>email</span>)


<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>app</span>.<span>run</span>(<span>debug</span><span>=</span><span>True</span>, <span>port</span><span>=</span><span>5050</span>)</pre></div>
<p dir="auto">Tesseral's
<a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask#getting-started" rel="nofollow"><code>require_auth()</code></a>
middleware (or its equivalent in your framework's SDK) validates access tokens
for you, and only authenticated requests will go through to your endpoint
handlers. A client can successfully <code>GET /api/hello</code> if and only if it has a
valid Tesseral access token.</p>
<p dir="auto">You can extract out details about the requester using:</p>
<ul dir="auto">
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask#getting-the-current-organization" rel="nofollow"><code>organization_id()</code></a></li>
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask#getting-the-requests-authenticated-credentials" rel="nofollow"><code>credentials()</code></a></li>
<li><a href="https://tesseral.com/docs/sdks/serverside-sdks/tesseral-sdk-flask#getting-details-about-the-current-user" rel="nofollow"><code>access_token_claims()</code></a></li>
<li><a href="https://tesseral.com/docs/features/role-based-access-control#permission-checks" rel="nofollow"><code>has_permission()</code></a></li>
</ul>
<p dir="auto">Or their equivalent in your framework's SDK.</p>
<p dir="auto">Once you have your backend integrated, you have implemented Tesseral!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/tesseral-labs/tesseral/blob/main/LICENSE">MIT</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome outside contributions!</p>
<p dir="auto">Please be aware, however, that auth software is complex and extremely delicate.
We are very cautious with the changes that we merge. We recommend you first open
a GitHub issue outlining any proposed changes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">Please immediately report any potential vulnerabilities to
<a href="mailto:security@tesseral.com">security@tesseral.com</a>. We will get back to you over email.</p>
<p dir="auto">Please do not open GitHub issues for any security-related concerns.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">We love enterprise software and the people building it.</p>
<p dir="auto">Please join our community and stay up to date on new releases, events, and other
Tesseral news by following us on
<a href="https://www.linkedin.com/company/tesseral" rel="nofollow">LinkedIn</a> and on <a href="https://x.com/tesseralhq" rel="nofollow">X
(Twitter)</a>. You can also check out our
<a href="https://newsletter.tesseral.com/" rel="nofollow">newsletter</a> and our
<a href="https://tesseral.com/blog" rel="nofollow">blog</a>.</p>
<p dir="auto">You should also feel welcome to get in touch at <a href="mailto:founders@tesseral.com">founders@tesseral.com</a> with
questions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Who we are</h2><a id="user-content-who-we-are" aria-label="Permalink: Who we are" href="#who-we-are"></a></p>
<p dir="auto">This is commercial open source software managed by Tesseral, a startup based in
San Francisco. We previously built
<a href="https://github.com/ssoready/ssoready">SSOReady</a>, an open source middleware for
SAML SSO and SCIM provisioning.</p>
<p dir="auto">Primary technical responsibility for Tesseral belongs to <a href="https://ucarion.com/" rel="nofollow">Ulysse
Carion</a>, cofounder and CTO at Tesseral, and to Tesseral's
technical staff: <a href="https://github.com/blakeofwilliam">Blake Williams</a> and <a href="https://github.com/dnys1">Dillon
Nys</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM codegen go brrr – Parallelization with Git worktrees and tmux (147 pts)]]></title>
            <link>https://www.skeptrune.com/posts/git-worktrees-agents-and-tmux/</link>
            <guid>44116872</guid>
            <pubDate>Wed, 28 May 2025 15:13:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.skeptrune.com/posts/git-worktrees-agents-and-tmux/">https://www.skeptrune.com/posts/git-worktrees-agents-and-tmux/</a>, See on <a href="https://news.ycombinator.com/item?id=44116872">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-g44mhg6z="">  <article> <p> May 26, 2025 , Nicholas Khami </p>   <p> <h6> If you're underwhelmed with AI coding agents or simply want to get more out of them, give parallelization a try. After seeing the results firsthand over the past month, I'm ready to call myself an evangelist. The throughput improvements are incredible, and I don't feel like I'm losing control of the codebase. </h6> </p>  <p>This realization isn’t unique to me; the effectiveness of using Git worktrees for simultaneous execution is gaining broader recognition, as evidenced by mentions in <a href="https://docs.anthropic.com/en/docs/claude-code/tutorials#run-parallel-claude-code-sessions-with-git-worktrees">Claude Code’s docs</a>, <a href="https://news.ycombinator.com/item?id=44043717">discussion on Hacker News</a>, projects like <a href="https://github.com/smtg-ai/claude-squad">Claude Squad</a>, and conversation on <a href="https://x.com/search?q=git%20worktree&amp;src=typed_query&amp;f=live">X</a>.</p>
<br>
<div>  <p>
I had to vibe code <i>something</i> for this post haha. Use mouse or touch to
    rotate and zoom. Click "Reset View" to return to the initial angle.
</p> </div> 
<h3 id="example-use-case-adding-a-ui-component">Example use-case: adding a UI component</h3>
<p>I’m building a component library called <a href="https://astrobits.dev/">astrobits</a> and wanted to add a <code>Toggle</code>. To tackle the task, I deployed two <a href="https://www.anthropic.com/claude-code">Claude Code</a> agents and two <a href="https://openai.com/index/introducing-codex/">Codex</a> agents, all with the same prompt, running in parallel within their own <a href="https://git-scm.com/docs/git-worktrees">git worktrees</a>. Worktrees are essential because they provide each agent with an isolated directory, allowing them to execute simultaneously without overwriting each other’s changes.</p>
<p>The number of agents I choose to rollout depends on the complexity of the task. Over time, you’ll develop an intuition for estimating the right number based on the situation. Here, I felt 4 was appropriate.</p>
<br>
<div data-astro-cid-xaorfurn=""> <div data-astro-cid-xaorfurn=""> <p><img src="https://www.skeptrune.com/_astro/4320-attempt.s98T-aCF_ZLWpD1.webp" alt="Worktree example run toggle image" data-astro-cid-xaorfurn="true" width="365" height="365" loading="lazy" decoding="async"></p><p data-astro-cid-xaorfurn=""><code>claude-1</code>. Mostly <b>correct</b>, workable, but pixelated border-image and shadow needs fixing.</p> </div><div data-astro-cid-xaorfurn=""> <p><img src="https://www.skeptrune.com/_astro/4321-attempt.BHAntrrQ_Z25wuP0.webp" alt="Worktree example run toggle image" data-astro-cid-xaorfurn="true" width="365" height="365" loading="lazy" decoding="async"></p><p data-astro-cid-xaorfurn=""><code>claude-2</code>. Completely <b>broken</b>, sliding circle too small, wrong color.</p> </div><div data-astro-cid-xaorfurn=""> <p><img src="https://www.skeptrune.com/_astro/4323-attempt.A25xk5py_Z7SM6S.webp" alt="Worktree example run toggle image" data-astro-cid-xaorfurn="true" width="365" height="365" loading="lazy" decoding="async"></p><p data-astro-cid-xaorfurn=""><code>codex-1</code>. Very <b>wrong</b> Shadow on top, active state wrong side.</p> </div><div data-astro-cid-xaorfurn=""> <p><img src="https://www.skeptrune.com/_astro/4324-attempt.DnwzufAQ_28akmr.webp" alt="Worktree example run toggle image" data-astro-cid-xaorfurn="true" width="365" height="365" loading="lazy" decoding="async"></p><p data-astro-cid-xaorfurn=""><code>codex-2</code>. Is <b>unusable</b>, circle color wrong, active side incorrect.</p> </div> </div> 

<p>Voila, results! Only one of the four LLMs produced a solution that actually saved me time. This validates the necessity of rolling multiple agents: if each has a <code>~25%</code> chance of producing something useful, then running four gives a <code>68%</code> chance that at least one will succeed <code>(1 - 0.75^4 ≈ 0.68)</code>. Four agents was essentially the bare minimum to have reasonable confidence in getting a workable solution.</p>
<p>With LLMs being so affordable, there’s virtually no downside to running multiple agents. The cost difference between using one agent ($0.10) versus four ($0.40) is negligible compared to the 20 minutes of development time saved. Since the financial risk is minimal, you can afford to be aggressive with parallelization. If anything, I could have run even more agents to further increase the odds of getting a perfect solution on the first try.</p>
<p>And yet, the process of running them is still cumbersome and manual, it’s more effort to setup 8 than 4, so I’m often lazy and opt to run the minimum number of agents I think will get the job done. This is where the problem comes in, and why I’m excited to share my proposed solution.</p>
<h3 id="current-workflow-pain-points">Current workflow pain points</h3>
<p>Right now, I manually create git worktrees using <code>git worktree add -b newbranch ../path</code>, start a <code>tmux</code> session for each one, run Claude Code in the first pane, paste a prompt, <code>leader+c</code> into a new pane, run <code>yarn dev</code> to get a preview, switch to my browser to review, repeat if no agents succeed, then finally commit, push, and create a PR once I’m satisfied with an output.</p>
<p>Here are the top frustrations:</p>
<ul>
<li>I can’t tell which branch a worktree was most recently rebased onto. For example, if <code>agent-1</code> was rebased onto <code>feature-x</code> but <code>agent-2</code> onto <code>main</code>, it’s easy to lose track without manual notes.</li>
<li>There is no easy way to send the same prompt to multiple agents at once. For instance, if all agents are stuck on the same misunderstanding of the requirements, I have to copy-paste the clarification into each session.</li>
<li>I really wish I had a shortcut to open my IDE for a given worktree without having to <code>tmux a</code>, <code>leader + c</code>, and <code>code .</code> manually. I could use a long one-liner with <code>tmux send-keys and xargs</code> to automate this, but that still feels clunky.</li>
<li>Web previewing is a pain. I have to run <code>yarn dev</code> in each worktree, and then hold the mental model of which port each worktree is on. Automating a reverse proxy to handle this with a decent naming scheme would be a game-changer.</li>
<li>Committing and creating pull requests (PRs) is also more cumbersome than it should be. For example, after finding a solution in <code>agent-3</code>, I have to manually attach to that tmux session then <code>commit</code>, <code>push</code>, and <code>gh pr</code>.</li>
</ul>
<p>I feel like I’ve been through the wringer enough times with this process that I can see a solution shape which would create a smoother experience.</p>
<h3 id="proposing-a-solution-uzi">Proposing a solution: <em>uzi</em></h3>
<p>To address these challenges head-on, the ideal developer experience (DX) would involve a lightweight CLI that wraps tmux, automating this complex orchestration. My co-founder Denzell and I felt these pain points acutely enough that we’ve begun developing such a tool, which we’re calling <a href="https://github.com/devflowinc/uzi"><em>uzi</em></a>. The core idea behind <em>uzi</em> is to abstract away the manual, repetitive tasks involved in managing multiple AI agent worktrees.</p>
<p>See some of the <code>uzi</code> commands we are thinking to implement below. Our goal is to make the workflow more seamless while sticking closely to the existing mechanics of worktres and tmux. We want to make sure that we feel at home using <code>uzi</code> alongside standard unix tools like <code>xargs</code>, <code>grep</code>, and <code>awk</code>.</p>
<ul>
<li><code>uzi start --agents claude:3,codex:2 --prompt "Implement feature X"</code> could initialize and prompt three Claude instances and two Codex instances, each in its own worktree.</li>
<li><code>uzi ls</code> would display all active agents, their target branches, and current statuses.</li>
<li><code>uzi exec --all -- yarn dev</code> could run a command like <code>yarn dev</code> across all agent worktrees.</li>
<li><code>uzi broadcast -- "Refine the previous response by focusing on Y"</code> would send a follow-up prompt to all active agents.</li>
<li><code>uzi checkpoint --agent claude-1 --message "Implemented initial draft"</code> could rebase the specified agent’s worktree and commit the changes.</li>
<li><code>uzi kill --agent codex-2</code> would clean up a specific agent’s tmux session and optionally its worktree.</li>
</ul>
<p>These commands would primarily operate via <code>tmux send-keys</code> instructions to the appropriate sessions. We don’t want to reinvent the wheel; we just want to polish the existing process and make it more efficient.</p>
<h3 id="the-future-is-parallel-beyond-code">The Future is Parallel: Beyond Code</h3>
<p>While <code>uzi</code> focuses on software developers, its methodology isn’t limited to tech; the principle of leveraging multiple agents running in parallel to increase the odds of finding an optimal solution applies universally.</p>
<p>Consider a company like <a href="https://www.versionstory.com/">versionstory</a>, which is pioneering version control for transactional lawyers. An attorney could leverage their software to run multiple instances of an agent to redline a contract. After reviewing the outputs, they could select and merge the best components to finalize the document. This approach would provide additional confidence in the quality of the final review as it would be based on multiple independent analyses rather than a single agent’s output.</p>
<p>Similarly, a marketing team could employ this parallel strategy to perform data analysis on ad performance. By prompting multiple AI instances, they could quickly gather a range of analyses, review them, and select the most insightful ones to inform their strategy. More coverage of the solution space leads to better decision-making and more effective campaigns.</p>
<p>This parallel paradigm isn’t just a new technique for developers; it’s a glimpse into a more efficient, robust, and powerful future for AI-assisted productivity across various fields. I expect to see existing software products start to gain more powerful version control and parallel execution capabilities which emulate the workflow enabled by git worktrees for software development.</p>
<p>My DMs are open if you want to chat about this topic or have any questions. I’m happy to discuss.</p> </article>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[xAI to pay telegram $300M to integrate Grok into the chat app (292 pts)]]></title>
            <link>https://techcrunch.com/2025/05/28/xai-to-invest-300m-in-telegram-integrate-grok-into-app/</link>
            <guid>44116862</guid>
            <pubDate>Wed, 28 May 2025 15:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/05/28/xai-to-invest-300m-in-telegram-integrate-grok-into-app/">https://techcrunch.com/2025/05/28/xai-to-invest-300m-in-telegram-integrate-grok-into-app/</a>, See on <a href="https://news.ycombinator.com/item?id=44116862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<div>
		<figure><img width="1024" height="683" src="https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?w=1024" alt="The logo for Telegram Signal messenger application arranged on a smartphone." decoding="async" fetchpriority="high" srcset="https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg 6427w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=150,100 150w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=300,200 300w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=768,512 768w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=680,453 680w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=1200,800 1200w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=1280,853 1280w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=430,287 430w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=720,480 720w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=900,600 900w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=800,533 800w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=1536,1024 1536w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=2048,1365 2048w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=668,445 668w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=562,375 562w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=925,617 925w, https://techcrunch.com/wp-content/uploads/2024/06/telegram-app-cellphone.jpg?resize=708,472 708w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong>Image Credits:</strong>Lam Yik/Bloomberg / Getty Images</figcaption></figure>	</div>
	<div>
						<p><time datetime="2025-05-28T06:25:29-07:00">6:25 AM PDT · May 28, 2025</time></p>											</div>
</div><div>
		
		<div>
			<div>
<p id="speakable-summary">Telegram has struck a partnership with Elon Musk’s AI company, xAI, to distribute the latter’s chatbot, Grok, via Telegram and integrate it into apps available on the chat app’s platform for one year.</p>

<p>xAI will pay $300 million in cash and equity to the chat app as part of the deal, Telegram’s CEO Pavel Durov <a href="https://x.com/durov/status/1927697402095378432" target="_blank" rel="noreferrer noopener nofollow">said</a> on Tuesday.</p>







<p>Durov said Telegram will also earn 50% of the revenue from xAI subscriptions purchased through the app.</p>

<p>Earlier this year, xAI made the Grok chatbot available to <a href="https://x.com/grok/status/1904840863622066629" target="_blank" rel="noreferrer noopener nofollow">Telegram’s premium users</a>. It seems Grok might now be made available to all users.</p>

<p>A video posted by Durov on X suggested that Grok can be pinned on top of chats within the app, and users can also ask questions to Grok from the search bar. Notably, Meta has also integrated Meta AI into <a href="https://techcrunch.com/2024/04/12/meta-is-testing-an-ai-powered-search-bar-in-instagram/">the search bar on Instagram and WhatsApp</a>.</p>

<p>The video also shows that you will be able to use Grok for writing suggestions, summarizing chats, links, and documents, and creating stickers. Grok will supposedly also help answer questions for businesses and assist with moderation.</p>

<p><em>Note: This story was corrected to clarify that xAI is paying Telegram $300 million for distributing Grok.</em></p>

</div>

			

			


			
			
			

			




			
			
			

			



			
<div>
	
	
	
	

	
<div>
	<p>
		Ivan covers global consumer tech developments at TechCrunch. He is based out of India and has previously worked at publications including Huffington Post and The Next Web. You can reach out to him at im[at]ivanmehta[dot]com	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/ivan-mehta/" data-event="button" href="https://techcrunch.com/author/ivan-mehta/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div>


		</div>
		

		
		<div id="wp-block-techcrunch-most-popular-posts__heading">
<h2 id="h-most-popular">Most Popular</h2>

</div>
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mullvad Leta (352 pts)]]></title>
            <link>https://leta.mullvad.net</link>
            <guid>44116503</guid>
            <pubDate>Wed, 28 May 2025 14:38:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://leta.mullvad.net">https://leta.mullvad.net</a>, See on <a href="https://news.ycombinator.com/item?id=44116503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-cy="locationSelect"><p><label for="country">Country</label></p><!--[!--><!--]--><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[De-anonymization attacks against the privacy coin XMR (178 pts)]]></title>
            <link>https://monero.forex/is-monero-totally-private-a-comprehensive-analysis-of-de-anonymization-attacks-against-the-privacy-coin/</link>
            <guid>44116236</guid>
            <pubDate>Wed, 28 May 2025 14:11:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://monero.forex/is-monero-totally-private-a-comprehensive-analysis-of-de-anonymization-attacks-against-the-privacy-coin/">https://monero.forex/is-monero-totally-private-a-comprehensive-analysis-of-de-anonymization-attacks-against-the-privacy-coin/</a>, See on <a href="https://news.ycombinator.com/item?id=44116236">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h3>Analyzing Attempts to Deanonymize and Track Monero Transactions: A Technical and Strategic Overview.</h3>


<p><strong>December 23, 2024<br>By: Trevor Baaddi</strong></p>


<p>Monero (XMR), a cryptocurrency renowned for its privacy-centric design, has drawn the attention of governments, cybersecurity experts, and analytics firms seeking to deanonymize its transactions. Unlike Bitcoin, where transactions are publicly visible on the blockchain, Monero employs sophisticated privacy features such as ring signatures, stealth addresses, and confidential transactions. This article analyzes notable attempts to compromise Monero’s privacy, detailing the methodologies used, their efficacy, and their limitations.</p>



<h4>Monero’s Privacy Features: A Brief Overview</h4>



<p>To appreciate the challenges of deanonymizing Monero, it is essential to understand its privacy architecture:</p>



<ul>
<li><strong>Ring Signatures</strong>: Combine a sender’s output with decoy outputs, obscuring the true origin of a transaction.</li>



<li><strong>Stealth Addresses</strong>: Generate unique one-time addresses for recipients, ensuring transactions cannot be linked back to a public address.</li>



<li><strong>Ring Confidential Transactions (RingCT)</strong>: Conceal transaction amounts.</li>



<li><strong>Dandelion++ Protocol</strong>: Helps obscure the origin of transactions during network propagation.</li>
</ul>



<p>These features collectively create a blockchain that is opaque by design, frustrating conventional blockchain analysis techniques.</p>



<hr>



<h4>1. Chainalysis and Monero Tracking Services</h4>



<p><strong>Attempt</strong>: Chainalysis, a prominent blockchain analytics company, has been reported to develop tools capable of providing some insights into Monero transactions. While specifics are scarce due to the proprietary nature of their methods, Chainalysis has publicly acknowledged limited success with Monero tracking.</p>



<p><strong>Methodology</strong>: Their approach likely involves exploiting known vulnerabilities, such as timing analysis of transactions or correlating off-chain data (e.g., exchange deposits and withdrawals).</p>



<p><strong>Efficacy</strong>: Limited. Chainalysis’s methods have reportedly provided probabilistic results rather than deterministic deanonymization. For example, law enforcement contracts suggest they may only achieve partial success in scenarios where Monero interacts with non-private cryptocurrencies or centralized exchanges.</p>



<hr>



<h4>2. CipherTrace’s Monero Analysis Tool</h4>



<p><strong>Attempt</strong>: In 2020, CipherTrace claimed to develop tools to track Monero transactions, purportedly offering these capabilities to the U.S. Department of Homeland Security (DHS).</p>



<p><strong>Methodology</strong>:</p>



<ul>
<li><strong>Transaction Heuristics</strong>: CipherTrace suggested it could identify patterns or anomalies in transaction data.</li>



<li><strong>Network Analysis</strong>: Monitoring IP addresses and network-level metadata during transaction broadcasts.</li>
</ul>



<p><strong>Efficacy</strong>: Controversial. Critics argue CipherTrace has not demonstrated comprehensive deanonymization and question the validity of their claims. Monero’s development team and community members have scrutinized CipherTrace’s assertions, pointing out the lack of independent verification.</p>



<hr>



<h4>3. Academic Research: Breaking Monero’s Privacy with Statistical Analysis</h4>



<p><strong>Attempt</strong>: Various academic papers have explored vulnerabilities in Monero’s privacy model. A notable example is the 2017 research by Möser, Kappos, and Böhme, which analyzed Monero’s ring signature scheme.</p>



<p><strong>Methodology</strong>:</p>



<ul>
<li><strong>Statistical Analysis of Ring Signatures</strong>: The researchers identified weaknesses in older versions of Monero’s ring signature implementation, where decoy selection was not truly random.</li>



<li><strong>Temporal Analysis</strong>: Exploiting the time at which outputs were used as inputs in subsequent transactions to infer relationships.</li>
</ul>



<p><strong>Efficacy</strong>: Significant but outdated. Monero developers promptly addressed these vulnerabilities by introducing mandatory RingCT and improving decoy selection algorithms.</p>



<hr>



<h4>4. Blockchain Analysis Firms and Metadata Correlation</h4>



<p><strong>Attempt</strong>: Firms like Elliptic and others have explored off-chain metadata correlation to deanonymize Monero users indirectly.</p>



<p><strong>Methodology</strong>:</p>



<ul>
<li><strong>Exchange Data</strong>: Linking Monero transactions to known addresses at centralized exchanges.</li>



<li><strong>IP and Geolocation Data</strong>: Using network-level surveillance to track transaction broadcasts.</li>
</ul>



<p><strong>Efficacy</strong>: Partial. Success depends on external factors, such as users’ operational security practices and reliance on exchanges with Know Your Customer (KYC) protocols.</p>



<hr>



<h4>5. Government Initiatives: The IRS Bounty Program</h4>



<p><strong>Attempt</strong>: In 2020, the Internal Revenue Service (IRS) offered a $625,000 bounty for anyone capable of cracking Monero’s privacy.</p>



<p><strong>Methodology</strong>:</p>



<ul>
<li><strong>Collaborations with Analytics Firms</strong>: Contracts with Chainalysis and Integra FEC aimed to develop Monero-tracking tools.</li>



<li><strong>Network Surveillance</strong>: Leveraging external data sources and possible timing attacks.</li>
</ul>



<p><strong>Efficacy</strong>: Unknown/Zero. While the bounty led to partnerships, there is no public evidence that these efforts resulted in comprehensive deanonymization.</p>



<hr>



<h4>6. Community-Driven Efforts: “Breaking Monero” Series</h4>



<p><strong>Attempt</strong>: The Monero Research Lab and community members created the “Breaking Monero” series, which proactively identifies and mitigates potential vulnerabilities.</p>



<p><strong>Methodology</strong>:</p>



<ul>
<li><strong>White-Hat Analysis</strong>: Evaluating transaction linkability, decoy selection, and network-level attacks.</li>



<li><strong>Ongoing Hard Forks</strong>: Implementing upgrades to enhance Monero’s privacy features.</li>
</ul>



<p><strong>Efficacy</strong>: Proactive and robust. These efforts have strengthened Monero’s resistance to tracking.</p>



<hr>



<h3>Conclusion: Monero’s Privacy Remains Resilient</h3>



<p>Despite various attempts by governments, firms, and researchers to deanonymize Monero, the cryptocurrency’s privacy features have proven remarkably resilient. While certain methodologies have exploited weaknesses or probabilistically reduced anonymity, none have achieved reliable, widespread deanonymization. Monero’s active development community continues to fortify its defenses, ensuring it remains a leading choice for privacy-focused users.</p>



<h4>References:</h4>



<ol start="1">
<li><a href="https://www.chainalysis.com/blog/2024-crypto-crime-report-introduction/" target="_blank">Chainalysis Insights</a></li>



<li><a href="https://ciphertrace.com/" target="_blank">CipherTrace Monero Tracking Announcement</a></li>



<li>Möser, Kappos, and Böhme (2017). “Empirical Analysis of Privacy in Monero.”</li>



<li><a href="https://www.irs.gov/compliance/criminal-investigation/former-security-engineer-for-international-technology-company-pleads-guilty-to-hacking-two-decentralized-cryptocurrency-exchanges" target="_blank">IRS Cryptocurrency Bounty</a></li>



<li><a href="https://www.youtube.com/playlist?list=PLsSYUeVwrHBnAUre2G_LYDsdo-tD0ov-y" target="_blank">Breaking Monero Series</a></li>
</ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Blowtorch Theory: A new model for structure formation in the universe (171 pts)]]></title>
            <link>https://theeggandtherock.com/p/the-blowtorch-theory-a-new-model</link>
            <guid>44115973</guid>
            <pubDate>Wed, 28 May 2025 13:43:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theeggandtherock.com/p/the-blowtorch-theory-a-new-model">https://theeggandtherock.com/p/the-blowtorch-theory-a-new-model</a>, See on <a href="https://news.ycombinator.com/item?id=44115973">Hacker News</a></p>
Couldn't get https://theeggandtherock.com/p/the-blowtorch-theory-a-new-model: Error: getaddrinfo ENOTFOUND theeggandtherock.com]]></description>
        </item>
    </channel>
</rss>