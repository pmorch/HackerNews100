<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 08 May 2025 08:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Mycoria is an open and secure overlay network that connects all participants (102 pts)]]></title>
            <link>https://mycoria.org/</link>
            <guid>43923372</guid>
            <pubDate>Thu, 08 May 2025 05:40:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mycoria.org/">https://mycoria.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43923372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="content">
              <article>
                
                  

  
  


<p><img alt="Mycoria Logo" src="https://mycoria.org/assets/logo/icon_transp_bg.png" width="150"></p>

<p>Mycoria is an open and secure overlay network that connects all participants. It values freedom of connectivity and aims to imitate the curious and adventurous spirit of the early Internet:</p>
<ul>
<li><mark>Everyone is equal</mark>: Easily connect to anyone</li>
<li><mark>Everyone is welcome</mark>: Open network without bureaucracy</li>
<li>No spooking: Everthing is authenticated</li>
<li>No surveillance: Everything is encrypted (+ Private Addresses!)</li>
<li>No barriers: Connect via the Internet or extend Mycoria with your own mesh</li>
</ul>
<h3 id="design-goals">Design Goals</h3>
<ul>
<li>Keep it small and simple</li>
<li>Compatible with existing infrastructure (eg. DNS)</li>
<li><mark>Secure by default</mark></li>
<li>Private by default (WIP)</li>
</ul>
<h3 id="features">Features</h3>
<ul>
<li><mark>Automatic end-to-end encryption</mark></li>
<li>Modern cryptography</li>
<li>Smart and scalable routing</li>
<li>Dashboard</li>
<li>Resolve .myco DNS (OS configuration required)</li>
<li>Simple Service Discovery</li>
<li>Auto-Optimization/Healing of Network (for Internet overlay) (WIP)</li>
<li>Rotating private addresses (WIP)</li>
</ul>
<p><a href="https://mycoria.org/concept/">Continue reading about the concept.</a></p>
<h2 id="dashboard-impressions">Dashboard Impressions</h2>
<p><img alt="Dashboard Overview" src="https://mycoria.org/img/dashboard_overview.png">
<img alt="Dashboard Overview Light" src="https://mycoria.org/img/dashboard_overview_light.png">
<img alt="Dashboard Discover" src="https://mycoria.org/img/dashboard_discover.png">
<img alt="Dashboard Domains" src="https://mycoria.org/img/dashboard_domains.png">
<img alt="Dashboard Routing Table" src="https://mycoria.org/img/dashboard_routing_table.png">
<img alt="Open New Domain" src="https://mycoria.org/img/dashboard_open_new_domain.png">
<img alt="Open Changed Domain" src="https://mycoria.org/img/dashboard_open_changed_domain.png">
<img alt="Open Reserved Domain" src="https://mycoria.org/img/dashboard_open_reserved_domain.png"></p>












                
              </article>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yggdrasil is an experimental compact routing scheme that is fully decentralised (127 pts)]]></title>
            <link>https://yggdrasil-network.github.io/about.html</link>
            <guid>43921624</guid>
            <pubDate>Wed, 07 May 2025 23:45:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yggdrasil-network.github.io/about.html">https://yggdrasil-network.github.io/about.html</a>, See on <a href="https://news.ycombinator.com/item?id=43921624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            

<p>Yggdrasil is an experimental compact routing scheme that is <strong>fully decentralised</strong> and only requires a small amount of state to work. It is predominanently a shortest-path scheme, whereby the network will attempt to find the most direct path to the destination.</p>

<p><img src="https://yggdrasil-network.github.io/assets/images/about/first.svg"></p>

<p>Nodes are equal participants and connect to each other using <strong>peering connections</strong> which carry network traffic. Peerings can be set up over any IP network — whether that’s a direct wired or wireless link, a local area network or even the Internet. In some cases, peerings can also be set up automatically by nearby devices on the same network using multicast discovery.</p>

<p>All nodes on an Yggdrasil network are routers and will automatically pass traffic to help it get closer to its destination where possible. This means that, even in a network that is only sparsely connected, <strong>all nodes will be reachable</strong> by all other nodes on that network. It doesn’t even matter if a node is behind a NAT — once a peering is established, traffic flows in both directions over that peering.</p>

<p>Yggdrasil is also designed to tolerate changes in the network. For example, if a link fails, the network will self-heal and use other links to route traffic where available. This makes it <strong>suitable for use in mesh networks</strong>, where the network topolopy can and often will change.</p>

<p>Each node on the network has a location-independent <strong>cryptographic identity</strong> and, in our <a href="https://yggdrasil-network.github.io/implementation.html">current experimental implementation</a>, stable IPv6 addresses are generated from this key. This allows IPv6-supporting applications to work over Yggdrasil largely without modification. The address is fully mobile and stays with the node as it moves around the network.</p>

<h3 id="why-yggdrasil">Why Yggdrasil?</h3>

<p>Many networks that exist today are hierarchical in nature, require extensive manual configuration and often rely on a certain degree of centralisation in order to scale. This often makes it difficult or impractical to set up networks quickly on an ad-hoc basis and so most people are heavily reliant on their Internet Service Providers (ISPs).</p>

<p>On the other hand, Yggdrasil requires <strong>very little configuration</strong> in order to work and full multi-hop networks can be built up very quickly and easily using Yggdrasil.</p>

<p>Nodes do not need to be assigned an address from a centralised authority; they can <strong>generate their own cryptographic identity</strong> and, more importantly, they can keep this address as they roam. Once peering connections are established, routing information is propagated quickly and automatically throughout the network.</p>

<p>This ability to provide full end-to-end routability between all network nodes means that Yggdrasil is potentially an enabling technology for true edge computing scenarios, as well as real-world mesh networks, as it <strong>does not rely on the Internet</strong> to function.</p>

<h3 id="how-does-yggdrasil-compare-to-other-projects">How does Yggdrasil compare to other projects?</h3>

<p>Yggdrasil is often compared to other projects attempting to create anonymous overlays, such as Tor, I2P, Lokinet and others. These projects are very different to Yggdrasil, in part because they try to guarantee anonymity. Yggdrasil does not aim to provide and <strong>does not guarantee anonymity</strong>. These projects are also intentionally overlay-by-design rather than by convenience, whereas Yggdrasil only exists as an overlay network today because it is an easy way to test the design.</p>

<p>Yggdrasil is frequently compared with VPN projects such as Wireguard, Tailscale, Nebula and Zerotier. Although it is possible to use Yggdrasil to build up private networks and/or point-to-point VPN links, this isn’t explicitly our primary goal. It’s also important to understand that connecting any single node of a private network to another network (such as a public peer) will result in <strong>both networks being bridged together</strong>.</p>

<p>Finally, Yggdrasil has <strong>no native exit nodes</strong>, nor does it have any concept of exit nodes, for providing access to the public Internet or to other networks. This can be achieved using proxies or other tunnelling solutions on top of Yggdrasil but this is not something we explicitly aim to provide.</p>

<h3 id="what-is-the-status-of-the-project">What is the status of the project?</h3>

<p>Yggdrasil is currently an <strong>alpha-level research project</strong>, with on-going development but actively maintained. Our expectation is that a future beta-quality release should know enough to be compatible in the face of wire format changes, and reasonably feature complete. A “stable” 1.0 release, if it ever happens, would probably be feature complete, with no expectation of future wire format changes, and free of known critical bugs.</p>

<p>The true goal of this project is to test the scalability of the Yggdrasil routing scheme and we are doing so with our <a href="https://yggdrasil-network.github.io/implementation.html">overlay network implementation</a>. Studying the behaviour of the network in the real world is most easily achieved with a large number of participants running the software and joining the public test network. We’ve done our best to support <a href="https://yggdrasil-network.github.io/installation.html">as many platforms as possible</a> and have a number of <a href="https://github.com/yggdrasil-network/public-peers">public peers</a> that you can connect to in order to join the network, so please feel free to experiment.</p>

<p>That said, we <strong>recommend against running any mission-critical workloads</strong> over Yggdrasil and it may be dangerous to rely solely on Yggdrasil for any life-or-death situation. There may be failure modes that we don’t yet know about yet!</p>

<p>The project is likely to reach a number of possible outcomes:</p>

<ol>
  <li>The project may reach a reasonably stable state but never attract a large enough number of users</li>
  <li>The project may attract a large enough number of users but reveal inherent design flaws in the process (a learning exercise for a future project or protocol version perhaps)</li>
  <li>The project may end up working perfectly even as the network grows, in which case it will become worthwhile to look at writing better-optimised implementations and/or moving the important parts into other projects</li>
</ol>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[June Huh dropped out to become a poet, now he’s won a Fields Medal (2022) (136 pts)]]></title>
            <link>https://www.quantamagazine.org/june-huh-high-school-dropout-wins-the-fields-medal-20220705/</link>
            <guid>43920792</guid>
            <pubDate>Wed, 07 May 2025 21:34:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/june-huh-high-school-dropout-wins-the-fields-medal-20220705/">https://www.quantamagazine.org/june-huh-high-school-dropout-wins-the-fields-medal-20220705/</a>, See on <a href="https://news.ycombinator.com/item?id=43920792">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody">
                <div>
            <p><span>SERIES</span>
        </p>
        
    <h2>He Dropped Out to Become a Poet. Now He’s Won a Fields Medal.</h2>
    
    <div>
        <p>
            June Huh wasn’t interested in mathematics until a chance encounter during his sixth year of college. Now his profound insights connecting combinatorics and geometry have led to math’s highest honor.        </p>
        
    </div>
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1440" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-scaled.jpg" alt="June Huh with a polyhedron." decoding="async" fetchpriority="high" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-scaled.jpg 2560w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-1720x968.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-520x293.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-768x432.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-1536x864.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_2880x1620_Lede-2048x1152.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>June Huh in his Princeton University office.</p>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>June Huh often finds himself lost. Every afternoon, he takes a long walk around Princeton University, where he’s a professor in the mathematics department. On this particular day in mid-May, he’s making his way through the woods around the nearby Institute for Advanced Study — “Just so you know,” he says as he considers a fork in the path ahead, “I don’t know where we are” — pausing every so often to point out the subtle movements of wildlife hiding beneath leaves or behind trees. Among the animals he spots over the next two hours of wandering are a pair of frogs, a red-crested bird, a turtle the size of a thimble, and a quick-footed fox, each given its own quiet moment of observation.</p>
<p>“I’m very good at finding stuff,” he says. “That’s one of my special abilities.”</p>
<p>Huh, 39, has now been awarded the Fields Medal, the highest honor in mathematics, for his ability to wander through mathematical landscapes and find just the right objects — objects that he then uses to get the seemingly disparate fields of geometry and combinatorics to talk to each other in new and exciting ways. Starting in graduate school, he has solved several major problems in combinatorics, forging a circuitous route by way of other branches of math to get to the heart of each proof. Every time, finding that path is akin to a “little miracle,” Huh said.</p>
<p>One might say the same of his path into mathematics itself: that it was characterized by much wandering and a series of small miracles. When he was younger, Huh had no desire to be a mathematician. He was indifferent to the subject, and he dropped out of high school to become a poet. It would take a chance encounter during his university years — and many moments of feeling lost — for him to find that mathematics held what he’d been looking for all along.</p>


    
<p>That poetic detour has since proved crucial to his mathematical breakthroughs. His artistry, according to his colleagues, is evident in the way he uncovers those just-right objects at the center of his work, and in the way he seeks a deeper significance in everything he does. “Mathematicians are a lot like artists in that really we’re looking for beauty,” said <a href="https://www.quantamagazine.org/mathematician-federico-ardila-dances-to-the-joys-and-sorrows-of-discovery-20171120/">Federico Ardila-Mantilla</a>, a mathematician at San Francisco State University and one of Huh’s collaborators. “But I think in his case, it’s really pronounced. And I just really like his taste. He makes beautiful things.”</p>
<p>“When I found out that he came to mathematics after poetry, I’m like, OK, this makes sense to me,” Ardila added.</p>
<p>Huh himself draws parallels between the artist and the mathematician. For both, he said, “it feels like you’re grabbing something that’s already there, rather than creating something in your mind.”</p>

<p>On any given day, Huh does about three hours of focused work. He might think about a math problem, or prepare to lecture a classroom of students, or schedule doctor’s appointments for his two sons. “Then I’m exhausted,” he said. “Doing something that’s valuable, meaningful, creative” — or a task that he doesn’t particularly want to do, like scheduling those appointments — “takes away a lot of your energy.”</p>
<p>To hear him tell it, he doesn’t usually have much control over what he decides to focus on in those three hours. For a few months in the spring of 2019, all he did was read. He felt an urge to revisit books he’d first encountered when he was younger — including <em>Meditations</em> by the Roman emperor Marcus Aurelius and several novels by the German author Hermann Hesse — so that’s what he did. “Which means I didn’t do any work,” Huh said. “So that’s kind of a problem.” (He’s since made peace with this constraint, though. “I used to try to resist … but I finally learned to give up to those temptations.” As a consequence, “I became better and better at ignoring deadlines.”)</p>
</div>
    </div>
    <figure>
        <div>
                            <p><img width="1600" height="1279" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Notes.jpg" alt="Handwritten notes." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Notes.jpg 1600w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Notes-520x416.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Notes-768x614.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Notes-1536x1228.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Huh’s notes from a recent lecture.</p>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>He finds that forcing himself to do something or defining a specific goal — even for something he enjoys — never works. It’s particularly difficult for him to move his attention from one thing to another. “I think intention and willpower … are highly overrated,” he said. “You rarely achieve anything with those things.”</p>
<p>This has been the case since he was young. He was born in 1983 in California, where his parents were finishing graduate school. The family then moved to Seoul, South Korea, when Huh was around 2 years old. There, his father taught statistics, his mother Russian language and literature.</p>
<p>School was excruciating for him. He loved to learn but couldn’t focus or absorb anything in a classroom setting. Instead, he preferred to read on his own — in elementary school, he devoured all 10 volumes of an encyclopedia about living things — and to explore a mountain near his family’s apartment. He quickly became familiar with every corner of it, but he still managed to get lost, one time even ending up in an area that was restricted due to the possible presence of land mines.</p>
<p>He tried his best to avoid math whenever possible. His father once tried to teach him out of a workbook, but rather than try to solve the problems, Huh would copy the solutions from the back. When his father caught on and tore those pages out, Huh went to a local bookstore and wrote down the answers there. “He gave up at that point,” Huh said.</p>
<p>When he was 16 years old and in the middle of his first year in high school (which lasts for three years in South Korea), he decided to drop out to write poetry. He was something of a romantic. “I could literally physically cry after listening to good music,” he said. He wrote about nature and about his own experiences. He planned to complete his masterpiece in the two years before he’d have to attend university. “So that didn’t happen,” he laughed.</p>
<p>He found the writing process too focused on the self — and for him, that exploration was often painful and depressing. Moreover, as he later realized, “I wanted to be someone who writes great poetry,” he said. “I didn’t want to write great poetry.” Now he sees that version of himself as almost a complete stranger.</p>
<p>When he entered Seoul National University in 2002, he felt adrift. He briefly flirted with the idea of being a science writer and decided to major in astronomy and physics. But he frequently skipped class, and he had to retake several courses. “I was just generally lost,” he said. “I didn’t know what I wanted to do. I didn’t know what I was good at.”</p>
<p>It turned out that he was good at math after all — something he discovered entirely by accident.</p>
<h2><strong>True Beauty</strong></h2>
<p>It took Huh six years to graduate. In that sixth year, he enrolled in a class taught by the famed Japanese mathematician Heisuke Hironaka, who <a href="https://www.mathunion.org/imu-awards/fields-medal/fields-medals-1970">won the Fields Medal in 1970</a>. Hironaka was charismatic, and Huh quickly fell under his sway.</p>
<p>But it wasn’t just his professor’s charm that attracted Huh that first day in class. It was also the math itself. Ostensibly, the course was an introduction to algebraic geometry, the study of solutions to algebraic equations and their geometric properties. Instead, Hironaka taught his own work in an area called singularity theory, which focuses on certain types of spaces. “Basically, he lectured about what he thought about yesterday,” Huh said — a very particular problem, and proofs that weren’t necessarily correct. What began as a 200-student class quickly dwindled; a few weeks later, only five students were left, Huh among them.</p>
<p>For the first time, he witnessed research mathematics unfolding in real time. Hironaka’s lectures weren’t polished as in other undergraduate courses, where everything was streamlined, the answers already worked out. Huh loved the suspense of it, the act of trying to do something no one really knew how to do — and the freedom that came with not knowing, the surprises that became possible. The typical material taught in college has been refined over the course of centuries, he said. “That’s very different from observing this raw mathematics in front of your eyes.”</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1801" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-scaled.jpg" alt="June Huh sitting outside." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-scaled.jpg 2560w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-1720x1210.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-520x366.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-768x540.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-1536x1081.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Garden-2048x1441.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Huh on the Princeton University campus.</p>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Huh discovered that this kind of mathematics could give him what poetry could not: the ability to search for beauty outside himself, to try to grasp something external, objective and true, in a way that opened him up more than writing ever had. “You don’t think about your small self,” he said. “There’s no place for ego.” He found that unlike when he was a poet, he was never motivated by the desire for recognition. He just wanted to do math.</p>
<p>Hironaka, perhaps recognizing this, took him under his wing. After Huh graduated and started a master’s program at Seoul National University — where he also met Nayoung Kim, now his wife — he spent a lot of time with Hironaka. During breaks, he followed the professor back to Japan, staying with him in Tokyo and Kyoto, carrying his bags, sharing meals, and of course continuing to discuss math.</p>
<h2><strong>An Unexpected Discovery</strong></h2>
<p>Huh applied to about a dozen doctoral programs in the U.S. But because of his undistinguished undergraduate experience, he was rejected by all of them save one. In 2009, he began his studies at the University of Illinois, Urbana-Champaign, before transferring to the University of Michigan in 2011 to complete his doctorate.</p>
<p>Despite the challenges — living in a new country, spending time apart from Kim (she stayed at Seoul National University for her doctorate in mathematics) — Huh cherished his experiences in graduate school. He was able to dedicate himself wholly to math, and he relished the freedom of exploration that had drawn him to the subject in the first place.</p>
<p>He immediately stood out. As a beginning graduate student in Illinois, he <a href="https://www.ams.org/journals/jams/2012-25-03/S0894-0347-2012-00731-0/">proved a conjecture in graph theory</a> that had been open for 40 years. In its simplest form, the problem, known as Read’s conjecture, concerned polynomials — equations like <em>n</em><sup>4</sup> + 5<em>n</em><sup>3</sup> + 6<em>n</em><sup>2</sup> + 3<em>n</em> + 1 — attached to graphs, which are collections of vertices (points) connected by edges (lines). In particular, let’s say you want to color the vertices of a graph so that no two adjacent vertices have the same color. Given a certain number of colors at your disposal, there are many ways to color the graph. It turns out that the total number of possibilities can be calculated using an equation called the chromatic polynomial (which is written in terms of the number of colors being used).</p>
<p>Mathematicians observed that the coefficients of chromatic polynomials, no matter the graph, always seem to obey certain patterns. First, they are unimodal, meaning they increase and then decrease. Take the previous example of a polynomial. The absolute values of its coefficients — 1, 5, 6, 3, 1 — form a unimodal sequence. Moreover, that sequence is also “log concave.” For any three consecutive numbers in the sequence, the square of the middle number is at least as large as the product of the terms on either side of it. (In the above polynomial, for instance, 6<sup>2</sup> ≥ 5 × 3.)</p>
<figure>
    <p><img src="https://www.quantamagazine.org/wp-content/uploads/2018/07/JH-2-CHROMATIC4_560-Desktop.svg" alt="" decoding="async"><img src="https://www.quantamagazine.org/wp-content/uploads/2018/07/JH-2-CHROMATIC4_560-Mobile.svg" alt="" decoding="async">    </p>
            <figcaption>
            <p>Merrill Sherman/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>Still, mathematicians struggled to prove these properties. And then, seemingly out of nowhere, along came Huh.</p>
<p>As a master’s student, he had studied algebraic geometry and singularity theory with Hironaka. The main objects of study in that field are called algebraic varieties, which can be thought of as shapes defined by certain equations. Intriguingly, associated to certain kinds of algebraic varieties are numbers that are known to be log concave — something Huh only knew because of the serendipitous direction his studies had taken him in. Huh’s key idea was to find a way to construct an algebraic variety such that those associated numbers were precisely the coefficients of the chromatic polynomial of the graph from the original question.</p>
<p>His solution stunned the math community. It was at that point that the University of Michigan, having rejected his initial application, recruited him to their graduate program.</p>
<p>Huh’s achievement was impressive not just because he had solved Read’s conjecture when it had seemed completely intractable for so long. He had shown that something much deeper — and geometric — was lurking beneath combinatorial properties of graphs.</p>
<p>Mathematicians were also impressed by his demeanor. His talks at conferences were always accessible and concrete; in speaking with him, it was clear that he was thinking both deeply and broadly about the concepts he was working with. “He was ridiculously mature for a graduate student,” said <a href="https://sites.google.com/view/mattbakermath/home/">Matthew Baker</a>, a mathematician at the Georgia Institute of Technology. After Baker met him for the first time, “I was just like, who is this guy?”</p>
<p>According to <a href="http://www-personal.umich.edu/~mmustata/">Mircea Mustaţă</a>, Huh’s adviser at the University of Michigan, he required almost no supervision or guidance. Unlike most graduate students, he already had a program in mind, and ideas about how to pursue it. “He was more like a colleague,” Mustaţă said. “He already had his own way of looking at things.”</p>
<p>Many of his collaborators note that he’s incredibly humble and down-to-earth. When he learned he’d won the Fields Medal, “it didn’t really feel that good,” Huh said. “Of course you are happy, but deep down, you’re a little bit worried that they might eventually figure out that you’re not actually that good. I am a reasonably good mathematician, but am I Fields Medal-worthy?”</p>
<h2><strong>Escape From Space</strong></h2>
<p>Graphs are actually just one type of object that can define more general structures called matroids. Consider, for example, points on a two-dimensional plane. If more than two points lie on a line in this plane, you can say that those points are “dependent.” Matroids are abstract objects that capture notions like dependence and independence in all sorts of different contexts — from graphs to vector spaces to algebraic fields.</p>
<figure>
    <p><img src="https://www.quantamagazine.org/wp-content/uploads/2018/07/JH2-METROID4_560-Desktop.svg" alt="" decoding="async"><img src="https://www.quantamagazine.org/wp-content/uploads/2018/07/JH2-METROID4_560-Mobile.svg" alt="" decoding="async">    </p>
            <figcaption>
            <p>Merrill Sherman/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>Just as graphs have chromatic polynomials associated with them, there are equations called characteristic polynomials attached to matroids. It was conjectured that the polynomials for these more general objects should also have coefficients that are log concave. But the techniques Huh used to prove Read’s conjecture only worked for showing log concavity for a very narrow class of matroids, such as the matroids that arise from graphs.</p>
<p>With the mathematician <a href="https://people.math.osu.edu/katz.60/">Eric Katz</a>, Huh <a href="https://link.springer.com/article/10.1007/s00208-011-0777-6">broadened the class of matroids</a> such a proof could apply to. They followed a recipe of sorts. As before, the strategy was to start with the object of interest — here, a matroid — and use it to construct an algebraic variety. From there, they could extract an object called a cohomology ring and use some of its properties to prove log concavity.</p>
<p>There was just one problem. Most matroids don’t have any sort of geometric foundation, which means there’s not actually an algebraic variety to associate to them. Instead, Huh, Katz and the mathematician <a href="http://www.math.huji.ac.il/~adiprasito/">Karim Adiprasito</a> figured out a way to write down the right cohomology ring straight from the matroid, essentially from scratch. They then showed, using a new set of techniques, that it behaved as if it had come from an actual algebraic variety, even though it hadn’t. In doing so, they proved log concavity for all matroids, <a href="https://www.quantamagazine.org/a-path-less-taken-to-the-peak-of-the-math-world-20170627/">resolving the problem known as Rota’s conjecture</a> once and for all. “It’s pretty remarkable that it works,” Baker said.</p>
<p>The work showed that “you don’t need space to do geometry,” Huh said. “That made me really fundamentally rethink what geometry is.” It would also guide him toward a host of other problems, where he continued to push that idea further, allowing him to develop an even broader range of methods.</p>
<p>But for all the specificity the work requires, building the right cohomology ring requires massive amounts of guesswork and groping around in the dark. It was an aspect of the work that Huh particularly enjoyed. “There is no guiding principle … no clearly defined goal,” he said. “You just have to make a guess.”</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1410" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-scaled.jpg" alt="June Huh at a blackboard." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-scaled.jpg 2560w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-1720x947.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-520x286.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-768x423.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-1536x846.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Blackboard-2048x1128.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Huh’s work involves investigating the properties of matroids. These abstract structures can sometimes arise from geometric objects.</p>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>That lack of intention precisely mirrors how he functions best in his day-to-day life, too. It was as if he’d uncovered a mathematical program that perfectly fit his personality. Once again, he found that “things just happen by themselves,” Huh said.</p>
<h2><strong>The Heart of Things</strong></h2>
<p>Huh speaks slowly, pausing often and choosing his words carefully, and carries himself in a calm, peaceful manner that borders on meditative. “He doesn’t get so easily excited,” said <a href="https://people.math.wisc.edu/~wang/">Botong Wang</a>, a mathematician at the University of Wisconsin, Madison who has collaborated with Huh on a number of important recent results.</p>
<p>He proceeds just as deliberately when doing mathematics. Wang was shocked when he first witnessed it. “I have this math competition experience, that as a mathematician you have to be clever, you have to be fast,” he said. “But June is the opposite. … If you talk to him for five minutes about some calculus problem, you’d think this guy wouldn’t pass a qualifying exam. He’s very slow.” So slow, in fact, that at first Wang thought they were wasting a lot of time on easy problems they already understood. But then he realized that Huh was learning even seemingly simple concepts in a much deeper way — and in precisely the way that would later prove useful.</p>
<p>“June likes to do things in the right way,” said <a href="http://gdenham.math.uwo.ca/">Graham Denham</a>, a mathematician at Western University in Ontario and one of Huh’s collaborators.</p>
<p>For instance, Denham, Ardila and Huh had just completed a 50-page proof of a problem closely related to Rota’s conjecture when Huh said they should take some more time to find a cleaner, more appealing approach. He thought there was a nicer explanation out there, and that it was best not to rush things. “Federico and I were like, oh, OK, so we’ll just chuck that, then, shall we?” Denham said.</p>
<p>It took two years to craft <a href="https://arxiv.org/abs/2004.13116">the better argument</a>. “It’s good we’re all tenured,” Ardila said. Ultimately, though, Ardila and Denham agreed that the extra work was worth it. Their end result “was totally different, and deeper, and [got to] the heart of things,” Ardila said.</p>

<p>This approach doesn’t just apply to Huh’s mathematical work. In 2013, he decided he wanted to learn to cook. As a total beginner, he adopted the strategy of making the same dish — a simple pasta in oil — every day until it was perfect. For six months, that’s exactly what he did. (To date, according to Kim, that’s the only dish he knows how to cook.)</p>
<p>Huh’s entire life is built on routine. “Almost all of my days are exactly the same,” he said. “I have a very high tolerance for repetition.” He has trouble staying asleep and usually wakes up at around 3 a.m. He then goes to the gym, has breakfast with his wife and two sons (one is 8 years old, the other just turned 1), and walks his eldest to school before heading to his Princeton office.</p>
<p>The office is spare, practically empty. There’s a large desk, a couch for sleeping — Huh typically takes a nap later in the morning — and a yoga mat rolled out on the floor (just for lying down, he said; he doesn’t actually know how to do yoga). No books, just a few stacks of papers neatly arranged on a shelf against one wall. In the corner is a vacuum cleaner. Huh likes repetitive, mindless activities like cleaning, dishwashing and the physical act of transcribing what he reads into a notebook.</p>
<p>He often works in the public library, in the children’s section, where it’s pretty noisy. “I don’t like quiet places,” he said. “It makes me sleepy.” Huh says this about many things.</p>
<p>He goes for a long walk after lunch each day, then returns to his office to do some more work (unless he’s already hit his three-hour quota) before heading home. He spends the rest of the evening with his family; they all go to sleep, together in one large bed, at around 9 p.m.</p>
<p>This preference for routine — and the tendency to get exhausted by anything that strays from it — can sometimes manifest in extreme ways. When he was completing his doctorate in Michigan, for instance, “I would cut off almost everything else,” Huh said. When he first moved to Ann Arbor, he found himself unequipped for the brutal winter. He had few belongings, and he needed a blanket. But when he looked up how to get to the local mall, he found it too logistically difficult. “It was just beyond my level of tolerance,” he said. “I did not want to waste my mental energy on figuring out how to go from here to there.” Instead, he walked to a nearby CVS drugstore, bought 10 squares of fabric and a giant stapler, and stapled the squares together to make a blanket.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1628" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-scaled.jpg" alt="June Huh stands between bookshelves." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-scaled.jpg 2560w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-1720x1094.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-520x331.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-768x488.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-1536x977.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Library-2048x1302.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Huh in Princeton’s Lewis Science Library.</p>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>He lived off frozen pizza for months at a time because he didn’t want to deal with getting groceries and cooking. He just wanted to do math. He describes that period of his life as “almost monastic.” In fact, at the time, he really only spoke with another person — Mustaţă, his adviser — once a week.</p>
<p>Kim recalls visiting Huh when he was still in Illinois, and “after that, I really rethought our relationship,” she said. “Should I marry him? Because he [cannot] handle real-life skills, surviving skills.”</p>
<p>Yet marry him she did, in 2014. They moved to Princeton, where they both started work at the Institute for Advanced Study. It was Kim’s first time living in the U.S., and she felt uncomfortable taking care of certain tasks in English; she had to depend on Huh to get things done. “Let’s just say, she was disappointed,” he said.</p>
<p>Later that year, Kim gave birth to their first son, Dan. While in labor, she caught Huh doing math.</p>
<p>“My wife is a much more balanced person than I am,” he said. “Life has very many facets, and math is a very, very, very tiny part of it.”</p>
<p>“I’m a real worker,” Kim said. “He is a thinker.”</p>
<p>But, she added, Huh has improved drastically since then. As the couple raised Dan, “I learned how to live a more balanced life,” Huh said. “That was a transformative period.” He spends a lot of time with Dan — drawing with him, solving problems in intricate math workbooks that Dan creates for him, and taking him to the bookstore and other local spots. He even takes care of the logistical tasks that Kim asks him to do, albeit begrudgingly. “I still don’t like it,” he said, “but I mean, we cannot just live with stapled blankets.”</p>
<p>Now he’s even able to step away from mathematics. His mind no longer returns to working on problems when he’s in an idle state, and he’s able to take a break when something else requires him to.</p>
<p>“He’s a totally different person,” Kim said.</p>
<h2><strong>Heavy on Top</strong></h2>
<p>Regardless, some things haven’t changed. Huh can still muster only enough energy to work for a few hours each day. “Other people work one hour and just take a five-minute rest,” Kim said. “He is like, one hour do something else, and just focus for five minutes, 10 minutes.”</p>
<p>His search for beauty hasn’t changed either. And often he returns to questions about log concavity or similar concepts as a way to unearth that beauty.</p>
<figure>
    <p><img width="1664" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-scaled.jpg" alt="June Huh standing by a glass wall." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-scaled.jpg 1664w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-1118x1720.jpg 1118w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-338x520.jpg 338w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-768x1182.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-998x1536.jpg 998w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Hall-1331x2048.jpg 1331w" sizes="(max-width: 1664px) 100vw, 1664px">    </p>
            <figcaption>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </figcaption>
    </figure>

<p>For instance, he, Wang and other collaborators recently proved a fundamental problem about configurations of points, lines and planes called the Dowling-Wilson “top-heavy” conjecture. Consider a finite collection of points in the plane, where every pair of points is connected by a line. The mathematicians Paul Erdős and Nicolaas Govert de Bruijn showed that the number of lines must always be greater than or equal to the number of points (unless all the points are located on one line). Consider, for example, four points arranged at the corners of a square. Lines trace out the square and also connect opposite corners, adding up to six lines in total.</p>
<p>The top-heavy conjecture generalizes this idea. Instead of the plane, you’re given a set of points in some high-dimensional space. Consider all the lines that connect pairs of points, the planes spanned by sets of three points, the three-dimensional subspaces constructed from four points, and so on. Now think about a sequence built from these numbers: the number of points, the number of lines, the number of planes. Compare numbers in symmetric positions in that sequence (the first and last numbers, the second and penultimate numbers, and so on). The number corresponding to the higher-dimensional space will be at least as large — that is, the sequence is top-heavy. (This sequence is also conjectured to be log concave, but that has not yet been proved; so far, Huh and Wang have shown that the first half of the sequence is unimodal.)</p>
</div>
    <figure>
        <div>
                            <p><img src="https://www.quantamagazine.org/wp-content/uploads/2018/07/JH-2-TOP_HEAVY4_560-Mobile.svg" alt="" decoding="async"><img src="https://www.quantamagazine.org/wp-content/uploads/2018/07/JH-2-TOP_HEAVY4_1160-Desktop-1.svg" alt="" decoding="async">                </p>
                        </div>
        <figcaption>
    <div>
            <p>Merrill Sherman/Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Huh and Wang adapted ideas from Huh’s work on Rota’s conjecture, but in doing so they had to push his program further. Again, they were working with matroids, algebraic varieties and cohomology rings. But this time the algebraic varieties they had to find involved singularities, places where a space looks different when you zoom in on it than it does at other points. That made it much more complicated to <a href="https://projecteuclid.org/journals/acta-mathematica/volume-218/issue-2/Enumeration-of-points-lines-planes-etc/10.4310/ACTA.2017.v218.n2.a2.full">build the right spaces</a> and prove certain properties about their cohomology rings — and even more difficult to solve the case where they had to construct those rings <a href="https://arxiv.org/abs/2010.06088">straight from the matroids</a>, without algebraic varieties to guide them.</p>
<p>During the five years they spent solving this problem, Huh also started investigating a way to complete the break from geometry. So much of his work until then involved the arduous task of building the exact cohomology that a problem required. Moreover, once that cohomology is found, mathematicians still have to prove that it satisfies certain properties, which can also take years.</p>
</div>
    <figure>
        <div>
                            <p><img width="2000" height="1131" src="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Couch.jpg" alt="June Huh on a green couch." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Couch.jpg 2000w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Couch-1720x973.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Couch-520x294.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Couch-768x434.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2022/06/Huh_Couch-1536x869.jpg 1536w" sizes="(max-width: 2000px) 100vw, 2000px">                </p>
                        </div>
        <figcaption>
    <div>
            <p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>The new theory that he developed (along with the mathematician <a href="https://www.kth.se/profile/pbranden">Petter Brändén</a>) was able to bypass those methods entirely. It allowed them to <a href="https://annals.math.princeton.edu/2020/192-3/p04">solve a problem</a> called the strong Mason conjecture (which asks questions about the number of independent sets in matroids), and other mathematicians have already used it to re-prove Rota’s conjecture in a more straightforward way. But even more important, it opens the door to finding entirely new problems, hints at an even deeper explanation for why all these log concavity statements are true, and intersects with problems in theoretical computer science in intriguing ways that are just beginning to be explored.</p>
<h2><strong>Click of the Connection</strong></h2>
        
        
<p>For Huh, when he is working, there’s something almost subconscious going on. In fact, he usually can’t trace how or when his ideas come to him. He doesn’t have sudden flashes of insight. Instead, “at some point, you just realize, oh, I know this,” he said. Maybe last week, he didn’t understand something, but now, without any additional input, the pieces have clicked into place without his realizing it. He likens it to the way your mind can surprise you and create unexpected connections when you’re dreaming. “It’s just amazing what human minds are capable of,” he said. “And it’s nice to admit that we don’t know what’s going on.”</p>
<p>Perhaps this, too, speaks to the artist in him. He hopes to continue uncovering unexpected connections between different areas of math.</p>
<p>“He just follows the vision of this original program that he had … already as a graduate student,” Baker said. “It will be very interesting to see what the limits are.”</p>
<p>So far, Huh hasn’t hit them. And mathematicians are sure he’ll continue to make beautiful things.</p>
<p>When asked if he’d ever entertain the earlier version of his artist self and try writing poetry again, he shrugged. “Maybe. But I don’t know,” he said. “I’m very much into something else.”</p>
</div>
                
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI for Countries (135 pts)]]></title>
            <link>https://openai.com/global-affairs/openai-for-countries/</link>
            <guid>43920555</guid>
            <pubDate>Wed, 07 May 2025 21:05:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/global-affairs/openai-for-countries/">https://openai.com/global-affairs/openai-for-countries/</a>, See on <a href="https://news.ycombinator.com/item?id=43920555">Hacker News</a></p>
Couldn't get https://openai.com/global-affairs/openai-for-countries/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA['I paid for the whole GPU, I am going to use the whole GPU' (131 pts)]]></title>
            <link>https://modal.com/blog/gpu-utilization-guide</link>
            <guid>43920544</guid>
            <pubDate>Wed, 07 May 2025 21:04:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modal.com/blog/gpu-utilization-guide">https://modal.com/blog/gpu-utilization-guide</a>, See on <a href="https://news.ycombinator.com/item?id=43920544">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>'I paid for the whole GPU, I am going to use the whole GPU': A high-level guide to GPU utilization</p><div><!----><p><img src="https://modal-cdn.com/blog-gpu-utilization-whole-speedometer.webp" alt="A t-shirt that says 'I paid for the whole speedometer, I am going to use the whole speedometer'"> <!--[!--><!--]--><!----></p> <p><modal-img-caption>Typical attire of a GPU utilization maximizer.</modal-img-caption></p> <p>Graphics Processing Units, or GPUs, are the hottest mathematical co-processor since the <a rel="nofollow" href="https://old.reddit.com/r/chiptunes/comments/qc0zl5/why_did_fm_synthesis_take_so_long_to_take_off/hhemu2v/"><!----><!---->FM synthesis chips that shaped the sounds of the 1990s<!----></a><!---->.</p> <p>Like all co-processors, they are chosen when the performance of more flexible commodity hardware, like an x86 Central Processing Unit (CPU), is insufficient. GPUs are in particular <a href="https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor"><!----><!---->designed for problems<!----></a><!----> where CPUs cannot achieve the desired throughput of mathematical operations (in particular, matrix multiplications).</p> <p>But GPUs are not cheap: high performance can command a high price.</p> <p>Combined together, the high price, performance sensitivity, and throughput-orientation of GPU applications mean that a large number of engineers and technical leaders find themselves concerned with <em>GPU utilization</em> of some form or another — “we’re paying a lot, so we’d better be using what we’re paying for”.</p> <p>At Modal, we have our own GPU utilization challenges to solve and we help our users solve theirs. We’ve noticed that the term “GPU utilization” gets used to mean very different things by people solving problems at different parts of the stack. So we put together this article to share our framework for thinking about GPU utilization across the stack and the tips and tricks we’ve learned along the way.</p> <p>In particular, we’ll talk about three very different things that all get called “GPU utilization”:</p> <ul><li><a href="#what-is-gpu-allocation-utilization"><!----><!---->GPU Allocation Utilization<!----></a><!---->, the fraction of your GPUs that are running application code,</li> <li><a href="#what-is-gpu-kernel-utilization"><!----><!---->GPU Kernel Utilization<!----></a><!---->, the fraction of time your application is running code on GPUs, and</li> <li><a href="#what-is-model-flops-utilization-mfu"><!----><!---->Model FLOP/s Utilization<!----></a><!---->, the fraction of the GPUs’ theoretical arithmetic bandwidth your application is using to run models.</li></ul> <p>We’ll specifically focus on neural network inference workloads — neural networks because they are workload generating the most demand right now and inference because, unlike training, inference is a revenue center not a cost center. We’re betting on the revenue center.</p> <h2 id="what-is-utilization">What is utilization?</h2> <h3 id="utilization--output-achieved--capacity-paid-for">Utilization = Output achieved ÷ Capacity paid for</h3> <p><em>Utilization</em> relates the available capacity of a system to that system’s output.</p> <p>In throughput-oriented systems like GPU applications, the capacity paid for is often a <em>bandwidth</em> (e.g. the arithmetic bandwidth) and the output achieved is then a <em>throughput</em> (e.g. floating point operations per second, FLOP/s).</p> <p>Because it is a ratio, utilization is unitless. That means <strong>there are actually many GPU-related quantities you might call “GPU utilization”</strong>, leaving off the implicit units of the capacity and output. These different quantities range across orders of magnitude of time and across different organizational capacities (e.g. procurement, DevOps, and low-level performance engineering).</p> <h2 id="what-is-gpu-allocation-utilization">What is GPU Allocation Utilization?</h2> <h3 id="gpu-allocation-utilization--gpu-seconds-running-application-code--gpu-seconds-paid-for">GPU Allocation Utilization = GPU-seconds running application code ÷ GPU-seconds paid for</h3> <p>First, consider the number of GPUs that you have allocated — whether that is fixed GPU capacity on-premise in your basement (or data center) or it is rented capacity in a cloud data center (or many people’s basements) — across a period of time.</p> <p>We use the term <em>GPU Allocation Utilization</em> for the fraction of those GPU-seconds during which you were running application code. This is the highest-level notion of “GPU utilization”.</p> <p>There are two key limits on GPU Allocation Utilization: economic and developer-operational.</p> <p>The economic limits on GPU Allocation Utilization rise from combined technical and market limitations. Purchasing, commissioning, decomissioning, and selling GPUs cannot be done as quickly as the output demanded by the application changes (on the scale of seconds or minutes).</p> <p>Of course, as for other hardware we are blessed with highly-virtualized data center platforms (“clouds”) where we can virtually allocate and de-allocate GPU capacity. Even there, however, existing pricing models and demand that exceeds supply leave providers dictating terms, like multi-month or multi-year commitments, which limit achievable utilization for a given quality-of-service.</p> <div><p><h3>With a fixed, over-provisioned GPU allocation, utilization is low</h3> <!--[!--><!--]--></p>  <!--[--><!--]--></div> <p>Modal helps organizations solve this problem. We aggregate GPU demand across consumers and GPU supply across providers to improve GPU allocation efficiency.</p> <p>But GPU Allocation Utilization isn’t just about the GPU-seconds paid for, it’s about the GPU-seconds spent running application code.</p> <p>That’s where the DevOps limits on GPU Allocation Utilization come in. Even in a fully liquid GPU market, there is latency between the time at which a GPU is purchased or rented and the time at which the GPU is running useful work — time to configure operating systems, perform health checks, copy over application code, etc. Absent the ability to precisely predict future demand at timescales greater than that latency, this leads to reduced GPU Allocation Utilization, reduced quality-of-service, or both!</p> <div><p><h3>If allocation is slow, utilization and QoS suffer</h3> <!--[!--><!--]--></p>  <!--[--><!--]--></div> <p>To achieve high GPU Allocation Utilization and meet quality-of-service goals, allocation and spin-up to application code needs to be fast enough to respond to increases in demand.</p> <div><p><h3>With fast, automatic allocation, utilization and QoS can both be high</h3> <!--[!--><!--]--></p>  <!--[--><!--]--></div> <p>This is one of the core problems solved by Modal. We manage a large multi-cloud GPU fleet, benefitting from economies of scale to unlock better engineering solutions and concentration of measure to improve predictability of demand. We <a rel="nofollow" href="https://www.youtube.com/watch?v=3jJ1GhGkLY0"><!----><!---->built a custom container stack (in Rust btw)<!----></a><!----> to reduce the latency from non-application code and system configuration. And users’ workloads spin up faster because the serverless runtime for that container execution system frames user workloads in terms of application code, not virtual machine maintenance. That allows us to skip the repetitive, undifferentiated work required to create virtual machines. That unlocks novel engineering optimizations for us, like <a href="https://modal.com/blog/mem-snapshots"><!----><!---->memory snapshotting and restoration<!----></a><!---->, and it just-so-happens to make application engineering easier for our users.</p> <h2 id="what-level-of-gpu-allocation-utilization-can-i-expect-to-achieve">What level of GPU Allocation Utilization can I expect to achieve?</h2> <p>The existing numbers are sobering. According to the <a rel="nofollow" href="https://ai-infrastructure.org/the-state-of-ai-infrastructure-at-scale-2024/"><!----><!---->State of AI Infrastructure at Scale 2024 report<!----></a><!---->, the majority of organizations achieve less than 70% GPU Allocation Utilization <em>when running at peak demand</em> — to say nothing of aggregate utilization. This is true even of sophisticated players, like the former <a rel="nofollow" href="https://www.banana.dev/blog/sunset"><!----><!---->Banana serverless GPU platform<!----></a><!---->, which operated at an aggregate utilization of around 20%.</p> <p>With Modal, users can achieve GPU Allocation Utilization in excess of 90% — in aggregate, not just at peak.</p> <p>If that interests you, check out our <a href="https://modal.com/docs"><!----><!---->docs<!----></a><!----> and our <a href="https://modal.com/pricing"><!----><!---->pricing page<!----></a><!---->.</p> <p>If it doesn’t, read on for more about the software engineering required to get the most out of your GPUs — on Modal or elsewhere.</p> <h2 id="what-is-gpu-kernel-utilization">What is GPU Kernel Utilization?</h2> <h3 id="gpu-kernel-utilization--gpu-seconds-running-kernels--gpu-seconds-paid-for">GPU Kernel Utilization = GPU-seconds running kernels ÷ GPU-seconds paid for</h3> <p>Just because an allocated GPU is running application code doesn’t mean it is running code <em>on the GPU.</em> The term of art for “code that runs on the GPU” in the popular <a href="https://modal.com/gpu-glossary/device-software/cuda-programming-model"><!----><!---->CUDA programming model<!----></a><!----> for GPUs is “kernel”, and so we call the fraction of time we spend running code on the GPU the <em>GPU Kernel Utilization</em>.</p> <p>This utilization metric is reported by, among others, the beloved <a href="https://modal.com/gpu-glossary/host-software/nvidia-smi"><!----><code>nvidia-smi</code> command line tool<!----></a><!----> wrapping <a href="https://modal.com/gpu-glossary/host-software/nvml"><!----><!---->NVIDIA’s Management Library<!----></a><!----> for their GPU hardware, and so it is commonly checked and cited. We <a href="https://modal.com/docs/guide/gpu-metrics"><!----><!---->expose it to our users<!----></a><!----> under the name that library uses, “GPU utilization”. Note that this name can be slightly misleading, since this metric does not care whether the code we’re running on the GPU is exercising the hardware’s actual capacity.</p> <p>An application that is achieving low GPU Allocation Utilization is necessarily going to achieve low GPU Kernel Utilization, so long as you consider all GPU-seconds being paid for: a unit not running application code can’t run kernels.</p> <p>Why else might you achieve low GPU Kernel Utilization? In particular, what patterns will show up as low kernel utilization per GPU?</p> <p>First, there might be lots of work to do that supports your application but doesn’t use the GPU, like moving input or output data via network or disk, downloading the many gigabytes of weights of a foundation model, or writing logs.</p> <p>These tasks can be sped up by usual means — judicious application of lazy and eager loading, parallelization, increased bandwidth for non-GPU components like networks, and deleting more code <a rel="nofollow" href="https://martinfowler.com/bliki/Yagni.html"><!----><!---->YAGN<!----></a><!---->.</p> <p>Second, the CPU might not be providing work to the GPU quickly enough. A typical GPU-accelerated program is, like a high-performance network application, a dance of concurrency between the CPU executing logic about what work must be done and specialized, but dumb, hardware that can actually do the work. For example, when multiplying two matrices, the popular PyTorch library needs to determine the shapes and types of those two matrices and then lookup the appropriate kernel — somewhat akin to a JIT database query optimizer selecting a physical operator mid-execution. If you are unable to complete this work before the GPU finishes its previous task, the GPU will idle. We’ll call this class of issue “host overhead”.</p> <p>Often, resolving host overhead is a matter of re-writing the host logic — preventing slow host work (like logging in Python) from blocking the host work that drives the GPU. But at the scale of milliseconds per task step, Python starts to become incapable of keeping up, and at the scale of microseconds per task step, the latency required to schedule kernels onto the GPU via <a href="https://modal.com/gpu-glossary/host-software/cuda-runtime-api"><!----><!---->the CUDA C++ APIs and driver<!----></a><!----> begins to bottleneck.</p> <p>In both cases, there are two basic optimizations. First, multiple kernels can be launched at once <a rel="nofollow" href="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/"><!----><!---->using CUDA Graphs<!----></a><!---->, which essentially convert a sequence of kernel launches into a DAG that only needs to be launched once. Second, the application can aggregate more work for the GPU to complete for a given unit of host work — for example by <a href="https://modal.com/docs/guide/dynamic-batching"><!----><!---->batching<!----></a><!----> requests together — to improve utilization with a possible penalty to latency.</p> <p>Code regions with low GPU Kernel Utilization can be identified from application traces, like those produced by the <a href="https://modal.com/docs/examples/torch_profiling"><!----><!---->PyTorch Profiler<!----></a><!---->. Specifically, any period of time where all CUDA streams are empty is a period of zero GPU Kernel Utilization, and so applications with low GPU Kernel Utilization have largely empty CUDA streams in their traces, like the one below. These periods of quiescence need to be correlated to activity on the host to determine which parts of the application code are leading to the bottleneck. GPU application profilers and trace viewers generally support this, e.g. by showing kernel launch dependencies, like the arrow in the trace below.</p> <p><img src="https://modal-public-assets.s3.amazonaws.com/tmpx_2c9bl5_c5aa7ab0.webp" alt="A trace of a PyTorch application with low GPU Kernel Utilization"> <!--[!--><!--]--><!----></p> <p><modal-img-caption>In traces of GPU applications, periods where no kernels are running appear as empty strips in the timelines of CUDA streams (e.g. Stream 7 7 in the trace above). For details, see <a href="https://modal.com/docs/examples/torch_profiling"><!----><!---->our documentation<!----></a><!---->.</modal-img-caption></p> <h2 id="what-level-of-gpu-kernel-utilization-can-i-hope-to-achieve">What level of GPU Kernel Utilization can I hope to achieve?</h2> <p>GPU Kernel Utilization is the closest metric in this article to the better-known CPU utilization. CPU utilization tracks the fraction of CPU cycles during which instructions were being executed on behalf of your program (as opposed to the CPU idling or running other programs).</p> <p>However, for CPU utilization, hitting 90%+ is often bad, even a trigger for alerts. But we want to and can achieve that level of GPU Kernel Utilization!</p> <p>Fundamentally, this is downstream of the greater predictability of many GPU applications. Running a transactional database replica at 90% CPU utilization baseline risks degraded quality-of-service if query patterns or quantity change. Typical GPU applications have much less variability — for a database analogue, imagine repeatedly running only one basic sequential scan aggregation query, but with slightly different parameters each time — and so have more controllable quality-of-service.</p> <h2 id="what-is-model-flops-utilization-mfu">What is Model FLOP/s Utilization (MFU)?</h2> <h3 id="model-flops-utilization--model-flops-throughput-achieved--flops-bandwidth-paid-for">Model FLOP/s Utilization = Model FLOP/s throughput achieved ÷ FLOP/s bandwidth paid for</h3> <p>At some galaxy-brained, CEO-math level, expenditures on GPUs are really expenditures on floating point operation bandwidth, and so the deepest and most fundamental utilization metric to measure is the ratio of that bandwidth to the throughput achieved.</p> <p>This metric is known as <em>MFU</em>, which either means “Maximum” or “Model” FLOP/s Utilization, depending on who you ask. We go with “Model”, since it’s more common.</p> <p>Instances that aren’t running application code or that aren’t running GPU kernels cannot achieve a high MFU, so low GPU Allocation Utilization or low GPU Kernel Utilization imply low Model FLOP/s Utilization.</p> <p>However, high utilization at these more abstract levels does not imply high MFU.</p> <p>First, as an implementation detail, communication between GPUs is frequently implemented via GPU kernels. This communication, like most communication in distributed systems, is subject to faults (hardware fault, programmer fault, <a rel="nofollow" href="https://slate.com/technology/2014/08/shark-attacks-threaten-google-s-undersea-internet-cables-video.html"><!----><!---->shark attack fault<!----></a><!---->), which frequently manifest as deadlock. From the perspective of GPU Kernel Utilization, a system that is deadlocked in the middle of running a communication kernel is fully utilized (!), but it is completing no useful work. We like to catch this particular issue by monitoring <a href="https://modal.com/docs/guide/gpu-metrics"><!----><!---->GPU power draw and heat<!----></a><!---->. More generally, optimizing communication is critical for achieving high MFU, especially for workloads that spread a single task across multiple nodes.</p> <p>Second, floating point computation is just one of the things a GPU must do to complete a task. The most important other task is moving data. Computation can only occur on data stored inside of the <a href="https://modal.com/gpu-glossary/device-hardware/register-file"><!----><!---->register file<!----></a><!----> of the GPU’s <a href="https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor"><!----><!---->streaming multiprocessors<!----></a><!---->, which each store less than a megabyte, while foundation models are measured in gigabytes. The data to which a computation applies must generally be moved from a slower, larger area of the <a href="https://modal.com/gpu-glossary/device-software/memory-hierarchy"><!----><!---->memory hierarchy<!----></a><!---->. The <a href="https://modal.com/gpu-glossary/device-hardware/gpu-ram"><!----><!---->bandwidth of this memory<!----></a><!----> is generally many times lower than the device’s FLOP/s bandwidth, especially in recent generations. The ratio of an algorithm’s FLOP/s throughput to its byte/s throughput is called the arithmetic intensity.</p> <p>Bottlenecking on memory is a particular challenge in latency-sensitive foundation model inference workloads, where the arithmetic intensity is low (perhaps a few FLOPs per byte). Besides algorithmic rewrites to increase arithmetic intensity, like <a rel="nofollow" href="https://arxiv.org/abs/2205.14135"><!----><!---->the online softmax in Flash Attention<!----></a><!---->, the primary generic strategy is <a href="https://modal.com/docs/guide/dynamic-batching"><!----><!---->batching<!----></a><!----> more work together, which increases FLOPs executed more than memory bytes moved for most neural network inference workloads, but generally adds per-task latency.</p> <p>Finally, GPU kernels must be carefully written to achieve high MFU. <a rel="nofollow" href="https://siboehm.com/articles/22/CUDA-MMM"><!----><!---->This public worklog by Si Boehm<!----></a><!----> gives a flavor for the effort required to reach state-of-the-art for a single kernel. Even that worklog stops short of truly maximizing MFU, since it tackles a problem that can’t make use of the fastest elements of contemporary GPUs, the <a href="https://modal.com/gpu-glossary/device-hardware/tensor-core"><!----><!---->Tensor Cores<!----></a><!---->, and writing kernels that can saturate Tensor Cores is even more challenging — see <a rel="nofollow" href="https://cudaforfun.substack.com/p/outperforming-cublas-on-h100-a-worklog"><!----><!---->this worklog from Pranjal Shankhdhar<!----></a><!---->. For this reason, most teams use high-quality open source kernels through libraries like CuBLAS or frameworks like PyTorch and vLLM.</p> <p>The achieved FLOP/s and memory throughput of a GPU application can be monitored using the <a rel="nofollow" href="https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/feature-overview.html#profiling-metrics"><!----><!---->NVIDIA Data Center GPU Management tool<!----></a><!---->, <code>dcgm</code>. The metrics prefixed with <code>DCGM_FI_PROF</code> are generally relevant. In particular, the <code>DCGM_FI_PROF_DRAM_ACTIVE</code> metric measures the utilization of the DRAM-to-SRAM memory bandwidth. The <code>DCGM_FI_PROF_PIPE_TENSOR_ACTIVE</code> metric measures the utilization of the Tensor Cores that provide the maximum FLOP/s bandwidth. This isn’t identical to MFU for subtle reasons covered well in Stas Bekman’s guide <a rel="nofollow" href="https://github.com/stas00/ml-engineering/blob/master/training/performance/README.md#mfu-vs-hfu"><!----><!---->here<!----></a><!---->.</p> <h2 id="what-level-of-model-flops-utilization-can-i-hope-to-achieve">What level of Model FLOP/s Utilization can I hope to achieve?</h2> <p>First, let’s note that measuring Model FLOP/s Utilization is tricky. The theoretical bandwidth can be read from manufacturer datasheets — but watch for asterisks like “with sparsity”. The achieved model throughput, on the other hand, can be hard to measure, in particular since some FLOPs might be spent on other computations, like activation recomputation in training. For that reason, it is often done based on pen-and-paper analysis of the algorithm and with approximate, “napkin” math.</p> <p>The state-of-the-art for MFU in training is achieved by the foundation model teams at leading organizations like OpenAI, Google, and Meta. Of these, Meta is the most open and reports an MFU of 38 - 41% when training <a rel="nofollow" href="https://arxiv.org/abs/2407.21783"><!----><!---->the LLaMA 3 405B model<!----></a><!---->. The more recent DeepSeek-v3 training run by DeepSeek achieved around 20-30% MFU (there’s no official number) <a rel="nofollow" href="https://semianalysis.com/2025/01/31/deepseek-debates/"><!----><!---->using GPUs with tighter communication bottlenecks<!----></a><!---->.</p> <p>Much of the shortfall is due to the need for inter-node communication in large training jobs, which creates bandwidth constraints that aren’t present in inference applications. For inference workloads, MFU might reach higher, closer to the <a rel="nofollow" href="https://github.com/stas00/ml-engineering/tree/master/compute/accelerator#maximum-achievable-flops"><!----><!---->70% - 80% MFU achieved by raw matrix multiplications<!----></a><!---->, but we aren’t aware of any published results from large-scale deployments. Let us know if we missed them!</p> <p>For context, it’s also helpful to consider the equivalent of MFU for a job running on a CPU. For concreteness, consider the <a rel="nofollow" href="https://github.com/gunnarmorling/1brc"><!----><!---->One Billion Row Challenge<!----></a><!---->, which led teams around the world to competitively optimize a large-scale aggregation problem on CPUs. This problem requires three floating point operations per row on one billion rows, and so has a total FLOP count of 3 billion. The leading results finished in about one second, and so achieved a FLOP/s throughput of about 3 billion. If we assume that the hardware used for the challenge, eight cores out of a <a rel="nofollow" href="https://www.hetzner.com/dedicated-rootserver/ax161"><!----><!---->32 core AMD EPYC 7502P<!----></a><!----> machine which can run at 3.35 GHz, is capable of issuing one FLOP per cycle, then the FLOP/s bandwidth is ~26 billion, for an MFU of ~10%. However, that CPU has <a rel="nofollow" href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions"><!----><!---->AVX2 SIMD vector instructions<!----></a><!----> with a lane width of 256 and so, assuming it can issue 16 FLOPs/cycle per core, the FLOP/s bandwidth is actually ~420 billion, leading to an MFU of under 1%.</p> <h2 id="how-can-i-improve-my-gpu-utilization">How can I improve my GPU utilization?</h2> <p>If you’re not using <a href="https://modal.com/"><!----><!---->Modal<!----></a><!---->, that’s a great place to start! Especially for GPU Allocation Utilization.</p> <p>Besides that, we recommend that if you want to improve your GPU utilization, you dive deeper into GPU-based computing.</p> <p>We wrote a <a href="https://modal.com/gpu-glossary"><!----><!---->GPU Glossary<!----></a><!----> to collect together our definitions of the most important terms in one place, complete with links to some of our favorite resources for learning more. Try starting there!</p> <p>Among those resources, a few stand out, like <a rel="nofollow" href="https://www.youtube.com/watch?v=139UPjoq7Kw&amp;t=1236s"><!----><!---->this talk by Horace He<!----></a><!---->, of the PyTorch team, and <a rel="nofollow" href="https://blog.codingconfessions.com/p/gpu-computing"><!----><!---->this dense blog post<!----></a><!----> by Abhinav Upadhyay of Coding Confessions. We also highly recommend the <a rel="nofollow" href="https://github.com/stas00/ml-engineering/"><!----><!---->ML Engineering Open Book<!----></a><!----> by Stas Bekman for deep dives and useful snippets all across the stack.</p> <p><em>We’d like to thank <a rel="nofollow" href="https://x.com/marksaroufim"><!----><!---->Mark Saroufim<!----></a><!----> of <a rel="nofollow" href="https://x.com/pytorch"><!----><!---->PyTorch<!----></a><!----> &amp; the <a rel="nofollow" href="https://x.com/GPU_MODE"><!----><!---->GPU_MODE Discord<!----></a><!----> (join it!) and <a rel="nofollow" href="https://x.com/erikdunteman"><!----><!---->Erik Dunteman<!----></a><!----> of <a rel="nofollow" href="https://pig.dev/"><!----><!---->Pig<!----></a><!----> for comments on a draft of this post.</em></p><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing Web Search on the Anthropic API (218 pts)]]></title>
            <link>https://www.anthropic.com/news/web-search-api</link>
            <guid>43920188</guid>
            <pubDate>Wed, 07 May 2025 20:18:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/web-search-api">https://www.anthropic.com/news/web-search-api</a>, See on <a href="https://news.ycombinator.com/item?id=43920188">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Today, we're introducing web search on the Anthropic API—a new tool that gives Claude access to current information from across the web. With web search enabled, developers can build Claude-powered applications and agents that deliver up-to-date insights.</p><h2 id="power-ai-agents-with-the-latest-information-from-the-web">Power AI agents with the latest information from the web</h2><p>Developers can now augment Claude’s comprehensive knowledge with current, real-world data by enabling the web search tool when making requests to the Messages API.</p><p>When Claude receives a request that would benefit from up-to-date information or specialized knowledge, it uses its reasoning capabilities to determine whether the web search tool would help provide a more accurate response. If searching the web would be beneficial, Claude generates a targeted search query, retrieves relevant results, analyzes them for key information, and provides a comprehensive answer with citations back to the source material.</p><p>Claude can also operate agentically and conduct multiple progressive searches, using earlier results to inform subsequent queries in order to do light research and generate a more comprehensive answer. Developers can control this by adjusting the <em>max_uses</em> parameter<em>.</em> Behind the scenes, Claude may also refine its queries to deliver a more accurate response.</p><p>With web search, developers can now build AI solutions that tap into current information without needing to manage their own web search infrastructure.</p><h2 id="use-cases">Use cases</h2><p>Web search enables Claude to power a wide range of use cases that benefit from real-time data and specialized knowledge across various industries. Use cases include:</p><ul><li><strong>Financial services:</strong> Build AI agents that analyze real-time stock prices, market trends, and regulatory updates.</li><li><strong>Legal research:</strong> Create tools that access recent court decisions, regulatory changes, and legal news.</li><li><strong>Developer tools:</strong> Enable Claude to reference the latest API documentation, GitHub releases, and technology updates.</li><li><strong>Productivity: </strong>Build agents that incorporate the latest company reports, competitive intelligence, or industry research.</li></ul><h2 id="build-with-trust-and-control">Build with trust and control</h2><p>Every web-sourced response includes citations to source materials, enabling users to verify information directly. This is particularly valuable for sensitive use cases that require accuracy and accountability.</p><div><figure><img alt="A screenshot of the UX showing blocked domains." loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fb57f878e8735a67a64c1463c8248f0f4b0797952-3840x2160.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fb57f878e8735a67a64c1463c8248f0f4b0797952-3840x2160.png&amp;w=3840&amp;q=75"></figure></div><p>Organizations can maintain additional control through the following admin settings:</p><ul><li><strong>Domain allow lists</strong>: Specify which domains Claude can search and retrieve information from, ensuring that results only come from approved sources.</li><li><strong>Domain block lists</strong>: Prevent Claude from accessing certain domains that may contain sensitive, competitive, or inappropriate content for your organization.</li><li><strong>Organization-level management</strong>: Administrators can allow or prohibit web search use at the organization level.</li></ul><h2 id="enhance-claude-code-with-web-search">Enhance Claude Code with web search</h2><p>Web search is also now available in Claude Code, adding the latest information from the web to development workflows.</p><p>With web search enabled, Claude Code can access current API documentation, technical articles, and other information on development tools and libraries. This is particularly valuable when working with new or rapidly evolving frameworks, troubleshooting obscure errors, or implementing features that require version-specific API references.</p><h2 id="customer-spotlight-poe">Customer Spotlight: Poe</h2><p>Quora is bringing web search to its AI platform, Poe.</p><p>“Anthropic's web search tool is a welcome addition to the Poe platform. It is cost effective and delivers search results with impressive speed, which will benefit people who need access to real-time information while using Claude models on Poe,” said Spencer Chan, Head of Poe Product, Quora.</p><h2 id="customer-spotlight-adaptiveai">Customer Spotlight: Adaptive.ai</h2><p>Adaptive is an AI tool for consumers to create end-to-end apps.</p><p>“Anthropic’s web search delivers consistently thorough results that have outperformed other tools we’ve tested. The depth and accuracy of Claude’s responses and its ability to function as a research agent will make a significant difference in how effectively we enable our customers to build web-enabled products,” said Dennis Xu, Co-founder, Adaptive.</p><h2 id="getting-started">Getting started</h2><p>Web search is now available on the Anthropic API for Claude 3.7 Sonnet, the upgraded Claude 3.5 Sonnet, and Claude 3.5 Haiku at $10 per 1,000 searches plus standard token costs.</p><p>To get started, enable the web search tool in your API requests. Explore our <a href="https://docs.anthropic.com/en/docs/build-with-claude/tool-use/web-search-tool">documentation</a> and <a href="https://www.anthropic.com/pricing#api">pricing</a> to learn more.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mac Themes Garden (159 pts)]]></title>
            <link>https://damien.zone/introducing-mac-themes-garden/</link>
            <guid>43919868</guid>
            <pubDate>Wed, 07 May 2025 19:44:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://damien.zone/introducing-mac-themes-garden/">https://damien.zone/introducing-mac-themes-garden/</a>, See on <a href="https://news.ycombinator.com/item?id=43919868">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
    <figure data-type="image"><a href="https://damien.zone/img/projects/macthemes-garden.webp?v=9d6b8774b4bb"><img src="https://damien.zone/img/projects/macthemes-garden.webp?v=9d6b8774b4bb" alt="Mac Themes Garden" loading="lazy" decoding="async"></a></figure>
<h2 id="the-short-version">The short version</h2>
<p>I've "launched" the <a href="https://macthemes.garden/">Mac Themes Garden</a>! It is a website showcasing more than 3,000 (and counting) Kaleidoscope from the Classic Mac era, ready to be seen, downloaded and explored! Check it out! Oh, and there also is an <a href="https://macthemes.garden/feed.xml">RSS feed</a> you can subscribe to see themes as they are added/updated!</p>
<p>And yes, there is a button that you can include on your website! <a href="https://macthemes.garden/about#buttons">Grab it here</a>! Isn't it cute?</p>
<center>
<a href="https://macthemes.garden/" title="Mac Themes Garden"><img src="https://macthemes.garden/buttons/88x31_macthemes.garden.png" alt="Mac Themes Garden"></a>
</center>
<p><strong>Now, for the yapping.</strong> Note: if you're reading this in an RSS reader, you might want to open the article on my website directly as it contains a bunch of CSS demos and those won't work well in an RSS reader.</p>
<h2 id="some-background">Some background</h2>
<p>If you know me from Online, you may know that I've been running the Mac Themes Bot on <a href="https://bsky.app/profile/macthemes.garden">Bluesky</a>/<a href="https://social.erambert.me/@macthemes">Mastodon</a>/<a href="https://cohost.org/macthemes">Cohost</a> for a few years now.</p>
<p>The idea of the bot was simple, showcasing custom themes from the Mac OS X and Classic Mac eras, on the rate of one an hour. Since I was inspired by <a href="https://web.archive.org/web/20191021204432/https://twitter.com/kaleidoscopemac">@kaleidoscopemac</a> on Twitter, I only started showcasing themes made for <a href="https://en.wikipedia.org/wiki/Unsanity">ShapeShifter by Unsanity</a>. A while later, that Twitter account got suspended.<br>
Since I already had the <a href="https://github.com/eramdam/shapeshifter-themes">tooling in place</a> to scrape and post themes for OS X, I figured I could add themes for Kaleidoscope (OS 7/8/9) into the mix. After trying (and failing) to get the original dataset from the author of the bot, I set on to scrape the Wayback Machine for records of the <a href="https://web.archive.org/web/20000823055322fw_/http://www.kaleidoscope.net/schemes/completelisting.shtml">Kaleidoscope Scheme Archive</a>.<br>
From that point on, my bot would post themes every hour, with a classic theme on even hours and an OS X theme on odd hours<sup><a href="#fn1" id="fnref1">[1]</a></sup>.</p>
<p>The years passed, the bot carried on, made me and a bunch of other people smile on the various websites where I would run it. The <a href="https://cohost.org/macthemes">Cohost</a> incarnation in particular was really special because Cohost was a special site, but also it was full of nerds (complimentary) and people would go nuts for the random gems in there.</p>
<p>Around maybe early 2023, I grew frustrated of the fact that the only images I had for the Kaleidoscope <s>themes</s> schemes were those <a href="https://github.com/eramdam/shapeshifter-themes/blob/master/assets/!.emperor.gif">tiny .gif files</a> from the late 90s.</p>
<h3 id="recording-25-year-old-schemes">"Recording" 25-year-old schemes</h3>
<p>So I did the reasonable thing: set up a terribly manual process to take screenshots and record the author information of the <a href="https://archive.org/details/kaleidoscope-scheme-archive">~4,000 themes available</a>, with the intention of making a website showcasing everything once I was done.</p>
<p>Without going into details (which you can read <a href="https://web.archive.org/web/20250106111834/https://cohost.org/eramdam/post/5246796-replying-to-this-com">here</a>), the process looks like this:</p>
<ul>
<li>Open my Mac OS 9 VM in <a href="https://getutm.app/">UTM.app</a> (QEMU frontend)</li>
<li>Go through the folder of schemes</li>
<li>Select a given scheme, apply it</li>
<li>Take 3 screenshots:
<ol>
<li>One of the scheme's about box.</li>
<li>One of the scheme being used in the Finder/regular desktop situation.</li>
<li>And finally, a screenshot of the application <a href="http://www.shurey.com/Soft/Share/KSA/index.html">KSA Sampler</a> in order to mimic the original screenshots from the Kaleidoscope Scheme Archive. That specific screenshot would get pasted into Photoshop to be cropped/trimmed of its opaque background using Photoshop Actions.</li>
</ol>
</li>
<li>Write down the name, author and release year of the scheme</li>
<li>Find the corresponding .sit archive file</li>
<li>Record all of this in a record inside an Airtable database.</li>
</ul>
<p>Here's how it looks inside Airtable:</p>
<figure data-type="image"><a href="https://damien.zone/img/blog/airtable-macthemes.png?v=84922ebd65b7"><img src="https://damien.zone/img/blog/airtable-macthemes.png?v=84922ebd65b7" alt="6 rows inside an Airtable database, showing screenshots and scheme information" loading="lazy" decoding="async"></a><figcaption>6 rows inside an Airtable database, showing screenshots and scheme informations</figcaption></figure>
<p>On a good day, I can maybe record, I don't know, a dozen or so themes an hour.</p>
<blockquote>
<p>But Damien, why didn't you automate this process?!</p>
</blockquote>
<p>I'm glad you asked! I tried! But I, at least until now, could not find a good way to reliably perform the actions I need to take. And that's not even touching on the fact that sometimes a scheme doesn't have any author or year information! Sometimes the author inside the Kaleidoscope scheme file is completely wrong, and the actual author is written in a separate "Read me" file. Sometimes there's barely any information to go by, sometimes the scheme is buggy and would crash my VM.</p>
<p>At that point, the only automations I have are:</p>
<ul>
<li>a <a href="https://www.keyboardmaestro.com/main/">Keyboard Maestro</a> <a href="https://damien.zone/img/blog/keyboard-mastro-macro.png?v=d9a26f888bf7">macro</a> that calls the <code>qemu-monitor</code> for the running VM, takes a lossless screenshot and puts it into my clipboard, ready to be pasted</li>
<li>Photoshop actions to:
<ul>
<li>create a document from the clipboard</li>
<li>after cropping, remove all pixels of a given color in a document and trim it to remove extra alpha pixels (for the KSA Sampler screenshots above)</li>
</ul>
</li>
<li>A <a href="https://macintoshgarden.org/forum/startly-quickeys-5">Quickeys</a> shortcut to call "Hide Others" inside of Mac OS 9. Turns out this action didn't have a keyboard shortcut until Mac OS X? Didn't know that!</li>
</ul>
<p>Beyond that, I'm afraid it's all manual since I want to record data that isn't straight forwardly extracted by just looking at files 😔.</p>
<p><em>At any rate</em>, I was and thought "I'll finish recording all these schemes, <strong>and then</strong> I'll make the website"...</p>
<p>Dear reader, I am not done. By my own estimations, I am maybe halfway done. I do not know when I will be fully done, but my good friend <a href="https://wavebeem.com/">Sage</a> pushed me to: make the damn website already.</p>
<p>And they were right, I should have made the website earlier! It was a fun and challenging distraction, and <em>fuck me</em> I could use distractions these days.</p>
<h2 id="making-da-website">Making Da Website</h2>
<p>So, around January of this year, I've started work on the website.</p>
<p>The first step was to interface with the <a href="https://airtable.com/">Airtable</a> API in order to download the data from my database and store all the assets into a folder in my repository.
<a href="https://github.com/eramdam/macthemes.garden/blob/main/scripts/airtable.ts">Nothing too crazy</a>, but had to be done.<br>
I did need to be careful around caching and not re-downloading images I already had on disk. We're talking about like, ~2,500 rows each containing 3 images, and you don't want to re-download 7,500 PNG files every time the script needs to run.</p>
<p>With the data on hand, the real fun began.</p>
<figure data-type="image"><a href="https://damien.zone/img/blog/macthemes-garden-v0.png?v=0de864f596fc"><img src="https://damien.zone/img/blog/macthemes-garden-v0.png?v=0de864f596fc" alt="Early version of the Mac Themes Garden site" loading="lazy" decoding="async"></a></figure>
<p>The proof-of-concept was using Eleventy which I chose purely because I had just finished remaking my website (you're reading it now!) using it, so I figured it would be a good fit because of its simplicity and speed.</p>
<p>And it might have been if it wasn't for <a href="https://www.11ty.dev/docs/languages/webc/">WebC</a> being so wonky. You see, I knew I wanted to have multiple OS9-like "windows" in the website's layout. So I figured that, surely, WebC could let me make a "component" and make a UI that way and, I swear to god, I could not make it work that way.<br>
It seems WebC is purely for <strong>W</strong>eb <strong>C</strong>omponents and nothing else, which itself is fine, but that wasn't going to cut it.<br>
I briefly experimented with a <a href="https://www.11ty.dev/docs/languages/liquid/#paired-shortcode">paired short code</a>, but I wasn't going to write HTML inside a JavaScript string. I wanted to have fun on this project.</p>
<h3 id="the-nitty-gritty">The nitty-gritty</h3>
<p>So I switched to <a href="https://astro.build/">Astro</a> whose concept of <a href="https://docs.astro.build/en/basics/astro-components/">components</a> was closer to what I wanted to do here, and I already knew how to use it because <a href="https://erambert.me/">erambert.me</a> uses it.</p>
<p>I will not do a play-by-play of the making of the website, because once the ball was rolling, most of my time was spent playing with UI ideas and using Astro's <a href="https://docs.astro.build/en/guides/content-collections/">content collections</a> such that building the whole website as a bunch of static pages didn't take forever.<br>
Don't get me wrong, Astro is plenty fast as it is, not as fast as Eleventy but still fast!</p>
<p>The "problem" is that I am playing with big numbers. Let's think about them:</p>
<ul>
<li>3,942 themes</li>
<li>868 authors</li>
</ul>
<p>As it is, if we assume one page per scheme and one page per author (which would list all the themes for that author), we arrive at: <strong>3,942 + 868 = 4,810 pages</strong>. Which isn't terrible, but that's already a lot of pages, and we're not doing anything fancy with it.</p>
<p>Let's start being fancy, let's add pagination and let's say we want to show 51 themes per page. Where:</p>
<ul>
<li><em>T</em> is the number of themes in the set (3,942)</li>
<li><em>A</em> is the number of authors in the set (868)</li>
<li><em>P</em> is the page size (51)</li>
</ul>
<pre><code><span>const</span> totalPages <span>=</span> <span>(</span><span>T</span> <span>*</span> <span>A</span><span>)</span> <span>+</span> Math<span>.</span><span>ceil</span><span>(</span><span>T</span> <span>/</span> <span>P</span><span>)</span>
<span>// 4,888 pages</span></code></pre>
<p>That's <strong>4,888 pages</strong>! Except I then wanted to add some fancy things like an authors page <em>(A / 26 (for each letter in the alphabet))</em>, that's another ~33 pages. This gets us close to 5,000 pages. Which is fine, but it means every page better be really quick to generate in order for the build time to not balloon out-of-control.</p>
<p>That's where I had to be careful. I wanted the author pages to show all the themes made by a given author, which I naively implemented like this:</p>
<pre><code><span>export</span> <span>const</span> getStaticPaths <span>=</span> <span>(</span><span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> authors <span>=</span> <span>await</span> <span>getCollection</span><span>(</span><span>"authors"</span><span>)</span><span>;</span>

  <span>return</span> authors<span>.</span><span>map</span><span>(</span><span>(</span>a<span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      props<span>:</span> <span>{</span> author<span>:</span> a <span>}</span><span>,</span>
      params<span>:</span> <span>{</span>
        author<span>:</span> a<span>.</span>data<span>.</span>slug<span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span> satisfies GetStaticPaths<span>;</span>
<span>const</span> <span>{</span> author <span>}</span> <span>=</span> Astro<span>.</span>props<span>;</span>
<span>const</span> themesByAuthor <span>=</span> <span>(</span><span>await</span> <span>getCollection</span><span>(</span><span>"themes"</span><span>)</span><span>)</span><span>.</span><span>filter</span><span>(</span><span>(</span>t<span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> t<span>.</span>data<span>.</span>authors<span>.</span><span>some</span><span>(</span><span>(</span>a<span>)</span> <span>=&gt;</span> a<span>.</span>id <span>===</span> author<span>.</span>id<span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>Sure, this seems fine as it is. After all, it "only" takes ~30ms to run in development! But running our math from earlier, this will run for every single author page. Suddenly we're looking at:</p>
<p><strong>30ms × 868 = 26,040 ms (26s)</strong> 😱!</p>
<p>After all, we're iterating over the 3,942 schemes 868 times, this isn't great!</p>
<p>What's the fix then?</p>
<p>As it is almost always the case when it comes to performance: doing less work and only doing the hard work once! I took advantage of <a href="https://docs.astro.build/en/guides/content-collections/#defining-collection-references">Astro's collection references</a>. I first declare a reference for authors inside my <code>themes</code> schema:</p>
<pre><code>const themes = defineCollection({
<span><span> </span> loader<span>:</span> themesLoader<span>,</span>
<span> </span> schema<span>:</span> z<span>.</span><span>object</span><span>(</span><span>{</span>
<span> </span>   name<span>:</span> z<span>.</span><span>string</span><span>(</span><span>)</span><span>,</span>
</span><span><span>+</span>   authors<span>:</span> z<span>.</span><span>array</span><span>(</span><span>reference</span><span>(</span><span>"authors"</span><span>)</span><span>)</span><span>,</span>
</span><span><span> </span>   year<span>:</span> z<span>.</span><span>string</span><span>(</span><span>)</span><span>.</span><span>optional</span><span>(</span><span>)</span><span>,</span>
<span> </span>   mainThumbnail<span>:</span> z<span>.</span><span>string</span><span>(</span><span>)</span><span>,</span>
<span> </span>   thumbnails<span>:</span> z<span>.</span><span>array</span><span>(</span>z<span>.</span><span>string</span><span>(</span><span>)</span><span>)</span><span>,</span>
<span> </span>   archiveFile<span>:</span> z<span>.</span><span>string</span><span>(</span><span>)</span><span>,</span>
<span> </span>   <span>// ...</span>
<span> </span> <span>}</span><span>)</span><span>,</span>
</span>});</code></pre>
<p>Which mean that I could simply call the <a href="https://docs.astro.build/en/reference/modules/astro-content/#getentries">getEntries</a> method to get the authors of a given theme.</p>
<pre><code><span>export</span> <span>const</span> getStaticPaths <span>=</span> <span>(</span><span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> authors <span>=</span> <span>await</span> <span>getCollection</span><span>(</span><span>"authors"</span><span>)</span><span>;</span>

  <span>return</span> authors<span>.</span><span>map</span><span>(</span><span>(</span>a<span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      props<span>:</span> <span>{</span> author<span>:</span> a <span>}</span><span>,</span>
      params<span>:</span> <span>{</span>
        author<span>:</span> a<span>.</span>data<span>.</span>slug<span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span> satisfies GetStaticPaths<span>;</span>
<span>const</span> <span>{</span> author <span>}</span> <span>=</span> Astro<span>.</span>props<span>;</span>
<span>const</span> themesByAuthor <span>=</span> <span>await</span> <span>getEntries</span><span>(</span>author<span>.</span>data<span>.</span>themes<span>)</span><span>;</span></code></pre>
<p>Which, depending on the number of themes, takes ~10ms <em>at most</em>, for most pages it takes less than 5ms! That is much better.</p>
<p>By applying this technique, I managed to keep the build time of the site under control and Astro builds almost 5,000 pages with various queries between each other in less than 16s!</p>
<figure data-type="image"><a href="https://damien.zone/img/blog/macthemes-build-time.png?v=0cd08b11b896"><img src="https://damien.zone/img/blog/macthemes-build-time.png?v=0cd08b11b896" alt="&quot;Astro's CLI showing it built 4920 pages in 15.54s&quot;" loading="lazy" decoding="async"></a></figure>
<h3 id="getting-cute-with-it">Getting cute with it</h3>
<p>Like mentioned above, I knew I wanted to mimic a Mac OS 9 UI for the website. Now, I <em>could</em> have just used images to make the UI... but where's the fun in that?</p>
<p>So of course I've used every CSS trick in the book to achieve the look. Let me go through some of the pieces of UI and explain how I re-created them.</p>
<h3 id="the-window-frame">The window frame</h3>
<figure data-type="image"><a href="https://damien.zone/img/blog/macthemes-garden-window.png?v=7f1017c11b6d"><img src="https://damien.zone/img/blog/macthemes-garden-window.png?v=7f1017c11b6d" alt="alt text" loading="lazy" decoding="async"></a></figure>
<p>This is, obviously, a big part of the UI, so I wanted to be as close to the actual look of OS 9 as possible. Let's take a simple, empty example:</p>

<p>A lot of the styles involve using multiple box shadows to achieve the "broken border" effects in the different areas of the main UI chrome. Here is the style for the main window body (in white in the preview above):</p>
<pre><code><span>.macos9-window-body</span> <span>{</span>
  <span>border</span><span>:</span> 1px solid <span>var</span><span>(</span>--primary-black<span>)</span><span>;</span>
  <span>box-shadow</span><span>:</span>
    -1px -1px 0 <span>rgb</span><span>(</span>from <span>var</span><span>(</span>--primary-black<span>)</span> r g b / 40%<span>)</span><span>,</span>
    1px 1px 0 <span>var</span><span>(</span>--primary-white<span>)</span><span>;</span>

  <span>--top-left-shadow</span><span>:</span> <span>var</span><span>(</span>--grays-600<span>)</span><span>;</span>
  <span>--bottom-right-shadow</span><span>:</span> <span>var</span><span>(</span>--primary-white<span>)</span><span>;</span>
  <span>box-shadow</span><span>:</span>
    -1px -1px 0 <span>var</span><span>(</span>--top-left-shadow<span>)</span><span>,</span>
    -1px 0px 0 <span>var</span><span>(</span>--top-left-shadow<span>)</span><span>,</span>
    0 -1px 0 <span>var</span><span>(</span>--top-left-shadow<span>)</span><span>,</span>
    1px 1px 0 <span>var</span><span>(</span>--bottom-right-shadow<span>)</span><span>,</span>
    1px 0 0 <span>var</span><span>(</span>--bottom-right-shadow<span>)</span><span>,</span>
    0 1px 0 <span>var</span><span>(</span>--bottom-right-shadow<span>)</span><span>;</span>

  <span>background-color</span><span>:</span> <span>var</span><span>(</span>--primary-white<span>)</span><span>;</span>
<span>}</span></code></pre>
<h3 id="the-title-bar">The title bar</h3>
<p>That part was fun, there's a lot going on so let's take a look step by step. Here's how it looks and the HTML markup:</p>

<pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>macos9-window-titlebar<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span> <span>class</span><span><span>=</span><span>"</span>button close<span>"</span></span> <span>data-action</span><span><span>=</span><span>"</span>close<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>button-dots<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>filler<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>title-text<span>"</span></span><span>&gt;</span></span>Welcome!<span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>filler<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span> <span>class</span><span><span>=</span><span>"</span>button zoom<span>"</span></span> <span>data-action</span><span><span>=</span><span>"</span>zoom<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>button-dots<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span> <span>class</span><span><span>=</span><span>"</span>button collapse<span>"</span></span> <span>data-action</span><span><span>=</span><span>"</span>collapse<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>span</span> <span>class</span><span><span>=</span><span>"</span>button-dots<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre>
<p>The "stripes" pattern is done using a repeating CSS gradient and two pseudo-elements on each side with a slightly different gradient:</p>
<pre><code><span>.macos9-window-titlebar &gt; span.filler</span> <span>{</span>
  <span>flex</span><span>:</span> 1<span>;</span>
  <span>background-color</span><span>:</span> #dddddd<span>;</span>
  <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span>#ffffff<span>,</span> #ffffff 50%<span>,</span> #777777 50%<span>,</span> #777777<span>)</span><span>;</span>
  <span>background-repeat</span><span>:</span> repeat<span>;</span>
  <span>background-size</span><span>:</span> 100% 2px<span>;</span>
  <span>height</span><span>:</span> 12px<span>;</span>

  <span>position</span><span>:</span> relative<span>;</span>

  <span>&amp;::before,
  &amp;::after</span> <span>{</span>
    <span>content</span><span>:</span> <span>""</span><span>;</span>
    <span>position</span><span>:</span> absolute<span>;</span>
    <span>width</span><span>:</span> 1px<span>;</span>
    <span>background-size</span><span>:</span> 100% 2px<span>;</span>
    <span>display</span><span>:</span> block<span>;</span>
  <span>}</span>

  <span>&amp;::before</span> <span>{</span>
    <span>left</span><span>:</span> 0<span>;</span>
    <span>top</span><span>:</span> 0<span>;</span>
    <span>bottom</span><span>:</span> 0<span>;</span>
    <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span>#fff<span>,</span> #fff 50%<span>,</span> #cccccc 50%<span>,</span> #cccccc<span>)</span><span>;</span>
    <span>border-bottom</span><span>:</span> 1px solid #cccccc<span>;</span>
  <span>}</span>
  <span>&amp;::after</span> <span>{</span>
    <span>right</span><span>:</span> 0<span>;</span>
    <span>top</span><span>:</span> 0<span>;</span>
    <span>bottom</span><span>:</span> 0<span>;</span>
    <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span>#ccc<span>,</span> #ccc 50%<span>,</span> #777777 50%<span>,</span> #777777<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>We then have the window buttons which are...you guessed it, a lot of box-shadows and borders put together:</p>

<pre><code><span>.macos9-window-titlebar &gt; button</span> <span>{</span>
  <span>appearance</span><span>:</span> none<span>;</span>
  <span>border</span><span>:</span> none<span>;</span>
  <span>height</span><span>:</span> 13px<span>;</span>
  <span>width</span><span>:</span> 13px<span>;</span>

  <span>background</span><span>:</span> transparent<span>;</span>
  <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span>135deg<span>,</span> #9a9a9a 0%<span>,</span> #f1f1f1 100%<span>)</span><span>;</span>
  <span>background-size</span><span>:</span> 9px 9px<span>;</span>
  <span>background-position</span><span>:</span> center<span>;</span>
  <span>box-shadow</span><span>:</span>
    inset 1px 1px 0 <span>var</span><span>(</span>--grays-700<span>)</span><span>,</span>
    inset -1px -1px 0 <span>var</span><span>(</span>--primary-white<span>)</span><span>,</span>
    inset 0 0 0 2px <span>var</span><span>(</span>--primary-black<span>)</span><span>,</span>
    inset 3px 3px 0 <span>var</span><span>(</span>--primary-white<span>)</span><span>,</span>
    inset -3px -3px 0 <span>var</span><span>(</span>--grays-700<span>)</span><span>;</span>

  <span>position</span><span>:</span> relative<span>;</span>
  <span>z-index</span><span>:</span> 0<span>;</span>

  <span>&amp;:active::before</span> <span>{</span>
    <span>content</span><span>:</span> <span>""</span><span>;</span>
    <span>inset</span><span>:</span> 2px<span>;</span>
    <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span>
      135deg<span>,</span>
      <span>rgba</span><span>(</span>53<span>,</span> 53<span>,</span> 53<span>,</span> 0.8<span>)</span> 0%<span>,</span>
      <span>rgba</span><span>(</span>156<span>,</span> 156<span>,</span> 156<span>,</span> 0.8<span>)</span> 100%
    <span>)</span><span>;</span>
    <span>display</span><span>:</span> block<span>;</span>
    <span>position</span><span>:</span> absolute<span>;</span>
    <span>z-index</span><span>:</span> 1<span>;</span>
  <span>}</span>
<span>}</span>

<span>.macos9-window-titlebar &gt; button .button-dots</span> <span>{</span>
  <span>position</span><span>:</span> absolute<span>;</span>
  <span>inset</span><span>:</span> 0<span>;</span>
  <span>display</span><span>:</span> block<span>;</span>

  <span>&amp;::before</span> <span>{</span>
    <span>content</span><span>:</span> <span>""</span><span>;</span>
    <span>position</span><span>:</span> absolute<span>;</span>
    <span>top</span><span>:</span> 0<span>;</span>
    <span>right</span><span>:</span> 0<span>;</span>
    <span>width</span><span>:</span> 1px<span>;</span>
    <span>height</span><span>:</span> 1px<span>;</span>
    <span>background-color</span><span>:</span> #cccccc<span>;</span>
  <span>}</span>
  <span>&amp;::after</span> <span>{</span>
    <span>content</span><span>:</span> <span>""</span><span>;</span>
    <span>position</span><span>:</span> absolute<span>;</span>
    <span>bottom</span><span>:</span> 0<span>;</span>
    <span>left</span><span>:</span> 0<span>;</span>
    <span>width</span><span>:</span> 1px<span>;</span>
    <span>height</span><span>:</span> 1px<span>;</span>
    <span>background-color</span><span>:</span> #cccccc<span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Oh, and there is also a neat trick: I'm using <code>:has()</code> to sometimes re-align the title so it's actually visually centered when there is an uneven number of buttons on each side:</p>
<pre><code><span>.macos9-window-titlebar:has(.button.close, .button.zoom, .button.close)
.button.close + .filler</span> <span>{</span>
  <span>padding-left</span><span>:</span> <span>calc</span><span>(</span>13px + <span>var</span><span>(</span>--macos9-window-titlebar-gap<span>)</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h3 id="buttons">Buttons</h3>
<p>This is the part of the design that made me question my sanity and my commitment to the bit. Let's take a look at a simple button:</p>

<p>Looks simple enough, right? Well. How do you preserve the pixelated look in CSS without using images? Why, you go insane and draw the pixels yourself using CSS Grid areas of course! This was a <a href="https://codepen.io/wavebeem/pen/VYYLqJv?editors=1100">suggestion</a> from <a href="https://wavebeem.com/">Sage</a>.</p>
<p>This requires some planning because CSS Grid areas have to be rectangular. That's when I went to Photoshop and drew a bunch of colored rectangles for each area with unique colors:</p>
<figure data-type="image"><a href="https://damien.zone/img/blog/macthemes-button-grid.png?v=36032ebdbd92"><img src="https://damien.zone/img/blog/macthemes-button-grid.png?v=36032ebdbd92" alt="" loading="lazy" decoding="async"></a></figure>
<p>That's 38 areas for the inner/outer shadows to cover, as well as 4 areas for the plain background! It's easy enough to just generate that using JSX, we take care to add a <code>data-n</code> attribute which will help us target the areas in CSS:</p>
<pre><code><span><span><span>&lt;</span>a</span> <span>className</span><span><span>=</span><span>"</span>os9-button<span>"</span></span><span>&gt;</span></span><span>
  </span><span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>grid<span>"</span></span><span>&gt;</span></span><span>
    </span><span>{</span><span>Array</span><span>.</span><span>from</span><span>(</span><span>{</span> length<span>:</span> <span>38</span> <span>}</span><span>)</span><span>.</span><span>map</span><span>(</span><span>(</span>_<span>,</span> index<span>)</span> <span>=&gt;</span> <span>(</span>
      <span><span><span>&lt;</span>div</span>
        <span>key</span><span><span>=</span><span>{</span>index<span>}</span></span>
        <span>className</span><span><span>=</span><span>"</span>shadow<span>"</span></span>
        <span>data-n</span><span><span>=</span><span>{</span><span>String</span><span>(</span>index <span>+</span> <span>1</span><span>)</span><span>.</span><span>padStart</span><span>(</span><span>2</span><span>,</span> <span>"0"</span><span>)</span><span>}</span></span>
      <span>/&gt;</span></span>
    <span>)</span><span>)</span><span>}</span><span>
    </span><span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>bgd<span>"</span></span> <span>data-n</span><span><span>=</span><span>"</span>1<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>bgd<span>"</span></span> <span>data-n</span><span><span>=</span><span>"</span>2<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>bgd<span>"</span></span> <span>data-n</span><span><span>=</span><span>"</span>3<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>bgd<span>"</span></span> <span>data-n</span><span><span>=</span><span>"</span>4<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>label<span>"</span></span><span>&gt;</span></span><span>{</span>children<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
  </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
</span><span><span><span>&lt;/</span>a</span><span>&gt;</span></span></code></pre>
<p>Then, we have to use Sass to create the necessary selectors:</p>
<pre><code><span>@use</span> <span>"sass:math"</span><span>;</span>

<span>@for</span> <span>$i</span> <span>from</span> 1 <span>through</span> <span>38 </span><span>{</span>
  <span><span>$n</span></span><span>:</span> <span>$i</span><span>;</span>
  <span>@if</span> <span><span>$n</span> &lt; 10 </span><span>{</span>
    <span><span>$n</span></span><span>:</span> <span>"0#{$n}"</span><span>;</span>
  <span>}</span>
  <span>.shadow[data-n="<span>#{$n}</span>"] </span><span>{</span>
    <span>grid-area</span><span>:</span> s<span>#{$n}</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>@for</span> <span>$i</span> <span>from</span> 1 <span>through</span> <span>4 </span><span>{</span>
  <span>.bgd[data-n="<span>#{$i}</span>"] </span><span>{</span>
    <span>grid-area</span><span>:</span> bg<span>#{$i}</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Then...we "draw" our CSS areas with code:</p>
<pre><code><span>.grid </span><span>{</span>
  <span>display</span><span>:</span> grid<span>;</span>
  <span>grid-template-areas</span><span>:</span>
    <span>"... ... s01 s02 s02 s02 s03 ... ..."</span>
    <span>"... s04 s05 s06 s06 s06 s07 s08 ..."</span>
    <span>"s09 s10 s38 s11 s11 s11 s12 s13 s14"</span>
    <span>"s15 s16 s17 s17 bg1 bg1 s18 s19 s20"</span>
    <span>"s15 s16 s37 bg2 txt bg3 s18 s19 s20"</span>
    <span>"s15 s16 s37 bg2 bg4 s21 s18 s19 s20"</span>
    <span>"s22 s23 s24 s25 s26 s26 s27 s28 s29"</span>
    <span>"... s30 s31 s32 s32 s32 s32 s33 ..."</span>
    <span>"... ... s34 s35 s35 s35 s36 ... ..."</span><span>;</span>
  <span>grid-template-columns</span><span>:</span> <span>repeat</span><span>(</span>4<span>,</span> max-content<span>)</span> 1fr <span>repeat</span><span>(</span>5<span>,</span> max-content<span>)</span><span>;</span>
  <span>grid-template-rows</span><span>:</span> <span>repeat</span><span>(</span>4<span>,</span> max-content<span>)</span> 1fr <span>repeat</span><span>(</span>4<span>,</span> max-content<span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Yes, this took a while and multiple tries to get right LMAO. The full <a href="https://github.com/eramdam/macthemes.garden/blob/main/src/components/OS9Button.scss">stylesheet is here</a> if you're curious.</p>
<h3 id="random-tidbits">Random tidbits</h3>
<h3 id="window-controls">Window controls</h3>
<p>The windows are actually interactive! You can "zoom" (expand) the main window and collapse it by clicking the right button/double-clicking the title bar!</p>
<div id="demo-window">
    <p> <span></span> <span>Welcome!</span> <span></span>  </p>
    <p>
      Play with the buttons!
    </p>
  </div>

<pre><code><span>const</span> windowElement <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#demo-window'</span><span>)</span><span>;</span>
windowElement<span>.</span><span>querySelectorAll</span><span>(</span><span>"button"</span><span>)</span><span>.</span><span>forEach</span><span>(</span><span>(</span><span>button</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span>button<span>.</span>dataset<span>.</span>action <span>===</span> <span>"collapse"</span><span>)</span> <span>{</span>
    <span>const</span> titlebar <span>=</span> windowElement<span>.</span><span>querySelector</span><span>(</span><span>".macos9-window-titlebar"</span><span>)</span><span>;</span>
    <span>if</span> <span>(</span>titlebar<span>)</span> <span>{</span>
      titlebar<span>.</span><span>addEventListener</span><span>(</span><span>"dblclick"</span><span>,</span> <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>if</span> <span>(</span>e<span>.</span>target <span>instanceof</span> <span>HTMLButtonElement</span><span>)</span> <span>{</span>
          <span>return</span><span>;</span>
        <span>}</span>

        windowElement<span>.</span>classList<span>.</span><span>toggle</span><span>(</span><span>"collapsed"</span><span>)</span><span>;</span>
        window<span>.</span><span>getSelection</span><span>(</span><span>)</span><span>?.</span><span>empty</span><span>(</span><span>)</span><span>;</span>
      <span>}</span><span>)</span><span>;</span>
    <span>}</span>
  <span>}</span>
  button<span>.</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> action <span>=</span> button<span>.</span>dataset<span>.</span>action<span>;</span>
    <span>if</span> <span>(</span>action <span>===</span> <span>"collapse"</span><span>)</span> <span>{</span>
      windowElement<span>.</span>classList<span>.</span><span>toggle</span><span>(</span><span>"collapsed"</span><span>)</span><span>;</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span>action <span>===</span> <span>"zoom"</span><span>)</span> <span>{</span>
      windowElement<span>.</span>classList<span>.</span><span>toggle</span><span>(</span><span>"zoomed"</span><span>)</span><span>;</span>
    <span>}</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<h3 id="open-graph-images">Open Graph images</h3>
<p>I could have taken the easy route when making the open graph images for each theme and simply dropped a PNG of the main window, something like this:</p>
<picture>
  <source srcset="https://damien.zone/img/blog/macthemes-embed-v1-dark.png?v=e52e251e312a" media="(prefers-color-scheme: dark)" type="image/png">
  <source srcset="https://damien.zone/img/blog/macthemes-embed-v1-light.png?v=4a2f5f4ea782" type="image/png">
  <img src="https://damien.zone/img/blog/macthemes-embed-v1-light.png?v=4a2f5f4ea782" alt="Discord embed with a simple window without any background" loading="lazy" decoding="async" width="437">
</picture>
<p>This is very cute in apps like Discord, but looks terrible about everywhere else because of the wrong aspect ratio and the non-support of alpha channels.</p>
<picture>
  <source srcset="https://damien.zone/img/blog/macthemes-embed-v1-bsky-dark.png?v=b4ccfc724027" media="(prefers-color-scheme: dark)" type="image/png">
  <source srcset="https://damien.zone/img/blog/macthemes-embed-v1-bsky-light.png?v=ad6a8204546d" type="image/png">
  <img src="https://damien.zone/img/blog/macthemes-embed-v1-bsky-light.png?v=ad6a8204546d" alt="Bluesky embed with a simple window without any background" loading="lazy" decoding="async" width="437">
</picture>
<p>So I took another approach:</p>
<figure data-type="image"><a href="https://macthemes.garden/themes-opengraph/13d46b4752aa-Monkey-Paradise.png"><img src="https://macthemes.garden/themes-opengraph/13d46b4752aa-Monkey-Paradise.png" alt="" loading="lazy" decoding="async"></a></figure>
<p>But, obviously, doing that kind of compositing manually would be a terrible idea, and I'm not good enough with ImageMagick, so I ended up using Vercel's <a href="https://github.com/vercel/satori">satori</a> to lay the two images out and generate an image for every single theme:</p>
<pre><code><span>import</span> <span>type</span> <span>{</span> InferEntrySchema <span>}</span> <span>from</span> <span>"astro:content"</span><span>;</span>
<span>import</span> satori <span>from</span> <span>"satori"</span><span>;</span>
<span>import</span> sharp <span>from</span> <span>"sharp"</span><span>;</span>

<span>export</span> <span>async</span> <span>function</span> <span>generateOpenGraphImageForTheme</span><span>(</span>
  theme<span>:</span> InferEntrySchema<span>&lt;</span><span>"themes"</span><span>&gt;</span><span>,</span>
<span>)</span> <span>{</span>
  <span>let</span> blurredImageData<span>:</span> Buffer <span>|</span> <span>undefined</span><span>;</span>
  <span>const</span> margin <span>=</span> <span>20</span><span>;</span>
  <span>const</span> imageDimension <span>=</span> <span>{</span>
    width<span>:</span> <span>1200</span><span>,</span>
    height<span>:</span> <span>630</span><span>,</span>
  <span>}</span><span>;</span>

  <span>if</span> <span>(</span>theme<span>.</span>thumbnails<span>.</span>length <span>&gt;</span> <span>1</span><span>)</span> <span>{</span>
    blurredImageData <span>=</span> <span>await</span> <span>sharp</span><span>(</span><span>"public/"</span> <span>+</span> theme<span>.</span>thumbnails<span>[</span><span>1</span><span>]</span><span>)</span>
      <span>.</span><span>resize</span><span>(</span>imageDimension<span>.</span>width<span>,</span> imageDimension<span>.</span>height<span>,</span> <span>{</span>
        fit<span>:</span> <span>"cover"</span><span>,</span>
        position<span>:</span> <span>"top"</span><span>,</span>
      <span>}</span><span>)</span>
      <span>.</span><span>blur</span><span>(</span><span>5</span><span>)</span>
      <span>.</span><span>toBuffer</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>

  <span>const</span> mainThumbnailSharp <span>=</span> <span>sharp</span><span>(</span><span>"public"</span> <span>+</span> theme<span>.</span>mainThumbnail<span>)</span><span>;</span>
  <span>const</span> mainThumbnail <span>=</span> <span>await</span> mainThumbnailSharp<span>.</span><span>png</span><span>(</span><span>)</span><span>.</span><span>toBuffer</span><span>(</span><span>)</span><span>;</span>

  <span>const</span> svg <span>=</span> <span>await</span> <span>satori</span><span>(</span>
    <span><span><span>&lt;</span>div</span>
      <span>style</span><span><span>=</span><span>{</span><span>{</span>
        display<span>:</span> <span>"flex"</span><span>,</span>
        alignItems<span>:</span> <span>"center"</span><span>,</span>
        justifyItems<span>:</span> <span>"center"</span><span>,</span>
        width<span>:</span> <span>"100%"</span><span>,</span>
        height<span>:</span> <span>"100%"</span><span>,</span>
        position<span>:</span> <span>"relative"</span><span>,</span>
        backgroundColor<span>:</span> <span>"white"</span><span>,</span>
      <span>}</span><span>}</span></span>
    <span>&gt;</span></span><span>
      </span><span>{</span>blurredImageData <span>&amp;&amp;</span> <span>(</span>
        <span><span><span>&lt;</span>img</span>
          <span>src</span><span><span>=</span><span>{</span><span>toArrayBuffer</span><span>(</span>blurredImageData<span>)</span><span>}</span></span>
          <span>style</span><span><span>=</span><span>{</span><span>{</span>
            position<span>:</span> <span>"absolute"</span><span>,</span>
            filter<span>:</span> <span>"brightness(40%)"</span><span>,</span>
            inset<span>:</span> <span>0</span><span>,</span>
          <span>}</span><span>}</span></span>
        <span>/&gt;</span></span>
      <span>)</span><span>}</span><span>
      </span><span><span><span>&lt;</span>img</span>
        <span>src</span><span><span>=</span><span>{</span><span>toArrayBuffer</span><span>(</span>mainThumbnail<span>)</span><span>}</span></span>
        <span>style</span><span><span>=</span><span>{</span><span>{</span>
          padding<span>:</span> margin<span>,</span>
          width<span>:</span> <span>"100%"</span><span>,</span>
          height<span>:</span> <span>"100%"</span><span>,</span>
          boxSizing<span>:</span> <span>"border-box"</span><span>,</span>
          objectFit<span>:</span> <span>"contain"</span><span>,</span>
          objectPosition<span>:</span> <span>"center center"</span><span>,</span>
        <span>}</span><span>}</span></span>
      <span>/&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>,</span>
    <span>{</span>
      width<span>:</span> imageDimension<span>.</span>width<span>,</span>
      height<span>:</span> imageDimension<span>.</span>height<span>,</span>
      fonts<span>:</span> <span>[</span><span>]</span><span>,</span>
    <span>}</span><span>,</span>
  <span>)</span><span>;</span>

  <span>return</span> <span>sharp</span><span>(</span>Buffer<span>.</span><span>from</span><span>(</span>svg<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>function</span> <span>toArrayBuffer</span><span>(</span>buffer<span>:</span> Buffer<span>)</span> <span>{</span>
  <span>const</span> arrayBuffer <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>(</span>buffer<span>.</span>length<span>)</span><span>;</span>
  <span>const</span> view <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span>arrayBuffer<span>)</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> buffer<span>.</span>length<span>;</span> <span>++</span>i<span>)</span> <span>{</span>
    view<span>[</span>i<span>]</span> <span>=</span> buffer<span>[</span>i<span>]</span><span>;</span>
  <span>}</span>
  <span>return</span> arrayBuffer<span>;</span>
<span>}</span></code></pre>
<p>I then put together a <a href="https://github.com/eramdam/macthemes.garden/blob/7a8983b64114d6305eb906169aaf64b6005321a5/scripts/opengraph-images.ts">script</a> to process all the images by spawning multiple process, the whole script takes ~2min30 to run on my M1 Max Mac Studio and generate ~3900 images.</p>
<p>As a bonus, these images will also be used by the Mac Themes Bot when available going forward.</p>
<h2 id="whats-next">What's next</h2>
<p>I don't know how long it will take, but I want to continue/finish "recording" the schemes I have access to. Hopefully I am done before next year lolsob. You should subscribe to the <a href="https://macthemes.garden/feed.xml">RSS feed</a> to see those as I update them!</p>
<p>Apart from that, I have a bunch of ideas:</p>
<ul>
<li>a "search by color" feature</li>
<li>a way to see/showcase the custom icons contained in each scheme when applicable. There are some gems in there, trust me!</li>
<li>Somehow, find a way to hook the site into <a href="https://infinitemac.org/">InfiniteMac</a> to quickly view a scheme "live"</li>
<li>a user-submitted gallery of old Macs running the schemes from the site. Hit me up if this is something you'd want to participate in :)</li>
</ul>
<p>That's all, folks, have a good life.<br>
- damien</p>


<hr>
<section>
<ol>
<li id="fn1"><p>or vice versa, I honestly do not remember nor do I care to check the Git history. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vagus Nerve Stimulation Erases PTSD: Study (115 pts)]]></title>
            <link>https://neurosciencenews.com/vagus-nerve-stimulation-ptsd-28818/</link>
            <guid>43919812</guid>
            <pubDate>Wed, 07 May 2025 19:38:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neurosciencenews.com/vagus-nerve-stimulation-ptsd-28818/">https://neurosciencenews.com/vagus-nerve-stimulation-ptsd-28818/</a>, See on <a href="https://news.ycombinator.com/item?id=43919812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><article><div><p><strong>Summary: </strong>A pioneering clinical study found that pairing vagus nerve stimulation (VNS) with traditional therapy eliminated PTSD diagnoses in all participants up to six months post-treatment. The trial combined prolonged exposure therapy with brief bursts of VNS via an implanted device, enhancing neuroplasticity and sustaining remission.</p><p>Prior research shows many PTSD patients fail to respond to standard treatments, making this approach especially promising. Future trials will explore the therapy further, aiming to offer new hope for those resistant to conventional methods.</p><p><strong>Key Facts:</strong></p><ul><li><strong>100% Remission:</strong> All participants were free from PTSD diagnosis six months after therapy paired with VNS.</li><li><strong>Neuroplasticity Boost:</strong> VNS enhances brain rewiring, improving outcomes for therapy-resistant PTSD patients.</li><li><strong>Next Steps:</strong> A double-blind Phase 2 trial is underway to confirm findings and move toward FDA approval.</li></ul><p><strong>Source: </strong>UT Dallas</p><p><strong>In a first-of-its-kind clinical study, scientists at The University of Texas at Dallas and Baylor University Medical Center showed that patients with treatment-resistant PTSD were symptom-free up to six months after completing traditional therapy paired with vagus nerve stimulation (VNS).</strong></p><p>The results of the nine-patient Phase 1 trial, conducted by scientists from UT Dallas’ Texas Biomedical Device Center (TxBDC) in collaboration with researchers from the Baylor Scott &amp; White Research Institute (BSWRI), were published online March 15 in Brain Stimulation.</p><figure><p> <iframe title="Vagus Nerve Stimulation Shows Promise in Erasing PTSD" width="1200" height="675" src="https://www.youtube.com/embed/pEn4RlAFqFc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p></figure><p>Credit: <a href="https://www.youtube.com/@Neuroscience" target="_blank" rel="noreferrer noopener">Neuroscience News</a></p><p>Dr. Michael Kilgard, the Margaret Fonde Jonsson Professor of neuroscience in the School of Behavioral and Brain Sciences, said the outcome highlighted the potential of this approach.</p><p>“In a trial like this, some subjects usually do get better, but rarely do they lose their PTSD diagnosis. Typically, the majority will have this diagnosis for the rest of their lives,” Kilgard said. “In this case, we had 100% loss of diagnosis. It’s very promising.”</p><p>Prolonged exposure therapy — a component of traditional PTSD treatment — is a form of cognitive behavioral therapy, conducted in a safe and supportive environment, that involves individuals gradually confronting thoughts, memories and situations they have avoided since experiencing a trauma.</p><p>In the study, scientists paired this therapy with concurrent delivery of short bursts of stimulation of the vagus nerve via a small device implanted in a participant’s neck.</p><p>After a standard 12-session therapy course, assessments were performed four times during the six months after its conclusion. Benefits persisted during that time for all nine participants.</p><p>The study is the largest clinical trial to date using an implanted device for the treatment of PTSD, Kilgard said.</p><p>Pioneering work by TxBDC researchers has demonstrated previously that VNS paired with physical rehabilitation can accelerate neuroplasticity — the rewiring of areas of the brain.</p><p>Their 13-year effort to treat a wide variety of conditions using VNS has resulted in approval by the Food and Drug Administration (FDA) for treating impaired upper-limb movement in stroke patients.</p><p>“The common theme in our VNS work is that we’re taking therapies that show potential, like prolonged exposure therapy for PTSD, and making them work better,” he said.</p><p>The National Center for PTSD, part of the Department of Veterans Affairs, estimates that 5% of adults in the U.S. have post-traumatic stress disorder in any given year, and that women are twice as likely to develop PTSD at some point in their life.</p><p>Many PTSD patients fail to respond to therapy or pharmacological intervention, or experience intolerable side effects or relapse, leaving them with no viable prospect for remission.</p><p>Kilgard said that PTSD patients are not only found among military veterans, but also among average citizens who have faced traumatic events.</p><p>“When you hear PTSD, you may picture a combat zone, but it’s much more prevalent than that,” he said.</p><p>“It can stem from any event that inspires fear of death or bodily injury, or death of a loved one.”</p><p>Co-corresponding author Dr. Seth Hays, associate professor of bioengineering in the Erik Jonsson School of Engineering and Computer Science and director of preclinical research at the TxBDC, has been a part of the VNS project since its earliest studies.</p><p>“It’s been an incredibly rewarding experience to see this technology evolve from early discovery experiments in the lab to clinical benefits in patients,” Hays said. “This whole process truly highlights the value of team-based science.”</p><p>More than a decade ago, Dr. Robert Rennaker, professor of neuroscience and the Texas Instruments Distinguished Chair in Bioengineering, began to design an innovative implantable VNS device that was much smaller and less expensive than devices already on the market. The most recent wireless version of the device is about the size of a dime.</p><p>“The technology we have is above and beyond anything else that’s out there. The device is about 50 times smaller than our version from just three years ago,” he said.</p><p>“The 49 people in the Dallas area with our devices have a combined 100 years of experience with it implanted. There have been no issues; the devices are all still functioning. And they don’t interfere with typical medical care; you can have an MRI, a CT scan or an ultrasound.”</p><p>The next step in the PTSD research — a double-blind, placebo-controlled Phase 2 pilot study — is ongoing in Dallas and Austin.</p><p>“We hope that it will represent another step toward FDA approval of a treatment that doesn’t exist now, and it would be invented, tested and delivered by UT Dallas, as was the case for upper-limb recovery after stroke,” Kilgard said.</p><p>Licensed clinical psychologist Dr. Mark Powers, a research center director of the Trauma Research Center at BSWRI, is the lead and co-corresponding author of the study.</p><p>Driven by his desire to improve quality of life among people who experience psychological trauma, Powers said that VNS has “changed the game” by improving both treatment efficacy and its tolerability.</p><p>“VNS has changed my work dramatically,” he said.</p><p>“Our gold-standard treatments for PTSD have about an 85% response rate, with 40% no longer having their diagnosis, and a 20% dropout rate. Soon we could have the option of VNS for people who don’t get better with cognitive behavioral therapy alone.”</p><p>Powers added that his collaboration with UTD has a multidisciplinary synergy that he regards as rare.</p><p>“With this alliance, we have people doing the preclinical and the clinical work at the same time, giving each other feedback and ideas,” he said. “Neither one of our groups could do this alone.”</p><p>Other UTD-affiliated study authors included Dr. Jane Wigginton, medical director and co-director of the UT Dallas Clinical and Translational Research Center; Amy Porter MBA’20, TxBDC director of operations; and Holle Carey Gallaway MBA’23, TxBDC research biomedical engineer.</p><p>Researchers from Southern Methodist University, UT Austin and Baylor Scott &amp; White Health also contributed to the study.</p><p><strong>Funding: </strong>The research was funded by a grant (N66001-15-2-4057) from the Biological Technologies Office at the Defense Advanced Research Projects Agency, part of the Department of Defense.</p><h2>About this PTSD and brain stimulation research news</h2><p><strong>Author: </strong><a href="https://neurosciencenews.com/cdn-cgi/l/email-protection#d5a6adb3e4e2e4e4e6e595a0a1b1b4b9b9b4a6fbb0b1a0" target="_blank" rel="noreferrer noopener">Stephen Fontenot</a><br><strong>Source: </strong><a href="https://utdallas.edu/" target="_blank" rel="noreferrer noopener">UT Dallas</a><br><strong>Contact: </strong>Stephen Fontenot – UT Dallas<br><strong>Image: </strong>The image is credited to Neuroscience News</p><p><strong>Original Research: </strong>Open access.<br>“<a href="https://dx.doi.org/10.1016/j.brs.2025.03.007" target="_blank" rel="noreferrer noopener">Vagus nerve stimulation therapy for treatment-resistant PTSD</a>” by Michael Kilgard et al. <em>Brain Stimulation</em></p><hr><p><strong>Abstract</strong></p><p><strong>Vagus nerve stimulation therapy for treatment-resistant PTSD</strong></p><h3>Background</h3><p>Posttraumatic stress disorder (PTSD) is common and debilitating, and many individuals do not respond to existing therapies. We developed a fundamentally novel neuromodulation-based therapy for treatment-resistant PTSD.</p><p>This approach is premised on coupling prolonged exposure therapy, a first-line evidence-based cognitive behavioral therapy that directs changes within fear networks, with concurrent delivery of short bursts of vagus nerve stimulation (VNS), which enhance synaptic plasticity.</p><h3>Methods</h3><p>We performed a first-in-human prospective open-label early feasibility study (EFS) using a next-generation miniaturized system to deliver VNS therapy in nine individuals with moderate to severe treatment-resistant PTSD. All individuals received a standard 12-session course of prolonged exposure therapy combined with VNS.</p><p>Assessments were performed before, 1 week after, and 1, 3, and 6 months after the completion of therapy.&nbsp;ClinicalTrials.gov&nbsp;registration: NCT04064762.</p><h3>Results</h3><p>VNS therapy resulted in significant, clinically-meaningful improvements in multiple metrics of PTSD symptoms and severity compared to baseline (CAPS-5, PCL-5, and HADS all p&nbsp;&lt;&nbsp;0.001 after therapy). These benefits persisted at 6 months after the cessation of therapy, suggesting lasting improvements.</p><p>All participants showed loss of PTSD diagnosis after completing treatment. No serious or unexpected device-related adverse events were observed.</p><h3>Conclusions</h3><p>These findings provide a demonstration of the safety and feasibility of VNS therapy for PTSD and highlight the potential of this approach. Collectively, these support the validation of VNS therapy for PTSD in a rigorous randomized controlled trial.</p> <!-- Form created by Optin Forms plugin by WPKube: create beautiful optin forms with ease! --> <!-- https://wpkube.com/ --><!--optinforms-form5-container--> <!-- / Optin Forms --> </div><!-- .entry-content --><!-- .entry-footer --></article><!-- #post-x --></main><!-- .site-main --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source Google Analytics replacement (262 pts)]]></title>
            <link>https://github.com/rybbit-io/rybbit</link>
            <guid>43918620</guid>
            <pubDate>Wed, 07 May 2025 17:45:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rybbit-io/rybbit">https://github.com/rybbit-io/rybbit</a>, See on <a href="https://news.ycombinator.com/item?id=43918620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/435507934-1425302a-40b6-4d97-bf4b-89927ea93fb9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80MzU1MDc5MzQtMTQyNTMwMmEtNDBiNi00ZDk3LWJmNGItODk5MjdlYTkzZmI5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE0ZDU2MGM5MWUzOWI3NmFhMmFiOWU5YWIwNjhhNmVlNWMwMDZkMjE0OWU5ZmQ4ZmNhODcxMWJhNTQ4MWY0OTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.rc3hle4IxYg71b9JczFQJU3lD5Vq26Fu_f2KxsNhBsM"><img src="https://private-user-images.githubusercontent.com/45103519/435507934-1425302a-40b6-4d97-bf4b-89927ea93fb9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80MzU1MDc5MzQtMTQyNTMwMmEtNDBiNi00ZDk3LWJmNGItODk5MjdlYTkzZmI5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE0ZDU2MGM5MWUzOWI3NmFhMmFiOWU5YWIwNjhhNmVlNWMwMDZkMjE0OWU5ZmQ4ZmNhODcxMWJhNTQ4MWY0OTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.rc3hle4IxYg71b9JczFQJU3lD5Vq26Fu_f2KxsNhBsM" height="250"></a>
    </p><p dir="auto"><h2 tabindex="-1" dir="auto">
        Rybbit Analytics 
    </h2><a id="user-content---------rybbit-analytics-----" aria-label="Permalink: 
        Rybbit Analytics 
    " href="#--------rybbit-analytics-----"></a></p>
    <p dir="auto">Open Source Web &amp; Product Analytics</p>
<p dir="auto">
  <a href="https://rybbit.io/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/9e50ed18f8a6041fdb4c654a345955ab054a3fd97708039cea784ea4a4b8af17/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d77656273697465266d6573736167653d7669657726636f6c6f723d677265656e" alt="website" data-canonical-src="https://img.shields.io/static/v1?label=website&amp;message=view&amp;color=green">
</a>
<a href="https://demo.rybbit.io/1" rel="nofollow">
    <img src="https://camo.githubusercontent.com/44aadb108d61ba74a6c901a1d5d39b466963b79f7f3c2480a9d6d90c111014f9/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d64656d6f266d6573736167653d7669657726636f6c6f723d677265656e" alt="Demo" data-canonical-src="https://img.shields.io/static/v1?label=demo&amp;message=view&amp;color=green">
</a>
<a href="https://rybbit.io/docs" rel="nofollow">
    <img src="https://camo.githubusercontent.com/d95f6ca545ef5e1c18c87a62a4dc066e32fac096ea7becd1e2ac57621c6321fc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d766965772d677265656e" alt="Documentation" data-canonical-src="https://img.shields.io/badge/docs-view-green">
</a>
<a href="https://discord.gg/DEhGb4hYBj" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e6907743e1ad37607c92a6da0552a9a83ddf481baab9a50c7183d6fd4c64acd7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d6a6f696e2d677265656e2e7376673f6c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Discord" data-canonical-src="https://img.shields.io/badge/discord-join-green.svg?logo=discord&amp;logoColor=white">
</a>
<a href="https://github.com/rybbit-io/rybbit?tab=AGPL-3.0-1-ov-file">
    <img src="https://camo.githubusercontent.com/64e4e5c77ccf13fb439e172169a93fddd05f615aa456e9729181f6e26ac68500/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d6c6963656e7365266d6573736167653d4147504c2d3326636f6c6f723d677265656e" alt="License" data-canonical-src="https://img.shields.io/static/v1?label=license&amp;message=AGPL-3&amp;color=green">
</a>
</p>

<p dir="auto"><a href="https://rybbit.io/" rel="nofollow">Rybbit</a> is the modern open source and privacy friendly alternative to Google Analytics. It takes only a couple minutes to setup and is super intuitive to use.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">
View a <strong><a href="https://demo.rybbit.io/1" rel="nofollow">live demo</a></strong> of Rybbit running on a real-life production site with over a million visits a month. 
</h3><a id="user-content-view-a-live-demo-of-rybbit-running-on-a-real-life-production-site-with-over-a-million-visits-a-month-" aria-label="Permalink: 
View a live demo of Rybbit running on a real-life production site with over a million visits a month. 
" href="#view-a-live-demo-of-rybbit-running-on-a-real-life-production-site-with-over-a-million-visits-a-month-"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
You can either sign up for our hosted service at <a href="https://rybbit.io/" rel="nofollow">https://rybbit.io</a> or <a href="https://rybbit.io/docs/self-hosting" rel="nofollow">self host</a> Rybbit on your own VPS.
<p dir="auto">Learn more about Rybbit by reading our <a href="https://rybbit.io/docs" rel="nofollow">documentation</a> .</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<ul dir="auto">
<li>All key web analytics metrics including sessions, unique users, pageviews, bounce rate, session duration</li>
<li>No cookies or user tracking - GDPR &amp; CCPA compliant</li>
<li>Customizable goals. retention, user journeys, and funnels dashboards</li>
<li>Advanced filtering across 15+ dimensions</li>
<li>Custom events</li>
<li>Live sessions dashboard</li>
<li>3 level location tracking (country -&gt; region -&gt; city) + advanced map visualizations</li>
<li>Real time dashboard</li>
<li>Support for organizations and unlimited number of sites</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dashboard Preview</h2><a id="user-content-dashboard-preview" aria-label="Permalink: Dashboard Preview" href="#dashboard-preview"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Main</h3><a id="user-content-main" aria-label="Permalink: Main" href="#main"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440199968-7f2d3b79-90b6-496b-9b47-373ba1c62a7e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAxOTk5NjgtN2YyZDNiNzktOTBiNi00OTZiLTliNDctMzczYmExYzYyYTdlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQyNzFmZmUzZjYwODVkY2RkMDMxMTdjODkzMmVmMWZjODRmZjk0MTdiNTRiODFkOGIxYzc5YzA5YWU2ZjRhMDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VzMym_AYX8My_DdeNnXRO_xmzCLeqY-JtiV0Phy6iRU"><img src="https://private-user-images.githubusercontent.com/45103519/440199968-7f2d3b79-90b6-496b-9b47-373ba1c62a7e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAxOTk5NjgtN2YyZDNiNzktOTBiNi00OTZiLTliNDctMzczYmExYzYyYTdlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQyNzFmZmUzZjYwODVkY2RkMDMxMTdjODkzMmVmMWZjODRmZjk0MTdiNTRiODFkOGIxYzc5YzA5YWU2ZjRhMDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VzMym_AYX8My_DdeNnXRO_xmzCLeqY-JtiV0Phy6iRU" alt="image"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Realtime</h3><a id="user-content-realtime" aria-label="Permalink: Realtime" href="#realtime"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440200166-54996620-4eff-4ecc-9135-10ce21483f6a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDAxNjYtNTQ5OTY2MjAtNGVmZi00ZWNjLTkxMzUtMTBjZTIxNDgzZjZhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTMzZjkyOGI3ZDhjMGI0YzIxYTM4NmFlZTg2NjdmNTRiMmVjNTJjYzA3NTQ0M2EzMzM4NmZlYmEzNmMyNzIzNzEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9NRbiWljTCn8rjeZRYx6RbfR5gzoyfwZNXBPHV5dXX8"><img src="https://private-user-images.githubusercontent.com/45103519/440200166-54996620-4eff-4ecc-9135-10ce21483f6a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDAxNjYtNTQ5OTY2MjAtNGVmZi00ZWNjLTkxMzUtMTBjZTIxNDgzZjZhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTMzZjkyOGI3ZDhjMGI0YzIxYTM4NmFlZTg2NjdmNTRiMmVjNTJjYzA3NTQ0M2EzMzM4NmZlYmEzNmMyNzIzNzEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9NRbiWljTCn8rjeZRYx6RbfR5gzoyfwZNXBPHV5dXX8" alt="image"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sessions</h3><a id="user-content-sessions" aria-label="Permalink: Sessions" href="#sessions"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440200241-b87769f3-650d-4069-9e18-5d59e41a175b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDAyNDEtYjg3NzY5ZjMtNjUwZC00MDY5LTllMTgtNWQ1OWU0MWExNzViLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRlODgxNDY0OWIzYjkxOGVmMzUxN2VkNmQ3YzY4ZDRlYWNiZjE1NGNjYWMzYjAxNTNkYzQ2ZGUxMmYxOGYzMWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.kV0uQohW5lN3eVnVXNEoQgKaHJl2nnHjGSiiOFqnk8w"><img src="https://private-user-images.githubusercontent.com/45103519/440200241-b87769f3-650d-4069-9e18-5d59e41a175b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDAyNDEtYjg3NzY5ZjMtNjUwZC00MDY5LTllMTgtNWQ1OWU0MWExNzViLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRlODgxNDY0OWIzYjkxOGVmMzUxN2VkNmQ3YzY4ZDRlYWNiZjE1NGNjYWMzYjAxNTNkYzQ2ZGUxMmYxOGYzMWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.kV0uQohW5lN3eVnVXNEoQgKaHJl2nnHjGSiiOFqnk8w" alt="image"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Journeys</h3><a id="user-content-journeys" aria-label="Permalink: Journeys" href="#journeys"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440200289-890f9de8-3025-4962-91c5-5a1b2ddf0d82.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDAyODktODkwZjlkZTgtMzAyNS00OTYyLTkxYzUtNWExYjJkZGYwZDgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg4MDY3NDVhY2ZjNTgwZGNmZjhhYzdmZDkyODZkMjA5ZjE3OTlhMWU4NWQ4NTJjYjJjMWNmOWFjZDMxMzA1NGEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.L1cRtiZ21ALLj61hTQjKb1dz9XMUlyIPIv1W1GeQLtU"><img src="https://private-user-images.githubusercontent.com/45103519/440200289-890f9de8-3025-4962-91c5-5a1b2ddf0d82.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDAyODktODkwZjlkZTgtMzAyNS00OTYyLTkxYzUtNWExYjJkZGYwZDgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg4MDY3NDVhY2ZjNTgwZGNmZjhhYzdmZDkyODZkMjA5ZjE3OTlhMWU4NWQ4NTJjYjJjMWNmOWFjZDMxMzA1NGEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.L1cRtiZ21ALLj61hTQjKb1dz9XMUlyIPIv1W1GeQLtU" alt="image"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Map</h3><a id="user-content-map" aria-label="Permalink: Map" href="#map"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440200520-b1f7be89-ec8d-4ccc-9a87-45b0fb31d3a1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDA1MjAtYjFmN2JlODktZWM4ZC00Y2NjLTlhODctNDViMGZiMzFkM2ExLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZjYzkzMDc3OWJjNTkzNDRmMGM5NjY3YzQyMjNkNjYwYWJmM2IzYWQzNTIxMmIzY2NiYWE2NjZhNjFjYTQ2NGEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.BHtSSM9-pKXG0S_VqBnMsCoiChPuIaABPlOS-ZyFZqU"><img src="https://private-user-images.githubusercontent.com/45103519/440200520-b1f7be89-ec8d-4ccc-9a87-45b0fb31d3a1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDA1MjAtYjFmN2JlODktZWM4ZC00Y2NjLTlhODctNDViMGZiMzFkM2ExLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZjYzkzMDc3OWJjNTkzNDRmMGM5NjY3YzQyMjNkNjYwYWJmM2IzYWQzNTIxMmIzY2NiYWE2NjZhNjFjYTQ2NGEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.BHtSSM9-pKXG0S_VqBnMsCoiChPuIaABPlOS-ZyFZqU" alt="image"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Funnels</h3><a id="user-content-funnels" aria-label="Permalink: Funnels" href="#funnels"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440200605-bad9e37c-1ff6-49b4-9285-6dde7f90051f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDA2MDUtYmFkOWUzN2MtMWZmNi00OWI0LTkyODUtNmRkZTdmOTAwNTFmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE1OTkxZDliMmIxZmVlN2Y3YWEwZDljOTc4MTZmMWVkNjNmYmQ3YzI0Mzk3OGYzMDExZDI0M2Q3ODlkMzBhZmEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.0Enm7N0EqXQfONGEiODUOwoKOXIOb6x7d9u2ckVmPTA"><img src="https://private-user-images.githubusercontent.com/45103519/440200605-bad9e37c-1ff6-49b4-9285-6dde7f90051f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDA2MDUtYmFkOWUzN2MtMWZmNi00OWI0LTkyODUtNmRkZTdmOTAwNTFmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE1OTkxZDliMmIxZmVlN2Y3YWEwZDljOTc4MTZmMWVkNjNmYmQ3YzI0Mzk3OGYzMDExZDI0M2Q3ODlkMzBhZmEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.0Enm7N0EqXQfONGEiODUOwoKOXIOb6x7d9u2ckVmPTA" alt="image"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Goals</h3><a id="user-content-goals" aria-label="Permalink: Goals" href="#goals"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/45103519/440200635-60503585-5daf-4cfe-927e-4e149749f538.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDA2MzUtNjA1MDM1ODUtNWRhZi00Y2ZlLTkyN2UtNGUxNDk3NDlmNTM4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQxNmQyNGFlMzAwYTA4NTZhNzc5NmI4YzdmZTU0NWY5MGNhNGQ5MjM0YzU4YjE1NzIzZmQ1NDk5NDdlNTU1MGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.THdmq2tnP0sHGW6WaHeRjhn-D1IRaJPPFVS7VWnXPKA"><img src="https://private-user-images.githubusercontent.com/45103519/440200635-60503585-5daf-4cfe-927e-4e149749f538.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NTczMDEsIm5iZiI6MTc0NjY1NzAwMSwicGF0aCI6Ii80NTEwMzUxOS80NDAyMDA2MzUtNjA1MDM1ODUtNWRhZi00Y2ZlLTkyN2UtNGUxNDk3NDlmNTM4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDIyMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQxNmQyNGFlMzAwYTA4NTZhNzc5NmI4YzdmZTU0NWY5MGNhNGQ5MjM0YzU4YjE1NzIzZmQ1NDk5NDdlNTU1MGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.THdmq2tnP0sHGW6WaHeRjhn-D1IRaJPPFVS7VWnXPKA" alt="image"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three Chapters at Cloudflare: Programmer to CTO to Board of Directors (146 pts)]]></title>
            <link>https://blog.cloudflare.com/en-us/three-chapters-at-cloudflare-programmer-to-cto-to-board-of-directors/</link>
            <guid>43918600</guid>
            <pubDate>Wed, 07 May 2025 17:43:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/en-us/three-chapters-at-cloudflare-programmer-to-cto-to-board-of-directors/">https://blog.cloudflare.com/en-us/three-chapters-at-cloudflare-programmer-to-cto-to-board-of-directors/</a>, See on <a href="https://news.ycombinator.com/item?id=43918600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2025-03-27</p><section><p>4 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3WjSvoGBEfq01eYJ0hrlVH/dfd40ec4bea05d31c9030c9ce2284d75/unnamed__1_.png" alt=""><div><p>Today, after more than 13 years at the company, I am joining Cloudflare’s board of directors and retiring from my full-time position as CTO. </p><p>Back in 2012 I wrote a short post on my personal site simply titled: <a href="https://blog.jgc.org/2012/02/programmer.html"><u>Programmer</u></a>. The post announced that I’d recently joined a company called CloudFlare (still sporting that capital “F”) with the job title Programmer. I’d chosen that title in part because it was the very first title I’d ever had, and because it would reflect what I’d be doing at Cloudflare.</p><p>I had spent a lot of time working at startups—in technical and then management roles—and wanted to go back to the really technical part that I loved most. Cloudflare gave me that opportunity, and I worked on a lot of systems that make up the Cloudflare that so many people around the world use today.</p><p>Looking back on my time at the company it’s really, really hard to pick my top highlights. In 2019 <a href="https://blog.cloudflare.com/helping-to-build-cloudflare-part-1/"><u>I wrote 6,000 words on the experience of helping build Cloudflare</u></a>. But here are five that stand out:</p>
          <p>
            <h3 id="always-be-shipping">Always be shipping</h3>
            
          </p>
        <p>The night we finished the preparation to launch <a href="https://blog.cloudflare.com/introducing-universal-ssl/"><u>Universal SSL</u></a> sticks in my memory. We set out to offer the Industry's First Universal SSL for free, effectively doubling the size of the encrypted web overnight, a big deal in 2014. I remember Cloudflare’s third co-founder, Lee Holloway, hunched over his laptop finishing the code. The team has been working on it all weekend, and late that Sunday night Lee announced “it’s done.”&nbsp;</p>
          <p>
            <h3 id="handling-adversity">Handling adversity</h3>
            
          </p>
        <p>It’s easy to pick moments of great success or when things went really well and <a href="https://blog.cloudflare.com/helping-to-build-cloudflare-part-2/"><u>Cloudbleed in 2017</u></a> may not seem like a special moment, but it helped show who we were. It showed how a team could come together under intense stress, and how we could set the standard going forward for how companies disclose and talk about security problems. I personally discovered that a Google Meet call can be kept running for 24 hours and sleeping in two hour chunks is possible.</p>
          <p>
            <h3 id="being-international-and-intentional">Being international and intentional</h3>
            
          </p>
        <p>Originally from the UK, I was the first team member located outside the United States. I got to help build the largest offices outside the US: first, Cloudflare’s London office and then Cloudflare’s <a href="https://blog.cloudflare.com/cloudflare-lisbon-office/"><u>Lisbon office</u></a>. These two offices are a big part of who we are today, with Lisbon being our European HQ.</p><p>When COVID halted our in-office work, I was blown away by the response from the team. As we all individually faced different difficulties because of the pandemic we continued to work together to ensure that the Internet, on which everyone was relying while confined at home, worked reliably and securely.</p>
          <p>
            <h3 id="truly-impactful-technology">Truly impactful technology</h3>
            
          </p>
        <p>Picking a favourite product would be a bit like asking someone to choose their favourite child, but I have soft spots for Cloudflare’s WAF, DNS, and DDoS solutions because I personally worked on those systems. And I still feel I need to apologize to the WAF team who took over my code and had to face that one Perl script that shall not be named!</p><p>Beyond the products there’s something much deeper: Cloudflare’s mission to help build a better Internet. I’ve been very proud of how we have supported and advanced the Internet itself through our work on the latest standards and protocols. And I’m even prouder of the role we’ve played through Project Galileo, The Athenian Project, and Cloudflare for Campaigns.</p>
          <p>
            <h3 id="the-people">The people</h3>
            
          </p>
        <p>Every week Cloudflare holds an all-hands company meeting which ends with “Shoutouts,” a chance to recognize members of the team who have gone above and beyond. Curiosity and empathy are two core values at Cloudflare, and I am struck every week by how often we’re recognizing teams of people who are being thanked for helping with a sale, fixing a bug, responding to an incident, or helping build Cloudflare. That team spirit is part of what makes Cloudflare a special place to work.</p><p>One of the things I will miss about not being at Cloudflare day-to-day is the incredible strength of the individual team members. I’ve been learning from them for 13 years straight!</p>
          <p>
            <h3 id="whats-next">What’s next</h3>
            
          </p>
        <p>When I joined the company the team was a lot smaller! We were 25 people and now, we’ve grown to more than 4,200 employees and 15 locations across the globe. As we grew I wore a lot of different hats. For a time I ran engineering, operations, security, and even IT. And, of course, I wrote for, and edited, the Cloudflare Blog for many, many years. Over time, we hired many great leaders to run those teams.</p><p>But the role that persisted was CTO. And today, we are announcing that, just as I gave up the title Programmer (and the programming that went along with it), I am giving up the title CTO (and the role’s responsibilities) for a new way to help Cloudflare grow and succeed, as a member of the board of directors.</p><p>Last year when I told Matthew that I planned to retire, I had not expected to be offered a seat on the company’s board. It’s an incredible and rare honour to go from being an employee of the company (albeit one who has been there from close to the beginning) to joining the board of directors. I am absolutely thrilled to be able to continue helping Cloudflare grow and succeed from a slightly different vantage point.</p><p>At the same time, Dane Knecht, who, until today, was SVP of Emerging Technology and Incubation, has become our CTO. Dane joined just a few months after me, and is uniquely positioned and experienced to take the CTO role. We’ve worked so closely for the last 13 years as peers, that in many meetings it would’ve been hard to distinguish our roles. I’m pretty sure that Dane bleeds Cloudflare orange, and I’ve never seen him wear a T-shirt that doesn’t say Cloudflare on it. He has been part of nearly every major milestone here at Cloudflare. He cares so deeply about the company, and its success; he will make a great CTO.</p><p>My plan isn’t to go off and work somewhere else, or start a new company. I intend to remain closely involved with Cloudflare in my role on the board. I am incredibly honoured, and grateful to have been part of Cloudflare’s incredible growth and success, and I am looking forward to helping the company continue its growth.</p><p>One area I’m particularly interested in assisting with is the company’s work across the product suite on AI. Back in 2002 (23 years ago! gulp!). I wrote a very popular open source machine learning (didn’t call it AI back then) <a href="https://en.wikipedia.org/wiki/POPFile"><u>email filtering program</u></a> and in 2004 worked on how to deal with what happens when <a href="https://blog.jgc.org/2023/07/how-to-beat-adaptivebayesian-spam.html"><u>one AI system is used to attack another</u></a>. At Cloudflare, we’ve used learning techniques to enhance security, block bots, and predict how our systems should behave and grow. There’s much more to do.</p><p>Just as co-founder <a href="https://blog.cloudflare.com/author/michelle-zatlyn/"><u>Michelle</u></a> likes to say: we’re just getting started. And so am I.</p></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/life-at-cloudflare/">Life at Cloudflare</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ty: A fast Python type checker and language server, written in Rust (712 pts)]]></title>
            <link>https://github.com/astral-sh/ty</link>
            <guid>43918484</guid>
            <pubDate>Wed, 07 May 2025 17:32:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/astral-sh/ty">https://github.com/astral-sh/ty</a>, See on <a href="https://news.ycombinator.com/item?id=43918484">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ty</h2><a id="user-content-ty" aria-label="Permalink: ty" href="#ty"></a></p>
<p dir="auto">An extremely fast Python type checker and language server, written in Rust.</p>
<p dir="auto"><strong>This project is still in development and is not ready for production use.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting involved</h2><a id="user-content-getting-involved" aria-label="Permalink: Getting involved" href="#getting-involved"></a></p>
<p dir="auto">If you have questions or want to report a bug, please open an
<a href="https://github.com/astral-sh/ty/issues">issue</a> in this repository.</p>
<p dir="auto">Development of this project takes place in the <a href="https://github.com/astral-sh/ruff">Ruff</a> repository
at this time. Please <a href="https://github.com/astral-sh/ruff/pulls">open pull requests</a> there for changes
to anything in the <code>ruff</code> submodule (which includes all of the Rust source code).</p>
<p dir="auto">See the
<a href="https://github.com/astral-sh/ty/blob/main/CONTRIBUTING.md">contributing guide</a> for more details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">ty is licensed under the MIT license (<a href="https://github.com/astral-sh/ty/blob/main/LICENSE">LICENSE</a> or
<a href="https://opensource.org/licenses/MIT" rel="nofollow">https://opensource.org/licenses/MIT</a>).</p>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in ty
by you, as defined in the MIT license, shall be licensed as above, without any additional terms or
conditions.</p>
<p><a href="https://astral.sh/" rel="nofollow">
    <img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg" alt="Made by Astral">
  </a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Samsung is paying $350M for audio brands B&W, Denon, Marantz and Polk (126 pts)]]></title>
            <link>https://www.engadget.com/audio/samsung-is-paying-350-million-for-audio-brands-bowers--wilkins-denon-marantz-and-polk-131514754.html</link>
            <guid>43918437</guid>
            <pubDate>Wed, 07 May 2025 17:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/audio/samsung-is-paying-350-million-for-audio-brands-bowers--wilkins-denon-marantz-and-polk-131514754.html">https://www.engadget.com/audio/samsung-is-paying-350-million-for-audio-brands-bowers--wilkins-denon-marantz-and-polk-131514754.html</a>, See on <a href="https://news.ycombinator.com/item?id=43918437">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Harman International, a wholly owned subsidiary of Samsung, is <a data-i13n="cpos:1;pos:1" href="https://news.harman.com/releases/masimo-to-sell-consumer-audio-business-to-harman-international" rel="nofollow noopener" target="_blank" data-ylk="slk:purchasing;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">purchasing</a> the audio business of health technology company Masimo for $350 million in cash. The deal is expected to finalized by the end of 2025, though it's still subject to regulatory approvals. Samsung <a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/2017-03-10-samsung-completes-its-biggest-acquisition-ever.html" data-ylk="slk:purchased Harman International;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas">purchased Harman International</a> back in 2017 for $8 billion, though it allowed the company to operate as an independent subsidiary. Harman's brands include JBL, <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/2020-01-06-harman-kardon-fly-wireless-headphones.html" data-ylk="slk:Harman Kardon;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas">Harman Kardon</a>, AKG, Mark Levinson, Arcam and Revel. If and when the acquisition pushes through, Masimo's audio brands under Sound United will be added to the list, including <a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/audio/headphones/bowers--wilkins-pi8-review-excellent-sound-comes-at-a-high-price-160032718.html" data-ylk="slk:Bowers &amp; Wilkins;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas">Bowers &amp; Wilkins</a>, <a data-i13n="cpos:5;pos:1" href="https://www.engadget.com/denons-latest-wireless-subwoofer-works-with-its-soundbar-550-and-wireless-speakers-055521736.html" data-ylk="slk:Denon;cpos:5;pos:1;elm:context_link;itc:0;sec:content-canvas">Denon</a>, <a data-i13n="cpos:6;pos:1" href="https://www.engadget.com/denon-marantz-avr-8k-120-4k-hdmi-2-1-034644796.html" data-ylk="slk:Marantz;cpos:6;pos:1;elm:context_link;itc:0;sec:content-canvas">Marantz</a> and <a data-i13n="cpos:7;pos:1" href="https://www.engadget.com/polk-audio-magnifi-mini-ax-soundbar-specs-price-090043733.html" data-ylk="slk:Polk Audio;cpos:7;pos:1;elm:context_link;itc:0;sec:content-canvas">Polk Audio</a>.</p><p>It is unclear if the purchase will lead to layoffs, but it sounds like Harman is taking on Sound United's employees. "Built on a shared legacy of innovation and excellence in audio technology, this combined family of brands, together with the talented employees of both companies, will deliver complementary audio products, strengthen our value proposition and offer more choices to consumers," said Dave Rogers, the President of Harman's Lifestyle division.</p><p>As noted by <a data-i13n="cpos:8;pos:1" href="https://www.theverge.com/news/662437/samsung-harman-masimo-aquisition-audio-empire" rel="nofollow noopener" target="_blank" data-ylk="slk:The Verge;cpos:8;pos:1;elm:context_link;itc:0;sec:content-canvas"><em>The Verge</em></a>, Samsung <a data-i13n="cpos:9;pos:1" href="https://news.samsung.com/kr/%EC%98%A4%EB%94%94%EC%98%A4-%E5%90%8D%E5%AE%B6-%ED%95%98%EB%A7%8C-%E7%BE%8E-%EB%A7%88%EC%8B%9C%EB%AA%A8%E7%A4%BE-%EC%98%A4%EB%94%94%EC%98%A4-%EC%82%AC%EC%97%85%EB%B6%80%EB%AC%B8-%EC%9D%B8%EC%88%98" rel="nofollow noopener" target="_blank" data-ylk="slk:published;cpos:9;pos:1;elm:context_link;itc:0;sec:content-canvas">published</a> a press release, where it briefly talked about the history of the brands it's acquiring. It mentioned some of Bowers &amp; Wilkins' most iconic products, such as the Nautilus loudspeaker (pictured above) and its <a data-i13n="cpos:10;pos:1" href="https://www.engadget.com/bowers-wilkins-new-zeppelin-speaker-070023824.html" data-ylk="slk:Zeppelin wireless speaker;cpos:10;pos:1;elm:context_link;itc:0;sec:content-canvas">Zeppelin wireless speaker</a>, as well as Denon's history as an early adopter of the CD player. Harman had a 60 percent market share in portable audio devices last year, and the company is looking to maintain that position with this purchase. "By combining the audio business of Masimo, which is being acquired this time, with Harman’s lifestyle business division, the company plans to solidify its global No. 1 position in the consumer audio market," Samsung said. Samsung also plans to apply the new brands' audio technologies to its smartphones, TVs, wireless earphones, soundbars and other devices in the future.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting Older Isn't What You Think (141 pts)]]></title>
            <link>https://www.katycowan.co.uk/blog/getting-old</link>
            <guid>43917855</guid>
            <pubDate>Wed, 07 May 2025 16:41:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.katycowan.co.uk/blog/getting-old">https://www.katycowan.co.uk/blog/getting-old</a>, See on <a href="https://news.ycombinator.com/item?id=43917855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-54a1062e88e967d6c807">
  <p>Getting old creeps up on you. It’s not sudden. There’s no dramatic moment where you wake up and realise you’re “not getting any younger”. No — it’s more like a slow progression. One day, you’re out at a bar, dancing with friends, living your best life, and the next, you’re peeking over your sunglasses in horror at someone calling 36 “old”.</p><p>Case in point: I was at a pub the other evening. Lovely place. Wood-fired pizza, fairy lights, good vibes. The chap manning the pizza oven — a friendly local lad — was chatting with some customers about how old he felt now he was 36. “It’s nice being this age because I have <em>wisdom</em>,” he said earnestly, as I slid my sunglasses to the tip of my nose to double-check I’d heard him right. “Oh please,” I muttered under my breath. “Add a decade, mate, and <em>then</em> we’ll talk…”</p><p>But I get it. I really do. Lately, I’ve been noticing little shifts in myself, too. I recently watched Bob Mortimer and Paul Whitehouse chatting about how they now prefer peace and quiet, and I felt seen. For years, I resisted it — the craving for calm. But these days, there’s nothing lovelier than a Saturday morning with a bit of jazz or classical playing, pottering about the kitchen, and then being tucked up in bed before 10pm. Wild.</p><p>And then there are the festivals. I saw a reel the other day of a young woman lamenting how too put-together everyone looks at Coachella now. She missed the old days — the raw Glastonbury vibes when Kate Moss and Alexa Chung looked cool in a completely effortless, “slightly grubby way”. Give me strength. In my day, we weren’t worried about matching our outfits to the sunset. We wore walking gear. Fleeces. Army boots. Practicality over aesthetics. The moment I saw girls tottering through the Glasto mud in silver hot pants and white knee-high boots, I knew the party was over — for me, at least.</p><p>I’m getting old. There, I said it. But honestly? Is this really an age thing, or more of a realisation that I might always have preferred a quieter life? I suspect it’s the latter. And where do these expectations and stereotypes come from anyway? Are they ones we put on ourselves, or do they come from others?</p><p>Yes, I once enjoyed the gigs, the clubbing… the organised fun of it all. But these days? Give me a freshly laundered set of pyjamas and a good book any day over a weekend at a boutique festival. This isn’t about the looming big birthday on the horizon. I know plenty of people my age who are still partying — because they always loved it.</p><p>I guess I’m feeling reflective. I’m turning 50 soon. And so far, this whole ageing conversation has been dominated by the Boomers, often blamed for the world’s problems or pitted against younger generations. A tad unfair. They just happened to get lucky, right?</p><p>Meanwhile, I come from a brilliant generation that’s hardly ever talked about.</p><p>We were the kids who missed the first wave of acid house but still got swept up in the afterglow. We straddle the line between Gen X and Millennials — the so-called Xennials. We grew up analogue and came of age in the digital revolution. We spent more time climbing trees, riding bikes and playing football than we looked at any screen. We remember our landline numbers (mine had four digits), taping songs off the radio, and the thrill of a HMV shopping spree. We experienced life without social media, but we also remember getting our first Nokia and the magic of MSN Messenger. And we watched in awe as computers went from enormous desktop towers to sleek little rectangles we now carry around in our pockets.</p><p>We had dial-up internet and floppy disks, but we also built our first websites on GeoCities and wrote painstaking HTML in Notepad. We remember MySpace before Facebook and how thrilling it was to burn your own CD mixes. We lived through the Y2K panic, wore chokers, ankle bracelets, and Kickers, and watched <em>Friends</em> live, not on Netflix. We worshipped the TV and waited weeks for new films to arrive on VHS. In our teenage years, many of us were into Rage Against The Machine, Faith No More, The Prodigy and LTJ Bukem. We loved The Word and EuroTrash. Some of us got stoned on purpose to enjoy playing WipeOut on the first-ever PlayStation. We bought MixMag for the gig and club listings. We remember festivals before they became a fashion parade. And yes, some of us took drugs and travelled the world. I certainly did. Fridays were once sacred, too, and Tim Westwood’s jingle on Radio One always marked the beginning of another weekend.</p><p>We’re a small generation, often overlooked, but we’ve lived through more change than most—from mixtapes to Spotify, from faxes to WhatsApp, from digital revolution to AI. And because we existed in that liminal space, we carry a weird dual wisdom: we know how to live offline, but we can thrive online, too.</p><p>We understand the value of privacy and impermanence because we remember a time before everything was public and permanent. And maybe that’s why so many of us are quietly deleting our social media accounts and leaning into real life again — books, dinners, walks, actual phone calls. Imagine!</p><p>We were also Cool Britannia — all about unity, not division. One love. It makes me sad to see what social media has done to the world — all the anxiety, the polarisation, the performance. And honestly? I’m quietly pleased to see its grip loosening.</p><p>These days, I sometimes catch myself muttering at the telly, shaking my head at a clueless reality show contestant, thinking: <em>You just wait, sunshine. You’ll get old, too.</em> And yes, I do roll my eyes at some of the newer buzzwords. But I try to check myself. Because if ageing has taught me anything, it’s that the biggest danger is certainty.</p><p>That’s the tension, isn’t it? The constant tug-of-war between feeling grumpy and still clinging to some version of youth. I never thought I’d be that person. But here I am.</p><p>Yes, getting older can mean becoming stuck or rigid. But ironically, I’ve seen just as much of that in younger people lately — unwilling to listen, quick to judge, terrified of being wrong. When nuanced debate disappears, we stop growing. And the less we challenge ourselves, the dumber we become, not smarter.</p><p>So here’s what I try to remember, at any age: stay curious. Never assume you’re right. Read the newspapers you’d generally avoid. Challenge even your most cherished opinions. Try to see more than one side. You won’t always succeed, but it’s worth the effort.</p><p>Because if growing older has taught me anything, it’s this: certainty is overrated, and listening is wildly underrated. Cosy nights in don’t mean you’ve given up. They just mean you know what you like — and that maybe, just maybe, you never truly loved going to gigs as much as you pretended to. You stop performing. You stop pretending. And that’s freedom.</p><p>It’s a funny thing, ageing. You get clearer on who you are, while also realising how much you still don’t know.</p><p>Being this age doesn’t mean your mind is closed. And youth doesn’t automatically mean fun. We’re all just figuring ourselves out, no matter the year on our birth certificate.</p><p>Getting older isn’t a bad thing. It’s when things get interesting. But no matter how old you are, stay curious. That’s the only thing worth clinging to.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Create and edit images with Gemini 2.0 in preview (198 pts)]]></title>
            <link>https://developers.googleblog.com/en/generate-images-gemini-2-0-flash-preview/</link>
            <guid>43917461</guid>
            <pubDate>Wed, 07 May 2025 16:06:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/generate-images-gemini-2-0-flash-preview/">https://developers.googleblog.com/en/generate-images-gemini-2-0-flash-preview/</a>, See on <a href="https://news.ycombinator.com/item?id=43917461">Hacker News</a></p>
<div id="readability-page-1" class="page">
        <!-- Google Tag Manager (noscript) -->
        
        <!-- End Google Tag Manager (noscript) -->

        

				
        

<!-- HTML -->


<div top-level-nav="">
  <nav aria-label="Side menu">
    
    <div>
        <ul>
          <li>
            <a href="https://developers.google.com/products" data-label="Tab: Products">
              <span tooltip="">
                Products
             </span>
            </a>
            <ul>
              <li>
                <span tabindex="0" data-label="More Products">
                  <span menu="Products">
                    More
                  </span>
                  <span menu="Products">
                    
                  </span>
                </span>
              </li>
            </ul>
          </li>
          <li>
            <a href="https://developers.google.com/solutions/catalog" data-label="Tab: Solutions">
              <span tooltip="">
                Solutions
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.google.com/events" data-label="Tab: Events">
              <span tooltip="">
                Events
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.google.com/learn" data-label="Tab: Learn">
              <span tooltip="">
                Learn
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.google.com/community" data-label="Tab: Community">
              <span tooltip="">
                Community
             </span>
            </a>
            <ul>
              <li>
                
              </li>
            </ul>
          </li>
          <li>
            <a href="https://developers.google.com/profile/u/me" data-label="Tab: Developer Program">
              <span tooltip="">
                Developer Program
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.googleblog.com/" data-label="Tab: Blog">
              <span tooltip="">
                Blog
             </span>
            </a>
          </li>
        </ul>
      </div>
  </nav>
  </div>



        
  <div>

    
      
    

    

    

    <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Kat+Kampf">Kat Kampf</a>
            
              <span>Product Manager</span>
            
            
              <span>Google AI Studio</span>
            
          </p>
        

      
      </section>

    
    <div>
          

<div>
    <p data-block-key="e2q03">Based on the enthusiasm from developers, we are excited to announce that <b>Image Generation</b> capabilities are now available in preview with <b>Gemini 2.0 Flash</b>.</p><p data-block-key="bek1n">Developers can start integrating conversational image generation and editing with higher rate limits via the Gemini API in <a href="https://aistudio.google.com/app/prompts/new_chat?model=gemini-2.0-flash-preview-image-generation">Google AI Studio</a> and <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a> today using the model name “gemini-2.0-flash-preview-image-generation”.</p><h2 data-block-key="5c4n8" id="what's-new-in-gemini-2.0-flash-image-generation"><b><br></b>What's new in Gemini 2.0 Flash image generation</h2><p data-block-key="egoj9">In addition to enabling <a href="https://ai.google.dev/gemini-api/docs/rate-limits#current-rate-limits">higher rate limits</a> and <a href="https://ai.google.dev/gemini-api/docs/pricing">pricing</a>, we have also improved the model with:</p><ul><li data-block-key="1m7bc">Better visual quality (vs experimental version)</li></ul><ul><li data-block-key="2ofkt">More accurate text rendering (vs experimental version)</li></ul><ul><li data-block-key="bmhqf">Significantly reduced filter block rates (vs experimental version)</li></ul><h2 data-block-key="tn0z7" id="gemini-2.0-flash-image-generation-in-action"><b><br></b>Gemini 2.0 Flash image generation in action</h2><p data-block-key="87qlc">We have loved seeing the community reception of Gemini's image generation capabilities. Here’s a closer look at some of the key functionalities developers have been excited about:</p><h3 data-block-key="sscig" id="1)-recontextualize-products-in-new-environments."><br><b>1) Recontextualize products in new environments.</b></h3>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-0-image-recontextualization-before-and.original.png" alt="Gemini 2.0 image recontextualization: before and after">
        
        
    </p>
</div>
  <div>
    <h3 data-block-key="58t08" id=""><b>2) Collaboratively edit images in real-time.</b></h3><p data-block-key="uf5t">Try it today with the <a href="https://aistudio.google.com/apps/bundled/gemini-co-drawing?showPreview=true">Gemini Co-Drawing Sample App</a> in AI Studio.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-zvio6zw2_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/gemini-co-drawing.mp4" type="video/mp4">
<p>Sorry, your browser doesn't support playback for this video</p>

</video>
    
    
</div>  <p>
    <h3 data-block-key="r0kg3" id=""><b>3) Edit specific parts of images conversationally, without changing anything else.</b></h3>
</p>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_2.0_Flash_conversational_image_editing_-.original_oTD4bK8.png" alt="Gemini 2.0 Flash conversational image editing - before and after">
        
        
    </p>
</div>
  <p>
    <h3 data-block-key="a4sqd" id="4)-dynamically-create-new-product-skus-with-text-rendering-and-image."><b>4) Dynamically create new product SKUs with text rendering and image.</b></h3>
</p>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_2.0_Flash_dynamically_creates_new_produc.original.png" alt="Gemini 2.0 Flash dynamically creates new product SKUs with image">
        
        
    </p>
</div>
   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-0-dynamically-creates-new-product-sku-.original.png" alt="Gemini 2.0 Flash dynamically creating new product SKUs with text rendering - result">
        
        
    </p>
</div>
  <p>
    <h3 data-block-key="68vm0" id=""><b>5) Ideate with Gemini 2.0 Flash as your partner:</b></h3>
</p>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-_7pt7bv8_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/Gemini_2.0_Flash_collaborative_editing.mp4" type="video/mp4">
<p>Sorry, your browser doesn't support playback for this video</p>

</video>
    
    
        
            <p>
                (right click and open in new tab to view)
            </p>
        
    
</div>  <p>
    <h2 data-block-key="91qfx" id="">Start building with Gemini’s native image capabilities today</h2>
</p>   

<div>
    <div><pre><span></span><span>from</span> <span>google</span> <span>import</span> <span>genai</span>
<span>from</span> <span>google.genai</span> <span>import</span> <span>types</span>
<span>client</span> <span>=</span> <span>genai</span><span>.</span><span>Client</span><span>(</span><span>api_key</span><span>=</span><span>"GEMINI_API_KEY"</span><span>)</span>
<span>response</span> <span>=</span> <span>client</span><span>.</span><span>models</span><span>.</span><span>generate_content</span><span>(</span>
   <span>model</span><span>=</span><span>"gemini-2.0-flash-preview-image-generation"</span><span>,</span>
   <span>contents</span><span>=</span><span>(</span>
       <span>"Show me how to bake a macaron with images."</span>
   <span>),</span>
   <span>config</span><span>=</span><span>types</span><span>.</span><span>GenerateContentConfig</span><span>(</span>
        <span>response_modalities</span><span>=</span><span>[</span><span>"TEXT"</span><span>,</span> <span>"IMAGE"</span><span>]</span>
   <span>),</span>
<span>)</span>
</pre></div>
    <p><span>Copied</span>
        
    </p>
</div>  <div>
    <p data-block-key="57v87">You can read more about image generation in our <a href="https://ai.google.dev/gemini-api/docs/image-generation">API docs</a>. This preview is available for developers to start building through <a href="https://aistudio.google.com/app/prompts/new_chat?model=gemini-2.0-flash-preview-image-generation">Google AI Studio</a> and <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a> .</p><p data-block-key="d5unj">We look forward to bringing further quality improvements, new capabilities, and expanded rate limits soon. We can’t wait to see what you build with Gemini 2.0 Flash Image Generation.</p>
</div> 
      </div>
    

    

    
    
    
  </div>


				
				





        
				

        
        
        
        

        

        
  

    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenSearch 3.0 Released (103 pts)]]></title>
            <link>https://opensearch.org/blog/opensearch-3-0-enhances-vector-database-performance/</link>
            <guid>43917122</guid>
            <pubDate>Wed, 07 May 2025 15:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensearch.org/blog/opensearch-3-0-enhances-vector-database-performance/">https://opensearch.org/blog/opensearch-3-0-enhances-vector-database-performance/</a>, See on <a href="https://news.ycombinator.com/item?id=43917122">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-4962">
  
  <div data-hide-featured-media="1"><p>Latest iteration bolsters open, scalable, community-driven search and analytics, enabling sustainable innovation</p>
<p><strong>SAN FRANCISCO – May 6, 2025 –</strong> The <a href="https://hubs.la/Q03ldHNd0">OpenSearch Software Foundation</a>, the vendor-neutral home for the OpenSearch Project, today announced the general availability of OpenSearch 3.0. This major release delivers a 9.5x performance improvement over OpenSearch 1.3, building on <a href="https://hubs.la/Q03ldJkL0">benchmarking data</a> that showed earlier iterations of OpenSearch operating 1.6x faster than its closest industry competitor.</p>
<p>Today’s AI applications — like generative AI, hybrid search, retrieval-augmented generation (RAG) and recommendation engines — rely heavily on vector databases to find patterns in massive, complex datasets, but as the number of vectors explodes into the billions, many organizations struggle with speed, spend and scalability. <a href="https://www.forrester.com/report/the-forrester-wave-tm-vector-databases-q3-2024/RES181372">Forrester</a> emphasizes that traditional databases are no longer able to meet the growing demands of generative AI due to limitations in supporting modern vector multidimensional data and performing similarity searches.</p>
<p>OpenSearch 3.0 addresses this challenge and enables users to increase efficiency, deliver superior performance, and accelerate AI application development via new data management, AI agent, and vector search capabilities. Simultaneously, enhancements such as GPU-supported capabilities can reduce costs by 3.75x.</p>
<p>“The enterprise search market is skyrocketing in tandem with the acceleration of AI, and it is projected to reach $8.9 billion by 2030,” said Carl Meadows, Governing Board Chair at the OpenSearch Software Foundation and Director of Product Management at Amazon Web Services (AWS). “OpenSearch 3.0 is a powerful step forward in our mission to support the community with an open, scalable platform built for the future of search and analytics, and it reflects our commitment to open collaboration and innovation that drives real-world impact.”</p>
<p><strong>Vector engine innovations increase processing speed and efficiency</strong></p>
<p>To support its large-scale search platform and manage a vast amount of vector data, OpenSearch introduced GPU-based acceleration, <a href="https://hubs.la/Q03ldJnV0">leveraging NVIDIA cuVS</a> for indexing workflows. New <a href="https://hubs.la/Q03ldxF_0">vector engine</a> features include:</p>
<ul>
<li aria-level="1"><strong>GPU Acceleration for OpenSearch Vector Engine:</strong> Delivers superior performance for large-scale vector workloads while significantly lowering operational spend by reducing index building time. By enabling GPU deployment, this experimental feature heightens performance for data-intensive workloads and accelerates index builds by up to 9.3x.</li>
<li aria-level="1"><strong>Model Context Protocol (MCP) Support:</strong> Native MCP support allows AI agents to easily communicate with OpenSearch, enabling more comprehensive and customizable AI-powered solutions.</li>
<li aria-level="1"><strong>Derived Source:</strong> Reduces storage consumption by one-third by removing redundant vector data sources and utilizing primary data to recreate source documents as needed for reindexing or source call back.</li>
</ul>
<p><strong>Data management features optimize resources, enhance flexibility and drive scalability</strong></p>
<p>OpenSearch 3.0 provides major advancements in how the platform ingests, transports and manages data including:</p>
<ul>
<li><strong>Support for gRPC:</strong> Enables faster and more efficient data transport and data processing for OpenSearch deployments. This experimental feature provides a new approach to data transport between clients, servers, and node-to-node communications in OpenSearch.</li>
<li><strong>Pull-based Ingestion:</strong> Enhances ingestion efficiency and gives OpenSearch more control over the flow of data and when it’s retrieved by decoupling data sources and data consumers. This experimental feature also allows users to pull data from streaming systems like Apache Kafka and Amazon Kinesis.</li>
<li><strong>Reader and Writer Separation:</strong> Ensures consistent, high-quality performance for indexing and search workloads by configuring each in isolation, allowing both workloads to work at optimal speed and scale, rather than decreasing in efficiency when the other is taxed.</li>
<li><strong>Apache Calcite Integration:</strong> Enables intuitive, iterative query building and exploration by integrating the query builder into OpenSearch SQL and PPL. Simplifies use cases for security, observability and log analysis.</li>
<li><strong>Index Type Detection:</strong> Enhances productivity by automatically determining whether an OpenSearch index contains log-related data and speeding up log analysis feature selection.</li>
</ul>
<p><strong>Core upgrades help future-proof OpenSearch’s search platform and analytics suite</strong></p>
<p>Enhancements to the platform’s search infrastructure – removing legacy code, adopting a modular architecture and aligning with the latest Java advancements – boosts maintainability, performance potential, and efficiency. Updates include:</p>
<ul>
<li><strong>Lucene 10 Upgrade:</strong> Modernizes the platform’s search infrastructure to ensure long-term innovation, improve indexing and search capabilities, and increase performance of parallel task execution.</li>
<li><strong>Java 21 Minimum Supported Runtime:</strong> Enables access to modern language features and performance improvements.</li>
<li aria-level="1"><strong>Java Platform Module System Support:</strong> Improves organization, eliminates top level split packages and creates a foundation for refactoring the monolithic server module into separable libraries.</li>
</ul>
<p>OpenSearch 3.0 is now available. See the official release <a href="https://hubs.la/Q03ldJsC0">blog</a> for more information and <a href="https://github.com/opensearch-project/opensearch-build/blob/main/release-notes/opensearch-release-notes-3.0.0.md">full release notes</a>. To learn more about the OpenSearch Software Foundation, including how to get involved, become a member or contribute, please visit <a href="https://hubs.la/Q03ldK8Z0">foundation.opensearch.org/</a>.</p>
<p><strong>About the OpenSearch Software Foundation</strong></p>
<p>The OpenSearch Software Foundation is a vendor-neutral community for search, analytics, observability, and vector database software. Hosted by the Linux Foundation and supported by premier members such as AWS, SAP and Uber, the OpenSearch Software Foundation works with community maintainers, developers, and member organizations to drive the continued growth of the OpenSearch project. With more than 900 million software downloads since its inception and participation from thousands of contributors, the OpenSearch project and its community are transforming how information is managed and discovered. To learn more, please visit <a href="http://foundation.opensearch.org/">foundation.opensearch.org</a>.</p>
<p><em>The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/legal/trademark-usage">trademark</a> usage page. Linux is a registered trademark of Linus Torvalds.</em></p>
<p>Media Contact<br>
Kristi Piechnik<br>
The Linux Foundation<br>
<a href="mailto:kpiechnik@linuxfoundation.org">kpiechnik@linuxfoundation.org</a></p>

                
                    <!--begin code -->

                    
                    <div data-post_id="137" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-137 box-instance-id-1">
                                                                                                                                    <p><span>
                                                                                                                        <ul>
                                                                                                                                                                                                                                                                                                                                                            
                                                                                                                    <li>
                                                                                                                                                                                    <div>
                                                                    <p><img alt="OpenSearch" src="https://secure.gravatar.com/avatar/?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/?s=96&amp;d=mm&amp;r=g 2x" height="96" width="96">                                                                                                                                                                                                            </p>
                                                                                                                                    </div>
                                                            
                                                            
                                                                                                                                                                                                                        </li>
                                                                                                                                                                                                                                    </ul>
                                                                            </span>
                                                                                                                        </p></div>
                    <!--end code -->
                    
                
                            
        

</div><!--/inner-wrap-->
    
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: eInk optimized manga with Kindle Comic Converter (+Kobo/ReMarkable) (215 pts)]]></title>
            <link>https://github.com/ciromattia/kcc</link>
            <guid>43916956</guid>
            <pubDate>Wed, 07 May 2025 15:26:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ciromattia/kcc">https://github.com/ciromattia/kcc</a>, See on <a href="https://news.ycombinator.com/item?id=43916956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ciromattia/kcc/blob/master/header.jpg"><img src="https://github.com/ciromattia/kcc/raw/master/header.jpg" alt="Header Image" width="400"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">KCC</h2><a id="user-content-kcc" aria-label="Permalink: KCC" href="#kcc"></a></p>
<p dir="auto"><a href="https://github.com/ciromattia/kcc/releases"><img src="https://camo.githubusercontent.com/861ac4533464de62050560a54760d40d2c760735f698f851092ab534801d57c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6369726f6d61747469612f6b63632e737667" alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/ciromattia/kcc.svg"></a>
<a href="https://github.com/ciromattia/kcc/pkgs/container/kcc"><img src="https://camo.githubusercontent.com/d03ab2b9b88cbde2cbe9ca27dc30b65ee73d4bd09ebd0175fd4be5feb1f57c6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f6369726f6d61747469612f6b63632f646f636b65722d7075626c6973682e796d6c3f6c6162656c3d646f636b65722532306275696c64" alt="GitHub Workflow Status" data-canonical-src="https://img.shields.io/github/actions/workflow/status/ciromattia/kcc/docker-publish.yml?label=docker%20build"></a></p>
<p dir="auto"><strong>Kindle Comic Converter</strong> optimizes comics and manga for eink readers like Kindle, Kobo, ReMarkable, and more.
Pages display in fullscreen without margins, with proper fixed layout support.
Its main feature is various optional image processing steps to look good on eink screens,
which have different requirements than normal LCD screens.
It also does filesize optimization by downscaling to your specific device's screen resolution,
which can improve performance on underpowered ereaders.
Supported input formats include folders/CBZ/CBR/PDF of JPG/PNG files and more.
Supported output formats include virtual panel view MOBI/AZW3, EPUB, KEPUB, and CBZ.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/20757319/419286843-36ad2131-6677-4559-bd6f-314a90c27218.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NDI5MDEsIm5iZiI6MTc0NjY0MjYwMSwicGF0aCI6Ii8yMDc1NzMxOS80MTkyODY4NDMtMzZhZDIxMzEtNjY3Ny00NTU5LWJkNmYtMzE0YTkwYzI3MjE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDE4MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE0MTQyMGQ0N2RmNDhlMTE4ZWFjZWVhZTQ1MDc3ZGRkNTU2NTBiMWQyNTc2NjJiZDMwZGJkZjAwOWJhZmQ0ZjMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.dtBq3_hoM_PjqPvxDiOyEFS6mNjAbTMN3lmbtNI_9HU"><img src="https://private-user-images.githubusercontent.com/20757319/419286843-36ad2131-6677-4559-bd6f-314a90c27218.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NDI5MDEsIm5iZiI6MTc0NjY0MjYwMSwicGF0aCI6Ii8yMDc1NzMxOS80MTkyODY4NDMtMzZhZDIxMzEtNjY3Ny00NTU5LWJkNmYtMzE0YTkwYzI3MjE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDE4MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE0MTQyMGQ0N2RmNDhlMTE4ZWFjZWVhZTQ1MDc3ZGRkNTU2NTBiMWQyNTc2NjJiZDMwZGJkZjAwOWJhZmQ0ZjMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.dtBq3_hoM_PjqPvxDiOyEFS6mNjAbTMN3lmbtNI_9HU" alt="image"></a></p>
<p dir="auto">YouTube tutorial (please subscribe): <a href="https://www.youtube.com/watch?v=IR2Fhcm9658" rel="nofollow">https://www.youtube.com/watch?v=IR2Fhcm9658</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">A word of warning</h3><a id="user-content-a-word-of-warning" aria-label="Permalink: A word of warning" href="#a-word-of-warning"></a></p>
<p dir="auto"><strong>KCC</strong> <em>is not</em> <a href="http://www.amazon.com/gp/feature.html?ie=UTF8&amp;docId=1001103761" rel="nofollow">Amazon's Kindle Comic Creator</a> nor is in any way endorsed by Amazon.
Amazon's tool is for comic publishers and involves a lot of manual effort, while <strong>KCC</strong> is for comic/manga readers.
<em>KC2</em> in no way is a replacement for <strong>KCC</strong> so you can be quite confident we are going to carry on developing our little monster ;-)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Issues / new features / donations</h3><a id="user-content-issues--new-features--donations" aria-label="Permalink: Issues / new features / donations" href="#issues--new-features--donations"></a></p>
<p dir="auto">If you have general questions about usage, feedback etc. please <a href="http://www.mobileread.com/forums/showthread.php?t=207461" rel="nofollow">post it here</a>.
If you have some <strong>technical</strong> problems using KCC please <a href="https://github.com/ciromattia/kcc/issues/new">file an issue here</a>.
If you can fix an open issue, fork &amp; make a pull request.</p>
<p dir="auto">If you find <strong>KCC</strong> valuable you can consider donating to the authors:</p>
<ul dir="auto">
<li>
<p dir="auto">Ciro Mattia Gonano (founder, active 2012-2014):</p>
<p dir="auto"><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=D8WNYNPBGDAS2" rel="nofollow"><img src="https://camo.githubusercontent.com/2b3b3f38604d749b543e8577afdc6bd9fab25244f6cb16bfb713273a74350fd7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e737667" alt="Donate PayPal" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg"></a></p>
</li>
<li>
<p dir="auto">Paweł Jastrzębski (active 2013-2019):</p>
<p dir="auto"><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=YTTJ4LK2JDHPS" rel="nofollow"><img src="https://camo.githubusercontent.com/2b3b3f38604d749b543e8577afdc6bd9fab25244f6cb16bfb713273a74350fd7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e737667" alt="Donate PayPal" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg"></a>
<a href="https://jastrzeb.ski/donate/" rel="nofollow"><img src="https://camo.githubusercontent.com/701a9ad9d998658034948eca1eaf11b00306ed7551ce5db53fffca76ac8d5dbf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d426974636f696e2d677265656e2e737667" alt="Donate Bitcoin" data-canonical-src="https://img.shields.io/badge/Donate-Bitcoin-green.svg"></a></p>
</li>
<li>
<p dir="auto">Alex Xu (active 2023-Present)</p>
<p dir="auto"><a href="https://ko-fi.com/Q5Q41BW8HS" rel="nofollow"><img src="https://camo.githubusercontent.com/70e2ef5e0263b261f9a2a314bb1d6919d1d43292eed117fe8fc766a68c7d96ea/68747470733a2f2f6b6f2d66692e636f6d2f696d672f676974687562627574746f6e5f736d2e737667" alt="ko-fi" data-canonical-src="https://ko-fi.com/img/githubbutton_sm.svg"></a></p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsors</h2><a id="user-content-sponsors" aria-label="Permalink: Sponsors" href="#sponsors"></a></p>
<ul dir="auto">
<li>Free code signing on Windows provided by <a href="https://about.signpath.io/" rel="nofollow">SignPath.io</a>, certificate by <a href="https://signpath.org/" rel="nofollow">SignPath Foundation</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">DOWNLOADS</h2><a id="user-content-downloads" aria-label="Permalink: DOWNLOADS" href="#downloads"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/ciromattia/kcc/releases">https://github.com/ciromattia/kcc/releases</a></strong></li>
</ul>
<p dir="auto">Click on <strong>Assets</strong> of the latest release.</p>
<p dir="auto">You probably want either</p>
<ul dir="auto">
<li><code>KCC_*.*.*.exe</code> (Windows)</li>
<li><code>kcc_macos_arm_*.*.*.dmg</code> (recent Mac with Apple Silicon M1 chip or later)</li>
<li><code>kcc_macos_i386_*.*.*.dmg</code> (older Mac with Intel chip)</li>
</ul>
<p dir="auto">The <code>c2e</code> and <code>c2p</code> versions are command line tools for power users.</p>
<p dir="auto">On Windows 11, you may need to run in compatibility mode for an older Windows version.</p>
<p dir="auto">On Mac, right click open to get past the security warning.</p>
<p dir="auto">For flatpak, Docker, and AppImage versions, refer to the wiki: <a href="https://github.com/ciromattia/kcc/wiki/Installation">https://github.com/ciromattia/kcc/wiki/Installation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<ul dir="auto">
<li><a href="https://github.com/ciromattia/kcc/issues/678" data-hovercard-type="issue" data-hovercard-url="/ciromattia/kcc/issues/678/hovercard">Windows 7 support</a></li>
<li><a href="https://github.com/ciromattia/kcc/issues/612#issuecomment-2117985011" data-hovercard-type="issue" data-hovercard-url="/ciromattia/kcc/issues/612/hovercard">Combine files/chapters</a></li>
<li><a href="https://github.com/ciromattia/kcc/wiki/Installation#linux">Flatpak mobi conversion stuck</a></li>
<li>Image too dark?
<ul dir="auto">
<li>The default gamma correction of 1.8 makes the image darker, and is useful for faded/gray artwork/text. Disable by setting gamma = 1.0</li>
</ul>
</li>
<li><a href="https://github.com/ciromattia/kcc/issues/680" data-hovercard-type="issue" data-hovercard-url="/ciromattia/kcc/issues/680/hovercard">Better PDF support (Humble Bundle, Fanatical, etc)</a></li>
<li>Cannot connect Kindle Scribe or 2024+ Kindle to macOS
<ul dir="auto">
<li>Use official MTP <a href="https://www.amazon.com/gp/help/customer/display.html/ref=hp_Connect_USB_MTP?nodeId=TCUBEdEkbIhK07ysFu" rel="nofollow">Amazon USB File Transfer app</a>
(no login required). Works much better than previously recommended Android File Transfer. Cannot run simutaneously with other transfer apps.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">PREREQUISITES</h2><a id="user-content-prerequisites" aria-label="Permalink: PREREQUISITES" href="#prerequisites"></a></p>
<p dir="auto">You'll need to install various tools to access important but optional features. Close and re-open KCC to get KCC to detect them.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">KindleGen</h3><a id="user-content-kindlegen" aria-label="Permalink: KindleGen" href="#kindlegen"></a></p>
<p dir="auto">On Windows and macOS, install <a href="https://www.amazon.com/Kindle-Previewer/b?ie=UTF8&amp;node=21381691011" rel="nofollow">Kindle Previewer</a> and <code>kindlegen</code> will be autodetected from it.</p>
<p dir="auto">If you have issues detecting it, get stuck on the MOBI conversion step, or use Linux AppImage or Flatpak, refer to the wiki: <a href="https://github.com/ciromattia/kcc/wiki/Installation#kindlegen">https://github.com/ciromattia/kcc/wiki/Installation#kindlegen</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">7-Zip</h3><a id="user-content-7-zip" aria-label="Permalink: 7-Zip" href="#7-zip"></a></p>
<p dir="auto">This is optional but will make conversions much faster.</p>
<p dir="auto">This is required for certain files and advanced features.</p>
<p dir="auto">KCC will ask you to install if needed.</p>
<p dir="auto">Refer to the wiki to install: <a href="https://github.com/ciromattia/kcc/wiki/Installation#7-zip">https://github.com/ciromattia/kcc/wiki/Installation#7-zip</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">INPUT FORMATS</h2><a id="user-content-input-formats" aria-label="Permalink: INPUT FORMATS" href="#input-formats"></a></p>
<p dir="auto"><strong>KCC</strong> can understand and convert, at the moment, the following input types:</p>
<ul dir="auto">
<li>Folders containing: PNG, JPG, GIF or WebP files</li>
<li>CBZ, ZIP <em>(With <code>7z</code> executable)</em></li>
<li>CBR, RAR <em>(With <code>7z</code> executable)</em></li>
<li>CB7, 7Z <em>(With <code>7z</code> executable)</em></li>
<li>PDF <em>(Only extracting JPG images)</em></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">USAGE</h2><a id="user-content-usage" aria-label="Permalink: USAGE" href="#usage"></a></p>
<p dir="auto">Should be pretty self-explanatory. All options have detailed information in tooltips.
After completed conversion, you should find ready file alongside the original input file (same directory).</p>
<p dir="auto">Please check <a href="https://github.com/ciromattia/kcc/wiki/">our wiki</a> for more details.</p>
<p dir="auto">CLI version of <strong>KCC</strong> is intended for power users. It allows using options that might not be compatible and decrease the quality of output.
CLI version has reduced dependencies, on Debian based distributions this commands should install all needed dependencies:</p>
<div data-snippet-clipboard-copy-content="sudo apt-get install python3 p7zip-full python3-pil python3-psutil python3-slugify"><pre><code>sudo apt-get install python3 p7zip-full python3-pil python3-psutil python3-slugify
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Profiles:</h3><a id="user-content-profiles" aria-label="Permalink: Profiles:" href="#profiles"></a></p>
<div data-snippet-clipboard-copy-content="        'K1': (&quot;Kindle 1&quot;, (600, 670), Palette4, 1.8),
        'K11': (&quot;Kindle 11&quot;, (1072, 1448), Palette16, 1.8),
        'K2': (&quot;Kindle 2&quot;, (600, 670), Palette15, 1.8),
        'K34': (&quot;Kindle Keyboard/Touch&quot;, (600, 800), Palette16, 1.8),
        'K578': (&quot;Kindle&quot;, (600, 800), Palette16, 1.8),
        'KDX': (&quot;Kindle DX/DXG&quot;, (824, 1000), Palette16, 1.8),
        'KPW': (&quot;Kindle Paperwhite 1/2&quot;, (758, 1024), Palette16, 1.8),
        'KV': (&quot;Kindle Paperwhite 3/4/Voyage/Oasis&quot;, (1072, 1448), Palette16, 1.8),
        'KPW5': (&quot;Kindle Paperwhite 5/Signature Edition&quot;, (1236, 1648), Palette16, 1.8),
        'KO': (&quot;Kindle Oasis 2/3/Paperwhite 12/Colorsoft 12&quot;, (1264, 1680), Palette16, 1.8),
        'KS': (&quot;Kindle Scribe&quot;, (1860, 2480), Palette16, 1.8),
        'KoMT': (&quot;Kobo Mini/Touch&quot;, (600, 800), Palette16, 1.8),
        'KoG': (&quot;Kobo Glo&quot;, (768, 1024), Palette16, 1.8),
        'KoGHD': (&quot;Kobo Glo HD&quot;, (1072, 1448), Palette16, 1.8),
        'KoA': (&quot;Kobo Aura&quot;, (758, 1024), Palette16, 1.8),
        'KoAHD': (&quot;Kobo Aura HD&quot;, (1080, 1440), Palette16, 1.8),
        'KoAH2O': (&quot;Kobo Aura H2O&quot;, (1080, 1430), Palette16, 1.8),
        'KoAO': (&quot;Kobo Aura ONE&quot;, (1404, 1872), Palette16, 1.8),
        'KoN': (&quot;Kobo Nia&quot;, (758, 1024), Palette16, 1.8),
        'KoC': (&quot;Kobo Clara HD/Kobo Clara 2E&quot;, (1072, 1448), Palette16, 1.8),
        'KoCC': (&quot;Kobo Clara Colour&quot;, (1072, 1448), Palette16, 1.8),
        'KoL': (&quot;Kobo Libra H2O/Kobo Libra 2&quot;, (1264, 1680), Palette16, 1.8),
        'KoLC': (&quot;Kobo Libra Colour&quot;, (1264, 1680), Palette16, 1.8),
        'KoF': (&quot;Kobo Forma&quot;, (1440, 1920), Palette16, 1.8),
        'KoS': (&quot;Kobo Sage&quot;, (1440, 1920), Palette16, 1.8),
        'KoE': (&quot;Kobo Elipsa&quot;, (1404, 1872), Palette16, 1.8),
        'Rmk1': (&quot;reMarkable 1&quot;, (1404, 1872), Palette16, 1.8),
        'Rmk2': (&quot;reMarkable 2&quot;, (1404, 1872), Palette16, 1.8),
        'RmkPP': (&quot;reMarkable Paper Pro&quot;, (1620, 2160), Palette16, 1.8),
        'OTHER': (&quot;Other&quot;, (0, 0), Palette16, 1.8),"><pre><code>        'K1': ("Kindle 1", (600, 670), Palette4, 1.8),
        'K11': ("Kindle 11", (1072, 1448), Palette16, 1.8),
        'K2': ("Kindle 2", (600, 670), Palette15, 1.8),
        'K34': ("Kindle Keyboard/Touch", (600, 800), Palette16, 1.8),
        'K578': ("Kindle", (600, 800), Palette16, 1.8),
        'KDX': ("Kindle DX/DXG", (824, 1000), Palette16, 1.8),
        'KPW': ("Kindle Paperwhite 1/2", (758, 1024), Palette16, 1.8),
        'KV': ("Kindle Paperwhite 3/4/Voyage/Oasis", (1072, 1448), Palette16, 1.8),
        'KPW5': ("Kindle Paperwhite 5/Signature Edition", (1236, 1648), Palette16, 1.8),
        'KO': ("Kindle Oasis 2/3/Paperwhite 12/Colorsoft 12", (1264, 1680), Palette16, 1.8),
        'KS': ("Kindle Scribe", (1860, 2480), Palette16, 1.8),
        'KoMT': ("Kobo Mini/Touch", (600, 800), Palette16, 1.8),
        'KoG': ("Kobo Glo", (768, 1024), Palette16, 1.8),
        'KoGHD': ("Kobo Glo HD", (1072, 1448), Palette16, 1.8),
        'KoA': ("Kobo Aura", (758, 1024), Palette16, 1.8),
        'KoAHD': ("Kobo Aura HD", (1080, 1440), Palette16, 1.8),
        'KoAH2O': ("Kobo Aura H2O", (1080, 1430), Palette16, 1.8),
        'KoAO': ("Kobo Aura ONE", (1404, 1872), Palette16, 1.8),
        'KoN': ("Kobo Nia", (758, 1024), Palette16, 1.8),
        'KoC': ("Kobo Clara HD/Kobo Clara 2E", (1072, 1448), Palette16, 1.8),
        'KoCC': ("Kobo Clara Colour", (1072, 1448), Palette16, 1.8),
        'KoL': ("Kobo Libra H2O/Kobo Libra 2", (1264, 1680), Palette16, 1.8),
        'KoLC': ("Kobo Libra Colour", (1264, 1680), Palette16, 1.8),
        'KoF': ("Kobo Forma", (1440, 1920), Palette16, 1.8),
        'KoS': ("Kobo Sage", (1440, 1920), Palette16, 1.8),
        'KoE': ("Kobo Elipsa", (1404, 1872), Palette16, 1.8),
        'Rmk1': ("reMarkable 1", (1404, 1872), Palette16, 1.8),
        'Rmk2': ("reMarkable 2", (1404, 1872), Palette16, 1.8),
        'RmkPP': ("reMarkable Paper Pro", (1620, 2160), Palette16, 1.8),
        'OTHER': ("Other", (0, 0), Palette16, 1.8),
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Standalone <code>kcc-c2e.py</code> usage:</h3><a id="user-content-standalone-kcc-c2epy-usage" aria-label="Permalink: Standalone kcc-c2e.py usage:" href="#standalone-kcc-c2epy-usage"></a></p>
<div data-snippet-clipboard-copy-content="usage: kcc-c2e [options] [input]

MANDATORY:
  input                 Full path to comic folder or file(s) to be processed.

MAIN:
  -p PROFILE, --profile PROFILE
                        Device profile (Available options: K1, K2, K34, K578, KDX, KPW, KPW5, KV, KO, K11, KS, KoMT, KoG, KoGHD, KoA, KoAHD, KoAH2O, KoAO, KoN, KoC, KoCC, KoL, KoLC, KoF, KoS, KoE)
                        [Default=KV]
  -m, --manga-style     Manga style (right-to-left reading and splitting)
  -q, --hq              Try to increase the quality of magnification
  -2, --two-panel       Display two not four panels in Panel View mode
  -w, --webtoon         Webtoon processing mode
  --ts TARGETSIZE, --targetsize TARGETSIZE
                        the maximal size of output file in MB. [Default=100MB for webtoon and 400MB for others]

PROCESSING:
  -n, --noprocessing    Do not modify image and ignore any profil or processing option
  -u, --upscale         Resize images smaller than device's resolution
  -s, --stretch         Stretch images to device's resolution
  -r SPLITTER, --splitter SPLITTER
                        Double page parsing mode. 0: Split 1: Rotate 2: Both [Default=0]
  -g GAMMA, --gamma GAMMA
                        Apply gamma correction to linearize the image [Default=Auto]
  -c CROPPING, --cropping CROPPING
                        Set cropping mode. 0: Disabled 1: Margins 2: Margins + page numbers [Default=2]
  --cp CROPPINGP, --croppingpower CROPPINGP
                        Set cropping power [Default=1.0]
  --preservemargin      After calculating crop, &quot;back up&quot; a specified percentage amount [Default=0]
  --cm CROPPINGM, --croppingminimum CROPPINGM
                        Set cropping minimum area ratio [Default=0.0]
  --ipc INTERPANELCROP, --interpanelcrop INTERPANELCROP
                        Crop empty sections. 0: Disabled 1: Horizontally 2: Both [Default=0]
  --blackborders        Disable autodetection and force black borders
  --whiteborders        Disable autodetection and force white borders
  --forcecolor          Don't convert images to grayscale
  --forcepng            Create PNG files instead JPEG
  --mozjpeg             Create JPEG files using mozJpeg
  --maximizestrips      Turn 1x4 strips to 2x2 strips
  -d, --delete          Delete source file(s) or a directory. It's not recoverable.

OUTPUT SETTINGS:
  -o OUTPUT, --output OUTPUT
                        Output generated file to specified directory or file
  -t TITLE, --title TITLE
                        Comic title [Default=filename or directory name]
  -a AUTHOR, --author AUTHOR
                        Author name [Default=KCC]
  -f FORMAT, --format FORMAT
                        Output format (Available options: Auto, MOBI, EPUB, CBZ, KFX, MOBI+EPUB) [Default=Auto]
  --nokepub             If format is EPUB, output file with '.epub' extension rather than '.kepub.epub'
  -b BATCHSPLIT, --batchsplit BATCHSPLIT
                        Split output into multiple files. 0: Don't split 1: Automatic mode 2: Consider every subdirectory as separate volume [Default=0]
  --spreadshift         Shift first page to opposite side in landscape for two page spread alignment
  --norotate            Do not rotate double page spreads in spread splitter option.
  --reducerainbow       Reduce rainbow effect on color eink by slightly blurring images

CUSTOM PROFILE:
  --customwidth CUSTOMWIDTH
                        Replace screen width provided by device profile
  --customheight CUSTOMHEIGHT
                        Replace screen height provided by device profile

OTHER:
  -h, --help            Show this help message and exit
"><pre><code>usage: kcc-c2e [options] [input]

MANDATORY:
  input                 Full path to comic folder or file(s) to be processed.

MAIN:
  -p PROFILE, --profile PROFILE
                        Device profile (Available options: K1, K2, K34, K578, KDX, KPW, KPW5, KV, KO, K11, KS, KoMT, KoG, KoGHD, KoA, KoAHD, KoAH2O, KoAO, KoN, KoC, KoCC, KoL, KoLC, KoF, KoS, KoE)
                        [Default=KV]
  -m, --manga-style     Manga style (right-to-left reading and splitting)
  -q, --hq              Try to increase the quality of magnification
  -2, --two-panel       Display two not four panels in Panel View mode
  -w, --webtoon         Webtoon processing mode
  --ts TARGETSIZE, --targetsize TARGETSIZE
                        the maximal size of output file in MB. [Default=100MB for webtoon and 400MB for others]

PROCESSING:
  -n, --noprocessing    Do not modify image and ignore any profil or processing option
  -u, --upscale         Resize images smaller than device's resolution
  -s, --stretch         Stretch images to device's resolution
  -r SPLITTER, --splitter SPLITTER
                        Double page parsing mode. 0: Split 1: Rotate 2: Both [Default=0]
  -g GAMMA, --gamma GAMMA
                        Apply gamma correction to linearize the image [Default=Auto]
  -c CROPPING, --cropping CROPPING
                        Set cropping mode. 0: Disabled 1: Margins 2: Margins + page numbers [Default=2]
  --cp CROPPINGP, --croppingpower CROPPINGP
                        Set cropping power [Default=1.0]
  --preservemargin      After calculating crop, "back up" a specified percentage amount [Default=0]
  --cm CROPPINGM, --croppingminimum CROPPINGM
                        Set cropping minimum area ratio [Default=0.0]
  --ipc INTERPANELCROP, --interpanelcrop INTERPANELCROP
                        Crop empty sections. 0: Disabled 1: Horizontally 2: Both [Default=0]
  --blackborders        Disable autodetection and force black borders
  --whiteborders        Disable autodetection and force white borders
  --forcecolor          Don't convert images to grayscale
  --forcepng            Create PNG files instead JPEG
  --mozjpeg             Create JPEG files using mozJpeg
  --maximizestrips      Turn 1x4 strips to 2x2 strips
  -d, --delete          Delete source file(s) or a directory. It's not recoverable.

OUTPUT SETTINGS:
  -o OUTPUT, --output OUTPUT
                        Output generated file to specified directory or file
  -t TITLE, --title TITLE
                        Comic title [Default=filename or directory name]
  -a AUTHOR, --author AUTHOR
                        Author name [Default=KCC]
  -f FORMAT, --format FORMAT
                        Output format (Available options: Auto, MOBI, EPUB, CBZ, KFX, MOBI+EPUB) [Default=Auto]
  --nokepub             If format is EPUB, output file with '.epub' extension rather than '.kepub.epub'
  -b BATCHSPLIT, --batchsplit BATCHSPLIT
                        Split output into multiple files. 0: Don't split 1: Automatic mode 2: Consider every subdirectory as separate volume [Default=0]
  --spreadshift         Shift first page to opposite side in landscape for two page spread alignment
  --norotate            Do not rotate double page spreads in spread splitter option.
  --reducerainbow       Reduce rainbow effect on color eink by slightly blurring images

CUSTOM PROFILE:
  --customwidth CUSTOMWIDTH
                        Replace screen width provided by device profile
  --customheight CUSTOMHEIGHT
                        Replace screen height provided by device profile

OTHER:
  -h, --help            Show this help message and exit

</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Standalone <code>kcc-c2p.py</code> usage:</h3><a id="user-content-standalone-kcc-c2ppy-usage" aria-label="Permalink: Standalone kcc-c2p.py usage:" href="#standalone-kcc-c2ppy-usage"></a></p>
<div data-snippet-clipboard-copy-content="usage: kcc-c2p [options] [input]

MANDATORY:
  input                 Full path to comic folder(s) to be processed. Separate multiple inputs with spaces.

MAIN:
  -y HEIGHT, --height HEIGHT
                        Height of the target device screen
  -i, --in-place        Overwrite source directory
  -m, --merge           Combine every directory into a single image before splitting

OTHER:
  -d, --debug           Create debug file for every split image
  -h, --help            Show this help message and exit"><pre><code>usage: kcc-c2p [options] [input]

MANDATORY:
  input                 Full path to comic folder(s) to be processed. Separate multiple inputs with spaces.

MAIN:
  -y HEIGHT, --height HEIGHT
                        Height of the target device screen
  -i, --in-place        Overwrite source directory
  -m, --merge           Combine every directory into a single image before splitting

OTHER:
  -d, --debug           Create debug file for every split image
  -h, --help            Show this help message and exit
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">INSTALL FROM SOURCE</h2><a id="user-content-install-from-source" aria-label="Permalink: INSTALL FROM SOURCE" href="#install-from-source"></a></p>
<p dir="auto">This section is for developers who want to contribute to KCC or power users who want to run the latest code without waiting for an official release.</p>
<p dir="auto">Easiest to use <a href="https://desktop.github.com/">GitHub Desktop</a> to clone the KCC repo. From GitHub Desktop, click on <code>Repository</code> in the toolbar, then <code>Command Prompt</code> (Windows)/<code>Terminal</code> (Mac) to open a window in the KCC repo.</p>
<p dir="auto">Depending on your system <a href="https://www.python.org/" rel="nofollow">Python</a> may be called either <code>python</code> or <code>python3</code>. We use virtual environments (venv) to manage dependencies.</p>
<p dir="auto">If you want to edit the code, a good code editor is <a href="https://code.visualstudio.com/" rel="nofollow">VS Code</a>.</p>
<p dir="auto">If you want to edit the <code>.ui</code> files, use <a href="https://www.qt.io/download-qt-installer-oss" rel="nofollow">Qt Creator</a>, included in <strong>Qt for desktop development</strong>.
Then use the <code>gen_ui_files</code> scripts to autogenerate the python UI.</p>
<p dir="auto">An example PR adding a new checkbox is here: <a data-error-text="Failed to load title" data-id="2739994471" data-permission-text="Title is private" data-url="https://github.com/ciromattia/kcc/issues/785" data-hovercard-type="pull_request" data-hovercard-url="/ciromattia/kcc/pull/785/hovercard" href="https://github.com/ciromattia/kcc/pull/785">#785</a></p>
<p dir="auto">Do not use <code>git merge</code> to merge master from upstream,
use the "Sync fork" button on your fork on GitHub in your branch
to avoid weird looking merges in pull requests.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows install from source</h3><a id="user-content-windows-install-from-source" aria-label="Permalink: Windows install from source" href="#windows-install-from-source"></a></p>
<p dir="auto">One time setup and running for the first time:</p>
<div data-snippet-clipboard-copy-content="python -m venv venv
venv\Scripts\activate.bat
pip install -r requirements.txt
python kcc.py"><pre><code>python -m venv venv
venv\Scripts\activate.bat
pip install -r requirements.txt
python kcc.py
</code></pre></div>
<p dir="auto">Every time you close Command Prompt, you will need to re-activate the virtual environment and re-run:</p>
<div data-snippet-clipboard-copy-content="venv\Scripts\activate.bat
python kcc.py"><pre><code>venv\Scripts\activate.bat
python kcc.py
</code></pre></div>
<p dir="auto">You can build a <code>.exe</code> of KCC like the downloads we offer with</p>
<div data-snippet-clipboard-copy-content="python setup.py build_binary"><pre><code>python setup.py build_binary
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS install from source</h3><a id="user-content-macos-install-from-source" aria-label="Permalink: macOS install from source" href="#macos-install-from-source"></a></p>
<p dir="auto">One time setup and running for the first time:</p>
<div data-snippet-clipboard-copy-content="python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python kcc.py"><pre><code>python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python kcc.py
</code></pre></div>
<p dir="auto">Every time you close Terminal, you will need to reactivate the virtual environment and re-run:</p>
<div data-snippet-clipboard-copy-content="source venv/bin/activate
python kcc.py"><pre><code>source venv/bin/activate
python kcc.py
</code></pre></div>
<p dir="auto">You can build a <code>.app</code> of KCC like the downloads we offer with</p>
<div data-snippet-clipboard-copy-content="python setup.py build_binary"><pre><code>python setup.py build_binary
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">CREDITS</h2><a id="user-content-credits" aria-label="Permalink: CREDITS" href="#credits"></a></p>
<p dir="auto"><strong>KCC</strong> is made by</p>
<ul dir="auto">
<li><a href="http://github.com/ciromattia">Ciro Mattia Gonano</a></li>
<li><a href="http://github.com/AcidWeb">Paweł Jastrzębski</a></li>
<li><a href="http://github.com/darodi">Darodi</a></li>
<li><a href="http://github.com/axu2">Alex Xu</a></li>
</ul>
<p dir="auto">This script born as a cross-platform alternative to <code>KindleComicParser</code> by <strong>Dc5e</strong> (published <a href="http://www.mobileread.com/forums/showthread.php?t=192783" rel="nofollow">here</a>).</p>
<p dir="auto">The app relies and includes the following scripts:</p>
<ul dir="auto">
<li><code>DualMetaFix</code> script by <strong>K. Hendricks</strong>. Released with GPL-3 License.</li>
<li><code>image.py</code> class from <strong>Alex Yatskov</strong>'s <a href="https://github.com/FooSoft/mangle/">Mangle</a> with subsequent <a href="https://github.com/proDOOMman/Mangle">proDOOMman</a>'s and <a href="https://github.com/Birua/Mangle">Birua</a>'s patches.</li>
<li>Icon is by <strong>Nikolay Verin</strong> (<a href="http://ncrow.deviantart.com/" rel="nofollow">http://ncrow.deviantart.com/</a>) and released under <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/" rel="nofollow">CC BY-NC-SA 3.0</a> License.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">SAMPLE FILES CREATED BY KCC</h2><a id="user-content-sample-files-created-by-kcc" aria-label="Permalink: SAMPLE FILES CREATED BY KCC" href="#sample-files-created-by-kcc"></a></p>
<ul dir="auto">
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-KO.mobi" rel="nofollow">Kindle Oasis 2 / 3</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-KV.mobi" rel="nofollow">Kindle Paperwhite 3 / 4 / Voyage / Oasis</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-KPW.mobi" rel="nofollow">Kindle Paperwhite 1 / 2</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-K578.mobi" rel="nofollow">Kindle</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoA.kepub.epub" rel="nofollow">Kobo Aura</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoAHD.kepub.epub" rel="nofollow">Kobo Aura HD</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoAH2O.kepub.epub" rel="nofollow">Kobo Aura H2O</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoAO.kepub.epub" rel="nofollow">Kobo Aura ONE</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoF.kepub.epub" rel="nofollow">Kobo Forma</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">PRIVACY</h2><a id="user-content-privacy" aria-label="Permalink: PRIVACY" href="#privacy"></a></p>
<p dir="auto"><strong>KCC</strong> is initiating internet connections in two cases:</p>
<ul dir="auto">
<li>During startup - Version check.</li>
<li>When error occurs - Automatic reporting on Windows and macOS.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">KNOWN ISSUES</h2><a id="user-content-known-issues" aria-label="Permalink: KNOWN ISSUES" href="#known-issues"></a></p>
<p dir="auto">Please check <a href="https://github.com/ciromattia/kcc/wiki/Known-issues">wiki page</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">COPYRIGHT</h2><a id="user-content-copyright" aria-label="Permalink: COPYRIGHT" href="#copyright"></a></p>
<p dir="auto">Copyright (c) 2012-2025 Ciro Mattia Gonano, Paweł Jastrzębski, Darodi and Alex Xu.
<strong>KCC</strong> is released under ISC LICENSE; see <a href="https://github.com/ciromattia/kcc/blob/master/LICENSE.txt">LICENSE.txt</a> for further details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waiting for Postgres 18: Accelerating Disk Reads with Asynchronous I/O (446 pts)]]></title>
            <link>https://pganalyze.com/blog/postgres-18-async-io</link>
            <guid>43916577</guid>
            <pubDate>Wed, 07 May 2025 14:57:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pganalyze.com/blog/postgres-18-async-io">https://pganalyze.com/blog/postgres-18-async-io</a>, See on <a href="https://news.ycombinator.com/item?id=43916577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>With the Postgres 18 Beta 1 release this week a multi-year effort, and significant architectural shift in Postgres is taking shape: <strong>Asynchronous I/O (AIO)</strong>. These capabilities are still under active development, but they represent a fundamental change in how Postgres handles I/O, offering the potential for significant performance gains, particularly in cloud environments where latency is often the bottleneck.</p>
<div>
<ul>
<li>
<p><a href="#why-asynchronous-io-matters">Why asynchronous I/O matters</a></p>
<ul>
<li><a href="#how-postgres-17s-read-streams-paved-the-way">How Postgres 17’s read streams paved the way</a></li>
</ul>
</li>
<li>
<p><a href="#new-io_method-setting-in-postgres-18">New io_method setting in Postgres 18</a></p>
<ul>
<li><a href="#io_method--sync">io_method = sync</a></li>
<li><a href="#io_method--worker">io_method = worker</a></li>
<li><a href="#io_method--io_uring">io_method = io_uring</a></li>
</ul>
</li>
<li>
<p><a href="#asynchronous-io-in-action">Asynchronous I/O in action</a></p>
<ul>
<li><a href="#benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring">Benchmark on AWS: Doubling read performance &amp; even greater gains from io_uring</a></li>
<li><a href="#tuning-effective_io_concurrency">Tuning effective_io_concurrency</a></li>
<li><a href="#monitoring-ios-in-flight-with-pg_aios">Monitoring I/Os in flight with pg_aios</a></li>
</ul>
</li>
<li>
<p><a href="#heads-up-async-io-makes-io-timing-information-hard-to-interpret">Heads Up: Async I/O makes I/O timing information hard to interpret</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
<ul>
<li><a href="#in-summary">In summary</a></li>
<li><a href="#references">References</a></li>
</ul>
</li>
</ul>
</div>
<p>While some features may still be adjusted or dropped during the beta period before the final release, now is the best time to test and validate how Postgres 18 performs in practice. In Postgres 18 AIO is limited to read operations; writes remain synchronous, though support may expand in future versions.</p>
<p>In this post, we explain what asynchronous I/O is, how it works in Postgres 18, and what it means for performance optimization.</p>
<h2 id="why-asynchronous-io-matters"><a href="#why-asynchronous-io-matters" aria-label="why asynchronous io matters permalink"></a>Why asynchronous I/O matters</h2>
<p>Postgres has historically operated under a synchronous I/O model, meaning every read request is a blocking system call. The database must pause and wait for the operating system to return the data before continuing. This design introduces unnecessary waits on I/O, especially in cloud environments where storage is often network-attached (e.g. Amazon EBS) and I/O can have over 1ms of latency.</p>
<p>In a simplified model, we can illustrate the difference like this, ignoring any prefetching/batching the Linux kernel might do:</p>
<p><span>
      <a href="https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/913b9/sync_vs_async.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Diagram showing synchronous vs asynchronous I/O model with concurrent requests" title="In the asynchronous I/O model, multiple read requests can be in flight simultaneously" src="https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/1d69c/sync_vs_async.png" srcset="https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/4dcb9/sync_vs_async.png 188w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/5ff7e/sync_vs_async.png 375w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/1d69c/sync_vs_async.png 750w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/78797/sync_vs_async.png 1125w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/aa440/sync_vs_async.png 1500w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/913b9/sync_vs_async.png 1822w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async">
  </a>
    </span></p>
<p>You can picture synchronous I/O like an imaginary librarian who retrieves one book at a time, returning before fetching the next. This inefficiency compounds as the number of physical reads for a logical operation increases.</p>
<p>Asynchronous I/O eliminates that bottleneck by allowing programs to issue multiple read requests concurrently, without waiting for prior reads to return. In an async program flow, I/O requests are scheduled to be read into a memory location and the program waits for completion of those reads, instead of issuing each read individually.</p>
<h3 id="how-postgres-17s-read-streams-paved-the-way"><a href="#how-postgres-17s-read-streams-paved-the-way" aria-label="how postgres 17s read streams paved the way permalink"></a>How Postgres 17’s read streams paved the way</h3>
<p>The work for implementing asynchronous I/O in Postgres has been many years in the making. Postgres 17 introduced an essential internal abstration, <a href="https://pganalyze.com/blog/5mins-postgres-17-streaming-io">with the introduction of read stream APIs</a>. These internal changes standardized how read operations were issued across different subsystems and streamlined the use of <code>posix_fadvise()</code> to request that the operating system prefetch data in advance.</p>
<p>However, this advisory mechanism only hinted to the kernel to load data into the OS page cache, not into Postgres’ own shared buffers. Postgres still had to issue syscalls for each read, and OS readahead behaviour is not always consistent.</p>
<p>The upcoming Postgres 18 release removes this indirection. With true asynchronous reads, data is fetched directly into shared buffers by the database itself, bypassing reliance on kernel-level heuristics and enabling more predictable, higher-throughput I/O behavior.</p>
<h2 id="new-io_method-setting-in-postgres-18"><a href="#new-io_method-setting-in-postgres-18" aria-label="new io_method setting in postgres 18 permalink"></a>New io_method setting in Postgres 18</h2>
<p>To control the mechanism used for asynchronous I/O, Postgres 18 introduces a new configuration parameter: <code>io_method</code>. This setting determines how read operations are dispatched under the hood, and whether they’re handled synchronously, offloaded to I/O workers, or submitted directly to the kernel via <code>io_uring</code>.</p>
<p>The <code>io_method</code> setting must be set in postgresql.conf and cannot be changed without restarting. It controls which  I/O implementation Postgres will use and is essential to understand when tuning I/O performance in Postgres 18. There are three possible settings for io_method, with the current default (as of Beta 1) being <code>worker</code>.</p>
<h3 id="io_method--sync"><a href="#io_method--sync" aria-label="io_method  sync permalink"></a>io_method = sync</h3>
<p>The <code>sync</code> setting in Postgres 18 mirrors the synchronous behavior as was implemented in Postgres 17. Reads are still synchronous and blocking, using <code>posix_fadvise()</code> to achieve read-ahead in the Linux kernel.</p>
<h3 id="io_method--worker"><a href="#io_method--worker" aria-label="io_method  worker permalink"></a>io_method = worker</h3>
<p>The <code>worker</code> setting utilizes dedicated <strong>I/O worker processes</strong> running in the background that retrieve data independently of query execution. The main backend process enqueues read requests, and these workers interact with the Linux kernel to fetch data, which is then delivered into shared buffers, <strong>without blocking the main process</strong>.</p>
<p>The number of I/O workers can be configured through the new <code>io_workers</code> setting, and defaults to <code>3</code>. These workers are always running, and shared across all connections and databases.</p>
<h3 id="io_method--io_uring"><a href="#io_method--io_uring" aria-label="io_method  io_uring permalink"></a>io_method = io_uring</h3>
<p>This Linux-specific method uses <strong><code>io_uring</code></strong>, a high-performance I/O interface introduced in kernel version 5.1. Asynchronous I/O has been available in Linux since kernel version 2.5, but it was largely considered inefficient and hard to use. <code>io_uring</code> establishes a <strong>shared ring buffer</strong> between Postgres and the kernel, minimizing syscall overhead. This is the most efficient option, <strong>eliminating the need for I/O worker processes entirely</strong>, but is only available on newer Linux kernels and requires file systems and configurations compatible with <code>io_uring</code> support.</p>
<p><strong>Important note:</strong> As of the Postgres 18 Beta 1, asynchronous I/O is supported for sequential scans, bitmap heap scans, and maintenance operations like <code>VACUUM</code>.</p>
<h2 id="asynchronous-io-in-action"><a href="#asynchronous-io-in-action" aria-label="asynchronous io in action permalink"></a>Asynchronous I/O in action</h2>
<p>Asynchronous I/O delivers the most noticeable gains in cloud environments where storage is network-attached, such as Amazon EBS volumes. In these setups, individual disk reads often take multiple milliseconds, introducing substantial latency compared to local SSDs.</p>
<p>With traditional synchronous I/O, each of these reads blocks query execution until the data arrives, leading to idle CPU time and degraded throughput. By contrast, asynchronous I/O allows Postgres to issue multiple read requests in parallel and continue processing while waiting for results. This reduces query latency and enables much more efficient use of available I/O bandwidth and CPU cycles.</p>
<h3 id="benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring"><a href="#benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring" aria-label="benchmark on aws doubling read performance  even greater gains from io_uring permalink"></a>Benchmark on AWS: Doubling read performance &amp; even greater gains from io_uring</h3>
<p>To evaluate the performance impact of asynchronous I/O, we benchmarked a representative workload on AWS, comparing Postgres 17 with Postgres 18 using different <code>io_method</code> settings. The workload remained identical across versions, allowing us to isolate the effects of the new I/O infrastructure.</p>
<p>We've tested on an AWS c7i.8xlarge instance (32 vCPUs, 64 GB RAM), with a dedicated 100GB <code>io2</code> EBS volume for Postgres, with 20,000 provisioned IOPS. The test table was 3.5GB in size:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> test<span>(</span>id <span>int</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> test <span>SELECT</span> <span>*</span> <span>FROM</span> generate_series<span>(</span><span>0</span><span>,</span> <span>100000000</span><span>)</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>test=# \dt+
                                   List of relations
 Schema | Name | Type  |  Owner   | Persistence | Access method |  Size   | Description 
--------+------+-------+----------+-------------+---------------+---------+-------------
 public | test | table | postgres | permanent   | heap          | 3458 MB | 
(1 row)</code></pre></div>
<p>Between test runs we cleared the OS page cache (<code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>), and restarted Postgres, to gather cold cache results. Warm cache results represent running the query a second time. We repeated the complete test run for each configuration multiple times, retaining the best result out of three.</p>
<p>Whilst we also tested with parallel query, to keep results easier to understand all results below are with parallel query turned off (<code>max_parallel_workers_per_gather = 0</code>).</p>
<p><strong>Cold cache results:</strong></p>
<p>Postgres 17, using synchronous I/O, established the baseline. It showed consistent read latency, but throughput was limited by the need to complete each I/O request before issuing the next:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 15830.880 ms (00:15.831)</code></pre></div>
<p>Postgres 18, when configured with <code>io_method = sync</code>, performed nearly identically, confirming that behavior remains unchanged without enabling asynchronous I/O:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 15071.089 ms (00:15.071)</code></pre></div>
<p>However, when we switch to using the <code>worker</code> method, with 3 I/O workers (the default) a clear improvement shows:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 10051.975 ms (00:10.052)</code></pre></div>
<p>We observed some gains by raising the number of I/O workers, but the biggested improvement comes when utilizing <code>io_uring</code>:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 5723.423 ms (00:05.723)</code></pre></div>
<p>When we graph this (measuring runtime in ms, lower is better), it’s clear that Postgres 18 performs significantly better in cold cache situations:</p>
<p><span>
      <a href="https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/50e7d/runtime-compared.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Read performance comparison between Postgres 17 and 18 with different io_method settings" title="Read performance comparison between Postgres 17 and 18 with different io_method settings" src="https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/1d69c/runtime-compared.png" srcset="https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/4dcb9/runtime-compared.png 188w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/5ff7e/runtime-compared.png 375w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/1d69c/runtime-compared.png 750w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/78797/runtime-compared.png 1125w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/aa440/runtime-compared.png 1500w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/50e7d/runtime-compared.png 1738w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async">
  </a>
    </span></p>
<p>For cold cache tests, both <code>worker</code> and <code>io_uring</code> delivered a consistent <strong>2-3x improvement</strong> in read performance compared to the legacy <code>sync</code> method.</p>
<p>Whilst <code>worker</code> offers a slight benefit for warm cache tests due to its parallelism, <code>io_uring</code> consistently performed better in cold cache tests, and its lower syscall overhead and reduced process coordination would make <strong><code>io_uring</code> the recommended setting</strong> for maximizing I/O performance in Postgres 18.</p>
<p>This performance shift for disk reads has meaningful implications for infrastructure planning, especially in cloud environments. By reducing I/O wait time, asynchronous reads can substantially increase query throughput, reduce latency and CPU overhead. For read-heavy workloads, this may translate into smaller instance sizes or better utilization of existing resources.</p>
<h3 id="tuning-effective_io_concurrency"><a href="#tuning-effective_io_concurrency" aria-label="tuning effective_io_concurrency permalink"></a>Tuning effective_io_concurrency</h3>
<p>In Postgres 18, <code>effective_io_concurrency</code> becomes more interesting, but only when used with an asynchronous <code>io_method</code> such as <code>worker</code> or <code>io_uring</code>. Previously, this setting merely advised the OS to prefetch data using <code>posix_fadvise</code>. Now, it directly controls how many asynchronous read-ahead requests Postgres issues internally.</p>
<p>The number of blocks read ahead is influenced by both <code>effective_io_concurrency</code> and <code>io_combine_limit</code>, following the general formula:</p>
<div data-language="text"><pre><code>maximum read-ahead = effective_io_concurrency × io_combine_limit</code></pre></div>
<p>This gives DBAs and engineers greater control over I/O behavior. The optimal value requires benchmarking, as it depends on your I/O subsystem. For example, higher values may benefit cloud environments with high latency that also support high concurrency, like AWS EBS with high provisioned IOPS.</p>
<p>When doing our benchmarks, we also tested higher <code>effective_io_concurrency</code> (between 16 and 128) but did not see a meaningful difference. However, that is likely due to the simple test query used.</p>
<p>It’s worth noting that the previous default of effective_io_concurrency was 1 in Postgres 17, which is now raised to 16, <a href="https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=ff79b5b2ab">based on benchmarks done by the Postgres community</a>.</p>
<h3 id="monitoring-ios-in-flight-with-pg_aios"><a href="#monitoring-ios-in-flight-with-pg_aios" aria-label="monitoring ios in flight with pg_aios permalink"></a>Monitoring I/Os in flight with pg_aios</h3>
<p>As mentioned, previous versions of Postgres with synchronous I/O made it easy to spot read delays: the backend process would block while waiting for disk access, and monitoring tools like pganalyze can reliably surface <code>IO / DataFileRead</code> as a wait event during these stalls.</p>
<p>For example, here we can see wait events clearly in Postgres 17 synchronous I/O.</p>
<p><span>
      <a href="https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/8deec/wait_events_io_read.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Screenshot of pganalyze showing wait events in Postgres 17" title="pganalyze interface showing clear IO / DataFileRead wait events in Postgres 17" src="https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/1d69c/wait_events_io_read.png" srcset="https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/4dcb9/wait_events_io_read.png 188w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/5ff7e/wait_events_io_read.png 375w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/1d69c/wait_events_io_read.png 750w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/78797/wait_events_io_read.png 1125w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/aa440/wait_events_io_read.png 1500w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/8deec/wait_events_io_read.png 2136w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async">
  </a>
    </span></p>
<p>With asynchronous I/O in Postgres 18, backend wait behavior changes. When using <code>io_method = worker</code>, the backend process delegates reads to a separate I/O worker. As a result, the backend may appear idle or show the new <code>IO / AioIoCompletion</code> wait event, while the I/O worker shows the actual I/O wait events:</p>
<div data-language="sql"><pre><code><span>SELECT</span> backend_type<span>,</span> query<span>,</span> state<span>,</span> wait_event_type<span>,</span> wait_event
  <span>FROM</span> pg_stat_activity
 <span>WHERE</span> backend_type <span>=</span> <span>'client backend'</span> <span>OR</span> backend_type <span>=</span> <span>'io worker'</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>  backend_type  | state  | wait_event_type |   wait_event    
----------------+--------+-----------------+-----------------
 client backend | active | IO              | AioIoCompletion
 io worker      |        | IO              | DataFileRead
 io worker      |        | IO              | DataFileRead
 io worker      |        | IO              | DataFileRead
(4 rows)</code></pre></div>
<p>With <code>io_method = io_uring</code>, read operations are submitted directly to the kernel and completed asynchronously. The backend does not block on a traditional I/O syscall, so this activity is not visible from the Postgres side, even though I/O is in progress.</p>
<p>To help with debugging of I/O requests in flight, the new <code>pg_aios</code> view can show Postgres internal state, even when using <code>io_uring</code>:</p>

<div data-language="text"><pre><code>  pid  | io_id | io_generation |    state     | operation |    off    | length | target | handle_data_len | raw_result | result  |                   target_desc                    | f_sync | f_localmem | f_buffered 
-------+-------+---------------+--------------+-----------+-----------+--------+--------+-----------------+------------+---------+--------------------------------------------------+--------+------------+------------
 91452 |     1 |          4781 | SUBMITTED    | read      | 996278272 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383760..383775 in file "base/16384/16389" | f      | f          | t
 91452 |     2 |          4785 | SUBMITTED    | read      | 996147200 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383744..383759 in file "base/16384/16389" | f      | f          | t
 91452 |     3 |          4796 | SUBMITTED    | read      | 996409344 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383776..383791 in file "base/16384/16389" | f      | f          | t
 91452 |     4 |          4802 | SUBMITTED    | read      | 996016128 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383728..383743 in file "base/16384/16389" | f      | f          | t
 91452 |     5 |          3175 | COMPLETED_IO | read      | 995885056 | 131072 | smgr   |              16 |     131072 | UNKNOWN | blocks 383712..383727 in file "base/16384/16389" | f      | f          | t
(5 rows)</code></pre></div>
<p>Understanding these behavior changes and understanding the impact of asynchronous execution is essential when optimizing I/O performance in Postgres 18.</p>
<h2 id="heads-up-async-io-makes-io-timing-information-hard-to-interpret"><a href="#heads-up-async-io-makes-io-timing-information-hard-to-interpret" aria-label="heads up async io makes io timing information hard to interpret permalink"></a>Heads Up: Async I/O makes I/O timing information hard to interpret</h2>
<p>Asynchronous I/O introduces a shift in how execution timing is reported. When the backend no longer blocks directly on disk reads (as is the case with <code>worker</code> or <code>io_uring</code>) the complete time spent doing I/O may not be reflected in <code>EXPLAIN ANALYZE</code> output. This can make I/O-bound queries seem to require less I/O effort than previously.</p>
<p>First, let's run the earlier query in <code>EXPLAIN ANALYZE</code> on a cold cache in Postgres 17:</p>
<div data-language="text"><pre><code>test=# EXPLAIN (ANALYZE, BUFFERS, TIMING OFF) SELECT COUNT(*) FROM test;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1692478.40..1692478.41 rows=1 width=8) (actual rows=1 loops=1)
   Buffers: shared read=442478
   I/O Timings: shared read=14779.316
   -&gt;  Seq Scan on test  (cost=0.00..1442478.32 rows=100000032 width=0) (actual rows=100000001 loops=1)
         Buffers: shared read=442478
         I/O Timings: shared read=14779.316
 Planning:
   Buffers: shared hit=13 read=6
   I/O Timings: shared read=3.182
 Planning Time: 8.136 ms
 Execution Time: 18006.405 ms
(11 rows)</code></pre></div>
<p>We've read 442,478 buffers in 14.8 seconds.</p>
<p>And now, we repeat the test on Postgres 18 with the default settings (<code>io_method = worker</code>):</p>
<div data-language="text"><pre><code>test=# EXPLAIN (ANALYZE, BUFFERS, TIMING OFF) SELECT COUNT(*) FROM test;
                                                QUERY PLAN                                                 
-----------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1692478.40..1692478.41 rows=1 width=8) (actual rows=1.00 loops=1)
   Buffers: shared read=442478
   I/O Timings: shared read=7218.835
   -&gt;  Seq Scan on test  (cost=0.00..1442478.32 rows=100000032 width=0) (actual rows=100000001.00 loops=1)
         Buffers: shared read=442478
         I/O Timings: shared read=7218.835
 Planning:
   Buffers: shared hit=13 read=6
   I/O Timings: shared read=2.709
 Planning Time: 2.925 ms
 Execution Time: 10480.827 ms
(11 rows)</code></pre></div>
<p>We've read 442,478 buffers in 7.2 seconds.</p>
<p>Whilst with parallel query we get a summary of all the I/O time across all parallel workers, no such summarization occurs with I/O workers. What we are seeing is the wait time for the I/O to be completed, ignoring any parallelism that may happen behind the scenes.</p>
<p>This is technically not a behaviour change, since even in Postgres 17 the time reported was the time spent waiting on I/Os, not the time spent performing the I/O, e.g. Kernel I/O time for readahead was never accounted for.</p>
<p>Historically I/O timing was often equated with I/O effort, instead of just looking at shared buffer read counts, in order to distinguish from a OS page cache hit. Now, in Postgres 18, interpreting I/O timing requires more caution: asynchronous I/O can hide I/O overhead in query plans.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>To summarize, the upcoming release of Postgres 18 marks the beginning of a major evolution in how I/O is handled. While currently limited to reads, asynchronous I/O already opens the door to significant performance improvements in high-latency cloud environments.</p>
<p>But some of these gains come with tradeoffs. Engineering teams will need to adjust their observability practices, learn new semantics for timing and wait events, and perhaps revisit tuning parameters with previously limited impact, like <code>effective_io_conurrency</code>.</p>
<h3 id="in-summary"><a href="#in-summary" aria-label="in summary permalink"></a>In summary</h3>
<ul>
<li>Asynchronous I/O support in Postgres 18 introduces <code>worker</code> (as the default) and <code>io_uring</code> options under the new <code>io_method</code> setting.</li>
<li>Benchmarks show up to a 2-3x throughput improvement for read-heavy workloads in cloud environments.</li>
<li>Observability practices need to evolve: <code>EXPLAIN ANALYZE</code> may underreport I/O effort, and new views like <code>pg_aios</code> will help provide insights.</li>
<li>Tools like pganalyze will be adapting to these changes to continue surfacing relevant performance insights.</li>
</ul>
<p>As Postgres development continues, future versions (19 and beyond) may bring asynchronous write support, further reducing I/O bottlenecks in modern workloads, and enabling production use of Direct I/O.</p>
<h3 id="references"><a href="#references" aria-label="references permalink"></a>References</h3>
<ul>
<li><a href="https://www.postgresql.org/docs/devel/runtime-config-resource.html#GUC-IO-METHOD">PostgreSQL <code>io_method</code> GUC (Postgres 18)</a></li>
<li><a href="https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-EFFECTIVE-IO-CONCURRENCY">PostgreSQL <code>effective_io_concurrency</code></a></li>
<li><a href="https://www.postgresql.org/docs/current/storage-buffer.html">PostgreSQL Shared Buffers and Buffer Management</a></li>
<li><a href="https://www.postgresql.org/docs/current/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW"><code>pg_stat_activity</code> View</a></li>
<li><a href="https://www.postgresql.org/docs/devel/monitoring-stats.html#PG-STAT-IO-VIEW"><code>pg_stat_io</code> View</a></li>
<li><a href="https://www.postgresql.org/docs/devel/monitoring-stats.html#PG-AIOS-VIEW"><code>pg_aios</code> View (New in Postgres 18)</a></li>
<li><a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise()</code> System Call</a></li>
<li><a href="https://www.google.com/url?q=https://www.man7.org/linux/man-pages/man7/io_uring.7.html&amp;sa=D&amp;source=docs&amp;ust=1746206271490972&amp;usg=AOvVaw1B_RmjsiRaB-HDroNJCv6b">Linux io_uring Man Page</a></li>
<li><a href="https://pganalyze.com/blog/5mins-postgres-17-streaming-io">5mins of Postgres: Waiting for Postgres 17: Streaming I/O for sequential scans &amp; ANALYZE</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral ships le chat – enterprise AI assistant that can run on prem (365 pts)]]></title>
            <link>https://mistral.ai/news/le-chat-enterprise</link>
            <guid>43916098</guid>
            <pubDate>Wed, 07 May 2025 14:24:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/le-chat-enterprise">https://mistral.ai/news/le-chat-enterprise</a>, See on <a href="https://news.ycombinator.com/item?id=43916098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today, we’re proud to introduce <a href="https://mistral.ai/products/le-chat">Le Chat Enterprise</a>&nbsp;— a feature-rich AI assistant, powered by our brand new <a href="https://mistral.ai/news/mistral-medium-3">Mistral Medium 3 model</a>. Solving enterprise AI challenges, like tool fragmentation, insecure knowledge integration, rigid models, and slow ROI, it delivers a unified AI platform for all organizational work.</p>
<p>Building on the foundation of Le Chat’s productivity tools, the new plan includes:</p>
<ul>
<li>Enterprise search</li>
<li>Agent builders</li>
<li>Custom data and tool connectors</li>
<li>Document libraries</li>
<li>Custom models</li>
<li>Hybrid deployments</li>
</ul>
<p>[All features rolling out over the next two weeks.]</p>
<p dir="ltr">We’re also announcing several big improvements to Le Chat Pro and Team — our plans for individuals and growing teams.</p>
<p dir="ltr">Le Chat Enterprise aims to provide AI productivity your team needs, in one platform, is fully private, and deeply customizable. Plus, our world-class AI engineering team offers support all the way through to value delivery.</p>
<p dir="ltr">Empower your team to be even more productive, more competitive, more everything.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/7Ssb4lybDag?si=uDW8R4kbvHmDbMci" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Unified AI for all organizational work.</h2>
<p dir="ltr">Transform complex tasks into achievable outcomes with AI that speaks every professional language.</p>
<p dir="ltr">Whether your team is analyzing data, writing code, or creating content, they can access cross-domain expertise through intuitive interfaces designed for both technical and non-technical users.</p>
<h3 dir="ltr">Enterprise search with secure data, tool connections and libraries.</h3>
<p dir="ltr">Unlock intelligence from your enterprise data, starting with Google Drive, Sharepoint, OneDrive, Google Calendar, and Gmail. With more connectors coming soon, including templates to build your own.</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Get improved, personalized answers by connecting Le Chat to your knowledge.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Organize external data sources, documents, and web content into complete knowledge bases for the most relevant answers.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Preview files quickly with Auto Summary for faster consumption.</p>
</li>
</ul>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/pvsSFUzEfjQ?si=anPGYFJ4xio4BlBb" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">Le Chat enables your team to maintain a handy personal library of frequently used documents across uploaded files as well as Drive / Sharepoint. Cite, extract, and analyze critical information.</p>
<p dir="ltr">We’re also adding MCP support soon, so your organization can easily connect Le Chat to even more enterprise systems.</p>
<h3 dir="ltr">Build and deploy custom AI agents for precise, automated task handling.</h3>
<p dir="ltr">Automate routine tasks with AI agents, connected to your apps and libraries for contextual understanding across tools. Le Chat will enable your team to easily build custom assistants that match your own requirements — no code required.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/dt8KbVyY_Ek?si=Ws_jwZoM-tXseJkh" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Privacy-first.</h2>
<p dir="ltr">Deploy Le Chat anywhere: self-hosted, in your public or private cloud, or as a service hosted in the Mistral cloud. Privacy-first data connections to enterprise tools —&nbsp; with strict ACL adherence — ensuring full data protection and safety.&nbsp;</p>
<p dir="ltr">Build your AI strategy with true flexibility — Mistral AI gives you the independence to choose your ideal infrastructure, without lock-in.</p>
<h2 dir="ltr">Complete control and configurability.&nbsp;</h2>
<p dir="ltr">We offer deep customizability and full control across the stack, from models and the platform, all the way to the interfaces.</p>
<p dir="ltr">You can customize your AI experience through bespoke integrations to your team’s enterprise data and custom platform and model capabilities, like personalizing your assistant with stored memories. Or take it further by enabling user feedback loops for continuous model self-improvement.</p>
<p dir="ltr">You'll have full control of your implementation within your security domain while providing employees access to SOTA intelligence.</p>
<p dir="ltr">Additionally, we provide comprehensive audit logging and storage.</p>
<h2 dir="ltr">Advanced solutioning and value delivery.</h2>
<p dir="ltr">Leverage Mistral applied AI expertise to tailor models to fit your exact use case. We provide hands-on assistance by the world’s best AI engineers and scientists across deployment, solutioning, safety, and beyond.</p>
<h2 dir="ltr">Get started today.</h2>
<p dir="ltr">Experience frontier artificial intelligence with Le Chat Pro, Team Enterprise plans, suited to your organization’s needs.</p>
<p dir="ltr">Le Chat Enterprise is now available in Google Cloud Marketplace, and will soon be on Azure AI and AWS Bedrock.</p>
<p dir="ltr"><a href="https://mistral.ai/contact/">Contact us</a> to learn more about how Le Chat Enterprise can transform your organization.</p>
<p dir="ltr">To get started with Le Chat today, try it at <a href="http://chat.mistral.ai/">chat.mistral.ai</a>, or download our mobile app from the <a href="https://apps.apple.com/us/app/le-chat-by-mistral-ai/id6740410176">App Store</a> or <a href="https://play.google.com/store/apps/details?id=ai.mistral.chat">Play Store</a> — no credit card needed.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mississippi Can't Possibly Have Good Schools (101 pts)]]></title>
            <link>https://www.educationdaly.us/p/mississippi-cant-possibly-have-good</link>
            <guid>43915586</guid>
            <pubDate>Wed, 07 May 2025 13:43:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.educationdaly.us/p/mississippi-cant-possibly-have-good">https://www.educationdaly.us/p/mississippi-cant-possibly-have-good</a>, See on <a href="https://news.ycombinator.com/item?id=43915586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Painting the Deep South as an embarrassing cultural backwater is one of the last socially acceptable forms of prejudice among elites. It’s not just tolerated - it’s venerated. </p><p><span>Mississippi is probably the top target. I don’t have to tell you why. You know about the </span><a href="https://mississippitoday.org/2023/06/22/mississippi-health-rankings-worst-in-country/" rel="">poor health outcomes</a><span>. </span><a href="https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_poverty_rate" rel="">The poverty</a><span>. </span><a href="https://www.datapandas.org/ranking/most-corrupt-states" rel="">The corruption</a><span>. </span><a href="https://www.cdc.gov/obesity/data-and-statistics/adult-obesity-prevalence-maps.html#:~:text=the%20highest%20(39.2%25).-,Map%3A%20Overall%20Obesity,-In%202023%2C%20more" rel="">The obesity</a><span>. </span><a href="https://www.nbcnews.com/think/opinion/mississippi-s-confederate-flag-gone-legacy-white-supremacist-policy-remains-ncna1232690" rel="">The confederacy stuff</a><span>. </span></p><p><span>Wikipedia has an entry dedicated to the phrase “</span><a href="https://en.wikipedia.org/wiki/Thank_God_for_Mississippi" rel="">Thank God for Mississippi</a><span>” because its horrible performance on so many metrics saves other states the embarrassment of finishing last. The term has been used </span><a href="https://barrypopik.com/blog/thank_god_for_mississippi_thank_heaven_for_mississippi" rel="">since at least 1945</a><span>.</span></p><p>Which has made it awkward in recent years as Mississippi has become the fastest improving school system in the country. </p><p>You read that right. Mississippi is taking names.</p><p><span>In 2003, only the District of Columbia had more fourth graders in the lowest achievement level on our national reading test (NAEP) than Mississippi.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-162505881" href="https://www.educationdaly.us/p/mississippi-cant-possibly-have-good#footnote-1-162505881" target="_self" rel="">1</a></span><span> By 2024, only four states had </span><em>fewer</em><span>.</span></p><p><span>When the Urban Institute </span><a href="https://www.urban.org/research/publication/states-demographically-adjusted-performance-2024-national-assessment" rel="">adjusted national test results</a><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-162505881" href="https://www.educationdaly.us/p/mississippi-cant-possibly-have-good#footnote-2-162505881" target="_self" rel="">2</a></span><span> for student demographics, this is where Mississippi ranked:</span></p><ul><li><p>Fourth grade math: 1st</p></li><li><p>Fourth grade reading: 1st</p></li><li><p>Eighth grade math: 1st</p></li><li><p><span>Eighth grade reading: 4th</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-162505881" href="https://www.educationdaly.us/p/mississippi-cant-possibly-have-good#footnote-3-162505881" target="_self" rel="">3</a></span></p></li></ul><p>How about Black students? The root of Mississippi’s bad reputation is its historically awful record on civil rights - including its refusal to integrate schools. </p><p>That was then. </p><p><span>Now, it has a different story to tell. Black students in Mississippi posted the third highest fourth grade reading scores in the nation. They walloped their counterparts in better-funded states. The average Black student in Mississippi performed about 1.5 grade levels ahead of the average Black student in Wisconsin. Just think about that for a moment. Wisconsin spends about </span><a href="https://educationdata.org/public-education-spending-statistics" rel="">35 percent more per pupil</a><span> to achieve worse results.</span></p><p><span>Mississippi has fellow southern stars. Louisiana was the only state to fully erase pandemic learning loss among fourth grade readers. It ranked in the top five for all four NAEP grades/subjects in the </span><a href="https://www.urban.org/research/publication/states-demographically-adjusted-performance-2024-national-assessment" rel="">demographically adjusted</a><span> results. Alabama was the only state whose fourth graders beat their pre-COVID performance in math. In years past, notable gains have been posted by </span><a href="https://www.educationnext.org/results-floridas-education-reforms-impressive-return-investment-totally-off-charts/#:~:text=The%20most%20compelling,low%2Dincome%20students." rel="">Florida</a><span>, </span><a href="https://tnscore.org/perspectives-and-press/perspectives/tennessee-is-approaching-the-national-average-on-the-nations-report-card" rel="">Tennessee</a><span> and </span><a href="https://edtrust.org/wp-content/uploads/2013/10/Texas-2009.pdf" rel="">Texas</a><span>. </span></p><p><span>These successes have not been wholly unacknowledged. They have been dutifully and perfunctorily name-checked in news stories. Nonetheless, there has been, shall we say, a reluctance among national voices to extol Deep South examples as worthy of emulation by their so-called “better off” peers.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-162505881" href="https://www.educationdaly.us/p/mississippi-cant-possibly-have-good#footnote-4-162505881" target="_self" rel="">4</a></span><span> </span></p><p><span>You can’t go around saying Maine ought to visit Mississippi to learn how to teach reading. It’s insulting. You could ruin a cocktail party. After all, Maine has </span><a href="https://www.nbc.com/nbc-insider/bush-family-compound-in-maine" rel="">Kennebunkport</a><span>. Mississippi has </span><a href="https://www.sunherald.com/news/local/crime/article289919799.html" rel="">Biloxi</a><span>. </span></p><p><span>But that’s exactly what </span><em>should</em><span> happen. Below are the reading scores for these two states over time. For context, 10 points on NAEP is approximately the equivalent of one grade level. In 2002, students in Mississippi were two years behind students in Maine. Today, they are about a year ahead.</span></p><p><span>Don’t you want to know how </span><em>that</em><span> happened? Me too.</span></p><p><span>There’s a much broader trend afoot. This spring, </span><a href="https://www.educationnext.org/red-states-have-seen-less-learning-loss-post-pandemic-scores-nations-report-card-naep/" rel="">Paul Peterson and Michael Hartney</a><span> showed that red states (as defined by 2024 presidential election votes) are overtaking their blue counterparts academically. In 2019, blue states had higher average NAEP scores on all four major tests (4th and 8th grade reading and math). By 2024, red states had taken the lead in three of the four.</span></p><p>With such striking patterns, one would expect some of these red states to be the hottest ticket in education. Reporters embedding in steamy southern capitals to write long form magazine profiles of crusading state chiefs. National commissions chaired by governors. Awards distributed at fancy black-tie dinners.</p><p><span>But none of that is happening. Because these are </span><a href="https://en.wikipedia.org/wiki/Southeastern_Conference" rel="">SEC</a><span> states.</span></p><p><span>More often, there have been sloppy attempts at debunking Mississippi’s success. Some of them </span><a href="https://www.latimes.com/business/story/2023-07-03/how-mississippi-gamed-national-reading-test-to-produce-miracle-gains" rel="">ran in national papers</a><span>. </span><a href="https://jabberwocking.com/mississippi-revisited-the-mississippi-reading-miracle-looks-to-be-real-after-all/" rel="">Others were withdrawn</a><span> when the authors realized they were based on flawed information. </span></p><p>This isn’t just wrong. It’s a problem. There are lessons for our education community and for both political parties.</p><ul><li><p><strong>We miss opportunities to help kids</strong><span>. I’m not saying we should go “</span><a href="https://www.educationdaly.us/p/the-rise-and-fall-of-finland-mania" rel="">full Finland</a><span>” and turn Mississippi into a junket destination and object of hero worship. It’s not perfect.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-162505881" href="https://www.educationdaly.us/p/mississippi-cant-possibly-have-good#footnote-5-162505881" target="_self" rel="">5</a></span><span> But we need to celebrate their thoughtful statewide strategy that has dramatically improved results without a colossal increase in spending. Their progress is not a fluke. It’s a clue. </span></p></li><li><p><strong>Underperforming states escape scrutiny</strong><span>. Our biases prevent us from asking, for instance, what’s going on in </span><a href="https://edunomicslab.org/oregon-roi-over-time/" rel="">Oregon</a><span>. Or </span><a href="https://edunomicslab.org/vermont-roi-over-time/" rel="">Vermont</a><span>. Or </span><a href="https://edunomicslab.org/maryland-roi-over-time/" rel="">Maryland</a><span>. There’s a case to be made that their instructional quality is among the weakest in the country based on their performance trends over the past decade. And yet, when’s the last time you heard them being pressed to defend their poor outcomes? They’re getting a pass.</span></p></li><li><p><strong>Our federal system becomes a weakness rather than a strength</strong><span>. Devolving most education authority to states theoretically allows innovation based on local needs. But it also presumes that successful practices will catch on with lagging states. That’s not happening. Instead, mediocre and low performing states are living in denial, cherry picking small wins to avoid confronting larger truths. This is one reason that the Every Student Succeeds Act, passed in 2015 and focused on reducing federal accountability, is increasingly seen as a colossal mistake.</span></p></li><li><p><strong>We waste money</strong><span>. </span><a href="https://www.census.gov/library/stories/2024/04/public-school-spending.html" rel="">Education spending has risen significantly</a><span> over the past decade, partly due to COVID relief funding. But student outcomes have not risen. In fact, they’ve </span><a href="https://www.educationdaly.us/p/we-are-in-the-midst-of-an-educational" rel="">gotten worse</a><span>. When states refuse to learn from peers because of a condescending attitude, they pour resources into failed strategies - and then ask taxpayers for more. This (probably) can’t go on forever. Some elected officials are beginning to </span><a href="https://www.oregonlive.com/education/2025/03/gov-koteks-diagnosis-for-schools-more-accountability-not-more-money.html" rel="">reach their limit</a><span>.</span></p></li></ul><p><a href="https://apnews.com/article/electoral-college-democrats-2030-census-election-republican-0d3c8e8d34cbfc87412a21796dddbd38" rel="">Blue states are losing population</a><span>. Estimates vary, but states Kamala Harris won in 2024 will probably surrender 12 congressional seats - and electoral votes - after the next census. </span></p><p><span>Given that reality, Democrats picked a terrible time to go </span><a href="https://nymag.com/intelligencer/article/kamala-harris-democrats-public-education-stance-reform-unions.html" rel="">AWOL on the issue of education</a><span>. Harris </span><a href="https://www.nytimes.com/2024/10/09/opinion/covid-education-crisis-election.html?unlocked_article_code=1.Ek8.ZeVC.oZmtWiwepNWz&amp;smid=url-share" rel="">barely mentioned schools</a><span> during her campaign and did not put forth any plan to address the incredible academic losses of the COVID era. What was </span><a href="https://dfer.org/2023/07/28/new-poll-dems-lose-historic-lead-on-education-in-battleground-states/#:~:text=Democrats%2C%20who%20once,maintained%20strong%20advantages." rel="">once a double-digit lead</a><span> in voter trust on education has now become a dead heat or a slight advantage for Republicans.</span></p><p>There is a future where blue states are left behind electorally, through declining clout, and educationally, through stubborn refusal to accept that a number of red states are solving important problems and expanding opportunity for kids while wealthier, complacent Democratic strongholds phone it in. If Republicans start running - and winning - on their education track records, look out.</p><p><span>A few politicians have caught on. </span><a href="https://www.washingtonpost.com/opinions/2025/03/25/reading-math-scores-education/" rel="">Rahm Emanuel</a><span> recently called on Democrats to apologize for the excessive length of pandemic school closures. Colorado Gov. Jared Polis described this as an “</span><a href="https://www.nga.org/news/press-releases/governors-call-for-education-innovation-to-tackle-declining-test-scores/" rel="">all-hands-on-deck</a><span>” moment. Sen. Michael Bennet has hinted that </span><a href="https://www.cpr.org/2025/03/21/bennet-congress-senate-colorado-springs/" rel="">party leaders need to step aside</a><span> so a new generation of ideas can win back voters who are defecting. All three of them see education as an issue where Democrats ought to be winning - but aren’t. My guess is that successful future Democratic policies sound more like them and less like </span><a href="https://www.the74million.org/article/chicago-fire-chaos-reigns-as-school-board-quits-elections-loom/" rel="">Brandon Johnson</a><span>.</span></p><p><span>Success in education is hard to sustain. Time and distraction wreak havoc on gains that took decades to achieve. Ask </span><a href="https://www.educationdaly.us/p/the-rise-and-fall-of-finland-mania-347" rel="">Finland</a><span>. Or </span><a href="https://www.nbcmiami.com/news/local/florida-test-scores-plummet-after-covid-19-pandemic-disrupted-schools/3529146/" rel="">Florida</a><span>. </span></p><p>Mississippi, Louisiana and Alabama climbed the charts because they focused on core academic instruction when much of the country used ESSA as an excuse to focus on anything and everything else. It paid off. </p><p><span>But it won’t be easy for red states to continue their impressive run when </span><a href="https://www.npr.org/2025/04/23/nx-s1-5374365/trump-signs-education-executive-actions" rel="">President Trump is firing off scattershot executive orders</a><span> advancing culture war priorities that have little to do with student learning. Governors and state chiefs are getting dizzy keeping up with the things they are supposed to do. </span><a href="https://www.edweek.org/policy-politics/most-voters-reject-trumps-push-to-cut-u-s-education-department-poll-finds/2025/01" rel="">Polling</a><span> suggests that moves like cutting every possible position and program at the Department of Education are unpopular. This could go south - no pun intended - in a hurry… especially if Democrats wake up and remember that education policy is a natural winner for them.</span></p><p>Not all the serious education players are in the Deep South. Two that you should watch - Indiana and Iowa - are midwestern states that Barack Obama won in 2008. More recently, though, they’ve gone for Donald Trump three times in a row. </p><p><span>Indiana and Iowa are already in the </span><a href="https://www.urban.org/research/publication/states-demographically-adjusted-performance-2024-national-assessment" rel="">Urban Institute’s top 10</a><span> for at least one NAEP test. They have </span><a href="https://www.in.gov/doe/about/secretary-jenner/" rel="">innovative</a><span> </span><a href="https://educate.iowa.gov/about#:~:text=a%20nonvoting%20role.-,Director%20McKenzie%20Snow,-Director%20McKenzie%20Snow" rel="">superintendents</a><span> who mean business. And they are committed to </span><a href="https://www.the74million.org/article/iowa-submits-plan-to-combine-federal-education-funds-and-experts-are-skeptical/" rel="">leveraging the flexibility</a><span> the Trump administration has promised. </span></p><p>If they rock the next decade of NAEP results, will they be overlooked in the national conversation because they are too farm-y, too milquetoast, too difficult for coastal people to locate on a map?</p><p>Probably. And it will be our loss.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unity’s Open-Source Double Standard: the ban of VLC (493 pts)]]></title>
            <link>https://mfkl.github.io/2024/01/10/unity-double-oss-standards.html</link>
            <guid>43914832</guid>
            <pubDate>Wed, 07 May 2025 12:33:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mfkl.github.io/2024/01/10/unity-double-oss-standards.html">https://mfkl.github.io/2024/01/10/unity-double-oss-standards.html</a>, See on <a href="https://news.ycombinator.com/item?id=43914832">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        
        <h2 id="vlc-for-unity-integration">VLC for Unity integration</h2>

<p>For the readers unaware, we started distributing binaries on the Unity Store for the open-source <a href="https://code.videolan.org/videolan/vlc-unity">VLC for Unity</a> integration back in December 2019.</p>

<p>The integration essentially was a bridge between the Unity game engine and the VLC multimedia engine, allowing to build your own media-player based on VLC technology in Unity-based games. Both Unity, through Mono, and LibVLC are highly portable so this is a compelling argument for this cross-platform integration.</p>

<p>Since the start, we have had many users downloading the assets from the Unity Store for their Unity apps and games when requiring demanding multimedia solutions. We had 3 assets targeting specific platforms:</p>
<ul>
  <li>Windows,</li>
  <li>UWP,</li>
  <li>Android.</li>
</ul>

<h2 id="unity-store-ban">Unity Store ban</h2>

<p>This all changed at the end of the summer 2023 when Unity emailed us the following:</p>

<p>
    <img src="https://mfkl.github.io/assets/unity-store-email.png">
</p>

<p>And just like this, our <a href="https://assetstore.unity.com/publishers/39987">publisher account was instantly banned</a>.</p>

<p>After <em>months</em> of slow back-and-forth over email trying to find a compromise, including offering to exclude LGPL code from the assets, Unity basically told us we were not welcome back to their Store, ever. <em>Even if we were to remove all LGPL code from the Unity package</em>.</p>

<p>Where it gets fun is that there are currently hundreds if not thousands of Unity assets that include LGPL dependencies (such as FFmpeg) in the Store <strong>right now</strong>. Enforcement is seemingly totally random, unless you get reported by someone, apparently.</p>

<p>It gets better… Unity itself, both the Editor and the runtime (which means <em>your shipped game</em>) <strong>is already using LGPL dependencies</strong>! Unity is built on libraries such as Lame, libiconv, libwebsockets and websockify.js (at least). Full list of open-source Unity dependencies <a href="https://gist.github.com/mfkl/ad5cbeadf144e52a762a09fac6a05a70">here</a>.</p>

<p>So Unity gets to use and benefit from LGPL open-source libraries, games built with Unity depend on LGPL code by default (hello glibc!), but publishers and Unity users are not allowed to do so through the Unity Store?</p>

<h2 id="introducing-the-videolabs-store">Introducing the <a href="https://videolabs.io/store">Videolabs Store</a></h2>

<p>
    <a href="https://videolabs.io/store"><img src="https://mfkl.github.io/assets/vlabs-store-1.png"></a>
</p>

<p>If you are a company requiring multimedia products or consulting for your own projects, this store will be of interest to you.</p>

<p>After our assets got removed, previous and new customers started emailing us about the status of VLC for Unity. Are we going to keep maintaining the assets? How to get build updates? etc.</p>

<p>Numerous companies make use of the LibVLC SDK and other related technologies (like FFmpeg).</p>

<p>For this reason, we decided to publish a simple Store on the <a href="https://videolabs.io/">Videolabs</a> website.</p>

<p>This way, existing and new customers can still <a href="https://videolabs.io/store/unity">purchase the binaries for the open-source VLC Unity plugin</a> without our presence on the Unity Store.</p>

<h3 id="flexible-multimedia-consulting-packages">Flexible multimedia consulting packages</h3>

<p>Sometimes users will run into issues or request a new feature and while the community can sometimes help, the limited time of a few volunteers only goes so far. I have written about <a href="https://mfkl.github.io/2020/10/25/OSS-sutainability.html">OSS sustainability before</a> and that is very much on topic here.</p>

<p>It is in the best interest of both open-source project maintainers and commercial consumers to have a clear products and services offering for a given project, and that is what we have created with the <a href="https://videolabs.io/store">Videolabs Store</a> for both LibVLC and FFmpeg.</p>

<p>The Videolabs team is composed of VLC and FFmpeg experts in most protocols, formats and platforms.</p>

<p>If you are using or planning to use LibVLC or FFmpeg in your project and need help, whether it be custom builds, bug fixes, SDK integration or simply answers to your questions for your specific needs, these packages are for you!</p>

<p>
    <a href="https://videolabs.io/store"><img src="https://mfkl.github.io/assets/vlabs-store-2.png"></a>
</p>

<p>We have created 3 multimedia consulting packages: 3 hours, 10 hours and 24 hours. They can be purchased for a one-time service or a monthly subscription.</p>

<p>No matter which OS platform or toolkit you are building with, we can help.</p>

<h3 id="other-products">Other products</h3>

<p>The <a href="https://videolabs.io/store/libvlcsharp/">LibVLCSharp commercial license</a> and the <a href="https://mfkl.gumroad.com/l/libvlc-good-parts">LibVLC ebook</a> can also be found in the <a href="https://videolabs.io/store">Videolabs Store</a>, as well as other upcoming products such as Kyber, our new ultra low latency game/desktop streaming and remote control SDK, and more game engine integration such as Unreal.</p>

<p>
    <a href="https://videolabs.io/store"><img src="https://mfkl.github.io/assets/vlabs-store-3.png"></a>
</p>

        
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CLion Is Now Free for Non-Commercial Use (551 pts)]]></title>
            <link>https://blog.jetbrains.com/clion/2025/05/clion-is-now-free-for-non-commercial-use/</link>
            <guid>43914705</guid>
            <pubDate>Wed, 07 May 2025 12:18:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jetbrains.com/clion/2025/05/clion-is-now-free-for-non-commercial-use/">https://blog.jetbrains.com/clion/2025/05/clion-is-now-free-for-non-commercial-use/</a>, See on <a href="https://news.ycombinator.com/item?id=43914705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    				<p><a href="https://blog.jetbrains.com/clion/category/news/">News</a></p><h2 id="major-updates">CLion Is Now Free for Non-Commercial Use</h2>                    
                    
<blockquote>

<cite>“C makes it easy to shoot yourself in the foot. C++ makes it harder, but when you do, it blows away your whole leg.” — Bjarne Stroustrup</cite></blockquote>



<p>We can’t make С and C++ simpler, but we can make working with them a bit easier. <a href="https://www.jetbrains.com/clion/" target="_blank" rel="noopener">CLion</a> is now free for non-commercial use!</p>



<p>Yes, finally.</p>



<p>Whether you’re a student, an Arduino experimenter, or someone who loves С and C++ with all your heart despite all the challenges these languages present, CLion is now available to you for free – as long as you’re not using it for commercial work.</p>



<h2>What’s happening?</h2>



<p>Last year we implemented a new licensing model for <a href="https://www.jetbrains.com/rust/" target="_blank" rel="noopener">RustRover</a>, <a href="https://www.jetbrains.com/rider/" target="_blank" rel="noopener">Rider</a>, and <a href="https://www.jetbrains.com/webstorm/" target="_blank" rel="noopener">WebStorm</a>, making them free for non-commercial use. We’re now extending this model to CLion. If you’re using it for non-commercial purposes, such as <strong>learning</strong>, <strong>open-source project development</strong>, <strong>content creation</strong>, or <strong>hobby development</strong>, you can now do so for free. For commercial use, our existing licensing model still applies.</p>



<p>Note that while CLion now joins RustRover, Rider, and WebStorm in being free for non-commercial use, this update <strong>doesn’t apply to other JetBrains IDEs</strong> at this time. We’re keeping an eye on how things go and will continue evaluating the impact of this initiative.</p>



<h2>Why are we doing this?</h2>



<p>In making non-commercial development free, we aim to make JetBrains IDEs more accessible to a broader audience. We hope the new licensing model will further lower the barrier to using our IDEs, helping you learn, grow, and stay creative.</p>



<p>You can find more details about why we’re introducing this update in the <a href="https://blog.jetbrains.com/blog/2024/10/24/webstorm-and-rider-are-now-free-for-non-commercial-use/">blog post making the original announcement</a>.</p>



<h2>Why CLion?</h2>



<p>C++ is powerful, but it’s not exactly known for being easy or forgiving. And then there’s C – lean, low-level, and still a core part of many computer science curricula. Whether you’re learning these languages, diving into systems programming, or exploring embedded development on your own, C and C++ often come with a steep learning curve.</p>



<p>We want to support that journey. With CLion now free for non-commercial use, it’s easier for you to experiment, learn, and build – without worrying about the IDE license.</p>



<h2>Commercial vs. non-commercial use</h2>



<p>As defined in the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>, commercial use means developing products and earning commercial benefits from your activities. However, certain categories are explicitly excluded from this definition. Common examples of non-commercial uses include learning and self-education, open-source contributions without earning commercial benefits, any form of content creation, and hobby development.</p>



<p>It’s important to note that, if you’re using a non-commercial license, you cannot opt out of the collection of anonymous usage statistics. We use this information to improve our products. The data we collect is exclusively that of anonymous feature usages of our IDEs. It is focused on what actions are performed and what types of functionality of the IDE are used. We do not collect any other data. This is similar to our Early Access Program (EAP) and is in compliance with our Privacy Policy.</p>



<h2>FAQ</h2>



<p>Below are answers to the most common questions. Check out the <a href="https://sales.jetbrains.com/hc/en-gb/articles/18950890312210-The-free-non-commercial-licensing-FAQ" target="_blank" rel="noopener"><strong>full FAQ</strong></a> for more information.</p>



<h3>Licensing</h3>



<h4>What features are included under the free license?</h4>



<p>With the new non-commercial license type, you can enjoy a full-featured IDE that is identical to its paid version. The only difference is in the Code With Me feature – you get <a href="https://www.jetbrains.com/code-with-me/buy/?section=personal&amp;billing=monthly" target="_blank" rel="noopener">Code With Me Community</a> with your free license.</p>



<h4>Which license should I choose if I want to use CLion for both non-commercial and commercial projects?</h4>



<p>If you intend to use CLion for commercial development for which you will receive direct or indirect commercial advantage or monetary compensation within the meaning of the definitions provided in the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>, you will need to purchase a commercial subscription (either individual or organizational). This license can then also be used for non-commercial development.</p>



<h4>How do renewals and upgrades work now?</h4>



<p>Non-commercial subscriptions are issued for one year and will automatically renew after that. However, for the renewal to happen, you must have used the assigned license at least once during the last 6 months of the subscription period. If it has been more than 6 months since you last used an IDE activated with this type of license and the renewal did not occur automatically, you can request a new non-commercial subscription again at any time.</p>



<h4>Am I eligible for a refund if I’ve already bought a paid subscription but do non-commercial development?</h4>



<p>If you’re unsure whether you qualify for a refund, you’ll find full details of our policy <a href="https://sales.jetbrains.com/hc/en-gb/articles/115000913704-How-can-I-get-a-refund" target="_blank" rel="noopener">here</a>. Please note that if you also work on projects that qualify as commercial usage, you can’t use the free license for them.</p>



<h3>Anonymous data collection&nbsp;</h3>



<h4>Does my IDE send any data to JetBrains?</h4>



<p>The terms of the non-commercial agreement assume that the product may also electronically send JetBrains anonymized statistics (IDE telemetry) related to your usage of the product’s features. This information may include but is not limited to frameworks, file templates used in the product, actions invoked, and other interactions with the product’s features. This information does not contain personal data.</p>



<h4>Is there a way to opt out of sending anonymized statistics?</h4>



<p>We appreciate that this might not be convenient for everyone, but there is unfortunately no way to opt out of sending anonymized statistics to JetBrains under the terms of the Toolbox agreement for non-commercial use. The only way to opt out is by switching to either a paid subscription or one of the complimentary options mentioned <a href="https://www.jetbrains.com/store/?section=students&amp;billing=yearly" target="_blank" rel="noopener">here</a>.</p>



<h3>Getting a non-commercial subscription&nbsp;</h3>



<h4>What should I do to apply for this subscription?</h4>



<p>It can be easily done right inside your IDE:</p>



<ol>
<li>Install CLion and run it.</li>



<li>Upon startup, there will be a license dialog box where you can choose the <em>Non-commercial use </em>option.</li>



<li>Log in to your JetBrains account or create a new one.&nbsp;</li>



<li>Accept the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>.</li>



<li>Enjoy development in your IDE.</li>
</ol>



<p>If you’ve already started a trial period or have activated your IDE using a paid license, you still can switch to a non-commercial subscription by following these steps:</p>



<ol>
<li>Go to <em>Help | Register.</em></li>



<li>In the window that opens, click on the <em>Remove License</em> button.</li>



<li>Choose <em>Non-commercial use.</em></li>



<li>Log in to your JetBrains account or create a new one.&nbsp;</li>



<li>Accept the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>.</li>



<li>Enjoy development in your IDE.</li>
</ol>



<h4>I don’t see the <em>Non-commercial use</em> option in my IDE. What should I do?&nbsp;</h4>



<p>The most likely explanation for this is that you’re using an older version of CLion. Unfortunately, we don’t support obtaining the non-commercial license for any releases prior to CLion 2025.1.1. That’s it for today! If you don’t find an answer to your question, feel free to leave a comment or contact us at <a href="https://www.jetbrains.com/support/sales/#email-sales" target="_blank" rel="noopener">sales@jetbrains.com</a>.</p>



<p>Your CLion team<br>
<em>JetBrains</em><br>
<em>Make it happen. With code.</em></p>
                    
                                                                                                                                                                                                                            <div>
                                <div>
                                                                            <h4>Subscribe to CLion Blog updates</h4>
                                                                                                            
                                </div>
                                
                                <p><img src="https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg" alt="image description">
                                                                    </p>
                            </div>
                                                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My quest to make motorcycle riding that tad bit safer (230 pts)]]></title>
            <link>https://gill.net.in/posts/my-quest-to-make-motorcycle-riding-safer/</link>
            <guid>43914235</guid>
            <pubDate>Wed, 07 May 2025 11:06:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gill.net.in/posts/my-quest-to-make-motorcycle-riding-safer/">https://gill.net.in/posts/my-quest-to-make-motorcycle-riding-safer/</a>, See on <a href="https://news.ycombinator.com/item?id=43914235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>It began with a spark—a dormant passion reignited after many years away from motorcycling. Life had steered me in different directions, away from the saddle, but something deep inside pulled me back to the thrill and freedom that only riding offers.</p><p>Returning to motorcycling after such an extended hiatus was daunting yet exhilarating. I vividly recall my first CBT session: the nerves, the good-natured laughter at my clumsy mistakes, and the sheer joy when everything finally clicked into place. It was during this session that a critical moment of inspiration occurred. My instructor casually suggested lightly applying the brakes during engine braking to alert drivers behind that I was slowing down. Given motorcycles’ inherent lightweight design and strong engine braking, the risk of being rear-ended was significant.</p><p>It struck me profoundly how something so vital could be left to mere habit—this realization triggered my engineering instincts. Relying solely on human memory and habitual action seemed inadequate and unreliable. I wondered: “Could technology automate this essential safety process?” Thus, BrakeBright was conceived—a smart brake-light system specifically tailored for motorcycles. BrakeBright intelligently detects when the motorcycle slows due to engine braking, activating the brake lights even before the rider manually applies the brakes. Moreover, during intense braking scenarios, it flashes proportionately to the braking intensity.</p><p>Curious to see what was already available, I purchased one of the few similar products on the market. To my surprise, it relied solely on a basic tilt switch, rattling excessively during rides despite claims of “advanced technology.” The device was not only ineffective but also potentially hazardous. Drivers instinctively focus on brake lights; unless the brake light itself clearly indicates deceleration, most would fail to notice.</p><p>Interestingly, adaptive brake light technology already exists in high-end vehicles. BMW’s dynamic brake light, for example, flashes during emergency braking to alert trailing drivers, greatly enhancing road safety. Similarly, KTM motorcycles incorporate an Adaptive Brake Light system for better visibility during sudden deceleration. However, such advanced safety features have traditionally been reserved for premium models. My vision for BrakeBright was to democratize this essential safety feature, making it accessible to every rider through a simple, straightforward modification. Installation requires no special tools—using posi-tap connectors, BrakeBright easily integrates with your motorcycle’s existing wiring in just minutes.</p><p>Developing BrakeBright involved starting with a simple motion sensor and microcontroller unit (MCU) on a breadboard. Countless hours went into refining the device—tweaking, programming, and improving—long before I even had my own motorcycle license. As the idea evolved, I designed the initial printed circuit board (PCB) prototype, carefully hand-soldering tiny surface-mount components late into the night.</p><p><img loading="lazy" src="https://gill.net.in/images/brakebright-breadboard.jpg" alt="BrakeBright PCB prototype"></p><p>Testing presented another unique challenge—I initially didn’t own a motorcycle. My friend Johny generously volunteered his bike for field testing. I sent each prototype iteration to him, and he diligently provided feedback that guided continuous improvements. This iterative process spanned several months, steadily bringing BrakeBright closer to perfection.</p><p>By the third PCB version, I had my motorcycle and could directly test and refine the system. Challenges arose frequently: vibration jitter interfering with sensor accuracy, synchronization issues between sampling rates and engine RPM, and false positives during long rides. To visually verify BrakeBright’s actions, I installed an LED at the front of my motorcycle, enabling real-time monitoring. This hands-on method significantly improved reliability, particularly the flashing-on-hard-braking feature. BrakeBright employs a sensitive accelerometer to detect velocity changes accurately, determining whether the motorcycle is slowing due to engine braking or active rider input. It’s also engineered to be fully waterproof and vibration-resistant, ensuring dependable performance under any riding conditions.</p><p><img loading="lazy" src="https://gill.net.in/images/brakebright-pcb.jpg" alt="BrakeBright PCB prototype"></p><p>Thousands of miles of rigorous testing followed, notably including Scotland’s iconic NC500 route alongside Johny—misty mornings, sweeping highland bends, and dramatic descents providing the ideal proving grounds. One vivid memory stands out: braking sharply on a tight, downhill hairpin near Applecross Pass, I observed BrakeBright’s flash sequence activate exactly as intended—clear, swift, and unmistakable. Riders especially appreciated BrakeBright’s flashing feature, noting how it significantly improved rearward visibility during intense braking situations.</p><p>Another challenge emerged when the initial BrakeBright unit required specialized equipment for firmware updates. Committed to empowering users, I developed a subsequent version incorporating a USB port. Currently, I’m finalizing user-friendly software utilities, enabling riders to easily update BrakeBright firmware, customize features, and personalize the system to match individual riding styles and preferences.</p><p>Months of effort culminated in the thrilling moment the first production batch arrived. I still recall opening the box at my workbench—the scent of fresh solder and cardboard filling the air—and seeing the finished BrakeBright units gleaming. Holding one in my hands, experiencing its meticulous craftsmanship and sleek design realized exactly as envisioned, was profoundly rewarding. I felt immense pride, a hint of nervous excitement, and deep satisfaction.</p><p>Yet, this is merely the beginning. The initial shipments and early customers symbolize far more than sales—they validate that risk-taking, passion, and belief can transform ideas into reality. With an open feedback loop and software upgrade tools nearing completion, I’m eager to see riders embrace BrakeBright, making it uniquely theirs.</p><p><img loading="lazy" src="https://gill.net.in/images/brakebright-first-batch.jpg" alt="BrakeBright First Batch"></p><p>If you’re interested in BrakeBright, want to test it, or simply enjoy discussing motorcycles and technology, please reach out or follow along for updates.</p><p>If you want to support my journey, consider purchasing a BrakeBright unit
<a href="https://shop.bikesafe.me/products/dynamic-brake-light-controller-kit" target="_blank" rel="noopener">here</a>
. Your support means the world to me and helps fuel my passion for making motorcycle riding safer and more enjoyable for everyone.</p><p>If you enjoyed reading this post, you can click 👍 at the top a few times.</p><p>Thank you for reading and <i>Happy Coding!</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So Much Blood (350 pts)]]></title>
            <link>https://dynomight.net/blood/</link>
            <guid>43913751</guid>
            <pubDate>Wed, 07 May 2025 09:41:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dynomight.net/blood/">https://dynomight.net/blood/</a>, See on <a href="https://news.ycombinator.com/item?id=43913751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
    
  <section>
    <p>In a recent post about <a href="https://dynomight.net/money/">trading stuff for money</a>, I mentioned:</p>

<blockquote>
  <p>Europe had a [blood plasma] shortage of around 38%, which it met by importing plasma from paid donors in the United States, where blood products account for 2% of <em>all</em> exports by value.</p>
</blockquote>

<p>The internet’s reaction was: “TWO PERCENT?” “<strong>TWO PERCENT OF U.S. EXPORTS ARE BLOOD!?</strong>”</p>

<p>Well, I took that 2% number from a 2024 <a href="https://www.economist.com/finance-and-economics/2024/08/29/the-plasma-trade-is-becoming-ever-more-hypocritical">article in the Economist</a>:</p>

<blockquote>
  <p>Last year American blood-product exports accounted for 1.8% of the country’s total goods exports, up from just 0.5% a decade ago—and were worth $37bn. That makes blood the country’s ninth-largest goods export, ahead of coal and gold. All told, America now supplies 70% or so of the plasma used to make medicine.</p>
</blockquote>

<p>I figured the Economist was trustworthy on matters of economics. But note:</p>

<ol>
  <li>That 1.8% number is for blood <em>products</em>, not just blood.</li>
  <li>It’s a percentage of <em>goods</em> exported, excluding services.</li>
  <li>It’s wrong.</li>
</ol>

<p>The article doesn’t explain how they arrived at 1.8%. And since the Economist speaks in the voice of God (without bylines), I can’t corner and harass the actual journalist. I’d have liked to reverse-engineer their calculations, but this was impossible since the world hasn’t yet caught on that they should always <a href="https://dynomight.net/digits/">show lots of digits</a>.</p>

<p>So what’s the right number? In 2023, total US goods exports were <a href="https://www.census.gov/foreign-trade/Press-Release/ft900/ft900_2405.pdf#page=20">$2,045 billion</a>, almost exactly ⅔ of all exports, including services.</p>

<p>How much of that involves blood? Well, the government keeps statistics on trade based on an insanely detailed <a href="https://hts.usitc.gov/reststop/file?release=2023HTSARev8&amp;filename=Chapter%2098">classification scheme</a>. All goods get some number. For example, <a href="https://en.wikipedia.org/wiki/Airship">dirigibles</a> fall under <a href="https://hts.usitc.gov/reststop/file?release=2025HTSRev9&amp;filename=Chapter%2088">HTS 8801.90.0000</a>:</p>

<p><img src="https://dynomight.net/img/blood/dirgibles.png" alt=""></p>

<p>Leg warmers fall under HTS 6406.99.1530:</p>

<p><img src="https://dynomight.net/img/blood/leg_warmers.png" alt="leg warmers"></p>

<p>So what about blood? Well, <a href="https://www.usitc.gov/publications/docs/tata/hts/bychapter/1000c30.pdf#page=3">HTS 3002</a> is the category for:</p>

<blockquote>
  <p>Human blood; animal blood prepared for therapeutic, prophylactic or diagnostic uses; antisera and other blood fractions and modified immunological products, whether or not obtained by means of biotechnological processes; vaccines, toxins, cultures of micro-organisms (excluding yeasts) and similar products:</p>
</blockquote>

<p>The total exports in this category in 2023 were 41.977 billion, or 2.05% of all goods exports. But that category includes many products that don’t require human blood such as most vaccines.</p>

<p>To get the actual data, you need to go through a <a href="https://dataweb.usitc.gov/trade/search/Export/HTS">website</a> maintained by the US Trade Commission. This website has good and bad aspects. On the one hand, it’s slow and clunky and confusing and often randomly fails to deliver any results. On the other hand, when you re-submit, it clears your query and then blocks you for submitting too many requests, which is nice.</p>

<p>But after a lot of tearing of hair, I got what seems to be the most detailed breakdown of that category available. There are some finer subcategories in the taxonomy, but they don’t seem to have any data.</p>

<p>So let’s go through those categories. To start, here are some that would seem to almost always contain human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.12.00.10</td>
      <td>HUMAN BLOOD PLASMA</td>
      <td>5,959,103,120</td>
      <td>0.2914%</td>
    </tr>
    <tr>
      <td>3002.12.00.20</td>
      <td>NORMAL HUMAN BLOOD SERA, WHETHER OR NOT FREEZE-DRIED</td>
      <td>38,992,251</td>
      <td>0.0019%</td>
    </tr>
    <tr>
      <td>3002.12.00.30</td>
      <td>HUMAN IMMUNE BLOOD SERA</td>
      <td>5,608,090</td>
      <td>0.0003%</td>
    </tr>
    <tr>
      <td>3002.12.00.90</td>
      <td>ANTISERA AND OTHER BLOOD FRACTIONS</td>
      <td>4,808,069,119</td>
      <td>0.2351%</td>
    </tr>
    <tr>
      <td>3002.90.52.10</td>
      <td>WHOLE HUMAN BLOOD</td>
      <td>22,710,898</td>
      <td>0.0011%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(YES BLOOD)</strong></td>
      <td><strong>10,834,483,478</strong></td>
      <td><strong>0.5298%</strong></td>
    </tr>
  </tbody>
</table>

<p>Next, there are several categories that would seem to essentially <em>never</em> contain human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.12.00.40</td>
      <td>FETAL BOVINE SERUM (FBS)</td>
      <td>146,026,727</td>
      <td>0.0071%</td>
    </tr>
    <tr>
      <td>3002.42.00.00</td>
      <td>VACCINES FOR VETERINARY MEDICINE</td>
      <td>638,191,743</td>
      <td>0.0312%</td>
    </tr>
    <tr>
      <td>3002.49.00.00</td>
      <td>VACCINES, TOXINS, CULTURES OF MICRO-ORGANISMS EXCLUDING YEASTS, AND SIMILAR PRODUCTS, NESOI</td>
      <td>1,630,036,341</td>
      <td>0.0797%</td>
    </tr>
    <tr>
      <td>3002.59.00.00</td>
      <td>CELL CULTURES, WHETHER OR NOT MODIFIED, NESOI</td>
      <td>79,384,134</td>
      <td>0.0039%</td>
    </tr>
    <tr>
      <td>3002.90.10.00</td>
      <td>FERMENTS</td>
      <td>361,418,233</td>
      <td>0.0177%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(NO BLOOD)</strong></td>
      <td><strong>2,869,107,296</strong></td>
      <td><strong>0.1403%</strong></td>
    </tr>
  </tbody>
</table>

<p>Finally, there are categories that include <em>some</em> products that <em>might</em> contain human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.13.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, UNMIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>624,283,112</td>
      <td>0.0305%</td>
    </tr>
    <tr>
      <td>3002.14.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, MIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>5,060,866,208</td>
      <td>0.2475%</td>
    </tr>
    <tr>
      <td>3002.15.01.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>13,317,356,469</td>
      <td>0.6512%</td>
    </tr>
    <tr>
      <td>3002.41.00.00</td>
      <td>VACCINES FOR HUMAN MEDICINE, NESOI</td>
      <td>7,760,695,744</td>
      <td>0.3795%</td>
    </tr>
    <tr>
      <td>3002.51.00.00</td>
      <td>CELL THERAPY PRODUCTS</td>
      <td>595,963,010</td>
      <td>0.0291%</td>
    </tr>
    <tr>
      <td>3002.90.52.50</td>
      <td>HUMAN BLOOD; ANIMAL BLOOD PREPARED FOR THERAPEUTIC, PROPHYLATIC OR DIAGNOSTIC USES; ANTISERA AND OTHER BLOOD FRACTIONS, ETC. NESOI</td>
      <td>914,348,561</td>
      <td>0.0447%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(MAYBE BLOOD)</strong></td>
      <td><strong>28,273,513,104</strong></td>
      <td><strong>1.3826%</strong></td>
    </tr>
  </tbody>
</table>

<p>The biggest contributor here is IMMUNOLOGICAL PRODUCTS (be they MIXED or UNMIXED, PUT UP or NOT PUT UP). The largest fraction of these is probably antibodies.</p>

<p>Antibodies are <em>sometimes</em> made from human blood. You may remember that in 2020, some organizations collected human blood from people who’d recovered from Covid to make antibodies. But it’s important to stress that this is quite rare. Human blood, after all, is expensive. So—because capitalism—whenever possible animals are used instead, often rabbits, goats, sheep, or <a href="https://en.wikipedia.org/wiki/Humanized_mouse">humanized mice</a>.</p>

<p>I can’t find any hard statistics on this. But I know several people who work in this industry. So I asked them to just guess what fraction might include human blood. Biologists don’t like numbers, so this took a lot of pleading, but my best estimate is 8%.</p>

<p>When looking at similar data a few years ago, <a href="http://marketdesigner.blogspot.com/2020/05/plasma-and-plasma-products-such-as.html">Market Design</a> suggested that that <a href="https://en.wikipedia.org/wiki/Immunoglobulin_therapy">immunoglobulin products</a> might also fall under this category. But as far as I can tell this is not true. I looked up the tariff codes for a few immunoglobulin products, and they all seem to fall under 3002.90 (“HUMAN BLOOD; ANIMAL BLOOD PREPARED FOR THERAPEUTIC, PROPHYLATIC OR DIAGNOSTIC USES; ANTISERA AND OTHER BLOOD FRACTIONS, ETC. NESOI”)</p>

<p>What about vaccines or <a href="https://en.wikipedia.org/wiki/Cell_therapy">cell therapy</a> products? These almost never contain human blood. But they are <em>sometimes</em> made by growing human cell lines, and <em>sometimes</em> those cell lines require human <a href="https://en.wikipedia.org/wiki/Serum_(blood)">blood <em>serum</em></a> to grow. More pleading with the biologists produced a guess that this is true for 5% of vaccines and 80% of cell therapies.</p>

<p><em>Aside</em>: Even if they do require blood serum, it’s somewhat debatable if they should count as “blood products”. How far down the supply chain does that classification apply? If I make cars, and one of my employees gets injured and needs a blood transfusion, are my cars now “blood products”?</p>

<p>Anyway, here’s my best guess for the percentage of products in this middle category that use human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Needs blood (guess)</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.13.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, UNMIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>8%</td>
      <td>49,942,648</td>
      <td>0.0024%</td>
    </tr>
    <tr>
      <td>3002.14.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, MIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>8%</td>
      <td>404,869,296</td>
      <td>0.0198%</td>
    </tr>
    <tr>
      <td>3002.15.01.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>8%</td>
      <td>1,065,388,517</td>
      <td>0.0521%</td>
    </tr>
    <tr>
      <td>3002.41.00.00</td>
      <td>VACCINES FOR HUMAN MEDICINE, NESOI</td>
      <td>5%</td>
      <td>388,034,787</td>
      <td>0.0190%</td>
    </tr>
    <tr>
      <td>3002.51.00.00</td>
      <td>CELL THERAPY PRODUCTS</td>
      <td>80%</td>
      <td>476,770,408</td>
      <td>0.0233%</td>
    </tr>
    <tr>
      <td>3002.90.52</td>
      <td>HUMAN BLOOD; ANIMAL BLOOD PREPARED FOR THERAPEUTIC, PROPHYLATIC OR DIAGNOSTIC USES; ANTISERA AND OTHER BLOOD FRACTIONS, ETC. NESOI</td>
      <td>90%</td>
      <td>822,913,704</td>
      <td>0.0402%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(GUESSED BLOOD)</strong></td>
      <td>&nbsp;</td>
      <td><strong>3,207,919,363</strong></td>
      <td><strong>0.1569%</strong></td>
    </tr>
  </tbody>
</table>

<p>So 0.5298% of goods exports almost certainly use blood, and my best guess is that another 0.1569% of exports also include blood, for a total of 0.6867%.</p>

<p>Obviously, this is a rough cut. But I couldn’t find any other source that shows their work in any detail, so I hoped that by publishing this I could at least prod Cunningham’s law into action. Sorry for all the numbers.</p>

  </section>
  
</div></div>]]></description>
        </item>
    </channel>
</rss>