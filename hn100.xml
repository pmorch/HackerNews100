<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 08 Mar 2025 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Kill your Feeds – Stop letting algorithms dictate what you think (320 pts)]]></title>
            <link>https://usher.dev/posts/2025-03-08-kill-your-feeds/</link>
            <guid>43302132</guid>
            <pubDate>Sat, 08 Mar 2025 18:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://usher.dev/posts/2025-03-08-kill-your-feeds/">https://usher.dev/posts/2025-03-08-kill-your-feeds/</a>, See on <a href="https://news.ycombinator.com/item?id=43302132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>
We are being boiled like frogs. It happened gradually, one algorithmic tweak at a time. What started as a way to connect with friends has become a system that gives the corporations that run social media control over what we consume and the ability to subtly shape how we think.
</p>
<p>We used to control apps like Facebook and Instagram with our own choices. They became daily comforts, making the world seem a little bit smaller and closer by bringing the people that we cared about together in to one place.</p>
<p>But from the perspective of these companies, that’s a problem. Our personal worlds, our friends, family, and connections, are finite. Once we’ve caught up, we put the app down. That’s bad for business.</p>
<p>Social media companies need us flicking through their apps as long as they can keep us there. More eyes on ads is more money. So they play the system a bit. You’ve lingered on enough photos of cute puppies, they know what you like.</p>
<p>Before long those feeds of finite content are replaced by infinite algorithmic content pulled from millions of users trying to optimise their posts to be picked up by the omnipotent algorithms. Algorithms which are completely opaque to us.</p>
<p>Sci-fi imagines megacorporations controlling our minds with brain implants. Some worry that companies are already listening in. But they don’t have to - they already control our eyes.</p>
<p>The creators of TikTok, Instagram etc. have gained control over exactly what we see. What we see strongly influences how we think. <a href="https://en.m.wikipedia.org/wiki/2021_Facebook_leak">They know</a> that their feeds make us angry, they know the negative effects on our mental health (particularly that of teens), and they know that they have an influence on our opinion.</p>
<p>With the power to shape what we see comes the power to shape what we believe. Whether through deliberate manipulation or the slow creep of algorithmic recommendations, engagement is fueled by outrage, and outrage breeds extremism. The result is a feedback loop that isolates users, reinforces beliefs, and deprioritises opposing viewpoints.</p>
<p>We live in times where being able to form our own opinion is more important than ever. Where knowing how to source and identify truthful information is a critical skill.</p>
<p>Our reliance on being spoon fed ideas is destroying those abilities, Alec of Technology Connections calls this <a href="https://youtu.be/QEJpZjg8GuA">algorithmic complacency</a>, referencing our increasing inability to look outside our algorithmically created bubble. The social media companies don’t care, the only person who has any interest in fixing this is you.</p>
<h2 id="take-the-power-back">Take the Power Back</h2>
<p>It’s time to take back control of how we think. We’ve identified the problem, now it’s time to take action.</p>
<p>We don’t all have the freedom, interest or willpower to delete social media from our lives entirely. It’s still where our friends are, an occasional distraction from reality and a source of entertainment. You don’t have to become a digital outcast to hold back this influence.</p>
<p>So what can we do?</p>
<ol>
<li>Go directly to the source - if you like a particular TikTok creator, Facebook page or YouTube channel, skip the feed and go directly to their pages. Consider bookmarking their profiles individually.</li>
<li>Learn to find information and entertainment without a feed - try to find a creator making videos or writing about a topic of interest without having to stumble across them in a feed.</li>
<li>Use platforms and platform features that let you control your experience - Instagram’s ‘Following’ feed, YouTube’s Subscriptions page, <a href="https://bsky.app/">Bluesky</a>, <a href="https://mastodon.social/">Mastodon</a> and <a href="https://zapier.com/blog/how-to-use-rss-feeds/">RSS feeds</a></li>
<li>Be mindful of engagement traps - recognise how algorithmic feeds are designed to keep you engaged and scrolling. Take a breath and stop the cycle.</li>
<li>Talk about it - if you’re reading this you a already know this is a problem. Your friends and family may not be aware of how their feeds are manipulating their attention and beliefs. Without intervention, the radicalisation of opinions, and the consequences we’re already seeing, will only escalate.</li>
</ol>
<p>The internet should serve you, not the other way around. Take back control. Kill your feeds before they kill your ability to think independently.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi Is Bringing Orion Web Browser to Linux (114 pts)]]></title>
            <link>https://www.omgubuntu.co.uk/2025/03/kag-orion-web-browser-coming-to-linux</link>
            <guid>43302073</guid>
            <pubDate>Sat, 08 Mar 2025 18:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.omgubuntu.co.uk/2025/03/kag-orion-web-browser-coming-to-linux">https://www.omgubuntu.co.uk/2025/03/kag-orion-web-browser-coming-to-linux</a>, See on <a href="https://news.ycombinator.com/item?id=43302073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
<p><strong>Kagi, the company behind a paid, private search engine</strong><sup data-fn="85d04576-418d-4a25-a22c-8a1b88ea1f05"><a id="85d04576-418d-4a25-a22c-8a1b88ea1f05-link" href="#85d04576-418d-4a25-a22c-8a1b88ea1f05">1</a></sup><strong> of the same name, has announced it’s bringing its Webkit-based <a href="https://kagi.com/orion/" target="_blank" rel="noreferrer noopener"><em>Orion</em> web browser</a> to Linux.</strong></p>



<p>In a post on BlueSky, Kagi said: <em>“We’re thrilled to announce that development of the Orion Browser for Linux has officially started!”</em>. </p>



<p><em>Orion</em> is currently only available on macOS and iOS but was built to be better than Apple’s own Safari, and best Google Chrome, Mozilla Firefox and other browsers in many areas.</p>



<p>Orion is a zero-telemetry browser; has built-in ad and tracking blocking; and reportedly offers lower memory usage, faster page speeds, and greater battery efficiency on Apple devices than other browsers. It also supports both Chrome and Firefox extensions.</p>


<div>
<figure><a href="https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1.jpg"><img decoding="async" width="840" height="441" src="https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-840x441.jpg" alt="Orion web browser" srcset="https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-840x441.jpg 840w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-300x158.jpg 300w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-768x403.jpg 768w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1-1536x806.jpg 1536w , https://149366088.v2.pressablecdn.com/wp-content/uploads/2025/03/Kargi-Orion-on-macOS-1.jpg 1920w " sizes="(max-width: 840px) 100vw, 840px"></a><figcaption>Orion Browser <span>on macOS</span> supports Chrome <em>and</em> Firefox Add-ons</figcaption></figure></div>


<p>Whether all of those USPs can be carried over to Linux—a less defined ‘platform’ than macOS if targeting things like power efficiency—remains to be seen. Kagi is hopeful; they say the Orion Linux build will have feature-parity with the macOS version by next year.</p>







<p>Obviously, Orion’s (current) closed-source nature will not endear it to everyone. Plenty of Linux users simply can’t countenance using <em>Steam</em>, <em>Spotify</em>, <em>Vivaldi</em>, <em>Slack</em>, <em>Discord</em>, <em>Google Chrome</em>, <em>WhatsApp</em> or other non-free apps, tools, or services.</p>



<p>—That’s fair; we’re free to choose the software that works for us on whatever level that matters, be it utility, integration, or indeed license model.</p>



<p>Yet, the idea of being able to run a fast, user-friendly, and flexible WebKit-based web browser on Linux is a promising development for choice, if nothing else. GNOME Web/Epiphany shows the promise WebKit offers – Orion may bring the polish.</p>



<p>Kagi has started work on open-sourcing <a href="https://github.com/OrionBrowser">many components</a>&nbsp;used in Orion and plans to open source more — the small team is the bottleneck; forking WebKit, porting hundreds of APIs, and building a browser from scratch takes resources.</p>



<p><em>“Properly maintaining an open-source project takes time and resources we’re short on at the moment, so if you want to contribute at this time, please consider becoming active on&nbsp;orionfeedback.org,” they add. </em></p>



<p>If you’re interested in learning more about Orion (for macOS) check out the <a href="https://kagi.com/orion/">Orion landing page</a> on the Kagi website, or read through a <a href="https://kagi.com/orion/faq.html" target="_blank" rel="noreferrer noopener">comprehensive FAQ</a>.  To sign-up for news on the upcoming Linux version, plug in an e-mail in the sign-up form.</p>



<p>The saying goes “if you’re not paying for the product, you are the product” —<em>unless open-source</em>, I tend to add if I hear someone say it! Alas, Mozilla’s recent faux-pas suggests that even noble projects aren’t immune to the shiny glint of <em>ick</em>.</p>



<p><em>Thanks Sambot!</em></p>


<ol><li id="85d04576-418d-4a25-a22c-8a1b88ea1f05">I haven’t tried Kagi Search but it’s tempting given how other search engines are <a href="https://wallethub.com/blog/google-quality-issues-report/147091" target="_blank" rel="noreferrer noopener">increasingly focused</a> on getting people to spend money, not find information.   <a href="#85d04576-418d-4a25-a22c-8a1b88ea1f05-link" aria-label="Jump to footnote reference 1">↩︎</a></li></ol>                                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Bankman-Fried thrown into solitary over Tucker Carlson interview: report (134 pts)]]></title>
            <link>https://gizmodo.com/sam-bankman-fried-thrown-into-solitary-over-tucker-carlson-interview-report-2000573371</link>
            <guid>43301702</guid>
            <pubDate>Sat, 08 Mar 2025 17:14:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/sam-bankman-fried-thrown-into-solitary-over-tucker-carlson-interview-report-2000573371">https://gizmodo.com/sam-bankman-fried-thrown-into-solitary-over-tucker-carlson-interview-report-2000573371</a>, See on <a href="https://news.ycombinator.com/item?id=43301702">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              
              <p>Tucker Carlson’s interview with disgraced crypto CEO Sam Bankman-Fried, which was distributed <a href="https://gizmodo.com/sbf-suggests-dems-didnt-save-him-because-he-gave-money-to-republicans-too-2000572852">online Thursday,</a> appeared to be a transparent ploy to get media attention with the goal of ultimately scoring a pardon from President Donald Trump. But it sounds like SBF is now paying a price for the interview. The former billionaire has reportedly been tossed into solitary confinement because the interview wasn’t approved by the U.S. Bureau of Prisons, according to a new report from the New York Times.</p> <p>According to <a href="https://www.nytimes.com/2025/03/07/technology/sam-bankman-fried-pardon-trump.html">the Times</a>, the Bureau of Prisons has strict rules about how interviews are conducted with inmates, and the federal agency confirmed to the newspaper that it did not give permission for the interview with Carlson to go forward. We don’t know when the interview actually took place, though clues suggest it was Wednesday, the day before it was published online to social media platforms like Rumble and X. SBF is currently being held at the Metropolitan Detention Center in Brooklyn.</p> <p>It’s also not clear what kind of equipment was used to allow SBF and Carlson to communicate. It’s entirely possible SBF simply used a smuggled smartphone to talk with Carlson, and while that does seem like the most straightforward way to accomplish an interview like this, that’s purely speculative.&nbsp; SBF suggested in his chat with Carlson that he was really missing having high-tech devices at his disposal, though the topic only came up when the former Fox News host asked if the crypto executive was previously on stimulants before he entered prison. SBF blamed his erratic appearance in old interviews on being distracted by tech devices. Carlson took the opportunity to say that tech wasn’t healthy.</p> <p>The new report from the New York Times seems to confirm what anyone with a little bit of common sense assumed when Carlson’s interview dropped: SBF, who’s currently serving a 25-year sentence for fraud after his crypto company FTX collapsed in 2022, is angling for a pardon from President Trump.</p> <p>Bankman-Fried’s parents, Joe Bankman and Barbara Fried, are two law professors at Stanford and are reportedly consulting with Kory Langhofer, an Arizona lawyer who previously worked on Trump’s presidential campaigns in 2016 and 2020, according to the Times. Langhofer would presumably have deep connections in Trump World, but the newspaper reports they haven’t had direct contact with Trump. At least, not yet.</p>

 <p>But it seems like it could be an uphill climb for SBF and his family to get a pardon from Trump. The Times says the effort “does not appear to have gained traction,” and it’s easy to guess that SBF’s old associations with high-profile Democrats may be hurting his chances. However, SBF himself admitted once he was in jail that he was also secretly donating to Republicans before the implosion of FTX.</p> <p>SBF said in the Thursday episode of Carlson’s show that he doesn’t believe Democrats “saved” him while being prosecuted during the Joe Biden years because they knew he was giving to Republicans as well. Carlson kept acting throughout the interview as though it’s just normal and reasonable for wealthy people who donate to politicians to expect corrupt favors from those same people in their time of need. But SBF didn’t really take the bait, saying that it would have been “inappropriate” to ask for help.</p>

 <p>Trump recently <a href="https://gizmodo.com/trump-pardons-silk-road-founder-ross-ulbricht-2000553405">pardoned Ross Ulbricht</a>, the Silk Road founder convicted in 2015 who was serving a 40-year sentence for money laundering, among a host of other charges related to the darknet site. Ulbricht’s pardon was actually a campaign promise made by Trump in the lead up to the election, largely seen as a favor to the crypto community, which considers Ulbricht a hero.</p> <p>Bankman-Fried never explicitly asked for a pardon from Trump during his interview either, and it seems pretty clear at this point that no matter how desperate he is to get out of prison, he’s going to let things happen behind the scenes rather than go begging. But who knows what might happen in the future. SBF turned 33 on Thursday and has only served a couple of years of a 25-year sentence.</p>
                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Undocumented backdoor found in Bluetooth chip used by a billion devices (242 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/undocumented-backdoor-found-in-bluetooth-chip-used-by-a-billion-devices/</link>
            <guid>43301369</guid>
            <pubDate>Sat, 08 Mar 2025 16:30:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/undocumented-backdoor-found-in-bluetooth-chip-used-by-a-billion-devices/">https://www.bleepingcomputer.com/news/security/undocumented-backdoor-found-in-bluetooth-chip-used-by-a-billion-devices/</a>, See on <a href="https://news.ycombinator.com/item?id=43301369">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="ESP32" height="900" src="https://www.bleepstatic.com/content/hl-images/2025/03/07/esp32.jpg" width="1600"></p>

<p>The ubiquitous ESP32 microchip made by Chinese manufacturer Espressif and used by over 1 billion units as of 2023 contains an undocumented backdoor that could be leveraged for attacks.</p>

<p>The undocumented commands allow spoofing of trusted devices, unauthorized data access, pivoting to other devices on the network, and potentially establishing long-term persistence.</p>

<p>This was discovered by Spanish researchers Miguel Tarascó Acuña and Antonio Vázquez Blanco of Tarlogic Security, who <a href="https://www.documentcloud.org/documents/25554812-2025-rootedcon-bluetoothtools/" target="_blank" rel="nofollow noopener">presented</a> their findings yesterday at <a href="https://reg.rootedcon.com/cfp/schedule/talk/5" target="_blank" rel="nofollow noopener">RootedCON</a> in Madrid.</p>

<p>The researchers warned that ESP32 is one of the world's most widely used chips for Wi-Fi + Bluetooth connectivity in IoT (Internet of Things) devices, so the risk of any backdoor in them is significant.</p>

<div>
<figure><img alt="Slide from the RootedCON presentation" height="600" src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/presentation.jpeg" width="800"><figcaption><strong>Slide from the RootedCON presentation</strong><br><em>Source: Tarlogic</em></figcaption></figure></div>

<h2>Discovering a backdoor in ESP32</h2>

<p>In their RootedCON presentation, the Tarlogic researchers explained that interest in Bluetooth security research has waned but not because the protocol or its implementation has become more secure.</p>

<p>Instead, most attacks presented last year didn't have working tools, didn't work with generic hardware, and used outdated/unmaintained tools largely incompatible with modern systems.</p>

<p>Tarlogic developed a new C-based USB Bluetooth driver that is hardware-independent and cross-platform, allowing direct access to the hardware without relying on OS-specific APIs.</p>

<p>Armed with this new tool, which enables raw access to Bluetooth traffic, Targolic discovered hidden vendor-specific commands (Opcode 0x3F) in the ESP32 Bluetooth firmware that allow low-level control over Bluetooth functions.</p>

<div>
<figure><img alt="ESP32 memory map" height="534" src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/diagram.jpg" width="751"><figcaption><strong>ESP32 memory map</strong><br><em>Source: Tarlogic</em></figcaption></figure></div>

<p>In total, they found 29 undocumented commands, collectively characterized as a "backdoor," that could be used for memory manipulation (read/write RAM and Flash), MAC address spoofing (device impersonation), and LMP/LLCP packet injection.</p>

<p>Espressif has not publicly documented these commands, so either they weren't meant to be accessible, or they were left in by mistake.</p>

<div>
<figure><img alt="Script that issues HCI commands" height="408" width="821" data-src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/demo.jpg" src="https://www.bleepstatic.com/images/news/u/1220909/2025/March/demo.jpg"><figcaption><strong>Script that issues HCI commands</strong><br><em>Source: Tarlogic</em></figcaption></figure></div>

<p>The risks arising from these commands include&nbsp;malicious implementations on the OEM level and supply chain attacks.</p>

<p>Depending on how Bluetooth stacks handle HCI commands on the device, remote exploitation of the backdoor might be possible via malicious firmware or rogue Bluetooth connections.</p>

<p>This is especially the case if an attacker already has root access, planted malware, or pushed a malicious update on the device that opens up low-level access.</p>

<p>In general, though, physical access to the device's USB or UART interface would be far riskier and a more realistic attack scenario.</p>

<p>"In a context where you can compromise an IOT device with as ESP32 you will be able to hide an APT inside the ESP memory and perform Bluetooth (or Wi-Fi) attacks against other devices, while controlling the device over Wi-Fi/Bluetooth," explained the researchers to BleepingComputer.</p>

<p>"Our findings would allow to fully take control over the ESP32 chips and to gain persistence in the chip via commands that allow for RAM and Flash modification."</p>

<p>"Also, with persistence in the chip, it may be possible to spread to other devices because the ESP32 allows for the execution of advanced Bluetooth attacks."</p>

<p>BleepingComputer has contacted Espressif for a statement on the researchers' findings, but a comment wasn't immediately available.</p>

	   
           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The program is the database is the interface (102 pts)]]></title>
            <link>https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/</link>
            <guid>43300528</guid>
            <pubDate>Sat, 08 Mar 2025 14:31:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/">https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/</a>, See on <a href="https://news.ycombinator.com/item?id=43300528">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <h2 id="draft">!!! DRAFT !!!</h2>
<p>I do my accounts each year with a simple script. Something like this:</p>
<pre data-lang="clj"><code data-lang="clj"><span>(ns </span><span>accounts
</span><span>  (</span><span>:require 
</span><span>    [clojure.string </span><span>:as </span><span>str]
</span><span>    [clojure.pprint </span><span>:as </span><span>pp]))
</span><span>
</span><span>;; converted from statement.csv
</span><span>(def </span><span>txs
</span><span>  [{</span><span>:date #inst "2022-05-13T11:01:56.532-00:00"
</span><span>    </span><span>:amount -3.30
</span><span>    </span><span>:text </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-12T10:41:56.843-00:00"
</span><span>    </span><span>:amount -3.30
</span><span>    </span><span>:text </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-12T00:01:03.264-00:00"
</span><span>    </span><span>:amount -72.79
</span><span>    </span><span>:text </span><span>"Card transaction of 72.79 CAD issued by Amazon.ca AMAZON.CA"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-10T10:33:04.011-00:00"
</span><span>    </span><span>:amount -20.00
</span><span>    </span><span>:text </span><span>"e-Transfer to: John Smith"</span><span>}
</span><span>   {</span><span>:date #inst "2022-05-11T17:12:43.098-00:00"
</span><span>    </span><span>:amount -90.00
</span><span>    </span><span>:text </span><span>"Card transaction of 90.00 CAD issued by Range Physiotherapy VANCOUVER"</span><span>}])
</span><span>
</span><span>(def </span><span>date-&gt;tag
</span><span>  {</span><span>#inst "2022-05-12T00:01:03.264-00:00" :things</span><span>})
</span><span>
</span><span>(def </span><span>text-&gt;tag 
</span><span>  {</span><span>"Coffee" </span><span>:eating-out
</span><span>   </span><span>"Range Physio" </span><span>:medical</span><span>})
</span><span>
</span><span>(defn </span><span>tx-&gt;tag </span><span>[tx]
</span><span>  (or
</span><span>    (date-&gt;tag (</span><span>:date </span><span>tx))
</span><span>    (first 
</span><span>      (for [[text tag] text-&gt;tag
</span><span>            </span><span>:when </span><span>(str/includes? (</span><span>:text </span><span>tx) text)]
</span><span>        tag))))
</span><span>
</span><span>(def </span><span>txs-with-tags
</span><span>  (vec 
</span><span>    (for [tx txs]
</span><span>      (assoc tx </span><span>:tag </span><span>(tx-&gt;tag tx)))))
</span><span>
</span><span>(def </span><span>total-per-tag
</span><span>  (reduce 
</span><span>    (fn [totals tx]
</span><span>      (update-in totals [(</span><span>:tag </span><span>tx)] #(+ (</span><span>:amount </span><span>tx) (or % </span><span>0</span><span>))))
</span><span>    {}
</span><span>    txs-with-tags))
</span><span>
</span><span>(def </span><span>untagged 
</span><span>  (vec
</span><span>    (for [tx txs-with-tags
</span><span>         </span><span>:when </span><span>(nil? (</span><span>:tag </span><span>tx))]
</span><span>      tx)))
</span><span>
</span><span>(pp/pprint 
</span><span>  [[</span><span>:untagged </span><span>untagged]
</span><span>   [</span><span>:total-per-tag </span><span>total-per-tag]])
</span></code></pre>
<p>There are many things about this which are nice.</p>
<ul>
<li>It's just a single file - easy to backup and version control.</li>
<li>It's composable - I can easily write code to answer unexpected questions (eg how much did I spend on currency conversions this year) or use the computed data in other calculations (eg runway projections).</li>
<li>It's easy - I just pretty-printed the data-structures I was already using instead of having to build a UI.</li>
</ul>
<p>But the workflow isn't always great. When I run the code above, I see:</p>
<pre data-lang="clj"><code data-lang="clj"><span>&gt; clj accounts.clj
</span><span>[[</span><span>:untagged
</span><span>  [{</span><span>:date #inst "2022-05-10T10:33:04.011-00:00"</span><span>,
</span><span>    </span><span>:amount -20.0</span><span>,
</span><span>    </span><span>:text </span><span>"e-Transfer to: John Smith"</span><span>,
</span><span>    </span><span>:tag nil</span><span>}]]
</span><span> [</span><span>:total-per-tag
</span><span>  {</span><span>:eating-out -3.3</span><span>, </span><span>:things -72.79</span><span>, </span><span>:medical -90.0</span><span>, </span><span>nil -20.0</span><span>}]]
</span></code></pre>
<p>That transfer to John Smith isn't covered by any of the tagging rules. So I select the date, switch to the editor window and paste the date into the date-&gt;tag definition:</p>
<pre data-lang="clj"><code data-lang="clj"><span>(def </span><span>date-&gt;tag
</span><span>  {</span><span>#inst "2022-05-12T00:01:03.264-00:00" :things
</span><span>   </span><span>#inst "2022-05-10T10:33:04.011-00:00" :eating-out</span><span>})
</span></code></pre>
<p>Now I see:</p>
<pre data-lang="clj"><code data-lang="clj"><span>&gt; clj accounts.clj
</span><span>[[</span><span>:untagged </span><span>[]]
</span><span> [</span><span>:total-per-tag
</span><span>  {</span><span>:eating-out -23.3</span><span>, </span><span>:things -72.79</span><span>, </span><span>:medical -90.0</span><span>}]]
</span></code></pre>
<p>Multiply this by a thousand transactions and it becomes tedious.</p>
<p>Pretty-printing also makes it difficult to decide the amount of detail I should print. Sometimes I want to see which transactions contribute to each tag total. But if I always print them all then it's hard to see the totals themselves without a lot of scrolling.</p>
<p>It's also hard to share this workflow with someone non-technical. I have to setup and maintain the correct environment on their machine, teach them how to use a text editor to change the tagging rules, how to interpret syntax errors, how to use git to share changes etc.</p>
<hr>
<p>I could solve these kinds of problems by writing a web app and storing <code>txs</code>, <code>date-&gt;tag</code> and <code>text-&gt;tag</code> in a database.</p>
<p>Then I could put controls on the transaction itself that allow changing the tag in place. And I could add an expandable section next to each total, so that it's easy to see the transactions for that tag when I want to but they don't take up space by default.</p>
<p>Plus sharing becomes trivial - everyone has a web browser.</p>
<p>But this is a big leap in effort:</p>
<ul>
<li>A database introduces a different data model - I have to translate between database data-types and my programming languages native data-types.</li>
<li>A database introduces a different language, or at least a new api that differs from the way I access native data-structures.</li>
<li>Rather than using a familiar text editor to read and change data, I can only access it via some query language or api.</li>
<li>I have to shuffle data back and forth between database and program at the correct times.</li>
<li>It isn't easy to version control the contents of the database.</li>
<li>Before I can add interactive elements, I have to map my existing data-structures to gui elements (eg to html and css) instead of just printing them.</li>
<li>I have to add an extra layer of state management to manage the state of the gui itself.</li>
<li>All of this work has to be repeated whenever I have a new question I want to answer.</li>
</ul>
<p>None of this is insurmountable, but it's definitely much more work than the original script.</p>
<p>So a simple script is low-effort but produces a low-quality experience. And a custom app can produce a high-quality experience but is high-effort.</p>
<hr>
<p>So I made a thing.</p>
<p>It is very hacky and easy to break. But it will hang together just long enough to convey the idea.</p>
<p>It's kind of like a notebook. There are cells where you can write code and the resulting values will be nicely rendered:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>;; converted from statement.csv
</span><span>(def txs
</span><span>  [{:date #inst "2022-05-13T11:01:56.532-00:00"
</span><span>    :amount -3.30
</span><span>    :text "Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"}
</span><span>   {:date #inst "2022-05-12T10:41:56.843-00:00"
</span><span>    :amount -3.30
</span><span>    :text "Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"}
</span><span>   {:date #inst "2022-05-12T00:01:03.264-00:00"
</span><span>    :amount -72.79
</span><span>    :text "Card transaction of 72.79 CAD issued by Amazon.ca AMAZON.CA"}
</span><span>   {:date #inst "2022-05-10T10:33:04.011-00:00"
</span><span>    :amount -20.00
</span><span>    :text "e-Transfer to: John Smith"}
</span><span>   {:date #inst "2022-05-11T17:12:43.098-00:00"
</span><span>    :amount -90.00
</span><span>    :text "Card transaction of 90.00 CAD issued by Range Physiotherapy VANCOUVER"}])
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs date-&gt;tag
</span><span>  {#inst "2022-05-12T00:01:03.264-00:00" :things})
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs keyword-&gt;tag
</span><span>  {"Coffee" :eating-out
</span><span>   "Range Physio" :medical})
</span></code></pre>
<p>Funtions render a little differently.</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn text-&gt;tag [text]
</span><span>  (first
</span><span>    (for [[keyword tag] keyword-&gt;tag
</span><span>          :when (clojure.string/includes? text keyword)]
</span><span>      tag)))
</span></code></pre>
<p>If you type <code>"Joe's Coffee Hut"</code> (including the <code>"</code>!) into the textbox above and hit the <code>text-&gt;tag</code> button, you'll see the result of running the <code>text-&gt;tag</code> function on that input.</p>
<p>Functions aren't limited to just returning values though. They can modify the values stored in other cells:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def txs-with-tags
</span><span>  (vec 
</span><span>    (for [tx txs]
</span><span>      (assoc tx 
</span><span>        :tag (or
</span><span>               (date-&gt;tag (:date tx))
</span><span>               (text-&gt;tag (:text tx)))
</span><span>        :actions [(fn ignore []
</span><span>                    (edit! 'date-&gt;tag assoc (:date tx) :ignore))
</span><span>                  (fn tag [tag] 
</span><span>                    (edit! 'date-&gt;tag assoc (:date tx) tag))]))))
</span></code></pre>
<p>If you type <code>:eating-out</code> into the one of the textboxes above and then hit the <code>tag</code> button, it will change the <code>date-&gt;tag</code> cell to contain an entry for the date of that transaction with the tag <code>:eating-out</code>.</p>
<p>And then any downstream cells will update, so you'll see the tag for that transaction change to <code>:eating-out</code>.</p>
<p>These actions are just values so they can be passed around like any other value. For example, if I make a list of untagged transactions then I'll still have access to the same actions:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def untagged
</span><span>  (vec
</span><span>    (for [tx txs-with-tags
</span><span>         :when (nil? (:tag tx))]
</span><span>      tx)))
</span></code></pre>
<p>We can also attach metadata to values to control how they render:</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def hidden-vec
</span><span>  (with-meta
</span><span>    [1 2 3]
</span><span>    {:preimp/hidden true}))
</span></code></pre>
<p>If you click on the <code>+</code> above it will reveal the contents of the vec. This is useful for controlling the default level of detail.</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn hidden [v]
</span><span>  (with-meta v {:preimp/hidden true}))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def total-per-tag
</span><span>  (reduce 
</span><span>    (fn [totals tx]
</span><span>      (if (= :ignore (:tag tx))
</span><span>        totals
</span><span>        (update-in totals [(:tag tx)] 
</span><span>          (fn [total+txs]
</span><span>            (let [[total txs] (or total+txs [0 (hidden [])])]
</span><span>              [(+ total (:amount tx))
</span><span>               (conj txs (update-in tx [:actions] hidden))])))))
</span><span>    {}
</span><span>    txs-with-tags))
</span></code></pre>
<p>You can click on a <code>+</code> above to reveal the transactions for that tag.</p>
<hr>
<p>The demo on this page is ephemeral - you could do something similar in many notebook environments using mutable data-structures.</p>
<p>But the <a href="https://github.com/jamii/preimp">preimp repo</a> contains a server which persists the entire history of the notebook to disk, and also syncs changes between different clients to allow (coarse-grained) collaborative editing.</p>
<video controls="">
  <source src="https://www.scattered-thoughts.net/writing/the-program-is-the-database-is-the-interface/demo.mp4" type="video/mp4">
</video>
<p>The server also allows reading and writing cell values over http. Here's the script that I use to upload my bank statements:</p>
<pre data-lang="clj"><code data-lang="clj"><span>(ns </span><span>wise
</span><span>  (</span><span>:require </span><span>[clj-http.client </span><span>:as </span><span>client]
</span><span>            [clojure.data.json </span><span>:as </span><span>json]))
</span><span>
</span><span>(def </span><span>endpoints </span><span>{
</span><span>  </span><span>;; FILL ME IN
</span><span>})
</span><span>
</span><span>(defn </span><span>api-get </span><span>[user path]
</span><span>  (let [domain (get-in endpoints [user </span><span>:wise-domain</span><span>])
</span><span>        url (str domain </span><span>"/" </span><span>path)
</span><span>        response (client/get url {</span><span>:headers </span><span>{</span><span>"Authorization" </span><span>(str </span><span>"Bearer " </span><span>(get-in endpoints [user </span><span>:wise-token</span><span>]))}})]
</span><span>    (assert (= </span><span>200 </span><span>(</span><span>:status </span><span>response)))
</span><span>    (json/read-str (</span><span>:body </span><span>response))))
</span><span>
</span><span>(def </span><span>now </span><span>(java.time.Instant/now))
</span><span>
</span><span>(defn </span><span>get-transactions </span><span>[user]
</span><span>  (into []
</span><span>        (for [profile (api-get user </span><span>"v2/profiles"</span><span>)
</span><span>              </span><span>:let </span><span>[profile-id (get profile </span><span>"id"</span><span>)]
</span><span>              balance (api-get user (str </span><span>"v4/profiles/" </span><span>profile-id </span><span>"/balances?types=STANDARD"</span><span>))
</span><span>              </span><span>:let </span><span>[balance-id (get balance </span><span>"id"</span><span>)
</span><span>                    statement (api-get user (str </span><span>"/v1/profiles/" </span><span>profile-id </span><span>"/balance-statements/" </span><span>balance-id </span><span>"/statement.json?intervalStart=2022-01-01T00:00:00.000Z&amp;intervalEnd=" </span><span>now </span><span>"&amp;type=COMPACT"</span><span>))]
</span><span>              transaction (get statement </span><span>"transactions"</span><span>)]
</span><span>          transaction)))
</span><span>          
</span><span>(defn </span><span>update-preimp </span><span>[user]
</span><span>  (let [transactions (get-transactions user)
</span><span>        cell-name (symbol (str (name user) </span><span>"-wise-transactions"</span><span>))
</span><span>        cell-value (pr-str </span><span>`</span><span>(</span><span>~'</span><span>defs </span><span>~</span><span>cell-name </span><span>~</span><span>transactions))
</span><span>        body (json/write-str
</span><span>              {</span><span>:cell-id </span><span>(get-in endpoints [user </span><span>:cell-id</span><span>])
</span><span>               </span><span>:value </span><span>cell-value})]
</span><span>    (client/put
</span><span>     (get-in endpoints [user </span><span>:preimp-domain</span><span>])
</span><span>     (merge (get-in endpoints [user </span><span>:preimp-headers</span><span>]) {</span><span>:body </span><span>body}))))
</span><span>
</span><span>(defn </span><span>update-preimp-dev </span><span>[_]
</span><span>  (update-preimp </span><span>:sandbox</span><span>))
</span><span>
</span><span>(defn </span><span>update-preimp-prod </span><span>[_]
</span><span>  (update-preimp </span><span>:jamie</span><span>)
</span><span>  (update-preimp </span><span>:cynthia</span><span>))
</span></code></pre>
<p>Finally, you can export a preimp notebook to produce a perfectly valid clojurescript program.</p>

<p>You can run this program in the repl:</p>
<pre data-lang="clj"><code data-lang="clj"><span>&gt; clj -M -m cljs.main -i ./exported.cljs --repl --repl-env node 
</span><span>
</span><span>preimp.exported=&gt; (require </span><span>'</span><span>clojure.pprint)
</span><span>nil
</span><span>
</span><span>preimp.exported=&gt; (clojure.pprint/pprint txs-with-tags)
</span><span>[{</span><span>:date #inst "2022-05-13T11:01:56.532-00:00"</span><span>,
</span><span>  </span><span>:amount -3.3</span><span>,
</span><span>  </span><span>:text
</span><span>  </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>,
</span><span>  </span><span>:tag :coffee</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-12T10:41:56.843-00:00"</span><span>,
</span><span>  </span><span>:amount -3.3</span><span>,
</span><span>  </span><span>:text
</span><span>  </span><span>"Card transaction of 3.30 CAD issued by Milano Coffee Roasters VANCOUVER"</span><span>,
</span><span>  </span><span>:tag :coffee</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-12T00:01:03.264-00:00"</span><span>,
</span><span>  </span><span>:amount -72.79</span><span>,
</span><span>  </span><span>:text </span><span>"Card transaction of 72.79 CAD issued by Amazon.ca AMAZON.CA"</span><span>,
</span><span>  </span><span>:tag :things</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-10T10:33:04.011-00:00"</span><span>,
</span><span>  </span><span>:amount -20</span><span>,
</span><span>  </span><span>:text </span><span>"e-Transfer to: John Smith"</span><span>,
</span><span>  </span><span>:tag :eating-out</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}
</span><span> {</span><span>:date #inst "2022-05-11T17:12:43.098-00:00"</span><span>,
</span><span>  </span><span>:amount -90</span><span>,
</span><span>  </span><span>:text
</span><span>  </span><span>"Card transaction of 90.00 CAD issued by Range Physiotherapy VANCOUVER"</span><span>,
</span><span>  </span><span>:tag :medical</span><span>,
</span><span>  </span><span>:actions
</span><span>  [</span><span>#object</span><span>[preimp$exported$iter__897_$_ignore]
</span><span>   </span><span>#object</span><span>[preimp$exported$iter__897_$_tag]]}]
</span><span>
</span><span>nil
</span></code></pre>
<hr>
<p>This tiny extension to the notebook model allows writing simple ugly crud apps with very little effort. You simply provide the logic and preimp gives you storage, sharing and UI for free. But the result is not an opaque image, nor is it tied to the preimp environment - you can export everything into a regular script and run it in the repl.</p>
<p>TODO rest of this section</p>
<p>required:
rich data model, which can be roundtripped through text
some way of attaching metadata to values, to control their rendering without interfering with execution in the repl</p>
<p>needed:
no declaration order
no mutable environment
no side-effects (other than edit!)
integrity constraints
perf (compiler latency) (thoughput only needs to be better than spreadsheet)</p>
<p>extensions:
much more ui options
selection (+ actions on the side)
dropdowns
understand types / destructuring
render values as copyable text (cf ?)
undo/vc (have whole history in db)
live repl, sandboxing
distribution - single binary, single-file db, optional server (like fossil)</p>
<p>research:
finer-grained collaboration (what data model?)
bidirectional editing / provenance</p>
<hr>
<p>We have to do the other demo too. You know the one.</p>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs next-id 2)
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs todos 
</span><span>  {0 {:text "make a cool demo" :status :done}
</span><span>   1 {:text "step 2: ???" :status :todo}})
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn new-todo [text] 
</span><span>  (edit! 'todos assoc next-id {:text text :status :todo})
</span><span>  (edit! 'next-id inc))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn named [name fn]
</span><span>  (with-meta fn {:preimp/named name}))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defn status-toggle [id]
</span><span>  (let [status (get-in todos [id :status])
</span><span>        other-status (case status
</span><span>                       :done :todo
</span><span>                       :todo :done)]
</span><span>    (named (name status)
</span><span>      (fn [] (edit! 'todos assoc-in [id :status] other-status)))))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(defs filter :all)
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def toggle-filter
</span><span>  (named (str "viewing " (name filter))
</span><span>    (fn [] (edit! 'filter #(case filter 
</span><span>                             :all :todo
</span><span>                             :todo :done
</span><span>                             :done :all)))))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def filtered-todos
</span><span>  (vec
</span><span>    (for [[id todo] todos
</span><span>          :when (#{:all (:status todo)} filter)]
</span><span>      [(:text todo)
</span><span>       (hidden [(fn set-text [text]
</span><span>                  (edit! 'todos assoc-in [:id :text] text))
</span><span>                (status-toggle id)
</span><span>                (fn delete []
</span><span>                  (edit! 'todos dissoc id))])])))
</span></code></pre>
<pre data-lang="preimp"><code data-lang="preimp"><span>(def app
</span><span>  (vec
</span><span>    (apply list
</span><span>      new-todo
</span><span>      toggle-filter
</span><span>      filtered-todos)))
</span></code></pre>



<hr>
<p>TODO
spreadsheets don't have state problem, but not interactive (at least in same way)</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discworld Rules (128 pts)]]></title>
            <link>https://contraptions.venkateshrao.com/p/discworld-rules</link>
            <guid>43299815</guid>
            <pubDate>Sat, 08 Mar 2025 12:48:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://contraptions.venkateshrao.com/p/discworld-rules">https://contraptions.venkateshrao.com/p/discworld-rules</a>, See on <a href="https://news.ycombinator.com/item?id=43299815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em><span>The </span><a href="https://contraptions.venkateshrao.com/p/contraptions-book-club" rel="">Contraptions Book club</a><span> March pick is </span><strong>Giordano Bruno and the Hermetic Tradition by Frances Yates</strong><span>. </span><a href="https://open.substack.com/chat/posts/09f4609d-7910-455b-b6b8-fb55a7bb80ee" rel="">Chat thread</a><span> here. We will discuss this the week of March 24th.</span></em></p><p><em><span>I’ll be co-hosting an online salon </span><strong><a href="https://lu.ma/5qh4qac2" rel="">Silicon Archipelago: A Salon On Open Distributed Southeast Asian Tech Futures</a><span> </span></strong><span>on Friday, March 14 (Southeast Asia time). This is a prequel for an in-person workshop on the same themes in Bangkok in late April (</span><a href="https://www.cmkl.ac.th/event/khlongs-and-subaks-open-distributed-ai-x-blockchain-protocols-in-southeast-asia" rel="">apply here</a><span> if interested — free but limited capacity, with some regional travel support available). I would appreciate any forwards to interesting techies, tech policy people, and tech culture people from the region.</span></em></p><p><em>The Lord of the Rings </em><span>is a great story, but I have to say, I’ve never understood the strange hold it seems to have on the imagination of a particular breed of technologists. </span></p><p><span>As a </span><em>story</em><span> it’s great. It is pure fantasy of course (in the </span><a href="https://protocolized.summerofprotocols.com/p/strange-new-rules" rel="">Chiang’s Law</a><span> sense of being about special people rather than strange rules), full of Chosen Ones doing Great Man (or Great Hobbit) things. As an extended allegory for society and technology it absolutely sucks and is also ludicrously wrong-headed. Humorless Chosen people presiding grimly over a world in terminal decline, fighting Dark Lords, playing out decline-and-fall scripts to which there is no alternative, no Plan B. </span></p><p>This is no way for a high-agency technological species to live, and thankfully it doesn’t have to be.</p><p><span>I mean, I get why politicians and economists might identify with the story. They enjoy little to no direct technological agency, harbor ridiculous Chosen One conceits, and operate in domains — political narratives and the dismal pseudoscience of economics —  that are natural intellectual monopolies or oligopolies. Domains that allow fantasies to be memed into existence (the technical term is </span><a href="https://www.full-stop.net/2020/10/21/features/essays/macon-holt/hyperstitional-theory-fiction/" rel="">hyperstitional theory-fictions</a><span>) for a while before they come crashing down to earth in flames, demonstrating yet again that no, you do not in fact get to create your own reality; that “reality is that which, when you stop believing in it, does not go away.”</span></p><p><span>There is a contrarian reading of </span><em>The Lord of the Rings </em><span>that argues that Sauron and Mordor are in fact the good guys, and represent technological progress, etc. But this is throwing good </span><s>money</s><span> narrativium after bad. Flipping the valence of a Chosen One story doesn’t make it any better. It’s still a Chosen One story with reversed roles. </span></p><p>No, you have to tell different sorts of stories altogether.</p><p><span>Such stories have, in fact, been told. They are Terry Pratchett’s </span><em>Discworld </em><span>stories. This post is an extended argument that as a lens for thinking about the world, </span><em>The</em><span> </span><em>Lord of the Rings, </em><span>is a work that you should “not set aside lightly, but throw across the room with great force,” and that in place of Middle Earth, you should install Terry Pratchett’s Discworld.</span></p><p><span>I won’t get into whether Discworld is better or worse as a fictional universe than Middle Earth. That is a matter of taste and which elements of craft you admire. But </span><em>as an allegory for technology and society, </em><span>Discworld is so radically, vastly superior, and LOTR is so terminally bad, it is not even a contest.</span></p><p><span>If you’re an actual, serious technologist, </span><em>Discworld </em><span>is where you should look for clues about how the world works, how it evolves in response to technological forces, and how humans should engage with those forces. It is catnip for actual technological curiosity, as opposed to validation of incuriously instrumental approaches to technology. If on the other hand, you’re really just a fantasist larping Chosen One stories bolstered by specious Straussian conceits, trying to meme your hyperstitional theory fictions into existence for a while, looting the commons with private-equity extraction engines until you get your Girardian comeuppance — by all means go for it. Though Margaret Thatcher and Neoliberalism are both dead, There Is No Alternative (TINA) — for </span><em>you. </em></p><p>The rest of humanity, thankfully, has more imaginative and generative models of reality to draw on. </p><p><span>Now, for those of you who haven’t read the </span><em>Discworld</em><span> series, it is basically the anti-</span><em>LOTR. </em><span>For starters, even though it is set in a pseudo-historical time rather than the future, and features all the common tropes of  fantasy, all that is in purely ironic mode.  </span><em>Discworld </em><span>is in fact the hardest of hard science fiction universes you can find. Entirely about strange rules rather than special people. </span></p><p>You just have to learn to look past the wizards, dragons, elves, and such. There is even a “Science of Discworld” meta-series to help with that.</p><p>The irony is not subtle. It’s in-your-face. For instance, the core world-building premise is that of a literal “flat earth” disc-shaped planet, resting on the back of four elephants that stand on the back of a giant turtle swimming through space. But this parody of the cosmologies of antiquity is put through its paces with deadpan faux-scientific earnestness. There’s an entire novel about how there was once a fifth elephant, whose fossilized remains are the basis of the fossil fuel industry of Discworld.</p><p>And it only gets sillier from there.</p><p><span>And the sillier it gets, the </span><em>better </em><span>it seems to model our own world (known as </span><em>Roundworld </em><span>in the Discworld cosmogony, a place Discworlders can and do travel to, generally causing mayhem). The wilder a Discworld plot, the more you learn about how technology, society, and progress in Roundworld actually work. </span></p><p>I have a rule-of-thumb: The more seriously you take Discworld, the smarter you get about Roundworld.</p><p>The silliness is a feature, not a bug. Our universe is a vast, crazy place, and we haven’t even begun to scratch the surface of the endless weirdness it harbors. As Douglas Adams noted, “If life is going to exist in a Universe of this size, then the one thing it cannot afford to have is a sense of proportion.” </p><p>Discworld is about curing yourself of the allure of a “sense of proportion.” There is no surer of way of becoming detached from reality and addicted to some notion of manufactured normalcy.</p><p><span>It is notable that one of the favorite rhetorical tricks of self-styled Special People is to point to something in incredulity and pretend to be aghast at how weird it is; how against “common sense” and “reasonable” and “first principles” understandings of the world. Those words and phrases are always suspicious, and </span><em>extra</em><span> suspicious — suspicious-squared as Pratchett might have said — when used by Chosen One types.</span></p><p><span>The </span><em>Lord of the Rings </em><span>on the other hand — the more seriously you take Middle Earth, the dumber you get about Roundworld. </span></p><p>Revealingly, Roundworld isn’t even modeled in the Middle Earth cosmology, except via vaguely racist and lazy allusions (In Middle Earth, I’m presumably one of those turbaned men-from-the-east riding an Oliphaunt and uncritically allied with Sauron). </p><p>If you double down on the LOTR brainrot, and add things like Ayn Rand and Rene Girard to the soup, you get a profoundly stupid vision of the world that it takes real genius to buy into. Which is what, as it happens, a lot of real geniuses (and I don’t mean this snarkily — Peter Thiel is a legit genius who happens to have bought into a really stupid vision of the world) have in fact done as of 2025, as they try to meme a revanchist Great Power world back into existence.</p><p>I’ve thought about this a lot in the last few months, and I’ve concluded the whole program is in fact exactly as stupid as it sounds, and will fail in profoundly stupid ways, doing a lot of irreversible damage (Brexit was a small scale model of what’s in store for us here in the US). </p><p>But to some extent I’ve made my peace with what’s coming, and have no desire to convince you that this is where things are headed. If you’ve bought into that, have fun being miserable in Middle Earth.</p><p>Instead, I want to sketch out for you how you can truly learn to think in pluralist there-are-many-alternatives ways.</p><p>The place to start is with the rules of Discworld.</p><p><span>If you haven’t read any Discworld novels, here is a map with a suggested reading order. I got it </span><a href="https://en.wikipedia.org/wiki/Discworld_(world)" rel="">from Wikipedia</a><span>, and literally checked off the books as I read them all a few years ago (except the Tiffany Aching ones). I recommend you do that too.</span></p><p><span>I read one Pratchett novel (</span><em>Thief of Time </em><span>I think) in college, but I’m glad I didn’t properly get into it till my mid-forties. These are books you cannot really appreciate if you’re too young. I read through the lot around 2017-19, during the first Trump admin, when I was in my early forties.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg" width="1456" height="1532" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1532,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:814386,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://contraptions.venkateshrao.com/i/158124604?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1078306-3ff2-456d-bc55-b1ef164ebc73_1698x1787.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Pratchett believed you should start with </span><em>Sourcery, </em><span>and he is right, not just because it is early in the in-world chronology of one of the main sequences, but because it forcefully establishes what is  perhaps the central dogma of Discworld:</span></p><p><em><strong>People who think they are Special and Chosen are dangerous and bad for the world.</strong></em></p><p><span>The story revolves around Discworld’s satirical version of the Chosen One plot arc. Here is the premise according to the </span><a href="https://en.wikipedia.org/wiki/Sourcery" rel="">Wikipedia entry</a><span>:</span></p><blockquote><p><span>On the Discworld, "sourcerers"—wizards who are sources of magic, and thus immensely more powerful than normal wizards—were the main cause of the Great Mage Wars that left areas of the Disc uninhabitable. As eight is a powerful magical number on Discworld, men born as the eighth son of an eighth son are commonly wizards. Since sourcerers are born the eighth son of an eighth son </span><em>of an eighth son</em><span>, they are "wizards squared". To prevent the creation of sourcerers, therefore, wizards are not allowed to marry or have children.</span></p></blockquote><p><span>These “sourcerers” are one species of annoying Chosen Ones in Discworld. In the novel, the prevention mechanisms fail, and a sourcerer is born, and wreaks havoc for a while trying to do dumb Chosen One things until one of the main protagonists of the world, Rincewind, a hapless, mediocre wizard, manages to contain him. With a lot of help of course — the mediocre protagonists of Discworld rarely act alone and never in hero-mode. Most Discworld stories are, to a first approximation, </span><a href="https://www.amazon.com/Carrier-Theory-Fiction-Terra-Ignota/dp/1999675991" rel="">carrier-bag</a><span> stories.</span></p><p>Discworld is essentially a kind place though, so the antagonists are usually just contained and neutralized, and sometimes even redeemed. They’re not vengefully made an example of by protagonists. That’s a Chosen One move. Discworlders are kinder, even if it costs them. That’s a point we’ll say more about.</p><p>The Rincewind stories are one of four major sequences in the Discworld universe. These are:</p><ul><li><p><strong>Unseen University</strong><span>: Revolving around events at Unseen University in Ankh-Morpork, the setting for most stories, where Rincewind is a professor of geography. It is a den of complacent, mediocre, academic wizards who mostly don’t do anything. They rarely actually use magic for anything practical, not because of any lofty ideas of great power requiring great responsibility, but because they are lazy and magic is messy and causes more problems than it solves.  The other residents of Ankh-Morpork agree, and rarely call on them to do anything.</span></p></li><li><p><strong>The City Watch novels</strong><span>, featuring a stubbornly everyman chief of police, </span><a href="https://en.wikipedia.org/wiki/Sam_Vimes" rel="">Sam Vimes</a><span> (based on the historic Robert Peel who founded London’s police force) who in the universe stands for regicidal skepticisms of power and a plodding, quiet integrity that cannot be bought off or stopped. His ancestor killed the last despotic king of Ankh-Morpork, the city-state in which much of the action unfolds. One of Vimes’ lieutenants, the nice but ordinary Carrot, is in fact the True King, but harbors no ambitions of ascending to a throne in a restored monarchy.</span></p></li><li><p><strong>The Witches novels</strong><span>, featuring a milieu of witches in the countryside, with Granny Weatherwax as the no-nonsense elder. Like the wizards of Unseen University, they too don’t really make much actual use of magic, preferring to solve problems through wisdom and skeptical common sense, frequently battling Chosen One ambitions in their own ranks. The hold the wizards of Unseen University in affectionate contempt, as wild theorists doing weird experiments.</span></p></li><li><p><strong>The Death novels</strong><span>, featuring the regular scythe-wielding figure of </span><a href="https://en.wikipedia.org/wiki/Death_(Discworld)" rel="">Death</a><span>, who is really the steward of life itself on Discworld. He works tirelessly to keep life generative, messy, rich, and varied with his curatorial efforts. His primary antagonist is a bureaucracy, the Auditors of Reality, who hate life because it is messy, and would rather have a lifeless universe following predictable and well-behaved laws. </span></p></li></ul><p><span>The Auditors of Reality are particularly interesting. They are the Discworld edition of what I’ve called the Great Bureaucrat archetype elsewhere. Their ideology is something like the Wokism of Discworld, a deadening, stifling, faceless force of intersectional lifelessness. But as Discworld historigraphy correctly theorizes, the antidote to the dangers of Auditors of Reality is not individual Chosen Ones like sourcerers, over-ambitious witches, or kings claiming divine rights, but </span><em>Death </em><span>itself, understood  as a personification of the process of renewal, regeneration, and stewardship of the organic messiness of life.</span></p><p>I like this as acerbic commentary on the longevity fetish and Eternalism of the Tech Right. </p><p>I have no issues with individuals simply making an extreme sport of literally trying to live as long as possible. Bryan Johnson is a friend and occasional client of mine, and Vitalik Buterin, whom I have interactions with through my protocols work, is also a longevity maven. At more regular-people level, friends of this newsletter like Sarah Constantin are into longevity. </p><p><span>I don’t object to any of this, though personally I want no part of it. I think </span><em>thar be ossified Asimovian spacer worlds</em><span>. But if people want that kind of life and arrange their own affairs to try and get there, I have no quarrel with them.</span></p><p><span>What I have a problem with is people trying to live forever </span><em>as part of a Chosen One script </em><span>which involves them trying to carve up all of the world into the dead empires of a dystopian Great Game world run according to a totalizing script.</span></p><p>I prefer a world run by ordinary mortals who have embraced both their ordinariness and mortality.</p><p>While most core Discworld characters are either mediocre anti-heroes or parodied Chosen One antagonists, there is a big supporting cast of colorful characters who are neither, but not NPCs either. </p><p><span>The most important of these is the wise</span><em> (</em><span>but ordinary and mortal) despot who rules the city of Ankh-Morpork, Vetinari (an allusion to the Medicis). Vetinari’s style of governance is a cross between Daoist and LBJ in </span><em>Master of the Senate</em><span> mode. </span></p><p><span>He operates with an acute and finely tuned sense of the nature of power and how to wield it in the subtlest ways possible. As much as possible, he limits himself to the tiniest possible nudges, conducting the balance-of-power constituent forces of Ankh-Morpork like an orchestra, almost always working through others. His main job is keeping all the guilds of Ankh-Morpork, and its relations with foreign powers, in a stable balance of power (he himself is an alumnus of the Assassin’s Guild). He does this with pragmatism and compromise, nudging the arc of the moral universe to slouch towards utopia, but not at a pace it cannot handle. He is nearly always on the right side of history and social evolution, though sometimes he has to be convinced by more idealistic characters that the time is ripe for a particular change </span><em>now</em><span>, rather than later. He is no broad-based accelerationist, but he surreptitiously, selectively, and surgically helps accelerate currents of positive change that he must publicly appear to oppose.</span></p><p><span>The guilds are the load-bearing elements of Ankh-Morpork’s society. Not NPCs, but usually running as background processes, with Vetinari as system administrator, albeit one who is </span><em>very </em><span>wary of sudo-ing anything.</span></p><p><span>Vetinari is something like an anti-Chosen One. In the most Chosen One story, </span><em>Sourcery</em><span>, the sourcerer turns him into a lizard and puts him in a cage, and he remains out of the picture for the whole novel. That’s one reason things get so out of hand in that story: The main adult in the room is locked away from the action while the Chosen One tries to bull-doge a new reality into being. But in most stories, he adds a decisive nudge or two that allows the world to smoothly and elegantly switch tracks to better futures. </span></p><p><span>Within the rules of Discworld, you could say Vetinari only acts to the extent the system is underdetermined. While he is sovereign in the Schmittian sense — the one with the power to make exceptions — he only has this power to the extent he uses it to nudge the system towards doing what it most </span><em>wants</em><span> to do anyway. He counteracts destabilizing noise in the signal but does not impose his opinions on what Discworld wants to do.</span></p><p><span>Before I get to that, a word on what Discworld does </span><em>not </em><span>want.</span></p><p><span>The main thing Discworld does </span><em>not </em><span>want is to </span><em>be at the mercy of the gods </em><span>(and Chosen Ones with god-delusions)</span><em>.</em></p><p><span>There </span><em>are</em><span> gods on Discworld, but fortunately they are for the most part living in peaceful retirement in Dunmanifestin (“done manifesting”), making it a  </span><em>de facto </em><span>atheist universe. </span></p><p><span>Unlike most of the supporting cast of Discworld, the gods </span><em>are </em><span>NPCs. They don’t do anything, and don’t want to. Ontologically, they are creatures of pure belief, being stronger or weaker, or altogether non-existent, depending on the extent to which mortals believe in them. The only story revolving consequentially around gods is </span><em>Small Gods, </em><span>about a meme-stock god named GameStop, whose power crashes, and who ambitiously plans to pump himself back up to a new high. A parody Chosen One story crossed with Greek mythology tropes.</span></p><p><span>So the story of Discworld is explicitly </span><em>not </em><span>the story of what the gods have planned for it. They got it going and retired, leaving it to its own potentialities. Discworld is </span><em>free </em><span>in a theological sense. There is no Discworld eschatology.</span></p><p><span>Discworld is also not a story scripted by priestly intercessors. There </span><em>is </em><span>a class of time monks (who come across as vaguely Daoist/Buddhist and keep the machinery of time itself going). They are allies of Death, stewards of the messiness of life like him, helping keep the Auditors of Reality at bay. Their job is to keep</span><em> </em><span>history free and evolving through a timescape of many alternatives (not “free” in some narrative-captured sense).</span></p><p>There is also an array of occasional antagonists who periodically show up with grand Thielean “determinate optimism” type plans, convinced they know better than average shmucks, and threatening the freedom of Discworld for its own good. </p><p><span>These include monsters and dragons from the dungeon dimensions, and </span><em>elves</em><span>. </span></p><p>These last named are perhaps the closest thing Discworld has to unredeemed and unredeemable villains. </p><p><span>In Discworld, elves are evil in an insidious, feckless sort of way, being an invasive parasitic species with no imagination but a lot of superficial charm. Here is the essence of their nature, from the </span><a href="https://discworld.fandom.com/wiki/Elves" rel="">Discworld wiki</a><span>:</span></p><blockquote><p>[Elves] are not native to the Disc, but come from a "parasite universe", sometimes called Fairyland. This pocket dimension can latch onto different universes at certain times… </p><p>…Elves have no proper imagination or real emotions, and therefore such things fascinate them. Because they cannot create they steal musicians and artists. Because they cannot have children (although they are capable of breeding with humans, resulting in offspring with superficially elvish characteristics - skinny, pointy ears, a tendency to giggle and burn easily in the sun - but fundamentally human traits i.e. empathy) they steal children from the Disc to be their toys. Because they cannot feel empathy they enjoy the suffering of others. Even if an elf is, for reasons of its own, trying to be nice, its lack of understanding of humans mean there's always something "off" about it.</p><p>Mostly they get away with this, due to the illusion-creating glamour they cast. While elves are, as mentioned above, not musical, elfsong is perceived as beautiful by humans, and is highly hypnotic. Elves are generally seen as innately beautiful and stylish, but this is just another aspect of the glamour. Some of them are only vaguely humanoid.</p></blockquote><p>At one point, the elves migrate to Roundworld and cause havoc there, by killing the narrative vigor of history with their empty and superficial illusions, until Discworlders save the day. I like to pretend this actually happened.</p><p><span>The elves are among the most sophisticated bits of world-building by Pratchett, because they are the personification of </span><em>anti-narrative </em><span>forces in the cosmology. They commonly pose a threat by obscuring the rich potentialities of reality with illusory, degenerative bullshit.</span></p><p><span>The ontological antithesis of the elves is </span><em>narrativium</em><span>, the most common element on Discworld. It is a kind of meta-fictional conceit on Pratchett’s part, allowing his universe to be metamodern without being tedious about it. </span></p><p>Everything satirized and parodied in Discworld, all the ironically deployed tropes of fantasy, are accounted for as the workings of narrativium. That means in-world, all the effects of narrativium are made fun of, but not treated as existential threats. Within the meta-story of Discworld, narrativium adds some of the coherence and discipline that the Auditors of Reality yearn for, but not in a deadening, joyless way. Narrativium is life-affirming narrative irony embodied and embraced.</p><p><span>Narrativium allows Discworld to escape the tyranny of hegemonic TINA stories that insist on destroying all alternative stories. It allows Discworld to have a history, but not be </span><em>bound </em><span>by history. It allows Discworld to constantly entertain and choose among </span><em>many </em><span>futures, as an entire entangled reality. It allows Discworld to forcefully reject (and sometimes eject from reality) the efforts of Chosen Ones to capture reality.</span></p><p><span>Narrativium is </span><em>also </em><span>what allows Discworld to escape the tyranny of the idea that there are, or should be, </span><em>no </em><span>stories (or what is the same thing, the idea that all stories are equally valid and good). This is the fatal flaw in the worldview of the Auditors of Reality who, like their Roundworld counterparts, want to arrive at an always-already bureaucratic perfection and forget anything imperfect ever happened, erasing not just history, but time itself. Death and the Time Monks might do the work necessary to keep them at bay, but Narrativium is what makes Discworld unauditable in the first place.</span></p><p><span>Narrativium is the </span><em>elan vital </em><span>that allows Discworld to pursue what it </span><em>wants </em><span>as opposed to merely avoiding what it does </span><em>not </em><span>want. </span></p><p>The essential property of Narrativium is that it ensures that the history of Discworld will unfold in satisfying ways that make it a good story. This property is most on display in the fifth major sequence of novels in the map: the Industrial Revolution sequence, which feature one of the most interesting characters, Moist Von Lipwig, who is Vetinari’s fixer, nudging technological progress along.</p><p><span>Through these books, Discworld in general, and Ankh-Morpork in particular, repeatedly breaks free of its own past with the help of technological innovations. There is an industrial revolution driven by steam, a postal system emerges, a film industry is born. A great deal more of this sort of thing happens. Discworld evolves a </span><em>lot </em><span>between the earliest and latest books by in-world chronology. That’s what makes the stories a “literature of change” in Ted Chiang terms. These are not stories of heroes restoring changeless sacred realities after profane excursions.</span></p><p>The details of these developments usually feature absurd (and absurdly entertaining) twists on the corresponding Roundworld historical events, while largely staying true to the logic of Roundworld history. For example, film technology on Discworld relies on some faux-science built around small goblins who sit in the cameras painting really fast (magical, but in an inconsequential way).</p><p>And it’s all very satisfying, in ways the corresponding histories on Roundworld are not. The story also feels a lot more forcefully inevitable and necessary, but not in a restrictive or totalizing way. It is intensified rather than revisionist Roundworld history. </p><p>That’s what makes narrativium good to have around.</p><p>This process is one of generative discovery and continuously improvised contingency. The rule that governs this evolutionary process on Discworld, in Pratchett’s own words, is “Our minds make stories, and stories make our minds.”</p><p>This is the Pratchett version of “hyperstitional theory fiction” which applies with much greater force in Discworld, such that far more consequential things can be memed into existence. </p><p>In the most extreme case, as we’ve seen, the gods of Discworld themselves are memed into existence by belief, like over-powered versions of the subjects of Roundworld cults of personality. Roundworld religions, thankfully, don’t have this kind of power to create Roundworld gods of equal substance, since unlike the retiring and lazy Discworld gods, we tend to imagine very interventionist and opinionated gods for ourselves.</p><p><span>In the case of more real things that exist by themselves, rather than as incarnated memes, narrativium undergirds a sort of theory of relativity. I actually independently rediscovered Pratchett’s theory of narrativium in 2019, just before encountering his version, by transposing J. A. Wheeler’s description of General Relativity to narratives. I wrote up my theory </span><a href="https://www.ribbonfarm.com/2019/04/25/worlding-raga-5-world-how/" rel="">as part of an extended series</a><span> on Worlding co-authored with Ian Cheng (that’s Ian’s term for world-building):</span></p><blockquote><p><span>A bit of fun synchronicity. A few weeks ago, I came up with a snowcloned line inspired by a famous tldr of general relativity: </span><em>narratives tell archetypes how to evolve, archetypes tell narratives how to curve.</em><span> </span><a href="https://www.ribbonfarm.com/2019/04/25/worlding-raga-5-world-how/#1" rel=""><sup>1</sup></a><span> Right after, I found a Terry Pratchett quote that says almost the same thing, but less ponderously: “Our minds make stories, and stories make our minds.” I prefer my version though, since I like the synaptic link to physics it creates.</span></p></blockquote><p>Roundworld, sadly, does not have more than trace quantities of narrativium, which is why Roundworld histories are often so unsatisfying and so easily fall prey to Discworld elves, or humans possessed by them.</p><p><span>The presence of narrativium, and the dynamic of stories and minds creating each other, lends to Discworld history a legitimate </span><em>telos. </em><span>On Roundworld all historicism (except perhaps Fukuyama’s) are simply bad thinking. But on Discworld, it is actually meaningful to ask, </span><em>what does Discworld want?</em></p><p><span>The answer is that Discworld </span><em>wants </em><span>to evolve in a way that could be interpreted as progress in the most neutral, non-ideological sense possible — that of an infinite game, where the goal is not for some to win at the expense of others, but for </span><em>all </em><span>to continue to play, and gradually learn to play ever more nicely and kindly as abundance and meaning increase in the world.</span></p><p>The sentiment behind the aspiration is perhaps a mark of British culture at its best. The high conceit of Discworld is that the infinite game always prevails and cannot truly be derailed by even by the most powerful forces. The mediocre efforts of ordinary characters powered by narrativium is enough to keep the infinite game going.</p><p><span>This is why the denizens of Discworld can often act with a generosity of spirit even towards their worst villains. A generosity that we on Roundworld can find hard to conjure up. They </span><em>know </em><span>they are good guys and necessarily on the winning side, while we can only </span><em>hope.</em></p><p><span>One of my favorite lines from </span><em>Doctor Who </em><span>captures the spirit of the Discworld’s narrativium-powered infinite game perfectly: </span><em>always try to be nice, but never fail to be kind. </em></p><p><span>That’s a line from the regeneration speech of the twelfth Doctor (Peter Capaldi). Like Pratchett’s universe, the </span><em>Doctor Who </em><span>universe too tries to be about keeping the infinite game going, albeit not as elegantly (since the Doctor is a Special Person, making it a fantasy universe). </span></p><p><span>The plot device of regeneration that is limited to the Doctor in </span><em>Doctor Who </em><span>applies to all of Discworld. The whole </span><em>world</em><span> periodically regenerates into a new, richer, more complex form, through a process that looks very much like technological progress. </span></p><p><span>Discworld is </span><em>almost </em><span>perfect science fiction by Chiang’s Law; a world of strange rules rather than special people. Almost, but not quite. There is </span><em>one </em><span>big way in which Discworld is in fact fantasy: the </span><em>world </em><span>itself is a special world. A Chosen World.</span></p><p><span>The </span><em>telos </em><span>of Discworld that Roundworld lacks — it </span><em>wants </em><span>to evolve in open-ended ways that make it preternaturally resistant to capture by totalizing narratives — makes it special. </span></p><p>The history of Roundworld in recent centuries has, at least empirically, exhibited such tendencies, but unlike the denizens of Discworld, we cannot trust in that being the intrinsic nature of our world. Certainly those currently in power are trying to prove it isn’t.</p><p><span>Not so on Discworld. On Discworld, the arc of the moral universe </span><em>does </em><span>in fact have a particular disposition; not towards justice or liberalism or any other such tawdry Roundworld ideological conceit, but towards </span><em>greater generativity and complexity and more alternatives.</em><span> On Discworld, the show </span><em>actually </em><span>must go on, due to the laws of narrativium.</span></p><p>Or to put it another way, Discworld has an astounding, unbreakable resistance to Chosen Ones at any scale except the scale of the world itself. Discworld is powered by the anthropic principle on steroids. It keeps discovering new ways in which its entire reality is special.</p><p>This is one reason Discworld can afford to be such a kind world. As a world that is intrinsically pre-disposed to reject totalizing narratives and protect multiple possibilities in an ever-expanding garden of forking paths, reality is on the side of pluralism and against totalizing conceits.</p><p>This is why, on Discworld, even the weakest, most mediocre protagonists, when going up against a powerful Chosen One who wants to capture and enslave reality, can afford to be gracious. Even when they are at the lowest, and cowering before a Chosen One who thinks he has won. Because thanks to the narrativium levels in the environment, the protagonists know they will win, and need never despair. </p><p>The Discworld protagonist seems to know that though they must always scramble comically and improvise energetically to save it from the monstrous Chosen One of the Week, the arc of their moral universe bends in their favor. </p><p>Discworld is a world that knows what it wants, and how to get it. With some nudging along by Vetinari, Death, and Time Monks, and a lot of reluctant anti-heroic adventuring by the likes of Rincewind, Vimes, Granny Weatherwax, and Moist von Lipwig. Narrativium helps those who help themselves. </p><p><span>I </span><em>wish </em><span>this were true of Roundworld.</span></p><p>Unlike Discworld, our own Roundworld has no such specific disposition. The ideas that the arc of moral history on Roundworld bends towards justice, or that “reality” has a well-known liberal bias (a comforting premise of the late-lamented hyperstitional theory fiction of traditional American politics known as “normalcy”) that are popular with us are no more than thin, wishful fictions. Probably planted in our heads by the Discworld elves.</p><p>Roundworld does not want anything in particular, and no future is necessary. As Discworld scientists have discovered on their trips here, life and civilization have evolved and been destroyed multiple times on Roundworld, in a meaningless process of fragile evolution.</p><p><span>Unlike on Discworld, totalizing narratives of bleak “determinate optimism” can capture and destroy Roundworld. They can </span><em>actually </em><span>end history as surely as our Sun going nova. All it takes is a couple of idiots with their fingers on nuclear triggers, surrounding by admiring Yes Men reassuring them of their greatness.</span></p><p><span>But kindness is perhaps one bit of hyperstitial theory fiction that is worth believing in, even if it does not have any of the force of Discworld’s sympathetic magic to it. Kindness is a feature of our moral universe we can </span><em>pretend </em><span>we can meme it into bending towards. </span></p><p>Because kindness is worth it for its own sake, even if Roundworld lacks the narrativium leverage to turn it into a world-protecting force.</p><p>The idea that there are many alternatives is the second most politically loaded one I’ve ever put out, after the idea that with the right technological scaffolding, a proper reckoning with history is in fact possible and desirable, and not necessarily an exercise in bad-faith book-keeping of resentments and grievances. </p><p><span>Both these ideas currently only exist as talks. I haven’t written them up as essays. The reckoning-with-history idea is my </span><a href="https://www.youtube.com/watch?v=ow43pFm9GLQ" rel="">Bloodcoin</a><span> talk from 2018, and the TAMA idea is in my </span><a href="https://www.youtube.com/watch?v=FxBA_9dm6xk" rel="">Civilizational Hypercomplexity</a><span> talk from 2021. Not surprisingly, both talks rely on blockchain-based models of reality. Blockchains are the closest thing to narrativium we Roundworlders have invented. They may be infested with scams and memes, but they cannot be easily captured by Chosen Ones peddling stupid TINAs.</span></p><p><span>The funny thing is, I was never against the original TINA story, neoliberalism. I rather liked it philosophically, liked living in it, and owe basically everything good in my life to it. Now that it is basically over, I do regret its passing, since every TINA hyperstitional theory fiction jockeying to replace it is </span><em>much</em><span> worse. </span></p><p>But at least we’re exploring many alternatives for the moment and not locking into one. And at least the value of real attempts to reckon with history, of the sort I gesture at in the Bloodcoin talk, is becoming crystal clear, given the barrage of wild and transparently motivated confabulations we are now enduring. </p><p><span>This thought inspired </span><a href="https://substack.com/@contraptions/note/c-98520101" rel="">a note</a><span> yesterday:</span></p><blockquote><p>If you want peace, prepare for war. If you want war, prepare for peace.</p><p>If you want the benefits of war without the costs of peace, lie through your teeth about everything</p></blockquote><p>Vetinari, incidentally, did not believe the popular first epigram; he thought the truth was more banal — If you want peace, prepare for peace, if you want war, prepare for war. But I think he would agree with my second thought. Whatever the causal pattern linking war and peace, it is clear that those possessed by elves (or Auditors of Reality) lie through their teeth about everything to justify doing whatever they please, as Chosen Ones.</p><p><span>All that said, there is still the question of kindness — should you be kind, </span><em>especially </em><span>to those you disagree with, and </span><em>especially especially </em><span>when they are strong and threatening to destroy all you hold dear, while you are weak and unable to protect any of it?</span></p><p>Should you live by Discworld rules of kindness and grace, when all that might get you is contempt and destruction? </p><p>Or should you tell yourself stories that make your mind of sterner stuff? </p><p><span>The thought I began with, that </span><em>The Lord of the Rings, </em><span>whatever its merits as a fantasy tale,</span><em> </em><span>is brain-rot for the technological mind, is one that I find so obvious it feels barely worth stating. I only started there because I think that’s where our world’s collective head is at. We not only lack the narrativium protections of Discworld, most humans seem to actively </span><em>prefer </em><span>totalizing single narratives and surrendering to Chosen Ones. Fantasy — in the regular, LOTR sense — is vastly more popular than science fiction.</span></p><p><span>But a comparison that is </span><em>not </em><span>so obvious is between Discworld and Iain M. Banks </span><em>very </em><span>similar Culture novels. Though the milieus couldn’t be more different (space opera vs. steampunk absurdist ironic fantasy), both are science fiction in the Chiang sense — literatures of change set in worlds governed by strange rules.</span></p><p>The Culture is a galactic-scale post-scarcity anarcho-capitalist mongrel utopia under the benevolent protection of superintelligent spaceships. The closest fully realized fictional universe to that meme about fully automated luxury gay space communism.</p><p><span>The Culture though </span><em>is </em><span>neither communism nor capitalism, but a post-capitalist anarchist milieu with few technological peers. It is a superpower on a galactic scale that behaves like a superpower — imposing its values on less developed civilizations with opinionated, unilateralist prejudice. That the values happen to be ones I agree with doesn’t make the Cultures actions more palatable. They are often very troubling (and meant to be).</span></p><p><span>If Discworld has the laws of narrativium going for it, so that mediocrities can serve as stewards, the Culture has a powerful and unapologetically interventionist secret service called Special Circumstances, which operates by the opposite of </span><em>Star Trek</em><span>’s Prime Directive. It cheerfully and heavily interferes all over the place, where it judges that history is headed in the wrong directions. It appoints itself as the Schmittian sovereign making exceptions wherever it likes.</span></p><p>The Culture’s AIs and drones have no compunctions about killing and destruction — this is no gentle Three Laws of Robotics Asimovian universe. In fact, the series opens in the aftermath of a bloody war between the Culture and a peer civilization.</p><p>In the Culture, what is a natural property of reality in Discworld is enforced with extreme prejudice and violence. The entirety of the Culture is like an Assassin’s Guild, with the agents and minds of Special Circumstances acting collectively like a much more forceful Vetinari. </p><p>While life inside the Culture is something like a high-abundance version of an Ursula Le Guin style peaceful anarchy, its actions in foreign space resemble those of the CIA and KGB at the height of the Cold War, rolled into one. Fomenting revolutions, deposing leaders, assassinations — the whole shebang.</p><p><span>To bring it back our core question, that of kindness, the Culture is often kind, though rarely tender, and acts to make sure it’s never in a weak position. It only ever needs to consider the question of kindness from a position of overwhelming strength. The question is never </span><em>if </em><span>it can prevail, but whether it can do so in keeping with its values.</span></p><p>Should we play by Discworld Rules or Culture Rules in the coming years? Should we try to become strong before choosing to be kind, or should we choose kindness whether or not we happen to be strong or weak at any given time?</p><p>I don’t know, but I like that I have at least two good alternatives to ponder. That is the power of not being tied to one narrative with no alternatives being admissible. </p><p>I may never end up choosing, but I think either set of rules would be better than LOTR rules.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Volkswagen reintroducing physical controls for vital functions (184 pts)]]></title>
            <link>https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions</link>
            <guid>43298271</guid>
            <pubDate>Sat, 08 Mar 2025 07:25:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions">https://www.autocar.co.uk/car-news/new-cars/volkswagen-reintroducing-physical-controls-vital-functions</a>, See on <a href="https://news.ycombinator.com/item?id=43298271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>All future <a href="https://www.autocar.co.uk/car-review/volkswagen">Volkswagen</a> models will feature physical controls for the most important functions, design chief Andreas Mindt has said.</p>
<p>The German firm has been criticised over the past few&nbsp;years for moving many of the vital controls in its cars from physical buttons and dials to the infotainment touchscreen. Volkswagen also introduced haptic ‘sliders’ below the touchscreen for the heating and volume&nbsp;and it started using haptic panels instead of buttons for controls mounted on the steering wheel.</p>
<p>More recently, the firm has reintroduced physical steering wheel buttons and Mindt said it is committed to reintroducing physical buttons, starting with the production version of the <a href="https://www.autocar.co.uk/car-news/new-cars/2025-volkswagen-id-2-will-be-even-better-concept">ID 2all concept</a> that will arrive next year.</p>

<p>“From the ID 2all onwards, we will have physical buttons for the five most important functions – the volume, the heating on each side of the car, the fans and the hazard light – below the screen,” said Mindt. “They will be in every car that we make from now on. We understood this.</p>
<p>“We will never, ever make this mistake any more. On the steering wheel, we will have physical buttons. No guessing any more. There's feedback, it's real, and people love this. Honestly, it's a car. It's not a phone: it's a car.”</p>
<p>Mindt said VW will continue to offer cars with touchscreens, in part due to new legal requirements that, as in the US, will require all cars to feature a reversing camera.&nbsp;</p>
<p>“There are a lot of functions you have to deliver in certain areas, so the screen will be big and you will find a lot of HMI [human-machine interface] contents in the depths of the system,” he added. “But the five main things will always be on the first physical layer. That’s very important.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PayPal honey extension has again "featured" flag in Chrome web store (303 pts)]]></title>
            <link>https://chromewebstore.google.com/detail/paypal-honey-automatic-co/bmnlcjabgnpnenekpadlanbbkooimhnj/reviews</link>
            <guid>43298054</guid>
            <pubDate>Sat, 08 Mar 2025 06:43:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chromewebstore.google.com/detail/paypal-honey-automatic-co/bmnlcjabgnpnenekpadlanbbkooimhnj/reviews">https://chromewebstore.google.com/detail/paypal-honey-automatic-co/bmnlcjabgnpnenekpadlanbbkooimhnj/reviews</a>, See on <a href="https://news.ycombinator.com/item?id=43298054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="zpNSJe" jscontroller="Xi0ENb" jsaction="PzrbKe:PxDP6e;Dg2tk:I8BRrf;JIbuQc:qkhPf(Btxakc);rcuQ6b:u9qk0d;"><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjW0qfanKQCgx16_nZw0E3-Ma3uvLP6e7YLpjpam1Llw2XjgrGA=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjW0qfanKQCgx16_nZw0E3-Ma3uvLP6e7YLpjpam1Llw2XjgrGA=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i7"><span>Mike Thompson</span><span>Mar 8, 2025</span></h3></div><p jsname="f27TO">Horrible scam that steals money from affiliates and creators!</p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjUNoSqb7JbnrX6Ihy8kqgZpkMgEkxvFdQJETGH-qiWWOn2v4_WJ=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjUNoSqb7JbnrX6Ihy8kqgZpkMgEkxvFdQJETGH-qiWWOn2v4_WJ=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i8"><span>Meow Meows</span><span>Mar 7, 2025</span></h3></div><p jsname="f27TO">Scammers and thieves.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">1 person found this review to be helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjX_vh2SONY6MM2CDkh7VE4IZZySNLINAeBXXlFhmraPeHeM4CfSHw=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjX_vh2SONY6MM2CDkh7VE4IZZySNLINAeBXXlFhmraPeHeM4CfSHw=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i9"><span>Tim</span><span>Mar 7, 2025</span></h3></div><p jsname="f27TO">Garbage.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjVjfhlJig9NzU8ImbO5HMGz7J0KHWfBtrfDi1PqFDOLnS7Rvu5rig=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjVjfhlJig9NzU8ImbO5HMGz7J0KHWfBtrfDi1PqFDOLnS7Rvu5rig=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i10"><span>Notna</span><span>Mar 7, 2025</span></h3></div><p jsname="f27TO">Massive scam, steals money from your faviorte online creators and bloggers. Shame on you honey!</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">3 out of 3 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a/ACg8ocJXd2Qe_Li9R8T3Xq1xlx6pJI48S8Zgph4brUdrRrTcMYfv9w=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a/ACg8ocJXd2Qe_Li9R8T3Xq1xlx6pJI48S8Zgph4brUdrRrTcMYfv9w=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i11"><span>matt pabla</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">Honey is a huge scam, look it up. Sad....</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">4 out of 4 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjWJtlX6SnWcn0dI832pfgdeKV9Uz7XMdTYn_fT7xQv8DadrIQ=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjWJtlX6SnWcn0dI832pfgdeKV9Uz7XMdTYn_fT7xQv8DadrIQ=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i12"><span>Paul</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">scam</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">3 out of 3 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a/ACg8ocKqbwhOzEC66AOLXkWZ7wZ1XmTbXR5P_815KqY16nVdjI71QA=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a/ACg8ocKqbwhOzEC66AOLXkWZ7wZ1XmTbXR5P_815KqY16nVdjI71QA=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i13"><span>Jordan Dion-Duval</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">Scam, you save more by uninstalling it smh</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjWdcQORdqkLJdX5HovggtAujb9ucHesrZR0bq6yEOUK5Pc10Qa5=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjWdcQORdqkLJdX5HovggtAujb9ucHesrZR0bq6yEOUK5Pc10Qa5=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i14"><span>Michael500ca</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">They deleted my Honey Gold points because I hadn't used them in a while. Horrible rewards program. I am not going to use them anymore.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjWK3dPHc0IAHZvyTKuETCwDi_cMqxBjuWORLvNqX7XmtvRYyto=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjWK3dPHc0IAHZvyTKuETCwDi_cMqxBjuWORLvNqX7XmtvRYyto=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i15"><span>Darshan Kolesar</span><span>Mar 6, 2025</span></h3></div><p jsname="f27TO">Although this doesn't scam you, it will scam affiliates. Many influencers live off of the money they get from affiliate codes, so please do not install this or use this in any way. I am very disappointed in PayPal for doing this, and I hope Google is competent enough to take down this extension from their store.</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">2 out of 2 found this helpful</span></p></section><section jscontroller="ECBKud" jsname="ShBeI" jsaction="change:BbBN0b(uHcrq); keydown:AWuxGc,pu39sc(uHcrq); input:pu39sc(uHcrq); keyup:BbBN0b(uHcrq);UKfqQ:BbBN0b(RZG7Xe);Fn2EM:HZuyid;KbznFd:mRsukd"><img src="https://lh3.googleusercontent.com/a-/ALV-UjXyUqD7mANi7DGIe0CWxUdivSEF6kmdgRO5byVoWCbCG7Kal20=s48-w48-h48" srcset="https://lh3.googleusercontent.com/a-/ALV-UjXyUqD7mANi7DGIe0CWxUdivSEF6kmdgRO5byVoWCbCG7Kal20=s96-w96-h96 2x" alt="Review's profile picture"><div><h3 id="i16"><span>Xavier</span><span>Mar 5, 2025</span></h3></div><p jsname="f27TO">scam</p><p><span jscontroller="KfQkxf" jsaction="h7N06c:MKYwnd" jsname="cDaQFd">4 out of 4 found this helpful</span></p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Falkon: A KDE Web Browser (146 pts)]]></title>
            <link>https://www.falkon.org</link>
            <guid>43297590</guid>
            <pubDate>Sat, 08 Mar 2025 04:51:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.falkon.org">https://www.falkon.org</a>, See on <a href="https://news.ycombinator.com/item?id=43297590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content" id="content"><div><div><div><h2>Privacy and security features enabled by default</h2><p>Falkon cares a lot about the security of your data and ship with an ads blocker enabled by default as well as a password manager. Additional configurations allows you to improve even more your security and privacy</p></div><div><picture><source srcset="https://www.falkon.org/images/adblocker_dark.png" media="(prefers-color-scheme: dark)"><img src="https://www.falkon.org/images/adblocker.png" alt=""></picture></div></div><div><div><h2>Customize your experience</h2><p>Falkon support theming so that you can choose how your browser looks. Multiple extensions are also available to help you make Falkon adapt to you.</p></div><div><picture><img src="https://www.falkon.org/images/themes.png" alt="Screenshot of Falkon with multiple themes"></picture></div></div></div><div><div><p><img src="https://www.falkon.org/images/plasma.svg" alt="" width="128" height="128"></p><h2>Integrated inside Plasma</h2><p>Falkon integrates inside Plasma and follows Plasma theming preferences.</p></div><div><p><img src="https://www.falkon.org/images/osi.svg" width="128" height="128" alt=""></p><h2>Open Source</h2><p>Falkon is Open Source and you can browse, edit and share the source code. Falkon is <a href="https://kde.org/">Made By KDE</a>, a community building high-quality projects that your are free to use. Check out all <a href="https://kde.org/products">our projects!</a></p></div></div><div><h2>Announcements</h2><div><div><p>Sunday, 15 December 2024</p><h3>Falkon 24.12 Release notes</h3><p>This release includes fixes for GreaseMonkey, VerticalTabs, Navigation bar (security icon), stability fixes, does not advertise the FTP support, fixes printing and more small fixes.
<a href="https://www.falkon.org/posts/2024/2024-12-15-falkon-24-12-release-notes/">Read More</a></p></div><div><p>Sunday, 29 September 2024</p><h3>Falkon 24.08 Release notes</h3><p>This release focuses on SiteSettings feature, so I will try to introduce it here.
<a href="https://www.falkon.org/posts/2024/2024-09-29-falkon-24-08-release-notes/">Read More</a></p></div><div><p>Saturday, 2 September 2023</p><h3>Falkon 23.08.0 released</h3><p>New Falkon version 23.08.0 is being released as part of KDE Gear.
Notable changes Zoom indicator to the AddressBar When the zoom level on the page is different than the default, show current zoom level in the address bar.
<a href="https://www.falkon.org/posts/2023/2023-09-02-falkon-23-08-0-release/">Read More</a></p></div><div><p>Friday, 21 April 2023</p><h3>Falkon 23.04.0 released</h3><p>New Falkon version 23.04.0 is being released as part of KDE Gear.
Notable changes There is a handful of changes in this release.
KWallet The format under which the passwords are stored has changed from Binary to Map. The passwords can now be viewed from within KWalletManager and even edited. While editing and adding new ones I would be careful with the data field and updated that as well. (This is some Falkon password internal mechanic) The Folder under which the passwords are stored changed from Falkon to FalkonPasswords. This was done to not overwrite the old passwords and potentialy ruin them during the migration to new format.
<a href="https://www.falkon.org/posts/2023/2023-04-21-falkon-23-04-0-release/">Read More</a></p></div></div><p><a href="https://www.falkon.org/posts/">📢 View all announcements</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An epic treatise on error models for systems programming languages (177 pts)]]></title>
            <link>https://typesanitizer.com/blog/errors.html</link>
            <guid>43297574</guid>
            <pubDate>Sat, 08 Mar 2025 04:46:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://typesanitizer.com/blog/errors.html">https://typesanitizer.com/blog/errors.html</a>, See on <a href="https://news.ycombinator.com/item?id=43297574">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
          <section>
	          
<p><strong>Target audience</strong>: Practitioners interested in programming language design
and familiar with representations of errors in at least a few different languages
such as error codes, checked/unchecked exceptions, tagged unions,
polymorphic variants etc.</p>
<p><strong>Estimated reading time</strong>: 60 to 90 mins.</p>
<p>In research papers on programming languages,
there is often a focus on sophisticated
type system features to rule out certain classes of errors,
whereas <em>error handling itself</em> receives
relatively little attention, despite its importance.<span><label for="sn-0"></label><span>This doesn’t seem too dissimilar to problems in the database community/literature, where less “cool” topics like better representation for strings receive relatively little attention compared to their importance. See also: <a href="http://databasearchitects.blogspot.com/2024/12/what-are-important-data-systems.html">What are important data systems problems, ignored by research?</a> and DuckDB creator Hannes Mühleisen’s <a href="https://www.youtube.com/watch?v=dv4A2LIFG80">CIDR 2023 keynote</a> on Developing Systems in Academia for related discussion.</span></span>
For example, in
<a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf">Simple testing can prevent most critical failures [PDF]</a><span><label for="sn-1"></label><span>Readers in a rush can skim sections 1 and 2 and read the ‘Findings’ in bold in section 4.</span></span> , Yuan et al.
found that in the context of distributed data-intensive systems:</p>
<ul>
<li><p>“Almost all catastrophic failures (92%) are the result of
incorrect handling of non-fatal errors explicitly signaled in software”
(Finding 10, p256)</p>
<ul>
<li>Out of these “35% [..] are caused by trivial mistakes in error
handling logic — ones that simply violate best programming practices;
and that can be detected without system specific knowledge.”
(Finding 11, p256)</li>
</ul></li>
</ul>
<p>In contrast, there is some excellent long-form writing on error models out
there by practitioners.</p>
<ul>
<li>Joe Duffy’s blog post on <a href="https://joeduffyblog.com/2016/02/07/the-error-model">the error model in Midori</a>:
This describes a variant of C# used to write a microkernel, drivers,
and a large amount of user code. Duffy describes a two-pronged error
model – “abandonment” (fail-fast error handling)
and a variation on checked exceptions (utilizing class hierarchies).</li>
<li><a href="https://github.com/swiftlang/swift/blob/main/docs/ErrorHandlingRationale.md">The design doc for Swift’s error model</a>: This discusses the pros and cons of error models in several
different languages.</li>
<li>The TigerBeetle docs on <a href="https://github.com/tigerbeetle/tigerbeetle/blob/main/docs/TIGER_STYLE.md#safety">“Tiger Style”</a>:
This describes how the TigerBeetle database tries to ensure various
forms of safety. The discussion on assertions in the Safety section
is particularly worth reading.</li>
<li><a href="https://rust-lang.github.io/rfcs/0236-error-conventions.html">Rust RFC 236 - Error conventions</a>:
This describes conventions for how Rust libraries
should use different error handling mechanisms
in different situations.</li>
<li>Joe Armstrong’s talk <a href="https://youtu.be/TTM_b7EJg5E?si=J321vwBsKhKwgy1s&amp;t=1293">The Do’s and Don’ts of Error Handling</a>:
Armstrong covers the key requirements for handling and recovering
from errors in distributed systems, based on his
<a href="https://erlang.org/download/armstrong_thesis_2003.pdf">PhD thesis from 2003</a> (PDF).<span><label for="sn-2"></label><span>By this point in time, Armstrong was about 52 years old, and had 10+ years of experience working on Erlang at Ericsson.</span></span></li>
</ul>
<p>Out of the above, Armstrong’s thesis is probably the most holistic,
but it’s grounding in Erlang means that it also does not take into
account one of the most widespread forms of static analysis we have today
– type systems. Here’s an excerpt from page 209:</p>
<blockquote>
<p>We can impose a type system on our programming language,
or we can impose a contract checking mechanism between any
two components in a message passing system. Of these two methods I
prefer the use of a contract checker</p>
</blockquote>
<p>In this post, I want to approach error models in a way that is both
<em>holistic</em> and <em>geared towards ecosystems of systems PLs</em>.</p>
<p>By <em>holistic</em>, I mean that I will approach error models from several different perspectives:</p>
<ul>
<li>From a “product” perspective: What are the core assumptions,
what are all the requirements and how are they informed by practical use cases.</li>
<li>From a type systems perspective: How can the type system assist
the programmer to accomplish what they want.</li>
<li>From a language design perspective: How API design guidelines,
conventions and tooling can be combined with type system features
to enable people to write more robust applications.</li>
</ul>
<p>By <em>geared towards ecosystems of systems PLs</em>,<span><label for="sn-3"></label><span>The term “systems programming language” inevitably seems to trigger people into rehashing the same “arguments” in comment sections – many people seem to like using it as a term for excluding other languages because they use reference counting or tracing GC as the default memory management strategy. I’m picking a definition here for the sake of this post. If you dislike this definition, you can either mentally replace all usages of “systems PL” with “language with XYZ memory management strategy” or you can stop reading the post.</span></span> I mean that the error
model must take into account the following needs:</p>
<ul>
<li>Graceful degradation in the presence of errors,
because the underlying platform and/or acceptance criteria
may offer limited recovery capabilities.</li>
<li>Optimizability – either by the compiler, the programmer or both
– as performance bottlenecks arise <em>within</em> the system
rather than from external sources.
This may involve trading off flexibility in error handling
for performance.</li>
<li>Facilitation of interoperability between and co-evolution of
libraries and applications.</li>
</ul>
<p>Some examples of such software include databases,
high-performance web servers, and interpreters.
I will be ignoring use cases
such as small-scale scripting for one-off tasks,
interactive data exploration etc.
I will also be ignoring ABI considerations, because
those can largely be resolved
by varying levels of indirection
in the run-time representation (e.g.&nbsp;see Swift).</p>
<p>The structure of this <del>thesis</del> blog post is as follows:</p>
<ul>
<li><a href="#section-1-key-definitions">Section 1</a> discusses definitions for important terms such as ‘error’,
‘error model’ etc.</li>
<li><a href="#section-2-key-theses">Section 2</a> goes over the primary theses about errors and how people reason
about them, along with examples.</li>
<li><a href="#section-3-key-criteria-for-an-error-model">Section 3</a> covers the key requirements for an error model,
and how these are justified based on the theses in Section 2.</li>
<li><a href="#section-4-an-immodest-proposal">Section 4</a> describes a hypothetical programming language Everr
and its error model.<span><label for="sn-4"></label><span>The reason for introducing a fake language
for the sake of discussion, instead of say proposing extensions
to an existing language, is that it offers a clean slate for combining
ideas across different existing languages without having to
worry about things like compatibility with existing
language features and/or idioms.</span></span></li>
<li><a href="#section-5-error-models-in-the-wild">Section 5</a> describes the error models of various existing
and upcoming programming languages.</li>
<li><a href="#section-6-everr-vs-the-world">Section 6</a> compares Everr with other languages based on the
requirements laid out in Section 3.</li>
<li><a href="#section-7-closing-thoughts">Section 7</a> concludes with some questions for you, an unorthodox choice
to introduce two new terms, a potpourri of metaphors, and some fluffy exhortations.</li>
</ul>
<p>For the die-hard <del>fans</del> readers, there is also an <a href="#appendix">Appendix</a> with 7 sections.</p>
<p>To this end, this post is fairly large, clocking in at 15K+ words
at the time of writing. You have been warned.</p>
<p>Still here? Let’s get started.</p>
<h2 id="section-1-key-definitions">Section 1: Key definitions</h2>
<p>For the sake of this post, I’m going to use the following definitions:</p>
<p><strong>Error</strong>: I’ll use this term in two ways:</p>
<ul>
<li>A program state that is undesirable or non-ideal in some way.</li>
<li>A value reifying an undesirable program state into something
that can be operated upon by the language’s constructs.
For example, errors may be represented as error codes (in C),
exceptions (in Java), <code>error</code> values (in Go), a <code>Result::Err</code> case
(in Rust) and so on. This value may or may not have some
<strong>metadata</strong> attached, such as a stack trace or some indicator
of progress made before hitting the error.</li>
</ul>
<p><strong>Error propagation</strong>: The act of passing an error received from
a function that was called to one’s own caller. During error propagation
one might want to attach more metadata, release some resources etc.</p>
<p><strong>Error handling</strong>: The act of inspecting an error value
and/or its metadata, and making some decision based on that.
For example, one might decide to log the error, propagate it,
discard it, or convert it to a different form.</p>
<p><strong>Error model</strong>: The overall system for representing, creating,
propagating, and handling errors in a programming language,
including best practices and common idioms.</p>
<p>In common parlance, this is just called “error handling”,
but it’s always felt a bit weird to me that seemingly very
different actions like declaring, propagating and inspecting
errors would get lumped together under “handling”. So I’m
borrowing this term from Duffy’s blog post instead.</p>
<p><strong>Exhaustive</strong>: An error (type) is said to be exhaustive when all
the possible data for that error is known up-front.
For example, conversion from an <code>Int64</code> value to a <code>UInt32</code>
value will only fail in a couple of ways: either the
value is negative, or it exceeds <code>2<sup>32</sup> - 1</code>.
Thus, such a conversion operation supports recording
an exhaustive error in case of failure.
In contrast, errors types from external systems,
such as third-party APIs, are typically non-exhaustive.</p>
<p>Exhaustiveness has two axes: fields and cases.<span><label for="sn-5"></label><span>I’m deliberately avoiding a discussion on records vs variants (or structs vs enums/tagged unions, or classes vs case classes) here; more on that in later sections.</span></span></p>
<hr>
<p>Hopefully, none of the above are too controversial.
Let’s keep moving.</p>
<h2 id="section-2-key-theses">Section 2: Key theses</h2>
<p>The rest of this post is going to be based on a few key theses:</p>
<ol type="1">
<li>Whether a program state is an error or not is contextual.</li>
<li>Whether an error can be recovered from or not is sometimes contextual.</li>
<li>Errors need to be able to carry metadata.</li>
<li>Robust error handling sometimes requires detailed understanding of possible error cases.</li>
<li>Errors and metadata in unstructured form are difficult to handle reliably.</li>
<li>Programs typically need to handle both exhaustive and non-exhaustive errors.</li>
<li>Programmers mostly operate with incomplete knowledge about errors.</li>
</ol>
<p>Let’s dig in to each of these one-by-one.</p>
<h3 id="thesis-1-whether-a-program-state-is-an-error-or-not-is-contextual">Thesis 1: Whether a program state is an error or not is contextual</h3>
<p>Let’s consider the classic example of opening a file.
You have some code trying to open a file and that file is not found.
Is that an error? Well, it depends!</p>
<p>For example, say you are writing a CLI application
that is doing a recursive lookup for a configuration file in ancestor
directories from the working directory.</p>
<p>Instead of first checking if the file exists
(e.g.&nbsp;using <a href="https://man7.org/linux/man-pages/man2/stat.2.html"><code>stat(2)</code></a> on Linux)
and then opening the file,
you write your code to open the file directly.<span><label for="sn-6"></label><span>You do this because the existence check + open strategy can still fail at the open stage with a ‘File not found’ error if some other process deleted the file in the middle of your operations.</span></span>
However, in this case, the file opening operation not succeeding
with a ‘File not found’ is not undesirable or incorrect in some way,
i.e., it is not an error, but it is part of normal operation.</p>
<p>Now consider the situation where the path to the
configuration file is obtained via a command-line argument.
In this case, if you get a ‘File not found’ error when opening the file,
it’s likely that the user made a mistake when providing
the command-line argument, so it would make sense to surface
the ‘File not found’ to the user.</p>
<h3 id="thesis-2-whether-an-error-can-be-recovered-from-or-not-is-sometimes-contextual">Thesis 2: Whether an error can be recovered from or not is sometimes contextual</h3>
<p>Some common examples of programming bugs that are often considered
as non-recoverable in the context of application languages
are out-of-bounds array accesses, unwrapping optionals
(or nil/null dereference) and out-of-memory – these are all
listed in the Swift docs and Joe Duffy’s blog post as examples.</p>
<p>Rust RFC 236 categorizes errors into three distinct types:
catastrophic errors, contract violations and obstructions.
Out of these, out-of-memory is considered as a catastrophic error,
whereas index out of bounds is considered a contract violation.<span><label for="sn-7"></label><span>Yes, I understand that this is a conventions RFC and that individual libraries may deviate from the conventions if they have a different set of needs. However, conventions strongly affect the design of language features and standard library APIs, so I think it’s worth discussing this here as well.</span></span>
For both of these, the RFC states that
“The basic principle of the conventions is that:
Catastrophic errors and programming errors (bugs) can and should only
be recovered at a coarse grain, i.e.&nbsp;a task boundary.”</p>
<p>I think it’s important to recognize that even for these errors,
the recoverability is contextual.
For example, in video game code, if there is an off-by-one error
in some rare cases in collision detection or lighting,
it’s possible that the game still works mostly fine,
and that’s good enough.</p>
<p>For out-of-memory in a web server, you may want to limit
the amount of memory a single task can consume,
to prevent the whole server from being terminated
when the server process runs out of memory.</p>
<p>Even if you don’t have per-request limits,
it’s possible that you breach the process-wide memory limit
<em>outside</em> of the context of a particular
task handling some request or background work.
If the server has the opportunity to recover from this,
it might be OK to shed load by
terminating the tasks for a few requests
(e.g.&nbsp;if they don’t use global state,
or only use it in a limited way that allows cleanup)
instead of terminating the entire process.</p>
<p>To be clear, I’m not saying that such examples represent
the majority of cases.
However, my point is that even for cases which <em>seem</em>
relatively cut-and-dry, there are situations where
the classification of an error into recoverable/non-recoverable
is not clear cut.</p>
<h3 id="thesis-3-errors-need-to-be-able-to-carry-metadata">Thesis 3: Errors need to be able to carry metadata</h3>
<p>Once code grows beyond a certain scale, understanding errors requires
collecting metadata about where/what/when/how/why. For example,
in a web server, you might care about tracking the following:</p>
<ul>
<li>A stack trace for the place where the error was originally created.</li>
<li>Severity of the error.</li>
<li>For data validation errors such as in validating JSON,
some ‘path’ within the larger structure
(at the time of the error),
as well as the value of the unexpected portion.</li>
<li>Retryability of operations, such as DB transactions or
<a href="https://grpc.io/docs/guides/retry/">RPC calls</a> in a framework like gRPC.</li>
</ul>
<p>Additionally, one needs to be able to have some logic
that can make use of this metadata (e.g.&nbsp;as methods on an error type,
if the language supports methods in some form),
such as something for generating key-value pairs for observability,
computing equality/hashes for checking sameness etc.</p>
<p><strong>Corollary</strong>: Error codes as the primary language-supported way
of error handling are inadequate for many use cases
(see also: <a href="https://github.com/ziglang/zig/issues/2647">Zig issue #2647 - Allow returning a value with an error</a>).</p>
<h3 id="thesis-4-robust-error-handling-sometimes-requires-detailed-understanding-of-possible-error-cases">Thesis 4: Robust error handling sometimes requires detailed understanding of possible error cases</h3>
<p>In <a href="https://dataintensive.net/"><em>Designing Data-Intensive Applications</em></a>, Martin Kleppman gives an excellent example of database transactions and retryability:</p>
<blockquote>
<p>popular object-relational-mapping (ORM) frameworks [..] don’t retry aborted transactions [..]. This is a shame, because the whole point of aborts is to enable safe retries.</p>
<p>Although retrying an aborted transaction is a simple and effective error handling mechanism, it isn’t perfect:</p>
<ul>
<li>If the transaction actually succeeded, but the network failed while the server tried to acknowledge the successful commit to the client [..], then retrying the transaction [is unsound without extra app-level de-duplication]</li>
<li>If the error is due to overload, retrying the transaction will make the problem worse [..]</li>
<li>It is only worth retrying after transient errors ([..] deadlock, isolation violation, temporary network interruptions, and failover); after a permanent error (e.g.&nbsp;constraint violation) a retry would be pointless</li>
</ul>
</blockquote>
<p>For a library or framework which provides APIs for interacting with a SQL database,
it is necessary to be able to distinguish the various cases of network errors and database errors
if it wants to support automatic retries for aborted transactions.</p>
<p>Of course, not all error handling needs this level of rigor in analyzing the various cases.
Depending on the context,
it might be OK to just log an error and keep going
if one is confident that
it won’t negatively impact the overall system.</p>
<p><strong>Corollary</strong>: An API specification language should probably
discourage hiding error information from return values
(see also: GraphQL’s <a href="https://graphql.org/learn/response/#request-errors">default machinery for error handling</a>).</p>
<h3 id="thesis-5-errors-and-metadata-in-unstructured-form-are-difficult-to-handle-reliably">Thesis 5: Errors and metadata in unstructured form are difficult to handle reliably</h3>
<p><img src="https://i.imgflip.com/9m5w3n.jpg" alt="Anakin and Padme meme. Anakin: I like using domain-specific types for return values. Padme: (smiling) For both success and failure, right? Anakin gives a blank stare. Padme (concerned): For both succcess and failure, right?"></p>
<p>I imagine this point is probably the least controversial.</p>
<p>Stuffing error case information and metadata into strings
makes an API harder to use for a client which cares about
error handling.</p>
<p>If you expose an API where the only way a conscentious user
can extract more data for an error is by parsing a string,
they’re going to write that error parser,
and all the options when you want to
change that error message are going to suck.
(see also: <a href="https://www.hyrumslaw.com/">Hyrum’s Law</a>).</p>
<p><strong>Corollary</strong>: A standard library should probably not encourage
people to easily attach arbitrary data to errors in a way that
cannot be recovered later (see also: Go’s <a href="https://pkg.go.dev/fmt#Errorf"><code>fmt.Errorf</code></a>
function which implicitly encourages users to create unstructured errors**.</p>
<h3 id="thesis-6-programs-typically-need-to-manage-both-exhaustive-and-non-exhaustive-errors">Thesis 6: Programs typically need to manage both exhaustive and non-exhaustive errors</h3>
<p>When a part of a program does not interact with any external systems,
but behaves like a pure function with a
well-understood set of possible behaviors,
using exhaustive error types allows one to model this certainty.</p>
<p>On the other hand, when interacting with external systems which
may change in the future, such as third-party APIs across a network,
OS APIs, databases etc., the program needs a way to model
and handle errors where all the cases and fields are not known up front.
In such situations, ideally, the addition of new error cases and/or fields
should not break existing third-party clients at a source level,
and lead to some reasonable dynamic behavior.</p>
<h3 id="thesis-7-programmers-mostly-operate-with-incomplete-knowledge-about-errors">Thesis 7: Programmers mostly operate with incomplete knowledge about errors</h3>
<p>Outside of safety critical contexts,
I think it’s fair to say that for most production systems,
most people working on them (myself included) have a fairly limited
picture of all the different things that could go wrong.</p>
<p>I suspect this is probably true even if one limits the scope
to just the situations where the underlying APIs are written
by oneself and just involve pure (but complex) computation,
as well as situations where all the inputs and system parameters
are within “acceptable” ranges.</p>
<p>To be clear, I mean this as an observation and not as a value judgement
– I think there are various contributing reasons for this;
competing priorities, high system complexity, poor docs,
minimal language/tooling support and perhaps even optimism.<span><label for="sn-8"></label><span>For more discussion on optimism specifically, see <a href="#appendix-a7-optimism">Appendix A7</a>.</span></span>
Discussing this more would probably take a full blog post or more by itself,
so I’m going to stop there.</p>
<h2 id="section-3-key-criteria-for-an-error-model">Section 3: Key criteria for an error model</h2>
<p>Based on the above theses and my personal experience, I believe
that an error model should be judged based on how well it
satisfies the following key criteria.<span><label for="sn-9"></label><span>If these sound a bit too abstract, I’ll be discussing them in more detail shortly.</span></span></p>
<ul>
<li><p>Error declarations must support:</p>
<ul>
<li><p><strong>Exhaustiveness annotation</strong>: The ability to mark a declaration
as being exhaustive (or not). This must support both axes: fields and cases.</p></li>
<li><p><strong>Case extension</strong>: The ability to extend errors with new cases
(at the declaration site itself) in a backward-compatible way,
if the error was declared to be non-exhaustive in terms of cases.</p></li>
<li><p><strong>Field extension</strong>: Analogous to the above but for fields.</p></li>
<li><p><strong>Case refinement</strong>: The ability to refine previously defined cases
into more fine-grained cases over time
(at the declaration site itself) in a backward-compatible way.</p></li>
</ul></li>
<li><p>Error propagation must support:</p>
<ul>
<li><p><strong>Explicit marking</strong>: The ability<span><label for="sn-10"></label><span>The choice of the word “ability” is intentional. Using an explicit marking discipline may or may not be the default, and may or may not be conventional, but following it must be possible.</span></span> to force code to be written
in a way such that:</p>
<ol type="1">
<li>Possible errors from primitive operations are indicated with explicit marks.</li>
<li>Propagating errors from an invoked operation to one’s own caller requires
an explicit mark.</li>
</ol>
<p>The absence of explicit marks must cause a localized static error.</p></li>
<li><p><strong>Structured metadata attachment</strong>: The ability to attach structured metadata
to an error. Attaching metadata must preserve the fact that the error
is still an error.</p></li>
<li><p><strong>Error combination</strong>: The ability to combine errors into a larger error.</p></li>
<li><p><strong>Erasure</strong>: The ability to abstract fine-grained errors into more
coarse-grained errors.</p></li>
</ul></li>
<li><p>Error handling must support:</p>
<ul>
<li><p><strong>Exhaustiveness checking</strong>:<span><label for="sn-11"></label><span>This needs to correctly account for access control rules. For example, in Rust, the <a href="https://doc.rust-lang.org/reference/attributes/type_system.html#the-non_exhaustive-attribute"><code>#[non_exhaustive]</code></a> attribute has no effect within the same crate.</span></span> For errors declared to be exhaustive,
the ability to match exhaustively against all cases.</p>
<p>Non-exhaustive matches for exhaustive errors must be diagnosed statically.</p>
<p>Additionally, for non-exhaustive errors, attempting an exhaustive match
against the known cases must be diagnosed statically.</p></li>
<li><p><strong>Structured metadata extraction</strong>: The ability to extract structured metadata
attached to an error (the dual of Structured metadata attachment).</p></li>
<li><p><strong>Error projection</strong>: The ability to inspect individual sub-errors out of a combined error (the dual of Error combination).</p></li>
<li><p><strong>Unerasure</strong>: The ability to unerase fine-grained information out of coarse-grained errors (the dual of Erasure).</p></li>
</ul></li>
</ul>
<ul>
<li><p>Criteria for error conventions:</p>
<ul>
<li><p><strong>Error category definitions</strong>: Different categories of errors
must be documented, so that the ecosystem can rely on centralized definitions.
These must be accompanied by examples of
when an error should be put in a certain category,
and when it may be considered as part of another category.</p></li>
<li><p><strong>Guidelines on error definitions</strong>: These should cover what ought to be
documented, which annotations should be considered and/or avoided,
as well as considerations for downstream users of libraries.</p></li>
<li><p><strong>Guidelines on error propagation</strong>: These should cover when it is appropriate
to return errors that are erased vs unerased.</p></li>
<li><p><strong>Guidelines on error handling</strong>: These should cover when it is and
is not appropriate to handle errors within and across library boundaries.</p></li>
</ul>
<p>Guidelines should generally be accompanied by rationale, as well as curated lists
of potential reasons to deviate from the guidelines.</p></li>
<li><p>Criteria for tooling:</p>
<ul>
<li><p><strong>Lint support</strong>: Certain classes of errors are likely best avoided through
lints/style checkers, rather than type system features.</p>
<ol type="1">
<li><p>(Important) A lint that prevents error values from being discarded using
standard shorthands (e.g.&nbsp;<code>_ = &lt;expr&gt;</code>), without an explicit annotation,
such as a comment or a call to an earmarked function
(to allow for ‘Find references’) etc.</p></li>
<li><p>(Nice-to-have) If exhaustiveness of cases/fields is the default at the
language level, then a lint to require manual exhaustiveness annotations
on every type.</p></li>
<li><p>(Nice-to-have) A lint for enforcing that fields and cases of error types
must be documented.</p></li>
</ol></li>
<li><p><strong>Editing support</strong>:</p>
<ol type="1">
<li>(Important) A structured flow for adding new error cases and fields.
The editing environment should identify locations which potentially
need changes – these will generally be locations which materialize
or handle errors of the same type.</li>
</ol></li>
</ul></li>
</ul>
<p>For each of these criteria, the following sub-sections
describe why they are useful.</p>
<h3 id="criteria-for-error-declarations">Criteria for error declarations</h3>
<p>Exhaustiveness annotation is necessary because of <a href="#thesis-6-programs-typically-need-to-manage-both-exhaustive-and-non-exhaustive-errors">Thesis 6</a> -
typical programs need to work with both exhaustive and non-exhaustive errors.
This should probably take the form of an <em>annotation</em> or similar, rather than two
entirely different type system features (e.g.&nbsp;subclasses for the non-exhaustive case
vs standard sum types for the exhaustive case), because:</p>
<ol type="1">
<li>It is possible for a non-exhaustive error to become exhaustive (if the underlying API stops evolving)</li>
<li>The small “conceptual diff” would probably be best reflected as a small syntax diff in code, rather than an entirely different way of organizing the program.</li>
</ol>
<p>Once one accepts that non-exhaustive errors are permitted,
for such errors to be usable across project boundaries,
it naturally follows that the language must support
adding new cases and fields to a non-exhaustive error type
without breaking source-level backward compatibility.</p>
<p>Lastly, when an API developer gains more knowledge<span><label for="sn-12"></label><span>Recall <a href="#thesis-7-programmers-mostly-operate-with-incomplete-knowledge-about-errors">Thesis 7</a> - Programmers mostly operate with incomplete knowledge about errors.</span></span> about a previously
broad error case, they need a way of communicating that to new clients without breaking
existing clients. This requires some way of expressing “this one case is now actually N other cases, where N &gt;= 2”
which is exactly how I described case refinement.</p>
<h3 id="criteria-for-error-propagation">Criteria for error propagation</h3>
<p>The ability to force code to be written using explicit marks for error
handling is valuable because it enables modular reasoning about control
flow and error handling, one function at a time.</p>
<p>Even if a programmer is able to magically keep track of which functions
can silently return which errors in their head,
they may stop working on the codebase,
and the next programmer working on the code
will need assistance in gradually assembling
a <a href="https://ingenieria-de-software-i.github.io/assets/bibliografia/programming-as-theory-building.pdf">new theory of the codebase</a>
they’ve inherited.</p>
<p>The ability to attach structured metadata is valuable because not all
errors can be described by simple primitive values,
and often, it is necessary to have contextual information
in order to debug why an error occurred
(e.g.&nbsp;where in the JSON file is there a missing <code>,</code> again, goddammit).</p>
<p>The ability to combine errors is valuable in the same way
that collections like arrays, sets and maps are valuable.</p>
<p>The ability to erase errors is valuable since not all code cares about
the details of an error. For example, code inside a supervisor task/process
might potentially only care about how to log an error.</p>
<h3 id="criteria-for-error-handling">Criteria for error handling</h3>
<p>Exhaustiveness checking is valuable because it provides clarity
that all cases have been handled. However, in some cases,
it is impossible to have that clarity, since:</p>
<ul>
<li>One might not have sufficient time to understand and analyze
all the cases.</li>
<li>If the error comes from a dependency:
<ul>
<li>One might be unable to change the code in the dependency</li>
<li>One might be unable to replace the dependency</li>
<li>One might not want to (or potentially, cannot)
lock to a certain version of the dependency.</li>
</ul></li>
</ul>
<p>This means that non-exhaustive errors must also get proper
treatment during exhaustiveness checking.</p>
<p>Features like structured metadata extraction,
error projection, and recovery are needed because
their corresponding duals only make sense when used
in concert with them.</p>
<hr>
<p>Now that we’ve covered a fair bit of ground related to error models themselves,
let’s switch gears and talk about what a language design
grounded in these observations could look like.</p>
<h2 id="section-4-an-immodest-proposal">Section 4: An immodest proposal</h2>
<p>I’m going to describe an error model in terms of a hypothetical
systems language Everr (“<strong>Ev</strong>olving <strong>err</strong>ors”)
and its ecosystem.
I’ll demonstrate Everr using examples.<span><label for="sn-13"></label><span>Normally, I’d hope that this is understood, but since this is the internet, I’m going to spell this out explicitly; the concrete syntax being used here is not the point. This is a language I literally just made up to illustrate some concepts.</span></span>
After that, we’ll see how well Everr’s error model compares
to existing mainstream languages with respect to the criteria
outlined in the previous section.</p>
<p>Here’s a rough summary of Everr’s core language constructs:</p>
<ul>
<li>Everr supports semantic attributes on declarations, similar to C++, Rust, Swift etc.</li>
<li>Everr supports structs (a.k.a. records / product types) and enums (a.k.a. variants / sum types).
These can be exhaustive or non-exhaustive.
<ul>
<li>Enums are second-class, like <a href="https://capnproto.org/language.html">Cap’n Proto</a>’s (tagged) union types.
However, they support dedicated sugar making them feel essentially first-class.</li>
</ul></li>
<li>Everr supports style pattern matching using a minor variation of
Cheng and Parreaux’s <a href="https://dl.acm.org/doi/10.1145/3689746">“Ultimate Conditional Syntax”</a>.</li>
<li>Everr has simple namespaces for grouping things,
similar to namespaces in C++ and modules in Rust.
Types themselves are not namespaces.<span><label for="sn-14"></label><span>This is largely for simplifying the description here. If types were allowed to function as namespaces, (or alternately, if namespaces were allowed to have type parameters), that would necessitate different syntax for referring to “outer” generic parameters vs introducing fresh generic parameters, and we’d end up going into the weeds.</span></span></li>
<li>Everr supports union types,<span><label for="sn-15"></label><span>When I say “union types”, I mean it in the type-theoretic sense, not in the sense of untagged unions as in C, C++ etc.</span></span> but only with a mandatory upper bound.
For brevity, I’ll refer to these as “bounded union types”.
Bounded union types come in two flavors – exhaustive and non-exhaustive.</li>
<li>Everr supports a Rust-like trait mechanism as well as a trait deriving mechanism.<span><label for="sn-16"></label><span>The exact mechanism powering trait derivations – whether they be hard-coded in the compiler, be implemented as macros, compiler plugins etc. – is not terribly important for this post, so I will ignore it.</span></span></li>
<li>Everr supports a delegation mechanism for field accesses
and method calls from one type to another.</li>
</ul>
<p>First, let’s do a tour of these core language features.
After that, I’ll describe Everr’s error model.</p>
<h3 id="a-tour-of-everr">A tour of Everr</h3>
<p>Everr has an <code>Optional</code> type for representing optional values:</p>
<pre><code>@exhaustive
enum Optional[A] {
    | None {}
    | Some { value: A }
}</code></pre>
<p>This is syntax sugar for the following code:</p>
<pre><code>namespace Optional {
    // ↓ None will never have new fields
    @exhaustive(fields)
    struct None {}

    // ↓ Some will never have new fields
    @exhaustive(fields)
    struct Some[A] { value: A }
}

// ↓ Optional will never have new fields
@exhaustive(fields)
struct Optional[A] {
    // ↓ Actual enum syntax, without the sugar
    case: @exhaustive(cases) enum {
        | type Optional.None
          // ↑ refers to struct None
        | type Optional.Some[A]
          // ↑ refers to struct Some[A]
    }
}</code></pre>
<p>So <code>Some</code> and <code>None</code> represent first-class types,<span><label for="sn-17"></label><span>For comparisons with Scala’s case classes and Rust’s proposed <a href="https://github.com/rust-lang/lang-team/issues/122">enum variant types</a>, see <a href="#appendix-a1-everr-type-system-discussion">Appendix A1</a>.</span></span>
not just cases of <code>Optional</code>.<span><label for="sn-18"></label><span>This kind of design does not preclude <a href="https://www.0xatticus.com/posts/understanding_rust_niche/">niche optimizations</a>, see <a href="#appendix-a2-niche-optimizations-with-second-class-enums">Appendix A2</a>.</span></span></p>
<p><code>Optional</code> values support pattern matching:</p>
<pre><code>fn demo0(x: Optional[Str]) -&gt; Str {
    if x.case is {
       Optional.None {} -&gt; return "Got None"
       // _ represents a value being discarded
       Optional.Some { value: _ } -&gt; return "Got Some"
    } // Compiler checks exhaustiveness for:
      // 1. Cases of Optional
      // 2. Fields of None
      // 3. Fields of Some
}</code></pre>
<p>Even though pattern matching <em>looks</em> like it happens against types directly,
internally it works like tagged union types in other languages,
so exhaustiveness checking is supported,
unlike pattern matching with open class hierarchies.</p>
<p>To reduce verbosity, Everr has some syntax sugar for pattern matching.</p>
<ul>
<li>Everr supports implicit projection of the field
named <code>case</code> to provide a more familiar syntax.<span><label for="sn-19"></label><span>This is the only special case (ahem) where Everr inserts a field projection operation implicitly.</span></span></li>
<li>To allow the user to omit the type name in common cases,
Everr supports looking up namespaces
with the same name as the type, so one can use “leading dot syntax”,
similar to Swift etc.</li>
</ul>
<p>Rewriting the code using the above sugar:</p>
<pre><code>fn demo1(x: Optional[Str]) -&gt; Str {
    if x is {
        .None {} -&gt; return "Got None"
        .Some { value: _ } -&gt; return "Got Some"
    }
}</code></pre>
<p>Neat! 😃 Things get more interesting
when Everr’s non-exhaustive enums come into the mix.</p>
<pre><code>@non-exhaustive
enum Dessert {
    | Cake { icing : Str }
    | IceCream {}
}</code></pre>
<p>The above type declaration desugars to:</p>
<pre><code>namespace Dessert {
    @non-exhaustive(fields)
    struct Cake { icing : Str }

    @non-exhaustive(fields)
    struct IceCream {}
}

@non-exhaustive(fields)
struct Dessert {
    case: @non-exhaustive(cases) enum {
        | type Dessert.IceCream
        | type Dessert.Cake
    }
}</code></pre>
<p>Here’s how one might write some string conversion functions
for these types in a different project.<span><label for="sn-20"></label><span>Everr’s rules around mandatory handling of future cases and fields are similar to the behavior of Rust’s <code>#[non_exhaustive]</code> – they only apply across access control boundaries.</span></span></p>
<pre><code>fn cake_to_str(cake: Dessert.Cake) -&gt; Str {
    if cake is Dessert.Cake { icing: i, !__ } {
        i.append(" cake");
        return i
    }
}</code></pre>
<p>There are two sigils here: <code>!</code> and <code>__</code>.</p>
<p><code>__</code> means “ignore any label-value pairs, if present”.
Since <code>Cake</code> has a <code>@non-exhaustive(fields)</code> annotation,
the <code>__</code> is mandatory, similar to mandatory catch-all
clauses for cases of an enum.</p>
<p><code>!</code> means “if the next identifier matches one or more known label-value pairs,
or one or more cases, please issue a warning”.<span><label for="sn-21"></label><span>This is a generalized version of <code>@unknown</code> in Swift (<a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/statements#Switching-Over-Future-Enumeration-Cases">docs for <span data-cites="unknown">@unknown</span></a>).</span></span>
Since <code>Cake</code> has a <code>@non-exhaustive(fields)</code> annotation, if a new field is
added to it in the future, then a warning will be issued inside
<code>cake_to_str</code>.</p>
<p>This design allows the author of the type to add new
fields without breaking source-level backward compataibility,
while still allowing the user of the type to opt-in to a “notification”
when the type definition changes.</p>
<p>Using the above function, one can write a function to convert
a <code>Dessert</code> to a string.</p>
<pre><code>fn dessert_to_str(d: Dessert) -&gt; Optional[Str] {
    if d is Dessert { case: dcase, !__ }
       and dcase is {                        // (1)
        .Cake c -&gt;
            return .Some { value: cake_to_str(c) }
        .IceCream { __ } -&gt;
            return .Some{value: "ice cream"} // (2)
        !_ -&gt; return .None{}                 // (3)
    }
}</code></pre>
<p>I know there’s a lot going on in the above code example,
so let’s take it step-by-step.</p>
<pre><code>    if d is Dessert { case: dcase, !__ }
       and dcase is {                        // (1)</code></pre>
<p>There are a few things going on here:</p>
<ul>
<li><p><code>dcase</code> is a new binding for the <code>case</code> field of <code>d</code>.
It is immediately matched on again after <code>and</code>,
using the aforementioned Ultimate Conditional Syntax.</p></li>
<li><p>The <code>__</code> matches the rest of the fields not covered by the pattern,
and their values are ignored.
Omitting <code>__</code> would trigger a compiler error,
since <code>Dessert</code> is a non-exhaustive struct.</p>
<p>Alternately, if one didn’t care about a new field being
added to <code>Dessert</code>, then one could directly use <code>if d.case is</code>.</p></li>
<li><p>Due to the <code>!</code>, the compiler will issue a warning
if the <code>__</code> matches one or more fields,
similar to the logic in <code>cake_to_str</code>.</p></li>
</ul>
<p>Let’s look at the branch (2):</p>
<pre><code>        .IceCream { __ } -&gt;
            return .Some{value: "ice cream"} // (2)</code></pre>
<p>Here again, <code>__</code> means that future fields are being ignored.
The absence of <code>!</code> means that this code will not issue any
warnings if the <code>IceCream</code> type has new fields in the future.</p>
<p>Lastly, since <code>d.case</code> has a non-exhaustive enum type,
a catch-all pattern is mandatory:</p>
<pre><code>        !_ -&gt; return .None{}                 // (3)</code></pre>
<p><code>_</code> means “ignore a single value” similar to other languages.
Due to the <code>!</code>, this line will trigger a compiler warning
if one or more new cases are added to <code>Dessert</code>.</p>
<p>Whew, that was a lot! Here’s an XKCD for a short break.</p>
<p><img src="https://imgs.xkcd.com/comics/in_the_trees.jpg"></p>
<p>Let’s continue. Suppose we have two people Alice and Bob
and we want to write two functions to describe which desserts
they like, in the same project as <code>Dessert</code>.<span><label for="sn-22"></label><span>If it were in a different project, the initialization syntax would not be available for non-exhaustive types.</span></span>
Here are their preferences:</p>
<ul>
<li>Alice likes cake with ganache on top, and also ice cream, but Alice is not open
to trying new desserts.</li>
<li>Bob likes cake with buttercream on top not ice cream. However,
Bob is open to trying new desserts if there are more options in the future.</li>
</ul>
<p>These preferences can be modeled using Everr’s bounded union types.</p>
<p>First, let’s model Alice’s preference.</p>
<pre><code>pub fn alice_likes() -&gt; Array[Dessert:union[.Cake | .IceCream]] {
    return Array.new(
        .Cake{icing: "ganache"},
        .IceCream{},
    )
}</code></pre>
<p>Here, <code>Dessert:union[.Cake | .IceCream]</code> represents an exhaustive (bounded) union type. It implies that values of types <code>Cake</code> and <code>IceCream</code> are allowed, and in the future, even if <code>Dessert</code> gains new cases, those will not be returned. Similar to exhaustive enums, if a caller tries to pattern match on the union value, they can match exhaustively, without needing a catch-all pattern.</p>
<p>Now let’s model Bob’s preference.</p>
<pre><code>pub fn bob_likes() -&gt; Array[Dessert:union+[.Cake]] {
    return Array.new(.Cake{icing: "buttercream"})
}
</code></pre>
<p>Here <code>Dessert:union+[.Cake]</code> represents a non-exhaustive (bounded) union type. It implies that only values of type <code>Cake</code> are allowed, but in the future, other cases of the top type – in this case, <code>Dessert</code> – may also appear. Similar to non-exhaustive enums, if a caller tries to pattern match on the union value, they must account for new cases being added (including <code>IceCream</code> if Bob changes his mind).</p>
<p>The exhaustiveness of a union type only applies to its cases. When pattern matching, one still needs to be explicit about handling unknown fields (using <code>__</code> or <code>!__</code>) since both <code>Cake</code> and <code>IceCream</code> have <code>@non-exhaustive(fields)</code>.</p>
<hr>
<p>Since enum cases have first-class struct types, different enums can share cases.</p>
<pre><code>enum BakeryItem {
    | Bread {}
    | type Dessert.Cake // OK
}</code></pre>
<p>This allows reuse of case types without needing to copy the case definition.</p>
<hr>
<p>Everr supports traits and trait derivations.
Everr has a built-in <code>UpCast</code> trait meant to represent O(1) conversions
from enum cases to a type containing the enum.</p>
<pre><code>trait UpCast[From, To] {
    fn up_cast(_: From) -&gt; To
}</code></pre>
<p>This trait is automatically implemented for enum cases.
So you’d have:</p>
<pre><code>impl UpCast[Dessert.Cake, Dessert] { ... }
impl UpCast[Dessert.IceCream, Dessert] { ... }

impl UpCast[BakeryItem.Bread, BakeryItem] { ... }
impl UpCast[Dessert.Cake, BakeryItem] { ... }</code></pre>
<p>Similar to interfaces in other languages, these can also be implemented by hand.</p>
<hr>
<p>Lastly, Everr supports a delegation mechanism across types.
For example, if you have code like:</p>
<pre><code>struct BakeryProduct {
    @delegate
    base: BakeryItem
    ingredients: Array[Ingredient]
    price: Money
}</code></pre>
<p>At usages of the <code>.</code> operator for field access and method calls
on a <code>BakeryProduct</code> value, the compiler first checks if
<code>BakeryProduct</code> has the field or method, and if not,
checks if <code>BakeryItem</code> has the field or method.</p>
<p>At most one field can have a <code>@delegate</code> annotation to maintain
predictability in the face of field re-ordering without needing
ad-hoc tie-breaking rules.</p>
<p>Because cases are represented through a special <code>.case</code> field,
pattern matching directly on a <code>BakeryProduct</code> value will work,
because <code>BakeryItem</code> has a <code>.case</code> field which allows pattern-matching.</p>
<hr>
<p>Okay, that concludes the tour of Everr’s core language features!
Now let’s talk about Everr’s error model.</p>
<h3 id="everrs-error-model---overview">Everr’s error model - Overview</h3>
<p>Everr’s error model is based on the core observation that the
handling and recovery from different errors is generally
context-dependent, so it provides flexibility and broad mechanisms
for different error handling strategies in different contexts.</p>
<p>There are two modes for error propagation and handling.</p>
<ul>
<li>Fail-slow error handling: This is done using the standard <code>Result</code> type,
which is an exhaustive enum equivalent to that in Rust and Swift.</li>
<li>Fail-fast error handling: This comes in two flavors:
<ul>
<li>Recoverable: This is done using <code>panic</code> and <code>catch panic</code>
primitives, similar to <code>panic</code>/<code>recover</code> in Go and
<code>panic!</code>/<code>catch_unwind</code> in Rust. Panicking and panic catching themselves
use memory pre-allocated at program startup to avoid out-of-memory
in the middle of a panic,
while accepting the risk of potentially needing to discard
some relevant data.</li>
<li>Non-recoverable, i.e.&nbsp;program termination. This is done using an
<code>exit</code> primitive.</li>
</ul></li>
</ul>
<p>OS signals are handled using callbacks and potentially
manifested using one of the above depending on the exact signal
and configuration.</p>
<p>Notably, there is no support for asynchronous termination of non-cooperative tasks
via asynchronous exceptions, such as that in Haskell, OCaml or Erlang.</p>
<p>For primitive operations, the defaults are as follows:</p>
<ul>
<li>Numeric operations on bounded integer types panic on failure,
prioritizing safety over performance.</li>
<li>Assertion failures trigger a panic.</li>
<li>Out-of-memory for the heap aborts the program.</li>
<li>Stack overflow aborts the program.</li>
</ul>
<p>However, these can be customized; more details on each of them soon.</p>
<p>One important aspect on how Everr code negotiates what is and is not allowed,
is through the designation of certain core language features as <em>capabilities</em>.
Examples of capabilities include heap allocation, panicking,
program termination and foreign function interface (FFI) usage.</p>
<p>Capabilities manifest at the boundaries of packages,
which are Everr’s units of distribution.
Each package has a manifest file, which supports specifying:</p>
<ul>
<li><p>The capabilities used by the given package, in addition to the defaults.
Each capability has three levels (other than <strong>Unavailable</strong>):</p>
<ul>
<li><p><strong>Implicit</strong>: All code is granted access to the capability, without needing
any annotation.</p></li>
<li><p><strong>Explicit</strong>: Code which uses the capability must have an explicit annotation.</p></li>
<li><p><strong>Binding</strong>: Code which uses the capability must have an explicit annotation,
and this annotation is considered part of the API contract;
weakening the annotation is considered a breaking change.</p>
<p>One can optionally configure the standard linter to enforce that
functions which do not use the capability also have an explicit annotation
indicating that the function is guaranteed to not use the capability
in the future or that it reserves the right to use the capability later on.</p></li>
</ul></li>
<li><p>The capabilities permitted for different dependencies.</p></li>
</ul>
<p>If that sounds a bit too abstract, don’t worry,
I’ll explain the capability system later with examples.</p>
<p>First, let’s discuss fail-slow and fail-fast error handling.</p>
<h3 id="fail-slow-error-handling">Fail-slow error handling</h3>
<p>For very basic operations where only a single failure is possible,
(e.g.&nbsp;a map lookup), the failure is exposed using the standard <code>Optional</code> type.
In most other cases, either the <code>Result</code> or <code>Hurdle</code> types are used.<span><label for="sn-23"></label><span><code>Result</code> and <code>Hurdle</code> are recognized specially by the standard Everr
linter, which issues warnings if <code>_</code> is used to ignore the <code>Fail</code> case the <code>problem</code> field.</span></span></p>
<pre><code>// Result represents computations where errors block progress.
//
// Most commonly used for short-circuiting logic.
@exhaustive
enum Result[A, E] {
    | Pass { value: A }
    | Fail { error: E }
}

// Hurdle represents computations where problems do not
// block progress, but they still need to be bubbled up,
// such as in the form of warnings.
@exhaustive
struct Hurdle[A, E] {
    data: A
    problem: E
}</code></pre>
<p>For the <code>E</code> type parameter, Everr programmers are recommended
to use domain-specific struct and enum types which define errors.
Since both enums and structs support exhaustiveness annotations,
it is easy to mark error types for future evolution.</p>
<p>Since enums are desugared to structs:</p>
<ul>
<li>It is possible to add a field common to all cases of an enum,
without breaking source-level backward compatibility.</li>
<li>It is possible to refine a coarse case into multiple sub-cases
by adding a <code>case: enum { ... }</code> field to the corresponding case.</li>
</ul>
<p>For example, say one has a float parsing function which returned
an error with the following type:</p>
<pre><code>@exhaustive(cases)
enum FloatParseError {
    | UnexpectedChar { byte_offset: UInt64 }
    | NotRepresentable {}
}</code></pre>
<p>Since this is marked specifically as being <code>@exhaustive(cases)</code>,
it means that adding new fields is allowed without it being
considered a breaking change.</p>
<p>One could add a field to the <code>NotRepresentable</code> case, and refine it,
without breaking backward compatibility:</p>
<pre><code>@exhaustive(cases)
enum FloatParseError {
    | UnexpectedChar { byte_offset: UInt64 }
    | NotRepresentable {
        // Represents the lower bound on the number of bits
        // that would be needed for a floating point type
        // to be able to represent the given value.
        min_bits_needed: UInt64
        case: @exhaustive enum {
            | TooSmall {}
            | TooLarge {}
        }
    }
}</code></pre>
<p>Once the type is refined, both of these forms of pattern-matching work.</p>
<pre><code>if err is {
    .UnexpectedChar { .. } -&gt; ..
    .NotRepresentable { __ } -&gt; ..
}
// or more fine-grained
if err is {
    .UnexpectedChar { .. } -&gt; ..
    .NotRepresentable nr and nr is {
        .TooSmall {} -&gt; ..
        .TooLarge {} -&gt; ..
    }
}</code></pre>
<p>Case refinement in Everr provides optionality without a-priori
factoring out enum definitions into separate enum and case struct
definitions, unlike typical languages in the ML family.
The cost of additional verbosity is paid when refinements are introduced.</p>
<hr>
<p>Errors can be propagated using a <code>try</code> operator,
which can be used at different granularities.
– it can be used for one-or-more statements,
or for a specific (tree of) expressions,
including individual call expressions.</p>
<pre><code>enum ABCError {
    | type SubError1
    | type SubError2
    | type SubError3
    | type SubError4
}

fn abc() -&gt; Result&lt;Int, ABCError&gt; {
    try {
        sub_op1(...)
        sub_op2(...)
    }
    let a = try sub_op3(...).some_method(...)
    let b = sub_op4(a).@try
    return ok(b.other_method())
}</code></pre>
<p><code>try</code> allows for a single level of automatic conversion of errors,
via the previously mentioned <code>UpCast</code> trait.
This is similar to <code>?</code> and <code>Try</code> in Rust.</p>
<p>Everr programmers are encouraged to define and use structured error types,
and attach metadata to errors by defining new struct fields.
Structs can be easily serialized
using the same mechanism as for trait derivation,
with minimal boilerplate.
This integrates well with observability libraries such as those
providing APIs for structured logging and tracing.</p>
<p>The Everr language server has a code action for defining error types for a given
function based on the error types of the functions that are called.
It also can intelligently suggest modifications to error cases
as the function body evolves over time, taking contextual rules such
as access control into consideration.</p>
<p>The Everr standard library exposes a standard type for call traces.<span><label for="sn-24"></label><span>A call trace covers different kinds of traces such as a stack trace, <a href="https://ziglang.org/documentation/master/#Error-Return-Traces">Zig-style error return trace</a>, as well as <a href="https://rust-lang.github.io/wg-async/design_docs/async_stack_traces.html">async stack traces</a>. While these are all recorded differently, they fall under the same concept (sequence of source code locations which describe “how did we get here”).</span></span></p>
<p>Even though the use of structured errors is encouraged,
the Everr standard library provides APIs for working
with unstructured errors.</p>
<ul>
<li>An <code>AnyErrorContext</code> type which exposes convenient APIs for:
<ul>
<li>Attaching key-value pairs.</li>
<li>Capturing and recording call traces.</li>
</ul></li>
<li>An <code>AnyError</code> type which pairs an error value along with an <code>AnyErrorContext</code> and zero-or-more child <code>AnyError</code> values (similar to <code>error</code> in Go). This exposes convenient APIs for:
<ul>
<li>Initialization from a specific struct/enum error type.</li>
<li>Merging several sub-errors into a larger error.</li>
<li>Tree traversal and inspection.</li>
</ul></li>
</ul>
<h3 id="fail-fast-error-handling">Fail-fast error handling</h3>
<p>Recoverable fail-fast error handling is done via panics,
which are similar to unchecked exceptions in languages like Java and C++.</p>
<p>Function declarations and types can optionally be annotated with a
<code>@panics</code> attribute which covers whether the function might panic,
it might panic when compiled in development mode
(but never in release mode), or never at all.</p>
<p>Panicking is a capability.
The default capability level for panicking is Implicit, so most
packages do not use <code>@panics</code> annotations.</p>
<p>For packages compiled with Explicit or Binding level for panic marking,
the Everr compiler checks if a function’s <code>@panics</code> annotation
(or lack thereof) matches with the annotations on other
functions that are called by it.</p>
<p>The standard linter recognizes functions with <code>@panics</code> annotations
and recommends adding a section to the function’s API docs
describing when the function might panic.</p>
<p>For the Binding level in particular, the standard linter
has an optional lint requires explicit <code>@panics(maybe)</code>
or <code>@panics(never)</code> annotations on all functions,
to avoid accidental API additions without <code>@panics</code>
annotations (which would prevent the implementation
from using assertions).</p>
<p>The Everr core libraries, including the standard library, use Explicit
panic marking.</p>
<p>A small portion of the Everr ecosystem, chiefly some minimal alternatives
to the standard library and related packages meant to be used in the
context of embedded systems, default to using the Binding level for panic marking.</p>
<p>Similar to panicking, program termination using the <code>exit</code> primitive
is treated as a capability; it has a matching <code>@exits</code> attribute.</p>
<p>However, unlike panicking, the default level for the termination capability
is Explicit, as it is fairly rare to require it in library code.</p>
<h3 id="primitives---bounded-integer-operations">Primitives - Bounded integer operations</h3>
<p>In Everr, numeric operations on bounded integer types panic on overflow.</p>
<p>One can opt-in to alternate behavior on overflow (commonly wrapping)
at the granularity of a package, one or more statements,
or an expression. Similar to <code>try</code>, this operates at a syntactic level.</p>
<pre><code>    let sum_plus_one = @math.wrap { 1 + vec.sum() }
    // Addition semantics in the sum() call itself are unaffected.</code></pre>
<p>When overflow behavior is overriden at the package level,
the Everr language server supports showing inlay hints
for the overflow behavior at function granularity.</p>
<h3 id="primitives---assertions">Primitives - Assertions</h3>
<p>Everr’s assertions are customizable.<span><label for="sn-25"></label><span>I’m deliberately not describing the exact APIs for assertions here as there is some room for building interesting APIs, such as <a href="https://antithesis.com/docs/best_practices/sometimes_assertions/">sometimes assertions</a>.</span></span>
By default, an assertion failure triggers a <code>panic</code>.
However, a binary package can customize the semantics of assertions,<span><label for="sn-26"></label><span>This customizability introduces some more complexity when considering the interaction with default capability levels and capability checking. I’ve not fully thought through the ramifications, but my gut feeling is that this is a solvable problem.</span></span>
by specifying an “assertion overlay” in its package manifest.
This acts as an override for the default assertion related APIs,
so every package in the dependency graph ends
up using one’s custom implementation of assertions.</p>
<p>The two most commonly used assertion overlays are:</p>
<ul>
<li>Profiling overlay: This helps collect metrics related to individual
assertions in production.</li>
<li>Toggling overlay: This helps disable assertions in dependencies,
either statically or dynamically.</li>
</ul>
<h3 id="out-of-memory-handling">Out-of-memory handling</h3>
<p>By default, out-of-memory for the heap results in program termination.</p>
<p>Heap usage is a capability, with the default level of Implicit.</p>
<p>Primitives which utilize heap allocation have fallible alternatives,
making it possible<span><label for="sn-27"></label><span>The design of ergonomic and performant APIs for using custom allocators while maintaining memory safety (or, at least, trying to reduce the number of footguns) is an open problem with several competing approaches. For more details, see Section 6 and Appendix A4.</span></span> to build APIs on top without having to rely on
heap allocation always being successful.</p>
<h3 id="stack-overflow-handling">Stack overflow handling</h3>
<p>By default, stack overflow results in program termination.</p>
<p>Recursion and usage of indirect calls are both considered capabilities,
with the default level of Implicit.</p>
<p>Code which cannot afford to have a stack overflow,
such as code following
<a href="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code">NASA’s rules for safety-critical code</a>,
can easily disable both of these features,
allowing the potential call graph of the program to be statically computed.</p>
<p>This allows computing the total stack usage of the program at the time
of compilation.</p>
<p>Stack usage is not guaranteed to be stable across minor or patch versions
of the Everr compiler, but since qualifying the compiler for safety-critical code
tends to be a time-consuming affair that is less frequent than compiler
releases, this is considered an acceptable trade-off.</p>
<p>For an alternative design which allows for more expressivity at the cost
of more implementation complexity, see Appendix A5.</p>
<h2 id="section-5-error-models-in-the-wild">Section 5: Error models in the wild</h2>
<p>The <a href="https://github.com/swiftlang/swift/blob/main/docs/ErrorHandlingRationale.md#survey">Swift Error Handling Rationale and Proposal</a>
doc I linked earlier covers the error model followed in
C, C++, Objective-C, Java, C#, Go, Rust and Haskell,
so I will not elaborate on those much more here.</p>
<p>Some older statically typed languages missing from that list include
D, OCaml and Ada. Some newer languages understandably missing include
Pony, Nim, Zig, Odin, Roc, Jai and Hare.</p>
<p>Scala does not market itself as a systems programming language,
but it’s type system offers interesting ways of expressing errors,
so it is included below. Other languages such as Dart, Kotlin,
Gleam and Unison are excluded because
I did not see any unusual or interesting ideas related to error
handling in their docs, and they seem to be more targeted towards
applications with less stringent performance requirements.</p>
<p>I’m going to try to summarize the error models very quickly here,
based on the language’s own docs. My summaries should not be considered
authoritiative, especially for pre-1.0 languages where conventions
are probably still in flux, and docs are perhaps more likely to be
out-of-date.</p>
<h3 id="d">D</h3>
<p>As of Feb 2025, the <a href="https://dlang.org/spec/errors.html">official D docs</a>
recommend using unchecked exceptions as the primary way of communicating errors.</p>
<p>However, <a href="https://youtu.be/XQHAIglE9CU?si=iYYy8R9GOEylPR6P&amp;t=1354">at DConf 2020</a>,
Walter Bright, the creator of D, stated that he thinks that
exceptions are obsolete.</p>
<p>Other noteworthy aspects:</p>
<ul>
<li>Functions can be marked <a href="https://dlang.org/spec/function.html#nothrow-functions">nothrow</a>.</li>
<li>The type <a href="https://dlang.org/phobos/object.html#.Exception">Exception</a>
is the base class for all “errors that are safe to catch and handle”.
Throwing an <code>Exception</code> is not allowed in <code>nothrow</code> functions.</li>
<li>The type <a href="https://dlang.org/phobos/object.html#.Error">Error</a>
is the base class of “all unrecoverable runtime errors”.
Throwing an <code>Error</code> is allowed in <code>nothrow</code> functions.</li>
<li>The default <code>assert</code> function/built-in throws an <code>Error</code>.</li>
</ul>
<h3 id="ocaml">OCaml</h3>
<p>Error propagation in OCaml comes in several flavors:</p>
<ul>
<li>Unchecked exceptions - These are widely used by the standard library.
Notably, assertion failures get converted to exceptions.</li>
<li>option and result types - Increasingly more library APIs have alternate
variants which return <code>option</code> or <code>result</code> in the failure case
rather than an exception.</li>
<li>Async exceptions are used for out-of-memory, stack overflow and
for OS signals like SIGINT.</li>
</ul>
<p>Additionally, OCaml supports <a href="https://ocaml.org/manual/5.3/bindingops.html">syntax sugar</a>
for short-circuiting evaluation/chaining of operations using <code>option</code> and <code>result</code>.</p>
<p>The <a href="https://ocaml.org/docs/error-handling">official OCaml docs</a> are probably
best described as being somewhat neutral in terms of prescribing a particular
error propagation strategy, but they do state:</p>
<blockquote>
<p>It tends to be considered good practice nowadays when a function can fail
in cases that are not bugs (i.e., not assert false, but network failures,
keys not present, etc.) to return type such as ’a option or (’a, ’b)
result (see next section) rather than throwing an exception.</p>
</blockquote>
<p>The book <a href="https://dev.realworldocaml.org/error-handling.html">Real World OCaml</a>
recommends using the <code>Base</code> library by Jane Street
in addition to the standard library. This library includes additional
helper types such as <code>Error.t</code> – a lazy string with various helper functions
for ease of construction – and helper functions such as <code>Or_Error.try_with</code>
to convert an exception throwing computation to a <code>result</code>.</p>
<p>Real World OCaml concludes:</p>
<blockquote>
<p>If you’re writing a rough-and-ready program where getting it done quickly is key and failure is not that expensive, then using exceptions extensively may be the way to go. If, on the other hand, you’re writing production software whose failure is costly, then you should probably lean in the direction of using error-aware return types.</p>
<p>[..] If an error occurs sufficiently rarely, then throwing an exception is often the right behavior.</p>
<p>Also, for errors that are omnipresent, error-aware return types may be overkill. A good example is out-of-memory errors, which can occur anywhere, and so you’d need to use error-aware return types everywhere to capture those.</p>
</blockquote>
<h3 id="ada">Ada</h3>
<p>Ada supports unchecked exceptions using values of a specific
type <code>exception</code> that can optionally carry a string payload.
If I understand correctly, exceptions have a notion of identity that is separate from the string payload.</p>
<p>The <a href="https://learn.adacore.com/courses/intro-to-ada/chapters/exceptions.html#predefined-exceptions">pre-defined exceptions</a> include:</p>
<ul>
<li><code>Constraint_Error</code> of out-of-bounds accesses, overflow, null dereference etc.</li>
<li><code>Storage_Error</code> for allocation failure and stack exhaustion</li>
</ul>
<p>In <a href="https://stackoverflow.com/q/63037858/2682729">one Stack Overflow discussion</a>, I found two different practitioners stating:</p>
<ul>
<li>“The reason for [not having a way to chain exceptions] is that the language has been designed for exceptions to be used scarcely”</li>
<li>“Ada exceptions are expected to be used for truly exceptional problems.”</li>
</ul>
<p>However, the <a href="https://en.wikibooks.org/wiki/Ada_Style_Guide/Program_Structure#Using_Exceptions_to_Help_Define_an_Abstraction">Ada style guide</a>
on Wikibooks has a guideline “Use Exceptions to Help Define an Abstraction”.
One of the code examples in this section is a stack where the <code>Pop</code> operation
raises an exception when the stack is empty.</p>
<p>I/O operations in the Ada standard library pervasively use exceptions.
I was not able to verify if there are other widely used standard library alternatives.</p>
<p>GNAT (Ada compiler toolchain in GCC) supports several settings for
restricting exception usage such as
<a href="https://docs.adacore.com/gnat_rm-docs/html/gnat_rm/gnat_rm/standard_and_implementation_defined_restrictions.html#no-exception-handlers"><code>No_Exception_Handlers</code></a>,
<a href="https://docs.adacore.com/gnat_rm-docs/html/gnat_rm/gnat_rm/standard_and_implementation_defined_restrictions.html#no-exception-propagation"><code>No_Exception_Propagation</code></a>,
and <a href="https://docs.adacore.com/gnat_rm-docs/html/gnat_rm/gnat_rm/standard_and_implementation_defined_restrictions.html#no-exceptions"><code>No_Exceptions</code></a>.
For example, <code>No_Exception_Propagation</code> requires functions to handle exceptions in callees.</p>
<h3 id="scala">Scala</h3>
<p>Scala 3 supports using <a href="https://www.scala-lang.org/api/3.x/scala/util/control/Exception$.html">unchecked exceptions</a>
as well as a tagged union type <a href="https://www.scala-lang.org/api/3.x/scala/util/Try.html">Try</a>
which enables easily catching exceptions and converting them to a sum type representation.</p>
<p>Some popular libraries such as Li Haoyi’s libraries for IO use exceptions
for errors such as a file not being found.</p>
<p>I’m guessing the more FP-oriented parts of the ecosystem probably use
case classes and/or Result to a greater extent, but I was not able to validate
this within 5~10 minutes of searching.</p>
<h3 id="nim">Nim</h3>
<p>Based on a quick skim of the Nim docs, I surmised the following:</p>
<ul>
<li>Nim supports <a href="https://nim-lang.org/docs/manual.html#effect-system-exception-tracking">exception handling</a>,
and this is used by standard library APIs such as for opening files.</li>
<li>Nim supports <code>raises</code> annotations on functions which indicate the types of
exceptions a function may throw (e.g.&nbsp;<code>{.raises: [ParseError]}</code>).</li>
<li>Nim supports a way to mandate explicit <code>raises</code> annotations across a module,
by putting <code>{.push raises: [].}</code> at the start of a module.
This setting ignores exceptions which inherit from <code>system.Defect</code>,
which is Nim’s way of signaling errors such as division by zero
and assertion failure.</li>
<li>Nim also has optional and result types.</li>
</ul>
<p>The <a href="https://nim-lang.org/docs/tut2.html#exceptions">Nim tutorial section on exceptions</a> states that</p>
<blockquote>
<p>A convention is that exceptions should be raised in exceptional cases,
they should not be used as an alternative method of control flow.</p>
</blockquote>
<p>The rest of the tutorial is descriptive –
it covers how to use different language features related to exceptions.</p>
<p>This <a href="https://status-im.github.io/nim-style-guide/errors.result.html">unofficial Nim style guide</a>
has more detailed recommendations on modeling and handling errors.
I was unable to find similar prescriptive language in
the official Nim docs.</p>
<hr>
<p>The below languages are pre-1.0 as of March 2025.<span><label for="sn-28"></label><span>The exception is Odin which currently uses date-based versioning. I’m assuming that as being equivalent to pre-1.0 in terms of stability guarantees given that Odin is less than 10 years old.</span></span></p>
<h3 id="pony">Pony</h3>
<p>The Pony tutorial has <a href="https://tutorial.ponylang.io/expressions/errors.html">a page on the <code>error</code> expression</a>,
which allows a function to abort execution until the enclosing <code>try</code> block.
All partial functions must be annotated with <code>?</code>.</p>
<p>As far as I can tell, there is no way to attach any data
when using the <code>error</code> statement.
If that is correct,
it means that the <code>error</code> primitive is similar
to an optional type which must be explicitly unwrapped.</p>
<p>Looking at unofficial sources,
based on <a href="https://journal.infinitenegativeutility.com/pony-errors-and-logging">this blog post</a>
and <a href="https://stackoverflow.com/questions/42845484/distinguishing-between-different-types-of-error-in-pony">StackOverflow discussion on distinguishing between different types of errors</a>,
it seems like the most common way is to do
error handling in Pony is using union types (e.g.&nbsp;<code>Int64 | OverflowError</code>).</p>
<p>As of Feb 2025, I could not find any official docs
further explaining how errors ought to be modeled and
how error handling should to be done, outside of the
<a href="https://www.ponylang.io/use/performance/pony-performance-cheat-sheet">performance cheat sheet</a>
which recommends avoiding <code>error</code>
and union types in performance-sensitive code,
both for different reasons.</p>
<p>Based on the docs, it looks like union types are compiled
using a <a href="https://tutorial.ponylang.io/expressions/match.html#matching-on-type-and-value">type ID pointer as the tag</a>
plus <a href="https://www.ponylang.io/use/performance/pony-performance-cheat-sheet/#boxing-machine-words">implicit boxing for the value</a>.<span><label for="sn-29"></label><span>This makes sense, as it allows implementing the natural subtyping relationship <code>T &lt;: (T | U)</code> to be implemented with zero run-time cost.</span></span></p>
<h3 id="zig">Zig</h3>
<p>The official Zig way to do error handling is by <a href="https://ziglang.org/documentation/master/#Error-Set-Type">defining “error sets”</a>:</p>
<pre><code>const FileOpenError = error{
    AccessDenied,
    OutOfMemory,
    FileNotFound,
};</code></pre>
<p>Error sets are structurally typed – identically named cases in different <code>error{...}</code>
declarations in different files are interchangeable.<span><label for="sn-30"></label><span>I’m curious to see how this decision pans out over time as the Zig ecosystem grows. Will library authors eventually start adding unique prefixes to library-specific errors, similar to prefixes in C and Objective-C, to avoid collisions?</span></span> This allows coercion of errors
from a subset to a superset, as well as merging using a <code>||</code> operator.</p>
<p><a href="https://github.com/ziglang/zig/issues/2647">Errors cannot not carry payloads</a>.
As a substitute, people use different patterns such as out parameters
and avoiding the standard error handling machinery.</p>
<p>Functions may write or omit the various error cases returned.</p>
<pre><code>// Inferred error set
pub fn parse_f32(...) !f32 { ... }

// Explicit error set
pub fn parse_f32(...) FloatParseError!f32 { ... }</code></pre>
<p>Here <code>FloatParseError!f32</code> is an <a href="https://ziglang.org/documentation/master/#Error-Union-Type">“error union type”</a>.</p>
<p>For handling an error union value returned from a function,
one can use <code>catch</code> keyword along with a default value or a code block.</p>
<p>Zig supports <code>try</code> as a shortcut for error propagation, which amounts
to being sugar for <code>catch |err| return err</code>.</p>
<p>Zig supports <a href="https://ziglang.org/documentation/master/#Non-exhaustive-enum">non-exhaustive enums</a>.
The docs do not explicitly mention support for non-exhaustive errors and structs
(but they do state that “An error set is like an enum”).</p>
<p>Zig programs are able to use a bevy of compile-time introspection facilities,
such as compile-time iteration over the fields of a struct.
The Zig docs do not state how compile-time introspection
interacts with non-exhaustive enums.</p>
<p>Zig uses whole program compilation. During this:</p>
<ul>
<li><p>Unique integer values are picked for different error cases.</p></li>
<li><p>The maximum height of the call graph is computed (recursion is capped to height 2),
and that is used for pre-allocating a buffer for <a href="https://ziglang.org/documentation/master/#Implementation-Details">error return traces</a>
in the Debug and ReleaseSafe modes.</p>
<ul>
<li>Return traces are implemented using a hidden function parameter.</li>
<li><code>catch</code> and <code>try</code> are integrated with return traces.</li>
</ul></li>
</ul>
<p>Zig has a <code>defer</code> statement for resource cleanup.
It also has an <code>errdefer</code> statement which runs a cleanup operation
only if the enclosing function returns an error.</p>
<p>Zig supports a customizable <code>@panic</code> operation.
By default, the implementation <a href="https://sourcegraph.com/github.com/ziglang/zig/-/blob/lib/std/debug.zig?L571">prints a stack trace and terminates the program</a>.
However, the “root file” (the one containing <code>main</code>) can
be used to override this implementation to do something else.</p>
<h3 id="odin">Odin</h3>
<p>Odin <a href="https://odin-lang.org/docs/overview/#unions">supports sum types</a> using the <code>union</code> keyword,
and C-style enums using the <code>enum</code> keyword.</p>
<p>The Odin docs do not have a dedicated section on the error model,
but the <a href="https://odin-lang.org/docs/overview/#union-tags">code examples in the docs</a>
showcase the usage of sum types for errors.</p>
<pre><code>Error :: union #shared_nil {
	File_Error,
	Memory_Error,
}

File_Error :: enum {
	None = 0,
	File_Not_Found,
	Cannot_Open_File,
}

Memory_Error :: enum {
	None = 0,
	Allocation_Failed,
	Resize_Failed,
}</code></pre>
<p>Similar to Go, all types in Odin have a <a href="https://odin-lang.org/docs/overview/#zero-values">zero value</a>.
Generally, <code>nil</code> is a valid value for sum types.<span><label for="sn-31"></label><span>This can be overriden with a <code>#no_nil</code> annotation on the declaration, in which case the sum type must have a default value.</span></span>
The <code>nil</code> values for the types for individual cases can be merged
using the <code>#shared_nil</code> keyword, which is used in the above example.</p>
<p>In 2018, the creator of Odin wrote a blog post
<a href="https://www.gingerbill.org/article/2018/09/05/exceptions-and-why-odin-will-never-have-them/">Exceptions — And Why Odin Will Never Have Them</a>.</p>
<blockquote>
<p>One of the consequences of exceptions is that errors can be raised anywhere and caught anywhere.
This means that the culture of pass the error up the stack for “someone else” to handle.
I hate this culture and I do not want to encourage it at the language level.
Handle errors there and then and don’t pass them up the stack.
You make your mess; you clean it.</p>
</blockquote>
<p>The Odin docs do not mention non-exhaustive structs or unions.</p>
<h3 id="roc">Roc</h3>
<p>Roc’s sum types are structural.</p>
<p>For error handling, Roc recommends the standard <code>Result</code> sum type,
and standard algebraic types for errors.</p>
<p>I searched for a bit, but could not tell if Roc supports some way
of representing non-exhaustive structs and enums.</p>
<p>Roc <a href="https://www.roc-lang.org/faq.html#option-type">deliberately does not define an <code>Optional</code> type</a>
and recommends the consistent use of <code>Result</code> for error handling instead.</p>
<p>Integer overflow in Roc translates to an irrecoverable program crash,
similar to Swift.</p>
<h3 id="jai">Jai</h3>
<p>I watched some of Jonathan Blow’s videos a few years back
and do not recall any particular discussion on the error model.</p>
<p>The <a href="https://pixeldroid.com/jailang/">unofficial Jai docs</a> do not
have any notable mentions of error handling.</p>
<h3 id="hare">Hare</h3>
<p>Hare supports declaring <a href="https://harelang.org/tutorials/introduction#user-defined-types">anonymous tagged union types</a> with implicit tags using <code>|</code>.</p>
<pre><code>type index = size;
type offs = size;

export fn main() void = {
	let z: (index | offs) = 1337: offs;
	assert(z is offs);
};</code></pre>
<p>Based on my reading of the docs, the <code>type A = B</code> syntax introduces
a <em>newtype</em> in Haskell-speak, not a type alias
unlike most other languages that I know of
using the same syntax (e.g.&nbsp;Rust, Go, Swift, Haskell, OCaml).<span><label for="sn-32"></label><span>In most languages, substitution of type aliases is expected to not affect program semantics. Recursive type aliases are also usually not permitted.</span></span></p>
<p>Hare’s tagged union types actually implement <em>union type</em> semantics
in the type-theoretic sense, not sum type semantics.
For more discussion, see Appendix A3.</p>
<p><a href="https://harelang.org/tutorials/introduction#defining-new-error-types">Error types in Hare</a>
can be declared using a prefix <code>!</code>.</p>
<pre><code>type error = !(io::error | invalid | unexpectedeof);</code></pre>
<p>Such an error type can be handled using <code>match</code>,
and supports implicit injection from individual component types.</p>
<p>For functions returning errors, apart from pattern matching,
the error can be propagated to the caller using post-fix <code>?</code>
and used to trigger a crash with post-fix <code>!</code>.</p>
<p>The Hare docs do not mention non-exhaustiveness for fields or cases.</p>
<h2 id="section-6-everr-vs-the-world">Section 6: Everr vs the World</h2>
<blockquote>
<p>The limits of my language mean the limits of my world.</p>
<p>– Ludwig Wittgenstein</p>
</blockquote>
<p>In this section, I’m going to compare Everr
against other existing programming languages
based on the key criteria outlined in Section 3.</p>
<p>I will be focused on <em>native support</em>, i.e.&nbsp;whether a language
supports a direct way of expressing a particular construct,
not whether it can be emulated using other constructs.</p>
<p>I recognize that some language prefer minimizing in-language
complexity in favor of pushing it out into libraries
and/or applications (e.g.&nbsp;by offering general purpose mechanisms
such as macros, compile-time reflection etc.).
However, as a trend, natively supported features
generally get special treatment in terms of syntax sugar,
recognition by tooling and dedicated error messages,
as well as more mentions in official documentation,
so it makes sense to focus on native support.</p>
<p>As the saying goes, “In theory, there is no difference
between theory and practice. In practice, there is.”
This is going to be a bit of an apples-to-wax apple comparison<span><label for="sn-33"></label><span>By “wax apple”, I mean an inedible apple-lookalike made out of wax, not the <a href="https://en.wikipedia.org/wiki/Syzygium_samarangense">wax apple</a> fruit.</span></span>
because there is no implementation of Everr,
so there is no real world evidence that these ideas
are workable without major changes.
All I have to offer is indirect evidence of “success” in
the form of usage of all the languages that Everr
<del>shamelessly copies</del> borrows ideas from.</p>
<p>With that big caveat, let’s proceed.</p>
<h3 id="error-declarations">Error declarations</h3>
<p>Languages using exceptions as the primary mode of error handling
generally lack a native way to enable exhaustiveness checking:
idiomatic error handling is non-exhaustive by construction.</p>
<p>In contrast, newer pre-1.0 languages such as Zig, Roc, Hare etc.
lack native support for non-exhaustive errors.</p>
<p>Older languages with algebraic data types such as Haskell and OCaml
do not have native support for non-exhaustiveness annotations
on data types.</p>
<p>Swift supports marking structs and enums as non-exhaustive,
but this is <a href="https://github.com/swiftlang/swift-evolution/blob/main/proposals/0192-non-exhaustive-enums.md#non-frozen-swift-enums-outside-the-standard-library">coupled to ‘Library Evolution’</a>,
which is Swift’s overarching feature
for maintaining ABI-compatibility guarantees.</p>
<p>Rust supports marking structs and enums as non-exhaustive,
and extending them with fields and cases respectively when
these annotations are used.
However, case refinement requires a-priori defining separate
structs for individual enum cases.</p>
<p>In languages with native support for algebraic data types,
generally sum types and product types are both first-class,
and sum types cannot carry shared fields.
This sometimes leads to soft recommendations of using
single-field structs instead of native enums to maintain
optionality in case one wants to ever add a field common
to all cases without breaking backward compatibility.</p>
<p>Scala should technically support case refinement very well
because case classes are first-class types that can be inherited from.
However, my understanding is that this is <a href="https://gist.github.com/chaotic3quilibrium/58e78a2e21ce43bfe0042bbfbb93e7dc">highly</a> <a href="https://users.scala-lang.org/t/simple-naive-and-wrong-more-than-you-wanted-to-know-about-case-classes/8300">frowned upon</a>.</p>
<p>Scala supports exhaustiveness annotations
along the cases axis using the <code>sealed</code> keyword.
However, the Scala docs do not mention support for non-exhaustiveness
annotations for fields of a case class.</p>
<p>Like Rust, Everr supports exhaustiveness annotations for fields and cases.</p>
<p>Like Cap’n Proto, Everr allows evolving a non-exhaustive enum to a
struct by adding shared fields without a source-level breaking change.</p>
<p>Everr supports case refinement, because cases are represented using
structs, and exhaustivity annotations from the outer type are propagated
to the structs for individual cases,
which allows addition of sub-cases using a <code>case</code> field.</p>
<h3 id="error-propagation---explicit-marking">Error propagation - Explicit marking</h3>
<p>Earlier, in the first sub-point under the bullet for ‘Error propagation’, I wrote:</p>
<blockquote>
<ul>
<li><strong>Explicit marking</strong>: The ability to force code to be written
in a way such that:
<ol type="1">
<li>Possible errors from primitive operations are indicated with explicit marks.</li>
<li>Propagating errors from an invoked operation to one’s own caller requires
an explicit mark.</li>
</ol>
The absence of explicit marks must cause a localized static error.</li>
</ul>
</blockquote>
<p>Let’s discuss the second bit first.</p>
<p>When exceptions are used for error handling, the most common
approach is that exceptions are silently propagated,
and that nearly any function may throw any exception.
This approach relies on programmers’ diligence
in reading, writing and maintaining doc comments.</p>
<p>Some languages which support finer control over exception propagation
are Java, D, Ada, Nim and C++.</p>
<p>My understanding is that the usage of checked exceptions in Java
is uncommon due to the added syntactic overhead, and the inability
to change code over time to return new error cases without jumping
through extra hoops.</p>
<p>Go and Rust have a panicking mechanism which is similar to exceptions,
and the typical recommendation is that these should only be used
for “exceptional” or “catastrophic” situations.</p>
<p>The Rust ecosystem has a <a href="https://blog.reverberate.org/2025/02/03/no-panic-rust.html">well-known “linker hack”</a>
which allows static enforcement over panic propagation
in optimized builds.</p>
<p>Swift, Pony, Zig, Roc and Odin do not have native support for any exception-like mechanism,
and require explicit propagation of errors (or crashing the program).</p>
<p>Rust, Swift and Zig have dedicated syntax for explicit error propagation.</p>
<ul>
<li>Rust has a post-fix <code>?</code> operator for short-circuiting control flow;
this is primarily used for error propagation.
Rust has an unstable feature <a href="https://doc.rust-lang.org/beta/unstable-book/language-features/try-blocks.html"><code>try_blocks</code></a>
to limit the scope of <code>?</code>.</li>
<li>Swift has a prefix <code>try</code> keyword which will bubble any errors
out of the enclosing function. This works at the level of
individual statements as well as sub-expressions.
Swift also supports <code>try?</code> for converting an error to <code>nil</code>
(an <code>Optional</code>), as well as <code>try!</code> for triggering a program crash
on encountering an error.</li>
<li>Zig has the <code>catch</code> and <code>try</code> keywords as explained earlier.</li>
</ul>
<p>Haskell’s <code>do</code> notation also provides similar functionality,
but it can require additional boilerplate depending on way effects
are being propagated (e.g.&nbsp;using effect types or monad transformers).</p>
<p>Some languages have on-going or recent work in a similar vein:</p>
<ul>
<li>Go has a <a href="https://github.com/golang/go/discussions/71460">on-going proposal</a>
for dedicated postfix <code>?</code> sugar for error propagation.
Apart from the sugar, programmers are recommended
to explicitly attach context to errors using
various standard library functions.</li>
<li>The OCaml docs note the trend towards increased use of explicit propagation.
The OCaml standard library also offers more APIs now with explicit errors.</li>
<li>OCaml’s sugar for error propagation helps in writing complex
logic without needing repeated explicit pattern matching.</li>
<li>C++23 added support for <code>std::expected</code>, analogous to Result in other languages.</li>
</ul>
<p>Error propagation in Everr is in some sense a blend of existing languages:</p>
<ul>
<li>It is flexible in allowing <code>try</code> in different places, like Swift.</li>
<li>It offers a third choice between function-wise propagation and
program termination, similar to exceptions.</li>
<li>It allows marking code as “cannot panic” like C++’s <code>noexcept</code>.</li>
</ul>
<p>Additionally, panicking being a capability, and capabilities supporting
different levels means that different levels of rigor can be used in
different contexts.</p>
<h3 id="error-propagation---primitive-operations">Error propagation - Primitive operations</h3>
<p>For overflow errors in integer operations, languages that tend
to offer control do so in the form of compiler flags and
standard library APIs rather than dedicated syntax.</p>
<p>Most languages use wrapping semantics for integer overflow,
with alternate semantics provided through standard library functions,
built-ins and/or types, if at all.</p>
<p>Some notable exceptions:</p>
<ul>
<li>Swift and Roc trigger a crash on overflow.</li>
<li>Rust triggers a panic on overflow in debug mode. This can be overriden
using compiler flags.</li>
<li>C++ treats signed integer overflow as undefined behavior – this can
be overriden to wrapping/trapping semantics using compiler flags.</li>
<li>In Zig, integer overflow triggers:
<ul>
<li>Undefined behavior in the <code>ReleaseFast</code> and <code>ReleaseSmall</code> build modes.</li>
<li>A panic in the <code>Debug</code> and <code>ReleaseSafe</code> build modes
(i.e.&nbsp;crash by default, but overridable).</li>
</ul></li>
</ul>
<p>Everr is somewhere between Swift and Rust in some sense;
it always triggers a panic, regardless of build mode.</p>
<hr>
<p>For heap allocation, most languages do not offer any reasonable
way of dealing with heap exhaustion apart from program termination.<span><label for="sn-34"></label><span>I recognize that on a shared system, the operating system is free to kill a process for consuming too much memory, and how much memory is “too much” can only be determined dynamically. However, at least in some contexts, such as servers, one often knows the amount of memory available at build time or program initialization time.</span></span></p>
<p>Zig and Odin are different from other languages here; allocators
are passed down ~everywhere as parameters (explicitly in Zig, and often
implicitly in Odin using the hidden <code>context</code> parameter).
This allows handling allocation failure at various levels.<span><label for="sn-35"></label><span>It would be interesting to examine what fraction of applications written in Zig and Odin actually have code paths for dedicated handling for out-of-memory errors, instead of just propagating it up the call stack and terminating the program. It would also be interesting to know what sub-fraction of that group has tests for the out-of-memory error handling code path, and how good that test coverage is.</span></span></p>
<p>Zig and Odin do not have any standard source-level markers for code
that is known to be memory safe vs code that is not.</p>
<p>Such discipline is possible in C++, Rust and other languages
to varying extents, but is less common.</p>
<ul>
<li>C++ standard types such as <code>std::string</code> and <code>std::vector</code> take
an optional type parameter for customizing the allocator.</li>
<li>Rust has an <a href="https://doc.rust-lang.org/std/alloc/trait.Allocator.html">unstable allocator_api</a> feature,
where the discussion <a href="https://github.com/rust-lang/rust/issues/32838">originally started in 2016</a>.
Rust also has a competing <a href="https://internals.rust-lang.org/t/pre-rfc-storage-api/18822">storage API</a>
proposal.</li>
</ul>
<p>Ada is somewhat unusual in that it allows returning
dynamically sized data through a secondary stack,
which can avoid the need for heap allocation in certain cases.</p>
<p>Older languages using tracing GCs have evolved to have features
which make it easier to write code free of heap allocations.
Unboxed types are now available to varying extents in Java,
C#, Haskell, OCaml etc.</p>
<p>Since I have not specified neither the memory management strategy
nor the type system for Everr, it doesn’t make sense to perform
a comparison of Everr with other languages for this particular point.</p>
<p>I believe Rust’s current approach of requiring you to use different
collection types
(e.g.&nbsp;<code>Vec</code>, <a href="https://docs.rs/bumpalo/latest/bumpalo/collections/vec/struct.Vec.html"><code>bumpalo::Vec</code></a>,
<a href="https://docs.rs/smallvec/latest/smallvec/struct.SmallVec.html"><code>smallvec::SmallVec</code></a>)
provides an OK sweet spot by putting the complexity
of dealing with different memory management strategies
onto users which need them, rather than on everyone.</p>
<p>See Appendix A4 for more details on some
interesting research in this space.</p>
<hr>
<p>I do not know of any non-research language which can statically
guarantee the absence of stack overflow.</p>
<p>The GNAT compiler for Ada supports
<a href="https://docs.adacore.com/gnat_ugn-docs/html/gnat_ugn/gnat_ugn/gnat_and_program_execution.html#static-stack-usage-analysis">static stack usage analysis</a>,
which allows gathering stack usage data.
Based on some searching, it is not clear if SPARK
can statically guarantee the absence of stack overflow.</p>
<p>Technically, one can employ techniques such as dynamic stack probing,
and then growing the stack using the heap
if it’s likely that one might need more space.
This approach is taken by the Rust <a href="https://github.com/rust-lang/stacker">stacker</a> crate.</p>
<p>Using the capability mechanism, by marking recursion
and indirect calls as capabilities, Everr can reduce
the risk of stack overflow, likely significantly so.
Similar to Ada, an Everr compiler can thus provide
concrete upper bounds on stack usage for functions
where these capabilities are turned off or not used.</p>
<p>See Appendix A5 for one potential idea on how a language
can rule out stack overflow statically while maintaining modularity.</p>

<p>Strictly speaking, structured metadata attachment, error combination and erasure
can be achieved in any mainstream language,
the question is really about how much boilerplate is needed.</p>
<p>For structured metadata attachment, in a language without inheritance,
adding more data to a type requires:</p>
<ol type="1">
<li>Duplicating the original type definition.</li>
<li>Updating the duplicate type definition to add a new field (or case).</li>
<li>Writing a conversion function from the old type to the new type.</li>
</ol>
<p>Depending on which type-aware compile-time metaprogramming facilities are available,
it should be possible to cut down on boilerplate for these kinds of operations
significantly. Languages such as Zig and Nim fall into this bucket.</p>
<p>When using metaprogramming for extending the types, programmers may
encounter difficulties in debugging metaprograms.
Metaprogramming also poses language design challenges by
requiring a clear design for how metaprograms interact with abstraction boundaries.
For example:</p>
<ul>
<li>Are private fields possible? As of Mar 2025, <a href="https://github.com/ziglang/zig/issues/9909">Zig says no</a> whereas Nim says yes.</li>
<li>If private fields are possible, is the metaprogram allowed to inspect private fields?
<ul>
<li>If the metaprogram can inspect private fields, how can the owner of the type definition
retain the ability to remove the private field?</li>
<li>If the metaprogram cannot inspect private fields, then how can it duplicate a type definition?</li>
</ul></li>
</ul>
<p>In theory, support for extensible records (similar to TypeScript and Elm) would
solve this problem cleanly. However, naively using structural extensible records
introduces compatibility hazards across library boundaries,
requires exposing the full structure
in type signatures (against encapsulation),
and increases type system complexity.</p>
<p>In Everr, you can “extend” a sum type defined in an upstream context such as:</p>
<pre><code>@exhaustive
enum ImageProcessingError {
    | DownloadingError { ... }
    | ProcessingError { ... }
    | StoringError { dbError: PgError }
      // Suppose 'PgError' represents a Postgres error which is a complex
      // data type with many fields and methods
}</code></pre>
<p>by defining a new type with specific information of interest:</p>
<pre><code>@exhaustive
struct DetailedStoringError {
    @delegate
    base: ImageProcessingError.StoringError,
    dbName: Str,
    dbURL: URL,
}</code></pre>
<p>and creating a replacement for the outer enum type:</p>
<pre><code>@exhaustive
enum DetailedImageProcessingError {
    | type ImageProcessingError.DownloadingError
    | type ImageProcessingError.ProcessingError
    | type DetailedStoringError
}</code></pre>
<p>this still requires duplicating the cases from the full <code>enum</code> definition,
but not any inline fields specified in it.<span><label for="sn-36"></label><span>Remapping the shared cases
still needs to be done “by hand” in a separate function or relying
on implicit injection from <code>T</code> to <code>A:union[.T | ...]</code>.</span></span></p>
<p>This relies on:</p>
<ul>
<li>The ability to share case types across enums.</li>
<li>The delegation mechanism to avoid duplicating the type definition
as well as explicit forwarding of methods.</li>
</ul>
<p>In languages with support for both union types and delegation
(e.g.&nbsp;via inheritance), such as Scala and Pony,
the same could be achieved with similar or less boilerplate.</p>
<p>Everr’s modeling can be copied over exactly to Odin,
because its tagged unions build on top of structs,
and it <a href="https://odin-lang.org/docs/overview/#using-statement-with-structs">supports delegation</a>.</p>
<p>In a language with sum types but without first-class enum case types
(e.g.&nbsp;Rust, Swift etc.) this requires making sure that you’re
defining dedicated structs for each enum case instead of
defining fields inline.</p>
<p>One way to get a fully static native solution with minimal boilerplate
would be to add support for defining new types using “diffs” from existing types.
While this would be independently useful
(e.g.&nbsp;simultaneously supporting multiple versions of a data format or API),
this introduces more complexities of its own,
and so I’ve chosen to omit that from this presentation.
For a sketch of how that could look like, and the complexities
such a system would have to deal with, see <a href="#appendix-a6-defining-new-types-using-diffs">Appendix A6</a>.</p>
<h3 id="error-handling">Error handling</h3>
<p>Error handling has four sub-criteria: exhaustiveness checking,
structured metadata extraction, error projection, and unerasure.</p>
<p>The latter three essentially amount to specific library calls
and support for field projection and method call syntax, which
are supported by ~most languages nowadays, including languages
which don’t identify themselves as “object-oriented”.</p>
<p>For exhaustiveness checking, most newer languages support it
in some form. The flexibility of pattern matching syntax
(or “switching” syntax) varies heavily based on language.
Depending on the language, the following features
may have varying levels of support:</p>
<ul>
<li>Nested patterns</li>
<li>Or patterns</li>
<li>Pattern guards (i.e.&nbsp;using arbitrary functions in a branch)</li>
</ul>
<p>Everr’s use of the the <a href="https://dl.acm.org/doi/10.1145/3689746">Ultimate Conditional Syntax</a> generalizes
all of these mechanisms, as well as allows more compact expression
of pattern matching by:</p>
<ul>
<li>Reducing the need for explicit temporaries by supporting “splits”</li>
<li>Allowing immediate inline use of bindings following <code>and</code>, without nesting,
generalizing <code>if let</code> style bindings in Rust and Swift.</li>
</ul>
<h3 id="error-conventions">Error conventions</h3>
<blockquote>
<p>Software development can be reduced to a single, iterative action. Almost everything we do in the course of a day — the pull requests, the meetings, the whiteboard diagrams, the hallway conversations — is an explanation. Our job is to explain, over and over, the meaning of our software: what it is, and what we expect it to become.</p>
<p>– Zach Tellman, <a href="https://explaining.software/archive/the-anatomy-of-an-explanation/">Explaining Software</a></p>
</blockquote>
<p>Language documentation generally takes a <em>descriptive</em> position on
error handling, describing all the different ways in which
error handling can be done, but avoids being prescriptive.</p>
<p>This means that projects often tend to follow either
(1) the path the standard library does OR
(2) the path which requires the least boilerplate.
Sometimes, these are the same.</p>
<p>The responsibility of <em>prescribing</em> error conventions for different
situations is generally left to style guides, managed by third parties.</p>
<p>Here’s a short, non-exhaustive list of plausible reasons for this phenomenon:</p>
<ul>
<li>Prescribing approaches is perceived to be “messy” as it requires deeply
understanding and taking into account many different contexts of usage.</li>
<li>Consensus building is both time-consuming and challenging, requiring
strong communication skills and high emotional energy.</li>
<li>Writing documentation is generally under-valued in practice compared
to programming. For example, language release notes typically mention
new features and APIs, not new docs.</li>
</ul>
<p>As ecosystems evolve over time, introducing conventions later in time
is more likely to face opposition, unless these conventions simply
codify existing practices as “best practice.”
This can be true even when evidence is presented in favor of newer conventions,
due to various <a href="https://en.wikipedia.org/wiki/Category:Cognitive_biases">cognitive biases</a>.</p>
<p>I belie
ve there is much more room for languages to provide clearer guidance
on appropriate contexts for using specific ways of defining, propagating
and handling errors.</p>
<p>I further believe that it is valuable to provide prescriptive guidance
earlier in a language’s lifespan than is common,
and to encourage thinking about guidance as an evolving artifact
grounded in evidence. For example, guidance can be accompanied by
short summaries of past evidence showing positive/zero/negative results
in relation to the guidance,
as well as explicit invitations for collecting further evidence.</p>
<h3 id="tooling">Tooling</h3>
<p>In principle, given sufficient resources, almost any kind of tooling can be
built for any language. The problem is that in practice,
“resources” are generally never “sufficient”, so it makes
sense to try to make it as easy as possible to build correct tools.</p>
<p>For this specific point,
I believe the Go ecosystem is a good example,<span><label for="sn-37"></label><span>Perhaps the point about “necessity is the mother of invention” applies here? From what I’ve heard, Java has excellent tools for heap profiling, whereas tooling for languages like Rust and C++ is much more lacking in comparison.</span></span>
where even though several bits of functionality considered
table-stakes in other ecosystems – such as exhaustiveness checking
– are not natively supported by the Go compiler,
it is easy to <a href="https://github.com/nishanths/exhaustive">create new linters</a>,
and then <a href="https://github.com/golangci/golangci-lint">integrate them with other linters</a>
and <a href="https://github.com/bazel-contrib/rules_go/blob/master/go/nogo.rst">build systems like Bazel</a>.</p>
<p>Standardizing on error propagation mechanisms in particular
across an ecosystem can also help motivate investment into
deterministic refactorings for simplifying repetitive tasks.
For example, in Everr, the language server could offer a refactoring
to attach metadata to an error by handling the boilerplate
of defining new error types etc.</p>
<hr>
<p>That’s the end of the comparison between the error models of
Everr and that of other languages.</p>
<p>While many languages offer different mechanisms for defining, propagating
and handling errors, there is not a language which is “strictly superior”
than the other ones along all of these axes.</p>
<p>I believe a design similar to that of Everr can potentially help
programmers express the different possibilities of error cases,
and how to handle them,
in a way that matches or improves upon most languages along most axes,
while preserving the ability to maintain code over long periods of time.</p>
<p>The next section is more philosophical than all the ones so far,
so if that’s not your cup of tea, you can stop reading here, no judgement. 😆</p>
<h2 id="section-7-closing-thoughts">Section 7: Closing thoughts</h2>
<p>In this section, I want to do something a bit different.
Before sharing my own thoughts, let me ask you some questions.</p>
<h3 id="questions-for-you">Questions for you</h3>
<p>Programmers accustomed to statically typed programming languages
are likely to raise an eyebrow if they encounter a codebase in the
same language where all functions return <code>Any</code> (or equivalent) upon success.</p>
<p>And yet, the use of untyped errors along with need for down-casting is widespread across languages.
For example, in Rust, a common recommendation is to use the <code>anyhow</code> crate in applications,
and in Go, functions which may fail return an <code>error</code> interface in the vast majority of cases.</p>
<p>Q: Why do you think this discrepancy exists?</p>
<hr>
<p>Much of the discourse around what consists of “good code” often avoids any detailed discussion of errors altogether. For example, in <em>A Philosophy of Software Design</em>,<span><label for="sn-38"></label><span>I’m discussing an example from <em>A Philosophy of Software Design</em> here because I’ve seen it widely recommended on forums such as Hacker News and Lobsters.</span></span> John Ousterhout writes:</p>
<blockquote>
<p>A module’s interface represents the complexity that the module imposes on the rest of the system: the smaller and simpler the interface, the less complexity that it introduces. [..]</p>
<p>The mechanism for file I/O provided by the Unix operating system and its descendants, such as Linux, is a beautiful example of a deep interface. There are only five basic system calls for I/O, with simple signatures:</p>
<pre><code>int open(const char *path, int flags, mode_t permissions);
ssize_t read(int fd, const void* buffer, size_t count);
ssize_t write(int fd, const void* buffer, size_t count);
off_t lseek(int fd, off_t offset, int referencePosition);
int close(int fd);</code></pre>
<p>[..] A modern implementation of the Unix I/O interface requires hundreds of thousands
of lines of code, which address complex issues [..] Deep modules such as Unix I/O
and garbage collectors provide powerful abstractions because they are easy to use,
yet they hide significant implementation complexity.</p>
<p>[..] If an interface has many features, but most developers only need to be
aware of a few of them, the effective complexity of that interface is just
the complexity of the commonly used features.</p>
</blockquote>
<p>One of the elephants in the room<span><label for="sn-39"></label><span>I have a deeper critique of the Unix file I/O API, but there is not enough space in this margin to write it. I may write a more detailed review of Ousterhout’s book some time later this year.</span></span> that Ousterhout ignores here is errors.
Let’s just consider <code>open</code>. If you look at man7.org, <code>open</code> can have the following different
error cases:</p>
<pre><code>EACCES, EBADF, EBUSY, EDQUOT,
EEXIST, EFAULT, EFBUBG, EINTR,
EINVAL, EISDIR, ELOOP, EMFILE,
ENAMETOOLONG, ENFILE, ENODEV, ENOENT,
ENOMEM, ENOSPC, ENOTDIR, ENXIO,
EOPNOTSUPP, EOVERFLOW, EPERM, EROFS,
ETXTBUSY, EWOULDBLOCK</code></pre>
<p>That’s 26 different error cases. Out of these, let’s look at when <code>EACCES</code> can be hit:</p>
<blockquote>
<p>The requested access to the file is not allowed, or search
permission is denied for one of the directories in the path
prefix of pathname, or the file did not exist yet and write
access to the parent directory is not allowed. (See also path_resolution(7).)</p>
<p>Where O_CREAT is specified, the <code>protected_fifos</code> or
<code>protected_regular sysctl</code> is enabled, the file already
exists and is a FIFO or regular file, the owner of the file
is neither the current user nor the owner of the containing
directory, and the containing directory is both world- or
group-writable and sticky. For details, see the
descriptions of <code>/proc/sys/fs/protected_fifos</code> and
<code>/proc/sys/fs/protected_regular</code> in <code>proc_sys_fs(5)</code>.</p>
</blockquote>
<p>If a kernel needs to return an <code>EACCES</code> error for any of these problems, it must detect them. Which means, at the time of detecting the error, it must have some contextual information about what failed. However, because of the API signature, the kernel cannot return this information to the caller. This means that either the kernel and caller need to separately cooperate on having a “side channel” for passing extra metadata, or the kernel can just drop the information.</p>
<p>Q: Have you ever hit an <code>EACCES</code> error when opening a file? What did you do to debug it the first time you hit it? What if you could go back to your past self, in the middle of debugging this for the first time, and tell them that a well-regarded book called <em>A Philosophy of Software Design</em> considers that as a “beautiful example of a deep API”, what do you think your past self’s reaction would be? How much does that matter?</p>
<h3 id="the-aesthetics-and-pragmatics-of-pl-design">The aesthetics and pragmatics of PL design</h3>
<blockquote>
<p>There are five essential components to learning a language:</p>
<ul>
<li>Syntax: [..]</li>
<li>Semantics: By semantics, we mean the rules that define the behavior of programs. [..] The dynamic semantics define the run-time behavior of a program as it is executed or evaluated. The static semantics define the compile-time checking that is done to ensure that a program is legal, beyond any syntactic requirements. The most important kind of static semantics is probably type checking: the rules that define whether a program is well typed or not.</li>
<li>Idioms: [..]</li>
<li>Libraries: [..]</li>
<li>Tools: [..]</li>
</ul>
<p>– Cornell CS 3110 <a href="https://www.cs.cornell.edu/courses/cs3110/2018sp/l/02-fun/notes.html">program course notes</a></p>
</blockquote>
<p>In some sense, program semantics has a sense of timelessness – they talk about <em>a program</em> and <em>a semantics</em>. But our programs (and their semantics) do change over time!</p>
<p>This leads to two different notions, which I’m going to call <em>evolution semantics</em> and <em>migration semantics</em> respectively.<span><label for="sn-40"></label><span>I believe there are no standard terms for these in the literature but happy to be corrected!</span></span> Here are some loose definitions:</p>
<ul>
<li><p>Evolution semantics: This covers the <em>interoperability</em> (or lack thereof) between program fragments and their static semantics as they evolve over time (e.g.&nbsp;as different versions). Some examples of work which would fall in this bucket:</p>
<ul>
<li><a href="https://github.com/obi1kenobi/cargo-semver-checks">cargo-semver-checks</a> which programmatically analyzes Rust crates for SemVer violations.</li>
<li><a href="https://github.com/swiftlang/swift/blob/main/docs/LibraryEvolution.rst">Swift’s Library Evolution feature</a>.</li>
<li><a href="https://research.swtch.com/vgo">Russ Cox’s writing on Go &amp; versioning</a>.</li>
</ul></li>
<li><p>Migration semantics: This covers the <em>interoperation</em> (or lack thereof) of running program fragments and their dynamic semantics as they evolve over time (e.g.&nbsp;as different versions). Some examples of work which would fall in this bucket:</p>
<ul>
<li>Various SQL constructs such as <a href="https://www.postgresql.org/docs/current/sql-altertable.html">ALTER TABLE</a>, and more generally, database migrations.</li>
<li>Debuggers which allow modification of control flow and/or data.</li>
<li>Hot reloading functionality found in many game and UI frameworks, and natively supported in Erlang.</li>
</ul></li>
</ul>
<p>I believe both of these areas are worth studying in their own right,
because reasoning about time is hard,
but reasoning about programs and their data over time
is increasingly important as our codebases and databases
grow older and larger.</p>
<p>“That’s all well and good,” you say, “but what does time have to do with error models?”
Please hold that thought for a moment.</p>
<hr>
<p>Perhaps while you’ve been reading this post, you might’ve had
the reaction that there is something unaesthetic, perhaps deeply so, about
Everr’s choice to make product types first-class and sum types second-class.</p>
<p>On the other hand, you might think of ML family languages as being more aesthetic,
putting sum types and product types on equal footing, mostly.<span><label for="sn-41"></label><span>I have to say “mostly” because a purist version of this would prevent inline record syntax for the cases of a sum type, such as in <a href="https://ocaml.org/manual/4.11/inlinerecords.html">pre-4.03 OCaml</a>.</span></span></p>
<p>I get that. To be honest, I had a similar reaction
when I first read about Cap’n Proto’s decision
to make records first-class and (tagged) union types second-class
(🧠: “Surely, there has to be a better way!”).
I also had a similar reaction when I first learnt
about the support for <code>IF EXISTS</code> in various SQL DDL
commands (🧠: “You can’t just extend syntax in ad-hoc ways like that!
That doesn’t seem orthogonal to other features!”).</p>
<p>There’s also something unaesthetic about having
implicit projection for a special field name <code>case</code>
(🧠: “Why should one field name be privileged over others!”).</p>
<p>The bounded union type syntax also has an unaesthetic quality
(🧠: “The presence of the type name ruins the symmetry present in typical union type syntax!”).
If we accept the frame of “programmers should be able to
read/write Everr code in their favourite editing environments,
which have text editing at the heart” as a premise,
then there needs to be some way of representing type syntax using ASCII characters,
and I do not have the audacity to suggest
that programmers write something like:</p>
<pre><code>       Dessert
 /----- union -----\
  .Cake | .IceCream</code></pre>
<p>Each of these decisions fulfills specific needs,
but many of them <em>still feel weird</em>,
perhaps with the exception of the Ultimate Conditional Syntax
(which I take zero credit for, because I literally just copied it from a paper).</p>
<p>Perhaps moreso than these individual decisions, you might’ve felt
an overall unaesthetic quality about the <em>kind of reasoning</em> used
throughout this post. Much of the reasoning is by case analysis,
instead of using induction or by providing a handful of core primitives
and combining them in elegant ways to address every challenge posed.</p>
<p>Everr’s language design itself reflects a pattern of accreting up and sanding down,
more like seeing an igloo or a sand castle being built over time,
and less like walking into a museum and having a Michelangelo sculpture come into view.</p>
<p>Can an igloo built by a novice be as beautiful as a Michelangelo sculpture?
Does the answer to that depend on whether you’re looking for shelter from an on-going blizzard?</p>
<hr>
<p>I believe the “lumpiness” in the landscape of computing –
be it heterogeneity in hardware,
the variations in the lifecycles of packages and the
interpersonal dynamics of package maintainers,
or all the “weird error cases” which defy easy classification
– is a omnipresent backdrop for the design for general-purpose PLs.</p>
<p>Which parts of this lumpy backdrop should be treated as a canvas to paint on
and which parts should be treated as something to be smoothened over
– that is a question of both one’s emotions and one’s values.</p>
<p>If we would like to paint certain parts of this canvas that are high up in the clouds,
and time is of the essence, perhaps, we need to be willing to stand on the shoulders
of Giants rather than insisting on climbing our way up all by ourselves.
Perhaps, it makes sense to befriend as many Giants as possible and try to cajole them into forming a Giant pyramid<span><label for="sn-42"></label><span>Grammar note: A Giant pyramid is necessarily a giant pyramid, because Giants are giant by definition, but a giant pyramid may not be a Giant pyramid, because it may be made of many individually small objects.</span></span> we can climb on.</p>
<p>Two such Giants which I believe are under-utilized in PL design today are:</p>
<ul>
<li>Special-purpose languages such as Cap’n Proto, where the design involves a fair number of considerations around time and evolution.</li>
<li>Tools which can help us formally reason about complex systems, such as:
<ul>
<li>Model checkers such as Alloy and TLA+. In particular, my initial experiments with Alloy makes me believe that Alloy can help with <a href="https://x.com/typesanitizer/status/1551575106194878464">modeling complex relationships across packages</a>, and potentially across time, without writing code.</li>
<li>Proof assistants.</li>
<li>Special-purpose tools such as <a href="https://www.ccs.neu.edu/home/stchang/pubs/cbtb-popl2020.pdf">Turnstile(+)</a> for type-checking and <a href="https://github.com/herd/herdtools7/">herdtools</a> for memory models.</li>
</ul></li>
</ul>
<p>While many of these tools are academic in origin, and thus have a steep usability curve, I think there is value in exploring them, as well as coming up with more user-friendly versions of them.</p>
<p>If you want to start somewhere and have a design problem, I think Alloy is likely a good place to start. Its syntax is easy to understand, and it comes with a visualizer out-of-the-box. You can also save the raw XML for counter-examples somewhere and visualize it using your own code.</p>
<p>Zooming back in to errors specifically, we now arrive at the final question.</p>
<h3 id="what-are-we-to-do">What are we to do?</h3>
<blockquote>
<p>All happy families are alike; each unhappy family is unhappy in its own way.</p>
<p>– Leo Tolstoy, Anna Karenina</p>
</blockquote>
<p>Pithy statements such as “only use exceptions for exceptional cases”
or <a href="https://wiki.c2.com/?LetItCrash">Let it crash</a>,
while catchy, do not do justice to the complexities
that programmers need to deal with when deciding how
to define, propagate, handle and reason about errors.</p>
<p>The fundamental nature of errors is that they are often multi-faceted,
and complex to reason about by virtue of being multi-faceted.
The wide variety of socio-technical contexts that software is created,
delivered and used in add further complexity.</p>
<p>It is important that we are able to reason about how software works,
but also about how it doesn’t quite work.
Reasoning enables better decision-making when we’re making a choice
on whether we should tweak, fix, disable or delete the software,
or maybe even just keep it as-is.</p>
<p>If we are to reason about and debug software
when it doesn’t work as expected,
our languages must empower us to do so.
While a programming language cannot magically help
fix all software issues at any scale,
I believe they can help move the needle,
by changing the often-implicit frame of reference
about how we think about errors.</p>
<p>I believe that it behooves us as an industry
to try to move the needle,
as increasingly more parts of the world
rely on software working correctly.</p>
<h2 id="appendix">Appendix</h2>
<h3 id="appendix-a1-everr-type-system-discussion">Appendix A1: Everr type system discussion</h3>
<p>Everr’s enums are closer to Scala’s case classes
rather than enums/sum types in languages like Rust, Swift,
Haskell and OCaml.</p>
<p>Similar to union types in other languages like Scala, Pony and TypeScript,
Everr’s union types (both the exhaustive and non-exhaustive variants)
satisfy commutativity, associativity and idempotence.
Additionally, an exhaustive union type is a subtype of the corresponding
non-exhaustive union type.</p>
<p>However, unlike Scala, Pony and TypeScript, Everr’s union types are more limited.
The elements of the union with a certain top type must either be:</p>
<ul>
<li>Base case: A type representing a case of the top type.</li>
<li>Recursive case: Another union type with the same top type
(interpreted via coalescing cases).</li>
</ul>
<p>Since Everr has no universal top type, arbitrary types cannot be unioned
together. This allows for an efficient run-time representation
(the same as enums) without needing whole-program analysis or a JIT,
while still providing the benefits of being able to deal with arbitrary subsets.</p>
<hr>
<p>Everr’s choice of making enum cases first-class and enums themselves second-class
is distinct from Rust’s proposed <a href="https://github.com/rust-lang/lang-team/issues/122">enum variant types</a>,
where enums continue to stay first-class but enum cases have second-class status.</p>
<p>Here are the major differences:</p>
<ul>
<li>In Everr, enum cases can separately carry type parameters, but Rust’s
enum variant types cannot.</li>
<li>In Everr, enum cases can separately implement different traits,
but Rust’s enum variant types cannot.</li>
<li>Going from an individual case type to the enum type requires attaching
a tag in Everr (but the <code>T:union[]</code> form shares the same layout as the enum).
In Rust, the enum variant type shares the same layout as the enum.</li>
<li>Everr supports arbitrary subsets of cases;
the initial Rust proposal does not support this. However, adding this would
be compatible with the Rust proposal.</li>
<li>Everr’s design allows composition of cases across enums, but Rust does not.</li>
</ul>
<hr>
<p>Everr’s delegation mechanism is similar to inheritance,
but without any association with subtyping,
and correspondingly there is no notion of up-casting or down-casting.</p>
<p>Imperative languages such as Go and Rust provide similar
functionality using different techniques: Go has <a href="https://gobyexample.com/struct-embedding">struct embedding</a>, and Rust has <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html#deref-coercion">Deref coercions</a>.</p>
<h3 id="appendix-a2-niche-optimizations-with-second-class-enums">Appendix A2: Niche optimizations with second-class enums</h3>
<p>Rust can do type layout optimization (also called “niche optimization”) by
considering excluded states. For example, the type: <code>Option&lt;NonZeroU8&gt;</code>
will take 8 bits, because the 0 state is reused by <code>None</code>.</p>
<p>In Everr, going from a type <code>MyEnum.MyCase</code> to <code>MyEnum:union[.MyCase]</code>
with zero or more other cases requires the compiler to generate
a function which attaches the corresponding enum tag.
For the <code>Optional</code> type discussed, one needs two such functions
for the two different cases, which will have the following signatures:</p>
<pre><code>fn _none_to_union[A](v: Optional.None) -&gt; Optional[A]:union[.None] {
    // implementation elided
}

fn _some_to_union[A](v: Optional.Some[A]) -&gt; Optional[A]:union[.Some[A]] {
    // implementation elided
}</code></pre>
<p>Since the generation of these functions is entirely under the compiler’s
control, it is possible for the compiler to directly generate specialized
versions of these functions for different types with different niches
during monomorphization, instead of attempting to generate one version.</p>
<p>This means that when a compiler sees an implicit conversion<span><label for="sn-43"></label><span>This is syntax-directed implicit conversion rather than being a subtyping rule, because it requires a change to the run-time representation. If it were a subtyping rule, and Everr were to support covariant and contravariant type parameters, that would require potentially-arbitrarily-expensive bridging conversions, <a href="https://forums.swift.org/t/generalization-of-implicit-conversions/51344">like Swift</a>.</span></span> from
<code>None</code> to <code>Optional[A]:union[.None]</code>, it can specialize the conversion
based on what <code>A</code> is instantiated to.</p>
<h3 id="appendix-a3-hare-type-system-discussion">Appendix A3: Hare type system discussion</h3>
<p>The Hare docs state that tagged union types are “commutative, associative, and reductive”
and that “the order of types, inclusion of the same type more than once,
or use of nested tagged unions has no effect on the final type.”</p>
<p>So Hare’s tagged unions implement <em>union types</em> in the type-theoretic sense,
not sum types, unlike most other languages with tagged unions.
<a href="https://harelang.org/documentation/faq.html#why-doesn-t-hare-have-generics">Hare does not support parametric polymorphism</a>,
so the choice to implement union type semantics via tagged unions:</p>
<ul>
<li>Offers a high degree of flexibility, like Scala, Pony and TypeScript,
by not requiring upper bounds (unlike Everr)
and allowing the union of arbitrary types (unlike Everr).</li>
<li>Does not require a uniform representation,
like Everr but unlike Scala, Pony and TypeScript.</li>
<li>Does not increase type system complexity significantly, because
there is no need for subtyping rules involving type inference
and polymorphism.</li>
</ul>
<h3 id="appendix-a4-safe-and-modular-memory-management">Appendix A4: Safe and modular memory management</h3>
<p>The research work on Verona has surfaced one potential direction
<a href="https://dl.acm.org/doi/pdf/10.1145/3622846">Reference Capabilities for Flexible Memory Management</a>:</p>
<blockquote>
<p>Verona is a concurrent object-oriented programming language
that organises all the objects in a program
into a forest of isolated regions.
Memory is managed locally for each region,
so programmers can control a program’s memory use by
adjusting objects’ partition into regions,
and by setting each region’s memory management strategy.</p>
</blockquote>
<p>The overall type system is more flexible than Rust’s in some ways,
but if you look closely, the paper points out that
field accesses may throw an exception if the region
corresponding to the field is already open. If I understand
correctly, this is similar to Rust’s <code>Cell</code> type which
does dynamic borrow-checking.</p>
<p>However, the paper also mentions that field a</p>
<blockquote>
<p>Entering a region borrows and/or buries the variable
or field referencing the bridge object.
In the case of a stack variable,
the variable is buried to prevent the region from being multiply opened</p>
<p>the case of a field, we instead resort to a dynamic check of the region’s state. If the region is closed,
it may be opened. If the region is already open, an exception is thrown</p>
</blockquote>
<p>I have not been able to absorb the paper deeply,</p>
<h3 id="appendix-a5-modular-static-analysis-for-stack-usage">Appendix A5: Modular static analysis for stack usage</h3>
<p>I believe it should be possible to support modular static analysis
for controlling stack usage without requiring eliminating indirect calls,
which can be useful with basic operations like <code>map</code>, <code>filter</code> etc.</p>
<p>The problem with an indirect call is that the stack usage for it will
be unknown. So the most direct “fix” is to equip calls with stack usage information.</p>
<p>Specifically, function types could be equipped with two kinds of stack usage budgets:</p>
<ul>
<li>Self budget: The maximum memory the function is allowed to use for temporaries.</li>
<li>Calls budget: The maximum stack usage for calls inside the function.</li>
</ul>
<p>When a function body is lowered to an IR
which makes temporaries explicit,
after some set of relatively stable baseline optimizations
(e.g.&nbsp;sparse conditional constant propagation and copy propagation, but no inlining),
a compiler can check the following:</p>
<ul>
<li>Does the self budget exceed the sum of stack usage for all temporaries assuming
no lifetime contraction/further optimization.</li>
<li>Does the calls budget exceed the total stack usage budget for each called function
(these calls may be indirect)</li>
</ul>
<p>Finally, after inlining and other optimizations but before generating assembly,
one could perform a validation check only for the total budget
(but not for the self and calls budgets, because of inlining).</p>
<p>In such a system, if you annotate <code>main</code> with a stack budget,
then you’d essentially trigger errors for each function call inside <code>main</code>
and so on until you’ve added stack budgets
for every function in the call graph.
Yes, this would necessitate writing your own
stack usage aware minimal standard library.</p>
<p>I believe such a system should be “workable” in practice in the limited
sense that compiler optimizations typically do not increase stack usage
of call trees, and the number of temporaries generally goes down
as the optimization crank is turned more. So I suspect that the final
validation check should fail not too often.</p>
<hr>
<p>Depending on the desired properties about where errors should be handled
(e.g.&nbsp;is it OK to emit errors after monomorphization?),
and which language features need to be supported in concert with stack budgets
(e.g.&nbsp;is it OK to only allow setting budgets on monomorphic functions?), one could:</p>
<ul>
<li>Potentially have the budget checks run on a polymorphic IR instead of
the post-monomorphization IR</li>
<li>Allow the budget to not just be an integer, but a more general expression,
allowing references to stack budgets of parameters, some basic numeric operations
like <code>+</code> etc.</li>
</ul>
<hr>
<p>I suspect that it’s not really possible to have a much simpler solution than
what I’ve described above <em>unless</em> one is willing to give up on (1) modularity
or (2) move the check to be dynamic.</p>
<p>Of course, one might ask: is this much complexity worth it “just” for statically
preventing stack overflows in a modular fashion?</p>
<p>For that, the answer is I don’t know.
If we believe existing languages,
the answer seems to largely be No.</p>
<h3 id="appendix-a6-defining-new-types-using-diffs">Appendix A6: Defining new types using diffs</h3>
<p>Say Everr supported type diffs. This could help reduce the boilerplate
involved in extending a type defined upstream from:</p>
<pre><code>@exhaustive
struct DetailedStoringError {
    @delegate
    base: ImageProcessingError.StoringError,
    dbName: Str,
    dbURL: URL,
}

@exhaustive
enum DetailedImageProcessingError {
    | type ImageProcessingError.DownloadingError
    | type ImageProcessingError.ProcessingError
    | type DetailedStoringError
}</code></pre>
<p>to something like:</p>
<pre><code>@exhaustive
enum DetailedImageProcessingError diff ImageProcessingError {
      | ...
    * | base: StoringError -&gt; DetailedStoringError {
          ...,
          + dbName: Str,
          + dbURL: URL,
        }
}</code></pre>
<p>Specifics of concrete syntax aside, it would technically be possible
to parse the syntax below and desugar it to
the one above. This may be particularly useful if there are lots of cases
in the upstream type being extended.</p>
<p>The Everr language server could show the desugared version as a large multi-line
“inlay hint” inside the editor.<span><label for="sn-44"></label><span>However, this runs into the further issue of how to represent the upstream type if the package containing the definition of the upstream type is not pinned to a specific version.</span></span></p>
<p>However, because this implicitly adds a <code>@delegate</code> attribute to preserve
the ability to do field projections and method calls,
chaining such type definitions makes it easy
to have multiple levels of delegation,
which can be confusing to debug (similar to deep inheritance hierarchies).
The interaction with the implicit project for <code>.case</code> also needs
to be thought through, and may be confusing.</p>
<p>On the other hand, forbidding multiple levels of definitions of
type diffs may be too restrictive if the target use case also needs
to cover code which needs to support 3+ versions of a data type over time.</p>
<p>This is only considering additive diffs. Subtractive diffs are likely
simpler – because <code>@delegate</code> cannot be involved without breaking abstraction
– but also less useful, since it’s more common to want
to create extended versions of third-party types in practice.</p>
<h3 id="appendix-a7-optimism">Appendix A7: Optimism</h3>
<p>Recently at work, I discovered that my assumption
that our DBs was configured so that queries which
are running fast would continue running fast
was proven wrong as the DBs went through a Postgres major version upgrade,
and the loss of statistics
– despite having <a href="https://www.postgresql.org/docs/current/runtime-config-autovacuum.html#GUC-AUTOVACUUM">autovacuum</a> turned on
– contributed to an incident.</p>
<p>The incident was resolved late on a Thursday night;
I was due to go on vacation the subsequent week.
When on vacation, when I had some time to kill,
I spent digging around mailing list threads,
Postgres source code, blog posts and asking Claude,
attempting to answer the question
“What are all the different possible situations
under which Postgres can have statistics that are
woefully out-of-date despite autovacuum being turned on,
and how can those be detected?”</p>
<p>When I came back, I noticed that nobody had really asked the same question,
at least in public. At first, I was puzzled,
“Surely, people are not just hoping that
this doesn’t happen again, right?”
Then I realized I was operating with a different mental model
altogether. My trust in Postgres’s ability to maintain
statistics had gone from confident to low (and the scarce
documentation did nothing to allay that fear),
whereas my colleagues were believing that
this was likely a one-off issue specific to major version upgrades.</p>
<p>Both of these beliefs make some sense in different ways.</p>
<ul>
<li><p>The more optimistic point-of-view assumes
that given that we did not have any such statistics related
issues earlier when running Postgres 12,
and that Postgres upgrades generally bring improvements,
it was likely that autovacuum in Postgres 16 is
at least as good and less buggy than Postgres 12.</p></li>
<li><p>The more pessimistic point-of-view assumes given the presence
of one undesirable behavior in the autovacuum daemon that
hadn’t yet been fixed despite Postgres being one of the most
mature and widely used DB systems in existence,
it was possible that more undesirable
behaviors in the same area were still lurking,
just waiting to be hit.</p></li>
</ul>
<p>When I was thinking about this, I was reminded of
<em>The Mythical Man Month</em>, where in the titular chapter,
Brooks devotes the very first section to discussing
programmers’ optimism.</p>
<blockquote>
<p>All programmers are optimists. [..]</p>
<p>In a single task, the assumption all will go well has
a probabilistic efect on the schedule. It might indeed go
as planned, for there is a probability distribution for
the delay that will be encountered, and “no delay” has a
fine probability. A large programming effort, however,
consists of many tasks, some chained end-to-end.
The probability that each will go well becomes vanishingly small.</p>
</blockquote>
<p>Here, Brooks is discussing optimism it in the context of planning.
Overall, the section is largely anecdotal and speculative about causes.
This point about optimism in the context of planning has been
<a href="https://blog.codinghorror.com/defeating-optimism/">repeated by Kent Beck and Jeff Atwood</a>.</p>
<p>However, the <a href="https://web.mit.edu/curhan/www/docs/Articles/biases/67_J_Personality_and_Social_Psychology_366,_1994.pdf">planning fallacy is common across professions</a>.</p>
<p>I’m curious: is there research showing programmers tend to be more optimistic than other professions? (🧠: “Am I the weird one?”)
And does this optimism apply when reasoning about error cases, and how programmers adjust their trust levels in particular bits of code as they discover bugs? I searched for a bit but didn’t get much, but if you’re reading this and know some research in this area, please let me know. 😃</p>
          </section>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-Source DocumentAI with Ollama (252 pts)]]></title>
            <link>https://rlama.dev/</link>
            <guid>43296918</guid>
            <pubDate>Sat, 08 Mar 2025 02:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rlama.dev/">https://rlama.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=43296918">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="features"><div><h3>Document Indexing</h3><p>Index any document folder for intelligent retrieval and querying.</p></div><div><h3>Multi-Format Support</h3><p>Support for text, code, PDF, DOCX, and many other document formats.</p></div><div><h3>Local Processing</h3><p>Process everything locally with Ollama models. No data leaves your machine.</p></div><div><h3>Interactive Sessions</h3><p>Create interactive RAG sessions to query your document knowledge base.</p></div><div><h3>Easy Management</h3><p>Simple commands to create, list, and delete your RAG systems.</p></div><div><h3>Developer Friendly</h3><p>Built with Go and designed for developers and technical users.</p></div></div><div id="examples"><pre tabindex="0"><code><span><span># Create a new RAG system named "documentation" using the llama3 model</span></span>
<span><span># and indexing all documents in the ./docs folder</span></span>
<span><span>rlama</span><span> rag</span><span> llama3</span><span> documentation</span><span> ./docs</span></span>
<span></span>
<span><span># You'll see progress as documents are processed</span></span>
<span><span>Processing</span><span> file:</span><span> docs/installation.md</span></span>
<span><span>Processing</span><span> file:</span><span> docs/commands.md</span></span>
<span><span>Processing</span><span> file:</span><span> docs/troubleshooting.pdf</span></span>
<span><span>...</span></span>
<span><span>RAG</span><span> system</span><span> "documentation"</span><span> created</span><span> successfully!</span></span>
<span></span></code></pre></div><div id="commands"><h2>Command Reference</h2><div><div><p>Create a new RAG system from documents</p><div><p>rlama rag [model] [rag-name] [folder-path]</p><div><p><span>Example:</span></p><!-- --><p>rlama rag llama3 documentation ./docs</p></div></div></div><div><p>Start an interactive session with a RAG system</p><div><p>rlama run [rag-name]</p><div><p><span>Example:</span></p><!-- --><p>rlama run documentation</p></div></div></div><div><p>List all available RAG systems</p></div><div><p>Delete a RAG system</p><div><p>rlama delete [rag-name] [--force/-f]</p><div><p><span>Example:</span></p><!-- --><p>rlama delete old-project --force</p></div></div></div><div><p>Update RLAMA to the latest version</p><div><p>rlama update [--force/-f]</p></div></div></div></div><div id="troubleshooting"><h2>Troubleshooting</h2><p>Common issues and their solutions</p></div><div id="formats"><h2>Supported File Formats</h2><div><div><h3>Text</h3><div><p>.txt</p><p>.md</p><p>.html</p><p>.json</p><p>.csv</p><p>.yaml</p><p>.yml</p><p>.xml</p></div></div><div><h3>Code</h3><div><p>.go</p><p>.py</p><p>.js</p><p>.java</p><p>.c</p><p>.cpp</p><p>.h</p><p>.rb</p><p>.php</p><p>.rs</p><p>.swift</p><p>.kt</p></div></div><div><h3>Documents</h3><div><p>.pdf</p><p>.docx</p><p>.doc</p><p>.rtf</p><p>.odt</p><p>.pptx</p><p>.ppt</p><p>.xlsx</p><p>.xls</p><p>.epub</p></div></div></div></div><div id="cta"><p>Ready to streamline your document question-answering?</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Take It Down Act: A Flawed Attempt to Protect Victims That'll Lead to Censorship (113 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship</link>
            <guid>43296886</guid>
            <pubDate>Sat, 08 Mar 2025 02:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship">https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship</a>, See on <a href="https://news.ycombinator.com/item?id=43296886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>Congress has begun debating the TAKE IT DOWN Act (</span><a href="https://www.congress.gov/bill/119th-congress/senate-bill/146"><span>S. 146</span></a><span>), a bill that seeks to speed up the removal of a troubling type of online content: non-consensual intimate imagery, or NCII. In recent years, concerns have also grown about the use of digital tools to alter or create such images, </span><a href="https://www.eff.org/deeplinks/2019/06/congress-should-not-rush-regulate-deepfakes"><span>sometimes called deepfakes</span></a><span>. <br></span></p>
<p><span>While protecting victims of these heinous privacy invasions is a legitimate goal, good intentions alone are not enough to make good policy. As currently drafted, the Act mandates a notice-and-takedown system that threatens free expression, user privacy, and due process, without addressing the problem it claims to solve. <br></span></p>
<h3><b>The Bill Will Lead To Overreach and Censorship</b></h3>
<p><span>S.B. 146&nbsp;mandates that websites and other online services remove flagged content within 48 hours and requires “reasonable efforts” to identify and remove known copies. Although this provision is designed to allow NCII victims to remove this harmful content, its broad definitions and lack of safeguards will likely lead to people misusing the notice-and-takedown system to remove lawful speech.</span></p>
<p><a href="https://act.eff.org/action/the-take-it-down-act-will-censor-legal-speech-without-helping-victims/">take action</a></p>
<p>"Take It Down" Has No real Safeguards<span>&nbsp;</span><span>&nbsp;</span></p>
<p><span>The takedown provision applies to a much broader category of content—potentially any images involving intimate or sexual content—than the narrower NCII definitions found elsewhere in the bill. The takedown provision also lacks critical safeguards against frivolous or bad-faith takedown requests. Lawful content—including satire, journalism, and political speech—could be wrongly censored. The legislation’s tight time frame requires that apps and websites remove content within 48 hours, meaning that online service providers, particularly smaller ones, will have to comply so quickly to avoid legal risk that they won’t be able to verify claims. Instead, automated filters will be used to catch duplicates, but these systems are </span><a href="https://www.eff.org/takedowns/automated-copyright-filter-cant-detect-infringement-or-irony"><span>infamous for flagging legal content</span></a><span>, from fair-use commentary to news reporting.</span></p>
<p><span>TAKE IT DOWN creates a far broader internet censorship regime than the Digital Millennium Copyright Act (DMCA), which has been </span><a href="https://www.eff.org/files/2020/09/04/mcsherry_statement_re_copyright_9.7.2020-final.pdf"><span>widely abused</span></a><span> to </span><a href="https://www.eff.org/takedowns"><span>censor legitimate speech</span></a><span>. But at least the DMCA has an anti-abuse provision and protects services from copyright claims should they comply.&nbsp;This bill contains none of those minimal speech protections and essentially greenlights misuse of its takedown regime.</span></p>
<h3><b>Threats To Encrypted Services <br></b></h3>
<p><span>The online services that do the best job of protecting user privacy could also be under threat from Take It Down. While the bill exempts email services, it does not provide clear exemptions for private messaging apps, cloud storage, and other end-to-end encrypted (E2EE) services. Services that use end-to-end encryption, by design, are </span><i><span>not able to access or view</span></i><span> unencrypted user content. <br></span></p>
<p><span>How could such services comply with the takedown requests mandated in this bill? Platforms may respond by abandoning encryption entirely in order to be able to monitor content—turning private conversations into surveilled spaces. <br></span></p>
<p><span>In fact, victims of NCII often rely on encryption for safety—to communicate with advocates they trust, store evidence, or escape abusive situations. The bill’s failure to protect encrypted communications could harm the very people it claims to help.</span></p>
<h3><b>Victims Of NCII Have Legal Options Under Existing Law</b></h3>
<p><span>An array of criminal and civil laws already exist to address NCII. In addition to 48 states that have specific laws </span><a href="https://www.findlaw.com/criminal/criminal-charges/revenge-porn-laws-by-state.html"><span>criminalizing the distribution of non-consensual pornography</span></a><span>, there are defamation, harassment, and extortion statutes that can all be wielded against people abusing NCII. Since 2022, NCII victims have also been able to bring </span><a href="https://www.justice.gov/atj/sharing-intimate-images-without-consent-know-your-rights"><span>federal civil lawsuits</span></a><span> against those who spread this harmful content. <br></span></p>
<p><span>As </span><a href="https://www.eff.org/deeplinks/2018/02/we-dont-need-new-laws-faked-videos-we-already-have-them"><span>we explained in 2018</span></a><span>: <br></span></p>
<blockquote><p><span>If a deepfake is used for criminal purposes, then criminal laws will apply. If a deepfake is used to pressure someone to pay money to have it suppressed or destroyed, extortion laws would apply. For any situations in which deepfakes were used to harass, harassment laws apply. There is no need to make new, specific laws about deepfakes in either of these situations.</span></p>
</blockquote>
<p><span><br></span><span>In many cases, civil claims could also be brought against those distributing the images under causes of action like False Light invasion of privacy. False light claims commonly address photo manipulation, embellishment, and distortion, as well as deceptive uses of non-manipulated photos for illustrative purposes. <br></span></p>
<p><span>A false light plaintiff (such as a person harmed by NCII) must prove that a defendant (such as a person who uploaded NCII) published something that gives a false or misleading impression of the plaintiff in such a way to damage the plaintiff’s reputation or cause them great offense.&nbsp;</span></p>
<p><span>Congress should focus on enforcing and improving these existing protections, rather than opting for a broad takedown regime that is bound to be abused. Private platforms can play a part as well, improving reporting and evidence collection systems.&nbsp; <br></span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feds Link $150M Cyberheist to 2022 LastPass Hacks (370 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/03/feds-link-150m-cyberheist-to-2022-lastpass-hacks/</link>
            <guid>43296656</guid>
            <pubDate>Sat, 08 Mar 2025 01:26:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/03/feds-link-150m-cyberheist-to-2022-lastpass-hacks/">https://krebsonsecurity.com/2025/03/feds-link-150m-cyberheist-to-2022-lastpass-hacks/</a>, See on <a href="https://news.ycombinator.com/item?id=43296656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>In September 2023, KrebsOnSecurity published findings from security researchers who concluded that a series of six-figure cyberheists across dozens of victims resulted from thieves cracking master passwords stolen from the password manager service <strong>LastPass</strong> in 2022. In a court filing this week, U.S. federal agents investigating a spectacular $150 million cryptocurrency heist said they had reached the same conclusion.</p>
<p><img decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2015/06/lastpass-580x132.png" alt="" width="580" height="132" srcset="https://krebsonsecurity.com/wp-content/uploads/2015/06/lastpass-580x132.png 580w, https://krebsonsecurity.com/wp-content/uploads/2015/06/lastpass.png 808w" sizes="(max-width: 580px) 100vw, 580px"></p>
<p>On March 6, federal prosecutors in northern California said they seized approximately $24 million worth of cryptocurrencies that were clawed back following a $150 million cyberheist on Jan. 30, 2024. The complaint refers to the person robbed only as “Victim-1,” but according to blockchain security research <strong>ZachXBT</strong> the theft was perpetrated against <strong>Chris Larsen</strong>, the co-founder of the cryptocurrency platform <strong>Ripple</strong>.</p>
<p>ZachXBT was the <a href="https://x.com/zachxbt/status/1752694489905528943" target="_blank" rel="noopener">first to report on the heist</a>, of which approximately $24 million was frozen by the feds before it could be withdrawn. This week’s action by the government merely allows investigators to officially seize the frozen funds.</p>
<p>But there is an important conclusion in this seizure document: It basically says the <strong>U.S. Secret Service</strong> and the <strong>FBI</strong> agree with the findings of <a href="https://krebsonsecurity.com/2023/09/experts-fear-crooks-are-cracking-keys-stolen-in-lastpass-breach/" target="_blank" rel="noopener">the LastPass breach story published here in September 2023</a>. That piece quoted security researchers who said they were witnessing six-figure crypto heists several times each month that they believed all appeared to be the result of crooks cracking master passwords for the password vaults stolen from LastPass in 2022.</p>
<p>“The Federal Bureau of Investigation has been investigating these data breaches, and law enforcement agents investigating the instant case have spoken with FBI agents about their investigation,” reads the seizure complaint, which was written by a U.S. Secret Service agent. “From those conversations, law enforcement agents in this case learned that the stolen data and passwords that were stored in several victims’ online password manager accounts were used to illegally, and without authorization, access the victims’ electronic accounts and steal information, cryptocurrency, and other data.”</p>
<p>The document continues:</p>
<p>“Based on this investigation, law enforcement had probable cause to believe the same attackers behind the above-described commercial online password manager attack used a stolen password held in Victim 1’s online password manager account and, without authorization, accessed his cryptocurrency wallet/account.”</p>
<p>Working with dozens of victims, security researchers <strong>Nick Bax</strong> and <strong>Taylor Monahan</strong> found that none of the six-figure cyberheist victims appeared to have suffered the sorts of attacks that typically preface a high-dollar crypto theft, such as the compromise of one’s email and/or mobile phone accounts, or SIM-swapping attacks.</p>
<p>They discovered the victims all had something else in common: Each had at one point stored their cryptocurrency seed phrase — the secret code that lets anyone gain access to your cryptocurrency holdings — in the “Secure Notes” area of their LastPass account prior to the 2022 breaches at the company.</p>
<p>Bax and Monahan found another common theme with these robberies: They all followed a similar pattern of cashing out, rapidly moving stolen funds to a dizzying number of drop accounts scattered across various cryptocurrency exchanges.</p>
<p>According to the government, a similar level of complexity was present in the $150 million heist against the Ripple co-founder last year.</p>
<p>“The scale of a theft and rapid dissipation of funds would have required the efforts of multiple malicious actors, and was consistent with the online password manager breaches and attack on other victims whose cryptocurrency was stolen,” the government wrote. “For these reasons, law enforcement agents believe the cryptocurrency stolen from Victim 1 was committed by the same attackers who conducted the attack on the online password manager, and cryptocurrency thefts from other similarly situated victims.”</p>
<p>Reached for comment, LastPass said it has seen no definitive proof — from federal investigators or others — that the cyberheists in question were linked to the LastPass breaches.</p>
<p>“Since we initially disclosed this incident back in 2022, LastPass has worked in close cooperation with multiple representatives from law enforcement,” LastPass said in a written statement. “To date, our law enforcement partners have not made us aware of any conclusive evidence that connects any crypto thefts to our incident. In the meantime, we have been investing heavily in enhancing our security measures and will continue to do so.”<span id="more-70634"></span></p>
<p>On August 25, 2022,&nbsp;<strong>LastPass CEO Karim Toubba</strong> told users the company had detected unusual activity in its software development environment, and that the intruders stole some source code and proprietary LastPass technical information. On Sept. 15, 2022, LastPass said an investigation into the August breach determined the attacker did not access any customer data or password vaults.</p>
<p>But on Nov. 30, 2022, LastPass notified customers about another, far more serious security incident that the company said leveraged data stolen in the August breach. LastPass disclosed that criminal hackers had compromised encrypted copies of some password vaults, as well as other personal information.</p>
<p>Experts say the breach would have given thieves “offline” access to encrypted password vaults, theoretically allowing them all the time in the world to try to crack some of the weaker master passwords using powerful systems that can attempt millions of password guesses per second.</p>
<p>Researchers found that many of the cyberheist victims had chosen master passwords with relatively low complexity, and were among LastPass’s oldest customers. That’s because legacy LastPass users were more likely to have master passwords that were protected with far fewer “iterations,” which refers to the number of times your password is run through the company’s encryption routines. In general, the more iterations, the longer it takes an offline attacker to crack your master password.</p>
<p>Over the years, LastPass forced new users to pick longer and more complex master passwords, and they increased the number of iterations on multiple occasions by several orders of magnitude. But researchers found strong indications that LastPass never succeeded in upgrading many of its older customers to the newer password requirements and protections.</p>
<p>Asked about LastPass’s continuing denials, Bax said that after the initial warning in our 2023 story, he naively hoped people would migrate their funds to new cryptocurrency wallets.</p>
<p>“While some did, the continued thefts underscore how much more needs to be done,” Bax told KrebsOnSecurity. “It’s validating to see the Secret Service and FBI corroborate our findings, but I’d much rather see fewer of these hacks in the first place. ZachXBT and <a href="https://x.com/_SEAL_Org/status/1868805837311074576" target="_blank" rel="noopener">SEAL 911&nbsp;reported yet another wave of thefts</a> as recently as December, showing the threat is still very real.”</p>
<p>Monahan said&nbsp;LastPass still hasn’t alerted their customers that their secrets—especially those stored in “Secure Notes”—may be at risk.</p>
<p>“Its been two and a half years since LastPass was first breached [and] hundreds of millions of dollars has been stolen from individuals and companies around the globe,” Monahan said. “They could have encouraged users to rotate their credentials. They could’ve prevented millions and millions of dollars from being stolen by these threat actors. But&nbsp; instead they chose to deny that their customers were are risk and blame the victims instead.”</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GeoCities in 1995: Building a Home Page on the Internet (153 pts)]]></title>
            <link>https://cybercultural.com/p/geocities-1995/</link>
            <guid>43296103</guid>
            <pubDate>Fri, 07 Mar 2025 23:52:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cybercultural.com/p/geocities-1995/">https://cybercultural.com/p/geocities-1995/</a>, See on <a href="https://news.ycombinator.com/item?id=43296103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
<article data-pagefind-body="">
  <div>
        
    <p>GeoCities, known throughout most of 1995 as Beverly Hills Internet, was one of the first commercial internet services to make it easy for people to publish a home page on the World Wide Web.</p>
    <p><picture><source type="image/webp" srcset="https://cybercultural.com/img/CxNXAycujt-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="eager" decoding="async" src="https://cybercultural.com/img/CxNXAycujt-1280.jpeg" alt="Beverley Hills Internet in 1995, before being renamed GeoCities" width="1280" height="720"></picture>
<em>Beverley Hills Internet in 1995, before being renamed GeoCities.</em></p>
<p>By 1995, people had begun to create their own web pages on the World Wide Web — or “home pages” as they were called back then. Previously, home pages had typically been created by professional coders, or academics who had technical knowledge of the web. Not only did you need to know how to code in HTML, <a href="https://cybercultural.com/p/1990-programming-the-world-wide-web/">the web’s programming language</a>, but you also needed to know how to operate <a href="https://cybercultural.com/p/1995-apache-microsoft-iis-web-server-market/">web servers</a> and FTP (File Transfer Protocol) software.</p>
<p>But as the web <a href="https://cybercultural.com/p/internet-1994/">became more popular</a>, consumer-friendly tools emerged to help people create a home page. Beverly Hills Internet (BHI), later renamed GeoCities, was one of them.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/TZ6Mjb6QSY-787.webp 787w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/TZ6Mjb6QSY-787.jpeg" alt="A rare 1995 screenshot of the Beverly Hills Internet website" width="787" height="1000"></picture>
<em>A rare 1995 screenshot of the Beverly Hills Internet website; from <a href="https://www.computerhistory.org/collections/catalog/102784973" target="_blank" rel="noopener">The David Bohnett papers</a>, Computer History Museum (<a href="https://digipres.club/@andrewjbtw/114120313604675698" target="_blank" rel="noopener">via Andrew Berger on Mastodon</a>).</em></p>
<p>GeoCities had been started in late 1994 by David Bohnett and John Rezner. Initially it was a web hosting service named Beverly Hills Internet (www.bhi90210.com), because that’s where Bohnett lived and worked. After getting some local businesses up and running with their first webpage, he began to think of what he could offer beyond web hosting.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/YPJwN_8ZLE-776.webp 776w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/YPJwN_8ZLE-776.jpeg" alt="Printout of a page from the Beverly Hills Internet website, 1995" width="776" height="1000"></picture>
<em>Printout from the original Beverly Hills Internet business plan in 1995; from <a href="https://www.computerhistory.org/collections/catalog/102784973" target="_blank" rel="noopener">The David Bohnett papers</a>, Computer History Museum (<a href="https://digipres.club/@andrewjbtw/114120313604675698" target="_blank" rel="noopener">via Andrew Berger on Mastodon</a>).</em></p>
<p>Bohnett then set up a couple of webcams, one at his Beverly Hills office and the other at the Hollywood office of a friend. This brought in a bit of traffic, which gave him the idea to offer free home pages to people based on those locations. For the webcam in Beverley Hills, people could set up a web page based around shopping. And for the Hollywood webcam, people would be able to create a fan page for a celebrity — or any entertainment product. These two “cyber cities” were called RodeoDrive and Hollywood.</p>
<p>Four other location-themed communities were added soon after: SunsetStrip (music and nightlife), WallStreet (business), the Colosseum (sports), and WestHollywood (for the gay and lesbian community — Bohnett is gay).</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/RfzJbTBnfp-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/RfzJbTBnfp-1280.jpeg" alt="Rick and Margaret's little part of the Web" width="1280" height="800"></picture>
<em><a href="https://web.archive.org/web/19961221111447/http://www.geocities.com/RodeoDrive/1201/" target="_blank" rel="noopener">Rick and Margaret's little part of the Web</a>, located on RodeoDrive; voted "Cool Homestead Page of the Day" <a href="https://web.archive.org/web/19961221024846/http://www.geocities.com/homestead/coolaug.html" target="_blank" rel="noopener">on 8 August 1995</a>.</em></p>
<h2>A Home on the Internet</h2>
<p>In July 1995, Beverly Hills Internet (BHI) <a href="https://web.archive.org/web/20140108022248/http://www.thefreelibrary.com/Beverly+Hills+Internet,+builder+of+interactive+cyber+cities,+launches...-a017190114" target="_blank" rel="noopener">announced</a> another four “virtual communities based on real-world locations” — SiliconValley (for technology), CapitolHill (for politics), Paris (for the arts) and Tokyo (for anime and “all things Asian,” according to <a href="https://www.bladesplace.id.au/geocities-neighborhoods-suburbs.html" target="_blank" rel="noopener">Blade’s Place</a>). By this time, the young company had begun to name these communities “GeoCities.” They’d also appropriated the term “Homesteader” to denote a person who published a web page on the service.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/jbbPhecUOU-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/jbbPhecUOU-1280.jpeg" alt="GeoCities homesteading" width="1280" height="800"></picture>
<em>GeoCities "homesteading" page, circa 1996.</em></p>
<p>The key to BHI's initial growth over 1995 was helping people who had no technical knowledge of HTML to build a web page on the internet. It offered a “Personal GeoPage Generator” that enabled homesteaders to easily create a home page. But more than that, and as the name for its users implied, Bohnett wanted to give people the sense that they had <em>a home</em> on the internet.</p>
<p>“You may surf the net via access utilities or online services but you'll live in BHI's GeoCities,” he said in a press release. “There, on the street or in the city of your choice, you'll dwell in a home that reflects the context of your life, become part of the fabric of the community and establish your own net culture.”</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/8CipgoPt_r-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/8CipgoPt_r-1280.jpeg" alt="Disco Stu on Geocities" width="1280" height="800"></picture>
<em>Disco Stu's House of Fun, in the SiliconValley community on GeoCities; <a href="https://geocities.restorativland.org/SiliconValley/1200/" target="_blank" rel="noopener">via restorativland</a>.</em></p>
<p>Bohnett was perhaps the first web entrepreneur with the gift of the gab for marketing. Essentially he was offering a way for people to create a web page on the internet, but he spun that basic idea into an elaborate geographic metaphor. When a new user joined a community, they were even given a “street number” for their virtual neighbourhood.</p>
<p>“This is the next wave of the net — not just information but habitation,” said Bohnett.</p>
<h2>GeoCities Design</h2>
<p>When we look back on GeoCities today, we often think about all the quirky elements that made up a GeoCities web page in the 1990s: the animated GIFs, the garish colours, the cartoon fonts, the “Under Construction” icons. But in 1995, when the site was still known as Beverly Hills Internet, the web pages were relatively sparse.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/SyjN5sMYZ9-800.webp 800w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/SyjN5sMYZ9-800.jpeg" alt="Bruce's Home Page" width="800" height="600"></picture>
<em>A GeoCities page from September 1995; <a href="https://blog.geocities.institute/archives/7175" target="_blank" rel="noopener">via One Terabyte of Kilobyte Age</a>.</em></p>
<p>Olia Lialina, an internet artist from Germany and co-founder of the <a href="https://anthology.rhizome.org/one-terabyte-of-kilobyte-age" target="_blank" rel="noopener">GeoCities Research Institute</a> with Dragan Espenschied, has studied the early web more than most. On <a href="https://blog.geocities.institute/archives/7198" target="_blank" rel="noopener">the project’s blog</a>, <em>One Terabyte of Kilobyte Age</em>, Lialina commented that many of the GeoCities pages archived from 1995 had design features in common, including “‘Under Construction’ and ‘Cool Links’ ribbons down the page, and the red bullet opening the ‘Links to other sites on the web’ section.” Horizontal bars were also common to these early pages, along with a limited selection of icons (small, usually square, image files).</p>
<p>Lialina concluded that these common design elements were the result of a template, via BHI’s “Personal GeoPage Generator.” She spoke with Bohnett about this and he described the generator as “a sample page, that one could edit in browser, by filling in text into the forms and by choosing icons, rulers and bullets from the menus.” The icons available were the result of Bohnett “surfing the web and saving items that would in his opinion match the expectations of the first webmasters.” Many of these early icons were national flags, but there were also things like an image of Dr Spock from Star Trek, Grover from Sesame Street, Calvin from the ‘Calvin and Hobbes’ cartoon strip, a newspaper icon, a bomb icon, and so forth.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/PTuX1ybH9o-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/PTuX1ybH9o-1280.jpeg" alt="GeoCities icons" width="1280" height="496"></picture>
<em>Some GeoCities icons circa 1995; <a href="https://blog.geocities.institute/archives/7198" target="_blank" rel="noopener">via Olia Lialina</a>.</em></p>
<p>Most BHI web pages from 1995 were relatively simple in construction and featured the elements noted above. The selection of images and icons became more extensive over time, while users also began to experiment more with web design. Another factor was the introduction of interactivity to websites at the end of 1995, when <a href="https://cybercultural.com/p/1995-the-birth-of-javascript/">JavaScript debuted</a> in Netscape Navigator 2.0 in December.</p>
<p>But it would take more time for scripting to infiltrate into GeoCities home pages. As <a href="https://olia.geocities.institute/@GIFmodel/114117144312113770" target="_blank" rel="noopener">Lialina told me on Mastodon</a>, "stylewise, the most significant thing about "Geo1995" in contrast to widely celebrated "Geo1996" is that the pages were very close to the sample page David Bohnett put online some time in between May and July 1995."</p>
<h2>Gated Communities?</h2>
<p>In <a href="https://web.archive.org/web/19961221012836/http://www.geocities.com/BHI/pr1215.html" target="_blank" rel="noopener">December 1995</a>, BHI changed its name to GeoCities (although its web address was initially www.geopages.com). By this point, there were fourteen different geographic-themed communities and the service had attracted more than 20,000 users since its launch in June.</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/IGJryUFP8Y-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/IGJryUFP8Y-1280.jpeg" alt="GeoCities web page 1995/96" width="1280" height="800"></picture>
<em><a href="https://geocities.restorativland.org/SiliconValley/2463/" target="_blank" rel="noopener">The Olivia Siu Home Page</a>; an example of a GeoCities web page from the SiliconValley community, circa end of 1995 or start of 1996 (judging by the Gary Numan reference — his website NuWorld launched in the latter part of '95).</em></p>
<p>GeoCities went on to become hugely influential over the rest of the 1990s. However, we have to remember that ultimately it was a centralized platform that put certain dimensions around the creativity of those early web users. Other, similar, web hosting services would emerge during the mid-to-late nineties, such as Tripod, Angelfire and Homestead.</p>
<p>If you knew how to set up a web server and do HTML coding, you could of course create your own website outside of those services. As Lialina put it in <a href="https://blog.geocities.institute/archives/6418" target="_blank" rel="noopener">a later blog post</a>, “the point about the web before social networks or before Web 2.0 is not that you had a profile on GeoCities, but that you had a chance to build your cyber home outside of it, you could exist and grow outside of a centralized service.”</p>
<p><picture><source type="image/webp" srcset="https://cybercultural.com/img/fx7LxncqQo-1280.webp 1280w" sizes="(max-width: 768px) 100vw, 1280px"><img loading="lazy" decoding="async" src="https://cybercultural.com/img/fx7LxncqQo-1280.jpeg" alt="GeoCities home" width="1280" height="720"></picture>
<em>GeoCities home icons; via <a href="https://www.cameronsworld.net/" target="_blank" rel="noopener">Cameron's World</a>.</em></p>
<p>Lialina claims that GeoCities was not even a very good web hosting service. “It was free and not worse than others,” she wrote, and “that’s why webmasters endured the pain of clumsy page builders, interventions from commercial scripts being injected into their pages, accidental file deletions, etc.”</p>
<p>Regardless, the emergence of GeoCities over 1995 did make it easier for non-technical people to create a presence on the World Wide Web. Its design elements were certainly clunky and destined to become clichéd, but services like GeoCities were an important stepping stone for the rise of <a href="https://cybercultural.com/p/1996-flash-css-web-design/">creative expression on the web</a>.</p>
<hr>




 

<h2>Buy the Book</h2>
<p>My <a href="https://cybercultural.com/p/book-release-bubbleblog/">Web 2.0 memoir</a>, <em>Bubble Blog: From Outsider to Insider in Silicon Valley's Web 2.0 Revolution</em>, is now available to purchase:</p>
<ul>
<li>Paperback, US$19.99: <a href="https://www.amazon.com/Bubble-Blog-Outsider-Insider-Revolution/dp/B0DQKRB3P5?&amp;linkCode=ll1&amp;tag=richardmacman-20&amp;linkId=b38f92f2c0bd2c9f05cda3a07413fd40&amp;language=en_US&amp;ref_=as_li_ss_tl" target="_blank" rel="noopener">Amazon</a>; <a href="https://bookshop.org/p/books/bubble-blog-from-outsider-to-insider-in-silicon-valley-s-web-2-0-revolution-richard-macmanus/22135084" target="_blank" rel="noopener">Bookshop.org</a></li>
<li>eBook, US$9.99: <a href="https://www.amazon.com/Bubble-Blog-Outsider-Insider-Revolution-ebook/dp/B0DQJQ4LJ9?&amp;linkCode=ll1&amp;tag=richardmacman-20&amp;linkId=63e982f1c9d1ded8c83666d8b6917ff7&amp;language=en_US&amp;ref_=as_li_ss_tl" target="_blank" rel="noopener">Amazon Kindle Store</a>; <a href="http://books.apple.com/us/book/id6739734992" target="_blank" rel="noopener">Apple Books</a>; <a href="https://play.google.com/store/books/details?id=Sug5EQAAQBAJ" target="_blank" rel="noopener">Google Play</a></li>
</ul>

<p>Or search for "Bubble Blog MacManus" on your local online bookstore.</p>
  </div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How did places like Bell Labs know how to ask the right questions? (2023) (161 pts)]]></title>
            <link>https://www.freaktakes.com/p/how-did-places-like-bell-labs-know</link>
            <guid>43295865</guid>
            <pubDate>Fri, 07 Mar 2025 23:14:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.freaktakes.com/p/how-did-places-like-bell-labs-know">https://www.freaktakes.com/p/how-did-places-like-bell-labs-know</a>, See on <a href="https://news.ycombinator.com/item?id=43295865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Many new science orgs are looking to pursue research that has the positive aspects of both “applied” research and “basic” research. To me, this is a very reasonable approach. After all, the “applied vs. basic research” distinction has always been </span><a href="https://freaktakes.substack.com/p/is-americas-applied-and-basic-research" rel="">a rather arbitrary one</a><span>.</span></p><p>Some research projects feel like they are squarely in one bucket or the other, but it’s not always that clear. Applied research is meant to be research with immediate applications in mind. But, of course, applied research could stumble upon something that leads to a fundamental insight. Basic research is meant to be curiosity-driven research without immediate applications in mind. But, of course, it could quickly lead to a killer application.</p><p>In the universe of possible courses of research, there exist many questions that, in the end, will satisfy the spirit of both applied and basic research.</p><p>The natural follow-up question is: is finding this subset of golden problems really feasible?</p><p>One’s knee-jerk reaction might be that it is not replicable in any kind of systematic way; it is a matter of unreliable personal taste. The history tells a different story. The mid-20th century’s great American R&amp;D labs show us that selecting profitable courses of research that satisfy the spirit of basic research has been done at a high level within large research organizations over the course of several decades.</p><p>In this piece, I dive into exactly how Bell Labs ensured that their researchers were working on the right problems. This piece will be the first in a series examining what modern applied research orgs can learn from the great dragons of industrial R&amp;D — places like Bell Labs, GE Research Laboratory, and DuPont’s research department.</p><p>Institutions like these not only had Nobel prizes to their names, but each — even though they’ve diminished for various reasons — was quite profitable too. They had their differences, but they all stumbled upon many aspects of managing their research operations that were rather similar. The managers of these organizations — and other researchers at the time — often felt the management decisions they made were common sense rather than some great discovery.</p><p>However, these common-sense decisions are things we often don’t do today – but almost certainly should.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg" width="460" height="295.39835164835165" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:935,&quot;width&quot;:1456,&quot;resizeWidth&quot;:460,&quot;bytes&quot;:655782,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63ec0960-abc8-44d5-aeba-547a3b9e3ea5_1600x1028.jpeg 1456w" sizes="100vw" loading="lazy" fetchpriority="high"></picture></div></a><figcaption><span>Image pulled from a 1922 issue of </span><em>Bell Telephone Magazine. </em><span>The image, portraying the switching development department, was used in an article explaining how “systems engineering has played a dominant part in every aspect of Bell Laboratories work” and why it was no surprise that the approach worked equally well in facilitating Bell Lab’s successful World War I work.</span></figcaption></figure></div><p><em>Sorry for the delay since my last post. I was 1) working on some projects for some applied science orgs and 2) wrote a piece for the coming issue of Works in Progress that is coming out soon!</em></p><p><em><span>You will be getting much more frequent releases from me in the coming couple of months, I promise. As always, if you’d like to discuss how to implement any of the ideas in the piece in your own operation, feel free to</span><a href="https://twitter.com/eric_is_weird" rel=""> reach out on Twitter</a><span>!</span></em></p><p><em><span>The initial inspiration for much of this piece comes from Jon Gertner’s book,</span><a href="https://amzn.to/3UvohyF" rel=""> Idea Factory</a><span>, on the history of Bell Labs. In places, I quote Gertner’s descriptions of events where his words did a better job than mine could.</span></em></p><p><em><span>This piece is done in partnership with the</span><a href="https://goodscience.substack.com/" rel=""> Good Science Project</a><span>.</span></em></p><p><em>Back to the action.</em><span>.</span></p><p>Bell Labs has become legendary in many tech circles. It’s no secret why. Famous ideas and technology like information theory, communications satellites, solar batteries, transistors, and countless other communications-related innovations trace their origins back to Bell Labs in one way or another.</p><p>Idolizing Bell Labs for its outcomes is very fair because its outcomes were extraordinary. Many, in recent years, have also begun to idolize Bell Labs’ for its processes. And there’s nothing conceptually wrong with that. If a place has consistently fantastic outcomes and seems to have some secret sauce that is super-additive to the productivity of its researchers, why would we not seek to replicate it?</p><p>We should. The issue is that many who idolize Bell’s processes seem to fundamentally misunderstand how the operation worked. The most notable misconception is that many put Bell forward as the poster child of how idle curiosity and the purest kind of basic research can have a role in industry. Looking at the historical sources, that’s not exactly an accurate takeaway.</p><p>Bell did a lot of astonishing basic research. But its research, while “basic” for an applied R&amp;D lab, was not nearly as free as many imagine — or, rather, it embodied a different kind of freedom. Equating the freedom of a Fine Hall mathematician at the Princeton Institute for Advanced Study and a physicist at Bell Labs in the 1950s is not an accurate way of looking at it.</p><p>Bell was an industrial R&amp;D lab. To an industrial R&amp;D lab, the mission is everything. Frank Jewett, the founding Director of Bell Labs, once said that his new industrial R&amp;D lab was to be:</p><blockquote><p>An instrument capable of avoiding many of the mistakes of a blind cut-and-try experimentation. It is likewise an instrument which can bring to bear an aggregate of creative force on any particular problem which is infinitely greater than any force which can be conceived of as residing in the intellectual capacity of an individual.</p></blockquote><p>This focus on applications leading the research is not one that faded over the course of Bell Labs’ lifetime.</p><p>John Pierce — whose 35-year career (1936-1971) at Bell Labs as researcher and manager encompassed most of Bell Labs’ existence — said this of what made Bell Labs a success:</p><blockquote><p>Someone depended on them for something, and was anxious to get it. They were really needed, and they rose to the need.</p></blockquote><p>The people who see Bell Labs as a bastion of freedom in private sector research are not entirely mistaken. Bell was pretty damn free for a private-sector lab. It’s just that there was a balancing act.</p><p>Jim Fisk was one of the “Young Turks” at Bell Labs — along with Pierce — who helped shepherd in its famous balance of deep research with careful problem selection. He said the following of Bell’s philosophy on problem selection when he was managing Bell Labs:</p><blockquote><p>Our fundamental belief is that there is no difference between good science and good science relevant to our business. Among a thousand scientific problems, a hundred or so will be interesting, but only one or two will be truly rewarding — both to the world of science and to us. What we try to provide is the atmosphere that will make selecting the one or two in a thousand a matter of individual responsibility and essentially automatic.</p></blockquote><p>This is not Fisk saying that the only relevant problems in electrical communication were those that served Bell’s business interests. But it was him saying that:</p><ul><li><p>Many scientific problems are kind of a bore or derivative. He ballparked it arbitrarily at 90%.</p></li><li><p>Some minority of problems are interesting. He ballparked it arbitrarily at 10%.</p></li><li><p><span>1%-2% of the interesting problems — that is .1%-.2% of the total problems — would turn out to be worthwhile </span><em>and</em><span> relevant to Bell’s work.</span></p></li></ul><p>The picture this paints of Bell’s preferences for its basic researchers is twofold:</p><ol><li><p>The universe of possible problems is very large. Bell would like its more fundamental researchers to feel free to work on interesting ones.</p></li><li><p>Among those interesting problems, Bell Labs management would implement systems to make sure researchers identified problems that had a high probability of turning into profitable answers for the Bell Telephone system.</p></li></ol><p>Over the years, Bell Labs management developed a small but coherent set of constraints and rules of thumb to ensure that its researchers internalized that, as Jim Fisk put it, it was “a matter of individual responsibility” to choose the right problems and that Bell Lab’s success in doing this at scale, across thousands of individuals, was “essentially automatic.”</p><p>The majority of Bell Labs was made up of applied researchers, development engineers, and other staff — not basic researchers. And these groups usually had a normal boss and projects assigned to them – while Bell’s basic researchers did not. Nevertheless, even though the basic researchers did not have bosses in the traditional sense, they were still nudged to Bell-relevant problems in various ways.</p><p>The three key ways Bell Labs nudged its basic researchers toward the right problems were:</p><ol><li><p>Granting researchers what I’ll call a “long leash, but a narrow fence” in which to conduct their explorations.</p></li><li><p>Facilitating very regular interactions between the basic researchers and Bell’s fundamental development researchers, engineers, manufacturing facilities, and implementation staff.</p></li><li><p>To top it off, Bell had a corps of what they called systems engineers who ensured that the integration of its best researchers and most pressing problems was not left to chance.</p></li></ol><p>Let’s explore each of these, in turn.</p><p>Bell didn’t exactly tell its basic researchers what they could and could not work on. Not usually at least. A basic researcher’s boss was more of a mentor or advisor than an actual boss.</p><p>(Note: the basic researchers made up anywhere from 7% to 18% of Bell Lab's headcount depending on the year and which Young Turk you quote.)</p><p>These individuals were guided toward the right problems in other ways. Firstly, it was made clear that the projects should have some obvious bearing on the Bell system and future business. And one was allowed to roam around, so to speak, for a bit before working out exactly what they would be spending their time on, but they should be looking to spend their time on something quite relevant to the business.</p><p><span>The following excerpt from</span><a href="https://oralhistories.library.caltech.edu/98/1/OH_Pierce_J.pdf" rel="">John Pierce’s oral history</a><span> briefly describes his reflection on his time immediately after joining Bell. He had a particularly high level of freedom in feeling his way around for work, but still found his way into the Bell Labs groove all the same:</span></p><blockquote><div><p><span>Pierce: I was told to do research on vacuum tubes. People sort of just left me alone. They did suggest that I go and see Philo Farnsworth, who was working on electron multipliers and television pick-up tubes, but I was left pretty much to myself. This was very, very confusing to me. I didn’t know what to do. </span></p><p><span>Interviewer: Were you doing it alone? </span></p><p><span>Pierce: Yes </span></p><p><span>Interviewer: Did they say, “So-and-so has been doing this and this is where he left off”? </span></p><p><span>Pierce: No. I was just supposed to plan something to do and do it. I think that is close to cruel and unusual punishment.</span></p></div></blockquote><p>Pierce, who was giving this interview after his retirement from Bell Labs while he was at CalTech, then continues his reflection:</p><blockquote><div><p><span>Pierce: Too much freedom is horrible. It’s like telling a young child, “Do whatever you want to.” You’ve heard this story. There are various outcomes. One is, “Do I have to do what I want to?” Complete freedom is not very helpful to a person who is inexperienced in the world. It’s certainly bad to be directed to do things very, very narrowly and with no freedom. It’s my guess that for every person who needs more freedom, there are ten people who need more help in finding their way. </span></p><p><span>Interviewer: So, did they tell you why they wanted the vacuum tubes, when you started off? </span></p><p><span>Pierce: Not really. I found out some way, inadvertently. Some people were working on electron multipliers, and I made some improvements on them. It became clear that people needed better vacuum tubes for building negative feedback amplifiers, and I worked on that. I don’t think I was told this formally; I just found out by talking to people. Then, as the war approached and we got into war, it became apparent that microwave radar was very, very important, and I worked on tubes for radar. It was a process of osmosis rather than direction that led me into these things, as I remember it.</span></p></div></blockquote><p>This Pierce story is an example of things working exactly as they should. An extremely talented young researcher with a background obviously relevant to Bell — multiple electrical engineering degrees from CalTech — came to understand exactly what development work was ongoing at Labs, what it looked like for a basic researcher to be useful to that work, and came up with a course of work to suit those needs.</p><p>Morry Tannenbaum, a long-time Bell Labs chemist, famously described this patented level of freedom as “circumscribed freedom.”</p><p>Pierce’s story leads us into the second way in which Bell Labs nudged its basic researchers toward the right problems.</p><p>Relationships with the folks who might eventually deploy your research – from those who modified cutting-edge engineering equipment to those that worked in Bell’s factories – ensured researchers were hyper-aware of the problems happening throughout Bell’s massive operation.</p><p>The one hard and fast rule Labs did seem to have was that you could not say no to any request for help from any of the applied folks — or other researchers for that matter. Your day-to-day tasks often pertained to your own courses of research, but one’s role as in-house expertise was equally important. These consultations, unsurprisingly, led to all sorts of new ideas for basic research projects.</p><p>Another excerpt in Pierce’s oral history is just one of many data points that speaks to the importance of this relationship:</p><blockquote><p>I remember that during the war we saw a good deal of people from Western Electric [Bell’s manufacturing arm], who were going to manufacture the things that we devised. Because all of these people were engaged in telephony, or during the war because they were all engaged in radar and other military things, you got to talk to people who were engaged in the operation of things, who were engaged in the manufacture of things, and you got a picture of the rest of the world which certainly influenced what research you did.</p></blockquote><p>He continues, diving into how this type of interaction was a natural partner to great basic researchers:</p><blockquote><p>I can understand a university, which does teaching and research. But the idea of a research institute without ties to either teaching or to manufacturing or operational organization seems a terribly sterile idea. You see that in the Soviet Union; there’s a lot of good activity that never results in anything. When they want to build automobiles, they hire Fiat to build an automobile plant, instead of relying on what they have learned.</p></blockquote><p>(Note: Pierce also believed the university model of research to be an inferior model — for him at least — for reasons I’ll discuss later.)</p><p>And, since Bell, as a business and research operation, was far too vast and complex to rely on serendipity to match researchers and problems, it had an entire class of engineers dedicated to ensuring problems and solutions found each other.</p><p>Systems engineers – 10% of Bell Labs’ total headcount – were usually technically-trained individuals who spent all of their time, as Jon Gertner put it, keeping:</p><blockquote><p>One eye on the reservoir of new knowledge and another on the existing phone system and analyzed how to integrate the two. In other words, the systems engineers considered whether new applications were possible, plausible, necessary, and economical.</p></blockquote><p>The existence of systems engineers was Bell acknowledging that a culture of openness and helpfulness was just not sufficient when it came to finding the best problems possible. Of course, implementation/manufacturing/applied research staff often can identify which of their problems are ripe for the research team’s eyes, but a lot of the time they can’t. And yeah, sometimes researchers can come up with great research questions in their area that are ripe for helping a specific group’s work, but a lot of the time they don’t do a great job.</p><p>Even if a basic researcher does find a good applied problem, who’s to say that the problem is the best use of their time? There is almost surely a better problem out there. That’s life. The question is, can someone reliably find it?</p><p>If a systems engineer does their job well, they can.</p><p>Mervin Kelly, long-time Bell Labs manager, described the background of his systems engineers as follows:</p><blockquote><p>[Systems Engineering] staff members must supply a proper blending of competence and background in each of the three areas that it contacts: research and fundamental development, specific systems and facilities development, and operations. It is, therefore, largely made up of men drawn from these areas who have exhibited unusual talents in analysis and the objectivity so essential to their appraisal responsibility.</p></blockquote><p>Of course, there is a tradeoff here. Instead of using a systems engineer’s skills for normal scientific research or engineering tasks, these individuals were doing other kinds of work. That’s not a small tradeoff. At points, Bell’s systems engineering team was about the same size as, maybe larger than, Bell’s basic research group. But, in a large and complex organization like Bell, this tradeoff was well worth it.</p><p>The systems engineers made it their business to be extremely aware of the happenings of the research portions of Bell Labs as well as the minutiae of the industrial portions of Bell Telephone. This included details like:</p><ul><li><p>Manufacturing processes to produce electrical parts</p></li><li><p>Which materials or parts tended to degrade and needed to be replaced in the telephone system</p></li><li><p>The cost and time of various repairs and maintenance</p></li><li><p>What portions of Bell’s service were currently bottlenecked by specific technical problems</p></li></ul><p>Of course, no individual systems engineer could know everything and everyone at Bell. But the department as a whole attempted to account for everything, ensuring as little as possible fell through the cracks. And this process worked both ways. These systems engineers, in addition to bringing problems to researchers, also found ways to deploy researchers’ findings in ways that could solve problems in the field or improve Bell’s products and processes.</p><p>Mundane systems engineering problem spotting happens when a systems engineer identifies that Bell is spending the equivalent of $1 billion yearly on telephone wire maintenance in certain climates. This engineer can then notify the metallurgy researchers that this problem exists and is begging to be solved.</p><p><span>One Bell Labs executive, a former chemist, loved to point out that a synthetic plastic created by Bell chemists to replace the existing telephone cable sheathing saved Bell “more than the total research budget of Bell Labs for the decade in which the innovation was worked out.” This was an operationally boring problem that </span><em>could</em><span> have been hidden in some maintenance budget, away from the eyes of normal researchers. A system engineer exists to identify opportunities just like that.</span></p><p>The ROI of an applied research operation can obviously go up if researchers have problems like this regularly brought to them. And, it should be remembered, these problems were being brought to researchers not just as a veritable gold mine, but with many research-relevant constraints worked out from the beginning. It was the job of the systems researchers to work out as much of this as possible beforehand.</p><p><span>Mervin Kelly believed that the Bell’s continuity was what made it special. If the first two rules of thumb established the continuity, the systems engineers were what </span><em>ensured</em><span> it. Kelly spoke about the importance everything connecting the two endpoints of manufacture and basic research in a speech to the Royal Society, saying:</span></p><blockquote><p>There has been so much emphasis on industrial research and mass-production methods in my country, that even our well-informed public is not sufficiently aware of the necessary and most important chain of events that lies between the initial step of basic research and the terminal operation of manufacture. In order to stress the continuity of procedures from research to engineering of product into manufacture and to emphasize their real unity, I speak of them as the single entity ‘organized creative technology.’</p></blockquote><p><span>(Please see the </span><a href="https://freaktakes.substack.com/p/bonus-more-details-on-how-bell-labs" rel="">bonus piece</a><span> to learn more about this speech.)</span></p><p>Systems engineers did not technically do anything that you wouldn’t hope would happen with a culture of collaboration, but they were the people that made finding the “one or two in a thousand” problems relevant to Bell and converting them into successful business applications “essentially automatic.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png" width="314" height="356.1219512195122" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1302,&quot;width&quot;:1148,&quot;resizeWidth&quot;:314,&quot;bytes&quot;:3249777,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8299d017-e6c7-4442-a65a-d1bac3d84cd6_1148x1302.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A Bell systems engineering sketch of Bell’s experimental rollout of a mobile telephone system in Chicago</figcaption></figure></div><p>These rules of thumb are contrary to what many believe of Bell Labs’s culture, but most accounts I’ve read from key Labs members point to these methods as a secret sauce that made Bell Labs effective.</p><p>The famous stories of Claude Shannon frittering away his days at Bell Labs is a special case. While most researchers did not have the kinds of freedoms Shannon — or many university professors at the time — had, they were usually happy with the tradeoffs. In other ways, many felt life at Bell Labs had a different kind of freedom.</p><p>Stories of Claude Shannon frittering away his time playing games in the Bell lunchroom have become legendary. And I get why. The stories of Shannon building chess machines, juggling, and riding around on unicycles or pogo sticks are great stories. But these stories were not the norm at Bell Labs.</p><p>The bulk of these Shannon stories, at least the most “fritter-y” ones, come from after he became a celebrity in the communications world with his discovery — or “invention” depending on your philosophical view of mathematics — of information theory.</p><p><span>On the heels of that discovery, instead of some big financial reward for Shannon, Bell Labs management seems to have paid Shannon with a kind of </span><em>emeritus</em><span> status in which they gave the genius the freedom to do whatever he wished. This came with freedom to do unique things like unicycle down hallways or work with the door to his office closed.</span></p><p><span>Prior to this </span><em>emeritus</em><span> lifestyle, Shannon had lived a much more applied, standard life at Labs in which he was often roped into advising the applied folks on their issues and undertook more pressing courses of basic research — fire control and cryptography for the war effort, the mathematics of carrying calls along wires more efficiently, etc.</span></p><p><span>(Also, it’s worth noting, he used this </span><em>emeritus</em><span>-style freedom to accomplish little-to-nothing either for Bell Labs or his personal research agenda in comparison to his earlier life when he was a normal Bell Labs employee or a graduate student on Vannevar Bush’s differential analyzer project.)</span></p><p>In deciding to eventually leave Bell Labs for MIT in 1956, Shannon wrote the following in a letter to his supervisor, Hendrik Bode, on how he was spending his time at Labs:</p><blockquote><p>It always seemed to me that the freedom I took [at the Labs] was something of a special favor.</p></blockquote><p>He knew that the way he was spending his time at Bell Labs was not in line with its culture. At a university, he felt the freedom he took in terms of focus and hours of work would be less unusual.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp" width="374" height="514.9421265141319" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1023,&quot;width&quot;:743,&quot;resizeWidth&quot;:374,&quot;bytes&quot;:105066,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27aa1d71-dfcc-4d64-a067-e0fc4bb15110_743x1023.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Claude Shannon being Claude Shannon</figcaption></figure></div><p>The lifestyle of a researcher at Bell Labs, on the face of it, does not seem to have the level of personal freedom university professors had.</p><p>Some researchers, like Shannon, did leave to work at universities. Their research often became smaller-scale in terms of resources, but they were more free to do as they wished. A Bell researcher leaving to join a university often viewed it as a lateral move. Shannon wrote in his letter to Bode:</p><blockquote><p>With regard to personnel, I feel Bell Labs is at least equal in caliber to the general level in academic circles. In some of their specialties Bell Labs is certainly stronger.</p></blockquote><p>University life surely had freedoms that Bell didn’t, but most Bell researchers seemed rather content with the tradeoffs.</p><p>Jon Gertner’s book has a great excerpt that recounts what John Pierce thought of the freedoms of his post-Bell home, CalTech, compared to his life at Bell. The excerpt helps one see how, in its own way, the circumscribed freedom of a researcher at Bell was much freer than a professor’s — even in a less bureaucratic era of university life. Gertner writes:</p><blockquote><p><span>Pierce went back home to Caltech. For six years he had been doing research and advising graduate students, but he was finding the adjustment difficult. At Bell Labs he had spent his days doing whatever suited him. The brunt of his management work there had consisted of dropping in, unannounced, on colleagues in their labs to ask how work was progressing. But at Caltech he had to give lectures at a prearranged time and then had to spend hours explaining complex ideas to grad students. At Bell Labs, as he recalled it, the same conversation with his colleagues would usually take minutes. (Whether his colleagues actually understood his explanations, or whether he simply walked away before he could field their questions, was a matter for debate.) “I didn’t adapt well to Cal Tech,” he later admitted. “Not that there was anything wrong. For years and years I’d had it too easy. There were very few times when it mattered where I was. I had very few obligations to be at a particular place at a particular time to do a particular thing at Bell Labs.” Pierce obviously seemed to favor the Bell Labs arrangement. </span><strong>As he saw it, the work at the Labs was vital; it was required to improve the network. “People cared about everything,” he said of colleagues there. On the contrary, he noted, in the university “no one can tell a professor what to do, on the one hand. But in any deep sense, nobody cares what he’s doing, either.”</strong></p></blockquote><p>To Pierce, being genuinely needed was its own kind of freedom.</p><p><span>Karl Compton, who would eventually become President of MIT, wrote a </span><em>Science </em><a href="https://freaktakes.substack.com/p/how-karl-compton-believed-a-research" rel="">article</a><span> in 1927 dedicated to all the things a university physics department could learn from how industry R&amp;D labs worked at the time. Some of his reasons for supporting this directly address Pierce’s “nobody ever actually depends on you for anything” conundrum. Compton writes:</span></p><blockquote><p>Much can…be done to promote cooperation and coordination through actual methods of organization. This has been strikingly demonstrated in some of the big industrial research laboratories, from which the output has greatly exceeded the individual capacities of the research workers and has been achieved only by coordination of effort.</p></blockquote><p>To Compton, the project coordination of places like Bell Labs or GE Research with a clear and limited set of goals — the narrow fence we speak of — was super-additive. The minds and hands, in this setting, added up to far more than they would’ve in a university setting.</p><p>It should also be noted that when Compton did eventually take over as the head of a physics department — at Princeton — he was not able to implement any of these lessons. I’m not even sure he tried. Then, as now, changing the structure of an old university was probably a non-starter.</p><p>Luckily, newer science organizations like the ones being started today are not so tradition-laden.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png" width="364" height="250.46502835538752" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:728,&quot;width&quot;:1058,&quot;resizeWidth&quot;:364,&quot;bytes&quot;:1303806,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47c32720-dd7c-4518-8efd-2dbcf1d5d8f4_1058x728.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>John Pierce, in high school, attempting to build his own glider (via CalTech archives)</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png" width="382" height="273.47727272727275" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:756,&quot;width&quot;:1056,&quot;resizeWidth&quot;:382,&quot;bytes&quot;:1253254,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf7c43-0094-420e-bc96-01508f1827c9_1056x756.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Teenage John Pierce mid-flight testing one of his gliders. (via CalTech archives)</figcaption></figure></div><p>Before concluding, I’d like to paint a picture of what fantastic systems engineering work can look like.</p><p>To some, the concept of systems engineers keeping one eye on the reservoir of new knowledge and the other on the details of the phone system does not leave a lot of room for personal glory. Those who feel this way might liken systems engineers to “system quarterbacks” — a mostly derisive word for American football quarterbacks who simply try to facilitate the careful running of the offense instead of attempting to make any big plays themselves.</p><p>I don’t think that’s accurate. Great systems engineering work, like great scientific research, has an element of glamor to it. The story of how a trio of Bell systems engineers helped make the mobile phone system a reality should help you see why.</p><p>In January 1966, there were rumors that the FCC was thinking about granting Bell Labs access to a larger portion of the limited radio spectrum — a finite resource that the US government decides how to allocate. The range of spectrum being allocated — which twenty years earlier had been allocated to television broadcasters — could be used to make the dream of widespread telephony a reality…probably…somehow.</p><p>There were many open questions, but Bell had a kernel of an idea on how to do this. The writeup of the idea was submitted to the FCC by Bell engineers two decades prior. Dick Frenkiel and Phil Porter now found themselves in charge of making the idea a reality. Frenkiel and Porter were both systems engineers at Bell’s rural Holmdel outpost — Frenkiel a mechanical engineer by training and Porter an electrical engineer with a master's in physics.</p><p>This was far more exciting work than their previous assignments — at least for Frenkiel who was previously working on machines that could read off pre-recorded messages such as the day’s date. The duo excitedly took to the work.</p><p>To start, the major question was, “What would a major course of development even look like for this primitive technology?”</p><p>Luckily, they were not starting from scratch. The first step was to dust off Doug Ring and Rae Young’s short 1947 memo to the FCC — two decades before — in which they proposed a non-obvious, very efficient (albeit hypothetical) system in which Bell could use the radio spectrum. Instead of providing coverage to some large circle of users with a cell antenna at the center of it, Ring and Young proposed Bell lay out the system as a honeycomb of hexagons with small antennas at the point of each hexagon and neighboring hexagons could use different frequencies. This would make the limited spectrum allocated to Bell go much further than it otherwise could.</p><p><span>To give the reader an idea, the following images were pulled from</span><a href="https://web.archive.org/web/20120207062016/http://www.privateline.com/archive/Ringcellreport1947.pdf" rel=""> Ring and Young’s initial 1947 report.</a><span> These images show what the layout would look like if the FCC granted Bell either three or four frequencies.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png" width="338" height="329.8225806451613" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:726,&quot;width&quot;:744,&quot;resizeWidth&quot;:338,&quot;bytes&quot;:642091,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ab41463-fbba-4c01-a3a6-3adb6c4fb96e_744x726.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I was not able to figure out if Ring and Young were systems engineers or simply engineers doing systems engineering style work. Regardless, it was fantastic work and a great start to the project. But the most impressive aspects of the project, in my opinion, were almost entirely ahead of this point. After all, the concept of a hexagonal honeycomb is not unfamiliar to many engineers as an efficient way to cover 100% of a space with a circle-like shape that still has vertices.</p><p>The honeycomb idea was still a great idea, it just wasn’t going to win anybody any awards on its own. It was the fantastic planning, troubleshooting, and engineering development work of Bell, all started by these two systems engineers, that would turn this idea from a document of eight short pages plus an appendix into a mass-scale engineering reality.</p><p>Gertner writes on the (varied) early work of Frenkiel and Porter on this project:</p><blockquote><p>Neither Frenkiel nor Porter knew precisely how this would be achieved. “It was just two of us,” Frenkiel says. “Nothing important.”</p><p>They spent most of 1966 working on the problem — or rather, the problems. The two men covered the walls of their offices with maps and climbed on ladders in various parts of the country to count hills. There were thousands of questions they would need to answer eventually. Many of these were extremely technical, regarding reception and transmission. They talked about signal strength and interference and channel width. They knew every cell would need to be served by what they called “base station” antennas. These antennas would (1) transmit and receive the signals from the mobile phones and (2) feed those signals, by cable, into a switching center that was connected to the nationwide Bell System. Still, several big conceptual problems stood out.</p><p><span>The first was, </span><em>How large should a hexagonal cell be?</em><span> Base station antennas would be expensive. How few could they install and still have a high-functioning system?</span></p><p><span>The second was, </span><em>How could you “split” a cell?</em><span> The system would almost certainly start with just a few users—meaning big cells. But as the number of users grew, those cells would subdivide to accommodate the traffic. And more, smaller cells would require more base stations. What was the best and cheapest way?</span></p><p><span>The third was, </span><em>How would you “hand off” a call from one cell to another?</em><span> It had never been done. But it would be the system’s essential characteristic. As a mobile telephone user moved around, how could you switch the call from one antenna to another — from cell to cell, in other words — without causing great distraction to the caller?</span></p></blockquote><p>Question by question, they persisted.</p><p>A year or so after this work began a third systems engineer, Joel Engel joined the project. Engel — who had a Ph.D. in electrical engineering — was currently assigned to a project on the Bell Boy — a kind of beeper — and was excited to use his spare time on this project because the beeper was largely uninteresting to him. He noted that to get ahead at Bell Labs, “you were supposed to work on more than you were asked to work on.” Still a bit of a newcomer to Bell Labs, he was right on this point. Mervin Kelly used to often tell new hires at Labs, “You get paid for the seven and a half hours a day you put in here, but you get your raises and promotions on what you do in the other sixteen and a half hours.”&nbsp;</p><p>So, Engel joined the duo. The now-trio would huddle into conference rooms to draw hexagons on the blackboard and figure out how the technical pieces of this thing could work.</p><p>They were neither true engineers nor business visionaries. The three would surely admit to this second point. They might be more reluctant on the first point — but the proper development engineers would sometimes mention this offhand. The three did not see the true scope of what their project could become. Engel once noted:</p><blockquote><p>We were not visionaries,” Engel says of the early cellular meetings. “We were techies. If there was a vision it was primarily as a business service. Real estate agents. Doctors who made house calls.</p></blockquote><p>Even as a specialized service for particular businesses, the economics worked. They’d done the math. They’d worked that out along with approximate answers to hundreds of technical questions that needed to be thought through before significant engineering time and resources should be invested in developing the project.</p><p>The trio was young and unafraid to work hard, diving into the open-ended, behemoth of a project. The trio’s in-depth planning leveraged:</p><ol><li><p>Heavy fieldwork — to understand issues involving the terrain and weather</p></li><li><p>The more conceptual side of their degrees — to understand and extend the initial hexagonal idea</p></li><li><p>(Most of all) Their knowledge of recent developments in various engineering fields — to facilitate the storage and passing of signals</p></li></ol><p>Working out a high-level, implementable, profitable system that could locate a user moving through a honeycomb cell, monitor the strength of the call, and pass the call between channels and towers was the job of the systems engineers. The task required deep scientific, engineering, and operational knowledge of Bell’s installation capacities.</p><p>In the end, the trio successfully navigated all of these difficulties. By any measurement, their individual effects on the massive field of mobile telephony are giant — even if their names are not.</p><p>Of course, the trio had their limitations. The win was a team win and required the skills of far more than just those three.</p><p>While the project did not require any brand-new, Nobel-level academic accomplishments, it did require hundreds of engineering innovations and improvements in the understanding of many pieces of technology. That is where the great development engineers at Bell came in — people like Bill Jakes and Gerry DiPiazza. These were some of “the guys who made cellular real,” as Frenkiel once said.</p><p>Jakes was the lead engineer on the fundamental development end of things — this group often carried out less open-ended research projects on things like engineering equipment. Jakes was known to lead crews of engineers out, piling into vans with recording equipment and headphones, to study the effects of forces like obstructions and distances on transmission and reception. They drove thousands of miles, over many months, working through problem after problem related to things like why some particular wave or piece of equipment behaved a certain way in a certain kind of terrain.</p><p>As was always the case, the systems engineers were there every step of the way helping coordinate this development work. This was exceedingly necessary as it was not only people like Jakes carrying out this sort of work. It grew into a very large operation — as projects like this always do — across many Bell Labs research locations and teams.</p><p><span>(Check out the </span><a href="https://freaktakes.substack.com/p/bonus-more-details-on-how-bell-labs" rel="">bonus piece</a><span> if you’d like to know more about how this work was coordinated)</span></p><p>One of these research teams operating in parallel, as an example, was led by another great Bell development engineer, Gerry DiPiazza — who I’ve seen called an “engineer’s engineer” in several places. His group was carrying out similar work learning how to build better signal hardware in a stripped trailer home outside of Philadelphia.</p><p>DiPiazza reflected on his team and what they were working on when they took their midnight research road trips — when they could test signal strengths and tinker with hardware in a more “noiseless” environment:</p><blockquote><p><span>You had to find out, what is the noise level in a suburban environment? How far would a signal go if the antenna was at ten feet, twenty feet, fifty feet? Would it go one mile, two miles, four miles? How many antennas do you need? How do you build an antenna? What are you going to put the antenna </span><em>on</em><span>?</span></p></blockquote><p>There were a haunting number of problems like the ones DiPiazza describes, worked through by many Bell engineers over many months. And, of course, there’s never any substitute for great fundamental development and engineering work. But, thanks to the likes of Frenkiel, Porter, and Engel, one could be confident that all this money and effort was being spent on the right sub-problems. More importantly, one could be confident that no wicked, unsolvable problems seemed to be awaiting them.</p><p>The whole thing had been planned exceedingly diligently. The planners were engineers and Ph.D.s. They already had deep familiarity with the phone system and all its details. They’d brought all the relevant scientific questions to top research minds, consulted engineers who work with relevant tech every day, and coordinated with Bell field staff. This is what they did. When you’re allocating this much money and research time to something, the confidence that systems engineers can provide is invaluable.</p><p>They kept a research organization like Bell Labs working on the best problems possible and helped ensure that as few resources as possible were wasted on research that would not turn out to be usable.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png" width="554" height="197.47664835164835" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:519,&quot;width&quot;:1456,&quot;resizeWidth&quot;:554,&quot;bytes&quot;:2060792,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4520b177-ed17-4194-b00c-9f72056ef0ec_1930x688.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The tools of the trade. Equipment testing vans and trailers used by Bell’s development researchers and engineers.</figcaption></figure></div><p>In applied scientific work, great systems engineering work can rival the importance of great research minds.</p><p>It was not only Bell that stumbled upon a position like systems engineer to help facilitate its operation. GE Research and Dupont’s research arm — also applied science orgs that left some room for idle curiosity — had similar positions in their own operations that went by other names.</p><p>Frankly, it just makes sense. Any new science org attempting to pair usable applied science with some kind of fundamental research should think long and hard before they decide that a full-time systems engineer is not for them.</p><p>I’m not saying that, like Bell, a young applied science org needs as many systems engineers as basic researchers. I imagine the ratio of systems engineers to basic researchers should grow as the complexity of either the research operation or the system in which discoveries are going to be applied grows. No new science org has a research operation as large and varied as the mature Bell Labs. So, naturally, the ratio should be smaller.</p><p><em>But</em><span> many new science orgs do hope to plug into complex systems and operations. Several of the orgs I’ve spoken with have problem scopes that, more or less, pertain to the needs/problems/holes present in all of life sciences research.</span></p><p><span>Finding </span><em>a problem</em><span> in these systems is not so hard for those familiar with the systems. That’s why many researchers and engineers do not feel the need to bring in help. But finding a set of </span><em>good problems</em><span> is not finding the </span><em>best problems</em><span>. Finding the best problems is a profession in and of itself. A systems engineer is worth it when, under the right scrutiny, it might turn out that the best problem is 10X as financially valuable, does 50X the social good, or is 2X as likely to work as just some run-of-the-mill good problem.</span></p><p><span>This </span><em>can</em><span> be left to researchers. But it shouldn’t.</span></p><p>For every ten or so basic researchers in an applied science org, it feels safe to say there should be at least one systems engineer. Bell Labs had about a 1:1 ratio of basic researchers to systems engineers and a 9:1 ratio of total research, engineering, and facilities development staff to systems engineering staff.</p><p>Different orgs will have different needs. But zero is almost surely the wrong number. Even some fraction of one, say 1/4, feels like it’s playing it needlessly cavalierly with such an important piece of an applied research organization. One person who is spending a day or two a week but most of their time on other things feels like a half-measure.</p><p>Bell had a massive sample size of engineers, researchers, and problems on their side, and even they didn’t rely on pure probability — serendipity — to do their problem identification for them.</p><p>There’s a reason: great problem selection is too important to be left to chance.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.freaktakes.com/p/how-did-places-like-bell-labs-know?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.freaktakes.com/p/how-did-places-like-bell-labs-know?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><em>Thanks so much for reading! For those interested, I’ve put together a document breaking a speech from longtime Bell Labs leader, Mervin Kelly, on:</em></p><ul><li><p><em>How Bell Labs was structured</em></p></li><li><p><em>What kinds of individuals were hired for each portion of Labs</em></p></li><li><p><em>How different sections of Bell Labs were integrated</em></p></li><li><p><em>And what day-to-day life looked like for the different roles.</em></p></li></ul><p><em>It is great information for those who run their own research operations or are just hardcore hobbyists/massive Bell Labs nerds.</em></p><p><a href="https://freaktakes.substack.com/p/bonus-more-details-on-how-bell-labs" rel="">Bonus: More detail on how Bell Labs operated</a></p><p>Citation: </p><ul><li><p><span>Gilliam, Eric. “How did places like Bell Labs know how to ask the right questions?” FreakTakes Substack. 2023. </span><a href="https://freaktakes.substack.com/p/how-did-places-like-bell-labs-know" rel="">https://freaktakes.substack.com/p/how-did-places-like-bell-labs-know</a></p></li></ul></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI tools are spotting errors in research papers: inside a growing movement (281 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-025-00648-5</link>
            <guid>43295692</guid>
            <pubDate>Fri, 07 Mar 2025 22:54:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-025-00648-5">https://www.nature.com/articles/d41586-025-00648-5</a>, See on <a href="https://news.ycombinator.com/item?id=43295692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="A large stack of papers and folders with coloured tabs." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg"><figcaption><p><span>Two new AI tools check for errors in research papers including in the calculations, methodology and references.</span><span>Credit: Jose A. Bernat Bacete/Getty</span></p></figcaption></picture></figure><p>Late last year, media outlets worldwide warned that black plastic cooking utensils contained worrying levels of cancer-linked flame retardants. The risk was found to be overhyped – a mathematical error in the underlying research suggested a key chemical exceeded the safe limit when in fact it was ten times lower than the limit. Keen-eyed researchers quickly showed that an artificial intelligence (AI) model could have spotted the error in seconds.</p><p>The incident has spurred two projects that use AI to find mistakes in the scientific literature. The Black Spatula Project is an open-source AI tool that has so far analysed around 500 papers for errors. The group, which has around eight active developers and hundreds of volunteer advisers, hasn’t made the errors public yet; instead, it is approaching the affected authors directly, says Joaquin Gulloso, an independent AI researcher based in Cartagena, Colombia, who helps to coordinate the project. “Already, it’s catching many errors,” says Gulloso. “It’s a huge list. It’s just crazy.”</p><p>The other effort is called YesNoError and was inspired by the Black Spatula Project, says founder and AI entrepreneur Matt Schlicht. The initiative, funded by its own dedicated cryptocurrency, has set its sights even higher. “I thought, why don’t we go through, like, all of the papers?” says Schlicht. He says that their AI tool has analysed more than 37,000 papers in two months. Its website flags papers in which it has found flaws – many of which have yet to be verified by a human, although Schlicht says that YesNoError has a plan to eventually do so at scale.</p><p>Both projects want researchers to use their tools before submitting work to a journal, and journals to use them before they publish, the idea being to avoid mistakes, as well as fraud, making their way into the <a href="https://www.nature.com/articles/d41586-025-00026-1" data-track="click" data-label="https://www.nature.com/articles/d41586-025-00026-1" data-track-category="body text link">scientific literature</a>.</p><p>The projects have tentative support from academic sleuths who work in research integrity. But there are also concerns over the potential risks. How well the tools can spot mistakes, and whether their claims have been verified, must be made clear, says Michèle Nuijten, a researcher in metascience at Tilburg University in the Netherlands. “If you start pointing fingers at people and then it turns out that there was no mistake, there might be reputational damage,” she says.</p><p>Others add that although there are risks and the projects need to be cautious about what they claim, the goal is the right one. It is much easier to churn out shoddy papers than it is to retract them, says James Heathers, a forensic metascientist at Linnaeus University in Växjö, Sweden. As a first step, AI could be used to triage papers for further scrutiny, says Heathers, who has acted as a consultant for the Black Spatula Project. “It’s early days, but I’m supportive” of the initiatives, he adds.</p><h2>AI sleuths</h2><p>Many researchers have <a href="https://www.nature.com/articles/nature.2015.18657" data-track="click" data-label="https://www.nature.com/articles/nature.2015.18657" data-track-category="body text link">dedicated their careers</a> to spotting integrity <a href="https://www.nature.com/articles/d41586-024-03427-w" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03427-w" data-track-category="body text link">concerns in papers</a> – and <a href="https://www.nature.com/articles/d41586-024-01247-6" data-track="click" data-label="https://www.nature.com/articles/d41586-024-01247-6" data-track-category="body text link">tools to check</a> certain facets of papers already exist. But advocates hope that AI could carry out a wider range of checks in a single shot and handle a larger volume of papers.</p><p>Both the Black Spatula Project and YesNoError use large language models (LLMs) to spot a range of errors in papers, including ones of fact as well as in calculations, methodology and referencing.</p><p>The systems first extract information, including tables and images, from the papers. They then craft a set of complex instructions, known as a prompt, which tells a ‘reasoning’ model — a specialist type of LLM — what it is looking at and what kinds of error to hunt for. The model might analyse a paper multiple times, either scanning for different types of error each time, or to cross-check results. The cost of analysing each paper ranges from 15 cents to a few dollars, depending on the length of the paper and the series of prompts used.</p><p>The rate of false positives, instances when the AI claims an error where there is none, is a major hurdle. Currently, the Black Spatula Project’s system is wrong about an error around 10% of the time, says Gulloso. Each alleged error must be checked with experts in the subject, and finding them is the project’s greatest bottleneck, says Steve Newman, the software engineer and entrepreneur who founded the Black Spatula Project.</p><p>So far, Schlicht’s YesNoError team has quantified the false positives in only around 100 mathematical errors that the AI found in an initial batch of 10,000 papers. Of the 90% of authors who responded to Schlicht, all but one agreed that the error detected was valid, he says. Eventually, YesNoError is planning to work with ResearchHub, a platform which pays PhD scientists in cryptocurrency to carry out peer review. When the AI has checked a paper, YesNoError will trigger a request to verify the results, although this has not yet started.</p><h2>False positives</h2></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Letta: Letta is a framework for creating LLM services with memory (101 pts)]]></title>
            <link>https://github.com/letta-ai/letta</link>
            <guid>43294974</guid>
            <pubDate>Fri, 07 Mar 2025 21:33:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/letta-ai/letta">https://github.com/letta-ai/letta</a>, See on <a href="https://news.ycombinator.com/item?id=43294974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/Letta-logo-RGB_GreyonTransparent_cropped_small.png">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/Letta-logo-RGB_OffBlackonTransparent_cropped_small.png">
    <img alt="Letta logo" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/Letta-logo-RGB_GreyonOffBlack_cropped_small.png" width="500">
  </picture></themed-picture>
</p>
<div dir="auto">
<p dir="auto"><h2 tabindex="-1" dir="auto">Letta (previously MemGPT)</h2><a id="user-content-letta-previously-memgpt" aria-label="Permalink: Letta (previously MemGPT)" href="#letta-previously-memgpt"></a></p>
<p dir="auto"><strong>☄️ New release: Letta Agent Development Environment (<em>read more <a href="#-access-the-ade-agent-development-environment">here</a></em>) ☄️</strong></p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_light.png">
    <img alt="Letta logo" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png" width="800">
  </picture></themed-picture>
</p>
<hr>

<p dir="auto"><strong>👾 Letta</strong> is an open source framework for building stateful LLM applications. You can use Letta to build <strong>stateful agents</strong> with advanced reasoning capabilities and transparent long-term memory. The Letta framework is white box and model-agnostic.</p>
<p dir="auto"><a href="https://discord.gg/letta" rel="nofollow"><img src="https://camo.githubusercontent.com/0a4c715eec8377e6695e904295b465ab9e37b7e6f332d37ac3846e37a3f07b79/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313136313733363234333334303634303431393f6c6162656c3d446973636f7264266c6f676f3d646973636f7264266c6f676f436f6c6f723d353836354632267374796c653d666c61742d73717561726526636f6c6f723d353836354632" alt="Discord" data-canonical-src="https://img.shields.io/discord/1161736243340640419?label=Discord&amp;logo=discord&amp;logoColor=5865F2&amp;style=flat-square&amp;color=5865F2"></a>
<a href="https://twitter.com/Letta_AI" rel="nofollow"><img src="https://camo.githubusercontent.com/da01994075ea1dbd944cf0883cee51ee589f9c87889d55b3b34386d20ba770c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466f6c6c6f772d2534304c657474615f5f41492d3144413146323f7374796c653d666c61742d737175617265266c6f676f3d78266c6f676f436f6c6f723d7768697465" alt="Twitter Follow" data-canonical-src="https://img.shields.io/badge/Follow-%40Letta__AI-1DA1F2?style=flat-square&amp;logo=x&amp;logoColor=white"></a>
<a href="https://arxiv.org/abs/2310.08560" rel="nofollow"><img src="https://camo.githubusercontent.com/0b3330583e437415c64ad9a738d8fa22746ffc83971ddab5713b407915e86589/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52657365617263682d323331302e30383536302d4233314231423f6c6f676f3d6172786976267374796c653d666c61742d737175617265" alt="arxiv 2310.08560" data-canonical-src="https://img.shields.io/badge/Research-2310.08560-B31B1B?logo=arxiv&amp;style=flat-square"></a></p>
<p dir="auto"><a href="https://github.com/letta-ai/letta/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/4dbaf2f6e74c99a9f7bc9100254cb9b95d49de1c27161fa5a9a8def2256c54f8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d73696c7665723f7374796c653d666c61742d737175617265" alt="Apache 2.0" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-silver?style=flat-square"></a>
<a href="https://github.com/cpacker/MemGPT/releases"><img src="https://camo.githubusercontent.com/30b28a2d55b2469371f8905f8bb91d19a44dadb64a5ee4af76afa9059c6c724f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f637061636b65722f4d656d4750543f7374796c653d666c61742d737175617265266c6162656c3d52656c6561736526636f6c6f723d6c696d65677265656e" alt="Release" data-canonical-src="https://img.shields.io/github/v/release/cpacker/MemGPT?style=flat-square&amp;label=Release&amp;color=limegreen"></a>
<a href="https://hub.docker.com/r/letta/letta" rel="nofollow"><img src="https://camo.githubusercontent.com/e0472f1ed32798e5bd4f58a36591f199297aad9cc2cfb4d645d3079a7ec1d778/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f762f6c657474612f6c657474613f7374796c653d666c61742d737175617265266c6f676f3d646f636b6572266c6162656c3d446f636b657226636f6c6f723d306462376564" alt="Docker" data-canonical-src="https://img.shields.io/docker/v/letta/letta?style=flat-square&amp;logo=docker&amp;label=Docker&amp;color=0db7ed"></a>
<a href="https://github.com/cpacker/MemGPT"><img src="https://camo.githubusercontent.com/a9532a1704444323339a5ecfb6fb8b6a721dfca412d9a22ba58aeb67ab157837/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637061636b65722f4d656d4750543f7374796c653d666c61742d737175617265266c6f676f3d676974687562266c6162656c3d537461727326636f6c6f723d676f6c64" alt="GitHub" data-canonical-src="https://img.shields.io/github/stars/cpacker/MemGPT?style=flat-square&amp;logo=github&amp;label=Stars&amp;color=gold"></a></p>
<p dir="auto"><a href="https://trendshift.io/repositories/3612" rel="nofollow"><img src="https://camo.githubusercontent.com/8757a96b2ad45cda1a5a5ce0de645d8a50d697bf9e17483e7298200f03c82127/68747470733a2f2f7472656e6473686966742e696f2f6170692f62616467652f7265706f7369746f726965732f33363132" alt="cpacker%2FMemGPT | Trendshift" width="250" height="55" data-canonical-src="https://trendshift.io/api/badge/repositories/3612"></a></p>
</div>
<div dir="auto"><p dir="auto">Important</p><p dir="auto"><strong>Looking for MemGPT?</strong> You're in the right place!</p>
<p dir="auto">The MemGPT package and Docker image have been renamed to <code>letta</code> to clarify the distinction between MemGPT <em>agents</em> and the Letta API <em>server</em> / <em>runtime</em> that runs LLM agents as <em>services</em>. Read more about the relationship between MemGPT and Letta <a href="https://www.letta.com/blog/memgpt-and-letta" rel="nofollow">here</a>.</p>
</div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡ Quickstart</h2><a id="user-content--quickstart" aria-label="Permalink: ⚡ Quickstart" href="#-quickstart"></a></p>
<p dir="auto"><em>The recommended way to use Letta is to run use Docker. To install Docker, see <a href="https://docs.docker.com/get-docker/" rel="nofollow">Docker's installation guide</a>. For issues with installing Docker, see <a href="https://docs.docker.com/desktop/troubleshoot-and-support/troubleshoot/" rel="nofollow">Docker's troubleshooting guide</a>. You can also install Letta using <code>pip</code> (see instructions <a href="#-quickstart-pip">below</a>).</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🌖 Run the Letta server</h3><a id="user-content--run-the-letta-server" aria-label="Permalink: 🌖 Run the Letta server" href="#-run-the-letta-server"></a></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Letta agents live inside the Letta server, which persists them to a database. You can interact with the Letta agents inside your Letta server via the <a href="https://docs.letta.com/api-reference" rel="nofollow">REST API</a> + Python / Typescript SDKs, and the <a href="https://app.letta.com/" rel="nofollow">Agent Development Environment</a> (a graphical interface).</p>
</div>
<p dir="auto">The Letta server can be connected to various LLM API backends (<a href="https://docs.letta.com/models/openai" rel="nofollow">OpenAI</a>, <a href="https://docs.letta.com/models/anthropic" rel="nofollow">Anthropic</a>, <a href="https://docs.letta.com/models/vllm" rel="nofollow">vLLM</a>, <a href="https://docs.letta.com/models/ollama" rel="nofollow">Ollama</a>, etc.). To enable access to these LLM API providers, set the appropriate environment variables when you use <code>docker run</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# replace `~/.letta/.persist/pgdata` with wherever you want to store your agent data
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  -e OPENAI_API_KEY=&quot;your_openai_api_key&quot; \
  letta/letta:latest"><pre><span><span>#</span> replace `~/.letta/.persist/pgdata` with wherever you want to store your agent data</span>
docker run \
  -v <span>~</span>/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  -e OPENAI_API_KEY=<span><span>"</span>your_openai_api_key<span>"</span></span> \
  letta/letta:latest</pre></div>
<p dir="auto">If you have many different LLM API keys, you can also set up a <code>.env</code> file instead and pass that to <code>docker run</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# using a .env file instead of passing environment variables
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  letta/letta:latest"><pre><span><span>#</span> using a .env file instead of passing environment variables</span>
docker run \
  -v <span>~</span>/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  letta/letta:latest</pre></div>
<p dir="auto">Once the Letta server is running, you can access it via port <code>8283</code> (e.g. sending REST API requests to <code>http://localhost:8283/v1</code>). You can also connect your server to the Letta ADE to access and manage your agents in a web interface.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">👾 Access the ADE (Agent Development Environment)</h3><a id="user-content--access-the-ade-agent-development-environment" aria-label="Permalink: 👾 Access the ADE (Agent Development Environment)" href="#-access-the-ade-agent-development-environment"></a></p>

<p dir="auto">The Letta ADE is a graphical user interface for creating, deploying, interacting and observing with your Letta agents. For example, if you're running a Letta server to power an end-user application (such as a customer support chatbot), you can use the ADE to test, debug, and observe the agents in your server. You can also use the ADE as a general chat interface to interact with your Letta agents.</p>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_light.png">
    <img alt="ADE screenshot" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot.png" width="800">
  </picture></themed-picture>
</p>
<p dir="auto">The ADE can connect to self-hosted Letta servers (e.g. a Letta server running on your laptop), as well as the Letta Cloud service. When connected to a self-hosted / private server, the ADE uses the Letta REST API to communicate with your server.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🖥️ Connecting the ADE to your local Letta server</h4><a id="user-content-️-connecting-the-ade-to-your-local-letta-server" aria-label="Permalink: 🖥️ Connecting the ADE to your local Letta server" href="#️-connecting-the-ade-to-your-local-letta-server"></a></p>
<p dir="auto">To connect the ADE with your local Letta server, simply:</p>
<ol dir="auto">
<li>Start your Letta server (<code>docker run ...</code>)</li>
<li>Visit <a href="https://app.letta.com/" rel="nofollow">https://app.letta.com</a> and you will see "Local server" as an option in the left panel</li>
</ol>
<p dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents.png">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents_light.png">
    <img alt="Letta logo" src="https://raw.githubusercontent.com/letta-ai/letta/refs/heads/main/assets/example_ade_screenshot_agents.png" width="800">
  </picture></themed-picture>
</p>
<p dir="auto">🔐 To password protect your server, include <code>SECURE=true</code> and <code>LETTA_SERVER_PASSWORD=yourpassword</code> in your <code>docker run</code> command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# If LETTA_SERVER_PASSWORD isn't set, the server will autogenerate a password
docker run \
  -v ~/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  -e SECURE=true \
  -e LETTA_SERVER_PASSWORD=yourpassword \
  letta/letta:latest"><pre><span><span>#</span> If LETTA_SERVER_PASSWORD isn't set, the server will autogenerate a password</span>
docker run \
  -v <span>~</span>/.letta/.persist/pgdata:/var/lib/postgresql/data \
  -p 8283:8283 \
  --env-file .env \
  -e SECURE=true \
  -e LETTA_SERVER_PASSWORD=yourpassword \
  letta/letta:latest</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌐 Connecting the ADE to an external (self-hosted) Letta server</h4><a id="user-content--connecting-the-ade-to-an-external-self-hosted-letta-server" aria-label="Permalink: 🌐 Connecting the ADE to an external (self-hosted) Letta server" href="#-connecting-the-ade-to-an-external-self-hosted-letta-server"></a></p>
<p dir="auto">If your Letta server isn't running on <code>localhost</code> (for example, you deployed it on an external service like EC2):</p>
<ol dir="auto">
<li>Click "Add remote server"</li>
<li>Enter your desired server name, the IP address of the server, and the server password (if set)</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧑‍🚀 Frequently asked questions (FAQ)</h2><a id="user-content--frequently-asked-questions-faq" aria-label="Permalink: 🧑‍🚀 Frequently asked questions (FAQ)" href="#-frequently-asked-questions-faq"></a></p>
<blockquote>
<p dir="auto"><em>"Do I need to install Docker to use Letta?"</em></p>
</blockquote>
<p dir="auto">No, you can install Letta using <code>pip</code> (via <code>pip install -U letta</code>), as well as from source (via <code>poetry install</code>). See instructions below.</p>
<blockquote>
<p dir="auto"><em>"What's the difference between installing with <code>pip</code> vs <code>Docker</code>?"</em></p>
</blockquote>
<p dir="auto">Letta gives your agents persistence (they live indefinitely) by storing all your agent data in a database. Letta is designed to be used with a <a href="https://en.wikipedia.org/wiki/PostgreSQL" rel="nofollow">PostgreSQL</a> (the world's most popular database), however, it is not possible to install PostgreSQL via <code>pip</code>, so the <code>pip</code> install of Letta defaults to using <a href="https://www.sqlite.org/" rel="nofollow">SQLite</a>. If you have a PostgreSQL instance running on your own computer, you can still connect Letta (installed via <code>pip</code>) to PostgreSQL by setting the environment variable <code>LETTA_PG_URI</code>.</p>
<p dir="auto"><strong>Database migrations are not officially supported for Letta when using SQLite</strong>, so if you would like to ensure that you're able to upgrade to the latest Letta version and migrate your Letta agents data, make sure that you're using PostgreSQL as your Letta database backend. Full compatability table below:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Installation method</th>
<th>Start server command</th>
<th>Database backend</th>
<th>Data migrations supported?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>pip install letta</code></td>
<td><code>letta server</code></td>
<td>SQLite</td>
<td>❌</td>
</tr>
<tr>
<td><code>pip install letta</code></td>
<td><code>export LETTA_PG_URI=...</code> + <code>letta server</code></td>
<td>PostgreSQL</td>
<td>✅</td>
</tr>
<tr>
<td><em><a href="https://www.docker.com/get-started/" rel="nofollow">Install Docker</a></em></td>
<td><code>docker run ...</code> (<a href="#-run-the-letta-server">full command</a>)</td>
<td>PostgreSQL</td>
<td>✅</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><em>"How do I use the ADE locally?"</em></p>
</blockquote>
<p dir="auto">To connect the ADE to your local Letta server, simply run your Letta server (make sure you can access <code>localhost:8283</code>) and go to <a href="https://app.letta.com/" rel="nofollow">https://app.letta.com</a>. If you would like to use the old version of the ADE (that runs on <code>localhost</code>), downgrade to Letta version <code>&lt;=0.5.0</code>.</p>
<blockquote>
<p dir="auto"><em>"If I connect the ADE to my local server, does my agent data get uploaded to letta.com?"</em></p>
</blockquote>
<p dir="auto">No, the data in your Letta server database stays on your machine. The Letta ADE web application simply connects to your local Letta server (via the REST API) and provides a graphical interface on top of it to visualize your local Letta data in your browser's local state.</p>
<blockquote>
<p dir="auto"><em>"Do I have to use your ADE? Can I build my own?"</em></p>
</blockquote>
<p dir="auto">The ADE is built on top of the (fully open source) Letta server and Letta Agents API. You can build your own application like the ADE on top of the REST API (view the documention <a href="https://docs.letta.com/api-reference" rel="nofollow">here</a>).</p>
<blockquote>
<p dir="auto"><em>"Can I interact with Letta agents via the CLI?"</em></p>
</blockquote>
<p dir="auto">The recommended way to use Letta is via the REST API and ADE, however you can also access your agents via the CLI.</p>
<details>
<summary>View instructions for running the Letta CLI</summary>
<p dir="auto">You can chat with your agents via the Letta CLI tool (<code>letta run</code>). If you have a Letta Docker container running, you can use <code>docker exec</code> to run the Letta CLI inside the container:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# replace `<letta_container_id>` with the ID of your Letta container, found via `docker ps`
docker exec -it <letta_container_id> letta run"><pre><span><span>#</span> replace `&lt;letta_container_id&gt;` with the ID of your Letta container, found via `docker ps`</span>
docker <span>exec</span> -it <span>&lt;</span>letta_container_id<span>&gt;</span> letta run</pre></div>
<p dir="auto">You can also use <code>docker ps</code> within the command to automatically find the ID of your Letta container:</p>
<div data-snippet-clipboard-copy-content="docker exec -it $(docker ps -q -f ancestor=letta/letta) letta run"><pre><code>docker exec -it $(docker ps -q -f ancestor=letta/letta) letta run
</code></pre></div>
<p dir="auto">In the CLI tool, you'll be able to create new agents, or load existing agents:</p>
<div data-snippet-clipboard-copy-content="🧬 Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
->  🤖 Using persona profile: 'sam_pov'
->  🧑 Using human profile: 'basic'
->  🛠️  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

🎉 Created new agent 'InspiringSpinach'

Hit enter to begin (will request first Letta message)

💭 User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
🤖 Hello, Chad. It's nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you'd like to discuss today?

> Enter your message: my name is Brad, not Chad...

💭 A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
⚡🧠 [function] updating memory with core_memory_replace
         First name: Chad
        → First name: Brad
💭 Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
🤖 I apologize for the oversight, Brad. Let's restart. It's a pleasure to meet you, Brad. Is there a specific topic you'd like to discuss today?

> Enter your message:"><pre><code>🧬 Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
-&gt;  🤖 Using persona profile: 'sam_pov'
-&gt;  🧑 Using human profile: 'basic'
-&gt;  🛠️  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

🎉 Created new agent 'InspiringSpinach'

Hit enter to begin (will request first Letta message)

💭 User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
🤖 Hello, Chad. It's nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you'd like to discuss today?

&gt; Enter your message: my name is Brad, not Chad...

💭 A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
⚡🧠 [function] updating memory with core_memory_replace
         First name: Chad
        → First name: Brad
💭 Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
🤖 I apologize for the oversight, Brad. Let's restart. It's a pleasure to meet you, Brad. Is there a specific topic you'd like to discuss today?

&gt; Enter your message:
</code></pre></div>
</details>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡ Quickstart (pip)</h2><a id="user-content--quickstart-pip" aria-label="Permalink: ⚡ Quickstart (pip)" href="#-quickstart-pip"></a></p>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto"><strong>Database migrations are not officially supported with <code>SQLite</code></strong></p>
<p dir="auto">When you install Letta with <code>pip</code>, the default database backend is <code>SQLite</code> (you can still use an external <code>postgres</code> service with your <code>pip</code> install of Letta by setting <code>LETTA_PG_URI</code>).</p>
<p dir="auto">We do not officially support migrations between Letta versions with <code>SQLite</code> backends, only <code>postgres</code>. If you would like to keep your agent data across multiple Letta versions we highly recommend using the Docker install method which is the easiest way to use <code>postgres</code> with Letta.</p>
</div>
<details>
<summary>View instructions for installing with pip</summary>
<p dir="auto">You can also install Letta with <code>pip</code>, which will default to using <code>SQLite</code> for the database backends (whereas Docker will default to using <code>postgres</code>).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 1 - Install Letta using <code>pip</code></h3><a id="user-content-step-1---install-letta-using-pip" aria-label="Permalink: Step 1 - Install Letta using pip" href="#step-1---install-letta-using-pip"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Step 2 - Set your environment variables for your chosen LLM / embedding providers</h3><a id="user-content-step-2---set-your-environment-variables-for-your-chosen-llm--embedding-providers" aria-label="Permalink: Step 2 - Set your environment variables for your chosen LLM / embedding providers" href="#step-2---set-your-environment-variables-for-your-chosen-llm--embedding-providers"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=sk-..."><pre><span>export</span> OPENAI_API_KEY=sk-...</pre></div>
<p dir="auto">For Ollama (see our full <a href="https://docs.letta.com/install" rel="nofollow">documentation</a> for examples of how to set up various providers):</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OLLAMA_BASE_URL=http://localhost:11434"><pre><span>export</span> OLLAMA_BASE_URL=http://localhost:11434</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 3 - Run the Letta CLI</h3><a id="user-content-step-3---run-the-letta-cli" aria-label="Permalink: Step 3 - Run the Letta CLI" href="#step-3---run-the-letta-cli"></a></p>
<p dir="auto">You can create agents and chat with them via the Letta CLI tool (<code>letta run</code>):</p>

<div data-snippet-clipboard-copy-content="🧬 Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
->  🤖 Using persona profile: 'sam_pov'
->  🧑 Using human profile: 'basic'
->  🛠️  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

🎉 Created new agent 'InspiringSpinach'

Hit enter to begin (will request first Letta message)

💭 User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
🤖 Hello, Chad. It's nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you'd like to discuss today?

> Enter your message: my name is Brad, not Chad...

💭 A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
⚡🧠 [function] updating memory with core_memory_replace
         First name: Chad
        → First name: Brad
💭 Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
🤖 I apologize for the oversight, Brad. Let's restart. It's a pleasure to meet you, Brad. Is there a specific topic you'd like to discuss today?

> Enter your message:"><pre><code>🧬 Creating new agent...
? Select LLM model: letta-free [type=openai] [ip=https://inference.memgpt.ai]
? Select embedding model: letta-free [type=hugging-face] [ip=https://embeddings.memgpt.ai]
-&gt;  🤖 Using persona profile: 'sam_pov'
-&gt;  🧑 Using human profile: 'basic'
-&gt;  🛠️  8 tools: send_message, pause_heartbeats, conversation_search, conversation_search_date, archival_memory_insert, archival_memory_search, core_memory_append, core_memory_replace

🎉 Created new agent 'InspiringSpinach'

Hit enter to begin (will request first Letta message)

💭 User engaged. Recognize as Chad. Acknowledge presence and establish connection. Explore interests and engage in meaningful discourse.
🤖 Hello, Chad. It's nice to meet you. I am keen on learning and exploring new ideas and concepts. Is there a specific topic you'd like to discuss today?

&gt; Enter your message: my name is Brad, not Chad...

💭 A discrepancy in identity. Reflect this change in core memory. Apologize for the oversight, and rectify the error.
⚡🧠 [function] updating memory with core_memory_replace
         First name: Chad
        → First name: Brad
💭 Apologize for the mistake in recognizing his name, and begin the conversation anew, addressing him by the correct name this time.
🤖 I apologize for the oversight, Brad. Let's restart. It's a pleasure to meet you, Brad. Is there a specific topic you'd like to discuss today?

&gt; Enter your message:
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 4 - Run the Letta server</h3><a id="user-content-step-4---run-the-letta-server" aria-label="Permalink: Step 4 - Run the Letta server" href="#step-4---run-the-letta-server"></a></p>
<p dir="auto">You can start the Letta API server with <code>letta server</code> (see the full API reference <a href="https://docs.letta.com/api-reference" rel="nofollow">here</a>):</p>

<div data-snippet-clipboard-copy-content="Initializing database...
Running: uvicorn server:app --host localhost --port 8283
INFO:     Started server process [47750]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:8283 (Press CTRL+C to quit)"><pre><code>Initializing database...
Running: uvicorn server:app --host localhost --port 8283
INFO:     Started server process [47750]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:8283 (Press CTRL+C to quit)
</code></pre></div>
</details>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤗 How to contribute</h2><a id="user-content--how-to-contribute" aria-label="Permalink: 🤗 How to contribute" href="#-how-to-contribute"></a></p>
<p dir="auto">Letta is an open source project built by over a hundred contributors. There are many ways to get involved in the Letta OSS project!</p>
<ul dir="auto">
<li><strong>Contribute to the project</strong>: Interested in contributing? Start by reading our <a href="https://github.com/cpacker/MemGPT/tree/main/CONTRIBUTING.md">Contribution Guidelines</a>.</li>
<li><strong>Ask a question</strong>: Join our community on <a href="https://discord.gg/letta" rel="nofollow">Discord</a> and direct your questions to the <code>#support</code> channel.</li>
<li><strong>Report issues or suggest features</strong>: Have an issue or a feature request? Please submit them through our <a href="https://github.com/cpacker/MemGPT/issues">GitHub Issues page</a>.</li>
<li><strong>Explore the roadmap</strong>: Curious about future developments? View and comment on our <a href="https://github.com/cpacker/MemGPT/issues/1533" data-hovercard-type="issue" data-hovercard-url="/letta-ai/letta/issues/1533/hovercard">project roadmap</a>.</li>
<li><strong>Join community events</strong>: Stay updated with the <a href="https://lu.ma/berkeley-llm-meetup" rel="nofollow">event calendar</a> or follow our <a href="https://twitter.com/Letta_AI" rel="nofollow">Twitter account</a>.</li>
</ul>
<hr>
<p dir="auto"><em><strong>Legal notices</strong>: By using Letta and related Letta services (such as the Letta endpoint or hosted service), you are agreeing to our <a href="https://www.letta.com/privacy-policy" rel="nofollow">privacy policy</a> and <a href="https://www.letta.com/terms-of-service" rel="nofollow">terms of service</a>.</em></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Polars Cloud: The Distributed Cloud Architecture to Run Polars Anywhere (243 pts)]]></title>
            <link>https://pola.rs/posts/polars-cloud-what-we-are-building/</link>
            <guid>43294566</guid>
            <pubDate>Fri, 07 Mar 2025 20:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pola.rs/posts/polars-cloud-what-we-are-building/">https://pola.rs/posts/polars-cloud-what-we-are-building/</a>, See on <a href="https://news.ycombinator.com/item?id=43294566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <h2 id="1-the-dataframe-scale-gap">1. The DataFrame scale gap</h2>
<p>When I started working on Polars, I was surprised how much DataFrame implementations differed from SQL and databases. SQL could run anywhere <sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>. It could run embedded, on a client server model, or on full OLAP data warehouses.</p>
<p>Whereas for dataframes, the API was different per use case and performance was drastically lacking behind SQL solutions. Locally, pandas was dominant, and remotely/distributed, it was PySpark. For end-users, pandas was very easy to get up and running, but it seems to have ignored what databases have learned over decades, there was no query optimization, poor data type implementation, many needless materializations, it offloaded memory handling to NumPy, and a few other design decisions that led to poor scaling and inconsistent behavior. PySpark was much closer to databases, it follows the relational model, has optimization, a distributed query engine and scaled properly. However PySpark is written in Scala, requires the JVM to run locally, has very poor unpythonic UX (java backtraces for one), and is very sensitive to OOMs. It also was designed for commodity hardware a decade ago and row-based OLAP execution has proven to be suboptimal.</p>
<p>With Polars we want to unify those two worlds under <strong>one flexible DataFrame API, backed by high performant compute</strong>. Our initial (and achieved) goal was offering an alternative for pandas with a flexible API that does enable query optimization, and parallel streaming execution. Second we want to make running DataFrame code remotely easy. Just like SQL, a Polars <code>LazyFrame</code> is a description of a query, and it can be sent to a server to be executed remotely. This should be dead easy. In the cloud dominant era, you should not be limited to the boundaries of your laptop.</p>
<h2 id="2-run-polars-everywhere">2. Run Polars everywhere</h2>
<p>Our goal is to enable <strong>Scalable data processing with all the flexibility and expressiveness of Polars’ API</strong>.
We are working on two things; <strong>Polars Cloud</strong> and a completely novel <strong>Streaming Engine</strong> design. We will explain more about the streaming engine in later posts; Today we want to share what are building with Polars Cloud.</p>
<p>The features we will offer:</p>
<ul>
<li>Distributed Polars; one API for all high performant DataFrame needs;</li>
<li>Serverless compute;</li>
<li>Configurable hardware, both GPU and CPU;</li>
<li>Diagonal scaling; scaling both horizontally and vertically;</li>
<li>Bring your own cloud; AWS, Azure and GCP;</li>
<li>On premise licensing;</li>
<li>Fault tolerance;</li>
<li>Data lineage;</li>
<li>Observability;</li>
</ul>
<p>It will be very seamless to spin up hardware and run Polars queries remotely, either in batch mode for production ETL jobs, or interactively doing data exploration. The rest of the post, we want to explore this through a few code examples.</p>
<h2 id="3-a-remote-query">3. A remote query.</h2>
<p>It’s important for us that starting a remote query feels native and seamless for the end user. Running a query remotely will be available from within Polars’ native API.</p>
<p>Note that we are agnostic of where you call this code. You can start a remote query from a notebook on your machine, an Airflow dag, an AWS Lambda, your server etc. The compute needed for data-processing is often much higher than the compute needed for orchestration in Airflow or Prefect. By not constraining you to a platform where you need to run your queries, we give you the flexibility to embed Polars Cloud in any environment.</p>
<p>In the query below we start our first query.</p>
<pre tabindex="0" data-language="python"><code><span><span>import</span><span> polars </span><span>as</span><span> pl</span></span>
<span><span>import</span><span> polars_cloud </span><span>as</span><span> pc</span></span>
<span><span>from</span><span> datetime </span><span>import</span><span> date</span></span>
<span></span>
<span><span>query </span><span>=</span><span> (pl</span><span>.</span><span>scan_parquet</span><span>(</span><span>"s3://my-dataset/"</span><span>)</span></span>
<span><span>   .</span><span>filter</span><span>(pl.</span><span>col</span><span>(</span><span>"l_shipdate"</span><span>) </span><span>&lt;=</span><span> date</span><span>(</span><span>1998</span><span>, </span><span>9</span><span>, </span><span>2</span><span>))</span></span>
<span><span>      .</span><span>group_by</span><span>(</span><span>"l_returnflag"</span><span>, </span><span>"l_linestatus"</span><span>)</span></span>
<span><span>       .</span><span>agg</span><span>(</span></span>
<span><span>            avg_price</span><span>=</span><span>pl.</span><span>mean</span><span>(</span><span>"l_extendedprice"</span><span>),</span></span>
<span><span>            avg_disc</span><span>=</span><span>pl.</span><span>mean</span><span>(</span><span>"l_discount"</span><span>),</span></span>
<span><span>            count_order</span><span>=</span><span>pl.</span><span>len</span><span>()</span></span>
<span><span>        )</span></span>
<span><span> )</span></span>
<span></span>
<span><span>in_progress </span><span>=</span><span> (</span></span>
<span><span>    query</span></span>
<span><span>    .</span><span>remote</span><span>(pc.</span><span>ComputeContext</span><span>(cpus</span><span>=</span><span>16</span><span>, memory</span><span>=</span><span>64</span><span>))</span></span>
<span><span>    .</span><span>sink_parquet</span><span>(</span><span>"s3://my-dst/"</span><span>)</span></span>
<span><span>)</span></span>
<span></span></code></pre>
<p>We create a <code>LazyFrame</code> and instead of collecting it locally, we can call <code>.remote()</code>, which tells Polars to run this query remotely with the given <code>pc.ComputeContext</code>. The <code>ComputeContext</code>
tells use what kind of hardware to spin up, and the <code>sink_parquet</code> call fires the query. We’ll get back an <code>InProgressQueryRemote</code> object indicating that our query runs remotely. In the mean time we can asynchronously
work on other stuff, or we can block and await the result. Finally, the <code>InProgressQueryRemote</code> can be turned into a <code>LazyFrame</code> again to continue working on the result of the remote query. Let’s do that.</p>
<pre tabindex="0" data-language="python"><code><span><span>result </span><span>=</span><span> in_progress</span><span>.</span><span>await_result</span><span>()</span></span>
<span><span>print</span><span>(result)</span></span>
<span></span>
<span><span>new_lf</span><span>:</span><span> pl</span><span>.</span><span>LazyFrame </span><span>=</span><span> result</span><span>.</span><span>lazy</span><span>()</span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="plaintext"><code><span><span>shape: (4, 5)</span></span>
<span><span>┌──────────────┬──────────────┬──────────────┬──────────┬─────────────┐</span></span>
<span><span>│ l_returnflag ┆ l_linestatus ┆ avg_price    ┆ avg_disc ┆ count_order │</span></span>
<span><span>│ ---          ┆ ---          ┆ ---          ┆ ---      ┆ ---         │</span></span>
<span><span>│ str          ┆ str          ┆ f64          ┆ f64      ┆ u32         │</span></span>
<span><span>╞══════════════╪══════════════╪══════════════╪══════════╪═════════════╡</span></span>
<span><span>│ A            ┆ F            ┆ 38273.129735 ┆ 0.049985 ┆ 1478493     │</span></span>
<span><span>│ N            ┆ O            ┆ 38249.117989 ┆ 0.049997 ┆ 2920374     │</span></span>
<span><span>│ R            ┆ F            ┆ 38250.854626 ┆ 0.050009 ┆ 1478870     │</span></span>
<span><span>│ N            ┆ F            ┆ 38284.467761 ┆ 0.050093 ┆ 38854       │</span></span>
<span><span>└──────────────┴──────────────┴──────────────┴──────────┴─────────────┘</span></span>
<span><span></span></span></code></pre>
<h2 id="4-scaling-strategies">4. Scaling strategies</h2>
<p>Polars can run these queries remotely differently than you would expect for Python libraries. We don’t require serialization via Pickle because we build a DSL tree natively in Rust. This DSL is send to the server to be analyzed and run.
Cluster side, we have built a distributed scheduler-worker architecture in Rust that can analyze these queries, runs an adapted Polars optimizer and, depending on the query, comes up with a physical plan that scales horizontally or vertically.
Polars is very strong in vertical scaling and we recognize that many queries will be most cost effective on a single machine. It however, is also very common that queries start with a set of operations that reduce the dataset size (think of group-by’s and filters).
When querying large data sizes from cloud storage, you are bound to the IO limit of a single node. With horizontal scaling we can drastically increase those download limits and after the size reductions finish off on a single machine.
We are building an architecture that shines in both horizontally and vertically scaling, dubbed diagonal scaling, choosing the optimal strategy dynamically.</p>
<h2 id="5-engines-cpu-and-gpu">5. Engines (CPU and GPU)</h2>
<p>Besides multiple scaling strategies, we are committed to run open source Polars as our engine on the worker nodes. This ensures our incentives are aligned and that the semantics of Polars cloud will not deviate. Polars will allow you to run all engines. That means
there will also be <strong>GPU</strong> support. You will be able to spin up a machine with a high end GPU and connect locally in interactive mode. Our new <strong>Streaming Engine</strong> has an <strong>out-of-core</strong> design, and will be able to spill to disk in an efficient manner. Together with distributed queries, this will truly scale Polars to any dataset. We already have the first preliminary results and on the PDS-H<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> Benchmark and they look very promising. We already beat our in-memory engine by a factor of ~3 (and there are still a lot of performance opportunities) and it goes without saying that the memory charachteristics are much better.</p>
<h2 id="6-distributions-strategies">6. Distributions strategies</h2>
<h3 id="distributed">Distributed</h3>
<p>As mentioned, you can spin up a cluster of machines. This allows you to run a query in distributed mode.</p>
<pre tabindex="0" data-language="python"><code><span><span>lf</span><span>:</span><span> LazyFrame</span></span>
<span></span>
<span><span>result </span><span>=</span><span> (</span></span>
<span><span>      lf</span><span>.</span><span>remote</span><span>()</span></span>
<span><span>      .</span><span>distributed</span><span>()</span></span>
<span><span>      .</span><span>collect</span><span>()</span></span>
<span><span>      .</span><span>await_result</span><span>()</span></span>
<span><span>)</span></span>
<span></span></code></pre>
<p>The semantics of a distributed query don’t change, it only tells Polars cloud it can use multiple nodes to finish the query if it needs to. Not every Polars operation is supported yet, but this will still be beneficial as distributed queries can reduce the dataset size until a single node can finish it on the streaming engine. Operations that are currently supported are all streamable operations, such as <code>filter</code>, <code>explode</code>, <code>map</code>, and partitionable operations such as <code>group-by</code> and <code>equi-joins</code>.</p>
<h3 id="partitioned">Partitioned</h3>
<p>Furthermore, we have partitioned queries, which partitions the query on a given <code>key</code> on the available nodes in the cluster. This will semantically change the query as you will get a result for every unique key, meaning that a single query will have <code>n_unique(key)</code> results:</p>
<pre tabindex="0" data-language="python"><code><span><span>lf</span><span>:</span><span> LazyFrame</span></span>
<span></span>
<span><span>result </span><span>=</span><span> (</span></span>
<span><span>      lf</span><span>.</span><span>remote</span><span>(pc.</span><span>ComputeContext</span><span>(cpus</span><span>=</span><span>16</span><span>, memory</span><span>=</span><span>64</span><span>, cluster_size</span><span>=</span><span>32</span><span>))</span></span>
<span><span>      .</span><span>partition_by</span><span>(</span><span>"day"</span><span>)</span></span>
<span><span>      .</span><span>collect</span><span>()</span></span>
<span><span>      .</span><span>await_result</span><span>()</span></span>
<span><span>)</span></span>
<span></span></code></pre>
<p>This can be very useful for timeseries where you want to run a query at a given time interval, e.g. daily, weekly, monthly etc.</p>
<h3 id="spawn-many-queries-in-parallel">Spawn many queries in parallel</h3>
<p>Finally we make it easy to run many queries remotely. We provide a function <code>spawn_many</code> which takes a list of <code>LazyFrame</code>’s, which will run on the cluster.</p>
<pre tabindex="0" data-language="python"><code><span><span>import</span><span> polars_cloud </span><span>as</span><span> pc</span></span>
<span></span>
<span><span>lazy_frames</span><span>:</span><span> list</span><span>[</span><span>LazyFrame</span><span>]</span></span>
<span><span>results </span><span>=</span><span> pc</span><span>.</span><span>spawn_many</span><span>(lazy_frames, partition_by</span><span>=</span><span>"day"</span><span>, dst</span><span>=</span><span>"s3://result_dst/"</span><span>).</span><span>await_result</span><span>()</span></span>
<span></span></code></pre>
<h2 id="7-fault-tolerance">7. Fault tolerance</h2>
<p>Once you start dealing with multiple workers and hardware, things will fail, disks will drop, machines will disconnect etc. This has to be completely hidden from the user and this complexity will be handled by us. We will reschedule tasks if workers failed and ensure a query finishes independent of hardware failure.</p>
<h2 id="apply-for-early-access">Apply for early access</h2>
<p>End of this month we are onboarding our first clients. Soon after we want to scale up and invite individuals that have their cloud stack on AWS. After that we will work on other cloud vendors and Kubernetes. Do you want have early access, reach out to us!</p>

<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>I don’t mean that you can swap backends easily. Different solutions have slightly different semantics, in ordering, null handling, supported functions, data-types, etc. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>This is a benchmark derived from TPC-H, but these results are not comparable to TPC-H results. See more <a href="https://github.com/pola-rs/polars-benchmark">details here</a>. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section> </div></div>]]></description>
        </item>
    </channel>
</rss>